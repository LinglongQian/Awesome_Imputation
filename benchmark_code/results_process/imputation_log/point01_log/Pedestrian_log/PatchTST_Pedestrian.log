2024-06-01 21:19:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:19:23 [INFO]: Using the given device: cuda:0
2024-06-01 21:19:23 [INFO]: Model files will be saved to results_point_rate01/PatchTST_Pedestrian/round_0/20240601_T211923
2024-06-01 21:19:23 [INFO]: Tensorboard file will be saved to results_point_rate01/PatchTST_Pedestrian/round_0/20240601_T211923/tensorboard
2024-06-01 21:19:23 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 106,905
2024-06-01 21:19:24 [INFO]: Epoch 001 - training loss: 1.1674, validation loss: 0.2826
2024-06-01 21:19:24 [INFO]: Epoch 002 - training loss: 0.7388, validation loss: 0.1497
2024-06-01 21:19:24 [INFO]: Epoch 003 - training loss: 0.6165, validation loss: 0.0879
2024-06-01 21:19:24 [INFO]: Epoch 004 - training loss: 0.5494, validation loss: 0.0709
2024-06-01 21:19:24 [INFO]: Epoch 005 - training loss: 0.5214, validation loss: 0.0632
2024-06-01 21:19:24 [INFO]: Epoch 006 - training loss: 0.5010, validation loss: 0.0537
2024-06-01 21:19:25 [INFO]: Epoch 007 - training loss: 0.4773, validation loss: 0.0647
2024-06-01 21:19:25 [INFO]: Epoch 008 - training loss: 0.4573, validation loss: 0.0510
2024-06-01 21:19:25 [INFO]: Epoch 009 - training loss: 0.4570, validation loss: 0.0514
2024-06-01 21:19:25 [INFO]: Epoch 010 - training loss: 0.4436, validation loss: 0.0493
2024-06-01 21:19:25 [INFO]: Epoch 011 - training loss: 0.4255, validation loss: 0.0488
2024-06-01 21:19:25 [INFO]: Epoch 012 - training loss: 0.4092, validation loss: 0.0467
2024-06-01 21:19:26 [INFO]: Epoch 013 - training loss: 0.4152, validation loss: 0.0511
2024-06-01 21:19:26 [INFO]: Epoch 014 - training loss: 0.4083, validation loss: 0.0444
2024-06-01 21:19:26 [INFO]: Epoch 015 - training loss: 0.3926, validation loss: 0.0430
2024-06-01 21:19:26 [INFO]: Epoch 016 - training loss: 0.3961, validation loss: 0.0410
2024-06-01 21:19:26 [INFO]: Epoch 017 - training loss: 0.3787, validation loss: 0.0422
2024-06-01 21:19:26 [INFO]: Epoch 018 - training loss: 0.3792, validation loss: 0.0428
2024-06-01 21:19:27 [INFO]: Epoch 019 - training loss: 0.3733, validation loss: 0.0449
2024-06-01 21:19:27 [INFO]: Epoch 020 - training loss: 0.3691, validation loss: 0.0429
2024-06-01 21:19:27 [INFO]: Epoch 021 - training loss: 0.3682, validation loss: 0.0421
2024-06-01 21:19:27 [INFO]: Epoch 022 - training loss: 0.3628, validation loss: 0.0401
2024-06-01 21:19:27 [INFO]: Epoch 023 - training loss: 0.3563, validation loss: 0.0392
2024-06-01 21:19:27 [INFO]: Epoch 024 - training loss: 0.3429, validation loss: 0.0382
2024-06-01 21:19:28 [INFO]: Epoch 025 - training loss: 0.3460, validation loss: 0.0391
2024-06-01 21:19:28 [INFO]: Epoch 026 - training loss: 0.3406, validation loss: 0.0377
2024-06-01 21:19:28 [INFO]: Epoch 027 - training loss: 0.3459, validation loss: 0.0371
2024-06-01 21:19:28 [INFO]: Epoch 028 - training loss: 0.3472, validation loss: 0.0398
2024-06-01 21:19:28 [INFO]: Epoch 029 - training loss: 0.3428, validation loss: 0.0356
2024-06-01 21:19:28 [INFO]: Epoch 030 - training loss: 0.3331, validation loss: 0.0379
2024-06-01 21:19:29 [INFO]: Epoch 031 - training loss: 0.3333, validation loss: 0.0372
2024-06-01 21:19:29 [INFO]: Epoch 032 - training loss: 0.3251, validation loss: 0.0359
2024-06-01 21:19:29 [INFO]: Epoch 033 - training loss: 0.3199, validation loss: 0.0349
2024-06-01 21:19:29 [INFO]: Epoch 034 - training loss: 0.3259, validation loss: 0.0372
2024-06-01 21:19:29 [INFO]: Epoch 035 - training loss: 0.3223, validation loss: 0.0385
2024-06-01 21:19:29 [INFO]: Epoch 036 - training loss: 0.3150, validation loss: 0.0370
2024-06-01 21:19:30 [INFO]: Epoch 037 - training loss: 0.3163, validation loss: 0.0358
2024-06-01 21:19:30 [INFO]: Epoch 038 - training loss: 0.3114, validation loss: 0.0340
2024-06-01 21:19:30 [INFO]: Epoch 039 - training loss: 0.3152, validation loss: 0.0340
2024-06-01 21:19:30 [INFO]: Epoch 040 - training loss: 0.3075, validation loss: 0.0336
2024-06-01 21:19:30 [INFO]: Epoch 041 - training loss: 0.3086, validation loss: 0.0348
2024-06-01 21:19:30 [INFO]: Epoch 042 - training loss: 0.3012, validation loss: 0.0346
2024-06-01 21:19:31 [INFO]: Epoch 043 - training loss: 0.3046, validation loss: 0.0322
2024-06-01 21:19:31 [INFO]: Epoch 044 - training loss: 0.2931, validation loss: 0.0327
2024-06-01 21:19:31 [INFO]: Epoch 045 - training loss: 0.3018, validation loss: 0.0337
2024-06-01 21:19:31 [INFO]: Epoch 046 - training loss: 0.2961, validation loss: 0.0321
2024-06-01 21:19:31 [INFO]: Epoch 047 - training loss: 0.3014, validation loss: 0.0377
2024-06-01 21:19:31 [INFO]: Epoch 048 - training loss: 0.2935, validation loss: 0.0315
2024-06-01 21:19:32 [INFO]: Epoch 049 - training loss: 0.2889, validation loss: 0.0329
2024-06-01 21:19:32 [INFO]: Epoch 050 - training loss: 0.2901, validation loss: 0.0323
2024-06-01 21:19:32 [INFO]: Epoch 051 - training loss: 0.2792, validation loss: 0.0323
2024-06-01 21:19:32 [INFO]: Epoch 052 - training loss: 0.2886, validation loss: 0.0323
2024-06-01 21:19:32 [INFO]: Epoch 053 - training loss: 0.2894, validation loss: 0.0332
2024-06-01 21:19:32 [INFO]: Epoch 054 - training loss: 0.2908, validation loss: 0.0331
2024-06-01 21:19:33 [INFO]: Epoch 055 - training loss: 0.2838, validation loss: 0.0320
2024-06-01 21:19:33 [INFO]: Epoch 056 - training loss: 0.2782, validation loss: 0.0298
2024-06-01 21:19:33 [INFO]: Epoch 057 - training loss: 0.2777, validation loss: 0.0314
2024-06-01 21:19:33 [INFO]: Epoch 058 - training loss: 0.2825, validation loss: 0.0379
2024-06-01 21:19:33 [INFO]: Epoch 059 - training loss: 0.2887, validation loss: 0.0321
2024-06-01 21:19:33 [INFO]: Epoch 060 - training loss: 0.2769, validation loss: 0.0328
2024-06-01 21:19:34 [INFO]: Epoch 061 - training loss: 0.2680, validation loss: 0.0320
2024-06-01 21:19:34 [INFO]: Epoch 062 - training loss: 0.2753, validation loss: 0.0332
2024-06-01 21:19:34 [INFO]: Epoch 063 - training loss: 0.2854, validation loss: 0.0289
2024-06-01 21:19:34 [INFO]: Epoch 064 - training loss: 0.2761, validation loss: 0.0320
2024-06-01 21:19:34 [INFO]: Epoch 065 - training loss: 0.2710, validation loss: 0.0309
2024-06-01 21:19:34 [INFO]: Epoch 066 - training loss: 0.2800, validation loss: 0.0296
2024-06-01 21:19:34 [INFO]: Epoch 067 - training loss: 0.2695, validation loss: 0.0322
2024-06-01 21:19:35 [INFO]: Epoch 068 - training loss: 0.2758, validation loss: 0.0306
2024-06-01 21:19:35 [INFO]: Epoch 069 - training loss: 0.2729, validation loss: 0.0295
2024-06-01 21:19:35 [INFO]: Epoch 070 - training loss: 0.2700, validation loss: 0.0298
2024-06-01 21:19:35 [INFO]: Epoch 071 - training loss: 0.2763, validation loss: 0.0309
2024-06-01 21:19:35 [INFO]: Epoch 072 - training loss: 0.2778, validation loss: 0.0335
2024-06-01 21:19:35 [INFO]: Epoch 073 - training loss: 0.2779, validation loss: 0.0286
2024-06-01 21:19:36 [INFO]: Epoch 074 - training loss: 0.2682, validation loss: 0.0309
2024-06-01 21:19:36 [INFO]: Epoch 075 - training loss: 0.2702, validation loss: 0.0316
2024-06-01 21:19:36 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.0301
2024-06-01 21:19:36 [INFO]: Epoch 077 - training loss: 0.2626, validation loss: 0.0304
2024-06-01 21:19:36 [INFO]: Epoch 078 - training loss: 0.2702, validation loss: 0.0303
2024-06-01 21:19:36 [INFO]: Epoch 079 - training loss: 0.2622, validation loss: 0.0311
2024-06-01 21:19:37 [INFO]: Epoch 080 - training loss: 0.2569, validation loss: 0.0277
2024-06-01 21:19:37 [INFO]: Epoch 081 - training loss: 0.2667, validation loss: 0.0276
2024-06-01 21:19:37 [INFO]: Epoch 082 - training loss: 0.2629, validation loss: 0.0298
2024-06-01 21:19:37 [INFO]: Epoch 083 - training loss: 0.2572, validation loss: 0.0293
2024-06-01 21:19:37 [INFO]: Epoch 084 - training loss: 0.2634, validation loss: 0.0295
2024-06-01 21:19:37 [INFO]: Epoch 085 - training loss: 0.2574, validation loss: 0.0313
2024-06-01 21:19:38 [INFO]: Epoch 086 - training loss: 0.2639, validation loss: 0.0301
2024-06-01 21:19:38 [INFO]: Epoch 087 - training loss: 0.2543, validation loss: 0.0290
2024-06-01 21:19:38 [INFO]: Epoch 088 - training loss: 0.2548, validation loss: 0.0301
2024-06-01 21:19:38 [INFO]: Epoch 089 - training loss: 0.2588, validation loss: 0.0326
2024-06-01 21:19:38 [INFO]: Epoch 090 - training loss: 0.2559, validation loss: 0.0313
2024-06-01 21:19:38 [INFO]: Epoch 091 - training loss: 0.2580, validation loss: 0.0291
2024-06-01 21:19:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:19:38 [INFO]: Finished training. The best model is from epoch#81.
2024-06-01 21:19:38 [INFO]: Saved the model to results_point_rate01/PatchTST_Pedestrian/round_0/20240601_T211923/PatchTST.pypots
2024-06-01 21:19:39 [INFO]: Successfully saved to results_point_rate01/PatchTST_Pedestrian/round_0/imputation.pkl
2024-06-01 21:19:39 [INFO]: Round0 - PatchTST on Pedestrian: MAE=0.1206, MSE=0.0683, MRE=0.1649
2024-06-01 21:19:39 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 21:19:39 [INFO]: Using the given device: cuda:0
2024-06-01 21:19:39 [INFO]: Model files will be saved to results_point_rate01/PatchTST_Pedestrian/round_1/20240601_T211939
2024-06-01 21:19:39 [INFO]: Tensorboard file will be saved to results_point_rate01/PatchTST_Pedestrian/round_1/20240601_T211939/tensorboard
2024-06-01 21:19:39 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 106,905
2024-06-01 21:19:39 [INFO]: Epoch 001 - training loss: 1.2906, validation loss: 0.3750
2024-06-01 21:19:39 [INFO]: Epoch 002 - training loss: 0.8350, validation loss: 0.2419
2024-06-01 21:19:39 [INFO]: Epoch 003 - training loss: 0.7181, validation loss: 0.1455
2024-06-01 21:19:39 [INFO]: Epoch 004 - training loss: 0.6084, validation loss: 0.0892
2024-06-01 21:19:39 [INFO]: Epoch 005 - training loss: 0.5333, validation loss: 0.0746
2024-06-01 21:19:40 [INFO]: Epoch 006 - training loss: 0.5161, validation loss: 0.0626
2024-06-01 21:19:40 [INFO]: Epoch 007 - training loss: 0.4877, validation loss: 0.0610
2024-06-01 21:19:40 [INFO]: Epoch 008 - training loss: 0.4635, validation loss: 0.0520
2024-06-01 21:19:40 [INFO]: Epoch 009 - training loss: 0.4550, validation loss: 0.0520
2024-06-01 21:19:40 [INFO]: Epoch 010 - training loss: 0.4415, validation loss: 0.0507
2024-06-01 21:19:40 [INFO]: Epoch 011 - training loss: 0.4339, validation loss: 0.0500
2024-06-01 21:19:41 [INFO]: Epoch 012 - training loss: 0.4273, validation loss: 0.0475
2024-06-01 21:19:41 [INFO]: Epoch 013 - training loss: 0.4062, validation loss: 0.0459
2024-06-01 21:19:41 [INFO]: Epoch 014 - training loss: 0.3966, validation loss: 0.0450
2024-06-01 21:19:41 [INFO]: Epoch 015 - training loss: 0.3910, validation loss: 0.0424
2024-06-01 21:19:41 [INFO]: Epoch 016 - training loss: 0.3948, validation loss: 0.0442
2024-06-01 21:19:41 [INFO]: Epoch 017 - training loss: 0.3791, validation loss: 0.0426
2024-06-01 21:19:42 [INFO]: Epoch 018 - training loss: 0.3699, validation loss: 0.0419
2024-06-01 21:19:42 [INFO]: Epoch 019 - training loss: 0.3755, validation loss: 0.0414
2024-06-01 21:19:42 [INFO]: Epoch 020 - training loss: 0.3701, validation loss: 0.0415
2024-06-01 21:19:42 [INFO]: Epoch 021 - training loss: 0.3610, validation loss: 0.0401
2024-06-01 21:19:42 [INFO]: Epoch 022 - training loss: 0.3572, validation loss: 0.0405
2024-06-01 21:19:42 [INFO]: Epoch 023 - training loss: 0.3433, validation loss: 0.0405
2024-06-01 21:19:43 [INFO]: Epoch 024 - training loss: 0.3508, validation loss: 0.0404
2024-06-01 21:19:43 [INFO]: Epoch 025 - training loss: 0.3553, validation loss: 0.0402
2024-06-01 21:19:43 [INFO]: Epoch 026 - training loss: 0.3379, validation loss: 0.0389
2024-06-01 21:19:43 [INFO]: Epoch 027 - training loss: 0.3409, validation loss: 0.0353
2024-06-01 21:19:43 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.0374
2024-06-01 21:19:43 [INFO]: Epoch 029 - training loss: 0.3337, validation loss: 0.0360
2024-06-01 21:19:44 [INFO]: Epoch 030 - training loss: 0.3310, validation loss: 0.0349
2024-06-01 21:19:44 [INFO]: Epoch 031 - training loss: 0.3252, validation loss: 0.0358
2024-06-01 21:19:44 [INFO]: Epoch 032 - training loss: 0.3236, validation loss: 0.0369
2024-06-01 21:19:44 [INFO]: Epoch 033 - training loss: 0.3357, validation loss: 0.0382
2024-06-01 21:19:44 [INFO]: Epoch 034 - training loss: 0.3117, validation loss: 0.0348
2024-06-01 21:19:44 [INFO]: Epoch 035 - training loss: 0.3190, validation loss: 0.0362
2024-06-01 21:19:45 [INFO]: Epoch 036 - training loss: 0.3193, validation loss: 0.0350
2024-06-01 21:19:45 [INFO]: Epoch 037 - training loss: 0.3234, validation loss: 0.0351
2024-06-01 21:19:45 [INFO]: Epoch 038 - training loss: 0.3117, validation loss: 0.0354
2024-06-01 21:19:45 [INFO]: Epoch 039 - training loss: 0.3023, validation loss: 0.0330
2024-06-01 21:19:45 [INFO]: Epoch 040 - training loss: 0.3158, validation loss: 0.0337
2024-06-01 21:19:45 [INFO]: Epoch 041 - training loss: 0.3084, validation loss: 0.0328
2024-06-01 21:19:46 [INFO]: Epoch 042 - training loss: 0.3007, validation loss: 0.0329
2024-06-01 21:19:46 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.0331
2024-06-01 21:19:46 [INFO]: Epoch 044 - training loss: 0.3003, validation loss: 0.0339
2024-06-01 21:19:46 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.0332
2024-06-01 21:19:46 [INFO]: Epoch 046 - training loss: 0.2905, validation loss: 0.0334
2024-06-01 21:19:46 [INFO]: Epoch 047 - training loss: 0.2928, validation loss: 0.0330
2024-06-01 21:19:47 [INFO]: Epoch 048 - training loss: 0.2930, validation loss: 0.0343
2024-06-01 21:19:47 [INFO]: Epoch 049 - training loss: 0.2922, validation loss: 0.0320
2024-06-01 21:19:47 [INFO]: Epoch 050 - training loss: 0.2905, validation loss: 0.0325
2024-06-01 21:19:47 [INFO]: Epoch 051 - training loss: 0.2854, validation loss: 0.0310
2024-06-01 21:19:47 [INFO]: Epoch 052 - training loss: 0.2915, validation loss: 0.0319
2024-06-01 21:19:47 [INFO]: Epoch 053 - training loss: 0.2816, validation loss: 0.0335
2024-06-01 21:19:47 [INFO]: Epoch 054 - training loss: 0.2840, validation loss: 0.0312
2024-06-01 21:19:48 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.0315
2024-06-01 21:19:48 [INFO]: Epoch 056 - training loss: 0.2907, validation loss: 0.0315
2024-06-01 21:19:48 [INFO]: Epoch 057 - training loss: 0.2713, validation loss: 0.0334
2024-06-01 21:19:48 [INFO]: Epoch 058 - training loss: 0.2792, validation loss: 0.0297
2024-06-01 21:19:48 [INFO]: Epoch 059 - training loss: 0.2775, validation loss: 0.0327
2024-06-01 21:19:48 [INFO]: Epoch 060 - training loss: 0.2818, validation loss: 0.0308
2024-06-01 21:19:49 [INFO]: Epoch 061 - training loss: 0.2766, validation loss: 0.0304
2024-06-01 21:19:49 [INFO]: Epoch 062 - training loss: 0.2810, validation loss: 0.0308
2024-06-01 21:19:49 [INFO]: Epoch 063 - training loss: 0.2667, validation loss: 0.0293
2024-06-01 21:19:49 [INFO]: Epoch 064 - training loss: 0.2703, validation loss: 0.0305
2024-06-01 21:19:49 [INFO]: Epoch 065 - training loss: 0.2784, validation loss: 0.0306
2024-06-01 21:19:49 [INFO]: Epoch 066 - training loss: 0.2672, validation loss: 0.0319
2024-06-01 21:19:50 [INFO]: Epoch 067 - training loss: 0.2704, validation loss: 0.0299
2024-06-01 21:19:50 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.0307
2024-06-01 21:19:50 [INFO]: Epoch 069 - training loss: 0.2687, validation loss: 0.0302
2024-06-01 21:19:50 [INFO]: Epoch 070 - training loss: 0.2741, validation loss: 0.0308
2024-06-01 21:19:50 [INFO]: Epoch 071 - training loss: 0.2655, validation loss: 0.0282
2024-06-01 21:19:50 [INFO]: Epoch 072 - training loss: 0.2688, validation loss: 0.0290
2024-06-01 21:19:51 [INFO]: Epoch 073 - training loss: 0.2661, validation loss: 0.0298
2024-06-01 21:19:51 [INFO]: Epoch 074 - training loss: 0.2608, validation loss: 0.0313
2024-06-01 21:19:51 [INFO]: Epoch 075 - training loss: 0.2727, validation loss: 0.0303
2024-06-01 21:19:51 [INFO]: Epoch 076 - training loss: 0.2699, validation loss: 0.0287
2024-06-01 21:19:51 [INFO]: Epoch 077 - training loss: 0.2639, validation loss: 0.0286
2024-06-01 21:19:51 [INFO]: Epoch 078 - training loss: 0.2591, validation loss: 0.0296
2024-06-01 21:19:52 [INFO]: Epoch 079 - training loss: 0.2624, validation loss: 0.0263
2024-06-01 21:19:52 [INFO]: Epoch 080 - training loss: 0.2646, validation loss: 0.0285
2024-06-01 21:19:52 [INFO]: Epoch 081 - training loss: 0.2607, validation loss: 0.0297
2024-06-01 21:19:52 [INFO]: Epoch 082 - training loss: 0.2582, validation loss: 0.0282
2024-06-01 21:19:52 [INFO]: Epoch 083 - training loss: 0.2591, validation loss: 0.0295
2024-06-01 21:19:52 [INFO]: Epoch 084 - training loss: 0.2579, validation loss: 0.0274
2024-06-01 21:19:53 [INFO]: Epoch 085 - training loss: 0.2551, validation loss: 0.0286
2024-06-01 21:19:53 [INFO]: Epoch 086 - training loss: 0.2572, validation loss: 0.0282
2024-06-01 21:19:53 [INFO]: Epoch 087 - training loss: 0.2587, validation loss: 0.0297
2024-06-01 21:19:53 [INFO]: Epoch 088 - training loss: 0.2573, validation loss: 0.0305
2024-06-01 21:19:53 [INFO]: Epoch 089 - training loss: 0.2574, validation loss: 0.0313
2024-06-01 21:19:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:19:53 [INFO]: Finished training. The best model is from epoch#79.
2024-06-01 21:19:53 [INFO]: Saved the model to results_point_rate01/PatchTST_Pedestrian/round_1/20240601_T211939/PatchTST.pypots
2024-06-01 21:19:53 [INFO]: Successfully saved to results_point_rate01/PatchTST_Pedestrian/round_1/imputation.pkl
2024-06-01 21:19:53 [INFO]: Round1 - PatchTST on Pedestrian: MAE=0.1256, MSE=0.0705, MRE=0.1716
2024-06-01 21:19:53 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 21:19:53 [INFO]: Using the given device: cuda:0
2024-06-01 21:19:53 [INFO]: Model files will be saved to results_point_rate01/PatchTST_Pedestrian/round_2/20240601_T211953
2024-06-01 21:19:53 [INFO]: Tensorboard file will be saved to results_point_rate01/PatchTST_Pedestrian/round_2/20240601_T211953/tensorboard
2024-06-01 21:19:53 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 106,905
2024-06-01 21:19:54 [INFO]: Epoch 001 - training loss: 1.3885, validation loss: 0.7831
2024-06-01 21:19:54 [INFO]: Epoch 002 - training loss: 1.1145, validation loss: 0.2662
2024-06-01 21:19:54 [INFO]: Epoch 003 - training loss: 0.7447, validation loss: 0.1790
2024-06-01 21:19:54 [INFO]: Epoch 004 - training loss: 0.5957, validation loss: 0.0900
2024-06-01 21:19:54 [INFO]: Epoch 005 - training loss: 0.5378, validation loss: 0.0727
2024-06-01 21:19:54 [INFO]: Epoch 006 - training loss: 0.4967, validation loss: 0.0617
2024-06-01 21:19:55 [INFO]: Epoch 007 - training loss: 0.4769, validation loss: 0.0598
2024-06-01 21:19:55 [INFO]: Epoch 008 - training loss: 0.4663, validation loss: 0.0592
2024-06-01 21:19:55 [INFO]: Epoch 009 - training loss: 0.4464, validation loss: 0.0551
2024-06-01 21:19:55 [INFO]: Epoch 010 - training loss: 0.4426, validation loss: 0.0527
2024-06-01 21:19:55 [INFO]: Epoch 011 - training loss: 0.4496, validation loss: 0.0513
2024-06-01 21:19:55 [INFO]: Epoch 012 - training loss: 0.4435, validation loss: 0.0562
2024-06-01 21:19:55 [INFO]: Epoch 013 - training loss: 0.4187, validation loss: 0.0527
2024-06-01 21:19:56 [INFO]: Epoch 014 - training loss: 0.4247, validation loss: 0.0503
2024-06-01 21:19:56 [INFO]: Epoch 015 - training loss: 0.4011, validation loss: 0.0523
2024-06-01 21:19:56 [INFO]: Epoch 016 - training loss: 0.4061, validation loss: 0.0484
2024-06-01 21:19:56 [INFO]: Epoch 017 - training loss: 0.3956, validation loss: 0.0507
2024-06-01 21:19:56 [INFO]: Epoch 018 - training loss: 0.3864, validation loss: 0.0487
2024-06-01 21:19:56 [INFO]: Epoch 019 - training loss: 0.3842, validation loss: 0.0474
2024-06-01 21:19:57 [INFO]: Epoch 020 - training loss: 0.3716, validation loss: 0.0516
2024-06-01 21:19:57 [INFO]: Epoch 021 - training loss: 0.3790, validation loss: 0.0502
2024-06-01 21:19:57 [INFO]: Epoch 022 - training loss: 0.3604, validation loss: 0.0495
2024-06-01 21:19:57 [INFO]: Epoch 023 - training loss: 0.3671, validation loss: 0.0461
2024-06-01 21:19:57 [INFO]: Epoch 024 - training loss: 0.3617, validation loss: 0.0447
2024-06-01 21:19:57 [INFO]: Epoch 025 - training loss: 0.3629, validation loss: 0.0470
2024-06-01 21:19:58 [INFO]: Epoch 026 - training loss: 0.3537, validation loss: 0.0444
2024-06-01 21:19:58 [INFO]: Epoch 027 - training loss: 0.3572, validation loss: 0.0454
2024-06-01 21:19:58 [INFO]: Epoch 028 - training loss: 0.3430, validation loss: 0.0489
2024-06-01 21:19:58 [INFO]: Epoch 029 - training loss: 0.3338, validation loss: 0.0428
2024-06-01 21:19:58 [INFO]: Epoch 030 - training loss: 0.3349, validation loss: 0.0433
2024-06-01 21:19:58 [INFO]: Epoch 031 - training loss: 0.3374, validation loss: 0.0439
2024-06-01 21:19:59 [INFO]: Epoch 032 - training loss: 0.3253, validation loss: 0.0408
2024-06-01 21:19:59 [INFO]: Epoch 033 - training loss: 0.3296, validation loss: 0.0418
2024-06-01 21:19:59 [INFO]: Epoch 034 - training loss: 0.3240, validation loss: 0.0384
2024-06-01 21:19:59 [INFO]: Epoch 035 - training loss: 0.3171, validation loss: 0.0396
2024-06-01 21:19:59 [INFO]: Epoch 036 - training loss: 0.3165, validation loss: 0.0396
2024-06-01 21:19:59 [INFO]: Epoch 037 - training loss: 0.3102, validation loss: 0.0402
2024-06-01 21:20:00 [INFO]: Epoch 038 - training loss: 0.3185, validation loss: 0.0411
2024-06-01 21:20:00 [INFO]: Epoch 039 - training loss: 0.3108, validation loss: 0.0393
2024-06-01 21:20:00 [INFO]: Epoch 040 - training loss: 0.3108, validation loss: 0.0386
2024-06-01 21:20:00 [INFO]: Epoch 041 - training loss: 0.2995, validation loss: 0.0413
2024-06-01 21:20:00 [INFO]: Epoch 042 - training loss: 0.2959, validation loss: 0.0395
2024-06-01 21:20:00 [INFO]: Epoch 043 - training loss: 0.2991, validation loss: 0.0368
2024-06-01 21:20:01 [INFO]: Epoch 044 - training loss: 0.2978, validation loss: 0.0370
2024-06-01 21:20:01 [INFO]: Epoch 045 - training loss: 0.3038, validation loss: 0.0360
2024-06-01 21:20:01 [INFO]: Epoch 046 - training loss: 0.3024, validation loss: 0.0362
2024-06-01 21:20:01 [INFO]: Epoch 047 - training loss: 0.2979, validation loss: 0.0351
2024-06-01 21:20:01 [INFO]: Epoch 048 - training loss: 0.2914, validation loss: 0.0390
2024-06-01 21:20:01 [INFO]: Epoch 049 - training loss: 0.2903, validation loss: 0.0360
2024-06-01 21:20:02 [INFO]: Epoch 050 - training loss: 0.2830, validation loss: 0.0356
2024-06-01 21:20:02 [INFO]: Epoch 051 - training loss: 0.2887, validation loss: 0.0334
2024-06-01 21:20:02 [INFO]: Epoch 052 - training loss: 0.2822, validation loss: 0.0354
2024-06-01 21:20:02 [INFO]: Epoch 053 - training loss: 0.2824, validation loss: 0.0337
2024-06-01 21:20:02 [INFO]: Epoch 054 - training loss: 0.2819, validation loss: 0.0349
2024-06-01 21:20:02 [INFO]: Epoch 055 - training loss: 0.2780, validation loss: 0.0364
2024-06-01 21:20:03 [INFO]: Epoch 056 - training loss: 0.2741, validation loss: 0.0362
2024-06-01 21:20:03 [INFO]: Epoch 057 - training loss: 0.2881, validation loss: 0.0342
2024-06-01 21:20:03 [INFO]: Epoch 058 - training loss: 0.2784, validation loss: 0.0314
2024-06-01 21:20:03 [INFO]: Epoch 059 - training loss: 0.2779, validation loss: 0.0338
2024-06-01 21:20:03 [INFO]: Epoch 060 - training loss: 0.2816, validation loss: 0.0323
2024-06-01 21:20:03 [INFO]: Epoch 061 - training loss: 0.2706, validation loss: 0.0312
2024-06-01 21:20:04 [INFO]: Epoch 062 - training loss: 0.2748, validation loss: 0.0357
2024-06-01 21:20:04 [INFO]: Epoch 063 - training loss: 0.2684, validation loss: 0.0332
2024-06-01 21:20:04 [INFO]: Epoch 064 - training loss: 0.2674, validation loss: 0.0317
2024-06-01 21:20:04 [INFO]: Epoch 065 - training loss: 0.2679, validation loss: 0.0329
2024-06-01 21:20:04 [INFO]: Epoch 066 - training loss: 0.2695, validation loss: 0.0325
2024-06-01 21:20:04 [INFO]: Epoch 067 - training loss: 0.2740, validation loss: 0.0337
2024-06-01 21:20:05 [INFO]: Epoch 068 - training loss: 0.2733, validation loss: 0.0343
2024-06-01 21:20:05 [INFO]: Epoch 069 - training loss: 0.2656, validation loss: 0.0324
2024-06-01 21:20:05 [INFO]: Epoch 070 - training loss: 0.2680, validation loss: 0.0317
2024-06-01 21:20:05 [INFO]: Epoch 071 - training loss: 0.2645, validation loss: 0.0317
2024-06-01 21:20:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:20:05 [INFO]: Finished training. The best model is from epoch#61.
2024-06-01 21:20:05 [INFO]: Saved the model to results_point_rate01/PatchTST_Pedestrian/round_2/20240601_T211953/PatchTST.pypots
2024-06-01 21:20:05 [INFO]: Successfully saved to results_point_rate01/PatchTST_Pedestrian/round_2/imputation.pkl
2024-06-01 21:20:05 [INFO]: Round2 - PatchTST on Pedestrian: MAE=0.1280, MSE=0.0750, MRE=0.1750
2024-06-01 21:20:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 21:20:05 [INFO]: Using the given device: cuda:0
2024-06-01 21:20:05 [INFO]: Model files will be saved to results_point_rate01/PatchTST_Pedestrian/round_3/20240601_T212005
2024-06-01 21:20:05 [INFO]: Tensorboard file will be saved to results_point_rate01/PatchTST_Pedestrian/round_3/20240601_T212005/tensorboard
2024-06-01 21:20:05 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 106,905
2024-06-01 21:20:05 [INFO]: Epoch 001 - training loss: 1.1609, validation loss: 0.2810
2024-06-01 21:20:05 [INFO]: Epoch 002 - training loss: 0.7636, validation loss: 0.1569
2024-06-01 21:20:06 [INFO]: Epoch 003 - training loss: 0.6376, validation loss: 0.1045
2024-06-01 21:20:06 [INFO]: Epoch 004 - training loss: 0.5593, validation loss: 0.0773
2024-06-01 21:20:06 [INFO]: Epoch 005 - training loss: 0.5246, validation loss: 0.0718
2024-06-01 21:20:06 [INFO]: Epoch 006 - training loss: 0.5137, validation loss: 0.0598
2024-06-01 21:20:06 [INFO]: Epoch 007 - training loss: 0.4937, validation loss: 0.0652
2024-06-01 21:20:06 [INFO]: Epoch 008 - training loss: 0.4704, validation loss: 0.0544
2024-06-01 21:20:07 [INFO]: Epoch 009 - training loss: 0.4539, validation loss: 0.0552
2024-06-01 21:20:07 [INFO]: Epoch 010 - training loss: 0.4487, validation loss: 0.0535
2024-06-01 21:20:07 [INFO]: Epoch 011 - training loss: 0.4269, validation loss: 0.0517
2024-06-01 21:20:07 [INFO]: Epoch 012 - training loss: 0.4263, validation loss: 0.0538
2024-06-01 21:20:07 [INFO]: Epoch 013 - training loss: 0.4201, validation loss: 0.0495
2024-06-01 21:20:07 [INFO]: Epoch 014 - training loss: 0.4212, validation loss: 0.0532
2024-06-01 21:20:08 [INFO]: Epoch 015 - training loss: 0.4010, validation loss: 0.0467
2024-06-01 21:20:08 [INFO]: Epoch 016 - training loss: 0.3889, validation loss: 0.0455
2024-06-01 21:20:08 [INFO]: Epoch 017 - training loss: 0.3847, validation loss: 0.0458
2024-06-01 21:20:08 [INFO]: Epoch 018 - training loss: 0.3822, validation loss: 0.0461
2024-06-01 21:20:08 [INFO]: Epoch 019 - training loss: 0.3755, validation loss: 0.0467
2024-06-01 21:20:08 [INFO]: Epoch 020 - training loss: 0.3763, validation loss: 0.0429
2024-06-01 21:20:09 [INFO]: Epoch 021 - training loss: 0.3694, validation loss: 0.0452
2024-06-01 21:20:09 [INFO]: Epoch 022 - training loss: 0.3623, validation loss: 0.0430
2024-06-01 21:20:09 [INFO]: Epoch 023 - training loss: 0.3597, validation loss: 0.0433
2024-06-01 21:20:09 [INFO]: Epoch 024 - training loss: 0.3556, validation loss: 0.0439
2024-06-01 21:20:09 [INFO]: Epoch 025 - training loss: 0.3449, validation loss: 0.0429
2024-06-01 21:20:09 [INFO]: Epoch 026 - training loss: 0.3426, validation loss: 0.0402
2024-06-01 21:20:10 [INFO]: Epoch 027 - training loss: 0.3306, validation loss: 0.0411
2024-06-01 21:20:10 [INFO]: Epoch 028 - training loss: 0.3341, validation loss: 0.0401
2024-06-01 21:20:10 [INFO]: Epoch 029 - training loss: 0.3264, validation loss: 0.0424
2024-06-01 21:20:10 [INFO]: Epoch 030 - training loss: 0.3341, validation loss: 0.0428
2024-06-01 21:20:10 [INFO]: Epoch 031 - training loss: 0.3246, validation loss: 0.0389
2024-06-01 21:20:10 [INFO]: Epoch 032 - training loss: 0.3228, validation loss: 0.0407
2024-06-01 21:20:11 [INFO]: Epoch 033 - training loss: 0.3224, validation loss: 0.0391
2024-06-01 21:20:11 [INFO]: Epoch 034 - training loss: 0.3248, validation loss: 0.0368
2024-06-01 21:20:11 [INFO]: Epoch 035 - training loss: 0.3149, validation loss: 0.0405
2024-06-01 21:20:11 [INFO]: Epoch 036 - training loss: 0.3148, validation loss: 0.0368
2024-06-01 21:20:11 [INFO]: Epoch 037 - training loss: 0.3180, validation loss: 0.0377
2024-06-01 21:20:11 [INFO]: Epoch 038 - training loss: 0.3098, validation loss: 0.0387
2024-06-01 21:20:12 [INFO]: Epoch 039 - training loss: 0.3141, validation loss: 0.0381
2024-06-01 21:20:12 [INFO]: Epoch 040 - training loss: 0.3085, validation loss: 0.0385
2024-06-01 21:20:12 [INFO]: Epoch 041 - training loss: 0.3060, validation loss: 0.0355
2024-06-01 21:20:12 [INFO]: Epoch 042 - training loss: 0.3015, validation loss: 0.0366
2024-06-01 21:20:12 [INFO]: Epoch 043 - training loss: 0.3001, validation loss: 0.0372
2024-06-01 21:20:12 [INFO]: Epoch 044 - training loss: 0.2884, validation loss: 0.0365
2024-06-01 21:20:13 [INFO]: Epoch 045 - training loss: 0.3005, validation loss: 0.0380
2024-06-01 21:20:13 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.0361
2024-06-01 21:20:13 [INFO]: Epoch 047 - training loss: 0.2957, validation loss: 0.0356
2024-06-01 21:20:13 [INFO]: Epoch 048 - training loss: 0.2907, validation loss: 0.0351
2024-06-01 21:20:13 [INFO]: Epoch 049 - training loss: 0.2905, validation loss: 0.0389
2024-06-01 21:20:13 [INFO]: Epoch 050 - training loss: 0.2878, validation loss: 0.0359
2024-06-01 21:20:14 [INFO]: Epoch 051 - training loss: 0.2973, validation loss: 0.0345
2024-06-01 21:20:14 [INFO]: Epoch 052 - training loss: 0.2912, validation loss: 0.0343
2024-06-01 21:20:14 [INFO]: Epoch 053 - training loss: 0.2910, validation loss: 0.0353
2024-06-01 21:20:14 [INFO]: Epoch 054 - training loss: 0.2766, validation loss: 0.0350
2024-06-01 21:20:14 [INFO]: Epoch 055 - training loss: 0.2831, validation loss: 0.0322
2024-06-01 21:20:15 [INFO]: Epoch 056 - training loss: 0.2763, validation loss: 0.0335
2024-06-01 21:20:15 [INFO]: Epoch 057 - training loss: 0.2797, validation loss: 0.0335
2024-06-01 21:20:15 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.0317
2024-06-01 21:20:15 [INFO]: Epoch 059 - training loss: 0.2741, validation loss: 0.0328
2024-06-01 21:20:15 [INFO]: Epoch 060 - training loss: 0.2761, validation loss: 0.0322
2024-06-01 21:20:15 [INFO]: Epoch 061 - training loss: 0.2799, validation loss: 0.0317
2024-06-01 21:20:15 [INFO]: Epoch 062 - training loss: 0.2723, validation loss: 0.0319
2024-06-01 21:20:16 [INFO]: Epoch 063 - training loss: 0.2768, validation loss: 0.0325
2024-06-01 21:20:16 [INFO]: Epoch 064 - training loss: 0.2651, validation loss: 0.0327
2024-06-01 21:20:16 [INFO]: Epoch 065 - training loss: 0.2648, validation loss: 0.0314
2024-06-01 21:20:16 [INFO]: Epoch 066 - training loss: 0.2681, validation loss: 0.0339
2024-06-01 21:20:16 [INFO]: Epoch 067 - training loss: 0.2663, validation loss: 0.0330
2024-06-01 21:20:16 [INFO]: Epoch 068 - training loss: 0.2667, validation loss: 0.0341
2024-06-01 21:20:17 [INFO]: Epoch 069 - training loss: 0.2728, validation loss: 0.0333
2024-06-01 21:20:17 [INFO]: Epoch 070 - training loss: 0.2725, validation loss: 0.0320
2024-06-01 21:20:17 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.0330
2024-06-01 21:20:17 [INFO]: Epoch 072 - training loss: 0.2623, validation loss: 0.0310
2024-06-01 21:20:17 [INFO]: Epoch 073 - training loss: 0.2699, validation loss: 0.0327
2024-06-01 21:20:17 [INFO]: Epoch 074 - training loss: 0.2680, validation loss: 0.0306
2024-06-01 21:20:18 [INFO]: Epoch 075 - training loss: 0.2632, validation loss: 0.0301
2024-06-01 21:20:18 [INFO]: Epoch 076 - training loss: 0.2592, validation loss: 0.0322
2024-06-01 21:20:18 [INFO]: Epoch 077 - training loss: 0.2617, validation loss: 0.0296
2024-06-01 21:20:18 [INFO]: Epoch 078 - training loss: 0.2612, validation loss: 0.0307
2024-06-01 21:20:18 [INFO]: Epoch 079 - training loss: 0.2605, validation loss: 0.0308
2024-06-01 21:20:18 [INFO]: Epoch 080 - training loss: 0.2695, validation loss: 0.0319
2024-06-01 21:20:19 [INFO]: Epoch 081 - training loss: 0.2581, validation loss: 0.0316
2024-06-01 21:20:19 [INFO]: Epoch 082 - training loss: 0.2601, validation loss: 0.0298
2024-06-01 21:20:19 [INFO]: Epoch 083 - training loss: 0.2579, validation loss: 0.0288
2024-06-01 21:20:19 [INFO]: Epoch 084 - training loss: 0.2543, validation loss: 0.0308
2024-06-01 21:20:19 [INFO]: Epoch 085 - training loss: 0.2586, validation loss: 0.0296
2024-06-01 21:20:19 [INFO]: Epoch 086 - training loss: 0.2531, validation loss: 0.0312
2024-06-01 21:20:20 [INFO]: Epoch 087 - training loss: 0.2562, validation loss: 0.0299
2024-06-01 21:20:20 [INFO]: Epoch 088 - training loss: 0.2561, validation loss: 0.0287
2024-06-01 21:20:20 [INFO]: Epoch 089 - training loss: 0.2545, validation loss: 0.0291
2024-06-01 21:20:20 [INFO]: Epoch 090 - training loss: 0.2527, validation loss: 0.0279
2024-06-01 21:20:20 [INFO]: Epoch 091 - training loss: 0.2569, validation loss: 0.0294
2024-06-01 21:20:20 [INFO]: Epoch 092 - training loss: 0.2514, validation loss: 0.0290
2024-06-01 21:20:21 [INFO]: Epoch 093 - training loss: 0.2577, validation loss: 0.0290
2024-06-01 21:20:21 [INFO]: Epoch 094 - training loss: 0.2504, validation loss: 0.0289
2024-06-01 21:20:21 [INFO]: Epoch 095 - training loss: 0.2482, validation loss: 0.0284
2024-06-01 21:20:21 [INFO]: Epoch 096 - training loss: 0.2500, validation loss: 0.0288
2024-06-01 21:20:21 [INFO]: Epoch 097 - training loss: 0.2466, validation loss: 0.0291
2024-06-01 21:20:21 [INFO]: Epoch 098 - training loss: 0.2554, validation loss: 0.0284
2024-06-01 21:20:22 [INFO]: Epoch 099 - training loss: 0.2461, validation loss: 0.0299
2024-06-01 21:20:22 [INFO]: Epoch 100 - training loss: 0.2502, validation loss: 0.0294
2024-06-01 21:20:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:20:22 [INFO]: Finished training. The best model is from epoch#90.
2024-06-01 21:20:22 [INFO]: Saved the model to results_point_rate01/PatchTST_Pedestrian/round_3/20240601_T212005/PatchTST.pypots
2024-06-01 21:20:22 [INFO]: Successfully saved to results_point_rate01/PatchTST_Pedestrian/round_3/imputation.pkl
2024-06-01 21:20:22 [INFO]: Round3 - PatchTST on Pedestrian: MAE=0.1260, MSE=0.0699, MRE=0.1722
2024-06-01 21:20:22 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 21:20:22 [INFO]: Using the given device: cuda:0
2024-06-01 21:20:22 [INFO]: Model files will be saved to results_point_rate01/PatchTST_Pedestrian/round_4/20240601_T212022
2024-06-01 21:20:22 [INFO]: Tensorboard file will be saved to results_point_rate01/PatchTST_Pedestrian/round_4/20240601_T212022/tensorboard
2024-06-01 21:20:22 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 106,905
2024-06-01 21:20:22 [INFO]: Epoch 001 - training loss: 1.2005, validation loss: 0.3228
2024-06-01 21:20:22 [INFO]: Epoch 002 - training loss: 0.8191, validation loss: 0.2503
2024-06-01 21:20:22 [INFO]: Epoch 003 - training loss: 0.7214, validation loss: 0.1750
2024-06-01 21:20:23 [INFO]: Epoch 004 - training loss: 0.6253, validation loss: 0.1052
2024-06-01 21:20:23 [INFO]: Epoch 005 - training loss: 0.5513, validation loss: 0.0854
2024-06-01 21:20:23 [INFO]: Epoch 006 - training loss: 0.5159, validation loss: 0.0731
2024-06-01 21:20:23 [INFO]: Epoch 007 - training loss: 0.4890, validation loss: 0.0668
2024-06-01 21:20:23 [INFO]: Epoch 008 - training loss: 0.4795, validation loss: 0.0609
2024-06-01 21:20:23 [INFO]: Epoch 009 - training loss: 0.4498, validation loss: 0.0579
2024-06-01 21:20:24 [INFO]: Epoch 010 - training loss: 0.4378, validation loss: 0.0532
2024-06-01 21:20:24 [INFO]: Epoch 011 - training loss: 0.4232, validation loss: 0.0527
2024-06-01 21:20:24 [INFO]: Epoch 012 - training loss: 0.4201, validation loss: 0.0524
2024-06-01 21:20:24 [INFO]: Epoch 013 - training loss: 0.4158, validation loss: 0.0501
2024-06-01 21:20:24 [INFO]: Epoch 014 - training loss: 0.4008, validation loss: 0.0445
2024-06-01 21:20:24 [INFO]: Epoch 015 - training loss: 0.3864, validation loss: 0.0474
2024-06-01 21:20:25 [INFO]: Epoch 016 - training loss: 0.3817, validation loss: 0.0447
2024-06-01 21:20:25 [INFO]: Epoch 017 - training loss: 0.3756, validation loss: 0.0453
2024-06-01 21:20:25 [INFO]: Epoch 018 - training loss: 0.3773, validation loss: 0.0417
2024-06-01 21:20:25 [INFO]: Epoch 019 - training loss: 0.3720, validation loss: 0.0433
2024-06-01 21:20:25 [INFO]: Epoch 020 - training loss: 0.3558, validation loss: 0.0399
2024-06-01 21:20:25 [INFO]: Epoch 021 - training loss: 0.3485, validation loss: 0.0434
2024-06-01 21:20:26 [INFO]: Epoch 022 - training loss: 0.3515, validation loss: 0.0416
2024-06-01 21:20:26 [INFO]: Epoch 023 - training loss: 0.3489, validation loss: 0.0415
2024-06-01 21:20:26 [INFO]: Epoch 024 - training loss: 0.3367, validation loss: 0.0390
2024-06-01 21:20:26 [INFO]: Epoch 025 - training loss: 0.3350, validation loss: 0.0403
2024-06-01 21:20:26 [INFO]: Epoch 026 - training loss: 0.3324, validation loss: 0.0407
2024-06-01 21:20:26 [INFO]: Epoch 027 - training loss: 0.3233, validation loss: 0.0383
2024-06-01 21:20:27 [INFO]: Epoch 028 - training loss: 0.3247, validation loss: 0.0392
2024-06-01 21:20:27 [INFO]: Epoch 029 - training loss: 0.3281, validation loss: 0.0411
2024-06-01 21:20:27 [INFO]: Epoch 030 - training loss: 0.3256, validation loss: 0.0361
2024-06-01 21:20:27 [INFO]: Epoch 031 - training loss: 0.3107, validation loss: 0.0373
2024-06-01 21:20:27 [INFO]: Epoch 032 - training loss: 0.3073, validation loss: 0.0357
2024-06-01 21:20:27 [INFO]: Epoch 033 - training loss: 0.3184, validation loss: 0.0372
2024-06-01 21:20:28 [INFO]: Epoch 034 - training loss: 0.3169, validation loss: 0.0332
2024-06-01 21:20:28 [INFO]: Epoch 035 - training loss: 0.3027, validation loss: 0.0366
2024-06-01 21:20:28 [INFO]: Epoch 036 - training loss: 0.3064, validation loss: 0.0345
2024-06-01 21:20:28 [INFO]: Epoch 037 - training loss: 0.3026, validation loss: 0.0325
2024-06-01 21:20:28 [INFO]: Epoch 038 - training loss: 0.2984, validation loss: 0.0333
2024-06-01 21:20:28 [INFO]: Epoch 039 - training loss: 0.2946, validation loss: 0.0335
2024-06-01 21:20:29 [INFO]: Epoch 040 - training loss: 0.3015, validation loss: 0.0323
2024-06-01 21:20:29 [INFO]: Epoch 041 - training loss: 0.2932, validation loss: 0.0314
2024-06-01 21:20:29 [INFO]: Epoch 042 - training loss: 0.2914, validation loss: 0.0331
2024-06-01 21:20:29 [INFO]: Epoch 043 - training loss: 0.2903, validation loss: 0.0325
2024-06-01 21:20:29 [INFO]: Epoch 044 - training loss: 0.2931, validation loss: 0.0325
2024-06-01 21:20:29 [INFO]: Epoch 045 - training loss: 0.2832, validation loss: 0.0327
2024-06-01 21:20:30 [INFO]: Epoch 046 - training loss: 0.2854, validation loss: 0.0316
2024-06-01 21:20:30 [INFO]: Epoch 047 - training loss: 0.2832, validation loss: 0.0306
2024-06-01 21:20:30 [INFO]: Epoch 048 - training loss: 0.2830, validation loss: 0.0308
2024-06-01 21:20:30 [INFO]: Epoch 049 - training loss: 0.2873, validation loss: 0.0328
2024-06-01 21:20:30 [INFO]: Epoch 050 - training loss: 0.2898, validation loss: 0.0331
2024-06-01 21:20:30 [INFO]: Epoch 051 - training loss: 0.2787, validation loss: 0.0325
2024-06-01 21:20:31 [INFO]: Epoch 052 - training loss: 0.2746, validation loss: 0.0341
2024-06-01 21:20:31 [INFO]: Epoch 053 - training loss: 0.2827, validation loss: 0.0310
2024-06-01 21:20:31 [INFO]: Epoch 054 - training loss: 0.2874, validation loss: 0.0313
2024-06-01 21:20:31 [INFO]: Epoch 055 - training loss: 0.2830, validation loss: 0.0323
2024-06-01 21:20:31 [INFO]: Epoch 056 - training loss: 0.2757, validation loss: 0.0312
2024-06-01 21:20:31 [INFO]: Epoch 057 - training loss: 0.2715, validation loss: 0.0313
2024-06-01 21:20:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:20:31 [INFO]: Finished training. The best model is from epoch#47.
2024-06-01 21:20:31 [INFO]: Saved the model to results_point_rate01/PatchTST_Pedestrian/round_4/20240601_T212022/PatchTST.pypots
2024-06-01 21:20:31 [INFO]: Successfully saved to results_point_rate01/PatchTST_Pedestrian/round_4/imputation.pkl
2024-06-01 21:20:31 [INFO]: Round4 - PatchTST on Pedestrian: MAE=0.1311, MSE=0.0762, MRE=0.1792
2024-06-01 21:20:31 [INFO]: Done! Final results:
Averaged PatchTST (n params: 106,905) on Pedestrian: MAE=0.1263 ± 0.0034269223628005576, MSE=0.0720 ± 0.0030640562805711153, MRE=0.1726 ± 0.004683408938305432, average inference time=0.09
