2024-06-01 21:17:51 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:17:51 [INFO]: Using the given device: cuda:0
2024-06-01 21:17:51 [INFO]: Model files will be saved to results_point_rate01/MRNN_Pedestrian/round_0/20240601_T211751
2024-06-01 21:17:51 [INFO]: Tensorboard file will be saved to results_point_rate01/MRNN_Pedestrian/round_0/20240601_T211751/tensorboard
2024-06-01 21:17:51 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 401,415
2024-06-01 21:17:53 [INFO]: Epoch 001 - training loss: 1.2578, validation loss: 0.8990
2024-06-01 21:17:53 [INFO]: Epoch 002 - training loss: 1.0311, validation loss: 0.8715
2024-06-01 21:17:53 [INFO]: Epoch 003 - training loss: 1.0234, validation loss: 0.8585
2024-06-01 21:17:53 [INFO]: Epoch 004 - training loss: 0.9988, validation loss: 0.8519
2024-06-01 21:17:53 [INFO]: Epoch 005 - training loss: 1.0096, validation loss: 0.8475
2024-06-01 21:17:53 [INFO]: Epoch 006 - training loss: 0.9986, validation loss: 0.8445
2024-06-01 21:17:53 [INFO]: Epoch 007 - training loss: 0.9922, validation loss: 0.8425
2024-06-01 21:17:54 [INFO]: Epoch 008 - training loss: 0.9976, validation loss: 0.8407
2024-06-01 21:17:54 [INFO]: Epoch 009 - training loss: 1.0142, validation loss: 0.8393
2024-06-01 21:17:54 [INFO]: Epoch 010 - training loss: 0.9952, validation loss: 0.8383
2024-06-01 21:17:54 [INFO]: Epoch 011 - training loss: 0.9803, validation loss: 0.8372
2024-06-01 21:17:54 [INFO]: Epoch 012 - training loss: 0.9874, validation loss: 0.8364
2024-06-01 21:17:54 [INFO]: Epoch 013 - training loss: 0.9906, validation loss: 0.8356
2024-06-01 21:17:54 [INFO]: Epoch 014 - training loss: 0.9927, validation loss: 0.8352
2024-06-01 21:17:54 [INFO]: Epoch 015 - training loss: 1.0002, validation loss: 0.8345
2024-06-01 21:17:55 [INFO]: Epoch 016 - training loss: 0.9744, validation loss: 0.8340
2024-06-01 21:17:55 [INFO]: Epoch 017 - training loss: 0.9886, validation loss: 0.8335
2024-06-01 21:17:55 [INFO]: Epoch 018 - training loss: 0.9937, validation loss: 0.8333
2024-06-01 21:17:55 [INFO]: Epoch 019 - training loss: 0.9711, validation loss: 0.8328
2024-06-01 21:17:55 [INFO]: Epoch 020 - training loss: 0.9822, validation loss: 0.8325
2024-06-01 21:17:55 [INFO]: Epoch 021 - training loss: 0.9954, validation loss: 0.8322
2024-06-01 21:17:55 [INFO]: Epoch 022 - training loss: 0.9737, validation loss: 0.8319
2024-06-01 21:17:55 [INFO]: Epoch 023 - training loss: 0.9758, validation loss: 0.8316
2024-06-01 21:17:56 [INFO]: Epoch 024 - training loss: 0.9882, validation loss: 0.8314
2024-06-01 21:17:56 [INFO]: Epoch 025 - training loss: 0.9777, validation loss: 0.8313
2024-06-01 21:17:56 [INFO]: Epoch 026 - training loss: 0.9717, validation loss: 0.8311
2024-06-01 21:17:56 [INFO]: Epoch 027 - training loss: 0.9723, validation loss: 0.8309
2024-06-01 21:17:56 [INFO]: Epoch 028 - training loss: 0.9778, validation loss: 0.8308
2024-06-01 21:17:56 [INFO]: Epoch 029 - training loss: 0.9842, validation loss: 0.8306
2024-06-01 21:17:56 [INFO]: Epoch 030 - training loss: 0.9779, validation loss: 0.8304
2024-06-01 21:17:56 [INFO]: Epoch 031 - training loss: 0.9845, validation loss: 0.8303
2024-06-01 21:17:57 [INFO]: Epoch 032 - training loss: 0.9790, validation loss: 0.8302
2024-06-01 21:17:57 [INFO]: Epoch 033 - training loss: 0.9813, validation loss: 0.8300
2024-06-01 21:17:57 [INFO]: Epoch 034 - training loss: 1.0116, validation loss: 0.8299
2024-06-01 21:17:57 [INFO]: Epoch 035 - training loss: 0.9760, validation loss: 0.8298
2024-06-01 21:17:57 [INFO]: Epoch 036 - training loss: 0.9834, validation loss: 0.8297
2024-06-01 21:17:57 [INFO]: Epoch 037 - training loss: 0.9695, validation loss: 0.8296
2024-06-01 21:17:57 [INFO]: Epoch 038 - training loss: 0.9685, validation loss: 0.8295
2024-06-01 21:17:57 [INFO]: Epoch 039 - training loss: 0.9783, validation loss: 0.8294
2024-06-01 21:17:57 [INFO]: Epoch 040 - training loss: 0.9827, validation loss: 0.8293
2024-06-01 21:17:58 [INFO]: Epoch 041 - training loss: 0.9833, validation loss: 0.8292
2024-06-01 21:17:58 [INFO]: Epoch 042 - training loss: 0.9683, validation loss: 0.8291
2024-06-01 21:17:58 [INFO]: Epoch 043 - training loss: 0.9735, validation loss: 0.8291
2024-06-01 21:17:58 [INFO]: Epoch 044 - training loss: 0.9828, validation loss: 0.8290
2024-06-01 21:17:58 [INFO]: Epoch 045 - training loss: 0.9922, validation loss: 0.8289
2024-06-01 21:17:58 [INFO]: Epoch 046 - training loss: 0.9722, validation loss: 0.8289
2024-06-01 21:17:58 [INFO]: Epoch 047 - training loss: 0.9829, validation loss: 0.8288
2024-06-01 21:17:58 [INFO]: Epoch 048 - training loss: 0.9839, validation loss: 0.8287
2024-06-01 21:17:59 [INFO]: Epoch 049 - training loss: 0.9754, validation loss: 0.8287
2024-06-01 21:17:59 [INFO]: Epoch 050 - training loss: 0.9818, validation loss: 0.8286
2024-06-01 21:17:59 [INFO]: Epoch 051 - training loss: 0.9763, validation loss: 0.8286
2024-06-01 21:17:59 [INFO]: Epoch 052 - training loss: 0.9817, validation loss: 0.8285
2024-06-01 21:17:59 [INFO]: Epoch 053 - training loss: 0.9825, validation loss: 0.8285
2024-06-01 21:17:59 [INFO]: Epoch 054 - training loss: 0.9735, validation loss: 0.8284
2024-06-01 21:17:59 [INFO]: Epoch 055 - training loss: 0.9835, validation loss: 0.8283
2024-06-01 21:17:59 [INFO]: Epoch 056 - training loss: 0.9763, validation loss: 0.8283
2024-06-01 21:18:00 [INFO]: Epoch 057 - training loss: 0.9664, validation loss: 0.8282
2024-06-01 21:18:00 [INFO]: Epoch 058 - training loss: 0.9843, validation loss: 0.8282
2024-06-01 21:18:00 [INFO]: Epoch 059 - training loss: 0.9833, validation loss: 0.8282
2024-06-01 21:18:00 [INFO]: Epoch 060 - training loss: 0.9796, validation loss: 0.8282
2024-06-01 21:18:00 [INFO]: Epoch 061 - training loss: 0.9787, validation loss: 0.8281
2024-06-01 21:18:00 [INFO]: Epoch 062 - training loss: 0.9755, validation loss: 0.8281
2024-06-01 21:18:00 [INFO]: Epoch 063 - training loss: 0.9772, validation loss: 0.8280
2024-06-01 21:18:00 [INFO]: Epoch 064 - training loss: 0.9796, validation loss: 0.8280
2024-06-01 21:18:01 [INFO]: Epoch 065 - training loss: 0.9827, validation loss: 0.8279
2024-06-01 21:18:01 [INFO]: Epoch 066 - training loss: 0.9772, validation loss: 0.8279
2024-06-01 21:18:01 [INFO]: Epoch 067 - training loss: 0.9707, validation loss: 0.8279
2024-06-01 21:18:01 [INFO]: Epoch 068 - training loss: 0.9794, validation loss: 0.8279
2024-06-01 21:18:01 [INFO]: Epoch 069 - training loss: 0.9714, validation loss: 0.8278
2024-06-01 21:18:01 [INFO]: Epoch 070 - training loss: 0.9795, validation loss: 0.8278
2024-06-01 21:18:01 [INFO]: Epoch 071 - training loss: 0.9768, validation loss: 0.8278
2024-06-01 21:18:01 [INFO]: Epoch 072 - training loss: 0.9774, validation loss: 0.8277
2024-06-01 21:18:02 [INFO]: Epoch 073 - training loss: 0.9723, validation loss: 0.8277
2024-06-01 21:18:02 [INFO]: Epoch 074 - training loss: 0.9729, validation loss: 0.8276
2024-06-01 21:18:02 [INFO]: Epoch 075 - training loss: 0.9676, validation loss: 0.8276
2024-06-01 21:18:02 [INFO]: Epoch 076 - training loss: 0.9817, validation loss: 0.8276
2024-06-01 21:18:02 [INFO]: Epoch 077 - training loss: 0.9691, validation loss: 0.8276
2024-06-01 21:18:02 [INFO]: Epoch 078 - training loss: 0.9700, validation loss: 0.8275
2024-06-01 21:18:02 [INFO]: Epoch 079 - training loss: 0.9773, validation loss: 0.8275
2024-06-01 21:18:02 [INFO]: Epoch 080 - training loss: 0.9688, validation loss: 0.8275
2024-06-01 21:18:02 [INFO]: Epoch 081 - training loss: 0.9670, validation loss: 0.8274
2024-06-01 21:18:03 [INFO]: Epoch 082 - training loss: 0.9800, validation loss: 0.8274
2024-06-01 21:18:03 [INFO]: Epoch 083 - training loss: 0.9763, validation loss: 0.8274
2024-06-01 21:18:03 [INFO]: Epoch 084 - training loss: 0.9687, validation loss: 0.8274
2024-06-01 21:18:03 [INFO]: Epoch 085 - training loss: 0.9855, validation loss: 0.8273
2024-06-01 21:18:03 [INFO]: Epoch 086 - training loss: 0.9693, validation loss: 0.8273
2024-06-01 21:18:03 [INFO]: Epoch 087 - training loss: 0.9667, validation loss: 0.8273
2024-06-01 21:18:03 [INFO]: Epoch 088 - training loss: 0.9597, validation loss: 0.8273
2024-06-01 21:18:03 [INFO]: Epoch 089 - training loss: 0.9790, validation loss: 0.8273
2024-06-01 21:18:04 [INFO]: Epoch 090 - training loss: 0.9745, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 091 - training loss: 0.9781, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 092 - training loss: 0.9702, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 093 - training loss: 0.9767, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 094 - training loss: 0.9676, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 095 - training loss: 0.9712, validation loss: 0.8272
2024-06-01 21:18:04 [INFO]: Epoch 096 - training loss: 0.9652, validation loss: 0.8271
2024-06-01 21:18:04 [INFO]: Epoch 097 - training loss: 0.9705, validation loss: 0.8271
2024-06-01 21:18:05 [INFO]: Epoch 098 - training loss: 0.9667, validation loss: 0.8271
2024-06-01 21:18:05 [INFO]: Epoch 099 - training loss: 0.9674, validation loss: 0.8271
2024-06-01 21:18:05 [INFO]: Epoch 100 - training loss: 0.9613, validation loss: 0.8271
2024-06-01 21:18:05 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 21:18:05 [INFO]: Saved the model to results_point_rate01/MRNN_Pedestrian/round_0/20240601_T211751/MRNN.pypots
2024-06-01 21:18:06 [INFO]: Successfully saved to results_point_rate01/MRNN_Pedestrian/round_0/imputation.pkl
2024-06-01 21:18:06 [INFO]: Round0 - MRNN on Pedestrian: MAE=0.7336, MSE=0.9209, MRE=1.0026
2024-06-01 21:18:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 21:18:06 [INFO]: Using the given device: cuda:0
2024-06-01 21:18:06 [INFO]: Model files will be saved to results_point_rate01/MRNN_Pedestrian/round_1/20240601_T211806
2024-06-01 21:18:06 [INFO]: Tensorboard file will be saved to results_point_rate01/MRNN_Pedestrian/round_1/20240601_T211806/tensorboard
2024-06-01 21:18:06 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 401,415
2024-06-01 21:18:07 [INFO]: Epoch 001 - training loss: 1.3631, validation loss: 0.9576
2024-06-01 21:18:07 [INFO]: Epoch 002 - training loss: 1.0732, validation loss: 0.9154
2024-06-01 21:18:07 [INFO]: Epoch 003 - training loss: 1.0254, validation loss: 0.8927
2024-06-01 21:18:07 [INFO]: Epoch 004 - training loss: 1.0069, validation loss: 0.8788
2024-06-01 21:18:07 [INFO]: Epoch 005 - training loss: 1.0114, validation loss: 0.8698
2024-06-01 21:18:07 [INFO]: Epoch 006 - training loss: 1.0008, validation loss: 0.8622
2024-06-01 21:18:07 [INFO]: Epoch 007 - training loss: 0.9932, validation loss: 0.8578
2024-06-01 21:18:07 [INFO]: Epoch 008 - training loss: 0.9882, validation loss: 0.8539
2024-06-01 21:18:08 [INFO]: Epoch 009 - training loss: 1.0032, validation loss: 0.8504
2024-06-01 21:18:08 [INFO]: Epoch 010 - training loss: 1.0082, validation loss: 0.8480
2024-06-01 21:18:08 [INFO]: Epoch 011 - training loss: 0.9933, validation loss: 0.8461
2024-06-01 21:18:08 [INFO]: Epoch 012 - training loss: 0.9836, validation loss: 0.8442
2024-06-01 21:18:08 [INFO]: Epoch 013 - training loss: 0.9958, validation loss: 0.8426
2024-06-01 21:18:08 [INFO]: Epoch 014 - training loss: 0.9835, validation loss: 0.8414
2024-06-01 21:18:08 [INFO]: Epoch 015 - training loss: 0.9825, validation loss: 0.8404
2024-06-01 21:18:08 [INFO]: Epoch 016 - training loss: 0.9797, validation loss: 0.8393
2024-06-01 21:18:09 [INFO]: Epoch 017 - training loss: 0.9837, validation loss: 0.8386
2024-06-01 21:18:09 [INFO]: Epoch 018 - training loss: 0.9819, validation loss: 0.8378
2024-06-01 21:18:09 [INFO]: Epoch 019 - training loss: 0.9701, validation loss: 0.8371
2024-06-01 21:18:09 [INFO]: Epoch 020 - training loss: 0.9789, validation loss: 0.8367
2024-06-01 21:18:09 [INFO]: Epoch 021 - training loss: 0.9783, validation loss: 0.8361
2024-06-01 21:18:09 [INFO]: Epoch 022 - training loss: 0.9851, validation loss: 0.8355
2024-06-01 21:18:09 [INFO]: Epoch 023 - training loss: 0.9742, validation loss: 0.8352
2024-06-01 21:18:09 [INFO]: Epoch 024 - training loss: 0.9774, validation loss: 0.8348
2024-06-01 21:18:10 [INFO]: Epoch 025 - training loss: 0.9726, validation loss: 0.8344
2024-06-01 21:18:10 [INFO]: Epoch 026 - training loss: 0.9700, validation loss: 0.8340
2024-06-01 21:18:10 [INFO]: Epoch 027 - training loss: 0.9694, validation loss: 0.8338
2024-06-01 21:18:10 [INFO]: Epoch 028 - training loss: 0.9855, validation loss: 0.8334
2024-06-01 21:18:10 [INFO]: Epoch 029 - training loss: 0.9872, validation loss: 0.8333
2024-06-01 21:18:10 [INFO]: Epoch 030 - training loss: 0.9780, validation loss: 0.8329
2024-06-01 21:18:10 [INFO]: Epoch 031 - training loss: 0.9797, validation loss: 0.8327
2024-06-01 21:18:10 [INFO]: Epoch 032 - training loss: 0.9781, validation loss: 0.8323
2024-06-01 21:18:11 [INFO]: Epoch 033 - training loss: 0.9856, validation loss: 0.8322
2024-06-01 21:18:11 [INFO]: Epoch 034 - training loss: 0.9923, validation loss: 0.8320
2024-06-01 21:18:11 [INFO]: Epoch 035 - training loss: 0.9803, validation loss: 0.8319
2024-06-01 21:18:11 [INFO]: Epoch 036 - training loss: 0.9771, validation loss: 0.8317
2024-06-01 21:18:11 [INFO]: Epoch 037 - training loss: 0.9963, validation loss: 0.8316
2024-06-01 21:18:11 [INFO]: Epoch 038 - training loss: 0.9774, validation loss: 0.8314
2024-06-01 21:18:11 [INFO]: Epoch 039 - training loss: 0.9937, validation loss: 0.8313
2024-06-01 21:18:11 [INFO]: Epoch 040 - training loss: 0.9834, validation loss: 0.8311
2024-06-01 21:18:12 [INFO]: Epoch 041 - training loss: 0.9771, validation loss: 0.8310
2024-06-01 21:18:12 [INFO]: Epoch 042 - training loss: 0.9794, validation loss: 0.8309
2024-06-01 21:18:12 [INFO]: Epoch 043 - training loss: 0.9691, validation loss: 0.8308
2024-06-01 21:18:12 [INFO]: Epoch 044 - training loss: 0.9702, validation loss: 0.8306
2024-06-01 21:18:12 [INFO]: Epoch 045 - training loss: 0.9658, validation loss: 0.8306
2024-06-01 21:18:12 [INFO]: Epoch 046 - training loss: 0.9901, validation loss: 0.8305
2024-06-01 21:18:12 [INFO]: Epoch 047 - training loss: 0.9761, validation loss: 0.8304
2024-06-01 21:18:12 [INFO]: Epoch 048 - training loss: 0.9749, validation loss: 0.8303
2024-06-01 21:18:13 [INFO]: Epoch 049 - training loss: 0.9829, validation loss: 0.8301
2024-06-01 21:18:13 [INFO]: Epoch 050 - training loss: 0.9856, validation loss: 0.8301
2024-06-01 21:18:13 [INFO]: Epoch 051 - training loss: 0.9688, validation loss: 0.8300
2024-06-01 21:18:13 [INFO]: Epoch 052 - training loss: 0.9658, validation loss: 0.8299
2024-06-01 21:18:13 [INFO]: Epoch 053 - training loss: 0.9722, validation loss: 0.8298
2024-06-01 21:18:13 [INFO]: Epoch 054 - training loss: 0.9867, validation loss: 0.8298
2024-06-01 21:18:13 [INFO]: Epoch 055 - training loss: 0.9787, validation loss: 0.8297
2024-06-01 21:18:13 [INFO]: Epoch 056 - training loss: 0.9787, validation loss: 0.8297
2024-06-01 21:18:14 [INFO]: Epoch 057 - training loss: 0.9698, validation loss: 0.8296
2024-06-01 21:18:14 [INFO]: Epoch 058 - training loss: 0.9788, validation loss: 0.8295
2024-06-01 21:18:14 [INFO]: Epoch 059 - training loss: 0.9697, validation loss: 0.8294
2024-06-01 21:18:14 [INFO]: Epoch 060 - training loss: 0.9755, validation loss: 0.8294
2024-06-01 21:18:14 [INFO]: Epoch 061 - training loss: 0.9806, validation loss: 0.8293
2024-06-01 21:18:14 [INFO]: Epoch 062 - training loss: 0.9803, validation loss: 0.8293
2024-06-01 21:18:14 [INFO]: Epoch 063 - training loss: 0.9808, validation loss: 0.8292
2024-06-01 21:18:14 [INFO]: Epoch 064 - training loss: 0.9695, validation loss: 0.8292
2024-06-01 21:18:15 [INFO]: Epoch 065 - training loss: 0.9641, validation loss: 0.8291
2024-06-01 21:18:15 [INFO]: Epoch 066 - training loss: 0.9742, validation loss: 0.8290
2024-06-01 21:18:15 [INFO]: Epoch 067 - training loss: 0.9697, validation loss: 0.8290
2024-06-01 21:18:15 [INFO]: Epoch 068 - training loss: 0.9683, validation loss: 0.8289
2024-06-01 21:18:15 [INFO]: Epoch 069 - training loss: 0.9687, validation loss: 0.8289
2024-06-01 21:18:15 [INFO]: Epoch 070 - training loss: 0.9734, validation loss: 0.8288
2024-06-01 21:18:15 [INFO]: Epoch 071 - training loss: 0.9648, validation loss: 0.8288
2024-06-01 21:18:15 [INFO]: Epoch 072 - training loss: 0.9685, validation loss: 0.8287
2024-06-01 21:18:16 [INFO]: Epoch 073 - training loss: 0.9691, validation loss: 0.8287
2024-06-01 21:18:16 [INFO]: Epoch 074 - training loss: 0.9685, validation loss: 0.8286
2024-06-01 21:18:16 [INFO]: Epoch 075 - training loss: 0.9711, validation loss: 0.8286
2024-06-01 21:18:16 [INFO]: Epoch 076 - training loss: 0.9694, validation loss: 0.8285
2024-06-01 21:18:16 [INFO]: Epoch 077 - training loss: 0.9723, validation loss: 0.8285
2024-06-01 21:18:16 [INFO]: Epoch 078 - training loss: 0.9723, validation loss: 0.8284
2024-06-01 21:18:16 [INFO]: Epoch 079 - training loss: 0.9693, validation loss: 0.8284
2024-06-01 21:18:16 [INFO]: Epoch 080 - training loss: 0.9705, validation loss: 0.8284
2024-06-01 21:18:17 [INFO]: Epoch 081 - training loss: 0.9698, validation loss: 0.8283
2024-06-01 21:18:17 [INFO]: Epoch 082 - training loss: 0.9727, validation loss: 0.8283
2024-06-01 21:18:17 [INFO]: Epoch 083 - training loss: 0.9814, validation loss: 0.8283
2024-06-01 21:18:17 [INFO]: Epoch 084 - training loss: 0.9733, validation loss: 0.8282
2024-06-01 21:18:17 [INFO]: Epoch 085 - training loss: 0.9765, validation loss: 0.8282
2024-06-01 21:18:17 [INFO]: Epoch 086 - training loss: 0.9866, validation loss: 0.8282
2024-06-01 21:18:17 [INFO]: Epoch 087 - training loss: 0.9855, validation loss: 0.8281
2024-06-01 21:18:17 [INFO]: Epoch 088 - training loss: 0.9783, validation loss: 0.8281
2024-06-01 21:18:17 [INFO]: Epoch 089 - training loss: 0.9720, validation loss: 0.8281
2024-06-01 21:18:18 [INFO]: Epoch 090 - training loss: 0.9692, validation loss: 0.8281
2024-06-01 21:18:18 [INFO]: Epoch 091 - training loss: 0.9753, validation loss: 0.8280
2024-06-01 21:18:18 [INFO]: Epoch 092 - training loss: 0.9693, validation loss: 0.8280
2024-06-01 21:18:18 [INFO]: Epoch 093 - training loss: 0.9731, validation loss: 0.8280
2024-06-01 21:18:18 [INFO]: Epoch 094 - training loss: 0.9733, validation loss: 0.8279
2024-06-01 21:18:18 [INFO]: Epoch 095 - training loss: 0.9805, validation loss: 0.8279
2024-06-01 21:18:18 [INFO]: Epoch 096 - training loss: 0.9778, validation loss: 0.8278
2024-06-01 21:18:18 [INFO]: Epoch 097 - training loss: 0.9739, validation loss: 0.8278
2024-06-01 21:18:19 [INFO]: Epoch 098 - training loss: 0.9653, validation loss: 0.8278
2024-06-01 21:18:19 [INFO]: Epoch 099 - training loss: 0.9717, validation loss: 0.8278
2024-06-01 21:18:19 [INFO]: Epoch 100 - training loss: 0.9785, validation loss: 0.8278
2024-06-01 21:18:19 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 21:18:19 [INFO]: Saved the model to results_point_rate01/MRNN_Pedestrian/round_1/20240601_T211806/MRNN.pypots
2024-06-01 21:18:20 [INFO]: Successfully saved to results_point_rate01/MRNN_Pedestrian/round_1/imputation.pkl
2024-06-01 21:18:20 [INFO]: Round1 - MRNN on Pedestrian: MAE=0.7348, MSE=0.9211, MRE=1.0043
2024-06-01 21:18:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 21:18:20 [INFO]: Using the given device: cuda:0
2024-06-01 21:18:20 [INFO]: Model files will be saved to results_point_rate01/MRNN_Pedestrian/round_2/20240601_T211820
2024-06-01 21:18:20 [INFO]: Tensorboard file will be saved to results_point_rate01/MRNN_Pedestrian/round_2/20240601_T211820/tensorboard
2024-06-01 21:18:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 401,415
2024-06-01 21:18:21 [INFO]: Epoch 001 - training loss: 1.2454, validation loss: 0.9505
2024-06-01 21:18:21 [INFO]: Epoch 002 - training loss: 1.0611, validation loss: 0.9112
2024-06-01 21:18:21 [INFO]: Epoch 003 - training loss: 1.0390, validation loss: 0.8883
2024-06-01 21:18:21 [INFO]: Epoch 004 - training loss: 1.0250, validation loss: 0.8740
2024-06-01 21:18:21 [INFO]: Epoch 005 - training loss: 1.0084, validation loss: 0.8659
2024-06-01 21:18:21 [INFO]: Epoch 006 - training loss: 1.0173, validation loss: 0.8596
2024-06-01 21:18:21 [INFO]: Epoch 007 - training loss: 0.9967, validation loss: 0.8550
2024-06-01 21:18:22 [INFO]: Epoch 008 - training loss: 0.9872, validation loss: 0.8512
2024-06-01 21:18:22 [INFO]: Epoch 009 - training loss: 0.9874, validation loss: 0.8488
2024-06-01 21:18:22 [INFO]: Epoch 010 - training loss: 1.0043, validation loss: 0.8464
2024-06-01 21:18:22 [INFO]: Epoch 011 - training loss: 1.0008, validation loss: 0.8448
2024-06-01 21:18:22 [INFO]: Epoch 012 - training loss: 0.9995, validation loss: 0.8431
2024-06-01 21:18:22 [INFO]: Epoch 013 - training loss: 1.0145, validation loss: 0.8422
2024-06-01 21:18:22 [INFO]: Epoch 014 - training loss: 0.9983, validation loss: 0.8410
2024-06-01 21:18:22 [INFO]: Epoch 015 - training loss: 0.9813, validation loss: 0.8399
2024-06-01 21:18:23 [INFO]: Epoch 016 - training loss: 0.9805, validation loss: 0.8391
2024-06-01 21:18:23 [INFO]: Epoch 017 - training loss: 0.9907, validation loss: 0.8384
2024-06-01 21:18:23 [INFO]: Epoch 018 - training loss: 0.9863, validation loss: 0.8378
2024-06-01 21:18:23 [INFO]: Epoch 019 - training loss: 0.9972, validation loss: 0.8375
2024-06-01 21:18:23 [INFO]: Epoch 020 - training loss: 0.9888, validation loss: 0.8366
2024-06-01 21:18:23 [INFO]: Epoch 021 - training loss: 0.9912, validation loss: 0.8363
2024-06-01 21:18:23 [INFO]: Epoch 022 - training loss: 0.9856, validation loss: 0.8358
2024-06-01 21:18:23 [INFO]: Epoch 023 - training loss: 0.9793, validation loss: 0.8354
2024-06-01 21:18:23 [INFO]: Epoch 024 - training loss: 0.9733, validation loss: 0.8351
2024-06-01 21:18:24 [INFO]: Epoch 025 - training loss: 0.9734, validation loss: 0.8347
2024-06-01 21:18:24 [INFO]: Epoch 026 - training loss: 0.9885, validation loss: 0.8345
2024-06-01 21:18:24 [INFO]: Epoch 027 - training loss: 0.9726, validation loss: 0.8340
2024-06-01 21:18:24 [INFO]: Epoch 028 - training loss: 0.9855, validation loss: 0.8339
2024-06-01 21:18:24 [INFO]: Epoch 029 - training loss: 0.9779, validation loss: 0.8334
2024-06-01 21:18:24 [INFO]: Epoch 030 - training loss: 0.9809, validation loss: 0.8333
2024-06-01 21:18:24 [INFO]: Epoch 031 - training loss: 0.9905, validation loss: 0.8331
2024-06-01 21:18:24 [INFO]: Epoch 032 - training loss: 0.9882, validation loss: 0.8329
2024-06-01 21:18:25 [INFO]: Epoch 033 - training loss: 0.9937, validation loss: 0.8327
2024-06-01 21:18:25 [INFO]: Epoch 034 - training loss: 0.9825, validation loss: 0.8325
2024-06-01 21:18:25 [INFO]: Epoch 035 - training loss: 0.9869, validation loss: 0.8323
2024-06-01 21:18:25 [INFO]: Epoch 036 - training loss: 0.9823, validation loss: 0.8320
2024-06-01 21:18:25 [INFO]: Epoch 037 - training loss: 0.9714, validation loss: 0.8319
2024-06-01 21:18:25 [INFO]: Epoch 038 - training loss: 0.9765, validation loss: 0.8318
2024-06-01 21:18:25 [INFO]: Epoch 039 - training loss: 0.9758, validation loss: 0.8316
2024-06-01 21:18:25 [INFO]: Epoch 040 - training loss: 0.9755, validation loss: 0.8314
2024-06-01 21:18:26 [INFO]: Epoch 041 - training loss: 0.9686, validation loss: 0.8314
2024-06-01 21:18:26 [INFO]: Epoch 042 - training loss: 0.9713, validation loss: 0.8311
2024-06-01 21:18:26 [INFO]: Epoch 043 - training loss: 0.9893, validation loss: 0.8311
2024-06-01 21:18:26 [INFO]: Epoch 044 - training loss: 0.9911, validation loss: 0.8310
2024-06-01 21:18:26 [INFO]: Epoch 045 - training loss: 0.9686, validation loss: 0.8308
2024-06-01 21:18:26 [INFO]: Epoch 046 - training loss: 0.9766, validation loss: 0.8307
2024-06-01 21:18:26 [INFO]: Epoch 047 - training loss: 0.9711, validation loss: 0.8306
2024-06-01 21:18:26 [INFO]: Epoch 048 - training loss: 0.9689, validation loss: 0.8305
2024-06-01 21:18:27 [INFO]: Epoch 049 - training loss: 0.9661, validation loss: 0.8305
2024-06-01 21:18:27 [INFO]: Epoch 050 - training loss: 0.9749, validation loss: 0.8304
2024-06-01 21:18:27 [INFO]: Epoch 051 - training loss: 0.9710, validation loss: 0.8303
2024-06-01 21:18:27 [INFO]: Epoch 052 - training loss: 0.9663, validation loss: 0.8301
2024-06-01 21:18:27 [INFO]: Epoch 053 - training loss: 0.9832, validation loss: 0.8301
2024-06-01 21:18:27 [INFO]: Epoch 054 - training loss: 0.9728, validation loss: 0.8300
2024-06-01 21:18:27 [INFO]: Epoch 055 - training loss: 0.9685, validation loss: 0.8299
2024-06-01 21:18:27 [INFO]: Epoch 056 - training loss: 0.9805, validation loss: 0.8299
2024-06-01 21:18:28 [INFO]: Epoch 057 - training loss: 0.9793, validation loss: 0.8298
2024-06-01 21:18:28 [INFO]: Epoch 058 - training loss: 0.9760, validation loss: 0.8297
2024-06-01 21:18:28 [INFO]: Epoch 059 - training loss: 0.9797, validation loss: 0.8297
2024-06-01 21:18:28 [INFO]: Epoch 060 - training loss: 0.9885, validation loss: 0.8296
2024-06-01 21:18:28 [INFO]: Epoch 061 - training loss: 0.9686, validation loss: 0.8295
2024-06-01 21:18:28 [INFO]: Epoch 062 - training loss: 0.9786, validation loss: 0.8294
2024-06-01 21:18:28 [INFO]: Epoch 063 - training loss: 0.9798, validation loss: 0.8294
2024-06-01 21:18:28 [INFO]: Epoch 064 - training loss: 0.9794, validation loss: 0.8293
2024-06-01 21:18:29 [INFO]: Epoch 065 - training loss: 0.9722, validation loss: 0.8292
2024-06-01 21:18:29 [INFO]: Epoch 066 - training loss: 0.9723, validation loss: 0.8292
2024-06-01 21:18:29 [INFO]: Epoch 067 - training loss: 0.9815, validation loss: 0.8291
2024-06-01 21:18:29 [INFO]: Epoch 068 - training loss: 0.9712, validation loss: 0.8291
2024-06-01 21:18:29 [INFO]: Epoch 069 - training loss: 0.9660, validation loss: 0.8290
2024-06-01 21:18:29 [INFO]: Epoch 070 - training loss: 0.9720, validation loss: 0.8289
2024-06-01 21:18:29 [INFO]: Epoch 071 - training loss: 0.9630, validation loss: 0.8289
2024-06-01 21:18:29 [INFO]: Epoch 072 - training loss: 0.9752, validation loss: 0.8289
2024-06-01 21:18:30 [INFO]: Epoch 073 - training loss: 0.9845, validation loss: 0.8288
2024-06-01 21:18:30 [INFO]: Epoch 074 - training loss: 0.9784, validation loss: 0.8288
2024-06-01 21:18:30 [INFO]: Epoch 075 - training loss: 0.9722, validation loss: 0.8287
2024-06-01 21:18:30 [INFO]: Epoch 076 - training loss: 0.9702, validation loss: 0.8287
2024-06-01 21:18:30 [INFO]: Epoch 077 - training loss: 0.9635, validation loss: 0.8287
2024-06-01 21:18:30 [INFO]: Epoch 078 - training loss: 0.9720, validation loss: 0.8286
2024-06-01 21:18:30 [INFO]: Epoch 079 - training loss: 0.9647, validation loss: 0.8286
2024-06-01 21:18:30 [INFO]: Epoch 080 - training loss: 0.9685, validation loss: 0.8286
2024-06-01 21:18:31 [INFO]: Epoch 081 - training loss: 0.9711, validation loss: 0.8285
2024-06-01 21:18:31 [INFO]: Epoch 082 - training loss: 0.9712, validation loss: 0.8285
2024-06-01 21:18:31 [INFO]: Epoch 083 - training loss: 0.9742, validation loss: 0.8284
2024-06-01 21:18:31 [INFO]: Epoch 084 - training loss: 0.9685, validation loss: 0.8284
2024-06-01 21:18:31 [INFO]: Epoch 085 - training loss: 0.9755, validation loss: 0.8284
2024-06-01 21:18:31 [INFO]: Epoch 086 - training loss: 0.9710, validation loss: 0.8283
2024-06-01 21:18:31 [INFO]: Epoch 087 - training loss: 0.9692, validation loss: 0.8283
2024-06-01 21:18:31 [INFO]: Epoch 088 - training loss: 0.9641, validation loss: 0.8282
2024-06-01 21:18:31 [INFO]: Epoch 089 - training loss: 0.9652, validation loss: 0.8282
2024-06-01 21:18:32 [INFO]: Epoch 090 - training loss: 0.9713, validation loss: 0.8282
2024-06-01 21:18:32 [INFO]: Epoch 091 - training loss: 0.9671, validation loss: 0.8281
2024-06-01 21:18:32 [INFO]: Epoch 092 - training loss: 0.9813, validation loss: 0.8281
2024-06-01 21:18:32 [INFO]: Epoch 093 - training loss: 0.9795, validation loss: 0.8281
2024-06-01 21:18:32 [INFO]: Epoch 094 - training loss: 0.9691, validation loss: 0.8281
2024-06-01 21:18:32 [INFO]: Epoch 095 - training loss: 0.9681, validation loss: 0.8280
2024-06-01 21:18:32 [INFO]: Epoch 096 - training loss: 0.9581, validation loss: 0.8280
2024-06-01 21:18:32 [INFO]: Epoch 097 - training loss: 0.9633, validation loss: 0.8279
2024-06-01 21:18:33 [INFO]: Epoch 098 - training loss: 0.9629, validation loss: 0.8279
2024-06-01 21:18:33 [INFO]: Epoch 099 - training loss: 0.9803, validation loss: 0.8279
2024-06-01 21:18:33 [INFO]: Epoch 100 - training loss: 0.9659, validation loss: 0.8279
2024-06-01 21:18:33 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 21:18:33 [INFO]: Saved the model to results_point_rate01/MRNN_Pedestrian/round_2/20240601_T211820/MRNN.pypots
2024-06-01 21:18:34 [INFO]: Successfully saved to results_point_rate01/MRNN_Pedestrian/round_2/imputation.pkl
2024-06-01 21:18:34 [INFO]: Round2 - MRNN on Pedestrian: MAE=0.7350, MSE=0.9212, MRE=1.0045
2024-06-01 21:18:34 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 21:18:34 [INFO]: Using the given device: cuda:0
2024-06-01 21:18:34 [INFO]: Model files will be saved to results_point_rate01/MRNN_Pedestrian/round_3/20240601_T211834
2024-06-01 21:18:34 [INFO]: Tensorboard file will be saved to results_point_rate01/MRNN_Pedestrian/round_3/20240601_T211834/tensorboard
2024-06-01 21:18:34 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 401,415
2024-06-01 21:18:35 [INFO]: Epoch 001 - training loss: 1.3079, validation loss: 1.0491
2024-06-01 21:18:35 [INFO]: Epoch 002 - training loss: 1.0852, validation loss: 0.9807
2024-06-01 21:18:35 [INFO]: Epoch 003 - training loss: 1.0457, validation loss: 0.9379
2024-06-01 21:18:35 [INFO]: Epoch 004 - training loss: 1.0364, validation loss: 0.9127
2024-06-01 21:18:35 [INFO]: Epoch 005 - training loss: 1.0220, validation loss: 0.8948
2024-06-01 21:18:35 [INFO]: Epoch 006 - training loss: 1.0308, validation loss: 0.8820
2024-06-01 21:18:35 [INFO]: Epoch 007 - training loss: 1.0388, validation loss: 0.8726
2024-06-01 21:18:36 [INFO]: Epoch 008 - training loss: 1.0021, validation loss: 0.8644
2024-06-01 21:18:36 [INFO]: Epoch 009 - training loss: 1.0127, validation loss: 0.8585
2024-06-01 21:18:36 [INFO]: Epoch 010 - training loss: 1.0013, validation loss: 0.8529
2024-06-01 21:18:36 [INFO]: Epoch 011 - training loss: 1.0108, validation loss: 0.8493
2024-06-01 21:18:36 [INFO]: Epoch 012 - training loss: 0.9873, validation loss: 0.8464
2024-06-01 21:18:36 [INFO]: Epoch 013 - training loss: 0.9834, validation loss: 0.8438
2024-06-01 21:18:36 [INFO]: Epoch 014 - training loss: 0.9897, validation loss: 0.8420
2024-06-01 21:18:36 [INFO]: Epoch 015 - training loss: 0.9956, validation loss: 0.8404
2024-06-01 21:18:36 [INFO]: Epoch 016 - training loss: 0.9737, validation loss: 0.8389
2024-06-01 21:18:37 [INFO]: Epoch 017 - training loss: 0.9754, validation loss: 0.8378
2024-06-01 21:18:37 [INFO]: Epoch 018 - training loss: 0.9796, validation loss: 0.8371
2024-06-01 21:18:37 [INFO]: Epoch 019 - training loss: 0.9799, validation loss: 0.8363
2024-06-01 21:18:37 [INFO]: Epoch 020 - training loss: 0.9834, validation loss: 0.8357
2024-06-01 21:18:37 [INFO]: Epoch 021 - training loss: 0.9925, validation loss: 0.8353
2024-06-01 21:18:37 [INFO]: Epoch 022 - training loss: 0.9709, validation loss: 0.8347
2024-06-01 21:18:37 [INFO]: Epoch 023 - training loss: 0.9850, validation loss: 0.8343
2024-06-01 21:18:37 [INFO]: Epoch 024 - training loss: 0.9989, validation loss: 0.8338
2024-06-01 21:18:38 [INFO]: Epoch 025 - training loss: 0.9783, validation loss: 0.8335
2024-06-01 21:18:38 [INFO]: Epoch 026 - training loss: 0.9815, validation loss: 0.8332
2024-06-01 21:18:38 [INFO]: Epoch 027 - training loss: 0.9790, validation loss: 0.8329
2024-06-01 21:18:38 [INFO]: Epoch 028 - training loss: 0.9802, validation loss: 0.8326
2024-06-01 21:18:38 [INFO]: Epoch 029 - training loss: 0.9760, validation loss: 0.8324
2024-06-01 21:18:38 [INFO]: Epoch 030 - training loss: 0.9764, validation loss: 0.8321
2024-06-01 21:18:38 [INFO]: Epoch 031 - training loss: 0.9747, validation loss: 0.8319
2024-06-01 21:18:38 [INFO]: Epoch 032 - training loss: 0.9757, validation loss: 0.8317
2024-06-01 21:18:39 [INFO]: Epoch 033 - training loss: 0.9846, validation loss: 0.8316
2024-06-01 21:18:39 [INFO]: Epoch 034 - training loss: 0.9813, validation loss: 0.8314
2024-06-01 21:18:39 [INFO]: Epoch 035 - training loss: 0.9730, validation loss: 0.8312
2024-06-01 21:18:39 [INFO]: Epoch 036 - training loss: 0.9734, validation loss: 0.8310
2024-06-01 21:18:39 [INFO]: Epoch 037 - training loss: 0.9677, validation loss: 0.8309
2024-06-01 21:18:39 [INFO]: Epoch 038 - training loss: 0.9709, validation loss: 0.8308
2024-06-01 21:18:39 [INFO]: Epoch 039 - training loss: 0.9719, validation loss: 0.8306
2024-06-01 21:18:39 [INFO]: Epoch 040 - training loss: 0.9918, validation loss: 0.8305
2024-06-01 21:18:40 [INFO]: Epoch 041 - training loss: 0.9772, validation loss: 0.8303
2024-06-01 21:18:40 [INFO]: Epoch 042 - training loss: 0.9842, validation loss: 0.8302
2024-06-01 21:18:40 [INFO]: Epoch 043 - training loss: 0.9819, validation loss: 0.8301
2024-06-01 21:18:40 [INFO]: Epoch 044 - training loss: 0.9849, validation loss: 0.8300
2024-06-01 21:18:40 [INFO]: Epoch 045 - training loss: 0.9746, validation loss: 0.8299
2024-06-01 21:18:40 [INFO]: Epoch 046 - training loss: 0.9812, validation loss: 0.8298
2024-06-01 21:18:40 [INFO]: Epoch 047 - training loss: 0.9817, validation loss: 0.8297
2024-06-01 21:18:40 [INFO]: Epoch 048 - training loss: 0.9653, validation loss: 0.8297
2024-06-01 21:18:40 [INFO]: Epoch 049 - training loss: 0.9792, validation loss: 0.8295
2024-06-01 21:18:41 [INFO]: Epoch 050 - training loss: 0.9733, validation loss: 0.8295
2024-06-01 21:18:41 [INFO]: Epoch 051 - training loss: 0.9776, validation loss: 0.8294
2024-06-01 21:18:41 [INFO]: Epoch 052 - training loss: 0.9760, validation loss: 0.8293
2024-06-01 21:18:41 [INFO]: Epoch 053 - training loss: 0.9741, validation loss: 0.8292
2024-06-01 21:18:41 [INFO]: Epoch 054 - training loss: 0.9783, validation loss: 0.8292
2024-06-01 21:18:41 [INFO]: Epoch 055 - training loss: 0.9795, validation loss: 0.8291
2024-06-01 21:18:41 [INFO]: Epoch 056 - training loss: 0.9758, validation loss: 0.8291
2024-06-01 21:18:41 [INFO]: Epoch 057 - training loss: 0.9737, validation loss: 0.8290
2024-06-01 21:18:42 [INFO]: Epoch 058 - training loss: 0.9700, validation loss: 0.8289
2024-06-01 21:18:42 [INFO]: Epoch 059 - training loss: 0.9713, validation loss: 0.8289
2024-06-01 21:18:42 [INFO]: Epoch 060 - training loss: 0.9737, validation loss: 0.8288
2024-06-01 21:18:42 [INFO]: Epoch 061 - training loss: 0.9743, validation loss: 0.8288
2024-06-01 21:18:42 [INFO]: Epoch 062 - training loss: 0.9881, validation loss: 0.8287
2024-06-01 21:18:42 [INFO]: Epoch 063 - training loss: 0.9715, validation loss: 0.8287
2024-06-01 21:18:42 [INFO]: Epoch 064 - training loss: 0.9767, validation loss: 0.8286
2024-06-01 21:18:42 [INFO]: Epoch 065 - training loss: 0.9704, validation loss: 0.8286
2024-06-01 21:18:43 [INFO]: Epoch 066 - training loss: 0.9668, validation loss: 0.8285
2024-06-01 21:18:43 [INFO]: Epoch 067 - training loss: 0.9679, validation loss: 0.8285
2024-06-01 21:18:43 [INFO]: Epoch 068 - training loss: 0.9720, validation loss: 0.8284
2024-06-01 21:18:43 [INFO]: Epoch 069 - training loss: 0.9767, validation loss: 0.8284
2024-06-01 21:18:43 [INFO]: Epoch 070 - training loss: 0.9800, validation loss: 0.8284
2024-06-01 21:18:43 [INFO]: Epoch 071 - training loss: 0.9745, validation loss: 0.8283
2024-06-01 21:18:43 [INFO]: Epoch 072 - training loss: 0.9649, validation loss: 0.8283
2024-06-01 21:18:43 [INFO]: Epoch 073 - training loss: 0.9659, validation loss: 0.8283
2024-06-01 21:18:44 [INFO]: Epoch 074 - training loss: 0.9729, validation loss: 0.8282
2024-06-01 21:18:44 [INFO]: Epoch 075 - training loss: 0.9809, validation loss: 0.8282
2024-06-01 21:18:44 [INFO]: Epoch 076 - training loss: 0.9710, validation loss: 0.8281
2024-06-01 21:18:44 [INFO]: Epoch 077 - training loss: 0.9675, validation loss: 0.8281
2024-06-01 21:18:44 [INFO]: Epoch 078 - training loss: 0.9732, validation loss: 0.8281
2024-06-01 21:18:44 [INFO]: Epoch 079 - training loss: 0.9679, validation loss: 0.8280
2024-06-01 21:18:44 [INFO]: Epoch 080 - training loss: 0.9679, validation loss: 0.8280
2024-06-01 21:18:44 [INFO]: Epoch 081 - training loss: 0.9692, validation loss: 0.8280
2024-06-01 21:18:45 [INFO]: Epoch 082 - training loss: 0.9649, validation loss: 0.8279
2024-06-01 21:18:45 [INFO]: Epoch 083 - training loss: 0.9747, validation loss: 0.8279
2024-06-01 21:18:45 [INFO]: Epoch 084 - training loss: 0.9803, validation loss: 0.8279
2024-06-01 21:18:45 [INFO]: Epoch 085 - training loss: 0.9730, validation loss: 0.8279
2024-06-01 21:18:45 [INFO]: Epoch 086 - training loss: 0.9657, validation loss: 0.8278
2024-06-01 21:18:45 [INFO]: Epoch 087 - training loss: 0.9681, validation loss: 0.8278
2024-06-01 21:18:45 [INFO]: Epoch 088 - training loss: 0.9790, validation loss: 0.8278
2024-06-01 21:18:45 [INFO]: Epoch 089 - training loss: 0.9719, validation loss: 0.8278
2024-06-01 21:18:46 [INFO]: Epoch 090 - training loss: 0.9749, validation loss: 0.8277
2024-06-01 21:18:46 [INFO]: Epoch 091 - training loss: 0.9803, validation loss: 0.8277
2024-06-01 21:18:46 [INFO]: Epoch 092 - training loss: 0.9694, validation loss: 0.8277
2024-06-01 21:18:46 [INFO]: Epoch 093 - training loss: 0.9788, validation loss: 0.8277
2024-06-01 21:18:46 [INFO]: Epoch 094 - training loss: 0.9707, validation loss: 0.8276
2024-06-01 21:18:46 [INFO]: Epoch 095 - training loss: 0.9733, validation loss: 0.8276
2024-06-01 21:18:46 [INFO]: Epoch 096 - training loss: 0.9696, validation loss: 0.8276
2024-06-01 21:18:46 [INFO]: Epoch 097 - training loss: 0.9734, validation loss: 0.8276
2024-06-01 21:18:46 [INFO]: Epoch 098 - training loss: 0.9668, validation loss: 0.8275
2024-06-01 21:18:47 [INFO]: Epoch 099 - training loss: 0.9691, validation loss: 0.8275
2024-06-01 21:18:47 [INFO]: Epoch 100 - training loss: 0.9760, validation loss: 0.8275
2024-06-01 21:18:47 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 21:18:47 [INFO]: Saved the model to results_point_rate01/MRNN_Pedestrian/round_3/20240601_T211834/MRNN.pypots
2024-06-01 21:18:48 [INFO]: Successfully saved to results_point_rate01/MRNN_Pedestrian/round_3/imputation.pkl
2024-06-01 21:18:48 [INFO]: Round3 - MRNN on Pedestrian: MAE=0.7344, MSE=0.9210, MRE=1.0037
2024-06-01 21:18:48 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 21:18:48 [INFO]: Using the given device: cuda:0
2024-06-01 21:18:48 [INFO]: Model files will be saved to results_point_rate01/MRNN_Pedestrian/round_4/20240601_T211848
2024-06-01 21:18:48 [INFO]: Tensorboard file will be saved to results_point_rate01/MRNN_Pedestrian/round_4/20240601_T211848/tensorboard
2024-06-01 21:18:48 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 401,415
2024-06-01 21:18:49 [INFO]: Epoch 001 - training loss: 1.3903, validation loss: 1.3165
2024-06-01 21:18:49 [INFO]: Epoch 002 - training loss: 1.1665, validation loss: 1.1680
2024-06-01 21:18:49 [INFO]: Epoch 003 - training loss: 1.1084, validation loss: 1.0420
2024-06-01 21:18:49 [INFO]: Epoch 004 - training loss: 1.0533, validation loss: 0.9571
2024-06-01 21:18:49 [INFO]: Epoch 005 - training loss: 1.0192, validation loss: 0.9170
2024-06-01 21:18:49 [INFO]: Epoch 006 - training loss: 1.0163, validation loss: 0.8946
2024-06-01 21:18:49 [INFO]: Epoch 007 - training loss: 1.0069, validation loss: 0.8811
2024-06-01 21:18:50 [INFO]: Epoch 008 - training loss: 0.9960, validation loss: 0.8717
2024-06-01 21:18:50 [INFO]: Epoch 009 - training loss: 1.0023, validation loss: 0.8647
2024-06-01 21:18:50 [INFO]: Epoch 010 - training loss: 1.0046, validation loss: 0.8597
2024-06-01 21:18:50 [INFO]: Epoch 011 - training loss: 1.0113, validation loss: 0.8557
2024-06-01 21:18:50 [INFO]: Epoch 012 - training loss: 1.0125, validation loss: 0.8528
2024-06-01 21:18:50 [INFO]: Epoch 013 - training loss: 0.9967, validation loss: 0.8505
2024-06-01 21:18:50 [INFO]: Epoch 014 - training loss: 0.9891, validation loss: 0.8482
2024-06-01 21:18:50 [INFO]: Epoch 015 - training loss: 0.9868, validation loss: 0.8462
2024-06-01 21:18:51 [INFO]: Epoch 016 - training loss: 0.9890, validation loss: 0.8449
2024-06-01 21:18:51 [INFO]: Epoch 017 - training loss: 0.9982, validation loss: 0.8439
2024-06-01 21:18:51 [INFO]: Epoch 018 - training loss: 0.9791, validation loss: 0.8428
2024-06-01 21:18:51 [INFO]: Epoch 019 - training loss: 0.9801, validation loss: 0.8417
2024-06-01 21:18:51 [INFO]: Epoch 020 - training loss: 0.9730, validation loss: 0.8408
2024-06-01 21:18:51 [INFO]: Epoch 021 - training loss: 0.9761, validation loss: 0.8399
2024-06-01 21:18:51 [INFO]: Epoch 022 - training loss: 0.9955, validation loss: 0.8392
2024-06-01 21:18:51 [INFO]: Epoch 023 - training loss: 0.9742, validation loss: 0.8387
2024-06-01 21:18:52 [INFO]: Epoch 024 - training loss: 0.9794, validation loss: 0.8382
2024-06-01 21:18:52 [INFO]: Epoch 025 - training loss: 0.9828, validation loss: 0.8376
2024-06-01 21:18:52 [INFO]: Epoch 026 - training loss: 0.9878, validation loss: 0.8371
2024-06-01 21:18:52 [INFO]: Epoch 027 - training loss: 0.9740, validation loss: 0.8366
2024-06-01 21:18:52 [INFO]: Epoch 028 - training loss: 0.9747, validation loss: 0.8362
2024-06-01 21:18:52 [INFO]: Epoch 029 - training loss: 0.9919, validation loss: 0.8358
2024-06-01 21:18:52 [INFO]: Epoch 030 - training loss: 0.9742, validation loss: 0.8354
2024-06-01 21:18:52 [INFO]: Epoch 031 - training loss: 0.9958, validation loss: 0.8351
2024-06-01 21:18:53 [INFO]: Epoch 032 - training loss: 0.9816, validation loss: 0.8348
2024-06-01 21:18:53 [INFO]: Epoch 033 - training loss: 0.9782, validation loss: 0.8345
2024-06-01 21:18:53 [INFO]: Epoch 034 - training loss: 0.9852, validation loss: 0.8342
2024-06-01 21:18:53 [INFO]: Epoch 035 - training loss: 0.9755, validation loss: 0.8339
2024-06-01 21:18:53 [INFO]: Epoch 036 - training loss: 0.9908, validation loss: 0.8338
2024-06-01 21:18:53 [INFO]: Epoch 037 - training loss: 0.9677, validation loss: 0.8335
2024-06-01 21:18:53 [INFO]: Epoch 038 - training loss: 0.9761, validation loss: 0.8333
2024-06-01 21:18:53 [INFO]: Epoch 039 - training loss: 0.9928, validation loss: 0.8331
2024-06-01 21:18:53 [INFO]: Epoch 040 - training loss: 0.9748, validation loss: 0.8329
2024-06-01 21:18:54 [INFO]: Epoch 041 - training loss: 0.9779, validation loss: 0.8327
2024-06-01 21:18:54 [INFO]: Epoch 042 - training loss: 0.9740, validation loss: 0.8324
2024-06-01 21:18:54 [INFO]: Epoch 043 - training loss: 0.9775, validation loss: 0.8322
2024-06-01 21:18:54 [INFO]: Epoch 044 - training loss: 0.9708, validation loss: 0.8321
2024-06-01 21:18:54 [INFO]: Epoch 045 - training loss: 0.9844, validation loss: 0.8319
2024-06-01 21:18:54 [INFO]: Epoch 046 - training loss: 0.9782, validation loss: 0.8318
2024-06-01 21:18:54 [INFO]: Epoch 047 - training loss: 0.9693, validation loss: 0.8316
2024-06-01 21:18:54 [INFO]: Epoch 048 - training loss: 0.9845, validation loss: 0.8315
2024-06-01 21:18:55 [INFO]: Epoch 049 - training loss: 0.9847, validation loss: 0.8314
2024-06-01 21:18:55 [INFO]: Epoch 050 - training loss: 0.9781, validation loss: 0.8312
2024-06-01 21:18:55 [INFO]: Epoch 051 - training loss: 0.9712, validation loss: 0.8311
2024-06-01 21:18:55 [INFO]: Epoch 052 - training loss: 0.9639, validation loss: 0.8310
2024-06-01 21:18:55 [INFO]: Epoch 053 - training loss: 0.9686, validation loss: 0.8309
2024-06-01 21:18:55 [INFO]: Epoch 054 - training loss: 0.9734, validation loss: 0.8308
2024-06-01 21:18:55 [INFO]: Epoch 055 - training loss: 0.9831, validation loss: 0.8307
2024-06-01 21:18:55 [INFO]: Epoch 056 - training loss: 0.9873, validation loss: 0.8306
2024-06-01 21:18:56 [INFO]: Epoch 057 - training loss: 0.9684, validation loss: 0.8305
2024-06-01 21:18:56 [INFO]: Epoch 058 - training loss: 0.9793, validation loss: 0.8304
2024-06-01 21:18:56 [INFO]: Epoch 059 - training loss: 0.9735, validation loss: 0.8303
2024-06-01 21:18:56 [INFO]: Epoch 060 - training loss: 0.9630, validation loss: 0.8302
2024-06-01 21:18:56 [INFO]: Epoch 061 - training loss: 0.9748, validation loss: 0.8302
2024-06-01 21:18:56 [INFO]: Epoch 062 - training loss: 0.9714, validation loss: 0.8301
2024-06-01 21:18:56 [INFO]: Epoch 063 - training loss: 0.9837, validation loss: 0.8300
2024-06-01 21:18:56 [INFO]: Epoch 064 - training loss: 0.9762, validation loss: 0.8300
2024-06-01 21:18:57 [INFO]: Epoch 065 - training loss: 0.9674, validation loss: 0.8299
2024-06-01 21:18:57 [INFO]: Epoch 066 - training loss: 0.9790, validation loss: 0.8298
2024-06-01 21:18:57 [INFO]: Epoch 067 - training loss: 0.9709, validation loss: 0.8298
2024-06-01 21:18:57 [INFO]: Epoch 068 - training loss: 0.9742, validation loss: 0.8297
2024-06-01 21:18:57 [INFO]: Epoch 069 - training loss: 0.9852, validation loss: 0.8296
2024-06-01 21:18:57 [INFO]: Epoch 070 - training loss: 0.9845, validation loss: 0.8295
2024-06-01 21:18:57 [INFO]: Epoch 071 - training loss: 0.9635, validation loss: 0.8295
2024-06-01 21:18:57 [INFO]: Epoch 072 - training loss: 0.9683, validation loss: 0.8294
2024-06-01 21:18:58 [INFO]: Epoch 073 - training loss: 0.9732, validation loss: 0.8294
2024-06-01 21:18:58 [INFO]: Epoch 074 - training loss: 0.9848, validation loss: 0.8293
2024-06-01 21:18:58 [INFO]: Epoch 075 - training loss: 0.9712, validation loss: 0.8292
2024-06-01 21:18:58 [INFO]: Epoch 076 - training loss: 0.9633, validation loss: 0.8292
2024-06-01 21:18:58 [INFO]: Epoch 077 - training loss: 0.9741, validation loss: 0.8291
2024-06-01 21:18:58 [INFO]: Epoch 078 - training loss: 0.9844, validation loss: 0.8291
2024-06-01 21:18:58 [INFO]: Epoch 079 - training loss: 0.9851, validation loss: 0.8290
2024-06-01 21:18:58 [INFO]: Epoch 080 - training loss: 0.9731, validation loss: 0.8290
2024-06-01 21:18:59 [INFO]: Epoch 081 - training loss: 0.9701, validation loss: 0.8289
2024-06-01 21:18:59 [INFO]: Epoch 082 - training loss: 0.9715, validation loss: 0.8289
2024-06-01 21:18:59 [INFO]: Epoch 083 - training loss: 0.9688, validation loss: 0.8289
2024-06-01 21:18:59 [INFO]: Epoch 084 - training loss: 0.9702, validation loss: 0.8288
2024-06-01 21:18:59 [INFO]: Epoch 085 - training loss: 0.9811, validation loss: 0.8288
2024-06-01 21:18:59 [INFO]: Epoch 086 - training loss: 0.9747, validation loss: 0.8287
2024-06-01 21:18:59 [INFO]: Epoch 087 - training loss: 0.9693, validation loss: 0.8287
2024-06-01 21:18:59 [INFO]: Epoch 088 - training loss: 0.9682, validation loss: 0.8286
2024-06-01 21:18:59 [INFO]: Epoch 089 - training loss: 0.9679, validation loss: 0.8286
2024-06-01 21:19:00 [INFO]: Epoch 090 - training loss: 0.9708, validation loss: 0.8286
2024-06-01 21:19:00 [INFO]: Epoch 091 - training loss: 0.9705, validation loss: 0.8285
2024-06-01 21:19:00 [INFO]: Epoch 092 - training loss: 0.9686, validation loss: 0.8285
2024-06-01 21:19:00 [INFO]: Epoch 093 - training loss: 0.9785, validation loss: 0.8285
2024-06-01 21:19:00 [INFO]: Epoch 094 - training loss: 1.0066, validation loss: 0.8284
2024-06-01 21:19:00 [INFO]: Epoch 095 - training loss: 0.9745, validation loss: 0.8284
2024-06-01 21:19:00 [INFO]: Epoch 096 - training loss: 0.9776, validation loss: 0.8284
2024-06-01 21:19:00 [INFO]: Epoch 097 - training loss: 0.9709, validation loss: 0.8283
2024-06-01 21:19:01 [INFO]: Epoch 098 - training loss: 0.9724, validation loss: 0.8283
2024-06-01 21:19:01 [INFO]: Epoch 099 - training loss: 0.9743, validation loss: 0.8283
2024-06-01 21:19:01 [INFO]: Epoch 100 - training loss: 0.9776, validation loss: 0.8282
2024-06-01 21:19:01 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 21:19:01 [INFO]: Saved the model to results_point_rate01/MRNN_Pedestrian/round_4/20240601_T211848/MRNN.pypots
2024-06-01 21:19:02 [INFO]: Successfully saved to results_point_rate01/MRNN_Pedestrian/round_4/imputation.pkl
2024-06-01 21:19:02 [INFO]: Round4 - MRNN on Pedestrian: MAE=0.7356, MSE=0.9213, MRE=1.0053
2024-06-01 21:19:02 [INFO]: Done! Final results:
Averaged MRNN (n params: 401,415) on Pedestrian: MAE=0.7347 ± 0.0006565096909281854, MSE=0.9211 ± 0.00010930247429448246, MRE=1.0041 ± 0.0008972200210758454, average inference time=1.21
