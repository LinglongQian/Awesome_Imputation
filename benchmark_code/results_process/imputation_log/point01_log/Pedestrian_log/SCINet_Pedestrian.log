2024-06-01 21:20:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:20:24 [INFO]: Using the given device: cuda:0
2024-06-01 21:20:24 [INFO]: Model files will be saved to results_point_rate01/SCINet_Pedestrian/round_0/20240601_T212024
2024-06-01 21:20:24 [INFO]: Tensorboard file will be saved to results_point_rate01/SCINet_Pedestrian/round_0/20240601_T212024/tensorboard
2024-06-01 21:20:25 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-01 21:20:26 [INFO]: Epoch 001 - training loss: 1.5289, validation loss: 0.8581
2024-06-01 21:20:26 [INFO]: Epoch 002 - training loss: 1.4323, validation loss: 0.8832
2024-06-01 21:20:27 [INFO]: Epoch 003 - training loss: 1.3894, validation loss: 0.8888
2024-06-01 21:20:27 [INFO]: Epoch 004 - training loss: 1.3626, validation loss: 0.8197
2024-06-01 21:20:27 [INFO]: Epoch 005 - training loss: 1.2902, validation loss: 0.7178
2024-06-01 21:20:28 [INFO]: Epoch 006 - training loss: 1.1827, validation loss: 0.5267
2024-06-01 21:20:28 [INFO]: Epoch 007 - training loss: 1.0118, validation loss: 0.4523
2024-06-01 21:20:29 [INFO]: Epoch 008 - training loss: 0.8731, validation loss: 0.3285
2024-06-01 21:20:29 [INFO]: Epoch 009 - training loss: 0.8127, validation loss: 0.3040
2024-06-01 21:20:29 [INFO]: Epoch 010 - training loss: 0.7703, validation loss: 0.2750
2024-06-01 21:20:30 [INFO]: Epoch 011 - training loss: 0.7481, validation loss: 0.2555
2024-06-01 21:20:30 [INFO]: Epoch 012 - training loss: 0.7110, validation loss: 0.2272
2024-06-01 21:20:30 [INFO]: Epoch 013 - training loss: 0.6759, validation loss: 0.2050
2024-06-01 21:20:31 [INFO]: Epoch 014 - training loss: 0.6351, validation loss: 0.1788
2024-06-01 21:20:31 [INFO]: Epoch 015 - training loss: 0.5920, validation loss: 0.1521
2024-06-01 21:20:31 [INFO]: Epoch 016 - training loss: 0.5717, validation loss: 0.1286
2024-06-01 21:20:32 [INFO]: Epoch 017 - training loss: 0.5176, validation loss: 0.1168
2024-06-01 21:20:32 [INFO]: Epoch 018 - training loss: 0.5247, validation loss: 0.1119
2024-06-01 21:20:32 [INFO]: Epoch 019 - training loss: 0.4978, validation loss: 0.1054
2024-06-01 21:20:33 [INFO]: Epoch 020 - training loss: 0.4757, validation loss: 0.0994
2024-06-01 21:20:33 [INFO]: Epoch 021 - training loss: 0.4711, validation loss: 0.0884
2024-06-01 21:20:33 [INFO]: Epoch 022 - training loss: 0.4556, validation loss: 0.0874
2024-06-01 21:20:34 [INFO]: Epoch 023 - training loss: 0.4450, validation loss: 0.0836
2024-06-01 21:20:34 [INFO]: Epoch 024 - training loss: 0.4408, validation loss: 0.0851
2024-06-01 21:20:34 [INFO]: Epoch 025 - training loss: 0.4296, validation loss: 0.0783
2024-06-01 21:20:35 [INFO]: Epoch 026 - training loss: 0.4281, validation loss: 0.0837
2024-06-01 21:20:35 [INFO]: Epoch 027 - training loss: 0.4160, validation loss: 0.0804
2024-06-01 21:20:35 [INFO]: Epoch 028 - training loss: 0.4236, validation loss: 0.0795
2024-06-01 21:20:36 [INFO]: Epoch 029 - training loss: 0.4132, validation loss: 0.0786
2024-06-01 21:20:36 [INFO]: Epoch 030 - training loss: 0.4048, validation loss: 0.0763
2024-06-01 21:20:37 [INFO]: Epoch 031 - training loss: 0.4053, validation loss: 0.0731
2024-06-01 21:20:37 [INFO]: Epoch 032 - training loss: 0.3905, validation loss: 0.0735
2024-06-01 21:20:37 [INFO]: Epoch 033 - training loss: 0.4117, validation loss: 0.0724
2024-06-01 21:20:38 [INFO]: Epoch 034 - training loss: 0.4012, validation loss: 0.0715
2024-06-01 21:20:38 [INFO]: Epoch 035 - training loss: 0.3850, validation loss: 0.0686
2024-06-01 21:20:38 [INFO]: Epoch 036 - training loss: 0.3846, validation loss: 0.0689
2024-06-01 21:20:39 [INFO]: Epoch 037 - training loss: 0.4099, validation loss: 0.0660
2024-06-01 21:20:39 [INFO]: Epoch 038 - training loss: 0.4007, validation loss: 0.0682
2024-06-01 21:20:39 [INFO]: Epoch 039 - training loss: 0.3846, validation loss: 0.0681
2024-06-01 21:20:40 [INFO]: Epoch 040 - training loss: 0.3990, validation loss: 0.0723
2024-06-01 21:20:40 [INFO]: Epoch 041 - training loss: 0.3951, validation loss: 0.0688
2024-06-01 21:20:40 [INFO]: Epoch 042 - training loss: 0.3957, validation loss: 0.0656
2024-06-01 21:20:41 [INFO]: Epoch 043 - training loss: 0.3761, validation loss: 0.0660
2024-06-01 21:20:41 [INFO]: Epoch 044 - training loss: 0.3790, validation loss: 0.0732
2024-06-01 21:20:41 [INFO]: Epoch 045 - training loss: 0.3837, validation loss: 0.0659
2024-06-01 21:20:42 [INFO]: Epoch 046 - training loss: 0.3755, validation loss: 0.0654
2024-06-01 21:20:42 [INFO]: Epoch 047 - training loss: 0.3736, validation loss: 0.0657
2024-06-01 21:20:42 [INFO]: Epoch 048 - training loss: 0.3769, validation loss: 0.0625
2024-06-01 21:20:43 [INFO]: Epoch 049 - training loss: 0.3899, validation loss: 0.0674
2024-06-01 21:20:43 [INFO]: Epoch 050 - training loss: 0.3827, validation loss: 0.0641
2024-06-01 21:20:43 [INFO]: Epoch 051 - training loss: 0.3685, validation loss: 0.0625
2024-06-01 21:20:44 [INFO]: Epoch 052 - training loss: 0.3675, validation loss: 0.0814
2024-06-01 21:20:44 [INFO]: Epoch 053 - training loss: 0.3713, validation loss: 0.0597
2024-06-01 21:20:44 [INFO]: Epoch 054 - training loss: 0.3700, validation loss: 0.0592
2024-06-01 21:20:45 [INFO]: Epoch 055 - training loss: 0.3745, validation loss: 0.0576
2024-06-01 21:20:45 [INFO]: Epoch 056 - training loss: 0.3622, validation loss: 0.0619
2024-06-01 21:20:46 [INFO]: Epoch 057 - training loss: 0.3624, validation loss: 0.0573
2024-06-01 21:20:46 [INFO]: Epoch 058 - training loss: 0.3543, validation loss: 0.0544
2024-06-01 21:20:46 [INFO]: Epoch 059 - training loss: 0.3639, validation loss: 0.0572
2024-06-01 21:20:47 [INFO]: Epoch 060 - training loss: 0.3589, validation loss: 0.0582
2024-06-01 21:20:47 [INFO]: Epoch 061 - training loss: 0.3640, validation loss: 0.0608
2024-06-01 21:20:47 [INFO]: Epoch 062 - training loss: 0.3398, validation loss: 0.0576
2024-06-01 21:20:48 [INFO]: Epoch 063 - training loss: 0.3368, validation loss: 0.0542
2024-06-01 21:20:48 [INFO]: Epoch 064 - training loss: 0.3624, validation loss: 0.0510
2024-06-01 21:20:48 [INFO]: Epoch 065 - training loss: 0.3519, validation loss: 0.0546
2024-06-01 21:20:49 [INFO]: Epoch 066 - training loss: 0.3574, validation loss: 0.0572
2024-06-01 21:20:49 [INFO]: Epoch 067 - training loss: 0.3535, validation loss: 0.0670
2024-06-01 21:20:49 [INFO]: Epoch 068 - training loss: 0.3488, validation loss: 0.0522
2024-06-01 21:20:50 [INFO]: Epoch 069 - training loss: 0.3510, validation loss: 0.0550
2024-06-01 21:20:50 [INFO]: Epoch 070 - training loss: 0.3438, validation loss: 0.0522
2024-06-01 21:20:50 [INFO]: Epoch 071 - training loss: 0.3401, validation loss: 0.0537
2024-06-01 21:20:51 [INFO]: Epoch 072 - training loss: 0.3579, validation loss: 0.0556
2024-06-01 21:20:51 [INFO]: Epoch 073 - training loss: 0.3528, validation loss: 0.0587
2024-06-01 21:20:51 [INFO]: Epoch 074 - training loss: 0.3515, validation loss: 0.0530
2024-06-01 21:20:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:20:51 [INFO]: Finished training. The best model is from epoch#64.
2024-06-01 21:20:51 [INFO]: Saved the model to results_point_rate01/SCINet_Pedestrian/round_0/20240601_T212024/SCINet.pypots
2024-06-01 21:20:52 [INFO]: Successfully saved to results_point_rate01/SCINet_Pedestrian/round_0/imputation.pkl
2024-06-01 21:20:52 [INFO]: Round0 - SCINet on Pedestrian: MAE=0.1618, MSE=0.0862, MRE=0.2211
2024-06-01 21:20:52 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 21:20:52 [INFO]: Using the given device: cuda:0
2024-06-01 21:20:52 [INFO]: Model files will be saved to results_point_rate01/SCINet_Pedestrian/round_1/20240601_T212052
2024-06-01 21:20:52 [INFO]: Tensorboard file will be saved to results_point_rate01/SCINet_Pedestrian/round_1/20240601_T212052/tensorboard
2024-06-01 21:20:52 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-01 21:20:52 [INFO]: Epoch 001 - training loss: 1.4293, validation loss: 0.7303
2024-06-01 21:20:52 [INFO]: Epoch 002 - training loss: 1.1789, validation loss: 0.4549
2024-06-01 21:20:53 [INFO]: Epoch 003 - training loss: 0.9491, validation loss: 0.3066
2024-06-01 21:20:53 [INFO]: Epoch 004 - training loss: 0.8053, validation loss: 0.2413
2024-06-01 21:20:53 [INFO]: Epoch 005 - training loss: 0.7273, validation loss: 0.2151
2024-06-01 21:20:54 [INFO]: Epoch 006 - training loss: 0.6890, validation loss: 0.1954
2024-06-01 21:20:54 [INFO]: Epoch 007 - training loss: 0.6481, validation loss: 0.1787
2024-06-01 21:20:54 [INFO]: Epoch 008 - training loss: 0.6122, validation loss: 0.1628
2024-06-01 21:20:55 [INFO]: Epoch 009 - training loss: 0.5760, validation loss: 0.1500
2024-06-01 21:20:55 [INFO]: Epoch 010 - training loss: 0.5549, validation loss: 0.1341
2024-06-01 21:20:56 [INFO]: Epoch 011 - training loss: 0.5385, validation loss: 0.1226
2024-06-01 21:20:56 [INFO]: Epoch 012 - training loss: 0.5177, validation loss: 0.1181
2024-06-01 21:20:56 [INFO]: Epoch 013 - training loss: 0.4905, validation loss: 0.1076
2024-06-01 21:20:57 [INFO]: Epoch 014 - training loss: 0.4779, validation loss: 0.1041
2024-06-01 21:20:57 [INFO]: Epoch 015 - training loss: 0.4676, validation loss: 0.0974
2024-06-01 21:20:57 [INFO]: Epoch 016 - training loss: 0.4547, validation loss: 0.0934
2024-06-01 21:20:58 [INFO]: Epoch 017 - training loss: 0.4329, validation loss: 0.0920
2024-06-01 21:20:58 [INFO]: Epoch 018 - training loss: 0.4206, validation loss: 0.0888
2024-06-01 21:20:58 [INFO]: Epoch 019 - training loss: 0.4163, validation loss: 0.0843
2024-06-01 21:20:59 [INFO]: Epoch 020 - training loss: 0.4237, validation loss: 0.0814
2024-06-01 21:20:59 [INFO]: Epoch 021 - training loss: 0.4019, validation loss: 0.0813
2024-06-01 21:20:59 [INFO]: Epoch 022 - training loss: 0.3951, validation loss: 0.0807
2024-06-01 21:21:00 [INFO]: Epoch 023 - training loss: 0.3915, validation loss: 0.0755
2024-06-01 21:21:00 [INFO]: Epoch 024 - training loss: 0.3756, validation loss: 0.0769
2024-06-01 21:21:00 [INFO]: Epoch 025 - training loss: 0.3755, validation loss: 0.0697
2024-06-01 21:21:01 [INFO]: Epoch 026 - training loss: 0.3742, validation loss: 0.0686
2024-06-01 21:21:01 [INFO]: Epoch 027 - training loss: 0.3760, validation loss: 0.0758
2024-06-01 21:21:01 [INFO]: Epoch 028 - training loss: 0.3742, validation loss: 0.0679
2024-06-01 21:21:02 [INFO]: Epoch 029 - training loss: 0.3724, validation loss: 0.0692
2024-06-01 21:21:02 [INFO]: Epoch 030 - training loss: 0.3756, validation loss: 0.0605
2024-06-01 21:21:02 [INFO]: Epoch 031 - training loss: 0.3646, validation loss: 0.0611
2024-06-01 21:21:03 [INFO]: Epoch 032 - training loss: 0.3543, validation loss: 0.0582
2024-06-01 21:21:03 [INFO]: Epoch 033 - training loss: 0.3658, validation loss: 0.0628
2024-06-01 21:21:04 [INFO]: Epoch 034 - training loss: 0.3681, validation loss: 0.0569
2024-06-01 21:21:04 [INFO]: Epoch 035 - training loss: 0.3533, validation loss: 0.0578
2024-06-01 21:21:04 [INFO]: Epoch 036 - training loss: 0.3548, validation loss: 0.0543
2024-06-01 21:21:05 [INFO]: Epoch 037 - training loss: 0.3366, validation loss: 0.0527
2024-06-01 21:21:05 [INFO]: Epoch 038 - training loss: 0.3475, validation loss: 0.0566
2024-06-01 21:21:05 [INFO]: Epoch 039 - training loss: 0.3532, validation loss: 0.0607
2024-06-01 21:21:06 [INFO]: Epoch 040 - training loss: 0.3482, validation loss: 0.0508
2024-06-01 21:21:06 [INFO]: Epoch 041 - training loss: 0.3436, validation loss: 0.0491
2024-06-01 21:21:06 [INFO]: Epoch 042 - training loss: 0.3400, validation loss: 0.0510
2024-06-01 21:21:07 [INFO]: Epoch 043 - training loss: 0.3313, validation loss: 0.0520
2024-06-01 21:21:07 [INFO]: Epoch 044 - training loss: 0.3458, validation loss: 0.0519
2024-06-01 21:21:07 [INFO]: Epoch 045 - training loss: 0.3444, validation loss: 0.0471
2024-06-01 21:21:08 [INFO]: Epoch 046 - training loss: 0.3338, validation loss: 0.0477
2024-06-01 21:21:08 [INFO]: Epoch 047 - training loss: 0.3308, validation loss: 0.0506
2024-06-01 21:21:08 [INFO]: Epoch 048 - training loss: 0.3394, validation loss: 0.0464
2024-06-01 21:21:09 [INFO]: Epoch 049 - training loss: 0.3383, validation loss: 0.0482
2024-06-01 21:21:09 [INFO]: Epoch 050 - training loss: 0.3302, validation loss: 0.0449
2024-06-01 21:21:09 [INFO]: Epoch 051 - training loss: 0.3219, validation loss: 0.0477
2024-06-01 21:21:10 [INFO]: Epoch 052 - training loss: 0.3346, validation loss: 0.0455
2024-06-01 21:21:10 [INFO]: Epoch 053 - training loss: 0.3305, validation loss: 0.0457
2024-06-01 21:21:10 [INFO]: Epoch 054 - training loss: 0.3299, validation loss: 0.0444
2024-06-01 21:21:11 [INFO]: Epoch 055 - training loss: 0.3294, validation loss: 0.0443
2024-06-01 21:21:11 [INFO]: Epoch 056 - training loss: 0.3231, validation loss: 0.0420
2024-06-01 21:21:11 [INFO]: Epoch 057 - training loss: 0.3244, validation loss: 0.0448
2024-06-01 21:21:12 [INFO]: Epoch 058 - training loss: 0.3252, validation loss: 0.0458
2024-06-01 21:21:12 [INFO]: Epoch 059 - training loss: 0.3194, validation loss: 0.0480
2024-06-01 21:21:13 [INFO]: Epoch 060 - training loss: 0.3163, validation loss: 0.0414
2024-06-01 21:21:13 [INFO]: Epoch 061 - training loss: 0.3209, validation loss: 0.0436
2024-06-01 21:21:13 [INFO]: Epoch 062 - training loss: 0.3161, validation loss: 0.0425
2024-06-01 21:21:14 [INFO]: Epoch 063 - training loss: 0.3208, validation loss: 0.0441
2024-06-01 21:21:14 [INFO]: Epoch 064 - training loss: 0.3107, validation loss: 0.0413
2024-06-01 21:21:14 [INFO]: Epoch 065 - training loss: 0.3086, validation loss: 0.0429
2024-06-01 21:21:15 [INFO]: Epoch 066 - training loss: 0.3121, validation loss: 0.0451
2024-06-01 21:21:15 [INFO]: Epoch 067 - training loss: 0.3156, validation loss: 0.0412
2024-06-01 21:21:15 [INFO]: Epoch 068 - training loss: 0.3044, validation loss: 0.0410
2024-06-01 21:21:16 [INFO]: Epoch 069 - training loss: 0.3158, validation loss: 0.0412
2024-06-01 21:21:16 [INFO]: Epoch 070 - training loss: 0.3145, validation loss: 0.0395
2024-06-01 21:21:16 [INFO]: Epoch 071 - training loss: 0.3053, validation loss: 0.0434
2024-06-01 21:21:17 [INFO]: Epoch 072 - training loss: 0.3085, validation loss: 0.0379
2024-06-01 21:21:17 [INFO]: Epoch 073 - training loss: 0.3109, validation loss: 0.0405
2024-06-01 21:21:17 [INFO]: Epoch 074 - training loss: 0.3093, validation loss: 0.0394
2024-06-01 21:21:18 [INFO]: Epoch 075 - training loss: 0.3099, validation loss: 0.0404
2024-06-01 21:21:18 [INFO]: Epoch 076 - training loss: 0.2996, validation loss: 0.0386
2024-06-01 21:21:18 [INFO]: Epoch 077 - training loss: 0.3082, validation loss: 0.0397
2024-06-01 21:21:19 [INFO]: Epoch 078 - training loss: 0.3153, validation loss: 0.0369
2024-06-01 21:21:19 [INFO]: Epoch 079 - training loss: 0.2983, validation loss: 0.0402
2024-06-01 21:21:19 [INFO]: Epoch 080 - training loss: 0.3024, validation loss: 0.0385
2024-06-01 21:21:20 [INFO]: Epoch 081 - training loss: 0.2958, validation loss: 0.0382
2024-06-01 21:21:20 [INFO]: Epoch 082 - training loss: 0.2950, validation loss: 0.0399
2024-06-01 21:21:21 [INFO]: Epoch 083 - training loss: 0.2969, validation loss: 0.0392
2024-06-01 21:21:21 [INFO]: Epoch 084 - training loss: 0.2894, validation loss: 0.0401
2024-06-01 21:21:21 [INFO]: Epoch 085 - training loss: 0.2982, validation loss: 0.0407
2024-06-01 21:21:22 [INFO]: Epoch 086 - training loss: 0.2896, validation loss: 0.0382
2024-06-01 21:21:22 [INFO]: Epoch 087 - training loss: 0.2932, validation loss: 0.0368
2024-06-01 21:21:22 [INFO]: Epoch 088 - training loss: 0.3059, validation loss: 0.0370
2024-06-01 21:21:23 [INFO]: Epoch 089 - training loss: 0.3000, validation loss: 0.0383
2024-06-01 21:21:23 [INFO]: Epoch 090 - training loss: 0.2984, validation loss: 0.0373
2024-06-01 21:21:23 [INFO]: Epoch 091 - training loss: 0.2933, validation loss: 0.0426
2024-06-01 21:21:24 [INFO]: Epoch 092 - training loss: 0.2943, validation loss: 0.0384
2024-06-01 21:21:24 [INFO]: Epoch 093 - training loss: 0.2959, validation loss: 0.0362
2024-06-01 21:21:24 [INFO]: Epoch 094 - training loss: 0.2822, validation loss: 0.0377
2024-06-01 21:21:25 [INFO]: Epoch 095 - training loss: 0.2982, validation loss: 0.0362
2024-06-01 21:21:25 [INFO]: Epoch 096 - training loss: 0.2960, validation loss: 0.0365
2024-06-01 21:21:26 [INFO]: Epoch 097 - training loss: 0.2869, validation loss: 0.0372
2024-06-01 21:21:26 [INFO]: Epoch 098 - training loss: 0.2937, validation loss: 0.0378
2024-06-01 21:21:26 [INFO]: Epoch 099 - training loss: 0.2947, validation loss: 0.0363
2024-06-01 21:21:27 [INFO]: Epoch 100 - training loss: 0.2907, validation loss: 0.0369
2024-06-01 21:21:27 [INFO]: Finished training. The best model is from epoch#93.
2024-06-01 21:21:27 [INFO]: Saved the model to results_point_rate01/SCINet_Pedestrian/round_1/20240601_T212052/SCINet.pypots
2024-06-01 21:21:27 [INFO]: Successfully saved to results_point_rate01/SCINet_Pedestrian/round_1/imputation.pkl
2024-06-01 21:21:27 [INFO]: Round1 - SCINet on Pedestrian: MAE=0.1399, MSE=0.0625, MRE=0.1912
2024-06-01 21:21:27 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 21:21:27 [INFO]: Using the given device: cuda:0
2024-06-01 21:21:27 [INFO]: Model files will be saved to results_point_rate01/SCINet_Pedestrian/round_2/20240601_T212127
2024-06-01 21:21:27 [INFO]: Tensorboard file will be saved to results_point_rate01/SCINet_Pedestrian/round_2/20240601_T212127/tensorboard
2024-06-01 21:21:27 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-01 21:21:27 [INFO]: Epoch 001 - training loss: 1.4810, validation loss: 0.8310
2024-06-01 21:21:28 [INFO]: Epoch 002 - training loss: 1.3058, validation loss: 0.5487
2024-06-01 21:21:28 [INFO]: Epoch 003 - training loss: 0.9501, validation loss: 0.3433
2024-06-01 21:21:28 [INFO]: Epoch 004 - training loss: 0.7991, validation loss: 0.2736
2024-06-01 21:21:29 [INFO]: Epoch 005 - training loss: 0.7291, validation loss: 0.2364
2024-06-01 21:21:29 [INFO]: Epoch 006 - training loss: 0.6877, validation loss: 0.2150
2024-06-01 21:21:29 [INFO]: Epoch 007 - training loss: 0.6201, validation loss: 0.1739
2024-06-01 21:21:30 [INFO]: Epoch 008 - training loss: 0.5708, validation loss: 0.1346
2024-06-01 21:21:30 [INFO]: Epoch 009 - training loss: 0.5240, validation loss: 0.1099
2024-06-01 21:21:30 [INFO]: Epoch 010 - training loss: 0.5078, validation loss: 0.0922
2024-06-01 21:21:31 [INFO]: Epoch 011 - training loss: 0.4816, validation loss: 0.0770
2024-06-01 21:21:31 [INFO]: Epoch 012 - training loss: 0.4455, validation loss: 0.0729
2024-06-01 21:21:31 [INFO]: Epoch 013 - training loss: 0.4285, validation loss: 0.0645
2024-06-01 21:21:32 [INFO]: Epoch 014 - training loss: 0.4244, validation loss: 0.0599
2024-06-01 21:21:32 [INFO]: Epoch 015 - training loss: 0.3935, validation loss: 0.0597
2024-06-01 21:21:32 [INFO]: Epoch 016 - training loss: 0.3965, validation loss: 0.0594
2024-06-01 21:21:33 [INFO]: Epoch 017 - training loss: 0.3791, validation loss: 0.0568
2024-06-01 21:21:33 [INFO]: Epoch 018 - training loss: 0.3874, validation loss: 0.0607
2024-06-01 21:21:34 [INFO]: Epoch 019 - training loss: 0.3783, validation loss: 0.0510
2024-06-01 21:21:34 [INFO]: Epoch 020 - training loss: 0.3661, validation loss: 0.0531
2024-06-01 21:21:34 [INFO]: Epoch 021 - training loss: 0.3789, validation loss: 0.0581
2024-06-01 21:21:35 [INFO]: Epoch 022 - training loss: 0.3737, validation loss: 0.0484
2024-06-01 21:21:35 [INFO]: Epoch 023 - training loss: 0.3750, validation loss: 0.0501
2024-06-01 21:21:35 [INFO]: Epoch 024 - training loss: 0.3583, validation loss: 0.0526
2024-06-01 21:21:36 [INFO]: Epoch 025 - training loss: 0.3574, validation loss: 0.0493
2024-06-01 21:21:36 [INFO]: Epoch 026 - training loss: 0.3496, validation loss: 0.0463
2024-06-01 21:21:36 [INFO]: Epoch 027 - training loss: 0.3618, validation loss: 0.0479
2024-06-01 21:21:37 [INFO]: Epoch 028 - training loss: 0.3513, validation loss: 0.0446
2024-06-01 21:21:37 [INFO]: Epoch 029 - training loss: 0.3498, validation loss: 0.0480
2024-06-01 21:21:37 [INFO]: Epoch 030 - training loss: 0.3443, validation loss: 0.0444
2024-06-01 21:21:38 [INFO]: Epoch 031 - training loss: 0.3501, validation loss: 0.0470
2024-06-01 21:21:38 [INFO]: Epoch 032 - training loss: 0.3536, validation loss: 0.0440
2024-06-01 21:21:38 [INFO]: Epoch 033 - training loss: 0.3446, validation loss: 0.0434
2024-06-01 21:21:39 [INFO]: Epoch 034 - training loss: 0.3443, validation loss: 0.0428
2024-06-01 21:21:39 [INFO]: Epoch 035 - training loss: 0.3382, validation loss: 0.0441
2024-06-01 21:21:40 [INFO]: Epoch 036 - training loss: 0.3434, validation loss: 0.0415
2024-06-01 21:21:40 [INFO]: Epoch 037 - training loss: 0.3301, validation loss: 0.0412
2024-06-01 21:21:40 [INFO]: Epoch 038 - training loss: 0.3288, validation loss: 0.0412
2024-06-01 21:21:41 [INFO]: Epoch 039 - training loss: 0.3247, validation loss: 0.0415
2024-06-01 21:21:41 [INFO]: Epoch 040 - training loss: 0.3192, validation loss: 0.0382
2024-06-01 21:21:41 [INFO]: Epoch 041 - training loss: 0.3161, validation loss: 0.0391
2024-06-01 21:21:42 [INFO]: Epoch 042 - training loss: 0.3293, validation loss: 0.0409
2024-06-01 21:21:42 [INFO]: Epoch 043 - training loss: 0.3111, validation loss: 0.0393
2024-06-01 21:21:42 [INFO]: Epoch 044 - training loss: 0.3273, validation loss: 0.0386
2024-06-01 21:21:43 [INFO]: Epoch 045 - training loss: 0.3280, validation loss: 0.0371
2024-06-01 21:21:43 [INFO]: Epoch 046 - training loss: 0.3209, validation loss: 0.0375
2024-06-01 21:21:43 [INFO]: Epoch 047 - training loss: 0.3320, validation loss: 0.0395
2024-06-01 21:21:44 [INFO]: Epoch 048 - training loss: 0.3236, validation loss: 0.0383
2024-06-01 21:21:44 [INFO]: Epoch 049 - training loss: 0.3160, validation loss: 0.0360
2024-06-01 21:21:44 [INFO]: Epoch 050 - training loss: 0.3156, validation loss: 0.0384
2024-06-01 21:21:45 [INFO]: Epoch 051 - training loss: 0.3218, validation loss: 0.0408
2024-06-01 21:21:45 [INFO]: Epoch 052 - training loss: 0.3050, validation loss: 0.0372
2024-06-01 21:21:45 [INFO]: Epoch 053 - training loss: 0.3258, validation loss: 0.0367
2024-06-01 21:21:46 [INFO]: Epoch 054 - training loss: 0.3162, validation loss: 0.0404
2024-06-01 21:21:46 [INFO]: Epoch 055 - training loss: 0.3215, validation loss: 0.0392
2024-06-01 21:21:47 [INFO]: Epoch 056 - training loss: 0.3192, validation loss: 0.0381
2024-06-01 21:21:47 [INFO]: Epoch 057 - training loss: 0.2971, validation loss: 0.0362
2024-06-01 21:21:47 [INFO]: Epoch 058 - training loss: 0.3089, validation loss: 0.0355
2024-06-01 21:21:48 [INFO]: Epoch 059 - training loss: 0.3110, validation loss: 0.0357
2024-06-01 21:21:48 [INFO]: Epoch 060 - training loss: 0.3152, validation loss: 0.0358
2024-06-01 21:21:48 [INFO]: Epoch 061 - training loss: 0.3006, validation loss: 0.0370
2024-06-01 21:21:49 [INFO]: Epoch 062 - training loss: 0.3129, validation loss: 0.0409
2024-06-01 21:21:49 [INFO]: Epoch 063 - training loss: 0.2952, validation loss: 0.0385
2024-06-01 21:21:49 [INFO]: Epoch 064 - training loss: 0.3043, validation loss: 0.0367
2024-06-01 21:21:50 [INFO]: Epoch 065 - training loss: 0.3087, validation loss: 0.0372
2024-06-01 21:21:50 [INFO]: Epoch 066 - training loss: 0.2920, validation loss: 0.0356
2024-06-01 21:21:50 [INFO]: Epoch 067 - training loss: 0.3016, validation loss: 0.0388
2024-06-01 21:21:51 [INFO]: Epoch 068 - training loss: 0.3036, validation loss: 0.0352
2024-06-01 21:21:51 [INFO]: Epoch 069 - training loss: 0.2969, validation loss: 0.0374
2024-06-01 21:21:52 [INFO]: Epoch 070 - training loss: 0.3009, validation loss: 0.0350
2024-06-01 21:21:52 [INFO]: Epoch 071 - training loss: 0.3110, validation loss: 0.0391
2024-06-01 21:21:52 [INFO]: Epoch 072 - training loss: 0.2935, validation loss: 0.0357
2024-06-01 21:21:53 [INFO]: Epoch 073 - training loss: 0.3050, validation loss: 0.0379
2024-06-01 21:21:53 [INFO]: Epoch 074 - training loss: 0.3050, validation loss: 0.0362
2024-06-01 21:21:53 [INFO]: Epoch 075 - training loss: 0.2964, validation loss: 0.0343
2024-06-01 21:21:54 [INFO]: Epoch 076 - training loss: 0.3124, validation loss: 0.0358
2024-06-01 21:21:54 [INFO]: Epoch 077 - training loss: 0.2896, validation loss: 0.0346
2024-06-01 21:21:54 [INFO]: Epoch 078 - training loss: 0.2952, validation loss: 0.0361
2024-06-01 21:21:55 [INFO]: Epoch 079 - training loss: 0.2906, validation loss: 0.0366
2024-06-01 21:21:55 [INFO]: Epoch 080 - training loss: 0.2864, validation loss: 0.0365
2024-06-01 21:21:55 [INFO]: Epoch 081 - training loss: 0.2996, validation loss: 0.0351
2024-06-01 21:21:56 [INFO]: Epoch 082 - training loss: 0.2949, validation loss: 0.0343
2024-06-01 21:21:56 [INFO]: Epoch 083 - training loss: 0.2955, validation loss: 0.0370
2024-06-01 21:21:57 [INFO]: Epoch 084 - training loss: 0.2856, validation loss: 0.0350
2024-06-01 21:21:57 [INFO]: Epoch 085 - training loss: 0.2978, validation loss: 0.0346
2024-06-01 21:21:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:21:57 [INFO]: Finished training. The best model is from epoch#75.
2024-06-01 21:21:57 [INFO]: Saved the model to results_point_rate01/SCINet_Pedestrian/round_2/20240601_T212127/SCINet.pypots
2024-06-01 21:21:57 [INFO]: Successfully saved to results_point_rate01/SCINet_Pedestrian/round_2/imputation.pkl
2024-06-01 21:21:57 [INFO]: Round2 - SCINet on Pedestrian: MAE=0.1375, MSE=0.0643, MRE=0.1880
2024-06-01 21:21:57 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 21:21:57 [INFO]: Using the given device: cuda:0
2024-06-01 21:21:57 [INFO]: Model files will be saved to results_point_rate01/SCINet_Pedestrian/round_3/20240601_T212157
2024-06-01 21:21:57 [INFO]: Tensorboard file will be saved to results_point_rate01/SCINet_Pedestrian/round_3/20240601_T212157/tensorboard
2024-06-01 21:21:57 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-01 21:21:58 [INFO]: Epoch 001 - training loss: 1.3977, validation loss: 0.7221
2024-06-01 21:21:58 [INFO]: Epoch 002 - training loss: 1.1450, validation loss: 0.5235
2024-06-01 21:21:58 [INFO]: Epoch 003 - training loss: 0.9193, validation loss: 0.3271
2024-06-01 21:21:59 [INFO]: Epoch 004 - training loss: 0.7912, validation loss: 0.2266
2024-06-01 21:21:59 [INFO]: Epoch 005 - training loss: 0.7265, validation loss: 0.2065
2024-06-01 21:21:59 [INFO]: Epoch 006 - training loss: 0.6898, validation loss: 0.1589
2024-06-01 21:22:00 [INFO]: Epoch 007 - training loss: 0.6295, validation loss: 0.1337
2024-06-01 21:22:00 [INFO]: Epoch 008 - training loss: 0.5841, validation loss: 0.1142
2024-06-01 21:22:00 [INFO]: Epoch 009 - training loss: 0.5532, validation loss: 0.1042
2024-06-01 21:22:01 [INFO]: Epoch 010 - training loss: 0.5254, validation loss: 0.0998
2024-06-01 21:22:01 [INFO]: Epoch 011 - training loss: 0.4959, validation loss: 0.1006
2024-06-01 21:22:01 [INFO]: Epoch 012 - training loss: 0.4849, validation loss: 0.0941
2024-06-01 21:22:02 [INFO]: Epoch 013 - training loss: 0.4654, validation loss: 0.0875
2024-06-01 21:22:02 [INFO]: Epoch 014 - training loss: 0.4623, validation loss: 0.0937
2024-06-01 21:22:03 [INFO]: Epoch 015 - training loss: 0.4616, validation loss: 0.0842
2024-06-01 21:22:03 [INFO]: Epoch 016 - training loss: 0.4537, validation loss: 0.0823
2024-06-01 21:22:03 [INFO]: Epoch 017 - training loss: 0.4306, validation loss: 0.0813
2024-06-01 21:22:04 [INFO]: Epoch 018 - training loss: 0.4322, validation loss: 0.0711
2024-06-01 21:22:04 [INFO]: Epoch 019 - training loss: 0.4169, validation loss: 0.0719
2024-06-01 21:22:04 [INFO]: Epoch 020 - training loss: 0.4313, validation loss: 0.0703
2024-06-01 21:22:05 [INFO]: Epoch 021 - training loss: 0.4322, validation loss: 0.0751
2024-06-01 21:22:05 [INFO]: Epoch 022 - training loss: 0.4224, validation loss: 0.0701
2024-06-01 21:22:05 [INFO]: Epoch 023 - training loss: 0.4109, validation loss: 0.0710
2024-06-01 21:22:06 [INFO]: Epoch 024 - training loss: 0.4046, validation loss: 0.0671
2024-06-01 21:22:06 [INFO]: Epoch 025 - training loss: 0.4095, validation loss: 0.0684
2024-06-01 21:22:06 [INFO]: Epoch 026 - training loss: 0.3909, validation loss: 0.0662
2024-06-01 21:22:07 [INFO]: Epoch 027 - training loss: 0.3924, validation loss: 0.0663
2024-06-01 21:22:07 [INFO]: Epoch 028 - training loss: 0.3934, validation loss: 0.0673
2024-06-01 21:22:07 [INFO]: Epoch 029 - training loss: 0.3917, validation loss: 0.0642
2024-06-01 21:22:08 [INFO]: Epoch 030 - training loss: 0.3961, validation loss: 0.0622
2024-06-01 21:22:08 [INFO]: Epoch 031 - training loss: 0.3927, validation loss: 0.0616
2024-06-01 21:22:08 [INFO]: Epoch 032 - training loss: 0.3851, validation loss: 0.0653
2024-06-01 21:22:09 [INFO]: Epoch 033 - training loss: 0.4044, validation loss: 0.0630
2024-06-01 21:22:09 [INFO]: Epoch 034 - training loss: 0.3806, validation loss: 0.0603
2024-06-01 21:22:09 [INFO]: Epoch 035 - training loss: 0.3772, validation loss: 0.0610
2024-06-01 21:22:10 [INFO]: Epoch 036 - training loss: 0.3721, validation loss: 0.0622
2024-06-01 21:22:10 [INFO]: Epoch 037 - training loss: 0.3650, validation loss: 0.0612
2024-06-01 21:22:11 [INFO]: Epoch 038 - training loss: 0.3772, validation loss: 0.0610
2024-06-01 21:22:11 [INFO]: Epoch 039 - training loss: 0.3645, validation loss: 0.0560
2024-06-01 21:22:11 [INFO]: Epoch 040 - training loss: 0.3675, validation loss: 0.0580
2024-06-01 21:22:12 [INFO]: Epoch 041 - training loss: 0.3688, validation loss: 0.0576
2024-06-01 21:22:12 [INFO]: Epoch 042 - training loss: 0.3683, validation loss: 0.0600
2024-06-01 21:22:12 [INFO]: Epoch 043 - training loss: 0.3554, validation loss: 0.0594
2024-06-01 21:22:13 [INFO]: Epoch 044 - training loss: 0.3572, validation loss: 0.0545
2024-06-01 21:22:13 [INFO]: Epoch 045 - training loss: 0.3734, validation loss: 0.0564
2024-06-01 21:22:13 [INFO]: Epoch 046 - training loss: 0.3660, validation loss: 0.0559
2024-06-01 21:22:14 [INFO]: Epoch 047 - training loss: 0.3623, validation loss: 0.0557
2024-06-01 21:22:14 [INFO]: Epoch 048 - training loss: 0.3655, validation loss: 0.0537
2024-06-01 21:22:14 [INFO]: Epoch 049 - training loss: 0.3531, validation loss: 0.0559
2024-06-01 21:22:15 [INFO]: Epoch 050 - training loss: 0.3450, validation loss: 0.0536
2024-06-01 21:22:15 [INFO]: Epoch 051 - training loss: 0.3460, validation loss: 0.0521
2024-06-01 21:22:15 [INFO]: Epoch 052 - training loss: 0.3525, validation loss: 0.0545
2024-06-01 21:22:16 [INFO]: Epoch 053 - training loss: 0.3473, validation loss: 0.0534
2024-06-01 21:22:16 [INFO]: Epoch 054 - training loss: 0.3512, validation loss: 0.0535
2024-06-01 21:22:16 [INFO]: Epoch 055 - training loss: 0.3444, validation loss: 0.0537
2024-06-01 21:22:17 [INFO]: Epoch 056 - training loss: 0.3426, validation loss: 0.0535
2024-06-01 21:22:17 [INFO]: Epoch 057 - training loss: 0.3424, validation loss: 0.0514
2024-06-01 21:22:17 [INFO]: Epoch 058 - training loss: 0.3382, validation loss: 0.0511
2024-06-01 21:22:18 [INFO]: Epoch 059 - training loss: 0.3437, validation loss: 0.0500
2024-06-01 21:22:18 [INFO]: Epoch 060 - training loss: 0.3457, validation loss: 0.0512
2024-06-01 21:22:19 [INFO]: Epoch 061 - training loss: 0.3511, validation loss: 0.0537
2024-06-01 21:22:19 [INFO]: Epoch 062 - training loss: 0.3321, validation loss: 0.0552
2024-06-01 21:22:19 [INFO]: Epoch 063 - training loss: 0.3406, validation loss: 0.0519
2024-06-01 21:22:20 [INFO]: Epoch 064 - training loss: 0.3381, validation loss: 0.0521
2024-06-01 21:22:20 [INFO]: Epoch 065 - training loss: 0.3325, validation loss: 0.0498
2024-06-01 21:22:20 [INFO]: Epoch 066 - training loss: 0.3269, validation loss: 0.0513
2024-06-01 21:22:21 [INFO]: Epoch 067 - training loss: 0.3390, validation loss: 0.0502
2024-06-01 21:22:21 [INFO]: Epoch 068 - training loss: 0.3305, validation loss: 0.0505
2024-06-01 21:22:21 [INFO]: Epoch 069 - training loss: 0.3252, validation loss: 0.0515
2024-06-01 21:22:22 [INFO]: Epoch 070 - training loss: 0.3332, validation loss: 0.0550
2024-06-01 21:22:22 [INFO]: Epoch 071 - training loss: 0.3350, validation loss: 0.0489
2024-06-01 21:22:22 [INFO]: Epoch 072 - training loss: 0.3317, validation loss: 0.0513
2024-06-01 21:22:23 [INFO]: Epoch 073 - training loss: 0.3256, validation loss: 0.0506
2024-06-01 21:22:23 [INFO]: Epoch 074 - training loss: 0.3283, validation loss: 0.0492
2024-06-01 21:22:23 [INFO]: Epoch 075 - training loss: 0.3222, validation loss: 0.0506
2024-06-01 21:22:24 [INFO]: Epoch 076 - training loss: 0.3339, validation loss: 0.0496
2024-06-01 21:22:24 [INFO]: Epoch 077 - training loss: 0.3124, validation loss: 0.0483
2024-06-01 21:22:24 [INFO]: Epoch 078 - training loss: 0.3145, validation loss: 0.0484
2024-06-01 21:22:25 [INFO]: Epoch 079 - training loss: 0.3157, validation loss: 0.0474
2024-06-01 21:22:25 [INFO]: Epoch 080 - training loss: 0.3313, validation loss: 0.0484
2024-06-01 21:22:26 [INFO]: Epoch 081 - training loss: 0.3349, validation loss: 0.0489
2024-06-01 21:22:26 [INFO]: Epoch 082 - training loss: 0.3327, validation loss: 0.0464
2024-06-01 21:22:26 [INFO]: Epoch 083 - training loss: 0.3157, validation loss: 0.0457
2024-06-01 21:22:27 [INFO]: Epoch 084 - training loss: 0.3218, validation loss: 0.0479
2024-06-01 21:22:27 [INFO]: Epoch 085 - training loss: 0.3265, validation loss: 0.0531
2024-06-01 21:22:27 [INFO]: Epoch 086 - training loss: 0.3256, validation loss: 0.0463
2024-06-01 21:22:28 [INFO]: Epoch 087 - training loss: 0.3340, validation loss: 0.0517
2024-06-01 21:22:28 [INFO]: Epoch 088 - training loss: 0.3259, validation loss: 0.0492
2024-06-01 21:22:28 [INFO]: Epoch 089 - training loss: 0.3241, validation loss: 0.0481
2024-06-01 21:22:29 [INFO]: Epoch 090 - training loss: 0.3227, validation loss: 0.0475
2024-06-01 21:22:29 [INFO]: Epoch 091 - training loss: 0.3173, validation loss: 0.0464
2024-06-01 21:22:29 [INFO]: Epoch 092 - training loss: 0.3260, validation loss: 0.0487
2024-06-01 21:22:30 [INFO]: Epoch 093 - training loss: 0.3094, validation loss: 0.0457
2024-06-01 21:22:30 [INFO]: Epoch 094 - training loss: 0.3144, validation loss: 0.0505
2024-06-01 21:22:30 [INFO]: Epoch 095 - training loss: 0.3250, validation loss: 0.0443
2024-06-01 21:22:31 [INFO]: Epoch 096 - training loss: 0.3091, validation loss: 0.0455
2024-06-01 21:22:31 [INFO]: Epoch 097 - training loss: 0.3140, validation loss: 0.0493
2024-06-01 21:22:31 [INFO]: Epoch 098 - training loss: 0.3162, validation loss: 0.0476
2024-06-01 21:22:32 [INFO]: Epoch 099 - training loss: 0.3119, validation loss: 0.0445
2024-06-01 21:22:32 [INFO]: Epoch 100 - training loss: 0.3091, validation loss: 0.0456
2024-06-01 21:22:32 [INFO]: Finished training. The best model is from epoch#95.
2024-06-01 21:22:32 [INFO]: Saved the model to results_point_rate01/SCINet_Pedestrian/round_3/20240601_T212157/SCINet.pypots
2024-06-01 21:22:32 [INFO]: Successfully saved to results_point_rate01/SCINet_Pedestrian/round_3/imputation.pkl
2024-06-01 21:22:32 [INFO]: Round3 - SCINet on Pedestrian: MAE=0.1426, MSE=0.0753, MRE=0.1949
2024-06-01 21:22:32 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 21:22:32 [INFO]: Using the given device: cuda:0
2024-06-01 21:22:32 [INFO]: Model files will be saved to results_point_rate01/SCINet_Pedestrian/round_4/20240601_T212232
2024-06-01 21:22:32 [INFO]: Tensorboard file will be saved to results_point_rate01/SCINet_Pedestrian/round_4/20240601_T212232/tensorboard
2024-06-01 21:22:32 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-01 21:22:33 [INFO]: Epoch 001 - training loss: 1.4551, validation loss: 0.7242
2024-06-01 21:22:33 [INFO]: Epoch 002 - training loss: 1.1481, validation loss: 0.3888
2024-06-01 21:22:34 [INFO]: Epoch 003 - training loss: 0.8656, validation loss: 0.2815
2024-06-01 21:22:34 [INFO]: Epoch 004 - training loss: 0.7836, validation loss: 0.2462
2024-06-01 21:22:34 [INFO]: Epoch 005 - training loss: 0.7263, validation loss: 0.2267
2024-06-01 21:22:35 [INFO]: Epoch 006 - training loss: 0.6839, validation loss: 0.2156
2024-06-01 21:22:35 [INFO]: Epoch 007 - training loss: 0.6764, validation loss: 0.1835
2024-06-01 21:22:35 [INFO]: Epoch 008 - training loss: 0.6494, validation loss: 0.1654
2024-06-01 21:22:36 [INFO]: Epoch 009 - training loss: 0.5995, validation loss: 0.1506
2024-06-01 21:22:36 [INFO]: Epoch 010 - training loss: 0.5624, validation loss: 0.1334
2024-06-01 21:22:36 [INFO]: Epoch 011 - training loss: 0.5596, validation loss: 0.1328
2024-06-01 21:22:37 [INFO]: Epoch 012 - training loss: 0.5211, validation loss: 0.1119
2024-06-01 21:22:37 [INFO]: Epoch 013 - training loss: 0.5050, validation loss: 0.1178
2024-06-01 21:22:37 [INFO]: Epoch 014 - training loss: 0.5105, validation loss: 0.1000
2024-06-01 21:22:38 [INFO]: Epoch 015 - training loss: 0.4690, validation loss: 0.0972
2024-06-01 21:22:38 [INFO]: Epoch 016 - training loss: 0.4530, validation loss: 0.1004
2024-06-01 21:22:38 [INFO]: Epoch 017 - training loss: 0.4565, validation loss: 0.0835
2024-06-01 21:22:39 [INFO]: Epoch 018 - training loss: 0.4387, validation loss: 0.0776
2024-06-01 21:22:39 [INFO]: Epoch 019 - training loss: 0.4285, validation loss: 0.0784
2024-06-01 21:22:39 [INFO]: Epoch 020 - training loss: 0.4279, validation loss: 0.0756
2024-06-01 21:22:40 [INFO]: Epoch 021 - training loss: 0.4178, validation loss: 0.0825
2024-06-01 21:22:40 [INFO]: Epoch 022 - training loss: 0.4290, validation loss: 0.0755
2024-06-01 21:22:40 [INFO]: Epoch 023 - training loss: 0.4211, validation loss: 0.0768
2024-06-01 21:22:41 [INFO]: Epoch 024 - training loss: 0.4245, validation loss: 0.0736
2024-06-01 21:22:41 [INFO]: Epoch 025 - training loss: 0.4150, validation loss: 0.0691
2024-06-01 21:22:41 [INFO]: Epoch 026 - training loss: 0.4128, validation loss: 0.0675
2024-06-01 21:22:42 [INFO]: Epoch 027 - training loss: 0.4033, validation loss: 0.0669
2024-06-01 21:22:42 [INFO]: Epoch 028 - training loss: 0.3911, validation loss: 0.0609
2024-06-01 21:22:43 [INFO]: Epoch 029 - training loss: 0.3851, validation loss: 0.0608
2024-06-01 21:22:43 [INFO]: Epoch 030 - training loss: 0.3782, validation loss: 0.0636
2024-06-01 21:22:43 [INFO]: Epoch 031 - training loss: 0.3950, validation loss: 0.0639
2024-06-01 21:22:44 [INFO]: Epoch 032 - training loss: 0.3888, validation loss: 0.0642
2024-06-01 21:22:44 [INFO]: Epoch 033 - training loss: 0.3960, validation loss: 0.0649
2024-06-01 21:22:44 [INFO]: Epoch 034 - training loss: 0.3860, validation loss: 0.0622
2024-06-01 21:22:45 [INFO]: Epoch 035 - training loss: 0.3890, validation loss: 0.0537
2024-06-01 21:22:45 [INFO]: Epoch 036 - training loss: 0.3771, validation loss: 0.0571
2024-06-01 21:22:45 [INFO]: Epoch 037 - training loss: 0.3798, validation loss: 0.0531
2024-06-01 21:22:46 [INFO]: Epoch 038 - training loss: 0.3807, validation loss: 0.0547
2024-06-01 21:22:46 [INFO]: Epoch 039 - training loss: 0.3736, validation loss: 0.0595
2024-06-01 21:22:46 [INFO]: Epoch 040 - training loss: 0.3709, validation loss: 0.0548
2024-06-01 21:22:47 [INFO]: Epoch 041 - training loss: 0.3665, validation loss: 0.0587
2024-06-01 21:22:47 [INFO]: Epoch 042 - training loss: 0.3591, validation loss: 0.0596
2024-06-01 21:22:48 [INFO]: Epoch 043 - training loss: 0.3638, validation loss: 0.0572
2024-06-01 21:22:48 [INFO]: Epoch 044 - training loss: 0.4011, validation loss: 0.0572
2024-06-01 21:22:48 [INFO]: Epoch 045 - training loss: 0.3608, validation loss: 0.0542
2024-06-01 21:22:49 [INFO]: Epoch 046 - training loss: 0.3700, validation loss: 0.0567
2024-06-01 21:22:49 [INFO]: Epoch 047 - training loss: 0.3795, validation loss: 0.0570
2024-06-01 21:22:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:22:49 [INFO]: Finished training. The best model is from epoch#37.
2024-06-01 21:22:49 [INFO]: Saved the model to results_point_rate01/SCINet_Pedestrian/round_4/20240601_T212232/SCINet.pypots
2024-06-01 21:22:49 [INFO]: Successfully saved to results_point_rate01/SCINet_Pedestrian/round_4/imputation.pkl
2024-06-01 21:22:49 [INFO]: Round4 - SCINet on Pedestrian: MAE=0.1646, MSE=0.0816, MRE=0.2249
2024-06-01 21:22:49 [INFO]: Done! Final results:
Averaged SCINet (n params: 43,783) on Pedestrian: MAE=0.1493 ± 0.01150991427222687, MSE=0.0740 ± 0.009301769129803069, MRE=0.2040 ± 0.015730042783234685, average inference time=0.31
