2024-06-01 21:09:26 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:09:26 [INFO]: Using the given device: cuda:0
2024-06-01 21:09:26 [INFO]: Model files will be saved to results_point_rate01/Crossformer_Pedestrian/round_0/20240601_T210926
2024-06-01 21:09:26 [INFO]: Tensorboard file will be saved to results_point_rate01/Crossformer_Pedestrian/round_0/20240601_T210926/tensorboard
2024-06-01 21:09:26 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 202,905
2024-06-01 21:09:27 [INFO]: Epoch 001 - training loss: 1.0876, validation loss: 0.2296
2024-06-01 21:09:27 [INFO]: Epoch 002 - training loss: 0.6596, validation loss: 0.1049
2024-06-01 21:09:27 [INFO]: Epoch 003 - training loss: 0.5328, validation loss: 0.0742
2024-06-01 21:09:28 [INFO]: Epoch 004 - training loss: 0.4843, validation loss: 0.0685
2024-06-01 21:09:28 [INFO]: Epoch 005 - training loss: 0.4565, validation loss: 0.0637
2024-06-01 21:09:28 [INFO]: Epoch 006 - training loss: 0.4299, validation loss: 0.0668
2024-06-01 21:09:28 [INFO]: Epoch 007 - training loss: 0.4202, validation loss: 0.0612
2024-06-01 21:09:29 [INFO]: Epoch 008 - training loss: 0.4054, validation loss: 0.0576
2024-06-01 21:09:29 [INFO]: Epoch 009 - training loss: 0.3922, validation loss: 0.0553
2024-06-01 21:09:29 [INFO]: Epoch 010 - training loss: 0.3826, validation loss: 0.0573
2024-06-01 21:09:30 [INFO]: Epoch 011 - training loss: 0.3775, validation loss: 0.0534
2024-06-01 21:09:30 [INFO]: Epoch 012 - training loss: 0.3586, validation loss: 0.0478
2024-06-01 21:09:30 [INFO]: Epoch 013 - training loss: 0.3618, validation loss: 0.0494
2024-06-01 21:09:30 [INFO]: Epoch 014 - training loss: 0.3401, validation loss: 0.0455
2024-06-01 21:09:31 [INFO]: Epoch 015 - training loss: 0.3395, validation loss: 0.0477
2024-06-01 21:09:31 [INFO]: Epoch 016 - training loss: 0.3402, validation loss: 0.0489
2024-06-01 21:09:31 [INFO]: Epoch 017 - training loss: 0.3416, validation loss: 0.0437
2024-06-01 21:09:31 [INFO]: Epoch 018 - training loss: 0.3270, validation loss: 0.0443
2024-06-01 21:09:32 [INFO]: Epoch 019 - training loss: 0.3278, validation loss: 0.0396
2024-06-01 21:09:32 [INFO]: Epoch 020 - training loss: 0.3198, validation loss: 0.0425
2024-06-01 21:09:32 [INFO]: Epoch 021 - training loss: 0.3152, validation loss: 0.0415
2024-06-01 21:09:32 [INFO]: Epoch 022 - training loss: 0.3053, validation loss: 0.0430
2024-06-01 21:09:33 [INFO]: Epoch 023 - training loss: 0.3140, validation loss: 0.0420
2024-06-01 21:09:33 [INFO]: Epoch 024 - training loss: 0.3042, validation loss: 0.0386
2024-06-01 21:09:33 [INFO]: Epoch 025 - training loss: 0.3064, validation loss: 0.0372
2024-06-01 21:09:33 [INFO]: Epoch 026 - training loss: 0.2921, validation loss: 0.0375
2024-06-01 21:09:34 [INFO]: Epoch 027 - training loss: 0.2873, validation loss: 0.0361
2024-06-01 21:09:34 [INFO]: Epoch 028 - training loss: 0.2936, validation loss: 0.0322
2024-06-01 21:09:34 [INFO]: Epoch 029 - training loss: 0.2847, validation loss: 0.0330
2024-06-01 21:09:34 [INFO]: Epoch 030 - training loss: 0.2875, validation loss: 0.0359
2024-06-01 21:09:35 [INFO]: Epoch 031 - training loss: 0.2870, validation loss: 0.0379
2024-06-01 21:09:35 [INFO]: Epoch 032 - training loss: 0.2794, validation loss: 0.0307
2024-06-01 21:09:35 [INFO]: Epoch 033 - training loss: 0.2829, validation loss: 0.0335
2024-06-01 21:09:35 [INFO]: Epoch 034 - training loss: 0.2809, validation loss: 0.0329
2024-06-01 21:09:36 [INFO]: Epoch 035 - training loss: 0.2802, validation loss: 0.0329
2024-06-01 21:09:36 [INFO]: Epoch 036 - training loss: 0.2842, validation loss: 0.0277
2024-06-01 21:09:36 [INFO]: Epoch 037 - training loss: 0.2810, validation loss: 0.0268
2024-06-01 21:09:36 [INFO]: Epoch 038 - training loss: 0.2736, validation loss: 0.0302
2024-06-01 21:09:37 [INFO]: Epoch 039 - training loss: 0.2684, validation loss: 0.0274
2024-06-01 21:09:37 [INFO]: Epoch 040 - training loss: 0.2721, validation loss: 0.0292
2024-06-01 21:09:37 [INFO]: Epoch 041 - training loss: 0.2776, validation loss: 0.0303
2024-06-01 21:09:38 [INFO]: Epoch 042 - training loss: 0.2704, validation loss: 0.0275
2024-06-01 21:09:38 [INFO]: Epoch 043 - training loss: 0.2685, validation loss: 0.0293
2024-06-01 21:09:38 [INFO]: Epoch 044 - training loss: 0.2638, validation loss: 0.0285
2024-06-01 21:09:38 [INFO]: Epoch 045 - training loss: 0.2812, validation loss: 0.0300
2024-06-01 21:09:39 [INFO]: Epoch 046 - training loss: 0.2658, validation loss: 0.0294
2024-06-01 21:09:39 [INFO]: Epoch 047 - training loss: 0.2571, validation loss: 0.0259
2024-06-01 21:09:39 [INFO]: Epoch 048 - training loss: 0.2621, validation loss: 0.0281
2024-06-01 21:09:39 [INFO]: Epoch 049 - training loss: 0.2503, validation loss: 0.0300
2024-06-01 21:09:40 [INFO]: Epoch 050 - training loss: 0.2464, validation loss: 0.0288
2024-06-01 21:09:40 [INFO]: Epoch 051 - training loss: 0.2632, validation loss: 0.0299
2024-06-01 21:09:40 [INFO]: Epoch 052 - training loss: 0.2585, validation loss: 0.0267
2024-06-01 21:09:40 [INFO]: Epoch 053 - training loss: 0.2508, validation loss: 0.0269
2024-06-01 21:09:41 [INFO]: Epoch 054 - training loss: 0.2650, validation loss: 0.0313
2024-06-01 21:09:41 [INFO]: Epoch 055 - training loss: 0.2591, validation loss: 0.0257
2024-06-01 21:09:41 [INFO]: Epoch 056 - training loss: 0.2510, validation loss: 0.0261
2024-06-01 21:09:41 [INFO]: Epoch 057 - training loss: 0.2536, validation loss: 0.0255
2024-06-01 21:09:42 [INFO]: Epoch 058 - training loss: 0.2472, validation loss: 0.0265
2024-06-01 21:09:42 [INFO]: Epoch 059 - training loss: 0.2481, validation loss: 0.0259
2024-06-01 21:09:42 [INFO]: Epoch 060 - training loss: 0.2597, validation loss: 0.0255
2024-06-01 21:09:42 [INFO]: Epoch 061 - training loss: 0.2456, validation loss: 0.0285
2024-06-01 21:09:43 [INFO]: Epoch 062 - training loss: 0.2456, validation loss: 0.0275
2024-06-01 21:09:43 [INFO]: Epoch 063 - training loss: 0.2492, validation loss: 0.0254
2024-06-01 21:09:43 [INFO]: Epoch 064 - training loss: 0.2428, validation loss: 0.0270
2024-06-01 21:09:43 [INFO]: Epoch 065 - training loss: 0.2398, validation loss: 0.0258
2024-06-01 21:09:44 [INFO]: Epoch 066 - training loss: 0.2428, validation loss: 0.0252
2024-06-01 21:09:44 [INFO]: Epoch 067 - training loss: 0.2370, validation loss: 0.0260
2024-06-01 21:09:44 [INFO]: Epoch 068 - training loss: 0.2491, validation loss: 0.0246
2024-06-01 21:09:44 [INFO]: Epoch 069 - training loss: 0.2410, validation loss: 0.0250
2024-06-01 21:09:45 [INFO]: Epoch 070 - training loss: 0.2459, validation loss: 0.0258
2024-06-01 21:09:45 [INFO]: Epoch 071 - training loss: 0.2400, validation loss: 0.0244
2024-06-01 21:09:45 [INFO]: Epoch 072 - training loss: 0.2457, validation loss: 0.0256
2024-06-01 21:09:45 [INFO]: Epoch 073 - training loss: 0.2399, validation loss: 0.0226
2024-06-01 21:09:46 [INFO]: Epoch 074 - training loss: 0.2461, validation loss: 0.0283
2024-06-01 21:09:46 [INFO]: Epoch 075 - training loss: 0.2386, validation loss: 0.0238
2024-06-01 21:09:46 [INFO]: Epoch 076 - training loss: 0.2369, validation loss: 0.0250
2024-06-01 21:09:47 [INFO]: Epoch 077 - training loss: 0.2383, validation loss: 0.0257
2024-06-01 21:09:47 [INFO]: Epoch 078 - training loss: 0.2417, validation loss: 0.0229
2024-06-01 21:09:47 [INFO]: Epoch 079 - training loss: 0.2387, validation loss: 0.0248
2024-06-01 21:09:47 [INFO]: Epoch 080 - training loss: 0.2378, validation loss: 0.0244
2024-06-01 21:09:48 [INFO]: Epoch 081 - training loss: 0.2345, validation loss: 0.0234
2024-06-01 21:09:48 [INFO]: Epoch 082 - training loss: 0.2415, validation loss: 0.0249
2024-06-01 21:09:48 [INFO]: Epoch 083 - training loss: 0.2364, validation loss: 0.0256
2024-06-01 21:09:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:09:48 [INFO]: Finished training. The best model is from epoch#73.
2024-06-01 21:09:48 [INFO]: Saved the model to results_point_rate01/Crossformer_Pedestrian/round_0/20240601_T210926/Crossformer.pypots
2024-06-01 21:09:48 [INFO]: Successfully saved to results_point_rate01/Crossformer_Pedestrian/round_0/imputation.pkl
2024-06-01 21:09:48 [INFO]: Round0 - Crossformer on Pedestrian: MAE=0.1189, MSE=0.0675, MRE=0.1624
2024-06-01 21:09:48 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 21:09:48 [INFO]: Using the given device: cuda:0
2024-06-01 21:09:48 [INFO]: Model files will be saved to results_point_rate01/Crossformer_Pedestrian/round_1/20240601_T210948
2024-06-01 21:09:48 [INFO]: Tensorboard file will be saved to results_point_rate01/Crossformer_Pedestrian/round_1/20240601_T210948/tensorboard
2024-06-01 21:09:48 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 202,905
2024-06-01 21:09:49 [INFO]: Epoch 001 - training loss: 1.1955, validation loss: 0.2464
2024-06-01 21:09:49 [INFO]: Epoch 002 - training loss: 0.6861, validation loss: 0.1265
2024-06-01 21:09:49 [INFO]: Epoch 003 - training loss: 0.5466, validation loss: 0.0759
2024-06-01 21:09:49 [INFO]: Epoch 004 - training loss: 0.4711, validation loss: 0.0707
2024-06-01 21:09:50 [INFO]: Epoch 005 - training loss: 0.4407, validation loss: 0.0692
2024-06-01 21:09:50 [INFO]: Epoch 006 - training loss: 0.4238, validation loss: 0.0647
2024-06-01 21:09:50 [INFO]: Epoch 007 - training loss: 0.4047, validation loss: 0.0573
2024-06-01 21:09:50 [INFO]: Epoch 008 - training loss: 0.3944, validation loss: 0.0563
2024-06-01 21:09:51 [INFO]: Epoch 009 - training loss: 0.3874, validation loss: 0.0533
2024-06-01 21:09:51 [INFO]: Epoch 010 - training loss: 0.3689, validation loss: 0.0539
2024-06-01 21:09:51 [INFO]: Epoch 011 - training loss: 0.3603, validation loss: 0.0544
2024-06-01 21:09:51 [INFO]: Epoch 012 - training loss: 0.3619, validation loss: 0.0479
2024-06-01 21:09:52 [INFO]: Epoch 013 - training loss: 0.3565, validation loss: 0.0464
2024-06-01 21:09:52 [INFO]: Epoch 014 - training loss: 0.3521, validation loss: 0.0469
2024-06-01 21:09:52 [INFO]: Epoch 015 - training loss: 0.3393, validation loss: 0.0464
2024-06-01 21:09:52 [INFO]: Epoch 016 - training loss: 0.3386, validation loss: 0.0481
2024-06-01 21:09:53 [INFO]: Epoch 017 - training loss: 0.3286, validation loss: 0.0428
2024-06-01 21:09:53 [INFO]: Epoch 018 - training loss: 0.3200, validation loss: 0.0401
2024-06-01 21:09:53 [INFO]: Epoch 019 - training loss: 0.3156, validation loss: 0.0418
2024-06-01 21:09:53 [INFO]: Epoch 020 - training loss: 0.3179, validation loss: 0.0405
2024-06-01 21:09:54 [INFO]: Epoch 021 - training loss: 0.3163, validation loss: 0.0386
2024-06-01 21:09:54 [INFO]: Epoch 022 - training loss: 0.3137, validation loss: 0.0405
2024-06-01 21:09:54 [INFO]: Epoch 023 - training loss: 0.3035, validation loss: 0.0367
2024-06-01 21:09:54 [INFO]: Epoch 024 - training loss: 0.3118, validation loss: 0.0402
2024-06-01 21:09:55 [INFO]: Epoch 025 - training loss: 0.2956, validation loss: 0.0356
2024-06-01 21:09:55 [INFO]: Epoch 026 - training loss: 0.2913, validation loss: 0.0344
2024-06-01 21:09:55 [INFO]: Epoch 027 - training loss: 0.2965, validation loss: 0.0329
2024-06-01 21:09:56 [INFO]: Epoch 028 - training loss: 0.2914, validation loss: 0.0350
2024-06-01 21:09:56 [INFO]: Epoch 029 - training loss: 0.2921, validation loss: 0.0370
2024-06-01 21:09:56 [INFO]: Epoch 030 - training loss: 0.2928, validation loss: 0.0363
2024-06-01 21:09:56 [INFO]: Epoch 031 - training loss: 0.2847, validation loss: 0.0329
2024-06-01 21:09:57 [INFO]: Epoch 032 - training loss: 0.2832, validation loss: 0.0327
2024-06-01 21:09:57 [INFO]: Epoch 033 - training loss: 0.2793, validation loss: 0.0345
2024-06-01 21:09:57 [INFO]: Epoch 034 - training loss: 0.2862, validation loss: 0.0333
2024-06-01 21:09:57 [INFO]: Epoch 035 - training loss: 0.2762, validation loss: 0.0317
2024-06-01 21:09:58 [INFO]: Epoch 036 - training loss: 0.2785, validation loss: 0.0331
2024-06-01 21:09:58 [INFO]: Epoch 037 - training loss: 0.2857, validation loss: 0.0337
2024-06-01 21:09:58 [INFO]: Epoch 038 - training loss: 0.2815, validation loss: 0.0303
2024-06-01 21:09:58 [INFO]: Epoch 039 - training loss: 0.2815, validation loss: 0.0340
2024-06-01 21:09:59 [INFO]: Epoch 040 - training loss: 0.2707, validation loss: 0.0307
2024-06-01 21:09:59 [INFO]: Epoch 041 - training loss: 0.2681, validation loss: 0.0305
2024-06-01 21:09:59 [INFO]: Epoch 042 - training loss: 0.2739, validation loss: 0.0315
2024-06-01 21:09:59 [INFO]: Epoch 043 - training loss: 0.2643, validation loss: 0.0329
2024-06-01 21:10:00 [INFO]: Epoch 044 - training loss: 0.2640, validation loss: 0.0309
2024-06-01 21:10:00 [INFO]: Epoch 045 - training loss: 0.2604, validation loss: 0.0300
2024-06-01 21:10:00 [INFO]: Epoch 046 - training loss: 0.2644, validation loss: 0.0295
2024-06-01 21:10:00 [INFO]: Epoch 047 - training loss: 0.2622, validation loss: 0.0275
2024-06-01 21:10:01 [INFO]: Epoch 048 - training loss: 0.2607, validation loss: 0.0305
2024-06-01 21:10:01 [INFO]: Epoch 049 - training loss: 0.2641, validation loss: 0.0313
2024-06-01 21:10:01 [INFO]: Epoch 050 - training loss: 0.2563, validation loss: 0.0301
2024-06-01 21:10:01 [INFO]: Epoch 051 - training loss: 0.2575, validation loss: 0.0338
2024-06-01 21:10:02 [INFO]: Epoch 052 - training loss: 0.2660, validation loss: 0.0317
2024-06-01 21:10:02 [INFO]: Epoch 053 - training loss: 0.2602, validation loss: 0.0308
2024-06-01 21:10:02 [INFO]: Epoch 054 - training loss: 0.2532, validation loss: 0.0312
2024-06-01 21:10:03 [INFO]: Epoch 055 - training loss: 0.2570, validation loss: 0.0312
2024-06-01 21:10:03 [INFO]: Epoch 056 - training loss: 0.2478, validation loss: 0.0280
2024-06-01 21:10:03 [INFO]: Epoch 057 - training loss: 0.2603, validation loss: 0.0313
2024-06-01 21:10:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:10:03 [INFO]: Finished training. The best model is from epoch#47.
2024-06-01 21:10:03 [INFO]: Saved the model to results_point_rate01/Crossformer_Pedestrian/round_1/20240601_T210948/Crossformer.pypots
2024-06-01 21:10:03 [INFO]: Successfully saved to results_point_rate01/Crossformer_Pedestrian/round_1/imputation.pkl
2024-06-01 21:10:03 [INFO]: Round1 - Crossformer on Pedestrian: MAE=0.1286, MSE=0.0741, MRE=0.1758
2024-06-01 21:10:03 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 21:10:03 [INFO]: Using the given device: cuda:0
2024-06-01 21:10:03 [INFO]: Model files will be saved to results_point_rate01/Crossformer_Pedestrian/round_2/20240601_T211003
2024-06-01 21:10:03 [INFO]: Tensorboard file will be saved to results_point_rate01/Crossformer_Pedestrian/round_2/20240601_T211003/tensorboard
2024-06-01 21:10:03 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 202,905
2024-06-01 21:10:03 [INFO]: Epoch 001 - training loss: 1.1506, validation loss: 0.2412
2024-06-01 21:10:04 [INFO]: Epoch 002 - training loss: 0.7064, validation loss: 0.1097
2024-06-01 21:10:04 [INFO]: Epoch 003 - training loss: 0.5325, validation loss: 0.0821
2024-06-01 21:10:04 [INFO]: Epoch 004 - training loss: 0.4744, validation loss: 0.0795
2024-06-01 21:10:05 [INFO]: Epoch 005 - training loss: 0.4536, validation loss: 0.0637
2024-06-01 21:10:05 [INFO]: Epoch 006 - training loss: 0.4223, validation loss: 0.0635
2024-06-01 21:10:05 [INFO]: Epoch 007 - training loss: 0.4134, validation loss: 0.0607
2024-06-01 21:10:05 [INFO]: Epoch 008 - training loss: 0.4005, validation loss: 0.0614
2024-06-01 21:10:06 [INFO]: Epoch 009 - training loss: 0.3841, validation loss: 0.0508
2024-06-01 21:10:06 [INFO]: Epoch 010 - training loss: 0.3704, validation loss: 0.0524
2024-06-01 21:10:06 [INFO]: Epoch 011 - training loss: 0.3675, validation loss: 0.0529
2024-06-01 21:10:06 [INFO]: Epoch 012 - training loss: 0.3761, validation loss: 0.0487
2024-06-01 21:10:07 [INFO]: Epoch 013 - training loss: 0.3593, validation loss: 0.0421
2024-06-01 21:10:07 [INFO]: Epoch 014 - training loss: 0.3420, validation loss: 0.0466
2024-06-01 21:10:07 [INFO]: Epoch 015 - training loss: 0.3407, validation loss: 0.0402
2024-06-01 21:10:07 [INFO]: Epoch 016 - training loss: 0.3294, validation loss: 0.0395
2024-06-01 21:10:08 [INFO]: Epoch 017 - training loss: 0.3331, validation loss: 0.0432
2024-06-01 21:10:08 [INFO]: Epoch 018 - training loss: 0.3164, validation loss: 0.0391
2024-06-01 21:10:08 [INFO]: Epoch 019 - training loss: 0.3208, validation loss: 0.0445
2024-06-01 21:10:08 [INFO]: Epoch 020 - training loss: 0.3147, validation loss: 0.0398
2024-06-01 21:10:09 [INFO]: Epoch 021 - training loss: 0.3190, validation loss: 0.0422
2024-06-01 21:10:09 [INFO]: Epoch 022 - training loss: 0.3110, validation loss: 0.0368
2024-06-01 21:10:09 [INFO]: Epoch 023 - training loss: 0.3066, validation loss: 0.0386
2024-06-01 21:10:09 [INFO]: Epoch 024 - training loss: 0.2996, validation loss: 0.0363
2024-06-01 21:10:10 [INFO]: Epoch 025 - training loss: 0.2995, validation loss: 0.0389
2024-06-01 21:10:10 [INFO]: Epoch 026 - training loss: 0.2930, validation loss: 0.0378
2024-06-01 21:10:10 [INFO]: Epoch 027 - training loss: 0.2980, validation loss: 0.0375
2024-06-01 21:10:10 [INFO]: Epoch 028 - training loss: 0.2904, validation loss: 0.0352
2024-06-01 21:10:11 [INFO]: Epoch 029 - training loss: 0.2919, validation loss: 0.0350
2024-06-01 21:10:11 [INFO]: Epoch 030 - training loss: 0.2868, validation loss: 0.0341
2024-06-01 21:10:11 [INFO]: Epoch 031 - training loss: 0.2893, validation loss: 0.0343
2024-06-01 21:10:12 [INFO]: Epoch 032 - training loss: 0.2799, validation loss: 0.0356
2024-06-01 21:10:12 [INFO]: Epoch 033 - training loss: 0.2770, validation loss: 0.0340
2024-06-01 21:10:12 [INFO]: Epoch 034 - training loss: 0.2818, validation loss: 0.0358
2024-06-01 21:10:13 [INFO]: Epoch 035 - training loss: 0.2680, validation loss: 0.0302
2024-06-01 21:10:13 [INFO]: Epoch 036 - training loss: 0.2775, validation loss: 0.0329
2024-06-01 21:10:13 [INFO]: Epoch 037 - training loss: 0.2718, validation loss: 0.0323
2024-06-01 21:10:13 [INFO]: Epoch 038 - training loss: 0.2726, validation loss: 0.0346
2024-06-01 21:10:14 [INFO]: Epoch 039 - training loss: 0.2767, validation loss: 0.0346
2024-06-01 21:10:14 [INFO]: Epoch 040 - training loss: 0.2664, validation loss: 0.0327
2024-06-01 21:10:14 [INFO]: Epoch 041 - training loss: 0.2665, validation loss: 0.0322
2024-06-01 21:10:14 [INFO]: Epoch 042 - training loss: 0.2607, validation loss: 0.0315
2024-06-01 21:10:15 [INFO]: Epoch 043 - training loss: 0.2639, validation loss: 0.0298
2024-06-01 21:10:15 [INFO]: Epoch 044 - training loss: 0.2656, validation loss: 0.0344
2024-06-01 21:10:15 [INFO]: Epoch 045 - training loss: 0.2635, validation loss: 0.0317
2024-06-01 21:10:15 [INFO]: Epoch 046 - training loss: 0.2678, validation loss: 0.0298
2024-06-01 21:10:16 [INFO]: Epoch 047 - training loss: 0.2599, validation loss: 0.0275
2024-06-01 21:10:16 [INFO]: Epoch 048 - training loss: 0.2598, validation loss: 0.0306
2024-06-01 21:10:16 [INFO]: Epoch 049 - training loss: 0.2552, validation loss: 0.0257
2024-06-01 21:10:16 [INFO]: Epoch 050 - training loss: 0.2553, validation loss: 0.0260
2024-06-01 21:10:17 [INFO]: Epoch 051 - training loss: 0.2571, validation loss: 0.0285
2024-06-01 21:10:17 [INFO]: Epoch 052 - training loss: 0.2648, validation loss: 0.0307
2024-06-01 21:10:17 [INFO]: Epoch 053 - training loss: 0.2664, validation loss: 0.0258
2024-06-01 21:10:17 [INFO]: Epoch 054 - training loss: 0.2573, validation loss: 0.0292
2024-06-01 21:10:18 [INFO]: Epoch 055 - training loss: 0.2532, validation loss: 0.0277
2024-06-01 21:10:18 [INFO]: Epoch 056 - training loss: 0.2539, validation loss: 0.0264
2024-06-01 21:10:18 [INFO]: Epoch 057 - training loss: 0.2493, validation loss: 0.0276
2024-06-01 21:10:18 [INFO]: Epoch 058 - training loss: 0.2462, validation loss: 0.0273
2024-06-01 21:10:19 [INFO]: Epoch 059 - training loss: 0.2520, validation loss: 0.0275
2024-06-01 21:10:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:10:19 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 21:10:19 [INFO]: Saved the model to results_point_rate01/Crossformer_Pedestrian/round_2/20240601_T211003/Crossformer.pypots
2024-06-01 21:10:19 [INFO]: Successfully saved to results_point_rate01/Crossformer_Pedestrian/round_2/imputation.pkl
2024-06-01 21:10:19 [INFO]: Round2 - Crossformer on Pedestrian: MAE=0.1193, MSE=0.0722, MRE=0.1630
2024-06-01 21:10:19 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 21:10:19 [INFO]: Using the given device: cuda:0
2024-06-01 21:10:19 [INFO]: Model files will be saved to results_point_rate01/Crossformer_Pedestrian/round_3/20240601_T211019
2024-06-01 21:10:19 [INFO]: Tensorboard file will be saved to results_point_rate01/Crossformer_Pedestrian/round_3/20240601_T211019/tensorboard
2024-06-01 21:10:19 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 202,905
2024-06-01 21:10:19 [INFO]: Epoch 001 - training loss: 1.1668, validation loss: 0.2335
2024-06-01 21:10:19 [INFO]: Epoch 002 - training loss: 0.7038, validation loss: 0.1145
2024-06-01 21:10:20 [INFO]: Epoch 003 - training loss: 0.5577, validation loss: 0.0836
2024-06-01 21:10:20 [INFO]: Epoch 004 - training loss: 0.4879, validation loss: 0.0686
2024-06-01 21:10:20 [INFO]: Epoch 005 - training loss: 0.4465, validation loss: 0.0614
2024-06-01 21:10:20 [INFO]: Epoch 006 - training loss: 0.4212, validation loss: 0.0594
2024-06-01 21:10:21 [INFO]: Epoch 007 - training loss: 0.4071, validation loss: 0.0602
2024-06-01 21:10:21 [INFO]: Epoch 008 - training loss: 0.3981, validation loss: 0.0567
2024-06-01 21:10:21 [INFO]: Epoch 009 - training loss: 0.3971, validation loss: 0.0548
2024-06-01 21:10:21 [INFO]: Epoch 010 - training loss: 0.3726, validation loss: 0.0556
2024-06-01 21:10:22 [INFO]: Epoch 011 - training loss: 0.3762, validation loss: 0.0543
2024-06-01 21:10:22 [INFO]: Epoch 012 - training loss: 0.3657, validation loss: 0.0509
2024-06-01 21:10:22 [INFO]: Epoch 013 - training loss: 0.3508, validation loss: 0.0518
2024-06-01 21:10:23 [INFO]: Epoch 014 - training loss: 0.3499, validation loss: 0.0504
2024-06-01 21:10:23 [INFO]: Epoch 015 - training loss: 0.3359, validation loss: 0.0419
2024-06-01 21:10:23 [INFO]: Epoch 016 - training loss: 0.3351, validation loss: 0.0425
2024-06-01 21:10:23 [INFO]: Epoch 017 - training loss: 0.3399, validation loss: 0.0433
2024-06-01 21:10:24 [INFO]: Epoch 018 - training loss: 0.3356, validation loss: 0.0420
2024-06-01 21:10:24 [INFO]: Epoch 019 - training loss: 0.3070, validation loss: 0.0396
2024-06-01 21:10:24 [INFO]: Epoch 020 - training loss: 0.3148, validation loss: 0.0443
2024-06-01 21:10:24 [INFO]: Epoch 021 - training loss: 0.3141, validation loss: 0.0350
2024-06-01 21:10:25 [INFO]: Epoch 022 - training loss: 0.3011, validation loss: 0.0369
2024-06-01 21:10:25 [INFO]: Epoch 023 - training loss: 0.3020, validation loss: 0.0404
2024-06-01 21:10:25 [INFO]: Epoch 024 - training loss: 0.3030, validation loss: 0.0392
2024-06-01 21:10:25 [INFO]: Epoch 025 - training loss: 0.2901, validation loss: 0.0373
2024-06-01 21:10:26 [INFO]: Epoch 026 - training loss: 0.2945, validation loss: 0.0397
2024-06-01 21:10:26 [INFO]: Epoch 027 - training loss: 0.3007, validation loss: 0.0340
2024-06-01 21:10:26 [INFO]: Epoch 028 - training loss: 0.2952, validation loss: 0.0320
2024-06-01 21:10:26 [INFO]: Epoch 029 - training loss: 0.2979, validation loss: 0.0361
2024-06-01 21:10:27 [INFO]: Epoch 030 - training loss: 0.3014, validation loss: 0.0331
2024-06-01 21:10:27 [INFO]: Epoch 031 - training loss: 0.2851, validation loss: 0.0331
2024-06-01 21:10:27 [INFO]: Epoch 032 - training loss: 0.2889, validation loss: 0.0314
2024-06-01 21:10:27 [INFO]: Epoch 033 - training loss: 0.2857, validation loss: 0.0344
2024-06-01 21:10:28 [INFO]: Epoch 034 - training loss: 0.2855, validation loss: 0.0325
2024-06-01 21:10:28 [INFO]: Epoch 035 - training loss: 0.2756, validation loss: 0.0316
2024-06-01 21:10:28 [INFO]: Epoch 036 - training loss: 0.2731, validation loss: 0.0309
2024-06-01 21:10:28 [INFO]: Epoch 037 - training loss: 0.2750, validation loss: 0.0320
2024-06-01 21:10:29 [INFO]: Epoch 038 - training loss: 0.2846, validation loss: 0.0306
2024-06-01 21:10:29 [INFO]: Epoch 039 - training loss: 0.2692, validation loss: 0.0322
2024-06-01 21:10:29 [INFO]: Epoch 040 - training loss: 0.2824, validation loss: 0.0335
2024-06-01 21:10:29 [INFO]: Epoch 041 - training loss: 0.2782, validation loss: 0.0298
2024-06-01 21:10:30 [INFO]: Epoch 042 - training loss: 0.2703, validation loss: 0.0324
2024-06-01 21:10:30 [INFO]: Epoch 043 - training loss: 0.2688, validation loss: 0.0294
2024-06-01 21:10:30 [INFO]: Epoch 044 - training loss: 0.2709, validation loss: 0.0295
2024-06-01 21:10:31 [INFO]: Epoch 045 - training loss: 0.2618, validation loss: 0.0297
2024-06-01 21:10:31 [INFO]: Epoch 046 - training loss: 0.2604, validation loss: 0.0277
2024-06-01 21:10:31 [INFO]: Epoch 047 - training loss: 0.2609, validation loss: 0.0310
2024-06-01 21:10:31 [INFO]: Epoch 048 - training loss: 0.2542, validation loss: 0.0301
2024-06-01 21:10:32 [INFO]: Epoch 049 - training loss: 0.2617, validation loss: 0.0275
2024-06-01 21:10:32 [INFO]: Epoch 050 - training loss: 0.2546, validation loss: 0.0274
2024-06-01 21:10:32 [INFO]: Epoch 051 - training loss: 0.2588, validation loss: 0.0277
2024-06-01 21:10:32 [INFO]: Epoch 052 - training loss: 0.2636, validation loss: 0.0286
2024-06-01 21:10:33 [INFO]: Epoch 053 - training loss: 0.2611, validation loss: 0.0274
2024-06-01 21:10:33 [INFO]: Epoch 054 - training loss: 0.2643, validation loss: 0.0282
2024-06-01 21:10:33 [INFO]: Epoch 055 - training loss: 0.2609, validation loss: 0.0284
2024-06-01 21:10:33 [INFO]: Epoch 056 - training loss: 0.2609, validation loss: 0.0301
2024-06-01 21:10:34 [INFO]: Epoch 057 - training loss: 0.2577, validation loss: 0.0286
2024-06-01 21:10:34 [INFO]: Epoch 058 - training loss: 0.2507, validation loss: 0.0270
2024-06-01 21:10:34 [INFO]: Epoch 059 - training loss: 0.2611, validation loss: 0.0291
2024-06-01 21:10:34 [INFO]: Epoch 060 - training loss: 0.2547, validation loss: 0.0303
2024-06-01 21:10:35 [INFO]: Epoch 061 - training loss: 0.2479, validation loss: 0.0300
2024-06-01 21:10:35 [INFO]: Epoch 062 - training loss: 0.2488, validation loss: 0.0284
2024-06-01 21:10:35 [INFO]: Epoch 063 - training loss: 0.2485, validation loss: 0.0290
2024-06-01 21:10:35 [INFO]: Epoch 064 - training loss: 0.2457, validation loss: 0.0299
2024-06-01 21:10:36 [INFO]: Epoch 065 - training loss: 0.2460, validation loss: 0.0265
2024-06-01 21:10:36 [INFO]: Epoch 066 - training loss: 0.2473, validation loss: 0.0283
2024-06-01 21:10:36 [INFO]: Epoch 067 - training loss: 0.2397, validation loss: 0.0259
2024-06-01 21:10:36 [INFO]: Epoch 068 - training loss: 0.2474, validation loss: 0.0281
2024-06-01 21:10:37 [INFO]: Epoch 069 - training loss: 0.2527, validation loss: 0.0274
2024-06-01 21:10:37 [INFO]: Epoch 070 - training loss: 0.2516, validation loss: 0.0279
2024-06-01 21:10:37 [INFO]: Epoch 071 - training loss: 0.2469, validation loss: 0.0285
2024-06-01 21:10:38 [INFO]: Epoch 072 - training loss: 0.2499, validation loss: 0.0263
2024-06-01 21:10:38 [INFO]: Epoch 073 - training loss: 0.2507, validation loss: 0.0250
2024-06-01 21:10:38 [INFO]: Epoch 074 - training loss: 0.2345, validation loss: 0.0270
2024-06-01 21:10:38 [INFO]: Epoch 075 - training loss: 0.2413, validation loss: 0.0256
2024-06-01 21:10:39 [INFO]: Epoch 076 - training loss: 0.2334, validation loss: 0.0260
2024-06-01 21:10:39 [INFO]: Epoch 077 - training loss: 0.2407, validation loss: 0.0263
2024-06-01 21:10:39 [INFO]: Epoch 078 - training loss: 0.2470, validation loss: 0.0254
2024-06-01 21:10:39 [INFO]: Epoch 079 - training loss: 0.2391, validation loss: 0.0234
2024-06-01 21:10:40 [INFO]: Epoch 080 - training loss: 0.2414, validation loss: 0.0250
2024-06-01 21:10:40 [INFO]: Epoch 081 - training loss: 0.2481, validation loss: 0.0227
2024-06-01 21:10:40 [INFO]: Epoch 082 - training loss: 0.2351, validation loss: 0.0270
2024-06-01 21:10:40 [INFO]: Epoch 083 - training loss: 0.2333, validation loss: 0.0259
2024-06-01 21:10:41 [INFO]: Epoch 084 - training loss: 0.2350, validation loss: 0.0261
2024-06-01 21:10:41 [INFO]: Epoch 085 - training loss: 0.2400, validation loss: 0.0290
2024-06-01 21:10:41 [INFO]: Epoch 086 - training loss: 0.2420, validation loss: 0.0257
2024-06-01 21:10:41 [INFO]: Epoch 087 - training loss: 0.2394, validation loss: 0.0288
2024-06-01 21:10:42 [INFO]: Epoch 088 - training loss: 0.2418, validation loss: 0.0264
2024-06-01 21:10:42 [INFO]: Epoch 089 - training loss: 0.2285, validation loss: 0.0273
2024-06-01 21:10:42 [INFO]: Epoch 090 - training loss: 0.2369, validation loss: 0.0272
2024-06-01 21:10:42 [INFO]: Epoch 091 - training loss: 0.2340, validation loss: 0.0240
2024-06-01 21:10:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:10:42 [INFO]: Finished training. The best model is from epoch#81.
2024-06-01 21:10:42 [INFO]: Saved the model to results_point_rate01/Crossformer_Pedestrian/round_3/20240601_T211019/Crossformer.pypots
2024-06-01 21:10:43 [INFO]: Successfully saved to results_point_rate01/Crossformer_Pedestrian/round_3/imputation.pkl
2024-06-01 21:10:43 [INFO]: Round3 - Crossformer on Pedestrian: MAE=0.1118, MSE=0.0675, MRE=0.1528
2024-06-01 21:10:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 21:10:43 [INFO]: Using the given device: cuda:0
2024-06-01 21:10:43 [INFO]: Model files will be saved to results_point_rate01/Crossformer_Pedestrian/round_4/20240601_T211043
2024-06-01 21:10:43 [INFO]: Tensorboard file will be saved to results_point_rate01/Crossformer_Pedestrian/round_4/20240601_T211043/tensorboard
2024-06-01 21:10:43 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 202,905
2024-06-01 21:10:43 [INFO]: Epoch 001 - training loss: 1.2306, validation loss: 0.2582
2024-06-01 21:10:43 [INFO]: Epoch 002 - training loss: 0.6935, validation loss: 0.1069
2024-06-01 21:10:43 [INFO]: Epoch 003 - training loss: 0.5393, validation loss: 0.0762
2024-06-01 21:10:44 [INFO]: Epoch 004 - training loss: 0.4820, validation loss: 0.0649
2024-06-01 21:10:44 [INFO]: Epoch 005 - training loss: 0.4666, validation loss: 0.0633
2024-06-01 21:10:44 [INFO]: Epoch 006 - training loss: 0.4340, validation loss: 0.0588
2024-06-01 21:10:44 [INFO]: Epoch 007 - training loss: 0.4151, validation loss: 0.0574
2024-06-01 21:10:45 [INFO]: Epoch 008 - training loss: 0.4026, validation loss: 0.0511
2024-06-01 21:10:45 [INFO]: Epoch 009 - training loss: 0.3895, validation loss: 0.0546
2024-06-01 21:10:45 [INFO]: Epoch 010 - training loss: 0.3774, validation loss: 0.0535
2024-06-01 21:10:45 [INFO]: Epoch 011 - training loss: 0.3735, validation loss: 0.0514
2024-06-01 21:10:46 [INFO]: Epoch 012 - training loss: 0.3690, validation loss: 0.0486
2024-06-01 21:10:46 [INFO]: Epoch 013 - training loss: 0.3553, validation loss: 0.0469
2024-06-01 21:10:46 [INFO]: Epoch 014 - training loss: 0.3424, validation loss: 0.0424
2024-06-01 21:10:46 [INFO]: Epoch 015 - training loss: 0.3467, validation loss: 0.0424
2024-06-01 21:10:47 [INFO]: Epoch 016 - training loss: 0.3389, validation loss: 0.0435
2024-06-01 21:10:47 [INFO]: Epoch 017 - training loss: 0.3281, validation loss: 0.0421
2024-06-01 21:10:47 [INFO]: Epoch 018 - training loss: 0.3267, validation loss: 0.0384
2024-06-01 21:10:47 [INFO]: Epoch 019 - training loss: 0.3241, validation loss: 0.0427
2024-06-01 21:10:48 [INFO]: Epoch 020 - training loss: 0.3146, validation loss: 0.0382
2024-06-01 21:10:48 [INFO]: Epoch 021 - training loss: 0.3175, validation loss: 0.0385
2024-06-01 21:10:48 [INFO]: Epoch 022 - training loss: 0.3082, validation loss: 0.0376
2024-06-01 21:10:49 [INFO]: Epoch 023 - training loss: 0.3121, validation loss: 0.0376
2024-06-01 21:10:49 [INFO]: Epoch 024 - training loss: 0.2967, validation loss: 0.0403
2024-06-01 21:10:49 [INFO]: Epoch 025 - training loss: 0.3153, validation loss: 0.0388
2024-06-01 21:10:49 [INFO]: Epoch 026 - training loss: 0.3039, validation loss: 0.0370
2024-06-01 21:10:50 [INFO]: Epoch 027 - training loss: 0.2990, validation loss: 0.0354
2024-06-01 21:10:50 [INFO]: Epoch 028 - training loss: 0.3017, validation loss: 0.0412
2024-06-01 21:10:50 [INFO]: Epoch 029 - training loss: 0.2916, validation loss: 0.0341
2024-06-01 21:10:50 [INFO]: Epoch 030 - training loss: 0.2900, validation loss: 0.0365
2024-06-01 21:10:51 [INFO]: Epoch 031 - training loss: 0.2835, validation loss: 0.0356
2024-06-01 21:10:51 [INFO]: Epoch 032 - training loss: 0.2822, validation loss: 0.0371
2024-06-01 21:10:51 [INFO]: Epoch 033 - training loss: 0.2939, validation loss: 0.0387
2024-06-01 21:10:51 [INFO]: Epoch 034 - training loss: 0.2848, validation loss: 0.0378
2024-06-01 21:10:52 [INFO]: Epoch 035 - training loss: 0.2829, validation loss: 0.0381
2024-06-01 21:10:52 [INFO]: Epoch 036 - training loss: 0.2853, validation loss: 0.0346
2024-06-01 21:10:52 [INFO]: Epoch 037 - training loss: 0.2761, validation loss: 0.0359
2024-06-01 21:10:52 [INFO]: Epoch 038 - training loss: 0.2784, validation loss: 0.0340
2024-06-01 21:10:53 [INFO]: Epoch 039 - training loss: 0.2739, validation loss: 0.0353
2024-06-01 21:10:53 [INFO]: Epoch 040 - training loss: 0.2784, validation loss: 0.0354
2024-06-01 21:10:53 [INFO]: Epoch 041 - training loss: 0.2753, validation loss: 0.0335
2024-06-01 21:10:54 [INFO]: Epoch 042 - training loss: 0.2686, validation loss: 0.0329
2024-06-01 21:10:54 [INFO]: Epoch 043 - training loss: 0.2669, validation loss: 0.0327
2024-06-01 21:10:54 [INFO]: Epoch 044 - training loss: 0.2617, validation loss: 0.0352
2024-06-01 21:10:54 [INFO]: Epoch 045 - training loss: 0.2625, validation loss: 0.0355
2024-06-01 21:10:55 [INFO]: Epoch 046 - training loss: 0.2602, validation loss: 0.0316
2024-06-01 21:10:55 [INFO]: Epoch 047 - training loss: 0.2743, validation loss: 0.0320
2024-06-01 21:10:55 [INFO]: Epoch 048 - training loss: 0.2604, validation loss: 0.0329
2024-06-01 21:10:55 [INFO]: Epoch 049 - training loss: 0.2589, validation loss: 0.0355
2024-06-01 21:10:56 [INFO]: Epoch 050 - training loss: 0.2663, validation loss: 0.0309
2024-06-01 21:10:56 [INFO]: Epoch 051 - training loss: 0.2613, validation loss: 0.0341
2024-06-01 21:10:56 [INFO]: Epoch 052 - training loss: 0.2639, validation loss: 0.0329
2024-06-01 21:10:56 [INFO]: Epoch 053 - training loss: 0.2713, validation loss: 0.0288
2024-06-01 21:10:57 [INFO]: Epoch 054 - training loss: 0.2610, validation loss: 0.0314
2024-06-01 21:10:57 [INFO]: Epoch 055 - training loss: 0.2556, validation loss: 0.0341
2024-06-01 21:10:57 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.0310
2024-06-01 21:10:57 [INFO]: Epoch 057 - training loss: 0.2580, validation loss: 0.0302
2024-06-01 21:10:58 [INFO]: Epoch 058 - training loss: 0.2507, validation loss: 0.0308
2024-06-01 21:10:58 [INFO]: Epoch 059 - training loss: 0.2538, validation loss: 0.0296
2024-06-01 21:10:58 [INFO]: Epoch 060 - training loss: 0.2522, validation loss: 0.0286
2024-06-01 21:10:58 [INFO]: Epoch 061 - training loss: 0.2549, validation loss: 0.0308
2024-06-01 21:10:59 [INFO]: Epoch 062 - training loss: 0.2486, validation loss: 0.0308
2024-06-01 21:10:59 [INFO]: Epoch 063 - training loss: 0.2628, validation loss: 0.0288
2024-06-01 21:10:59 [INFO]: Epoch 064 - training loss: 0.2550, validation loss: 0.0282
2024-06-01 21:10:59 [INFO]: Epoch 065 - training loss: 0.2559, validation loss: 0.0293
2024-06-01 21:11:00 [INFO]: Epoch 066 - training loss: 0.2488, validation loss: 0.0280
2024-06-01 21:11:00 [INFO]: Epoch 067 - training loss: 0.2451, validation loss: 0.0273
2024-06-01 21:11:00 [INFO]: Epoch 068 - training loss: 0.2542, validation loss: 0.0264
2024-06-01 21:11:00 [INFO]: Epoch 069 - training loss: 0.2526, validation loss: 0.0306
2024-06-01 21:11:01 [INFO]: Epoch 070 - training loss: 0.2532, validation loss: 0.0284
2024-06-01 21:11:01 [INFO]: Epoch 071 - training loss: 0.2532, validation loss: 0.0296
2024-06-01 21:11:01 [INFO]: Epoch 072 - training loss: 0.2419, validation loss: 0.0279
2024-06-01 21:11:02 [INFO]: Epoch 073 - training loss: 0.2404, validation loss: 0.0274
2024-06-01 21:11:02 [INFO]: Epoch 074 - training loss: 0.2387, validation loss: 0.0261
2024-06-01 21:11:02 [INFO]: Epoch 075 - training loss: 0.2499, validation loss: 0.0278
2024-06-01 21:11:02 [INFO]: Epoch 076 - training loss: 0.2408, validation loss: 0.0252
2024-06-01 21:11:03 [INFO]: Epoch 077 - training loss: 0.2436, validation loss: 0.0257
2024-06-01 21:11:03 [INFO]: Epoch 078 - training loss: 0.2408, validation loss: 0.0288
2024-06-01 21:11:03 [INFO]: Epoch 079 - training loss: 0.2490, validation loss: 0.0266
2024-06-01 21:11:03 [INFO]: Epoch 080 - training loss: 0.2398, validation loss: 0.0264
2024-06-01 21:11:04 [INFO]: Epoch 081 - training loss: 0.2420, validation loss: 0.0260
2024-06-01 21:11:04 [INFO]: Epoch 082 - training loss: 0.2360, validation loss: 0.0248
2024-06-01 21:11:04 [INFO]: Epoch 083 - training loss: 0.2319, validation loss: 0.0271
2024-06-01 21:11:04 [INFO]: Epoch 084 - training loss: 0.2375, validation loss: 0.0278
2024-06-01 21:11:05 [INFO]: Epoch 085 - training loss: 0.2316, validation loss: 0.0257
2024-06-01 21:11:05 [INFO]: Epoch 086 - training loss: 0.2348, validation loss: 0.0275
2024-06-01 21:11:05 [INFO]: Epoch 087 - training loss: 0.2325, validation loss: 0.0260
2024-06-01 21:11:05 [INFO]: Epoch 088 - training loss: 0.2383, validation loss: 0.0274
2024-06-01 21:11:06 [INFO]: Epoch 089 - training loss: 0.2391, validation loss: 0.0267
2024-06-01 21:11:06 [INFO]: Epoch 090 - training loss: 0.2314, validation loss: 0.0252
2024-06-01 21:11:06 [INFO]: Epoch 091 - training loss: 0.2256, validation loss: 0.0277
2024-06-01 21:11:06 [INFO]: Epoch 092 - training loss: 0.2404, validation loss: 0.0276
2024-06-01 21:11:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:11:06 [INFO]: Finished training. The best model is from epoch#82.
2024-06-01 21:11:06 [INFO]: Saved the model to results_point_rate01/Crossformer_Pedestrian/round_4/20240601_T211043/Crossformer.pypots
2024-06-01 21:11:07 [INFO]: Successfully saved to results_point_rate01/Crossformer_Pedestrian/round_4/imputation.pkl
2024-06-01 21:11:07 [INFO]: Round4 - Crossformer on Pedestrian: MAE=0.1165, MSE=0.0638, MRE=0.1592
2024-06-01 21:11:07 [INFO]: Done! Final results:
Averaged Crossformer (n params: 202,905) on Pedestrian: MAE=0.1190 ± 0.00548902306917518, MSE=0.0690 ± 0.0036792649935262728, MRE=0.1627 ± 0.007501582172912463, average inference time=0.16
