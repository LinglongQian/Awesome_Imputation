2024-06-02 20:43:21 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:43:21 [INFO]: Using the given device: cuda:0
2024-06-02 20:43:22 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_0/20240602_T204322
2024-06-02 20:43:22 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_0/20240602_T204322/tensorboard
2024-06-02 20:43:24 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 130,594
2024-06-02 20:43:31 [INFO]: Epoch 001 - training loss: 1578.4862, validation loss: 1.2864
2024-06-02 20:43:33 [INFO]: Epoch 002 - training loss: 1075.2364, validation loss: 0.6492
2024-06-02 20:43:36 [INFO]: Epoch 003 - training loss: 1063.9461, validation loss: 0.5095
2024-06-02 20:43:38 [INFO]: Epoch 004 - training loss: 1056.5867, validation loss: 0.4790
2024-06-02 20:43:41 [INFO]: Epoch 005 - training loss: 1053.7972, validation loss: 0.5452
2024-06-02 20:43:44 [INFO]: Epoch 006 - training loss: 1053.7561, validation loss: 0.4272
2024-06-02 20:43:46 [INFO]: Epoch 007 - training loss: 1051.4572, validation loss: 0.4824
2024-06-02 20:43:49 [INFO]: Epoch 008 - training loss: 1054.0898, validation loss: 1.5346
2024-06-02 20:43:52 [INFO]: Epoch 009 - training loss: 1058.6906, validation loss: 0.5238
2024-06-02 20:43:55 [INFO]: Epoch 010 - training loss: 1057.7338, validation loss: 0.5175
2024-06-02 20:43:57 [INFO]: Epoch 011 - training loss: 1052.7147, validation loss: 0.6099
2024-06-02 20:44:00 [INFO]: Epoch 012 - training loss: 1051.9106, validation loss: 0.3865
2024-06-02 20:44:03 [INFO]: Epoch 013 - training loss: 1051.0145, validation loss: 0.4506
2024-06-02 20:44:05 [INFO]: Epoch 014 - training loss: 1051.0080, validation loss: 0.4010
2024-06-02 20:44:08 [INFO]: Epoch 015 - training loss: 1050.6109, validation loss: 0.4357
2024-06-02 20:44:10 [INFO]: Epoch 016 - training loss: 1049.5085, validation loss: 0.3636
2024-06-02 20:44:13 [INFO]: Epoch 017 - training loss: 1049.0858, validation loss: 0.3892
2024-06-02 20:44:16 [INFO]: Epoch 018 - training loss: 1049.7226, validation loss: 0.5536
2024-06-02 20:44:18 [INFO]: Epoch 019 - training loss: 1054.6172, validation loss: 0.5695
2024-06-02 20:44:20 [INFO]: Epoch 020 - training loss: 1050.8375, validation loss: 0.4167
2024-06-02 20:44:23 [INFO]: Epoch 021 - training loss: 1049.8196, validation loss: 0.3633
2024-06-02 20:44:25 [INFO]: Epoch 022 - training loss: 1049.0262, validation loss: 0.3902
2024-06-02 20:44:27 [INFO]: Epoch 023 - training loss: 1049.1455, validation loss: 0.3739
2024-06-02 20:44:30 [INFO]: Epoch 024 - training loss: 1048.7044, validation loss: 0.3591
2024-06-02 20:44:32 [INFO]: Epoch 025 - training loss: 1048.2981, validation loss: 0.3857
2024-06-02 20:44:35 [INFO]: Epoch 026 - training loss: 1048.3809, validation loss: 0.4187
2024-06-02 20:44:38 [INFO]: Epoch 027 - training loss: 1048.4437, validation loss: 0.3489
2024-06-02 20:44:40 [INFO]: Epoch 028 - training loss: 1048.6613, validation loss: 0.5438
2024-06-02 20:44:43 [INFO]: Epoch 029 - training loss: 1049.4195, validation loss: 0.3888
2024-06-02 20:44:46 [INFO]: Epoch 030 - training loss: 1049.4883, validation loss: 0.3695
2024-06-02 20:44:48 [INFO]: Epoch 031 - training loss: 1048.3807, validation loss: 0.3296
2024-06-02 20:44:51 [INFO]: Epoch 032 - training loss: 1047.3067, validation loss: 0.3267
2024-06-02 20:44:54 [INFO]: Epoch 033 - training loss: 1047.3775, validation loss: 0.3439
2024-06-02 20:44:57 [INFO]: Epoch 034 - training loss: 1047.4415, validation loss: 0.3122
2024-06-02 20:44:59 [INFO]: Epoch 035 - training loss: 1047.2855, validation loss: 0.3355
2024-06-02 20:45:02 [INFO]: Epoch 036 - training loss: 1047.6206, validation loss: 0.2945
2024-06-02 20:45:04 [INFO]: Epoch 037 - training loss: 1048.4890, validation loss: 0.5144
2024-06-02 20:45:07 [INFO]: Epoch 038 - training loss: 1055.1283, validation loss: 0.4267
2024-06-02 20:45:10 [INFO]: Epoch 039 - training loss: 1049.1642, validation loss: 0.3669
2024-06-02 20:45:12 [INFO]: Epoch 040 - training loss: 1048.0197, validation loss: 0.3309
2024-06-02 20:45:14 [INFO]: Epoch 041 - training loss: 1047.1454, validation loss: 0.2988
2024-06-02 20:45:17 [INFO]: Epoch 042 - training loss: 1047.0384, validation loss: 0.3051
2024-06-02 20:45:20 [INFO]: Epoch 043 - training loss: 1046.8799, validation loss: 0.3002
2024-06-02 20:45:23 [INFO]: Epoch 044 - training loss: 1046.6525, validation loss: 0.3371
2024-06-02 20:45:25 [INFO]: Epoch 045 - training loss: 1046.9118, validation loss: 0.3454
2024-06-02 20:45:28 [INFO]: Epoch 046 - training loss: 1047.0966, validation loss: 0.2946
2024-06-02 20:45:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:45:28 [INFO]: Finished training. The best model is from epoch#36.
2024-06-02 20:45:28 [INFO]: Saved the model to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_0/20240602_T204322/GPVAE.pypots
2024-06-02 20:45:29 [INFO]: Successfully saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_0/imputation.pkl
2024-06-02 20:45:29 [INFO]: Round0 - GPVAE on ItalyAir: MAE=0.3846, MSE=0.3286, MRE=0.5191
2024-06-02 20:45:29 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:45:29 [INFO]: Using the given device: cuda:0
2024-06-02 20:45:29 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_1/20240602_T204529
2024-06-02 20:45:29 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_1/20240602_T204529/tensorboard
2024-06-02 20:45:29 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 130,594
2024-06-02 20:45:31 [INFO]: Epoch 001 - training loss: 1533.6499, validation loss: 1.4503
2024-06-02 20:45:34 [INFO]: Epoch 002 - training loss: 1079.8632, validation loss: 0.8428
2024-06-02 20:45:37 [INFO]: Epoch 003 - training loss: 1085.2306, validation loss: 0.7130
2024-06-02 20:45:39 [INFO]: Epoch 004 - training loss: 1064.8604, validation loss: 0.6321
2024-06-02 20:45:42 [INFO]: Epoch 005 - training loss: 1060.8272, validation loss: 0.4844
2024-06-02 20:45:44 [INFO]: Epoch 006 - training loss: 1056.3124, validation loss: 0.4819
2024-06-02 20:45:47 [INFO]: Epoch 007 - training loss: 1053.5585, validation loss: 0.5271
2024-06-02 20:45:49 [INFO]: Epoch 008 - training loss: 1052.3638, validation loss: 0.4219
2024-06-02 20:45:52 [INFO]: Epoch 009 - training loss: 1051.5446, validation loss: 0.3960
2024-06-02 20:45:54 [INFO]: Epoch 010 - training loss: 1050.8303, validation loss: 0.5333
2024-06-02 20:45:57 [INFO]: Epoch 011 - training loss: 1052.2850, validation loss: 0.4403
2024-06-02 20:45:59 [INFO]: Epoch 012 - training loss: 1051.4008, validation loss: 0.4483
2024-06-02 20:46:01 [INFO]: Epoch 013 - training loss: 1051.3122, validation loss: 0.4026
2024-06-02 20:46:04 [INFO]: Epoch 014 - training loss: 1050.9200, validation loss: 0.4049
2024-06-02 20:46:07 [INFO]: Epoch 015 - training loss: 1056.8124, validation loss: 0.6162
2024-06-02 20:46:09 [INFO]: Epoch 016 - training loss: 1052.1958, validation loss: 0.4133
2024-06-02 20:46:12 [INFO]: Epoch 017 - training loss: 1050.7172, validation loss: 0.3703
2024-06-02 20:46:15 [INFO]: Epoch 018 - training loss: 1050.3102, validation loss: 0.3805
2024-06-02 20:46:17 [INFO]: Epoch 019 - training loss: 1049.5095, validation loss: 0.4247
2024-06-02 20:46:20 [INFO]: Epoch 020 - training loss: 1049.5934, validation loss: 0.3804
2024-06-02 20:46:23 [INFO]: Epoch 021 - training loss: 1049.5901, validation loss: 0.3760
2024-06-02 20:46:25 [INFO]: Epoch 022 - training loss: 1049.4723, validation loss: 0.4204
2024-06-02 20:46:28 [INFO]: Epoch 023 - training loss: 1050.2435, validation loss: 0.3968
2024-06-02 20:46:30 [INFO]: Epoch 024 - training loss: 1049.5829, validation loss: 0.3727
2024-06-02 20:46:33 [INFO]: Epoch 025 - training loss: 1049.0951, validation loss: 0.4108
2024-06-02 20:46:35 [INFO]: Epoch 026 - training loss: 1048.9303, validation loss: 0.3476
2024-06-02 20:46:38 [INFO]: Epoch 027 - training loss: 1050.1664, validation loss: 0.4112
2024-06-02 20:46:40 [INFO]: Epoch 028 - training loss: 1051.1308, validation loss: 0.6623
2024-06-02 20:46:43 [INFO]: Epoch 029 - training loss: 1054.2753, validation loss: 0.5716
2024-06-02 20:46:45 [INFO]: Epoch 030 - training loss: 1052.1251, validation loss: 0.4530
2024-06-02 20:46:48 [INFO]: Epoch 031 - training loss: 1049.1639, validation loss: 0.3589
2024-06-02 20:46:50 [INFO]: Epoch 032 - training loss: 1048.4810, validation loss: 0.3895
2024-06-02 20:46:53 [INFO]: Epoch 033 - training loss: 1048.4203, validation loss: 0.3927
2024-06-02 20:46:55 [INFO]: Epoch 034 - training loss: 1049.7053, validation loss: 0.5732
2024-06-02 20:46:57 [INFO]: Epoch 035 - training loss: 1050.1465, validation loss: 0.3500
2024-06-02 20:47:00 [INFO]: Epoch 036 - training loss: 1048.3352, validation loss: 0.3382
2024-06-02 20:47:03 [INFO]: Epoch 037 - training loss: 1047.9061, validation loss: 0.3578
2024-06-02 20:47:05 [INFO]: Epoch 038 - training loss: 1047.5758, validation loss: 0.3314
2024-06-02 20:47:08 [INFO]: Epoch 039 - training loss: 1047.4537, validation loss: 0.2991
2024-06-02 20:47:11 [INFO]: Epoch 040 - training loss: 1047.5522, validation loss: 0.3847
2024-06-02 20:47:13 [INFO]: Epoch 041 - training loss: 1048.6533, validation loss: 0.3273
2024-06-02 20:47:16 [INFO]: Epoch 042 - training loss: 1048.0551, validation loss: 0.3310
2024-06-02 20:47:18 [INFO]: Epoch 043 - training loss: 1047.3628, validation loss: 0.3095
2024-06-02 20:47:20 [INFO]: Epoch 044 - training loss: 1047.0152, validation loss: 0.3038
2024-06-02 20:47:23 [INFO]: Epoch 045 - training loss: 1047.4284, validation loss: 0.3129
2024-06-02 20:47:26 [INFO]: Epoch 046 - training loss: 1046.9695, validation loss: 0.3100
2024-06-02 20:47:28 [INFO]: Epoch 047 - training loss: 1047.3766, validation loss: 0.2968
2024-06-02 20:47:31 [INFO]: Epoch 048 - training loss: 1047.7472, validation loss: 0.3676
2024-06-02 20:47:33 [INFO]: Epoch 049 - training loss: 1047.8309, validation loss: 0.3117
2024-06-02 20:47:36 [INFO]: Epoch 050 - training loss: 1046.9646, validation loss: 0.2945
2024-06-02 20:47:39 [INFO]: Epoch 051 - training loss: 1046.4032, validation loss: 0.2928
2024-06-02 20:47:41 [INFO]: Epoch 052 - training loss: 1046.8501, validation loss: 0.3078
2024-06-02 20:47:44 [INFO]: Epoch 053 - training loss: 1046.5494, validation loss: 0.3103
2024-06-02 20:47:47 [INFO]: Epoch 054 - training loss: 1046.7803, validation loss: 0.2951
2024-06-02 20:47:49 [INFO]: Epoch 055 - training loss: 1046.3429, validation loss: 0.2846
2024-06-02 20:47:52 [INFO]: Epoch 056 - training loss: 1046.3545, validation loss: 0.3123
2024-06-02 20:47:55 [INFO]: Epoch 057 - training loss: 1047.3701, validation loss: 0.3756
2024-06-02 20:47:57 [INFO]: Epoch 058 - training loss: 1049.1086, validation loss: 0.4136
2024-06-02 20:48:00 [INFO]: Epoch 059 - training loss: 1048.8702, validation loss: 0.3188
2024-06-02 20:48:02 [INFO]: Epoch 060 - training loss: 1047.6295, validation loss: 0.3027
2024-06-02 20:48:04 [INFO]: Epoch 061 - training loss: 1046.9801, validation loss: 0.2793
2024-06-02 20:48:07 [INFO]: Epoch 062 - training loss: 1046.5664, validation loss: 0.2921
2024-06-02 20:48:09 [INFO]: Epoch 063 - training loss: 1046.3933, validation loss: 0.2972
2024-06-02 20:48:12 [INFO]: Epoch 064 - training loss: 1046.6085, validation loss: 0.2574
2024-06-02 20:48:14 [INFO]: Epoch 065 - training loss: 1046.5913, validation loss: 0.3010
2024-06-02 20:48:16 [INFO]: Epoch 066 - training loss: 1046.8736, validation loss: 0.2765
2024-06-02 20:48:18 [INFO]: Epoch 067 - training loss: 1046.6755, validation loss: 0.2621
2024-06-02 20:48:20 [INFO]: Epoch 068 - training loss: 1046.6638, validation loss: 0.2999
2024-06-02 20:48:22 [INFO]: Epoch 069 - training loss: 1046.9073, validation loss: 0.2791
2024-06-02 20:48:25 [INFO]: Epoch 070 - training loss: 1046.5917, validation loss: 0.3253
2024-06-02 20:48:27 [INFO]: Epoch 071 - training loss: 1046.7852, validation loss: 0.3067
2024-06-02 20:48:30 [INFO]: Epoch 072 - training loss: 1046.7387, validation loss: 0.2847
2024-06-02 20:48:32 [INFO]: Epoch 073 - training loss: 1046.2455, validation loss: 0.2794
2024-06-02 20:48:34 [INFO]: Epoch 074 - training loss: 1045.7644, validation loss: 0.2661
2024-06-02 20:48:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:48:34 [INFO]: Finished training. The best model is from epoch#64.
2024-06-02 20:48:34 [INFO]: Saved the model to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_1/20240602_T204529/GPVAE.pypots
2024-06-02 20:48:35 [INFO]: Successfully saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_1/imputation.pkl
2024-06-02 20:48:35 [INFO]: Round1 - GPVAE on ItalyAir: MAE=0.3538, MSE=0.2917, MRE=0.4776
2024-06-02 20:48:35 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:48:35 [INFO]: Using the given device: cuda:0
2024-06-02 20:48:35 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_2/20240602_T204835
2024-06-02 20:48:35 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_2/20240602_T204835/tensorboard
2024-06-02 20:48:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 130,594
2024-06-02 20:48:37 [INFO]: Epoch 001 - training loss: 1523.0870, validation loss: 1.1628
2024-06-02 20:48:40 [INFO]: Epoch 002 - training loss: 1074.4544, validation loss: 0.5879
2024-06-02 20:48:42 [INFO]: Epoch 003 - training loss: 1061.9720, validation loss: 0.5169
2024-06-02 20:48:45 [INFO]: Epoch 004 - training loss: 1056.7104, validation loss: 0.4677
2024-06-02 20:48:47 [INFO]: Epoch 005 - training loss: 1054.1771, validation loss: 0.4622
2024-06-02 20:48:49 [INFO]: Epoch 006 - training loss: 1053.0561, validation loss: 0.4661
2024-06-02 20:48:51 [INFO]: Epoch 007 - training loss: 1059.2926, validation loss: 0.5466
2024-06-02 20:48:54 [INFO]: Epoch 008 - training loss: 1053.5702, validation loss: 0.4103
2024-06-02 20:48:56 [INFO]: Epoch 009 - training loss: 1052.0535, validation loss: 0.4118
2024-06-02 20:48:58 [INFO]: Epoch 010 - training loss: 1050.8900, validation loss: 0.3899
2024-06-02 20:49:01 [INFO]: Epoch 011 - training loss: 1050.3709, validation loss: 0.3972
2024-06-02 20:49:03 [INFO]: Epoch 012 - training loss: 1050.3573, validation loss: 0.4642
2024-06-02 20:49:05 [INFO]: Epoch 013 - training loss: 1050.1510, validation loss: 0.3891
2024-06-02 20:49:07 [INFO]: Epoch 014 - training loss: 1049.4440, validation loss: 0.3824
2024-06-02 20:49:10 [INFO]: Epoch 015 - training loss: 1049.8891, validation loss: 0.7255
2024-06-02 20:49:12 [INFO]: Epoch 016 - training loss: 1058.0218, validation loss: 0.8341
2024-06-02 20:49:15 [INFO]: Epoch 017 - training loss: 1063.2084, validation loss: 0.8002
2024-06-02 20:49:17 [INFO]: Epoch 018 - training loss: 1056.5576, validation loss: 0.5872
2024-06-02 20:49:19 [INFO]: Epoch 019 - training loss: 1051.9027, validation loss: 0.3531
2024-06-02 20:49:22 [INFO]: Epoch 020 - training loss: 1050.7708, validation loss: 0.3833
2024-06-02 20:49:24 [INFO]: Epoch 021 - training loss: 1050.5261, validation loss: 0.3997
2024-06-02 20:49:27 [INFO]: Epoch 022 - training loss: 1049.7425, validation loss: 0.3599
2024-06-02 20:49:29 [INFO]: Epoch 023 - training loss: 1049.0028, validation loss: 0.3477
2024-06-02 20:49:31 [INFO]: Epoch 024 - training loss: 1048.5840, validation loss: 0.3524
2024-06-02 20:49:34 [INFO]: Epoch 025 - training loss: 1048.3023, validation loss: 0.3930
2024-06-02 20:49:36 [INFO]: Epoch 026 - training loss: 1049.1764, validation loss: 0.4825
2024-06-02 20:49:38 [INFO]: Epoch 027 - training loss: 1048.5209, validation loss: 0.3194
2024-06-02 20:49:41 [INFO]: Epoch 028 - training loss: 1048.5795, validation loss: 0.3349
2024-06-02 20:49:44 [INFO]: Epoch 029 - training loss: 1048.8815, validation loss: 0.3463
2024-06-02 20:49:46 [INFO]: Epoch 030 - training loss: 1047.8973, validation loss: 0.3284
2024-06-02 20:49:47 [INFO]: Epoch 031 - training loss: 1047.8549, validation loss: 0.3287
2024-06-02 20:49:49 [INFO]: Epoch 032 - training loss: 1049.0182, validation loss: 0.3500
2024-06-02 20:49:51 [INFO]: Epoch 033 - training loss: 1047.8899, validation loss: 0.3258
2024-06-02 20:49:53 [INFO]: Epoch 034 - training loss: 1047.7075, validation loss: 0.3224
2024-06-02 20:49:56 [INFO]: Epoch 035 - training loss: 1047.0004, validation loss: 0.3542
2024-06-02 20:49:58 [INFO]: Epoch 036 - training loss: 1047.1526, validation loss: 0.3406
2024-06-02 20:50:00 [INFO]: Epoch 037 - training loss: 1047.3390, validation loss: 0.3156
2024-06-02 20:50:03 [INFO]: Epoch 038 - training loss: 1046.9548, validation loss: 0.3411
2024-06-02 20:50:05 [INFO]: Epoch 039 - training loss: 1046.7865, validation loss: 0.3226
2024-06-02 20:50:07 [INFO]: Epoch 040 - training loss: 1047.0370, validation loss: 0.3212
2024-06-02 20:50:09 [INFO]: Epoch 041 - training loss: 1047.5081, validation loss: 0.3073
2024-06-02 20:50:12 [INFO]: Epoch 042 - training loss: 1046.9683, validation loss: 0.3383
2024-06-02 20:50:14 [INFO]: Epoch 043 - training loss: 1046.8093, validation loss: 0.3342
2024-06-02 20:50:16 [INFO]: Epoch 044 - training loss: 1047.0504, validation loss: 0.3090
2024-06-02 20:50:19 [INFO]: Epoch 045 - training loss: 1047.3363, validation loss: 0.3207
2024-06-02 20:50:21 [INFO]: Epoch 046 - training loss: 1046.9197, validation loss: 0.2964
2024-06-02 20:50:24 [INFO]: Epoch 047 - training loss: 1046.7315, validation loss: 0.3014
2024-06-02 20:50:26 [INFO]: Epoch 048 - training loss: 1046.8201, validation loss: 0.3051
2024-06-02 20:50:28 [INFO]: Epoch 049 - training loss: 1046.6718, validation loss: 0.2894
2024-06-02 20:50:31 [INFO]: Epoch 050 - training loss: 1046.4777, validation loss: 0.3102
2024-06-02 20:50:33 [INFO]: Epoch 051 - training loss: 1046.5216, validation loss: 0.3191
2024-06-02 20:50:35 [INFO]: Epoch 052 - training loss: 1046.2240, validation loss: 0.3064
2024-06-02 20:50:38 [INFO]: Epoch 053 - training loss: 1047.3209, validation loss: 0.5519
2024-06-02 20:50:40 [INFO]: Epoch 054 - training loss: 1049.2103, validation loss: 0.3186
2024-06-02 20:50:42 [INFO]: Epoch 055 - training loss: 1048.1234, validation loss: 0.3425
2024-06-02 20:50:45 [INFO]: Epoch 056 - training loss: 1047.4216, validation loss: 0.3384
2024-06-02 20:50:47 [INFO]: Epoch 057 - training loss: 1046.3698, validation loss: 0.2801
2024-06-02 20:50:49 [INFO]: Epoch 058 - training loss: 1046.7277, validation loss: 0.3625
2024-06-02 20:50:51 [INFO]: Epoch 059 - training loss: 1047.4166, validation loss: 0.2861
2024-06-02 20:50:54 [INFO]: Epoch 060 - training loss: 1046.8371, validation loss: 0.2836
2024-06-02 20:50:56 [INFO]: Epoch 061 - training loss: 1046.6100, validation loss: 0.2859
2024-06-02 20:50:58 [INFO]: Epoch 062 - training loss: 1047.1353, validation loss: 0.3177
2024-06-02 20:51:01 [INFO]: Epoch 063 - training loss: 1046.3542, validation loss: 0.2972
2024-06-02 20:51:03 [INFO]: Epoch 064 - training loss: 1046.0127, validation loss: 0.2777
2024-06-02 20:51:05 [INFO]: Epoch 065 - training loss: 1046.1918, validation loss: 0.2699
2024-06-02 20:51:08 [INFO]: Epoch 066 - training loss: 1047.0047, validation loss: 0.2710
2024-06-02 20:51:10 [INFO]: Epoch 067 - training loss: 1046.1722, validation loss: 0.3024
2024-06-02 20:51:13 [INFO]: Epoch 068 - training loss: 1046.0880, validation loss: 0.2650
2024-06-02 20:51:15 [INFO]: Epoch 069 - training loss: 1046.2847, validation loss: 0.2984
2024-06-02 20:51:18 [INFO]: Epoch 070 - training loss: 1046.2345, validation loss: 0.2781
2024-06-02 20:51:20 [INFO]: Epoch 071 - training loss: 1046.6565, validation loss: 0.2834
2024-06-02 20:51:22 [INFO]: Epoch 072 - training loss: 1046.2291, validation loss: 0.2570
2024-06-02 20:51:25 [INFO]: Epoch 073 - training loss: 1048.2339, validation loss: 0.2911
2024-06-02 20:51:27 [INFO]: Epoch 074 - training loss: 1047.9283, validation loss: 0.2753
2024-06-02 20:51:29 [INFO]: Epoch 075 - training loss: 1046.1250, validation loss: 0.2557
2024-06-02 20:51:32 [INFO]: Epoch 076 - training loss: 1046.5771, validation loss: 0.2625
2024-06-02 20:51:34 [INFO]: Epoch 077 - training loss: 1046.2237, validation loss: 0.3308
2024-06-02 20:51:36 [INFO]: Epoch 078 - training loss: 1046.9359, validation loss: 0.2964
2024-06-02 20:51:38 [INFO]: Epoch 079 - training loss: 1047.8822, validation loss: 0.2872
2024-06-02 20:51:41 [INFO]: Epoch 080 - training loss: 1046.9970, validation loss: 0.2662
2024-06-02 20:51:43 [INFO]: Epoch 081 - training loss: 1047.3516, validation loss: 0.2916
2024-06-02 20:51:45 [INFO]: Epoch 082 - training loss: 1046.5396, validation loss: 0.2764
2024-06-02 20:51:47 [INFO]: Epoch 083 - training loss: 1046.6259, validation loss: 0.2769
2024-06-02 20:51:50 [INFO]: Epoch 084 - training loss: 1045.8598, validation loss: 0.2680
2024-06-02 20:51:53 [INFO]: Epoch 085 - training loss: 1045.8964, validation loss: 0.2678
2024-06-02 20:51:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:51:53 [INFO]: Finished training. The best model is from epoch#75.
2024-06-02 20:51:53 [INFO]: Saved the model to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_2/20240602_T204835/GPVAE.pypots
2024-06-02 20:51:53 [INFO]: Successfully saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_2/imputation.pkl
2024-06-02 20:51:53 [INFO]: Round2 - GPVAE on ItalyAir: MAE=0.3559, MSE=0.2994, MRE=0.4803
2024-06-02 20:51:53 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:51:53 [INFO]: Using the given device: cuda:0
2024-06-02 20:51:53 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_3/20240602_T205153
2024-06-02 20:51:53 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_3/20240602_T205153/tensorboard
2024-06-02 20:51:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 130,594
2024-06-02 20:51:56 [INFO]: Epoch 001 - training loss: 1548.0985, validation loss: 1.1619
2024-06-02 20:51:58 [INFO]: Epoch 002 - training loss: 1075.1370, validation loss: 0.6772
2024-06-02 20:52:00 [INFO]: Epoch 003 - training loss: 1063.1448, validation loss: 0.4651
2024-06-02 20:52:03 [INFO]: Epoch 004 - training loss: 1059.0819, validation loss: 0.5006
2024-06-02 20:52:05 [INFO]: Epoch 005 - training loss: 1053.8817, validation loss: 0.8476
2024-06-02 20:52:07 [INFO]: Epoch 006 - training loss: 1055.9216, validation loss: 0.4640
2024-06-02 20:52:09 [INFO]: Epoch 007 - training loss: 1052.6916, validation loss: 0.4830
2024-06-02 20:52:11 [INFO]: Epoch 008 - training loss: 1054.7527, validation loss: 0.4862
2024-06-02 20:52:14 [INFO]: Epoch 009 - training loss: 1052.0959, validation loss: 0.4403
2024-06-02 20:52:16 [INFO]: Epoch 010 - training loss: 1051.6447, validation loss: 0.4407
2024-06-02 20:52:18 [INFO]: Epoch 011 - training loss: 1051.6072, validation loss: 1.0930
2024-06-02 20:52:20 [INFO]: Epoch 012 - training loss: 1061.8764, validation loss: 0.4269
2024-06-02 20:52:23 [INFO]: Epoch 013 - training loss: 1054.5202, validation loss: 0.4762
2024-06-02 20:52:25 [INFO]: Epoch 014 - training loss: 1052.7599, validation loss: 0.5595
2024-06-02 20:52:27 [INFO]: Epoch 015 - training loss: 1053.5267, validation loss: 0.5097
2024-06-02 20:52:29 [INFO]: Epoch 016 - training loss: 1056.5913, validation loss: 0.4209
2024-06-02 20:52:31 [INFO]: Epoch 017 - training loss: 1052.9927, validation loss: 0.4131
2024-06-02 20:52:33 [INFO]: Epoch 018 - training loss: 1050.6199, validation loss: 0.4122
2024-06-02 20:52:35 [INFO]: Epoch 019 - training loss: 1049.5512, validation loss: 0.3709
2024-06-02 20:52:38 [INFO]: Epoch 020 - training loss: 1049.7574, validation loss: 0.3610
2024-06-02 20:52:40 [INFO]: Epoch 021 - training loss: 1049.2964, validation loss: 0.3580
2024-06-02 20:52:42 [INFO]: Epoch 022 - training loss: 1048.9942, validation loss: 0.3845
2024-06-02 20:52:45 [INFO]: Epoch 023 - training loss: 1048.7834, validation loss: 0.3239
2024-06-02 20:52:47 [INFO]: Epoch 024 - training loss: 1048.5766, validation loss: 0.3803
2024-06-02 20:52:50 [INFO]: Epoch 025 - training loss: 1048.5176, validation loss: 0.3308
2024-06-02 20:52:52 [INFO]: Epoch 026 - training loss: 1049.1444, validation loss: 0.2926
2024-06-02 20:52:54 [INFO]: Epoch 027 - training loss: 1050.2239, validation loss: 0.3260
2024-06-02 20:52:55 [INFO]: Epoch 028 - training loss: 1048.6532, validation loss: 0.3236
2024-06-02 20:52:57 [INFO]: Epoch 029 - training loss: 1048.2324, validation loss: 0.3637
2024-06-02 20:53:00 [INFO]: Epoch 030 - training loss: 1048.1877, validation loss: 0.3318
2024-06-02 20:53:01 [INFO]: Epoch 031 - training loss: 1048.4023, validation loss: 0.3337
2024-06-02 20:53:03 [INFO]: Epoch 032 - training loss: 1047.9318, validation loss: 0.3127
2024-06-02 20:53:06 [INFO]: Epoch 033 - training loss: 1047.8447, validation loss: 0.3032
2024-06-02 20:53:08 [INFO]: Epoch 034 - training loss: 1047.9451, validation loss: 0.3175
2024-06-02 20:53:10 [INFO]: Epoch 035 - training loss: 1047.9414, validation loss: 0.3003
2024-06-02 20:53:12 [INFO]: Epoch 036 - training loss: 1047.3119, validation loss: 0.3265
2024-06-02 20:53:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:53:12 [INFO]: Finished training. The best model is from epoch#26.
2024-06-02 20:53:12 [INFO]: Saved the model to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_3/20240602_T205153/GPVAE.pypots
2024-06-02 20:53:12 [INFO]: Successfully saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_3/imputation.pkl
2024-06-02 20:53:12 [INFO]: Round3 - GPVAE on ItalyAir: MAE=0.3746, MSE=0.3170, MRE=0.5057
2024-06-02 20:53:12 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:53:12 [INFO]: Using the given device: cuda:0
2024-06-02 20:53:12 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_4/20240602_T205312
2024-06-02 20:53:12 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_4/20240602_T205312/tensorboard
2024-06-02 20:53:12 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 130,594
2024-06-02 20:53:14 [INFO]: Epoch 001 - training loss: 1500.0834, validation loss: 0.8707
2024-06-02 20:53:16 [INFO]: Epoch 002 - training loss: 1071.7838, validation loss: 0.6401
2024-06-02 20:53:18 [INFO]: Epoch 003 - training loss: 1067.3388, validation loss: 0.9017
2024-06-02 20:53:20 [INFO]: Epoch 004 - training loss: 1060.2965, validation loss: 0.5768
2024-06-02 20:53:22 [INFO]: Epoch 005 - training loss: 1055.7998, validation loss: 0.4979
2024-06-02 20:53:24 [INFO]: Epoch 006 - training loss: 1056.6838, validation loss: 0.7437
2024-06-02 20:53:27 [INFO]: Epoch 007 - training loss: 1056.2023, validation loss: 0.6079
2024-06-02 20:53:29 [INFO]: Epoch 008 - training loss: 1054.0323, validation loss: 0.4731
2024-06-02 20:53:31 [INFO]: Epoch 009 - training loss: 1052.7108, validation loss: 0.4509
2024-06-02 20:53:33 [INFO]: Epoch 010 - training loss: 1052.3949, validation loss: 0.5396
2024-06-02 20:53:35 [INFO]: Epoch 011 - training loss: 1055.0076, validation loss: 0.8685
2024-06-02 20:53:37 [INFO]: Epoch 012 - training loss: 1055.3624, validation loss: 0.5701
2024-06-02 20:53:39 [INFO]: Epoch 013 - training loss: 1053.2760, validation loss: 0.4689
2024-06-02 20:53:41 [INFO]: Epoch 014 - training loss: 1052.2112, validation loss: 0.3908
2024-06-02 20:53:43 [INFO]: Epoch 015 - training loss: 1051.4671, validation loss: 0.4134
2024-06-02 20:53:45 [INFO]: Epoch 016 - training loss: 1051.0735, validation loss: 0.3959
2024-06-02 20:53:47 [INFO]: Epoch 017 - training loss: 1051.0309, validation loss: 0.3690
2024-06-02 20:53:49 [INFO]: Epoch 018 - training loss: 1050.2203, validation loss: 0.3937
2024-06-02 20:53:51 [INFO]: Epoch 019 - training loss: 1049.9998, validation loss: 0.4437
2024-06-02 20:53:53 [INFO]: Epoch 020 - training loss: 1052.2902, validation loss: 0.5057
2024-06-02 20:53:55 [INFO]: Epoch 021 - training loss: 1051.8337, validation loss: 0.3849
2024-06-02 20:53:57 [INFO]: Epoch 022 - training loss: 1050.1499, validation loss: 0.3714
2024-06-02 20:54:00 [INFO]: Epoch 023 - training loss: 1053.6396, validation loss: 0.5755
2024-06-02 20:54:02 [INFO]: Epoch 024 - training loss: 1052.5625, validation loss: 0.5352
2024-06-02 20:54:04 [INFO]: Epoch 025 - training loss: 1050.7302, validation loss: 0.4569
2024-06-02 20:54:06 [INFO]: Epoch 026 - training loss: 1049.2114, validation loss: 0.3965
2024-06-02 20:54:08 [INFO]: Epoch 027 - training loss: 1048.6228, validation loss: 0.3455
2024-06-02 20:54:10 [INFO]: Epoch 028 - training loss: 1048.0511, validation loss: 0.3549
2024-06-02 20:54:12 [INFO]: Epoch 029 - training loss: 1047.9751, validation loss: 0.3567
2024-06-02 20:54:14 [INFO]: Epoch 030 - training loss: 1047.6771, validation loss: 0.3749
2024-06-02 20:54:16 [INFO]: Epoch 031 - training loss: 1048.0288, validation loss: 0.3930
2024-06-02 20:54:18 [INFO]: Epoch 032 - training loss: 1049.1519, validation loss: 0.3810
2024-06-02 20:54:20 [INFO]: Epoch 033 - training loss: 1049.1763, validation loss: 0.4420
2024-06-02 20:54:22 [INFO]: Epoch 034 - training loss: 1048.1037, validation loss: 0.3096
2024-06-02 20:54:24 [INFO]: Epoch 035 - training loss: 1047.4021, validation loss: 0.3212
2024-06-02 20:54:26 [INFO]: Epoch 036 - training loss: 1047.2181, validation loss: 0.3305
2024-06-02 20:54:29 [INFO]: Epoch 037 - training loss: 1047.4363, validation loss: 0.3524
2024-06-02 20:54:31 [INFO]: Epoch 038 - training loss: 1047.1430, validation loss: 0.3451
2024-06-02 20:54:33 [INFO]: Epoch 039 - training loss: 1046.9981, validation loss: 0.3084
2024-06-02 20:54:35 [INFO]: Epoch 040 - training loss: 1046.6295, validation loss: 0.3101
2024-06-02 20:54:37 [INFO]: Epoch 041 - training loss: 1046.6959, validation loss: 0.3363
2024-06-02 20:54:39 [INFO]: Epoch 042 - training loss: 1046.5718, validation loss: 0.3077
2024-06-02 20:54:40 [INFO]: Epoch 043 - training loss: 1046.4617, validation loss: 0.3510
2024-06-02 20:54:42 [INFO]: Epoch 044 - training loss: 1047.6567, validation loss: 0.2883
2024-06-02 20:54:44 [INFO]: Epoch 045 - training loss: 1046.9726, validation loss: 0.2895
2024-06-02 20:54:46 [INFO]: Epoch 046 - training loss: 1047.3520, validation loss: 0.3470
2024-06-02 20:54:48 [INFO]: Epoch 047 - training loss: 1048.0562, validation loss: 0.3279
2024-06-02 20:54:50 [INFO]: Epoch 048 - training loss: 1048.1067, validation loss: 0.7855
2024-06-02 20:54:52 [INFO]: Epoch 049 - training loss: 1057.0120, validation loss: 0.6472
2024-06-02 20:54:54 [INFO]: Epoch 050 - training loss: 1055.2498, validation loss: 0.6032
2024-06-02 20:54:56 [INFO]: Epoch 051 - training loss: 1051.4138, validation loss: 0.4580
2024-06-02 20:54:59 [INFO]: Epoch 052 - training loss: 1050.0966, validation loss: 0.3462
2024-06-02 20:55:01 [INFO]: Epoch 053 - training loss: 1048.2823, validation loss: 0.3186
2024-06-02 20:55:03 [INFO]: Epoch 054 - training loss: 1046.9351, validation loss: 0.2996
2024-06-02 20:55:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:55:03 [INFO]: Finished training. The best model is from epoch#44.
2024-06-02 20:55:03 [INFO]: Saved the model to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_4/20240602_T205312/GPVAE.pypots
2024-06-02 20:55:03 [INFO]: Successfully saved to results_point_rate01/ItalyAir/GPVAE_ItalyAir/round_4/imputation.pkl
2024-06-02 20:55:03 [INFO]: Round4 - GPVAE on ItalyAir: MAE=0.3763, MSE=0.3340, MRE=0.5079
2024-06-02 20:55:03 [INFO]: Done! Final results:
Averaged GPVAE (130,594 params) on ItalyAir: MAE=0.3690 ± 0.012086377923514687, MSE=0.3141 ± 0.016308361903885776, MRE=0.4981 ± 0.016314532825170713, average inference time=0.39
