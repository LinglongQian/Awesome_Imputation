2024-06-02 20:43:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:43:24 [INFO]: Using the given device: cuda:0
2024-06-02 20:43:24 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_0/20240602_T204324
2024-06-02 20:43:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_0/20240602_T204324/tensorboard
2024-06-02 20:43:25 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,441,077
2024-06-02 20:43:33 [INFO]: Epoch 001 - training loss: 0.5167, validation loss: 0.3416
2024-06-02 20:43:35 [INFO]: Epoch 002 - training loss: 0.4302, validation loss: 0.3044
2024-06-02 20:43:38 [INFO]: Epoch 003 - training loss: 0.4209, validation loss: 0.3011
2024-06-02 20:43:41 [INFO]: Epoch 004 - training loss: 0.4064, validation loss: 0.2928
2024-06-02 20:43:44 [INFO]: Epoch 005 - training loss: 0.3990, validation loss: 0.2767
2024-06-02 20:43:47 [INFO]: Epoch 006 - training loss: 0.3976, validation loss: 0.2758
2024-06-02 20:43:49 [INFO]: Epoch 007 - training loss: 0.3864, validation loss: 0.2675
2024-06-02 20:43:53 [INFO]: Epoch 008 - training loss: 0.3783, validation loss: 0.2803
2024-06-02 20:43:55 [INFO]: Epoch 009 - training loss: 0.3847, validation loss: 0.2699
2024-06-02 20:43:58 [INFO]: Epoch 010 - training loss: 0.3817, validation loss: 0.2828
2024-06-02 20:44:00 [INFO]: Epoch 011 - training loss: 0.3863, validation loss: 0.2700
2024-06-02 20:44:03 [INFO]: Epoch 012 - training loss: 0.3845, validation loss: 0.2643
2024-06-02 20:44:05 [INFO]: Epoch 013 - training loss: 0.3686, validation loss: 0.2756
2024-06-02 20:44:08 [INFO]: Epoch 014 - training loss: 0.3814, validation loss: 0.2565
2024-06-02 20:44:11 [INFO]: Epoch 015 - training loss: 0.3828, validation loss: 0.2583
2024-06-02 20:44:13 [INFO]: Epoch 016 - training loss: 0.3724, validation loss: 0.2696
2024-06-02 20:44:16 [INFO]: Epoch 017 - training loss: 0.3721, validation loss: 0.2674
2024-06-02 20:44:19 [INFO]: Epoch 018 - training loss: 0.3726, validation loss: 0.2703
2024-06-02 20:44:21 [INFO]: Epoch 019 - training loss: 0.3726, validation loss: 0.2643
2024-06-02 20:44:24 [INFO]: Epoch 020 - training loss: 0.3689, validation loss: 0.2577
2024-06-02 20:44:26 [INFO]: Epoch 021 - training loss: 0.3682, validation loss: 0.2554
2024-06-02 20:44:29 [INFO]: Epoch 022 - training loss: 0.3626, validation loss: 0.2619
2024-06-02 20:44:31 [INFO]: Epoch 023 - training loss: 0.3666, validation loss: 0.2505
2024-06-02 20:44:34 [INFO]: Epoch 024 - training loss: 0.3658, validation loss: 0.2776
2024-06-02 20:44:37 [INFO]: Epoch 025 - training loss: 0.3615, validation loss: 0.2614
2024-06-02 20:44:39 [INFO]: Epoch 026 - training loss: 0.3647, validation loss: 0.2577
2024-06-02 20:44:42 [INFO]: Epoch 027 - training loss: 0.3650, validation loss: 0.2509
2024-06-02 20:44:44 [INFO]: Epoch 028 - training loss: 0.3588, validation loss: 0.2523
2024-06-02 20:44:47 [INFO]: Epoch 029 - training loss: 0.3724, validation loss: 0.2494
2024-06-02 20:44:50 [INFO]: Epoch 030 - training loss: 0.3656, validation loss: 0.2445
2024-06-02 20:44:52 [INFO]: Epoch 031 - training loss: 0.3608, validation loss: 0.2426
2024-06-02 20:44:55 [INFO]: Epoch 032 - training loss: 0.3627, validation loss: 0.2480
2024-06-02 20:44:57 [INFO]: Epoch 033 - training loss: 0.3585, validation loss: 0.2508
2024-06-02 20:45:00 [INFO]: Epoch 034 - training loss: 0.3553, validation loss: 0.2425
2024-06-02 20:45:02 [INFO]: Epoch 035 - training loss: 0.3518, validation loss: 0.2594
2024-06-02 20:45:05 [INFO]: Epoch 036 - training loss: 0.3534, validation loss: 0.2576
2024-06-02 20:45:08 [INFO]: Epoch 037 - training loss: 0.3601, validation loss: 0.2627
2024-06-02 20:45:11 [INFO]: Epoch 038 - training loss: 0.3547, validation loss: 0.2603
2024-06-02 20:45:13 [INFO]: Epoch 039 - training loss: 0.3535, validation loss: 0.2476
2024-06-02 20:45:16 [INFO]: Epoch 040 - training loss: 0.3589, validation loss: 0.2380
2024-06-02 20:45:18 [INFO]: Epoch 041 - training loss: 0.3501, validation loss: 0.2473
2024-06-02 20:45:21 [INFO]: Epoch 042 - training loss: 0.3462, validation loss: 0.2497
2024-06-02 20:45:24 [INFO]: Epoch 043 - training loss: 0.3595, validation loss: 0.2567
2024-06-02 20:45:26 [INFO]: Epoch 044 - training loss: 0.3513, validation loss: 0.2485
2024-06-02 20:45:29 [INFO]: Epoch 045 - training loss: 0.3515, validation loss: 0.2422
2024-06-02 20:45:31 [INFO]: Epoch 046 - training loss: 0.3578, validation loss: 0.2420
2024-06-02 20:45:34 [INFO]: Epoch 047 - training loss: 0.3574, validation loss: 0.2441
2024-06-02 20:45:37 [INFO]: Epoch 048 - training loss: 0.3480, validation loss: 0.2502
2024-06-02 20:45:39 [INFO]: Epoch 049 - training loss: 0.3509, validation loss: 0.2493
2024-06-02 20:45:42 [INFO]: Epoch 050 - training loss: 0.3426, validation loss: 0.2456
2024-06-02 20:45:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:45:42 [INFO]: Finished training. The best model is from epoch#40.
2024-06-02 20:45:42 [INFO]: Saved the model to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_0/20240602_T204324/NonstationaryTransformer.pypots
2024-06-02 20:45:42 [INFO]: Successfully saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_0/imputation.pkl
2024-06-02 20:45:42 [INFO]: Round0 - NonstationaryTransformer on ItalyAir: MAE=0.2569, MSE=0.2291, MRE=0.3468
2024-06-02 20:45:42 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:45:42 [INFO]: Using the given device: cuda:0
2024-06-02 20:45:42 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_1/20240602_T204542
2024-06-02 20:45:42 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_1/20240602_T204542/tensorboard
2024-06-02 20:45:42 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,441,077
2024-06-02 20:45:45 [INFO]: Epoch 001 - training loss: 0.4896, validation loss: 0.3208
2024-06-02 20:45:47 [INFO]: Epoch 002 - training loss: 0.4288, validation loss: 0.3008
2024-06-02 20:45:50 [INFO]: Epoch 003 - training loss: 0.4144, validation loss: 0.3091
2024-06-02 20:45:53 [INFO]: Epoch 004 - training loss: 0.4067, validation loss: 0.3104
2024-06-02 20:45:55 [INFO]: Epoch 005 - training loss: 0.4080, validation loss: 0.2936
2024-06-02 20:45:58 [INFO]: Epoch 006 - training loss: 0.3969, validation loss: 0.2941
2024-06-02 20:46:00 [INFO]: Epoch 007 - training loss: 0.3906, validation loss: 0.2862
2024-06-02 20:46:03 [INFO]: Epoch 008 - training loss: 0.3874, validation loss: 0.2945
2024-06-02 20:46:05 [INFO]: Epoch 009 - training loss: 0.3875, validation loss: 0.2776
2024-06-02 20:46:08 [INFO]: Epoch 010 - training loss: 0.3807, validation loss: 0.2927
2024-06-02 20:46:11 [INFO]: Epoch 011 - training loss: 0.3899, validation loss: 0.2776
2024-06-02 20:46:14 [INFO]: Epoch 012 - training loss: 0.3814, validation loss: 0.2613
2024-06-02 20:46:16 [INFO]: Epoch 013 - training loss: 0.3744, validation loss: 0.2788
2024-06-02 20:46:19 [INFO]: Epoch 014 - training loss: 0.3768, validation loss: 0.2683
2024-06-02 20:46:22 [INFO]: Epoch 015 - training loss: 0.3752, validation loss: 0.2828
2024-06-02 20:46:24 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2745
2024-06-02 20:46:27 [INFO]: Epoch 017 - training loss: 0.3717, validation loss: 0.2671
2024-06-02 20:46:30 [INFO]: Epoch 018 - training loss: 0.3653, validation loss: 0.2590
2024-06-02 20:46:32 [INFO]: Epoch 019 - training loss: 0.3736, validation loss: 0.2534
2024-06-02 20:46:35 [INFO]: Epoch 020 - training loss: 0.3691, validation loss: 0.2579
2024-06-02 20:46:38 [INFO]: Epoch 021 - training loss: 0.3653, validation loss: 0.2546
2024-06-02 20:46:40 [INFO]: Epoch 022 - training loss: 0.3643, validation loss: 0.2853
2024-06-02 20:46:43 [INFO]: Epoch 023 - training loss: 0.3640, validation loss: 0.2733
2024-06-02 20:46:45 [INFO]: Epoch 024 - training loss: 0.3589, validation loss: 0.2714
2024-06-02 20:46:48 [INFO]: Epoch 025 - training loss: 0.3673, validation loss: 0.2656
2024-06-02 20:46:51 [INFO]: Epoch 026 - training loss: 0.3596, validation loss: 0.2628
2024-06-02 20:46:54 [INFO]: Epoch 027 - training loss: 0.3586, validation loss: 0.2664
2024-06-02 20:46:56 [INFO]: Epoch 028 - training loss: 0.3619, validation loss: 0.2605
2024-06-02 20:46:59 [INFO]: Epoch 029 - training loss: 0.3587, validation loss: 0.2591
2024-06-02 20:46:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:46:59 [INFO]: Finished training. The best model is from epoch#19.
2024-06-02 20:46:59 [INFO]: Saved the model to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_1/20240602_T204542/NonstationaryTransformer.pypots
2024-06-02 20:46:59 [INFO]: Successfully saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_1/imputation.pkl
2024-06-02 20:46:59 [INFO]: Round1 - NonstationaryTransformer on ItalyAir: MAE=0.2791, MSE=0.2592, MRE=0.3767
2024-06-02 20:46:59 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:46:59 [INFO]: Using the given device: cuda:0
2024-06-02 20:46:59 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_2/20240602_T204659
2024-06-02 20:46:59 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_2/20240602_T204659/tensorboard
2024-06-02 20:46:59 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,441,077
2024-06-02 20:47:02 [INFO]: Epoch 001 - training loss: 0.4949, validation loss: 0.3556
2024-06-02 20:47:05 [INFO]: Epoch 002 - training loss: 0.4308, validation loss: 0.3363
2024-06-02 20:47:07 [INFO]: Epoch 003 - training loss: 0.4151, validation loss: 0.3231
2024-06-02 20:47:10 [INFO]: Epoch 004 - training loss: 0.4032, validation loss: 0.3207
2024-06-02 20:47:13 [INFO]: Epoch 005 - training loss: 0.3981, validation loss: 0.3470
2024-06-02 20:47:15 [INFO]: Epoch 006 - training loss: 0.3956, validation loss: 0.3044
2024-06-02 20:47:18 [INFO]: Epoch 007 - training loss: 0.3903, validation loss: 0.2978
2024-06-02 20:47:21 [INFO]: Epoch 008 - training loss: 0.3878, validation loss: 0.2924
2024-06-02 20:47:23 [INFO]: Epoch 009 - training loss: 0.3871, validation loss: 0.2941
2024-06-02 20:47:26 [INFO]: Epoch 010 - training loss: 0.3867, validation loss: 0.2762
2024-06-02 20:47:28 [INFO]: Epoch 011 - training loss: 0.3765, validation loss: 0.2959
2024-06-02 20:47:31 [INFO]: Epoch 012 - training loss: 0.3804, validation loss: 0.3013
2024-06-02 20:47:34 [INFO]: Epoch 013 - training loss: 0.3847, validation loss: 0.2836
2024-06-02 20:47:36 [INFO]: Epoch 014 - training loss: 0.3753, validation loss: 0.2933
2024-06-02 20:47:39 [INFO]: Epoch 015 - training loss: 0.3696, validation loss: 0.2799
2024-06-02 20:47:42 [INFO]: Epoch 016 - training loss: 0.3657, validation loss: 0.2799
2024-06-02 20:47:44 [INFO]: Epoch 017 - training loss: 0.3712, validation loss: 0.2908
2024-06-02 20:47:47 [INFO]: Epoch 018 - training loss: 0.3735, validation loss: 0.2731
2024-06-02 20:47:49 [INFO]: Epoch 019 - training loss: 0.3770, validation loss: 0.2794
2024-06-02 20:47:52 [INFO]: Epoch 020 - training loss: 0.3680, validation loss: 0.2771
2024-06-02 20:47:55 [INFO]: Epoch 021 - training loss: 0.3598, validation loss: 0.2690
2024-06-02 20:47:57 [INFO]: Epoch 022 - training loss: 0.3669, validation loss: 0.2820
2024-06-02 20:48:00 [INFO]: Epoch 023 - training loss: 0.3682, validation loss: 0.2787
2024-06-02 20:48:02 [INFO]: Epoch 024 - training loss: 0.3628, validation loss: 0.2788
2024-06-02 20:48:04 [INFO]: Epoch 025 - training loss: 0.3609, validation loss: 0.2756
2024-06-02 20:48:06 [INFO]: Epoch 026 - training loss: 0.3631, validation loss: 0.2689
2024-06-02 20:48:09 [INFO]: Epoch 027 - training loss: 0.3701, validation loss: 0.2661
2024-06-02 20:48:11 [INFO]: Epoch 028 - training loss: 0.3571, validation loss: 0.2920
2024-06-02 20:48:13 [INFO]: Epoch 029 - training loss: 0.3591, validation loss: 0.2908
2024-06-02 20:48:16 [INFO]: Epoch 030 - training loss: 0.3587, validation loss: 0.2800
2024-06-02 20:48:18 [INFO]: Epoch 031 - training loss: 0.3551, validation loss: 0.2740
2024-06-02 20:48:20 [INFO]: Epoch 032 - training loss: 0.3603, validation loss: 0.2529
2024-06-02 20:48:22 [INFO]: Epoch 033 - training loss: 0.3564, validation loss: 0.2651
2024-06-02 20:48:25 [INFO]: Epoch 034 - training loss: 0.3636, validation loss: 0.2571
2024-06-02 20:48:27 [INFO]: Epoch 035 - training loss: 0.3568, validation loss: 0.2614
2024-06-02 20:48:30 [INFO]: Epoch 036 - training loss: 0.3505, validation loss: 0.2626
2024-06-02 20:48:32 [INFO]: Epoch 037 - training loss: 0.3564, validation loss: 0.2572
2024-06-02 20:48:34 [INFO]: Epoch 038 - training loss: 0.3501, validation loss: 0.2608
2024-06-02 20:48:36 [INFO]: Epoch 039 - training loss: 0.3534, validation loss: 0.2858
2024-06-02 20:48:39 [INFO]: Epoch 040 - training loss: 0.3520, validation loss: 0.2526
2024-06-02 20:48:41 [INFO]: Epoch 041 - training loss: 0.3472, validation loss: 0.2757
2024-06-02 20:48:44 [INFO]: Epoch 042 - training loss: 0.3534, validation loss: 0.2570
2024-06-02 20:48:46 [INFO]: Epoch 043 - training loss: 0.3528, validation loss: 0.2634
2024-06-02 20:48:48 [INFO]: Epoch 044 - training loss: 0.3545, validation loss: 0.2574
2024-06-02 20:48:50 [INFO]: Epoch 045 - training loss: 0.3491, validation loss: 0.2624
2024-06-02 20:48:52 [INFO]: Epoch 046 - training loss: 0.3501, validation loss: 0.2524
2024-06-02 20:48:55 [INFO]: Epoch 047 - training loss: 0.3478, validation loss: 0.2753
2024-06-02 20:48:57 [INFO]: Epoch 048 - training loss: 0.3502, validation loss: 0.2546
2024-06-02 20:48:59 [INFO]: Epoch 049 - training loss: 0.3463, validation loss: 0.2498
2024-06-02 20:49:01 [INFO]: Epoch 050 - training loss: 0.3509, validation loss: 0.2478
2024-06-02 20:49:03 [INFO]: Epoch 051 - training loss: 0.3465, validation loss: 0.2544
2024-06-02 20:49:06 [INFO]: Epoch 052 - training loss: 0.3477, validation loss: 0.2499
2024-06-02 20:49:08 [INFO]: Epoch 053 - training loss: 0.3462, validation loss: 0.2734
2024-06-02 20:49:10 [INFO]: Epoch 054 - training loss: 0.3480, validation loss: 0.2610
2024-06-02 20:49:13 [INFO]: Epoch 055 - training loss: 0.3524, validation loss: 0.2665
2024-06-02 20:49:15 [INFO]: Epoch 056 - training loss: 0.3425, validation loss: 0.2706
2024-06-02 20:49:17 [INFO]: Epoch 057 - training loss: 0.3452, validation loss: 0.2718
2024-06-02 20:49:19 [INFO]: Epoch 058 - training loss: 0.3482, validation loss: 0.2683
2024-06-02 20:49:22 [INFO]: Epoch 059 - training loss: 0.3429, validation loss: 0.2556
2024-06-02 20:49:24 [INFO]: Epoch 060 - training loss: 0.3422, validation loss: 0.2554
2024-06-02 20:49:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:49:24 [INFO]: Finished training. The best model is from epoch#50.
2024-06-02 20:49:24 [INFO]: Saved the model to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_2/20240602_T204659/NonstationaryTransformer.pypots
2024-06-02 20:49:25 [INFO]: Successfully saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_2/imputation.pkl
2024-06-02 20:49:25 [INFO]: Round2 - NonstationaryTransformer on ItalyAir: MAE=0.2629, MSE=0.2367, MRE=0.3548
2024-06-02 20:49:25 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:49:25 [INFO]: Using the given device: cuda:0
2024-06-02 20:49:25 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_3/20240602_T204925
2024-06-02 20:49:25 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_3/20240602_T204925/tensorboard
2024-06-02 20:49:25 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,441,077
2024-06-02 20:49:27 [INFO]: Epoch 001 - training loss: 0.4912, validation loss: 0.3430
2024-06-02 20:49:30 [INFO]: Epoch 002 - training loss: 0.4322, validation loss: 0.3359
2024-06-02 20:49:32 [INFO]: Epoch 003 - training loss: 0.4144, validation loss: 0.3179
2024-06-02 20:49:34 [INFO]: Epoch 004 - training loss: 0.3986, validation loss: 0.2850
2024-06-02 20:49:37 [INFO]: Epoch 005 - training loss: 0.3965, validation loss: 0.3003
2024-06-02 20:49:39 [INFO]: Epoch 006 - training loss: 0.3955, validation loss: 0.2930
2024-06-02 20:49:41 [INFO]: Epoch 007 - training loss: 0.3915, validation loss: 0.2897
2024-06-02 20:49:44 [INFO]: Epoch 008 - training loss: 0.3876, validation loss: 0.2830
2024-06-02 20:49:46 [INFO]: Epoch 009 - training loss: 0.3894, validation loss: 0.2743
2024-06-02 20:49:48 [INFO]: Epoch 010 - training loss: 0.3801, validation loss: 0.2776
2024-06-02 20:49:50 [INFO]: Epoch 011 - training loss: 0.3825, validation loss: 0.2830
2024-06-02 20:49:52 [INFO]: Epoch 012 - training loss: 0.3781, validation loss: 0.2681
2024-06-02 20:49:55 [INFO]: Epoch 013 - training loss: 0.3711, validation loss: 0.2968
2024-06-02 20:49:57 [INFO]: Epoch 014 - training loss: 0.3755, validation loss: 0.2640
2024-06-02 20:49:59 [INFO]: Epoch 015 - training loss: 0.3744, validation loss: 0.2799
2024-06-02 20:50:01 [INFO]: Epoch 016 - training loss: 0.3733, validation loss: 0.2669
2024-06-02 20:50:04 [INFO]: Epoch 017 - training loss: 0.3742, validation loss: 0.2536
2024-06-02 20:50:06 [INFO]: Epoch 018 - training loss: 0.3671, validation loss: 0.2728
2024-06-02 20:50:08 [INFO]: Epoch 019 - training loss: 0.3698, validation loss: 0.2606
2024-06-02 20:50:11 [INFO]: Epoch 020 - training loss: 0.3737, validation loss: 0.2639
2024-06-02 20:50:13 [INFO]: Epoch 021 - training loss: 0.3655, validation loss: 0.2591
2024-06-02 20:50:15 [INFO]: Epoch 022 - training loss: 0.3662, validation loss: 0.2613
2024-06-02 20:50:18 [INFO]: Epoch 023 - training loss: 0.3670, validation loss: 0.2664
2024-06-02 20:50:20 [INFO]: Epoch 024 - training loss: 0.3752, validation loss: 0.2907
2024-06-02 20:50:22 [INFO]: Epoch 025 - training loss: 0.3755, validation loss: 0.3077
2024-06-02 20:50:25 [INFO]: Epoch 026 - training loss: 0.3693, validation loss: 0.2906
2024-06-02 20:50:27 [INFO]: Epoch 027 - training loss: 0.3647, validation loss: 0.2542
2024-06-02 20:50:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:50:27 [INFO]: Finished training. The best model is from epoch#17.
2024-06-02 20:50:27 [INFO]: Saved the model to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_3/20240602_T204925/NonstationaryTransformer.pypots
2024-06-02 20:50:28 [INFO]: Successfully saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_3/imputation.pkl
2024-06-02 20:50:28 [INFO]: Round3 - NonstationaryTransformer on ItalyAir: MAE=0.2666, MSE=0.2351, MRE=0.3599
2024-06-02 20:50:28 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:50:28 [INFO]: Using the given device: cuda:0
2024-06-02 20:50:28 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_4/20240602_T205028
2024-06-02 20:50:28 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_4/20240602_T205028/tensorboard
2024-06-02 20:50:28 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,441,077
2024-06-02 20:50:30 [INFO]: Epoch 001 - training loss: 0.5022, validation loss: 0.3732
2024-06-02 20:50:33 [INFO]: Epoch 002 - training loss: 0.4278, validation loss: 0.3485
2024-06-02 20:50:35 [INFO]: Epoch 003 - training loss: 0.4087, validation loss: 0.3599
2024-06-02 20:50:38 [INFO]: Epoch 004 - training loss: 0.4116, validation loss: 0.3401
2024-06-02 20:50:40 [INFO]: Epoch 005 - training loss: 0.3977, validation loss: 0.3379
2024-06-02 20:50:42 [INFO]: Epoch 006 - training loss: 0.3999, validation loss: 0.2979
2024-06-02 20:50:45 [INFO]: Epoch 007 - training loss: 0.3838, validation loss: 0.3004
2024-06-02 20:50:47 [INFO]: Epoch 008 - training loss: 0.3835, validation loss: 0.3018
2024-06-02 20:50:49 [INFO]: Epoch 009 - training loss: 0.3831, validation loss: 0.3085
2024-06-02 20:50:52 [INFO]: Epoch 010 - training loss: 0.3842, validation loss: 0.3068
2024-06-02 20:50:54 [INFO]: Epoch 011 - training loss: 0.3817, validation loss: 0.2978
2024-06-02 20:50:56 [INFO]: Epoch 012 - training loss: 0.3760, validation loss: 0.2929
2024-06-02 20:50:58 [INFO]: Epoch 013 - training loss: 0.3778, validation loss: 0.3106
2024-06-02 20:51:01 [INFO]: Epoch 014 - training loss: 0.3804, validation loss: 0.2909
2024-06-02 20:51:03 [INFO]: Epoch 015 - training loss: 0.3714, validation loss: 0.3118
2024-06-02 20:51:05 [INFO]: Epoch 016 - training loss: 0.3684, validation loss: 0.3341
2024-06-02 20:51:08 [INFO]: Epoch 017 - training loss: 0.3691, validation loss: 0.2714
2024-06-02 20:51:10 [INFO]: Epoch 018 - training loss: 0.3671, validation loss: 0.3132
2024-06-02 20:51:13 [INFO]: Epoch 019 - training loss: 0.3717, validation loss: 0.3051
2024-06-02 20:51:15 [INFO]: Epoch 020 - training loss: 0.3642, validation loss: 0.2956
2024-06-02 20:51:17 [INFO]: Epoch 021 - training loss: 0.3687, validation loss: 0.2838
2024-06-02 20:51:19 [INFO]: Epoch 022 - training loss: 0.3695, validation loss: 0.2852
2024-06-02 20:51:22 [INFO]: Epoch 023 - training loss: 0.3574, validation loss: 0.2811
2024-06-02 20:51:24 [INFO]: Epoch 024 - training loss: 0.3658, validation loss: 0.2850
2024-06-02 20:51:26 [INFO]: Epoch 025 - training loss: 0.3643, validation loss: 0.2927
2024-06-02 20:51:29 [INFO]: Epoch 026 - training loss: 0.3649, validation loss: 0.2893
2024-06-02 20:51:31 [INFO]: Epoch 027 - training loss: 0.3544, validation loss: 0.2678
2024-06-02 20:51:33 [INFO]: Epoch 028 - training loss: 0.3572, validation loss: 0.2788
2024-06-02 20:51:35 [INFO]: Epoch 029 - training loss: 0.3554, validation loss: 0.2679
2024-06-02 20:51:37 [INFO]: Epoch 030 - training loss: 0.3547, validation loss: 0.2733
2024-06-02 20:51:40 [INFO]: Epoch 031 - training loss: 0.3648, validation loss: 0.2653
2024-06-02 20:51:42 [INFO]: Epoch 032 - training loss: 0.3610, validation loss: 0.2719
2024-06-02 20:51:44 [INFO]: Epoch 033 - training loss: 0.3554, validation loss: 0.2752
2024-06-02 20:51:46 [INFO]: Epoch 034 - training loss: 0.3511, validation loss: 0.2568
2024-06-02 20:51:48 [INFO]: Epoch 035 - training loss: 0.3543, validation loss: 0.2888
2024-06-02 20:51:51 [INFO]: Epoch 036 - training loss: 0.3574, validation loss: 0.2753
2024-06-02 20:51:53 [INFO]: Epoch 037 - training loss: 0.3554, validation loss: 0.2767
2024-06-02 20:51:55 [INFO]: Epoch 038 - training loss: 0.3560, validation loss: 0.2719
2024-06-02 20:51:58 [INFO]: Epoch 039 - training loss: 0.3607, validation loss: 0.2718
2024-06-02 20:52:00 [INFO]: Epoch 040 - training loss: 0.3549, validation loss: 0.2613
2024-06-02 20:52:02 [INFO]: Epoch 041 - training loss: 0.3474, validation loss: 0.2481
2024-06-02 20:52:05 [INFO]: Epoch 042 - training loss: 0.3541, validation loss: 0.2560
2024-06-02 20:52:07 [INFO]: Epoch 043 - training loss: 0.3563, validation loss: 0.2617
2024-06-02 20:52:10 [INFO]: Epoch 044 - training loss: 0.3583, validation loss: 0.2530
2024-06-02 20:52:12 [INFO]: Epoch 045 - training loss: 0.3608, validation loss: 0.2523
2024-06-02 20:52:14 [INFO]: Epoch 046 - training loss: 0.3555, validation loss: 0.2556
2024-06-02 20:52:17 [INFO]: Epoch 047 - training loss: 0.3522, validation loss: 0.2750
2024-06-02 20:52:19 [INFO]: Epoch 048 - training loss: 0.3515, validation loss: 0.2666
2024-06-02 20:52:21 [INFO]: Epoch 049 - training loss: 0.3480, validation loss: 0.2474
2024-06-02 20:52:23 [INFO]: Epoch 050 - training loss: 0.3496, validation loss: 0.2515
2024-06-02 20:52:26 [INFO]: Epoch 051 - training loss: 0.3459, validation loss: 0.2587
2024-06-02 20:52:28 [INFO]: Epoch 052 - training loss: 0.3466, validation loss: 0.2418
2024-06-02 20:52:30 [INFO]: Epoch 053 - training loss: 0.3490, validation loss: 0.2518
2024-06-02 20:52:32 [INFO]: Epoch 054 - training loss: 0.3440, validation loss: 0.2750
2024-06-02 20:52:34 [INFO]: Epoch 055 - training loss: 0.3515, validation loss: 0.2730
2024-06-02 20:52:37 [INFO]: Epoch 056 - training loss: 0.3457, validation loss: 0.2575
2024-06-02 20:52:39 [INFO]: Epoch 057 - training loss: 0.3492, validation loss: 0.2547
2024-06-02 20:52:41 [INFO]: Epoch 058 - training loss: 0.3434, validation loss: 0.2481
2024-06-02 20:52:43 [INFO]: Epoch 059 - training loss: 0.3389, validation loss: 0.2512
2024-06-02 20:52:46 [INFO]: Epoch 060 - training loss: 0.3471, validation loss: 0.2641
2024-06-02 20:52:48 [INFO]: Epoch 061 - training loss: 0.3525, validation loss: 0.2579
2024-06-02 20:52:50 [INFO]: Epoch 062 - training loss: 0.3439, validation loss: 0.2603
2024-06-02 20:52:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:52:50 [INFO]: Finished training. The best model is from epoch#52.
2024-06-02 20:52:50 [INFO]: Saved the model to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_4/20240602_T205028/NonstationaryTransformer.pypots
2024-06-02 20:52:51 [INFO]: Successfully saved to results_point_rate01/ItalyAir/NonstationaryTransformer_ItalyAir/round_4/imputation.pkl
2024-06-02 20:52:51 [INFO]: Round4 - NonstationaryTransformer on ItalyAir: MAE=0.2636, MSE=0.2334, MRE=0.3559
2024-06-02 20:52:51 [INFO]: Done! Final results:
Averaged NonstationaryTransformer (8,441,077 params) on ItalyAir: MAE=0.2658 ± 0.007341339389495976, MSE=0.2387 ± 0.010552127930341555, MRE=0.3588 ± 0.009909546367703007, average inference time=0.21
