2024-06-02 20:21:50 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:21:51 [INFO]: Using the given device: cuda:0
2024-06-02 20:21:52 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_0/20240602_T202151
2024-06-02 20:21:52 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_0/20240602_T202151/tensorboard
2024-06-02 20:21:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-02 20:22:09 [INFO]: Epoch 001 - training loss: 1.1306, validation loss: 1.2759
2024-06-02 20:22:20 [INFO]: Epoch 002 - training loss: 0.8750, validation loss: 0.6867
2024-06-02 20:22:32 [INFO]: Epoch 003 - training loss: 0.7303, validation loss: 0.3961
2024-06-02 20:22:45 [INFO]: Epoch 004 - training loss: 0.6427, validation loss: 0.3288
2024-06-02 20:22:56 [INFO]: Epoch 005 - training loss: 0.5838, validation loss: 0.2961
2024-06-02 20:23:07 [INFO]: Epoch 006 - training loss: 0.5462, validation loss: 0.2836
2024-06-02 20:23:19 [INFO]: Epoch 007 - training loss: 0.5115, validation loss: 0.2560
2024-06-02 20:23:30 [INFO]: Epoch 008 - training loss: 0.4857, validation loss: 0.2612
2024-06-02 20:23:42 [INFO]: Epoch 009 - training loss: 0.4679, validation loss: 0.2405
2024-06-02 20:23:53 [INFO]: Epoch 010 - training loss: 0.4541, validation loss: 0.2436
2024-06-02 20:24:06 [INFO]: Epoch 011 - training loss: 0.4361, validation loss: 0.2252
2024-06-02 20:24:19 [INFO]: Epoch 012 - training loss: 0.4288, validation loss: 0.2328
2024-06-02 20:24:31 [INFO]: Epoch 013 - training loss: 0.4209, validation loss: 0.2238
2024-06-02 20:24:42 [INFO]: Epoch 014 - training loss: 0.4123, validation loss: 0.2252
2024-06-02 20:24:53 [INFO]: Epoch 015 - training loss: 0.4052, validation loss: 0.2222
2024-06-02 20:25:05 [INFO]: Epoch 016 - training loss: 0.3998, validation loss: 0.2162
2024-06-02 20:25:16 [INFO]: Epoch 017 - training loss: 0.3984, validation loss: 0.2254
2024-06-02 20:25:28 [INFO]: Epoch 018 - training loss: 0.3943, validation loss: 0.2188
2024-06-02 20:25:39 [INFO]: Epoch 019 - training loss: 0.3847, validation loss: 0.2122
2024-06-02 20:25:49 [INFO]: Epoch 020 - training loss: 0.3824, validation loss: 0.2127
2024-06-02 20:25:59 [INFO]: Epoch 021 - training loss: 0.3785, validation loss: 0.2114
2024-06-02 20:26:07 [INFO]: Epoch 022 - training loss: 0.3758, validation loss: 0.2060
2024-06-02 20:26:18 [INFO]: Epoch 023 - training loss: 0.3721, validation loss: 0.2098
2024-06-02 20:26:29 [INFO]: Epoch 024 - training loss: 0.3684, validation loss: 0.2116
2024-06-02 20:26:37 [INFO]: Epoch 025 - training loss: 0.3644, validation loss: 0.2095
2024-06-02 20:26:45 [INFO]: Epoch 026 - training loss: 0.3636, validation loss: 0.2045
2024-06-02 20:26:53 [INFO]: Epoch 027 - training loss: 0.3615, validation loss: 0.2018
2024-06-02 20:27:01 [INFO]: Epoch 028 - training loss: 0.3594, validation loss: 0.2026
2024-06-02 20:27:09 [INFO]: Epoch 029 - training loss: 0.3561, validation loss: 0.2004
2024-06-02 20:27:18 [INFO]: Epoch 030 - training loss: 0.3565, validation loss: 0.1945
2024-06-02 20:27:26 [INFO]: Epoch 031 - training loss: 0.3535, validation loss: 0.1917
2024-06-02 20:27:35 [INFO]: Epoch 032 - training loss: 0.3523, validation loss: 0.1960
2024-06-02 20:27:43 [INFO]: Epoch 033 - training loss: 0.3492, validation loss: 0.1897
2024-06-02 20:27:50 [INFO]: Epoch 034 - training loss: 0.3461, validation loss: 0.1948
2024-06-02 20:27:59 [INFO]: Epoch 035 - training loss: 0.3464, validation loss: 0.1937
2024-06-02 20:28:08 [INFO]: Epoch 036 - training loss: 0.3460, validation loss: 0.1910
2024-06-02 20:28:17 [INFO]: Epoch 037 - training loss: 0.3429, validation loss: 0.1895
2024-06-02 20:28:25 [INFO]: Epoch 038 - training loss: 0.3409, validation loss: 0.1812
2024-06-02 20:28:34 [INFO]: Epoch 039 - training loss: 0.3404, validation loss: 0.1859
2024-06-02 20:28:42 [INFO]: Epoch 040 - training loss: 0.3398, validation loss: 0.1897
2024-06-02 20:28:50 [INFO]: Epoch 041 - training loss: 0.3354, validation loss: 0.1840
2024-06-02 20:28:57 [INFO]: Epoch 042 - training loss: 0.3349, validation loss: 0.1883
2024-06-02 20:29:01 [INFO]: Epoch 043 - training loss: 0.3328, validation loss: 0.1790
2024-06-02 20:29:05 [INFO]: Epoch 044 - training loss: 0.3301, validation loss: 0.1761
2024-06-02 20:29:10 [INFO]: Epoch 045 - training loss: 0.3288, validation loss: 0.1859
2024-06-02 20:29:15 [INFO]: Epoch 046 - training loss: 0.3294, validation loss: 0.1822
2024-06-02 20:29:20 [INFO]: Epoch 047 - training loss: 0.3290, validation loss: 0.1760
2024-06-02 20:29:25 [INFO]: Epoch 048 - training loss: 0.3271, validation loss: 0.1828
2024-06-02 20:29:29 [INFO]: Epoch 049 - training loss: 0.3240, validation loss: 0.1742
2024-06-02 20:29:32 [INFO]: Epoch 050 - training loss: 0.3259, validation loss: 0.1770
2024-06-02 20:29:37 [INFO]: Epoch 051 - training loss: 0.3228, validation loss: 0.1728
2024-06-02 20:29:41 [INFO]: Epoch 052 - training loss: 0.3218, validation loss: 0.1728
2024-06-02 20:29:46 [INFO]: Epoch 053 - training loss: 0.3219, validation loss: 0.1726
2024-06-02 20:29:50 [INFO]: Epoch 054 - training loss: 0.3218, validation loss: 0.1707
2024-06-02 20:29:54 [INFO]: Epoch 055 - training loss: 0.3200, validation loss: 0.1737
2024-06-02 20:29:58 [INFO]: Epoch 056 - training loss: 0.3167, validation loss: 0.1687
2024-06-02 20:30:02 [INFO]: Epoch 057 - training loss: 0.3161, validation loss: 0.1653
2024-06-02 20:30:06 [INFO]: Epoch 058 - training loss: 0.3162, validation loss: 0.1685
2024-06-02 20:30:11 [INFO]: Epoch 059 - training loss: 0.3156, validation loss: 0.1731
2024-06-02 20:30:15 [INFO]: Epoch 060 - training loss: 0.3174, validation loss: 0.1680
2024-06-02 20:30:19 [INFO]: Epoch 061 - training loss: 0.3127, validation loss: 0.1692
2024-06-02 20:30:23 [INFO]: Epoch 062 - training loss: 0.3120, validation loss: 0.1677
2024-06-02 20:30:27 [INFO]: Epoch 063 - training loss: 0.3083, validation loss: 0.1662
2024-06-02 20:30:32 [INFO]: Epoch 064 - training loss: 0.3081, validation loss: 0.1642
2024-06-02 20:30:35 [INFO]: Epoch 065 - training loss: 0.3068, validation loss: 0.1725
2024-06-02 20:30:39 [INFO]: Epoch 066 - training loss: 0.3076, validation loss: 0.1598
2024-06-02 20:30:43 [INFO]: Epoch 067 - training loss: 0.3043, validation loss: 0.1630
2024-06-02 20:30:48 [INFO]: Epoch 068 - training loss: 0.3032, validation loss: 0.1588
2024-06-02 20:30:52 [INFO]: Epoch 069 - training loss: 0.3030, validation loss: 0.1672
2024-06-02 20:30:56 [INFO]: Epoch 070 - training loss: 0.3018, validation loss: 0.1617
2024-06-02 20:31:00 [INFO]: Epoch 071 - training loss: 0.2995, validation loss: 0.1610
2024-06-02 20:31:04 [INFO]: Epoch 072 - training loss: 0.2990, validation loss: 0.1611
2024-06-02 20:31:09 [INFO]: Epoch 073 - training loss: 0.2970, validation loss: 0.1619
2024-06-02 20:31:13 [INFO]: Epoch 074 - training loss: 0.2979, validation loss: 0.1614
2024-06-02 20:31:17 [INFO]: Epoch 075 - training loss: 0.2991, validation loss: 0.1637
2024-06-02 20:31:21 [INFO]: Epoch 076 - training loss: 0.2955, validation loss: 0.1614
2024-06-02 20:31:25 [INFO]: Epoch 077 - training loss: 0.2931, validation loss: 0.1596
2024-06-02 20:31:29 [INFO]: Epoch 078 - training loss: 0.2922, validation loss: 0.1599
2024-06-02 20:31:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:31:29 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 20:31:29 [INFO]: Saved the model to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_0/20240602_T202151/BRITS.pypots
2024-06-02 20:31:30 [INFO]: Successfully saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_0/imputation.pkl
2024-06-02 20:31:30 [INFO]: Round0 - BRITS on ItalyAir: MAE=0.2344, MSE=0.1462, MRE=0.3164
2024-06-02 20:31:30 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:31:30 [INFO]: Using the given device: cuda:0
2024-06-02 20:31:30 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_1/20240602_T203130
2024-06-02 20:31:30 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_1/20240602_T203130/tensorboard
2024-06-02 20:31:30 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-02 20:31:36 [INFO]: Epoch 001 - training loss: 1.1378, validation loss: 1.3016
2024-06-02 20:31:40 [INFO]: Epoch 002 - training loss: 0.8695, validation loss: 0.6753
2024-06-02 20:31:44 [INFO]: Epoch 003 - training loss: 0.7343, validation loss: 0.4169
2024-06-02 20:31:48 [INFO]: Epoch 004 - training loss: 0.6485, validation loss: 0.3244
2024-06-02 20:31:52 [INFO]: Epoch 005 - training loss: 0.5891, validation loss: 0.2899
2024-06-02 20:31:56 [INFO]: Epoch 006 - training loss: 0.5448, validation loss: 0.2756
2024-06-02 20:32:00 [INFO]: Epoch 007 - training loss: 0.5124, validation loss: 0.2550
2024-06-02 20:32:05 [INFO]: Epoch 008 - training loss: 0.4870, validation loss: 0.2578
2024-06-02 20:32:09 [INFO]: Epoch 009 - training loss: 0.4718, validation loss: 0.2365
2024-06-02 20:32:13 [INFO]: Epoch 010 - training loss: 0.4552, validation loss: 0.2361
2024-06-02 20:32:17 [INFO]: Epoch 011 - training loss: 0.4415, validation loss: 0.2252
2024-06-02 20:32:21 [INFO]: Epoch 012 - training loss: 0.4323, validation loss: 0.2227
2024-06-02 20:32:26 [INFO]: Epoch 013 - training loss: 0.4212, validation loss: 0.2220
2024-06-02 20:32:30 [INFO]: Epoch 014 - training loss: 0.4138, validation loss: 0.2250
2024-06-02 20:32:34 [INFO]: Epoch 015 - training loss: 0.4095, validation loss: 0.2262
2024-06-02 20:32:36 [INFO]: Epoch 016 - training loss: 0.4018, validation loss: 0.2301
2024-06-02 20:32:40 [INFO]: Epoch 017 - training loss: 0.3954, validation loss: 0.2195
2024-06-02 20:32:45 [INFO]: Epoch 018 - training loss: 0.3904, validation loss: 0.2143
2024-06-02 20:32:50 [INFO]: Epoch 019 - training loss: 0.3863, validation loss: 0.2166
2024-06-02 20:32:54 [INFO]: Epoch 020 - training loss: 0.3807, validation loss: 0.2164
2024-06-02 20:32:58 [INFO]: Epoch 021 - training loss: 0.3756, validation loss: 0.2174
2024-06-02 20:33:03 [INFO]: Epoch 022 - training loss: 0.3731, validation loss: 0.2153
2024-06-02 20:33:09 [INFO]: Epoch 023 - training loss: 0.3728, validation loss: 0.2116
2024-06-02 20:33:18 [INFO]: Epoch 024 - training loss: 0.3668, validation loss: 0.2104
2024-06-02 20:33:23 [INFO]: Epoch 025 - training loss: 0.3694, validation loss: 0.2066
2024-06-02 20:33:26 [INFO]: Epoch 026 - training loss: 0.3628, validation loss: 0.2056
2024-06-02 20:33:31 [INFO]: Epoch 027 - training loss: 0.3618, validation loss: 0.2087
2024-06-02 20:33:36 [INFO]: Epoch 028 - training loss: 0.3580, validation loss: 0.2107
2024-06-02 20:33:41 [INFO]: Epoch 029 - training loss: 0.3545, validation loss: 0.1983
2024-06-02 20:33:45 [INFO]: Epoch 030 - training loss: 0.3552, validation loss: 0.2005
2024-06-02 20:33:49 [INFO]: Epoch 031 - training loss: 0.3553, validation loss: 0.2002
2024-06-02 20:33:54 [INFO]: Epoch 032 - training loss: 0.3517, validation loss: 0.2042
2024-06-02 20:33:58 [INFO]: Epoch 033 - training loss: 0.3531, validation loss: 0.1961
2024-06-02 20:34:03 [INFO]: Epoch 034 - training loss: 0.3479, validation loss: 0.2022
2024-06-02 20:34:07 [INFO]: Epoch 035 - training loss: 0.3444, validation loss: 0.1890
2024-06-02 20:34:12 [INFO]: Epoch 036 - training loss: 0.3468, validation loss: 0.1967
2024-06-02 20:34:17 [INFO]: Epoch 037 - training loss: 0.3429, validation loss: 0.1931
2024-06-02 20:34:21 [INFO]: Epoch 038 - training loss: 0.3407, validation loss: 0.1868
2024-06-02 20:34:25 [INFO]: Epoch 039 - training loss: 0.3381, validation loss: 0.1907
2024-06-02 20:34:29 [INFO]: Epoch 040 - training loss: 0.3393, validation loss: 0.1851
2024-06-02 20:34:34 [INFO]: Epoch 041 - training loss: 0.3342, validation loss: 0.1838
2024-06-02 20:34:38 [INFO]: Epoch 042 - training loss: 0.3339, validation loss: 0.1811
2024-06-02 20:34:42 [INFO]: Epoch 043 - training loss: 0.3314, validation loss: 0.1820
2024-06-02 20:34:47 [INFO]: Epoch 044 - training loss: 0.3345, validation loss: 0.1823
2024-06-02 20:34:50 [INFO]: Epoch 045 - training loss: 0.3312, validation loss: 0.1884
2024-06-02 20:34:55 [INFO]: Epoch 046 - training loss: 0.3313, validation loss: 0.1822
2024-06-02 20:34:59 [INFO]: Epoch 047 - training loss: 0.3303, validation loss: 0.1816
2024-06-02 20:35:04 [INFO]: Epoch 048 - training loss: 0.3278, validation loss: 0.1791
2024-06-02 20:35:08 [INFO]: Epoch 049 - training loss: 0.3245, validation loss: 0.1774
2024-06-02 20:35:13 [INFO]: Epoch 050 - training loss: 0.3252, validation loss: 0.1763
2024-06-02 20:35:18 [INFO]: Epoch 051 - training loss: 0.3245, validation loss: 0.1800
2024-06-02 20:35:22 [INFO]: Epoch 052 - training loss: 0.3201, validation loss: 0.1756
2024-06-02 20:35:27 [INFO]: Epoch 053 - training loss: 0.3182, validation loss: 0.1728
2024-06-02 20:35:31 [INFO]: Epoch 054 - training loss: 0.3177, validation loss: 0.1768
2024-06-02 20:35:36 [INFO]: Epoch 055 - training loss: 0.3161, validation loss: 0.1771
2024-06-02 20:35:41 [INFO]: Epoch 056 - training loss: 0.3150, validation loss: 0.1696
2024-06-02 20:35:45 [INFO]: Epoch 057 - training loss: 0.3155, validation loss: 0.1680
2024-06-02 20:35:49 [INFO]: Epoch 058 - training loss: 0.3140, validation loss: 0.1744
2024-06-02 20:35:53 [INFO]: Epoch 059 - training loss: 0.3128, validation loss: 0.1733
2024-06-02 20:35:59 [INFO]: Epoch 060 - training loss: 0.3121, validation loss: 0.1657
2024-06-02 20:36:06 [INFO]: Epoch 061 - training loss: 0.3127, validation loss: 0.1784
2024-06-02 20:36:11 [INFO]: Epoch 062 - training loss: 0.3085, validation loss: 0.1685
2024-06-02 20:36:15 [INFO]: Epoch 063 - training loss: 0.3070, validation loss: 0.1689
2024-06-02 20:36:19 [INFO]: Epoch 064 - training loss: 0.3060, validation loss: 0.1638
2024-06-02 20:36:24 [INFO]: Epoch 065 - training loss: 0.3069, validation loss: 0.1635
2024-06-02 20:36:29 [INFO]: Epoch 066 - training loss: 0.3082, validation loss: 0.1673
2024-06-02 20:36:32 [INFO]: Epoch 067 - training loss: 0.3068, validation loss: 0.1664
2024-06-02 20:36:37 [INFO]: Epoch 068 - training loss: 0.3070, validation loss: 0.1761
2024-06-02 20:36:41 [INFO]: Epoch 069 - training loss: 0.3052, validation loss: 0.1664
2024-06-02 20:36:45 [INFO]: Epoch 070 - training loss: 0.3019, validation loss: 0.1656
2024-06-02 20:36:49 [INFO]: Epoch 071 - training loss: 0.2992, validation loss: 0.1634
2024-06-02 20:36:54 [INFO]: Epoch 072 - training loss: 0.3010, validation loss: 0.1591
2024-06-02 20:36:57 [INFO]: Epoch 073 - training loss: 0.3003, validation loss: 0.1613
2024-06-02 20:37:02 [INFO]: Epoch 074 - training loss: 0.2984, validation loss: 0.1572
2024-06-02 20:37:07 [INFO]: Epoch 075 - training loss: 0.2966, validation loss: 0.1640
2024-06-02 20:37:11 [INFO]: Epoch 076 - training loss: 0.2958, validation loss: 0.1658
2024-06-02 20:37:15 [INFO]: Epoch 077 - training loss: 0.2940, validation loss: 0.1645
2024-06-02 20:37:19 [INFO]: Epoch 078 - training loss: 0.2969, validation loss: 0.1628
2024-06-02 20:37:23 [INFO]: Epoch 079 - training loss: 0.2930, validation loss: 0.1621
2024-06-02 20:37:28 [INFO]: Epoch 080 - training loss: 0.2917, validation loss: 0.1651
2024-06-02 20:37:33 [INFO]: Epoch 081 - training loss: 0.2913, validation loss: 0.1604
2024-06-02 20:37:39 [INFO]: Epoch 082 - training loss: 0.2908, validation loss: 0.1737
2024-06-02 20:37:48 [INFO]: Epoch 083 - training loss: 0.2948, validation loss: 0.1561
2024-06-02 20:37:52 [INFO]: Epoch 084 - training loss: 0.2925, validation loss: 0.1687
2024-06-02 20:37:56 [INFO]: Epoch 085 - training loss: 0.2892, validation loss: 0.1625
2024-06-02 20:38:01 [INFO]: Epoch 086 - training loss: 0.2881, validation loss: 0.1613
2024-06-02 20:38:06 [INFO]: Epoch 087 - training loss: 0.2888, validation loss: 0.1589
2024-06-02 20:38:11 [INFO]: Epoch 088 - training loss: 0.2892, validation loss: 0.1612
2024-06-02 20:38:16 [INFO]: Epoch 089 - training loss: 0.2858, validation loss: 0.1706
2024-06-02 20:38:20 [INFO]: Epoch 090 - training loss: 0.2867, validation loss: 0.1627
2024-06-02 20:38:24 [INFO]: Epoch 091 - training loss: 0.2845, validation loss: 0.1650
2024-06-02 20:38:29 [INFO]: Epoch 092 - training loss: 0.2814, validation loss: 0.1621
2024-06-02 20:38:33 [INFO]: Epoch 093 - training loss: 0.2823, validation loss: 0.1721
2024-06-02 20:38:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:38:33 [INFO]: Finished training. The best model is from epoch#83.
2024-06-02 20:38:33 [INFO]: Saved the model to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_1/20240602_T203130/BRITS.pypots
2024-06-02 20:38:34 [INFO]: Successfully saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_1/imputation.pkl
2024-06-02 20:38:34 [INFO]: Round1 - BRITS on ItalyAir: MAE=0.2485, MSE=0.1590, MRE=0.3354
2024-06-02 20:38:34 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:38:34 [INFO]: Using the given device: cuda:0
2024-06-02 20:38:34 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_2/20240602_T203834
2024-06-02 20:38:34 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_2/20240602_T203834/tensorboard
2024-06-02 20:38:34 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-02 20:38:38 [INFO]: Epoch 001 - training loss: 1.1355, validation loss: 1.1564
2024-06-02 20:38:43 [INFO]: Epoch 002 - training loss: 0.8732, validation loss: 0.6695
2024-06-02 20:38:48 [INFO]: Epoch 003 - training loss: 0.7345, validation loss: 0.4149
2024-06-02 20:38:52 [INFO]: Epoch 004 - training loss: 0.6553, validation loss: 0.3317
2024-06-02 20:38:56 [INFO]: Epoch 005 - training loss: 0.5977, validation loss: 0.2681
2024-06-02 20:39:00 [INFO]: Epoch 006 - training loss: 0.5518, validation loss: 0.2644
2024-06-02 20:39:05 [INFO]: Epoch 007 - training loss: 0.5212, validation loss: 0.2734
2024-06-02 20:39:10 [INFO]: Epoch 008 - training loss: 0.4934, validation loss: 0.2580
2024-06-02 20:39:14 [INFO]: Epoch 009 - training loss: 0.4766, validation loss: 0.2457
2024-06-02 20:39:19 [INFO]: Epoch 010 - training loss: 0.4556, validation loss: 0.2502
2024-06-02 20:39:24 [INFO]: Epoch 011 - training loss: 0.4413, validation loss: 0.2393
2024-06-02 20:39:28 [INFO]: Epoch 012 - training loss: 0.4303, validation loss: 0.2291
2024-06-02 20:39:33 [INFO]: Epoch 013 - training loss: 0.4261, validation loss: 0.2342
2024-06-02 20:39:37 [INFO]: Epoch 014 - training loss: 0.4169, validation loss: 0.2287
2024-06-02 20:39:41 [INFO]: Epoch 015 - training loss: 0.4090, validation loss: 0.2091
2024-06-02 20:39:46 [INFO]: Epoch 016 - training loss: 0.4045, validation loss: 0.2195
2024-06-02 20:39:50 [INFO]: Epoch 017 - training loss: 0.3974, validation loss: 0.2159
2024-06-02 20:39:54 [INFO]: Epoch 018 - training loss: 0.3961, validation loss: 0.2238
2024-06-02 20:39:59 [INFO]: Epoch 019 - training loss: 0.3907, validation loss: 0.2120
2024-06-02 20:40:03 [INFO]: Epoch 020 - training loss: 0.3843, validation loss: 0.2123
2024-06-02 20:40:07 [INFO]: Epoch 021 - training loss: 0.3806, validation loss: 0.2093
2024-06-02 20:40:12 [INFO]: Epoch 022 - training loss: 0.3757, validation loss: 0.2179
2024-06-02 20:40:17 [INFO]: Epoch 023 - training loss: 0.3741, validation loss: 0.2171
2024-06-02 20:40:27 [INFO]: Epoch 024 - training loss: 0.3754, validation loss: 0.2083
2024-06-02 20:40:29 [INFO]: Epoch 025 - training loss: 0.3685, validation loss: 0.2120
2024-06-02 20:40:29 [INFO]: Epoch 026 - training loss: 0.3648, validation loss: 0.2115
2024-06-02 20:40:30 [INFO]: Epoch 027 - training loss: 0.3621, validation loss: 0.2046
2024-06-02 20:40:31 [INFO]: Epoch 028 - training loss: 0.3592, validation loss: 0.2114
2024-06-02 20:40:31 [INFO]: Epoch 029 - training loss: 0.3593, validation loss: 0.2036
2024-06-02 20:40:32 [INFO]: Epoch 030 - training loss: 0.3565, validation loss: 0.2041
2024-06-02 20:40:33 [INFO]: Epoch 031 - training loss: 0.3550, validation loss: 0.1992
2024-06-02 20:40:33 [INFO]: Epoch 032 - training loss: 0.3506, validation loss: 0.2015
2024-06-02 20:40:34 [INFO]: Epoch 033 - training loss: 0.3512, validation loss: 0.2050
2024-06-02 20:40:35 [INFO]: Epoch 034 - training loss: 0.3537, validation loss: 0.1988
2024-06-02 20:40:35 [INFO]: Epoch 035 - training loss: 0.3518, validation loss: 0.2031
2024-06-02 20:40:36 [INFO]: Epoch 036 - training loss: 0.3466, validation loss: 0.1940
2024-06-02 20:40:36 [INFO]: Epoch 037 - training loss: 0.3446, validation loss: 0.1970
2024-06-02 20:40:37 [INFO]: Epoch 038 - training loss: 0.3432, validation loss: 0.1913
2024-06-02 20:40:38 [INFO]: Epoch 039 - training loss: 0.3412, validation loss: 0.1946
2024-06-02 20:40:39 [INFO]: Epoch 040 - training loss: 0.3395, validation loss: 0.1932
2024-06-02 20:40:39 [INFO]: Epoch 041 - training loss: 0.3377, validation loss: 0.1878
2024-06-02 20:40:40 [INFO]: Epoch 042 - training loss: 0.3369, validation loss: 0.1802
2024-06-02 20:40:40 [INFO]: Epoch 043 - training loss: 0.3350, validation loss: 0.1851
2024-06-02 20:40:41 [INFO]: Epoch 044 - training loss: 0.3332, validation loss: 0.1812
2024-06-02 20:40:42 [INFO]: Epoch 045 - training loss: 0.3318, validation loss: 0.1824
2024-06-02 20:40:42 [INFO]: Epoch 046 - training loss: 0.3311, validation loss: 0.1794
2024-06-02 20:40:43 [INFO]: Epoch 047 - training loss: 0.3294, validation loss: 0.1810
2024-06-02 20:40:44 [INFO]: Epoch 048 - training loss: 0.3275, validation loss: 0.1847
2024-06-02 20:40:44 [INFO]: Epoch 049 - training loss: 0.3250, validation loss: 0.1807
2024-06-02 20:40:45 [INFO]: Epoch 050 - training loss: 0.3257, validation loss: 0.1769
2024-06-02 20:40:45 [INFO]: Epoch 051 - training loss: 0.3261, validation loss: 0.1776
2024-06-02 20:40:46 [INFO]: Epoch 052 - training loss: 0.3220, validation loss: 0.1742
2024-06-02 20:40:47 [INFO]: Epoch 053 - training loss: 0.3216, validation loss: 0.1743
2024-06-02 20:40:47 [INFO]: Epoch 054 - training loss: 0.3183, validation loss: 0.1713
2024-06-02 20:40:48 [INFO]: Epoch 055 - training loss: 0.3189, validation loss: 0.1691
2024-06-02 20:40:49 [INFO]: Epoch 056 - training loss: 0.3176, validation loss: 0.1712
2024-06-02 20:40:49 [INFO]: Epoch 057 - training loss: 0.3172, validation loss: 0.1691
2024-06-02 20:40:50 [INFO]: Epoch 058 - training loss: 0.3152, validation loss: 0.1705
2024-06-02 20:40:50 [INFO]: Epoch 059 - training loss: 0.3139, validation loss: 0.1674
2024-06-02 20:40:51 [INFO]: Epoch 060 - training loss: 0.3128, validation loss: 0.1689
2024-06-02 20:40:52 [INFO]: Epoch 061 - training loss: 0.3115, validation loss: 0.1650
2024-06-02 20:40:53 [INFO]: Epoch 062 - training loss: 0.3092, validation loss: 0.1596
2024-06-02 20:40:53 [INFO]: Epoch 063 - training loss: 0.3066, validation loss: 0.1620
2024-06-02 20:40:54 [INFO]: Epoch 064 - training loss: 0.3079, validation loss: 0.1620
2024-06-02 20:40:54 [INFO]: Epoch 065 - training loss: 0.3066, validation loss: 0.1685
2024-06-02 20:40:55 [INFO]: Epoch 066 - training loss: 0.3034, validation loss: 0.1623
2024-06-02 20:40:56 [INFO]: Epoch 067 - training loss: 0.3049, validation loss: 0.1649
2024-06-02 20:40:56 [INFO]: Epoch 068 - training loss: 0.3022, validation loss: 0.1657
2024-06-02 20:40:57 [INFO]: Epoch 069 - training loss: 0.3011, validation loss: 0.1595
2024-06-02 20:40:58 [INFO]: Epoch 070 - training loss: 0.3013, validation loss: 0.1647
2024-06-02 20:40:58 [INFO]: Epoch 071 - training loss: 0.2992, validation loss: 0.1601
2024-06-02 20:40:59 [INFO]: Epoch 072 - training loss: 0.2979, validation loss: 0.1531
2024-06-02 20:41:00 [INFO]: Epoch 073 - training loss: 0.2973, validation loss: 0.1596
2024-06-02 20:41:00 [INFO]: Epoch 074 - training loss: 0.2969, validation loss: 0.1582
2024-06-02 20:41:01 [INFO]: Epoch 075 - training loss: 0.2982, validation loss: 0.1587
2024-06-02 20:41:01 [INFO]: Epoch 076 - training loss: 0.2964, validation loss: 0.1609
2024-06-02 20:41:02 [INFO]: Epoch 077 - training loss: 0.2949, validation loss: 0.1556
2024-06-02 20:41:03 [INFO]: Epoch 078 - training loss: 0.2942, validation loss: 0.1554
2024-06-02 20:41:03 [INFO]: Epoch 079 - training loss: 0.2944, validation loss: 0.1539
2024-06-02 20:41:04 [INFO]: Epoch 080 - training loss: 0.2925, validation loss: 0.1583
2024-06-02 20:41:05 [INFO]: Epoch 081 - training loss: 0.2928, validation loss: 0.1618
2024-06-02 20:41:05 [INFO]: Epoch 082 - training loss: 0.2905, validation loss: 0.1548
2024-06-02 20:41:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:41:06 [INFO]: Finished training. The best model is from epoch#72.
2024-06-02 20:41:06 [INFO]: Saved the model to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_2/20240602_T203834/BRITS.pypots
2024-06-02 20:41:06 [INFO]: Successfully saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_2/imputation.pkl
2024-06-02 20:41:06 [INFO]: Round2 - BRITS on ItalyAir: MAE=0.2331, MSE=0.1429, MRE=0.3147
2024-06-02 20:41:06 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:41:06 [INFO]: Using the given device: cuda:0
2024-06-02 20:41:06 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_3/20240602_T204106
2024-06-02 20:41:06 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_3/20240602_T204106/tensorboard
2024-06-02 20:41:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-02 20:41:07 [INFO]: Epoch 001 - training loss: 1.1200, validation loss: 1.1565
2024-06-02 20:41:08 [INFO]: Epoch 002 - training loss: 0.8630, validation loss: 0.6636
2024-06-02 20:41:09 [INFO]: Epoch 003 - training loss: 0.7190, validation loss: 0.4033
2024-06-02 20:41:09 [INFO]: Epoch 004 - training loss: 0.6284, validation loss: 0.3331
2024-06-02 20:41:10 [INFO]: Epoch 005 - training loss: 0.5791, validation loss: 0.2846
2024-06-02 20:41:11 [INFO]: Epoch 006 - training loss: 0.5380, validation loss: 0.2632
2024-06-02 20:41:11 [INFO]: Epoch 007 - training loss: 0.5083, validation loss: 0.2473
2024-06-02 20:41:12 [INFO]: Epoch 008 - training loss: 0.4874, validation loss: 0.2526
2024-06-02 20:41:13 [INFO]: Epoch 009 - training loss: 0.4632, validation loss: 0.2393
2024-06-02 20:41:13 [INFO]: Epoch 010 - training loss: 0.4496, validation loss: 0.2304
2024-06-02 20:41:14 [INFO]: Epoch 011 - training loss: 0.4363, validation loss: 0.2223
2024-06-02 20:41:15 [INFO]: Epoch 012 - training loss: 0.4252, validation loss: 0.2195
2024-06-02 20:41:15 [INFO]: Epoch 013 - training loss: 0.4173, validation loss: 0.2183
2024-06-02 20:41:16 [INFO]: Epoch 014 - training loss: 0.4097, validation loss: 0.2156
2024-06-02 20:41:17 [INFO]: Epoch 015 - training loss: 0.4046, validation loss: 0.2125
2024-06-02 20:41:17 [INFO]: Epoch 016 - training loss: 0.3972, validation loss: 0.2077
2024-06-02 20:41:18 [INFO]: Epoch 017 - training loss: 0.3951, validation loss: 0.2052
2024-06-02 20:41:19 [INFO]: Epoch 018 - training loss: 0.3907, validation loss: 0.2026
2024-06-02 20:41:19 [INFO]: Epoch 019 - training loss: 0.3864, validation loss: 0.2038
2024-06-02 20:41:20 [INFO]: Epoch 020 - training loss: 0.3846, validation loss: 0.2016
2024-06-02 20:41:20 [INFO]: Epoch 021 - training loss: 0.3811, validation loss: 0.1976
2024-06-02 20:41:21 [INFO]: Epoch 022 - training loss: 0.3757, validation loss: 0.2076
2024-06-02 20:41:22 [INFO]: Epoch 023 - training loss: 0.3719, validation loss: 0.2001
2024-06-02 20:41:22 [INFO]: Epoch 024 - training loss: 0.3722, validation loss: 0.1942
2024-06-02 20:41:23 [INFO]: Epoch 025 - training loss: 0.3706, validation loss: 0.2024
2024-06-02 20:41:23 [INFO]: Epoch 026 - training loss: 0.3647, validation loss: 0.2011
2024-06-02 20:41:24 [INFO]: Epoch 027 - training loss: 0.3622, validation loss: 0.2020
2024-06-02 20:41:25 [INFO]: Epoch 028 - training loss: 0.3607, validation loss: 0.1968
2024-06-02 20:41:25 [INFO]: Epoch 029 - training loss: 0.3590, validation loss: 0.2003
2024-06-02 20:41:26 [INFO]: Epoch 030 - training loss: 0.3560, validation loss: 0.1950
2024-06-02 20:41:27 [INFO]: Epoch 031 - training loss: 0.3545, validation loss: 0.1956
2024-06-02 20:41:27 [INFO]: Epoch 032 - training loss: 0.3545, validation loss: 0.1916
2024-06-02 20:41:28 [INFO]: Epoch 033 - training loss: 0.3528, validation loss: 0.2005
2024-06-02 20:41:28 [INFO]: Epoch 034 - training loss: 0.3506, validation loss: 0.1949
2024-06-02 20:41:29 [INFO]: Epoch 035 - training loss: 0.3489, validation loss: 0.1870
2024-06-02 20:41:30 [INFO]: Epoch 036 - training loss: 0.3461, validation loss: 0.1912
2024-06-02 20:41:30 [INFO]: Epoch 037 - training loss: 0.3447, validation loss: 0.1977
2024-06-02 20:41:31 [INFO]: Epoch 038 - training loss: 0.3441, validation loss: 0.1900
2024-06-02 20:41:32 [INFO]: Epoch 039 - training loss: 0.3432, validation loss: 0.1866
2024-06-02 20:41:32 [INFO]: Epoch 040 - training loss: 0.3418, validation loss: 0.1876
2024-06-02 20:41:33 [INFO]: Epoch 041 - training loss: 0.3385, validation loss: 0.1836
2024-06-02 20:41:34 [INFO]: Epoch 042 - training loss: 0.3355, validation loss: 0.1848
2024-06-02 20:41:34 [INFO]: Epoch 043 - training loss: 0.3357, validation loss: 0.1827
2024-06-02 20:41:35 [INFO]: Epoch 044 - training loss: 0.3349, validation loss: 0.1841
2024-06-02 20:41:36 [INFO]: Epoch 045 - training loss: 0.3297, validation loss: 0.1823
2024-06-02 20:41:36 [INFO]: Epoch 046 - training loss: 0.3274, validation loss: 0.1835
2024-06-02 20:41:37 [INFO]: Epoch 047 - training loss: 0.3257, validation loss: 0.1789
2024-06-02 20:41:38 [INFO]: Epoch 048 - training loss: 0.3254, validation loss: 0.1797
2024-06-02 20:41:38 [INFO]: Epoch 049 - training loss: 0.3264, validation loss: 0.1794
2024-06-02 20:41:39 [INFO]: Epoch 050 - training loss: 0.3257, validation loss: 0.1737
2024-06-02 20:41:40 [INFO]: Epoch 051 - training loss: 0.3226, validation loss: 0.1786
2024-06-02 20:41:40 [INFO]: Epoch 052 - training loss: 0.3215, validation loss: 0.1746
2024-06-02 20:41:41 [INFO]: Epoch 053 - training loss: 0.3199, validation loss: 0.1696
2024-06-02 20:41:42 [INFO]: Epoch 054 - training loss: 0.3168, validation loss: 0.1722
2024-06-02 20:41:42 [INFO]: Epoch 055 - training loss: 0.3184, validation loss: 0.1704
2024-06-02 20:41:43 [INFO]: Epoch 056 - training loss: 0.3164, validation loss: 0.1703
2024-06-02 20:41:44 [INFO]: Epoch 057 - training loss: 0.3130, validation loss: 0.1700
2024-06-02 20:41:44 [INFO]: Epoch 058 - training loss: 0.3158, validation loss: 0.1688
2024-06-02 20:41:45 [INFO]: Epoch 059 - training loss: 0.3132, validation loss: 0.1710
2024-06-02 20:41:46 [INFO]: Epoch 060 - training loss: 0.3135, validation loss: 0.1706
2024-06-02 20:41:46 [INFO]: Epoch 061 - training loss: 0.3114, validation loss: 0.1676
2024-06-02 20:41:47 [INFO]: Epoch 062 - training loss: 0.3105, validation loss: 0.1668
2024-06-02 20:41:48 [INFO]: Epoch 063 - training loss: 0.3079, validation loss: 0.1659
2024-06-02 20:41:48 [INFO]: Epoch 064 - training loss: 0.3081, validation loss: 0.1629
2024-06-02 20:41:49 [INFO]: Epoch 065 - training loss: 0.3076, validation loss: 0.1683
2024-06-02 20:41:49 [INFO]: Epoch 066 - training loss: 0.3071, validation loss: 0.1665
2024-06-02 20:41:50 [INFO]: Epoch 067 - training loss: 0.3073, validation loss: 0.1606
2024-06-02 20:41:51 [INFO]: Epoch 068 - training loss: 0.3054, validation loss: 0.1620
2024-06-02 20:41:51 [INFO]: Epoch 069 - training loss: 0.3024, validation loss: 0.1609
2024-06-02 20:41:52 [INFO]: Epoch 070 - training loss: 0.3001, validation loss: 0.1648
2024-06-02 20:41:53 [INFO]: Epoch 071 - training loss: 0.2993, validation loss: 0.1624
2024-06-02 20:41:53 [INFO]: Epoch 072 - training loss: 0.3010, validation loss: 0.1627
2024-06-02 20:41:54 [INFO]: Epoch 073 - training loss: 0.2982, validation loss: 0.1647
2024-06-02 20:41:55 [INFO]: Epoch 074 - training loss: 0.2978, validation loss: 0.1604
2024-06-02 20:41:55 [INFO]: Epoch 075 - training loss: 0.3032, validation loss: 0.1615
2024-06-02 20:41:56 [INFO]: Epoch 076 - training loss: 0.2969, validation loss: 0.1588
2024-06-02 20:41:57 [INFO]: Epoch 077 - training loss: 0.2966, validation loss: 0.1590
2024-06-02 20:41:57 [INFO]: Epoch 078 - training loss: 0.2961, validation loss: 0.1623
2024-06-02 20:41:58 [INFO]: Epoch 079 - training loss: 0.2922, validation loss: 0.1623
2024-06-02 20:41:59 [INFO]: Epoch 080 - training loss: 0.2940, validation loss: 0.1608
2024-06-02 20:41:59 [INFO]: Epoch 081 - training loss: 0.2907, validation loss: 0.1626
2024-06-02 20:42:00 [INFO]: Epoch 082 - training loss: 0.2900, validation loss: 0.1569
2024-06-02 20:42:00 [INFO]: Epoch 083 - training loss: 0.2902, validation loss: 0.1613
2024-06-02 20:42:01 [INFO]: Epoch 084 - training loss: 0.2899, validation loss: 0.1592
2024-06-02 20:42:02 [INFO]: Epoch 085 - training loss: 0.2915, validation loss: 0.1552
2024-06-02 20:42:02 [INFO]: Epoch 086 - training loss: 0.2891, validation loss: 0.1586
2024-06-02 20:42:03 [INFO]: Epoch 087 - training loss: 0.2872, validation loss: 0.1603
2024-06-02 20:42:04 [INFO]: Epoch 088 - training loss: 0.2864, validation loss: 0.1586
2024-06-02 20:42:04 [INFO]: Epoch 089 - training loss: 0.2861, validation loss: 0.1573
2024-06-02 20:42:05 [INFO]: Epoch 090 - training loss: 0.2856, validation loss: 0.1582
2024-06-02 20:42:06 [INFO]: Epoch 091 - training loss: 0.2830, validation loss: 0.1607
2024-06-02 20:42:06 [INFO]: Epoch 092 - training loss: 0.2848, validation loss: 0.1615
2024-06-02 20:42:07 [INFO]: Epoch 093 - training loss: 0.2840, validation loss: 0.1592
2024-06-02 20:42:08 [INFO]: Epoch 094 - training loss: 0.2809, validation loss: 0.1597
2024-06-02 20:42:08 [INFO]: Epoch 095 - training loss: 0.2828, validation loss: 0.1632
2024-06-02 20:42:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:42:08 [INFO]: Finished training. The best model is from epoch#85.
2024-06-02 20:42:08 [INFO]: Saved the model to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_3/20240602_T204106/BRITS.pypots
2024-06-02 20:42:08 [INFO]: Successfully saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_3/imputation.pkl
2024-06-02 20:42:08 [INFO]: Round3 - BRITS on ItalyAir: MAE=0.2282, MSE=0.1424, MRE=0.3080
2024-06-02 20:42:08 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:42:08 [INFO]: Using the given device: cuda:0
2024-06-02 20:42:08 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_4/20240602_T204208
2024-06-02 20:42:08 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_4/20240602_T204208/tensorboard
2024-06-02 20:42:08 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-02 20:42:09 [INFO]: Epoch 001 - training loss: 1.1565, validation loss: 1.3080
2024-06-02 20:42:10 [INFO]: Epoch 002 - training loss: 0.8885, validation loss: 0.7177
2024-06-02 20:42:10 [INFO]: Epoch 003 - training loss: 0.7468, validation loss: 0.4171
2024-06-02 20:42:11 [INFO]: Epoch 004 - training loss: 0.6609, validation loss: 0.3128
2024-06-02 20:42:12 [INFO]: Epoch 005 - training loss: 0.6033, validation loss: 0.2862
2024-06-02 20:42:12 [INFO]: Epoch 006 - training loss: 0.5656, validation loss: 0.2693
2024-06-02 20:42:13 [INFO]: Epoch 007 - training loss: 0.5318, validation loss: 0.2683
2024-06-02 20:42:14 [INFO]: Epoch 008 - training loss: 0.5071, validation loss: 0.2636
2024-06-02 20:42:14 [INFO]: Epoch 009 - training loss: 0.4850, validation loss: 0.2484
2024-06-02 20:42:15 [INFO]: Epoch 010 - training loss: 0.4693, validation loss: 0.2384
2024-06-02 20:42:15 [INFO]: Epoch 011 - training loss: 0.4561, validation loss: 0.2251
2024-06-02 20:42:16 [INFO]: Epoch 012 - training loss: 0.4436, validation loss: 0.2329
2024-06-02 20:42:17 [INFO]: Epoch 013 - training loss: 0.4327, validation loss: 0.2264
2024-06-02 20:42:17 [INFO]: Epoch 014 - training loss: 0.4256, validation loss: 0.2227
2024-06-02 20:42:18 [INFO]: Epoch 015 - training loss: 0.4191, validation loss: 0.2167
2024-06-02 20:42:19 [INFO]: Epoch 016 - training loss: 0.4104, validation loss: 0.1982
2024-06-02 20:42:19 [INFO]: Epoch 017 - training loss: 0.4040, validation loss: 0.2115
2024-06-02 20:42:20 [INFO]: Epoch 018 - training loss: 0.3991, validation loss: 0.2008
2024-06-02 20:42:20 [INFO]: Epoch 019 - training loss: 0.3962, validation loss: 0.2020
2024-06-02 20:42:21 [INFO]: Epoch 020 - training loss: 0.3891, validation loss: 0.2001
2024-06-02 20:42:22 [INFO]: Epoch 021 - training loss: 0.3858, validation loss: 0.1914
2024-06-02 20:42:22 [INFO]: Epoch 022 - training loss: 0.3841, validation loss: 0.1986
2024-06-02 20:42:23 [INFO]: Epoch 023 - training loss: 0.3773, validation loss: 0.1932
2024-06-02 20:42:24 [INFO]: Epoch 024 - training loss: 0.3746, validation loss: 0.1906
2024-06-02 20:42:24 [INFO]: Epoch 025 - training loss: 0.3701, validation loss: 0.1916
2024-06-02 20:42:25 [INFO]: Epoch 026 - training loss: 0.3683, validation loss: 0.1932
2024-06-02 20:42:25 [INFO]: Epoch 027 - training loss: 0.3673, validation loss: 0.1899
2024-06-02 20:42:26 [INFO]: Epoch 028 - training loss: 0.3638, validation loss: 0.1835
2024-06-02 20:42:27 [INFO]: Epoch 029 - training loss: 0.3600, validation loss: 0.1906
2024-06-02 20:42:27 [INFO]: Epoch 030 - training loss: 0.3606, validation loss: 0.1818
2024-06-02 20:42:28 [INFO]: Epoch 031 - training loss: 0.3597, validation loss: 0.1917
2024-06-02 20:42:29 [INFO]: Epoch 032 - training loss: 0.3565, validation loss: 0.1832
2024-06-02 20:42:29 [INFO]: Epoch 033 - training loss: 0.3556, validation loss: 0.1824
2024-06-02 20:42:30 [INFO]: Epoch 034 - training loss: 0.3515, validation loss: 0.1793
2024-06-02 20:42:31 [INFO]: Epoch 035 - training loss: 0.3508, validation loss: 0.1864
2024-06-02 20:42:31 [INFO]: Epoch 036 - training loss: 0.3496, validation loss: 0.1815
2024-06-02 20:42:32 [INFO]: Epoch 037 - training loss: 0.3454, validation loss: 0.1801
2024-06-02 20:42:33 [INFO]: Epoch 038 - training loss: 0.3447, validation loss: 0.1882
2024-06-02 20:42:33 [INFO]: Epoch 039 - training loss: 0.3420, validation loss: 0.1905
2024-06-02 20:42:34 [INFO]: Epoch 040 - training loss: 0.3406, validation loss: 0.1727
2024-06-02 20:42:34 [INFO]: Epoch 041 - training loss: 0.3370, validation loss: 0.1768
2024-06-02 20:42:35 [INFO]: Epoch 042 - training loss: 0.3371, validation loss: 0.1741
2024-06-02 20:42:36 [INFO]: Epoch 043 - training loss: 0.3348, validation loss: 0.1760
2024-06-02 20:42:36 [INFO]: Epoch 044 - training loss: 0.3325, validation loss: 0.1773
2024-06-02 20:42:37 [INFO]: Epoch 045 - training loss: 0.3317, validation loss: 0.1743
2024-06-02 20:42:38 [INFO]: Epoch 046 - training loss: 0.3328, validation loss: 0.1757
2024-06-02 20:42:38 [INFO]: Epoch 047 - training loss: 0.3287, validation loss: 0.1750
2024-06-02 20:42:39 [INFO]: Epoch 048 - training loss: 0.3263, validation loss: 0.1775
2024-06-02 20:42:40 [INFO]: Epoch 049 - training loss: 0.3255, validation loss: 0.1689
2024-06-02 20:42:40 [INFO]: Epoch 050 - training loss: 0.3241, validation loss: 0.1753
2024-06-02 20:42:41 [INFO]: Epoch 051 - training loss: 0.3233, validation loss: 0.1734
2024-06-02 20:42:42 [INFO]: Epoch 052 - training loss: 0.3216, validation loss: 0.1716
2024-06-02 20:42:42 [INFO]: Epoch 053 - training loss: 0.3215, validation loss: 0.1695
2024-06-02 20:42:43 [INFO]: Epoch 054 - training loss: 0.3200, validation loss: 0.1703
2024-06-02 20:42:44 [INFO]: Epoch 055 - training loss: 0.3190, validation loss: 0.1713
2024-06-02 20:42:44 [INFO]: Epoch 056 - training loss: 0.3175, validation loss: 0.1694
2024-06-02 20:42:45 [INFO]: Epoch 057 - training loss: 0.3158, validation loss: 0.1685
2024-06-02 20:42:45 [INFO]: Epoch 058 - training loss: 0.3169, validation loss: 0.1608
2024-06-02 20:42:46 [INFO]: Epoch 059 - training loss: 0.3163, validation loss: 0.1631
2024-06-02 20:42:47 [INFO]: Epoch 060 - training loss: 0.3125, validation loss: 0.1670
2024-06-02 20:42:47 [INFO]: Epoch 061 - training loss: 0.3115, validation loss: 0.1612
2024-06-02 20:42:48 [INFO]: Epoch 062 - training loss: 0.3093, validation loss: 0.1610
2024-06-02 20:42:49 [INFO]: Epoch 063 - training loss: 0.3092, validation loss: 0.1587
2024-06-02 20:42:49 [INFO]: Epoch 064 - training loss: 0.3090, validation loss: 0.1616
2024-06-02 20:42:50 [INFO]: Epoch 065 - training loss: 0.3108, validation loss: 0.1639
2024-06-02 20:42:51 [INFO]: Epoch 066 - training loss: 0.3059, validation loss: 0.1602
2024-06-02 20:42:51 [INFO]: Epoch 067 - training loss: 0.3058, validation loss: 0.1650
2024-06-02 20:42:52 [INFO]: Epoch 068 - training loss: 0.3035, validation loss: 0.1601
2024-06-02 20:42:52 [INFO]: Epoch 069 - training loss: 0.3028, validation loss: 0.1622
2024-06-02 20:42:53 [INFO]: Epoch 070 - training loss: 0.3039, validation loss: 0.1608
2024-06-02 20:42:54 [INFO]: Epoch 071 - training loss: 0.3006, validation loss: 0.1562
2024-06-02 20:42:54 [INFO]: Epoch 072 - training loss: 0.3036, validation loss: 0.1601
2024-06-02 20:42:55 [INFO]: Epoch 073 - training loss: 0.3003, validation loss: 0.1596
2024-06-02 20:42:56 [INFO]: Epoch 074 - training loss: 0.2995, validation loss: 0.1579
2024-06-02 20:42:56 [INFO]: Epoch 075 - training loss: 0.2975, validation loss: 0.1536
2024-06-02 20:42:57 [INFO]: Epoch 076 - training loss: 0.2979, validation loss: 0.1568
2024-06-02 20:42:58 [INFO]: Epoch 077 - training loss: 0.2962, validation loss: 0.1531
2024-06-02 20:42:58 [INFO]: Epoch 078 - training loss: 0.2945, validation loss: 0.1517
2024-06-02 20:42:59 [INFO]: Epoch 079 - training loss: 0.2928, validation loss: 0.1620
2024-06-02 20:43:00 [INFO]: Epoch 080 - training loss: 0.2929, validation loss: 0.1555
2024-06-02 20:43:00 [INFO]: Epoch 081 - training loss: 0.2936, validation loss: 0.1546
2024-06-02 20:43:01 [INFO]: Epoch 082 - training loss: 0.2940, validation loss: 0.1519
2024-06-02 20:43:01 [INFO]: Epoch 083 - training loss: 0.2916, validation loss: 0.1563
2024-06-02 20:43:02 [INFO]: Epoch 084 - training loss: 0.2900, validation loss: 0.1458
2024-06-02 20:43:03 [INFO]: Epoch 085 - training loss: 0.2901, validation loss: 0.1573
2024-06-02 20:43:03 [INFO]: Epoch 086 - training loss: 0.2881, validation loss: 0.1566
2024-06-02 20:43:04 [INFO]: Epoch 087 - training loss: 0.2870, validation loss: 0.1561
2024-06-02 20:43:05 [INFO]: Epoch 088 - training loss: 0.2872, validation loss: 0.1519
2024-06-02 20:43:05 [INFO]: Epoch 089 - training loss: 0.2868, validation loss: 0.1544
2024-06-02 20:43:06 [INFO]: Epoch 090 - training loss: 0.2854, validation loss: 0.1491
2024-06-02 20:43:06 [INFO]: Epoch 091 - training loss: 0.2858, validation loss: 0.1539
2024-06-02 20:43:07 [INFO]: Epoch 092 - training loss: 0.2858, validation loss: 0.1544
2024-06-02 20:43:08 [INFO]: Epoch 093 - training loss: 0.2854, validation loss: 0.1552
2024-06-02 20:43:08 [INFO]: Epoch 094 - training loss: 0.2840, validation loss: 0.1524
2024-06-02 20:43:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:43:08 [INFO]: Finished training. The best model is from epoch#84.
2024-06-02 20:43:08 [INFO]: Saved the model to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_4/20240602_T204208/BRITS.pypots
2024-06-02 20:43:08 [INFO]: Successfully saved to results_point_rate01/ItalyAir/BRITS_ItalyAir/round_4/imputation.pkl
2024-06-02 20:43:08 [INFO]: Round4 - BRITS on ItalyAir: MAE=0.2308, MSE=0.1414, MRE=0.3116
2024-06-02 20:43:08 [INFO]: Done! Final results:
Averaged BRITS (596,912 params) on ItalyAir: MAE=0.2350 ± 0.007053754650444742, MSE=0.1464 ± 0.006522651648728386, MRE=0.3172 ± 0.009521356399214493, average inference time=0.41
