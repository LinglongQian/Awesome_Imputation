2024-06-02 20:21:50 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:21:50 [INFO]: Using the given device: cuda:0
2024-06-02 20:21:52 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202152
2024-06-02 20:21:52 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202152/tensorboard
2024-06-02 20:21:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:22:07 [INFO]: Epoch 001 - training loss: 0.6225, validation loss: 0.4954
2024-06-02 20:22:16 [INFO]: Epoch 002 - training loss: 0.3669, validation loss: 0.4120
2024-06-02 20:22:24 [INFO]: Epoch 003 - training loss: 0.2993, validation loss: 0.3788
2024-06-02 20:22:34 [INFO]: Epoch 004 - training loss: 0.3213, validation loss: 0.3752
2024-06-02 20:22:43 [INFO]: Epoch 005 - training loss: 0.2990, validation loss: 0.3761
2024-06-02 20:22:51 [INFO]: Epoch 006 - training loss: 0.3339, validation loss: 0.3884
2024-06-02 20:23:00 [INFO]: Epoch 007 - training loss: 0.2939, validation loss: 0.3552
2024-06-02 20:23:09 [INFO]: Epoch 008 - training loss: 0.2812, validation loss: 0.3912
2024-06-02 20:23:18 [INFO]: Epoch 009 - training loss: 0.2574, validation loss: 0.3481
2024-06-02 20:23:27 [INFO]: Epoch 010 - training loss: 0.2552, validation loss: 0.3320
2024-06-02 20:23:35 [INFO]: Epoch 011 - training loss: 0.2743, validation loss: 0.3074
2024-06-02 20:23:44 [INFO]: Epoch 012 - training loss: 0.2320, validation loss: 0.2786
2024-06-02 20:23:52 [INFO]: Epoch 013 - training loss: 0.2482, validation loss: 0.2995
2024-06-02 20:24:01 [INFO]: Epoch 014 - training loss: 0.2173, validation loss: 0.3080
2024-06-02 20:24:10 [INFO]: Epoch 015 - training loss: 0.2323, validation loss: 0.2518
2024-06-02 20:24:19 [INFO]: Epoch 016 - training loss: 0.2207, validation loss: 0.2596
2024-06-02 20:24:28 [INFO]: Epoch 017 - training loss: 0.2062, validation loss: 0.2594
2024-06-02 20:24:37 [INFO]: Epoch 018 - training loss: 0.1842, validation loss: 0.2374
2024-06-02 20:24:46 [INFO]: Epoch 019 - training loss: 0.1712, validation loss: 0.2361
2024-06-02 20:24:55 [INFO]: Epoch 020 - training loss: 0.1867, validation loss: 0.2446
2024-06-02 20:25:04 [INFO]: Epoch 021 - training loss: 0.2156, validation loss: 0.2285
2024-06-02 20:25:12 [INFO]: Epoch 022 - training loss: 0.1904, validation loss: 0.2172
2024-06-02 20:25:21 [INFO]: Epoch 023 - training loss: 0.1847, validation loss: 0.2048
2024-06-02 20:25:30 [INFO]: Epoch 024 - training loss: 0.1845, validation loss: 0.2022
2024-06-02 20:25:39 [INFO]: Epoch 025 - training loss: 0.1740, validation loss: 0.1897
2024-06-02 20:25:47 [INFO]: Epoch 026 - training loss: 0.1698, validation loss: 0.1974
2024-06-02 20:25:54 [INFO]: Epoch 027 - training loss: 0.1996, validation loss: 0.1937
2024-06-02 20:26:02 [INFO]: Epoch 028 - training loss: 0.1938, validation loss: 0.1912
2024-06-02 20:26:09 [INFO]: Epoch 029 - training loss: 0.1715, validation loss: 0.1878
2024-06-02 20:26:15 [INFO]: Epoch 030 - training loss: 0.1659, validation loss: 0.1833
2024-06-02 20:26:22 [INFO]: Epoch 031 - training loss: 0.1746, validation loss: 0.1820
2024-06-02 20:26:29 [INFO]: Epoch 032 - training loss: 0.1898, validation loss: 0.1749
2024-06-02 20:26:36 [INFO]: Epoch 033 - training loss: 0.1615, validation loss: 0.1683
2024-06-02 20:26:42 [INFO]: Epoch 034 - training loss: 0.1683, validation loss: 0.1819
2024-06-02 20:26:47 [INFO]: Epoch 035 - training loss: 0.1736, validation loss: 0.1634
2024-06-02 20:26:53 [INFO]: Epoch 036 - training loss: 0.1470, validation loss: 0.1744
2024-06-02 20:26:58 [INFO]: Epoch 037 - training loss: 0.1737, validation loss: 0.1761
2024-06-02 20:27:03 [INFO]: Epoch 038 - training loss: 0.1812, validation loss: 0.1581
2024-06-02 20:27:08 [INFO]: Epoch 039 - training loss: 0.1671, validation loss: 0.1655
2024-06-02 20:27:14 [INFO]: Epoch 040 - training loss: 0.1690, validation loss: 0.1547
2024-06-02 20:27:20 [INFO]: Epoch 041 - training loss: 0.1382, validation loss: 0.1506
2024-06-02 20:27:25 [INFO]: Epoch 042 - training loss: 0.1567, validation loss: 0.1550
2024-06-02 20:27:30 [INFO]: Epoch 043 - training loss: 0.1643, validation loss: 0.1664
2024-06-02 20:27:35 [INFO]: Epoch 044 - training loss: 0.1584, validation loss: 0.1584
2024-06-02 20:27:41 [INFO]: Epoch 045 - training loss: 0.1434, validation loss: 0.1456
2024-06-02 20:27:46 [INFO]: Epoch 046 - training loss: 0.1432, validation loss: 0.1525
2024-06-02 20:27:52 [INFO]: Epoch 047 - training loss: 0.1456, validation loss: 0.1503
2024-06-02 20:27:57 [INFO]: Epoch 048 - training loss: 0.1507, validation loss: 0.1579
2024-06-02 20:28:02 [INFO]: Epoch 049 - training loss: 0.1436, validation loss: 0.1440
2024-06-02 20:28:07 [INFO]: Epoch 050 - training loss: 0.1250, validation loss: 0.1429
2024-06-02 20:28:13 [INFO]: Epoch 051 - training loss: 0.1535, validation loss: 0.1375
2024-06-02 20:28:18 [INFO]: Epoch 052 - training loss: 0.1396, validation loss: 0.1379
2024-06-02 20:28:24 [INFO]: Epoch 053 - training loss: 0.1412, validation loss: 0.1435
2024-06-02 20:28:29 [INFO]: Epoch 054 - training loss: 0.1496, validation loss: 0.1378
2024-06-02 20:28:35 [INFO]: Epoch 055 - training loss: 0.1441, validation loss: 0.1468
2024-06-02 20:28:40 [INFO]: Epoch 056 - training loss: 0.1489, validation loss: 0.1503
2024-06-02 20:28:46 [INFO]: Epoch 057 - training loss: 0.1500, validation loss: 0.1429
2024-06-02 20:28:51 [INFO]: Epoch 058 - training loss: 0.1276, validation loss: 0.1444
2024-06-02 20:28:56 [INFO]: Epoch 059 - training loss: 0.1582, validation loss: 0.1395
2024-06-02 20:29:00 [INFO]: Epoch 060 - training loss: 0.1267, validation loss: 0.1430
2024-06-02 20:29:03 [INFO]: Epoch 061 - training loss: 0.1529, validation loss: 0.1566
2024-06-02 20:29:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:29:03 [INFO]: Finished training. The best model is from epoch#51.
2024-06-02 20:29:03 [INFO]: Saved the model to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202152/CSDI.pypots
2024-06-02 20:29:20 [INFO]: Successfully saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_0/imputation.pkl
2024-06-02 20:29:20 [INFO]: Round0 - CSDI on ItalyAir: MAE=1.3525, MSE=94.4533, MRE=1.8257
2024-06-02 20:29:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:29:20 [INFO]: Using the given device: cuda:0
2024-06-02 20:29:20 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_1/20240602_T202920
2024-06-02 20:29:20 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_1/20240602_T202920/tensorboard
2024-06-02 20:29:20 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:29:23 [INFO]: Epoch 001 - training loss: 0.6236, validation loss: 0.4243
2024-06-02 20:29:25 [INFO]: Epoch 002 - training loss: 0.3637, validation loss: 0.4025
2024-06-02 20:29:28 [INFO]: Epoch 003 - training loss: 0.3381, validation loss: 0.3934
2024-06-02 20:29:30 [INFO]: Epoch 004 - training loss: 0.3395, validation loss: 0.3881
2024-06-02 20:29:33 [INFO]: Epoch 005 - training loss: 0.3350, validation loss: 0.3671
2024-06-02 20:29:35 [INFO]: Epoch 006 - training loss: 0.2943, validation loss: 0.4098
2024-06-02 20:29:37 [INFO]: Epoch 007 - training loss: 0.2794, validation loss: 0.3379
2024-06-02 20:29:40 [INFO]: Epoch 008 - training loss: 0.2768, validation loss: 0.3268
2024-06-02 20:29:42 [INFO]: Epoch 009 - training loss: 0.2687, validation loss: 0.2956
2024-06-02 20:29:45 [INFO]: Epoch 010 - training loss: 0.2252, validation loss: 0.2871
2024-06-02 20:29:47 [INFO]: Epoch 011 - training loss: 0.2326, validation loss: 0.2766
2024-06-02 20:29:50 [INFO]: Epoch 012 - training loss: 0.2406, validation loss: 0.2728
2024-06-02 20:29:53 [INFO]: Epoch 013 - training loss: 0.2121, validation loss: 0.2939
2024-06-02 20:29:55 [INFO]: Epoch 014 - training loss: 0.1967, validation loss: 0.2541
2024-06-02 20:29:58 [INFO]: Epoch 015 - training loss: 0.2579, validation loss: 0.2429
2024-06-02 20:30:00 [INFO]: Epoch 016 - training loss: 0.2159, validation loss: 0.2452
2024-06-02 20:30:02 [INFO]: Epoch 017 - training loss: 0.2113, validation loss: 0.2276
2024-06-02 20:30:05 [INFO]: Epoch 018 - training loss: 0.2041, validation loss: 0.2190
2024-06-02 20:30:08 [INFO]: Epoch 019 - training loss: 0.1982, validation loss: 0.2181
2024-06-02 20:30:10 [INFO]: Epoch 020 - training loss: 0.2150, validation loss: 0.2074
2024-06-02 20:30:12 [INFO]: Epoch 021 - training loss: 0.2385, validation loss: 0.2035
2024-06-02 20:30:14 [INFO]: Epoch 022 - training loss: 0.1783, validation loss: 0.1885
2024-06-02 20:30:17 [INFO]: Epoch 023 - training loss: 0.1870, validation loss: 0.1897
2024-06-02 20:30:19 [INFO]: Epoch 024 - training loss: 0.1767, validation loss: 0.1914
2024-06-02 20:30:22 [INFO]: Epoch 025 - training loss: 0.1647, validation loss: 0.1783
2024-06-02 20:30:24 [INFO]: Epoch 026 - training loss: 0.1689, validation loss: 0.1924
2024-06-02 20:30:27 [INFO]: Epoch 027 - training loss: 0.1490, validation loss: 0.1813
2024-06-02 20:30:30 [INFO]: Epoch 028 - training loss: 0.1565, validation loss: 0.1764
2024-06-02 20:30:32 [INFO]: Epoch 029 - training loss: 0.1537, validation loss: 0.1737
2024-06-02 20:30:35 [INFO]: Epoch 030 - training loss: 0.1780, validation loss: 0.1623
2024-06-02 20:30:37 [INFO]: Epoch 031 - training loss: 0.1737, validation loss: 0.1751
2024-06-02 20:30:40 [INFO]: Epoch 032 - training loss: 0.1963, validation loss: 0.1669
2024-06-02 20:30:42 [INFO]: Epoch 033 - training loss: 0.1663, validation loss: 0.1697
2024-06-02 20:30:45 [INFO]: Epoch 034 - training loss: 0.1485, validation loss: 0.1597
2024-06-02 20:30:48 [INFO]: Epoch 035 - training loss: 0.1765, validation loss: 0.1553
2024-06-02 20:30:50 [INFO]: Epoch 036 - training loss: 0.1571, validation loss: 0.1636
2024-06-02 20:30:53 [INFO]: Epoch 037 - training loss: 0.1457, validation loss: 0.1539
2024-06-02 20:30:55 [INFO]: Epoch 038 - training loss: 0.1533, validation loss: 0.1587
2024-06-02 20:30:58 [INFO]: Epoch 039 - training loss: 0.1557, validation loss: 0.1613
2024-06-02 20:31:00 [INFO]: Epoch 040 - training loss: 0.1576, validation loss: 0.1566
2024-06-02 20:31:03 [INFO]: Epoch 041 - training loss: 0.1817, validation loss: 0.1489
2024-06-02 20:31:05 [INFO]: Epoch 042 - training loss: 0.1505, validation loss: 0.1451
2024-06-02 20:31:08 [INFO]: Epoch 043 - training loss: 0.1646, validation loss: 0.1435
2024-06-02 20:31:10 [INFO]: Epoch 044 - training loss: 0.1563, validation loss: 0.1547
2024-06-02 20:31:12 [INFO]: Epoch 045 - training loss: 0.1634, validation loss: 0.1442
2024-06-02 20:31:15 [INFO]: Epoch 046 - training loss: 0.1432, validation loss: 0.1598
2024-06-02 20:31:17 [INFO]: Epoch 047 - training loss: 0.1580, validation loss: 0.1461
2024-06-02 20:31:20 [INFO]: Epoch 048 - training loss: 0.1511, validation loss: 0.1463
2024-06-02 20:31:22 [INFO]: Epoch 049 - training loss: 0.1456, validation loss: 0.1399
2024-06-02 20:31:25 [INFO]: Epoch 050 - training loss: 0.1719, validation loss: 0.1426
2024-06-02 20:31:27 [INFO]: Epoch 051 - training loss: 0.1575, validation loss: 0.1579
2024-06-02 20:31:30 [INFO]: Epoch 052 - training loss: 0.1590, validation loss: 0.1509
2024-06-02 20:31:32 [INFO]: Epoch 053 - training loss: 0.1340, validation loss: 0.1373
2024-06-02 20:31:34 [INFO]: Epoch 054 - training loss: 0.1477, validation loss: 0.1387
2024-06-02 20:31:37 [INFO]: Epoch 055 - training loss: 0.1544, validation loss: 0.1378
2024-06-02 20:31:39 [INFO]: Epoch 056 - training loss: 0.1635, validation loss: 0.1437
2024-06-02 20:31:42 [INFO]: Epoch 057 - training loss: 0.1450, validation loss: 0.1368
2024-06-02 20:31:44 [INFO]: Epoch 058 - training loss: 0.1611, validation loss: 0.1358
2024-06-02 20:31:47 [INFO]: Epoch 059 - training loss: 0.1235, validation loss: 0.1314
2024-06-02 20:31:50 [INFO]: Epoch 060 - training loss: 0.1416, validation loss: 0.1386
2024-06-02 20:31:52 [INFO]: Epoch 061 - training loss: 0.1448, validation loss: 0.1316
2024-06-02 20:31:55 [INFO]: Epoch 062 - training loss: 0.1634, validation loss: 0.1340
2024-06-02 20:31:58 [INFO]: Epoch 063 - training loss: 0.1494, validation loss: 0.1338
2024-06-02 20:32:00 [INFO]: Epoch 064 - training loss: 0.1515, validation loss: 0.1297
2024-06-02 20:32:03 [INFO]: Epoch 065 - training loss: 0.1162, validation loss: 0.1272
2024-06-02 20:32:05 [INFO]: Epoch 066 - training loss: 0.1213, validation loss: 0.1259
2024-06-02 20:32:07 [INFO]: Epoch 067 - training loss: 0.1547, validation loss: 0.1258
2024-06-02 20:32:10 [INFO]: Epoch 068 - training loss: 0.1336, validation loss: 0.1291
2024-06-02 20:32:13 [INFO]: Epoch 069 - training loss: 0.1203, validation loss: 0.1268
2024-06-02 20:32:15 [INFO]: Epoch 070 - training loss: 0.1426, validation loss: 0.1403
2024-06-02 20:32:18 [INFO]: Epoch 071 - training loss: 0.1204, validation loss: 0.1304
2024-06-02 20:32:21 [INFO]: Epoch 072 - training loss: 0.1408, validation loss: 0.1331
2024-06-02 20:32:23 [INFO]: Epoch 073 - training loss: 0.1306, validation loss: 0.1383
2024-06-02 20:32:25 [INFO]: Epoch 074 - training loss: 0.1341, validation loss: 0.1292
2024-06-02 20:32:28 [INFO]: Epoch 075 - training loss: 0.1358, validation loss: 0.1286
2024-06-02 20:32:30 [INFO]: Epoch 076 - training loss: 0.1318, validation loss: 0.1267
2024-06-02 20:32:33 [INFO]: Epoch 077 - training loss: 0.1264, validation loss: 0.1215
2024-06-02 20:32:35 [INFO]: Epoch 078 - training loss: 0.1198, validation loss: 0.1255
2024-06-02 20:32:37 [INFO]: Epoch 079 - training loss: 0.1405, validation loss: 0.1231
2024-06-02 20:32:39 [INFO]: Epoch 080 - training loss: 0.1487, validation loss: 0.1352
2024-06-02 20:32:40 [INFO]: Epoch 081 - training loss: 0.1454, validation loss: 0.1246
2024-06-02 20:32:42 [INFO]: Epoch 082 - training loss: 0.1090, validation loss: 0.1291
2024-06-02 20:32:44 [INFO]: Epoch 083 - training loss: 0.1290, validation loss: 0.1217
2024-06-02 20:32:45 [INFO]: Epoch 084 - training loss: 0.1457, validation loss: 0.1211
2024-06-02 20:32:47 [INFO]: Epoch 085 - training loss: 0.1297, validation loss: 0.1283
2024-06-02 20:32:49 [INFO]: Epoch 086 - training loss: 0.1142, validation loss: 0.1209
2024-06-02 20:32:50 [INFO]: Epoch 087 - training loss: 0.1381, validation loss: 0.1164
2024-06-02 20:32:52 [INFO]: Epoch 088 - training loss: 0.1380, validation loss: 0.1221
2024-06-02 20:32:54 [INFO]: Epoch 089 - training loss: 0.1271, validation loss: 0.1203
2024-06-02 20:32:55 [INFO]: Epoch 090 - training loss: 0.1244, validation loss: 0.1271
2024-06-02 20:32:57 [INFO]: Epoch 091 - training loss: 0.1317, validation loss: 0.1189
2024-06-02 20:32:58 [INFO]: Epoch 092 - training loss: 0.1235, validation loss: 0.1252
2024-06-02 20:33:00 [INFO]: Epoch 093 - training loss: 0.1154, validation loss: 0.1240
2024-06-02 20:33:02 [INFO]: Epoch 094 - training loss: 0.1267, validation loss: 0.1186
2024-06-02 20:33:03 [INFO]: Epoch 095 - training loss: 0.1130, validation loss: 0.1239
2024-06-02 20:33:05 [INFO]: Epoch 096 - training loss: 0.1274, validation loss: 0.1223
2024-06-02 20:33:07 [INFO]: Epoch 097 - training loss: 0.1343, validation loss: 0.1228
2024-06-02 20:33:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:33:07 [INFO]: Finished training. The best model is from epoch#87.
2024-06-02 20:33:07 [INFO]: Saved the model to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_1/20240602_T202920/CSDI.pypots
2024-06-02 20:33:18 [INFO]: Successfully saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_1/imputation.pkl
2024-06-02 20:33:18 [INFO]: Round1 - CSDI on ItalyAir: MAE=0.2850, MSE=3.2864, MRE=0.3848
2024-06-02 20:33:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:33:18 [INFO]: Using the given device: cuda:0
2024-06-02 20:33:18 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203318
2024-06-02 20:33:18 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203318/tensorboard
2024-06-02 20:33:18 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:33:19 [INFO]: Epoch 001 - training loss: 0.6196, validation loss: 0.4445
2024-06-02 20:33:21 [INFO]: Epoch 002 - training loss: 0.3426, validation loss: 0.3857
2024-06-02 20:33:23 [INFO]: Epoch 003 - training loss: 0.3039, validation loss: 0.3853
2024-06-02 20:33:24 [INFO]: Epoch 004 - training loss: 0.3326, validation loss: 0.3983
2024-06-02 20:33:26 [INFO]: Epoch 005 - training loss: 0.3044, validation loss: 0.3860
2024-06-02 20:33:28 [INFO]: Epoch 006 - training loss: 0.3205, validation loss: 0.3669
2024-06-02 20:33:29 [INFO]: Epoch 007 - training loss: 0.2751, validation loss: 0.3733
2024-06-02 20:33:31 [INFO]: Epoch 008 - training loss: 0.2720, validation loss: 0.3435
2024-06-02 20:33:33 [INFO]: Epoch 009 - training loss: 0.2546, validation loss: 0.3149
2024-06-02 20:33:34 [INFO]: Epoch 010 - training loss: 0.2423, validation loss: 0.3058
2024-06-02 20:33:36 [INFO]: Epoch 011 - training loss: 0.2492, validation loss: 0.2831
2024-06-02 20:33:38 [INFO]: Epoch 012 - training loss: 0.2172, validation loss: 0.2658
2024-06-02 20:33:39 [INFO]: Epoch 013 - training loss: 0.2244, validation loss: 0.2600
2024-06-02 20:33:41 [INFO]: Epoch 014 - training loss: 0.2028, validation loss: 0.2417
2024-06-02 20:33:42 [INFO]: Epoch 015 - training loss: 0.1989, validation loss: 0.2312
2024-06-02 20:33:44 [INFO]: Epoch 016 - training loss: 0.1909, validation loss: 0.2189
2024-06-02 20:33:46 [INFO]: Epoch 017 - training loss: 0.1981, validation loss: 0.2141
2024-06-02 20:33:47 [INFO]: Epoch 018 - training loss: 0.2130, validation loss: 0.2055
2024-06-02 20:33:49 [INFO]: Epoch 019 - training loss: 0.1963, validation loss: 0.2037
2024-06-02 20:33:51 [INFO]: Epoch 020 - training loss: 0.1806, validation loss: 0.2114
2024-06-02 20:33:52 [INFO]: Epoch 021 - training loss: 0.1869, validation loss: 0.2018
2024-06-02 20:33:54 [INFO]: Epoch 022 - training loss: 0.1941, validation loss: 0.1912
2024-06-02 20:33:56 [INFO]: Epoch 023 - training loss: 0.1883, validation loss: 0.1875
2024-06-02 20:33:57 [INFO]: Epoch 024 - training loss: 0.1902, validation loss: 0.2017
2024-06-02 20:33:59 [INFO]: Epoch 025 - training loss: 0.1618, validation loss: 0.1919
2024-06-02 20:34:01 [INFO]: Epoch 026 - training loss: 0.1502, validation loss: 0.1750
2024-06-02 20:34:02 [INFO]: Epoch 027 - training loss: 0.1693, validation loss: 0.1757
2024-06-02 20:34:04 [INFO]: Epoch 028 - training loss: 0.1581, validation loss: 0.1751
2024-06-02 20:34:05 [INFO]: Epoch 029 - training loss: 0.1644, validation loss: 0.1764
2024-06-02 20:34:07 [INFO]: Epoch 030 - training loss: 0.1832, validation loss: 0.1616
2024-06-02 20:34:09 [INFO]: Epoch 031 - training loss: 0.1465, validation loss: 0.1589
2024-06-02 20:34:10 [INFO]: Epoch 032 - training loss: 0.1671, validation loss: 0.1656
2024-06-02 20:34:12 [INFO]: Epoch 033 - training loss: 0.1836, validation loss: 0.1810
2024-06-02 20:34:14 [INFO]: Epoch 034 - training loss: 0.1765, validation loss: 0.1630
2024-06-02 20:34:15 [INFO]: Epoch 035 - training loss: 0.1519, validation loss: 0.1576
2024-06-02 20:34:17 [INFO]: Epoch 036 - training loss: 0.1932, validation loss: 0.1623
2024-06-02 20:34:18 [INFO]: Epoch 037 - training loss: 0.1522, validation loss: 0.1561
2024-06-02 20:34:20 [INFO]: Epoch 038 - training loss: 0.1548, validation loss: 0.1550
2024-06-02 20:34:22 [INFO]: Epoch 039 - training loss: 0.1379, validation loss: 0.1664
2024-06-02 20:34:24 [INFO]: Epoch 040 - training loss: 0.1501, validation loss: 0.1445
2024-06-02 20:34:25 [INFO]: Epoch 041 - training loss: 0.1476, validation loss: 0.1529
2024-06-02 20:34:27 [INFO]: Epoch 042 - training loss: 0.1752, validation loss: 0.1442
2024-06-02 20:34:29 [INFO]: Epoch 043 - training loss: 0.1559, validation loss: 0.1561
2024-06-02 20:34:30 [INFO]: Epoch 044 - training loss: 0.1548, validation loss: 0.1705
2024-06-02 20:34:32 [INFO]: Epoch 045 - training loss: 0.1469, validation loss: 0.1608
2024-06-02 20:34:33 [INFO]: Epoch 046 - training loss: 0.1597, validation loss: 0.1513
2024-06-02 20:34:35 [INFO]: Epoch 047 - training loss: 0.1479, validation loss: 0.1443
2024-06-02 20:34:37 [INFO]: Epoch 048 - training loss: 0.1416, validation loss: 0.1415
2024-06-02 20:34:38 [INFO]: Epoch 049 - training loss: 0.1569, validation loss: 0.1399
2024-06-02 20:34:40 [INFO]: Epoch 050 - training loss: 0.1219, validation loss: 0.1450
2024-06-02 20:34:42 [INFO]: Epoch 051 - training loss: 0.1541, validation loss: 0.1416
2024-06-02 20:34:43 [INFO]: Epoch 052 - training loss: 0.1458, validation loss: 0.1482
2024-06-02 20:34:45 [INFO]: Epoch 053 - training loss: 0.1427, validation loss: 0.1496
2024-06-02 20:34:47 [INFO]: Epoch 054 - training loss: 0.1551, validation loss: 0.1415
2024-06-02 20:34:48 [INFO]: Epoch 055 - training loss: 0.1612, validation loss: 0.1382
2024-06-02 20:34:50 [INFO]: Epoch 056 - training loss: 0.1343, validation loss: 0.1388
2024-06-02 20:34:52 [INFO]: Epoch 057 - training loss: 0.1468, validation loss: 0.1391
2024-06-02 20:34:53 [INFO]: Epoch 058 - training loss: 0.1331, validation loss: 0.1336
2024-06-02 20:34:55 [INFO]: Epoch 059 - training loss: 0.1335, validation loss: 0.1314
2024-06-02 20:34:57 [INFO]: Epoch 060 - training loss: 0.1229, validation loss: 0.1324
2024-06-02 20:34:58 [INFO]: Epoch 061 - training loss: 0.1445, validation loss: 0.1286
2024-06-02 20:35:00 [INFO]: Epoch 062 - training loss: 0.1507, validation loss: 0.1333
2024-06-02 20:35:02 [INFO]: Epoch 063 - training loss: 0.1397, validation loss: 0.1261
2024-06-02 20:35:03 [INFO]: Epoch 064 - training loss: 0.1420, validation loss: 0.1389
2024-06-02 20:35:05 [INFO]: Epoch 065 - training loss: 0.1389, validation loss: 0.1414
2024-06-02 20:35:07 [INFO]: Epoch 066 - training loss: 0.1373, validation loss: 0.1303
2024-06-02 20:35:08 [INFO]: Epoch 067 - training loss: 0.1217, validation loss: 0.1319
2024-06-02 20:35:10 [INFO]: Epoch 068 - training loss: 0.1227, validation loss: 0.1256
2024-06-02 20:35:11 [INFO]: Epoch 069 - training loss: 0.1376, validation loss: 0.1302
2024-06-02 20:35:13 [INFO]: Epoch 070 - training loss: 0.1292, validation loss: 0.1215
2024-06-02 20:35:15 [INFO]: Epoch 071 - training loss: 0.1419, validation loss: 0.1212
2024-06-02 20:35:16 [INFO]: Epoch 072 - training loss: 0.1423, validation loss: 0.1202
2024-06-02 20:35:18 [INFO]: Epoch 073 - training loss: 0.1512, validation loss: 0.1247
2024-06-02 20:35:20 [INFO]: Epoch 074 - training loss: 0.1470, validation loss: 0.1289
2024-06-02 20:35:21 [INFO]: Epoch 075 - training loss: 0.1299, validation loss: 0.1409
2024-06-02 20:35:23 [INFO]: Epoch 076 - training loss: 0.1147, validation loss: 0.1301
2024-06-02 20:35:25 [INFO]: Epoch 077 - training loss: 0.1488, validation loss: 0.1267
2024-06-02 20:35:26 [INFO]: Epoch 078 - training loss: 0.1173, validation loss: 0.1258
2024-06-02 20:35:28 [INFO]: Epoch 079 - training loss: 0.1207, validation loss: 0.1198
2024-06-02 20:35:30 [INFO]: Epoch 080 - training loss: 0.1347, validation loss: 0.1225
2024-06-02 20:35:31 [INFO]: Epoch 081 - training loss: 0.1406, validation loss: 0.1257
2024-06-02 20:35:33 [INFO]: Epoch 082 - training loss: 0.1548, validation loss: 0.1244
2024-06-02 20:35:35 [INFO]: Epoch 083 - training loss: 0.1191, validation loss: 0.1357
2024-06-02 20:35:36 [INFO]: Epoch 084 - training loss: 0.1287, validation loss: 0.1267
2024-06-02 20:35:38 [INFO]: Epoch 085 - training loss: 0.1192, validation loss: 0.1166
2024-06-02 20:35:39 [INFO]: Epoch 086 - training loss: 0.1328, validation loss: 0.1222
2024-06-02 20:35:41 [INFO]: Epoch 087 - training loss: 0.1326, validation loss: 0.1321
2024-06-02 20:35:43 [INFO]: Epoch 088 - training loss: 0.1289, validation loss: 0.1241
2024-06-02 20:35:44 [INFO]: Epoch 089 - training loss: 0.1142, validation loss: 0.1264
2024-06-02 20:35:46 [INFO]: Epoch 090 - training loss: 0.1285, validation loss: 0.1174
2024-06-02 20:35:48 [INFO]: Epoch 091 - training loss: 0.1457, validation loss: 0.1264
2024-06-02 20:35:49 [INFO]: Epoch 092 - training loss: 0.1145, validation loss: 0.1240
2024-06-02 20:35:51 [INFO]: Epoch 093 - training loss: 0.1256, validation loss: 0.1228
2024-06-02 20:35:53 [INFO]: Epoch 094 - training loss: 0.1329, validation loss: 0.1204
2024-06-02 20:35:54 [INFO]: Epoch 095 - training loss: 0.1161, validation loss: 0.1241
2024-06-02 20:35:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:35:55 [INFO]: Finished training. The best model is from epoch#85.
2024-06-02 20:35:55 [INFO]: Saved the model to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203318/CSDI.pypots
2024-06-02 20:36:06 [INFO]: Successfully saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_2/imputation.pkl
2024-06-02 20:36:06 [INFO]: Round2 - CSDI on ItalyAir: MAE=0.2828, MSE=3.7241, MRE=0.3817
2024-06-02 20:36:06 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:36:06 [INFO]: Using the given device: cuda:0
2024-06-02 20:36:06 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203606
2024-06-02 20:36:06 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203606/tensorboard
2024-06-02 20:36:06 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:36:07 [INFO]: Epoch 001 - training loss: 0.6375, validation loss: 0.5168
2024-06-02 20:36:09 [INFO]: Epoch 002 - training loss: 0.3719, validation loss: 0.4170
2024-06-02 20:36:11 [INFO]: Epoch 003 - training loss: 0.3155, validation loss: 0.3751
2024-06-02 20:36:12 [INFO]: Epoch 004 - training loss: 0.3146, validation loss: 0.3641
2024-06-02 20:36:14 [INFO]: Epoch 005 - training loss: 0.3285, validation loss: 0.3574
2024-06-02 20:36:16 [INFO]: Epoch 006 - training loss: 0.2956, validation loss: 0.3530
2024-06-02 20:36:17 [INFO]: Epoch 007 - training loss: 0.2773, validation loss: 0.3581
2024-06-02 20:36:19 [INFO]: Epoch 008 - training loss: 0.2880, validation loss: 0.3451
2024-06-02 20:36:21 [INFO]: Epoch 009 - training loss: 0.3050, validation loss: 0.3250
2024-06-02 20:36:22 [INFO]: Epoch 010 - training loss: 0.2540, validation loss: 0.3266
2024-06-02 20:36:24 [INFO]: Epoch 011 - training loss: 0.2790, validation loss: 0.2964
2024-06-02 20:36:25 [INFO]: Epoch 012 - training loss: 0.2041, validation loss: 0.3066
2024-06-02 20:36:27 [INFO]: Epoch 013 - training loss: 0.2408, validation loss: 0.2788
2024-06-02 20:36:29 [INFO]: Epoch 014 - training loss: 0.2206, validation loss: 0.2478
2024-06-02 20:36:30 [INFO]: Epoch 015 - training loss: 0.1986, validation loss: 0.2554
2024-06-02 20:36:32 [INFO]: Epoch 016 - training loss: 0.1996, validation loss: 0.2367
2024-06-02 20:36:34 [INFO]: Epoch 017 - training loss: 0.1936, validation loss: 0.2295
2024-06-02 20:36:35 [INFO]: Epoch 018 - training loss: 0.2018, validation loss: 0.2330
2024-06-02 20:36:37 [INFO]: Epoch 019 - training loss: 0.2117, validation loss: 0.2370
2024-06-02 20:36:39 [INFO]: Epoch 020 - training loss: 0.2191, validation loss: 0.2177
2024-06-02 20:36:40 [INFO]: Epoch 021 - training loss: 0.1923, validation loss: 0.2123
2024-06-02 20:36:42 [INFO]: Epoch 022 - training loss: 0.1712, validation loss: 0.2003
2024-06-02 20:36:44 [INFO]: Epoch 023 - training loss: 0.1984, validation loss: 0.2137
2024-06-02 20:36:45 [INFO]: Epoch 024 - training loss: 0.1957, validation loss: 0.1980
2024-06-02 20:36:47 [INFO]: Epoch 025 - training loss: 0.1684, validation loss: 0.1823
2024-06-02 20:36:49 [INFO]: Epoch 026 - training loss: 0.1671, validation loss: 0.2029
2024-06-02 20:36:50 [INFO]: Epoch 027 - training loss: 0.1876, validation loss: 0.1758
2024-06-02 20:36:52 [INFO]: Epoch 028 - training loss: 0.1614, validation loss: 0.1808
2024-06-02 20:36:54 [INFO]: Epoch 029 - training loss: 0.1942, validation loss: 0.1787
2024-06-02 20:36:55 [INFO]: Epoch 030 - training loss: 0.1664, validation loss: 0.1847
2024-06-02 20:36:57 [INFO]: Epoch 031 - training loss: 0.1793, validation loss: 0.1866
2024-06-02 20:36:59 [INFO]: Epoch 032 - training loss: 0.1567, validation loss: 0.1876
2024-06-02 20:37:00 [INFO]: Epoch 033 - training loss: 0.1752, validation loss: 0.1582
2024-06-02 20:37:02 [INFO]: Epoch 034 - training loss: 0.1511, validation loss: 0.1748
2024-06-02 20:37:04 [INFO]: Epoch 035 - training loss: 0.1666, validation loss: 0.1644
2024-06-02 20:37:05 [INFO]: Epoch 036 - training loss: 0.1756, validation loss: 0.1656
2024-06-02 20:37:07 [INFO]: Epoch 037 - training loss: 0.1715, validation loss: 0.1613
2024-06-02 20:37:08 [INFO]: Epoch 038 - training loss: 0.1540, validation loss: 0.1596
2024-06-02 20:37:10 [INFO]: Epoch 039 - training loss: 0.1695, validation loss: 0.1505
2024-06-02 20:37:12 [INFO]: Epoch 040 - training loss: 0.1602, validation loss: 0.1583
2024-06-02 20:37:14 [INFO]: Epoch 041 - training loss: 0.1799, validation loss: 0.1625
2024-06-02 20:37:15 [INFO]: Epoch 042 - training loss: 0.1636, validation loss: 0.1709
2024-06-02 20:37:17 [INFO]: Epoch 043 - training loss: 0.1417, validation loss: 0.1526
2024-06-02 20:37:18 [INFO]: Epoch 044 - training loss: 0.1594, validation loss: 0.1597
2024-06-02 20:37:20 [INFO]: Epoch 045 - training loss: 0.1373, validation loss: 0.1392
2024-06-02 20:37:22 [INFO]: Epoch 046 - training loss: 0.1407, validation loss: 0.1402
2024-06-02 20:37:23 [INFO]: Epoch 047 - training loss: 0.1671, validation loss: 0.1472
2024-06-02 20:37:25 [INFO]: Epoch 048 - training loss: 0.1656, validation loss: 0.1410
2024-06-02 20:37:27 [INFO]: Epoch 049 - training loss: 0.1494, validation loss: 0.1545
2024-06-02 20:37:28 [INFO]: Epoch 050 - training loss: 0.1423, validation loss: 0.1441
2024-06-02 20:37:30 [INFO]: Epoch 051 - training loss: 0.1307, validation loss: 0.1430
2024-06-02 20:37:32 [INFO]: Epoch 052 - training loss: 0.1613, validation loss: 0.1499
2024-06-02 20:37:33 [INFO]: Epoch 053 - training loss: 0.1491, validation loss: 0.1423
2024-06-02 20:37:35 [INFO]: Epoch 054 - training loss: 0.1474, validation loss: 0.1409
2024-06-02 20:37:36 [INFO]: Epoch 055 - training loss: 0.1655, validation loss: 0.1403
2024-06-02 20:37:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:37:36 [INFO]: Finished training. The best model is from epoch#45.
2024-06-02 20:37:36 [INFO]: Saved the model to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203606/CSDI.pypots
2024-06-02 20:37:48 [INFO]: Successfully saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_3/imputation.pkl
2024-06-02 20:37:48 [INFO]: Round3 - CSDI on ItalyAir: MAE=0.5224, MSE=13.2333, MRE=0.7051
2024-06-02 20:37:48 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:37:48 [INFO]: Using the given device: cuda:0
2024-06-02 20:37:48 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_4/20240602_T203748
2024-06-02 20:37:48 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_4/20240602_T203748/tensorboard
2024-06-02 20:37:48 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:37:49 [INFO]: Epoch 001 - training loss: 0.6310, validation loss: 0.4252
2024-06-02 20:37:51 [INFO]: Epoch 002 - training loss: 0.3256, validation loss: 0.4056
2024-06-02 20:37:53 [INFO]: Epoch 003 - training loss: 0.3384, validation loss: 0.3789
2024-06-02 20:37:54 [INFO]: Epoch 004 - training loss: 0.3148, validation loss: 0.3890
2024-06-02 20:37:56 [INFO]: Epoch 005 - training loss: 0.3152, validation loss: 0.3714
2024-06-02 20:37:57 [INFO]: Epoch 006 - training loss: 0.2781, validation loss: 0.3920
2024-06-02 20:37:59 [INFO]: Epoch 007 - training loss: 0.2650, validation loss: 0.3604
2024-06-02 20:38:01 [INFO]: Epoch 008 - training loss: 0.2665, validation loss: 0.3269
2024-06-02 20:38:02 [INFO]: Epoch 009 - training loss: 0.2653, validation loss: 0.3406
2024-06-02 20:38:04 [INFO]: Epoch 010 - training loss: 0.2527, validation loss: 0.3021
2024-06-02 20:38:06 [INFO]: Epoch 011 - training loss: 0.2573, validation loss: 0.2883
2024-06-02 20:38:07 [INFO]: Epoch 012 - training loss: 0.2586, validation loss: 0.2699
2024-06-02 20:38:09 [INFO]: Epoch 013 - training loss: 0.2123, validation loss: 0.2633
2024-06-02 20:38:10 [INFO]: Epoch 014 - training loss: 0.2162, validation loss: 0.2462
2024-06-02 20:38:12 [INFO]: Epoch 015 - training loss: 0.1990, validation loss: 0.2317
2024-06-02 20:38:14 [INFO]: Epoch 016 - training loss: 0.2228, validation loss: 0.2238
2024-06-02 20:38:15 [INFO]: Epoch 017 - training loss: 0.2128, validation loss: 0.2020
2024-06-02 20:38:17 [INFO]: Epoch 018 - training loss: 0.2088, validation loss: 0.2029
2024-06-02 20:38:19 [INFO]: Epoch 019 - training loss: 0.1893, validation loss: 0.2036
2024-06-02 20:38:20 [INFO]: Epoch 020 - training loss: 0.2021, validation loss: 0.1989
2024-06-02 20:38:22 [INFO]: Epoch 021 - training loss: 0.1862, validation loss: 0.1982
2024-06-02 20:38:24 [INFO]: Epoch 022 - training loss: 0.1935, validation loss: 0.1801
2024-06-02 20:38:25 [INFO]: Epoch 023 - training loss: 0.1686, validation loss: 0.1684
2024-06-02 20:38:27 [INFO]: Epoch 024 - training loss: 0.1775, validation loss: 0.1753
2024-06-02 20:38:29 [INFO]: Epoch 025 - training loss: 0.1629, validation loss: 0.1647
2024-06-02 20:38:30 [INFO]: Epoch 026 - training loss: 0.1565, validation loss: 0.1665
2024-06-02 20:38:32 [INFO]: Epoch 027 - training loss: 0.1610, validation loss: 0.1825
2024-06-02 20:38:33 [INFO]: Epoch 028 - training loss: 0.1890, validation loss: 0.1710
2024-06-02 20:38:35 [INFO]: Epoch 029 - training loss: 0.1756, validation loss: 0.1797
2024-06-02 20:38:37 [INFO]: Epoch 030 - training loss: 0.1637, validation loss: 0.1655
2024-06-02 20:38:38 [INFO]: Epoch 031 - training loss: 0.1646, validation loss: 0.1752
2024-06-02 20:38:40 [INFO]: Epoch 032 - training loss: 0.1593, validation loss: 0.1667
2024-06-02 20:38:42 [INFO]: Epoch 033 - training loss: 0.1445, validation loss: 0.1537
2024-06-02 20:38:43 [INFO]: Epoch 034 - training loss: 0.1648, validation loss: 0.1532
2024-06-02 20:38:45 [INFO]: Epoch 035 - training loss: 0.1511, validation loss: 0.1524
2024-06-02 20:38:47 [INFO]: Epoch 036 - training loss: 0.1567, validation loss: 0.1475
2024-06-02 20:38:48 [INFO]: Epoch 037 - training loss: 0.1392, validation loss: 0.1445
2024-06-02 20:38:50 [INFO]: Epoch 038 - training loss: 0.1382, validation loss: 0.1428
2024-06-02 20:38:51 [INFO]: Epoch 039 - training loss: 0.1619, validation loss: 0.1515
2024-06-02 20:38:53 [INFO]: Epoch 040 - training loss: 0.1662, validation loss: 0.1467
2024-06-02 20:38:55 [INFO]: Epoch 041 - training loss: 0.1425, validation loss: 0.1426
2024-06-02 20:38:56 [INFO]: Epoch 042 - training loss: 0.1416, validation loss: 0.1478
2024-06-02 20:38:58 [INFO]: Epoch 043 - training loss: 0.1399, validation loss: 0.1368
2024-06-02 20:39:00 [INFO]: Epoch 044 - training loss: 0.1388, validation loss: 0.1419
2024-06-02 20:39:02 [INFO]: Epoch 045 - training loss: 0.1586, validation loss: 0.1371
2024-06-02 20:39:03 [INFO]: Epoch 046 - training loss: 0.1331, validation loss: 0.1428
2024-06-02 20:39:05 [INFO]: Epoch 047 - training loss: 0.1608, validation loss: 0.1438
2024-06-02 20:39:06 [INFO]: Epoch 048 - training loss: 0.1404, validation loss: 0.1317
2024-06-02 20:39:08 [INFO]: Epoch 049 - training loss: 0.1549, validation loss: 0.1322
2024-06-02 20:39:10 [INFO]: Epoch 050 - training loss: 0.1505, validation loss: 0.1380
2024-06-02 20:39:11 [INFO]: Epoch 051 - training loss: 0.1366, validation loss: 0.1375
2024-06-02 20:39:13 [INFO]: Epoch 052 - training loss: 0.1551, validation loss: 0.1349
2024-06-02 20:39:14 [INFO]: Epoch 053 - training loss: 0.1389, validation loss: 0.1374
2024-06-02 20:39:16 [INFO]: Epoch 054 - training loss: 0.1413, validation loss: 0.1367
2024-06-02 20:39:18 [INFO]: Epoch 055 - training loss: 0.1595, validation loss: 0.1323
2024-06-02 20:39:19 [INFO]: Epoch 056 - training loss: 0.1104, validation loss: 0.1332
2024-06-02 20:39:21 [INFO]: Epoch 057 - training loss: 0.1469, validation loss: 0.1282
2024-06-02 20:39:23 [INFO]: Epoch 058 - training loss: 0.1347, validation loss: 0.1296
2024-06-02 20:39:24 [INFO]: Epoch 059 - training loss: 0.1528, validation loss: 0.1350
2024-06-02 20:39:26 [INFO]: Epoch 060 - training loss: 0.1624, validation loss: 0.1321
2024-06-02 20:39:28 [INFO]: Epoch 061 - training loss: 0.1432, validation loss: 0.1305
2024-06-02 20:39:29 [INFO]: Epoch 062 - training loss: 0.1525, validation loss: 0.1281
2024-06-02 20:39:31 [INFO]: Epoch 063 - training loss: 0.1365, validation loss: 0.1424
2024-06-02 20:39:32 [INFO]: Epoch 064 - training loss: 0.1045, validation loss: 0.1318
2024-06-02 20:39:34 [INFO]: Epoch 065 - training loss: 0.1389, validation loss: 0.1326
2024-06-02 20:39:36 [INFO]: Epoch 066 - training loss: 0.1415, validation loss: 0.1417
2024-06-02 20:39:37 [INFO]: Epoch 067 - training loss: 0.1582, validation loss: 0.1326
2024-06-02 20:39:39 [INFO]: Epoch 068 - training loss: 0.1304, validation loss: 0.1228
2024-06-02 20:39:41 [INFO]: Epoch 069 - training loss: 0.1317, validation loss: 0.1234
2024-06-02 20:39:42 [INFO]: Epoch 070 - training loss: 0.1449, validation loss: 0.1278
2024-06-02 20:39:44 [INFO]: Epoch 071 - training loss: 0.1250, validation loss: 0.1260
2024-06-02 20:39:46 [INFO]: Epoch 072 - training loss: 0.1230, validation loss: 0.1400
2024-06-02 20:39:47 [INFO]: Epoch 073 - training loss: 0.1526, validation loss: 0.1289
2024-06-02 20:39:49 [INFO]: Epoch 074 - training loss: 0.1225, validation loss: 0.1238
2024-06-02 20:39:51 [INFO]: Epoch 075 - training loss: 0.1374, validation loss: 0.1193
2024-06-02 20:39:52 [INFO]: Epoch 076 - training loss: 0.1166, validation loss: 0.1274
2024-06-02 20:39:54 [INFO]: Epoch 077 - training loss: 0.1435, validation loss: 0.1397
2024-06-02 20:39:56 [INFO]: Epoch 078 - training loss: 0.1339, validation loss: 0.1419
2024-06-02 20:39:57 [INFO]: Epoch 079 - training loss: 0.1262, validation loss: 0.1291
2024-06-02 20:39:59 [INFO]: Epoch 080 - training loss: 0.1364, validation loss: 0.1202
2024-06-02 20:40:00 [INFO]: Epoch 081 - training loss: 0.1037, validation loss: 0.1164
2024-06-02 20:40:02 [INFO]: Epoch 082 - training loss: 0.1189, validation loss: 0.1269
2024-06-02 20:40:04 [INFO]: Epoch 083 - training loss: 0.1543, validation loss: 0.1210
2024-06-02 20:40:05 [INFO]: Epoch 084 - training loss: 0.1447, validation loss: 0.1259
2024-06-02 20:40:07 [INFO]: Epoch 085 - training loss: 0.1382, validation loss: 0.1299
2024-06-02 20:40:09 [INFO]: Epoch 086 - training loss: 0.1425, validation loss: 0.1422
2024-06-02 20:40:10 [INFO]: Epoch 087 - training loss: 0.1181, validation loss: 0.1201
2024-06-02 20:40:12 [INFO]: Epoch 088 - training loss: 0.1217, validation loss: 0.1201
2024-06-02 20:40:14 [INFO]: Epoch 089 - training loss: 0.1299, validation loss: 0.1261
2024-06-02 20:40:15 [INFO]: Epoch 090 - training loss: 0.1220, validation loss: 0.1187
2024-06-02 20:40:17 [INFO]: Epoch 091 - training loss: 0.1283, validation loss: 0.1233
2024-06-02 20:40:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:40:17 [INFO]: Finished training. The best model is from epoch#81.
2024-06-02 20:40:17 [INFO]: Saved the model to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_4/20240602_T203748/CSDI.pypots
2024-06-02 20:40:28 [INFO]: Successfully saved to results_point_rate01/ItalyAir/CSDI_ItalyAir/round_4/imputation.pkl
2024-06-02 20:40:28 [INFO]: Round4 - CSDI on ItalyAir: MAE=0.2532, MSE=2.8193, MRE=0.3417
2024-06-02 20:40:28 [INFO]: Done! Final results:
Averaged CSDI (933,161 params) on ItalyAir: MAE=0.5392 ± 0.4180746190524155, MSE=23.5033 ± 35.685119556205365, MRE=0.7278 ± 0.5643288782680999, average inference time=12.39
