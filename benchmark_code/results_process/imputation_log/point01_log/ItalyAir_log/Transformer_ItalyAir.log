2024-06-02 21:10:27 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 21:10:27 [INFO]: Using the given device: cuda:0
2024-06-02 21:10:27 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_0/20240602_T211027
2024-06-02 21:10:27 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_0/20240602_T211027/tensorboard
2024-06-02 21:10:27 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=2, d_k=256
2024-06-02 21:10:27 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (2) * d_k (256)
2024-06-02 21:10:28 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 4,749,837
2024-06-02 21:10:31 [INFO]: Epoch 001 - training loss: 1.0898, validation loss: 1.2503
2024-06-02 21:10:32 [INFO]: Epoch 002 - training loss: 0.6662, validation loss: 0.9274
2024-06-02 21:10:33 [INFO]: Epoch 003 - training loss: 0.5432, validation loss: 0.6249
2024-06-02 21:10:33 [INFO]: Epoch 004 - training loss: 0.4650, validation loss: 0.4308
2024-06-02 21:10:34 [INFO]: Epoch 005 - training loss: 0.4197, validation loss: 0.3101
2024-06-02 21:10:35 [INFO]: Epoch 006 - training loss: 0.3955, validation loss: 0.2333
2024-06-02 21:10:36 [INFO]: Epoch 007 - training loss: 0.3766, validation loss: 0.2102
2024-06-02 21:10:37 [INFO]: Epoch 008 - training loss: 0.3549, validation loss: 0.1846
2024-06-02 21:10:38 [INFO]: Epoch 009 - training loss: 0.3478, validation loss: 0.1618
2024-06-02 21:10:39 [INFO]: Epoch 010 - training loss: 0.3326, validation loss: 0.1564
2024-06-02 21:10:40 [INFO]: Epoch 011 - training loss: 0.3313, validation loss: 0.1427
2024-06-02 21:10:41 [INFO]: Epoch 012 - training loss: 0.3167, validation loss: 0.1317
2024-06-02 21:10:42 [INFO]: Epoch 013 - training loss: 0.3043, validation loss: 0.1256
2024-06-02 21:10:43 [INFO]: Epoch 014 - training loss: 0.2930, validation loss: 0.1191
2024-06-02 21:10:44 [INFO]: Epoch 015 - training loss: 0.2835, validation loss: 0.1231
2024-06-02 21:10:45 [INFO]: Epoch 016 - training loss: 0.2866, validation loss: 0.1175
2024-06-02 21:10:46 [INFO]: Epoch 017 - training loss: 0.2739, validation loss: 0.1231
2024-06-02 21:10:47 [INFO]: Epoch 018 - training loss: 0.2743, validation loss: 0.1171
2024-06-02 21:10:48 [INFO]: Epoch 019 - training loss: 0.2644, validation loss: 0.1193
2024-06-02 21:10:50 [INFO]: Epoch 020 - training loss: 0.2668, validation loss: 0.1083
2024-06-02 21:10:51 [INFO]: Epoch 021 - training loss: 0.2611, validation loss: 0.1142
2024-06-02 21:10:52 [INFO]: Epoch 022 - training loss: 0.2558, validation loss: 0.1054
2024-06-02 21:10:53 [INFO]: Epoch 023 - training loss: 0.2436, validation loss: 0.1029
2024-06-02 21:10:54 [INFO]: Epoch 024 - training loss: 0.2512, validation loss: 0.1053
2024-06-02 21:10:55 [INFO]: Epoch 025 - training loss: 0.2447, validation loss: 0.1073
2024-06-02 21:10:56 [INFO]: Epoch 026 - training loss: 0.2332, validation loss: 0.1048
2024-06-02 21:10:57 [INFO]: Epoch 027 - training loss: 0.2394, validation loss: 0.0962
2024-06-02 21:10:59 [INFO]: Epoch 028 - training loss: 0.2296, validation loss: 0.1011
2024-06-02 21:11:00 [INFO]: Epoch 029 - training loss: 0.2269, validation loss: 0.1026
2024-06-02 21:11:01 [INFO]: Epoch 030 - training loss: 0.2214, validation loss: 0.1045
2024-06-02 21:11:02 [INFO]: Epoch 031 - training loss: 0.2293, validation loss: 0.0975
2024-06-02 21:11:03 [INFO]: Epoch 032 - training loss: 0.2318, validation loss: 0.0994
2024-06-02 21:11:04 [INFO]: Epoch 033 - training loss: 0.2248, validation loss: 0.0945
2024-06-02 21:11:05 [INFO]: Epoch 034 - training loss: 0.2238, validation loss: 0.0940
2024-06-02 21:11:06 [INFO]: Epoch 035 - training loss: 0.2206, validation loss: 0.0931
2024-06-02 21:11:07 [INFO]: Epoch 036 - training loss: 0.2173, validation loss: 0.0953
2024-06-02 21:11:08 [INFO]: Epoch 037 - training loss: 0.2129, validation loss: 0.0903
2024-06-02 21:11:09 [INFO]: Epoch 038 - training loss: 0.2129, validation loss: 0.0888
2024-06-02 21:11:10 [INFO]: Epoch 039 - training loss: 0.2222, validation loss: 0.0947
2024-06-02 21:11:11 [INFO]: Epoch 040 - training loss: 0.2212, validation loss: 0.0870
2024-06-02 21:11:12 [INFO]: Epoch 041 - training loss: 0.2118, validation loss: 0.0914
2024-06-02 21:11:13 [INFO]: Epoch 042 - training loss: 0.2115, validation loss: 0.0900
2024-06-02 21:11:14 [INFO]: Epoch 043 - training loss: 0.2043, validation loss: 0.0877
2024-06-02 21:11:15 [INFO]: Epoch 044 - training loss: 0.2017, validation loss: 0.0933
2024-06-02 21:11:16 [INFO]: Epoch 045 - training loss: 0.2027, validation loss: 0.0817
2024-06-02 21:11:17 [INFO]: Epoch 046 - training loss: 0.2003, validation loss: 0.0850
2024-06-02 21:11:18 [INFO]: Epoch 047 - training loss: 0.1973, validation loss: 0.0900
2024-06-02 21:11:19 [INFO]: Epoch 048 - training loss: 0.1941, validation loss: 0.0853
2024-06-02 21:11:20 [INFO]: Epoch 049 - training loss: 0.1994, validation loss: 0.0835
2024-06-02 21:11:21 [INFO]: Epoch 050 - training loss: 0.1981, validation loss: 0.0846
2024-06-02 21:11:22 [INFO]: Epoch 051 - training loss: 0.1962, validation loss: 0.0846
2024-06-02 21:11:23 [INFO]: Epoch 052 - training loss: 0.1916, validation loss: 0.0849
2024-06-02 21:11:24 [INFO]: Epoch 053 - training loss: 0.1919, validation loss: 0.0809
2024-06-02 21:11:25 [INFO]: Epoch 054 - training loss: 0.1909, validation loss: 0.0862
2024-06-02 21:11:26 [INFO]: Epoch 055 - training loss: 0.1888, validation loss: 0.0814
2024-06-02 21:11:27 [INFO]: Epoch 056 - training loss: 0.1928, validation loss: 0.0819
2024-06-02 21:11:29 [INFO]: Epoch 057 - training loss: 0.1937, validation loss: 0.0817
2024-06-02 21:11:30 [INFO]: Epoch 058 - training loss: 0.1813, validation loss: 0.0783
2024-06-02 21:11:31 [INFO]: Epoch 059 - training loss: 0.1866, validation loss: 0.0812
2024-06-02 21:11:32 [INFO]: Epoch 060 - training loss: 0.1884, validation loss: 0.0776
2024-06-02 21:11:33 [INFO]: Epoch 061 - training loss: 0.1857, validation loss: 0.0748
2024-06-02 21:11:34 [INFO]: Epoch 062 - training loss: 0.1833, validation loss: 0.0754
2024-06-02 21:11:35 [INFO]: Epoch 063 - training loss: 0.1853, validation loss: 0.0814
2024-06-02 21:11:36 [INFO]: Epoch 064 - training loss: 0.1767, validation loss: 0.0741
2024-06-02 21:11:37 [INFO]: Epoch 065 - training loss: 0.1823, validation loss: 0.0800
2024-06-02 21:11:38 [INFO]: Epoch 066 - training loss: 0.1766, validation loss: 0.0803
2024-06-02 21:11:39 [INFO]: Epoch 067 - training loss: 0.1809, validation loss: 0.0811
2024-06-02 21:11:40 [INFO]: Epoch 068 - training loss: 0.1763, validation loss: 0.0716
2024-06-02 21:11:41 [INFO]: Epoch 069 - training loss: 0.1757, validation loss: 0.0767
2024-06-02 21:11:42 [INFO]: Epoch 070 - training loss: 0.1729, validation loss: 0.0782
2024-06-02 21:11:43 [INFO]: Epoch 071 - training loss: 0.1725, validation loss: 0.0762
2024-06-02 21:11:44 [INFO]: Epoch 072 - training loss: 0.1784, validation loss: 0.0785
2024-06-02 21:11:45 [INFO]: Epoch 073 - training loss: 0.1771, validation loss: 0.0824
2024-06-02 21:11:46 [INFO]: Epoch 074 - training loss: 0.1718, validation loss: 0.0705
2024-06-02 21:11:47 [INFO]: Epoch 075 - training loss: 0.1755, validation loss: 0.0838
2024-06-02 21:11:48 [INFO]: Epoch 076 - training loss: 0.1783, validation loss: 0.0762
2024-06-02 21:11:49 [INFO]: Epoch 077 - training loss: 0.1746, validation loss: 0.0767
2024-06-02 21:11:50 [INFO]: Epoch 078 - training loss: 0.1661, validation loss: 0.0746
2024-06-02 21:11:52 [INFO]: Epoch 079 - training loss: 0.1724, validation loss: 0.0787
2024-06-02 21:11:53 [INFO]: Epoch 080 - training loss: 0.1696, validation loss: 0.0721
2024-06-02 21:11:54 [INFO]: Epoch 081 - training loss: 0.1664, validation loss: 0.0812
2024-06-02 21:11:55 [INFO]: Epoch 082 - training loss: 0.1718, validation loss: 0.0745
2024-06-02 21:11:56 [INFO]: Epoch 083 - training loss: 0.1721, validation loss: 0.0809
2024-06-02 21:11:57 [INFO]: Epoch 084 - training loss: 0.1833, validation loss: 0.0751
2024-06-02 21:11:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:11:57 [INFO]: Finished training. The best model is from epoch#74.
2024-06-02 21:11:57 [INFO]: Saved the model to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_0/20240602_T211027/Transformer.pypots
2024-06-02 21:11:57 [INFO]: Successfully saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_0/imputation.pkl
2024-06-02 21:11:57 [INFO]: Round0 - Transformer on ItalyAir: MAE=0.1901, MSE=0.1026, MRE=0.2566
2024-06-02 21:11:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 21:11:57 [INFO]: Using the given device: cuda:0
2024-06-02 21:11:57 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_1/20240602_T211157
2024-06-02 21:11:57 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_1/20240602_T211157/tensorboard
2024-06-02 21:11:57 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=2, d_k=256
2024-06-02 21:11:57 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (2) * d_k (256)
2024-06-02 21:11:57 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 4,749,837
2024-06-02 21:11:59 [INFO]: Epoch 001 - training loss: 1.0456, validation loss: 1.1295
2024-06-02 21:12:00 [INFO]: Epoch 002 - training loss: 0.6546, validation loss: 0.7684
2024-06-02 21:12:01 [INFO]: Epoch 003 - training loss: 0.5298, validation loss: 0.4726
2024-06-02 21:12:02 [INFO]: Epoch 004 - training loss: 0.4576, validation loss: 0.2976
2024-06-02 21:12:03 [INFO]: Epoch 005 - training loss: 0.4281, validation loss: 0.2592
2024-06-02 21:12:04 [INFO]: Epoch 006 - training loss: 0.3957, validation loss: 0.1943
2024-06-02 21:12:05 [INFO]: Epoch 007 - training loss: 0.3666, validation loss: 0.1738
2024-06-02 21:12:06 [INFO]: Epoch 008 - training loss: 0.3462, validation loss: 0.1541
2024-06-02 21:12:07 [INFO]: Epoch 009 - training loss: 0.3435, validation loss: 0.1506
2024-06-02 21:12:09 [INFO]: Epoch 010 - training loss: 0.3363, validation loss: 0.1394
2024-06-02 21:12:10 [INFO]: Epoch 011 - training loss: 0.3227, validation loss: 0.1416
2024-06-02 21:12:11 [INFO]: Epoch 012 - training loss: 0.3062, validation loss: 0.1379
2024-06-02 21:12:12 [INFO]: Epoch 013 - training loss: 0.2965, validation loss: 0.1317
2024-06-02 21:12:13 [INFO]: Epoch 014 - training loss: 0.2877, validation loss: 0.1331
2024-06-02 21:12:14 [INFO]: Epoch 015 - training loss: 0.2936, validation loss: 0.1188
2024-06-02 21:12:15 [INFO]: Epoch 016 - training loss: 0.2881, validation loss: 0.1206
2024-06-02 21:12:16 [INFO]: Epoch 017 - training loss: 0.2773, validation loss: 0.1189
2024-06-02 21:12:17 [INFO]: Epoch 018 - training loss: 0.2691, validation loss: 0.1085
2024-06-02 21:12:18 [INFO]: Epoch 019 - training loss: 0.2617, validation loss: 0.1109
2024-06-02 21:12:19 [INFO]: Epoch 020 - training loss: 0.2611, validation loss: 0.1120
2024-06-02 21:12:20 [INFO]: Epoch 021 - training loss: 0.2632, validation loss: 0.1096
2024-06-02 21:12:21 [INFO]: Epoch 022 - training loss: 0.2554, validation loss: 0.1070
2024-06-02 21:12:23 [INFO]: Epoch 023 - training loss: 0.2594, validation loss: 0.1058
2024-06-02 21:12:24 [INFO]: Epoch 024 - training loss: 0.2591, validation loss: 0.0973
2024-06-02 21:12:25 [INFO]: Epoch 025 - training loss: 0.2523, validation loss: 0.1025
2024-06-02 21:12:26 [INFO]: Epoch 026 - training loss: 0.2448, validation loss: 0.0990
2024-06-02 21:12:27 [INFO]: Epoch 027 - training loss: 0.2386, validation loss: 0.1058
2024-06-02 21:12:28 [INFO]: Epoch 028 - training loss: 0.2325, validation loss: 0.1054
2024-06-02 21:12:29 [INFO]: Epoch 029 - training loss: 0.2353, validation loss: 0.0936
2024-06-02 21:12:30 [INFO]: Epoch 030 - training loss: 0.2354, validation loss: 0.1083
2024-06-02 21:12:31 [INFO]: Epoch 031 - training loss: 0.2398, validation loss: 0.0941
2024-06-02 21:12:32 [INFO]: Epoch 032 - training loss: 0.2389, validation loss: 0.1000
2024-06-02 21:12:34 [INFO]: Epoch 033 - training loss: 0.2307, validation loss: 0.0863
2024-06-02 21:12:35 [INFO]: Epoch 034 - training loss: 0.2280, validation loss: 0.0909
2024-06-02 21:12:36 [INFO]: Epoch 035 - training loss: 0.2189, validation loss: 0.0867
2024-06-02 21:12:37 [INFO]: Epoch 036 - training loss: 0.2263, validation loss: 0.0954
2024-06-02 21:12:38 [INFO]: Epoch 037 - training loss: 0.2204, validation loss: 0.0881
2024-06-02 21:12:39 [INFO]: Epoch 038 - training loss: 0.2200, validation loss: 0.0883
2024-06-02 21:12:40 [INFO]: Epoch 039 - training loss: 0.2159, validation loss: 0.0875
2024-06-02 21:12:41 [INFO]: Epoch 040 - training loss: 0.2068, validation loss: 0.0859
2024-06-02 21:12:42 [INFO]: Epoch 041 - training loss: 0.2024, validation loss: 0.0841
2024-06-02 21:12:43 [INFO]: Epoch 042 - training loss: 0.2107, validation loss: 0.0948
2024-06-02 21:12:44 [INFO]: Epoch 043 - training loss: 0.2155, validation loss: 0.0832
2024-06-02 21:12:45 [INFO]: Epoch 044 - training loss: 0.2074, validation loss: 0.0812
2024-06-02 21:12:46 [INFO]: Epoch 045 - training loss: 0.2046, validation loss: 0.0838
2024-06-02 21:12:47 [INFO]: Epoch 046 - training loss: 0.2038, validation loss: 0.0831
2024-06-02 21:12:48 [INFO]: Epoch 047 - training loss: 0.2046, validation loss: 0.0878
2024-06-02 21:12:49 [INFO]: Epoch 048 - training loss: 0.1975, validation loss: 0.0824
2024-06-02 21:12:50 [INFO]: Epoch 049 - training loss: 0.2032, validation loss: 0.0909
2024-06-02 21:12:52 [INFO]: Epoch 050 - training loss: 0.1975, validation loss: 0.0763
2024-06-02 21:12:53 [INFO]: Epoch 051 - training loss: 0.1937, validation loss: 0.0809
2024-06-02 21:12:53 [INFO]: Epoch 052 - training loss: 0.1946, validation loss: 0.0824
2024-06-02 21:12:55 [INFO]: Epoch 053 - training loss: 0.1933, validation loss: 0.0806
2024-06-02 21:12:56 [INFO]: Epoch 054 - training loss: 0.2016, validation loss: 0.0807
2024-06-02 21:12:57 [INFO]: Epoch 055 - training loss: 0.1962, validation loss: 0.0811
2024-06-02 21:12:58 [INFO]: Epoch 056 - training loss: 0.1940, validation loss: 0.0796
2024-06-02 21:12:59 [INFO]: Epoch 057 - training loss: 0.1889, validation loss: 0.0736
2024-06-02 21:13:00 [INFO]: Epoch 058 - training loss: 0.1900, validation loss: 0.0796
2024-06-02 21:13:01 [INFO]: Epoch 059 - training loss: 0.1832, validation loss: 0.0789
2024-06-02 21:13:02 [INFO]: Epoch 060 - training loss: 0.1877, validation loss: 0.0749
2024-06-02 21:13:02 [INFO]: Epoch 061 - training loss: 0.1856, validation loss: 0.0722
2024-06-02 21:13:04 [INFO]: Epoch 062 - training loss: 0.1838, validation loss: 0.0790
2024-06-02 21:13:05 [INFO]: Epoch 063 - training loss: 0.1811, validation loss: 0.0724
2024-06-02 21:13:06 [INFO]: Epoch 064 - training loss: 0.1832, validation loss: 0.0761
2024-06-02 21:13:07 [INFO]: Epoch 065 - training loss: 0.1808, validation loss: 0.0756
2024-06-02 21:13:08 [INFO]: Epoch 066 - training loss: 0.1763, validation loss: 0.0813
2024-06-02 21:13:09 [INFO]: Epoch 067 - training loss: 0.1798, validation loss: 0.0697
2024-06-02 21:13:10 [INFO]: Epoch 068 - training loss: 0.1763, validation loss: 0.0739
2024-06-02 21:13:11 [INFO]: Epoch 069 - training loss: 0.1746, validation loss: 0.0737
2024-06-02 21:13:12 [INFO]: Epoch 070 - training loss: 0.1787, validation loss: 0.0712
2024-06-02 21:13:13 [INFO]: Epoch 071 - training loss: 0.1785, validation loss: 0.0741
2024-06-02 21:13:14 [INFO]: Epoch 072 - training loss: 0.1781, validation loss: 0.0738
2024-06-02 21:13:15 [INFO]: Epoch 073 - training loss: 0.1743, validation loss: 0.0745
2024-06-02 21:13:16 [INFO]: Epoch 074 - training loss: 0.1798, validation loss: 0.0724
2024-06-02 21:13:17 [INFO]: Epoch 075 - training loss: 0.1769, validation loss: 0.0799
2024-06-02 21:13:18 [INFO]: Epoch 076 - training loss: 0.1751, validation loss: 0.0706
2024-06-02 21:13:19 [INFO]: Epoch 077 - training loss: 0.1808, validation loss: 0.0740
2024-06-02 21:13:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:13:19 [INFO]: Finished training. The best model is from epoch#67.
2024-06-02 21:13:19 [INFO]: Saved the model to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_1/20240602_T211157/Transformer.pypots
2024-06-02 21:13:19 [INFO]: Successfully saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_1/imputation.pkl
2024-06-02 21:13:19 [INFO]: Round1 - Transformer on ItalyAir: MAE=0.1955, MSE=0.1004, MRE=0.2639
2024-06-02 21:13:19 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 21:13:19 [INFO]: Using the given device: cuda:0
2024-06-02 21:13:19 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_2/20240602_T211319
2024-06-02 21:13:19 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_2/20240602_T211319/tensorboard
2024-06-02 21:13:19 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=2, d_k=256
2024-06-02 21:13:19 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (2) * d_k (256)
2024-06-02 21:13:19 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 4,749,837
2024-06-02 21:13:21 [INFO]: Epoch 001 - training loss: 1.0950, validation loss: 1.2768
2024-06-02 21:13:22 [INFO]: Epoch 002 - training loss: 0.6973, validation loss: 0.8651
2024-06-02 21:13:23 [INFO]: Epoch 003 - training loss: 0.5584, validation loss: 0.5133
2024-06-02 21:13:24 [INFO]: Epoch 004 - training loss: 0.4711, validation loss: 0.3796
2024-06-02 21:13:25 [INFO]: Epoch 005 - training loss: 0.4145, validation loss: 0.2612
2024-06-02 21:13:26 [INFO]: Epoch 006 - training loss: 0.3826, validation loss: 0.2056
2024-06-02 21:13:27 [INFO]: Epoch 007 - training loss: 0.3596, validation loss: 0.1617
2024-06-02 21:13:28 [INFO]: Epoch 008 - training loss: 0.3357, validation loss: 0.1455
2024-06-02 21:13:29 [INFO]: Epoch 009 - training loss: 0.3261, validation loss: 0.1462
2024-06-02 21:13:30 [INFO]: Epoch 010 - training loss: 0.3206, validation loss: 0.1329
2024-06-02 21:13:31 [INFO]: Epoch 011 - training loss: 0.3059, validation loss: 0.1328
2024-06-02 21:13:32 [INFO]: Epoch 012 - training loss: 0.2940, validation loss: 0.1212
2024-06-02 21:13:33 [INFO]: Epoch 013 - training loss: 0.2886, validation loss: 0.1237
2024-06-02 21:13:34 [INFO]: Epoch 014 - training loss: 0.2841, validation loss: 0.1277
2024-06-02 21:13:35 [INFO]: Epoch 015 - training loss: 0.2839, validation loss: 0.1216
2024-06-02 21:13:36 [INFO]: Epoch 016 - training loss: 0.2850, validation loss: 0.1127
2024-06-02 21:13:37 [INFO]: Epoch 017 - training loss: 0.2666, validation loss: 0.1108
2024-06-02 21:13:39 [INFO]: Epoch 018 - training loss: 0.2647, validation loss: 0.1113
2024-06-02 21:13:40 [INFO]: Epoch 019 - training loss: 0.2665, validation loss: 0.1156
2024-06-02 21:13:41 [INFO]: Epoch 020 - training loss: 0.2734, validation loss: 0.1022
2024-06-02 21:13:42 [INFO]: Epoch 021 - training loss: 0.2568, validation loss: 0.1090
2024-06-02 21:13:43 [INFO]: Epoch 022 - training loss: 0.2527, validation loss: 0.1014
2024-06-02 21:13:44 [INFO]: Epoch 023 - training loss: 0.2412, validation loss: 0.1156
2024-06-02 21:13:45 [INFO]: Epoch 024 - training loss: 0.2429, validation loss: 0.1003
2024-06-02 21:13:46 [INFO]: Epoch 025 - training loss: 0.2454, validation loss: 0.1008
2024-06-02 21:13:47 [INFO]: Epoch 026 - training loss: 0.2360, validation loss: 0.1025
2024-06-02 21:13:48 [INFO]: Epoch 027 - training loss: 0.2366, validation loss: 0.0922
2024-06-02 21:13:49 [INFO]: Epoch 028 - training loss: 0.2293, validation loss: 0.1052
2024-06-02 21:13:50 [INFO]: Epoch 029 - training loss: 0.2332, validation loss: 0.0981
2024-06-02 21:13:51 [INFO]: Epoch 030 - training loss: 0.2247, validation loss: 0.0971
2024-06-02 21:13:52 [INFO]: Epoch 031 - training loss: 0.2273, validation loss: 0.0915
2024-06-02 21:13:52 [INFO]: Epoch 032 - training loss: 0.2257, validation loss: 0.0944
2024-06-02 21:13:53 [INFO]: Epoch 033 - training loss: 0.2209, validation loss: 0.0905
2024-06-02 21:13:54 [INFO]: Epoch 034 - training loss: 0.2178, validation loss: 0.0901
2024-06-02 21:13:55 [INFO]: Epoch 035 - training loss: 0.2179, validation loss: 0.0953
2024-06-02 21:13:56 [INFO]: Epoch 036 - training loss: 0.2227, validation loss: 0.1052
2024-06-02 21:13:57 [INFO]: Epoch 037 - training loss: 0.2150, validation loss: 0.0868
2024-06-02 21:13:57 [INFO]: Epoch 038 - training loss: 0.2115, validation loss: 0.0864
2024-06-02 21:13:58 [INFO]: Epoch 039 - training loss: 0.2082, validation loss: 0.0865
2024-06-02 21:13:59 [INFO]: Epoch 040 - training loss: 0.2029, validation loss: 0.0922
2024-06-02 21:14:00 [INFO]: Epoch 041 - training loss: 0.2040, validation loss: 0.0835
2024-06-02 21:14:01 [INFO]: Epoch 042 - training loss: 0.2022, validation loss: 0.0806
2024-06-02 21:14:01 [INFO]: Epoch 043 - training loss: 0.1980, validation loss: 0.0974
2024-06-02 21:14:02 [INFO]: Epoch 044 - training loss: 0.2004, validation loss: 0.0809
2024-06-02 21:14:03 [INFO]: Epoch 045 - training loss: 0.2004, validation loss: 0.0807
2024-06-02 21:14:04 [INFO]: Epoch 046 - training loss: 0.2056, validation loss: 0.0876
2024-06-02 21:14:04 [INFO]: Epoch 047 - training loss: 0.2009, validation loss: 0.0894
2024-06-02 21:14:05 [INFO]: Epoch 048 - training loss: 0.2066, validation loss: 0.0887
2024-06-02 21:14:06 [INFO]: Epoch 049 - training loss: 0.1965, validation loss: 0.0807
2024-06-02 21:14:06 [INFO]: Epoch 050 - training loss: 0.1947, validation loss: 0.0836
2024-06-02 21:14:07 [INFO]: Epoch 051 - training loss: 0.1961, validation loss: 0.0841
2024-06-02 21:14:08 [INFO]: Epoch 052 - training loss: 0.1899, validation loss: 0.0849
2024-06-02 21:14:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:14:08 [INFO]: Finished training. The best model is from epoch#42.
2024-06-02 21:14:08 [INFO]: Saved the model to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_2/20240602_T211319/Transformer.pypots
2024-06-02 21:14:08 [INFO]: Successfully saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_2/imputation.pkl
2024-06-02 21:14:08 [INFO]: Round2 - Transformer on ItalyAir: MAE=0.1977, MSE=0.1070, MRE=0.2669
2024-06-02 21:14:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 21:14:08 [INFO]: Using the given device: cuda:0
2024-06-02 21:14:08 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_3/20240602_T211408
2024-06-02 21:14:08 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_3/20240602_T211408/tensorboard
2024-06-02 21:14:08 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=2, d_k=256
2024-06-02 21:14:08 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (2) * d_k (256)
2024-06-02 21:14:08 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 4,749,837
2024-06-02 21:14:09 [INFO]: Epoch 001 - training loss: 1.1799, validation loss: 1.2928
2024-06-02 21:14:10 [INFO]: Epoch 002 - training loss: 0.7009, validation loss: 0.8334
2024-06-02 21:14:11 [INFO]: Epoch 003 - training loss: 0.5698, validation loss: 0.5409
2024-06-02 21:14:12 [INFO]: Epoch 004 - training loss: 0.4692, validation loss: 0.3901
2024-06-02 21:14:12 [INFO]: Epoch 005 - training loss: 0.4259, validation loss: 0.2880
2024-06-02 21:14:13 [INFO]: Epoch 006 - training loss: 0.3917, validation loss: 0.2414
2024-06-02 21:14:14 [INFO]: Epoch 007 - training loss: 0.3706, validation loss: 0.2057
2024-06-02 21:14:15 [INFO]: Epoch 008 - training loss: 0.3618, validation loss: 0.1714
2024-06-02 21:14:16 [INFO]: Epoch 009 - training loss: 0.3389, validation loss: 0.1591
2024-06-02 21:14:17 [INFO]: Epoch 010 - training loss: 0.3238, validation loss: 0.1423
2024-06-02 21:14:17 [INFO]: Epoch 011 - training loss: 0.3240, validation loss: 0.1339
2024-06-02 21:14:18 [INFO]: Epoch 012 - training loss: 0.3023, validation loss: 0.1423
2024-06-02 21:14:19 [INFO]: Epoch 013 - training loss: 0.2974, validation loss: 0.1414
2024-06-02 21:14:20 [INFO]: Epoch 014 - training loss: 0.2901, validation loss: 0.1241
2024-06-02 21:14:21 [INFO]: Epoch 015 - training loss: 0.2824, validation loss: 0.1324
2024-06-02 21:14:22 [INFO]: Epoch 016 - training loss: 0.2802, validation loss: 0.1244
2024-06-02 21:14:23 [INFO]: Epoch 017 - training loss: 0.2699, validation loss: 0.1245
2024-06-02 21:14:24 [INFO]: Epoch 018 - training loss: 0.2756, validation loss: 0.1173
2024-06-02 21:14:24 [INFO]: Epoch 019 - training loss: 0.2722, validation loss: 0.1194
2024-06-02 21:14:25 [INFO]: Epoch 020 - training loss: 0.2629, validation loss: 0.1145
2024-06-02 21:14:26 [INFO]: Epoch 021 - training loss: 0.2580, validation loss: 0.1096
2024-06-02 21:14:27 [INFO]: Epoch 022 - training loss: 0.2492, validation loss: 0.1118
2024-06-02 21:14:27 [INFO]: Epoch 023 - training loss: 0.2466, validation loss: 0.1115
2024-06-02 21:14:28 [INFO]: Epoch 024 - training loss: 0.2493, validation loss: 0.1076
2024-06-02 21:14:29 [INFO]: Epoch 025 - training loss: 0.2466, validation loss: 0.1005
2024-06-02 21:14:30 [INFO]: Epoch 026 - training loss: 0.2417, validation loss: 0.0998
2024-06-02 21:14:31 [INFO]: Epoch 027 - training loss: 0.2400, validation loss: 0.1008
2024-06-02 21:14:31 [INFO]: Epoch 028 - training loss: 0.2512, validation loss: 0.0961
2024-06-02 21:14:32 [INFO]: Epoch 029 - training loss: 0.2368, validation loss: 0.1051
2024-06-02 21:14:33 [INFO]: Epoch 030 - training loss: 0.2316, validation loss: 0.0980
2024-06-02 21:14:34 [INFO]: Epoch 031 - training loss: 0.2385, validation loss: 0.0954
2024-06-02 21:14:35 [INFO]: Epoch 032 - training loss: 0.2294, validation loss: 0.0945
2024-06-02 21:14:35 [INFO]: Epoch 033 - training loss: 0.2249, validation loss: 0.1028
2024-06-02 21:14:36 [INFO]: Epoch 034 - training loss: 0.2223, validation loss: 0.0979
2024-06-02 21:14:37 [INFO]: Epoch 035 - training loss: 0.2173, validation loss: 0.0941
2024-06-02 21:14:38 [INFO]: Epoch 036 - training loss: 0.2159, validation loss: 0.0926
2024-06-02 21:14:39 [INFO]: Epoch 037 - training loss: 0.2168, validation loss: 0.0943
2024-06-02 21:14:39 [INFO]: Epoch 038 - training loss: 0.2207, validation loss: 0.1125
2024-06-02 21:14:40 [INFO]: Epoch 039 - training loss: 0.2233, validation loss: 0.0947
2024-06-02 21:14:41 [INFO]: Epoch 040 - training loss: 0.2185, validation loss: 0.0922
2024-06-02 21:14:42 [INFO]: Epoch 041 - training loss: 0.2101, validation loss: 0.0888
2024-06-02 21:14:42 [INFO]: Epoch 042 - training loss: 0.2093, validation loss: 0.0924
2024-06-02 21:14:43 [INFO]: Epoch 043 - training loss: 0.2110, validation loss: 0.0993
2024-06-02 21:14:44 [INFO]: Epoch 044 - training loss: 0.2131, validation loss: 0.0928
2024-06-02 21:14:45 [INFO]: Epoch 045 - training loss: 0.2101, validation loss: 0.0918
2024-06-02 21:14:45 [INFO]: Epoch 046 - training loss: 0.2012, validation loss: 0.0920
2024-06-02 21:14:46 [INFO]: Epoch 047 - training loss: 0.2005, validation loss: 0.0866
2024-06-02 21:14:47 [INFO]: Epoch 048 - training loss: 0.2066, validation loss: 0.0906
2024-06-02 21:14:48 [INFO]: Epoch 049 - training loss: 0.2003, validation loss: 0.0909
2024-06-02 21:14:49 [INFO]: Epoch 050 - training loss: 0.1951, validation loss: 0.0958
2024-06-02 21:14:49 [INFO]: Epoch 051 - training loss: 0.1980, validation loss: 0.0823
2024-06-02 21:14:50 [INFO]: Epoch 052 - training loss: 0.1915, validation loss: 0.0879
2024-06-02 21:14:51 [INFO]: Epoch 053 - training loss: 0.1937, validation loss: 0.0857
2024-06-02 21:14:52 [INFO]: Epoch 054 - training loss: 0.1989, validation loss: 0.0810
2024-06-02 21:14:52 [INFO]: Epoch 055 - training loss: 0.1944, validation loss: 0.0892
2024-06-02 21:14:53 [INFO]: Epoch 056 - training loss: 0.1985, validation loss: 0.0854
2024-06-02 21:14:54 [INFO]: Epoch 057 - training loss: 0.1929, validation loss: 0.0828
2024-06-02 21:14:54 [INFO]: Epoch 058 - training loss: 0.1951, validation loss: 0.0846
2024-06-02 21:14:55 [INFO]: Epoch 059 - training loss: 0.1864, validation loss: 0.0902
2024-06-02 21:14:56 [INFO]: Epoch 060 - training loss: 0.1833, validation loss: 0.0777
2024-06-02 21:14:57 [INFO]: Epoch 061 - training loss: 0.1819, validation loss: 0.0817
2024-06-02 21:14:58 [INFO]: Epoch 062 - training loss: 0.1865, validation loss: 0.0840
2024-06-02 21:14:58 [INFO]: Epoch 063 - training loss: 0.1792, validation loss: 0.0758
2024-06-02 21:14:59 [INFO]: Epoch 064 - training loss: 0.1903, validation loss: 0.0839
2024-06-02 21:15:00 [INFO]: Epoch 065 - training loss: 0.1903, validation loss: 0.0846
2024-06-02 21:15:01 [INFO]: Epoch 066 - training loss: 0.1823, validation loss: 0.0812
2024-06-02 21:15:01 [INFO]: Epoch 067 - training loss: 0.1845, validation loss: 0.0769
2024-06-02 21:15:02 [INFO]: Epoch 068 - training loss: 0.1793, validation loss: 0.0771
2024-06-02 21:15:03 [INFO]: Epoch 069 - training loss: 0.1787, validation loss: 0.0826
2024-06-02 21:15:04 [INFO]: Epoch 070 - training loss: 0.1823, validation loss: 0.0843
2024-06-02 21:15:05 [INFO]: Epoch 071 - training loss: 0.1744, validation loss: 0.0767
2024-06-02 21:15:05 [INFO]: Epoch 072 - training loss: 0.1787, validation loss: 0.0795
2024-06-02 21:15:06 [INFO]: Epoch 073 - training loss: 0.1717, validation loss: 0.0778
2024-06-02 21:15:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:15:06 [INFO]: Finished training. The best model is from epoch#63.
2024-06-02 21:15:06 [INFO]: Saved the model to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_3/20240602_T211408/Transformer.pypots
2024-06-02 21:15:06 [INFO]: Successfully saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_3/imputation.pkl
2024-06-02 21:15:06 [INFO]: Round3 - Transformer on ItalyAir: MAE=0.1995, MSE=0.1028, MRE=0.2693
2024-06-02 21:15:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 21:15:06 [INFO]: Using the given device: cuda:0
2024-06-02 21:15:06 [INFO]: Model files will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_4/20240602_T211506
2024-06-02 21:15:06 [INFO]: Tensorboard file will be saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_4/20240602_T211506/tensorboard
2024-06-02 21:15:06 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=2, d_k=256
2024-06-02 21:15:06 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (2) * d_k (256)
2024-06-02 21:15:07 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 4,749,837
2024-06-02 21:15:07 [INFO]: Epoch 001 - training loss: 1.0652, validation loss: 1.1069
2024-06-02 21:15:08 [INFO]: Epoch 002 - training loss: 0.6764, validation loss: 0.7296
2024-06-02 21:15:09 [INFO]: Epoch 003 - training loss: 0.5415, validation loss: 0.4344
2024-06-02 21:15:10 [INFO]: Epoch 004 - training loss: 0.4571, validation loss: 0.2880
2024-06-02 21:15:10 [INFO]: Epoch 005 - training loss: 0.4067, validation loss: 0.2170
2024-06-02 21:15:11 [INFO]: Epoch 006 - training loss: 0.3744, validation loss: 0.1774
2024-06-02 21:15:12 [INFO]: Epoch 007 - training loss: 0.3565, validation loss: 0.1527
2024-06-02 21:15:13 [INFO]: Epoch 008 - training loss: 0.3396, validation loss: 0.1624
2024-06-02 21:15:14 [INFO]: Epoch 009 - training loss: 0.3294, validation loss: 0.1594
2024-06-02 21:15:15 [INFO]: Epoch 010 - training loss: 0.3162, validation loss: 0.1353
2024-06-02 21:15:15 [INFO]: Epoch 011 - training loss: 0.3137, validation loss: 0.1354
2024-06-02 21:15:16 [INFO]: Epoch 012 - training loss: 0.3028, validation loss: 0.1372
2024-06-02 21:15:17 [INFO]: Epoch 013 - training loss: 0.2936, validation loss: 0.1240
2024-06-02 21:15:18 [INFO]: Epoch 014 - training loss: 0.2910, validation loss: 0.1275
2024-06-02 21:15:19 [INFO]: Epoch 015 - training loss: 0.2828, validation loss: 0.1138
2024-06-02 21:15:19 [INFO]: Epoch 016 - training loss: 0.2808, validation loss: 0.1197
2024-06-02 21:15:20 [INFO]: Epoch 017 - training loss: 0.2721, validation loss: 0.1205
2024-06-02 21:15:21 [INFO]: Epoch 018 - training loss: 0.2706, validation loss: 0.1135
2024-06-02 21:15:22 [INFO]: Epoch 019 - training loss: 0.2658, validation loss: 0.1064
2024-06-02 21:15:23 [INFO]: Epoch 020 - training loss: 0.2576, validation loss: 0.1149
2024-06-02 21:15:23 [INFO]: Epoch 021 - training loss: 0.2611, validation loss: 0.1071
2024-06-02 21:15:24 [INFO]: Epoch 022 - training loss: 0.2551, validation loss: 0.1107
2024-06-02 21:15:25 [INFO]: Epoch 023 - training loss: 0.2502, validation loss: 0.1080
2024-06-02 21:15:26 [INFO]: Epoch 024 - training loss: 0.2479, validation loss: 0.1105
2024-06-02 21:15:27 [INFO]: Epoch 025 - training loss: 0.2446, validation loss: 0.0981
2024-06-02 21:15:28 [INFO]: Epoch 026 - training loss: 0.2363, validation loss: 0.1059
2024-06-02 21:15:29 [INFO]: Epoch 027 - training loss: 0.2406, validation loss: 0.1030
2024-06-02 21:15:30 [INFO]: Epoch 028 - training loss: 0.2415, validation loss: 0.1033
2024-06-02 21:15:30 [INFO]: Epoch 029 - training loss: 0.2380, validation loss: 0.1078
2024-06-02 21:15:31 [INFO]: Epoch 030 - training loss: 0.2362, validation loss: 0.1026
2024-06-02 21:15:32 [INFO]: Epoch 031 - training loss: 0.2281, validation loss: 0.1008
2024-06-02 21:15:33 [INFO]: Epoch 032 - training loss: 0.2243, validation loss: 0.0925
2024-06-02 21:15:34 [INFO]: Epoch 033 - training loss: 0.2226, validation loss: 0.0910
2024-06-02 21:15:35 [INFO]: Epoch 034 - training loss: 0.2182, validation loss: 0.0991
2024-06-02 21:15:36 [INFO]: Epoch 035 - training loss: 0.2230, validation loss: 0.0888
2024-06-02 21:15:37 [INFO]: Epoch 036 - training loss: 0.2185, validation loss: 0.0940
2024-06-02 21:15:38 [INFO]: Epoch 037 - training loss: 0.2101, validation loss: 0.0870
2024-06-02 21:15:38 [INFO]: Epoch 038 - training loss: 0.2033, validation loss: 0.0915
2024-06-02 21:15:39 [INFO]: Epoch 039 - training loss: 0.2052, validation loss: 0.0909
2024-06-02 21:15:40 [INFO]: Epoch 040 - training loss: 0.2076, validation loss: 0.0965
2024-06-02 21:15:41 [INFO]: Epoch 041 - training loss: 0.2060, validation loss: 0.0932
2024-06-02 21:15:42 [INFO]: Epoch 042 - training loss: 0.2057, validation loss: 0.0859
2024-06-02 21:15:43 [INFO]: Epoch 043 - training loss: 0.2028, validation loss: 0.0944
2024-06-02 21:15:43 [INFO]: Epoch 044 - training loss: 0.2007, validation loss: 0.0827
2024-06-02 21:15:44 [INFO]: Epoch 045 - training loss: 0.2015, validation loss: 0.0895
2024-06-02 21:15:45 [INFO]: Epoch 046 - training loss: 0.2001, validation loss: 0.0834
2024-06-02 21:15:46 [INFO]: Epoch 047 - training loss: 0.2055, validation loss: 0.0881
2024-06-02 21:15:46 [INFO]: Epoch 048 - training loss: 0.2029, validation loss: 0.0831
2024-06-02 21:15:47 [INFO]: Epoch 049 - training loss: 0.2030, validation loss: 0.0863
2024-06-02 21:15:47 [INFO]: Epoch 050 - training loss: 0.2073, validation loss: 0.0884
2024-06-02 21:15:48 [INFO]: Epoch 051 - training loss: 0.1990, validation loss: 0.0809
2024-06-02 21:15:49 [INFO]: Epoch 052 - training loss: 0.1993, validation loss: 0.0883
2024-06-02 21:15:50 [INFO]: Epoch 053 - training loss: 0.2077, validation loss: 0.0785
2024-06-02 21:15:50 [INFO]: Epoch 054 - training loss: 0.1907, validation loss: 0.0873
2024-06-02 21:15:51 [INFO]: Epoch 055 - training loss: 0.1907, validation loss: 0.0798
2024-06-02 21:15:51 [INFO]: Epoch 056 - training loss: 0.1908, validation loss: 0.0818
2024-06-02 21:15:52 [INFO]: Epoch 057 - training loss: 0.1909, validation loss: 0.0854
2024-06-02 21:15:53 [INFO]: Epoch 058 - training loss: 0.1924, validation loss: 0.0827
2024-06-02 21:15:53 [INFO]: Epoch 059 - training loss: 0.1895, validation loss: 0.0834
2024-06-02 21:15:54 [INFO]: Epoch 060 - training loss: 0.1841, validation loss: 0.0877
2024-06-02 21:15:55 [INFO]: Epoch 061 - training loss: 0.1863, validation loss: 0.0782
2024-06-02 21:15:56 [INFO]: Epoch 062 - training loss: 0.1836, validation loss: 0.0884
2024-06-02 21:15:56 [INFO]: Epoch 063 - training loss: 0.1810, validation loss: 0.0798
2024-06-02 21:15:57 [INFO]: Epoch 064 - training loss: 0.1803, validation loss: 0.0802
2024-06-02 21:15:57 [INFO]: Epoch 065 - training loss: 0.1844, validation loss: 0.0792
2024-06-02 21:15:58 [INFO]: Epoch 066 - training loss: 0.1812, validation loss: 0.0729
2024-06-02 21:15:59 [INFO]: Epoch 067 - training loss: 0.1794, validation loss: 0.0849
2024-06-02 21:15:59 [INFO]: Epoch 068 - training loss: 0.1777, validation loss: 0.0801
2024-06-02 21:16:00 [INFO]: Epoch 069 - training loss: 0.1783, validation loss: 0.0796
2024-06-02 21:16:00 [INFO]: Epoch 070 - training loss: 0.1737, validation loss: 0.0731
2024-06-02 21:16:01 [INFO]: Epoch 071 - training loss: 0.1741, validation loss: 0.0775
2024-06-02 21:16:01 [INFO]: Epoch 072 - training loss: 0.1809, validation loss: 0.0780
2024-06-02 21:16:02 [INFO]: Epoch 073 - training loss: 0.1878, validation loss: 0.0843
2024-06-02 21:16:03 [INFO]: Epoch 074 - training loss: 0.1856, validation loss: 0.0776
2024-06-02 21:16:04 [INFO]: Epoch 075 - training loss: 0.1706, validation loss: 0.0715
2024-06-02 21:16:04 [INFO]: Epoch 076 - training loss: 0.1732, validation loss: 0.0847
2024-06-02 21:16:05 [INFO]: Epoch 077 - training loss: 0.1712, validation loss: 0.0797
2024-06-02 21:16:06 [INFO]: Epoch 078 - training loss: 0.1723, validation loss: 0.0799
2024-06-02 21:16:06 [INFO]: Epoch 079 - training loss: 0.1701, validation loss: 0.0725
2024-06-02 21:16:07 [INFO]: Epoch 080 - training loss: 0.1724, validation loss: 0.0788
2024-06-02 21:16:08 [INFO]: Epoch 081 - training loss: 0.1696, validation loss: 0.0776
2024-06-02 21:16:08 [INFO]: Epoch 082 - training loss: 0.1687, validation loss: 0.0729
2024-06-02 21:16:09 [INFO]: Epoch 083 - training loss: 0.1634, validation loss: 0.0774
2024-06-02 21:16:10 [INFO]: Epoch 084 - training loss: 0.1643, validation loss: 0.0748
2024-06-02 21:16:10 [INFO]: Epoch 085 - training loss: 0.1657, validation loss: 0.0740
2024-06-02 21:16:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:16:10 [INFO]: Finished training. The best model is from epoch#75.
2024-06-02 21:16:10 [INFO]: Saved the model to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_4/20240602_T211506/Transformer.pypots
2024-06-02 21:16:11 [INFO]: Successfully saved to results_point_rate01/ItalyAir/Transformer_ItalyAir/round_4/imputation.pkl
2024-06-02 21:16:11 [INFO]: Round4 - Transformer on ItalyAir: MAE=0.1729, MSE=0.0935, MRE=0.2333
2024-06-02 21:16:11 [INFO]: Done! Final results:
Averaged Transformer (4,749,837 params) on ItalyAir: MAE=0.1911 ± 0.009664367118375202, MSE=0.1013 ± 0.004423660668627656, MRE=0.2580 ± 0.013045234526423173, average inference time=0.07
