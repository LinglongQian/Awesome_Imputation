2024-06-02 18:54:01 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 18:54:01 [INFO]: Using the given device: cuda:0
2024-06-02 18:54:01 [INFO]: Model files will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_0/20240602_T185401
2024-06-02 18:54:01 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_0/20240602_T185401/tensorboard
2024-06-02 18:54:02 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 9,467,304
2024-06-02 18:54:15 [INFO]: Epoch 001 - training loss: 0.4038, validation loss: 2.7400
2024-06-02 18:54:21 [INFO]: Epoch 002 - training loss: 0.2133, validation loss: 2.5570
2024-06-02 18:54:27 [INFO]: Epoch 003 - training loss: 0.1776, validation loss: 2.4547
2024-06-02 18:54:32 [INFO]: Epoch 004 - training loss: 0.1575, validation loss: 2.3796
2024-06-02 18:54:37 [INFO]: Epoch 005 - training loss: 0.1444, validation loss: 2.3123
2024-06-02 18:54:43 [INFO]: Epoch 006 - training loss: 0.1346, validation loss: 2.2550
2024-06-02 18:54:48 [INFO]: Epoch 007 - training loss: 0.1273, validation loss: 2.2050
2024-06-02 18:54:54 [INFO]: Epoch 008 - training loss: 0.1212, validation loss: 2.1651
2024-06-02 18:54:59 [INFO]: Epoch 009 - training loss: 0.1165, validation loss: 2.1302
2024-06-02 18:55:04 [INFO]: Epoch 010 - training loss: 0.1124, validation loss: 2.0990
2024-06-02 18:55:10 [INFO]: Epoch 011 - training loss: 0.1091, validation loss: 2.0676
2024-06-02 18:55:15 [INFO]: Epoch 012 - training loss: 0.1059, validation loss: 2.0391
2024-06-02 18:55:21 [INFO]: Epoch 013 - training loss: 0.1032, validation loss: 2.0199
2024-06-02 18:55:26 [INFO]: Epoch 014 - training loss: 0.1007, validation loss: 1.9921
2024-06-02 18:55:32 [INFO]: Epoch 015 - training loss: 0.0987, validation loss: 1.9760
2024-06-02 18:55:37 [INFO]: Epoch 016 - training loss: 0.0967, validation loss: 1.9566
2024-06-02 18:55:43 [INFO]: Epoch 017 - training loss: 0.0949, validation loss: 1.9411
2024-06-02 18:55:48 [INFO]: Epoch 018 - training loss: 0.0933, validation loss: 1.9233
2024-06-02 18:55:54 [INFO]: Epoch 019 - training loss: 0.0917, validation loss: 1.9109
2024-06-02 18:55:59 [INFO]: Epoch 020 - training loss: 0.0902, validation loss: 1.9011
2024-06-02 18:56:04 [INFO]: Epoch 021 - training loss: 0.0890, validation loss: 1.8889
2024-06-02 18:56:10 [INFO]: Epoch 022 - training loss: 0.0877, validation loss: 1.8779
2024-06-02 18:56:15 [INFO]: Epoch 023 - training loss: 0.0867, validation loss: 1.8672
2024-06-02 18:56:20 [INFO]: Epoch 024 - training loss: 0.0857, validation loss: 1.8617
2024-06-02 18:56:26 [INFO]: Epoch 025 - training loss: 0.0846, validation loss: 1.8520
2024-06-02 18:56:31 [INFO]: Epoch 026 - training loss: 0.0837, validation loss: 1.8431
2024-06-02 18:56:37 [INFO]: Epoch 027 - training loss: 0.0829, validation loss: 1.8355
2024-06-02 18:56:42 [INFO]: Epoch 028 - training loss: 0.0821, validation loss: 1.8283
2024-06-02 18:56:48 [INFO]: Epoch 029 - training loss: 0.0812, validation loss: 1.8240
2024-06-02 18:56:54 [INFO]: Epoch 030 - training loss: 0.0804, validation loss: 1.8178
2024-06-02 18:56:59 [INFO]: Epoch 031 - training loss: 0.0797, validation loss: 1.8131
2024-06-02 18:57:05 [INFO]: Epoch 032 - training loss: 0.0791, validation loss: 1.8069
2024-06-02 18:57:10 [INFO]: Epoch 033 - training loss: 0.0783, validation loss: 1.8020
2024-06-02 18:57:16 [INFO]: Epoch 034 - training loss: 0.0776, validation loss: 1.7968
2024-06-02 18:57:21 [INFO]: Epoch 035 - training loss: 0.0770, validation loss: 1.7947
2024-06-02 18:57:26 [INFO]: Epoch 036 - training loss: 0.0768, validation loss: 1.7855
2024-06-02 18:57:32 [INFO]: Epoch 037 - training loss: 0.0771, validation loss: 1.7868
2024-06-02 18:57:38 [INFO]: Epoch 038 - training loss: 0.0756, validation loss: 1.7840
2024-06-02 18:57:43 [INFO]: Epoch 039 - training loss: 0.0749, validation loss: 1.7803
2024-06-02 18:57:49 [INFO]: Epoch 040 - training loss: 0.0744, validation loss: 1.7760
2024-06-02 18:57:54 [INFO]: Epoch 041 - training loss: 0.0739, validation loss: 1.7768
2024-06-02 18:57:59 [INFO]: Epoch 042 - training loss: 0.0734, validation loss: 1.7715
2024-06-02 18:58:05 [INFO]: Epoch 043 - training loss: 0.0729, validation loss: 1.7712
2024-06-02 18:58:11 [INFO]: Epoch 044 - training loss: 0.0725, validation loss: 1.7674
2024-06-02 18:58:16 [INFO]: Epoch 045 - training loss: 0.0720, validation loss: 1.7623
2024-06-02 18:58:21 [INFO]: Epoch 046 - training loss: 0.0717, validation loss: 1.7622
2024-06-02 18:58:27 [INFO]: Epoch 047 - training loss: 0.0712, validation loss: 1.7615
2024-06-02 18:58:32 [INFO]: Epoch 048 - training loss: 0.0707, validation loss: 1.7605
2024-06-02 18:58:38 [INFO]: Epoch 049 - training loss: 0.0702, validation loss: 1.7567
2024-06-02 18:58:43 [INFO]: Epoch 050 - training loss: 0.0698, validation loss: 1.7568
2024-06-02 18:58:48 [INFO]: Epoch 051 - training loss: 0.0695, validation loss: 1.7533
2024-06-02 18:58:54 [INFO]: Epoch 052 - training loss: 0.0690, validation loss: 1.7532
2024-06-02 18:59:00 [INFO]: Epoch 053 - training loss: 0.0688, validation loss: 1.7538
2024-06-02 18:59:05 [INFO]: Epoch 054 - training loss: 0.0683, validation loss: 1.7484
2024-06-02 18:59:10 [INFO]: Epoch 055 - training loss: 0.0694, validation loss: 1.7520
2024-06-02 18:59:16 [INFO]: Epoch 056 - training loss: 0.0680, validation loss: 1.7544
2024-06-02 18:59:21 [INFO]: Epoch 057 - training loss: 0.0673, validation loss: 1.7506
2024-06-02 18:59:26 [INFO]: Epoch 058 - training loss: 0.0670, validation loss: 1.7489
2024-06-02 18:59:32 [INFO]: Epoch 059 - training loss: 0.0667, validation loss: 1.7469
2024-06-02 18:59:37 [INFO]: Epoch 060 - training loss: 0.0665, validation loss: 1.7479
2024-06-02 18:59:43 [INFO]: Epoch 061 - training loss: 0.0664, validation loss: 1.7459
2024-06-02 18:59:49 [INFO]: Epoch 062 - training loss: 0.0658, validation loss: 1.7441
2024-06-02 18:59:54 [INFO]: Epoch 063 - training loss: 0.0655, validation loss: 1.7468
2024-06-02 18:59:59 [INFO]: Epoch 064 - training loss: 0.0651, validation loss: 1.7402
2024-06-02 19:00:05 [INFO]: Epoch 065 - training loss: 0.0649, validation loss: 1.7469
2024-06-02 19:00:10 [INFO]: Epoch 066 - training loss: 0.0646, validation loss: 1.7461
2024-06-02 19:00:16 [INFO]: Epoch 067 - training loss: 0.0641, validation loss: 1.7446
2024-06-02 19:00:21 [INFO]: Epoch 068 - training loss: 0.0639, validation loss: 1.7475
2024-06-02 19:00:27 [INFO]: Epoch 069 - training loss: 0.0637, validation loss: 1.7459
2024-06-02 19:00:32 [INFO]: Epoch 070 - training loss: 0.0634, validation loss: 1.7441
2024-06-02 19:00:37 [INFO]: Epoch 071 - training loss: 0.0631, validation loss: 1.7468
2024-06-02 19:00:43 [INFO]: Epoch 072 - training loss: 0.0637, validation loss: 1.7479
2024-06-02 19:00:48 [INFO]: Epoch 073 - training loss: 0.0638, validation loss: 1.7470
2024-06-02 19:00:54 [INFO]: Epoch 074 - training loss: 0.0628, validation loss: 1.7451
2024-06-02 19:00:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:00:54 [INFO]: Finished training. The best model is from epoch#64.
2024-06-02 19:00:54 [INFO]: Saved the model to results_point_rate01/Electricity/GRUD_Electricity/round_0/20240602_T185401/GRUD.pypots
2024-06-02 19:00:56 [INFO]: Successfully saved to results_point_rate01/Electricity/GRUD_Electricity/round_0/imputation.pkl
2024-06-02 19:00:56 [INFO]: Round0 - GRUD on Electricity: MAE=0.9659, MSE=1.8249, MRE=0.5167
2024-06-02 19:00:56 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:00:56 [INFO]: Using the given device: cuda:0
2024-06-02 19:00:56 [INFO]: Model files will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_1/20240602_T190056
2024-06-02 19:00:56 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_1/20240602_T190056/tensorboard
2024-06-02 19:00:56 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 9,467,304
2024-06-02 19:01:09 [INFO]: Epoch 001 - training loss: 0.4083, validation loss: 2.7573
2024-06-02 19:01:14 [INFO]: Epoch 002 - training loss: 0.2148, validation loss: 2.5649
2024-06-02 19:01:19 [INFO]: Epoch 003 - training loss: 0.1780, validation loss: 2.4615
2024-06-02 19:01:25 [INFO]: Epoch 004 - training loss: 0.1584, validation loss: 2.3874
2024-06-02 19:01:30 [INFO]: Epoch 005 - training loss: 0.1444, validation loss: 2.3161
2024-06-02 19:01:35 [INFO]: Epoch 006 - training loss: 0.1348, validation loss: 2.2572
2024-06-02 19:01:40 [INFO]: Epoch 007 - training loss: 0.1271, validation loss: 2.2110
2024-06-02 19:01:46 [INFO]: Epoch 008 - training loss: 0.1212, validation loss: 2.1689
2024-06-02 19:01:51 [INFO]: Epoch 009 - training loss: 0.1164, validation loss: 2.1338
2024-06-02 19:01:56 [INFO]: Epoch 010 - training loss: 0.1121, validation loss: 2.1033
2024-06-02 19:02:02 [INFO]: Epoch 011 - training loss: 0.1086, validation loss: 2.0737
2024-06-02 19:02:08 [INFO]: Epoch 012 - training loss: 0.1056, validation loss: 2.0460
2024-06-02 19:02:13 [INFO]: Epoch 013 - training loss: 0.1030, validation loss: 2.0213
2024-06-02 19:02:18 [INFO]: Epoch 014 - training loss: 0.1006, validation loss: 2.0004
2024-06-02 19:02:24 [INFO]: Epoch 015 - training loss: 0.0983, validation loss: 1.9800
2024-06-02 19:02:29 [INFO]: Epoch 016 - training loss: 0.0964, validation loss: 1.9664
2024-06-02 19:02:34 [INFO]: Epoch 017 - training loss: 0.0947, validation loss: 1.9510
2024-06-02 19:02:40 [INFO]: Epoch 018 - training loss: 0.0930, validation loss: 1.9391
2024-06-02 19:02:45 [INFO]: Epoch 019 - training loss: 0.0917, validation loss: 1.9266
2024-06-02 19:02:51 [INFO]: Epoch 020 - training loss: 0.0901, validation loss: 1.9134
2024-06-02 19:02:56 [INFO]: Epoch 021 - training loss: 0.0889, validation loss: 1.9018
2024-06-02 19:03:02 [INFO]: Epoch 022 - training loss: 0.0876, validation loss: 1.8918
2024-06-02 19:03:07 [INFO]: Epoch 023 - training loss: 0.0865, validation loss: 1.8870
2024-06-02 19:03:13 [INFO]: Epoch 024 - training loss: 0.0855, validation loss: 1.8735
2024-06-02 19:03:18 [INFO]: Epoch 025 - training loss: 0.0845, validation loss: 1.8670
2024-06-02 19:03:24 [INFO]: Epoch 026 - training loss: 0.0836, validation loss: 1.8605
2024-06-02 19:03:29 [INFO]: Epoch 027 - training loss: 0.0828, validation loss: 1.8560
2024-06-02 19:03:34 [INFO]: Epoch 028 - training loss: 0.0820, validation loss: 1.8477
2024-06-02 19:03:40 [INFO]: Epoch 029 - training loss: 0.0810, validation loss: 1.8426
2024-06-02 19:03:45 [INFO]: Epoch 030 - training loss: 0.0803, validation loss: 1.8343
2024-06-02 19:03:50 [INFO]: Epoch 031 - training loss: 0.0796, validation loss: 1.8288
2024-06-02 19:03:56 [INFO]: Epoch 032 - training loss: 0.0789, validation loss: 1.8252
2024-06-02 19:04:02 [INFO]: Epoch 033 - training loss: 0.0783, validation loss: 1.8179
2024-06-02 19:04:07 [INFO]: Epoch 034 - training loss: 0.0775, validation loss: 1.8157
2024-06-02 19:04:12 [INFO]: Epoch 035 - training loss: 0.0771, validation loss: 1.8081
2024-06-02 19:04:18 [INFO]: Epoch 036 - training loss: 0.0767, validation loss: 1.8066
2024-06-02 19:04:23 [INFO]: Epoch 037 - training loss: 0.0764, validation loss: 1.8005
2024-06-02 19:04:29 [INFO]: Epoch 038 - training loss: 0.0754, validation loss: 1.7999
2024-06-02 19:04:34 [INFO]: Epoch 039 - training loss: 0.0750, validation loss: 1.7919
2024-06-02 19:04:39 [INFO]: Epoch 040 - training loss: 0.0743, validation loss: 1.7889
2024-06-02 19:04:45 [INFO]: Epoch 041 - training loss: 0.0737, validation loss: 1.7888
2024-06-02 19:04:50 [INFO]: Epoch 042 - training loss: 0.0733, validation loss: 1.7817
2024-06-02 19:04:55 [INFO]: Epoch 043 - training loss: 0.0729, validation loss: 1.7819
2024-06-02 19:05:01 [INFO]: Epoch 044 - training loss: 0.0726, validation loss: 1.7798
2024-06-02 19:05:07 [INFO]: Epoch 045 - training loss: 0.0721, validation loss: 1.7772
2024-06-02 19:05:12 [INFO]: Epoch 046 - training loss: 0.0717, validation loss: 1.7707
2024-06-02 19:05:18 [INFO]: Epoch 047 - training loss: 0.0712, validation loss: 1.7689
2024-06-02 19:05:23 [INFO]: Epoch 048 - training loss: 0.0706, validation loss: 1.7719
2024-06-02 19:05:29 [INFO]: Epoch 049 - training loss: 0.0703, validation loss: 1.7676
2024-06-02 19:05:34 [INFO]: Epoch 050 - training loss: 0.0700, validation loss: 1.7673
2024-06-02 19:05:39 [INFO]: Epoch 051 - training loss: 0.0697, validation loss: 1.7648
2024-06-02 19:05:44 [INFO]: Epoch 052 - training loss: 0.0693, validation loss: 1.7587
2024-06-02 19:05:50 [INFO]: Epoch 053 - training loss: 0.0687, validation loss: 1.7613
2024-06-02 19:05:55 [INFO]: Epoch 054 - training loss: 0.0683, validation loss: 1.7564
2024-06-02 19:06:00 [INFO]: Epoch 055 - training loss: 0.0679, validation loss: 1.7572
2024-06-02 19:06:06 [INFO]: Epoch 056 - training loss: 0.0675, validation loss: 1.7552
2024-06-02 19:06:11 [INFO]: Epoch 057 - training loss: 0.0673, validation loss: 1.7524
2024-06-02 19:06:16 [INFO]: Epoch 058 - training loss: 0.0671, validation loss: 1.7514
2024-06-02 19:06:22 [INFO]: Epoch 059 - training loss: 0.0666, validation loss: 1.7523
2024-06-02 19:06:27 [INFO]: Epoch 060 - training loss: 0.0662, validation loss: 1.7498
2024-06-02 19:06:32 [INFO]: Epoch 061 - training loss: 0.0661, validation loss: 1.7492
2024-06-02 19:06:37 [INFO]: Epoch 062 - training loss: 0.0659, validation loss: 1.7480
2024-06-02 19:06:43 [INFO]: Epoch 063 - training loss: 0.0654, validation loss: 1.7452
2024-06-02 19:06:48 [INFO]: Epoch 064 - training loss: 0.0670, validation loss: 1.7464
2024-06-02 19:06:54 [INFO]: Epoch 065 - training loss: 0.0651, validation loss: 1.7423
2024-06-02 19:06:59 [INFO]: Epoch 066 - training loss: 0.0644, validation loss: 1.7449
2024-06-02 19:07:04 [INFO]: Epoch 067 - training loss: 0.0639, validation loss: 1.7410
2024-06-02 19:07:10 [INFO]: Epoch 068 - training loss: 0.0637, validation loss: 1.7454
2024-06-02 19:07:15 [INFO]: Epoch 069 - training loss: 0.0635, validation loss: 1.7416
2024-06-02 19:07:20 [INFO]: Epoch 070 - training loss: 0.0635, validation loss: 1.7421
2024-06-02 19:07:26 [INFO]: Epoch 071 - training loss: 0.0632, validation loss: 1.7409
2024-06-02 19:07:31 [INFO]: Epoch 072 - training loss: 0.0628, validation loss: 1.7438
2024-06-02 19:07:36 [INFO]: Epoch 073 - training loss: 0.0626, validation loss: 1.7425
2024-06-02 19:07:42 [INFO]: Epoch 074 - training loss: 0.0623, validation loss: 1.7417
2024-06-02 19:07:47 [INFO]: Epoch 075 - training loss: 0.0620, validation loss: 1.7431
2024-06-02 19:07:53 [INFO]: Epoch 076 - training loss: 0.0618, validation loss: 1.7429
2024-06-02 19:07:58 [INFO]: Epoch 077 - training loss: 0.0616, validation loss: 1.7407
2024-06-02 19:08:03 [INFO]: Epoch 078 - training loss: 0.0615, validation loss: 1.7392
2024-06-02 19:08:08 [INFO]: Epoch 079 - training loss: 0.0610, validation loss: 1.7360
2024-06-02 19:08:14 [INFO]: Epoch 080 - training loss: 0.0608, validation loss: 1.7392
2024-06-02 19:08:19 [INFO]: Epoch 081 - training loss: 0.0606, validation loss: 1.7388
2024-06-02 19:08:25 [INFO]: Epoch 082 - training loss: 0.0603, validation loss: 1.7385
2024-06-02 19:08:30 [INFO]: Epoch 083 - training loss: 0.0601, validation loss: 1.7423
2024-06-02 19:08:35 [INFO]: Epoch 084 - training loss: 0.0600, validation loss: 1.7380
2024-06-02 19:08:41 [INFO]: Epoch 085 - training loss: 0.0597, validation loss: 1.7406
2024-06-02 19:08:47 [INFO]: Epoch 086 - training loss: 0.0605, validation loss: 1.7449
2024-06-02 19:08:52 [INFO]: Epoch 087 - training loss: 0.0598, validation loss: 1.7430
2024-06-02 19:08:57 [INFO]: Epoch 088 - training loss: 0.0591, validation loss: 1.7450
2024-06-02 19:09:03 [INFO]: Epoch 089 - training loss: 0.0588, validation loss: 1.7432
2024-06-02 19:09:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:09:03 [INFO]: Finished training. The best model is from epoch#79.
2024-06-02 19:09:03 [INFO]: Saved the model to results_point_rate01/Electricity/GRUD_Electricity/round_1/20240602_T190056/GRUD.pypots
2024-06-02 19:09:06 [INFO]: Successfully saved to results_point_rate01/Electricity/GRUD_Electricity/round_1/imputation.pkl
2024-06-02 19:09:06 [INFO]: Round1 - GRUD on Electricity: MAE=1.0030, MSE=1.9022, MRE=0.5366
2024-06-02 19:09:06 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:09:06 [INFO]: Using the given device: cuda:0
2024-06-02 19:09:06 [INFO]: Model files will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_2/20240602_T190906
2024-06-02 19:09:06 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_2/20240602_T190906/tensorboard
2024-06-02 19:09:06 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 9,467,304
2024-06-02 19:09:18 [INFO]: Epoch 001 - training loss: 0.4041, validation loss: 2.7585
2024-06-02 19:09:23 [INFO]: Epoch 002 - training loss: 0.2132, validation loss: 2.5702
2024-06-02 19:09:28 [INFO]: Epoch 003 - training loss: 0.1765, validation loss: 2.4609
2024-06-02 19:09:34 [INFO]: Epoch 004 - training loss: 0.1570, validation loss: 2.3761
2024-06-02 19:09:39 [INFO]: Epoch 005 - training loss: 0.1438, validation loss: 2.3172
2024-06-02 19:09:45 [INFO]: Epoch 006 - training loss: 0.1340, validation loss: 2.2673
2024-06-02 19:09:50 [INFO]: Epoch 007 - training loss: 0.1266, validation loss: 2.2214
2024-06-02 19:09:55 [INFO]: Epoch 008 - training loss: 0.1210, validation loss: 2.1799
2024-06-02 19:10:01 [INFO]: Epoch 009 - training loss: 0.1161, validation loss: 2.1419
2024-06-02 19:10:06 [INFO]: Epoch 010 - training loss: 0.1119, validation loss: 2.1117
2024-06-02 19:10:11 [INFO]: Epoch 011 - training loss: 0.1085, validation loss: 2.0788
2024-06-02 19:10:17 [INFO]: Epoch 012 - training loss: 0.1053, validation loss: 2.0526
2024-06-02 19:10:23 [INFO]: Epoch 013 - training loss: 0.1027, validation loss: 2.0265
2024-06-02 19:10:28 [INFO]: Epoch 014 - training loss: 0.1003, validation loss: 2.0062
2024-06-02 19:10:33 [INFO]: Epoch 015 - training loss: 0.0982, validation loss: 1.9806
2024-06-02 19:10:38 [INFO]: Epoch 016 - training loss: 0.0964, validation loss: 1.9629
2024-06-02 19:10:44 [INFO]: Epoch 017 - training loss: 0.0944, validation loss: 1.9461
2024-06-02 19:10:49 [INFO]: Epoch 018 - training loss: 0.0928, validation loss: 1.9335
2024-06-02 19:10:54 [INFO]: Epoch 019 - training loss: 0.0913, validation loss: 1.9169
2024-06-02 19:11:00 [INFO]: Epoch 020 - training loss: 0.0898, validation loss: 1.9049
2024-06-02 19:11:05 [INFO]: Epoch 021 - training loss: 0.0886, validation loss: 1.8932
2024-06-02 19:11:10 [INFO]: Epoch 022 - training loss: 0.0876, validation loss: 1.8848
2024-06-02 19:11:16 [INFO]: Epoch 023 - training loss: 0.0864, validation loss: 1.8740
2024-06-02 19:11:21 [INFO]: Epoch 024 - training loss: 0.0852, validation loss: 1.8632
2024-06-02 19:11:26 [INFO]: Epoch 025 - training loss: 0.0845, validation loss: 1.8541
2024-06-02 19:11:32 [INFO]: Epoch 026 - training loss: 0.0835, validation loss: 1.8463
2024-06-02 19:11:37 [INFO]: Epoch 027 - training loss: 0.0826, validation loss: 1.8386
2024-06-02 19:11:42 [INFO]: Epoch 028 - training loss: 0.0819, validation loss: 1.8292
2024-06-02 19:11:48 [INFO]: Epoch 029 - training loss: 0.0811, validation loss: 1.8242
2024-06-02 19:11:53 [INFO]: Epoch 030 - training loss: 0.0801, validation loss: 1.8179
2024-06-02 19:11:58 [INFO]: Epoch 031 - training loss: 0.0794, validation loss: 1.8115
2024-06-02 19:12:03 [INFO]: Epoch 032 - training loss: 0.0786, validation loss: 1.8070
2024-06-02 19:12:09 [INFO]: Epoch 033 - training loss: 0.0781, validation loss: 1.8028
2024-06-02 19:12:14 [INFO]: Epoch 034 - training loss: 0.0775, validation loss: 1.7999
2024-06-02 19:12:20 [INFO]: Epoch 035 - training loss: 0.0769, validation loss: 1.7935
2024-06-02 19:12:26 [INFO]: Epoch 036 - training loss: 0.0763, validation loss: 1.7884
2024-06-02 19:12:31 [INFO]: Epoch 037 - training loss: 0.0758, validation loss: 1.7864
2024-06-02 19:12:37 [INFO]: Epoch 038 - training loss: 0.0752, validation loss: 1.7812
2024-06-02 19:12:43 [INFO]: Epoch 039 - training loss: 0.0752, validation loss: 1.7791
2024-06-02 19:12:48 [INFO]: Epoch 040 - training loss: 0.0743, validation loss: 1.7732
2024-06-02 19:12:53 [INFO]: Epoch 041 - training loss: 0.0740, validation loss: 1.7715
2024-06-02 19:12:59 [INFO]: Epoch 042 - training loss: 0.0733, validation loss: 1.7697
2024-06-02 19:13:04 [INFO]: Epoch 043 - training loss: 0.0729, validation loss: 1.7654
2024-06-02 19:13:10 [INFO]: Epoch 044 - training loss: 0.0724, validation loss: 1.7634
2024-06-02 19:13:15 [INFO]: Epoch 045 - training loss: 0.0720, validation loss: 1.7602
2024-06-02 19:13:21 [INFO]: Epoch 046 - training loss: 0.0716, validation loss: 1.7602
2024-06-02 19:13:26 [INFO]: Epoch 047 - training loss: 0.0709, validation loss: 1.7547
2024-06-02 19:13:32 [INFO]: Epoch 048 - training loss: 0.0704, validation loss: 1.7554
2024-06-02 19:13:37 [INFO]: Epoch 049 - training loss: 0.0703, validation loss: 1.7528
2024-06-02 19:13:43 [INFO]: Epoch 050 - training loss: 0.0699, validation loss: 1.7472
2024-06-02 19:13:48 [INFO]: Epoch 051 - training loss: 0.0694, validation loss: 1.7477
2024-06-02 19:13:53 [INFO]: Epoch 052 - training loss: 0.0689, validation loss: 1.7447
2024-06-02 19:13:59 [INFO]: Epoch 053 - training loss: 0.0686, validation loss: 1.7433
2024-06-02 19:14:04 [INFO]: Epoch 054 - training loss: 0.0683, validation loss: 1.7451
2024-06-02 19:14:09 [INFO]: Epoch 055 - training loss: 0.0681, validation loss: 1.7434
2024-06-02 19:14:15 [INFO]: Epoch 056 - training loss: 0.0698, validation loss: 1.7400
2024-06-02 19:14:20 [INFO]: Epoch 057 - training loss: 0.0679, validation loss: 1.7390
2024-06-02 19:14:26 [INFO]: Epoch 058 - training loss: 0.0671, validation loss: 1.7394
2024-06-02 19:14:31 [INFO]: Epoch 059 - training loss: 0.0667, validation loss: 1.7385
2024-06-02 19:14:37 [INFO]: Epoch 060 - training loss: 0.0662, validation loss: 1.7326
2024-06-02 19:14:42 [INFO]: Epoch 061 - training loss: 0.0658, validation loss: 1.7342
2024-06-02 19:14:48 [INFO]: Epoch 062 - training loss: 0.0655, validation loss: 1.7359
2024-06-02 19:14:53 [INFO]: Epoch 063 - training loss: 0.0654, validation loss: 1.7356
2024-06-02 19:14:58 [INFO]: Epoch 064 - training loss: 0.0651, validation loss: 1.7336
2024-06-02 19:15:04 [INFO]: Epoch 065 - training loss: 0.0649, validation loss: 1.7311
2024-06-02 19:15:09 [INFO]: Epoch 066 - training loss: 0.0647, validation loss: 1.7311
2024-06-02 19:15:15 [INFO]: Epoch 067 - training loss: 0.0645, validation loss: 1.7298
2024-06-02 19:15:20 [INFO]: Epoch 068 - training loss: 0.0640, validation loss: 1.7272
2024-06-02 19:15:25 [INFO]: Epoch 069 - training loss: 0.0637, validation loss: 1.7314
2024-06-02 19:15:31 [INFO]: Epoch 070 - training loss: 0.0634, validation loss: 1.7293
2024-06-02 19:15:36 [INFO]: Epoch 071 - training loss: 0.0630, validation loss: 1.7290
2024-06-02 19:15:41 [INFO]: Epoch 072 - training loss: 0.0628, validation loss: 1.7282
2024-06-02 19:15:47 [INFO]: Epoch 073 - training loss: 0.0626, validation loss: 1.7299
2024-06-02 19:15:52 [INFO]: Epoch 074 - training loss: 0.0624, validation loss: 1.7286
2024-06-02 19:15:58 [INFO]: Epoch 075 - training loss: 0.0620, validation loss: 1.7304
2024-06-02 19:16:03 [INFO]: Epoch 076 - training loss: 0.0617, validation loss: 1.7318
2024-06-02 19:16:09 [INFO]: Epoch 077 - training loss: 0.0614, validation loss: 1.7320
2024-06-02 19:16:14 [INFO]: Epoch 078 - training loss: 0.0614, validation loss: 1.7333
2024-06-02 19:16:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:16:14 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 19:16:14 [INFO]: Saved the model to results_point_rate01/Electricity/GRUD_Electricity/round_2/20240602_T190906/GRUD.pypots
2024-06-02 19:16:17 [INFO]: Successfully saved to results_point_rate01/Electricity/GRUD_Electricity/round_2/imputation.pkl
2024-06-02 19:16:17 [INFO]: Round2 - GRUD on Electricity: MAE=0.9784, MSE=1.8520, MRE=0.5234
2024-06-02 19:16:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:16:17 [INFO]: Using the given device: cuda:0
2024-06-02 19:16:17 [INFO]: Model files will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_3/20240602_T191617
2024-06-02 19:16:17 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_3/20240602_T191617/tensorboard
2024-06-02 19:16:17 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 9,467,304
2024-06-02 19:16:29 [INFO]: Epoch 001 - training loss: 0.4066, validation loss: 2.7224
2024-06-02 19:16:34 [INFO]: Epoch 002 - training loss: 0.2136, validation loss: 2.5457
2024-06-02 19:16:40 [INFO]: Epoch 003 - training loss: 0.1783, validation loss: 2.4452
2024-06-02 19:16:45 [INFO]: Epoch 004 - training loss: 0.1580, validation loss: 2.3601
2024-06-02 19:16:50 [INFO]: Epoch 005 - training loss: 0.1443, validation loss: 2.2989
2024-06-02 19:16:56 [INFO]: Epoch 006 - training loss: 0.1343, validation loss: 2.2434
2024-06-02 19:17:01 [INFO]: Epoch 007 - training loss: 0.1268, validation loss: 2.1974
2024-06-02 19:17:06 [INFO]: Epoch 008 - training loss: 0.1208, validation loss: 2.1587
2024-06-02 19:17:12 [INFO]: Epoch 009 - training loss: 0.1162, validation loss: 2.1237
2024-06-02 19:17:17 [INFO]: Epoch 010 - training loss: 0.1121, validation loss: 2.0901
2024-06-02 19:17:22 [INFO]: Epoch 011 - training loss: 0.1084, validation loss: 2.0642
2024-06-02 19:17:28 [INFO]: Epoch 012 - training loss: 0.1051, validation loss: 2.0352
2024-06-02 19:17:33 [INFO]: Epoch 013 - training loss: 0.1025, validation loss: 2.0124
2024-06-02 19:17:38 [INFO]: Epoch 014 - training loss: 0.1002, validation loss: 1.9889
2024-06-02 19:17:44 [INFO]: Epoch 015 - training loss: 0.0979, validation loss: 1.9713
2024-06-02 19:17:49 [INFO]: Epoch 016 - training loss: 0.0961, validation loss: 1.9557
2024-06-02 19:17:54 [INFO]: Epoch 017 - training loss: 0.0943, validation loss: 1.9395
2024-06-02 19:18:00 [INFO]: Epoch 018 - training loss: 0.0927, validation loss: 1.9232
2024-06-02 19:18:05 [INFO]: Epoch 019 - training loss: 0.0913, validation loss: 1.9116
2024-06-02 19:18:10 [INFO]: Epoch 020 - training loss: 0.0898, validation loss: 1.8991
2024-06-02 19:18:16 [INFO]: Epoch 021 - training loss: 0.0886, validation loss: 1.8900
2024-06-02 19:18:21 [INFO]: Epoch 022 - training loss: 0.0874, validation loss: 1.8763
2024-06-02 19:18:27 [INFO]: Epoch 023 - training loss: 0.0863, validation loss: 1.8686
2024-06-02 19:18:32 [INFO]: Epoch 024 - training loss: 0.0853, validation loss: 1.8604
2024-06-02 19:18:37 [INFO]: Epoch 025 - training loss: 0.0845, validation loss: 1.8542
2024-06-02 19:18:43 [INFO]: Epoch 026 - training loss: 0.0836, validation loss: 1.8449
2024-06-02 19:18:48 [INFO]: Epoch 027 - training loss: 0.0826, validation loss: 1.8353
2024-06-02 19:18:54 [INFO]: Epoch 028 - training loss: 0.0819, validation loss: 1.8304
2024-06-02 19:18:59 [INFO]: Epoch 029 - training loss: 0.0811, validation loss: 1.8255
2024-06-02 19:19:04 [INFO]: Epoch 030 - training loss: 0.0804, validation loss: 1.8220
2024-06-02 19:19:09 [INFO]: Epoch 031 - training loss: 0.0797, validation loss: 1.8167
2024-06-02 19:19:15 [INFO]: Epoch 032 - training loss: 0.0789, validation loss: 1.8117
2024-06-02 19:19:20 [INFO]: Epoch 033 - training loss: 0.0782, validation loss: 1.8060
2024-06-02 19:19:26 [INFO]: Epoch 034 - training loss: 0.0774, validation loss: 1.8009
2024-06-02 19:19:31 [INFO]: Epoch 035 - training loss: 0.0769, validation loss: 1.7967
2024-06-02 19:19:37 [INFO]: Epoch 036 - training loss: 0.0764, validation loss: 1.7936
2024-06-02 19:19:42 [INFO]: Epoch 037 - training loss: 0.0759, validation loss: 1.7883
2024-06-02 19:19:48 [INFO]: Epoch 038 - training loss: 0.0753, validation loss: 1.7862
2024-06-02 19:19:53 [INFO]: Epoch 039 - training loss: 0.0748, validation loss: 1.7824
2024-06-02 19:19:58 [INFO]: Epoch 040 - training loss: 0.0744, validation loss: 1.7784
2024-06-02 19:20:04 [INFO]: Epoch 041 - training loss: 0.0750, validation loss: 1.7770
2024-06-02 19:20:09 [INFO]: Epoch 042 - training loss: 0.0736, validation loss: 1.7717
2024-06-02 19:20:15 [INFO]: Epoch 043 - training loss: 0.0729, validation loss: 1.7725
2024-06-02 19:20:20 [INFO]: Epoch 044 - training loss: 0.0723, validation loss: 1.7699
2024-06-02 19:20:25 [INFO]: Epoch 045 - training loss: 0.0718, validation loss: 1.7660
2024-06-02 19:20:30 [INFO]: Epoch 046 - training loss: 0.0713, validation loss: 1.7619
2024-06-02 19:20:33 [INFO]: Epoch 047 - training loss: 0.0709, validation loss: 1.7598
2024-06-02 19:20:36 [INFO]: Epoch 048 - training loss: 0.0706, validation loss: 1.7593
2024-06-02 19:20:41 [INFO]: Epoch 049 - training loss: 0.0703, validation loss: 1.7585
2024-06-02 19:20:45 [INFO]: Epoch 050 - training loss: 0.0707, validation loss: 1.7562
2024-06-02 19:20:49 [INFO]: Epoch 051 - training loss: 0.0696, validation loss: 1.7529
2024-06-02 19:20:54 [INFO]: Epoch 052 - training loss: 0.0690, validation loss: 1.7538
2024-06-02 19:20:57 [INFO]: Epoch 053 - training loss: 0.0687, validation loss: 1.7503
2024-06-02 19:21:01 [INFO]: Epoch 054 - training loss: 0.0683, validation loss: 1.7513
2024-06-02 19:21:05 [INFO]: Epoch 055 - training loss: 0.0680, validation loss: 1.7505
2024-06-02 19:21:08 [INFO]: Epoch 056 - training loss: 0.0675, validation loss: 1.7444
2024-06-02 19:21:12 [INFO]: Epoch 057 - training loss: 0.0672, validation loss: 1.7462
2024-06-02 19:21:16 [INFO]: Epoch 058 - training loss: 0.0669, validation loss: 1.7446
2024-06-02 19:21:20 [INFO]: Epoch 059 - training loss: 0.0668, validation loss: 1.7447
2024-06-02 19:21:23 [INFO]: Epoch 060 - training loss: 0.0666, validation loss: 1.7404
2024-06-02 19:21:26 [INFO]: Epoch 061 - training loss: 0.0661, validation loss: 1.7393
2024-06-02 19:21:30 [INFO]: Epoch 062 - training loss: 0.0657, validation loss: 1.7360
2024-06-02 19:21:34 [INFO]: Epoch 063 - training loss: 0.0653, validation loss: 1.7358
2024-06-02 19:21:38 [INFO]: Epoch 064 - training loss: 0.0650, validation loss: 1.7383
2024-06-02 19:21:41 [INFO]: Epoch 065 - training loss: 0.0649, validation loss: 1.7346
2024-06-02 19:21:45 [INFO]: Epoch 066 - training loss: 0.0646, validation loss: 1.7389
2024-06-02 19:21:49 [INFO]: Epoch 067 - training loss: 0.0651, validation loss: 1.7365
2024-06-02 19:21:52 [INFO]: Epoch 068 - training loss: 0.0640, validation loss: 1.7364
2024-06-02 19:21:57 [INFO]: Epoch 069 - training loss: 0.0637, validation loss: 1.7357
2024-06-02 19:22:01 [INFO]: Epoch 070 - training loss: 0.0632, validation loss: 1.7338
2024-06-02 19:22:05 [INFO]: Epoch 071 - training loss: 0.0630, validation loss: 1.7346
2024-06-02 19:22:09 [INFO]: Epoch 072 - training loss: 0.0626, validation loss: 1.7312
2024-06-02 19:22:12 [INFO]: Epoch 073 - training loss: 0.0625, validation loss: 1.7293
2024-06-02 19:22:17 [INFO]: Epoch 074 - training loss: 0.0622, validation loss: 1.7318
2024-06-02 19:22:21 [INFO]: Epoch 075 - training loss: 0.0619, validation loss: 1.7321
2024-06-02 19:22:24 [INFO]: Epoch 076 - training loss: 0.0618, validation loss: 1.7296
2024-06-02 19:22:29 [INFO]: Epoch 077 - training loss: 0.0618, validation loss: 1.7290
2024-06-02 19:22:32 [INFO]: Epoch 078 - training loss: 0.0616, validation loss: 1.7347
2024-06-02 19:22:35 [INFO]: Epoch 079 - training loss: 0.0610, validation loss: 1.7300
2024-06-02 19:22:39 [INFO]: Epoch 080 - training loss: 0.0605, validation loss: 1.7280
2024-06-02 19:22:43 [INFO]: Epoch 081 - training loss: 0.0604, validation loss: 1.7288
2024-06-02 19:22:47 [INFO]: Epoch 082 - training loss: 0.0601, validation loss: 1.7309
2024-06-02 19:22:51 [INFO]: Epoch 083 - training loss: 0.0600, validation loss: 1.7281
2024-06-02 19:22:55 [INFO]: Epoch 084 - training loss: 0.0597, validation loss: 1.7346
2024-06-02 19:22:58 [INFO]: Epoch 085 - training loss: 0.0597, validation loss: 1.7297
2024-06-02 19:23:02 [INFO]: Epoch 086 - training loss: 0.0595, validation loss: 1.7320
2024-06-02 19:23:05 [INFO]: Epoch 087 - training loss: 0.0593, validation loss: 1.7319
2024-06-02 19:23:08 [INFO]: Epoch 088 - training loss: 0.0591, validation loss: 1.7355
2024-06-02 19:23:12 [INFO]: Epoch 089 - training loss: 0.0588, validation loss: 1.7335
2024-06-02 19:23:15 [INFO]: Epoch 090 - training loss: 0.0585, validation loss: 1.7340
2024-06-02 19:23:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:23:15 [INFO]: Finished training. The best model is from epoch#80.
2024-06-02 19:23:15 [INFO]: Saved the model to results_point_rate01/Electricity/GRUD_Electricity/round_3/20240602_T191617/GRUD.pypots
2024-06-02 19:23:17 [INFO]: Successfully saved to results_point_rate01/Electricity/GRUD_Electricity/round_3/imputation.pkl
2024-06-02 19:23:17 [INFO]: Round3 - GRUD on Electricity: MAE=0.9721, MSE=1.8509, MRE=0.5200
2024-06-02 19:23:17 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:23:17 [INFO]: Using the given device: cuda:0
2024-06-02 19:23:17 [INFO]: Model files will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_4/20240602_T192317
2024-06-02 19:23:17 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/GRUD_Electricity/round_4/20240602_T192317/tensorboard
2024-06-02 19:23:17 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 9,467,304
2024-06-02 19:23:26 [INFO]: Epoch 001 - training loss: 0.4094, validation loss: 2.7565
2024-06-02 19:23:31 [INFO]: Epoch 002 - training loss: 0.2140, validation loss: 2.5752
2024-06-02 19:23:34 [INFO]: Epoch 003 - training loss: 0.1783, validation loss: 2.4713
2024-06-02 19:23:37 [INFO]: Epoch 004 - training loss: 0.1585, validation loss: 2.3871
2024-06-02 19:23:42 [INFO]: Epoch 005 - training loss: 0.1450, validation loss: 2.3229
2024-06-02 19:23:46 [INFO]: Epoch 006 - training loss: 0.1350, validation loss: 2.2609
2024-06-02 19:23:50 [INFO]: Epoch 007 - training loss: 0.1273, validation loss: 2.2184
2024-06-02 19:23:53 [INFO]: Epoch 008 - training loss: 0.1216, validation loss: 2.1793
2024-06-02 19:23:56 [INFO]: Epoch 009 - training loss: 0.1162, validation loss: 2.1411
2024-06-02 19:23:59 [INFO]: Epoch 010 - training loss: 0.1123, validation loss: 2.1104
2024-06-02 19:24:03 [INFO]: Epoch 011 - training loss: 0.1087, validation loss: 2.0786
2024-06-02 19:24:07 [INFO]: Epoch 012 - training loss: 0.1057, validation loss: 2.0504
2024-06-02 19:24:11 [INFO]: Epoch 013 - training loss: 0.1030, validation loss: 2.0282
2024-06-02 19:24:15 [INFO]: Epoch 014 - training loss: 0.1005, validation loss: 2.0079
2024-06-02 19:24:19 [INFO]: Epoch 015 - training loss: 0.0985, validation loss: 1.9846
2024-06-02 19:24:22 [INFO]: Epoch 016 - training loss: 0.0963, validation loss: 1.9686
2024-06-02 19:24:27 [INFO]: Epoch 017 - training loss: 0.0946, validation loss: 1.9533
2024-06-02 19:24:31 [INFO]: Epoch 018 - training loss: 0.0930, validation loss: 1.9371
2024-06-02 19:24:34 [INFO]: Epoch 019 - training loss: 0.0915, validation loss: 1.9233
2024-06-02 19:24:38 [INFO]: Epoch 020 - training loss: 0.0902, validation loss: 1.9116
2024-06-02 19:24:42 [INFO]: Epoch 021 - training loss: 0.0889, validation loss: 1.9014
2024-06-02 19:24:46 [INFO]: Epoch 022 - training loss: 0.0876, validation loss: 1.8917
2024-06-02 19:24:50 [INFO]: Epoch 023 - training loss: 0.0865, validation loss: 1.8801
2024-06-02 19:24:54 [INFO]: Epoch 024 - training loss: 0.0856, validation loss: 1.8689
2024-06-02 19:24:57 [INFO]: Epoch 025 - training loss: 0.0846, validation loss: 1.8622
2024-06-02 19:25:01 [INFO]: Epoch 026 - training loss: 0.0836, validation loss: 1.8543
2024-06-02 19:25:04 [INFO]: Epoch 027 - training loss: 0.0826, validation loss: 1.8466
2024-06-02 19:25:08 [INFO]: Epoch 028 - training loss: 0.0818, validation loss: 1.8393
2024-06-02 19:25:12 [INFO]: Epoch 029 - training loss: 0.0811, validation loss: 1.8338
2024-06-02 19:25:16 [INFO]: Epoch 030 - training loss: 0.0804, validation loss: 1.8290
2024-06-02 19:25:19 [INFO]: Epoch 031 - training loss: 0.0800, validation loss: 1.8225
2024-06-02 19:25:23 [INFO]: Epoch 032 - training loss: 0.0792, validation loss: 1.8183
2024-06-02 19:25:27 [INFO]: Epoch 033 - training loss: 0.0785, validation loss: 1.8129
2024-06-02 19:25:30 [INFO]: Epoch 034 - training loss: 0.0778, validation loss: 1.8088
2024-06-02 19:25:34 [INFO]: Epoch 035 - training loss: 0.0771, validation loss: 1.8022
2024-06-02 19:25:38 [INFO]: Epoch 036 - training loss: 0.0766, validation loss: 1.7987
2024-06-02 19:25:41 [INFO]: Epoch 037 - training loss: 0.0760, validation loss: 1.7939
2024-06-02 19:25:44 [INFO]: Epoch 038 - training loss: 0.0755, validation loss: 1.7932
2024-06-02 19:25:48 [INFO]: Epoch 039 - training loss: 0.0747, validation loss: 1.7875
2024-06-02 19:25:52 [INFO]: Epoch 040 - training loss: 0.0742, validation loss: 1.7853
2024-06-02 19:25:55 [INFO]: Epoch 041 - training loss: 0.0739, validation loss: 1.7801
2024-06-02 19:25:59 [INFO]: Epoch 042 - training loss: 0.0736, validation loss: 1.7786
2024-06-02 19:26:02 [INFO]: Epoch 043 - training loss: 0.0730, validation loss: 1.7763
2024-06-02 19:26:06 [INFO]: Epoch 044 - training loss: 0.0726, validation loss: 1.7720
2024-06-02 19:26:09 [INFO]: Epoch 045 - training loss: 0.0721, validation loss: 1.7704
2024-06-02 19:26:13 [INFO]: Epoch 046 - training loss: 0.0717, validation loss: 1.7671
2024-06-02 19:26:18 [INFO]: Epoch 047 - training loss: 0.0713, validation loss: 1.7628
2024-06-02 19:26:22 [INFO]: Epoch 048 - training loss: 0.0708, validation loss: 1.7618
2024-06-02 19:26:26 [INFO]: Epoch 049 - training loss: 0.0710, validation loss: 1.7583
2024-06-02 19:26:29 [INFO]: Epoch 050 - training loss: 0.0708, validation loss: 1.7562
2024-06-02 19:26:34 [INFO]: Epoch 051 - training loss: 0.0700, validation loss: 1.7511
2024-06-02 19:26:37 [INFO]: Epoch 052 - training loss: 0.0693, validation loss: 1.7531
2024-06-02 19:26:41 [INFO]: Epoch 053 - training loss: 0.0690, validation loss: 1.7527
2024-06-02 19:26:44 [INFO]: Epoch 054 - training loss: 0.0685, validation loss: 1.7459
2024-06-02 19:26:48 [INFO]: Epoch 055 - training loss: 0.0680, validation loss: 1.7457
2024-06-02 19:26:51 [INFO]: Epoch 056 - training loss: 0.0678, validation loss: 1.7430
2024-06-02 19:26:55 [INFO]: Epoch 057 - training loss: 0.0676, validation loss: 1.7440
2024-06-02 19:26:59 [INFO]: Epoch 058 - training loss: 0.0672, validation loss: 1.7409
2024-06-02 19:27:03 [INFO]: Epoch 059 - training loss: 0.0668, validation loss: 1.7402
2024-06-02 19:27:06 [INFO]: Epoch 060 - training loss: 0.0664, validation loss: 1.7428
2024-06-02 19:27:09 [INFO]: Epoch 061 - training loss: 0.0662, validation loss: 1.7368
2024-06-02 19:27:12 [INFO]: Epoch 062 - training loss: 0.0661, validation loss: 1.7370
2024-06-02 19:27:16 [INFO]: Epoch 063 - training loss: 0.0663, validation loss: 1.7360
2024-06-02 19:27:19 [INFO]: Epoch 064 - training loss: 0.0659, validation loss: 1.7406
2024-06-02 19:27:22 [INFO]: Epoch 065 - training loss: 0.0652, validation loss: 1.7345
2024-06-02 19:27:27 [INFO]: Epoch 066 - training loss: 0.0647, validation loss: 1.7301
2024-06-02 19:27:31 [INFO]: Epoch 067 - training loss: 0.0646, validation loss: 1.7339
2024-06-02 19:27:35 [INFO]: Epoch 068 - training loss: 0.0641, validation loss: 1.7330
2024-06-02 19:27:38 [INFO]: Epoch 069 - training loss: 0.0641, validation loss: 1.7334
2024-06-02 19:27:42 [INFO]: Epoch 070 - training loss: 0.0636, validation loss: 1.7316
2024-06-02 19:27:46 [INFO]: Epoch 071 - training loss: 0.0633, validation loss: 1.7342
2024-06-02 19:27:50 [INFO]: Epoch 072 - training loss: 0.0630, validation loss: 1.7317
2024-06-02 19:27:54 [INFO]: Epoch 073 - training loss: 0.0626, validation loss: 1.7308
2024-06-02 19:27:58 [INFO]: Epoch 074 - training loss: 0.0623, validation loss: 1.7310
2024-06-02 19:28:01 [INFO]: Epoch 075 - training loss: 0.0623, validation loss: 1.7325
2024-06-02 19:28:05 [INFO]: Epoch 076 - training loss: 0.0620, validation loss: 1.7338
2024-06-02 19:28:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:28:05 [INFO]: Finished training. The best model is from epoch#66.
2024-06-02 19:28:05 [INFO]: Saved the model to results_point_rate01/Electricity/GRUD_Electricity/round_4/20240602_T192317/GRUD.pypots
2024-06-02 19:28:07 [INFO]: Successfully saved to results_point_rate01/Electricity/GRUD_Electricity/round_4/imputation.pkl
2024-06-02 19:28:07 [INFO]: Round4 - GRUD on Electricity: MAE=0.9583, MSE=1.8395, MRE=0.5127
2024-06-02 19:28:07 [INFO]: Done! Final results:
Averaged GRUD (9,467,304 params) on Electricity: MAE=0.9755 ± 0.015263343153315196, MSE=1.8539 ± 0.026052258635391477, MRE=0.5219 ± 0.008165177770392593, average inference time=2.14
