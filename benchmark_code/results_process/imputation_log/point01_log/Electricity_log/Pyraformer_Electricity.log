2024-06-02 15:18:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 15:18:58 [INFO]: Using the given device: cuda:0
2024-06-02 15:18:58 [INFO]: Model files will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_0/20240602_T151858
2024-06-02 15:18:58 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_0/20240602_T151858/tensorboard
2024-06-02 15:18:59 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-02 15:19:15 [INFO]: Epoch 001 - training loss: 1.0088, validation loss: 2.8302
2024-06-02 15:19:24 [INFO]: Epoch 002 - training loss: 0.7518, validation loss: 2.6911
2024-06-02 15:19:33 [INFO]: Epoch 003 - training loss: 0.6844, validation loss: 2.6780
2024-06-02 15:19:42 [INFO]: Epoch 004 - training loss: 0.6421, validation loss: 2.6209
2024-06-02 15:19:52 [INFO]: Epoch 005 - training loss: 0.6114, validation loss: 2.5971
2024-06-02 15:20:01 [INFO]: Epoch 006 - training loss: 0.5988, validation loss: 2.5929
2024-06-02 15:20:10 [INFO]: Epoch 007 - training loss: 0.5873, validation loss: 2.5506
2024-06-02 15:20:19 [INFO]: Epoch 008 - training loss: 0.5696, validation loss: 2.5526
2024-06-02 15:20:28 [INFO]: Epoch 009 - training loss: 0.5581, validation loss: 2.5343
2024-06-02 15:20:37 [INFO]: Epoch 010 - training loss: 0.5455, validation loss: 2.5193
2024-06-02 15:20:46 [INFO]: Epoch 011 - training loss: 0.5377, validation loss: 2.4994
2024-06-02 15:20:55 [INFO]: Epoch 012 - training loss: 0.5284, validation loss: 2.5086
2024-06-02 15:21:04 [INFO]: Epoch 013 - training loss: 0.5199, validation loss: 2.4826
2024-06-02 15:21:13 [INFO]: Epoch 014 - training loss: 0.5179, validation loss: 2.4873
2024-06-02 15:21:22 [INFO]: Epoch 015 - training loss: 0.5122, validation loss: 2.4995
2024-06-02 15:21:32 [INFO]: Epoch 016 - training loss: 0.5083, validation loss: 2.4508
2024-06-02 15:21:41 [INFO]: Epoch 017 - training loss: 0.5019, validation loss: 2.4516
2024-06-02 15:21:50 [INFO]: Epoch 018 - training loss: 0.4957, validation loss: 2.4361
2024-06-02 15:21:59 [INFO]: Epoch 019 - training loss: 0.4935, validation loss: 2.4355
2024-06-02 15:22:08 [INFO]: Epoch 020 - training loss: 0.4864, validation loss: 2.4095
2024-06-02 15:22:17 [INFO]: Epoch 021 - training loss: 0.4832, validation loss: 2.4036
2024-06-02 15:22:26 [INFO]: Epoch 022 - training loss: 0.4818, validation loss: 2.3983
2024-06-02 15:22:35 [INFO]: Epoch 023 - training loss: 0.4794, validation loss: 2.4083
2024-06-02 15:22:44 [INFO]: Epoch 024 - training loss: 0.4780, validation loss: 2.4051
2024-06-02 15:22:54 [INFO]: Epoch 025 - training loss: 0.4763, validation loss: 2.4038
2024-06-02 15:23:03 [INFO]: Epoch 026 - training loss: 0.4738, validation loss: 2.3913
2024-06-02 15:23:12 [INFO]: Epoch 027 - training loss: 0.4700, validation loss: 2.3666
2024-06-02 15:23:20 [INFO]: Epoch 028 - training loss: 0.4635, validation loss: 2.3671
2024-06-02 15:23:30 [INFO]: Epoch 029 - training loss: 0.4622, validation loss: 2.3763
2024-06-02 15:23:39 [INFO]: Epoch 030 - training loss: 0.4613, validation loss: 2.3587
2024-06-02 15:23:48 [INFO]: Epoch 031 - training loss: 0.4563, validation loss: 2.3622
2024-06-02 15:23:57 [INFO]: Epoch 032 - training loss: 0.4583, validation loss: 2.3566
2024-06-02 15:24:06 [INFO]: Epoch 033 - training loss: 0.4530, validation loss: 2.3571
2024-06-02 15:24:15 [INFO]: Epoch 034 - training loss: 0.4534, validation loss: 2.3445
2024-06-02 15:24:24 [INFO]: Epoch 035 - training loss: 0.4521, validation loss: 2.3391
2024-06-02 15:24:33 [INFO]: Epoch 036 - training loss: 0.4475, validation loss: 2.3389
2024-06-02 15:24:42 [INFO]: Epoch 037 - training loss: 0.4472, validation loss: 2.3398
2024-06-02 15:24:51 [INFO]: Epoch 038 - training loss: 0.4447, validation loss: 2.3110
2024-06-02 15:25:00 [INFO]: Epoch 039 - training loss: 0.4422, validation loss: 2.3437
2024-06-02 15:25:10 [INFO]: Epoch 040 - training loss: 0.4402, validation loss: 2.3157
2024-06-02 15:25:19 [INFO]: Epoch 041 - training loss: 0.4400, validation loss: 2.2993
2024-06-02 15:25:28 [INFO]: Epoch 042 - training loss: 0.4386, validation loss: 2.3049
2024-06-02 15:25:37 [INFO]: Epoch 043 - training loss: 0.4393, validation loss: 2.3112
2024-06-02 15:25:46 [INFO]: Epoch 044 - training loss: 0.4389, validation loss: 2.3132
2024-06-02 15:25:56 [INFO]: Epoch 045 - training loss: 0.4353, validation loss: 2.3130
2024-06-02 15:26:05 [INFO]: Epoch 046 - training loss: 0.4343, validation loss: 2.3106
2024-06-02 15:26:14 [INFO]: Epoch 047 - training loss: 0.4314, validation loss: 2.3103
2024-06-02 15:26:23 [INFO]: Epoch 048 - training loss: 0.4323, validation loss: 2.3060
2024-06-02 15:26:32 [INFO]: Epoch 049 - training loss: 0.4312, validation loss: 2.2819
2024-06-02 15:26:42 [INFO]: Epoch 050 - training loss: 0.4313, validation loss: 2.2825
2024-06-02 15:26:51 [INFO]: Epoch 051 - training loss: 0.4309, validation loss: 2.2641
2024-06-02 15:27:00 [INFO]: Epoch 052 - training loss: 0.4310, validation loss: 2.2621
2024-06-02 15:27:09 [INFO]: Epoch 053 - training loss: 0.4293, validation loss: 2.2888
2024-06-02 15:27:18 [INFO]: Epoch 054 - training loss: 0.4290, validation loss: 2.2783
2024-06-02 15:27:27 [INFO]: Epoch 055 - training loss: 0.4273, validation loss: 2.2732
2024-06-02 15:27:36 [INFO]: Epoch 056 - training loss: 0.4309, validation loss: 2.2927
2024-06-02 15:27:45 [INFO]: Epoch 057 - training loss: 0.4254, validation loss: 2.2745
2024-06-02 15:27:55 [INFO]: Epoch 058 - training loss: 0.4223, validation loss: 2.2591
2024-06-02 15:28:04 [INFO]: Epoch 059 - training loss: 0.4231, validation loss: 2.2508
2024-06-02 15:28:13 [INFO]: Epoch 060 - training loss: 0.4213, validation loss: 2.2492
2024-06-02 15:28:22 [INFO]: Epoch 061 - training loss: 0.4194, validation loss: 2.2416
2024-06-02 15:28:31 [INFO]: Epoch 062 - training loss: 0.4191, validation loss: 2.2587
2024-06-02 15:28:40 [INFO]: Epoch 063 - training loss: 0.4193, validation loss: 2.2445
2024-06-02 15:28:49 [INFO]: Epoch 064 - training loss: 0.4185, validation loss: 2.2414
2024-06-02 15:28:58 [INFO]: Epoch 065 - training loss: 0.4182, validation loss: 2.2291
2024-06-02 15:29:08 [INFO]: Epoch 066 - training loss: 0.4165, validation loss: 2.2243
2024-06-02 15:29:16 [INFO]: Epoch 067 - training loss: 0.4165, validation loss: 2.2467
2024-06-02 15:29:26 [INFO]: Epoch 068 - training loss: 0.4155, validation loss: 2.2260
2024-06-02 15:29:35 [INFO]: Epoch 069 - training loss: 0.4142, validation loss: 2.2132
2024-06-02 15:29:44 [INFO]: Epoch 070 - training loss: 0.4122, validation loss: 2.2430
2024-06-02 15:29:53 [INFO]: Epoch 071 - training loss: 0.4115, validation loss: 2.2124
2024-06-02 15:30:02 [INFO]: Epoch 072 - training loss: 0.4106, validation loss: 2.2207
2024-06-02 15:30:11 [INFO]: Epoch 073 - training loss: 0.4110, validation loss: 2.2339
2024-06-02 15:30:21 [INFO]: Epoch 074 - training loss: 0.4104, validation loss: 2.2429
2024-06-02 15:30:30 [INFO]: Epoch 075 - training loss: 0.4100, validation loss: 2.2194
2024-06-02 15:30:39 [INFO]: Epoch 076 - training loss: 0.4096, validation loss: 2.2156
2024-06-02 15:30:48 [INFO]: Epoch 077 - training loss: 0.4082, validation loss: 2.2162
2024-06-02 15:30:57 [INFO]: Epoch 078 - training loss: 0.4076, validation loss: 2.2083
2024-06-02 15:31:06 [INFO]: Epoch 079 - training loss: 0.4081, validation loss: 2.2139
2024-06-02 15:31:16 [INFO]: Epoch 080 - training loss: 0.4067, validation loss: 2.2057
2024-06-02 15:31:25 [INFO]: Epoch 081 - training loss: 0.4070, validation loss: 2.2011
2024-06-02 15:31:34 [INFO]: Epoch 082 - training loss: 0.4063, validation loss: 2.2224
2024-06-02 15:31:43 [INFO]: Epoch 083 - training loss: 0.4057, validation loss: 2.1930
2024-06-02 15:31:52 [INFO]: Epoch 084 - training loss: 0.4051, validation loss: 2.1980
2024-06-02 15:32:01 [INFO]: Epoch 085 - training loss: 0.4051, validation loss: 2.2061
2024-06-02 15:32:11 [INFO]: Epoch 086 - training loss: 0.4040, validation loss: 2.2123
2024-06-02 15:32:20 [INFO]: Epoch 087 - training loss: 0.4050, validation loss: 2.2033
2024-06-02 15:32:29 [INFO]: Epoch 088 - training loss: 0.4035, validation loss: 2.2054
2024-06-02 15:32:38 [INFO]: Epoch 089 - training loss: 0.4034, validation loss: 2.2154
2024-06-02 15:32:47 [INFO]: Epoch 090 - training loss: 0.4026, validation loss: 2.1889
2024-06-02 15:32:56 [INFO]: Epoch 091 - training loss: 0.4027, validation loss: 2.1992
2024-06-02 15:33:05 [INFO]: Epoch 092 - training loss: 0.4032, validation loss: 2.1810
2024-06-02 15:33:14 [INFO]: Epoch 093 - training loss: 0.4015, validation loss: 2.1893
2024-06-02 15:33:23 [INFO]: Epoch 094 - training loss: 0.4033, validation loss: 2.2299
2024-06-02 15:33:32 [INFO]: Epoch 095 - training loss: 0.4015, validation loss: 2.2067
2024-06-02 15:33:41 [INFO]: Epoch 096 - training loss: 0.3986, validation loss: 2.1922
2024-06-02 15:33:51 [INFO]: Epoch 097 - training loss: 0.3977, validation loss: 2.1977
2024-06-02 15:34:00 [INFO]: Epoch 098 - training loss: 0.4018, validation loss: 2.2293
2024-06-02 15:34:09 [INFO]: Epoch 099 - training loss: 0.4013, validation loss: 2.1860
2024-06-02 15:34:18 [INFO]: Epoch 100 - training loss: 0.3986, validation loss: 2.1652
2024-06-02 15:34:18 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 15:34:18 [INFO]: Saved the model to results_point_rate01/Electricity/Pyraformer_Electricity/round_0/20240602_T151858/Pyraformer.pypots
2024-06-02 15:34:20 [INFO]: Successfully saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_0/imputation.pkl
2024-06-02 15:34:20 [INFO]: Round0 - Pyraformer on Electricity: MAE=1.0643, MSE=2.1949, MRE=0.5693
2024-06-02 15:34:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 15:34:20 [INFO]: Using the given device: cuda:0
2024-06-02 15:34:20 [INFO]: Model files will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_1/20240602_T153420
2024-06-02 15:34:20 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_1/20240602_T153420/tensorboard
2024-06-02 15:34:20 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-02 15:34:29 [INFO]: Epoch 001 - training loss: 1.0006, validation loss: 2.8416
2024-06-02 15:34:39 [INFO]: Epoch 002 - training loss: 0.7294, validation loss: 2.6852
2024-06-02 15:34:48 [INFO]: Epoch 003 - training loss: 0.6603, validation loss: 2.6589
2024-06-02 15:34:57 [INFO]: Epoch 004 - training loss: 0.6308, validation loss: 2.5995
2024-06-02 15:35:06 [INFO]: Epoch 005 - training loss: 0.6114, validation loss: 2.5880
2024-06-02 15:35:15 [INFO]: Epoch 006 - training loss: 0.5967, validation loss: 2.5913
2024-06-02 15:35:24 [INFO]: Epoch 007 - training loss: 0.5779, validation loss: 2.5627
2024-06-02 15:35:33 [INFO]: Epoch 008 - training loss: 0.5710, validation loss: 2.5503
2024-06-02 15:35:42 [INFO]: Epoch 009 - training loss: 0.5559, validation loss: 2.5182
2024-06-02 15:35:51 [INFO]: Epoch 010 - training loss: 0.5452, validation loss: 2.4946
2024-06-02 15:36:01 [INFO]: Epoch 011 - training loss: 0.5315, validation loss: 2.4814
2024-06-02 15:36:10 [INFO]: Epoch 012 - training loss: 0.5315, validation loss: 2.4625
2024-06-02 15:36:19 [INFO]: Epoch 013 - training loss: 0.5243, validation loss: 2.4816
2024-06-02 15:36:28 [INFO]: Epoch 014 - training loss: 0.5161, validation loss: 2.4829
2024-06-02 15:36:37 [INFO]: Epoch 015 - training loss: 0.5085, validation loss: 2.4467
2024-06-02 15:36:46 [INFO]: Epoch 016 - training loss: 0.5025, validation loss: 2.4445
2024-06-02 15:36:55 [INFO]: Epoch 017 - training loss: 0.5076, validation loss: 2.4388
2024-06-02 15:37:04 [INFO]: Epoch 018 - training loss: 0.5003, validation loss: 2.4285
2024-06-02 15:37:13 [INFO]: Epoch 019 - training loss: 0.4958, validation loss: 2.4231
2024-06-02 15:37:23 [INFO]: Epoch 020 - training loss: 0.4877, validation loss: 2.4242
2024-06-02 15:37:32 [INFO]: Epoch 021 - training loss: 0.4856, validation loss: 2.3992
2024-06-02 15:37:42 [INFO]: Epoch 022 - training loss: 0.4801, validation loss: 2.3911
2024-06-02 15:37:52 [INFO]: Epoch 023 - training loss: 0.4815, validation loss: 2.3820
2024-06-02 15:38:01 [INFO]: Epoch 024 - training loss: 0.4743, validation loss: 2.3690
2024-06-02 15:38:10 [INFO]: Epoch 025 - training loss: 0.4693, validation loss: 2.3702
2024-06-02 15:38:20 [INFO]: Epoch 026 - training loss: 0.4699, validation loss: 2.3498
2024-06-02 15:38:30 [INFO]: Epoch 027 - training loss: 0.4723, validation loss: 2.3364
2024-06-02 15:38:39 [INFO]: Epoch 028 - training loss: 0.4680, validation loss: 2.3467
2024-06-02 15:38:48 [INFO]: Epoch 029 - training loss: 0.4630, validation loss: 2.3404
2024-06-02 15:38:58 [INFO]: Epoch 030 - training loss: 0.4580, validation loss: 2.3371
2024-06-02 15:39:07 [INFO]: Epoch 031 - training loss: 0.4604, validation loss: 2.3237
2024-06-02 15:39:16 [INFO]: Epoch 032 - training loss: 0.4569, validation loss: 2.3232
2024-06-02 15:39:26 [INFO]: Epoch 033 - training loss: 0.4529, validation loss: 2.3030
2024-06-02 15:39:35 [INFO]: Epoch 034 - training loss: 0.4509, validation loss: 2.3201
2024-06-02 15:39:44 [INFO]: Epoch 035 - training loss: 0.4497, validation loss: 2.3012
2024-06-02 15:39:53 [INFO]: Epoch 036 - training loss: 0.4488, validation loss: 2.2951
2024-06-02 15:40:02 [INFO]: Epoch 037 - training loss: 0.4481, validation loss: 2.2964
2024-06-02 15:40:12 [INFO]: Epoch 038 - training loss: 0.4449, validation loss: 2.3090
2024-06-02 15:40:21 [INFO]: Epoch 039 - training loss: 0.4449, validation loss: 2.2899
2024-06-02 15:40:30 [INFO]: Epoch 040 - training loss: 0.4443, validation loss: 2.3080
2024-06-02 15:40:39 [INFO]: Epoch 041 - training loss: 0.4399, validation loss: 2.2898
2024-06-02 15:40:48 [INFO]: Epoch 042 - training loss: 0.4388, validation loss: 2.2786
2024-06-02 15:40:57 [INFO]: Epoch 043 - training loss: 0.4417, validation loss: 2.2975
2024-06-02 15:41:06 [INFO]: Epoch 044 - training loss: 0.4396, validation loss: 2.2880
2024-06-02 15:41:15 [INFO]: Epoch 045 - training loss: 0.4409, validation loss: 2.2664
2024-06-02 15:41:24 [INFO]: Epoch 046 - training loss: 0.4374, validation loss: 2.2715
2024-06-02 15:41:32 [INFO]: Epoch 047 - training loss: 0.4329, validation loss: 2.2794
2024-06-02 15:41:40 [INFO]: Epoch 048 - training loss: 0.4332, validation loss: 2.2639
2024-06-02 15:41:49 [INFO]: Epoch 049 - training loss: 0.4327, validation loss: 2.2603
2024-06-02 15:41:58 [INFO]: Epoch 050 - training loss: 0.4293, validation loss: 2.2618
2024-06-02 15:42:08 [INFO]: Epoch 051 - training loss: 0.4300, validation loss: 2.2619
2024-06-02 15:42:17 [INFO]: Epoch 052 - training loss: 0.4273, validation loss: 2.2590
2024-06-02 15:42:26 [INFO]: Epoch 053 - training loss: 0.4254, validation loss: 2.2510
2024-06-02 15:42:35 [INFO]: Epoch 054 - training loss: 0.4249, validation loss: 2.2587
2024-06-02 15:42:44 [INFO]: Epoch 055 - training loss: 0.4215, validation loss: 2.2319
2024-06-02 15:42:53 [INFO]: Epoch 056 - training loss: 0.4205, validation loss: 2.2576
2024-06-02 15:43:02 [INFO]: Epoch 057 - training loss: 0.4208, validation loss: 2.2341
2024-06-02 15:43:11 [INFO]: Epoch 058 - training loss: 0.4219, validation loss: 2.2318
2024-06-02 15:43:20 [INFO]: Epoch 059 - training loss: 0.4207, validation loss: 2.2262
2024-06-02 15:43:29 [INFO]: Epoch 060 - training loss: 0.4189, validation loss: 2.2428
2024-06-02 15:43:38 [INFO]: Epoch 061 - training loss: 0.4179, validation loss: 2.2187
2024-06-02 15:43:47 [INFO]: Epoch 062 - training loss: 0.4167, validation loss: 2.2279
2024-06-02 15:43:56 [INFO]: Epoch 063 - training loss: 0.4178, validation loss: 2.2254
2024-06-02 15:44:05 [INFO]: Epoch 064 - training loss: 0.4227, validation loss: 2.2301
2024-06-02 15:44:14 [INFO]: Epoch 065 - training loss: 0.4173, validation loss: 2.2192
2024-06-02 15:44:23 [INFO]: Epoch 066 - training loss: 0.4159, validation loss: 2.2119
2024-06-02 15:44:32 [INFO]: Epoch 067 - training loss: 0.4139, validation loss: 2.1993
2024-06-02 15:44:41 [INFO]: Epoch 068 - training loss: 0.4143, validation loss: 2.2085
2024-06-02 15:44:50 [INFO]: Epoch 069 - training loss: 0.4148, validation loss: 2.2255
2024-06-02 15:45:00 [INFO]: Epoch 070 - training loss: 0.4119, validation loss: 2.2077
2024-06-02 15:45:09 [INFO]: Epoch 071 - training loss: 0.4117, validation loss: 2.2103
2024-06-02 15:45:18 [INFO]: Epoch 072 - training loss: 0.4096, validation loss: 2.2112
2024-06-02 15:45:27 [INFO]: Epoch 073 - training loss: 0.4114, validation loss: 2.1989
2024-06-02 15:45:36 [INFO]: Epoch 074 - training loss: 0.4091, validation loss: 2.1953
2024-06-02 15:45:45 [INFO]: Epoch 075 - training loss: 0.4080, validation loss: 2.2074
2024-06-02 15:45:54 [INFO]: Epoch 076 - training loss: 0.4073, validation loss: 2.1867
2024-06-02 15:46:03 [INFO]: Epoch 077 - training loss: 0.4076, validation loss: 2.1872
2024-06-02 15:46:12 [INFO]: Epoch 078 - training loss: 0.4084, validation loss: 2.1873
2024-06-02 15:46:21 [INFO]: Epoch 079 - training loss: 0.4079, validation loss: 2.1984
2024-06-02 15:46:30 [INFO]: Epoch 080 - training loss: 0.4059, validation loss: 2.2018
2024-06-02 15:46:39 [INFO]: Epoch 081 - training loss: 0.4053, validation loss: 2.1892
2024-06-02 15:46:48 [INFO]: Epoch 082 - training loss: 0.4054, validation loss: 2.1804
2024-06-02 15:46:58 [INFO]: Epoch 083 - training loss: 0.4036, validation loss: 2.1882
2024-06-02 15:47:07 [INFO]: Epoch 084 - training loss: 0.4022, validation loss: 2.1758
2024-06-02 15:47:16 [INFO]: Epoch 085 - training loss: 0.4034, validation loss: 2.1919
2024-06-02 15:47:25 [INFO]: Epoch 086 - training loss: 0.4059, validation loss: 2.1862
2024-06-02 15:47:34 [INFO]: Epoch 087 - training loss: 0.4039, validation loss: 2.1703
2024-06-02 15:47:43 [INFO]: Epoch 088 - training loss: 0.4042, validation loss: 2.1702
2024-06-02 15:47:52 [INFO]: Epoch 089 - training loss: 0.4034, validation loss: 2.1680
2024-06-02 15:48:01 [INFO]: Epoch 090 - training loss: 0.4021, validation loss: 2.1630
2024-06-02 15:48:11 [INFO]: Epoch 091 - training loss: 0.4005, validation loss: 2.1588
2024-06-02 15:48:20 [INFO]: Epoch 092 - training loss: 0.3988, validation loss: 2.1680
2024-06-02 15:48:29 [INFO]: Epoch 093 - training loss: 0.4017, validation loss: 2.1659
2024-06-02 15:48:38 [INFO]: Epoch 094 - training loss: 0.4020, validation loss: 2.1760
2024-06-02 15:48:47 [INFO]: Epoch 095 - training loss: 0.4011, validation loss: 2.1848
2024-06-02 15:48:56 [INFO]: Epoch 096 - training loss: 0.3998, validation loss: 2.1583
2024-06-02 15:49:05 [INFO]: Epoch 097 - training loss: 0.4000, validation loss: 2.1570
2024-06-02 15:49:14 [INFO]: Epoch 098 - training loss: 0.3984, validation loss: 2.1650
2024-06-02 15:49:24 [INFO]: Epoch 099 - training loss: 0.3977, validation loss: 2.1555
2024-06-02 15:49:33 [INFO]: Epoch 100 - training loss: 0.3975, validation loss: 2.1427
2024-06-02 15:49:33 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 15:49:33 [INFO]: Saved the model to results_point_rate01/Electricity/Pyraformer_Electricity/round_1/20240602_T153420/Pyraformer.pypots
2024-06-02 15:49:34 [INFO]: Successfully saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_1/imputation.pkl
2024-06-02 15:49:34 [INFO]: Round1 - Pyraformer on Electricity: MAE=1.0827, MSE=2.0919, MRE=0.5792
2024-06-02 15:49:34 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 15:49:34 [INFO]: Using the given device: cuda:0
2024-06-02 15:49:34 [INFO]: Model files will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_2/20240602_T154934
2024-06-02 15:49:34 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_2/20240602_T154934/tensorboard
2024-06-02 15:49:35 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-02 15:49:44 [INFO]: Epoch 001 - training loss: 1.0128, validation loss: 2.8152
2024-06-02 15:49:53 [INFO]: Epoch 002 - training loss: 0.7373, validation loss: 2.6714
2024-06-02 15:50:02 [INFO]: Epoch 003 - training loss: 0.6711, validation loss: 2.6274
2024-06-02 15:50:12 [INFO]: Epoch 004 - training loss: 0.6360, validation loss: 2.6303
2024-06-02 15:50:21 [INFO]: Epoch 005 - training loss: 0.6108, validation loss: 2.5838
2024-06-02 15:50:30 [INFO]: Epoch 006 - training loss: 0.5948, validation loss: 2.5704
2024-06-02 15:50:39 [INFO]: Epoch 007 - training loss: 0.5884, validation loss: 2.5516
2024-06-02 15:50:48 [INFO]: Epoch 008 - training loss: 0.5683, validation loss: 2.5284
2024-06-02 15:50:57 [INFO]: Epoch 009 - training loss: 0.5602, validation loss: 2.5159
2024-06-02 15:51:06 [INFO]: Epoch 010 - training loss: 0.5516, validation loss: 2.5054
2024-06-02 15:51:15 [INFO]: Epoch 011 - training loss: 0.5434, validation loss: 2.4935
2024-06-02 15:51:24 [INFO]: Epoch 012 - training loss: 0.5307, validation loss: 2.4632
2024-06-02 15:51:33 [INFO]: Epoch 013 - training loss: 0.5215, validation loss: 2.4544
2024-06-02 15:51:42 [INFO]: Epoch 014 - training loss: 0.5218, validation loss: 2.4614
2024-06-02 15:51:52 [INFO]: Epoch 015 - training loss: 0.5150, validation loss: 2.4334
2024-06-02 15:52:01 [INFO]: Epoch 016 - training loss: 0.5083, validation loss: 2.4352
2024-06-02 15:52:10 [INFO]: Epoch 017 - training loss: 0.5007, validation loss: 2.4193
2024-06-02 15:52:19 [INFO]: Epoch 018 - training loss: 0.5019, validation loss: 2.4162
2024-06-02 15:52:28 [INFO]: Epoch 019 - training loss: 0.4957, validation loss: 2.4224
2024-06-02 15:52:37 [INFO]: Epoch 020 - training loss: 0.4910, validation loss: 2.3913
2024-06-02 15:52:46 [INFO]: Epoch 021 - training loss: 0.4849, validation loss: 2.3985
2024-06-02 15:52:55 [INFO]: Epoch 022 - training loss: 0.4820, validation loss: 2.4049
2024-06-02 15:53:04 [INFO]: Epoch 023 - training loss: 0.4776, validation loss: 2.3888
2024-06-02 15:53:12 [INFO]: Epoch 024 - training loss: 0.4739, validation loss: 2.4035
2024-06-02 15:53:22 [INFO]: Epoch 025 - training loss: 0.4756, validation loss: 2.3668
2024-06-02 15:53:31 [INFO]: Epoch 026 - training loss: 0.4740, validation loss: 2.3681
2024-06-02 15:53:40 [INFO]: Epoch 027 - training loss: 0.4677, validation loss: 2.3669
2024-06-02 15:53:49 [INFO]: Epoch 028 - training loss: 0.4667, validation loss: 2.3524
2024-06-02 15:53:58 [INFO]: Epoch 029 - training loss: 0.4656, validation loss: 2.3310
2024-06-02 15:54:08 [INFO]: Epoch 030 - training loss: 0.4607, validation loss: 2.3427
2024-06-02 15:54:17 [INFO]: Epoch 031 - training loss: 0.4566, validation loss: 2.3426
2024-06-02 15:54:27 [INFO]: Epoch 032 - training loss: 0.4593, validation loss: 2.3280
2024-06-02 15:54:36 [INFO]: Epoch 033 - training loss: 0.4552, validation loss: 2.3266
2024-06-02 15:54:46 [INFO]: Epoch 034 - training loss: 0.4519, validation loss: 2.3254
2024-06-02 15:54:54 [INFO]: Epoch 035 - training loss: 0.4497, validation loss: 2.3249
2024-06-02 15:55:02 [INFO]: Epoch 036 - training loss: 0.4483, validation loss: 2.3410
2024-06-02 15:55:11 [INFO]: Epoch 037 - training loss: 0.4480, validation loss: 2.3092
2024-06-02 15:55:20 [INFO]: Epoch 038 - training loss: 0.4462, validation loss: 2.3157
2024-06-02 15:55:29 [INFO]: Epoch 039 - training loss: 0.4446, validation loss: 2.3127
2024-06-02 15:55:38 [INFO]: Epoch 040 - training loss: 0.4450, validation loss: 2.2980
2024-06-02 15:55:48 [INFO]: Epoch 041 - training loss: 0.4429, validation loss: 2.2933
2024-06-02 15:55:57 [INFO]: Epoch 042 - training loss: 0.4414, validation loss: 2.2904
2024-06-02 15:56:06 [INFO]: Epoch 043 - training loss: 0.4384, validation loss: 2.2939
2024-06-02 15:56:15 [INFO]: Epoch 044 - training loss: 0.4378, validation loss: 2.3065
2024-06-02 15:56:24 [INFO]: Epoch 045 - training loss: 0.4369, validation loss: 2.2911
2024-06-02 15:56:33 [INFO]: Epoch 046 - training loss: 0.4338, validation loss: 2.2800
2024-06-02 15:56:43 [INFO]: Epoch 047 - training loss: 0.4333, validation loss: 2.2974
2024-06-02 15:56:51 [INFO]: Epoch 048 - training loss: 0.4343, validation loss: 2.2789
2024-06-02 15:57:00 [INFO]: Epoch 049 - training loss: 0.4327, validation loss: 2.2827
2024-06-02 15:57:09 [INFO]: Epoch 050 - training loss: 0.4312, validation loss: 2.2851
2024-06-02 15:57:18 [INFO]: Epoch 051 - training loss: 0.4301, validation loss: 2.2923
2024-06-02 15:57:27 [INFO]: Epoch 052 - training loss: 0.4285, validation loss: 2.2734
2024-06-02 15:57:37 [INFO]: Epoch 053 - training loss: 0.4269, validation loss: 2.2562
2024-06-02 15:57:46 [INFO]: Epoch 054 - training loss: 0.4262, validation loss: 2.2645
2024-06-02 15:57:55 [INFO]: Epoch 055 - training loss: 0.4248, validation loss: 2.2741
2024-06-02 15:58:01 [INFO]: Epoch 056 - training loss: 0.4242, validation loss: 2.2637
2024-06-02 15:58:09 [INFO]: Epoch 057 - training loss: 0.4255, validation loss: 2.2633
2024-06-02 15:58:15 [INFO]: Epoch 058 - training loss: 0.4242, validation loss: 2.2391
2024-06-02 15:58:22 [INFO]: Epoch 059 - training loss: 0.4228, validation loss: 2.2405
2024-06-02 15:58:29 [INFO]: Epoch 060 - training loss: 0.4216, validation loss: 2.2481
2024-06-02 15:58:36 [INFO]: Epoch 061 - training loss: 0.4211, validation loss: 2.2267
2024-06-02 15:58:43 [INFO]: Epoch 062 - training loss: 0.4215, validation loss: 2.2329
2024-06-02 15:58:50 [INFO]: Epoch 063 - training loss: 0.4174, validation loss: 2.2254
2024-06-02 15:58:57 [INFO]: Epoch 064 - training loss: 0.4184, validation loss: 2.2244
2024-06-02 15:59:04 [INFO]: Epoch 065 - training loss: 0.4178, validation loss: 2.2156
2024-06-02 15:59:11 [INFO]: Epoch 066 - training loss: 0.4171, validation loss: 2.2077
2024-06-02 15:59:17 [INFO]: Epoch 067 - training loss: 0.4174, validation loss: 2.2037
2024-06-02 15:59:24 [INFO]: Epoch 068 - training loss: 0.4169, validation loss: 2.2166
2024-06-02 15:59:31 [INFO]: Epoch 069 - training loss: 0.4155, validation loss: 2.1946
2024-06-02 15:59:37 [INFO]: Epoch 070 - training loss: 0.4156, validation loss: 2.1879
2024-06-02 15:59:44 [INFO]: Epoch 071 - training loss: 0.4143, validation loss: 2.1973
2024-06-02 15:59:51 [INFO]: Epoch 072 - training loss: 0.4132, validation loss: 2.2176
2024-06-02 15:59:58 [INFO]: Epoch 073 - training loss: 0.4123, validation loss: 2.1966
2024-06-02 16:00:05 [INFO]: Epoch 074 - training loss: 0.4122, validation loss: 2.1774
2024-06-02 16:00:11 [INFO]: Epoch 075 - training loss: 0.4118, validation loss: 2.1645
2024-06-02 16:00:18 [INFO]: Epoch 076 - training loss: 0.4098, validation loss: 2.1836
2024-06-02 16:00:25 [INFO]: Epoch 077 - training loss: 0.4094, validation loss: 2.1853
2024-06-02 16:00:32 [INFO]: Epoch 078 - training loss: 0.4085, validation loss: 2.1853
2024-06-02 16:00:38 [INFO]: Epoch 079 - training loss: 0.4077, validation loss: 2.1954
2024-06-02 16:00:45 [INFO]: Epoch 080 - training loss: 0.4090, validation loss: 2.1936
2024-06-02 16:00:52 [INFO]: Epoch 081 - training loss: 0.4086, validation loss: 2.1595
2024-06-02 16:00:58 [INFO]: Epoch 082 - training loss: 0.4092, validation loss: 2.1416
2024-06-02 16:01:05 [INFO]: Epoch 083 - training loss: 0.4053, validation loss: 2.1758
2024-06-02 16:01:12 [INFO]: Epoch 084 - training loss: 0.4063, validation loss: 2.1614
2024-06-02 16:01:19 [INFO]: Epoch 085 - training loss: 0.4056, validation loss: 2.1723
2024-06-02 16:01:25 [INFO]: Epoch 086 - training loss: 0.4042, validation loss: 2.1669
2024-06-02 16:01:32 [INFO]: Epoch 087 - training loss: 0.4035, validation loss: 2.1769
2024-06-02 16:01:39 [INFO]: Epoch 088 - training loss: 0.4042, validation loss: 2.1685
2024-06-02 16:01:45 [INFO]: Epoch 089 - training loss: 0.4037, validation loss: 2.1691
2024-06-02 16:01:52 [INFO]: Epoch 090 - training loss: 0.4046, validation loss: 2.1809
2024-06-02 16:01:59 [INFO]: Epoch 091 - training loss: 0.4028, validation loss: 2.1575
2024-06-02 16:02:06 [INFO]: Epoch 092 - training loss: 0.4051, validation loss: 2.1729
2024-06-02 16:02:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 16:02:06 [INFO]: Finished training. The best model is from epoch#82.
2024-06-02 16:02:06 [INFO]: Saved the model to results_point_rate01/Electricity/Pyraformer_Electricity/round_2/20240602_T154934/Pyraformer.pypots
2024-06-02 16:02:07 [INFO]: Successfully saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_2/imputation.pkl
2024-06-02 16:02:07 [INFO]: Round2 - Pyraformer on Electricity: MAE=1.0655, MSE=2.1499, MRE=0.5700
2024-06-02 16:02:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 16:02:07 [INFO]: Using the given device: cuda:0
2024-06-02 16:02:07 [INFO]: Model files will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_3/20240602_T160207
2024-06-02 16:02:07 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_3/20240602_T160207/tensorboard
2024-06-02 16:02:07 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-02 16:02:14 [INFO]: Epoch 001 - training loss: 0.9980, validation loss: 2.8149
2024-06-02 16:02:21 [INFO]: Epoch 002 - training loss: 0.7400, validation loss: 2.6905
2024-06-02 16:02:28 [INFO]: Epoch 003 - training loss: 0.6704, validation loss: 2.6415
2024-06-02 16:02:35 [INFO]: Epoch 004 - training loss: 0.6390, validation loss: 2.6189
2024-06-02 16:02:42 [INFO]: Epoch 005 - training loss: 0.6168, validation loss: 2.6338
2024-06-02 16:02:48 [INFO]: Epoch 006 - training loss: 0.5969, validation loss: 2.5856
2024-06-02 16:02:55 [INFO]: Epoch 007 - training loss: 0.5780, validation loss: 2.5462
2024-06-02 16:03:02 [INFO]: Epoch 008 - training loss: 0.5663, validation loss: 2.5442
2024-06-02 16:03:08 [INFO]: Epoch 009 - training loss: 0.5565, validation loss: 2.5469
2024-06-02 16:03:15 [INFO]: Epoch 010 - training loss: 0.5540, validation loss: 2.5260
2024-06-02 16:03:22 [INFO]: Epoch 011 - training loss: 0.5401, validation loss: 2.5142
2024-06-02 16:03:29 [INFO]: Epoch 012 - training loss: 0.5268, validation loss: 2.5054
2024-06-02 16:03:36 [INFO]: Epoch 013 - training loss: 0.5216, validation loss: 2.4941
2024-06-02 16:03:42 [INFO]: Epoch 014 - training loss: 0.5184, validation loss: 2.4556
2024-06-02 16:03:49 [INFO]: Epoch 015 - training loss: 0.5172, validation loss: 2.4719
2024-06-02 16:03:55 [INFO]: Epoch 016 - training loss: 0.5052, validation loss: 2.4555
2024-06-02 16:04:02 [INFO]: Epoch 017 - training loss: 0.5027, validation loss: 2.4791
2024-06-02 16:04:09 [INFO]: Epoch 018 - training loss: 0.4973, validation loss: 2.4557
2024-06-02 16:04:16 [INFO]: Epoch 019 - training loss: 0.4975, validation loss: 2.4464
2024-06-02 16:04:23 [INFO]: Epoch 020 - training loss: 0.4912, validation loss: 2.4364
2024-06-02 16:04:29 [INFO]: Epoch 021 - training loss: 0.4851, validation loss: 2.4215
2024-06-02 16:04:36 [INFO]: Epoch 022 - training loss: 0.4823, validation loss: 2.4001
2024-06-02 16:04:43 [INFO]: Epoch 023 - training loss: 0.4807, validation loss: 2.4145
2024-06-02 16:04:50 [INFO]: Epoch 024 - training loss: 0.4788, validation loss: 2.3920
2024-06-02 16:04:56 [INFO]: Epoch 025 - training loss: 0.4752, validation loss: 2.3967
2024-06-02 16:05:03 [INFO]: Epoch 026 - training loss: 0.4711, validation loss: 2.3697
2024-06-02 16:05:10 [INFO]: Epoch 027 - training loss: 0.4677, validation loss: 2.3739
2024-06-02 16:05:17 [INFO]: Epoch 028 - training loss: 0.4642, validation loss: 2.3775
2024-06-02 16:05:24 [INFO]: Epoch 029 - training loss: 0.4638, validation loss: 2.3740
2024-06-02 16:05:30 [INFO]: Epoch 030 - training loss: 0.4647, validation loss: 2.3576
2024-06-02 16:05:37 [INFO]: Epoch 031 - training loss: 0.4622, validation loss: 2.3342
2024-06-02 16:05:44 [INFO]: Epoch 032 - training loss: 0.4564, validation loss: 2.3359
2024-06-02 16:05:50 [INFO]: Epoch 033 - training loss: 0.4558, validation loss: 2.3340
2024-06-02 16:05:57 [INFO]: Epoch 034 - training loss: 0.4547, validation loss: 2.3214
2024-06-02 16:06:03 [INFO]: Epoch 035 - training loss: 0.4531, validation loss: 2.3183
2024-06-02 16:06:10 [INFO]: Epoch 036 - training loss: 0.4527, validation loss: 2.3380
2024-06-02 16:06:17 [INFO]: Epoch 037 - training loss: 0.4507, validation loss: 2.3349
2024-06-02 16:06:23 [INFO]: Epoch 038 - training loss: 0.4460, validation loss: 2.3196
2024-06-02 16:06:30 [INFO]: Epoch 039 - training loss: 0.4459, validation loss: 2.3264
2024-06-02 16:06:36 [INFO]: Epoch 040 - training loss: 0.4437, validation loss: 2.3224
2024-06-02 16:06:43 [INFO]: Epoch 041 - training loss: 0.4409, validation loss: 2.3175
2024-06-02 16:06:49 [INFO]: Epoch 042 - training loss: 0.4377, validation loss: 2.3215
2024-06-02 16:06:57 [INFO]: Epoch 043 - training loss: 0.4388, validation loss: 2.3149
2024-06-02 16:07:04 [INFO]: Epoch 044 - training loss: 0.4367, validation loss: 2.3167
2024-06-02 16:07:10 [INFO]: Epoch 045 - training loss: 0.4360, validation loss: 2.3203
2024-06-02 16:07:17 [INFO]: Epoch 046 - training loss: 0.4334, validation loss: 2.3182
2024-06-02 16:07:24 [INFO]: Epoch 047 - training loss: 0.4327, validation loss: 2.3391
2024-06-02 16:07:30 [INFO]: Epoch 048 - training loss: 0.4302, validation loss: 2.3159
2024-06-02 16:07:37 [INFO]: Epoch 049 - training loss: 0.4293, validation loss: 2.3075
2024-06-02 16:07:44 [INFO]: Epoch 050 - training loss: 0.4305, validation loss: 2.3004
2024-06-02 16:07:50 [INFO]: Epoch 051 - training loss: 0.4298, validation loss: 2.2972
2024-06-02 16:07:57 [INFO]: Epoch 052 - training loss: 0.4268, validation loss: 2.3003
2024-06-02 16:08:04 [INFO]: Epoch 053 - training loss: 0.4287, validation loss: 2.3020
2024-06-02 16:08:10 [INFO]: Epoch 054 - training loss: 0.4276, validation loss: 2.2877
2024-06-02 16:08:17 [INFO]: Epoch 055 - training loss: 0.4264, validation loss: 2.2925
2024-06-02 16:08:24 [INFO]: Epoch 056 - training loss: 0.4227, validation loss: 2.2765
2024-06-02 16:08:30 [INFO]: Epoch 057 - training loss: 0.4232, validation loss: 2.2967
2024-06-02 16:08:37 [INFO]: Epoch 058 - training loss: 0.4235, validation loss: 2.2932
2024-06-02 16:08:44 [INFO]: Epoch 059 - training loss: 0.4211, validation loss: 2.2887
2024-06-02 16:08:50 [INFO]: Epoch 060 - training loss: 0.4182, validation loss: 2.2755
2024-06-02 16:08:57 [INFO]: Epoch 061 - training loss: 0.4188, validation loss: 2.2857
2024-06-02 16:09:04 [INFO]: Epoch 062 - training loss: 0.4181, validation loss: 2.2902
2024-06-02 16:09:11 [INFO]: Epoch 063 - training loss: 0.4170, validation loss: 2.2889
2024-06-02 16:09:17 [INFO]: Epoch 064 - training loss: 0.4156, validation loss: 2.2862
2024-06-02 16:09:24 [INFO]: Epoch 065 - training loss: 0.4148, validation loss: 2.2729
2024-06-02 16:09:31 [INFO]: Epoch 066 - training loss: 0.4166, validation loss: 2.2613
2024-06-02 16:09:38 [INFO]: Epoch 067 - training loss: 0.4154, validation loss: 2.2833
2024-06-02 16:09:45 [INFO]: Epoch 068 - training loss: 0.4154, validation loss: 2.2580
2024-06-02 16:09:52 [INFO]: Epoch 069 - training loss: 0.4152, validation loss: 2.2712
2024-06-02 16:09:59 [INFO]: Epoch 070 - training loss: 0.4139, validation loss: 2.2695
2024-06-02 16:10:06 [INFO]: Epoch 071 - training loss: 0.4112, validation loss: 2.2747
2024-06-02 16:10:12 [INFO]: Epoch 072 - training loss: 0.4112, validation loss: 2.2742
2024-06-02 16:10:19 [INFO]: Epoch 073 - training loss: 0.4122, validation loss: 2.2994
2024-06-02 16:10:26 [INFO]: Epoch 074 - training loss: 0.4107, validation loss: 2.2738
2024-06-02 16:10:33 [INFO]: Epoch 075 - training loss: 0.4102, validation loss: 2.2644
2024-06-02 16:10:40 [INFO]: Epoch 076 - training loss: 0.4119, validation loss: 2.3023
2024-06-02 16:10:46 [INFO]: Epoch 077 - training loss: 0.4094, validation loss: 2.2772
2024-06-02 16:10:53 [INFO]: Epoch 078 - training loss: 0.4074, validation loss: 2.2816
2024-06-02 16:10:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 16:10:53 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 16:10:53 [INFO]: Saved the model to results_point_rate01/Electricity/Pyraformer_Electricity/round_3/20240602_T160207/Pyraformer.pypots
2024-06-02 16:10:54 [INFO]: Successfully saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_3/imputation.pkl
2024-06-02 16:10:54 [INFO]: Round3 - Pyraformer on Electricity: MAE=1.1494, MSE=2.5590, MRE=0.6149
2024-06-02 16:10:54 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 16:10:54 [INFO]: Using the given device: cuda:0
2024-06-02 16:10:54 [INFO]: Model files will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_4/20240602_T161054
2024-06-02 16:10:54 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_4/20240602_T161054/tensorboard
2024-06-02 16:10:54 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-02 16:11:01 [INFO]: Epoch 001 - training loss: 1.0039, validation loss: 2.8350
2024-06-02 16:11:07 [INFO]: Epoch 002 - training loss: 0.7463, validation loss: 2.6775
2024-06-02 16:11:14 [INFO]: Epoch 003 - training loss: 0.6713, validation loss: 2.6481
2024-06-02 16:11:21 [INFO]: Epoch 004 - training loss: 0.6339, validation loss: 2.6041
2024-06-02 16:11:28 [INFO]: Epoch 005 - training loss: 0.6086, validation loss: 2.6044
2024-06-02 16:11:34 [INFO]: Epoch 006 - training loss: 0.5963, validation loss: 2.5917
2024-06-02 16:11:41 [INFO]: Epoch 007 - training loss: 0.5838, validation loss: 2.5756
2024-06-02 16:11:48 [INFO]: Epoch 008 - training loss: 0.5689, validation loss: 2.5593
2024-06-02 16:11:54 [INFO]: Epoch 009 - training loss: 0.5520, validation loss: 2.5495
2024-06-02 16:12:01 [INFO]: Epoch 010 - training loss: 0.5433, validation loss: 2.5111
2024-06-02 16:12:08 [INFO]: Epoch 011 - training loss: 0.5398, validation loss: 2.4762
2024-06-02 16:12:14 [INFO]: Epoch 012 - training loss: 0.5275, validation loss: 2.4590
2024-06-02 16:12:21 [INFO]: Epoch 013 - training loss: 0.5244, validation loss: 2.4600
2024-06-02 16:12:27 [INFO]: Epoch 014 - training loss: 0.5190, validation loss: 2.4511
2024-06-02 16:12:35 [INFO]: Epoch 015 - training loss: 0.5122, validation loss: 2.4382
2024-06-02 16:12:41 [INFO]: Epoch 016 - training loss: 0.5045, validation loss: 2.4404
2024-06-02 16:12:48 [INFO]: Epoch 017 - training loss: 0.5113, validation loss: 2.4175
2024-06-02 16:12:54 [INFO]: Epoch 018 - training loss: 0.4996, validation loss: 2.4026
2024-06-02 16:13:01 [INFO]: Epoch 019 - training loss: 0.4934, validation loss: 2.3921
2024-06-02 16:13:07 [INFO]: Epoch 020 - training loss: 0.4900, validation loss: 2.3963
2024-06-02 16:13:14 [INFO]: Epoch 021 - training loss: 0.4874, validation loss: 2.3847
2024-06-02 16:13:21 [INFO]: Epoch 022 - training loss: 0.4816, validation loss: 2.3661
2024-06-02 16:13:27 [INFO]: Epoch 023 - training loss: 0.4748, validation loss: 2.3614
2024-06-02 16:13:34 [INFO]: Epoch 024 - training loss: 0.4726, validation loss: 2.3705
2024-06-02 16:13:41 [INFO]: Epoch 025 - training loss: 0.4744, validation loss: 2.3518
2024-06-02 16:13:47 [INFO]: Epoch 026 - training loss: 0.4736, validation loss: 2.3661
2024-06-02 16:13:54 [INFO]: Epoch 027 - training loss: 0.4654, validation loss: 2.3378
2024-06-02 16:14:01 [INFO]: Epoch 028 - training loss: 0.4632, validation loss: 2.3443
2024-06-02 16:14:08 [INFO]: Epoch 029 - training loss: 0.4625, validation loss: 2.3381
2024-06-02 16:14:15 [INFO]: Epoch 030 - training loss: 0.4587, validation loss: 2.3296
2024-06-02 16:14:22 [INFO]: Epoch 031 - training loss: 0.4581, validation loss: 2.3268
2024-06-02 16:14:28 [INFO]: Epoch 032 - training loss: 0.4565, validation loss: 2.3177
2024-06-02 16:14:35 [INFO]: Epoch 033 - training loss: 0.4532, validation loss: 2.3375
2024-06-02 16:14:42 [INFO]: Epoch 034 - training loss: 0.4496, validation loss: 2.3250
2024-06-02 16:14:48 [INFO]: Epoch 035 - training loss: 0.4481, validation loss: 2.3162
2024-06-02 16:14:54 [INFO]: Epoch 036 - training loss: 0.4478, validation loss: 2.3278
2024-06-02 16:15:01 [INFO]: Epoch 037 - training loss: 0.4464, validation loss: 2.3315
2024-06-02 16:15:08 [INFO]: Epoch 038 - training loss: 0.4452, validation loss: 2.3391
2024-06-02 16:15:14 [INFO]: Epoch 039 - training loss: 0.4440, validation loss: 2.3457
2024-06-02 16:15:21 [INFO]: Epoch 040 - training loss: 0.4434, validation loss: 2.3167
2024-06-02 16:15:28 [INFO]: Epoch 041 - training loss: 0.4403, validation loss: 2.3260
2024-06-02 16:15:34 [INFO]: Epoch 042 - training loss: 0.4364, validation loss: 2.3218
2024-06-02 16:15:41 [INFO]: Epoch 043 - training loss: 0.4394, validation loss: 2.3141
2024-06-02 16:15:48 [INFO]: Epoch 044 - training loss: 0.4382, validation loss: 2.3172
2024-06-02 16:15:54 [INFO]: Epoch 045 - training loss: 0.4341, validation loss: 2.3166
2024-06-02 16:16:01 [INFO]: Epoch 046 - training loss: 0.4340, validation loss: 2.3000
2024-06-02 16:16:08 [INFO]: Epoch 047 - training loss: 0.4319, validation loss: 2.3106
2024-06-02 16:16:14 [INFO]: Epoch 048 - training loss: 0.4309, validation loss: 2.3066
2024-06-02 16:16:21 [INFO]: Epoch 049 - training loss: 0.4306, validation loss: 2.3120
2024-06-02 16:16:28 [INFO]: Epoch 050 - training loss: 0.4295, validation loss: 2.2857
2024-06-02 16:16:34 [INFO]: Epoch 051 - training loss: 0.4281, validation loss: 2.2858
2024-06-02 16:16:41 [INFO]: Epoch 052 - training loss: 0.4259, validation loss: 2.2787
2024-06-02 16:16:47 [INFO]: Epoch 053 - training loss: 0.4289, validation loss: 2.3042
2024-06-02 16:16:53 [INFO]: Epoch 054 - training loss: 0.4257, validation loss: 2.2963
2024-06-02 16:16:59 [INFO]: Epoch 055 - training loss: 0.4221, validation loss: 2.2788
2024-06-02 16:17:05 [INFO]: Epoch 056 - training loss: 0.4230, validation loss: 2.2914
2024-06-02 16:17:12 [INFO]: Epoch 057 - training loss: 0.4239, validation loss: 2.2669
2024-06-02 16:17:18 [INFO]: Epoch 058 - training loss: 0.4213, validation loss: 2.2928
2024-06-02 16:17:25 [INFO]: Epoch 059 - training loss: 0.4211, validation loss: 2.2757
2024-06-02 16:17:31 [INFO]: Epoch 060 - training loss: 0.4206, validation loss: 2.2779
2024-06-02 16:17:38 [INFO]: Epoch 061 - training loss: 0.4203, validation loss: 2.2917
2024-06-02 16:17:44 [INFO]: Epoch 062 - training loss: 0.4165, validation loss: 2.2722
2024-06-02 16:17:51 [INFO]: Epoch 063 - training loss: 0.4156, validation loss: 2.2713
2024-06-02 16:17:57 [INFO]: Epoch 064 - training loss: 0.4150, validation loss: 2.2618
2024-06-02 16:18:04 [INFO]: Epoch 065 - training loss: 0.4140, validation loss: 2.2673
2024-06-02 16:18:10 [INFO]: Epoch 066 - training loss: 0.4146, validation loss: 2.2583
2024-06-02 16:18:17 [INFO]: Epoch 067 - training loss: 0.4183, validation loss: 2.2359
2024-06-02 16:18:23 [INFO]: Epoch 068 - training loss: 0.4158, validation loss: 2.2460
2024-06-02 16:18:29 [INFO]: Epoch 069 - training loss: 0.4188, validation loss: 2.2754
2024-06-02 16:18:36 [INFO]: Epoch 070 - training loss: 0.4169, validation loss: 2.2668
2024-06-02 16:18:43 [INFO]: Epoch 071 - training loss: 0.4116, validation loss: 2.2589
2024-06-02 16:18:50 [INFO]: Epoch 072 - training loss: 0.4120, validation loss: 2.2456
2024-06-02 16:18:57 [INFO]: Epoch 073 - training loss: 0.4098, validation loss: 2.2506
2024-06-02 16:19:03 [INFO]: Epoch 074 - training loss: 0.4116, validation loss: 2.2362
2024-06-02 16:19:10 [INFO]: Epoch 075 - training loss: 0.4090, validation loss: 2.2238
2024-06-02 16:19:16 [INFO]: Epoch 076 - training loss: 0.4073, validation loss: 2.2216
2024-06-02 16:19:23 [INFO]: Epoch 077 - training loss: 0.4077, validation loss: 2.2237
2024-06-02 16:19:30 [INFO]: Epoch 078 - training loss: 0.4068, validation loss: 2.2361
2024-06-02 16:19:36 [INFO]: Epoch 079 - training loss: 0.4081, validation loss: 2.2346
2024-06-02 16:19:43 [INFO]: Epoch 080 - training loss: 0.4062, validation loss: 2.2313
2024-06-02 16:19:50 [INFO]: Epoch 081 - training loss: 0.4056, validation loss: 2.2056
2024-06-02 16:19:56 [INFO]: Epoch 082 - training loss: 0.4048, validation loss: 2.2146
2024-06-02 16:20:03 [INFO]: Epoch 083 - training loss: 0.4048, validation loss: 2.2121
2024-06-02 16:20:10 [INFO]: Epoch 084 - training loss: 0.4037, validation loss: 2.2081
2024-06-02 16:20:17 [INFO]: Epoch 085 - training loss: 0.4028, validation loss: 2.2036
2024-06-02 16:20:23 [INFO]: Epoch 086 - training loss: 0.4043, validation loss: 2.2121
2024-06-02 16:20:30 [INFO]: Epoch 087 - training loss: 0.4010, validation loss: 2.2113
2024-06-02 16:20:36 [INFO]: Epoch 088 - training loss: 0.4018, validation loss: 2.1996
2024-06-02 16:20:42 [INFO]: Epoch 089 - training loss: 0.4025, validation loss: 2.2145
2024-06-02 16:20:49 [INFO]: Epoch 090 - training loss: 0.4017, validation loss: 2.2151
2024-06-02 16:20:56 [INFO]: Epoch 091 - training loss: 0.4015, validation loss: 2.2094
2024-06-02 16:21:02 [INFO]: Epoch 092 - training loss: 0.4022, validation loss: 2.2288
2024-06-02 16:21:09 [INFO]: Epoch 093 - training loss: 0.4015, validation loss: 2.2288
2024-06-02 16:21:16 [INFO]: Epoch 094 - training loss: 0.4005, validation loss: 2.2132
2024-06-02 16:21:22 [INFO]: Epoch 095 - training loss: 0.3978, validation loss: 2.2159
2024-06-02 16:21:28 [INFO]: Epoch 096 - training loss: 0.3972, validation loss: 2.2106
2024-06-02 16:21:35 [INFO]: Epoch 097 - training loss: 0.3991, validation loss: 2.2233
2024-06-02 16:21:41 [INFO]: Epoch 098 - training loss: 0.3984, validation loss: 2.2192
2024-06-02 16:21:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 16:21:41 [INFO]: Finished training. The best model is from epoch#88.
2024-06-02 16:21:42 [INFO]: Saved the model to results_point_rate01/Electricity/Pyraformer_Electricity/round_4/20240602_T161054/Pyraformer.pypots
2024-06-02 16:21:43 [INFO]: Successfully saved to results_point_rate01/Electricity/Pyraformer_Electricity/round_4/imputation.pkl
2024-06-02 16:21:43 [INFO]: Round4 - Pyraformer on Electricity: MAE=1.1167, MSE=2.3937, MRE=0.5974
2024-06-02 16:21:43 [INFO]: Done! Final results:
Averaged Pyraformer (15,940,914 params) on Electricity: MAE=1.0957 ± 0.03284248082134876, MSE=2.2779 ± 0.17337067981293247, MRE=0.5862 ± 0.017569197759193123, average inference time=1.00
