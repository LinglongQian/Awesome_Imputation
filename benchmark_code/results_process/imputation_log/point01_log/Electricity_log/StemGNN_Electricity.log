2024-06-02 15:18:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 15:18:58 [INFO]: Using the given device: cuda:0
2024-06-02 15:18:58 [INFO]: Model files will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_0/20240602_T151858
2024-06-02 15:18:58 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_0/20240602_T151858/tensorboard
2024-06-02 15:18:59 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-02 15:19:27 [INFO]: Epoch 001 - training loss: 1.4860, validation loss: 3.6662
2024-06-02 15:19:49 [INFO]: Epoch 002 - training loss: 1.1869, validation loss: 3.5168
2024-06-02 15:20:11 [INFO]: Epoch 003 - training loss: 1.0442, validation loss: 3.4201
2024-06-02 15:20:34 [INFO]: Epoch 004 - training loss: 0.8889, validation loss: 3.2289
2024-06-02 15:20:56 [INFO]: Epoch 005 - training loss: 0.7375, validation loss: 3.0658
2024-06-02 15:21:19 [INFO]: Epoch 006 - training loss: 0.6837, validation loss: 3.0046
2024-06-02 15:21:41 [INFO]: Epoch 007 - training loss: 0.6605, validation loss: 2.9912
2024-06-02 15:22:04 [INFO]: Epoch 008 - training loss: 0.6402, validation loss: 2.9963
2024-06-02 15:22:26 [INFO]: Epoch 009 - training loss: 0.6200, validation loss: 2.9998
2024-06-02 15:22:49 [INFO]: Epoch 010 - training loss: 0.6010, validation loss: 2.9939
2024-06-02 15:23:11 [INFO]: Epoch 011 - training loss: 0.5854, validation loss: 2.9794
2024-06-02 15:23:34 [INFO]: Epoch 012 - training loss: 0.5731, validation loss: 2.9675
2024-06-02 15:23:56 [INFO]: Epoch 013 - training loss: 0.5609, validation loss: 2.9645
2024-06-02 15:24:19 [INFO]: Epoch 014 - training loss: 0.5500, validation loss: 2.9624
2024-06-02 15:24:42 [INFO]: Epoch 015 - training loss: 0.5424, validation loss: 2.9454
2024-06-02 15:25:04 [INFO]: Epoch 016 - training loss: 0.5349, validation loss: 2.9213
2024-06-02 15:25:27 [INFO]: Epoch 017 - training loss: 0.5280, validation loss: 2.9043
2024-06-02 15:25:50 [INFO]: Epoch 018 - training loss: 0.5222, validation loss: 2.8935
2024-06-02 15:26:12 [INFO]: Epoch 019 - training loss: 0.5164, validation loss: 2.8838
2024-06-02 15:26:34 [INFO]: Epoch 020 - training loss: 0.5116, validation loss: 2.8803
2024-06-02 15:26:56 [INFO]: Epoch 021 - training loss: 0.5056, validation loss: 2.8730
2024-06-02 15:27:19 [INFO]: Epoch 022 - training loss: 0.5010, validation loss: 2.8621
2024-06-02 15:27:41 [INFO]: Epoch 023 - training loss: 0.4975, validation loss: 2.8458
2024-06-02 15:28:03 [INFO]: Epoch 024 - training loss: 0.4936, validation loss: 2.8423
2024-06-02 15:28:26 [INFO]: Epoch 025 - training loss: 0.4896, validation loss: 2.8296
2024-06-02 15:28:48 [INFO]: Epoch 026 - training loss: 0.4865, validation loss: 2.8293
2024-06-02 15:29:11 [INFO]: Epoch 027 - training loss: 0.4828, validation loss: 2.8104
2024-06-02 15:29:33 [INFO]: Epoch 028 - training loss: 0.4803, validation loss: 2.8097
2024-06-02 15:29:56 [INFO]: Epoch 029 - training loss: 0.4764, validation loss: 2.7916
2024-06-02 15:30:18 [INFO]: Epoch 030 - training loss: 0.4730, validation loss: 2.7858
2024-06-02 15:30:40 [INFO]: Epoch 031 - training loss: 0.4708, validation loss: 2.7715
2024-06-02 15:31:03 [INFO]: Epoch 032 - training loss: 0.4680, validation loss: 2.7688
2024-06-02 15:31:25 [INFO]: Epoch 033 - training loss: 0.4645, validation loss: 2.7713
2024-06-02 15:31:48 [INFO]: Epoch 034 - training loss: 0.4631, validation loss: 2.7584
2024-06-02 15:32:10 [INFO]: Epoch 035 - training loss: 0.4593, validation loss: 2.7453
2024-06-02 15:32:33 [INFO]: Epoch 036 - training loss: 0.4569, validation loss: 2.7447
2024-06-02 15:32:55 [INFO]: Epoch 037 - training loss: 0.4548, validation loss: 2.7375
2024-06-02 15:33:18 [INFO]: Epoch 038 - training loss: 0.4536, validation loss: 2.7197
2024-06-02 15:33:40 [INFO]: Epoch 039 - training loss: 0.4516, validation loss: 2.7261
2024-06-02 15:34:03 [INFO]: Epoch 040 - training loss: 0.4490, validation loss: 2.7181
2024-06-02 15:34:25 [INFO]: Epoch 041 - training loss: 0.4470, validation loss: 2.7171
2024-06-02 15:34:47 [INFO]: Epoch 042 - training loss: 0.4450, validation loss: 2.7106
2024-06-02 15:35:09 [INFO]: Epoch 043 - training loss: 0.4433, validation loss: 2.7041
2024-06-02 15:35:32 [INFO]: Epoch 044 - training loss: 0.4415, validation loss: 2.7129
2024-06-02 15:35:55 [INFO]: Epoch 045 - training loss: 0.4401, validation loss: 2.7085
2024-06-02 15:36:17 [INFO]: Epoch 046 - training loss: 0.4377, validation loss: 2.6893
2024-06-02 15:36:40 [INFO]: Epoch 047 - training loss: 0.4371, validation loss: 2.6968
2024-06-02 15:37:02 [INFO]: Epoch 048 - training loss: 0.4353, validation loss: 2.6924
2024-06-02 15:37:24 [INFO]: Epoch 049 - training loss: 0.4341, validation loss: 2.6866
2024-06-02 15:37:47 [INFO]: Epoch 050 - training loss: 0.4320, validation loss: 2.6732
2024-06-02 15:38:09 [INFO]: Epoch 051 - training loss: 0.4311, validation loss: 2.6703
2024-06-02 15:38:32 [INFO]: Epoch 052 - training loss: 0.4291, validation loss: 2.6811
2024-06-02 15:38:54 [INFO]: Epoch 053 - training loss: 0.4277, validation loss: 2.6630
2024-06-02 15:39:17 [INFO]: Epoch 054 - training loss: 0.4266, validation loss: 2.6521
2024-06-02 15:39:40 [INFO]: Epoch 055 - training loss: 0.4248, validation loss: 2.6514
2024-06-02 15:40:02 [INFO]: Epoch 056 - training loss: 0.4238, validation loss: 2.6545
2024-06-02 15:40:25 [INFO]: Epoch 057 - training loss: 0.4222, validation loss: 2.6399
2024-06-02 15:40:47 [INFO]: Epoch 058 - training loss: 0.4217, validation loss: 2.6424
2024-06-02 15:41:10 [INFO]: Epoch 059 - training loss: 0.4205, validation loss: 2.6371
2024-06-02 15:41:29 [INFO]: Epoch 060 - training loss: 0.4190, validation loss: 2.6358
2024-06-02 15:41:48 [INFO]: Epoch 061 - training loss: 0.4175, validation loss: 2.6310
2024-06-02 15:42:10 [INFO]: Epoch 062 - training loss: 0.4156, validation loss: 2.6245
2024-06-02 15:42:33 [INFO]: Epoch 063 - training loss: 0.4146, validation loss: 2.6209
2024-06-02 15:42:55 [INFO]: Epoch 064 - training loss: 0.4140, validation loss: 2.6103
2024-06-02 15:43:18 [INFO]: Epoch 065 - training loss: 0.4127, validation loss: 2.6055
2024-06-02 15:43:40 [INFO]: Epoch 066 - training loss: 0.4124, validation loss: 2.6048
2024-06-02 15:44:03 [INFO]: Epoch 067 - training loss: 0.4114, validation loss: 2.6015
2024-06-02 15:44:25 [INFO]: Epoch 068 - training loss: 0.4102, validation loss: 2.5956
2024-06-02 15:44:47 [INFO]: Epoch 069 - training loss: 0.4091, validation loss: 2.5879
2024-06-02 15:45:10 [INFO]: Epoch 070 - training loss: 0.4074, validation loss: 2.5946
2024-06-02 15:45:32 [INFO]: Epoch 071 - training loss: 0.4060, validation loss: 2.5866
2024-06-02 15:45:55 [INFO]: Epoch 072 - training loss: 0.4055, validation loss: 2.5792
2024-06-02 15:46:17 [INFO]: Epoch 073 - training loss: 0.4044, validation loss: 2.5831
2024-06-02 15:46:40 [INFO]: Epoch 074 - training loss: 0.4033, validation loss: 2.5742
2024-06-02 15:47:03 [INFO]: Epoch 075 - training loss: 0.4032, validation loss: 2.5716
2024-06-02 15:47:25 [INFO]: Epoch 076 - training loss: 0.4021, validation loss: 2.5623
2024-06-02 15:47:48 [INFO]: Epoch 077 - training loss: 0.4006, validation loss: 2.5695
2024-06-02 15:48:11 [INFO]: Epoch 078 - training loss: 0.4012, validation loss: 2.5552
2024-06-02 15:48:33 [INFO]: Epoch 079 - training loss: 0.3992, validation loss: 2.5593
2024-06-02 15:48:56 [INFO]: Epoch 080 - training loss: 0.3984, validation loss: 2.5582
2024-06-02 15:49:18 [INFO]: Epoch 081 - training loss: 0.3980, validation loss: 2.5671
2024-06-02 15:49:41 [INFO]: Epoch 082 - training loss: 0.3969, validation loss: 2.5590
2024-06-02 15:50:02 [INFO]: Epoch 083 - training loss: 0.3961, validation loss: 2.5477
2024-06-02 15:50:25 [INFO]: Epoch 084 - training loss: 0.3949, validation loss: 2.5499
2024-06-02 15:50:48 [INFO]: Epoch 085 - training loss: 0.3949, validation loss: 2.5576
2024-06-02 15:51:10 [INFO]: Epoch 086 - training loss: 0.3934, validation loss: 2.5470
2024-06-02 15:51:32 [INFO]: Epoch 087 - training loss: 0.3930, validation loss: 2.5525
2024-06-02 15:51:55 [INFO]: Epoch 088 - training loss: 0.3918, validation loss: 2.5485
2024-06-02 15:52:17 [INFO]: Epoch 089 - training loss: 0.3914, validation loss: 2.5542
2024-06-02 15:52:40 [INFO]: Epoch 090 - training loss: 0.3908, validation loss: 2.5432
2024-06-02 15:53:02 [INFO]: Epoch 091 - training loss: 0.3900, validation loss: 2.5368
2024-06-02 15:53:25 [INFO]: Epoch 092 - training loss: 0.3895, validation loss: 2.5408
2024-06-02 15:53:47 [INFO]: Epoch 093 - training loss: 0.3890, validation loss: 2.5472
2024-06-02 15:54:10 [INFO]: Epoch 094 - training loss: 0.3878, validation loss: 2.5399
2024-06-02 15:54:32 [INFO]: Epoch 095 - training loss: 0.3868, validation loss: 2.5329
2024-06-02 15:54:52 [INFO]: Epoch 096 - training loss: 0.3875, validation loss: 2.5359
2024-06-02 15:55:10 [INFO]: Epoch 097 - training loss: 0.3864, validation loss: 2.5282
2024-06-02 15:55:33 [INFO]: Epoch 098 - training loss: 0.3857, validation loss: 2.5258
2024-06-02 15:55:55 [INFO]: Epoch 099 - training loss: 0.3849, validation loss: 2.5223
2024-06-02 15:56:18 [INFO]: Epoch 100 - training loss: 0.3842, validation loss: 2.5251
2024-06-02 15:56:18 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 15:56:18 [INFO]: Saved the model to results_point_rate01/Electricity/StemGNN_Electricity/round_0/20240602_T151858/StemGNN.pypots
2024-06-02 15:56:20 [INFO]: Successfully saved to results_point_rate01/Electricity/StemGNN_Electricity/round_0/imputation.pkl
2024-06-02 15:56:20 [INFO]: Round0 - StemGNN on Electricity: MAE=1.4086, MSE=3.7268, MRE=0.7535
2024-06-02 15:56:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 15:56:20 [INFO]: Using the given device: cuda:0
2024-06-02 15:56:20 [INFO]: Model files will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_1/20240602_T155620
2024-06-02 15:56:20 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_1/20240602_T155620/tensorboard
2024-06-02 15:56:21 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-02 15:56:43 [INFO]: Epoch 001 - training loss: 1.4889, validation loss: 3.6519
2024-06-02 15:57:06 [INFO]: Epoch 002 - training loss: 1.1864, validation loss: 3.5126
2024-06-02 15:57:29 [INFO]: Epoch 003 - training loss: 1.0415, validation loss: 3.4376
2024-06-02 15:57:51 [INFO]: Epoch 004 - training loss: 0.9115, validation loss: 3.2998
2024-06-02 15:58:09 [INFO]: Epoch 005 - training loss: 0.7892, validation loss: 3.2003
2024-06-02 15:58:27 [INFO]: Epoch 006 - training loss: 0.7043, validation loss: 3.1069
2024-06-02 15:58:44 [INFO]: Epoch 007 - training loss: 0.6653, validation loss: 3.0286
2024-06-02 15:59:01 [INFO]: Epoch 008 - training loss: 0.6448, validation loss: 2.9849
2024-06-02 15:59:19 [INFO]: Epoch 009 - training loss: 0.6253, validation loss: 2.9306
2024-06-02 15:59:37 [INFO]: Epoch 010 - training loss: 0.6042, validation loss: 2.8904
2024-06-02 15:59:54 [INFO]: Epoch 011 - training loss: 0.5859, validation loss: 2.8566
2024-06-02 16:00:11 [INFO]: Epoch 012 - training loss: 0.5729, validation loss: 2.8205
2024-06-02 16:00:29 [INFO]: Epoch 013 - training loss: 0.5638, validation loss: 2.8018
2024-06-02 16:00:46 [INFO]: Epoch 014 - training loss: 0.5547, validation loss: 2.7944
2024-06-02 16:01:03 [INFO]: Epoch 015 - training loss: 0.5458, validation loss: 2.7855
2024-06-02 16:01:21 [INFO]: Epoch 016 - training loss: 0.5365, validation loss: 2.7797
2024-06-02 16:01:39 [INFO]: Epoch 017 - training loss: 0.5284, validation loss: 2.7705
2024-06-02 16:01:56 [INFO]: Epoch 018 - training loss: 0.5207, validation loss: 2.7592
2024-06-02 16:02:13 [INFO]: Epoch 019 - training loss: 0.5150, validation loss: 2.7554
2024-06-02 16:02:31 [INFO]: Epoch 020 - training loss: 0.5100, validation loss: 2.7467
2024-06-02 16:02:48 [INFO]: Epoch 021 - training loss: 0.5056, validation loss: 2.7523
2024-06-02 16:03:06 [INFO]: Epoch 022 - training loss: 0.5009, validation loss: 2.7416
2024-06-02 16:03:23 [INFO]: Epoch 023 - training loss: 0.4963, validation loss: 2.7326
2024-06-02 16:03:41 [INFO]: Epoch 024 - training loss: 0.4921, validation loss: 2.7312
2024-06-02 16:03:58 [INFO]: Epoch 025 - training loss: 0.4887, validation loss: 2.7174
2024-06-02 16:04:16 [INFO]: Epoch 026 - training loss: 0.4856, validation loss: 2.7132
2024-06-02 16:04:33 [INFO]: Epoch 027 - training loss: 0.4825, validation loss: 2.7100
2024-06-02 16:04:50 [INFO]: Epoch 028 - training loss: 0.4797, validation loss: 2.6906
2024-06-02 16:05:08 [INFO]: Epoch 029 - training loss: 0.4777, validation loss: 2.6965
2024-06-02 16:05:25 [INFO]: Epoch 030 - training loss: 0.4748, validation loss: 2.7004
2024-06-02 16:05:43 [INFO]: Epoch 031 - training loss: 0.4719, validation loss: 2.6848
2024-06-02 16:06:01 [INFO]: Epoch 032 - training loss: 0.4701, validation loss: 2.6895
2024-06-02 16:06:18 [INFO]: Epoch 033 - training loss: 0.4669, validation loss: 2.6878
2024-06-02 16:06:36 [INFO]: Epoch 034 - training loss: 0.4647, validation loss: 2.6736
2024-06-02 16:06:53 [INFO]: Epoch 035 - training loss: 0.4627, validation loss: 2.6647
2024-06-02 16:07:11 [INFO]: Epoch 036 - training loss: 0.4606, validation loss: 2.6628
2024-06-02 16:07:29 [INFO]: Epoch 037 - training loss: 0.4582, validation loss: 2.6664
2024-06-02 16:07:47 [INFO]: Epoch 038 - training loss: 0.4561, validation loss: 2.6578
2024-06-02 16:08:04 [INFO]: Epoch 039 - training loss: 0.4538, validation loss: 2.6470
2024-06-02 16:08:22 [INFO]: Epoch 040 - training loss: 0.4517, validation loss: 2.6597
2024-06-02 16:08:40 [INFO]: Epoch 041 - training loss: 0.4495, validation loss: 2.6464
2024-06-02 16:08:57 [INFO]: Epoch 042 - training loss: 0.4471, validation loss: 2.6506
2024-06-02 16:09:15 [INFO]: Epoch 043 - training loss: 0.4449, validation loss: 2.6336
2024-06-02 16:09:32 [INFO]: Epoch 044 - training loss: 0.4437, validation loss: 2.6330
2024-06-02 16:09:49 [INFO]: Epoch 045 - training loss: 0.4418, validation loss: 2.6322
2024-06-02 16:10:07 [INFO]: Epoch 046 - training loss: 0.4396, validation loss: 2.6250
2024-06-02 16:10:25 [INFO]: Epoch 047 - training loss: 0.4379, validation loss: 2.6109
2024-06-02 16:10:42 [INFO]: Epoch 048 - training loss: 0.4363, validation loss: 2.6177
2024-06-02 16:11:00 [INFO]: Epoch 049 - training loss: 0.4343, validation loss: 2.6135
2024-06-02 16:11:17 [INFO]: Epoch 050 - training loss: 0.4336, validation loss: 2.6082
2024-06-02 16:11:35 [INFO]: Epoch 051 - training loss: 0.4323, validation loss: 2.6079
2024-06-02 16:11:52 [INFO]: Epoch 052 - training loss: 0.4307, validation loss: 2.5971
2024-06-02 16:12:10 [INFO]: Epoch 053 - training loss: 0.4285, validation loss: 2.5973
2024-06-02 16:12:28 [INFO]: Epoch 054 - training loss: 0.4274, validation loss: 2.5925
2024-06-02 16:12:45 [INFO]: Epoch 055 - training loss: 0.4257, validation loss: 2.5906
2024-06-02 16:13:03 [INFO]: Epoch 056 - training loss: 0.4247, validation loss: 2.5845
2024-06-02 16:13:21 [INFO]: Epoch 057 - training loss: 0.4231, validation loss: 2.5743
2024-06-02 16:13:38 [INFO]: Epoch 058 - training loss: 0.4220, validation loss: 2.5788
2024-06-02 16:13:55 [INFO]: Epoch 059 - training loss: 0.4204, validation loss: 2.5743
2024-06-02 16:14:13 [INFO]: Epoch 060 - training loss: 0.4196, validation loss: 2.5686
2024-06-02 16:14:31 [INFO]: Epoch 061 - training loss: 0.4183, validation loss: 2.5697
2024-06-02 16:14:48 [INFO]: Epoch 062 - training loss: 0.4168, validation loss: 2.5619
2024-06-02 16:15:06 [INFO]: Epoch 063 - training loss: 0.4157, validation loss: 2.5521
2024-06-02 16:15:23 [INFO]: Epoch 064 - training loss: 0.4144, validation loss: 2.5557
2024-06-02 16:15:41 [INFO]: Epoch 065 - training loss: 0.4134, validation loss: 2.5409
2024-06-02 16:15:58 [INFO]: Epoch 066 - training loss: 0.4125, validation loss: 2.5493
2024-06-02 16:16:16 [INFO]: Epoch 067 - training loss: 0.4116, validation loss: 2.5345
2024-06-02 16:16:34 [INFO]: Epoch 068 - training loss: 0.4104, validation loss: 2.5303
2024-06-02 16:16:49 [INFO]: Epoch 069 - training loss: 0.4102, validation loss: 2.5218
2024-06-02 16:17:03 [INFO]: Epoch 070 - training loss: 0.4091, validation loss: 2.5291
2024-06-02 16:17:20 [INFO]: Epoch 071 - training loss: 0.4073, validation loss: 2.5172
2024-06-02 16:17:37 [INFO]: Epoch 072 - training loss: 0.4065, validation loss: 2.5042
2024-06-02 16:17:55 [INFO]: Epoch 073 - training loss: 0.4052, validation loss: 2.5005
2024-06-02 16:18:13 [INFO]: Epoch 074 - training loss: 0.4045, validation loss: 2.4989
2024-06-02 16:18:30 [INFO]: Epoch 075 - training loss: 0.4040, validation loss: 2.4876
2024-06-02 16:18:48 [INFO]: Epoch 076 - training loss: 0.4029, validation loss: 2.4968
2024-06-02 16:19:05 [INFO]: Epoch 077 - training loss: 0.4020, validation loss: 2.4960
2024-06-02 16:19:23 [INFO]: Epoch 078 - training loss: 0.4006, validation loss: 2.4923
2024-06-02 16:19:41 [INFO]: Epoch 079 - training loss: 0.4003, validation loss: 2.4770
2024-06-02 16:19:59 [INFO]: Epoch 080 - training loss: 0.3992, validation loss: 2.4749
2024-06-02 16:20:16 [INFO]: Epoch 081 - training loss: 0.3982, validation loss: 2.4712
2024-06-02 16:20:34 [INFO]: Epoch 082 - training loss: 0.3973, validation loss: 2.4649
2024-06-02 16:20:51 [INFO]: Epoch 083 - training loss: 0.3970, validation loss: 2.4583
2024-06-02 16:21:09 [INFO]: Epoch 084 - training loss: 0.3959, validation loss: 2.4485
2024-06-02 16:21:26 [INFO]: Epoch 085 - training loss: 0.3955, validation loss: 2.4517
2024-06-02 16:21:44 [INFO]: Epoch 086 - training loss: 0.3959, validation loss: 2.4636
2024-06-02 16:21:59 [INFO]: Epoch 087 - training loss: 0.3942, validation loss: 2.4531
2024-06-02 16:22:14 [INFO]: Epoch 088 - training loss: 0.3935, validation loss: 2.4414
2024-06-02 16:22:29 [INFO]: Epoch 089 - training loss: 0.3928, validation loss: 2.4499
2024-06-02 16:22:44 [INFO]: Epoch 090 - training loss: 0.3919, validation loss: 2.4393
2024-06-02 16:23:00 [INFO]: Epoch 091 - training loss: 0.3913, validation loss: 2.4324
2024-06-02 16:23:15 [INFO]: Epoch 092 - training loss: 0.3907, validation loss: 2.4289
2024-06-02 16:23:30 [INFO]: Epoch 093 - training loss: 0.3903, validation loss: 2.4265
2024-06-02 16:23:45 [INFO]: Epoch 094 - training loss: 0.3900, validation loss: 2.4300
2024-06-02 16:24:00 [INFO]: Epoch 095 - training loss: 0.3886, validation loss: 2.4242
2024-06-02 16:24:15 [INFO]: Epoch 096 - training loss: 0.3877, validation loss: 2.4156
2024-06-02 16:24:31 [INFO]: Epoch 097 - training loss: 0.3877, validation loss: 2.4213
2024-06-02 16:24:46 [INFO]: Epoch 098 - training loss: 0.3872, validation loss: 2.4098
2024-06-02 16:25:01 [INFO]: Epoch 099 - training loss: 0.3868, validation loss: 2.4062
2024-06-02 16:25:16 [INFO]: Epoch 100 - training loss: 0.3868, validation loss: 2.4171
2024-06-02 16:25:16 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 16:25:16 [INFO]: Saved the model to results_point_rate01/Electricity/StemGNN_Electricity/round_1/20240602_T155620/StemGNN.pypots
2024-06-02 16:25:18 [INFO]: Successfully saved to results_point_rate01/Electricity/StemGNN_Electricity/round_1/imputation.pkl
2024-06-02 16:25:18 [INFO]: Round1 - StemGNN on Electricity: MAE=1.3468, MSE=3.5924, MRE=0.7205
2024-06-02 16:25:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 16:25:18 [INFO]: Using the given device: cuda:0
2024-06-02 16:25:18 [INFO]: Model files will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_2/20240602_T162518
2024-06-02 16:25:18 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_2/20240602_T162518/tensorboard
2024-06-02 16:25:18 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-02 16:25:34 [INFO]: Epoch 001 - training loss: 1.4844, validation loss: 3.6746
2024-06-02 16:25:49 [INFO]: Epoch 002 - training loss: 1.1866, validation loss: 3.5231
2024-06-02 16:26:04 [INFO]: Epoch 003 - training loss: 1.0040, validation loss: 3.3970
2024-06-02 16:26:19 [INFO]: Epoch 004 - training loss: 0.8413, validation loss: 3.1970
2024-06-02 16:26:34 [INFO]: Epoch 005 - training loss: 0.7526, validation loss: 3.1751
2024-06-02 16:26:49 [INFO]: Epoch 006 - training loss: 0.6863, validation loss: 3.1177
2024-06-02 16:27:04 [INFO]: Epoch 007 - training loss: 0.6480, validation loss: 3.0697
2024-06-02 16:27:20 [INFO]: Epoch 008 - training loss: 0.6247, validation loss: 3.0405
2024-06-02 16:27:35 [INFO]: Epoch 009 - training loss: 0.6017, validation loss: 2.9697
2024-06-02 16:27:50 [INFO]: Epoch 010 - training loss: 0.5800, validation loss: 2.9490
2024-06-02 16:28:05 [INFO]: Epoch 011 - training loss: 0.5644, validation loss: 2.9132
2024-06-02 16:28:20 [INFO]: Epoch 012 - training loss: 0.5556, validation loss: 2.9042
2024-06-02 16:28:36 [INFO]: Epoch 013 - training loss: 0.5493, validation loss: 2.8800
2024-06-02 16:28:51 [INFO]: Epoch 014 - training loss: 0.5433, validation loss: 2.8589
2024-06-02 16:29:06 [INFO]: Epoch 015 - training loss: 0.5364, validation loss: 2.8326
2024-06-02 16:29:21 [INFO]: Epoch 016 - training loss: 0.5294, validation loss: 2.8146
2024-06-02 16:29:36 [INFO]: Epoch 017 - training loss: 0.5239, validation loss: 2.7990
2024-06-02 16:29:51 [INFO]: Epoch 018 - training loss: 0.5189, validation loss: 2.7758
2024-06-02 16:30:07 [INFO]: Epoch 019 - training loss: 0.5135, validation loss: 2.7787
2024-06-02 16:30:22 [INFO]: Epoch 020 - training loss: 0.5096, validation loss: 2.7762
2024-06-02 16:30:37 [INFO]: Epoch 021 - training loss: 0.5042, validation loss: 2.7615
2024-06-02 16:30:52 [INFO]: Epoch 022 - training loss: 0.4982, validation loss: 2.7410
2024-06-02 16:31:07 [INFO]: Epoch 023 - training loss: 0.4956, validation loss: 2.7454
2024-06-02 16:31:22 [INFO]: Epoch 024 - training loss: 0.4905, validation loss: 2.7248
2024-06-02 16:31:38 [INFO]: Epoch 025 - training loss: 0.4872, validation loss: 2.7211
2024-06-02 16:31:53 [INFO]: Epoch 026 - training loss: 0.4841, validation loss: 2.7126
2024-06-02 16:32:08 [INFO]: Epoch 027 - training loss: 0.4811, validation loss: 2.7018
2024-06-02 16:32:23 [INFO]: Epoch 028 - training loss: 0.4787, validation loss: 2.6938
2024-06-02 16:32:38 [INFO]: Epoch 029 - training loss: 0.4759, validation loss: 2.6903
2024-06-02 16:32:53 [INFO]: Epoch 030 - training loss: 0.4730, validation loss: 2.6692
2024-06-02 16:33:08 [INFO]: Epoch 031 - training loss: 0.4705, validation loss: 2.6761
2024-06-02 16:33:24 [INFO]: Epoch 032 - training loss: 0.4688, validation loss: 2.6651
2024-06-02 16:33:39 [INFO]: Epoch 033 - training loss: 0.4665, validation loss: 2.6621
2024-06-02 16:33:54 [INFO]: Epoch 034 - training loss: 0.4635, validation loss: 2.6625
2024-06-02 16:34:09 [INFO]: Epoch 035 - training loss: 0.4605, validation loss: 2.6414
2024-06-02 16:34:24 [INFO]: Epoch 036 - training loss: 0.4581, validation loss: 2.6432
2024-06-02 16:34:40 [INFO]: Epoch 037 - training loss: 0.4557, validation loss: 2.6354
2024-06-02 16:34:55 [INFO]: Epoch 038 - training loss: 0.4530, validation loss: 2.6244
2024-06-02 16:35:10 [INFO]: Epoch 039 - training loss: 0.4515, validation loss: 2.6105
2024-06-02 16:35:25 [INFO]: Epoch 040 - training loss: 0.4495, validation loss: 2.6042
2024-06-02 16:35:35 [INFO]: Epoch 041 - training loss: 0.4472, validation loss: 2.6026
2024-06-02 16:35:49 [INFO]: Epoch 042 - training loss: 0.4462, validation loss: 2.5999
2024-06-02 16:36:04 [INFO]: Epoch 043 - training loss: 0.4437, validation loss: 2.5933
2024-06-02 16:36:19 [INFO]: Epoch 044 - training loss: 0.4419, validation loss: 2.5883
2024-06-02 16:36:35 [INFO]: Epoch 045 - training loss: 0.4411, validation loss: 2.5676
2024-06-02 16:36:50 [INFO]: Epoch 046 - training loss: 0.4384, validation loss: 2.5661
2024-06-02 16:37:05 [INFO]: Epoch 047 - training loss: 0.4374, validation loss: 2.5636
2024-06-02 16:37:20 [INFO]: Epoch 048 - training loss: 0.4349, validation loss: 2.5622
2024-06-02 16:37:35 [INFO]: Epoch 049 - training loss: 0.4335, validation loss: 2.5503
2024-06-02 16:37:51 [INFO]: Epoch 050 - training loss: 0.4319, validation loss: 2.5373
2024-06-02 16:38:06 [INFO]: Epoch 051 - training loss: 0.4305, validation loss: 2.5373
2024-06-02 16:38:21 [INFO]: Epoch 052 - training loss: 0.4305, validation loss: 2.5355
2024-06-02 16:38:36 [INFO]: Epoch 053 - training loss: 0.4277, validation loss: 2.5293
2024-06-02 16:38:51 [INFO]: Epoch 054 - training loss: 0.4261, validation loss: 2.5052
2024-06-02 16:39:06 [INFO]: Epoch 055 - training loss: 0.4246, validation loss: 2.5161
2024-06-02 16:39:22 [INFO]: Epoch 056 - training loss: 0.4227, validation loss: 2.5027
2024-06-02 16:39:37 [INFO]: Epoch 057 - training loss: 0.4224, validation loss: 2.4897
2024-06-02 16:39:52 [INFO]: Epoch 058 - training loss: 0.4209, validation loss: 2.4956
2024-06-02 16:40:07 [INFO]: Epoch 059 - training loss: 0.4211, validation loss: 2.4797
2024-06-02 16:40:22 [INFO]: Epoch 060 - training loss: 0.4198, validation loss: 2.4747
2024-06-02 16:40:37 [INFO]: Epoch 061 - training loss: 0.4175, validation loss: 2.4749
2024-06-02 16:40:53 [INFO]: Epoch 062 - training loss: 0.4164, validation loss: 2.4650
2024-06-02 16:41:08 [INFO]: Epoch 063 - training loss: 0.4148, validation loss: 2.4442
2024-06-02 16:41:23 [INFO]: Epoch 064 - training loss: 0.4151, validation loss: 2.4572
2024-06-02 16:41:38 [INFO]: Epoch 065 - training loss: 0.4125, validation loss: 2.4489
2024-06-02 16:41:54 [INFO]: Epoch 066 - training loss: 0.4114, validation loss: 2.4405
2024-06-02 16:42:09 [INFO]: Epoch 067 - training loss: 0.4112, validation loss: 2.4411
2024-06-02 16:42:24 [INFO]: Epoch 068 - training loss: 0.4102, validation loss: 2.4379
2024-06-02 16:42:39 [INFO]: Epoch 069 - training loss: 0.4092, validation loss: 2.4291
2024-06-02 16:42:54 [INFO]: Epoch 070 - training loss: 0.4081, validation loss: 2.4136
2024-06-02 16:43:10 [INFO]: Epoch 071 - training loss: 0.4073, validation loss: 2.4181
2024-06-02 16:43:25 [INFO]: Epoch 072 - training loss: 0.4062, validation loss: 2.4168
2024-06-02 16:43:40 [INFO]: Epoch 073 - training loss: 0.4052, validation loss: 2.4199
2024-06-02 16:43:55 [INFO]: Epoch 074 - training loss: 0.4058, validation loss: 2.4098
2024-06-02 16:44:10 [INFO]: Epoch 075 - training loss: 0.4035, validation loss: 2.3993
2024-06-02 16:44:25 [INFO]: Epoch 076 - training loss: 0.4027, validation loss: 2.4043
2024-06-02 16:44:40 [INFO]: Epoch 077 - training loss: 0.4016, validation loss: 2.3993
2024-06-02 16:44:56 [INFO]: Epoch 078 - training loss: 0.4007, validation loss: 2.3873
2024-06-02 16:45:11 [INFO]: Epoch 079 - training loss: 0.4007, validation loss: 2.3874
2024-06-02 16:45:26 [INFO]: Epoch 080 - training loss: 0.4002, validation loss: 2.3822
2024-06-02 16:45:41 [INFO]: Epoch 081 - training loss: 0.3991, validation loss: 2.3805
2024-06-02 16:45:56 [INFO]: Epoch 082 - training loss: 0.3980, validation loss: 2.3746
2024-06-02 16:46:11 [INFO]: Epoch 083 - training loss: 0.3966, validation loss: 2.3684
2024-06-02 16:46:27 [INFO]: Epoch 084 - training loss: 0.3960, validation loss: 2.3636
2024-06-02 16:46:42 [INFO]: Epoch 085 - training loss: 0.3962, validation loss: 2.3632
2024-06-02 16:46:57 [INFO]: Epoch 086 - training loss: 0.3952, validation loss: 2.3643
2024-06-02 16:47:12 [INFO]: Epoch 087 - training loss: 0.3945, validation loss: 2.3676
2024-06-02 16:47:27 [INFO]: Epoch 088 - training loss: 0.3936, validation loss: 2.3673
2024-06-02 16:47:42 [INFO]: Epoch 089 - training loss: 0.3944, validation loss: 2.3560
2024-06-02 16:47:57 [INFO]: Epoch 090 - training loss: 0.3931, validation loss: 2.3522
2024-06-02 16:48:13 [INFO]: Epoch 091 - training loss: 0.3923, validation loss: 2.3574
2024-06-02 16:48:28 [INFO]: Epoch 092 - training loss: 0.3910, validation loss: 2.3500
2024-06-02 16:48:43 [INFO]: Epoch 093 - training loss: 0.3902, validation loss: 2.3399
2024-06-02 16:48:58 [INFO]: Epoch 094 - training loss: 0.3910, validation loss: 2.3389
2024-06-02 16:49:13 [INFO]: Epoch 095 - training loss: 0.3890, validation loss: 2.3363
2024-06-02 16:49:28 [INFO]: Epoch 096 - training loss: 0.3885, validation loss: 2.3356
2024-06-02 16:49:44 [INFO]: Epoch 097 - training loss: 0.3885, validation loss: 2.3353
2024-06-02 16:49:59 [INFO]: Epoch 098 - training loss: 0.3878, validation loss: 2.3284
2024-06-02 16:50:14 [INFO]: Epoch 099 - training loss: 0.3863, validation loss: 2.3266
2024-06-02 16:50:29 [INFO]: Epoch 100 - training loss: 0.3862, validation loss: 2.3223
2024-06-02 16:50:29 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 16:50:29 [INFO]: Saved the model to results_point_rate01/Electricity/StemGNN_Electricity/round_2/20240602_T162518/StemGNN.pypots
2024-06-02 16:50:31 [INFO]: Successfully saved to results_point_rate01/Electricity/StemGNN_Electricity/round_2/imputation.pkl
2024-06-02 16:50:31 [INFO]: Round2 - StemGNN on Electricity: MAE=1.2305, MSE=3.0338, MRE=0.6583
2024-06-02 16:50:31 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 16:50:31 [INFO]: Using the given device: cuda:0
2024-06-02 16:50:31 [INFO]: Model files will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_3/20240602_T165031
2024-06-02 16:50:31 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_3/20240602_T165031/tensorboard
2024-06-02 16:50:31 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-02 16:50:40 [INFO]: Epoch 001 - training loss: 1.4969, validation loss: 3.6941
2024-06-02 16:50:47 [INFO]: Epoch 002 - training loss: 1.2127, validation loss: 3.5305
2024-06-02 16:50:55 [INFO]: Epoch 003 - training loss: 1.0370, validation loss: 3.4185
2024-06-02 16:51:02 [INFO]: Epoch 004 - training loss: 0.8610, validation loss: 3.2348
2024-06-02 16:51:10 [INFO]: Epoch 005 - training loss: 0.7207, validation loss: 3.1318
2024-06-02 16:51:17 [INFO]: Epoch 006 - training loss: 0.6711, validation loss: 3.0701
2024-06-02 16:51:25 [INFO]: Epoch 007 - training loss: 0.6492, validation loss: 3.0178
2024-06-02 16:51:32 [INFO]: Epoch 008 - training loss: 0.6350, validation loss: 3.0195
2024-06-02 16:51:40 [INFO]: Epoch 009 - training loss: 0.6197, validation loss: 2.9886
2024-06-02 16:51:47 [INFO]: Epoch 010 - training loss: 0.6015, validation loss: 2.9687
2024-06-02 16:51:55 [INFO]: Epoch 011 - training loss: 0.5824, validation loss: 2.9589
2024-06-02 16:52:02 [INFO]: Epoch 012 - training loss: 0.5674, validation loss: 2.9467
2024-06-02 16:52:10 [INFO]: Epoch 013 - training loss: 0.5540, validation loss: 2.9249
2024-06-02 16:52:18 [INFO]: Epoch 014 - training loss: 0.5439, validation loss: 2.9192
2024-06-02 16:52:25 [INFO]: Epoch 015 - training loss: 0.5357, validation loss: 2.9051
2024-06-02 16:52:33 [INFO]: Epoch 016 - training loss: 0.5276, validation loss: 2.9013
2024-06-02 16:52:40 [INFO]: Epoch 017 - training loss: 0.5208, validation loss: 2.8999
2024-06-02 16:52:48 [INFO]: Epoch 018 - training loss: 0.5150, validation loss: 2.8888
2024-06-02 16:52:55 [INFO]: Epoch 019 - training loss: 0.5096, validation loss: 2.8812
2024-06-02 16:53:03 [INFO]: Epoch 020 - training loss: 0.5050, validation loss: 2.8704
2024-06-02 16:53:10 [INFO]: Epoch 021 - training loss: 0.5000, validation loss: 2.8598
2024-06-02 16:53:18 [INFO]: Epoch 022 - training loss: 0.4953, validation loss: 2.8544
2024-06-02 16:53:25 [INFO]: Epoch 023 - training loss: 0.4902, validation loss: 2.8435
2024-06-02 16:53:33 [INFO]: Epoch 024 - training loss: 0.4855, validation loss: 2.8276
2024-06-02 16:53:40 [INFO]: Epoch 025 - training loss: 0.4818, validation loss: 2.8256
2024-06-02 16:53:48 [INFO]: Epoch 026 - training loss: 0.4783, validation loss: 2.8217
2024-06-02 16:53:55 [INFO]: Epoch 027 - training loss: 0.4753, validation loss: 2.8156
2024-06-02 16:54:03 [INFO]: Epoch 028 - training loss: 0.4723, validation loss: 2.8007
2024-06-02 16:54:11 [INFO]: Epoch 029 - training loss: 0.4688, validation loss: 2.7913
2024-06-02 16:54:18 [INFO]: Epoch 030 - training loss: 0.4655, validation loss: 2.7775
2024-06-02 16:54:26 [INFO]: Epoch 031 - training loss: 0.4630, validation loss: 2.7700
2024-06-02 16:54:33 [INFO]: Epoch 032 - training loss: 0.4597, validation loss: 2.7646
2024-06-02 16:54:41 [INFO]: Epoch 033 - training loss: 0.4576, validation loss: 2.7580
2024-06-02 16:54:48 [INFO]: Epoch 034 - training loss: 0.4553, validation loss: 2.7423
2024-06-02 16:54:56 [INFO]: Epoch 035 - training loss: 0.4527, validation loss: 2.7314
2024-06-02 16:55:03 [INFO]: Epoch 036 - training loss: 0.4513, validation loss: 2.7311
2024-06-02 16:55:11 [INFO]: Epoch 037 - training loss: 0.4480, validation loss: 2.7199
2024-06-02 16:55:18 [INFO]: Epoch 038 - training loss: 0.4457, validation loss: 2.7142
2024-06-02 16:55:26 [INFO]: Epoch 039 - training loss: 0.4430, validation loss: 2.7053
2024-06-02 16:55:33 [INFO]: Epoch 040 - training loss: 0.4411, validation loss: 2.6957
2024-06-02 16:55:41 [INFO]: Epoch 041 - training loss: 0.4407, validation loss: 2.6864
2024-06-02 16:55:48 [INFO]: Epoch 042 - training loss: 0.4373, validation loss: 2.6743
2024-06-02 16:55:56 [INFO]: Epoch 043 - training loss: 0.4352, validation loss: 2.6692
2024-06-02 16:56:03 [INFO]: Epoch 044 - training loss: 0.4328, validation loss: 2.6567
2024-06-02 16:56:11 [INFO]: Epoch 045 - training loss: 0.4317, validation loss: 2.6508
2024-06-02 16:56:19 [INFO]: Epoch 046 - training loss: 0.4294, validation loss: 2.6462
2024-06-02 16:56:26 [INFO]: Epoch 047 - training loss: 0.4291, validation loss: 2.6351
2024-06-02 16:56:34 [INFO]: Epoch 048 - training loss: 0.4268, validation loss: 2.6284
2024-06-02 16:56:41 [INFO]: Epoch 049 - training loss: 0.4250, validation loss: 2.6224
2024-06-02 16:56:49 [INFO]: Epoch 050 - training loss: 0.4231, validation loss: 2.6198
2024-06-02 16:56:56 [INFO]: Epoch 051 - training loss: 0.4216, validation loss: 2.6147
2024-06-02 16:57:04 [INFO]: Epoch 052 - training loss: 0.4204, validation loss: 2.6051
2024-06-02 16:57:11 [INFO]: Epoch 053 - training loss: 0.4184, validation loss: 2.6002
2024-06-02 16:57:19 [INFO]: Epoch 054 - training loss: 0.4171, validation loss: 2.5898
2024-06-02 16:57:26 [INFO]: Epoch 055 - training loss: 0.4157, validation loss: 2.5864
2024-06-02 16:57:34 [INFO]: Epoch 056 - training loss: 0.4150, validation loss: 2.5769
2024-06-02 16:57:41 [INFO]: Epoch 057 - training loss: 0.4131, validation loss: 2.5729
2024-06-02 16:57:49 [INFO]: Epoch 058 - training loss: 0.4112, validation loss: 2.5657
2024-06-02 16:57:56 [INFO]: Epoch 059 - training loss: 0.4106, validation loss: 2.5597
2024-06-02 16:58:04 [INFO]: Epoch 060 - training loss: 0.4098, validation loss: 2.5573
2024-06-02 16:58:11 [INFO]: Epoch 061 - training loss: 0.4099, validation loss: 2.5553
2024-06-02 16:58:19 [INFO]: Epoch 062 - training loss: 0.4091, validation loss: 2.5532
2024-06-02 16:58:27 [INFO]: Epoch 063 - training loss: 0.4058, validation loss: 2.5452
2024-06-02 16:58:34 [INFO]: Epoch 064 - training loss: 0.4046, validation loss: 2.5371
2024-06-02 16:58:42 [INFO]: Epoch 065 - training loss: 0.4042, validation loss: 2.5377
2024-06-02 16:58:49 [INFO]: Epoch 066 - training loss: 0.4028, validation loss: 2.5344
2024-06-02 16:58:57 [INFO]: Epoch 067 - training loss: 0.4016, validation loss: 2.5268
2024-06-02 16:59:04 [INFO]: Epoch 068 - training loss: 0.4005, validation loss: 2.5212
2024-06-02 16:59:12 [INFO]: Epoch 069 - training loss: 0.3994, validation loss: 2.5155
2024-06-02 16:59:19 [INFO]: Epoch 070 - training loss: 0.3986, validation loss: 2.5098
2024-06-02 16:59:27 [INFO]: Epoch 071 - training loss: 0.3977, validation loss: 2.5037
2024-06-02 16:59:34 [INFO]: Epoch 072 - training loss: 0.3974, validation loss: 2.5028
2024-06-02 16:59:42 [INFO]: Epoch 073 - training loss: 0.3957, validation loss: 2.4911
2024-06-02 16:59:49 [INFO]: Epoch 074 - training loss: 0.3947, validation loss: 2.4860
2024-06-02 16:59:57 [INFO]: Epoch 075 - training loss: 0.3940, validation loss: 2.4863
2024-06-02 17:00:04 [INFO]: Epoch 076 - training loss: 0.3935, validation loss: 2.4810
2024-06-02 17:00:12 [INFO]: Epoch 077 - training loss: 0.3921, validation loss: 2.4801
2024-06-02 17:00:20 [INFO]: Epoch 078 - training loss: 0.3912, validation loss: 2.4673
2024-06-02 17:00:27 [INFO]: Epoch 079 - training loss: 0.3906, validation loss: 2.4653
2024-06-02 17:00:35 [INFO]: Epoch 080 - training loss: 0.3904, validation loss: 2.4554
2024-06-02 17:00:42 [INFO]: Epoch 081 - training loss: 0.3900, validation loss: 2.4665
2024-06-02 17:00:50 [INFO]: Epoch 082 - training loss: 0.3886, validation loss: 2.4562
2024-06-02 17:00:57 [INFO]: Epoch 083 - training loss: 0.3877, validation loss: 2.4509
2024-06-02 17:01:05 [INFO]: Epoch 084 - training loss: 0.3871, validation loss: 2.4441
2024-06-02 17:01:12 [INFO]: Epoch 085 - training loss: 0.3859, validation loss: 2.4417
2024-06-02 17:01:20 [INFO]: Epoch 086 - training loss: 0.3861, validation loss: 2.4396
2024-06-02 17:01:27 [INFO]: Epoch 087 - training loss: 0.3850, validation loss: 2.4405
2024-06-02 17:01:35 [INFO]: Epoch 088 - training loss: 0.3842, validation loss: 2.4314
2024-06-02 17:01:42 [INFO]: Epoch 089 - training loss: 0.3832, validation loss: 2.4295
2024-06-02 17:01:50 [INFO]: Epoch 090 - training loss: 0.3827, validation loss: 2.4243
2024-06-02 17:01:57 [INFO]: Epoch 091 - training loss: 0.3825, validation loss: 2.4275
2024-06-02 17:02:05 [INFO]: Epoch 092 - training loss: 0.3817, validation loss: 2.4191
2024-06-02 17:02:12 [INFO]: Epoch 093 - training loss: 0.3809, validation loss: 2.4231
2024-06-02 17:02:20 [INFO]: Epoch 094 - training loss: 0.3801, validation loss: 2.4186
2024-06-02 17:02:28 [INFO]: Epoch 095 - training loss: 0.3794, validation loss: 2.4162
2024-06-02 17:02:35 [INFO]: Epoch 096 - training loss: 0.3790, validation loss: 2.4110
2024-06-02 17:02:43 [INFO]: Epoch 097 - training loss: 0.3783, validation loss: 2.4141
2024-06-02 17:02:50 [INFO]: Epoch 098 - training loss: 0.3782, validation loss: 2.4131
2024-06-02 17:02:58 [INFO]: Epoch 099 - training loss: 0.3768, validation loss: 2.4053
2024-06-02 17:03:05 [INFO]: Epoch 100 - training loss: 0.3768, validation loss: 2.4061
2024-06-02 17:03:05 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 17:03:05 [INFO]: Saved the model to results_point_rate01/Electricity/StemGNN_Electricity/round_3/20240602_T165031/StemGNN.pypots
2024-06-02 17:03:06 [INFO]: Successfully saved to results_point_rate01/Electricity/StemGNN_Electricity/round_3/imputation.pkl
2024-06-02 17:03:06 [INFO]: Round3 - StemGNN on Electricity: MAE=1.3491, MSE=3.7068, MRE=0.7217
2024-06-02 17:03:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 17:03:06 [INFO]: Using the given device: cuda:0
2024-06-02 17:03:06 [INFO]: Model files will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_4/20240602_T170306
2024-06-02 17:03:06 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/StemGNN_Electricity/round_4/20240602_T170306/tensorboard
2024-06-02 17:03:06 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-02 17:03:14 [INFO]: Epoch 001 - training loss: 1.4756, validation loss: 3.6835
2024-06-02 17:03:21 [INFO]: Epoch 002 - training loss: 1.2102, validation loss: 3.5374
2024-06-02 17:03:29 [INFO]: Epoch 003 - training loss: 1.0399, validation loss: 3.4941
2024-06-02 17:03:37 [INFO]: Epoch 004 - training loss: 0.8608, validation loss: 3.3931
2024-06-02 17:03:44 [INFO]: Epoch 005 - training loss: 0.7258, validation loss: 3.3216
2024-06-02 17:03:52 [INFO]: Epoch 006 - training loss: 0.6809, validation loss: 3.2790
2024-06-02 17:03:59 [INFO]: Epoch 007 - training loss: 0.6559, validation loss: 3.2563
2024-06-02 17:04:07 [INFO]: Epoch 008 - training loss: 0.6313, validation loss: 3.2428
2024-06-02 17:04:14 [INFO]: Epoch 009 - training loss: 0.6095, validation loss: 3.2395
2024-06-02 17:04:22 [INFO]: Epoch 010 - training loss: 0.5888, validation loss: 3.2193
2024-06-02 17:04:29 [INFO]: Epoch 011 - training loss: 0.5749, validation loss: 3.2034
2024-06-02 17:04:37 [INFO]: Epoch 012 - training loss: 0.5640, validation loss: 3.1881
2024-06-02 17:04:44 [INFO]: Epoch 013 - training loss: 0.5523, validation loss: 3.1568
2024-06-02 17:04:52 [INFO]: Epoch 014 - training loss: 0.5449, validation loss: 3.1358
2024-06-02 17:04:59 [INFO]: Epoch 015 - training loss: 0.5363, validation loss: 3.1226
2024-06-02 17:05:07 [INFO]: Epoch 016 - training loss: 0.5275, validation loss: 3.1005
2024-06-02 17:05:14 [INFO]: Epoch 017 - training loss: 0.5214, validation loss: 3.0744
2024-06-02 17:05:22 [INFO]: Epoch 018 - training loss: 0.5151, validation loss: 3.0649
2024-06-02 17:05:29 [INFO]: Epoch 019 - training loss: 0.5093, validation loss: 3.0535
2024-06-02 17:05:37 [INFO]: Epoch 020 - training loss: 0.5046, validation loss: 3.0274
2024-06-02 17:05:45 [INFO]: Epoch 021 - training loss: 0.4986, validation loss: 3.0129
2024-06-02 17:05:52 [INFO]: Epoch 022 - training loss: 0.4935, validation loss: 2.9938
2024-06-02 17:06:00 [INFO]: Epoch 023 - training loss: 0.4898, validation loss: 2.9866
2024-06-02 17:06:07 [INFO]: Epoch 024 - training loss: 0.4861, validation loss: 2.9718
2024-06-02 17:06:15 [INFO]: Epoch 025 - training loss: 0.4838, validation loss: 2.9596
2024-06-02 17:06:22 [INFO]: Epoch 026 - training loss: 0.4806, validation loss: 2.9464
2024-06-02 17:06:30 [INFO]: Epoch 027 - training loss: 0.4774, validation loss: 2.9484
2024-06-02 17:06:37 [INFO]: Epoch 028 - training loss: 0.4746, validation loss: 2.9388
2024-06-02 17:06:45 [INFO]: Epoch 029 - training loss: 0.4723, validation loss: 2.9332
2024-06-02 17:06:52 [INFO]: Epoch 030 - training loss: 0.4694, validation loss: 2.9208
2024-06-02 17:07:00 [INFO]: Epoch 031 - training loss: 0.4680, validation loss: 2.9097
2024-06-02 17:07:07 [INFO]: Epoch 032 - training loss: 0.4659, validation loss: 2.9097
2024-06-02 17:07:15 [INFO]: Epoch 033 - training loss: 0.4630, validation loss: 2.8982
2024-06-02 17:07:22 [INFO]: Epoch 034 - training loss: 0.4599, validation loss: 2.8950
2024-06-02 17:07:30 [INFO]: Epoch 035 - training loss: 0.4582, validation loss: 2.8854
2024-06-02 17:07:37 [INFO]: Epoch 036 - training loss: 0.4558, validation loss: 2.8760
2024-06-02 17:07:45 [INFO]: Epoch 037 - training loss: 0.4533, validation loss: 2.8855
2024-06-02 17:07:53 [INFO]: Epoch 038 - training loss: 0.4517, validation loss: 2.8661
2024-06-02 17:08:00 [INFO]: Epoch 039 - training loss: 0.4501, validation loss: 2.8615
2024-06-02 17:08:08 [INFO]: Epoch 040 - training loss: 0.4486, validation loss: 2.8600
2024-06-02 17:08:15 [INFO]: Epoch 041 - training loss: 0.4467, validation loss: 2.8612
2024-06-02 17:08:23 [INFO]: Epoch 042 - training loss: 0.4446, validation loss: 2.8536
2024-06-02 17:08:30 [INFO]: Epoch 043 - training loss: 0.4426, validation loss: 2.8411
2024-06-02 17:08:38 [INFO]: Epoch 044 - training loss: 0.4399, validation loss: 2.8319
2024-06-02 17:08:45 [INFO]: Epoch 045 - training loss: 0.4385, validation loss: 2.8321
2024-06-02 17:08:53 [INFO]: Epoch 046 - training loss: 0.4371, validation loss: 2.8242
2024-06-02 17:09:00 [INFO]: Epoch 047 - training loss: 0.4355, validation loss: 2.8246
2024-06-02 17:09:08 [INFO]: Epoch 048 - training loss: 0.4342, validation loss: 2.8173
2024-06-02 17:09:15 [INFO]: Epoch 049 - training loss: 0.4334, validation loss: 2.8125
2024-06-02 17:09:23 [INFO]: Epoch 050 - training loss: 0.4319, validation loss: 2.8096
2024-06-02 17:09:30 [INFO]: Epoch 051 - training loss: 0.4301, validation loss: 2.8008
2024-06-02 17:09:38 [INFO]: Epoch 052 - training loss: 0.4291, validation loss: 2.7982
2024-06-02 17:09:45 [INFO]: Epoch 053 - training loss: 0.4272, validation loss: 2.7877
2024-06-02 17:09:53 [INFO]: Epoch 054 - training loss: 0.4259, validation loss: 2.7862
2024-06-02 17:10:01 [INFO]: Epoch 055 - training loss: 0.4248, validation loss: 2.7820
2024-06-02 17:10:08 [INFO]: Epoch 056 - training loss: 0.4240, validation loss: 2.7742
2024-06-02 17:10:16 [INFO]: Epoch 057 - training loss: 0.4222, validation loss: 2.7714
2024-06-02 17:10:23 [INFO]: Epoch 058 - training loss: 0.4209, validation loss: 2.7668
2024-06-02 17:10:31 [INFO]: Epoch 059 - training loss: 0.4198, validation loss: 2.7601
2024-06-02 17:10:38 [INFO]: Epoch 060 - training loss: 0.4183, validation loss: 2.7568
2024-06-02 17:10:46 [INFO]: Epoch 061 - training loss: 0.4181, validation loss: 2.7540
2024-06-02 17:10:53 [INFO]: Epoch 062 - training loss: 0.4171, validation loss: 2.7494
2024-06-02 17:11:01 [INFO]: Epoch 063 - training loss: 0.4159, validation loss: 2.7415
2024-06-02 17:11:08 [INFO]: Epoch 064 - training loss: 0.4148, validation loss: 2.7306
2024-06-02 17:11:16 [INFO]: Epoch 065 - training loss: 0.4147, validation loss: 2.7345
2024-06-02 17:11:23 [INFO]: Epoch 066 - training loss: 0.4128, validation loss: 2.7283
2024-06-02 17:11:31 [INFO]: Epoch 067 - training loss: 0.4116, validation loss: 2.7233
2024-06-02 17:11:38 [INFO]: Epoch 068 - training loss: 0.4109, validation loss: 2.7194
2024-06-02 17:11:46 [INFO]: Epoch 069 - training loss: 0.4096, validation loss: 2.7121
2024-06-02 17:11:53 [INFO]: Epoch 070 - training loss: 0.4086, validation loss: 2.7103
2024-06-02 17:12:01 [INFO]: Epoch 071 - training loss: 0.4080, validation loss: 2.7072
2024-06-02 17:12:09 [INFO]: Epoch 072 - training loss: 0.4067, validation loss: 2.7001
2024-06-02 17:12:16 [INFO]: Epoch 073 - training loss: 0.4059, validation loss: 2.6951
2024-06-02 17:12:24 [INFO]: Epoch 074 - training loss: 0.4046, validation loss: 2.6917
2024-06-02 17:12:31 [INFO]: Epoch 075 - training loss: 0.4039, validation loss: 2.6856
2024-06-02 17:12:39 [INFO]: Epoch 076 - training loss: 0.4032, validation loss: 2.6788
2024-06-02 17:12:46 [INFO]: Epoch 077 - training loss: 0.4027, validation loss: 2.6766
2024-06-02 17:12:54 [INFO]: Epoch 078 - training loss: 0.4019, validation loss: 2.6729
2024-06-02 17:13:01 [INFO]: Epoch 079 - training loss: 0.4011, validation loss: 2.6723
2024-06-02 17:13:09 [INFO]: Epoch 080 - training loss: 0.3996, validation loss: 2.6673
2024-06-02 17:13:16 [INFO]: Epoch 081 - training loss: 0.3992, validation loss: 2.6659
2024-06-02 17:13:24 [INFO]: Epoch 082 - training loss: 0.3985, validation loss: 2.6581
2024-06-02 17:13:31 [INFO]: Epoch 083 - training loss: 0.3979, validation loss: 2.6595
2024-06-02 17:13:39 [INFO]: Epoch 084 - training loss: 0.3976, validation loss: 2.6547
2024-06-02 17:13:46 [INFO]: Epoch 085 - training loss: 0.3971, validation loss: 2.6522
2024-06-02 17:13:54 [INFO]: Epoch 086 - training loss: 0.3966, validation loss: 2.6509
2024-06-02 17:14:01 [INFO]: Epoch 087 - training loss: 0.3966, validation loss: 2.6503
2024-06-02 17:14:09 [INFO]: Epoch 088 - training loss: 0.3949, validation loss: 2.6474
2024-06-02 17:14:17 [INFO]: Epoch 089 - training loss: 0.3937, validation loss: 2.6419
2024-06-02 17:14:24 [INFO]: Epoch 090 - training loss: 0.3935, validation loss: 2.6377
2024-06-02 17:14:32 [INFO]: Epoch 091 - training loss: 0.3941, validation loss: 2.6444
2024-06-02 17:14:39 [INFO]: Epoch 092 - training loss: 0.3928, validation loss: 2.6369
2024-06-02 17:14:47 [INFO]: Epoch 093 - training loss: 0.3911, validation loss: 2.6301
2024-06-02 17:14:54 [INFO]: Epoch 094 - training loss: 0.3920, validation loss: 2.6338
2024-06-02 17:15:02 [INFO]: Epoch 095 - training loss: 0.3907, validation loss: 2.6337
2024-06-02 17:15:09 [INFO]: Epoch 096 - training loss: 0.3893, validation loss: 2.6233
2024-06-02 17:15:17 [INFO]: Epoch 097 - training loss: 0.3888, validation loss: 2.6176
2024-06-02 17:15:24 [INFO]: Epoch 098 - training loss: 0.3881, validation loss: 2.6242
2024-06-02 17:15:32 [INFO]: Epoch 099 - training loss: 0.3878, validation loss: 2.6193
2024-06-02 17:15:39 [INFO]: Epoch 100 - training loss: 0.3877, validation loss: 2.6180
2024-06-02 17:15:39 [INFO]: Finished training. The best model is from epoch#97.
2024-06-02 17:15:39 [INFO]: Saved the model to results_point_rate01/Electricity/StemGNN_Electricity/round_4/20240602_T170306/StemGNN.pypots
2024-06-02 17:15:40 [INFO]: Successfully saved to results_point_rate01/Electricity/StemGNN_Electricity/round_4/imputation.pkl
2024-06-02 17:15:40 [INFO]: Round4 - StemGNN on Electricity: MAE=1.4659, MSE=4.3075, MRE=0.7842
2024-06-02 17:15:40 [INFO]: Done! Final results:
Averaged StemGNN (16,863,634 params) on Electricity: MAE=1.3602 ± 0.07828116802284155, MSE=3.6735 ± 0.40537101520881547, MRE=0.7276 ± 0.041876779324170596, average inference time=1.48
