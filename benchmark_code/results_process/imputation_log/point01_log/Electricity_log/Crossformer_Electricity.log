2024-06-01 21:58:29 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:58:29 [INFO]: Using the given device: cuda:0
2024-06-01 21:58:29 [INFO]: Model files will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_0/20240601_T215829
2024-06-01 21:58:29 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_0/20240601_T215829/tensorboard
2024-06-01 21:58:30 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-01 21:58:47 [INFO]: Epoch 001 - training loss: 1.1334, validation loss: 3.2862
2024-06-01 21:59:04 [INFO]: Epoch 002 - training loss: 0.7568, validation loss: 2.8504
2024-06-01 21:59:22 [INFO]: Epoch 003 - training loss: 0.6504, validation loss: 2.6859
2024-06-01 21:59:41 [INFO]: Epoch 004 - training loss: 0.6025, validation loss: 2.5593
2024-06-01 21:59:59 [INFO]: Epoch 005 - training loss: 0.5704, validation loss: 2.4639
2024-06-01 22:00:18 [INFO]: Epoch 006 - training loss: 0.5482, validation loss: 2.3796
2024-06-01 22:00:37 [INFO]: Epoch 007 - training loss: 0.5302, validation loss: 2.3122
2024-06-01 22:00:55 [INFO]: Epoch 008 - training loss: 0.5142, validation loss: 2.2583
2024-06-01 22:01:14 [INFO]: Epoch 009 - training loss: 0.5019, validation loss: 2.1981
2024-06-01 22:01:33 [INFO]: Epoch 010 - training loss: 0.4874, validation loss: 2.1481
2024-06-01 22:01:52 [INFO]: Epoch 011 - training loss: 0.4754, validation loss: 2.0972
2024-06-01 22:02:10 [INFO]: Epoch 012 - training loss: 0.4666, validation loss: 2.0548
2024-06-01 22:02:28 [INFO]: Epoch 013 - training loss: 0.4595, validation loss: 2.0177
2024-06-01 22:02:46 [INFO]: Epoch 014 - training loss: 0.4524, validation loss: 1.9728
2024-06-01 22:03:03 [INFO]: Epoch 015 - training loss: 0.4462, validation loss: 1.9413
2024-06-01 22:03:22 [INFO]: Epoch 016 - training loss: 0.4402, validation loss: 1.9067
2024-06-01 22:03:41 [INFO]: Epoch 017 - training loss: 0.4358, validation loss: 1.8762
2024-06-01 22:03:59 [INFO]: Epoch 018 - training loss: 0.4310, validation loss: 1.8368
2024-06-01 22:04:18 [INFO]: Epoch 019 - training loss: 0.4284, validation loss: 1.8231
2024-06-01 22:04:36 [INFO]: Epoch 020 - training loss: 0.4237, validation loss: 1.7809
2024-06-01 22:04:55 [INFO]: Epoch 021 - training loss: 0.4191, validation loss: 1.7517
2024-06-01 22:05:13 [INFO]: Epoch 022 - training loss: 0.4152, validation loss: 1.7281
2024-06-01 22:05:32 [INFO]: Epoch 023 - training loss: 0.4125, validation loss: 1.7038
2024-06-01 22:05:50 [INFO]: Epoch 024 - training loss: 0.4100, validation loss: 1.6752
2024-06-01 22:06:09 [INFO]: Epoch 025 - training loss: 0.4093, validation loss: 1.6634
2024-06-01 22:06:27 [INFO]: Epoch 026 - training loss: 0.4049, validation loss: 1.6336
2024-06-01 22:06:44 [INFO]: Epoch 027 - training loss: 0.4007, validation loss: 1.6047
2024-06-01 22:07:02 [INFO]: Epoch 028 - training loss: 0.3993, validation loss: 1.5873
2024-06-01 22:07:20 [INFO]: Epoch 029 - training loss: 0.3976, validation loss: 1.5654
2024-06-01 22:07:39 [INFO]: Epoch 030 - training loss: 0.3978, validation loss: 1.5674
2024-06-01 22:07:58 [INFO]: Epoch 031 - training loss: 0.3936, validation loss: 1.5379
2024-06-01 22:08:17 [INFO]: Epoch 032 - training loss: 0.3910, validation loss: 1.5146
2024-06-01 22:08:35 [INFO]: Epoch 033 - training loss: 0.3896, validation loss: 1.4998
2024-06-01 22:08:54 [INFO]: Epoch 034 - training loss: 0.3899, validation loss: 1.4859
2024-06-01 22:09:13 [INFO]: Epoch 035 - training loss: 0.3888, validation loss: 1.4798
2024-06-01 22:09:31 [INFO]: Epoch 036 - training loss: 0.3857, validation loss: 1.4500
2024-06-01 22:09:50 [INFO]: Epoch 037 - training loss: 0.3846, validation loss: 1.4391
2024-06-01 22:10:08 [INFO]: Epoch 038 - training loss: 0.3840, validation loss: 1.4299
2024-06-01 22:10:26 [INFO]: Epoch 039 - training loss: 0.3816, validation loss: 1.4198
2024-06-01 22:10:43 [INFO]: Epoch 040 - training loss: 0.3822, validation loss: 1.4121
2024-06-01 22:11:01 [INFO]: Epoch 041 - training loss: 0.3802, validation loss: 1.3966
2024-06-01 22:11:20 [INFO]: Epoch 042 - training loss: 0.3787, validation loss: 1.3934
2024-06-01 22:11:39 [INFO]: Epoch 043 - training loss: 0.3769, validation loss: 1.3776
2024-06-01 22:11:57 [INFO]: Epoch 044 - training loss: 0.3765, validation loss: 1.3703
2024-06-01 22:12:16 [INFO]: Epoch 045 - training loss: 0.3756, validation loss: 1.3531
2024-06-01 22:12:34 [INFO]: Epoch 046 - training loss: 0.3753, validation loss: 1.3655
2024-06-01 22:12:53 [INFO]: Epoch 047 - training loss: 0.3737, validation loss: 1.3504
2024-06-01 22:13:12 [INFO]: Epoch 048 - training loss: 0.3738, validation loss: 1.3403
2024-06-01 22:13:31 [INFO]: Epoch 049 - training loss: 0.3723, validation loss: 1.3359
2024-06-01 22:13:49 [INFO]: Epoch 050 - training loss: 0.3710, validation loss: 1.3248
2024-06-01 22:14:07 [INFO]: Epoch 051 - training loss: 0.3717, validation loss: 1.3155
2024-06-01 22:14:24 [INFO]: Epoch 052 - training loss: 0.3696, validation loss: 1.3058
2024-06-01 22:14:42 [INFO]: Epoch 053 - training loss: 0.3691, validation loss: 1.3009
2024-06-01 22:15:00 [INFO]: Epoch 054 - training loss: 0.3692, validation loss: 1.3030
2024-06-01 22:15:17 [INFO]: Epoch 055 - training loss: 0.3692, validation loss: 1.2986
2024-06-01 22:15:34 [INFO]: Epoch 056 - training loss: 0.3679, validation loss: 1.2922
2024-06-01 22:15:51 [INFO]: Epoch 057 - training loss: 0.3673, validation loss: 1.2973
2024-06-01 22:16:08 [INFO]: Epoch 058 - training loss: 0.3673, validation loss: 1.2819
2024-06-01 22:16:25 [INFO]: Epoch 059 - training loss: 0.3651, validation loss: 1.2801
2024-06-01 22:16:42 [INFO]: Epoch 060 - training loss: 0.3651, validation loss: 1.2709
2024-06-01 22:16:59 [INFO]: Epoch 061 - training loss: 0.3640, validation loss: 1.2692
2024-06-01 22:17:16 [INFO]: Epoch 062 - training loss: 0.3638, validation loss: 1.2603
2024-06-01 22:17:33 [INFO]: Epoch 063 - training loss: 0.3640, validation loss: 1.2652
2024-06-01 22:17:49 [INFO]: Epoch 064 - training loss: 0.3624, validation loss: 1.2641
2024-06-01 22:18:04 [INFO]: Epoch 065 - training loss: 0.3623, validation loss: 1.2576
2024-06-01 22:18:21 [INFO]: Epoch 066 - training loss: 0.3627, validation loss: 1.2599
2024-06-01 22:18:38 [INFO]: Epoch 067 - training loss: 0.3613, validation loss: 1.2515
2024-06-01 22:18:55 [INFO]: Epoch 068 - training loss: 0.3606, validation loss: 1.2453
2024-06-01 22:19:12 [INFO]: Epoch 069 - training loss: 0.3600, validation loss: 1.2510
2024-06-01 22:19:28 [INFO]: Epoch 070 - training loss: 0.3602, validation loss: 1.2431
2024-06-01 22:19:45 [INFO]: Epoch 071 - training loss: 0.3600, validation loss: 1.2399
2024-06-01 22:20:02 [INFO]: Epoch 072 - training loss: 0.3594, validation loss: 1.2423
2024-06-01 22:20:19 [INFO]: Epoch 073 - training loss: 0.3611, validation loss: 1.2496
2024-06-01 22:20:36 [INFO]: Epoch 074 - training loss: 0.3587, validation loss: 1.2383
2024-06-01 22:20:53 [INFO]: Epoch 075 - training loss: 0.3579, validation loss: 1.2331
2024-06-01 22:21:10 [INFO]: Epoch 076 - training loss: 0.3575, validation loss: 1.2283
2024-06-01 22:21:26 [INFO]: Epoch 077 - training loss: 0.3574, validation loss: 1.2231
2024-06-01 22:21:42 [INFO]: Epoch 078 - training loss: 0.3566, validation loss: 1.2182
2024-06-01 22:21:59 [INFO]: Epoch 079 - training loss: 0.3565, validation loss: 1.2256
2024-06-01 22:22:15 [INFO]: Epoch 080 - training loss: 0.3563, validation loss: 1.2249
2024-06-01 22:22:33 [INFO]: Epoch 081 - training loss: 0.3569, validation loss: 1.2243
2024-06-01 22:22:49 [INFO]: Epoch 082 - training loss: 0.3556, validation loss: 1.2188
2024-06-01 22:23:06 [INFO]: Epoch 083 - training loss: 0.3562, validation loss: 1.2194
2024-06-01 22:23:23 [INFO]: Epoch 084 - training loss: 0.3544, validation loss: 1.2149
2024-06-01 22:23:40 [INFO]: Epoch 085 - training loss: 0.3545, validation loss: 1.2139
2024-06-01 22:23:57 [INFO]: Epoch 086 - training loss: 0.3549, validation loss: 1.2059
2024-06-01 22:24:14 [INFO]: Epoch 087 - training loss: 0.3538, validation loss: 1.2290
2024-06-01 22:24:31 [INFO]: Epoch 088 - training loss: 0.3542, validation loss: 1.2024
2024-06-01 22:24:48 [INFO]: Epoch 089 - training loss: 0.3534, validation loss: 1.2035
2024-06-01 22:25:04 [INFO]: Epoch 090 - training loss: 0.3529, validation loss: 1.2076
2024-06-01 22:25:19 [INFO]: Epoch 091 - training loss: 0.3563, validation loss: 1.2139
2024-06-01 22:25:36 [INFO]: Epoch 092 - training loss: 0.3551, validation loss: 1.2168
2024-06-01 22:25:53 [INFO]: Epoch 093 - training loss: 0.3537, validation loss: 1.2018
2024-06-01 22:26:10 [INFO]: Epoch 094 - training loss: 0.3531, validation loss: 1.2047
2024-06-01 22:26:27 [INFO]: Epoch 095 - training loss: 0.3517, validation loss: 1.1984
2024-06-01 22:26:44 [INFO]: Epoch 096 - training loss: 0.3514, validation loss: 1.1885
2024-06-01 22:27:01 [INFO]: Epoch 097 - training loss: 0.3519, validation loss: 1.1948
2024-06-01 22:27:18 [INFO]: Epoch 098 - training loss: 0.3510, validation loss: 1.1968
2024-06-01 22:27:35 [INFO]: Epoch 099 - training loss: 0.3503, validation loss: 1.1889
2024-06-01 22:27:52 [INFO]: Epoch 100 - training loss: 0.3500, validation loss: 1.1889
2024-06-01 22:27:52 [INFO]: Finished training. The best model is from epoch#96.
2024-06-01 22:27:52 [INFO]: Saved the model to results_point_rate01/Electricity/Crossformer_Electricity/round_0/20240601_T215829/Crossformer.pypots
2024-06-01 22:27:54 [INFO]: Successfully saved to results_point_rate01/Electricity/Crossformer_Electricity/round_0/imputation.pkl
2024-06-01 22:27:54 [INFO]: Round0 - Crossformer on Electricity: MAE=0.5719, MSE=0.6563, MRE=0.3059
2024-06-01 22:27:54 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:27:54 [INFO]: Using the given device: cuda:0
2024-06-01 22:27:54 [INFO]: Model files will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_1/20240601_T222754
2024-06-01 22:27:54 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_1/20240601_T222754/tensorboard
2024-06-01 22:27:54 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-01 22:28:11 [INFO]: Epoch 001 - training loss: 1.1300, validation loss: 3.2834
2024-06-01 22:28:28 [INFO]: Epoch 002 - training loss: 0.7402, validation loss: 2.8205
2024-06-01 22:28:43 [INFO]: Epoch 003 - training loss: 0.6368, validation loss: 2.6295
2024-06-01 22:28:59 [INFO]: Epoch 004 - training loss: 0.5904, validation loss: 2.4874
2024-06-01 22:29:16 [INFO]: Epoch 005 - training loss: 0.5602, validation loss: 2.3927
2024-06-01 22:29:33 [INFO]: Epoch 006 - training loss: 0.5351, validation loss: 2.3140
2024-06-01 22:29:49 [INFO]: Epoch 007 - training loss: 0.5153, validation loss: 2.2538
2024-06-01 22:30:06 [INFO]: Epoch 008 - training loss: 0.4988, validation loss: 2.1852
2024-06-01 22:30:23 [INFO]: Epoch 009 - training loss: 0.4858, validation loss: 2.1277
2024-06-01 22:30:40 [INFO]: Epoch 010 - training loss: 0.4769, validation loss: 2.0906
2024-06-01 22:30:57 [INFO]: Epoch 011 - training loss: 0.4666, validation loss: 2.0368
2024-06-01 22:31:14 [INFO]: Epoch 012 - training loss: 0.4608, validation loss: 2.0045
2024-06-01 22:31:31 [INFO]: Epoch 013 - training loss: 0.4543, validation loss: 1.9574
2024-06-01 22:31:48 [INFO]: Epoch 014 - training loss: 0.4456, validation loss: 1.9205
2024-06-01 22:32:05 [INFO]: Epoch 015 - training loss: 0.4407, validation loss: 1.8921
2024-06-01 22:32:21 [INFO]: Epoch 016 - training loss: 0.4377, validation loss: 1.8631
2024-06-01 22:32:36 [INFO]: Epoch 017 - training loss: 0.4327, validation loss: 1.8260
2024-06-01 22:32:53 [INFO]: Epoch 018 - training loss: 0.4263, validation loss: 1.7930
2024-06-01 22:33:10 [INFO]: Epoch 019 - training loss: 0.4226, validation loss: 1.7629
2024-06-01 22:33:27 [INFO]: Epoch 020 - training loss: 0.4209, validation loss: 1.7348
2024-06-01 22:33:44 [INFO]: Epoch 021 - training loss: 0.4181, validation loss: 1.7119
2024-06-01 22:34:01 [INFO]: Epoch 022 - training loss: 0.4121, validation loss: 1.6757
2024-06-01 22:34:17 [INFO]: Epoch 023 - training loss: 0.4087, validation loss: 1.6537
2024-06-01 22:34:34 [INFO]: Epoch 024 - training loss: 0.4069, validation loss: 1.6309
2024-06-01 22:34:51 [INFO]: Epoch 025 - training loss: 0.4040, validation loss: 1.6071
2024-06-01 22:35:08 [INFO]: Epoch 026 - training loss: 0.4015, validation loss: 1.5887
2024-06-01 22:35:25 [INFO]: Epoch 027 - training loss: 0.3992, validation loss: 1.5726
2024-06-01 22:35:41 [INFO]: Epoch 028 - training loss: 0.3974, validation loss: 1.5508
2024-06-01 22:35:57 [INFO]: Epoch 029 - training loss: 0.3952, validation loss: 1.5376
2024-06-01 22:36:13 [INFO]: Epoch 030 - training loss: 0.3933, validation loss: 1.5090
2024-06-01 22:36:30 [INFO]: Epoch 031 - training loss: 0.3905, validation loss: 1.4891
2024-06-01 22:36:47 [INFO]: Epoch 032 - training loss: 0.3895, validation loss: 1.4766
2024-06-01 22:37:03 [INFO]: Epoch 033 - training loss: 0.3887, validation loss: 1.4633
2024-06-01 22:37:20 [INFO]: Epoch 034 - training loss: 0.3865, validation loss: 1.4408
2024-06-01 22:37:37 [INFO]: Epoch 035 - training loss: 0.3856, validation loss: 1.4264
2024-06-01 22:37:54 [INFO]: Epoch 036 - training loss: 0.3831, validation loss: 1.4132
2024-06-01 22:38:11 [INFO]: Epoch 037 - training loss: 0.3827, validation loss: 1.4060
2024-06-01 22:38:28 [INFO]: Epoch 038 - training loss: 0.3809, validation loss: 1.3918
2024-06-01 22:38:45 [INFO]: Epoch 039 - training loss: 0.3809, validation loss: 1.3812
2024-06-01 22:39:02 [INFO]: Epoch 040 - training loss: 0.3789, validation loss: 1.3668
2024-06-01 22:39:18 [INFO]: Epoch 041 - training loss: 0.3767, validation loss: 1.3541
2024-06-01 22:39:34 [INFO]: Epoch 042 - training loss: 0.3765, validation loss: 1.3460
2024-06-01 22:39:50 [INFO]: Epoch 043 - training loss: 0.3750, validation loss: 1.3336
2024-06-01 22:40:06 [INFO]: Epoch 044 - training loss: 0.3744, validation loss: 1.3174
2024-06-01 22:40:23 [INFO]: Epoch 045 - training loss: 0.3729, validation loss: 1.3198
2024-06-01 22:40:40 [INFO]: Epoch 046 - training loss: 0.3735, validation loss: 1.3090
2024-06-01 22:40:57 [INFO]: Epoch 047 - training loss: 0.3714, validation loss: 1.3113
2024-06-01 22:41:13 [INFO]: Epoch 048 - training loss: 0.3709, validation loss: 1.2964
2024-06-01 22:41:30 [INFO]: Epoch 049 - training loss: 0.3698, validation loss: 1.2886
2024-06-01 22:41:47 [INFO]: Epoch 050 - training loss: 0.3702, validation loss: 1.2776
2024-06-01 22:42:04 [INFO]: Epoch 051 - training loss: 0.3689, validation loss: 1.2918
2024-06-01 22:42:21 [INFO]: Epoch 052 - training loss: 0.3684, validation loss: 1.2794
2024-06-01 22:42:38 [INFO]: Epoch 053 - training loss: 0.3668, validation loss: 1.2712
2024-06-01 22:42:54 [INFO]: Epoch 054 - training loss: 0.3669, validation loss: 1.2684
2024-06-01 22:43:10 [INFO]: Epoch 055 - training loss: 0.3669, validation loss: 1.2606
2024-06-01 22:43:26 [INFO]: Epoch 056 - training loss: 0.3647, validation loss: 1.2630
2024-06-01 22:43:43 [INFO]: Epoch 057 - training loss: 0.3644, validation loss: 1.2605
2024-06-01 22:44:00 [INFO]: Epoch 058 - training loss: 0.3630, validation loss: 1.2594
2024-06-01 22:44:17 [INFO]: Epoch 059 - training loss: 0.3625, validation loss: 1.2452
2024-06-01 22:44:34 [INFO]: Epoch 060 - training loss: 0.3627, validation loss: 1.2368
2024-06-01 22:44:51 [INFO]: Epoch 061 - training loss: 0.3617, validation loss: 1.2351
2024-06-01 22:45:08 [INFO]: Epoch 062 - training loss: 0.3617, validation loss: 1.2340
2024-06-01 22:45:25 [INFO]: Epoch 063 - training loss: 0.3610, validation loss: 1.2236
2024-06-01 22:45:41 [INFO]: Epoch 064 - training loss: 0.3635, validation loss: 1.2446
2024-06-01 22:45:58 [INFO]: Epoch 065 - training loss: 0.3619, validation loss: 1.2389
2024-06-01 22:46:15 [INFO]: Epoch 066 - training loss: 0.3593, validation loss: 1.2227
2024-06-01 22:46:31 [INFO]: Epoch 067 - training loss: 0.3588, validation loss: 1.2198
2024-06-01 22:46:47 [INFO]: Epoch 068 - training loss: 0.3585, validation loss: 1.2091
2024-06-01 22:47:03 [INFO]: Epoch 069 - training loss: 0.3575, validation loss: 1.2128
2024-06-01 22:47:20 [INFO]: Epoch 070 - training loss: 0.3578, validation loss: 1.2024
2024-06-01 22:47:37 [INFO]: Epoch 071 - training loss: 0.3576, validation loss: 1.2014
2024-06-01 22:47:54 [INFO]: Epoch 072 - training loss: 0.3565, validation loss: 1.2026
2024-06-01 22:48:11 [INFO]: Epoch 073 - training loss: 0.3561, validation loss: 1.2066
2024-06-01 22:48:28 [INFO]: Epoch 074 - training loss: 0.3556, validation loss: 1.1920
2024-06-01 22:48:44 [INFO]: Epoch 075 - training loss: 0.3584, validation loss: 1.2043
2024-06-01 22:49:02 [INFO]: Epoch 076 - training loss: 0.3568, validation loss: 1.2035
2024-06-01 22:49:19 [INFO]: Epoch 077 - training loss: 0.3550, validation loss: 1.1979
2024-06-01 22:49:36 [INFO]: Epoch 078 - training loss: 0.3540, validation loss: 1.1930
2024-06-01 22:49:52 [INFO]: Epoch 079 - training loss: 0.3541, validation loss: 1.2021
2024-06-01 22:50:09 [INFO]: Epoch 080 - training loss: 0.3535, validation loss: 1.1858
2024-06-01 22:50:25 [INFO]: Epoch 081 - training loss: 0.3534, validation loss: 1.1819
2024-06-01 22:50:41 [INFO]: Epoch 082 - training loss: 0.3537, validation loss: 1.1822
2024-06-01 22:50:58 [INFO]: Epoch 083 - training loss: 0.3529, validation loss: 1.1844
2024-06-01 22:51:15 [INFO]: Epoch 084 - training loss: 0.3522, validation loss: 1.1793
2024-06-01 22:51:32 [INFO]: Epoch 085 - training loss: 0.3526, validation loss: 1.1795
2024-06-01 22:51:48 [INFO]: Epoch 086 - training loss: 0.3526, validation loss: 1.1834
2024-06-01 22:52:05 [INFO]: Epoch 087 - training loss: 0.3525, validation loss: 1.1894
2024-06-01 22:52:22 [INFO]: Epoch 088 - training loss: 0.3515, validation loss: 1.1921
2024-06-01 22:52:39 [INFO]: Epoch 089 - training loss: 0.3519, validation loss: 1.1806
2024-06-01 22:52:56 [INFO]: Epoch 090 - training loss: 0.3511, validation loss: 1.1759
2024-06-01 22:53:13 [INFO]: Epoch 091 - training loss: 0.3512, validation loss: 1.1662
2024-06-01 22:53:30 [INFO]: Epoch 092 - training loss: 0.3498, validation loss: 1.1789
2024-06-01 22:53:46 [INFO]: Epoch 093 - training loss: 0.3499, validation loss: 1.1859
2024-06-01 22:54:02 [INFO]: Epoch 094 - training loss: 0.3504, validation loss: 1.1903
2024-06-01 22:54:18 [INFO]: Epoch 095 - training loss: 0.3498, validation loss: 1.1800
2024-06-01 22:54:35 [INFO]: Epoch 096 - training loss: 0.3490, validation loss: 1.1774
2024-06-01 22:54:52 [INFO]: Epoch 097 - training loss: 0.3496, validation loss: 1.1750
2024-06-01 22:55:08 [INFO]: Epoch 098 - training loss: 0.3486, validation loss: 1.1777
2024-06-01 22:55:25 [INFO]: Epoch 099 - training loss: 0.3489, validation loss: 1.1801
2024-06-01 22:55:42 [INFO]: Epoch 100 - training loss: 0.3486, validation loss: 1.1716
2024-06-01 22:55:42 [INFO]: Finished training. The best model is from epoch#91.
2024-06-01 22:55:42 [INFO]: Saved the model to results_point_rate01/Electricity/Crossformer_Electricity/round_1/20240601_T222754/Crossformer.pypots
2024-06-01 22:55:44 [INFO]: Successfully saved to results_point_rate01/Electricity/Crossformer_Electricity/round_1/imputation.pkl
2024-06-01 22:55:44 [INFO]: Round1 - Crossformer on Electricity: MAE=0.5885, MSE=0.6661, MRE=0.3148
2024-06-01 22:55:44 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:55:44 [INFO]: Using the given device: cuda:0
2024-06-01 22:55:44 [INFO]: Model files will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_2/20240601_T225544
2024-06-01 22:55:44 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_2/20240601_T225544/tensorboard
2024-06-01 22:55:44 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-01 22:56:01 [INFO]: Epoch 001 - training loss: 1.1450, validation loss: 3.1923
2024-06-01 22:56:18 [INFO]: Epoch 002 - training loss: 0.7470, validation loss: 2.8078
2024-06-01 22:56:35 [INFO]: Epoch 003 - training loss: 0.6376, validation loss: 2.6372
2024-06-01 22:56:51 [INFO]: Epoch 004 - training loss: 0.5928, validation loss: 2.5219
2024-06-01 22:57:08 [INFO]: Epoch 005 - training loss: 0.5610, validation loss: 2.4383
2024-06-01 22:57:24 [INFO]: Epoch 006 - training loss: 0.5366, validation loss: 2.3468
2024-06-01 22:57:40 [INFO]: Epoch 007 - training loss: 0.5157, validation loss: 2.2766
2024-06-01 22:57:56 [INFO]: Epoch 008 - training loss: 0.5022, validation loss: 2.2115
2024-06-01 22:58:13 [INFO]: Epoch 009 - training loss: 0.4888, validation loss: 2.1557
2024-06-01 22:58:29 [INFO]: Epoch 010 - training loss: 0.4778, validation loss: 2.1114
2024-06-01 22:58:46 [INFO]: Epoch 011 - training loss: 0.4698, validation loss: 2.0687
2024-06-01 22:59:03 [INFO]: Epoch 012 - training loss: 0.4623, validation loss: 2.0294
2024-06-01 22:59:20 [INFO]: Epoch 013 - training loss: 0.4548, validation loss: 1.9877
2024-06-01 22:59:37 [INFO]: Epoch 014 - training loss: 0.4487, validation loss: 1.9494
2024-06-01 22:59:54 [INFO]: Epoch 015 - training loss: 0.4427, validation loss: 1.9183
2024-06-01 23:00:10 [INFO]: Epoch 016 - training loss: 0.4366, validation loss: 1.8836
2024-06-01 23:00:27 [INFO]: Epoch 017 - training loss: 0.4326, validation loss: 1.8551
2024-06-01 23:00:44 [INFO]: Epoch 018 - training loss: 0.4287, validation loss: 1.8229
2024-06-01 23:01:00 [INFO]: Epoch 019 - training loss: 0.4237, validation loss: 1.7937
2024-06-01 23:01:16 [INFO]: Epoch 020 - training loss: 0.4212, validation loss: 1.7687
2024-06-01 23:01:32 [INFO]: Epoch 021 - training loss: 0.4166, validation loss: 1.7498
2024-06-01 23:01:49 [INFO]: Epoch 022 - training loss: 0.4125, validation loss: 1.7116
2024-06-01 23:02:06 [INFO]: Epoch 023 - training loss: 0.4116, validation loss: 1.7033
2024-06-01 23:02:23 [INFO]: Epoch 024 - training loss: 0.4100, validation loss: 1.6737
2024-06-01 23:02:40 [INFO]: Epoch 025 - training loss: 0.4046, validation loss: 1.6491
2024-06-01 23:02:56 [INFO]: Epoch 026 - training loss: 0.4015, validation loss: 1.6246
2024-06-01 23:03:13 [INFO]: Epoch 027 - training loss: 0.3995, validation loss: 1.5996
2024-06-01 23:03:30 [INFO]: Epoch 028 - training loss: 0.3979, validation loss: 1.5819
2024-06-01 23:03:47 [INFO]: Epoch 029 - training loss: 0.3955, validation loss: 1.5637
2024-06-01 23:04:04 [INFO]: Epoch 030 - training loss: 0.3943, validation loss: 1.5419
2024-06-01 23:04:21 [INFO]: Epoch 031 - training loss: 0.3922, validation loss: 1.5275
2024-06-01 23:04:37 [INFO]: Epoch 032 - training loss: 0.3913, validation loss: 1.5081
2024-06-01 23:04:53 [INFO]: Epoch 033 - training loss: 0.3888, validation loss: 1.4954
2024-06-01 23:05:09 [INFO]: Epoch 034 - training loss: 0.3866, validation loss: 1.4792
2024-06-01 23:05:26 [INFO]: Epoch 035 - training loss: 0.3846, validation loss: 1.4578
2024-06-01 23:05:42 [INFO]: Epoch 036 - training loss: 0.3839, validation loss: 1.4509
2024-06-01 23:05:59 [INFO]: Epoch 037 - training loss: 0.3830, validation loss: 1.4284
2024-06-01 23:06:16 [INFO]: Epoch 038 - training loss: 0.3818, validation loss: 1.4133
2024-06-01 23:06:33 [INFO]: Epoch 039 - training loss: 0.3809, validation loss: 1.4107
2024-06-01 23:06:50 [INFO]: Epoch 040 - training loss: 0.3785, validation loss: 1.3943
2024-06-01 23:07:07 [INFO]: Epoch 041 - training loss: 0.3778, validation loss: 1.3908
2024-06-01 23:07:24 [INFO]: Epoch 042 - training loss: 0.3767, validation loss: 1.3757
2024-06-01 23:07:40 [INFO]: Epoch 043 - training loss: 0.3763, validation loss: 1.3641
2024-06-01 23:07:57 [INFO]: Epoch 044 - training loss: 0.3749, validation loss: 1.3545
2024-06-01 23:08:13 [INFO]: Epoch 045 - training loss: 0.3736, validation loss: 1.3413
2024-06-01 23:08:29 [INFO]: Epoch 046 - training loss: 0.3730, validation loss: 1.3371
2024-06-01 23:08:45 [INFO]: Epoch 047 - training loss: 0.3729, validation loss: 1.3332
2024-06-01 23:09:02 [INFO]: Epoch 048 - training loss: 0.3761, validation loss: 1.3349
2024-06-01 23:09:19 [INFO]: Epoch 049 - training loss: 0.3710, validation loss: 1.3256
2024-06-01 23:09:36 [INFO]: Epoch 050 - training loss: 0.3691, validation loss: 1.3157
2024-06-01 23:09:53 [INFO]: Epoch 051 - training loss: 0.3689, validation loss: 1.3021
2024-06-01 23:10:10 [INFO]: Epoch 052 - training loss: 0.3687, validation loss: 1.3070
2024-06-01 23:10:27 [INFO]: Epoch 053 - training loss: 0.3673, validation loss: 1.2975
2024-06-01 23:10:44 [INFO]: Epoch 054 - training loss: 0.3682, validation loss: 1.2915
2024-06-01 23:11:01 [INFO]: Epoch 055 - training loss: 0.3675, validation loss: 1.2921
2024-06-01 23:11:18 [INFO]: Epoch 056 - training loss: 0.3651, validation loss: 1.2778
2024-06-01 23:11:35 [INFO]: Epoch 057 - training loss: 0.3638, validation loss: 1.2667
2024-06-01 23:11:51 [INFO]: Epoch 058 - training loss: 0.3637, validation loss: 1.2673
2024-06-01 23:12:07 [INFO]: Epoch 059 - training loss: 0.3630, validation loss: 1.2635
2024-06-01 23:12:23 [INFO]: Epoch 060 - training loss: 0.3639, validation loss: 1.2665
2024-06-01 23:12:40 [INFO]: Epoch 061 - training loss: 0.3623, validation loss: 1.2502
2024-06-01 23:12:57 [INFO]: Epoch 062 - training loss: 0.3617, validation loss: 1.2478
2024-06-01 23:13:13 [INFO]: Epoch 063 - training loss: 0.3613, validation loss: 1.2441
2024-06-01 23:13:30 [INFO]: Epoch 064 - training loss: 0.3608, validation loss: 1.2409
2024-06-01 23:13:47 [INFO]: Epoch 065 - training loss: 0.3606, validation loss: 1.2369
2024-06-01 23:14:03 [INFO]: Epoch 066 - training loss: 0.3604, validation loss: 1.2409
2024-06-01 23:14:20 [INFO]: Epoch 067 - training loss: 0.3588, validation loss: 1.2387
2024-06-01 23:14:37 [INFO]: Epoch 068 - training loss: 0.3598, validation loss: 1.2353
2024-06-01 23:14:54 [INFO]: Epoch 069 - training loss: 0.3581, validation loss: 1.2201
2024-06-01 23:15:11 [INFO]: Epoch 070 - training loss: 0.3582, validation loss: 1.2285
2024-06-01 23:15:27 [INFO]: Epoch 071 - training loss: 0.3595, validation loss: 1.2262
2024-06-01 23:15:43 [INFO]: Epoch 072 - training loss: 0.3573, validation loss: 1.2182
2024-06-01 23:15:59 [INFO]: Epoch 073 - training loss: 0.3572, validation loss: 1.2177
2024-06-01 23:16:16 [INFO]: Epoch 074 - training loss: 0.3569, validation loss: 1.2168
2024-06-01 23:16:33 [INFO]: Epoch 075 - training loss: 0.3564, validation loss: 1.2197
2024-06-01 23:16:50 [INFO]: Epoch 076 - training loss: 0.3568, validation loss: 1.2133
2024-06-01 23:17:06 [INFO]: Epoch 077 - training loss: 0.3552, validation loss: 1.1960
2024-06-01 23:17:23 [INFO]: Epoch 078 - training loss: 0.3544, validation loss: 1.1992
2024-06-01 23:17:40 [INFO]: Epoch 079 - training loss: 0.3544, validation loss: 1.1967
2024-06-01 23:17:57 [INFO]: Epoch 080 - training loss: 0.3553, validation loss: 1.1978
2024-06-01 23:18:14 [INFO]: Epoch 081 - training loss: 0.3534, validation loss: 1.1828
2024-06-01 23:18:31 [INFO]: Epoch 082 - training loss: 0.3529, validation loss: 1.1942
2024-06-01 23:18:48 [INFO]: Epoch 083 - training loss: 0.3545, validation loss: 1.1989
2024-06-01 23:19:04 [INFO]: Epoch 084 - training loss: 0.3538, validation loss: 1.1953
2024-06-01 23:19:20 [INFO]: Epoch 085 - training loss: 0.3530, validation loss: 1.1934
2024-06-01 23:19:35 [INFO]: Epoch 086 - training loss: 0.3526, validation loss: 1.1839
2024-06-01 23:19:52 [INFO]: Epoch 087 - training loss: 0.3513, validation loss: 1.1873
2024-06-01 23:20:09 [INFO]: Epoch 088 - training loss: 0.3519, validation loss: 1.1781
2024-06-01 23:20:26 [INFO]: Epoch 089 - training loss: 0.3523, validation loss: 1.1836
2024-06-01 23:20:43 [INFO]: Epoch 090 - training loss: 0.3516, validation loss: 1.1857
2024-06-01 23:21:00 [INFO]: Epoch 091 - training loss: 0.3517, validation loss: 1.1781
2024-06-01 23:21:17 [INFO]: Epoch 092 - training loss: 0.3522, validation loss: 1.1845
2024-06-01 23:21:33 [INFO]: Epoch 093 - training loss: 0.3504, validation loss: 1.1835
2024-06-01 23:21:50 [INFO]: Epoch 094 - training loss: 0.3503, validation loss: 1.1701
2024-06-01 23:22:07 [INFO]: Epoch 095 - training loss: 0.3497, validation loss: 1.1770
2024-06-01 23:22:24 [INFO]: Epoch 096 - training loss: 0.3494, validation loss: 1.1649
2024-06-01 23:22:40 [INFO]: Epoch 097 - training loss: 0.3492, validation loss: 1.1601
2024-06-01 23:22:56 [INFO]: Epoch 098 - training loss: 0.3496, validation loss: 1.1755
2024-06-01 23:23:12 [INFO]: Epoch 099 - training loss: 0.3489, validation loss: 1.1665
2024-06-01 23:23:29 [INFO]: Epoch 100 - training loss: 0.3491, validation loss: 1.1672
2024-06-01 23:23:29 [INFO]: Finished training. The best model is from epoch#97.
2024-06-01 23:23:29 [INFO]: Saved the model to results_point_rate01/Electricity/Crossformer_Electricity/round_2/20240601_T225544/Crossformer.pypots
2024-06-01 23:23:31 [INFO]: Successfully saved to results_point_rate01/Electricity/Crossformer_Electricity/round_2/imputation.pkl
2024-06-01 23:23:31 [INFO]: Round2 - Crossformer on Electricity: MAE=0.5300, MSE=0.5669, MRE=0.2835
2024-06-01 23:23:31 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 23:23:31 [INFO]: Using the given device: cuda:0
2024-06-01 23:23:31 [INFO]: Model files will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_3/20240601_T232331
2024-06-01 23:23:31 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_3/20240601_T232331/tensorboard
2024-06-01 23:23:31 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-01 23:23:48 [INFO]: Epoch 001 - training loss: 1.1689, validation loss: 3.4741
2024-06-01 23:24:05 [INFO]: Epoch 002 - training loss: 0.8530, validation loss: 3.0239
2024-06-01 23:24:22 [INFO]: Epoch 003 - training loss: 0.6724, validation loss: 2.7859
2024-06-01 23:24:38 [INFO]: Epoch 004 - training loss: 0.6105, validation loss: 2.6221
2024-06-01 23:24:55 [INFO]: Epoch 005 - training loss: 0.5743, validation loss: 2.5153
2024-06-01 23:25:12 [INFO]: Epoch 006 - training loss: 0.5468, validation loss: 2.4272
2024-06-01 23:25:29 [INFO]: Epoch 007 - training loss: 0.5260, validation loss: 2.3503
2024-06-01 23:25:46 [INFO]: Epoch 008 - training loss: 0.5070, validation loss: 2.2704
2024-06-01 23:26:03 [INFO]: Epoch 009 - training loss: 0.4951, validation loss: 2.2139
2024-06-01 23:26:19 [INFO]: Epoch 010 - training loss: 0.4853, validation loss: 2.1694
2024-06-01 23:26:35 [INFO]: Epoch 011 - training loss: 0.4749, validation loss: 2.1168
2024-06-01 23:26:51 [INFO]: Epoch 012 - training loss: 0.4653, validation loss: 2.0695
2024-06-01 23:27:08 [INFO]: Epoch 013 - training loss: 0.4589, validation loss: 2.0255
2024-06-01 23:27:25 [INFO]: Epoch 014 - training loss: 0.4520, validation loss: 1.9931
2024-06-01 23:27:41 [INFO]: Epoch 015 - training loss: 0.4504, validation loss: 1.9712
2024-06-01 23:27:58 [INFO]: Epoch 016 - training loss: 0.4440, validation loss: 1.9223
2024-06-01 23:28:15 [INFO]: Epoch 017 - training loss: 0.4363, validation loss: 1.8893
2024-06-01 23:28:32 [INFO]: Epoch 018 - training loss: 0.4312, validation loss: 1.8613
2024-06-01 23:28:49 [INFO]: Epoch 019 - training loss: 0.4274, validation loss: 1.8295
2024-06-01 23:29:06 [INFO]: Epoch 020 - training loss: 0.4233, validation loss: 1.7999
2024-06-01 23:29:23 [INFO]: Epoch 021 - training loss: 0.4192, validation loss: 1.7734
2024-06-01 23:29:40 [INFO]: Epoch 022 - training loss: 0.4158, validation loss: 1.7505
2024-06-01 23:29:56 [INFO]: Epoch 023 - training loss: 0.4126, validation loss: 1.7186
2024-06-01 23:30:12 [INFO]: Epoch 024 - training loss: 0.4105, validation loss: 1.7026
2024-06-01 23:30:28 [INFO]: Epoch 025 - training loss: 0.4063, validation loss: 1.6772
2024-06-01 23:30:45 [INFO]: Epoch 026 - training loss: 0.4046, validation loss: 1.6501
2024-06-01 23:31:02 [INFO]: Epoch 027 - training loss: 0.4030, validation loss: 1.6234
2024-06-01 23:31:19 [INFO]: Epoch 028 - training loss: 0.4015, validation loss: 1.6075
2024-06-01 23:31:36 [INFO]: Epoch 029 - training loss: 0.3977, validation loss: 1.5872
2024-06-01 23:31:52 [INFO]: Epoch 030 - training loss: 0.3950, validation loss: 1.5564
2024-06-01 23:32:09 [INFO]: Epoch 031 - training loss: 0.3924, validation loss: 1.5462
2024-06-01 23:32:26 [INFO]: Epoch 032 - training loss: 0.3905, validation loss: 1.5264
2024-06-01 23:32:43 [INFO]: Epoch 033 - training loss: 0.3888, validation loss: 1.5058
2024-06-01 23:33:00 [INFO]: Epoch 034 - training loss: 0.3881, validation loss: 1.4929
2024-06-01 23:33:17 [INFO]: Epoch 035 - training loss: 0.3869, validation loss: 1.4795
2024-06-01 23:33:33 [INFO]: Epoch 036 - training loss: 0.3874, validation loss: 1.4634
2024-06-01 23:33:49 [INFO]: Epoch 037 - training loss: 0.3837, validation loss: 1.4434
2024-06-01 23:34:05 [INFO]: Epoch 038 - training loss: 0.3825, validation loss: 1.4162
2024-06-01 23:34:21 [INFO]: Epoch 039 - training loss: 0.3808, validation loss: 1.4160
2024-06-01 23:34:38 [INFO]: Epoch 040 - training loss: 0.3789, validation loss: 1.3919
2024-06-01 23:34:55 [INFO]: Epoch 041 - training loss: 0.3776, validation loss: 1.3820
2024-06-01 23:35:12 [INFO]: Epoch 042 - training loss: 0.3779, validation loss: 1.3786
2024-06-01 23:35:29 [INFO]: Epoch 043 - training loss: 0.3772, validation loss: 1.3569
2024-06-01 23:35:45 [INFO]: Epoch 044 - training loss: 0.3756, validation loss: 1.3515
2024-06-01 23:36:02 [INFO]: Epoch 045 - training loss: 0.3740, validation loss: 1.3396
2024-06-01 23:36:19 [INFO]: Epoch 046 - training loss: 0.3732, validation loss: 1.3383
2024-06-01 23:36:35 [INFO]: Epoch 047 - training loss: 0.3732, validation loss: 1.3437
2024-06-01 23:36:52 [INFO]: Epoch 048 - training loss: 0.3712, validation loss: 1.3217
2024-06-01 23:37:08 [INFO]: Epoch 049 - training loss: 0.3711, validation loss: 1.3056
2024-06-01 23:37:24 [INFO]: Epoch 050 - training loss: 0.3702, validation loss: 1.3117
2024-06-01 23:37:40 [INFO]: Epoch 051 - training loss: 0.3701, validation loss: 1.3026
2024-06-01 23:37:57 [INFO]: Epoch 052 - training loss: 0.3676, validation loss: 1.2853
2024-06-01 23:38:14 [INFO]: Epoch 053 - training loss: 0.3676, validation loss: 1.2950
2024-06-01 23:38:31 [INFO]: Epoch 054 - training loss: 0.3680, validation loss: 1.2906
2024-06-01 23:38:48 [INFO]: Epoch 055 - training loss: 0.3678, validation loss: 1.2856
2024-06-01 23:39:04 [INFO]: Epoch 056 - training loss: 0.3668, validation loss: 1.2624
2024-06-01 23:39:21 [INFO]: Epoch 057 - training loss: 0.3645, validation loss: 1.2526
2024-06-01 23:39:38 [INFO]: Epoch 058 - training loss: 0.3638, validation loss: 1.2542
2024-06-01 23:39:55 [INFO]: Epoch 059 - training loss: 0.3629, validation loss: 1.2447
2024-06-01 23:40:12 [INFO]: Epoch 060 - training loss: 0.3627, validation loss: 1.2378
2024-06-01 23:40:29 [INFO]: Epoch 061 - training loss: 0.3622, validation loss: 1.2437
2024-06-01 23:40:46 [INFO]: Epoch 062 - training loss: 0.3619, validation loss: 1.2273
2024-06-01 23:41:01 [INFO]: Epoch 063 - training loss: 0.3615, validation loss: 1.2329
2024-06-01 23:41:17 [INFO]: Epoch 064 - training loss: 0.3616, validation loss: 1.2476
2024-06-01 23:41:33 [INFO]: Epoch 065 - training loss: 0.3608, validation loss: 1.2296
2024-06-01 23:41:50 [INFO]: Epoch 066 - training loss: 0.3598, validation loss: 1.2287
2024-06-01 23:42:07 [INFO]: Epoch 067 - training loss: 0.3592, validation loss: 1.2175
2024-06-01 23:42:24 [INFO]: Epoch 068 - training loss: 0.3586, validation loss: 1.2158
2024-06-01 23:42:41 [INFO]: Epoch 069 - training loss: 0.3585, validation loss: 1.2301
2024-06-01 23:42:58 [INFO]: Epoch 070 - training loss: 0.3587, validation loss: 1.2233
2024-06-01 23:43:15 [INFO]: Epoch 071 - training loss: 0.3578, validation loss: 1.2197
2024-06-01 23:43:32 [INFO]: Epoch 072 - training loss: 0.3574, validation loss: 1.2215
2024-06-01 23:43:48 [INFO]: Epoch 073 - training loss: 0.3567, validation loss: 1.2128
2024-06-01 23:44:05 [INFO]: Epoch 074 - training loss: 0.3572, validation loss: 1.2208
2024-06-01 23:44:22 [INFO]: Epoch 075 - training loss: 0.3572, validation loss: 1.2186
2024-06-01 23:44:38 [INFO]: Epoch 076 - training loss: 0.3575, validation loss: 1.2097
2024-06-01 23:44:54 [INFO]: Epoch 077 - training loss: 0.3579, validation loss: 1.2206
2024-06-01 23:45:10 [INFO]: Epoch 078 - training loss: 0.3574, validation loss: 1.2093
2024-06-01 23:45:27 [INFO]: Epoch 079 - training loss: 0.3563, validation loss: 1.1952
2024-06-01 23:45:44 [INFO]: Epoch 080 - training loss: 0.3563, validation loss: 1.1924
2024-06-01 23:46:01 [INFO]: Epoch 081 - training loss: 0.3539, validation loss: 1.1851
2024-06-01 23:46:17 [INFO]: Epoch 082 - training loss: 0.3533, validation loss: 1.1847
2024-06-01 23:46:34 [INFO]: Epoch 083 - training loss: 0.3530, validation loss: 1.1780
2024-06-01 23:46:51 [INFO]: Epoch 084 - training loss: 0.3528, validation loss: 1.1789
2024-06-01 23:47:08 [INFO]: Epoch 085 - training loss: 0.3521, validation loss: 1.1783
2024-06-01 23:47:25 [INFO]: Epoch 086 - training loss: 0.3525, validation loss: 1.1806
2024-06-01 23:47:41 [INFO]: Epoch 087 - training loss: 0.3517, validation loss: 1.1838
2024-06-01 23:47:57 [INFO]: Epoch 088 - training loss: 0.3516, validation loss: 1.1846
2024-06-01 23:48:13 [INFO]: Epoch 089 - training loss: 0.3515, validation loss: 1.1834
2024-06-01 23:48:29 [INFO]: Epoch 090 - training loss: 0.3527, validation loss: 1.1743
2024-06-01 23:48:46 [INFO]: Epoch 091 - training loss: 0.3516, validation loss: 1.1721
2024-06-01 23:49:02 [INFO]: Epoch 092 - training loss: 0.3504, validation loss: 1.1666
2024-06-01 23:49:19 [INFO]: Epoch 093 - training loss: 0.3505, validation loss: 1.1729
2024-06-01 23:49:36 [INFO]: Epoch 094 - training loss: 0.3512, validation loss: 1.1641
2024-06-01 23:49:53 [INFO]: Epoch 095 - training loss: 0.3509, validation loss: 1.1744
2024-06-01 23:50:10 [INFO]: Epoch 096 - training loss: 0.3496, validation loss: 1.1619
2024-06-01 23:50:27 [INFO]: Epoch 097 - training loss: 0.3500, validation loss: 1.1725
2024-06-01 23:50:44 [INFO]: Epoch 098 - training loss: 0.3490, validation loss: 1.1632
2024-06-01 23:51:01 [INFO]: Epoch 099 - training loss: 0.3490, validation loss: 1.1698
2024-06-01 23:51:18 [INFO]: Epoch 100 - training loss: 0.3487, validation loss: 1.1688
2024-06-01 23:51:18 [INFO]: Finished training. The best model is from epoch#96.
2024-06-01 23:51:18 [INFO]: Saved the model to results_point_rate01/Electricity/Crossformer_Electricity/round_3/20240601_T232331/Crossformer.pypots
2024-06-01 23:51:20 [INFO]: Successfully saved to results_point_rate01/Electricity/Crossformer_Electricity/round_3/imputation.pkl
2024-06-01 23:51:20 [INFO]: Round3 - Crossformer on Electricity: MAE=0.4990, MSE=0.4870, MRE=0.2670
2024-06-01 23:51:20 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 23:51:20 [INFO]: Using the given device: cuda:0
2024-06-01 23:51:20 [INFO]: Model files will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_4/20240601_T235120
2024-06-01 23:51:20 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Crossformer_Electricity/round_4/20240601_T235120/tensorboard
2024-06-01 23:51:20 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-01 23:51:37 [INFO]: Epoch 001 - training loss: 1.1380, validation loss: 3.1786
2024-06-01 23:51:52 [INFO]: Epoch 002 - training loss: 0.7534, validation loss: 2.8270
2024-06-01 23:52:08 [INFO]: Epoch 003 - training loss: 0.6456, validation loss: 2.6370
2024-06-01 23:52:25 [INFO]: Epoch 004 - training loss: 0.5963, validation loss: 2.4953
2024-06-01 23:52:42 [INFO]: Epoch 005 - training loss: 0.5638, validation loss: 2.4006
2024-06-01 23:52:59 [INFO]: Epoch 006 - training loss: 0.5427, validation loss: 2.3087
2024-06-01 23:53:16 [INFO]: Epoch 007 - training loss: 0.5208, validation loss: 2.2342
2024-06-01 23:53:32 [INFO]: Epoch 008 - training loss: 0.5041, validation loss: 2.1742
2024-06-01 23:53:49 [INFO]: Epoch 009 - training loss: 0.4903, validation loss: 2.1065
2024-06-01 23:54:06 [INFO]: Epoch 010 - training loss: 0.4802, validation loss: 2.0644
2024-06-01 23:54:23 [INFO]: Epoch 011 - training loss: 0.4691, validation loss: 2.0213
2024-06-01 23:54:40 [INFO]: Epoch 012 - training loss: 0.4606, validation loss: 1.9926
2024-06-01 23:54:56 [INFO]: Epoch 013 - training loss: 0.4538, validation loss: 1.9441
2024-06-01 23:55:13 [INFO]: Epoch 014 - training loss: 0.4476, validation loss: 1.9155
2024-06-01 23:55:28 [INFO]: Epoch 015 - training loss: 0.4422, validation loss: 1.8818
2024-06-01 23:55:44 [INFO]: Epoch 016 - training loss: 0.4354, validation loss: 1.8434
2024-06-01 23:56:01 [INFO]: Epoch 017 - training loss: 0.4313, validation loss: 1.8170
2024-06-01 23:56:18 [INFO]: Epoch 018 - training loss: 0.4284, validation loss: 1.7911
2024-06-01 23:56:34 [INFO]: Epoch 019 - training loss: 0.4233, validation loss: 1.7581
2024-06-01 23:56:51 [INFO]: Epoch 020 - training loss: 0.4182, validation loss: 1.7324
2024-06-01 23:57:08 [INFO]: Epoch 021 - training loss: 0.4149, validation loss: 1.7048
2024-06-01 23:57:25 [INFO]: Epoch 022 - training loss: 0.4128, validation loss: 1.6780
2024-06-01 23:57:42 [INFO]: Epoch 023 - training loss: 0.4099, validation loss: 1.6576
2024-06-01 23:57:58 [INFO]: Epoch 024 - training loss: 0.4068, validation loss: 1.6412
2024-06-01 23:58:15 [INFO]: Epoch 025 - training loss: 0.4037, validation loss: 1.6150
2024-06-01 23:58:32 [INFO]: Epoch 026 - training loss: 0.4013, validation loss: 1.5900
2024-06-01 23:58:49 [INFO]: Epoch 027 - training loss: 0.4025, validation loss: 1.5760
2024-06-01 23:59:04 [INFO]: Epoch 028 - training loss: 0.4042, validation loss: 1.5717
2024-06-01 23:59:20 [INFO]: Epoch 029 - training loss: 0.3948, validation loss: 1.5383
2024-06-01 23:59:37 [INFO]: Epoch 030 - training loss: 0.3937, validation loss: 1.5237
2024-06-01 23:59:53 [INFO]: Epoch 031 - training loss: 0.3911, validation loss: 1.4979
2024-06-02 00:00:10 [INFO]: Epoch 032 - training loss: 0.3892, validation loss: 1.4779
2024-06-02 00:00:27 [INFO]: Epoch 033 - training loss: 0.3869, validation loss: 1.4600
2024-06-02 00:00:44 [INFO]: Epoch 034 - training loss: 0.3867, validation loss: 1.4502
2024-06-02 00:01:01 [INFO]: Epoch 035 - training loss: 0.3856, validation loss: 1.4321
2024-06-02 00:01:18 [INFO]: Epoch 036 - training loss: 0.3836, validation loss: 1.4161
2024-06-02 00:01:35 [INFO]: Epoch 037 - training loss: 0.3835, validation loss: 1.4074
2024-06-02 00:01:52 [INFO]: Epoch 038 - training loss: 0.3817, validation loss: 1.3931
2024-06-02 00:02:09 [INFO]: Epoch 039 - training loss: 0.3814, validation loss: 1.3890
2024-06-02 00:02:25 [INFO]: Epoch 040 - training loss: 0.3797, validation loss: 1.3727
2024-06-02 00:02:41 [INFO]: Epoch 041 - training loss: 0.3779, validation loss: 1.3561
2024-06-02 00:02:57 [INFO]: Epoch 042 - training loss: 0.3776, validation loss: 1.3495
2024-06-02 00:03:14 [INFO]: Epoch 043 - training loss: 0.3773, validation loss: 1.3476
2024-06-02 00:03:30 [INFO]: Epoch 044 - training loss: 0.3759, validation loss: 1.3314
2024-06-02 00:03:47 [INFO]: Epoch 045 - training loss: 0.3746, validation loss: 1.3238
2024-06-02 00:04:04 [INFO]: Epoch 046 - training loss: 0.3731, validation loss: 1.3185
2024-06-02 00:04:20 [INFO]: Epoch 047 - training loss: 0.3732, validation loss: 1.3213
2024-06-02 00:04:37 [INFO]: Epoch 048 - training loss: 0.3757, validation loss: 1.3191
2024-06-02 00:04:53 [INFO]: Epoch 049 - training loss: 0.3721, validation loss: 1.3135
2024-06-02 00:05:10 [INFO]: Epoch 050 - training loss: 0.3708, validation loss: 1.2983
2024-06-02 00:05:27 [INFO]: Epoch 051 - training loss: 0.3691, validation loss: 1.3010
2024-06-02 00:05:44 [INFO]: Epoch 052 - training loss: 0.3688, validation loss: 1.2917
2024-06-02 00:06:01 [INFO]: Epoch 053 - training loss: 0.3674, validation loss: 1.2853
2024-06-02 00:06:16 [INFO]: Epoch 054 - training loss: 0.3676, validation loss: 1.2824
2024-06-02 00:06:32 [INFO]: Epoch 055 - training loss: 0.3663, validation loss: 1.2760
2024-06-02 00:06:49 [INFO]: Epoch 056 - training loss: 0.3653, validation loss: 1.2721
2024-06-02 00:07:05 [INFO]: Epoch 057 - training loss: 0.3652, validation loss: 1.2735
2024-06-02 00:07:22 [INFO]: Epoch 058 - training loss: 0.3654, validation loss: 1.2648
2024-06-02 00:07:39 [INFO]: Epoch 059 - training loss: 0.3667, validation loss: 1.2622
2024-06-02 00:07:56 [INFO]: Epoch 060 - training loss: 0.3644, validation loss: 1.2581
2024-06-02 00:08:13 [INFO]: Epoch 061 - training loss: 0.3626, validation loss: 1.2519
2024-06-02 00:08:29 [INFO]: Epoch 062 - training loss: 0.3631, validation loss: 1.2461
2024-06-02 00:08:46 [INFO]: Epoch 063 - training loss: 0.3616, validation loss: 1.2497
2024-06-02 00:09:03 [INFO]: Epoch 064 - training loss: 0.3620, validation loss: 1.2411
2024-06-02 00:09:20 [INFO]: Epoch 065 - training loss: 0.3622, validation loss: 1.2343
2024-06-02 00:09:37 [INFO]: Epoch 066 - training loss: 0.3607, validation loss: 1.2321
2024-06-02 00:09:53 [INFO]: Epoch 067 - training loss: 0.3598, validation loss: 1.2297
2024-06-02 00:10:08 [INFO]: Epoch 068 - training loss: 0.3594, validation loss: 1.2312
2024-06-02 00:10:24 [INFO]: Epoch 069 - training loss: 0.3590, validation loss: 1.2292
2024-06-02 00:10:41 [INFO]: Epoch 070 - training loss: 0.3587, validation loss: 1.2270
2024-06-02 00:10:58 [INFO]: Epoch 071 - training loss: 0.3590, validation loss: 1.2184
2024-06-02 00:11:15 [INFO]: Epoch 072 - training loss: 0.3588, validation loss: 1.2296
2024-06-02 00:11:32 [INFO]: Epoch 073 - training loss: 0.3594, validation loss: 1.2157
2024-06-02 00:11:49 [INFO]: Epoch 074 - training loss: 0.3574, validation loss: 1.2147
2024-06-02 00:12:06 [INFO]: Epoch 075 - training loss: 0.3572, validation loss: 1.2170
2024-06-02 00:12:23 [INFO]: Epoch 076 - training loss: 0.3580, validation loss: 1.2174
2024-06-02 00:12:39 [INFO]: Epoch 077 - training loss: 0.3559, validation loss: 1.2089
2024-06-02 00:12:56 [INFO]: Epoch 078 - training loss: 0.3555, validation loss: 1.2101
2024-06-02 00:13:13 [INFO]: Epoch 079 - training loss: 0.3552, validation loss: 1.2035
2024-06-02 00:13:29 [INFO]: Epoch 080 - training loss: 0.3553, validation loss: 1.1937
2024-06-02 00:13:45 [INFO]: Epoch 081 - training loss: 0.3545, validation loss: 1.1992
2024-06-02 00:14:01 [INFO]: Epoch 082 - training loss: 0.3544, validation loss: 1.2074
2024-06-02 00:14:18 [INFO]: Epoch 083 - training loss: 0.3553, validation loss: 1.1950
2024-06-02 00:14:35 [INFO]: Epoch 084 - training loss: 0.3541, validation loss: 1.2006
2024-06-02 00:14:52 [INFO]: Epoch 085 - training loss: 0.3543, validation loss: 1.1996
2024-06-02 00:15:09 [INFO]: Epoch 086 - training loss: 0.3531, validation loss: 1.2055
2024-06-02 00:15:26 [INFO]: Epoch 087 - training loss: 0.3529, validation loss: 1.1967
2024-06-02 00:15:42 [INFO]: Epoch 088 - training loss: 0.3526, validation loss: 1.1934
2024-06-02 00:15:59 [INFO]: Epoch 089 - training loss: 0.3526, validation loss: 1.1888
2024-06-02 00:16:16 [INFO]: Epoch 090 - training loss: 0.3530, validation loss: 1.1956
2024-06-02 00:16:33 [INFO]: Epoch 091 - training loss: 0.3518, validation loss: 1.1874
2024-06-02 00:16:50 [INFO]: Epoch 092 - training loss: 0.3516, validation loss: 1.1932
2024-06-02 00:17:05 [INFO]: Epoch 093 - training loss: 0.3524, validation loss: 1.1878
2024-06-02 00:17:21 [INFO]: Epoch 094 - training loss: 0.3520, validation loss: 1.1827
2024-06-02 00:17:38 [INFO]: Epoch 095 - training loss: 0.3510, validation loss: 1.1904
2024-06-02 00:17:55 [INFO]: Epoch 096 - training loss: 0.3514, validation loss: 1.1850
2024-06-02 00:18:12 [INFO]: Epoch 097 - training loss: 0.3496, validation loss: 1.1694
2024-06-02 00:18:29 [INFO]: Epoch 098 - training loss: 0.3495, validation loss: 1.1960
2024-06-02 00:18:45 [INFO]: Epoch 099 - training loss: 0.3492, validation loss: 1.1803
2024-06-02 00:19:02 [INFO]: Epoch 100 - training loss: 0.3492, validation loss: 1.1832
2024-06-02 00:19:02 [INFO]: Finished training. The best model is from epoch#97.
2024-06-02 00:19:02 [INFO]: Saved the model to results_point_rate01/Electricity/Crossformer_Electricity/round_4/20240601_T235120/Crossformer.pypots
2024-06-02 00:19:04 [INFO]: Successfully saved to results_point_rate01/Electricity/Crossformer_Electricity/round_4/imputation.pkl
2024-06-02 00:19:04 [INFO]: Round4 - Crossformer on Electricity: MAE=0.5117, MSE=0.5276, MRE=0.2738
2024-06-02 00:19:04 [INFO]: Done! Final results:
Averaged Crossformer (n params: 9,967,314) on Electricity: MAE=0.5402 ± 0.03447756966090993, MSE=0.5808 ± 0.07042343546807517, MRE=0.2890 ± 0.018443894141977512, average inference time=1.55
