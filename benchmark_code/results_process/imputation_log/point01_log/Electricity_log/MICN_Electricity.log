2024-06-02 11:04:32 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 11:04:32 [INFO]: Using the given device: cuda:0
2024-06-02 11:04:32 [INFO]: Model files will be saved to results_point_rate01/Electricity/MICN_Electricity/round_0/20240602_T110432
2024-06-02 11:04:32 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/MICN_Electricity/round_0/20240602_T110432/tensorboard
2024-06-02 11:04:33 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-02 11:04:43 [INFO]: Epoch 001 - training loss: 0.7169, validation loss: 0.4148
2024-06-02 11:04:50 [INFO]: Epoch 002 - training loss: 0.5792, validation loss: 0.3946
2024-06-02 11:04:57 [INFO]: Epoch 003 - training loss: 0.5244, validation loss: 0.3933
2024-06-02 11:05:04 [INFO]: Epoch 004 - training loss: 0.5143, validation loss: 0.3926
2024-06-02 11:05:11 [INFO]: Epoch 005 - training loss: 0.5072, validation loss: 0.3922
2024-06-02 11:05:18 [INFO]: Epoch 006 - training loss: 0.5008, validation loss: 0.3909
2024-06-02 11:05:25 [INFO]: Epoch 007 - training loss: 0.4988, validation loss: 0.3894
2024-06-02 11:05:32 [INFO]: Epoch 008 - training loss: 0.4958, validation loss: 0.3893
2024-06-02 11:05:39 [INFO]: Epoch 009 - training loss: 0.4924, validation loss: 0.3889
2024-06-02 11:05:46 [INFO]: Epoch 010 - training loss: 0.4889, validation loss: 0.3880
2024-06-02 11:05:52 [INFO]: Epoch 011 - training loss: 0.4866, validation loss: 0.3887
2024-06-02 11:05:59 [INFO]: Epoch 012 - training loss: 0.4855, validation loss: 0.3876
2024-06-02 11:06:06 [INFO]: Epoch 013 - training loss: 0.4835, validation loss: 0.3855
2024-06-02 11:06:13 [INFO]: Epoch 014 - training loss: 0.4796, validation loss: 0.3852
2024-06-02 11:06:20 [INFO]: Epoch 015 - training loss: 0.4761, validation loss: 0.3872
2024-06-02 11:06:27 [INFO]: Epoch 016 - training loss: 0.4754, validation loss: 0.3835
2024-06-02 11:06:34 [INFO]: Epoch 017 - training loss: 0.4698, validation loss: 0.3824
2024-06-02 11:06:41 [INFO]: Epoch 018 - training loss: 0.4667, validation loss: 0.3799
2024-06-02 11:06:48 [INFO]: Epoch 019 - training loss: 0.4646, validation loss: 0.3798
2024-06-02 11:06:55 [INFO]: Epoch 020 - training loss: 0.4628, validation loss: 0.3791
2024-06-02 11:07:02 [INFO]: Epoch 021 - training loss: 0.4625, validation loss: 0.3819
2024-06-02 11:07:09 [INFO]: Epoch 022 - training loss: 0.4604, validation loss: 0.3789
2024-06-02 11:07:16 [INFO]: Epoch 023 - training loss: 0.4591, validation loss: 0.3781
2024-06-02 11:07:22 [INFO]: Epoch 024 - training loss: 0.4585, validation loss: 0.3798
2024-06-02 11:07:29 [INFO]: Epoch 025 - training loss: 0.4576, validation loss: 0.3780
2024-06-02 11:07:36 [INFO]: Epoch 026 - training loss: 0.4570, validation loss: 0.3778
2024-06-02 11:07:43 [INFO]: Epoch 027 - training loss: 0.4560, validation loss: 0.3760
2024-06-02 11:07:50 [INFO]: Epoch 028 - training loss: 0.4555, validation loss: 0.3768
2024-06-02 11:07:57 [INFO]: Epoch 029 - training loss: 0.4548, validation loss: 0.3764
2024-06-02 11:08:05 [INFO]: Epoch 030 - training loss: 0.4538, validation loss: 0.3756
2024-06-02 11:08:12 [INFO]: Epoch 031 - training loss: 0.4532, validation loss: 0.3755
2024-06-02 11:08:19 [INFO]: Epoch 032 - training loss: 0.4522, validation loss: 0.3767
2024-06-02 11:08:26 [INFO]: Epoch 033 - training loss: 0.4515, validation loss: 0.3769
2024-06-02 11:08:33 [INFO]: Epoch 034 - training loss: 0.4515, validation loss: 0.3769
2024-06-02 11:08:40 [INFO]: Epoch 035 - training loss: 0.4503, validation loss: 0.3762
2024-06-02 11:08:47 [INFO]: Epoch 036 - training loss: 0.4487, validation loss: 0.3783
2024-06-02 11:08:54 [INFO]: Epoch 037 - training loss: 0.4466, validation loss: 0.3746
2024-06-02 11:09:00 [INFO]: Epoch 038 - training loss: 0.4415, validation loss: 0.3718
2024-06-02 11:09:07 [INFO]: Epoch 039 - training loss: 0.4388, validation loss: 0.3730
2024-06-02 11:09:14 [INFO]: Epoch 040 - training loss: 0.4366, validation loss: 0.3685
2024-06-02 11:09:21 [INFO]: Epoch 041 - training loss: 0.4351, validation loss: 0.3720
2024-06-02 11:09:28 [INFO]: Epoch 042 - training loss: 0.4337, validation loss: 0.3694
2024-06-02 11:09:35 [INFO]: Epoch 043 - training loss: 0.4329, validation loss: 0.3704
2024-06-02 11:09:42 [INFO]: Epoch 044 - training loss: 0.4313, validation loss: 0.3692
2024-06-02 11:09:49 [INFO]: Epoch 045 - training loss: 0.4300, validation loss: 0.3682
2024-06-02 11:09:56 [INFO]: Epoch 046 - training loss: 0.4292, validation loss: 0.3676
2024-06-02 11:10:03 [INFO]: Epoch 047 - training loss: 0.4279, validation loss: 0.3688
2024-06-02 11:10:10 [INFO]: Epoch 048 - training loss: 0.4263, validation loss: 0.3690
2024-06-02 11:10:17 [INFO]: Epoch 049 - training loss: 0.4261, validation loss: 0.3665
2024-06-02 11:10:24 [INFO]: Epoch 050 - training loss: 0.4265, validation loss: 0.3662
2024-06-02 11:10:31 [INFO]: Epoch 051 - training loss: 0.4228, validation loss: 0.3660
2024-06-02 11:10:39 [INFO]: Epoch 052 - training loss: 0.4217, validation loss: 0.3649
2024-06-02 11:10:45 [INFO]: Epoch 053 - training loss: 0.4204, validation loss: 0.3622
2024-06-02 11:10:53 [INFO]: Epoch 054 - training loss: 0.4203, validation loss: 0.3642
2024-06-02 11:10:59 [INFO]: Epoch 055 - training loss: 0.4192, validation loss: 0.3640
2024-06-02 11:11:06 [INFO]: Epoch 056 - training loss: 0.4176, validation loss: 0.3644
2024-06-02 11:11:13 [INFO]: Epoch 057 - training loss: 0.4172, validation loss: 0.3648
2024-06-02 11:11:20 [INFO]: Epoch 058 - training loss: 0.4170, validation loss: 0.3639
2024-06-02 11:11:28 [INFO]: Epoch 059 - training loss: 0.4173, validation loss: 0.3650
2024-06-02 11:11:35 [INFO]: Epoch 060 - training loss: 0.4161, validation loss: 0.3638
2024-06-02 11:11:42 [INFO]: Epoch 061 - training loss: 0.4165, validation loss: 0.3633
2024-06-02 11:11:49 [INFO]: Epoch 062 - training loss: 0.4158, validation loss: 0.3649
2024-06-02 11:11:56 [INFO]: Epoch 063 - training loss: 0.4144, validation loss: 0.3624
2024-06-02 11:11:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 11:11:56 [INFO]: Finished training. The best model is from epoch#53.
2024-06-02 11:11:56 [INFO]: Saved the model to results_point_rate01/Electricity/MICN_Electricity/round_0/20240602_T110432/MICN.pypots
2024-06-02 11:11:57 [INFO]: Successfully saved to results_point_rate01/Electricity/MICN_Electricity/round_0/imputation.pkl
2024-06-02 11:11:57 [INFO]: Round0 - MICN on Electricity: MAE=0.3827, MSE=0.3504, MRE=0.2047
2024-06-02 11:11:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 11:11:57 [INFO]: Using the given device: cuda:0
2024-06-02 11:11:57 [INFO]: Model files will be saved to results_point_rate01/Electricity/MICN_Electricity/round_1/20240602_T111157
2024-06-02 11:11:57 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/MICN_Electricity/round_1/20240602_T111157/tensorboard
2024-06-02 11:11:57 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-02 11:12:04 [INFO]: Epoch 001 - training loss: 0.7192, validation loss: 0.4350
2024-06-02 11:12:11 [INFO]: Epoch 002 - training loss: 0.5770, validation loss: 0.4145
2024-06-02 11:12:18 [INFO]: Epoch 003 - training loss: 0.5325, validation loss: 0.4105
2024-06-02 11:12:25 [INFO]: Epoch 004 - training loss: 0.5188, validation loss: 0.4067
2024-06-02 11:12:32 [INFO]: Epoch 005 - training loss: 0.5129, validation loss: 0.4035
2024-06-02 11:12:39 [INFO]: Epoch 006 - training loss: 0.5062, validation loss: 0.4024
2024-06-02 11:12:45 [INFO]: Epoch 007 - training loss: 0.5007, validation loss: 0.4012
2024-06-02 11:12:52 [INFO]: Epoch 008 - training loss: 0.4983, validation loss: 0.4008
2024-06-02 11:12:59 [INFO]: Epoch 009 - training loss: 0.4953, validation loss: 0.3993
2024-06-02 11:13:06 [INFO]: Epoch 010 - training loss: 0.4930, validation loss: 0.3981
2024-06-02 11:13:13 [INFO]: Epoch 011 - training loss: 0.4905, validation loss: 0.3961
2024-06-02 11:13:20 [INFO]: Epoch 012 - training loss: 0.4881, validation loss: 0.3949
2024-06-02 11:13:27 [INFO]: Epoch 013 - training loss: 0.4867, validation loss: 0.3955
2024-06-02 11:13:34 [INFO]: Epoch 014 - training loss: 0.4854, validation loss: 0.3940
2024-06-02 11:13:40 [INFO]: Epoch 015 - training loss: 0.4836, validation loss: 0.3939
2024-06-02 11:13:47 [INFO]: Epoch 016 - training loss: 0.4821, validation loss: 0.3912
2024-06-02 11:13:53 [INFO]: Epoch 017 - training loss: 0.4808, validation loss: 0.3932
2024-06-02 11:13:59 [INFO]: Epoch 018 - training loss: 0.4787, validation loss: 0.3932
2024-06-02 11:14:05 [INFO]: Epoch 019 - training loss: 0.4738, validation loss: 0.3886
2024-06-02 11:14:11 [INFO]: Epoch 020 - training loss: 0.4691, validation loss: 0.3864
2024-06-02 11:14:17 [INFO]: Epoch 021 - training loss: 0.4672, validation loss: 0.3867
2024-06-02 11:14:23 [INFO]: Epoch 022 - training loss: 0.4644, validation loss: 0.3849
2024-06-02 11:14:29 [INFO]: Epoch 023 - training loss: 0.4620, validation loss: 0.3832
2024-06-02 11:14:35 [INFO]: Epoch 024 - training loss: 0.4607, validation loss: 0.3804
2024-06-02 11:14:41 [INFO]: Epoch 025 - training loss: 0.4594, validation loss: 0.3823
2024-06-02 11:14:47 [INFO]: Epoch 026 - training loss: 0.4583, validation loss: 0.3806
2024-06-02 11:14:54 [INFO]: Epoch 027 - training loss: 0.4582, validation loss: 0.3821
2024-06-02 11:15:00 [INFO]: Epoch 028 - training loss: 0.4571, validation loss: 0.3827
2024-06-02 11:15:06 [INFO]: Epoch 029 - training loss: 0.4555, validation loss: 0.3802
2024-06-02 11:15:12 [INFO]: Epoch 030 - training loss: 0.4543, validation loss: 0.3796
2024-06-02 11:15:18 [INFO]: Epoch 031 - training loss: 0.4537, validation loss: 0.3802
2024-06-02 11:15:24 [INFO]: Epoch 032 - training loss: 0.4532, validation loss: 0.3816
2024-06-02 11:15:30 [INFO]: Epoch 033 - training loss: 0.4523, validation loss: 0.3812
2024-06-02 11:15:37 [INFO]: Epoch 034 - training loss: 0.4524, validation loss: 0.3801
2024-06-02 11:15:43 [INFO]: Epoch 035 - training loss: 0.4520, validation loss: 0.3795
2024-06-02 11:15:49 [INFO]: Epoch 036 - training loss: 0.4505, validation loss: 0.3819
2024-06-02 11:15:55 [INFO]: Epoch 037 - training loss: 0.4497, validation loss: 0.3838
2024-06-02 11:16:02 [INFO]: Epoch 038 - training loss: 0.4476, validation loss: 0.3810
2024-06-02 11:16:08 [INFO]: Epoch 039 - training loss: 0.4433, validation loss: 0.3779
2024-06-02 11:16:14 [INFO]: Epoch 040 - training loss: 0.4394, validation loss: 0.3747
2024-06-02 11:16:20 [INFO]: Epoch 041 - training loss: 0.4375, validation loss: 0.3747
2024-06-02 11:16:26 [INFO]: Epoch 042 - training loss: 0.4357, validation loss: 0.3732
2024-06-02 11:16:32 [INFO]: Epoch 043 - training loss: 0.4345, validation loss: 0.3727
2024-06-02 11:16:38 [INFO]: Epoch 044 - training loss: 0.4328, validation loss: 0.3723
2024-06-02 11:16:44 [INFO]: Epoch 045 - training loss: 0.4304, validation loss: 0.3713
2024-06-02 11:16:50 [INFO]: Epoch 046 - training loss: 0.4287, validation loss: 0.3742
2024-06-02 11:16:56 [INFO]: Epoch 047 - training loss: 0.4271, validation loss: 0.3693
2024-06-02 11:17:01 [INFO]: Epoch 048 - training loss: 0.4250, validation loss: 0.3719
2024-06-02 11:17:07 [INFO]: Epoch 049 - training loss: 0.4235, validation loss: 0.3682
2024-06-02 11:17:13 [INFO]: Epoch 050 - training loss: 0.4222, validation loss: 0.3678
2024-06-02 11:17:19 [INFO]: Epoch 051 - training loss: 0.4211, validation loss: 0.3667
2024-06-02 11:17:26 [INFO]: Epoch 052 - training loss: 0.4206, validation loss: 0.3678
2024-06-02 11:17:32 [INFO]: Epoch 053 - training loss: 0.4206, validation loss: 0.3677
2024-06-02 11:17:38 [INFO]: Epoch 054 - training loss: 0.4193, validation loss: 0.3678
2024-06-02 11:17:44 [INFO]: Epoch 055 - training loss: 0.4185, validation loss: 0.3651
2024-06-02 11:17:51 [INFO]: Epoch 056 - training loss: 0.4179, validation loss: 0.3667
2024-06-02 11:17:57 [INFO]: Epoch 057 - training loss: 0.4176, validation loss: 0.3668
2024-06-02 11:18:03 [INFO]: Epoch 058 - training loss: 0.4164, validation loss: 0.3656
2024-06-02 11:18:09 [INFO]: Epoch 059 - training loss: 0.4165, validation loss: 0.3644
2024-06-02 11:18:15 [INFO]: Epoch 060 - training loss: 0.4169, validation loss: 0.3660
2024-06-02 11:18:21 [INFO]: Epoch 061 - training loss: 0.4149, validation loss: 0.3648
2024-06-02 11:18:27 [INFO]: Epoch 062 - training loss: 0.4156, validation loss: 0.3632
2024-06-02 11:18:32 [INFO]: Epoch 063 - training loss: 0.4140, validation loss: 0.3639
2024-06-02 11:18:37 [INFO]: Epoch 064 - training loss: 0.4140, validation loss: 0.3633
2024-06-02 11:18:43 [INFO]: Epoch 065 - training loss: 0.4129, validation loss: 0.3640
2024-06-02 11:18:48 [INFO]: Epoch 066 - training loss: 0.4163, validation loss: 0.3655
2024-06-02 11:18:54 [INFO]: Epoch 067 - training loss: 0.4154, validation loss: 0.3624
2024-06-02 11:18:59 [INFO]: Epoch 068 - training loss: 0.4132, validation loss: 0.3641
2024-06-02 11:19:04 [INFO]: Epoch 069 - training loss: 0.4118, validation loss: 0.3610
2024-06-02 11:19:09 [INFO]: Epoch 070 - training loss: 0.4114, validation loss: 0.3621
2024-06-02 11:19:15 [INFO]: Epoch 071 - training loss: 0.4111, validation loss: 0.3601
2024-06-02 11:19:20 [INFO]: Epoch 072 - training loss: 0.4102, validation loss: 0.3628
2024-06-02 11:19:25 [INFO]: Epoch 073 - training loss: 0.4098, validation loss: 0.3601
2024-06-02 11:19:31 [INFO]: Epoch 074 - training loss: 0.4097, validation loss: 0.3618
2024-06-02 11:19:36 [INFO]: Epoch 075 - training loss: 0.4093, validation loss: 0.3616
2024-06-02 11:19:41 [INFO]: Epoch 076 - training loss: 0.4087, validation loss: 0.3620
2024-06-02 11:19:47 [INFO]: Epoch 077 - training loss: 0.4087, validation loss: 0.3629
2024-06-02 11:19:52 [INFO]: Epoch 078 - training loss: 0.4085, validation loss: 0.3626
2024-06-02 11:19:57 [INFO]: Epoch 079 - training loss: 0.4079, validation loss: 0.3647
2024-06-02 11:20:03 [INFO]: Epoch 080 - training loss: 0.4081, validation loss: 0.3609
2024-06-02 11:20:08 [INFO]: Epoch 081 - training loss: 0.4088, validation loss: 0.3626
2024-06-02 11:20:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 11:20:08 [INFO]: Finished training. The best model is from epoch#71.
2024-06-02 11:20:08 [INFO]: Saved the model to results_point_rate01/Electricity/MICN_Electricity/round_1/20240602_T111157/MICN.pypots
2024-06-02 11:20:09 [INFO]: Successfully saved to results_point_rate01/Electricity/MICN_Electricity/round_1/imputation.pkl
2024-06-02 11:20:09 [INFO]: Round1 - MICN on Electricity: MAE=0.3885, MSE=0.3529, MRE=0.2078
2024-06-02 11:20:09 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 11:20:09 [INFO]: Using the given device: cuda:0
2024-06-02 11:20:09 [INFO]: Model files will be saved to results_point_rate01/Electricity/MICN_Electricity/round_2/20240602_T112009
2024-06-02 11:20:09 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/MICN_Electricity/round_2/20240602_T112009/tensorboard
2024-06-02 11:20:09 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-02 11:20:15 [INFO]: Epoch 001 - training loss: 0.7157, validation loss: 0.4579
2024-06-02 11:20:20 [INFO]: Epoch 002 - training loss: 0.6213, validation loss: 0.4465
2024-06-02 11:20:26 [INFO]: Epoch 003 - training loss: 0.5552, validation loss: 0.4257
2024-06-02 11:20:31 [INFO]: Epoch 004 - training loss: 0.5199, validation loss: 0.4229
2024-06-02 11:20:36 [INFO]: Epoch 005 - training loss: 0.5109, validation loss: 0.4198
2024-06-02 11:20:42 [INFO]: Epoch 006 - training loss: 0.5042, validation loss: 0.4177
2024-06-02 11:20:47 [INFO]: Epoch 007 - training loss: 0.5018, validation loss: 0.4172
2024-06-02 11:20:52 [INFO]: Epoch 008 - training loss: 0.4991, validation loss: 0.4151
2024-06-02 11:20:58 [INFO]: Epoch 009 - training loss: 0.4968, validation loss: 0.4143
2024-06-02 11:21:03 [INFO]: Epoch 010 - training loss: 0.4944, validation loss: 0.4119
2024-06-02 11:21:08 [INFO]: Epoch 011 - training loss: 0.4922, validation loss: 0.4114
2024-06-02 11:21:14 [INFO]: Epoch 012 - training loss: 0.4893, validation loss: 0.4101
2024-06-02 11:21:19 [INFO]: Epoch 013 - training loss: 0.4886, validation loss: 0.4083
2024-06-02 11:21:25 [INFO]: Epoch 014 - training loss: 0.4871, validation loss: 0.4078
2024-06-02 11:21:30 [INFO]: Epoch 015 - training loss: 0.4856, validation loss: 0.4066
2024-06-02 11:21:35 [INFO]: Epoch 016 - training loss: 0.4840, validation loss: 0.4052
2024-06-02 11:21:41 [INFO]: Epoch 017 - training loss: 0.4813, validation loss: 0.4035
2024-06-02 11:21:46 [INFO]: Epoch 018 - training loss: 0.4775, validation loss: 0.3997
2024-06-02 11:21:51 [INFO]: Epoch 019 - training loss: 0.4729, validation loss: 0.4003
2024-06-02 11:21:57 [INFO]: Epoch 020 - training loss: 0.4694, validation loss: 0.3982
2024-06-02 11:22:02 [INFO]: Epoch 021 - training loss: 0.4667, validation loss: 0.3976
2024-06-02 11:22:08 [INFO]: Epoch 022 - training loss: 0.4645, validation loss: 0.3972
2024-06-02 11:22:13 [INFO]: Epoch 023 - training loss: 0.4635, validation loss: 0.3938
2024-06-02 11:22:18 [INFO]: Epoch 024 - training loss: 0.4618, validation loss: 0.3918
2024-06-02 11:22:24 [INFO]: Epoch 025 - training loss: 0.4605, validation loss: 0.3926
2024-06-02 11:22:29 [INFO]: Epoch 026 - training loss: 0.4598, validation loss: 0.3911
2024-06-02 11:22:34 [INFO]: Epoch 027 - training loss: 0.4589, validation loss: 0.3912
2024-06-02 11:22:39 [INFO]: Epoch 028 - training loss: 0.4591, validation loss: 0.3902
2024-06-02 11:22:43 [INFO]: Epoch 029 - training loss: 0.4581, validation loss: 0.3886
2024-06-02 11:22:49 [INFO]: Epoch 030 - training loss: 0.4565, validation loss: 0.3901
2024-06-02 11:22:54 [INFO]: Epoch 031 - training loss: 0.4560, validation loss: 0.3879
2024-06-02 11:22:59 [INFO]: Epoch 032 - training loss: 0.4552, validation loss: 0.3880
2024-06-02 11:23:04 [INFO]: Epoch 033 - training loss: 0.4542, validation loss: 0.3874
2024-06-02 11:23:10 [INFO]: Epoch 034 - training loss: 0.4533, validation loss: 0.3891
2024-06-02 11:23:15 [INFO]: Epoch 035 - training loss: 0.4525, validation loss: 0.3880
2024-06-02 11:23:21 [INFO]: Epoch 036 - training loss: 0.4508, validation loss: 0.3863
2024-06-02 11:23:26 [INFO]: Epoch 037 - training loss: 0.4480, validation loss: 0.3845
2024-06-02 11:23:31 [INFO]: Epoch 038 - training loss: 0.4443, validation loss: 0.3817
2024-06-02 11:23:37 [INFO]: Epoch 039 - training loss: 0.4413, validation loss: 0.3809
2024-06-02 11:23:42 [INFO]: Epoch 040 - training loss: 0.4390, validation loss: 0.3813
2024-06-02 11:23:48 [INFO]: Epoch 041 - training loss: 0.4387, validation loss: 0.3787
2024-06-02 11:23:53 [INFO]: Epoch 042 - training loss: 0.4370, validation loss: 0.3777
2024-06-02 11:23:59 [INFO]: Epoch 043 - training loss: 0.4358, validation loss: 0.3805
2024-06-02 11:24:04 [INFO]: Epoch 044 - training loss: 0.4351, validation loss: 0.3806
2024-06-02 11:24:09 [INFO]: Epoch 045 - training loss: 0.4346, validation loss: 0.3779
2024-06-02 11:24:15 [INFO]: Epoch 046 - training loss: 0.4337, validation loss: 0.3779
2024-06-02 11:24:20 [INFO]: Epoch 047 - training loss: 0.4324, validation loss: 0.3770
2024-06-02 11:24:25 [INFO]: Epoch 048 - training loss: 0.4322, validation loss: 0.3781
2024-06-02 11:24:30 [INFO]: Epoch 049 - training loss: 0.4309, validation loss: 0.3756
2024-06-02 11:24:36 [INFO]: Epoch 050 - training loss: 0.4286, validation loss: 0.3738
2024-06-02 11:24:41 [INFO]: Epoch 051 - training loss: 0.4264, validation loss: 0.3765
2024-06-02 11:24:46 [INFO]: Epoch 052 - training loss: 0.4246, validation loss: 0.3724
2024-06-02 11:24:52 [INFO]: Epoch 053 - training loss: 0.4232, validation loss: 0.3736
2024-06-02 11:24:57 [INFO]: Epoch 054 - training loss: 0.4224, validation loss: 0.3708
2024-06-02 11:25:02 [INFO]: Epoch 055 - training loss: 0.4218, validation loss: 0.3696
2024-06-02 11:25:08 [INFO]: Epoch 056 - training loss: 0.4208, validation loss: 0.3695
2024-06-02 11:25:13 [INFO]: Epoch 057 - training loss: 0.4201, validation loss: 0.3694
2024-06-02 11:25:18 [INFO]: Epoch 058 - training loss: 0.4188, validation loss: 0.3696
2024-06-02 11:25:23 [INFO]: Epoch 059 - training loss: 0.4187, validation loss: 0.3692
2024-06-02 11:25:28 [INFO]: Epoch 060 - training loss: 0.4181, validation loss: 0.3694
2024-06-02 11:25:34 [INFO]: Epoch 061 - training loss: 0.4186, validation loss: 0.3697
2024-06-02 11:25:39 [INFO]: Epoch 062 - training loss: 0.4171, validation loss: 0.3687
2024-06-02 11:25:44 [INFO]: Epoch 063 - training loss: 0.4163, validation loss: 0.3663
2024-06-02 11:25:49 [INFO]: Epoch 064 - training loss: 0.4153, validation loss: 0.3668
2024-06-02 11:25:54 [INFO]: Epoch 065 - training loss: 0.4149, validation loss: 0.3655
2024-06-02 11:25:59 [INFO]: Epoch 066 - training loss: 0.4146, validation loss: 0.3670
2024-06-02 11:26:04 [INFO]: Epoch 067 - training loss: 0.4144, validation loss: 0.3660
2024-06-02 11:26:10 [INFO]: Epoch 068 - training loss: 0.4154, validation loss: 0.3676
2024-06-02 11:26:15 [INFO]: Epoch 069 - training loss: 0.4146, validation loss: 0.3673
2024-06-02 11:26:20 [INFO]: Epoch 070 - training loss: 0.4133, validation loss: 0.3661
2024-06-02 11:26:26 [INFO]: Epoch 071 - training loss: 0.4138, validation loss: 0.3652
2024-06-02 11:26:31 [INFO]: Epoch 072 - training loss: 0.4129, validation loss: 0.3649
2024-06-02 11:26:36 [INFO]: Epoch 073 - training loss: 0.4117, validation loss: 0.3643
2024-06-02 11:26:42 [INFO]: Epoch 074 - training loss: 0.4120, validation loss: 0.3644
2024-06-02 11:26:47 [INFO]: Epoch 075 - training loss: 0.4116, validation loss: 0.3643
2024-06-02 11:26:52 [INFO]: Epoch 076 - training loss: 0.4107, validation loss: 0.3639
2024-06-02 11:26:58 [INFO]: Epoch 077 - training loss: 0.4099, validation loss: 0.3639
2024-06-02 11:27:03 [INFO]: Epoch 078 - training loss: 0.4102, validation loss: 0.3638
2024-06-02 11:27:08 [INFO]: Epoch 079 - training loss: 0.4100, validation loss: 0.3648
2024-06-02 11:27:13 [INFO]: Epoch 080 - training loss: 0.4095, validation loss: 0.3635
2024-06-02 11:27:19 [INFO]: Epoch 081 - training loss: 0.4094, validation loss: 0.3644
2024-06-02 11:27:24 [INFO]: Epoch 082 - training loss: 0.4098, validation loss: 0.3624
2024-06-02 11:27:30 [INFO]: Epoch 083 - training loss: 0.4089, validation loss: 0.3623
2024-06-02 11:27:35 [INFO]: Epoch 084 - training loss: 0.4094, validation loss: 0.3629
2024-06-02 11:27:41 [INFO]: Epoch 085 - training loss: 0.4085, validation loss: 0.3624
2024-06-02 11:27:46 [INFO]: Epoch 086 - training loss: 0.4079, validation loss: 0.3628
2024-06-02 11:27:51 [INFO]: Epoch 087 - training loss: 0.4079, validation loss: 0.3627
2024-06-02 11:27:56 [INFO]: Epoch 088 - training loss: 0.4074, validation loss: 0.3601
2024-06-02 11:28:02 [INFO]: Epoch 089 - training loss: 0.4073, validation loss: 0.3616
2024-06-02 11:28:07 [INFO]: Epoch 090 - training loss: 0.4067, validation loss: 0.3604
2024-06-02 11:28:12 [INFO]: Epoch 091 - training loss: 0.4062, validation loss: 0.3618
2024-06-02 11:28:18 [INFO]: Epoch 092 - training loss: 0.4063, validation loss: 0.3619
2024-06-02 11:28:23 [INFO]: Epoch 093 - training loss: 0.4067, validation loss: 0.3620
2024-06-02 11:28:28 [INFO]: Epoch 094 - training loss: 0.4073, validation loss: 0.3629
2024-06-02 11:28:34 [INFO]: Epoch 095 - training loss: 0.4076, validation loss: 0.3615
2024-06-02 11:28:39 [INFO]: Epoch 096 - training loss: 0.4062, validation loss: 0.3626
2024-06-02 11:28:44 [INFO]: Epoch 097 - training loss: 0.4058, validation loss: 0.3624
2024-06-02 11:28:50 [INFO]: Epoch 098 - training loss: 0.4052, validation loss: 0.3614
2024-06-02 11:28:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 11:28:50 [INFO]: Finished training. The best model is from epoch#88.
2024-06-02 11:28:50 [INFO]: Saved the model to results_point_rate01/Electricity/MICN_Electricity/round_2/20240602_T112009/MICN.pypots
2024-06-02 11:28:50 [INFO]: Successfully saved to results_point_rate01/Electricity/MICN_Electricity/round_2/imputation.pkl
2024-06-02 11:28:50 [INFO]: Round2 - MICN on Electricity: MAE=0.3938, MSE=0.3578, MRE=0.2106
2024-06-02 11:28:50 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 11:28:50 [INFO]: Using the given device: cuda:0
2024-06-02 11:28:50 [INFO]: Model files will be saved to results_point_rate01/Electricity/MICN_Electricity/round_3/20240602_T112850
2024-06-02 11:28:50 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/MICN_Electricity/round_3/20240602_T112850/tensorboard
2024-06-02 11:28:51 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-02 11:28:56 [INFO]: Epoch 001 - training loss: 0.7171, validation loss: 0.4340
2024-06-02 11:29:01 [INFO]: Epoch 002 - training loss: 0.5597, validation loss: 0.4136
2024-06-02 11:29:06 [INFO]: Epoch 003 - training loss: 0.5267, validation loss: 0.4110
2024-06-02 11:29:12 [INFO]: Epoch 004 - training loss: 0.5194, validation loss: 0.4090
2024-06-02 11:29:17 [INFO]: Epoch 005 - training loss: 0.5130, validation loss: 0.4079
2024-06-02 11:29:22 [INFO]: Epoch 006 - training loss: 0.5077, validation loss: 0.4071
2024-06-02 11:29:28 [INFO]: Epoch 007 - training loss: 0.5054, validation loss: 0.4063
2024-06-02 11:29:33 [INFO]: Epoch 008 - training loss: 0.5011, validation loss: 0.4011
2024-06-02 11:29:38 [INFO]: Epoch 009 - training loss: 0.4961, validation loss: 0.4002
2024-06-02 11:29:44 [INFO]: Epoch 010 - training loss: 0.4921, validation loss: 0.3996
2024-06-02 11:29:49 [INFO]: Epoch 011 - training loss: 0.4875, validation loss: 0.3970
2024-06-02 11:29:54 [INFO]: Epoch 012 - training loss: 0.4830, validation loss: 0.3956
2024-06-02 11:30:00 [INFO]: Epoch 013 - training loss: 0.4813, validation loss: 0.3954
2024-06-02 11:30:05 [INFO]: Epoch 014 - training loss: 0.4774, validation loss: 0.3937
2024-06-02 11:30:10 [INFO]: Epoch 015 - training loss: 0.4750, validation loss: 0.3921
2024-06-02 11:30:15 [INFO]: Epoch 016 - training loss: 0.4742, validation loss: 0.3904
2024-06-02 11:30:21 [INFO]: Epoch 017 - training loss: 0.4712, validation loss: 0.3908
2024-06-02 11:30:26 [INFO]: Epoch 018 - training loss: 0.4710, validation loss: 0.3881
2024-06-02 11:30:31 [INFO]: Epoch 019 - training loss: 0.4680, validation loss: 0.3865
2024-06-02 11:30:37 [INFO]: Epoch 020 - training loss: 0.4668, validation loss: 0.3850
2024-06-02 11:30:42 [INFO]: Epoch 021 - training loss: 0.4657, validation loss: 0.3867
2024-06-02 11:30:47 [INFO]: Epoch 022 - training loss: 0.4643, validation loss: 0.3842
2024-06-02 11:30:52 [INFO]: Epoch 023 - training loss: 0.4632, validation loss: 0.3842
2024-06-02 11:30:57 [INFO]: Epoch 024 - training loss: 0.4621, validation loss: 0.3824
2024-06-02 11:31:03 [INFO]: Epoch 025 - training loss: 0.4607, validation loss: 0.3819
2024-06-02 11:31:08 [INFO]: Epoch 026 - training loss: 0.4607, validation loss: 0.3855
2024-06-02 11:31:13 [INFO]: Epoch 027 - training loss: 0.4598, validation loss: 0.3817
2024-06-02 11:31:18 [INFO]: Epoch 028 - training loss: 0.4579, validation loss: 0.3811
2024-06-02 11:31:23 [INFO]: Epoch 029 - training loss: 0.4573, validation loss: 0.3812
2024-06-02 11:31:29 [INFO]: Epoch 030 - training loss: 0.4561, validation loss: 0.3810
2024-06-02 11:31:34 [INFO]: Epoch 031 - training loss: 0.4556, validation loss: 0.3797
2024-06-02 11:31:39 [INFO]: Epoch 032 - training loss: 0.4551, validation loss: 0.3789
2024-06-02 11:31:44 [INFO]: Epoch 033 - training loss: 0.4540, validation loss: 0.3813
2024-06-02 11:31:50 [INFO]: Epoch 034 - training loss: 0.4518, validation loss: 0.3809
2024-06-02 11:31:55 [INFO]: Epoch 035 - training loss: 0.4507, validation loss: 0.3812
2024-06-02 11:32:00 [INFO]: Epoch 036 - training loss: 0.4475, validation loss: 0.3784
2024-06-02 11:32:05 [INFO]: Epoch 037 - training loss: 0.4442, validation loss: 0.3760
2024-06-02 11:32:10 [INFO]: Epoch 038 - training loss: 0.4408, validation loss: 0.3721
2024-06-02 11:32:15 [INFO]: Epoch 039 - training loss: 0.4414, validation loss: 0.3740
2024-06-02 11:32:21 [INFO]: Epoch 040 - training loss: 0.4380, validation loss: 0.3729
2024-06-02 11:32:26 [INFO]: Epoch 041 - training loss: 0.4369, validation loss: 0.3717
2024-06-02 11:32:31 [INFO]: Epoch 042 - training loss: 0.4351, validation loss: 0.3722
2024-06-02 11:32:37 [INFO]: Epoch 043 - training loss: 0.4342, validation loss: 0.3728
2024-06-02 11:32:42 [INFO]: Epoch 044 - training loss: 0.4336, validation loss: 0.3712
2024-06-02 11:32:47 [INFO]: Epoch 045 - training loss: 0.4331, validation loss: 0.3721
2024-06-02 11:32:53 [INFO]: Epoch 046 - training loss: 0.4318, validation loss: 0.3721
2024-06-02 11:32:58 [INFO]: Epoch 047 - training loss: 0.4310, validation loss: 0.3710
2024-06-02 11:33:03 [INFO]: Epoch 048 - training loss: 0.4298, validation loss: 0.3719
2024-06-02 11:33:09 [INFO]: Epoch 049 - training loss: 0.4285, validation loss: 0.3704
2024-06-02 11:33:13 [INFO]: Epoch 050 - training loss: 0.4263, validation loss: 0.3696
2024-06-02 11:33:18 [INFO]: Epoch 051 - training loss: 0.4259, validation loss: 0.3704
2024-06-02 11:33:23 [INFO]: Epoch 052 - training loss: 0.4247, validation loss: 0.3697
2024-06-02 11:33:28 [INFO]: Epoch 053 - training loss: 0.4223, validation loss: 0.3679
2024-06-02 11:33:34 [INFO]: Epoch 054 - training loss: 0.4206, validation loss: 0.3689
2024-06-02 11:33:39 [INFO]: Epoch 055 - training loss: 0.4188, validation loss: 0.3668
2024-06-02 11:33:44 [INFO]: Epoch 056 - training loss: 0.4190, validation loss: 0.3668
2024-06-02 11:33:50 [INFO]: Epoch 057 - training loss: 0.4179, validation loss: 0.3686
2024-06-02 11:33:55 [INFO]: Epoch 058 - training loss: 0.4169, validation loss: 0.3677
2024-06-02 11:34:01 [INFO]: Epoch 059 - training loss: 0.4168, validation loss: 0.3664
2024-06-02 11:34:06 [INFO]: Epoch 060 - training loss: 0.4154, validation loss: 0.3674
2024-06-02 11:34:11 [INFO]: Epoch 061 - training loss: 0.4164, validation loss: 0.3674
2024-06-02 11:34:16 [INFO]: Epoch 062 - training loss: 0.4173, validation loss: 0.3661
2024-06-02 11:34:22 [INFO]: Epoch 063 - training loss: 0.4146, validation loss: 0.3656
2024-06-02 11:34:27 [INFO]: Epoch 064 - training loss: 0.4136, validation loss: 0.3666
2024-06-02 11:34:32 [INFO]: Epoch 065 - training loss: 0.4136, validation loss: 0.3690
2024-06-02 11:34:37 [INFO]: Epoch 066 - training loss: 0.4124, validation loss: 0.3664
2024-06-02 11:34:43 [INFO]: Epoch 067 - training loss: 0.4126, validation loss: 0.3665
2024-06-02 11:34:48 [INFO]: Epoch 068 - training loss: 0.4118, validation loss: 0.3644
2024-06-02 11:34:53 [INFO]: Epoch 069 - training loss: 0.4116, validation loss: 0.3659
2024-06-02 11:34:59 [INFO]: Epoch 070 - training loss: 0.4111, validation loss: 0.3662
2024-06-02 11:35:04 [INFO]: Epoch 071 - training loss: 0.4112, validation loss: 0.3651
2024-06-02 11:35:09 [INFO]: Epoch 072 - training loss: 0.4119, validation loss: 0.3657
2024-06-02 11:35:14 [INFO]: Epoch 073 - training loss: 0.4114, validation loss: 0.3656
2024-06-02 11:35:19 [INFO]: Epoch 074 - training loss: 0.4100, validation loss: 0.3663
2024-06-02 11:35:24 [INFO]: Epoch 075 - training loss: 0.4100, validation loss: 0.3671
2024-06-02 11:35:30 [INFO]: Epoch 076 - training loss: 0.4093, validation loss: 0.3659
2024-06-02 11:35:35 [INFO]: Epoch 077 - training loss: 0.4093, validation loss: 0.3655
2024-06-02 11:35:40 [INFO]: Epoch 078 - training loss: 0.4090, validation loss: 0.3652
2024-06-02 11:35:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 11:35:40 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 11:35:40 [INFO]: Saved the model to results_point_rate01/Electricity/MICN_Electricity/round_3/20240602_T112850/MICN.pypots
2024-06-02 11:35:41 [INFO]: Successfully saved to results_point_rate01/Electricity/MICN_Electricity/round_3/imputation.pkl
2024-06-02 11:35:41 [INFO]: Round3 - MICN on Electricity: MAE=0.4006, MSE=0.3677, MRE=0.2143
2024-06-02 11:35:41 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 11:35:41 [INFO]: Using the given device: cuda:0
2024-06-02 11:35:41 [INFO]: Model files will be saved to results_point_rate01/Electricity/MICN_Electricity/round_4/20240602_T113541
2024-06-02 11:35:41 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/MICN_Electricity/round_4/20240602_T113541/tensorboard
2024-06-02 11:35:42 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-02 11:35:47 [INFO]: Epoch 001 - training loss: 0.7191, validation loss: 0.4607
2024-06-02 11:35:53 [INFO]: Epoch 002 - training loss: 0.6206, validation loss: 0.4463
2024-06-02 11:35:58 [INFO]: Epoch 003 - training loss: 0.5552, validation loss: 0.4316
2024-06-02 11:36:04 [INFO]: Epoch 004 - training loss: 0.5291, validation loss: 0.4278
2024-06-02 11:36:09 [INFO]: Epoch 005 - training loss: 0.5193, validation loss: 0.4239
2024-06-02 11:36:14 [INFO]: Epoch 006 - training loss: 0.5124, validation loss: 0.4210
2024-06-02 11:36:20 [INFO]: Epoch 007 - training loss: 0.5088, validation loss: 0.4206
2024-06-02 11:36:25 [INFO]: Epoch 008 - training loss: 0.5061, validation loss: 0.4177
2024-06-02 11:36:30 [INFO]: Epoch 009 - training loss: 0.5027, validation loss: 0.4175
2024-06-02 11:36:36 [INFO]: Epoch 010 - training loss: 0.5003, validation loss: 0.4163
2024-06-02 11:36:41 [INFO]: Epoch 011 - training loss: 0.4993, validation loss: 0.4149
2024-06-02 11:36:46 [INFO]: Epoch 012 - training loss: 0.4975, validation loss: 0.4139
2024-06-02 11:36:51 [INFO]: Epoch 013 - training loss: 0.4952, validation loss: 0.4121
2024-06-02 11:36:57 [INFO]: Epoch 014 - training loss: 0.4932, validation loss: 0.4105
2024-06-02 11:37:02 [INFO]: Epoch 015 - training loss: 0.4910, validation loss: 0.4092
2024-06-02 11:37:07 [INFO]: Epoch 016 - training loss: 0.4886, validation loss: 0.4064
2024-06-02 11:37:12 [INFO]: Epoch 017 - training loss: 0.4852, validation loss: 0.4036
2024-06-02 11:37:16 [INFO]: Epoch 018 - training loss: 0.4809, validation loss: 0.4043
2024-06-02 11:37:20 [INFO]: Epoch 019 - training loss: 0.4777, validation loss: 0.4029
2024-06-02 11:37:25 [INFO]: Epoch 020 - training loss: 0.4735, validation loss: 0.4003
2024-06-02 11:37:29 [INFO]: Epoch 021 - training loss: 0.4704, validation loss: 0.3968
2024-06-02 11:37:33 [INFO]: Epoch 022 - training loss: 0.4687, validation loss: 0.3986
2024-06-02 11:37:37 [INFO]: Epoch 023 - training loss: 0.4670, validation loss: 0.3972
2024-06-02 11:37:42 [INFO]: Epoch 024 - training loss: 0.4647, validation loss: 0.3949
2024-06-02 11:37:46 [INFO]: Epoch 025 - training loss: 0.4627, validation loss: 0.3932
2024-06-02 11:37:51 [INFO]: Epoch 026 - training loss: 0.4616, validation loss: 0.3942
2024-06-02 11:37:55 [INFO]: Epoch 027 - training loss: 0.4608, validation loss: 0.3913
2024-06-02 11:37:59 [INFO]: Epoch 028 - training loss: 0.4598, validation loss: 0.3917
2024-06-02 11:38:04 [INFO]: Epoch 029 - training loss: 0.4579, validation loss: 0.3911
2024-06-02 11:38:08 [INFO]: Epoch 030 - training loss: 0.4570, validation loss: 0.3926
2024-06-02 11:38:13 [INFO]: Epoch 031 - training loss: 0.4557, validation loss: 0.3881
2024-06-02 11:38:17 [INFO]: Epoch 032 - training loss: 0.4503, validation loss: 0.3877
2024-06-02 11:38:21 [INFO]: Epoch 033 - training loss: 0.4471, validation loss: 0.3848
2024-06-02 11:38:25 [INFO]: Epoch 034 - training loss: 0.4436, validation loss: 0.3837
2024-06-02 11:38:30 [INFO]: Epoch 035 - training loss: 0.4418, validation loss: 0.3831
2024-06-02 11:38:34 [INFO]: Epoch 036 - training loss: 0.4415, validation loss: 0.3823
2024-06-02 11:38:39 [INFO]: Epoch 037 - training loss: 0.4392, validation loss: 0.3819
2024-06-02 11:38:43 [INFO]: Epoch 038 - training loss: 0.4384, validation loss: 0.3792
2024-06-02 11:38:47 [INFO]: Epoch 039 - training loss: 0.4375, validation loss: 0.3798
2024-06-02 11:38:52 [INFO]: Epoch 040 - training loss: 0.4367, validation loss: 0.3804
2024-06-02 11:38:56 [INFO]: Epoch 041 - training loss: 0.4352, validation loss: 0.3805
2024-06-02 11:39:00 [INFO]: Epoch 042 - training loss: 0.4342, validation loss: 0.3790
2024-06-02 11:39:05 [INFO]: Epoch 043 - training loss: 0.4331, validation loss: 0.3783
2024-06-02 11:39:09 [INFO]: Epoch 044 - training loss: 0.4319, validation loss: 0.3794
2024-06-02 11:39:14 [INFO]: Epoch 045 - training loss: 0.4320, validation loss: 0.3770
2024-06-02 11:39:18 [INFO]: Epoch 046 - training loss: 0.4311, validation loss: 0.3770
2024-06-02 11:39:23 [INFO]: Epoch 047 - training loss: 0.4308, validation loss: 0.3752
2024-06-02 11:39:27 [INFO]: Epoch 048 - training loss: 0.4293, validation loss: 0.3749
2024-06-02 11:39:31 [INFO]: Epoch 049 - training loss: 0.4290, validation loss: 0.3749
2024-06-02 11:39:36 [INFO]: Epoch 050 - training loss: 0.4283, validation loss: 0.3745
2024-06-02 11:39:40 [INFO]: Epoch 051 - training loss: 0.4274, validation loss: 0.3743
2024-06-02 11:39:45 [INFO]: Epoch 052 - training loss: 0.4259, validation loss: 0.3717
2024-06-02 11:39:49 [INFO]: Epoch 053 - training loss: 0.4251, validation loss: 0.3726
2024-06-02 11:39:54 [INFO]: Epoch 054 - training loss: 0.4229, validation loss: 0.3716
2024-06-02 11:39:58 [INFO]: Epoch 055 - training loss: 0.4215, validation loss: 0.3705
2024-06-02 11:40:03 [INFO]: Epoch 056 - training loss: 0.4204, validation loss: 0.3689
2024-06-02 11:40:07 [INFO]: Epoch 057 - training loss: 0.4192, validation loss: 0.3687
2024-06-02 11:40:11 [INFO]: Epoch 058 - training loss: 0.4177, validation loss: 0.3691
2024-06-02 11:40:15 [INFO]: Epoch 059 - training loss: 0.4181, validation loss: 0.3686
2024-06-02 11:40:19 [INFO]: Epoch 060 - training loss: 0.4163, validation loss: 0.3692
2024-06-02 11:40:23 [INFO]: Epoch 061 - training loss: 0.4161, validation loss: 0.3681
2024-06-02 11:40:27 [INFO]: Epoch 062 - training loss: 0.4156, validation loss: 0.3677
2024-06-02 11:40:31 [INFO]: Epoch 063 - training loss: 0.4149, validation loss: 0.3679
2024-06-02 11:40:36 [INFO]: Epoch 064 - training loss: 0.4144, validation loss: 0.3676
2024-06-02 11:40:40 [INFO]: Epoch 065 - training loss: 0.4147, validation loss: 0.3685
2024-06-02 11:40:44 [INFO]: Epoch 066 - training loss: 0.4146, validation loss: 0.3689
2024-06-02 11:40:48 [INFO]: Epoch 067 - training loss: 0.4136, validation loss: 0.3656
2024-06-02 11:40:53 [INFO]: Epoch 068 - training loss: 0.4128, validation loss: 0.3662
2024-06-02 11:40:57 [INFO]: Epoch 069 - training loss: 0.4128, validation loss: 0.3677
2024-06-02 11:41:01 [INFO]: Epoch 070 - training loss: 0.4122, validation loss: 0.3651
2024-06-02 11:41:06 [INFO]: Epoch 071 - training loss: 0.4116, validation loss: 0.3657
2024-06-02 11:41:10 [INFO]: Epoch 072 - training loss: 0.4117, validation loss: 0.3656
2024-06-02 11:41:15 [INFO]: Epoch 073 - training loss: 0.4109, validation loss: 0.3658
2024-06-02 11:41:19 [INFO]: Epoch 074 - training loss: 0.4126, validation loss: 0.3665
2024-06-02 11:41:23 [INFO]: Epoch 075 - training loss: 0.4114, validation loss: 0.3654
2024-06-02 11:41:27 [INFO]: Epoch 076 - training loss: 0.4102, validation loss: 0.3641
2024-06-02 11:41:32 [INFO]: Epoch 077 - training loss: 0.4100, validation loss: 0.3644
2024-06-02 11:41:36 [INFO]: Epoch 078 - training loss: 0.4087, validation loss: 0.3644
2024-06-02 11:41:40 [INFO]: Epoch 079 - training loss: 0.4089, validation loss: 0.3641
2024-06-02 11:41:45 [INFO]: Epoch 080 - training loss: 0.4080, validation loss: 0.3643
2024-06-02 11:41:49 [INFO]: Epoch 081 - training loss: 0.4075, validation loss: 0.3652
2024-06-02 11:41:53 [INFO]: Epoch 082 - training loss: 0.4074, validation loss: 0.3645
2024-06-02 11:41:58 [INFO]: Epoch 083 - training loss: 0.4074, validation loss: 0.3633
2024-06-02 11:42:02 [INFO]: Epoch 084 - training loss: 0.4069, validation loss: 0.3639
2024-06-02 11:42:06 [INFO]: Epoch 085 - training loss: 0.4070, validation loss: 0.3632
2024-06-02 11:42:11 [INFO]: Epoch 086 - training loss: 0.4066, validation loss: 0.3648
2024-06-02 11:42:15 [INFO]: Epoch 087 - training loss: 0.4061, validation loss: 0.3629
2024-06-02 11:42:19 [INFO]: Epoch 088 - training loss: 0.4061, validation loss: 0.3611
2024-06-02 11:42:24 [INFO]: Epoch 089 - training loss: 0.4055, validation loss: 0.3625
2024-06-02 11:42:28 [INFO]: Epoch 090 - training loss: 0.4056, validation loss: 0.3621
2024-06-02 11:42:32 [INFO]: Epoch 091 - training loss: 0.4062, validation loss: 0.3626
2024-06-02 11:42:37 [INFO]: Epoch 092 - training loss: 0.4072, validation loss: 0.3639
2024-06-02 11:42:41 [INFO]: Epoch 093 - training loss: 0.4056, validation loss: 0.3623
2024-06-02 11:42:45 [INFO]: Epoch 094 - training loss: 0.4048, validation loss: 0.3643
2024-06-02 11:42:50 [INFO]: Epoch 095 - training loss: 0.4052, validation loss: 0.3626
2024-06-02 11:42:54 [INFO]: Epoch 096 - training loss: 0.4052, validation loss: 0.3624
2024-06-02 11:42:58 [INFO]: Epoch 097 - training loss: 0.4044, validation loss: 0.3623
2024-06-02 11:43:03 [INFO]: Epoch 098 - training loss: 0.4042, validation loss: 0.3633
2024-06-02 11:43:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 11:43:03 [INFO]: Finished training. The best model is from epoch#88.
2024-06-02 11:43:03 [INFO]: Saved the model to results_point_rate01/Electricity/MICN_Electricity/round_4/20240602_T113541/MICN.pypots
2024-06-02 11:43:03 [INFO]: Successfully saved to results_point_rate01/Electricity/MICN_Electricity/round_4/imputation.pkl
2024-06-02 11:43:03 [INFO]: Round4 - MICN on Electricity: MAE=0.3933, MSE=0.3583, MRE=0.2104
2024-06-02 11:43:03 [INFO]: Done! Final results:
Averaged MICN (5,457,910 params) on Electricity: MAE=0.3918 ± 0.005944687650205252, MSE=0.3574 ± 0.005923740058162251, MRE=0.2096 ± 0.0031801310476886253, average inference time=0.40
