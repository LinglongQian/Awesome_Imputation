2024-06-02 18:54:01 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 18:54:01 [INFO]: Using the given device: cuda:0
2024-06-02 18:54:01 [INFO]: Model files will be saved to results_point_rate01/Electricity/Informer_Electricity/round_0/20240602_T185401
2024-06-02 18:54:01 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Informer_Electricity/round_0/20240602_T185401/tensorboard
2024-06-02 18:54:02 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 18:54:11 [INFO]: Epoch 001 - training loss: 0.9460, validation loss: 2.9295
2024-06-02 18:54:19 [INFO]: Epoch 002 - training loss: 0.6398, validation loss: 2.8059
2024-06-02 18:54:27 [INFO]: Epoch 003 - training loss: 0.5868, validation loss: 2.7106
2024-06-02 18:54:35 [INFO]: Epoch 004 - training loss: 0.5570, validation loss: 2.6974
2024-06-02 18:54:42 [INFO]: Epoch 005 - training loss: 0.5359, validation loss: 2.6555
2024-06-02 18:54:51 [INFO]: Epoch 006 - training loss: 0.5211, validation loss: 2.6430
2024-06-02 18:55:00 [INFO]: Epoch 007 - training loss: 0.5088, validation loss: 2.6141
2024-06-02 18:55:08 [INFO]: Epoch 008 - training loss: 0.4979, validation loss: 2.6274
2024-06-02 18:55:16 [INFO]: Epoch 009 - training loss: 0.4902, validation loss: 2.6195
2024-06-02 18:55:25 [INFO]: Epoch 010 - training loss: 0.4829, validation loss: 2.6026
2024-06-02 18:55:33 [INFO]: Epoch 011 - training loss: 0.4780, validation loss: 2.5934
2024-06-02 18:55:42 [INFO]: Epoch 012 - training loss: 0.4722, validation loss: 2.5771
2024-06-02 18:55:49 [INFO]: Epoch 013 - training loss: 0.4685, validation loss: 2.5645
2024-06-02 18:55:58 [INFO]: Epoch 014 - training loss: 0.4630, validation loss: 2.5577
2024-06-02 18:56:06 [INFO]: Epoch 015 - training loss: 0.4591, validation loss: 2.5497
2024-06-02 18:56:15 [INFO]: Epoch 016 - training loss: 0.4555, validation loss: 2.5401
2024-06-02 18:56:23 [INFO]: Epoch 017 - training loss: 0.4515, validation loss: 2.5376
2024-06-02 18:56:31 [INFO]: Epoch 018 - training loss: 0.4475, validation loss: 2.5303
2024-06-02 18:56:39 [INFO]: Epoch 019 - training loss: 0.4442, validation loss: 2.5202
2024-06-02 18:56:47 [INFO]: Epoch 020 - training loss: 0.4417, validation loss: 2.5056
2024-06-02 18:56:55 [INFO]: Epoch 021 - training loss: 0.4375, validation loss: 2.4978
2024-06-02 18:57:03 [INFO]: Epoch 022 - training loss: 0.4332, validation loss: 2.4924
2024-06-02 18:57:11 [INFO]: Epoch 023 - training loss: 0.4306, validation loss: 2.4819
2024-06-02 18:57:18 [INFO]: Epoch 024 - training loss: 0.4291, validation loss: 2.4717
2024-06-02 18:57:27 [INFO]: Epoch 025 - training loss: 0.4259, validation loss: 2.4611
2024-06-02 18:57:36 [INFO]: Epoch 026 - training loss: 0.4259, validation loss: 2.4598
2024-06-02 18:57:43 [INFO]: Epoch 027 - training loss: 0.4264, validation loss: 2.4503
2024-06-02 18:57:51 [INFO]: Epoch 028 - training loss: 0.4213, validation loss: 2.4445
2024-06-02 18:57:59 [INFO]: Epoch 029 - training loss: 0.4178, validation loss: 2.4304
2024-06-02 18:58:07 [INFO]: Epoch 030 - training loss: 0.4148, validation loss: 2.4480
2024-06-02 18:58:16 [INFO]: Epoch 031 - training loss: 0.4123, validation loss: 2.4257
2024-06-02 18:58:23 [INFO]: Epoch 032 - training loss: 0.4147, validation loss: 2.4163
2024-06-02 18:58:31 [INFO]: Epoch 033 - training loss: 0.4158, validation loss: 2.4301
2024-06-02 18:58:40 [INFO]: Epoch 034 - training loss: 0.4106, validation loss: 2.4169
2024-06-02 18:58:48 [INFO]: Epoch 035 - training loss: 0.4067, validation loss: 2.4217
2024-06-02 18:58:56 [INFO]: Epoch 036 - training loss: 0.4043, validation loss: 2.4134
2024-06-02 18:59:04 [INFO]: Epoch 037 - training loss: 0.4031, validation loss: 2.4111
2024-06-02 18:59:13 [INFO]: Epoch 038 - training loss: 0.4028, validation loss: 2.4181
2024-06-02 18:59:21 [INFO]: Epoch 039 - training loss: 0.4004, validation loss: 2.4184
2024-06-02 18:59:30 [INFO]: Epoch 040 - training loss: 0.3982, validation loss: 2.4150
2024-06-02 18:59:38 [INFO]: Epoch 041 - training loss: 0.3984, validation loss: 2.3993
2024-06-02 18:59:46 [INFO]: Epoch 042 - training loss: 0.3953, validation loss: 2.4064
2024-06-02 18:59:55 [INFO]: Epoch 043 - training loss: 0.3943, validation loss: 2.3960
2024-06-02 19:00:02 [INFO]: Epoch 044 - training loss: 0.3942, validation loss: 2.4030
2024-06-02 19:00:11 [INFO]: Epoch 045 - training loss: 0.3929, validation loss: 2.4038
2024-06-02 19:00:19 [INFO]: Epoch 046 - training loss: 0.3926, validation loss: 2.4007
2024-06-02 19:00:28 [INFO]: Epoch 047 - training loss: 0.3918, validation loss: 2.4061
2024-06-02 19:00:36 [INFO]: Epoch 048 - training loss: 0.3898, validation loss: 2.3997
2024-06-02 19:00:44 [INFO]: Epoch 049 - training loss: 0.3882, validation loss: 2.4011
2024-06-02 19:00:52 [INFO]: Epoch 050 - training loss: 0.3891, validation loss: 2.4025
2024-06-02 19:00:58 [INFO]: Epoch 051 - training loss: 0.3885, validation loss: 2.3965
2024-06-02 19:01:05 [INFO]: Epoch 052 - training loss: 0.3866, validation loss: 2.3955
2024-06-02 19:01:11 [INFO]: Epoch 053 - training loss: 0.3837, validation loss: 2.3906
2024-06-02 19:01:20 [INFO]: Epoch 054 - training loss: 0.3822, validation loss: 2.3836
2024-06-02 19:01:29 [INFO]: Epoch 055 - training loss: 0.3802, validation loss: 2.3969
2024-06-02 19:01:37 [INFO]: Epoch 056 - training loss: 0.3798, validation loss: 2.3949
2024-06-02 19:01:45 [INFO]: Epoch 057 - training loss: 0.3804, validation loss: 2.3948
2024-06-02 19:01:53 [INFO]: Epoch 058 - training loss: 0.3786, validation loss: 2.3947
2024-06-02 19:02:00 [INFO]: Epoch 059 - training loss: 0.3782, validation loss: 2.3978
2024-06-02 19:02:09 [INFO]: Epoch 060 - training loss: 0.3781, validation loss: 2.3964
2024-06-02 19:02:17 [INFO]: Epoch 061 - training loss: 0.3764, validation loss: 2.4000
2024-06-02 19:02:25 [INFO]: Epoch 062 - training loss: 0.3756, validation loss: 2.4064
2024-06-02 19:02:33 [INFO]: Epoch 063 - training loss: 0.3792, validation loss: 2.4033
2024-06-02 19:02:41 [INFO]: Epoch 064 - training loss: 0.3771, validation loss: 2.3987
2024-06-02 19:02:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:02:41 [INFO]: Finished training. The best model is from epoch#54.
2024-06-02 19:02:42 [INFO]: Saved the model to results_point_rate01/Electricity/Informer_Electricity/round_0/20240602_T185401/Informer.pypots
2024-06-02 19:02:43 [INFO]: Successfully saved to results_point_rate01/Electricity/Informer_Electricity/round_0/imputation.pkl
2024-06-02 19:02:43 [INFO]: Round0 - Informer on Electricity: MAE=1.2729, MSE=3.0870, MRE=0.6810
2024-06-02 19:02:43 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:02:43 [INFO]: Using the given device: cuda:0
2024-06-02 19:02:43 [INFO]: Model files will be saved to results_point_rate01/Electricity/Informer_Electricity/round_1/20240602_T190243
2024-06-02 19:02:43 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Informer_Electricity/round_1/20240602_T190243/tensorboard
2024-06-02 19:02:44 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 19:02:52 [INFO]: Epoch 001 - training loss: 0.9386, validation loss: 2.9116
2024-06-02 19:03:01 [INFO]: Epoch 002 - training loss: 0.6382, validation loss: 2.7722
2024-06-02 19:03:09 [INFO]: Epoch 003 - training loss: 0.5873, validation loss: 2.7128
2024-06-02 19:03:17 [INFO]: Epoch 004 - training loss: 0.5554, validation loss: 2.6888
2024-06-02 19:03:25 [INFO]: Epoch 005 - training loss: 0.5374, validation loss: 2.6643
2024-06-02 19:03:34 [INFO]: Epoch 006 - training loss: 0.5227, validation loss: 2.6356
2024-06-02 19:03:42 [INFO]: Epoch 007 - training loss: 0.5088, validation loss: 2.6200
2024-06-02 19:03:51 [INFO]: Epoch 008 - training loss: 0.5018, validation loss: 2.6345
2024-06-02 19:03:59 [INFO]: Epoch 009 - training loss: 0.4942, validation loss: 2.6208
2024-06-02 19:04:07 [INFO]: Epoch 010 - training loss: 0.4840, validation loss: 2.5960
2024-06-02 19:04:15 [INFO]: Epoch 011 - training loss: 0.4761, validation loss: 2.5793
2024-06-02 19:04:24 [INFO]: Epoch 012 - training loss: 0.4714, validation loss: 2.5730
2024-06-02 19:04:32 [INFO]: Epoch 013 - training loss: 0.4662, validation loss: 2.5635
2024-06-02 19:04:40 [INFO]: Epoch 014 - training loss: 0.4626, validation loss: 2.5548
2024-06-02 19:04:48 [INFO]: Epoch 015 - training loss: 0.4592, validation loss: 2.5562
2024-06-02 19:04:56 [INFO]: Epoch 016 - training loss: 0.4527, validation loss: 2.5361
2024-06-02 19:05:04 [INFO]: Epoch 017 - training loss: 0.4499, validation loss: 2.5303
2024-06-02 19:05:11 [INFO]: Epoch 018 - training loss: 0.4483, validation loss: 2.5246
2024-06-02 19:05:20 [INFO]: Epoch 019 - training loss: 0.4439, validation loss: 2.5090
2024-06-02 19:05:28 [INFO]: Epoch 020 - training loss: 0.4427, validation loss: 2.5085
2024-06-02 19:05:37 [INFO]: Epoch 021 - training loss: 0.4371, validation loss: 2.5067
2024-06-02 19:05:45 [INFO]: Epoch 022 - training loss: 0.4340, validation loss: 2.4915
2024-06-02 19:05:54 [INFO]: Epoch 023 - training loss: 0.4322, validation loss: 2.4877
2024-06-02 19:06:02 [INFO]: Epoch 024 - training loss: 0.4308, validation loss: 2.4777
2024-06-02 19:06:10 [INFO]: Epoch 025 - training loss: 0.4270, validation loss: 2.4731
2024-06-02 19:06:18 [INFO]: Epoch 026 - training loss: 0.4255, validation loss: 2.4674
2024-06-02 19:06:27 [INFO]: Epoch 027 - training loss: 0.4251, validation loss: 2.4640
2024-06-02 19:06:35 [INFO]: Epoch 028 - training loss: 0.4216, validation loss: 2.4673
2024-06-02 19:06:43 [INFO]: Epoch 029 - training loss: 0.4192, validation loss: 2.4604
2024-06-02 19:06:51 [INFO]: Epoch 030 - training loss: 0.4165, validation loss: 2.4505
2024-06-02 19:06:59 [INFO]: Epoch 031 - training loss: 0.4124, validation loss: 2.4587
2024-06-02 19:07:08 [INFO]: Epoch 032 - training loss: 0.4114, validation loss: 2.4482
2024-06-02 19:07:17 [INFO]: Epoch 033 - training loss: 0.4097, validation loss: 2.4448
2024-06-02 19:07:23 [INFO]: Epoch 034 - training loss: 0.4083, validation loss: 2.4417
2024-06-02 19:07:31 [INFO]: Epoch 035 - training loss: 0.4085, validation loss: 2.4426
2024-06-02 19:07:40 [INFO]: Epoch 036 - training loss: 0.4057, validation loss: 2.4319
2024-06-02 19:07:48 [INFO]: Epoch 037 - training loss: 0.4058, validation loss: 2.4265
2024-06-02 19:07:57 [INFO]: Epoch 038 - training loss: 0.4034, validation loss: 2.4173
2024-06-02 19:08:05 [INFO]: Epoch 039 - training loss: 0.4013, validation loss: 2.4103
2024-06-02 19:08:13 [INFO]: Epoch 040 - training loss: 0.4006, validation loss: 2.4069
2024-06-02 19:08:21 [INFO]: Epoch 041 - training loss: 0.3979, validation loss: 2.3970
2024-06-02 19:08:29 [INFO]: Epoch 042 - training loss: 0.3974, validation loss: 2.3984
2024-06-02 19:08:38 [INFO]: Epoch 043 - training loss: 0.3946, validation loss: 2.3974
2024-06-02 19:08:45 [INFO]: Epoch 044 - training loss: 0.3930, validation loss: 2.4065
2024-06-02 19:08:54 [INFO]: Epoch 045 - training loss: 0.3953, validation loss: 2.4035
2024-06-02 19:09:02 [INFO]: Epoch 046 - training loss: 0.3930, validation loss: 2.3942
2024-06-02 19:09:08 [INFO]: Epoch 047 - training loss: 0.3933, validation loss: 2.3967
2024-06-02 19:09:15 [INFO]: Epoch 048 - training loss: 0.3896, validation loss: 2.4077
2024-06-02 19:09:23 [INFO]: Epoch 049 - training loss: 0.3882, validation loss: 2.3990
2024-06-02 19:09:31 [INFO]: Epoch 050 - training loss: 0.3870, validation loss: 2.4024
2024-06-02 19:09:39 [INFO]: Epoch 051 - training loss: 0.3874, validation loss: 2.3896
2024-06-02 19:09:48 [INFO]: Epoch 052 - training loss: 0.3862, validation loss: 2.3955
2024-06-02 19:09:57 [INFO]: Epoch 053 - training loss: 0.3860, validation loss: 2.3864
2024-06-02 19:10:05 [INFO]: Epoch 054 - training loss: 0.3869, validation loss: 2.3977
2024-06-02 19:10:14 [INFO]: Epoch 055 - training loss: 0.3826, validation loss: 2.3914
2024-06-02 19:10:22 [INFO]: Epoch 056 - training loss: 0.3814, validation loss: 2.3805
2024-06-02 19:10:29 [INFO]: Epoch 057 - training loss: 0.3817, validation loss: 2.3963
2024-06-02 19:10:37 [INFO]: Epoch 058 - training loss: 0.3803, validation loss: 2.3861
2024-06-02 19:10:45 [INFO]: Epoch 059 - training loss: 0.3793, validation loss: 2.3889
2024-06-02 19:10:53 [INFO]: Epoch 060 - training loss: 0.3797, validation loss: 2.3882
2024-06-02 19:11:01 [INFO]: Epoch 061 - training loss: 0.3799, validation loss: 2.3803
2024-06-02 19:11:08 [INFO]: Epoch 062 - training loss: 0.3787, validation loss: 2.3825
2024-06-02 19:11:16 [INFO]: Epoch 063 - training loss: 0.3759, validation loss: 2.3681
2024-06-02 19:11:25 [INFO]: Epoch 064 - training loss: 0.3757, validation loss: 2.3878
2024-06-02 19:11:33 [INFO]: Epoch 065 - training loss: 0.3764, validation loss: 2.3804
2024-06-02 19:11:42 [INFO]: Epoch 066 - training loss: 0.3752, validation loss: 2.3803
2024-06-02 19:11:49 [INFO]: Epoch 067 - training loss: 0.3742, validation loss: 2.3805
2024-06-02 19:11:58 [INFO]: Epoch 068 - training loss: 0.3720, validation loss: 2.3818
2024-06-02 19:12:06 [INFO]: Epoch 069 - training loss: 0.3715, validation loss: 2.3821
2024-06-02 19:12:15 [INFO]: Epoch 070 - training loss: 0.3721, validation loss: 2.3839
2024-06-02 19:12:23 [INFO]: Epoch 071 - training loss: 0.3702, validation loss: 2.3804
2024-06-02 19:12:31 [INFO]: Epoch 072 - training loss: 0.3686, validation loss: 2.3708
2024-06-02 19:12:39 [INFO]: Epoch 073 - training loss: 0.3694, validation loss: 2.3675
2024-06-02 19:12:47 [INFO]: Epoch 074 - training loss: 0.3687, validation loss: 2.3649
2024-06-02 19:12:55 [INFO]: Epoch 075 - training loss: 0.3682, validation loss: 2.3680
2024-06-02 19:13:03 [INFO]: Epoch 076 - training loss: 0.3692, validation loss: 2.3663
2024-06-02 19:13:11 [INFO]: Epoch 077 - training loss: 0.3710, validation loss: 2.3572
2024-06-02 19:13:20 [INFO]: Epoch 078 - training loss: 0.3685, validation loss: 2.3766
2024-06-02 19:13:28 [INFO]: Epoch 079 - training loss: 0.3692, validation loss: 2.3750
2024-06-02 19:13:36 [INFO]: Epoch 080 - training loss: 0.3685, validation loss: 2.3669
2024-06-02 19:13:44 [INFO]: Epoch 081 - training loss: 0.3664, validation loss: 2.3626
2024-06-02 19:13:52 [INFO]: Epoch 082 - training loss: 0.3639, validation loss: 2.3622
2024-06-02 19:14:00 [INFO]: Epoch 083 - training loss: 0.3626, validation loss: 2.3591
2024-06-02 19:14:08 [INFO]: Epoch 084 - training loss: 0.3624, validation loss: 2.3592
2024-06-02 19:14:16 [INFO]: Epoch 085 - training loss: 0.3625, validation loss: 2.3577
2024-06-02 19:14:25 [INFO]: Epoch 086 - training loss: 0.3612, validation loss: 2.3524
2024-06-02 19:14:32 [INFO]: Epoch 087 - training loss: 0.3623, validation loss: 2.3654
2024-06-02 19:14:40 [INFO]: Epoch 088 - training loss: 0.3615, validation loss: 2.3595
2024-06-02 19:14:48 [INFO]: Epoch 089 - training loss: 0.3602, validation loss: 2.3582
2024-06-02 19:14:57 [INFO]: Epoch 090 - training loss: 0.3606, validation loss: 2.3535
2024-06-02 19:15:05 [INFO]: Epoch 091 - training loss: 0.3603, validation loss: 2.3628
2024-06-02 19:15:13 [INFO]: Epoch 092 - training loss: 0.3599, validation loss: 2.3600
2024-06-02 19:15:22 [INFO]: Epoch 093 - training loss: 0.3619, validation loss: 2.3537
2024-06-02 19:15:30 [INFO]: Epoch 094 - training loss: 0.3621, validation loss: 2.3614
2024-06-02 19:15:38 [INFO]: Epoch 095 - training loss: 0.3604, validation loss: 2.3515
2024-06-02 19:15:46 [INFO]: Epoch 096 - training loss: 0.3606, validation loss: 2.3625
2024-06-02 19:15:54 [INFO]: Epoch 097 - training loss: 0.3588, validation loss: 2.3603
2024-06-02 19:16:01 [INFO]: Epoch 098 - training loss: 0.3563, validation loss: 2.3445
2024-06-02 19:16:09 [INFO]: Epoch 099 - training loss: 0.3566, validation loss: 2.3436
2024-06-02 19:16:17 [INFO]: Epoch 100 - training loss: 0.3564, validation loss: 2.3575
2024-06-02 19:16:17 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 19:16:17 [INFO]: Saved the model to results_point_rate01/Electricity/Informer_Electricity/round_1/20240602_T190243/Informer.pypots
2024-06-02 19:16:18 [INFO]: Successfully saved to results_point_rate01/Electricity/Informer_Electricity/round_1/imputation.pkl
2024-06-02 19:16:18 [INFO]: Round1 - Informer on Electricity: MAE=1.2663, MSE=3.0587, MRE=0.6774
2024-06-02 19:16:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:16:18 [INFO]: Using the given device: cuda:0
2024-06-02 19:16:18 [INFO]: Model files will be saved to results_point_rate01/Electricity/Informer_Electricity/round_2/20240602_T191618
2024-06-02 19:16:18 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Informer_Electricity/round_2/20240602_T191618/tensorboard
2024-06-02 19:16:18 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 19:16:25 [INFO]: Epoch 001 - training loss: 0.9528, validation loss: 2.9140
2024-06-02 19:16:33 [INFO]: Epoch 002 - training loss: 0.6441, validation loss: 2.7924
2024-06-02 19:16:40 [INFO]: Epoch 003 - training loss: 0.5894, validation loss: 2.7221
2024-06-02 19:16:49 [INFO]: Epoch 004 - training loss: 0.5567, validation loss: 2.6796
2024-06-02 19:16:58 [INFO]: Epoch 005 - training loss: 0.5340, validation loss: 2.6463
2024-06-02 19:17:06 [INFO]: Epoch 006 - training loss: 0.5198, validation loss: 2.6203
2024-06-02 19:17:14 [INFO]: Epoch 007 - training loss: 0.5075, validation loss: 2.6110
2024-06-02 19:17:23 [INFO]: Epoch 008 - training loss: 0.4994, validation loss: 2.5986
2024-06-02 19:17:31 [INFO]: Epoch 009 - training loss: 0.4884, validation loss: 2.6008
2024-06-02 19:17:39 [INFO]: Epoch 010 - training loss: 0.4847, validation loss: 2.5761
2024-06-02 19:17:48 [INFO]: Epoch 011 - training loss: 0.4771, validation loss: 2.5692
2024-06-02 19:17:55 [INFO]: Epoch 012 - training loss: 0.4713, validation loss: 2.5678
2024-06-02 19:18:03 [INFO]: Epoch 013 - training loss: 0.4679, validation loss: 2.5470
2024-06-02 19:18:11 [INFO]: Epoch 014 - training loss: 0.4623, validation loss: 2.5408
2024-06-02 19:18:19 [INFO]: Epoch 015 - training loss: 0.4555, validation loss: 2.5264
2024-06-02 19:18:28 [INFO]: Epoch 016 - training loss: 0.4536, validation loss: 2.5429
2024-06-02 19:18:36 [INFO]: Epoch 017 - training loss: 0.4551, validation loss: 2.5350
2024-06-02 19:18:44 [INFO]: Epoch 018 - training loss: 0.4517, validation loss: 2.5257
2024-06-02 19:18:52 [INFO]: Epoch 019 - training loss: 0.4466, validation loss: 2.5002
2024-06-02 19:19:00 [INFO]: Epoch 020 - training loss: 0.4401, validation loss: 2.4948
2024-06-02 19:19:08 [INFO]: Epoch 021 - training loss: 0.4344, validation loss: 2.4888
2024-06-02 19:19:16 [INFO]: Epoch 022 - training loss: 0.4340, validation loss: 2.4974
2024-06-02 19:19:24 [INFO]: Epoch 023 - training loss: 0.4296, validation loss: 2.4804
2024-06-02 19:19:32 [INFO]: Epoch 024 - training loss: 0.4282, validation loss: 2.4748
2024-06-02 19:19:41 [INFO]: Epoch 025 - training loss: 0.4267, validation loss: 2.4605
2024-06-02 19:19:49 [INFO]: Epoch 026 - training loss: 0.4226, validation loss: 2.4634
2024-06-02 19:19:57 [INFO]: Epoch 027 - training loss: 0.4213, validation loss: 2.4549
2024-06-02 19:20:05 [INFO]: Epoch 028 - training loss: 0.4204, validation loss: 2.4460
2024-06-02 19:20:13 [INFO]: Epoch 029 - training loss: 0.4174, validation loss: 2.4531
2024-06-02 19:20:22 [INFO]: Epoch 030 - training loss: 0.4180, validation loss: 2.4528
2024-06-02 19:20:28 [INFO]: Epoch 031 - training loss: 0.4156, validation loss: 2.4545
2024-06-02 19:20:32 [INFO]: Epoch 032 - training loss: 0.4095, validation loss: 2.4483
2024-06-02 19:20:36 [INFO]: Epoch 033 - training loss: 0.4101, validation loss: 2.4465
2024-06-02 19:20:39 [INFO]: Epoch 034 - training loss: 0.4076, validation loss: 2.4525
2024-06-02 19:20:42 [INFO]: Epoch 035 - training loss: 0.4060, validation loss: 2.4448
2024-06-02 19:20:45 [INFO]: Epoch 036 - training loss: 0.4035, validation loss: 2.4436
2024-06-02 19:20:48 [INFO]: Epoch 037 - training loss: 0.4053, validation loss: 2.4350
2024-06-02 19:20:51 [INFO]: Epoch 038 - training loss: 0.4029, validation loss: 2.4369
2024-06-02 19:20:53 [INFO]: Epoch 039 - training loss: 0.3990, validation loss: 2.4385
2024-06-02 19:20:57 [INFO]: Epoch 040 - training loss: 0.4024, validation loss: 2.4504
2024-06-02 19:21:00 [INFO]: Epoch 041 - training loss: 0.3995, validation loss: 2.4313
2024-06-02 19:21:03 [INFO]: Epoch 042 - training loss: 0.3969, validation loss: 2.4481
2024-06-02 19:21:07 [INFO]: Epoch 043 - training loss: 0.3965, validation loss: 2.4349
2024-06-02 19:21:10 [INFO]: Epoch 044 - training loss: 0.3945, validation loss: 2.4305
2024-06-02 19:21:13 [INFO]: Epoch 045 - training loss: 0.3938, validation loss: 2.4206
2024-06-02 19:21:16 [INFO]: Epoch 046 - training loss: 0.3924, validation loss: 2.4279
2024-06-02 19:21:19 [INFO]: Epoch 047 - training loss: 0.3911, validation loss: 2.4330
2024-06-02 19:21:24 [INFO]: Epoch 048 - training loss: 0.3894, validation loss: 2.4281
2024-06-02 19:21:27 [INFO]: Epoch 049 - training loss: 0.3877, validation loss: 2.4290
2024-06-02 19:21:30 [INFO]: Epoch 050 - training loss: 0.3861, validation loss: 2.4279
2024-06-02 19:21:33 [INFO]: Epoch 051 - training loss: 0.3889, validation loss: 2.4351
2024-06-02 19:21:36 [INFO]: Epoch 052 - training loss: 0.3855, validation loss: 2.4294
2024-06-02 19:21:39 [INFO]: Epoch 053 - training loss: 0.3845, validation loss: 2.4239
2024-06-02 19:21:42 [INFO]: Epoch 054 - training loss: 0.3844, validation loss: 2.4309
2024-06-02 19:21:46 [INFO]: Epoch 055 - training loss: 0.3826, validation loss: 2.4162
2024-06-02 19:21:49 [INFO]: Epoch 056 - training loss: 0.3802, validation loss: 2.4234
2024-06-02 19:21:53 [INFO]: Epoch 057 - training loss: 0.3792, validation loss: 2.4195
2024-06-02 19:21:56 [INFO]: Epoch 058 - training loss: 0.3786, validation loss: 2.4052
2024-06-02 19:21:59 [INFO]: Epoch 059 - training loss: 0.3796, validation loss: 2.4205
2024-06-02 19:22:02 [INFO]: Epoch 060 - training loss: 0.3782, validation loss: 2.4121
2024-06-02 19:22:05 [INFO]: Epoch 061 - training loss: 0.3776, validation loss: 2.4126
2024-06-02 19:22:07 [INFO]: Epoch 062 - training loss: 0.3793, validation loss: 2.4050
2024-06-02 19:22:11 [INFO]: Epoch 063 - training loss: 0.3787, validation loss: 2.4135
2024-06-02 19:22:14 [INFO]: Epoch 064 - training loss: 0.3752, validation loss: 2.4137
2024-06-02 19:22:17 [INFO]: Epoch 065 - training loss: 0.3742, validation loss: 2.4143
2024-06-02 19:22:20 [INFO]: Epoch 066 - training loss: 0.3736, validation loss: 2.4120
2024-06-02 19:22:23 [INFO]: Epoch 067 - training loss: 0.3734, validation loss: 2.4214
2024-06-02 19:22:26 [INFO]: Epoch 068 - training loss: 0.3717, validation loss: 2.4071
2024-06-02 19:22:29 [INFO]: Epoch 069 - training loss: 0.3717, validation loss: 2.4110
2024-06-02 19:22:32 [INFO]: Epoch 070 - training loss: 0.3701, validation loss: 2.4040
2024-06-02 19:22:36 [INFO]: Epoch 071 - training loss: 0.3696, validation loss: 2.4079
2024-06-02 19:22:40 [INFO]: Epoch 072 - training loss: 0.3686, validation loss: 2.4143
2024-06-02 19:22:43 [INFO]: Epoch 073 - training loss: 0.3686, validation loss: 2.4159
2024-06-02 19:22:45 [INFO]: Epoch 074 - training loss: 0.3690, validation loss: 2.4000
2024-06-02 19:22:48 [INFO]: Epoch 075 - training loss: 0.3693, validation loss: 2.4182
2024-06-02 19:22:51 [INFO]: Epoch 076 - training loss: 0.3684, validation loss: 2.4089
2024-06-02 19:22:54 [INFO]: Epoch 077 - training loss: 0.3706, validation loss: 2.4151
2024-06-02 19:22:58 [INFO]: Epoch 078 - training loss: 0.3691, validation loss: 2.4144
2024-06-02 19:23:01 [INFO]: Epoch 079 - training loss: 0.3666, validation loss: 2.4027
2024-06-02 19:23:05 [INFO]: Epoch 080 - training loss: 0.3657, validation loss: 2.4251
2024-06-02 19:23:09 [INFO]: Epoch 081 - training loss: 0.3647, validation loss: 2.4132
2024-06-02 19:23:12 [INFO]: Epoch 082 - training loss: 0.3641, validation loss: 2.4075
2024-06-02 19:23:15 [INFO]: Epoch 083 - training loss: 0.3642, validation loss: 2.4136
2024-06-02 19:23:18 [INFO]: Epoch 084 - training loss: 0.3620, validation loss: 2.4155
2024-06-02 19:23:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:23:18 [INFO]: Finished training. The best model is from epoch#74.
2024-06-02 19:23:18 [INFO]: Saved the model to results_point_rate01/Electricity/Informer_Electricity/round_2/20240602_T191618/Informer.pypots
2024-06-02 19:23:18 [INFO]: Successfully saved to results_point_rate01/Electricity/Informer_Electricity/round_2/imputation.pkl
2024-06-02 19:23:18 [INFO]: Round2 - Informer on Electricity: MAE=1.2927, MSE=3.1643, MRE=0.6916
2024-06-02 19:23:18 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:23:18 [INFO]: Using the given device: cuda:0
2024-06-02 19:23:18 [INFO]: Model files will be saved to results_point_rate01/Electricity/Informer_Electricity/round_3/20240602_T192318
2024-06-02 19:23:18 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Informer_Electricity/round_3/20240602_T192318/tensorboard
2024-06-02 19:23:19 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 19:23:21 [INFO]: Epoch 001 - training loss: 0.9343, validation loss: 2.9188
2024-06-02 19:23:24 [INFO]: Epoch 002 - training loss: 0.6386, validation loss: 2.7713
2024-06-02 19:23:27 [INFO]: Epoch 003 - training loss: 0.5848, validation loss: 2.7030
2024-06-02 19:23:30 [INFO]: Epoch 004 - training loss: 0.5537, validation loss: 2.6888
2024-06-02 19:23:33 [INFO]: Epoch 005 - training loss: 0.5366, validation loss: 2.6480
2024-06-02 19:23:37 [INFO]: Epoch 006 - training loss: 0.5240, validation loss: 2.6275
2024-06-02 19:23:40 [INFO]: Epoch 007 - training loss: 0.5139, validation loss: 2.6282
2024-06-02 19:23:43 [INFO]: Epoch 008 - training loss: 0.4998, validation loss: 2.6190
2024-06-02 19:23:47 [INFO]: Epoch 009 - training loss: 0.4904, validation loss: 2.6124
2024-06-02 19:23:49 [INFO]: Epoch 010 - training loss: 0.4846, validation loss: 2.5954
2024-06-02 19:23:53 [INFO]: Epoch 011 - training loss: 0.4796, validation loss: 2.5896
2024-06-02 19:23:57 [INFO]: Epoch 012 - training loss: 0.4735, validation loss: 2.5736
2024-06-02 19:24:00 [INFO]: Epoch 013 - training loss: 0.4665, validation loss: 2.5596
2024-06-02 19:24:04 [INFO]: Epoch 014 - training loss: 0.4650, validation loss: 2.5640
2024-06-02 19:24:06 [INFO]: Epoch 015 - training loss: 0.4620, validation loss: 2.5499
2024-06-02 19:24:10 [INFO]: Epoch 016 - training loss: 0.4555, validation loss: 2.5538
2024-06-02 19:24:12 [INFO]: Epoch 017 - training loss: 0.4510, validation loss: 2.5361
2024-06-02 19:24:16 [INFO]: Epoch 018 - training loss: 0.4466, validation loss: 2.5308
2024-06-02 19:24:19 [INFO]: Epoch 019 - training loss: 0.4423, validation loss: 2.5198
2024-06-02 19:24:22 [INFO]: Epoch 020 - training loss: 0.4408, validation loss: 2.5132
2024-06-02 19:24:24 [INFO]: Epoch 021 - training loss: 0.4381, validation loss: 2.5093
2024-06-02 19:24:27 [INFO]: Epoch 022 - training loss: 0.4353, validation loss: 2.5008
2024-06-02 19:24:30 [INFO]: Epoch 023 - training loss: 0.4324, validation loss: 2.5060
2024-06-02 19:24:34 [INFO]: Epoch 024 - training loss: 0.4297, validation loss: 2.4841
2024-06-02 19:24:37 [INFO]: Epoch 025 - training loss: 0.4254, validation loss: 2.4730
2024-06-02 19:24:39 [INFO]: Epoch 026 - training loss: 0.4236, validation loss: 2.4893
2024-06-02 19:24:43 [INFO]: Epoch 027 - training loss: 0.4214, validation loss: 2.4664
2024-06-02 19:24:46 [INFO]: Epoch 028 - training loss: 0.4187, validation loss: 2.4564
2024-06-02 19:24:49 [INFO]: Epoch 029 - training loss: 0.4171, validation loss: 2.4578
2024-06-02 19:24:52 [INFO]: Epoch 030 - training loss: 0.4158, validation loss: 2.4441
2024-06-02 19:24:55 [INFO]: Epoch 031 - training loss: 0.4150, validation loss: 2.4517
2024-06-02 19:24:58 [INFO]: Epoch 032 - training loss: 0.4135, validation loss: 2.4550
2024-06-02 19:25:02 [INFO]: Epoch 033 - training loss: 0.4095, validation loss: 2.4521
2024-06-02 19:25:05 [INFO]: Epoch 034 - training loss: 0.4066, validation loss: 2.4343
2024-06-02 19:25:09 [INFO]: Epoch 035 - training loss: 0.4053, validation loss: 2.4313
2024-06-02 19:25:12 [INFO]: Epoch 036 - training loss: 0.4027, validation loss: 2.4315
2024-06-02 19:25:14 [INFO]: Epoch 037 - training loss: 0.4041, validation loss: 2.4343
2024-06-02 19:25:17 [INFO]: Epoch 038 - training loss: 0.4026, validation loss: 2.4296
2024-06-02 19:25:21 [INFO]: Epoch 039 - training loss: 0.4006, validation loss: 2.4273
2024-06-02 19:25:24 [INFO]: Epoch 040 - training loss: 0.3997, validation loss: 2.4200
2024-06-02 19:25:27 [INFO]: Epoch 041 - training loss: 0.3975, validation loss: 2.4294
2024-06-02 19:25:31 [INFO]: Epoch 042 - training loss: 0.3961, validation loss: 2.4165
2024-06-02 19:25:34 [INFO]: Epoch 043 - training loss: 0.3955, validation loss: 2.4259
2024-06-02 19:25:37 [INFO]: Epoch 044 - training loss: 0.3941, validation loss: 2.4263
2024-06-02 19:25:42 [INFO]: Epoch 045 - training loss: 0.3935, validation loss: 2.4216
2024-06-02 19:25:45 [INFO]: Epoch 046 - training loss: 0.3910, validation loss: 2.4172
2024-06-02 19:25:48 [INFO]: Epoch 047 - training loss: 0.3907, validation loss: 2.4161
2024-06-02 19:25:51 [INFO]: Epoch 048 - training loss: 0.3905, validation loss: 2.4114
2024-06-02 19:25:55 [INFO]: Epoch 049 - training loss: 0.3895, validation loss: 2.4100
2024-06-02 19:25:58 [INFO]: Epoch 050 - training loss: 0.3875, validation loss: 2.4002
2024-06-02 19:26:01 [INFO]: Epoch 051 - training loss: 0.3882, validation loss: 2.4020
2024-06-02 19:26:04 [INFO]: Epoch 052 - training loss: 0.3862, validation loss: 2.3887
2024-06-02 19:26:07 [INFO]: Epoch 053 - training loss: 0.3850, validation loss: 2.3991
2024-06-02 19:26:11 [INFO]: Epoch 054 - training loss: 0.3822, validation loss: 2.3947
2024-06-02 19:26:14 [INFO]: Epoch 055 - training loss: 0.3818, validation loss: 2.4002
2024-06-02 19:26:17 [INFO]: Epoch 056 - training loss: 0.3808, validation loss: 2.4007
2024-06-02 19:26:20 [INFO]: Epoch 057 - training loss: 0.3816, validation loss: 2.3914
2024-06-02 19:26:23 [INFO]: Epoch 058 - training loss: 0.3804, validation loss: 2.3876
2024-06-02 19:26:26 [INFO]: Epoch 059 - training loss: 0.3793, validation loss: 2.3886
2024-06-02 19:26:29 [INFO]: Epoch 060 - training loss: 0.3773, validation loss: 2.3835
2024-06-02 19:26:32 [INFO]: Epoch 061 - training loss: 0.3765, validation loss: 2.3737
2024-06-02 19:26:35 [INFO]: Epoch 062 - training loss: 0.3748, validation loss: 2.3668
2024-06-02 19:26:38 [INFO]: Epoch 063 - training loss: 0.3742, validation loss: 2.3649
2024-06-02 19:26:41 [INFO]: Epoch 064 - training loss: 0.3758, validation loss: 2.3485
2024-06-02 19:26:45 [INFO]: Epoch 065 - training loss: 0.3751, validation loss: 2.3406
2024-06-02 19:26:49 [INFO]: Epoch 066 - training loss: 0.3730, validation loss: 2.3443
2024-06-02 19:26:53 [INFO]: Epoch 067 - training loss: 0.3730, validation loss: 2.3414
2024-06-02 19:26:56 [INFO]: Epoch 068 - training loss: 0.3743, validation loss: 2.3308
2024-06-02 19:26:59 [INFO]: Epoch 069 - training loss: 0.3740, validation loss: 2.3366
2024-06-02 19:27:02 [INFO]: Epoch 070 - training loss: 0.3711, validation loss: 2.3692
2024-06-02 19:27:05 [INFO]: Epoch 071 - training loss: 0.3703, validation loss: 2.3744
2024-06-02 19:27:09 [INFO]: Epoch 072 - training loss: 0.3701, validation loss: 2.3880
2024-06-02 19:27:13 [INFO]: Epoch 073 - training loss: 0.3706, validation loss: 2.4108
2024-06-02 19:27:17 [INFO]: Epoch 074 - training loss: 0.3686, validation loss: 2.4134
2024-06-02 19:27:20 [INFO]: Epoch 075 - training loss: 0.3668, validation loss: 2.4036
2024-06-02 19:27:23 [INFO]: Epoch 076 - training loss: 0.3671, validation loss: 2.4332
2024-06-02 19:27:26 [INFO]: Epoch 077 - training loss: 0.3675, validation loss: 2.4415
2024-06-02 19:27:29 [INFO]: Epoch 078 - training loss: 0.3661, validation loss: 2.4614
2024-06-02 19:27:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:27:29 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 19:27:29 [INFO]: Saved the model to results_point_rate01/Electricity/Informer_Electricity/round_3/20240602_T192318/Informer.pypots
2024-06-02 19:27:30 [INFO]: Successfully saved to results_point_rate01/Electricity/Informer_Electricity/round_3/imputation.pkl
2024-06-02 19:27:30 [INFO]: Round3 - Informer on Electricity: MAE=1.3501, MSE=3.7222, MRE=0.7222
2024-06-02 19:27:30 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:27:30 [INFO]: Using the given device: cuda:0
2024-06-02 19:27:30 [INFO]: Model files will be saved to results_point_rate01/Electricity/Informer_Electricity/round_4/20240602_T192730
2024-06-02 19:27:30 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/Informer_Electricity/round_4/20240602_T192730/tensorboard
2024-06-02 19:27:30 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 19:27:34 [INFO]: Epoch 001 - training loss: 0.9337, validation loss: 2.9220
2024-06-02 19:27:37 [INFO]: Epoch 002 - training loss: 0.6425, validation loss: 2.7638
2024-06-02 19:27:40 [INFO]: Epoch 003 - training loss: 0.5856, validation loss: 2.6923
2024-06-02 19:27:43 [INFO]: Epoch 004 - training loss: 0.5548, validation loss: 2.6865
2024-06-02 19:27:47 [INFO]: Epoch 005 - training loss: 0.5359, validation loss: 2.6477
2024-06-02 19:27:50 [INFO]: Epoch 006 - training loss: 0.5199, validation loss: 2.6241
2024-06-02 19:27:52 [INFO]: Epoch 007 - training loss: 0.5070, validation loss: 2.6188
2024-06-02 19:27:56 [INFO]: Epoch 008 - training loss: 0.4980, validation loss: 2.6040
2024-06-02 19:27:59 [INFO]: Epoch 009 - training loss: 0.4905, validation loss: 2.5997
2024-06-02 19:28:02 [INFO]: Epoch 010 - training loss: 0.4829, validation loss: 2.5893
2024-06-02 19:28:05 [INFO]: Epoch 011 - training loss: 0.4784, validation loss: 2.5854
2024-06-02 19:28:08 [INFO]: Epoch 012 - training loss: 0.4720, validation loss: 2.5748
2024-06-02 19:28:10 [INFO]: Epoch 013 - training loss: 0.4657, validation loss: 2.5631
2024-06-02 19:28:11 [INFO]: Epoch 014 - training loss: 0.4605, validation loss: 2.5614
2024-06-02 19:28:13 [INFO]: Epoch 015 - training loss: 0.4551, validation loss: 2.5390
2024-06-02 19:28:14 [INFO]: Epoch 016 - training loss: 0.4531, validation loss: 2.5463
2024-06-02 19:28:16 [INFO]: Epoch 017 - training loss: 0.4501, validation loss: 2.5315
2024-06-02 19:28:17 [INFO]: Epoch 018 - training loss: 0.4496, validation loss: 2.5188
2024-06-02 19:28:19 [INFO]: Epoch 019 - training loss: 0.4430, validation loss: 2.5137
2024-06-02 19:28:21 [INFO]: Epoch 020 - training loss: 0.4400, validation loss: 2.5130
2024-06-02 19:28:22 [INFO]: Epoch 021 - training loss: 0.4422, validation loss: 2.5229
2024-06-02 19:28:24 [INFO]: Epoch 022 - training loss: 0.4363, validation loss: 2.4963
2024-06-02 19:28:25 [INFO]: Epoch 023 - training loss: 0.4320, validation loss: 2.4966
2024-06-02 19:28:27 [INFO]: Epoch 024 - training loss: 0.4282, validation loss: 2.4832
2024-06-02 19:28:29 [INFO]: Epoch 025 - training loss: 0.4285, validation loss: 2.4842
2024-06-02 19:28:30 [INFO]: Epoch 026 - training loss: 0.4248, validation loss: 2.4695
2024-06-02 19:28:32 [INFO]: Epoch 027 - training loss: 0.4229, validation loss: 2.4552
2024-06-02 19:28:33 [INFO]: Epoch 028 - training loss: 0.4199, validation loss: 2.4623
2024-06-02 19:28:35 [INFO]: Epoch 029 - training loss: 0.4168, validation loss: 2.4629
2024-06-02 19:28:36 [INFO]: Epoch 030 - training loss: 0.4155, validation loss: 2.4535
2024-06-02 19:28:38 [INFO]: Epoch 031 - training loss: 0.4132, validation loss: 2.4461
2024-06-02 19:28:40 [INFO]: Epoch 032 - training loss: 0.4148, validation loss: 2.4502
2024-06-02 19:28:41 [INFO]: Epoch 033 - training loss: 0.4119, validation loss: 2.4469
2024-06-02 19:28:43 [INFO]: Epoch 034 - training loss: 0.4087, validation loss: 2.4377
2024-06-02 19:28:44 [INFO]: Epoch 035 - training loss: 0.4069, validation loss: 2.4301
2024-06-02 19:28:46 [INFO]: Epoch 036 - training loss: 0.4056, validation loss: 2.4354
2024-06-02 19:28:48 [INFO]: Epoch 037 - training loss: 0.4039, validation loss: 2.4267
2024-06-02 19:28:49 [INFO]: Epoch 038 - training loss: 0.4023, validation loss: 2.4202
2024-06-02 19:28:51 [INFO]: Epoch 039 - training loss: 0.3990, validation loss: 2.4178
2024-06-02 19:28:52 [INFO]: Epoch 040 - training loss: 0.4000, validation loss: 2.4151
2024-06-02 19:28:54 [INFO]: Epoch 041 - training loss: 0.3993, validation loss: 2.4174
2024-06-02 19:28:55 [INFO]: Epoch 042 - training loss: 0.3983, validation loss: 2.4073
2024-06-02 19:28:57 [INFO]: Epoch 043 - training loss: 0.3965, validation loss: 2.4023
2024-06-02 19:28:59 [INFO]: Epoch 044 - training loss: 0.3935, validation loss: 2.4007
2024-06-02 19:29:00 [INFO]: Epoch 045 - training loss: 0.3926, validation loss: 2.3978
2024-06-02 19:29:02 [INFO]: Epoch 046 - training loss: 0.3934, validation loss: 2.4018
2024-06-02 19:29:03 [INFO]: Epoch 047 - training loss: 0.3918, validation loss: 2.4072
2024-06-02 19:29:05 [INFO]: Epoch 048 - training loss: 0.3905, validation loss: 2.4125
2024-06-02 19:29:07 [INFO]: Epoch 049 - training loss: 0.3892, validation loss: 2.4226
2024-06-02 19:29:08 [INFO]: Epoch 050 - training loss: 0.3896, validation loss: 2.4060
2024-06-02 19:29:10 [INFO]: Epoch 051 - training loss: 0.3893, validation loss: 2.4029
2024-06-02 19:29:11 [INFO]: Epoch 052 - training loss: 0.3858, validation loss: 2.4276
2024-06-02 19:29:13 [INFO]: Epoch 053 - training loss: 0.3858, validation loss: 2.3964
2024-06-02 19:29:14 [INFO]: Epoch 054 - training loss: 0.3841, validation loss: 2.4107
2024-06-02 19:29:16 [INFO]: Epoch 055 - training loss: 0.3842, validation loss: 2.4195
2024-06-02 19:29:18 [INFO]: Epoch 056 - training loss: 0.3849, validation loss: 2.4027
2024-06-02 19:29:19 [INFO]: Epoch 057 - training loss: 0.3825, validation loss: 2.4133
2024-06-02 19:29:21 [INFO]: Epoch 058 - training loss: 0.3796, validation loss: 2.4082
2024-06-02 19:29:22 [INFO]: Epoch 059 - training loss: 0.3794, validation loss: 2.4060
2024-06-02 19:29:24 [INFO]: Epoch 060 - training loss: 0.3796, validation loss: 2.3954
2024-06-02 19:29:26 [INFO]: Epoch 061 - training loss: 0.3784, validation loss: 2.4023
2024-06-02 19:29:27 [INFO]: Epoch 062 - training loss: 0.3810, validation loss: 2.4083
2024-06-02 19:29:29 [INFO]: Epoch 063 - training loss: 0.3781, validation loss: 2.4018
2024-06-02 19:29:30 [INFO]: Epoch 064 - training loss: 0.3755, validation loss: 2.4042
2024-06-02 19:29:32 [INFO]: Epoch 065 - training loss: 0.3753, validation loss: 2.3916
2024-06-02 19:29:34 [INFO]: Epoch 066 - training loss: 0.3756, validation loss: 2.3960
2024-06-02 19:29:35 [INFO]: Epoch 067 - training loss: 0.3746, validation loss: 2.4055
2024-06-02 19:29:37 [INFO]: Epoch 068 - training loss: 0.3739, validation loss: 2.4028
2024-06-02 19:29:38 [INFO]: Epoch 069 - training loss: 0.3743, validation loss: 2.4100
2024-06-02 19:29:40 [INFO]: Epoch 070 - training loss: 0.3725, validation loss: 2.3956
2024-06-02 19:29:42 [INFO]: Epoch 071 - training loss: 0.3702, validation loss: 2.3994
2024-06-02 19:29:43 [INFO]: Epoch 072 - training loss: 0.3702, validation loss: 2.3939
2024-06-02 19:29:45 [INFO]: Epoch 073 - training loss: 0.3707, validation loss: 2.3887
2024-06-02 19:29:47 [INFO]: Epoch 074 - training loss: 0.3687, validation loss: 2.3849
2024-06-02 19:29:48 [INFO]: Epoch 075 - training loss: 0.3675, validation loss: 2.3892
2024-06-02 19:29:50 [INFO]: Epoch 076 - training loss: 0.3670, validation loss: 2.3823
2024-06-02 19:29:52 [INFO]: Epoch 077 - training loss: 0.3662, validation loss: 2.3947
2024-06-02 19:29:53 [INFO]: Epoch 078 - training loss: 0.3683, validation loss: 2.3784
2024-06-02 19:29:55 [INFO]: Epoch 079 - training loss: 0.3676, validation loss: 2.3886
2024-06-02 19:29:57 [INFO]: Epoch 080 - training loss: 0.3661, validation loss: 2.3879
2024-06-02 19:29:58 [INFO]: Epoch 081 - training loss: 0.3664, validation loss: 2.3818
2024-06-02 19:30:00 [INFO]: Epoch 082 - training loss: 0.3633, validation loss: 2.3907
2024-06-02 19:30:01 [INFO]: Epoch 083 - training loss: 0.3634, validation loss: 2.3768
2024-06-02 19:30:03 [INFO]: Epoch 084 - training loss: 0.3635, validation loss: 2.3861
2024-06-02 19:30:04 [INFO]: Epoch 085 - training loss: 0.3650, validation loss: 2.3801
2024-06-02 19:30:06 [INFO]: Epoch 086 - training loss: 0.3633, validation loss: 2.3784
2024-06-02 19:30:08 [INFO]: Epoch 087 - training loss: 0.3639, validation loss: 2.3819
2024-06-02 19:30:09 [INFO]: Epoch 088 - training loss: 0.3637, validation loss: 2.3804
2024-06-02 19:30:11 [INFO]: Epoch 089 - training loss: 0.3633, validation loss: 2.3795
2024-06-02 19:30:13 [INFO]: Epoch 090 - training loss: 0.3630, validation loss: 2.3866
2024-06-02 19:30:14 [INFO]: Epoch 091 - training loss: 0.3610, validation loss: 2.3790
2024-06-02 19:30:16 [INFO]: Epoch 092 - training loss: 0.3597, validation loss: 2.3800
2024-06-02 19:30:17 [INFO]: Epoch 093 - training loss: 0.3589, validation loss: 2.3665
2024-06-02 19:30:19 [INFO]: Epoch 094 - training loss: 0.3581, validation loss: 2.3732
2024-06-02 19:30:21 [INFO]: Epoch 095 - training loss: 0.3577, validation loss: 2.3721
2024-06-02 19:30:22 [INFO]: Epoch 096 - training loss: 0.3581, validation loss: 2.3738
2024-06-02 19:30:24 [INFO]: Epoch 097 - training loss: 0.3581, validation loss: 2.3695
2024-06-02 19:30:25 [INFO]: Epoch 098 - training loss: 0.3590, validation loss: 2.3956
2024-06-02 19:30:27 [INFO]: Epoch 099 - training loss: 0.3588, validation loss: 2.3802
2024-06-02 19:30:29 [INFO]: Epoch 100 - training loss: 0.3588, validation loss: 2.3665
2024-06-02 19:30:29 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 19:30:29 [INFO]: Saved the model to results_point_rate01/Electricity/Informer_Electricity/round_4/20240602_T192730/Informer.pypots
2024-06-02 19:30:30 [INFO]: Successfully saved to results_point_rate01/Electricity/Informer_Electricity/round_4/imputation.pkl
2024-06-02 19:30:30 [INFO]: Round4 - Informer on Electricity: MAE=1.2715, MSE=3.0864, MRE=0.6802
2024-06-02 19:30:30 [INFO]: Done! Final results:
Averaged Informer (15,311,986 params) on Electricity: MAE=1.2907 ± 0.031025146034416303, MSE=3.2237 ± 0.2517257734148707, MRE=0.6905 ± 0.016597008281791552, average inference time=0.64
