2024-06-02 18:18:28 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 18:18:28 [INFO]: Using the given device: cuda:0
2024-06-02 18:18:29 [INFO]: Model files will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_0/20240602_T181829
2024-06-02 18:18:29 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_0/20240602_T181829/tensorboard
2024-06-02 18:18:29 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 18:18:33 [INFO]: Epoch 001 - training loss: 1.4216, validation loss: 3.7102
2024-06-02 18:18:37 [INFO]: Epoch 002 - training loss: 1.1866, validation loss: 3.8388
2024-06-02 18:18:41 [INFO]: Epoch 003 - training loss: 1.0962, validation loss: 3.8325
2024-06-02 18:18:45 [INFO]: Epoch 004 - training loss: 1.0675, validation loss: 3.6636
2024-06-02 18:18:49 [INFO]: Epoch 005 - training loss: 1.0526, validation loss: 3.6781
2024-06-02 18:18:53 [INFO]: Epoch 006 - training loss: 1.0424, validation loss: 3.6496
2024-06-02 18:18:57 [INFO]: Epoch 007 - training loss: 1.0352, validation loss: 3.7959
2024-06-02 18:19:01 [INFO]: Epoch 008 - training loss: 1.0298, validation loss: 3.6072
2024-06-02 18:19:05 [INFO]: Epoch 009 - training loss: 1.0263, validation loss: 3.5572
2024-06-02 18:19:09 [INFO]: Epoch 010 - training loss: 1.0228, validation loss: 3.5322
2024-06-02 18:19:13 [INFO]: Epoch 011 - training loss: 1.0197, validation loss: 3.5850
2024-06-02 18:19:17 [INFO]: Epoch 012 - training loss: 1.0161, validation loss: 3.5786
2024-06-02 18:19:21 [INFO]: Epoch 013 - training loss: 1.0135, validation loss: 3.6158
2024-06-02 18:19:24 [INFO]: Epoch 014 - training loss: 1.0111, validation loss: 3.3755
2024-06-02 18:19:28 [INFO]: Epoch 015 - training loss: 1.0098, validation loss: 3.5380
2024-06-02 18:19:32 [INFO]: Epoch 016 - training loss: 1.0080, validation loss: 3.4860
2024-06-02 18:19:36 [INFO]: Epoch 017 - training loss: 1.0063, validation loss: 3.4323
2024-06-02 18:19:40 [INFO]: Epoch 018 - training loss: 1.0052, validation loss: 3.3025
2024-06-02 18:19:44 [INFO]: Epoch 019 - training loss: 1.0047, validation loss: 3.3571
2024-06-02 18:19:48 [INFO]: Epoch 020 - training loss: 1.0002, validation loss: 3.3046
2024-06-02 18:19:52 [INFO]: Epoch 021 - training loss: 0.9989, validation loss: 3.3496
2024-06-02 18:19:56 [INFO]: Epoch 022 - training loss: 0.9964, validation loss: 3.2016
2024-06-02 18:20:00 [INFO]: Epoch 023 - training loss: 0.9951, validation loss: 3.1485
2024-06-02 18:20:04 [INFO]: Epoch 024 - training loss: 0.9964, validation loss: 3.1275
2024-06-02 18:20:08 [INFO]: Epoch 025 - training loss: 0.9924, validation loss: 3.2688
2024-06-02 18:20:12 [INFO]: Epoch 026 - training loss: 0.9915, validation loss: 3.0768
2024-06-02 18:20:16 [INFO]: Epoch 027 - training loss: 0.9906, validation loss: 3.1937
2024-06-02 18:20:19 [INFO]: Epoch 028 - training loss: 0.9896, validation loss: 3.0751
2024-06-02 18:20:23 [INFO]: Epoch 029 - training loss: 0.9903, validation loss: 3.0740
2024-06-02 18:20:27 [INFO]: Epoch 030 - training loss: 0.9897, validation loss: 3.0444
2024-06-02 18:20:31 [INFO]: Epoch 031 - training loss: 0.9868, validation loss: 3.0339
2024-06-02 18:20:34 [INFO]: Epoch 032 - training loss: 0.9855, validation loss: 3.1706
2024-06-02 18:20:38 [INFO]: Epoch 033 - training loss: 0.9849, validation loss: 3.0843
2024-06-02 18:20:42 [INFO]: Epoch 034 - training loss: 0.9832, validation loss: 3.0474
2024-06-02 18:20:46 [INFO]: Epoch 035 - training loss: 0.9842, validation loss: 3.0403
2024-06-02 18:20:50 [INFO]: Epoch 036 - training loss: 0.9822, validation loss: 3.0294
2024-06-02 18:20:54 [INFO]: Epoch 037 - training loss: 0.9822, validation loss: 2.9735
2024-06-02 18:20:58 [INFO]: Epoch 038 - training loss: 0.9815, validation loss: 3.0138
2024-06-02 18:21:02 [INFO]: Epoch 039 - training loss: 0.9799, validation loss: 3.0431
2024-06-02 18:21:06 [INFO]: Epoch 040 - training loss: 0.9798, validation loss: 2.9771
2024-06-02 18:21:09 [INFO]: Epoch 041 - training loss: 0.9798, validation loss: 3.0092
2024-06-02 18:21:14 [INFO]: Epoch 042 - training loss: 0.9781, validation loss: 3.0242
2024-06-02 18:21:17 [INFO]: Epoch 043 - training loss: 0.9771, validation loss: 2.9535
2024-06-02 18:21:21 [INFO]: Epoch 044 - training loss: 0.9765, validation loss: 2.9925
2024-06-02 18:21:25 [INFO]: Epoch 045 - training loss: 0.9763, validation loss: 2.9636
2024-06-02 18:21:28 [INFO]: Epoch 046 - training loss: 0.9745, validation loss: 2.9959
2024-06-02 18:21:33 [INFO]: Epoch 047 - training loss: 0.9751, validation loss: 2.8844
2024-06-02 18:21:37 [INFO]: Epoch 048 - training loss: 0.9738, validation loss: 2.8826
2024-06-02 18:21:41 [INFO]: Epoch 049 - training loss: 0.9734, validation loss: 2.8530
2024-06-02 18:21:45 [INFO]: Epoch 050 - training loss: 0.9728, validation loss: 2.8497
2024-06-02 18:21:49 [INFO]: Epoch 051 - training loss: 0.9724, validation loss: 2.8449
2024-06-02 18:21:53 [INFO]: Epoch 052 - training loss: 0.9720, validation loss: 2.7820
2024-06-02 18:21:57 [INFO]: Epoch 053 - training loss: 0.9718, validation loss: 2.7897
2024-06-02 18:22:01 [INFO]: Epoch 054 - training loss: 0.9713, validation loss: 2.6966
2024-06-02 18:22:05 [INFO]: Epoch 055 - training loss: 0.9690, validation loss: 2.7246
2024-06-02 18:22:09 [INFO]: Epoch 056 - training loss: 0.9681, validation loss: 2.7316
2024-06-02 18:22:13 [INFO]: Epoch 057 - training loss: 0.9682, validation loss: 2.7681
2024-06-02 18:22:17 [INFO]: Epoch 058 - training loss: 0.9678, validation loss: 2.6667
2024-06-02 18:22:21 [INFO]: Epoch 059 - training loss: 0.9665, validation loss: 2.6209
2024-06-02 18:22:25 [INFO]: Epoch 060 - training loss: 0.9666, validation loss: 2.6368
2024-06-02 18:22:28 [INFO]: Epoch 061 - training loss: 0.9658, validation loss: 2.6906
2024-06-02 18:22:32 [INFO]: Epoch 062 - training loss: 0.9668, validation loss: 2.5685
2024-06-02 18:22:36 [INFO]: Epoch 063 - training loss: 0.9662, validation loss: 2.4795
2024-06-02 18:22:40 [INFO]: Epoch 064 - training loss: 0.9648, validation loss: 2.5170
2024-06-02 18:22:44 [INFO]: Epoch 065 - training loss: 0.9633, validation loss: 2.4910
2024-06-02 18:22:47 [INFO]: Epoch 066 - training loss: 0.9628, validation loss: 2.5133
2024-06-02 18:22:51 [INFO]: Epoch 067 - training loss: 0.9631, validation loss: 2.4231
2024-06-02 18:22:55 [INFO]: Epoch 068 - training loss: 0.9628, validation loss: 2.4167
2024-06-02 18:22:59 [INFO]: Epoch 069 - training loss: 0.9622, validation loss: 2.4421
2024-06-02 18:23:03 [INFO]: Epoch 070 - training loss: 0.9621, validation loss: 2.4015
2024-06-02 18:23:07 [INFO]: Epoch 071 - training loss: 0.9610, validation loss: 2.3509
2024-06-02 18:23:11 [INFO]: Epoch 072 - training loss: 0.9597, validation loss: 2.3418
2024-06-02 18:23:15 [INFO]: Epoch 073 - training loss: 0.9605, validation loss: 2.3151
2024-06-02 18:23:19 [INFO]: Epoch 074 - training loss: 0.9604, validation loss: 2.3327
2024-06-02 18:23:23 [INFO]: Epoch 075 - training loss: 0.9592, validation loss: 2.3286
2024-06-02 18:23:27 [INFO]: Epoch 076 - training loss: 0.9604, validation loss: 2.2688
2024-06-02 18:23:30 [INFO]: Epoch 077 - training loss: 0.9597, validation loss: 2.2468
2024-06-02 18:23:35 [INFO]: Epoch 078 - training loss: 0.9589, validation loss: 2.2870
2024-06-02 18:23:38 [INFO]: Epoch 079 - training loss: 0.9583, validation loss: 2.2455
2024-06-02 18:23:42 [INFO]: Epoch 080 - training loss: 0.9578, validation loss: 2.2305
2024-06-02 18:23:46 [INFO]: Epoch 081 - training loss: 0.9577, validation loss: 2.2357
2024-06-02 18:23:50 [INFO]: Epoch 082 - training loss: 0.9566, validation loss: 2.1743
2024-06-02 18:23:55 [INFO]: Epoch 083 - training loss: 0.9566, validation loss: 2.1567
2024-06-02 18:23:58 [INFO]: Epoch 084 - training loss: 0.9562, validation loss: 2.1730
2024-06-02 18:24:02 [INFO]: Epoch 085 - training loss: 0.9580, validation loss: 2.1553
2024-06-02 18:24:07 [INFO]: Epoch 086 - training loss: 0.9572, validation loss: 2.1282
2024-06-02 18:24:10 [INFO]: Epoch 087 - training loss: 0.9561, validation loss: 2.1280
2024-06-02 18:24:14 [INFO]: Epoch 088 - training loss: 0.9559, validation loss: 2.0947
2024-06-02 18:24:18 [INFO]: Epoch 089 - training loss: 0.9562, validation loss: 2.1169
2024-06-02 18:24:22 [INFO]: Epoch 090 - training loss: 0.9567, validation loss: 2.0923
2024-06-02 18:24:26 [INFO]: Epoch 091 - training loss: 0.9554, validation loss: 2.1149
2024-06-02 18:24:30 [INFO]: Epoch 092 - training loss: 0.9551, validation loss: 2.0811
2024-06-02 18:24:34 [INFO]: Epoch 093 - training loss: 0.9538, validation loss: 2.0783
2024-06-02 18:24:38 [INFO]: Epoch 094 - training loss: 0.9541, validation loss: 2.0747
2024-06-02 18:24:42 [INFO]: Epoch 095 - training loss: 0.9547, validation loss: 2.0364
2024-06-02 18:24:46 [INFO]: Epoch 096 - training loss: 0.9551, validation loss: 2.0492
2024-06-02 18:24:50 [INFO]: Epoch 097 - training loss: 0.9550, validation loss: 2.0250
2024-06-02 18:24:54 [INFO]: Epoch 098 - training loss: 0.9544, validation loss: 2.0442
2024-06-02 18:24:58 [INFO]: Epoch 099 - training loss: 0.9547, validation loss: 2.0257
2024-06-02 18:25:02 [INFO]: Epoch 100 - training loss: 0.9544, validation loss: 2.0037
2024-06-02 18:25:02 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 18:25:02 [INFO]: Saved the model to results_point_rate01/Electricity/FiLM_Electricity/round_0/20240602_T181829/FiLM.pypots
2024-06-02 18:25:03 [INFO]: Successfully saved to results_point_rate01/Electricity/FiLM_Electricity/round_0/imputation.pkl
2024-06-02 18:25:03 [INFO]: Round0 - FiLM on Electricity: MAE=0.8745, MSE=1.4140, MRE=0.4678
2024-06-02 18:25:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 18:25:03 [INFO]: Using the given device: cuda:0
2024-06-02 18:25:03 [INFO]: Model files will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_1/20240602_T182503
2024-06-02 18:25:03 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_1/20240602_T182503/tensorboard
2024-06-02 18:25:03 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 18:25:07 [INFO]: Epoch 001 - training loss: 1.3729, validation loss: 3.5739
2024-06-02 18:25:11 [INFO]: Epoch 002 - training loss: 1.1507, validation loss: 3.3673
2024-06-02 18:25:15 [INFO]: Epoch 003 - training loss: 1.0794, validation loss: 3.3540
2024-06-02 18:25:18 [INFO]: Epoch 004 - training loss: 1.0509, validation loss: 3.2090
2024-06-02 18:25:22 [INFO]: Epoch 005 - training loss: 1.0403, validation loss: 3.1433
2024-06-02 18:25:26 [INFO]: Epoch 006 - training loss: 1.0310, validation loss: 3.0909
2024-06-02 18:25:30 [INFO]: Epoch 007 - training loss: 1.0238, validation loss: 3.0152
2024-06-02 18:25:34 [INFO]: Epoch 008 - training loss: 1.0178, validation loss: 2.9848
2024-06-02 18:25:38 [INFO]: Epoch 009 - training loss: 1.0113, validation loss: 2.9681
2024-06-02 18:25:41 [INFO]: Epoch 010 - training loss: 1.0073, validation loss: 2.9444
2024-06-02 18:25:45 [INFO]: Epoch 011 - training loss: 1.0021, validation loss: 2.8925
2024-06-02 18:25:49 [INFO]: Epoch 012 - training loss: 0.9992, validation loss: 2.8872
2024-06-02 18:25:53 [INFO]: Epoch 013 - training loss: 0.9959, validation loss: 2.7936
2024-06-02 18:25:57 [INFO]: Epoch 014 - training loss: 0.9935, validation loss: 2.7991
2024-06-02 18:26:01 [INFO]: Epoch 015 - training loss: 0.9904, validation loss: 2.7609
2024-06-02 18:26:05 [INFO]: Epoch 016 - training loss: 0.9884, validation loss: 2.7566
2024-06-02 18:26:09 [INFO]: Epoch 017 - training loss: 0.9872, validation loss: 2.7106
2024-06-02 18:26:13 [INFO]: Epoch 018 - training loss: 0.9846, validation loss: 2.7347
2024-06-02 18:26:17 [INFO]: Epoch 019 - training loss: 0.9831, validation loss: 2.6995
2024-06-02 18:26:20 [INFO]: Epoch 020 - training loss: 0.9818, validation loss: 2.6220
2024-06-02 18:26:24 [INFO]: Epoch 021 - training loss: 0.9808, validation loss: 2.6445
2024-06-02 18:26:28 [INFO]: Epoch 022 - training loss: 0.9785, validation loss: 2.6049
2024-06-02 18:26:32 [INFO]: Epoch 023 - training loss: 0.9766, validation loss: 2.5766
2024-06-02 18:26:36 [INFO]: Epoch 024 - training loss: 0.9761, validation loss: 2.5652
2024-06-02 18:26:40 [INFO]: Epoch 025 - training loss: 0.9759, validation loss: 2.5803
2024-06-02 18:26:44 [INFO]: Epoch 026 - training loss: 0.9743, validation loss: 2.5135
2024-06-02 18:26:48 [INFO]: Epoch 027 - training loss: 0.9742, validation loss: 2.5502
2024-06-02 18:26:51 [INFO]: Epoch 028 - training loss: 0.9726, validation loss: 2.5770
2024-06-02 18:26:55 [INFO]: Epoch 029 - training loss: 0.9717, validation loss: 2.5004
2024-06-02 18:26:59 [INFO]: Epoch 030 - training loss: 0.9709, validation loss: 2.5055
2024-06-02 18:27:03 [INFO]: Epoch 031 - training loss: 0.9703, validation loss: 2.4890
2024-06-02 18:27:07 [INFO]: Epoch 032 - training loss: 0.9696, validation loss: 2.4474
2024-06-02 18:27:11 [INFO]: Epoch 033 - training loss: 0.9681, validation loss: 2.4732
2024-06-02 18:27:15 [INFO]: Epoch 034 - training loss: 0.9674, validation loss: 2.4390
2024-06-02 18:27:19 [INFO]: Epoch 035 - training loss: 0.9666, validation loss: 2.4611
2024-06-02 18:27:23 [INFO]: Epoch 036 - training loss: 0.9673, validation loss: 2.4391
2024-06-02 18:27:26 [INFO]: Epoch 037 - training loss: 0.9670, validation loss: 2.4248
2024-06-02 18:27:30 [INFO]: Epoch 038 - training loss: 0.9675, validation loss: 2.4214
2024-06-02 18:27:34 [INFO]: Epoch 039 - training loss: 0.9661, validation loss: 2.3741
2024-06-02 18:27:38 [INFO]: Epoch 040 - training loss: 0.9647, validation loss: 2.3786
2024-06-02 18:27:42 [INFO]: Epoch 041 - training loss: 0.9636, validation loss: 2.3439
2024-06-02 18:27:46 [INFO]: Epoch 042 - training loss: 0.9628, validation loss: 2.3567
2024-06-02 18:27:50 [INFO]: Epoch 043 - training loss: 0.9631, validation loss: 2.3951
2024-06-02 18:27:54 [INFO]: Epoch 044 - training loss: 0.9623, validation loss: 2.3105
2024-06-02 18:27:58 [INFO]: Epoch 045 - training loss: 0.9617, validation loss: 2.3006
2024-06-02 18:28:02 [INFO]: Epoch 046 - training loss: 0.9612, validation loss: 2.2912
2024-06-02 18:28:06 [INFO]: Epoch 047 - training loss: 0.9604, validation loss: 2.2713
2024-06-02 18:28:10 [INFO]: Epoch 048 - training loss: 0.9605, validation loss: 2.2806
2024-06-02 18:28:14 [INFO]: Epoch 049 - training loss: 0.9599, validation loss: 2.2602
2024-06-02 18:28:18 [INFO]: Epoch 050 - training loss: 0.9600, validation loss: 2.3148
2024-06-02 18:28:22 [INFO]: Epoch 051 - training loss: 0.9604, validation loss: 2.2796
2024-06-02 18:28:25 [INFO]: Epoch 052 - training loss: 0.9588, validation loss: 2.2545
2024-06-02 18:28:29 [INFO]: Epoch 053 - training loss: 0.9590, validation loss: 2.2233
2024-06-02 18:28:33 [INFO]: Epoch 054 - training loss: 0.9586, validation loss: 2.2358
2024-06-02 18:28:37 [INFO]: Epoch 055 - training loss: 0.9582, validation loss: 2.2134
2024-06-02 18:28:40 [INFO]: Epoch 056 - training loss: 0.9581, validation loss: 2.1838
2024-06-02 18:28:44 [INFO]: Epoch 057 - training loss: 0.9594, validation loss: 2.1666
2024-06-02 18:28:48 [INFO]: Epoch 058 - training loss: 0.9580, validation loss: 2.1824
2024-06-02 18:28:52 [INFO]: Epoch 059 - training loss: 0.9578, validation loss: 2.1612
2024-06-02 18:28:56 [INFO]: Epoch 060 - training loss: 0.9575, validation loss: 2.1732
2024-06-02 18:29:00 [INFO]: Epoch 061 - training loss: 0.9580, validation loss: 2.1638
2024-06-02 18:29:04 [INFO]: Epoch 062 - training loss: 0.9577, validation loss: 2.1330
2024-06-02 18:29:08 [INFO]: Epoch 063 - training loss: 0.9564, validation loss: 2.1182
2024-06-02 18:29:12 [INFO]: Epoch 064 - training loss: 0.9574, validation loss: 2.0827
2024-06-02 18:29:16 [INFO]: Epoch 065 - training loss: 0.9569, validation loss: 2.1193
2024-06-02 18:29:20 [INFO]: Epoch 066 - training loss: 0.9561, validation loss: 2.0855
2024-06-02 18:29:24 [INFO]: Epoch 067 - training loss: 0.9558, validation loss: 2.0928
2024-06-02 18:29:28 [INFO]: Epoch 068 - training loss: 0.9570, validation loss: 2.0889
2024-06-02 18:29:32 [INFO]: Epoch 069 - training loss: 0.9558, validation loss: 2.0964
2024-06-02 18:29:35 [INFO]: Epoch 070 - training loss: 0.9554, validation loss: 2.0897
2024-06-02 18:29:39 [INFO]: Epoch 071 - training loss: 0.9551, validation loss: 2.0613
2024-06-02 18:29:43 [INFO]: Epoch 072 - training loss: 0.9556, validation loss: 2.0906
2024-06-02 18:29:47 [INFO]: Epoch 073 - training loss: 0.9565, validation loss: 2.0790
2024-06-02 18:29:50 [INFO]: Epoch 074 - training loss: 0.9553, validation loss: 2.0787
2024-06-02 18:29:54 [INFO]: Epoch 075 - training loss: 0.9548, validation loss: 2.0265
2024-06-02 18:29:58 [INFO]: Epoch 076 - training loss: 0.9552, validation loss: 2.0187
2024-06-02 18:30:02 [INFO]: Epoch 077 - training loss: 0.9547, validation loss: 2.0214
2024-06-02 18:30:06 [INFO]: Epoch 078 - training loss: 0.9545, validation loss: 2.0254
2024-06-02 18:30:10 [INFO]: Epoch 079 - training loss: 0.9545, validation loss: 1.9829
2024-06-02 18:30:14 [INFO]: Epoch 080 - training loss: 0.9532, validation loss: 1.9936
2024-06-02 18:30:18 [INFO]: Epoch 081 - training loss: 0.9542, validation loss: 1.9924
2024-06-02 18:30:22 [INFO]: Epoch 082 - training loss: 0.9531, validation loss: 1.9911
2024-06-02 18:30:26 [INFO]: Epoch 083 - training loss: 0.9538, validation loss: 1.9935
2024-06-02 18:30:30 [INFO]: Epoch 084 - training loss: 0.9540, validation loss: 1.9589
2024-06-02 18:30:33 [INFO]: Epoch 085 - training loss: 0.9533, validation loss: 1.9654
2024-06-02 18:30:38 [INFO]: Epoch 086 - training loss: 0.9532, validation loss: 1.9375
2024-06-02 18:30:41 [INFO]: Epoch 087 - training loss: 0.9530, validation loss: 1.9477
2024-06-02 18:30:45 [INFO]: Epoch 088 - training loss: 0.9524, validation loss: 1.9425
2024-06-02 18:30:49 [INFO]: Epoch 089 - training loss: 0.9526, validation loss: 1.9437
2024-06-02 18:30:53 [INFO]: Epoch 090 - training loss: 0.9539, validation loss: 1.9172
2024-06-02 18:30:56 [INFO]: Epoch 091 - training loss: 0.9516, validation loss: 1.9019
2024-06-02 18:31:01 [INFO]: Epoch 092 - training loss: 0.9525, validation loss: 1.9335
2024-06-02 18:31:04 [INFO]: Epoch 093 - training loss: 0.9527, validation loss: 1.9313
2024-06-02 18:31:08 [INFO]: Epoch 094 - training loss: 0.9533, validation loss: 1.8989
2024-06-02 18:31:12 [INFO]: Epoch 095 - training loss: 0.9528, validation loss: 1.9100
2024-06-02 18:31:16 [INFO]: Epoch 096 - training loss: 0.9522, validation loss: 1.8990
2024-06-02 18:31:20 [INFO]: Epoch 097 - training loss: 0.9520, validation loss: 1.8976
2024-06-02 18:31:24 [INFO]: Epoch 098 - training loss: 0.9526, validation loss: 1.9047
2024-06-02 18:31:27 [INFO]: Epoch 099 - training loss: 0.9524, validation loss: 1.8702
2024-06-02 18:31:31 [INFO]: Epoch 100 - training loss: 0.9518, validation loss: 1.8961
2024-06-02 18:31:31 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 18:31:31 [INFO]: Saved the model to results_point_rate01/Electricity/FiLM_Electricity/round_1/20240602_T182503/FiLM.pypots
2024-06-02 18:31:32 [INFO]: Successfully saved to results_point_rate01/Electricity/FiLM_Electricity/round_1/imputation.pkl
2024-06-02 18:31:32 [INFO]: Round1 - FiLM on Electricity: MAE=0.8643, MSE=1.3543, MRE=0.4624
2024-06-02 18:31:32 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 18:31:32 [INFO]: Using the given device: cuda:0
2024-06-02 18:31:32 [INFO]: Model files will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_2/20240602_T183132
2024-06-02 18:31:32 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_2/20240602_T183132/tensorboard
2024-06-02 18:31:32 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 18:31:36 [INFO]: Epoch 001 - training loss: 1.4583, validation loss: 3.9623
2024-06-02 18:31:40 [INFO]: Epoch 002 - training loss: 1.2026, validation loss: 3.6643
2024-06-02 18:31:44 [INFO]: Epoch 003 - training loss: 1.0972, validation loss: 3.6215
2024-06-02 18:31:48 [INFO]: Epoch 004 - training loss: 1.0662, validation loss: 3.6157
2024-06-02 18:31:51 [INFO]: Epoch 005 - training loss: 1.0528, validation loss: 3.6021
2024-06-02 18:31:55 [INFO]: Epoch 006 - training loss: 1.0428, validation loss: 3.4995
2024-06-02 18:31:59 [INFO]: Epoch 007 - training loss: 1.0357, validation loss: 3.5748
2024-06-02 18:32:03 [INFO]: Epoch 008 - training loss: 1.0302, validation loss: 3.4390
2024-06-02 18:32:07 [INFO]: Epoch 009 - training loss: 1.0233, validation loss: 3.4335
2024-06-02 18:32:11 [INFO]: Epoch 010 - training loss: 1.0184, validation loss: 3.3650
2024-06-02 18:32:15 [INFO]: Epoch 011 - training loss: 1.0128, validation loss: 3.2586
2024-06-02 18:32:19 [INFO]: Epoch 012 - training loss: 1.0083, validation loss: 3.2214
2024-06-02 18:32:23 [INFO]: Epoch 013 - training loss: 1.0028, validation loss: 3.2193
2024-06-02 18:32:27 [INFO]: Epoch 014 - training loss: 0.9986, validation loss: 3.2040
2024-06-02 18:32:31 [INFO]: Epoch 015 - training loss: 0.9968, validation loss: 3.1232
2024-06-02 18:32:34 [INFO]: Epoch 016 - training loss: 0.9947, validation loss: 3.1328
2024-06-02 18:32:38 [INFO]: Epoch 017 - training loss: 0.9906, validation loss: 2.9128
2024-06-02 18:32:42 [INFO]: Epoch 018 - training loss: 0.9869, validation loss: 2.8844
2024-06-02 18:32:46 [INFO]: Epoch 019 - training loss: 0.9848, validation loss: 2.8596
2024-06-02 18:32:50 [INFO]: Epoch 020 - training loss: 0.9832, validation loss: 2.8272
2024-06-02 18:32:53 [INFO]: Epoch 021 - training loss: 0.9818, validation loss: 2.8576
2024-06-02 18:32:57 [INFO]: Epoch 022 - training loss: 0.9799, validation loss: 2.8021
2024-06-02 18:33:01 [INFO]: Epoch 023 - training loss: 0.9786, validation loss: 2.8204
2024-06-02 18:33:05 [INFO]: Epoch 024 - training loss: 0.9770, validation loss: 2.7126
2024-06-02 18:33:09 [INFO]: Epoch 025 - training loss: 0.9756, validation loss: 2.7434
2024-06-02 18:33:13 [INFO]: Epoch 026 - training loss: 0.9748, validation loss: 2.6999
2024-06-02 18:33:17 [INFO]: Epoch 027 - training loss: 0.9754, validation loss: 2.7693
2024-06-02 18:33:20 [INFO]: Epoch 028 - training loss: 0.9741, validation loss: 2.6783
2024-06-02 18:33:24 [INFO]: Epoch 029 - training loss: 0.9711, validation loss: 2.6821
2024-06-02 18:33:28 [INFO]: Epoch 030 - training loss: 0.9704, validation loss: 2.6555
2024-06-02 18:33:32 [INFO]: Epoch 031 - training loss: 0.9703, validation loss: 2.5890
2024-06-02 18:33:36 [INFO]: Epoch 032 - training loss: 0.9690, validation loss: 2.6131
2024-06-02 18:33:39 [INFO]: Epoch 033 - training loss: 0.9681, validation loss: 2.5577
2024-06-02 18:33:44 [INFO]: Epoch 034 - training loss: 0.9671, validation loss: 2.5906
2024-06-02 18:33:47 [INFO]: Epoch 035 - training loss: 0.9664, validation loss: 2.5348
2024-06-02 18:33:51 [INFO]: Epoch 036 - training loss: 0.9666, validation loss: 2.5316
2024-06-02 18:33:55 [INFO]: Epoch 037 - training loss: 0.9654, validation loss: 2.5090
2024-06-02 18:33:59 [INFO]: Epoch 038 - training loss: 0.9652, validation loss: 2.5354
2024-06-02 18:34:03 [INFO]: Epoch 039 - training loss: 0.9652, validation loss: 2.3949
2024-06-02 18:34:07 [INFO]: Epoch 040 - training loss: 0.9664, validation loss: 2.4105
2024-06-02 18:34:11 [INFO]: Epoch 041 - training loss: 0.9638, validation loss: 2.4093
2024-06-02 18:34:14 [INFO]: Epoch 042 - training loss: 0.9625, validation loss: 2.4200
2024-06-02 18:34:18 [INFO]: Epoch 043 - training loss: 0.9630, validation loss: 2.3730
2024-06-02 18:34:22 [INFO]: Epoch 044 - training loss: 0.9628, validation loss: 2.3876
2024-06-02 18:34:26 [INFO]: Epoch 045 - training loss: 0.9618, validation loss: 2.3550
2024-06-02 18:34:30 [INFO]: Epoch 046 - training loss: 0.9609, validation loss: 2.3637
2024-06-02 18:34:34 [INFO]: Epoch 047 - training loss: 0.9607, validation loss: 2.3427
2024-06-02 18:34:37 [INFO]: Epoch 048 - training loss: 0.9604, validation loss: 2.3561
2024-06-02 18:34:41 [INFO]: Epoch 049 - training loss: 0.9599, validation loss: 2.3174
2024-06-02 18:34:45 [INFO]: Epoch 050 - training loss: 0.9594, validation loss: 2.3299
2024-06-02 18:34:49 [INFO]: Epoch 051 - training loss: 0.9608, validation loss: 2.3123
2024-06-02 18:34:53 [INFO]: Epoch 052 - training loss: 0.9594, validation loss: 2.3072
2024-06-02 18:34:57 [INFO]: Epoch 053 - training loss: 0.9592, validation loss: 2.2971
2024-06-02 18:35:01 [INFO]: Epoch 054 - training loss: 0.9586, validation loss: 2.2833
2024-06-02 18:35:04 [INFO]: Epoch 055 - training loss: 0.9589, validation loss: 2.2359
2024-06-02 18:35:08 [INFO]: Epoch 056 - training loss: 0.9599, validation loss: 2.2186
2024-06-02 18:35:12 [INFO]: Epoch 057 - training loss: 0.9597, validation loss: 2.1889
2024-06-02 18:35:16 [INFO]: Epoch 058 - training loss: 0.9586, validation loss: 2.1952
2024-06-02 18:35:19 [INFO]: Epoch 059 - training loss: 0.9569, validation loss: 2.1615
2024-06-02 18:35:23 [INFO]: Epoch 060 - training loss: 0.9578, validation loss: 2.2269
2024-06-02 18:35:27 [INFO]: Epoch 061 - training loss: 0.9568, validation loss: 2.1703
2024-06-02 18:35:30 [INFO]: Epoch 062 - training loss: 0.9562, validation loss: 2.1531
2024-06-02 18:35:34 [INFO]: Epoch 063 - training loss: 0.9558, validation loss: 2.1546
2024-06-02 18:35:38 [INFO]: Epoch 064 - training loss: 0.9553, validation loss: 2.1587
2024-06-02 18:35:42 [INFO]: Epoch 065 - training loss: 0.9565, validation loss: 2.1496
2024-06-02 18:35:46 [INFO]: Epoch 066 - training loss: 0.9563, validation loss: 2.1656
2024-06-02 18:35:49 [INFO]: Epoch 067 - training loss: 0.9565, validation loss: 2.1046
2024-06-02 18:35:53 [INFO]: Epoch 068 - training loss: 0.9543, validation loss: 2.1447
2024-06-02 18:35:57 [INFO]: Epoch 069 - training loss: 0.9562, validation loss: 2.0993
2024-06-02 18:36:01 [INFO]: Epoch 070 - training loss: 0.9554, validation loss: 2.0607
2024-06-02 18:36:05 [INFO]: Epoch 071 - training loss: 0.9547, validation loss: 2.0766
2024-06-02 18:36:09 [INFO]: Epoch 072 - training loss: 0.9555, validation loss: 2.0681
2024-06-02 18:36:12 [INFO]: Epoch 073 - training loss: 0.9546, validation loss: 2.0828
2024-06-02 18:36:16 [INFO]: Epoch 074 - training loss: 0.9545, validation loss: 2.0538
2024-06-02 18:36:20 [INFO]: Epoch 075 - training loss: 0.9547, validation loss: 2.0503
2024-06-02 18:36:24 [INFO]: Epoch 076 - training loss: 0.9535, validation loss: 2.0194
2024-06-02 18:36:28 [INFO]: Epoch 077 - training loss: 0.9535, validation loss: 2.0514
2024-06-02 18:36:32 [INFO]: Epoch 078 - training loss: 0.9538, validation loss: 2.0111
2024-06-02 18:36:35 [INFO]: Epoch 079 - training loss: 0.9541, validation loss: 1.9913
2024-06-02 18:36:39 [INFO]: Epoch 080 - training loss: 0.9534, validation loss: 1.9960
2024-06-02 18:36:44 [INFO]: Epoch 081 - training loss: 0.9538, validation loss: 1.9972
2024-06-02 18:36:47 [INFO]: Epoch 082 - training loss: 0.9531, validation loss: 1.9854
2024-06-02 18:36:51 [INFO]: Epoch 083 - training loss: 0.9532, validation loss: 1.9758
2024-06-02 18:36:55 [INFO]: Epoch 084 - training loss: 0.9530, validation loss: 1.9856
2024-06-02 18:36:59 [INFO]: Epoch 085 - training loss: 0.9528, validation loss: 1.9700
2024-06-02 18:37:03 [INFO]: Epoch 086 - training loss: 0.9526, validation loss: 1.9520
2024-06-02 18:37:07 [INFO]: Epoch 087 - training loss: 0.9527, validation loss: 1.9423
2024-06-02 18:37:11 [INFO]: Epoch 088 - training loss: 0.9539, validation loss: 1.9590
2024-06-02 18:37:14 [INFO]: Epoch 089 - training loss: 0.9524, validation loss: 1.9440
2024-06-02 18:37:18 [INFO]: Epoch 090 - training loss: 0.9533, validation loss: 1.9258
2024-06-02 18:37:22 [INFO]: Epoch 091 - training loss: 0.9532, validation loss: 1.9223
2024-06-02 18:37:24 [INFO]: Epoch 092 - training loss: 0.9522, validation loss: 1.9019
2024-06-02 18:37:28 [INFO]: Epoch 093 - training loss: 0.9526, validation loss: 1.8918
2024-06-02 18:37:30 [INFO]: Epoch 094 - training loss: 0.9534, validation loss: 1.8969
2024-06-02 18:37:33 [INFO]: Epoch 095 - training loss: 0.9524, validation loss: 1.9114
2024-06-02 18:37:36 [INFO]: Epoch 096 - training loss: 0.9519, validation loss: 1.9009
2024-06-02 18:37:40 [INFO]: Epoch 097 - training loss: 0.9520, validation loss: 1.9017
2024-06-02 18:37:43 [INFO]: Epoch 098 - training loss: 0.9515, validation loss: 1.8716
2024-06-02 18:37:46 [INFO]: Epoch 099 - training loss: 0.9519, validation loss: 1.8541
2024-06-02 18:37:50 [INFO]: Epoch 100 - training loss: 0.9521, validation loss: 1.8679
2024-06-02 18:37:50 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 18:37:50 [INFO]: Saved the model to results_point_rate01/Electricity/FiLM_Electricity/round_2/20240602_T183132/FiLM.pypots
2024-06-02 18:37:50 [INFO]: Successfully saved to results_point_rate01/Electricity/FiLM_Electricity/round_2/imputation.pkl
2024-06-02 18:37:50 [INFO]: Round2 - FiLM on Electricity: MAE=0.8292, MSE=1.2958, MRE=0.4436
2024-06-02 18:37:50 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 18:37:50 [INFO]: Using the given device: cuda:0
2024-06-02 18:37:50 [INFO]: Model files will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_3/20240602_T183750
2024-06-02 18:37:50 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_3/20240602_T183750/tensorboard
2024-06-02 18:37:50 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 18:37:54 [INFO]: Epoch 001 - training loss: 1.3846, validation loss: 3.8083
2024-06-02 18:37:57 [INFO]: Epoch 002 - training loss: 1.1184, validation loss: 3.4247
2024-06-02 18:38:01 [INFO]: Epoch 003 - training loss: 1.0644, validation loss: 3.4208
2024-06-02 18:38:04 [INFO]: Epoch 004 - training loss: 1.0437, validation loss: 3.3036
2024-06-02 18:38:07 [INFO]: Epoch 005 - training loss: 1.0349, validation loss: 3.0979
2024-06-02 18:38:10 [INFO]: Epoch 006 - training loss: 1.0270, validation loss: 3.1292
2024-06-02 18:38:13 [INFO]: Epoch 007 - training loss: 1.0184, validation loss: 3.0969
2024-06-02 18:38:17 [INFO]: Epoch 008 - training loss: 1.0119, validation loss: 3.0257
2024-06-02 18:38:19 [INFO]: Epoch 009 - training loss: 1.0060, validation loss: 3.0192
2024-06-02 18:38:23 [INFO]: Epoch 010 - training loss: 1.0004, validation loss: 2.9523
2024-06-02 18:38:26 [INFO]: Epoch 011 - training loss: 0.9973, validation loss: 2.9274
2024-06-02 18:38:29 [INFO]: Epoch 012 - training loss: 0.9934, validation loss: 2.8342
2024-06-02 18:38:32 [INFO]: Epoch 013 - training loss: 0.9918, validation loss: 2.8448
2024-06-02 18:38:35 [INFO]: Epoch 014 - training loss: 0.9883, validation loss: 2.8179
2024-06-02 18:38:38 [INFO]: Epoch 015 - training loss: 0.9848, validation loss: 2.7754
2024-06-02 18:38:41 [INFO]: Epoch 016 - training loss: 0.9833, validation loss: 2.7479
2024-06-02 18:38:45 [INFO]: Epoch 017 - training loss: 0.9820, validation loss: 2.7020
2024-06-02 18:38:48 [INFO]: Epoch 018 - training loss: 0.9823, validation loss: 2.7487
2024-06-02 18:38:51 [INFO]: Epoch 019 - training loss: 0.9802, validation loss: 2.6441
2024-06-02 18:38:54 [INFO]: Epoch 020 - training loss: 0.9771, validation loss: 2.6750
2024-06-02 18:38:57 [INFO]: Epoch 021 - training loss: 0.9771, validation loss: 2.5792
2024-06-02 18:39:00 [INFO]: Epoch 022 - training loss: 0.9749, validation loss: 2.5796
2024-06-02 18:39:03 [INFO]: Epoch 023 - training loss: 0.9742, validation loss: 2.5628
2024-06-02 18:39:07 [INFO]: Epoch 024 - training loss: 0.9719, validation loss: 2.5253
2024-06-02 18:39:10 [INFO]: Epoch 025 - training loss: 0.9708, validation loss: 2.5488
2024-06-02 18:39:13 [INFO]: Epoch 026 - training loss: 0.9721, validation loss: 2.4574
2024-06-02 18:39:16 [INFO]: Epoch 027 - training loss: 0.9703, validation loss: 2.4957
2024-06-02 18:39:18 [INFO]: Epoch 028 - training loss: 0.9690, validation loss: 2.4683
2024-06-02 18:39:22 [INFO]: Epoch 029 - training loss: 0.9680, validation loss: 2.4644
2024-06-02 18:39:25 [INFO]: Epoch 030 - training loss: 0.9670, validation loss: 2.4448
2024-06-02 18:39:28 [INFO]: Epoch 031 - training loss: 0.9666, validation loss: 2.4201
2024-06-02 18:39:30 [INFO]: Epoch 032 - training loss: 0.9656, validation loss: 2.4415
2024-06-02 18:39:33 [INFO]: Epoch 033 - training loss: 0.9663, validation loss: 2.4167
2024-06-02 18:39:37 [INFO]: Epoch 034 - training loss: 0.9663, validation loss: 2.3568
2024-06-02 18:39:40 [INFO]: Epoch 035 - training loss: 0.9639, validation loss: 2.3488
2024-06-02 18:39:43 [INFO]: Epoch 036 - training loss: 0.9640, validation loss: 2.3110
2024-06-02 18:39:46 [INFO]: Epoch 037 - training loss: 0.9632, validation loss: 2.3559
2024-06-02 18:39:49 [INFO]: Epoch 038 - training loss: 0.9629, validation loss: 2.3447
2024-06-02 18:39:52 [INFO]: Epoch 039 - training loss: 0.9623, validation loss: 2.3190
2024-06-02 18:39:55 [INFO]: Epoch 040 - training loss: 0.9627, validation loss: 2.2733
2024-06-02 18:39:58 [INFO]: Epoch 041 - training loss: 0.9629, validation loss: 2.2710
2024-06-02 18:40:01 [INFO]: Epoch 042 - training loss: 0.9622, validation loss: 2.2489
2024-06-02 18:40:04 [INFO]: Epoch 043 - training loss: 0.9606, validation loss: 2.2399
2024-06-02 18:40:08 [INFO]: Epoch 044 - training loss: 0.9594, validation loss: 2.2530
2024-06-02 18:40:10 [INFO]: Epoch 045 - training loss: 0.9597, validation loss: 2.2322
2024-06-02 18:40:14 [INFO]: Epoch 046 - training loss: 0.9592, validation loss: 2.2305
2024-06-02 18:40:17 [INFO]: Epoch 047 - training loss: 0.9600, validation loss: 2.2363
2024-06-02 18:40:20 [INFO]: Epoch 048 - training loss: 0.9583, validation loss: 2.1823
2024-06-02 18:40:23 [INFO]: Epoch 049 - training loss: 0.9585, validation loss: 2.1796
2024-06-02 18:40:26 [INFO]: Epoch 050 - training loss: 0.9582, validation loss: 2.1892
2024-06-02 18:40:29 [INFO]: Epoch 051 - training loss: 0.9588, validation loss: 2.1865
2024-06-02 18:40:32 [INFO]: Epoch 052 - training loss: 0.9575, validation loss: 2.1756
2024-06-02 18:40:35 [INFO]: Epoch 053 - training loss: 0.9579, validation loss: 2.1411
2024-06-02 18:40:38 [INFO]: Epoch 054 - training loss: 0.9574, validation loss: 2.1347
2024-06-02 18:40:41 [INFO]: Epoch 055 - training loss: 0.9570, validation loss: 2.1466
2024-06-02 18:40:44 [INFO]: Epoch 056 - training loss: 0.9570, validation loss: 2.1246
2024-06-02 18:40:48 [INFO]: Epoch 057 - training loss: 0.9570, validation loss: 2.1060
2024-06-02 18:40:51 [INFO]: Epoch 058 - training loss: 0.9565, validation loss: 2.0879
2024-06-02 18:40:54 [INFO]: Epoch 059 - training loss: 0.9563, validation loss: 2.0979
2024-06-02 18:40:57 [INFO]: Epoch 060 - training loss: 0.9572, validation loss: 2.0886
2024-06-02 18:41:00 [INFO]: Epoch 061 - training loss: 0.9558, validation loss: 2.0862
2024-06-02 18:41:04 [INFO]: Epoch 062 - training loss: 0.9551, validation loss: 2.0732
2024-06-02 18:41:06 [INFO]: Epoch 063 - training loss: 0.9561, validation loss: 2.0534
2024-06-02 18:41:09 [INFO]: Epoch 064 - training loss: 0.9565, validation loss: 2.0268
2024-06-02 18:41:12 [INFO]: Epoch 065 - training loss: 0.9553, validation loss: 2.0291
2024-06-02 18:41:16 [INFO]: Epoch 066 - training loss: 0.9547, validation loss: 2.0312
2024-06-02 18:41:19 [INFO]: Epoch 067 - training loss: 0.9545, validation loss: 2.0284
2024-06-02 18:41:22 [INFO]: Epoch 068 - training loss: 0.9549, validation loss: 2.0037
2024-06-02 18:41:25 [INFO]: Epoch 069 - training loss: 0.9545, validation loss: 2.0166
2024-06-02 18:41:28 [INFO]: Epoch 070 - training loss: 0.9550, validation loss: 2.0012
2024-06-02 18:41:31 [INFO]: Epoch 071 - training loss: 0.9550, validation loss: 1.9772
2024-06-02 18:41:34 [INFO]: Epoch 072 - training loss: 0.9540, validation loss: 1.9896
2024-06-02 18:41:37 [INFO]: Epoch 073 - training loss: 0.9539, validation loss: 1.9905
2024-06-02 18:41:40 [INFO]: Epoch 074 - training loss: 0.9536, validation loss: 1.9635
2024-06-02 18:41:43 [INFO]: Epoch 075 - training loss: 0.9555, validation loss: 1.9625
2024-06-02 18:41:46 [INFO]: Epoch 076 - training loss: 0.9544, validation loss: 1.9561
2024-06-02 18:41:49 [INFO]: Epoch 077 - training loss: 0.9539, validation loss: 1.9491
2024-06-02 18:41:53 [INFO]: Epoch 078 - training loss: 0.9535, validation loss: 1.9516
2024-06-02 18:41:56 [INFO]: Epoch 079 - training loss: 0.9538, validation loss: 1.9480
2024-06-02 18:41:59 [INFO]: Epoch 080 - training loss: 0.9533, validation loss: 1.9319
2024-06-02 18:42:02 [INFO]: Epoch 081 - training loss: 0.9530, validation loss: 1.9329
2024-06-02 18:42:05 [INFO]: Epoch 082 - training loss: 0.9534, validation loss: 1.9429
2024-06-02 18:42:09 [INFO]: Epoch 083 - training loss: 0.9538, validation loss: 1.9374
2024-06-02 18:42:12 [INFO]: Epoch 084 - training loss: 0.9525, validation loss: 1.9299
2024-06-02 18:42:15 [INFO]: Epoch 085 - training loss: 0.9531, validation loss: 1.9206
2024-06-02 18:42:18 [INFO]: Epoch 086 - training loss: 0.9537, validation loss: 1.9095
2024-06-02 18:42:21 [INFO]: Epoch 087 - training loss: 0.9526, validation loss: 1.8975
2024-06-02 18:42:24 [INFO]: Epoch 088 - training loss: 0.9524, validation loss: 1.8935
2024-06-02 18:42:27 [INFO]: Epoch 089 - training loss: 0.9526, validation loss: 1.8784
2024-06-02 18:42:30 [INFO]: Epoch 090 - training loss: 0.9521, validation loss: 1.8932
2024-06-02 18:42:33 [INFO]: Epoch 091 - training loss: 0.9519, validation loss: 1.8739
2024-06-02 18:42:37 [INFO]: Epoch 092 - training loss: 0.9526, validation loss: 1.8604
2024-06-02 18:42:40 [INFO]: Epoch 093 - training loss: 0.9513, validation loss: 1.8485
2024-06-02 18:42:44 [INFO]: Epoch 094 - training loss: 0.9530, validation loss: 1.8574
2024-06-02 18:42:47 [INFO]: Epoch 095 - training loss: 0.9528, validation loss: 1.8693
2024-06-02 18:42:50 [INFO]: Epoch 096 - training loss: 0.9515, validation loss: 1.8600
2024-06-02 18:42:53 [INFO]: Epoch 097 - training loss: 0.9518, validation loss: 1.8559
2024-06-02 18:42:56 [INFO]: Epoch 098 - training loss: 0.9521, validation loss: 1.8512
2024-06-02 18:42:59 [INFO]: Epoch 099 - training loss: 0.9507, validation loss: 1.8451
2024-06-02 18:43:02 [INFO]: Epoch 100 - training loss: 0.9511, validation loss: 1.8549
2024-06-02 18:43:02 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 18:43:02 [INFO]: Saved the model to results_point_rate01/Electricity/FiLM_Electricity/round_3/20240602_T183750/FiLM.pypots
2024-06-02 18:43:02 [INFO]: Successfully saved to results_point_rate01/Electricity/FiLM_Electricity/round_3/imputation.pkl
2024-06-02 18:43:02 [INFO]: Round3 - FiLM on Electricity: MAE=0.7906, MSE=1.2115, MRE=0.4229
2024-06-02 18:43:02 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 18:43:02 [INFO]: Using the given device: cuda:0
2024-06-02 18:43:02 [INFO]: Model files will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_4/20240602_T184302
2024-06-02 18:43:02 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/FiLM_Electricity/round_4/20240602_T184302/tensorboard
2024-06-02 18:43:03 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 18:43:06 [INFO]: Epoch 001 - training loss: 1.3640, validation loss: 3.3634
2024-06-02 18:43:09 [INFO]: Epoch 002 - training loss: 1.1054, validation loss: 3.1728
2024-06-02 18:43:13 [INFO]: Epoch 003 - training loss: 1.0669, validation loss: 3.2086
2024-06-02 18:43:16 [INFO]: Epoch 004 - training loss: 1.0504, validation loss: 3.2245
2024-06-02 18:43:19 [INFO]: Epoch 005 - training loss: 1.0400, validation loss: 3.1451
2024-06-02 18:43:23 [INFO]: Epoch 006 - training loss: 1.0331, validation loss: 3.0767
2024-06-02 18:43:25 [INFO]: Epoch 007 - training loss: 1.0245, validation loss: 3.0477
2024-06-02 18:43:29 [INFO]: Epoch 008 - training loss: 1.0185, validation loss: 3.0324
2024-06-02 18:43:32 [INFO]: Epoch 009 - training loss: 1.0132, validation loss: 2.9161
2024-06-02 18:43:35 [INFO]: Epoch 010 - training loss: 1.0091, validation loss: 2.8968
2024-06-02 18:43:38 [INFO]: Epoch 011 - training loss: 1.0041, validation loss: 2.8914
2024-06-02 18:43:40 [INFO]: Epoch 012 - training loss: 1.0001, validation loss: 2.8436
2024-06-02 18:43:43 [INFO]: Epoch 013 - training loss: 0.9969, validation loss: 2.8011
2024-06-02 18:43:46 [INFO]: Epoch 014 - training loss: 0.9948, validation loss: 2.7482
2024-06-02 18:43:49 [INFO]: Epoch 015 - training loss: 0.9910, validation loss: 2.7390
2024-06-02 18:43:52 [INFO]: Epoch 016 - training loss: 0.9880, validation loss: 2.7087
2024-06-02 18:43:55 [INFO]: Epoch 017 - training loss: 0.9867, validation loss: 2.7094
2024-06-02 18:43:58 [INFO]: Epoch 018 - training loss: 0.9849, validation loss: 2.6836
2024-06-02 18:44:01 [INFO]: Epoch 019 - training loss: 0.9832, validation loss: 2.6641
2024-06-02 18:44:04 [INFO]: Epoch 020 - training loss: 0.9832, validation loss: 2.6404
2024-06-02 18:44:07 [INFO]: Epoch 021 - training loss: 0.9802, validation loss: 2.5939
2024-06-02 18:44:10 [INFO]: Epoch 022 - training loss: 0.9798, validation loss: 2.5907
2024-06-02 18:44:12 [INFO]: Epoch 023 - training loss: 0.9789, validation loss: 2.6001
2024-06-02 18:44:16 [INFO]: Epoch 024 - training loss: 0.9768, validation loss: 2.5414
2024-06-02 18:44:19 [INFO]: Epoch 025 - training loss: 0.9756, validation loss: 2.5413
2024-06-02 18:44:23 [INFO]: Epoch 026 - training loss: 0.9746, validation loss: 2.5486
2024-06-02 18:44:26 [INFO]: Epoch 027 - training loss: 0.9747, validation loss: 2.5274
2024-06-02 18:44:29 [INFO]: Epoch 028 - training loss: 0.9740, validation loss: 2.5196
2024-06-02 18:44:32 [INFO]: Epoch 029 - training loss: 0.9716, validation loss: 2.4893
2024-06-02 18:44:35 [INFO]: Epoch 030 - training loss: 0.9714, validation loss: 2.4802
2024-06-02 18:44:38 [INFO]: Epoch 031 - training loss: 0.9701, validation loss: 2.4701
2024-06-02 18:44:41 [INFO]: Epoch 032 - training loss: 0.9692, validation loss: 2.4587
2024-06-02 18:44:44 [INFO]: Epoch 033 - training loss: 0.9683, validation loss: 2.4426
2024-06-02 18:44:47 [INFO]: Epoch 034 - training loss: 0.9680, validation loss: 2.4617
2024-06-02 18:44:50 [INFO]: Epoch 035 - training loss: 0.9683, validation loss: 2.4139
2024-06-02 18:44:53 [INFO]: Epoch 036 - training loss: 0.9669, validation loss: 2.4176
2024-06-02 18:44:56 [INFO]: Epoch 037 - training loss: 0.9671, validation loss: 2.3820
2024-06-02 18:44:58 [INFO]: Epoch 038 - training loss: 0.9655, validation loss: 2.4049
2024-06-02 18:45:02 [INFO]: Epoch 039 - training loss: 0.9647, validation loss: 2.3660
2024-06-02 18:45:05 [INFO]: Epoch 040 - training loss: 0.9645, validation loss: 2.3557
2024-06-02 18:45:07 [INFO]: Epoch 041 - training loss: 0.9640, validation loss: 2.3548
2024-06-02 18:45:11 [INFO]: Epoch 042 - training loss: 0.9627, validation loss: 2.3199
2024-06-02 18:45:14 [INFO]: Epoch 043 - training loss: 0.9636, validation loss: 2.3209
2024-06-02 18:45:17 [INFO]: Epoch 044 - training loss: 0.9631, validation loss: 2.3042
2024-06-02 18:45:20 [INFO]: Epoch 045 - training loss: 0.9620, validation loss: 2.3051
2024-06-02 18:45:23 [INFO]: Epoch 046 - training loss: 0.9617, validation loss: 2.2700
2024-06-02 18:45:26 [INFO]: Epoch 047 - training loss: 0.9615, validation loss: 2.2899
2024-06-02 18:45:29 [INFO]: Epoch 048 - training loss: 0.9622, validation loss: 2.2399
2024-06-02 18:45:32 [INFO]: Epoch 049 - training loss: 0.9619, validation loss: 2.2468
2024-06-02 18:45:35 [INFO]: Epoch 050 - training loss: 0.9607, validation loss: 2.2153
2024-06-02 18:45:38 [INFO]: Epoch 051 - training loss: 0.9596, validation loss: 2.2170
2024-06-02 18:45:40 [INFO]: Epoch 052 - training loss: 0.9596, validation loss: 2.2174
2024-06-02 18:45:43 [INFO]: Epoch 053 - training loss: 0.9591, validation loss: 2.2007
2024-06-02 18:45:47 [INFO]: Epoch 054 - training loss: 0.9592, validation loss: 2.1758
2024-06-02 18:45:50 [INFO]: Epoch 055 - training loss: 0.9595, validation loss: 2.1752
2024-06-02 18:45:53 [INFO]: Epoch 056 - training loss: 0.9589, validation loss: 2.1838
2024-06-02 18:45:55 [INFO]: Epoch 057 - training loss: 0.9583, validation loss: 2.1697
2024-06-02 18:45:59 [INFO]: Epoch 058 - training loss: 0.9578, validation loss: 2.1559
2024-06-02 18:46:02 [INFO]: Epoch 059 - training loss: 0.9570, validation loss: 2.1632
2024-06-02 18:46:05 [INFO]: Epoch 060 - training loss: 0.9580, validation loss: 2.1228
2024-06-02 18:46:08 [INFO]: Epoch 061 - training loss: 0.9576, validation loss: 2.1103
2024-06-02 18:46:11 [INFO]: Epoch 062 - training loss: 0.9561, validation loss: 2.1158
2024-06-02 18:46:14 [INFO]: Epoch 063 - training loss: 0.9571, validation loss: 2.0987
2024-06-02 18:46:17 [INFO]: Epoch 064 - training loss: 0.9562, validation loss: 2.0901
2024-06-02 18:46:21 [INFO]: Epoch 065 - training loss: 0.9561, validation loss: 2.0912
2024-06-02 18:46:24 [INFO]: Epoch 066 - training loss: 0.9560, validation loss: 2.0725
2024-06-02 18:46:27 [INFO]: Epoch 067 - training loss: 0.9562, validation loss: 2.0855
2024-06-02 18:46:31 [INFO]: Epoch 068 - training loss: 0.9573, validation loss: 2.0928
2024-06-02 18:46:34 [INFO]: Epoch 069 - training loss: 0.9567, validation loss: 2.0963
2024-06-02 18:46:37 [INFO]: Epoch 070 - training loss: 0.9565, validation loss: 2.0413
2024-06-02 18:46:40 [INFO]: Epoch 071 - training loss: 0.9546, validation loss: 2.0379
2024-06-02 18:46:43 [INFO]: Epoch 072 - training loss: 0.9549, validation loss: 2.0332
2024-06-02 18:46:47 [INFO]: Epoch 073 - training loss: 0.9549, validation loss: 2.0222
2024-06-02 18:46:50 [INFO]: Epoch 074 - training loss: 0.9547, validation loss: 2.0245
2024-06-02 18:46:53 [INFO]: Epoch 075 - training loss: 0.9547, validation loss: 1.9958
2024-06-02 18:46:57 [INFO]: Epoch 076 - training loss: 0.9545, validation loss: 2.0031
2024-06-02 18:47:00 [INFO]: Epoch 077 - training loss: 0.9536, validation loss: 1.9965
2024-06-02 18:47:03 [INFO]: Epoch 078 - training loss: 0.9540, validation loss: 1.9724
2024-06-02 18:47:06 [INFO]: Epoch 079 - training loss: 0.9548, validation loss: 2.0013
2024-06-02 18:47:09 [INFO]: Epoch 080 - training loss: 0.9550, validation loss: 1.9695
2024-06-02 18:47:12 [INFO]: Epoch 081 - training loss: 0.9538, validation loss: 1.9823
2024-06-02 18:47:16 [INFO]: Epoch 082 - training loss: 0.9540, validation loss: 1.9710
2024-06-02 18:47:19 [INFO]: Epoch 083 - training loss: 0.9531, validation loss: 1.9635
2024-06-02 18:47:22 [INFO]: Epoch 084 - training loss: 0.9528, validation loss: 1.9616
2024-06-02 18:47:25 [INFO]: Epoch 085 - training loss: 0.9540, validation loss: 1.9603
2024-06-02 18:47:28 [INFO]: Epoch 086 - training loss: 0.9538, validation loss: 1.9475
2024-06-02 18:47:31 [INFO]: Epoch 087 - training loss: 0.9531, validation loss: 1.9359
2024-06-02 18:47:34 [INFO]: Epoch 088 - training loss: 0.9527, validation loss: 1.9384
2024-06-02 18:47:37 [INFO]: Epoch 089 - training loss: 0.9524, validation loss: 1.9249
2024-06-02 18:47:40 [INFO]: Epoch 090 - training loss: 0.9534, validation loss: 1.9157
2024-06-02 18:47:43 [INFO]: Epoch 091 - training loss: 0.9527, validation loss: 1.9302
2024-06-02 18:47:45 [INFO]: Epoch 092 - training loss: 0.9523, validation loss: 1.9191
2024-06-02 18:47:49 [INFO]: Epoch 093 - training loss: 0.9518, validation loss: 1.9271
2024-06-02 18:47:52 [INFO]: Epoch 094 - training loss: 0.9519, validation loss: 1.8880
2024-06-02 18:47:55 [INFO]: Epoch 095 - training loss: 0.9520, validation loss: 1.9133
2024-06-02 18:47:58 [INFO]: Epoch 096 - training loss: 0.9522, validation loss: 1.8996
2024-06-02 18:48:01 [INFO]: Epoch 097 - training loss: 0.9519, validation loss: 1.8893
2024-06-02 18:48:05 [INFO]: Epoch 098 - training loss: 0.9517, validation loss: 1.8917
2024-06-02 18:48:08 [INFO]: Epoch 099 - training loss: 0.9517, validation loss: 1.8916
2024-06-02 18:48:11 [INFO]: Epoch 100 - training loss: 0.9511, validation loss: 1.8800
2024-06-02 18:48:11 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 18:48:11 [INFO]: Saved the model to results_point_rate01/Electricity/FiLM_Electricity/round_4/20240602_T184302/FiLM.pypots
2024-06-02 18:48:11 [INFO]: Successfully saved to results_point_rate01/Electricity/FiLM_Electricity/round_4/imputation.pkl
2024-06-02 18:48:11 [INFO]: Round4 - FiLM on Electricity: MAE=0.8133, MSE=1.2329, MRE=0.4351
2024-06-02 18:48:11 [INFO]: Done! Final results:
Averaged FiLM (570,613 params) on Electricity: MAE=0.8344 ± 0.03128857955657729, MSE=1.3017 ± 0.07520326303349469, MRE=0.4463 ± 0.016737932948001286, average inference time=0.37
