2024-06-02 15:18:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 15:18:58 [INFO]: Using the given device: cuda:0
2024-06-02 15:18:58 [INFO]: Model files will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_0/20240602_T151858
2024-06-02 15:18:58 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_0/20240602_T151858/tensorboard
2024-06-02 15:19:01 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-02 15:19:22 [INFO]: Epoch 001 - training loss: 1.2072, validation loss: 3.4098
2024-06-02 15:19:38 [INFO]: Epoch 002 - training loss: 0.8256, validation loss: 3.2796
2024-06-02 15:19:54 [INFO]: Epoch 003 - training loss: 0.6848, validation loss: 2.9996
2024-06-02 15:20:11 [INFO]: Epoch 004 - training loss: 0.6288, validation loss: 2.7958
2024-06-02 15:20:27 [INFO]: Epoch 005 - training loss: 0.5933, validation loss: 2.6512
2024-06-02 15:20:44 [INFO]: Epoch 006 - training loss: 0.5685, validation loss: 2.4449
2024-06-02 15:21:00 [INFO]: Epoch 007 - training loss: 0.5487, validation loss: 2.2775
2024-06-02 15:21:17 [INFO]: Epoch 008 - training loss: 0.5312, validation loss: 2.1091
2024-06-02 15:21:33 [INFO]: Epoch 009 - training loss: 0.5163, validation loss: 1.9614
2024-06-02 15:21:50 [INFO]: Epoch 010 - training loss: 0.5046, validation loss: 1.8256
2024-06-02 15:22:06 [INFO]: Epoch 011 - training loss: 0.4929, validation loss: 1.7358
2024-06-02 15:22:23 [INFO]: Epoch 012 - training loss: 0.4841, validation loss: 1.5907
2024-06-02 15:22:39 [INFO]: Epoch 013 - training loss: 0.4755, validation loss: 1.4960
2024-06-02 15:22:55 [INFO]: Epoch 014 - training loss: 0.4700, validation loss: 1.4118
2024-06-02 15:23:12 [INFO]: Epoch 015 - training loss: 0.4634, validation loss: 1.3340
2024-06-02 15:23:28 [INFO]: Epoch 016 - training loss: 0.4587, validation loss: 1.2756
2024-06-02 15:23:44 [INFO]: Epoch 017 - training loss: 0.4534, validation loss: 1.2132
2024-06-02 15:24:01 [INFO]: Epoch 018 - training loss: 0.4490, validation loss: 1.1554
2024-06-02 15:24:17 [INFO]: Epoch 019 - training loss: 0.4466, validation loss: 1.0986
2024-06-02 15:24:34 [INFO]: Epoch 020 - training loss: 0.4418, validation loss: 1.0577
2024-06-02 15:24:50 [INFO]: Epoch 021 - training loss: 0.4387, validation loss: 0.9934
2024-06-02 15:25:06 [INFO]: Epoch 022 - training loss: 0.4351, validation loss: 0.9600
2024-06-02 15:25:22 [INFO]: Epoch 023 - training loss: 0.4322, validation loss: 0.9264
2024-06-02 15:25:39 [INFO]: Epoch 024 - training loss: 0.4292, validation loss: 0.8871
2024-06-02 15:25:56 [INFO]: Epoch 025 - training loss: 0.4257, validation loss: 0.8426
2024-06-02 15:26:12 [INFO]: Epoch 026 - training loss: 0.4225, validation loss: 0.8045
2024-06-02 15:26:28 [INFO]: Epoch 027 - training loss: 0.4199, validation loss: 0.7647
2024-06-02 15:26:45 [INFO]: Epoch 028 - training loss: 0.4178, validation loss: 0.7613
2024-06-02 15:27:01 [INFO]: Epoch 029 - training loss: 0.4138, validation loss: 0.7373
2024-06-02 15:27:18 [INFO]: Epoch 030 - training loss: 0.4125, validation loss: 0.7103
2024-06-02 15:27:34 [INFO]: Epoch 031 - training loss: 0.4098, validation loss: 0.6996
2024-06-02 15:27:51 [INFO]: Epoch 032 - training loss: 0.4069, validation loss: 0.6660
2024-06-02 15:28:07 [INFO]: Epoch 033 - training loss: 0.4057, validation loss: 0.6411
2024-06-02 15:28:24 [INFO]: Epoch 034 - training loss: 0.4032, validation loss: 0.6117
2024-06-02 15:28:40 [INFO]: Epoch 035 - training loss: 0.4018, validation loss: 0.5926
2024-06-02 15:28:57 [INFO]: Epoch 036 - training loss: 0.3993, validation loss: 0.5783
2024-06-02 15:29:13 [INFO]: Epoch 037 - training loss: 0.3979, validation loss: 0.5507
2024-06-02 15:29:30 [INFO]: Epoch 038 - training loss: 0.3972, validation loss: 0.5400
2024-06-02 15:29:47 [INFO]: Epoch 039 - training loss: 0.3946, validation loss: 0.5217
2024-06-02 15:30:03 [INFO]: Epoch 040 - training loss: 0.3929, validation loss: 0.5162
2024-06-02 15:30:19 [INFO]: Epoch 041 - training loss: 0.3915, validation loss: 0.5186
2024-06-02 15:30:36 [INFO]: Epoch 042 - training loss: 0.3886, validation loss: 0.5076
2024-06-02 15:30:52 [INFO]: Epoch 043 - training loss: 0.3871, validation loss: 0.5055
2024-06-02 15:31:09 [INFO]: Epoch 044 - training loss: 0.3865, validation loss: 0.4945
2024-06-02 15:31:26 [INFO]: Epoch 045 - training loss: 0.3853, validation loss: 0.4899
2024-06-02 15:31:42 [INFO]: Epoch 046 - training loss: 0.3837, validation loss: 0.4809
2024-06-02 15:31:59 [INFO]: Epoch 047 - training loss: 0.3826, validation loss: 0.4865
2024-06-02 15:32:15 [INFO]: Epoch 048 - training loss: 0.3828, validation loss: 0.4886
2024-06-02 15:32:32 [INFO]: Epoch 049 - training loss: 0.3822, validation loss: 0.4836
2024-06-02 15:32:48 [INFO]: Epoch 050 - training loss: 0.3831, validation loss: 0.4842
2024-06-02 15:33:05 [INFO]: Epoch 051 - training loss: 0.3812, validation loss: 0.4777
2024-06-02 15:33:21 [INFO]: Epoch 052 - training loss: 0.3805, validation loss: 0.4705
2024-06-02 15:33:38 [INFO]: Epoch 053 - training loss: 0.3798, validation loss: 0.4746
2024-06-02 15:33:55 [INFO]: Epoch 054 - training loss: 0.3794, validation loss: 0.4687
2024-06-02 15:34:11 [INFO]: Epoch 055 - training loss: 0.3795, validation loss: 0.4740
2024-06-02 15:34:27 [INFO]: Epoch 056 - training loss: 0.3798, validation loss: 0.4799
2024-06-02 15:34:43 [INFO]: Epoch 057 - training loss: 0.3795, validation loss: 0.4670
2024-06-02 15:35:00 [INFO]: Epoch 058 - training loss: 0.3786, validation loss: 0.4689
2024-06-02 15:35:16 [INFO]: Epoch 059 - training loss: 0.3782, validation loss: 0.4641
2024-06-02 15:35:32 [INFO]: Epoch 060 - training loss: 0.3786, validation loss: 0.4614
2024-06-02 15:35:49 [INFO]: Epoch 061 - training loss: 0.3784, validation loss: 0.4615
2024-06-02 15:36:06 [INFO]: Epoch 062 - training loss: 0.3784, validation loss: 0.4634
2024-06-02 15:36:22 [INFO]: Epoch 063 - training loss: 0.3785, validation loss: 0.4583
2024-06-02 15:36:39 [INFO]: Epoch 064 - training loss: 0.3778, validation loss: 0.4550
2024-06-02 15:36:55 [INFO]: Epoch 065 - training loss: 0.3783, validation loss: 0.4608
2024-06-02 15:37:12 [INFO]: Epoch 066 - training loss: 0.3780, validation loss: 0.4614
2024-06-02 15:37:29 [INFO]: Epoch 067 - training loss: 0.3781, validation loss: 0.4535
2024-06-02 15:37:46 [INFO]: Epoch 068 - training loss: 0.3771, validation loss: 0.4571
2024-06-02 15:38:02 [INFO]: Epoch 069 - training loss: 0.3775, validation loss: 0.4660
2024-06-02 15:38:19 [INFO]: Epoch 070 - training loss: 0.3774, validation loss: 0.4680
2024-06-02 15:38:35 [INFO]: Epoch 071 - training loss: 0.3771, validation loss: 0.4466
2024-06-02 15:38:52 [INFO]: Epoch 072 - training loss: 0.3776, validation loss: 0.4538
2024-06-02 15:39:08 [INFO]: Epoch 073 - training loss: 0.3773, validation loss: 0.4580
2024-06-02 15:39:25 [INFO]: Epoch 074 - training loss: 0.3782, validation loss: 0.4578
2024-06-02 15:39:41 [INFO]: Epoch 075 - training loss: 0.3773, validation loss: 0.4492
2024-06-02 15:39:57 [INFO]: Epoch 076 - training loss: 0.3774, validation loss: 0.4515
2024-06-02 15:40:14 [INFO]: Epoch 077 - training loss: 0.3773, validation loss: 0.4586
2024-06-02 15:40:30 [INFO]: Epoch 078 - training loss: 0.3768, validation loss: 0.4582
2024-06-02 15:40:47 [INFO]: Epoch 079 - training loss: 0.3769, validation loss: 0.4538
2024-06-02 15:41:03 [INFO]: Epoch 080 - training loss: 0.3764, validation loss: 0.4539
2024-06-02 15:41:20 [INFO]: Epoch 081 - training loss: 0.3763, validation loss: 0.4524
2024-06-02 15:41:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 15:41:20 [INFO]: Finished training. The best model is from epoch#71.
2024-06-02 15:41:26 [INFO]: Saved the model to results_point_rate01/Electricity/SCINet_Electricity/round_0/20240602_T151858/SCINet.pypots
2024-06-02 15:41:27 [INFO]: Successfully saved to results_point_rate01/Electricity/SCINet_Electricity/round_0/imputation.pkl
2024-06-02 15:41:27 [INFO]: Round0 - SCINet on Electricity: MAE=0.5891, MSE=0.5881, MRE=0.3151
2024-06-02 15:41:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 15:41:27 [INFO]: Using the given device: cuda:0
2024-06-02 15:41:27 [INFO]: Model files will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_1/20240602_T154127
2024-06-02 15:41:27 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_1/20240602_T154127/tensorboard
2024-06-02 15:41:35 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-02 15:41:51 [INFO]: Epoch 001 - training loss: 1.1925, validation loss: 3.1104
2024-06-02 15:42:07 [INFO]: Epoch 002 - training loss: 0.7442, validation loss: 2.7427
2024-06-02 15:42:24 [INFO]: Epoch 003 - training loss: 0.6383, validation loss: 2.5746
2024-06-02 15:42:40 [INFO]: Epoch 004 - training loss: 0.5856, validation loss: 2.3976
2024-06-02 15:42:57 [INFO]: Epoch 005 - training loss: 0.5518, validation loss: 2.2655
2024-06-02 15:43:13 [INFO]: Epoch 006 - training loss: 0.5271, validation loss: 2.0946
2024-06-02 15:43:30 [INFO]: Epoch 007 - training loss: 0.5084, validation loss: 1.9836
2024-06-02 15:43:46 [INFO]: Epoch 008 - training loss: 0.4940, validation loss: 1.8401
2024-06-02 15:44:03 [INFO]: Epoch 009 - training loss: 0.4796, validation loss: 1.7049
2024-06-02 15:44:19 [INFO]: Epoch 010 - training loss: 0.4687, validation loss: 1.5799
2024-06-02 15:44:36 [INFO]: Epoch 011 - training loss: 0.4605, validation loss: 1.4695
2024-06-02 15:44:53 [INFO]: Epoch 012 - training loss: 0.4528, validation loss: 1.3530
2024-06-02 15:45:09 [INFO]: Epoch 013 - training loss: 0.4449, validation loss: 1.2692
2024-06-02 15:45:25 [INFO]: Epoch 014 - training loss: 0.4382, validation loss: 1.1645
2024-06-02 15:45:42 [INFO]: Epoch 015 - training loss: 0.4342, validation loss: 1.0935
2024-06-02 15:45:58 [INFO]: Epoch 016 - training loss: 0.4285, validation loss: 1.0263
2024-06-02 15:46:15 [INFO]: Epoch 017 - training loss: 0.4240, validation loss: 0.9645
2024-06-02 15:46:31 [INFO]: Epoch 018 - training loss: 0.4200, validation loss: 0.9103
2024-06-02 15:46:47 [INFO]: Epoch 019 - training loss: 0.4170, validation loss: 0.8748
2024-06-02 15:47:04 [INFO]: Epoch 020 - training loss: 0.4132, validation loss: 0.8346
2024-06-02 15:47:20 [INFO]: Epoch 021 - training loss: 0.4099, validation loss: 0.7808
2024-06-02 15:47:37 [INFO]: Epoch 022 - training loss: 0.4064, validation loss: 0.7412
2024-06-02 15:47:53 [INFO]: Epoch 023 - training loss: 0.4003, validation loss: 0.7028
2024-06-02 15:48:10 [INFO]: Epoch 024 - training loss: 0.3978, validation loss: 0.6711
2024-06-02 15:48:26 [INFO]: Epoch 025 - training loss: 0.3953, validation loss: 0.6528
2024-06-02 15:48:43 [INFO]: Epoch 026 - training loss: 0.3917, validation loss: 0.6312
2024-06-02 15:48:59 [INFO]: Epoch 027 - training loss: 0.3911, validation loss: 0.6175
2024-06-02 15:49:16 [INFO]: Epoch 028 - training loss: 0.3897, validation loss: 0.6041
2024-06-02 15:49:32 [INFO]: Epoch 029 - training loss: 0.3876, validation loss: 0.5818
2024-06-02 15:49:48 [INFO]: Epoch 030 - training loss: 0.3846, validation loss: 0.5663
2024-06-02 15:50:04 [INFO]: Epoch 031 - training loss: 0.3825, validation loss: 0.5615
2024-06-02 15:50:21 [INFO]: Epoch 032 - training loss: 0.3801, validation loss: 0.5528
2024-06-02 15:50:38 [INFO]: Epoch 033 - training loss: 0.3765, validation loss: 0.5499
2024-06-02 15:50:54 [INFO]: Epoch 034 - training loss: 0.3752, validation loss: 0.5477
2024-06-02 15:51:11 [INFO]: Epoch 035 - training loss: 0.3725, validation loss: 0.5496
2024-06-02 15:51:28 [INFO]: Epoch 036 - training loss: 0.3696, validation loss: 0.5471
2024-06-02 15:51:44 [INFO]: Epoch 037 - training loss: 0.3659, validation loss: 0.5465
2024-06-02 15:52:01 [INFO]: Epoch 038 - training loss: 0.3629, validation loss: 0.5433
2024-06-02 15:52:17 [INFO]: Epoch 039 - training loss: 0.3593, validation loss: 0.5510
2024-06-02 15:52:33 [INFO]: Epoch 040 - training loss: 0.3557, validation loss: 0.5558
2024-06-02 15:52:50 [INFO]: Epoch 041 - training loss: 0.3526, validation loss: 0.5615
2024-06-02 15:53:06 [INFO]: Epoch 042 - training loss: 0.3507, validation loss: 0.5587
2024-06-02 15:53:23 [INFO]: Epoch 043 - training loss: 0.3494, validation loss: 0.5658
2024-06-02 15:53:39 [INFO]: Epoch 044 - training loss: 0.3472, validation loss: 0.5725
2024-06-02 15:53:56 [INFO]: Epoch 045 - training loss: 0.3434, validation loss: 0.5670
2024-06-02 15:54:12 [INFO]: Epoch 046 - training loss: 0.3412, validation loss: 0.5712
2024-06-02 15:54:28 [INFO]: Epoch 047 - training loss: 0.3387, validation loss: 0.5751
2024-06-02 15:54:45 [INFO]: Epoch 048 - training loss: 0.3371, validation loss: 0.5789
2024-06-02 15:54:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 15:54:45 [INFO]: Finished training. The best model is from epoch#38.
2024-06-02 15:54:51 [INFO]: Saved the model to results_point_rate01/Electricity/SCINet_Electricity/round_1/20240602_T154127/SCINet.pypots
2024-06-02 15:54:52 [INFO]: Successfully saved to results_point_rate01/Electricity/SCINet_Electricity/round_1/imputation.pkl
2024-06-02 15:54:52 [INFO]: Round1 - SCINet on Electricity: MAE=0.5969, MSE=0.6205, MRE=0.3193
2024-06-02 15:54:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 15:54:52 [INFO]: Using the given device: cuda:0
2024-06-02 15:54:52 [INFO]: Model files will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_2/20240602_T155452
2024-06-02 15:54:52 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_2/20240602_T155452/tensorboard
2024-06-02 15:55:00 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-02 15:55:17 [INFO]: Epoch 001 - training loss: 1.2065, validation loss: 3.3938
2024-06-02 15:55:33 [INFO]: Epoch 002 - training loss: 0.8108, validation loss: 3.0874
2024-06-02 15:55:49 [INFO]: Epoch 003 - training loss: 0.6883, validation loss: 2.8962
2024-06-02 15:56:06 [INFO]: Epoch 004 - training loss: 0.6269, validation loss: 2.7257
2024-06-02 15:56:21 [INFO]: Epoch 005 - training loss: 0.5926, validation loss: 2.5788
2024-06-02 15:56:38 [INFO]: Epoch 006 - training loss: 0.5687, validation loss: 2.4564
2024-06-02 15:56:54 [INFO]: Epoch 007 - training loss: 0.5464, validation loss: 2.3705
2024-06-02 15:57:11 [INFO]: Epoch 008 - training loss: 0.5310, validation loss: 2.2896
2024-06-02 15:57:27 [INFO]: Epoch 009 - training loss: 0.5181, validation loss: 2.1919
2024-06-02 15:57:44 [INFO]: Epoch 010 - training loss: 0.5060, validation loss: 2.0965
2024-06-02 15:57:58 [INFO]: Epoch 011 - training loss: 0.4963, validation loss: 2.0250
2024-06-02 15:58:11 [INFO]: Epoch 012 - training loss: 0.4879, validation loss: 1.9398
2024-06-02 15:58:23 [INFO]: Epoch 013 - training loss: 0.4806, validation loss: 1.8578
2024-06-02 15:58:36 [INFO]: Epoch 014 - training loss: 0.4747, validation loss: 1.7572
2024-06-02 15:58:48 [INFO]: Epoch 015 - training loss: 0.4707, validation loss: 1.6987
2024-06-02 15:59:01 [INFO]: Epoch 016 - training loss: 0.4651, validation loss: 1.6070
2024-06-02 15:59:14 [INFO]: Epoch 017 - training loss: 0.4615, validation loss: 1.5471
2024-06-02 15:59:26 [INFO]: Epoch 018 - training loss: 0.4558, validation loss: 1.4473
2024-06-02 15:59:39 [INFO]: Epoch 019 - training loss: 0.4516, validation loss: 1.3763
2024-06-02 15:59:52 [INFO]: Epoch 020 - training loss: 0.4491, validation loss: 1.3287
2024-06-02 16:00:05 [INFO]: Epoch 021 - training loss: 0.4434, validation loss: 1.2279
2024-06-02 16:00:17 [INFO]: Epoch 022 - training loss: 0.4411, validation loss: 1.1654
2024-06-02 16:00:30 [INFO]: Epoch 023 - training loss: 0.4374, validation loss: 1.1017
2024-06-02 16:00:43 [INFO]: Epoch 024 - training loss: 0.4338, validation loss: 1.0311
2024-06-02 16:00:56 [INFO]: Epoch 025 - training loss: 0.4289, validation loss: 0.9537
2024-06-02 16:01:08 [INFO]: Epoch 026 - training loss: 0.4260, validation loss: 0.8779
2024-06-02 16:01:21 [INFO]: Epoch 027 - training loss: 0.4217, validation loss: 0.8203
2024-06-02 16:01:33 [INFO]: Epoch 028 - training loss: 0.4154, validation loss: 0.7572
2024-06-02 16:01:46 [INFO]: Epoch 029 - training loss: 0.4115, validation loss: 0.7245
2024-06-02 16:01:59 [INFO]: Epoch 030 - training loss: 0.4088, validation loss: 0.6814
2024-06-02 16:02:11 [INFO]: Epoch 031 - training loss: 0.4048, validation loss: 0.6379
2024-06-02 16:02:24 [INFO]: Epoch 032 - training loss: 0.4027, validation loss: 0.6148
2024-06-02 16:02:37 [INFO]: Epoch 033 - training loss: 0.4005, validation loss: 0.6044
2024-06-02 16:02:49 [INFO]: Epoch 034 - training loss: 0.3968, validation loss: 0.5841
2024-06-02 16:03:02 [INFO]: Epoch 035 - training loss: 0.3944, validation loss: 0.5705
2024-06-02 16:03:15 [INFO]: Epoch 036 - training loss: 0.3927, validation loss: 0.5586
2024-06-02 16:03:28 [INFO]: Epoch 037 - training loss: 0.3900, validation loss: 0.5490
2024-06-02 16:03:40 [INFO]: Epoch 038 - training loss: 0.3880, validation loss: 0.5332
2024-06-02 16:03:53 [INFO]: Epoch 039 - training loss: 0.3880, validation loss: 0.5336
2024-06-02 16:04:06 [INFO]: Epoch 040 - training loss: 0.3867, validation loss: 0.5249
2024-06-02 16:04:18 [INFO]: Epoch 041 - training loss: 0.3856, validation loss: 0.5208
2024-06-02 16:04:31 [INFO]: Epoch 042 - training loss: 0.3846, validation loss: 0.5209
2024-06-02 16:04:44 [INFO]: Epoch 043 - training loss: 0.3837, validation loss: 0.5052
2024-06-02 16:04:57 [INFO]: Epoch 044 - training loss: 0.3830, validation loss: 0.5017
2024-06-02 16:05:09 [INFO]: Epoch 045 - training loss: 0.3831, validation loss: 0.4989
2024-06-02 16:05:22 [INFO]: Epoch 046 - training loss: 0.3824, validation loss: 0.4847
2024-06-02 16:05:35 [INFO]: Epoch 047 - training loss: 0.3831, validation loss: 0.4946
2024-06-02 16:05:47 [INFO]: Epoch 048 - training loss: 0.3825, validation loss: 0.4843
2024-06-02 16:06:00 [INFO]: Epoch 049 - training loss: 0.3824, validation loss: 0.4856
2024-06-02 16:06:13 [INFO]: Epoch 050 - training loss: 0.3818, validation loss: 0.4823
2024-06-02 16:06:26 [INFO]: Epoch 051 - training loss: 0.3810, validation loss: 0.4745
2024-06-02 16:06:38 [INFO]: Epoch 052 - training loss: 0.3812, validation loss: 0.4749
2024-06-02 16:06:51 [INFO]: Epoch 053 - training loss: 0.3809, validation loss: 0.4769
2024-06-02 16:07:04 [INFO]: Epoch 054 - training loss: 0.3810, validation loss: 0.4674
2024-06-02 16:07:16 [INFO]: Epoch 055 - training loss: 0.3805, validation loss: 0.4640
2024-06-02 16:07:29 [INFO]: Epoch 056 - training loss: 0.3795, validation loss: 0.4634
2024-06-02 16:07:41 [INFO]: Epoch 057 - training loss: 0.3802, validation loss: 0.4645
2024-06-02 16:07:54 [INFO]: Epoch 058 - training loss: 0.3799, validation loss: 0.4609
2024-06-02 16:08:07 [INFO]: Epoch 059 - training loss: 0.3792, validation loss: 0.4606
2024-06-02 16:08:20 [INFO]: Epoch 060 - training loss: 0.3791, validation loss: 0.4571
2024-06-02 16:08:32 [INFO]: Epoch 061 - training loss: 0.3791, validation loss: 0.4623
2024-06-02 16:08:45 [INFO]: Epoch 062 - training loss: 0.3802, validation loss: 0.4605
2024-06-02 16:08:57 [INFO]: Epoch 063 - training loss: 0.3787, validation loss: 0.4606
2024-06-02 16:09:10 [INFO]: Epoch 064 - training loss: 0.3786, validation loss: 0.4589
2024-06-02 16:09:22 [INFO]: Epoch 065 - training loss: 0.3790, validation loss: 0.4498
2024-06-02 16:09:35 [INFO]: Epoch 066 - training loss: 0.3786, validation loss: 0.4490
2024-06-02 16:09:48 [INFO]: Epoch 067 - training loss: 0.3789, validation loss: 0.4546
2024-06-02 16:10:01 [INFO]: Epoch 068 - training loss: 0.3790, validation loss: 0.4558
2024-06-02 16:10:14 [INFO]: Epoch 069 - training loss: 0.3783, validation loss: 0.4534
2024-06-02 16:10:26 [INFO]: Epoch 070 - training loss: 0.3782, validation loss: 0.4486
2024-06-02 16:10:39 [INFO]: Epoch 071 - training loss: 0.3780, validation loss: 0.4507
2024-06-02 16:10:52 [INFO]: Epoch 072 - training loss: 0.3775, validation loss: 0.4477
2024-06-02 16:11:05 [INFO]: Epoch 073 - training loss: 0.3787, validation loss: 0.4508
2024-06-02 16:11:17 [INFO]: Epoch 074 - training loss: 0.3778, validation loss: 0.4447
2024-06-02 16:11:30 [INFO]: Epoch 075 - training loss: 0.3782, validation loss: 0.4403
2024-06-02 16:11:42 [INFO]: Epoch 076 - training loss: 0.3781, validation loss: 0.4470
2024-06-02 16:11:55 [INFO]: Epoch 077 - training loss: 0.3774, validation loss: 0.4495
2024-06-02 16:12:08 [INFO]: Epoch 078 - training loss: 0.3773, validation loss: 0.4450
2024-06-02 16:12:20 [INFO]: Epoch 079 - training loss: 0.3769, validation loss: 0.4427
2024-06-02 16:12:33 [INFO]: Epoch 080 - training loss: 0.3774, validation loss: 0.4487
2024-06-02 16:12:46 [INFO]: Epoch 081 - training loss: 0.3772, validation loss: 0.4472
2024-06-02 16:12:58 [INFO]: Epoch 082 - training loss: 0.3768, validation loss: 0.4394
2024-06-02 16:13:11 [INFO]: Epoch 083 - training loss: 0.3775, validation loss: 0.4453
2024-06-02 16:13:24 [INFO]: Epoch 084 - training loss: 0.3765, validation loss: 0.4459
2024-06-02 16:13:37 [INFO]: Epoch 085 - training loss: 0.3767, validation loss: 0.4352
2024-06-02 16:13:49 [INFO]: Epoch 086 - training loss: 0.3770, validation loss: 0.4453
2024-06-02 16:14:02 [INFO]: Epoch 087 - training loss: 0.3762, validation loss: 0.4385
2024-06-02 16:14:14 [INFO]: Epoch 088 - training loss: 0.3758, validation loss: 0.4388
2024-06-02 16:14:27 [INFO]: Epoch 089 - training loss: 0.3757, validation loss: 0.4340
2024-06-02 16:14:40 [INFO]: Epoch 090 - training loss: 0.3746, validation loss: 0.4336
2024-06-02 16:14:52 [INFO]: Epoch 091 - training loss: 0.3711, validation loss: 0.4352
2024-06-02 16:15:05 [INFO]: Epoch 092 - training loss: 0.3665, validation loss: 0.4440
2024-06-02 16:15:18 [INFO]: Epoch 093 - training loss: 0.3618, validation loss: 0.4401
2024-06-02 16:15:31 [INFO]: Epoch 094 - training loss: 0.3567, validation loss: 0.4487
2024-06-02 16:15:43 [INFO]: Epoch 095 - training loss: 0.3526, validation loss: 0.4396
2024-06-02 16:15:56 [INFO]: Epoch 096 - training loss: 0.3493, validation loss: 0.4559
2024-06-02 16:16:09 [INFO]: Epoch 097 - training loss: 0.3460, validation loss: 0.4667
2024-06-02 16:16:21 [INFO]: Epoch 098 - training loss: 0.3439, validation loss: 0.4709
2024-06-02 16:16:34 [INFO]: Epoch 099 - training loss: 0.3415, validation loss: 0.4764
2024-06-02 16:16:46 [INFO]: Epoch 100 - training loss: 0.3390, validation loss: 0.4819
2024-06-02 16:16:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 16:16:46 [INFO]: Finished training. The best model is from epoch#90.
2024-06-02 16:16:50 [INFO]: Saved the model to results_point_rate01/Electricity/SCINet_Electricity/round_2/20240602_T155452/SCINet.pypots
2024-06-02 16:16:52 [INFO]: Successfully saved to results_point_rate01/Electricity/SCINet_Electricity/round_2/imputation.pkl
2024-06-02 16:16:52 [INFO]: Round2 - SCINet on Electricity: MAE=0.5610, MSE=0.5696, MRE=0.3001
2024-06-02 16:16:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 16:16:52 [INFO]: Using the given device: cuda:0
2024-06-02 16:16:52 [INFO]: Model files will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_3/20240602_T161652
2024-06-02 16:16:52 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_3/20240602_T161652/tensorboard
2024-06-02 16:16:57 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-02 16:17:10 [INFO]: Epoch 001 - training loss: 1.1566, validation loss: 3.1492
2024-06-02 16:17:23 [INFO]: Epoch 002 - training loss: 0.7353, validation loss: 2.7615
2024-06-02 16:17:36 [INFO]: Epoch 003 - training loss: 0.6221, validation loss: 2.5140
2024-06-02 16:17:48 [INFO]: Epoch 004 - training loss: 0.5702, validation loss: 2.3430
2024-06-02 16:18:01 [INFO]: Epoch 005 - training loss: 0.5387, validation loss: 2.1864
2024-06-02 16:18:14 [INFO]: Epoch 006 - training loss: 0.5158, validation loss: 2.0626
2024-06-02 16:18:27 [INFO]: Epoch 007 - training loss: 0.4984, validation loss: 1.9308
2024-06-02 16:18:40 [INFO]: Epoch 008 - training loss: 0.4835, validation loss: 1.7949
2024-06-02 16:18:52 [INFO]: Epoch 009 - training loss: 0.4702, validation loss: 1.6677
2024-06-02 16:19:05 [INFO]: Epoch 010 - training loss: 0.4604, validation loss: 1.5320
2024-06-02 16:19:17 [INFO]: Epoch 011 - training loss: 0.4504, validation loss: 1.4219
2024-06-02 16:19:30 [INFO]: Epoch 012 - training loss: 0.4415, validation loss: 1.3043
2024-06-02 16:19:42 [INFO]: Epoch 013 - training loss: 0.4333, validation loss: 1.1984
2024-06-02 16:19:55 [INFO]: Epoch 014 - training loss: 0.4262, validation loss: 1.1085
2024-06-02 16:20:08 [INFO]: Epoch 015 - training loss: 0.4207, validation loss: 1.0258
2024-06-02 16:20:20 [INFO]: Epoch 016 - training loss: 0.4153, validation loss: 0.9529
2024-06-02 16:20:33 [INFO]: Epoch 017 - training loss: 0.4114, validation loss: 0.8908
2024-06-02 16:20:46 [INFO]: Epoch 018 - training loss: 0.4074, validation loss: 0.8357
2024-06-02 16:20:58 [INFO]: Epoch 019 - training loss: 0.4039, validation loss: 0.7893
2024-06-02 16:21:11 [INFO]: Epoch 020 - training loss: 0.4026, validation loss: 0.7484
2024-06-02 16:21:24 [INFO]: Epoch 021 - training loss: 0.4001, validation loss: 0.7087
2024-06-02 16:21:37 [INFO]: Epoch 022 - training loss: 0.3980, validation loss: 0.6835
2024-06-02 16:21:48 [INFO]: Epoch 023 - training loss: 0.3968, validation loss: 0.6546
2024-06-02 16:21:59 [INFO]: Epoch 024 - training loss: 0.3962, validation loss: 0.6280
2024-06-02 16:22:10 [INFO]: Epoch 025 - training loss: 0.3935, validation loss: 0.6197
2024-06-02 16:22:20 [INFO]: Epoch 026 - training loss: 0.3918, validation loss: 0.6052
2024-06-02 16:22:31 [INFO]: Epoch 027 - training loss: 0.3933, validation loss: 0.5981
2024-06-02 16:22:42 [INFO]: Epoch 028 - training loss: 0.3907, validation loss: 0.5776
2024-06-02 16:22:52 [INFO]: Epoch 029 - training loss: 0.3884, validation loss: 0.5616
2024-06-02 16:23:03 [INFO]: Epoch 030 - training loss: 0.3882, validation loss: 0.5461
2024-06-02 16:23:14 [INFO]: Epoch 031 - training loss: 0.3891, validation loss: 0.5474
2024-06-02 16:23:24 [INFO]: Epoch 032 - training loss: 0.3879, validation loss: 0.5356
2024-06-02 16:23:35 [INFO]: Epoch 033 - training loss: 0.3859, validation loss: 0.5326
2024-06-02 16:23:46 [INFO]: Epoch 034 - training loss: 0.3850, validation loss: 0.5204
2024-06-02 16:23:56 [INFO]: Epoch 035 - training loss: 0.3858, validation loss: 0.5198
2024-06-02 16:24:07 [INFO]: Epoch 036 - training loss: 0.3850, validation loss: 0.5166
2024-06-02 16:24:18 [INFO]: Epoch 037 - training loss: 0.3847, validation loss: 0.5147
2024-06-02 16:24:28 [INFO]: Epoch 038 - training loss: 0.3842, validation loss: 0.5123
2024-06-02 16:24:39 [INFO]: Epoch 039 - training loss: 0.3833, validation loss: 0.4984
2024-06-02 16:24:50 [INFO]: Epoch 040 - training loss: 0.3828, validation loss: 0.4914
2024-06-02 16:25:00 [INFO]: Epoch 041 - training loss: 0.3831, validation loss: 0.4876
2024-06-02 16:25:11 [INFO]: Epoch 042 - training loss: 0.3829, validation loss: 0.4908
2024-06-02 16:25:21 [INFO]: Epoch 043 - training loss: 0.3827, validation loss: 0.4900
2024-06-02 16:25:32 [INFO]: Epoch 044 - training loss: 0.3822, validation loss: 0.4885
2024-06-02 16:25:43 [INFO]: Epoch 045 - training loss: 0.3820, validation loss: 0.4817
2024-06-02 16:25:53 [INFO]: Epoch 046 - training loss: 0.3821, validation loss: 0.4863
2024-06-02 16:26:04 [INFO]: Epoch 047 - training loss: 0.3824, validation loss: 0.4780
2024-06-02 16:26:15 [INFO]: Epoch 048 - training loss: 0.3817, validation loss: 0.4784
2024-06-02 16:26:25 [INFO]: Epoch 049 - training loss: 0.3805, validation loss: 0.4791
2024-06-02 16:26:36 [INFO]: Epoch 050 - training loss: 0.3801, validation loss: 0.4748
2024-06-02 16:26:47 [INFO]: Epoch 051 - training loss: 0.3799, validation loss: 0.4706
2024-06-02 16:26:57 [INFO]: Epoch 052 - training loss: 0.3801, validation loss: 0.4656
2024-06-02 16:27:08 [INFO]: Epoch 053 - training loss: 0.3798, validation loss: 0.4600
2024-06-02 16:27:19 [INFO]: Epoch 054 - training loss: 0.3804, validation loss: 0.4544
2024-06-02 16:27:29 [INFO]: Epoch 055 - training loss: 0.3797, validation loss: 0.4588
2024-06-02 16:27:40 [INFO]: Epoch 056 - training loss: 0.3790, validation loss: 0.4544
2024-06-02 16:27:51 [INFO]: Epoch 057 - training loss: 0.3797, validation loss: 0.4520
2024-06-02 16:28:01 [INFO]: Epoch 058 - training loss: 0.3793, validation loss: 0.4556
2024-06-02 16:28:12 [INFO]: Epoch 059 - training loss: 0.3789, validation loss: 0.4631
2024-06-02 16:28:22 [INFO]: Epoch 060 - training loss: 0.3797, validation loss: 0.4702
2024-06-02 16:28:33 [INFO]: Epoch 061 - training loss: 0.3800, validation loss: 0.4620
2024-06-02 16:28:44 [INFO]: Epoch 062 - training loss: 0.3788, validation loss: 0.4551
2024-06-02 16:28:54 [INFO]: Epoch 063 - training loss: 0.3784, validation loss: 0.4584
2024-06-02 16:29:05 [INFO]: Epoch 064 - training loss: 0.3781, validation loss: 0.4445
2024-06-02 16:29:16 [INFO]: Epoch 065 - training loss: 0.3787, validation loss: 0.4533
2024-06-02 16:29:26 [INFO]: Epoch 066 - training loss: 0.3783, validation loss: 0.4506
2024-06-02 16:29:37 [INFO]: Epoch 067 - training loss: 0.3785, validation loss: 0.4447
2024-06-02 16:29:48 [INFO]: Epoch 068 - training loss: 0.3789, validation loss: 0.4537
2024-06-02 16:29:58 [INFO]: Epoch 069 - training loss: 0.3781, validation loss: 0.4472
2024-06-02 16:30:09 [INFO]: Epoch 070 - training loss: 0.3777, validation loss: 0.4457
2024-06-02 16:30:20 [INFO]: Epoch 071 - training loss: 0.3780, validation loss: 0.4446
2024-06-02 16:30:30 [INFO]: Epoch 072 - training loss: 0.3776, validation loss: 0.4466
2024-06-02 16:30:41 [INFO]: Epoch 073 - training loss: 0.3769, validation loss: 0.4478
2024-06-02 16:30:52 [INFO]: Epoch 074 - training loss: 0.3767, validation loss: 0.4387
2024-06-02 16:31:02 [INFO]: Epoch 075 - training loss: 0.3772, validation loss: 0.4437
2024-06-02 16:31:13 [INFO]: Epoch 076 - training loss: 0.3776, validation loss: 0.4483
2024-06-02 16:31:24 [INFO]: Epoch 077 - training loss: 0.3769, validation loss: 0.4397
2024-06-02 16:31:34 [INFO]: Epoch 078 - training loss: 0.3778, validation loss: 0.4387
2024-06-02 16:31:45 [INFO]: Epoch 079 - training loss: 0.3778, validation loss: 0.4419
2024-06-02 16:31:56 [INFO]: Epoch 080 - training loss: 0.3774, validation loss: 0.4381
2024-06-02 16:32:06 [INFO]: Epoch 081 - training loss: 0.3766, validation loss: 0.4425
2024-06-02 16:32:17 [INFO]: Epoch 082 - training loss: 0.3767, validation loss: 0.4397
2024-06-02 16:32:27 [INFO]: Epoch 083 - training loss: 0.3769, validation loss: 0.4403
2024-06-02 16:32:38 [INFO]: Epoch 084 - training loss: 0.3765, validation loss: 0.4367
2024-06-02 16:32:49 [INFO]: Epoch 085 - training loss: 0.3762, validation loss: 0.4366
2024-06-02 16:32:59 [INFO]: Epoch 086 - training loss: 0.3756, validation loss: 0.4359
2024-06-02 16:33:10 [INFO]: Epoch 087 - training loss: 0.3760, validation loss: 0.4383
2024-06-02 16:33:21 [INFO]: Epoch 088 - training loss: 0.3761, validation loss: 0.4358
2024-06-02 16:33:31 [INFO]: Epoch 089 - training loss: 0.3759, validation loss: 0.4368
2024-06-02 16:33:42 [INFO]: Epoch 090 - training loss: 0.3763, validation loss: 0.4346
2024-06-02 16:33:53 [INFO]: Epoch 091 - training loss: 0.3763, validation loss: 0.4338
2024-06-02 16:34:04 [INFO]: Epoch 092 - training loss: 0.3762, validation loss: 0.4282
2024-06-02 16:34:14 [INFO]: Epoch 093 - training loss: 0.3761, validation loss: 0.4398
2024-06-02 16:34:25 [INFO]: Epoch 094 - training loss: 0.3759, validation loss: 0.4381
2024-06-02 16:34:36 [INFO]: Epoch 095 - training loss: 0.3764, validation loss: 0.4401
2024-06-02 16:34:46 [INFO]: Epoch 096 - training loss: 0.3763, validation loss: 0.4311
2024-06-02 16:34:57 [INFO]: Epoch 097 - training loss: 0.3770, validation loss: 0.4326
2024-06-02 16:35:08 [INFO]: Epoch 098 - training loss: 0.3759, validation loss: 0.4335
2024-06-02 16:35:18 [INFO]: Epoch 099 - training loss: 0.3758, validation loss: 0.4321
2024-06-02 16:35:29 [INFO]: Epoch 100 - training loss: 0.3758, validation loss: 0.4280
2024-06-02 16:35:29 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 16:35:32 [INFO]: Saved the model to results_point_rate01/Electricity/SCINet_Electricity/round_3/20240602_T161652/SCINet.pypots
2024-06-02 16:35:33 [INFO]: Successfully saved to results_point_rate01/Electricity/SCINet_Electricity/round_3/imputation.pkl
2024-06-02 16:35:33 [INFO]: Round3 - SCINet on Electricity: MAE=0.5658, MSE=0.5304, MRE=0.3027
2024-06-02 16:35:33 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 16:35:33 [INFO]: Using the given device: cuda:0
2024-06-02 16:35:33 [INFO]: Model files will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_4/20240602_T163533
2024-06-02 16:35:33 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/SCINet_Electricity/round_4/20240602_T163533/tensorboard
2024-06-02 16:35:37 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-02 16:35:48 [INFO]: Epoch 001 - training loss: 1.1191, validation loss: 3.0416
2024-06-02 16:35:58 [INFO]: Epoch 002 - training loss: 0.7209, validation loss: 2.6578
2024-06-02 16:36:09 [INFO]: Epoch 003 - training loss: 0.6153, validation loss: 2.4758
2024-06-02 16:36:20 [INFO]: Epoch 004 - training loss: 0.5646, validation loss: 2.3445
2024-06-02 16:36:30 [INFO]: Epoch 005 - training loss: 0.5307, validation loss: 2.1913
2024-06-02 16:36:41 [INFO]: Epoch 006 - training loss: 0.5060, validation loss: 2.0625
2024-06-02 16:36:52 [INFO]: Epoch 007 - training loss: 0.4881, validation loss: 1.9310
2024-06-02 16:37:02 [INFO]: Epoch 008 - training loss: 0.4734, validation loss: 1.8082
2024-06-02 16:37:13 [INFO]: Epoch 009 - training loss: 0.4615, validation loss: 1.6833
2024-06-02 16:37:23 [INFO]: Epoch 010 - training loss: 0.4515, validation loss: 1.5579
2024-06-02 16:37:34 [INFO]: Epoch 011 - training loss: 0.4427, validation loss: 1.4269
2024-06-02 16:37:45 [INFO]: Epoch 012 - training loss: 0.4350, validation loss: 1.3354
2024-06-02 16:37:56 [INFO]: Epoch 013 - training loss: 0.4281, validation loss: 1.2333
2024-06-02 16:38:06 [INFO]: Epoch 014 - training loss: 0.4235, validation loss: 1.1384
2024-06-02 16:38:17 [INFO]: Epoch 015 - training loss: 0.4186, validation loss: 1.0531
2024-06-02 16:38:27 [INFO]: Epoch 016 - training loss: 0.4134, validation loss: 0.9928
2024-06-02 16:38:38 [INFO]: Epoch 017 - training loss: 0.4100, validation loss: 0.9230
2024-06-02 16:38:49 [INFO]: Epoch 018 - training loss: 0.4060, validation loss: 0.8520
2024-06-02 16:38:59 [INFO]: Epoch 019 - training loss: 0.4029, validation loss: 0.8149
2024-06-02 16:39:10 [INFO]: Epoch 020 - training loss: 0.3995, validation loss: 0.7784
2024-06-02 16:39:21 [INFO]: Epoch 021 - training loss: 0.3978, validation loss: 0.7394
2024-06-02 16:39:31 [INFO]: Epoch 022 - training loss: 0.3964, validation loss: 0.7067
2024-06-02 16:39:42 [INFO]: Epoch 023 - training loss: 0.3961, validation loss: 0.6887
2024-06-02 16:39:53 [INFO]: Epoch 024 - training loss: 0.3925, validation loss: 0.6524
2024-06-02 16:40:03 [INFO]: Epoch 025 - training loss: 0.3907, validation loss: 0.6268
2024-06-02 16:40:14 [INFO]: Epoch 026 - training loss: 0.3899, validation loss: 0.6106
2024-06-02 16:40:25 [INFO]: Epoch 027 - training loss: 0.3885, validation loss: 0.5993
2024-06-02 16:40:35 [INFO]: Epoch 028 - training loss: 0.3881, validation loss: 0.5848
2024-06-02 16:40:46 [INFO]: Epoch 029 - training loss: 0.3872, validation loss: 0.5760
2024-06-02 16:40:57 [INFO]: Epoch 030 - training loss: 0.3873, validation loss: 0.5612
2024-06-02 16:41:07 [INFO]: Epoch 031 - training loss: 0.3851, validation loss: 0.5570
2024-06-02 16:41:18 [INFO]: Epoch 032 - training loss: 0.3856, validation loss: 0.5520
2024-06-02 16:41:29 [INFO]: Epoch 033 - training loss: 0.3858, validation loss: 0.5495
2024-06-02 16:41:39 [INFO]: Epoch 034 - training loss: 0.3840, validation loss: 0.5331
2024-06-02 16:41:50 [INFO]: Epoch 035 - training loss: 0.3842, validation loss: 0.5360
2024-06-02 16:42:01 [INFO]: Epoch 036 - training loss: 0.3836, validation loss: 0.5341
2024-06-02 16:42:11 [INFO]: Epoch 037 - training loss: 0.3836, validation loss: 0.5166
2024-06-02 16:42:22 [INFO]: Epoch 038 - training loss: 0.3828, validation loss: 0.5086
2024-06-02 16:42:33 [INFO]: Epoch 039 - training loss: 0.3824, validation loss: 0.5053
2024-06-02 16:42:43 [INFO]: Epoch 040 - training loss: 0.3823, validation loss: 0.5110
2024-06-02 16:42:54 [INFO]: Epoch 041 - training loss: 0.3815, validation loss: 0.4984
2024-06-02 16:43:05 [INFO]: Epoch 042 - training loss: 0.3806, validation loss: 0.4946
2024-06-02 16:43:15 [INFO]: Epoch 043 - training loss: 0.3801, validation loss: 0.4932
2024-06-02 16:43:26 [INFO]: Epoch 044 - training loss: 0.3794, validation loss: 0.4892
2024-06-02 16:43:37 [INFO]: Epoch 045 - training loss: 0.3796, validation loss: 0.4867
2024-06-02 16:43:47 [INFO]: Epoch 046 - training loss: 0.3801, validation loss: 0.4853
2024-06-02 16:43:58 [INFO]: Epoch 047 - training loss: 0.3793, validation loss: 0.4852
2024-06-02 16:44:09 [INFO]: Epoch 048 - training loss: 0.3800, validation loss: 0.4774
2024-06-02 16:44:19 [INFO]: Epoch 049 - training loss: 0.3799, validation loss: 0.4761
2024-06-02 16:44:30 [INFO]: Epoch 050 - training loss: 0.3792, validation loss: 0.4757
2024-06-02 16:44:41 [INFO]: Epoch 051 - training loss: 0.3782, validation loss: 0.4688
2024-06-02 16:44:51 [INFO]: Epoch 052 - training loss: 0.3792, validation loss: 0.4798
2024-06-02 16:45:02 [INFO]: Epoch 053 - training loss: 0.3783, validation loss: 0.4751
2024-06-02 16:45:13 [INFO]: Epoch 054 - training loss: 0.3785, validation loss: 0.4782
2024-06-02 16:45:23 [INFO]: Epoch 055 - training loss: 0.3775, validation loss: 0.4693
2024-06-02 16:45:34 [INFO]: Epoch 056 - training loss: 0.3779, validation loss: 0.4648
2024-06-02 16:45:45 [INFO]: Epoch 057 - training loss: 0.3779, validation loss: 0.4573
2024-06-02 16:45:55 [INFO]: Epoch 058 - training loss: 0.3770, validation loss: 0.4684
2024-06-02 16:46:06 [INFO]: Epoch 059 - training loss: 0.3773, validation loss: 0.4657
2024-06-02 16:46:17 [INFO]: Epoch 060 - training loss: 0.3767, validation loss: 0.4598
2024-06-02 16:46:27 [INFO]: Epoch 061 - training loss: 0.3768, validation loss: 0.4609
2024-06-02 16:46:38 [INFO]: Epoch 062 - training loss: 0.3764, validation loss: 0.4600
2024-06-02 16:46:48 [INFO]: Epoch 063 - training loss: 0.3771, validation loss: 0.4580
2024-06-02 16:46:59 [INFO]: Epoch 064 - training loss: 0.3773, validation loss: 0.4600
2024-06-02 16:47:10 [INFO]: Epoch 065 - training loss: 0.3761, validation loss: 0.4524
2024-06-02 16:47:20 [INFO]: Epoch 066 - training loss: 0.3763, validation loss: 0.4526
2024-06-02 16:47:31 [INFO]: Epoch 067 - training loss: 0.3764, validation loss: 0.4547
2024-06-02 16:47:42 [INFO]: Epoch 068 - training loss: 0.3757, validation loss: 0.4511
2024-06-02 16:47:52 [INFO]: Epoch 069 - training loss: 0.3762, validation loss: 0.4472
2024-06-02 16:48:03 [INFO]: Epoch 070 - training loss: 0.3761, validation loss: 0.4487
2024-06-02 16:48:14 [INFO]: Epoch 071 - training loss: 0.3758, validation loss: 0.4438
2024-06-02 16:48:24 [INFO]: Epoch 072 - training loss: 0.3757, validation loss: 0.4440
2024-06-02 16:48:35 [INFO]: Epoch 073 - training loss: 0.3758, validation loss: 0.4465
2024-06-02 16:48:46 [INFO]: Epoch 074 - training loss: 0.3751, validation loss: 0.4428
2024-06-02 16:48:56 [INFO]: Epoch 075 - training loss: 0.3758, validation loss: 0.4511
2024-06-02 16:49:07 [INFO]: Epoch 076 - training loss: 0.3760, validation loss: 0.4571
2024-06-02 16:49:18 [INFO]: Epoch 077 - training loss: 0.3749, validation loss: 0.4561
2024-06-02 16:49:28 [INFO]: Epoch 078 - training loss: 0.3751, validation loss: 0.4518
2024-06-02 16:49:39 [INFO]: Epoch 079 - training loss: 0.3748, validation loss: 0.4520
2024-06-02 16:49:50 [INFO]: Epoch 080 - training loss: 0.3748, validation loss: 0.4495
2024-06-02 16:50:00 [INFO]: Epoch 081 - training loss: 0.3754, validation loss: 0.4451
2024-06-02 16:50:11 [INFO]: Epoch 082 - training loss: 0.3752, validation loss: 0.4512
2024-06-02 16:50:22 [INFO]: Epoch 083 - training loss: 0.3753, validation loss: 0.4450
2024-06-02 16:50:32 [INFO]: Epoch 084 - training loss: 0.3744, validation loss: 0.4438
2024-06-02 16:50:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 16:50:32 [INFO]: Finished training. The best model is from epoch#74.
2024-06-02 16:50:35 [INFO]: Saved the model to results_point_rate01/Electricity/SCINet_Electricity/round_4/20240602_T163533/SCINet.pypots
2024-06-02 16:50:36 [INFO]: Successfully saved to results_point_rate01/Electricity/SCINet_Electricity/round_4/imputation.pkl
2024-06-02 16:50:36 [INFO]: Round4 - SCINet on Electricity: MAE=0.5939, MSE=0.5875, MRE=0.3177
2024-06-02 16:50:36 [INFO]: Done! Final results:
Averaged SCINet (421,053,386 params) on Electricity: MAE=0.5813 ± 0.01492380911189033, MSE=0.5792 ± 0.02940860195995254, MRE=0.3110 ± 0.00798354287039151, average inference time=1.10
