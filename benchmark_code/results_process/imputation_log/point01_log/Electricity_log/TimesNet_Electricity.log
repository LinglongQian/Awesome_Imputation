2024-06-02 17:15:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 17:15:47 [INFO]: Using the given device: cuda:0
2024-06-02 17:15:47 [INFO]: Model files will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_0/20240602_T171547
2024-06-02 17:15:47 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_0/20240602_T171547/tensorboard
2024-06-02 17:15:48 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-02 17:15:56 [INFO]: Epoch 001 - training loss: 0.5696, validation loss: 2.9690
2024-06-02 17:16:01 [INFO]: Epoch 002 - training loss: 0.2814, validation loss: 2.8017
2024-06-02 17:16:06 [INFO]: Epoch 003 - training loss: 0.2313, validation loss: 2.7073
2024-06-02 17:16:11 [INFO]: Epoch 004 - training loss: 0.2095, validation loss: 2.6454
2024-06-02 17:16:16 [INFO]: Epoch 005 - training loss: 0.1951, validation loss: 2.6021
2024-06-02 17:16:21 [INFO]: Epoch 006 - training loss: 0.1846, validation loss: 2.5688
2024-06-02 17:16:26 [INFO]: Epoch 007 - training loss: 0.1765, validation loss: 2.5322
2024-06-02 17:16:30 [INFO]: Epoch 008 - training loss: 0.1706, validation loss: 2.5110
2024-06-02 17:16:36 [INFO]: Epoch 009 - training loss: 0.1652, validation loss: 2.4819
2024-06-02 17:16:40 [INFO]: Epoch 010 - training loss: 0.1615, validation loss: 2.4655
2024-06-02 17:16:45 [INFO]: Epoch 011 - training loss: 0.1571, validation loss: 2.4428
2024-06-02 17:16:51 [INFO]: Epoch 012 - training loss: 0.1537, validation loss: 2.4264
2024-06-02 17:16:55 [INFO]: Epoch 013 - training loss: 0.1510, validation loss: 2.4114
2024-06-02 17:17:00 [INFO]: Epoch 014 - training loss: 0.1475, validation loss: 2.3931
2024-06-02 17:17:05 [INFO]: Epoch 015 - training loss: 0.1459, validation loss: 2.3773
2024-06-02 17:17:10 [INFO]: Epoch 016 - training loss: 0.1428, validation loss: 2.3620
2024-06-02 17:17:15 [INFO]: Epoch 017 - training loss: 0.1405, validation loss: 2.3464
2024-06-02 17:17:20 [INFO]: Epoch 018 - training loss: 0.1382, validation loss: 2.3295
2024-06-02 17:17:25 [INFO]: Epoch 019 - training loss: 0.1361, validation loss: 2.3146
2024-06-02 17:17:30 [INFO]: Epoch 020 - training loss: 0.1339, validation loss: 2.3000
2024-06-02 17:17:35 [INFO]: Epoch 021 - training loss: 0.1322, validation loss: 2.2878
2024-06-02 17:17:39 [INFO]: Epoch 022 - training loss: 0.1303, validation loss: 2.2759
2024-06-02 17:17:44 [INFO]: Epoch 023 - training loss: 0.1293, validation loss: 2.2635
2024-06-02 17:17:49 [INFO]: Epoch 024 - training loss: 0.1278, validation loss: 2.2567
2024-06-02 17:17:54 [INFO]: Epoch 025 - training loss: 0.1263, validation loss: 2.2440
2024-06-02 17:17:59 [INFO]: Epoch 026 - training loss: 0.1249, validation loss: 2.2316
2024-06-02 17:18:04 [INFO]: Epoch 027 - training loss: 0.1232, validation loss: 2.2188
2024-06-02 17:18:08 [INFO]: Epoch 028 - training loss: 0.1224, validation loss: 2.2123
2024-06-02 17:18:14 [INFO]: Epoch 029 - training loss: 0.1210, validation loss: 2.1965
2024-06-02 17:18:18 [INFO]: Epoch 030 - training loss: 0.1197, validation loss: 2.1920
2024-06-02 17:18:23 [INFO]: Epoch 031 - training loss: 0.1192, validation loss: 2.1762
2024-06-02 17:18:28 [INFO]: Epoch 032 - training loss: 0.1182, validation loss: 2.1644
2024-06-02 17:18:34 [INFO]: Epoch 033 - training loss: 0.1171, validation loss: 2.1564
2024-06-02 17:18:38 [INFO]: Epoch 034 - training loss: 0.1158, validation loss: 2.1470
2024-06-02 17:18:43 [INFO]: Epoch 035 - training loss: 0.1144, validation loss: 2.1343
2024-06-02 17:18:48 [INFO]: Epoch 036 - training loss: 0.1139, validation loss: 2.1284
2024-06-02 17:18:53 [INFO]: Epoch 037 - training loss: 0.1136, validation loss: 2.1215
2024-06-02 17:18:58 [INFO]: Epoch 038 - training loss: 0.1120, validation loss: 2.1145
2024-06-02 17:19:03 [INFO]: Epoch 039 - training loss: 0.1119, validation loss: 2.1025
2024-06-02 17:19:08 [INFO]: Epoch 040 - training loss: 0.1106, validation loss: 2.0921
2024-06-02 17:19:13 [INFO]: Epoch 041 - training loss: 0.1098, validation loss: 2.0869
2024-06-02 17:19:18 [INFO]: Epoch 042 - training loss: 0.1097, validation loss: 2.0804
2024-06-02 17:19:23 [INFO]: Epoch 043 - training loss: 0.1084, validation loss: 2.0716
2024-06-02 17:19:28 [INFO]: Epoch 044 - training loss: 0.1084, validation loss: 2.0570
2024-06-02 17:19:33 [INFO]: Epoch 045 - training loss: 0.1073, validation loss: 2.0529
2024-06-02 17:19:38 [INFO]: Epoch 046 - training loss: 0.1065, validation loss: 2.0431
2024-06-02 17:19:42 [INFO]: Epoch 047 - training loss: 0.1063, validation loss: 2.0395
2024-06-02 17:19:47 [INFO]: Epoch 048 - training loss: 0.1056, validation loss: 2.0291
2024-06-02 17:19:52 [INFO]: Epoch 049 - training loss: 0.1053, validation loss: 2.0233
2024-06-02 17:19:57 [INFO]: Epoch 050 - training loss: 0.1044, validation loss: 2.0143
2024-06-02 17:20:02 [INFO]: Epoch 051 - training loss: 0.1037, validation loss: 2.0107
2024-06-02 17:20:07 [INFO]: Epoch 052 - training loss: 0.1032, validation loss: 2.0027
2024-06-02 17:20:11 [INFO]: Epoch 053 - training loss: 0.1030, validation loss: 1.9972
2024-06-02 17:20:16 [INFO]: Epoch 054 - training loss: 0.1025, validation loss: 1.9868
2024-06-02 17:20:21 [INFO]: Epoch 055 - training loss: 0.1019, validation loss: 1.9846
2024-06-02 17:20:26 [INFO]: Epoch 056 - training loss: 0.1018, validation loss: 1.9761
2024-06-02 17:20:31 [INFO]: Epoch 057 - training loss: 0.1010, validation loss: 1.9723
2024-06-02 17:20:36 [INFO]: Epoch 058 - training loss: 0.1007, validation loss: 1.9674
2024-06-02 17:20:41 [INFO]: Epoch 059 - training loss: 0.1001, validation loss: 1.9623
2024-06-02 17:20:45 [INFO]: Epoch 060 - training loss: 0.0995, validation loss: 1.9608
2024-06-02 17:20:50 [INFO]: Epoch 061 - training loss: 0.0994, validation loss: 1.9511
2024-06-02 17:20:55 [INFO]: Epoch 062 - training loss: 0.0992, validation loss: 1.9474
2024-06-02 17:21:00 [INFO]: Epoch 063 - training loss: 0.0991, validation loss: 1.9394
2024-06-02 17:21:05 [INFO]: Epoch 064 - training loss: 0.0977, validation loss: 1.9371
2024-06-02 17:21:10 [INFO]: Epoch 065 - training loss: 0.0980, validation loss: 1.9355
2024-06-02 17:21:15 [INFO]: Epoch 066 - training loss: 0.0973, validation loss: 1.9273
2024-06-02 17:21:20 [INFO]: Epoch 067 - training loss: 0.0974, validation loss: 1.9236
2024-06-02 17:21:25 [INFO]: Epoch 068 - training loss: 0.0966, validation loss: 1.9232
2024-06-02 17:21:30 [INFO]: Epoch 069 - training loss: 0.0961, validation loss: 1.9180
2024-06-02 17:21:35 [INFO]: Epoch 070 - training loss: 0.0964, validation loss: 1.9144
2024-06-02 17:21:40 [INFO]: Epoch 071 - training loss: 0.0962, validation loss: 1.9158
2024-06-02 17:21:45 [INFO]: Epoch 072 - training loss: 0.0956, validation loss: 1.9095
2024-06-02 17:21:50 [INFO]: Epoch 073 - training loss: 0.0950, validation loss: 1.9069
2024-06-02 17:21:55 [INFO]: Epoch 074 - training loss: 0.0948, validation loss: 1.9031
2024-06-02 17:22:00 [INFO]: Epoch 075 - training loss: 0.0946, validation loss: 1.8981
2024-06-02 17:22:04 [INFO]: Epoch 076 - training loss: 0.0945, validation loss: 1.8949
2024-06-02 17:22:09 [INFO]: Epoch 077 - training loss: 0.0941, validation loss: 1.8935
2024-06-02 17:22:14 [INFO]: Epoch 078 - training loss: 0.0939, validation loss: 1.8885
2024-06-02 17:22:19 [INFO]: Epoch 079 - training loss: 0.0936, validation loss: 1.8862
2024-06-02 17:22:24 [INFO]: Epoch 080 - training loss: 0.0931, validation loss: 1.8834
2024-06-02 17:22:29 [INFO]: Epoch 081 - training loss: 0.0927, validation loss: 1.8821
2024-06-02 17:22:34 [INFO]: Epoch 082 - training loss: 0.0930, validation loss: 1.8768
2024-06-02 17:22:39 [INFO]: Epoch 083 - training loss: 0.0927, validation loss: 1.8789
2024-06-02 17:22:44 [INFO]: Epoch 084 - training loss: 0.0923, validation loss: 1.8718
2024-06-02 17:22:49 [INFO]: Epoch 085 - training loss: 0.0922, validation loss: 1.8694
2024-06-02 17:22:54 [INFO]: Epoch 086 - training loss: 0.0922, validation loss: 1.8668
2024-06-02 17:22:58 [INFO]: Epoch 087 - training loss: 0.0915, validation loss: 1.8680
2024-06-02 17:23:03 [INFO]: Epoch 088 - training loss: 0.0920, validation loss: 1.8615
2024-06-02 17:23:08 [INFO]: Epoch 089 - training loss: 0.0918, validation loss: 1.8590
2024-06-02 17:23:13 [INFO]: Epoch 090 - training loss: 0.0910, validation loss: 1.8597
2024-06-02 17:23:18 [INFO]: Epoch 091 - training loss: 0.0907, validation loss: 1.8577
2024-06-02 17:23:22 [INFO]: Epoch 092 - training loss: 0.0904, validation loss: 1.8484
2024-06-02 17:23:27 [INFO]: Epoch 093 - training loss: 0.0903, validation loss: 1.8500
2024-06-02 17:23:32 [INFO]: Epoch 094 - training loss: 0.0903, validation loss: 1.8448
2024-06-02 17:23:37 [INFO]: Epoch 095 - training loss: 0.0900, validation loss: 1.8452
2024-06-02 17:23:42 [INFO]: Epoch 096 - training loss: 0.0898, validation loss: 1.8437
2024-06-02 17:23:47 [INFO]: Epoch 097 - training loss: 0.0897, validation loss: 1.8370
2024-06-02 17:23:52 [INFO]: Epoch 098 - training loss: 0.0891, validation loss: 1.8420
2024-06-02 17:23:57 [INFO]: Epoch 099 - training loss: 0.0895, validation loss: 1.8363
2024-06-02 17:24:02 [INFO]: Epoch 100 - training loss: 0.0892, validation loss: 1.8418
2024-06-02 17:24:02 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 17:24:02 [INFO]: Saved the model to results_point_rate01/Electricity/TimesNet_Electricity/round_0/20240602_T171547/TimesNet.pypots
2024-06-02 17:24:03 [INFO]: Successfully saved to results_point_rate01/Electricity/TimesNet_Electricity/round_0/imputation.pkl
2024-06-02 17:24:03 [INFO]: Round0 - TimesNet on Electricity: MAE=1.0236, MSE=2.0734, MRE=0.5476
2024-06-02 17:24:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 17:24:03 [INFO]: Using the given device: cuda:0
2024-06-02 17:24:04 [INFO]: Model files will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_1/20240602_T172403
2024-06-02 17:24:04 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_1/20240602_T172403/tensorboard
2024-06-02 17:24:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-02 17:24:10 [INFO]: Epoch 001 - training loss: 0.5732, validation loss: 2.9788
2024-06-02 17:24:15 [INFO]: Epoch 002 - training loss: 0.2777, validation loss: 2.8061
2024-06-02 17:24:20 [INFO]: Epoch 003 - training loss: 0.2280, validation loss: 2.7083
2024-06-02 17:24:25 [INFO]: Epoch 004 - training loss: 0.2063, validation loss: 2.6454
2024-06-02 17:24:30 [INFO]: Epoch 005 - training loss: 0.1933, validation loss: 2.6091
2024-06-02 17:24:35 [INFO]: Epoch 006 - training loss: 0.1849, validation loss: 2.5780
2024-06-02 17:24:40 [INFO]: Epoch 007 - training loss: 0.1758, validation loss: 2.5404
2024-06-02 17:24:45 [INFO]: Epoch 008 - training loss: 0.1706, validation loss: 2.5117
2024-06-02 17:24:50 [INFO]: Epoch 009 - training loss: 0.1652, validation loss: 2.4937
2024-06-02 17:24:55 [INFO]: Epoch 010 - training loss: 0.1608, validation loss: 2.4732
2024-06-02 17:25:00 [INFO]: Epoch 011 - training loss: 0.1572, validation loss: 2.4534
2024-06-02 17:25:04 [INFO]: Epoch 012 - training loss: 0.1536, validation loss: 2.4274
2024-06-02 17:25:09 [INFO]: Epoch 013 - training loss: 0.1508, validation loss: 2.4055
2024-06-02 17:25:14 [INFO]: Epoch 014 - training loss: 0.1480, validation loss: 2.3938
2024-06-02 17:25:19 [INFO]: Epoch 015 - training loss: 0.1452, validation loss: 2.3743
2024-06-02 17:25:24 [INFO]: Epoch 016 - training loss: 0.1432, validation loss: 2.3552
2024-06-02 17:25:29 [INFO]: Epoch 017 - training loss: 0.1410, validation loss: 2.3409
2024-06-02 17:25:34 [INFO]: Epoch 018 - training loss: 0.1387, validation loss: 2.3264
2024-06-02 17:25:39 [INFO]: Epoch 019 - training loss: 0.1367, validation loss: 2.3094
2024-06-02 17:25:44 [INFO]: Epoch 020 - training loss: 0.1347, validation loss: 2.2951
2024-06-02 17:25:49 [INFO]: Epoch 021 - training loss: 0.1328, validation loss: 2.2771
2024-06-02 17:25:54 [INFO]: Epoch 022 - training loss: 0.1312, validation loss: 2.2680
2024-06-02 17:25:59 [INFO]: Epoch 023 - training loss: 0.1296, validation loss: 2.2508
2024-06-02 17:26:03 [INFO]: Epoch 024 - training loss: 0.1275, validation loss: 2.2379
2024-06-02 17:26:08 [INFO]: Epoch 025 - training loss: 0.1263, validation loss: 2.2279
2024-06-02 17:26:13 [INFO]: Epoch 026 - training loss: 0.1252, validation loss: 2.2132
2024-06-02 17:26:18 [INFO]: Epoch 027 - training loss: 0.1239, validation loss: 2.2005
2024-06-02 17:26:23 [INFO]: Epoch 028 - training loss: 0.1229, validation loss: 2.1909
2024-06-02 17:26:28 [INFO]: Epoch 029 - training loss: 0.1214, validation loss: 2.1778
2024-06-02 17:26:33 [INFO]: Epoch 030 - training loss: 0.1204, validation loss: 2.1660
2024-06-02 17:26:37 [INFO]: Epoch 031 - training loss: 0.1192, validation loss: 2.1555
2024-06-02 17:26:42 [INFO]: Epoch 032 - training loss: 0.1181, validation loss: 2.1476
2024-06-02 17:26:47 [INFO]: Epoch 033 - training loss: 0.1170, validation loss: 2.1373
2024-06-02 17:26:52 [INFO]: Epoch 034 - training loss: 0.1161, validation loss: 2.1226
2024-06-02 17:26:57 [INFO]: Epoch 035 - training loss: 0.1150, validation loss: 2.1127
2024-06-02 17:27:02 [INFO]: Epoch 036 - training loss: 0.1142, validation loss: 2.1016
2024-06-02 17:27:06 [INFO]: Epoch 037 - training loss: 0.1133, validation loss: 2.0956
2024-06-02 17:27:11 [INFO]: Epoch 038 - training loss: 0.1123, validation loss: 2.0889
2024-06-02 17:27:15 [INFO]: Epoch 039 - training loss: 0.1119, validation loss: 2.0800
2024-06-02 17:27:19 [INFO]: Epoch 040 - training loss: 0.1110, validation loss: 2.0676
2024-06-02 17:27:24 [INFO]: Epoch 041 - training loss: 0.1102, validation loss: 2.0600
2024-06-02 17:27:28 [INFO]: Epoch 042 - training loss: 0.1095, validation loss: 2.0530
2024-06-02 17:27:33 [INFO]: Epoch 043 - training loss: 0.1087, validation loss: 2.0441
2024-06-02 17:27:38 [INFO]: Epoch 044 - training loss: 0.1086, validation loss: 2.0366
2024-06-02 17:27:43 [INFO]: Epoch 045 - training loss: 0.1073, validation loss: 2.0318
2024-06-02 17:27:48 [INFO]: Epoch 046 - training loss: 0.1076, validation loss: 2.0229
2024-06-02 17:27:53 [INFO]: Epoch 047 - training loss: 0.1066, validation loss: 2.0130
2024-06-02 17:27:58 [INFO]: Epoch 048 - training loss: 0.1054, validation loss: 2.0064
2024-06-02 17:28:04 [INFO]: Epoch 049 - training loss: 0.1054, validation loss: 2.0045
2024-06-02 17:28:08 [INFO]: Epoch 050 - training loss: 0.1046, validation loss: 1.9995
2024-06-02 17:28:13 [INFO]: Epoch 051 - training loss: 0.1043, validation loss: 1.9935
2024-06-02 17:28:18 [INFO]: Epoch 052 - training loss: 0.1038, validation loss: 1.9859
2024-06-02 17:28:23 [INFO]: Epoch 053 - training loss: 0.1033, validation loss: 1.9777
2024-06-02 17:28:28 [INFO]: Epoch 054 - training loss: 0.1028, validation loss: 1.9754
2024-06-02 17:28:33 [INFO]: Epoch 055 - training loss: 0.1024, validation loss: 1.9700
2024-06-02 17:28:38 [INFO]: Epoch 056 - training loss: 0.1013, validation loss: 1.9635
2024-06-02 17:28:43 [INFO]: Epoch 057 - training loss: 0.1012, validation loss: 1.9578
2024-06-02 17:28:48 [INFO]: Epoch 058 - training loss: 0.1007, validation loss: 1.9515
2024-06-02 17:28:53 [INFO]: Epoch 059 - training loss: 0.1004, validation loss: 1.9448
2024-06-02 17:28:58 [INFO]: Epoch 060 - training loss: 0.1002, validation loss: 1.9381
2024-06-02 17:29:03 [INFO]: Epoch 061 - training loss: 0.0998, validation loss: 1.9307
2024-06-02 17:29:08 [INFO]: Epoch 062 - training loss: 0.0993, validation loss: 1.9247
2024-06-02 17:29:13 [INFO]: Epoch 063 - training loss: 0.0983, validation loss: 1.9166
2024-06-02 17:29:18 [INFO]: Epoch 064 - training loss: 0.0985, validation loss: 1.9143
2024-06-02 17:29:23 [INFO]: Epoch 065 - training loss: 0.0982, validation loss: 1.9133
2024-06-02 17:29:28 [INFO]: Epoch 066 - training loss: 0.0974, validation loss: 1.9122
2024-06-02 17:29:33 [INFO]: Epoch 067 - training loss: 0.0976, validation loss: 1.9060
2024-06-02 17:29:37 [INFO]: Epoch 068 - training loss: 0.0973, validation loss: 1.9013
2024-06-02 17:29:42 [INFO]: Epoch 069 - training loss: 0.0970, validation loss: 1.9025
2024-06-02 17:29:47 [INFO]: Epoch 070 - training loss: 0.0966, validation loss: 1.9011
2024-06-02 17:29:52 [INFO]: Epoch 071 - training loss: 0.0959, validation loss: 1.8951
2024-06-02 17:29:57 [INFO]: Epoch 072 - training loss: 0.0955, validation loss: 1.8861
2024-06-02 17:30:02 [INFO]: Epoch 073 - training loss: 0.0954, validation loss: 1.8864
2024-06-02 17:30:07 [INFO]: Epoch 074 - training loss: 0.0951, validation loss: 1.8780
2024-06-02 17:30:12 [INFO]: Epoch 075 - training loss: 0.0951, validation loss: 1.8792
2024-06-02 17:30:17 [INFO]: Epoch 076 - training loss: 0.0946, validation loss: 1.8736
2024-06-02 17:30:22 [INFO]: Epoch 077 - training loss: 0.0940, validation loss: 1.8730
2024-06-02 17:30:26 [INFO]: Epoch 078 - training loss: 0.0944, validation loss: 1.8666
2024-06-02 17:30:31 [INFO]: Epoch 079 - training loss: 0.0940, validation loss: 1.8647
2024-06-02 17:30:36 [INFO]: Epoch 080 - training loss: 0.0932, validation loss: 1.8593
2024-06-02 17:30:41 [INFO]: Epoch 081 - training loss: 0.0932, validation loss: 1.8573
2024-06-02 17:30:46 [INFO]: Epoch 082 - training loss: 0.0935, validation loss: 1.8580
2024-06-02 17:30:51 [INFO]: Epoch 083 - training loss: 0.0927, validation loss: 1.8492
2024-06-02 17:30:56 [INFO]: Epoch 084 - training loss: 0.0926, validation loss: 1.8527
2024-06-02 17:31:01 [INFO]: Epoch 085 - training loss: 0.0923, validation loss: 1.8487
2024-06-02 17:31:06 [INFO]: Epoch 086 - training loss: 0.0924, validation loss: 1.8475
2024-06-02 17:31:11 [INFO]: Epoch 087 - training loss: 0.0922, validation loss: 1.8428
2024-06-02 17:31:16 [INFO]: Epoch 088 - training loss: 0.0915, validation loss: 1.8449
2024-06-02 17:31:21 [INFO]: Epoch 089 - training loss: 0.0911, validation loss: 1.8389
2024-06-02 17:31:26 [INFO]: Epoch 090 - training loss: 0.0914, validation loss: 1.8347
2024-06-02 17:31:31 [INFO]: Epoch 091 - training loss: 0.0913, validation loss: 1.8336
2024-06-02 17:31:36 [INFO]: Epoch 092 - training loss: 0.0906, validation loss: 1.8350
2024-06-02 17:31:41 [INFO]: Epoch 093 - training loss: 0.0904, validation loss: 1.8310
2024-06-02 17:31:46 [INFO]: Epoch 094 - training loss: 0.0906, validation loss: 1.8326
2024-06-02 17:31:51 [INFO]: Epoch 095 - training loss: 0.0904, validation loss: 1.8365
2024-06-02 17:31:55 [INFO]: Epoch 096 - training loss: 0.0898, validation loss: 1.8316
2024-06-02 17:32:00 [INFO]: Epoch 097 - training loss: 0.0899, validation loss: 1.8295
2024-06-02 17:32:05 [INFO]: Epoch 098 - training loss: 0.0896, validation loss: 1.8290
2024-06-02 17:32:10 [INFO]: Epoch 099 - training loss: 0.0896, validation loss: 1.8265
2024-06-02 17:32:15 [INFO]: Epoch 100 - training loss: 0.0894, validation loss: 1.8248
2024-06-02 17:32:15 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 17:32:16 [INFO]: Saved the model to results_point_rate01/Electricity/TimesNet_Electricity/round_1/20240602_T172403/TimesNet.pypots
2024-06-02 17:32:17 [INFO]: Successfully saved to results_point_rate01/Electricity/TimesNet_Electricity/round_1/imputation.pkl
2024-06-02 17:32:17 [INFO]: Round1 - TimesNet on Electricity: MAE=0.9871, MSE=1.9201, MRE=0.5281
2024-06-02 17:32:17 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 17:32:17 [INFO]: Using the given device: cuda:0
2024-06-02 17:32:17 [INFO]: Model files will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_2/20240602_T173217
2024-06-02 17:32:17 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_2/20240602_T173217/tensorboard
2024-06-02 17:32:17 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-02 17:32:23 [INFO]: Epoch 001 - training loss: 0.5609, validation loss: 3.0035
2024-06-02 17:32:27 [INFO]: Epoch 002 - training loss: 0.2778, validation loss: 2.8158
2024-06-02 17:32:32 [INFO]: Epoch 003 - training loss: 0.2290, validation loss: 2.7175
2024-06-02 17:32:37 [INFO]: Epoch 004 - training loss: 0.2081, validation loss: 2.6501
2024-06-02 17:32:42 [INFO]: Epoch 005 - training loss: 0.1951, validation loss: 2.6048
2024-06-02 17:32:48 [INFO]: Epoch 006 - training loss: 0.1846, validation loss: 2.5638
2024-06-02 17:32:52 [INFO]: Epoch 007 - training loss: 0.1768, validation loss: 2.5300
2024-06-02 17:32:57 [INFO]: Epoch 008 - training loss: 0.1707, validation loss: 2.5010
2024-06-02 17:33:02 [INFO]: Epoch 009 - training loss: 0.1660, validation loss: 2.4787
2024-06-02 17:33:07 [INFO]: Epoch 010 - training loss: 0.1609, validation loss: 2.4543
2024-06-02 17:33:12 [INFO]: Epoch 011 - training loss: 0.1570, validation loss: 2.4340
2024-06-02 17:33:17 [INFO]: Epoch 012 - training loss: 0.1541, validation loss: 2.4081
2024-06-02 17:33:22 [INFO]: Epoch 013 - training loss: 0.1505, validation loss: 2.4002
2024-06-02 17:33:27 [INFO]: Epoch 014 - training loss: 0.1478, validation loss: 2.3807
2024-06-02 17:33:32 [INFO]: Epoch 015 - training loss: 0.1451, validation loss: 2.3640
2024-06-02 17:33:37 [INFO]: Epoch 016 - training loss: 0.1426, validation loss: 2.3533
2024-06-02 17:33:41 [INFO]: Epoch 017 - training loss: 0.1406, validation loss: 2.3396
2024-06-02 17:33:46 [INFO]: Epoch 018 - training loss: 0.1375, validation loss: 2.3236
2024-06-02 17:33:51 [INFO]: Epoch 019 - training loss: 0.1361, validation loss: 2.3104
2024-06-02 17:33:56 [INFO]: Epoch 020 - training loss: 0.1344, validation loss: 2.2993
2024-06-02 17:34:01 [INFO]: Epoch 021 - training loss: 0.1328, validation loss: 2.2841
2024-06-02 17:34:06 [INFO]: Epoch 022 - training loss: 0.1311, validation loss: 2.2751
2024-06-02 17:34:11 [INFO]: Epoch 023 - training loss: 0.1295, validation loss: 2.2589
2024-06-02 17:34:16 [INFO]: Epoch 024 - training loss: 0.1276, validation loss: 2.2490
2024-06-02 17:34:21 [INFO]: Epoch 025 - training loss: 0.1260, validation loss: 2.2355
2024-06-02 17:34:26 [INFO]: Epoch 026 - training loss: 0.1245, validation loss: 2.2241
2024-06-02 17:34:31 [INFO]: Epoch 027 - training loss: 0.1237, validation loss: 2.2213
2024-06-02 17:34:36 [INFO]: Epoch 028 - training loss: 0.1222, validation loss: 2.2062
2024-06-02 17:34:41 [INFO]: Epoch 029 - training loss: 0.1210, validation loss: 2.1967
2024-06-02 17:34:45 [INFO]: Epoch 030 - training loss: 0.1204, validation loss: 2.1843
2024-06-02 17:34:51 [INFO]: Epoch 031 - training loss: 0.1185, validation loss: 2.1741
2024-06-02 17:34:55 [INFO]: Epoch 032 - training loss: 0.1183, validation loss: 2.1684
2024-06-02 17:35:00 [INFO]: Epoch 033 - training loss: 0.1168, validation loss: 2.1559
2024-06-02 17:35:05 [INFO]: Epoch 034 - training loss: 0.1156, validation loss: 2.1377
2024-06-02 17:35:08 [INFO]: Epoch 035 - training loss: 0.1157, validation loss: 2.1340
2024-06-02 17:35:13 [INFO]: Epoch 036 - training loss: 0.1146, validation loss: 2.1217
2024-06-02 17:35:18 [INFO]: Epoch 037 - training loss: 0.1135, validation loss: 2.1162
2024-06-02 17:35:23 [INFO]: Epoch 038 - training loss: 0.1125, validation loss: 2.1052
2024-06-02 17:35:28 [INFO]: Epoch 039 - training loss: 0.1117, validation loss: 2.0923
2024-06-02 17:35:33 [INFO]: Epoch 040 - training loss: 0.1109, validation loss: 2.0917
2024-06-02 17:35:38 [INFO]: Epoch 041 - training loss: 0.1100, validation loss: 2.0785
2024-06-02 17:35:43 [INFO]: Epoch 042 - training loss: 0.1094, validation loss: 2.0704
2024-06-02 17:35:48 [INFO]: Epoch 043 - training loss: 0.1087, validation loss: 2.0677
2024-06-02 17:35:53 [INFO]: Epoch 044 - training loss: 0.1084, validation loss: 2.0565
2024-06-02 17:35:58 [INFO]: Epoch 045 - training loss: 0.1072, validation loss: 2.0526
2024-06-02 17:36:03 [INFO]: Epoch 046 - training loss: 0.1070, validation loss: 2.0449
2024-06-02 17:36:08 [INFO]: Epoch 047 - training loss: 0.1063, validation loss: 2.0382
2024-06-02 17:36:13 [INFO]: Epoch 048 - training loss: 0.1054, validation loss: 2.0320
2024-06-02 17:36:18 [INFO]: Epoch 049 - training loss: 0.1049, validation loss: 2.0201
2024-06-02 17:36:22 [INFO]: Epoch 050 - training loss: 0.1045, validation loss: 2.0168
2024-06-02 17:36:28 [INFO]: Epoch 051 - training loss: 0.1040, validation loss: 2.0128
2024-06-02 17:36:32 [INFO]: Epoch 052 - training loss: 0.1034, validation loss: 2.0023
2024-06-02 17:36:37 [INFO]: Epoch 053 - training loss: 0.1027, validation loss: 1.9959
2024-06-02 17:36:42 [INFO]: Epoch 054 - training loss: 0.1026, validation loss: 1.9926
2024-06-02 17:36:47 [INFO]: Epoch 055 - training loss: 0.1021, validation loss: 1.9815
2024-06-02 17:36:52 [INFO]: Epoch 056 - training loss: 0.1017, validation loss: 1.9793
2024-06-02 17:36:57 [INFO]: Epoch 057 - training loss: 0.1011, validation loss: 1.9723
2024-06-02 17:37:02 [INFO]: Epoch 058 - training loss: 0.1009, validation loss: 1.9662
2024-06-02 17:37:07 [INFO]: Epoch 059 - training loss: 0.1002, validation loss: 1.9684
2024-06-02 17:37:12 [INFO]: Epoch 060 - training loss: 0.0998, validation loss: 1.9646
2024-06-02 17:37:17 [INFO]: Epoch 061 - training loss: 0.0992, validation loss: 1.9564
2024-06-02 17:37:22 [INFO]: Epoch 062 - training loss: 0.0988, validation loss: 1.9499
2024-06-02 17:37:27 [INFO]: Epoch 063 - training loss: 0.0986, validation loss: 1.9436
2024-06-02 17:37:32 [INFO]: Epoch 064 - training loss: 0.0979, validation loss: 1.9400
2024-06-02 17:37:36 [INFO]: Epoch 065 - training loss: 0.0982, validation loss: 1.9371
2024-06-02 17:37:41 [INFO]: Epoch 066 - training loss: 0.0974, validation loss: 1.9326
2024-06-02 17:37:46 [INFO]: Epoch 067 - training loss: 0.0974, validation loss: 1.9285
2024-06-02 17:37:51 [INFO]: Epoch 068 - training loss: 0.0968, validation loss: 1.9234
2024-06-02 17:37:56 [INFO]: Epoch 069 - training loss: 0.0965, validation loss: 1.9232
2024-06-02 17:38:01 [INFO]: Epoch 070 - training loss: 0.0961, validation loss: 1.9185
2024-06-02 17:38:06 [INFO]: Epoch 071 - training loss: 0.0959, validation loss: 1.9138
2024-06-02 17:38:11 [INFO]: Epoch 072 - training loss: 0.0953, validation loss: 1.9100
2024-06-02 17:38:16 [INFO]: Epoch 073 - training loss: 0.0954, validation loss: 1.9082
2024-06-02 17:38:21 [INFO]: Epoch 074 - training loss: 0.0949, validation loss: 1.9013
2024-06-02 17:38:26 [INFO]: Epoch 075 - training loss: 0.0948, validation loss: 1.8994
2024-06-02 17:38:30 [INFO]: Epoch 076 - training loss: 0.0942, validation loss: 1.8989
2024-06-02 17:38:35 [INFO]: Epoch 077 - training loss: 0.0940, validation loss: 1.8943
2024-06-02 17:38:40 [INFO]: Epoch 078 - training loss: 0.0939, validation loss: 1.8920
2024-06-02 17:38:45 [INFO]: Epoch 079 - training loss: 0.0937, validation loss: 1.8888
2024-06-02 17:38:50 [INFO]: Epoch 080 - training loss: 0.0932, validation loss: 1.8858
2024-06-02 17:38:55 [INFO]: Epoch 081 - training loss: 0.0929, validation loss: 1.8869
2024-06-02 17:39:00 [INFO]: Epoch 082 - training loss: 0.0929, validation loss: 1.8802
2024-06-02 17:39:05 [INFO]: Epoch 083 - training loss: 0.0929, validation loss: 1.8773
2024-06-02 17:39:10 [INFO]: Epoch 084 - training loss: 0.0923, validation loss: 1.8717
2024-06-02 17:39:14 [INFO]: Epoch 085 - training loss: 0.0922, validation loss: 1.8793
2024-06-02 17:39:19 [INFO]: Epoch 086 - training loss: 0.0918, validation loss: 1.8710
2024-06-02 17:39:25 [INFO]: Epoch 087 - training loss: 0.0923, validation loss: 1.8726
2024-06-02 17:39:29 [INFO]: Epoch 088 - training loss: 0.0915, validation loss: 1.8681
2024-06-02 17:39:34 [INFO]: Epoch 089 - training loss: 0.0912, validation loss: 1.8695
2024-06-02 17:39:39 [INFO]: Epoch 090 - training loss: 0.0915, validation loss: 1.8675
2024-06-02 17:39:45 [INFO]: Epoch 091 - training loss: 0.0909, validation loss: 1.8735
2024-06-02 17:39:50 [INFO]: Epoch 092 - training loss: 0.0908, validation loss: 1.8650
2024-06-02 17:39:55 [INFO]: Epoch 093 - training loss: 0.0904, validation loss: 1.8688
2024-06-02 17:39:59 [INFO]: Epoch 094 - training loss: 0.0899, validation loss: 1.8618
2024-06-02 17:40:04 [INFO]: Epoch 095 - training loss: 0.0901, validation loss: 1.8592
2024-06-02 17:40:09 [INFO]: Epoch 096 - training loss: 0.0899, validation loss: 1.8597
2024-06-02 17:40:14 [INFO]: Epoch 097 - training loss: 0.0896, validation loss: 1.8585
2024-06-02 17:40:19 [INFO]: Epoch 098 - training loss: 0.0892, validation loss: 1.8565
2024-06-02 17:40:24 [INFO]: Epoch 099 - training loss: 0.0890, validation loss: 1.8554
2024-06-02 17:40:29 [INFO]: Epoch 100 - training loss: 0.0897, validation loss: 1.8518
2024-06-02 17:40:29 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 17:40:29 [INFO]: Saved the model to results_point_rate01/Electricity/TimesNet_Electricity/round_2/20240602_T173217/TimesNet.pypots
2024-06-02 17:40:30 [INFO]: Successfully saved to results_point_rate01/Electricity/TimesNet_Electricity/round_2/imputation.pkl
2024-06-02 17:40:30 [INFO]: Round2 - TimesNet on Electricity: MAE=1.0034, MSE=2.0565, MRE=0.5367
2024-06-02 17:40:30 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 17:40:30 [INFO]: Using the given device: cuda:0
2024-06-02 17:40:30 [INFO]: Model files will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_3/20240602_T174030
2024-06-02 17:40:30 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_3/20240602_T174030/tensorboard
2024-06-02 17:40:31 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-02 17:40:36 [INFO]: Epoch 001 - training loss: 0.5689, validation loss: 2.9491
2024-06-02 17:40:41 [INFO]: Epoch 002 - training loss: 0.2756, validation loss: 2.7707
2024-06-02 17:40:46 [INFO]: Epoch 003 - training loss: 0.2287, validation loss: 2.6881
2024-06-02 17:40:51 [INFO]: Epoch 004 - training loss: 0.2094, validation loss: 2.6261
2024-06-02 17:40:56 [INFO]: Epoch 005 - training loss: 0.1958, validation loss: 2.5906
2024-06-02 17:41:01 [INFO]: Epoch 006 - training loss: 0.1871, validation loss: 2.5587
2024-06-02 17:41:06 [INFO]: Epoch 007 - training loss: 0.1788, validation loss: 2.5266
2024-06-02 17:41:10 [INFO]: Epoch 008 - training loss: 0.1721, validation loss: 2.5047
2024-06-02 17:41:15 [INFO]: Epoch 009 - training loss: 0.1676, validation loss: 2.4766
2024-06-02 17:41:20 [INFO]: Epoch 010 - training loss: 0.1625, validation loss: 2.4544
2024-06-02 17:41:25 [INFO]: Epoch 011 - training loss: 0.1580, validation loss: 2.4372
2024-06-02 17:41:30 [INFO]: Epoch 012 - training loss: 0.1548, validation loss: 2.4175
2024-06-02 17:41:35 [INFO]: Epoch 013 - training loss: 0.1519, validation loss: 2.3966
2024-06-02 17:41:40 [INFO]: Epoch 014 - training loss: 0.1483, validation loss: 2.3811
2024-06-02 17:41:45 [INFO]: Epoch 015 - training loss: 0.1457, validation loss: 2.3703
2024-06-02 17:41:50 [INFO]: Epoch 016 - training loss: 0.1431, validation loss: 2.3542
2024-06-02 17:41:55 [INFO]: Epoch 017 - training loss: 0.1407, validation loss: 2.3456
2024-06-02 17:42:00 [INFO]: Epoch 018 - training loss: 0.1387, validation loss: 2.3357
2024-06-02 17:42:05 [INFO]: Epoch 019 - training loss: 0.1367, validation loss: 2.3204
2024-06-02 17:42:10 [INFO]: Epoch 020 - training loss: 0.1347, validation loss: 2.3080
2024-06-02 17:42:14 [INFO]: Epoch 021 - training loss: 0.1326, validation loss: 2.2993
2024-06-02 17:42:19 [INFO]: Epoch 022 - training loss: 0.1309, validation loss: 2.2825
2024-06-02 17:42:24 [INFO]: Epoch 023 - training loss: 0.1291, validation loss: 2.2693
2024-06-02 17:42:29 [INFO]: Epoch 024 - training loss: 0.1277, validation loss: 2.2596
2024-06-02 17:42:34 [INFO]: Epoch 025 - training loss: 0.1262, validation loss: 2.2425
2024-06-02 17:42:39 [INFO]: Epoch 026 - training loss: 0.1253, validation loss: 2.2346
2024-06-02 17:42:44 [INFO]: Epoch 027 - training loss: 0.1236, validation loss: 2.2247
2024-06-02 17:42:49 [INFO]: Epoch 028 - training loss: 0.1225, validation loss: 2.2079
2024-06-02 17:42:54 [INFO]: Epoch 029 - training loss: 0.1213, validation loss: 2.1995
2024-06-02 17:42:59 [INFO]: Epoch 030 - training loss: 0.1202, validation loss: 2.1900
2024-06-02 17:43:04 [INFO]: Epoch 031 - training loss: 0.1189, validation loss: 2.1772
2024-06-02 17:43:08 [INFO]: Epoch 032 - training loss: 0.1179, validation loss: 2.1722
2024-06-02 17:43:13 [INFO]: Epoch 033 - training loss: 0.1167, validation loss: 2.1606
2024-06-02 17:43:18 [INFO]: Epoch 034 - training loss: 0.1161, validation loss: 2.1490
2024-06-02 17:43:23 [INFO]: Epoch 035 - training loss: 0.1148, validation loss: 2.1410
2024-06-02 17:43:28 [INFO]: Epoch 036 - training loss: 0.1144, validation loss: 2.1303
2024-06-02 17:43:33 [INFO]: Epoch 037 - training loss: 0.1130, validation loss: 2.1185
2024-06-02 17:43:38 [INFO]: Epoch 038 - training loss: 0.1121, validation loss: 2.1103
2024-06-02 17:43:43 [INFO]: Epoch 039 - training loss: 0.1117, validation loss: 2.1026
2024-06-02 17:43:48 [INFO]: Epoch 040 - training loss: 0.1107, validation loss: 2.0943
2024-06-02 17:43:53 [INFO]: Epoch 041 - training loss: 0.1100, validation loss: 2.0917
2024-06-02 17:43:58 [INFO]: Epoch 042 - training loss: 0.1098, validation loss: 2.0783
2024-06-02 17:44:03 [INFO]: Epoch 043 - training loss: 0.1085, validation loss: 2.0673
2024-06-02 17:44:08 [INFO]: Epoch 044 - training loss: 0.1081, validation loss: 2.0556
2024-06-02 17:44:12 [INFO]: Epoch 045 - training loss: 0.1078, validation loss: 2.0549
2024-06-02 17:44:17 [INFO]: Epoch 046 - training loss: 0.1072, validation loss: 2.0406
2024-06-02 17:44:22 [INFO]: Epoch 047 - training loss: 0.1065, validation loss: 2.0342
2024-06-02 17:44:27 [INFO]: Epoch 048 - training loss: 0.1054, validation loss: 2.0261
2024-06-02 17:44:32 [INFO]: Epoch 049 - training loss: 0.1055, validation loss: 2.0175
2024-06-02 17:44:37 [INFO]: Epoch 050 - training loss: 0.1046, validation loss: 2.0120
2024-06-02 17:44:42 [INFO]: Epoch 051 - training loss: 0.1041, validation loss: 2.0035
2024-06-02 17:44:47 [INFO]: Epoch 052 - training loss: 0.1035, validation loss: 1.9960
2024-06-02 17:44:52 [INFO]: Epoch 053 - training loss: 0.1034, validation loss: 1.9877
2024-06-02 17:44:57 [INFO]: Epoch 054 - training loss: 0.1024, validation loss: 1.9805
2024-06-02 17:45:02 [INFO]: Epoch 055 - training loss: 0.1023, validation loss: 1.9755
2024-06-02 17:45:07 [INFO]: Epoch 056 - training loss: 0.1016, validation loss: 1.9686
2024-06-02 17:45:11 [INFO]: Epoch 057 - training loss: 0.1012, validation loss: 1.9614
2024-06-02 17:45:16 [INFO]: Epoch 058 - training loss: 0.1004, validation loss: 1.9563
2024-06-02 17:45:21 [INFO]: Epoch 059 - training loss: 0.1003, validation loss: 1.9470
2024-06-02 17:45:26 [INFO]: Epoch 060 - training loss: 0.0999, validation loss: 1.9448
2024-06-02 17:45:31 [INFO]: Epoch 061 - training loss: 0.0992, validation loss: 1.9435
2024-06-02 17:45:36 [INFO]: Epoch 062 - training loss: 0.0990, validation loss: 1.9353
2024-06-02 17:45:41 [INFO]: Epoch 063 - training loss: 0.0987, validation loss: 1.9339
2024-06-02 17:45:46 [INFO]: Epoch 064 - training loss: 0.0984, validation loss: 1.9269
2024-06-02 17:45:51 [INFO]: Epoch 065 - training loss: 0.0978, validation loss: 1.9238
2024-06-02 17:45:56 [INFO]: Epoch 066 - training loss: 0.0976, validation loss: 1.9161
2024-06-02 17:46:01 [INFO]: Epoch 067 - training loss: 0.0971, validation loss: 1.9125
2024-06-02 17:46:05 [INFO]: Epoch 068 - training loss: 0.0970, validation loss: 1.9083
2024-06-02 17:46:10 [INFO]: Epoch 069 - training loss: 0.0963, validation loss: 1.9050
2024-06-02 17:46:15 [INFO]: Epoch 070 - training loss: 0.0963, validation loss: 1.8945
2024-06-02 17:46:20 [INFO]: Epoch 071 - training loss: 0.0954, validation loss: 1.8963
2024-06-02 17:46:25 [INFO]: Epoch 072 - training loss: 0.0957, validation loss: 1.8898
2024-06-02 17:46:30 [INFO]: Epoch 073 - training loss: 0.0951, validation loss: 1.8915
2024-06-02 17:46:35 [INFO]: Epoch 074 - training loss: 0.0950, validation loss: 1.8847
2024-06-02 17:46:40 [INFO]: Epoch 075 - training loss: 0.0950, validation loss: 1.8826
2024-06-02 17:46:45 [INFO]: Epoch 076 - training loss: 0.0943, validation loss: 1.8836
2024-06-02 17:46:50 [INFO]: Epoch 077 - training loss: 0.0940, validation loss: 1.8784
2024-06-02 17:46:55 [INFO]: Epoch 078 - training loss: 0.0941, validation loss: 1.8756
2024-06-02 17:47:00 [INFO]: Epoch 079 - training loss: 0.0934, validation loss: 1.8696
2024-06-02 17:47:04 [INFO]: Epoch 080 - training loss: 0.0935, validation loss: 1.8767
2024-06-02 17:47:09 [INFO]: Epoch 081 - training loss: 0.0936, validation loss: 1.8683
2024-06-02 17:47:14 [INFO]: Epoch 082 - training loss: 0.0929, validation loss: 1.8738
2024-06-02 17:47:19 [INFO]: Epoch 083 - training loss: 0.0927, validation loss: 1.8716
2024-06-02 17:47:24 [INFO]: Epoch 084 - training loss: 0.0925, validation loss: 1.8624
2024-06-02 17:47:29 [INFO]: Epoch 085 - training loss: 0.0923, validation loss: 1.8592
2024-06-02 17:47:34 [INFO]: Epoch 086 - training loss: 0.0919, validation loss: 1.8593
2024-06-02 17:47:39 [INFO]: Epoch 087 - training loss: 0.0919, validation loss: 1.8572
2024-06-02 17:47:44 [INFO]: Epoch 088 - training loss: 0.0918, validation loss: 1.8519
2024-06-02 17:47:49 [INFO]: Epoch 089 - training loss: 0.0919, validation loss: 1.8550
2024-06-02 17:47:54 [INFO]: Epoch 090 - training loss: 0.0908, validation loss: 1.8539
2024-06-02 17:47:59 [INFO]: Epoch 091 - training loss: 0.0911, validation loss: 1.8529
2024-06-02 17:48:04 [INFO]: Epoch 092 - training loss: 0.0910, validation loss: 1.8502
2024-06-02 17:48:09 [INFO]: Epoch 093 - training loss: 0.0907, validation loss: 1.8499
2024-06-02 17:48:14 [INFO]: Epoch 094 - training loss: 0.0903, validation loss: 1.8484
2024-06-02 17:48:19 [INFO]: Epoch 095 - training loss: 0.0906, validation loss: 1.8425
2024-06-02 17:48:24 [INFO]: Epoch 096 - training loss: 0.0899, validation loss: 1.8418
2024-06-02 17:48:29 [INFO]: Epoch 097 - training loss: 0.0898, validation loss: 1.8414
2024-06-02 17:48:34 [INFO]: Epoch 098 - training loss: 0.0894, validation loss: 1.8394
2024-06-02 17:48:37 [INFO]: Epoch 099 - training loss: 0.0897, validation loss: 1.8379
2024-06-02 17:48:42 [INFO]: Epoch 100 - training loss: 0.0893, validation loss: 1.8323
2024-06-02 17:48:42 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 17:48:42 [INFO]: Saved the model to results_point_rate01/Electricity/TimesNet_Electricity/round_3/20240602_T174030/TimesNet.pypots
2024-06-02 17:48:43 [INFO]: Successfully saved to results_point_rate01/Electricity/TimesNet_Electricity/round_3/imputation.pkl
2024-06-02 17:48:43 [INFO]: Round3 - TimesNet on Electricity: MAE=1.0062, MSE=2.0014, MRE=0.5383
2024-06-02 17:48:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 17:48:43 [INFO]: Using the given device: cuda:0
2024-06-02 17:48:43 [INFO]: Model files will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_4/20240602_T174843
2024-06-02 17:48:43 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/TimesNet_Electricity/round_4/20240602_T174843/tensorboard
2024-06-02 17:48:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-02 17:48:49 [INFO]: Epoch 001 - training loss: 0.5733, validation loss: 2.9993
2024-06-02 17:48:54 [INFO]: Epoch 002 - training loss: 0.2791, validation loss: 2.8094
2024-06-02 17:48:59 [INFO]: Epoch 003 - training loss: 0.2289, validation loss: 2.7119
2024-06-02 17:49:03 [INFO]: Epoch 004 - training loss: 0.2082, validation loss: 2.6583
2024-06-02 17:49:09 [INFO]: Epoch 005 - training loss: 0.1960, validation loss: 2.6090
2024-06-02 17:49:13 [INFO]: Epoch 006 - training loss: 0.1852, validation loss: 2.5878
2024-06-02 17:49:18 [INFO]: Epoch 007 - training loss: 0.1774, validation loss: 2.5483
2024-06-02 17:49:23 [INFO]: Epoch 008 - training loss: 0.1714, validation loss: 2.5245
2024-06-02 17:49:28 [INFO]: Epoch 009 - training loss: 0.1667, validation loss: 2.4988
2024-06-02 17:49:33 [INFO]: Epoch 010 - training loss: 0.1620, validation loss: 2.4725
2024-06-02 17:49:38 [INFO]: Epoch 011 - training loss: 0.1583, validation loss: 2.4505
2024-06-02 17:49:43 [INFO]: Epoch 012 - training loss: 0.1543, validation loss: 2.4322
2024-06-02 17:49:48 [INFO]: Epoch 013 - training loss: 0.1511, validation loss: 2.4137
2024-06-02 17:49:53 [INFO]: Epoch 014 - training loss: 0.1480, validation loss: 2.3983
2024-06-02 17:49:57 [INFO]: Epoch 015 - training loss: 0.1458, validation loss: 2.3801
2024-06-02 17:50:02 [INFO]: Epoch 016 - training loss: 0.1426, validation loss: 2.3633
2024-06-02 17:50:07 [INFO]: Epoch 017 - training loss: 0.1402, validation loss: 2.3428
2024-06-02 17:50:12 [INFO]: Epoch 018 - training loss: 0.1388, validation loss: 2.3290
2024-06-02 17:50:17 [INFO]: Epoch 019 - training loss: 0.1365, validation loss: 2.3190
2024-06-02 17:50:22 [INFO]: Epoch 020 - training loss: 0.1347, validation loss: 2.3061
2024-06-02 17:50:27 [INFO]: Epoch 021 - training loss: 0.1325, validation loss: 2.2867
2024-06-02 17:50:32 [INFO]: Epoch 022 - training loss: 0.1309, validation loss: 2.2786
2024-06-02 17:50:37 [INFO]: Epoch 023 - training loss: 0.1292, validation loss: 2.2677
2024-06-02 17:50:42 [INFO]: Epoch 024 - training loss: 0.1275, validation loss: 2.2539
2024-06-02 17:50:46 [INFO]: Epoch 025 - training loss: 0.1260, validation loss: 2.2469
2024-06-02 17:50:51 [INFO]: Epoch 026 - training loss: 0.1249, validation loss: 2.2350
2024-06-02 17:50:56 [INFO]: Epoch 027 - training loss: 0.1232, validation loss: 2.2199
2024-06-02 17:51:01 [INFO]: Epoch 028 - training loss: 0.1228, validation loss: 2.2160
2024-06-02 17:51:06 [INFO]: Epoch 029 - training loss: 0.1213, validation loss: 2.2039
2024-06-02 17:51:11 [INFO]: Epoch 030 - training loss: 0.1202, validation loss: 2.1887
2024-06-02 17:51:16 [INFO]: Epoch 031 - training loss: 0.1185, validation loss: 2.1841
2024-06-02 17:51:21 [INFO]: Epoch 032 - training loss: 0.1176, validation loss: 2.1753
2024-06-02 17:51:26 [INFO]: Epoch 033 - training loss: 0.1167, validation loss: 2.1646
2024-06-02 17:51:31 [INFO]: Epoch 034 - training loss: 0.1157, validation loss: 2.1524
2024-06-02 17:51:35 [INFO]: Epoch 035 - training loss: 0.1148, validation loss: 2.1413
2024-06-02 17:51:40 [INFO]: Epoch 036 - training loss: 0.1139, validation loss: 2.1342
2024-06-02 17:51:45 [INFO]: Epoch 037 - training loss: 0.1134, validation loss: 2.1245
2024-06-02 17:51:50 [INFO]: Epoch 038 - training loss: 0.1121, validation loss: 2.1201
2024-06-02 17:51:55 [INFO]: Epoch 039 - training loss: 0.1113, validation loss: 2.1065
2024-06-02 17:52:00 [INFO]: Epoch 040 - training loss: 0.1106, validation loss: 2.1010
2024-06-02 17:52:05 [INFO]: Epoch 041 - training loss: 0.1101, validation loss: 2.0931
2024-06-02 17:52:10 [INFO]: Epoch 042 - training loss: 0.1094, validation loss: 2.0918
2024-06-02 17:52:15 [INFO]: Epoch 043 - training loss: 0.1090, validation loss: 2.0771
2024-06-02 17:52:20 [INFO]: Epoch 044 - training loss: 0.1086, validation loss: 2.0742
2024-06-02 17:52:24 [INFO]: Epoch 045 - training loss: 0.1073, validation loss: 2.0608
2024-06-02 17:52:29 [INFO]: Epoch 046 - training loss: 0.1068, validation loss: 2.0531
2024-06-02 17:52:34 [INFO]: Epoch 047 - training loss: 0.1065, validation loss: 2.0476
2024-06-02 17:52:39 [INFO]: Epoch 048 - training loss: 0.1059, validation loss: 2.0426
2024-06-02 17:52:44 [INFO]: Epoch 049 - training loss: 0.1050, validation loss: 2.0379
2024-06-02 17:52:49 [INFO]: Epoch 050 - training loss: 0.1041, validation loss: 2.0263
2024-06-02 17:52:54 [INFO]: Epoch 051 - training loss: 0.1041, validation loss: 2.0216
2024-06-02 17:52:59 [INFO]: Epoch 052 - training loss: 0.1034, validation loss: 2.0139
2024-06-02 17:53:04 [INFO]: Epoch 053 - training loss: 0.1029, validation loss: 2.0087
2024-06-02 17:53:09 [INFO]: Epoch 054 - training loss: 0.1027, validation loss: 1.9997
2024-06-02 17:53:13 [INFO]: Epoch 055 - training loss: 0.1019, validation loss: 1.9927
2024-06-02 17:53:18 [INFO]: Epoch 056 - training loss: 0.1016, validation loss: 1.9835
2024-06-02 17:53:23 [INFO]: Epoch 057 - training loss: 0.1014, validation loss: 1.9818
2024-06-02 17:53:28 [INFO]: Epoch 058 - training loss: 0.1009, validation loss: 1.9745
2024-06-02 17:53:33 [INFO]: Epoch 059 - training loss: 0.1003, validation loss: 1.9712
2024-06-02 17:53:38 [INFO]: Epoch 060 - training loss: 0.0996, validation loss: 1.9669
2024-06-02 17:53:43 [INFO]: Epoch 061 - training loss: 0.0995, validation loss: 1.9594
2024-06-02 17:53:48 [INFO]: Epoch 062 - training loss: 0.0992, validation loss: 1.9568
2024-06-02 17:53:53 [INFO]: Epoch 063 - training loss: 0.0983, validation loss: 1.9521
2024-06-02 17:53:58 [INFO]: Epoch 064 - training loss: 0.0982, validation loss: 1.9535
2024-06-02 17:54:03 [INFO]: Epoch 065 - training loss: 0.0979, validation loss: 1.9418
2024-06-02 17:54:08 [INFO]: Epoch 066 - training loss: 0.0981, validation loss: 1.9410
2024-06-02 17:54:13 [INFO]: Epoch 067 - training loss: 0.0969, validation loss: 1.9340
2024-06-02 17:54:17 [INFO]: Epoch 068 - training loss: 0.0970, validation loss: 1.9334
2024-06-02 17:54:22 [INFO]: Epoch 069 - training loss: 0.0964, validation loss: 1.9278
2024-06-02 17:54:28 [INFO]: Epoch 070 - training loss: 0.0959, validation loss: 1.9251
2024-06-02 17:54:32 [INFO]: Epoch 071 - training loss: 0.0960, validation loss: 1.9236
2024-06-02 17:54:38 [INFO]: Epoch 072 - training loss: 0.0952, validation loss: 1.9182
2024-06-02 17:54:42 [INFO]: Epoch 073 - training loss: 0.0955, validation loss: 1.9142
2024-06-02 17:54:47 [INFO]: Epoch 074 - training loss: 0.0952, validation loss: 1.9117
2024-06-02 17:54:52 [INFO]: Epoch 075 - training loss: 0.0950, validation loss: 1.9093
2024-06-02 17:54:57 [INFO]: Epoch 076 - training loss: 0.0944, validation loss: 1.9047
2024-06-02 17:55:02 [INFO]: Epoch 077 - training loss: 0.0941, validation loss: 1.9005
2024-06-02 17:55:07 [INFO]: Epoch 078 - training loss: 0.0941, validation loss: 1.9049
2024-06-02 17:55:12 [INFO]: Epoch 079 - training loss: 0.0937, validation loss: 1.8969
2024-06-02 17:55:16 [INFO]: Epoch 080 - training loss: 0.0935, validation loss: 1.8906
2024-06-02 17:55:21 [INFO]: Epoch 081 - training loss: 0.0931, validation loss: 1.8940
2024-06-02 17:55:26 [INFO]: Epoch 082 - training loss: 0.0931, validation loss: 1.8898
2024-06-02 17:55:31 [INFO]: Epoch 083 - training loss: 0.0924, validation loss: 1.8881
2024-06-02 17:55:36 [INFO]: Epoch 084 - training loss: 0.0927, validation loss: 1.8879
2024-06-02 17:55:40 [INFO]: Epoch 085 - training loss: 0.0921, validation loss: 1.8844
2024-06-02 17:55:45 [INFO]: Epoch 086 - training loss: 0.0923, validation loss: 1.8770
2024-06-02 17:55:50 [INFO]: Epoch 087 - training loss: 0.0915, validation loss: 1.8793
2024-06-02 17:55:55 [INFO]: Epoch 088 - training loss: 0.0913, validation loss: 1.8784
2024-06-02 17:56:00 [INFO]: Epoch 089 - training loss: 0.0913, validation loss: 1.8738
2024-06-02 17:56:05 [INFO]: Epoch 090 - training loss: 0.0911, validation loss: 1.8710
2024-06-02 17:56:10 [INFO]: Epoch 091 - training loss: 0.0908, validation loss: 1.8734
2024-06-02 17:56:15 [INFO]: Epoch 092 - training loss: 0.0907, validation loss: 1.8762
2024-06-02 17:56:20 [INFO]: Epoch 093 - training loss: 0.0903, validation loss: 1.8694
2024-06-02 17:56:25 [INFO]: Epoch 094 - training loss: 0.0904, validation loss: 1.8650
2024-06-02 17:56:30 [INFO]: Epoch 095 - training loss: 0.0904, validation loss: 1.8694
2024-06-02 17:56:34 [INFO]: Epoch 096 - training loss: 0.0900, validation loss: 1.8612
2024-06-02 17:56:39 [INFO]: Epoch 097 - training loss: 0.0896, validation loss: 1.8604
2024-06-02 17:56:44 [INFO]: Epoch 098 - training loss: 0.0893, validation loss: 1.8585
2024-06-02 17:56:49 [INFO]: Epoch 099 - training loss: 0.0892, validation loss: 1.8556
2024-06-02 17:56:54 [INFO]: Epoch 100 - training loss: 0.0892, validation loss: 1.8605
2024-06-02 17:56:54 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 17:56:55 [INFO]: Saved the model to results_point_rate01/Electricity/TimesNet_Electricity/round_4/20240602_T174843/TimesNet.pypots
2024-06-02 17:56:55 [INFO]: Successfully saved to results_point_rate01/Electricity/TimesNet_Electricity/round_4/imputation.pkl
2024-06-02 17:56:55 [INFO]: Round4 - TimesNet on Electricity: MAE=1.0331, MSE=2.1365, MRE=0.5527
2024-06-02 17:56:55 [INFO]: Done! Final results:
Averaged TimesNet (45,569,394 params) on Electricity: MAE=1.0107 ± 0.01611640592593994, MSE=2.0376 ± 0.07285402857240073, MRE=0.5407 ± 0.008621526626460324, average inference time=0.71
