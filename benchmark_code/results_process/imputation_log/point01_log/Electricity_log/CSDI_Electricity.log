2024-06-01 21:58:29 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:58:29 [INFO]: Using the given device: cuda:0
2024-06-01 21:58:29 [INFO]: Model files will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_0/20240601_T215829
2024-06-01 21:58:29 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_0/20240601_T215829/tensorboard
2024-06-01 21:58:29 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-01 22:02:24 [INFO]: Epoch 001 - training loss: 0.7058, validation loss: 0.5324
2024-06-01 22:06:14 [INFO]: Epoch 002 - training loss: 0.4098, validation loss: 0.4346
2024-06-01 22:10:05 [INFO]: Epoch 003 - training loss: 0.3553, validation loss: 0.4128
2024-06-01 22:13:55 [INFO]: Epoch 004 - training loss: 0.3490, validation loss: 0.4019
2024-06-01 22:17:35 [INFO]: Epoch 005 - training loss: 0.3655, validation loss: 0.3918
2024-06-01 22:21:12 [INFO]: Epoch 006 - training loss: 0.3292, validation loss: 0.3744
2024-06-01 22:24:48 [INFO]: Epoch 007 - training loss: 0.3162, validation loss: 0.3483
2024-06-01 22:28:24 [INFO]: Epoch 008 - training loss: 0.2928, validation loss: 0.3285
2024-06-01 22:32:01 [INFO]: Epoch 009 - training loss: 0.2820, validation loss: 0.3221
2024-06-01 22:35:37 [INFO]: Epoch 010 - training loss: 0.2820, validation loss: 0.3033
2024-06-01 22:39:14 [INFO]: Epoch 011 - training loss: 0.2608, validation loss: 0.2954
2024-06-01 22:42:51 [INFO]: Epoch 012 - training loss: 0.2575, validation loss: 0.2796
2024-06-01 22:46:27 [INFO]: Epoch 013 - training loss: 0.2431, validation loss: 0.2675
2024-06-01 22:50:04 [INFO]: Epoch 014 - training loss: 0.2470, validation loss: 0.2586
2024-06-01 22:53:39 [INFO]: Epoch 015 - training loss: 0.2149, validation loss: 0.2517
2024-06-01 22:57:15 [INFO]: Epoch 016 - training loss: 0.2394, validation loss: 0.2398
2024-06-01 23:00:53 [INFO]: Epoch 017 - training loss: 0.2389, validation loss: 0.2343
2024-06-01 23:04:30 [INFO]: Epoch 018 - training loss: 0.2159, validation loss: 0.2317
2024-06-01 23:08:07 [INFO]: Epoch 019 - training loss: 0.2438, validation loss: 0.2213
2024-06-01 23:11:45 [INFO]: Epoch 020 - training loss: 0.2264, validation loss: 0.2168
2024-06-01 23:15:21 [INFO]: Epoch 021 - training loss: 0.1992, validation loss: 0.2109
2024-06-01 23:18:59 [INFO]: Epoch 022 - training loss: 0.1981, validation loss: 0.2073
2024-06-01 23:22:36 [INFO]: Epoch 023 - training loss: 0.2191, validation loss: 0.2041
2024-06-01 23:26:11 [INFO]: Epoch 024 - training loss: 0.2053, validation loss: 0.2003
2024-06-01 23:29:49 [INFO]: Epoch 025 - training loss: 0.2010, validation loss: 0.1994
2024-06-01 23:33:26 [INFO]: Epoch 026 - training loss: 0.2040, validation loss: 0.1990
2024-06-01 23:37:04 [INFO]: Epoch 027 - training loss: 0.1946, validation loss: 0.1990
2024-06-01 23:40:42 [INFO]: Epoch 028 - training loss: 0.1629, validation loss: 0.1976
2024-06-01 23:44:19 [INFO]: Epoch 029 - training loss: 0.2019, validation loss: 0.1960
2024-06-01 23:47:55 [INFO]: Epoch 030 - training loss: 0.1929, validation loss: 0.1938
2024-06-01 23:51:32 [INFO]: Epoch 031 - training loss: 0.1939, validation loss: 0.1945
2024-06-01 23:55:09 [INFO]: Epoch 032 - training loss: 0.1964, validation loss: 0.1915
2024-06-01 23:58:46 [INFO]: Epoch 033 - training loss: 0.1702, validation loss: 0.1907
2024-06-02 00:02:24 [INFO]: Epoch 034 - training loss: 0.1890, validation loss: 0.1894
2024-06-02 00:06:00 [INFO]: Epoch 035 - training loss: 0.1906, validation loss: 0.1878
2024-06-02 00:09:37 [INFO]: Epoch 036 - training loss: 0.1956, validation loss: 0.1903
2024-06-02 00:13:14 [INFO]: Epoch 037 - training loss: 0.1951, validation loss: 0.1910
2024-06-02 00:16:51 [INFO]: Epoch 038 - training loss: 0.1911, validation loss: 0.1889
2024-06-02 00:19:53 [INFO]: Epoch 039 - training loss: 0.1805, validation loss: 0.1843
2024-06-02 00:21:59 [INFO]: Epoch 040 - training loss: 0.2080, validation loss: 0.1842
2024-06-02 00:24:06 [INFO]: Epoch 041 - training loss: 0.1813, validation loss: 0.1890
2024-06-02 00:26:13 [INFO]: Epoch 042 - training loss: 0.1855, validation loss: 0.1827
2024-06-02 00:28:19 [INFO]: Epoch 043 - training loss: 0.1898, validation loss: 0.1855
2024-06-02 00:30:26 [INFO]: Epoch 044 - training loss: 0.1990, validation loss: 0.1798
2024-06-02 00:32:33 [INFO]: Epoch 045 - training loss: 0.1906, validation loss: 0.1771
2024-06-02 00:34:39 [INFO]: Epoch 046 - training loss: 0.1929, validation loss: 0.1818
2024-06-02 00:36:46 [INFO]: Epoch 047 - training loss: 0.1934, validation loss: 0.1798
2024-06-02 00:38:53 [INFO]: Epoch 048 - training loss: 0.1949, validation loss: 0.1754
2024-06-02 00:41:00 [INFO]: Epoch 049 - training loss: 0.1864, validation loss: 0.1746
2024-06-02 00:43:07 [INFO]: Epoch 050 - training loss: 0.1738, validation loss: 0.1734
2024-06-02 00:45:13 [INFO]: Epoch 051 - training loss: 0.1778, validation loss: 0.1753
2024-06-02 00:47:20 [INFO]: Epoch 052 - training loss: 0.1735, validation loss: 0.1725
2024-06-02 00:49:27 [INFO]: Epoch 053 - training loss: 0.2014, validation loss: 0.1710
2024-06-02 00:51:34 [INFO]: Epoch 054 - training loss: 0.1835, validation loss: 0.1724
2024-06-02 00:53:40 [INFO]: Epoch 055 - training loss: 0.1732, validation loss: 0.1706
2024-06-02 00:55:47 [INFO]: Epoch 056 - training loss: 0.1759, validation loss: 0.1731
2024-06-02 00:57:54 [INFO]: Epoch 057 - training loss: 0.1772, validation loss: 0.1703
2024-06-02 01:00:01 [INFO]: Epoch 058 - training loss: 0.1789, validation loss: 0.1683
2024-06-02 01:02:08 [INFO]: Epoch 059 - training loss: 0.1842, validation loss: 0.1713
2024-06-02 01:04:14 [INFO]: Epoch 060 - training loss: 0.1669, validation loss: 0.1692
2024-06-02 01:06:22 [INFO]: Epoch 061 - training loss: 0.1845, validation loss: 0.1699
2024-06-02 01:08:28 [INFO]: Epoch 062 - training loss: 0.1922, validation loss: 0.1692
2024-06-02 01:10:36 [INFO]: Epoch 063 - training loss: 0.1884, validation loss: 0.1673
2024-06-02 01:12:42 [INFO]: Epoch 064 - training loss: 0.1771, validation loss: 0.1698
2024-06-02 01:14:49 [INFO]: Epoch 065 - training loss: 0.1814, validation loss: 0.1702
2024-06-02 01:16:56 [INFO]: Epoch 066 - training loss: 0.1839, validation loss: 0.1704
2024-06-02 01:19:02 [INFO]: Epoch 067 - training loss: 0.1627, validation loss: 0.1689
2024-06-02 01:21:09 [INFO]: Epoch 068 - training loss: 0.1713, validation loss: 0.1684
2024-06-02 01:23:16 [INFO]: Epoch 069 - training loss: 0.1706, validation loss: 0.1669
2024-06-02 01:25:22 [INFO]: Epoch 070 - training loss: 0.1795, validation loss: 0.1655
2024-06-02 01:27:29 [INFO]: Epoch 071 - training loss: 0.1696, validation loss: 0.1666
2024-06-02 01:29:35 [INFO]: Epoch 072 - training loss: 0.1676, validation loss: 0.1691
2024-06-02 01:31:42 [INFO]: Epoch 073 - training loss: 0.1616, validation loss: 0.1671
2024-06-02 01:33:49 [INFO]: Epoch 074 - training loss: 0.1711, validation loss: 0.1648
2024-06-02 01:35:55 [INFO]: Epoch 075 - training loss: 0.1872, validation loss: 0.1633
2024-06-02 01:38:02 [INFO]: Epoch 076 - training loss: 0.1858, validation loss: 0.1626
2024-06-02 01:40:09 [INFO]: Epoch 077 - training loss: 0.1758, validation loss: 0.1665
2024-06-02 01:42:15 [INFO]: Epoch 078 - training loss: 0.1939, validation loss: 0.1650
2024-06-02 01:44:22 [INFO]: Epoch 079 - training loss: 0.1815, validation loss: 0.1668
2024-06-02 01:46:29 [INFO]: Epoch 080 - training loss: 0.1918, validation loss: 0.1643
2024-06-02 01:48:35 [INFO]: Epoch 081 - training loss: 0.1839, validation loss: 0.1633
2024-06-02 01:50:42 [INFO]: Epoch 082 - training loss: 0.1833, validation loss: 0.1624
2024-06-02 01:52:48 [INFO]: Epoch 083 - training loss: 0.1812, validation loss: 0.1647
2024-06-02 01:54:55 [INFO]: Epoch 084 - training loss: 0.1970, validation loss: 0.1637
2024-06-02 01:57:02 [INFO]: Epoch 085 - training loss: 0.1945, validation loss: 0.1628
2024-06-02 01:59:09 [INFO]: Epoch 086 - training loss: 0.1829, validation loss: 0.1698
2024-06-02 02:01:15 [INFO]: Epoch 087 - training loss: 0.1884, validation loss: 0.1636
2024-06-02 02:03:22 [INFO]: Epoch 088 - training loss: 0.1646, validation loss: 0.1638
2024-06-02 02:05:28 [INFO]: Epoch 089 - training loss: 0.1777, validation loss: 0.1628
2024-06-02 02:07:35 [INFO]: Epoch 090 - training loss: 0.1618, validation loss: 0.1623
2024-06-02 02:09:42 [INFO]: Epoch 091 - training loss: 0.1898, validation loss: 0.1635
2024-06-02 02:11:48 [INFO]: Epoch 092 - training loss: 0.1719, validation loss: 0.1610
2024-06-02 02:13:55 [INFO]: Epoch 093 - training loss: 0.1837, validation loss: 0.1634
2024-06-02 02:16:02 [INFO]: Epoch 094 - training loss: 0.1834, validation loss: 0.1628
2024-06-02 02:18:08 [INFO]: Epoch 095 - training loss: 0.1810, validation loss: 0.1647
2024-06-02 02:20:15 [INFO]: Epoch 096 - training loss: 0.1760, validation loss: 0.1632
2024-06-02 02:22:22 [INFO]: Epoch 097 - training loss: 0.1643, validation loss: 0.1604
2024-06-02 02:24:29 [INFO]: Epoch 098 - training loss: 0.1785, validation loss: 0.1609
2024-06-02 02:26:35 [INFO]: Epoch 099 - training loss: 0.1746, validation loss: 0.1606
2024-06-02 02:28:42 [INFO]: Epoch 100 - training loss: 0.1707, validation loss: 0.1600
2024-06-02 02:28:42 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 02:28:42 [INFO]: Saved the model to results_point_rate01/Electricity/CSDI_Electricity/round_0/20240601_T215829/CSDI.pypots
2024-06-02 02:45:47 [INFO]: Successfully saved to results_point_rate01/Electricity/CSDI_Electricity/round_0/imputation.pkl
2024-06-02 02:45:47 [INFO]: Round0 - CSDI on Electricity: MAE=1.6825, MSE=124.0335, MRE=0.9001
2024-06-02 02:45:47 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 02:45:47 [INFO]: Using the given device: cuda:0
2024-06-02 02:45:47 [INFO]: Model files will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_1/20240602_T024547
2024-06-02 02:45:47 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_1/20240602_T024547/tensorboard
2024-06-02 02:45:47 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-02 02:47:54 [INFO]: Epoch 001 - training loss: 0.6833, validation loss: 0.5035
2024-06-02 02:50:01 [INFO]: Epoch 002 - training loss: 0.3691, validation loss: 0.4333
2024-06-02 02:52:07 [INFO]: Epoch 003 - training loss: 0.3502, validation loss: 0.4153
2024-06-02 02:54:14 [INFO]: Epoch 004 - training loss: 0.3586, validation loss: 0.3993
2024-06-02 02:56:21 [INFO]: Epoch 005 - training loss: 0.3272, validation loss: 0.3755
2024-06-02 02:58:28 [INFO]: Epoch 006 - training loss: 0.2988, validation loss: 0.3661
2024-06-02 03:00:34 [INFO]: Epoch 007 - training loss: 0.3055, validation loss: 0.3684
2024-06-02 03:02:41 [INFO]: Epoch 008 - training loss: 0.2977, validation loss: 0.3402
2024-06-02 03:04:48 [INFO]: Epoch 009 - training loss: 0.2676, validation loss: 0.3215
2024-06-02 03:06:54 [INFO]: Epoch 010 - training loss: 0.2573, validation loss: 0.3178
2024-06-02 03:09:02 [INFO]: Epoch 011 - training loss: 0.2892, validation loss: 0.2998
2024-06-02 03:11:08 [INFO]: Epoch 012 - training loss: 0.2544, validation loss: 0.2942
2024-06-02 03:13:15 [INFO]: Epoch 013 - training loss: 0.2351, validation loss: 0.3069
2024-06-02 03:15:22 [INFO]: Epoch 014 - training loss: 0.2440, validation loss: 0.2941
2024-06-02 03:17:28 [INFO]: Epoch 015 - training loss: 0.2410, validation loss: 0.2765
2024-06-02 03:19:35 [INFO]: Epoch 016 - training loss: 0.2338, validation loss: 0.2635
2024-06-02 03:21:42 [INFO]: Epoch 017 - training loss: 0.2447, validation loss: 0.2646
2024-06-02 03:23:49 [INFO]: Epoch 018 - training loss: 0.2281, validation loss: 0.2529
2024-06-02 03:25:56 [INFO]: Epoch 019 - training loss: 0.2112, validation loss: 0.2449
2024-06-02 03:28:03 [INFO]: Epoch 020 - training loss: 0.2219, validation loss: 0.2422
2024-06-02 03:30:09 [INFO]: Epoch 021 - training loss: 0.2379, validation loss: 0.2347
2024-06-02 03:32:16 [INFO]: Epoch 022 - training loss: 0.2150, validation loss: 0.2310
2024-06-02 03:34:23 [INFO]: Epoch 023 - training loss: 0.2170, validation loss: 0.2249
2024-06-02 03:36:30 [INFO]: Epoch 024 - training loss: 0.2082, validation loss: 0.2256
2024-06-02 03:38:37 [INFO]: Epoch 025 - training loss: 0.2184, validation loss: 0.2171
2024-06-02 03:40:44 [INFO]: Epoch 026 - training loss: 0.2075, validation loss: 0.2175
2024-06-02 03:42:50 [INFO]: Epoch 027 - training loss: 0.1993, validation loss: 0.2126
2024-06-02 03:44:57 [INFO]: Epoch 028 - training loss: 0.2185, validation loss: 0.2101
2024-06-02 03:47:04 [INFO]: Epoch 029 - training loss: 0.2155, validation loss: 0.2086
2024-06-02 03:49:10 [INFO]: Epoch 030 - training loss: 0.1969, validation loss: 0.2079
2024-06-02 03:51:17 [INFO]: Epoch 031 - training loss: 0.1964, validation loss: 0.2032
2024-06-02 03:53:24 [INFO]: Epoch 032 - training loss: 0.2264, validation loss: 0.2024
2024-06-02 03:55:30 [INFO]: Epoch 033 - training loss: 0.2011, validation loss: 0.1966
2024-06-02 03:57:37 [INFO]: Epoch 034 - training loss: 0.1922, validation loss: 0.1991
2024-06-02 03:59:44 [INFO]: Epoch 035 - training loss: 0.1771, validation loss: 0.1972
2024-06-02 04:01:50 [INFO]: Epoch 036 - training loss: 0.2117, validation loss: 0.1938
2024-06-02 04:03:57 [INFO]: Epoch 037 - training loss: 0.2150, validation loss: 0.1984
2024-06-02 04:06:03 [INFO]: Epoch 038 - training loss: 0.1800, validation loss: 0.1928
2024-06-02 04:08:10 [INFO]: Epoch 039 - training loss: 0.1810, validation loss: 0.1923
2024-06-02 04:10:17 [INFO]: Epoch 040 - training loss: 0.1888, validation loss: 0.1915
2024-06-02 04:12:23 [INFO]: Epoch 041 - training loss: 0.2060, validation loss: 0.1918
2024-06-02 04:14:30 [INFO]: Epoch 042 - training loss: 0.1849, validation loss: 0.1905
2024-06-02 04:16:37 [INFO]: Epoch 043 - training loss: 0.1958, validation loss: 0.1915
2024-06-02 04:18:43 [INFO]: Epoch 044 - training loss: 0.2007, validation loss: 0.1867
2024-06-02 04:20:50 [INFO]: Epoch 045 - training loss: 0.1807, validation loss: 0.1853
2024-06-02 04:22:57 [INFO]: Epoch 046 - training loss: 0.1724, validation loss: 0.1862
2024-06-02 04:25:04 [INFO]: Epoch 047 - training loss: 0.1939, validation loss: 0.1826
2024-06-02 04:27:10 [INFO]: Epoch 048 - training loss: 0.1816, validation loss: 0.1829
2024-06-02 04:29:16 [INFO]: Epoch 049 - training loss: 0.2012, validation loss: 0.1808
2024-06-02 04:31:23 [INFO]: Epoch 050 - training loss: 0.1824, validation loss: 0.1811
2024-06-02 04:33:30 [INFO]: Epoch 051 - training loss: 0.1899, validation loss: 0.1797
2024-06-02 04:35:37 [INFO]: Epoch 052 - training loss: 0.1851, validation loss: 0.1864
2024-06-02 04:37:44 [INFO]: Epoch 053 - training loss: 0.1829, validation loss: 0.1806
2024-06-02 04:39:51 [INFO]: Epoch 054 - training loss: 0.1954, validation loss: 0.1817
2024-06-02 04:41:57 [INFO]: Epoch 055 - training loss: 0.1862, validation loss: 0.1802
2024-06-02 04:44:04 [INFO]: Epoch 056 - training loss: 0.1704, validation loss: 0.1773
2024-06-02 04:46:11 [INFO]: Epoch 057 - training loss: 0.1826, validation loss: 0.1812
2024-06-02 04:48:17 [INFO]: Epoch 058 - training loss: 0.1912, validation loss: 0.1809
2024-06-02 04:50:24 [INFO]: Epoch 059 - training loss: 0.1847, validation loss: 0.1799
2024-06-02 04:52:31 [INFO]: Epoch 060 - training loss: 0.1897, validation loss: 0.1771
2024-06-02 04:54:37 [INFO]: Epoch 061 - training loss: 0.1797, validation loss: 0.1769
2024-06-02 04:56:45 [INFO]: Epoch 062 - training loss: 0.1912, validation loss: 0.1760
2024-06-02 04:58:51 [INFO]: Epoch 063 - training loss: 0.1825, validation loss: 0.1755
2024-06-02 05:00:58 [INFO]: Epoch 064 - training loss: 0.1798, validation loss: 0.1749
2024-06-02 05:03:05 [INFO]: Epoch 065 - training loss: 0.1888, validation loss: 0.1747
2024-06-02 05:05:11 [INFO]: Epoch 066 - training loss: 0.1738, validation loss: 0.1744
2024-06-02 05:07:18 [INFO]: Epoch 067 - training loss: 0.1836, validation loss: 0.1744
2024-06-02 05:09:25 [INFO]: Epoch 068 - training loss: 0.1843, validation loss: 0.1752
2024-06-02 05:11:32 [INFO]: Epoch 069 - training loss: 0.1657, validation loss: 0.1748
2024-06-02 05:13:38 [INFO]: Epoch 070 - training loss: 0.1776, validation loss: 0.1741
2024-06-02 05:15:45 [INFO]: Epoch 071 - training loss: 0.1721, validation loss: 0.1772
2024-06-02 05:17:52 [INFO]: Epoch 072 - training loss: 0.1841, validation loss: 0.1761
2024-06-02 05:19:58 [INFO]: Epoch 073 - training loss: 0.1848, validation loss: 0.1735
2024-06-02 05:22:05 [INFO]: Epoch 074 - training loss: 0.1777, validation loss: 0.1725
2024-06-02 05:24:12 [INFO]: Epoch 075 - training loss: 0.1825, validation loss: 0.1701
2024-06-02 05:26:18 [INFO]: Epoch 076 - training loss: 0.1842, validation loss: 0.1711
2024-06-02 05:28:25 [INFO]: Epoch 077 - training loss: 0.1704, validation loss: 0.1859
2024-06-02 05:30:32 [INFO]: Epoch 078 - training loss: 0.1843, validation loss: 0.1753
2024-06-02 05:32:38 [INFO]: Epoch 079 - training loss: 0.1852, validation loss: 0.1702
2024-06-02 05:34:45 [INFO]: Epoch 080 - training loss: 0.1699, validation loss: 0.1727
2024-06-02 05:36:52 [INFO]: Epoch 081 - training loss: 0.1874, validation loss: 0.1717
2024-06-02 05:38:59 [INFO]: Epoch 082 - training loss: 0.1770, validation loss: 0.1708
2024-06-02 05:41:06 [INFO]: Epoch 083 - training loss: 0.1741, validation loss: 0.1690
2024-06-02 05:43:12 [INFO]: Epoch 084 - training loss: 0.1973, validation loss: 0.1697
2024-06-02 05:45:19 [INFO]: Epoch 085 - training loss: 0.1781, validation loss: 0.1685
2024-06-02 05:47:26 [INFO]: Epoch 086 - training loss: 0.1692, validation loss: 0.1674
2024-06-02 05:49:33 [INFO]: Epoch 087 - training loss: 0.1771, validation loss: 0.1725
2024-06-02 05:51:40 [INFO]: Epoch 088 - training loss: 0.1874, validation loss: 0.1710
2024-06-02 05:53:47 [INFO]: Epoch 089 - training loss: 0.1998, validation loss: 0.1688
2024-06-02 05:55:54 [INFO]: Epoch 090 - training loss: 0.1676, validation loss: 0.1684
2024-06-02 05:58:00 [INFO]: Epoch 091 - training loss: 0.1827, validation loss: 0.1687
2024-06-02 06:00:07 [INFO]: Epoch 092 - training loss: 0.1711, validation loss: 0.1678
2024-06-02 06:02:14 [INFO]: Epoch 093 - training loss: 0.1755, validation loss: 0.1656
2024-06-02 06:04:21 [INFO]: Epoch 094 - training loss: 0.1719, validation loss: 0.1688
2024-06-02 06:06:28 [INFO]: Epoch 095 - training loss: 0.1668, validation loss: 0.1721
2024-06-02 06:08:35 [INFO]: Epoch 096 - training loss: 0.1875, validation loss: 0.1737
2024-06-02 06:10:42 [INFO]: Epoch 097 - training loss: 0.1883, validation loss: 0.1659
2024-06-02 06:12:50 [INFO]: Epoch 098 - training loss: 0.1676, validation loss: 0.1668
2024-06-02 06:14:57 [INFO]: Epoch 099 - training loss: 0.1942, validation loss: 0.1659
2024-06-02 06:17:04 [INFO]: Epoch 100 - training loss: 0.1705, validation loss: 0.1639
2024-06-02 06:17:04 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 06:17:04 [INFO]: Saved the model to results_point_rate01/Electricity/CSDI_Electricity/round_1/20240602_T024547/CSDI.pypots
2024-06-02 06:34:14 [INFO]: Successfully saved to results_point_rate01/Electricity/CSDI_Electricity/round_1/imputation.pkl
2024-06-02 06:34:14 [INFO]: Round1 - CSDI on Electricity: MAE=0.7102, MSE=25.3858, MRE=0.3799
2024-06-02 06:34:14 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 06:34:14 [INFO]: Using the given device: cuda:0
2024-06-02 06:34:14 [INFO]: Model files will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_2/20240602_T063414
2024-06-02 06:34:14 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_2/20240602_T063414/tensorboard
2024-06-02 06:34:14 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-02 06:36:21 [INFO]: Epoch 001 - training loss: 0.6940, validation loss: 0.5264
2024-06-02 06:38:27 [INFO]: Epoch 002 - training loss: 0.3857, validation loss: 0.4310
2024-06-02 06:40:34 [INFO]: Epoch 003 - training loss: 0.3717, validation loss: 0.3994
2024-06-02 06:42:41 [INFO]: Epoch 004 - training loss: 0.3504, validation loss: 0.3918
2024-06-02 06:44:48 [INFO]: Epoch 005 - training loss: 0.2990, validation loss: 0.3440
2024-06-02 06:46:55 [INFO]: Epoch 006 - training loss: 0.2897, validation loss: 0.3229
2024-06-02 06:49:01 [INFO]: Epoch 007 - training loss: 0.2797, validation loss: 0.3064
2024-06-02 06:51:09 [INFO]: Epoch 008 - training loss: 0.2597, validation loss: 0.2974
2024-06-02 06:53:15 [INFO]: Epoch 009 - training loss: 0.2945, validation loss: 0.2866
2024-06-02 06:55:23 [INFO]: Epoch 010 - training loss: 0.2464, validation loss: 0.2907
2024-06-02 06:57:29 [INFO]: Epoch 011 - training loss: 0.2525, validation loss: 0.2787
2024-06-02 06:59:36 [INFO]: Epoch 012 - training loss: 0.2631, validation loss: 0.2688
2024-06-02 07:01:43 [INFO]: Epoch 013 - training loss: 0.2232, validation loss: 0.2596
2024-06-02 07:03:49 [INFO]: Epoch 014 - training loss: 0.2117, validation loss: 0.2485
2024-06-02 07:05:57 [INFO]: Epoch 015 - training loss: 0.2498, validation loss: 0.2540
2024-06-02 07:08:04 [INFO]: Epoch 016 - training loss: 0.2505, validation loss: 0.2368
2024-06-02 07:10:11 [INFO]: Epoch 017 - training loss: 0.2344, validation loss: 0.2314
2024-06-02 07:12:17 [INFO]: Epoch 018 - training loss: 0.2246, validation loss: 0.2226
2024-06-02 07:14:25 [INFO]: Epoch 019 - training loss: 0.2435, validation loss: 0.2282
2024-06-02 07:16:31 [INFO]: Epoch 020 - training loss: 0.2280, validation loss: 0.2245
2024-06-02 07:18:39 [INFO]: Epoch 021 - training loss: 0.2133, validation loss: 0.2324
2024-06-02 07:20:45 [INFO]: Epoch 022 - training loss: 0.2019, validation loss: 0.2193
2024-06-02 07:22:52 [INFO]: Epoch 023 - training loss: 0.2246, validation loss: 0.2142
2024-06-02 07:24:59 [INFO]: Epoch 024 - training loss: 0.2474, validation loss: 0.2138
2024-06-02 07:27:05 [INFO]: Epoch 025 - training loss: 0.2271, validation loss: 0.2062
2024-06-02 07:29:12 [INFO]: Epoch 026 - training loss: 0.2248, validation loss: 0.2095
2024-06-02 07:31:19 [INFO]: Epoch 027 - training loss: 0.2055, validation loss: 0.2148
2024-06-02 07:33:25 [INFO]: Epoch 028 - training loss: 0.2158, validation loss: 0.2107
2024-06-02 07:35:32 [INFO]: Epoch 029 - training loss: 0.1879, validation loss: 0.2011
2024-06-02 07:37:39 [INFO]: Epoch 030 - training loss: 0.2081, validation loss: 0.2002
2024-06-02 07:39:45 [INFO]: Epoch 031 - training loss: 0.2139, validation loss: 0.1961
2024-06-02 07:41:52 [INFO]: Epoch 032 - training loss: 0.2200, validation loss: 0.1966
2024-06-02 07:43:59 [INFO]: Epoch 033 - training loss: 0.1968, validation loss: 0.2028
2024-06-02 07:46:06 [INFO]: Epoch 034 - training loss: 0.2263, validation loss: 0.1953
2024-06-02 07:48:13 [INFO]: Epoch 035 - training loss: 0.2072, validation loss: 0.2010
2024-06-02 07:50:19 [INFO]: Epoch 036 - training loss: 0.2054, validation loss: 0.1920
2024-06-02 07:52:27 [INFO]: Epoch 037 - training loss: 0.2215, validation loss: 0.1894
2024-06-02 07:54:33 [INFO]: Epoch 038 - training loss: 0.1915, validation loss: 0.1867
2024-06-02 07:56:40 [INFO]: Epoch 039 - training loss: 0.1992, validation loss: 0.1917
2024-06-02 07:58:47 [INFO]: Epoch 040 - training loss: 0.1904, validation loss: 0.1848
2024-06-02 08:00:54 [INFO]: Epoch 041 - training loss: 0.2093, validation loss: 0.1855
2024-06-02 08:03:01 [INFO]: Epoch 042 - training loss: 0.1884, validation loss: 0.1827
2024-06-02 08:05:07 [INFO]: Epoch 043 - training loss: 0.1926, validation loss: 0.1919
2024-06-02 08:07:14 [INFO]: Epoch 044 - training loss: 0.2065, validation loss: 0.1814
2024-06-02 08:09:21 [INFO]: Epoch 045 - training loss: 0.2053, validation loss: 0.1779
2024-06-02 08:11:28 [INFO]: Epoch 046 - training loss: 0.1805, validation loss: 0.1825
2024-06-02 08:13:34 [INFO]: Epoch 047 - training loss: 0.1875, validation loss: 0.1807
2024-06-02 08:15:41 [INFO]: Epoch 048 - training loss: 0.1959, validation loss: 0.1938
2024-06-02 08:17:48 [INFO]: Epoch 049 - training loss: 0.1942, validation loss: 0.1865
2024-06-02 08:19:55 [INFO]: Epoch 050 - training loss: 0.1953, validation loss: 0.1820
2024-06-02 08:22:02 [INFO]: Epoch 051 - training loss: 0.1702, validation loss: 0.1819
2024-06-02 08:24:08 [INFO]: Epoch 052 - training loss: 0.1981, validation loss: 0.1819
2024-06-02 08:26:15 [INFO]: Epoch 053 - training loss: 0.1979, validation loss: 0.1749
2024-06-02 08:28:22 [INFO]: Epoch 054 - training loss: 0.1792, validation loss: 0.1807
2024-06-02 08:30:29 [INFO]: Epoch 055 - training loss: 0.1731, validation loss: 0.1788
2024-06-02 08:32:35 [INFO]: Epoch 056 - training loss: 0.1746, validation loss: 0.1730
2024-06-02 08:34:42 [INFO]: Epoch 057 - training loss: 0.1812, validation loss: 0.1752
2024-06-02 08:36:49 [INFO]: Epoch 058 - training loss: 0.1940, validation loss: 0.1773
2024-06-02 08:38:56 [INFO]: Epoch 059 - training loss: 0.1741, validation loss: 0.1776
2024-06-02 08:41:02 [INFO]: Epoch 060 - training loss: 0.1854, validation loss: 0.1776
2024-06-02 08:43:09 [INFO]: Epoch 061 - training loss: 0.2017, validation loss: 0.1746
2024-06-02 08:45:16 [INFO]: Epoch 062 - training loss: 0.1873, validation loss: 0.1765
2024-06-02 08:47:23 [INFO]: Epoch 063 - training loss: 0.1808, validation loss: 0.1754
2024-06-02 08:49:30 [INFO]: Epoch 064 - training loss: 0.1686, validation loss: 0.1713
2024-06-02 08:51:37 [INFO]: Epoch 065 - training loss: 0.1722, validation loss: 0.1699
2024-06-02 08:53:44 [INFO]: Epoch 066 - training loss: 0.1944, validation loss: 0.1684
2024-06-02 08:55:51 [INFO]: Epoch 067 - training loss: 0.1618, validation loss: 0.1648
2024-06-02 08:57:57 [INFO]: Epoch 068 - training loss: 0.1884, validation loss: 0.1692
2024-06-02 09:00:05 [INFO]: Epoch 069 - training loss: 0.1706, validation loss: 0.1719
2024-06-02 09:02:11 [INFO]: Epoch 070 - training loss: 0.1800, validation loss: 0.1797
2024-06-02 09:04:18 [INFO]: Epoch 071 - training loss: 0.1821, validation loss: 0.1753
2024-06-02 09:06:25 [INFO]: Epoch 072 - training loss: 0.1811, validation loss: 0.1705
2024-06-02 09:08:31 [INFO]: Epoch 073 - training loss: 0.1727, validation loss: 0.1662
2024-06-02 09:10:38 [INFO]: Epoch 074 - training loss: 0.1737, validation loss: 0.1722
2024-06-02 09:12:45 [INFO]: Epoch 075 - training loss: 0.1788, validation loss: 0.1695
2024-06-02 09:14:52 [INFO]: Epoch 076 - training loss: 0.1839, validation loss: 0.1679
2024-06-02 09:16:59 [INFO]: Epoch 077 - training loss: 0.1957, validation loss: 0.1644
2024-06-02 09:19:06 [INFO]: Epoch 078 - training loss: 0.1833, validation loss: 0.1632
2024-06-02 09:21:13 [INFO]: Epoch 079 - training loss: 0.1800, validation loss: 0.1664
2024-06-02 09:23:20 [INFO]: Epoch 080 - training loss: 0.1637, validation loss: 0.1651
2024-06-02 09:25:26 [INFO]: Epoch 081 - training loss: 0.1687, validation loss: 0.1649
2024-06-02 09:27:33 [INFO]: Epoch 082 - training loss: 0.1822, validation loss: 0.1615
2024-06-02 09:29:40 [INFO]: Epoch 083 - training loss: 0.1769, validation loss: 0.1599
2024-06-02 09:31:46 [INFO]: Epoch 084 - training loss: 0.1901, validation loss: 0.1649
2024-06-02 09:33:53 [INFO]: Epoch 085 - training loss: 0.1720, validation loss: 0.1615
2024-06-02 09:36:00 [INFO]: Epoch 086 - training loss: 0.1692, validation loss: 0.1620
2024-06-02 09:38:05 [INFO]: Epoch 087 - training loss: 0.1632, validation loss: 0.1618
2024-06-02 09:40:11 [INFO]: Epoch 088 - training loss: 0.1640, validation loss: 0.1608
2024-06-02 09:42:18 [INFO]: Epoch 089 - training loss: 0.1833, validation loss: 0.1638
2024-06-02 09:44:24 [INFO]: Epoch 090 - training loss: 0.1822, validation loss: 0.1624
2024-06-02 09:46:31 [INFO]: Epoch 091 - training loss: 0.1730, validation loss: 0.1640
2024-06-02 09:48:38 [INFO]: Epoch 092 - training loss: 0.1796, validation loss: 0.1588
2024-06-02 09:50:44 [INFO]: Epoch 093 - training loss: 0.1648, validation loss: 0.1612
2024-06-02 09:52:51 [INFO]: Epoch 094 - training loss: 0.1709, validation loss: 0.1629
2024-06-02 09:54:58 [INFO]: Epoch 095 - training loss: 0.1837, validation loss: 0.1569
2024-06-02 09:57:04 [INFO]: Epoch 096 - training loss: 0.1651, validation loss: 0.1601
2024-06-02 09:59:11 [INFO]: Epoch 097 - training loss: 0.1610, validation loss: 0.1617
2024-06-02 10:01:18 [INFO]: Epoch 098 - training loss: 0.1769, validation loss: 0.1587
2024-06-02 10:03:24 [INFO]: Epoch 099 - training loss: 0.1768, validation loss: 0.1563
2024-06-02 10:05:31 [INFO]: Epoch 100 - training loss: 0.1889, validation loss: 0.1593
2024-06-02 10:05:31 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 10:05:31 [INFO]: Saved the model to results_point_rate01/Electricity/CSDI_Electricity/round_2/20240602_T063414/CSDI.pypots
2024-06-02 10:22:36 [INFO]: Successfully saved to results_point_rate01/Electricity/CSDI_Electricity/round_2/imputation.pkl
2024-06-02 10:22:36 [INFO]: Round2 - CSDI on Electricity: MAE=1.6938, MSE=152.8954, MRE=0.9061
2024-06-02 10:22:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 10:22:36 [INFO]: Using the given device: cuda:0
2024-06-02 10:22:36 [INFO]: Model files will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_3/20240602_T102236
2024-06-02 10:22:36 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_3/20240602_T102236/tensorboard
2024-06-02 10:22:36 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-02 10:24:43 [INFO]: Epoch 001 - training loss: 0.6808, validation loss: 0.5452
2024-06-02 10:26:49 [INFO]: Epoch 002 - training loss: 0.3499, validation loss: 0.4827
2024-06-02 10:28:56 [INFO]: Epoch 003 - training loss: 0.3790, validation loss: 0.4556
2024-06-02 10:31:03 [INFO]: Epoch 004 - training loss: 0.3069, validation loss: 0.3984
2024-06-02 10:33:09 [INFO]: Epoch 005 - training loss: 0.3089, validation loss: 0.3435
2024-06-02 10:35:16 [INFO]: Epoch 006 - training loss: 0.2613, validation loss: 0.3266
2024-06-02 10:37:23 [INFO]: Epoch 007 - training loss: 0.2700, validation loss: 0.3051
2024-06-02 10:39:29 [INFO]: Epoch 008 - training loss: 0.2861, validation loss: 0.2974
2024-06-02 10:41:36 [INFO]: Epoch 009 - training loss: 0.2656, validation loss: 0.2835
2024-06-02 10:43:43 [INFO]: Epoch 010 - training loss: 0.2496, validation loss: 0.2789
2024-06-02 10:45:49 [INFO]: Epoch 011 - training loss: 0.2449, validation loss: 0.2701
2024-06-02 10:47:56 [INFO]: Epoch 012 - training loss: 0.2644, validation loss: 0.2637
2024-06-02 10:50:03 [INFO]: Epoch 013 - training loss: 0.2133, validation loss: 0.2593
2024-06-02 10:52:10 [INFO]: Epoch 014 - training loss: 0.2446, validation loss: 0.2598
2024-06-02 10:54:16 [INFO]: Epoch 015 - training loss: 0.2231, validation loss: 0.2542
2024-06-02 10:56:23 [INFO]: Epoch 016 - training loss: 0.2390, validation loss: 0.2468
2024-06-02 10:58:30 [INFO]: Epoch 017 - training loss: 0.2401, validation loss: 0.2423
2024-06-02 11:00:37 [INFO]: Epoch 018 - training loss: 0.2369, validation loss: 0.2411
2024-06-02 11:02:43 [INFO]: Epoch 019 - training loss: 0.2183, validation loss: 0.2376
2024-06-02 11:04:50 [INFO]: Epoch 020 - training loss: 0.2310, validation loss: 0.2336
2024-06-02 11:06:57 [INFO]: Epoch 021 - training loss: 0.2170, validation loss: 0.2290
2024-06-02 11:09:04 [INFO]: Epoch 022 - training loss: 0.2143, validation loss: 0.2239
2024-06-02 11:11:11 [INFO]: Epoch 023 - training loss: 0.2274, validation loss: 0.2182
2024-06-02 11:13:18 [INFO]: Epoch 024 - training loss: 0.2178, validation loss: 0.2184
2024-06-02 11:15:24 [INFO]: Epoch 025 - training loss: 0.2025, validation loss: 0.2115
2024-06-02 11:17:31 [INFO]: Epoch 026 - training loss: 0.1937, validation loss: 0.2105
2024-06-02 11:19:38 [INFO]: Epoch 027 - training loss: 0.2170, validation loss: 0.2099
2024-06-02 11:21:44 [INFO]: Epoch 028 - training loss: 0.1869, validation loss: 0.2014
2024-06-02 11:23:51 [INFO]: Epoch 029 - training loss: 0.2127, validation loss: 0.1995
2024-06-02 11:25:58 [INFO]: Epoch 030 - training loss: 0.1938, validation loss: 0.2060
2024-06-02 11:28:04 [INFO]: Epoch 031 - training loss: 0.1860, validation loss: 0.2030
2024-06-02 11:30:11 [INFO]: Epoch 032 - training loss: 0.1958, validation loss: 0.1970
2024-06-02 11:32:18 [INFO]: Epoch 033 - training loss: 0.1934, validation loss: 0.1927
2024-06-02 11:34:24 [INFO]: Epoch 034 - training loss: 0.1784, validation loss: 0.1934
2024-06-02 11:36:31 [INFO]: Epoch 035 - training loss: 0.1953, validation loss: 0.1892
2024-06-02 11:38:38 [INFO]: Epoch 036 - training loss: 0.2043, validation loss: 0.1893
2024-06-02 11:40:44 [INFO]: Epoch 037 - training loss: 0.1869, validation loss: 0.1849
2024-06-02 11:42:51 [INFO]: Epoch 038 - training loss: 0.1862, validation loss: 0.1903
2024-06-02 11:44:58 [INFO]: Epoch 039 - training loss: 0.2114, validation loss: 0.1845
2024-06-02 11:47:05 [INFO]: Epoch 040 - training loss: 0.1755, validation loss: 0.1833
2024-06-02 11:49:12 [INFO]: Epoch 041 - training loss: 0.1755, validation loss: 0.1810
2024-06-02 11:51:19 [INFO]: Epoch 042 - training loss: 0.2011, validation loss: 0.1825
2024-06-02 11:53:25 [INFO]: Epoch 043 - training loss: 0.1686, validation loss: 0.1814
2024-06-02 11:55:32 [INFO]: Epoch 044 - training loss: 0.1898, validation loss: 0.1778
2024-06-02 11:57:39 [INFO]: Epoch 045 - training loss: 0.1832, validation loss: 0.1807
2024-06-02 11:59:45 [INFO]: Epoch 046 - training loss: 0.2081, validation loss: 0.1855
2024-06-02 12:01:52 [INFO]: Epoch 047 - training loss: 0.1879, validation loss: 0.1866
2024-06-02 12:03:59 [INFO]: Epoch 048 - training loss: 0.1883, validation loss: 0.1799
2024-06-02 12:06:05 [INFO]: Epoch 049 - training loss: 0.1927, validation loss: 0.1777
2024-06-02 12:08:13 [INFO]: Epoch 050 - training loss: 0.1857, validation loss: 0.1769
2024-06-02 12:10:19 [INFO]: Epoch 051 - training loss: 0.1757, validation loss: 0.1804
2024-06-02 12:12:26 [INFO]: Epoch 052 - training loss: 0.1877, validation loss: 0.1746
2024-06-02 12:14:32 [INFO]: Epoch 053 - training loss: 0.1911, validation loss: 0.1779
2024-06-02 12:16:39 [INFO]: Epoch 054 - training loss: 0.1806, validation loss: 0.1761
2024-06-02 12:18:46 [INFO]: Epoch 055 - training loss: 0.1640, validation loss: 0.1767
2024-06-02 12:20:52 [INFO]: Epoch 056 - training loss: 0.1830, validation loss: 0.1794
2024-06-02 12:22:59 [INFO]: Epoch 057 - training loss: 0.1900, validation loss: 0.1740
2024-06-02 12:25:06 [INFO]: Epoch 058 - training loss: 0.1889, validation loss: 0.1744
2024-06-02 12:27:12 [INFO]: Epoch 059 - training loss: 0.1873, validation loss: 0.1745
2024-06-02 12:29:19 [INFO]: Epoch 060 - training loss: 0.1766, validation loss: 0.1764
2024-06-02 12:31:26 [INFO]: Epoch 061 - training loss: 0.2079, validation loss: 0.1982
2024-06-02 12:33:32 [INFO]: Epoch 062 - training loss: 0.1837, validation loss: 0.1885
2024-06-02 12:35:39 [INFO]: Epoch 063 - training loss: 0.1834, validation loss: 0.1773
2024-06-02 12:37:45 [INFO]: Epoch 064 - training loss: 0.1870, validation loss: 0.1743
2024-06-02 12:39:52 [INFO]: Epoch 065 - training loss: 0.1910, validation loss: 0.1724
2024-06-02 12:41:59 [INFO]: Epoch 066 - training loss: 0.1805, validation loss: 0.1735
2024-06-02 12:44:05 [INFO]: Epoch 067 - training loss: 0.1777, validation loss: 0.1758
2024-06-02 12:46:12 [INFO]: Epoch 068 - training loss: 0.1816, validation loss: 0.1714
2024-06-02 12:48:19 [INFO]: Epoch 069 - training loss: 0.1620, validation loss: 0.1725
2024-06-02 12:50:25 [INFO]: Epoch 070 - training loss: 0.1981, validation loss: 0.1733
2024-06-02 12:52:32 [INFO]: Epoch 071 - training loss: 0.1761, validation loss: 0.1689
2024-06-02 12:54:39 [INFO]: Epoch 072 - training loss: 0.1722, validation loss: 0.1700
2024-06-02 12:56:45 [INFO]: Epoch 073 - training loss: 0.1914, validation loss: 0.1770
2024-06-02 12:58:52 [INFO]: Epoch 074 - training loss: 0.1747, validation loss: 0.1731
2024-06-02 13:00:58 [INFO]: Epoch 075 - training loss: 0.2133, validation loss: 0.1704
2024-06-02 13:03:05 [INFO]: Epoch 076 - training loss: 0.1846, validation loss: 0.1725
2024-06-02 13:05:12 [INFO]: Epoch 077 - training loss: 0.1829, validation loss: 0.1677
2024-06-02 13:07:18 [INFO]: Epoch 078 - training loss: 0.1809, validation loss: 0.1661
2024-06-02 13:09:25 [INFO]: Epoch 079 - training loss: 0.1677, validation loss: 0.1689
2024-06-02 13:11:32 [INFO]: Epoch 080 - training loss: 0.1729, validation loss: 0.1689
2024-06-02 13:13:38 [INFO]: Epoch 081 - training loss: 0.1930, validation loss: 0.1648
2024-06-02 13:15:45 [INFO]: Epoch 082 - training loss: 0.1700, validation loss: 0.1654
2024-06-02 13:17:52 [INFO]: Epoch 083 - training loss: 0.1683, validation loss: 0.1789
2024-06-02 13:19:58 [INFO]: Epoch 084 - training loss: 0.1841, validation loss: 0.1713
2024-06-02 13:22:05 [INFO]: Epoch 085 - training loss: 0.1741, validation loss: 0.1657
2024-06-02 13:24:12 [INFO]: Epoch 086 - training loss: 0.1655, validation loss: 0.1639
2024-06-02 13:26:18 [INFO]: Epoch 087 - training loss: 0.1821, validation loss: 0.1700
2024-06-02 13:28:25 [INFO]: Epoch 088 - training loss: 0.1917, validation loss: 0.1724
2024-06-02 13:30:32 [INFO]: Epoch 089 - training loss: 0.1752, validation loss: 0.1675
2024-06-02 13:32:39 [INFO]: Epoch 090 - training loss: 0.1731, validation loss: 0.1684
2024-06-02 13:34:45 [INFO]: Epoch 091 - training loss: 0.1590, validation loss: 0.1661
2024-06-02 13:36:52 [INFO]: Epoch 092 - training loss: 0.1940, validation loss: 0.1660
2024-06-02 13:38:59 [INFO]: Epoch 093 - training loss: 0.1703, validation loss: 0.1682
2024-06-02 13:41:05 [INFO]: Epoch 094 - training loss: 0.1831, validation loss: 0.1679
2024-06-02 13:43:12 [INFO]: Epoch 095 - training loss: 0.1778, validation loss: 0.1736
2024-06-02 13:45:19 [INFO]: Epoch 096 - training loss: 0.1760, validation loss: 0.1658
2024-06-02 13:45:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 13:45:19 [INFO]: Finished training. The best model is from epoch#86.
2024-06-02 13:45:19 [INFO]: Saved the model to results_point_rate01/Electricity/CSDI_Electricity/round_3/20240602_T102236/CSDI.pypots
2024-06-02 14:02:24 [INFO]: Successfully saved to results_point_rate01/Electricity/CSDI_Electricity/round_3/imputation.pkl
2024-06-02 14:02:24 [INFO]: Round3 - CSDI on Electricity: MAE=2.0546, MSE=201.7743, MRE=1.0991
2024-06-02 14:02:24 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 14:02:24 [INFO]: Using the given device: cuda:0
2024-06-02 14:02:24 [INFO]: Model files will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_4/20240602_T140224
2024-06-02 14:02:24 [INFO]: Tensorboard file will be saved to results_point_rate01/Electricity/CSDI_Electricity/round_4/20240602_T140224/tensorboard
2024-06-02 14:02:24 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-02 14:04:31 [INFO]: Epoch 001 - training loss: 0.6988, validation loss: 0.6234
2024-06-02 14:06:38 [INFO]: Epoch 002 - training loss: 0.4000, validation loss: 0.4672
2024-06-02 14:08:44 [INFO]: Epoch 003 - training loss: 0.3542, validation loss: 0.4402
2024-06-02 14:10:51 [INFO]: Epoch 004 - training loss: 0.3260, validation loss: 0.4192
2024-06-02 14:12:57 [INFO]: Epoch 005 - training loss: 0.3276, validation loss: 0.3835
2024-06-02 14:15:04 [INFO]: Epoch 006 - training loss: 0.3108, validation loss: 0.3537
2024-06-02 14:17:11 [INFO]: Epoch 007 - training loss: 0.2901, validation loss: 0.3458
2024-06-02 14:19:18 [INFO]: Epoch 008 - training loss: 0.2789, validation loss: 0.3381
2024-06-02 14:21:25 [INFO]: Epoch 009 - training loss: 0.2507, validation loss: 0.3327
2024-06-02 14:23:32 [INFO]: Epoch 010 - training loss: 0.2404, validation loss: 0.3092
2024-06-02 14:25:39 [INFO]: Epoch 011 - training loss: 0.2745, validation loss: 0.3114
2024-06-02 14:27:45 [INFO]: Epoch 012 - training loss: 0.2575, validation loss: 0.2938
2024-06-02 14:29:52 [INFO]: Epoch 013 - training loss: 0.2309, validation loss: 0.2923
2024-06-02 14:31:59 [INFO]: Epoch 014 - training loss: 0.2268, validation loss: 0.2820
2024-06-02 14:34:06 [INFO]: Epoch 015 - training loss: 0.2308, validation loss: 0.2649
2024-06-02 14:36:12 [INFO]: Epoch 016 - training loss: 0.2253, validation loss: 0.2572
2024-06-02 14:38:19 [INFO]: Epoch 017 - training loss: 0.2225, validation loss: 0.2397
2024-06-02 14:40:25 [INFO]: Epoch 018 - training loss: 0.2426, validation loss: 0.2311
2024-06-02 14:42:31 [INFO]: Epoch 019 - training loss: 0.2072, validation loss: 0.2227
2024-06-02 14:44:38 [INFO]: Epoch 020 - training loss: 0.1891, validation loss: 0.2190
2024-06-02 14:46:44 [INFO]: Epoch 021 - training loss: 0.1985, validation loss: 0.2135
2024-06-02 14:48:51 [INFO]: Epoch 022 - training loss: 0.2137, validation loss: 0.2069
2024-06-02 14:50:58 [INFO]: Epoch 023 - training loss: 0.1841, validation loss: 0.2064
2024-06-02 14:53:04 [INFO]: Epoch 024 - training loss: 0.1906, validation loss: 0.2046
2024-06-02 14:55:11 [INFO]: Epoch 025 - training loss: 0.2115, validation loss: 0.2357
2024-06-02 14:57:18 [INFO]: Epoch 026 - training loss: 0.2071, validation loss: 0.2072
2024-06-02 14:59:24 [INFO]: Epoch 027 - training loss: 0.1910, validation loss: 0.2042
2024-06-02 15:01:31 [INFO]: Epoch 028 - training loss: 0.1904, validation loss: 0.1960
2024-06-02 15:03:38 [INFO]: Epoch 029 - training loss: 0.1728, validation loss: 0.1952
2024-06-02 15:05:44 [INFO]: Epoch 030 - training loss: 0.1860, validation loss: 0.1919
2024-06-02 15:07:51 [INFO]: Epoch 031 - training loss: 0.1829, validation loss: 0.1912
2024-06-02 15:09:58 [INFO]: Epoch 032 - training loss: 0.1984, validation loss: 0.1896
2024-06-02 15:12:05 [INFO]: Epoch 033 - training loss: 0.1921, validation loss: 0.1899
2024-06-02 15:14:12 [INFO]: Epoch 034 - training loss: 0.2035, validation loss: 0.1864
2024-06-02 15:16:18 [INFO]: Epoch 035 - training loss: 0.2271, validation loss: 0.1872
2024-06-02 15:18:25 [INFO]: Epoch 036 - training loss: 0.2010, validation loss: 0.1856
2024-06-02 15:20:32 [INFO]: Epoch 037 - training loss: 0.1872, validation loss: 0.1883
2024-06-02 15:22:38 [INFO]: Epoch 038 - training loss: 0.1779, validation loss: 0.1853
2024-06-02 15:24:46 [INFO]: Epoch 039 - training loss: 0.1937, validation loss: 0.1837
2024-06-02 15:26:52 [INFO]: Epoch 040 - training loss: 0.1621, validation loss: 0.1829
2024-06-02 15:28:59 [INFO]: Epoch 041 - training loss: 0.1716, validation loss: 0.1849
2024-06-02 15:31:05 [INFO]: Epoch 042 - training loss: 0.1606, validation loss: 0.1937
2024-06-02 15:33:12 [INFO]: Epoch 043 - training loss: 0.1971, validation loss: 0.1827
2024-06-02 15:35:19 [INFO]: Epoch 044 - training loss: 0.1791, validation loss: 0.1819
2024-06-02 15:37:26 [INFO]: Epoch 045 - training loss: 0.1879, validation loss: 0.1781
2024-06-02 15:39:33 [INFO]: Epoch 046 - training loss: 0.1887, validation loss: 0.1778
2024-06-02 15:41:39 [INFO]: Epoch 047 - training loss: 0.1851, validation loss: 0.1765
2024-06-02 15:43:46 [INFO]: Epoch 048 - training loss: 0.1776, validation loss: 0.1745
2024-06-02 15:45:53 [INFO]: Epoch 049 - training loss: 0.1937, validation loss: 0.1756
2024-06-02 15:47:59 [INFO]: Epoch 050 - training loss: 0.2025, validation loss: 0.1721
2024-06-02 15:50:06 [INFO]: Epoch 051 - training loss: 0.2016, validation loss: 0.1779
2024-06-02 15:52:13 [INFO]: Epoch 052 - training loss: 0.1920, validation loss: 0.1728
2024-06-02 15:54:19 [INFO]: Epoch 053 - training loss: 0.1784, validation loss: 0.1739
2024-06-02 15:56:26 [INFO]: Epoch 054 - training loss: 0.1996, validation loss: 0.1737
2024-06-02 15:58:33 [INFO]: Epoch 055 - training loss: 0.1797, validation loss: 0.1724
2024-06-02 16:00:39 [INFO]: Epoch 056 - training loss: 0.1967, validation loss: 0.1723
2024-06-02 16:02:46 [INFO]: Epoch 057 - training loss: 0.1864, validation loss: 0.1916
2024-06-02 16:04:52 [INFO]: Epoch 058 - training loss: 0.1906, validation loss: 0.1693
2024-06-02 16:06:59 [INFO]: Epoch 059 - training loss: 0.2056, validation loss: 0.1754
2024-06-02 16:09:06 [INFO]: Epoch 060 - training loss: 0.1729, validation loss: 0.1683
2024-06-02 16:11:12 [INFO]: Epoch 061 - training loss: 0.1601, validation loss: 0.1705
2024-06-02 16:13:19 [INFO]: Epoch 062 - training loss: 0.1763, validation loss: 0.1698
2024-06-02 16:15:26 [INFO]: Epoch 063 - training loss: 0.1851, validation loss: 0.1704
2024-06-02 16:17:33 [INFO]: Epoch 064 - training loss: 0.1773, validation loss: 0.1671
2024-06-02 16:19:39 [INFO]: Epoch 065 - training loss: 0.1868, validation loss: 0.1695
2024-06-02 16:21:46 [INFO]: Epoch 066 - training loss: 0.1772, validation loss: 0.1673
2024-06-02 16:23:53 [INFO]: Epoch 067 - training loss: 0.1798, validation loss: 0.1725
2024-06-02 16:25:59 [INFO]: Epoch 068 - training loss: 0.1848, validation loss: 0.1702
2024-06-02 16:28:06 [INFO]: Epoch 069 - training loss: 0.1686, validation loss: 0.1691
2024-06-02 16:30:13 [INFO]: Epoch 070 - training loss: 0.1790, validation loss: 0.1676
2024-06-02 16:32:19 [INFO]: Epoch 071 - training loss: 0.1812, validation loss: 0.1725
2024-06-02 16:34:26 [INFO]: Epoch 072 - training loss: 0.1806, validation loss: 0.1667
2024-06-02 16:36:33 [INFO]: Epoch 073 - training loss: 0.1714, validation loss: 0.1660
2024-06-02 16:38:39 [INFO]: Epoch 074 - training loss: 0.1742, validation loss: 0.1702
2024-06-02 16:40:46 [INFO]: Epoch 075 - training loss: 0.1698, validation loss: 0.1699
2024-06-02 16:42:52 [INFO]: Epoch 076 - training loss: 0.1690, validation loss: 0.1674
2024-06-02 16:44:59 [INFO]: Epoch 077 - training loss: 0.1666, validation loss: 0.1672
2024-06-02 16:47:06 [INFO]: Epoch 078 - training loss: 0.1698, validation loss: 0.1642
2024-06-02 16:49:12 [INFO]: Epoch 079 - training loss: 0.1744, validation loss: 0.1666
2024-06-02 16:51:19 [INFO]: Epoch 080 - training loss: 0.1733, validation loss: 0.1634
2024-06-02 16:53:25 [INFO]: Epoch 081 - training loss: 0.1756, validation loss: 0.1655
2024-06-02 16:55:32 [INFO]: Epoch 082 - training loss: 0.1783, validation loss: 0.1632
2024-06-02 16:57:39 [INFO]: Epoch 083 - training loss: 0.1898, validation loss: 0.1670
2024-06-02 16:59:45 [INFO]: Epoch 084 - training loss: 0.1774, validation loss: 0.1666
2024-06-02 17:01:52 [INFO]: Epoch 085 - training loss: 0.1602, validation loss: 0.1651
2024-06-02 17:03:58 [INFO]: Epoch 086 - training loss: 0.1566, validation loss: 0.1644
2024-06-02 17:06:05 [INFO]: Epoch 087 - training loss: 0.1747, validation loss: 0.1638
2024-06-02 17:08:12 [INFO]: Epoch 088 - training loss: 0.1657, validation loss: 0.1621
2024-06-02 17:10:18 [INFO]: Epoch 089 - training loss: 0.1563, validation loss: 0.1640
2024-06-02 17:12:25 [INFO]: Epoch 090 - training loss: 0.1681, validation loss: 0.1637
2024-06-02 17:14:31 [INFO]: Epoch 091 - training loss: 0.1669, validation loss: 0.1621
2024-06-02 17:16:38 [INFO]: Epoch 092 - training loss: 0.1728, validation loss: 0.1615
2024-06-02 17:18:45 [INFO]: Epoch 093 - training loss: 0.1540, validation loss: 0.1637
2024-06-02 17:20:51 [INFO]: Epoch 094 - training loss: 0.1643, validation loss: 0.1656
2024-06-02 17:22:58 [INFO]: Epoch 095 - training loss: 0.1804, validation loss: 0.1616
2024-06-02 17:25:04 [INFO]: Epoch 096 - training loss: 0.1894, validation loss: 0.1635
2024-06-02 17:27:11 [INFO]: Epoch 097 - training loss: 0.1686, validation loss: 0.1732
2024-06-02 17:29:17 [INFO]: Epoch 098 - training loss: 0.1720, validation loss: 0.1650
2024-06-02 17:31:24 [INFO]: Epoch 099 - training loss: 0.1684, validation loss: 0.1632
2024-06-02 17:33:31 [INFO]: Epoch 100 - training loss: 0.1754, validation loss: 0.1624
2024-06-02 17:33:31 [INFO]: Finished training. The best model is from epoch#92.
2024-06-02 17:33:31 [INFO]: Saved the model to results_point_rate01/Electricity/CSDI_Electricity/round_4/20240602_T140224/CSDI.pypots
2024-06-02 17:50:36 [INFO]: Successfully saved to results_point_rate01/Electricity/CSDI_Electricity/round_4/imputation.pkl
2024-06-02 17:50:36 [INFO]: Round4 - CSDI on Electricity: MAE=1.2756, MSE=85.4820, MRE=0.6824
2024-06-02 17:50:36 [INFO]: Done! Final results:
Averaged CSDI (n params: 43,185) on Electricity: MAE=1.4833 ± 0.4585332973133529, MSE=117.9142 ± 59.844791538607495, MRE=0.7935 ± 0.24529396008466176, average inference time=1025.88
