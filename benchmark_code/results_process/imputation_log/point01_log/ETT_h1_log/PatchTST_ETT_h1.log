2024-06-01 22:19:19 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:19:19 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:19 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_0/20240601_T221919
2024-06-01 22:19:19 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_0/20240601_T221919/tensorboard
2024-06-01 22:19:19 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-01 22:19:19 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-01 22:19:19 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-01 22:19:21 [INFO]: Epoch 001 - training loss: 1.6122, validation loss: 1.2419
2024-06-01 22:19:21 [INFO]: Epoch 002 - training loss: 1.3552, validation loss: 0.7901
2024-06-01 22:19:22 [INFO]: Epoch 003 - training loss: 1.0261, validation loss: 0.5775
2024-06-01 22:19:22 [INFO]: Epoch 004 - training loss: 0.8952, validation loss: 0.5941
2024-06-01 22:19:22 [INFO]: Epoch 005 - training loss: 0.8446, validation loss: 0.4200
2024-06-01 22:19:22 [INFO]: Epoch 006 - training loss: 0.7977, validation loss: 0.3270
2024-06-01 22:19:23 [INFO]: Epoch 007 - training loss: 0.7002, validation loss: 0.1948
2024-06-01 22:19:23 [INFO]: Epoch 008 - training loss: 0.6196, validation loss: 0.1403
2024-06-01 22:19:23 [INFO]: Epoch 009 - training loss: 0.5601, validation loss: 0.1890
2024-06-01 22:19:23 [INFO]: Epoch 010 - training loss: 0.4995, validation loss: 0.1045
2024-06-01 22:19:23 [INFO]: Epoch 011 - training loss: 0.4742, validation loss: 0.1038
2024-06-01 22:19:24 [INFO]: Epoch 012 - training loss: 0.4650, validation loss: 0.1362
2024-06-01 22:19:24 [INFO]: Epoch 013 - training loss: 0.4592, validation loss: 0.0958
2024-06-01 22:19:24 [INFO]: Epoch 014 - training loss: 0.4663, validation loss: 0.1002
2024-06-01 22:19:24 [INFO]: Epoch 015 - training loss: 0.4532, validation loss: 0.1213
2024-06-01 22:19:24 [INFO]: Epoch 016 - training loss: 0.4436, validation loss: 0.0924
2024-06-01 22:19:25 [INFO]: Epoch 017 - training loss: 0.4319, validation loss: 0.0907
2024-06-01 22:19:25 [INFO]: Epoch 018 - training loss: 0.4281, validation loss: 0.0889
2024-06-01 22:19:25 [INFO]: Epoch 019 - training loss: 0.4298, validation loss: 0.0950
2024-06-01 22:19:25 [INFO]: Epoch 020 - training loss: 0.4250, validation loss: 0.1010
2024-06-01 22:19:25 [INFO]: Epoch 021 - training loss: 0.4297, validation loss: 0.0979
2024-06-01 22:19:26 [INFO]: Epoch 022 - training loss: 0.4203, validation loss: 0.0807
2024-06-01 22:19:26 [INFO]: Epoch 023 - training loss: 0.4210, validation loss: 0.0840
2024-06-01 22:19:26 [INFO]: Epoch 024 - training loss: 0.4132, validation loss: 0.0927
2024-06-01 22:19:26 [INFO]: Epoch 025 - training loss: 0.4174, validation loss: 0.1025
2024-06-01 22:19:27 [INFO]: Epoch 026 - training loss: 0.4166, validation loss: 0.0853
2024-06-01 22:19:27 [INFO]: Epoch 027 - training loss: 0.4163, validation loss: 0.0889
2024-06-01 22:19:27 [INFO]: Epoch 028 - training loss: 0.4090, validation loss: 0.0910
2024-06-01 22:19:27 [INFO]: Epoch 029 - training loss: 0.4082, validation loss: 0.0924
2024-06-01 22:19:27 [INFO]: Epoch 030 - training loss: 0.4189, validation loss: 0.1369
2024-06-01 22:19:28 [INFO]: Epoch 031 - training loss: 0.4450, validation loss: 0.1012
2024-06-01 22:19:28 [INFO]: Epoch 032 - training loss: 0.4195, validation loss: 0.0782
2024-06-01 22:19:28 [INFO]: Epoch 033 - training loss: 0.4087, validation loss: 0.1073
2024-06-01 22:19:28 [INFO]: Epoch 034 - training loss: 0.4181, validation loss: 0.0899
2024-06-01 22:19:29 [INFO]: Epoch 035 - training loss: 0.4193, validation loss: 0.0782
2024-06-01 22:19:29 [INFO]: Epoch 036 - training loss: 0.4066, validation loss: 0.0916
2024-06-01 22:19:29 [INFO]: Epoch 037 - training loss: 0.4122, validation loss: 0.1029
2024-06-01 22:19:29 [INFO]: Epoch 038 - training loss: 0.4112, validation loss: 0.0842
2024-06-01 22:19:29 [INFO]: Epoch 039 - training loss: 0.4052, validation loss: 0.0836
2024-06-01 22:19:30 [INFO]: Epoch 040 - training loss: 0.4084, validation loss: 0.0913
2024-06-01 22:19:30 [INFO]: Epoch 041 - training loss: 0.4016, validation loss: 0.0907
2024-06-01 22:19:30 [INFO]: Epoch 042 - training loss: 0.4026, validation loss: 0.0932
2024-06-01 22:19:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:30 [INFO]: Finished training. The best model is from epoch#32.
2024-06-01 22:19:30 [INFO]: Saved the model to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_0/20240601_T221919/PatchTST.pypots
2024-06-01 22:19:30 [INFO]: Successfully saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_0/imputation.pkl
2024-06-01 22:19:30 [INFO]: Round0 - PatchTST on ETT_h1: MAE=0.2508, MSE=0.1196, MRE=0.2960
2024-06-01 22:19:30 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:19:30 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:30 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_1/20240601_T221930
2024-06-01 22:19:30 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_1/20240601_T221930/tensorboard
2024-06-01 22:19:30 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-01 22:19:30 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-01 22:19:30 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-01 22:19:30 [INFO]: Epoch 001 - training loss: 1.6985, validation loss: 1.1321
2024-06-01 22:19:31 [INFO]: Epoch 002 - training loss: 1.1246, validation loss: 0.6301
2024-06-01 22:19:31 [INFO]: Epoch 003 - training loss: 0.9823, validation loss: 0.5047
2024-06-01 22:19:31 [INFO]: Epoch 004 - training loss: 0.8709, validation loss: 0.4297
2024-06-01 22:19:31 [INFO]: Epoch 005 - training loss: 0.8283, validation loss: 0.5135
2024-06-01 22:19:31 [INFO]: Epoch 006 - training loss: 0.8143, validation loss: 0.3416
2024-06-01 22:19:32 [INFO]: Epoch 007 - training loss: 0.7509, validation loss: 0.3007
2024-06-01 22:19:32 [INFO]: Epoch 008 - training loss: 0.6628, validation loss: 0.1933
2024-06-01 22:19:32 [INFO]: Epoch 009 - training loss: 0.6180, validation loss: 0.1509
2024-06-01 22:19:32 [INFO]: Epoch 010 - training loss: 0.5570, validation loss: 0.1289
2024-06-01 22:19:33 [INFO]: Epoch 011 - training loss: 0.5354, validation loss: 0.1403
2024-06-01 22:19:33 [INFO]: Epoch 012 - training loss: 0.5156, validation loss: 0.1491
2024-06-01 22:19:33 [INFO]: Epoch 013 - training loss: 0.4961, validation loss: 0.1075
2024-06-01 22:19:33 [INFO]: Epoch 014 - training loss: 0.4903, validation loss: 0.1409
2024-06-01 22:19:33 [INFO]: Epoch 015 - training loss: 0.4700, validation loss: 0.1154
2024-06-01 22:19:34 [INFO]: Epoch 016 - training loss: 0.4521, validation loss: 0.1120
2024-06-01 22:19:34 [INFO]: Epoch 017 - training loss: 0.4491, validation loss: 0.1040
2024-06-01 22:19:34 [INFO]: Epoch 018 - training loss: 0.4363, validation loss: 0.0998
2024-06-01 22:19:34 [INFO]: Epoch 019 - training loss: 0.4369, validation loss: 0.0967
2024-06-01 22:19:35 [INFO]: Epoch 020 - training loss: 0.4321, validation loss: 0.0985
2024-06-01 22:19:35 [INFO]: Epoch 021 - training loss: 0.4257, validation loss: 0.0960
2024-06-01 22:19:35 [INFO]: Epoch 022 - training loss: 0.4310, validation loss: 0.1018
2024-06-01 22:19:35 [INFO]: Epoch 023 - training loss: 0.4263, validation loss: 0.1330
2024-06-01 22:19:36 [INFO]: Epoch 024 - training loss: 0.4280, validation loss: 0.1016
2024-06-01 22:19:36 [INFO]: Epoch 025 - training loss: 0.4173, validation loss: 0.0831
2024-06-01 22:19:36 [INFO]: Epoch 026 - training loss: 0.4096, validation loss: 0.0930
2024-06-01 22:19:36 [INFO]: Epoch 027 - training loss: 0.4131, validation loss: 0.1071
2024-06-01 22:19:36 [INFO]: Epoch 028 - training loss: 0.4116, validation loss: 0.1004
2024-06-01 22:19:37 [INFO]: Epoch 029 - training loss: 0.4059, validation loss: 0.0828
2024-06-01 22:19:37 [INFO]: Epoch 030 - training loss: 0.4086, validation loss: 0.0892
2024-06-01 22:19:37 [INFO]: Epoch 031 - training loss: 0.3972, validation loss: 0.0884
2024-06-01 22:19:37 [INFO]: Epoch 032 - training loss: 0.3970, validation loss: 0.0867
2024-06-01 22:19:37 [INFO]: Epoch 033 - training loss: 0.4003, validation loss: 0.0964
2024-06-01 22:19:38 [INFO]: Epoch 034 - training loss: 0.3965, validation loss: 0.0863
2024-06-01 22:19:38 [INFO]: Epoch 035 - training loss: 0.4011, validation loss: 0.0988
2024-06-01 22:19:38 [INFO]: Epoch 036 - training loss: 0.4007, validation loss: 0.0854
2024-06-01 22:19:38 [INFO]: Epoch 037 - training loss: 0.4024, validation loss: 0.0872
2024-06-01 22:19:38 [INFO]: Epoch 038 - training loss: 0.3968, validation loss: 0.0874
2024-06-01 22:19:39 [INFO]: Epoch 039 - training loss: 0.3950, validation loss: 0.0961
2024-06-01 22:19:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:39 [INFO]: Finished training. The best model is from epoch#29.
2024-06-01 22:19:39 [INFO]: Saved the model to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_1/20240601_T221930/PatchTST.pypots
2024-06-01 22:19:39 [INFO]: Successfully saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_1/imputation.pkl
2024-06-01 22:19:39 [INFO]: Round1 - PatchTST on ETT_h1: MAE=0.2541, MSE=0.1301, MRE=0.2999
2024-06-01 22:19:39 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:19:39 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:39 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_2/20240601_T221939
2024-06-01 22:19:39 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_2/20240601_T221939/tensorboard
2024-06-01 22:19:39 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-01 22:19:39 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-01 22:19:39 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-01 22:19:39 [INFO]: Epoch 001 - training loss: 1.4958, validation loss: 0.8805
2024-06-01 22:19:39 [INFO]: Epoch 002 - training loss: 1.1138, validation loss: 0.5846
2024-06-01 22:19:39 [INFO]: Epoch 003 - training loss: 0.9298, validation loss: 0.4429
2024-06-01 22:19:40 [INFO]: Epoch 004 - training loss: 0.8352, validation loss: 0.3484
2024-06-01 22:19:40 [INFO]: Epoch 005 - training loss: 0.7298, validation loss: 0.1889
2024-06-01 22:19:40 [INFO]: Epoch 006 - training loss: 0.6046, validation loss: 0.1284
2024-06-01 22:19:40 [INFO]: Epoch 007 - training loss: 0.5308, validation loss: 0.1156
2024-06-01 22:19:41 [INFO]: Epoch 008 - training loss: 0.5031, validation loss: 0.1066
2024-06-01 22:19:41 [INFO]: Epoch 009 - training loss: 0.4831, validation loss: 0.0984
2024-06-01 22:19:41 [INFO]: Epoch 010 - training loss: 0.4689, validation loss: 0.0889
2024-06-01 22:19:41 [INFO]: Epoch 011 - training loss: 0.4545, validation loss: 0.1012
2024-06-01 22:19:41 [INFO]: Epoch 012 - training loss: 0.4413, validation loss: 0.0911
2024-06-01 22:19:42 [INFO]: Epoch 013 - training loss: 0.4407, validation loss: 0.1023
2024-06-01 22:19:42 [INFO]: Epoch 014 - training loss: 0.4482, validation loss: 0.0810
2024-06-01 22:19:42 [INFO]: Epoch 015 - training loss: 0.4394, validation loss: 0.0817
2024-06-01 22:19:42 [INFO]: Epoch 016 - training loss: 0.4346, validation loss: 0.0995
2024-06-01 22:19:43 [INFO]: Epoch 017 - training loss: 0.4306, validation loss: 0.0875
2024-06-01 22:19:43 [INFO]: Epoch 018 - training loss: 0.4244, validation loss: 0.0831
2024-06-01 22:19:43 [INFO]: Epoch 019 - training loss: 0.4217, validation loss: 0.0826
2024-06-01 22:19:43 [INFO]: Epoch 020 - training loss: 0.4218, validation loss: 0.0938
2024-06-01 22:19:43 [INFO]: Epoch 021 - training loss: 0.4250, validation loss: 0.0927
2024-06-01 22:19:44 [INFO]: Epoch 022 - training loss: 0.4222, validation loss: 0.1115
2024-06-01 22:19:44 [INFO]: Epoch 023 - training loss: 0.4320, validation loss: 0.0814
2024-06-01 22:19:44 [INFO]: Epoch 024 - training loss: 0.4243, validation loss: 0.0781
2024-06-01 22:19:44 [INFO]: Epoch 025 - training loss: 0.4144, validation loss: 0.0967
2024-06-01 22:19:45 [INFO]: Epoch 026 - training loss: 0.4175, validation loss: 0.0919
2024-06-01 22:19:45 [INFO]: Epoch 027 - training loss: 0.4152, validation loss: 0.0895
2024-06-01 22:19:45 [INFO]: Epoch 028 - training loss: 0.4219, validation loss: 0.0912
2024-06-01 22:19:45 [INFO]: Epoch 029 - training loss: 0.4129, validation loss: 0.0800
2024-06-01 22:19:45 [INFO]: Epoch 030 - training loss: 0.4141, validation loss: 0.0896
2024-06-01 22:19:45 [INFO]: Epoch 031 - training loss: 0.4070, validation loss: 0.0822
2024-06-01 22:19:46 [INFO]: Epoch 032 - training loss: 0.4005, validation loss: 0.0794
2024-06-01 22:19:46 [INFO]: Epoch 033 - training loss: 0.4097, validation loss: 0.0893
2024-06-01 22:19:46 [INFO]: Epoch 034 - training loss: 0.4099, validation loss: 0.0763
2024-06-01 22:19:46 [INFO]: Epoch 035 - training loss: 0.4131, validation loss: 0.0993
2024-06-01 22:19:46 [INFO]: Epoch 036 - training loss: 0.4113, validation loss: 0.0753
2024-06-01 22:19:46 [INFO]: Epoch 037 - training loss: 0.4038, validation loss: 0.0757
2024-06-01 22:19:46 [INFO]: Epoch 038 - training loss: 0.4068, validation loss: 0.0774
2024-06-01 22:19:47 [INFO]: Epoch 039 - training loss: 0.4045, validation loss: 0.0812
2024-06-01 22:19:47 [INFO]: Epoch 040 - training loss: 0.4004, validation loss: 0.0773
2024-06-01 22:19:47 [INFO]: Epoch 041 - training loss: 0.3900, validation loss: 0.0816
2024-06-01 22:19:47 [INFO]: Epoch 042 - training loss: 0.3925, validation loss: 0.0752
2024-06-01 22:19:47 [INFO]: Epoch 043 - training loss: 0.3967, validation loss: 0.0765
2024-06-01 22:19:47 [INFO]: Epoch 044 - training loss: 0.3829, validation loss: 0.0706
2024-06-01 22:19:48 [INFO]: Epoch 045 - training loss: 0.3945, validation loss: 0.0828
2024-06-01 22:19:48 [INFO]: Epoch 046 - training loss: 0.3890, validation loss: 0.0816
2024-06-01 22:19:48 [INFO]: Epoch 047 - training loss: 0.3864, validation loss: 0.0699
2024-06-01 22:19:48 [INFO]: Epoch 048 - training loss: 0.3824, validation loss: 0.0685
2024-06-01 22:19:49 [INFO]: Epoch 049 - training loss: 0.3801, validation loss: 0.0687
2024-06-01 22:19:49 [INFO]: Epoch 050 - training loss: 0.3738, validation loss: 0.0694
2024-06-01 22:19:49 [INFO]: Epoch 051 - training loss: 0.3823, validation loss: 0.0691
2024-06-01 22:19:49 [INFO]: Epoch 052 - training loss: 0.3850, validation loss: 0.0709
2024-06-01 22:19:50 [INFO]: Epoch 053 - training loss: 0.3896, validation loss: 0.0725
2024-06-01 22:19:50 [INFO]: Epoch 054 - training loss: 0.3782, validation loss: 0.0719
2024-06-01 22:19:50 [INFO]: Epoch 055 - training loss: 0.3742, validation loss: 0.0728
2024-06-01 22:19:50 [INFO]: Epoch 056 - training loss: 0.3670, validation loss: 0.0667
2024-06-01 22:19:50 [INFO]: Epoch 057 - training loss: 0.3688, validation loss: 0.0677
2024-06-01 22:19:51 [INFO]: Epoch 058 - training loss: 0.3665, validation loss: 0.0729
2024-06-01 22:19:51 [INFO]: Epoch 059 - training loss: 0.3648, validation loss: 0.0729
2024-06-01 22:19:51 [INFO]: Epoch 060 - training loss: 0.3672, validation loss: 0.0702
2024-06-01 22:19:51 [INFO]: Epoch 061 - training loss: 0.3616, validation loss: 0.0682
2024-06-01 22:19:52 [INFO]: Epoch 062 - training loss: 0.3659, validation loss: 0.0653
2024-06-01 22:19:52 [INFO]: Epoch 063 - training loss: 0.3621, validation loss: 0.0621
2024-06-01 22:19:52 [INFO]: Epoch 064 - training loss: 0.3626, validation loss: 0.0634
2024-06-01 22:19:52 [INFO]: Epoch 065 - training loss: 0.3533, validation loss: 0.0630
2024-06-01 22:19:52 [INFO]: Epoch 066 - training loss: 0.3635, validation loss: 0.0661
2024-06-01 22:19:53 [INFO]: Epoch 067 - training loss: 0.3661, validation loss: 0.0605
2024-06-01 22:19:53 [INFO]: Epoch 068 - training loss: 0.3612, validation loss: 0.0657
2024-06-01 22:19:53 [INFO]: Epoch 069 - training loss: 0.3631, validation loss: 0.0640
2024-06-01 22:19:53 [INFO]: Epoch 070 - training loss: 0.3584, validation loss: 0.0686
2024-06-01 22:19:54 [INFO]: Epoch 071 - training loss: 0.3661, validation loss: 0.0673
2024-06-01 22:19:54 [INFO]: Epoch 072 - training loss: 0.3490, validation loss: 0.0637
2024-06-01 22:19:54 [INFO]: Epoch 073 - training loss: 0.3504, validation loss: 0.0625
2024-06-01 22:19:54 [INFO]: Epoch 074 - training loss: 0.3461, validation loss: 0.0651
2024-06-01 22:19:54 [INFO]: Epoch 075 - training loss: 0.3441, validation loss: 0.0645
2024-06-01 22:19:55 [INFO]: Epoch 076 - training loss: 0.3504, validation loss: 0.0632
2024-06-01 22:19:55 [INFO]: Epoch 077 - training loss: 0.3533, validation loss: 0.0641
2024-06-01 22:19:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:55 [INFO]: Finished training. The best model is from epoch#67.
2024-06-01 22:19:55 [INFO]: Saved the model to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_2/20240601_T221939/PatchTST.pypots
2024-06-01 22:19:55 [INFO]: Successfully saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_2/imputation.pkl
2024-06-01 22:19:55 [INFO]: Round2 - PatchTST on ETT_h1: MAE=0.2171, MSE=0.0967, MRE=0.2562
2024-06-01 22:19:55 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:19:55 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:55 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_3/20240601_T221955
2024-06-01 22:19:55 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_3/20240601_T221955/tensorboard
2024-06-01 22:19:55 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-01 22:19:55 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-01 22:19:55 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-01 22:19:55 [INFO]: Epoch 001 - training loss: 1.5954, validation loss: 1.1279
2024-06-01 22:19:55 [INFO]: Epoch 002 - training loss: 1.3660, validation loss: 0.7952
2024-06-01 22:19:56 [INFO]: Epoch 003 - training loss: 1.1222, validation loss: 0.6916
2024-06-01 22:19:56 [INFO]: Epoch 004 - training loss: 1.0433, validation loss: 0.5620
2024-06-01 22:19:56 [INFO]: Epoch 005 - training loss: 0.8974, validation loss: 0.4706
2024-06-01 22:19:56 [INFO]: Epoch 006 - training loss: 0.8593, validation loss: 0.4390
2024-06-01 22:19:56 [INFO]: Epoch 007 - training loss: 0.8135, validation loss: 0.4015
2024-06-01 22:19:57 [INFO]: Epoch 008 - training loss: 0.7844, validation loss: 0.4093
2024-06-01 22:19:57 [INFO]: Epoch 009 - training loss: 0.7439, validation loss: 0.3195
2024-06-01 22:19:57 [INFO]: Epoch 010 - training loss: 0.6391, validation loss: 0.2162
2024-06-01 22:19:57 [INFO]: Epoch 011 - training loss: 0.5561, validation loss: 0.1676
2024-06-01 22:19:58 [INFO]: Epoch 012 - training loss: 0.5138, validation loss: 0.1244
2024-06-01 22:19:58 [INFO]: Epoch 013 - training loss: 0.5069, validation loss: 0.1070
2024-06-01 22:19:58 [INFO]: Epoch 014 - training loss: 0.4734, validation loss: 0.1171
2024-06-01 22:19:58 [INFO]: Epoch 015 - training loss: 0.4561, validation loss: 0.1145
2024-06-01 22:19:58 [INFO]: Epoch 016 - training loss: 0.4428, validation loss: 0.0996
2024-06-01 22:19:58 [INFO]: Epoch 017 - training loss: 0.4364, validation loss: 0.0989
2024-06-01 22:19:59 [INFO]: Epoch 018 - training loss: 0.4344, validation loss: 0.1003
2024-06-01 22:19:59 [INFO]: Epoch 019 - training loss: 0.4292, validation loss: 0.0869
2024-06-01 22:19:59 [INFO]: Epoch 020 - training loss: 0.4331, validation loss: 0.0919
2024-06-01 22:19:59 [INFO]: Epoch 021 - training loss: 0.4330, validation loss: 0.0907
2024-06-01 22:19:59 [INFO]: Epoch 022 - training loss: 0.4275, validation loss: 0.1005
2024-06-01 22:19:59 [INFO]: Epoch 023 - training loss: 0.4252, validation loss: 0.0866
2024-06-01 22:20:00 [INFO]: Epoch 024 - training loss: 0.4249, validation loss: 0.0870
2024-06-01 22:20:00 [INFO]: Epoch 025 - training loss: 0.4183, validation loss: 0.0918
2024-06-01 22:20:00 [INFO]: Epoch 026 - training loss: 0.4182, validation loss: 0.0948
2024-06-01 22:20:00 [INFO]: Epoch 027 - training loss: 0.4138, validation loss: 0.0826
2024-06-01 22:20:00 [INFO]: Epoch 028 - training loss: 0.4204, validation loss: 0.0816
2024-06-01 22:20:01 [INFO]: Epoch 029 - training loss: 0.4190, validation loss: 0.0880
2024-06-01 22:20:01 [INFO]: Epoch 030 - training loss: 0.4176, validation loss: 0.0880
2024-06-01 22:20:01 [INFO]: Epoch 031 - training loss: 0.4086, validation loss: 0.0847
2024-06-01 22:20:01 [INFO]: Epoch 032 - training loss: 0.4088, validation loss: 0.0892
2024-06-01 22:20:01 [INFO]: Epoch 033 - training loss: 0.4055, validation loss: 0.0816
2024-06-01 22:20:01 [INFO]: Epoch 034 - training loss: 0.4055, validation loss: 0.0812
2024-06-01 22:20:02 [INFO]: Epoch 035 - training loss: 0.4029, validation loss: 0.0894
2024-06-01 22:20:02 [INFO]: Epoch 036 - training loss: 0.4067, validation loss: 0.0869
2024-06-01 22:20:02 [INFO]: Epoch 037 - training loss: 0.4173, validation loss: 0.0862
2024-06-01 22:20:02 [INFO]: Epoch 038 - training loss: 0.4168, validation loss: 0.0879
2024-06-01 22:20:02 [INFO]: Epoch 039 - training loss: 0.4088, validation loss: 0.0819
2024-06-01 22:20:02 [INFO]: Epoch 040 - training loss: 0.4109, validation loss: 0.0841
2024-06-01 22:20:02 [INFO]: Epoch 041 - training loss: 0.4058, validation loss: 0.0814
2024-06-01 22:20:03 [INFO]: Epoch 042 - training loss: 0.4001, validation loss: 0.0771
2024-06-01 22:20:03 [INFO]: Epoch 043 - training loss: 0.3982, validation loss: 0.0791
2024-06-01 22:20:03 [INFO]: Epoch 044 - training loss: 0.3914, validation loss: 0.0822
2024-06-01 22:20:03 [INFO]: Epoch 045 - training loss: 0.3943, validation loss: 0.0863
2024-06-01 22:20:03 [INFO]: Epoch 046 - training loss: 0.3902, validation loss: 0.0773
2024-06-01 22:20:03 [INFO]: Epoch 047 - training loss: 0.4013, validation loss: 0.0779
2024-06-01 22:20:04 [INFO]: Epoch 048 - training loss: 0.4018, validation loss: 0.0799
2024-06-01 22:20:04 [INFO]: Epoch 049 - training loss: 0.3995, validation loss: 0.0906
2024-06-01 22:20:04 [INFO]: Epoch 050 - training loss: 0.3944, validation loss: 0.0805
2024-06-01 22:20:04 [INFO]: Epoch 051 - training loss: 0.3950, validation loss: 0.0768
2024-06-01 22:20:04 [INFO]: Epoch 052 - training loss: 0.3910, validation loss: 0.0889
2024-06-01 22:20:05 [INFO]: Epoch 053 - training loss: 0.3840, validation loss: 0.0826
2024-06-01 22:20:05 [INFO]: Epoch 054 - training loss: 0.3812, validation loss: 0.0711
2024-06-01 22:20:05 [INFO]: Epoch 055 - training loss: 0.3766, validation loss: 0.0714
2024-06-01 22:20:05 [INFO]: Epoch 056 - training loss: 0.3743, validation loss: 0.0726
2024-06-01 22:20:05 [INFO]: Epoch 057 - training loss: 0.3669, validation loss: 0.0732
2024-06-01 22:20:05 [INFO]: Epoch 058 - training loss: 0.3727, validation loss: 0.0727
2024-06-01 22:20:05 [INFO]: Epoch 059 - training loss: 0.3690, validation loss: 0.0841
2024-06-01 22:20:06 [INFO]: Epoch 060 - training loss: 0.3783, validation loss: 0.0898
2024-06-01 22:20:06 [INFO]: Epoch 061 - training loss: 0.3856, validation loss: 0.0976
2024-06-01 22:20:06 [INFO]: Epoch 062 - training loss: 0.3877, validation loss: 0.0735
2024-06-01 22:20:06 [INFO]: Epoch 063 - training loss: 0.3849, validation loss: 0.0724
2024-06-01 22:20:06 [INFO]: Epoch 064 - training loss: 0.3724, validation loss: 0.0795
2024-06-01 22:20:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:20:06 [INFO]: Finished training. The best model is from epoch#54.
2024-06-01 22:20:06 [INFO]: Saved the model to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_3/20240601_T221955/PatchTST.pypots
2024-06-01 22:20:06 [INFO]: Successfully saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_3/imputation.pkl
2024-06-01 22:20:06 [INFO]: Round3 - PatchTST on ETT_h1: MAE=0.2398, MSE=0.1121, MRE=0.2830
2024-06-01 22:20:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:20:06 [INFO]: Using the given device: cuda:0
2024-06-01 22:20:06 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_4/20240601_T222006
2024-06-01 22:20:06 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_4/20240601_T222006/tensorboard
2024-06-01 22:20:06 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-01 22:20:06 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-01 22:20:06 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-01 22:20:06 [INFO]: Epoch 001 - training loss: 1.6294, validation loss: 1.0452
2024-06-01 22:20:07 [INFO]: Epoch 002 - training loss: 1.3177, validation loss: 0.7889
2024-06-01 22:20:07 [INFO]: Epoch 003 - training loss: 1.1350, validation loss: 0.6106
2024-06-01 22:20:07 [INFO]: Epoch 004 - training loss: 0.9873, validation loss: 0.4818
2024-06-01 22:20:07 [INFO]: Epoch 005 - training loss: 0.8931, validation loss: 0.4029
2024-06-01 22:20:07 [INFO]: Epoch 006 - training loss: 0.8364, validation loss: 0.4205
2024-06-01 22:20:07 [INFO]: Epoch 007 - training loss: 0.7913, validation loss: 0.4104
2024-06-01 22:20:07 [INFO]: Epoch 008 - training loss: 0.7523, validation loss: 0.3706
2024-06-01 22:20:08 [INFO]: Epoch 009 - training loss: 0.6864, validation loss: 0.2823
2024-06-01 22:20:08 [INFO]: Epoch 010 - training loss: 0.5982, validation loss: 0.1594
2024-06-01 22:20:08 [INFO]: Epoch 011 - training loss: 0.5269, validation loss: 0.1284
2024-06-01 22:20:08 [INFO]: Epoch 012 - training loss: 0.4847, validation loss: 0.1186
2024-06-01 22:20:08 [INFO]: Epoch 013 - training loss: 0.4686, validation loss: 0.1194
2024-06-01 22:20:09 [INFO]: Epoch 014 - training loss: 0.4716, validation loss: 0.1033
2024-06-01 22:20:09 [INFO]: Epoch 015 - training loss: 0.4637, validation loss: 0.0958
2024-06-01 22:20:09 [INFO]: Epoch 016 - training loss: 0.4557, validation loss: 0.0861
2024-06-01 22:20:09 [INFO]: Epoch 017 - training loss: 0.4467, validation loss: 0.1152
2024-06-01 22:20:09 [INFO]: Epoch 018 - training loss: 0.4358, validation loss: 0.0920
2024-06-01 22:20:09 [INFO]: Epoch 019 - training loss: 0.4299, validation loss: 0.1010
2024-06-01 22:20:09 [INFO]: Epoch 020 - training loss: 0.4352, validation loss: 0.0882
2024-06-01 22:20:09 [INFO]: Epoch 021 - training loss: 0.4269, validation loss: 0.0926
2024-06-01 22:20:10 [INFO]: Epoch 022 - training loss: 0.4215, validation loss: 0.0933
2024-06-01 22:20:10 [INFO]: Epoch 023 - training loss: 0.4165, validation loss: 0.0839
2024-06-01 22:20:10 [INFO]: Epoch 024 - training loss: 0.4212, validation loss: 0.0806
2024-06-01 22:20:10 [INFO]: Epoch 025 - training loss: 0.4211, validation loss: 0.0931
2024-06-01 22:20:10 [INFO]: Epoch 026 - training loss: 0.4173, validation loss: 0.0870
2024-06-01 22:20:10 [INFO]: Epoch 027 - training loss: 0.4119, validation loss: 0.0811
2024-06-01 22:20:11 [INFO]: Epoch 028 - training loss: 0.4190, validation loss: 0.0845
2024-06-01 22:20:11 [INFO]: Epoch 029 - training loss: 0.4097, validation loss: 0.0841
2024-06-01 22:20:11 [INFO]: Epoch 030 - training loss: 0.4094, validation loss: 0.0838
2024-06-01 22:20:11 [INFO]: Epoch 031 - training loss: 0.4113, validation loss: 0.0851
2024-06-01 22:20:11 [INFO]: Epoch 032 - training loss: 0.4167, validation loss: 0.0860
2024-06-01 22:20:12 [INFO]: Epoch 033 - training loss: 0.4136, validation loss: 0.1015
2024-06-01 22:20:12 [INFO]: Epoch 034 - training loss: 0.4130, validation loss: 0.0878
2024-06-01 22:20:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:20:12 [INFO]: Finished training. The best model is from epoch#24.
2024-06-01 22:20:12 [INFO]: Saved the model to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_4/20240601_T222006/PatchTST.pypots
2024-06-01 22:20:12 [INFO]: Successfully saved to results_point_rate01/ETT_h1/PatchTST_ETT_h1/round_4/imputation.pkl
2024-06-01 22:20:12 [INFO]: Round4 - PatchTST on ETT_h1: MAE=0.2388, MSE=0.1145, MRE=0.2818
2024-06-01 22:20:12 [INFO]: Done! Final results:
Averaged PatchTST (n params: 72,247) on ETT_h1: MAE=0.2401 ± 0.012999971190256665, MSE=0.1146 ± 0.010879998067425846, MRE=0.2834 ± 0.015341149852870356, average inference time=0.01
