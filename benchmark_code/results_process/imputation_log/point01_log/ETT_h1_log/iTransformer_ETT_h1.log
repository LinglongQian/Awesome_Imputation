2024-06-01 22:17:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:17:24 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:24 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_0/20240601_T221724
2024-06-01 22:17:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_0/20240601_T221724/tensorboard
2024-06-01 22:17:24 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=128
2024-06-01 22:17:24 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-01 22:17:25 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 23,723,056
2024-06-01 22:17:26 [INFO]: Epoch 001 - training loss: 1.3183, validation loss: 0.4582
2024-06-01 22:17:26 [INFO]: Epoch 002 - training loss: 0.9042, validation loss: 0.3109
2024-06-01 22:17:26 [INFO]: Epoch 003 - training loss: 0.7480, validation loss: 0.2591
2024-06-01 22:17:26 [INFO]: Epoch 004 - training loss: 0.6771, validation loss: 0.2187
2024-06-01 22:17:27 [INFO]: Epoch 005 - training loss: 0.6120, validation loss: 0.1865
2024-06-01 22:17:27 [INFO]: Epoch 006 - training loss: 0.5645, validation loss: 0.1568
2024-06-01 22:17:27 [INFO]: Epoch 007 - training loss: 0.5360, validation loss: 0.1404
2024-06-01 22:17:27 [INFO]: Epoch 008 - training loss: 0.5057, validation loss: 0.1251
2024-06-01 22:17:27 [INFO]: Epoch 009 - training loss: 0.4856, validation loss: 0.1185
2024-06-01 22:17:28 [INFO]: Epoch 010 - training loss: 0.4757, validation loss: 0.1152
2024-06-01 22:17:28 [INFO]: Epoch 011 - training loss: 0.4657, validation loss: 0.1108
2024-06-01 22:17:28 [INFO]: Epoch 012 - training loss: 0.4580, validation loss: 0.1064
2024-06-01 22:17:29 [INFO]: Epoch 013 - training loss: 0.4515, validation loss: 0.1091
2024-06-01 22:17:29 [INFO]: Epoch 014 - training loss: 0.4474, validation loss: 0.1089
2024-06-01 22:17:29 [INFO]: Epoch 015 - training loss: 0.4433, validation loss: 0.1028
2024-06-01 22:17:30 [INFO]: Epoch 016 - training loss: 0.4293, validation loss: 0.1005
2024-06-01 22:17:30 [INFO]: Epoch 017 - training loss: 0.4290, validation loss: 0.1010
2024-06-01 22:17:30 [INFO]: Epoch 018 - training loss: 0.4182, validation loss: 0.1004
2024-06-01 22:17:31 [INFO]: Epoch 019 - training loss: 0.4250, validation loss: 0.0982
2024-06-01 22:17:31 [INFO]: Epoch 020 - training loss: 0.4150, validation loss: 0.0992
2024-06-01 22:17:31 [INFO]: Epoch 021 - training loss: 0.4164, validation loss: 0.0943
2024-06-01 22:17:32 [INFO]: Epoch 022 - training loss: 0.4118, validation loss: 0.0953
2024-06-01 22:17:32 [INFO]: Epoch 023 - training loss: 0.4109, validation loss: 0.0970
2024-06-01 22:17:32 [INFO]: Epoch 024 - training loss: 0.4110, validation loss: 0.0977
2024-06-01 22:17:33 [INFO]: Epoch 025 - training loss: 0.4129, validation loss: 0.0950
2024-06-01 22:17:33 [INFO]: Epoch 026 - training loss: 0.4008, validation loss: 0.0930
2024-06-01 22:17:33 [INFO]: Epoch 027 - training loss: 0.4024, validation loss: 0.0953
2024-06-01 22:17:34 [INFO]: Epoch 028 - training loss: 0.4009, validation loss: 0.0967
2024-06-01 22:17:34 [INFO]: Epoch 029 - training loss: 0.4019, validation loss: 0.0959
2024-06-01 22:17:34 [INFO]: Epoch 030 - training loss: 0.3996, validation loss: 0.0969
2024-06-01 22:17:35 [INFO]: Epoch 031 - training loss: 0.4010, validation loss: 0.0974
2024-06-01 22:17:35 [INFO]: Epoch 032 - training loss: 0.3989, validation loss: 0.0975
2024-06-01 22:17:36 [INFO]: Epoch 033 - training loss: 0.3929, validation loss: 0.0938
2024-06-01 22:17:36 [INFO]: Epoch 034 - training loss: 0.3920, validation loss: 0.0949
2024-06-01 22:17:36 [INFO]: Epoch 035 - training loss: 0.3893, validation loss: 0.0939
2024-06-01 22:17:36 [INFO]: Epoch 036 - training loss: 0.3892, validation loss: 0.0962
2024-06-01 22:17:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:17:36 [INFO]: Finished training. The best model is from epoch#26.
2024-06-01 22:17:37 [INFO]: Saved the model to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_0/20240601_T221724/iTransformer.pypots
2024-06-01 22:17:37 [INFO]: Successfully saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:17:37 [INFO]: Round0 - iTransformer on ETT_h1: MAE=0.2646, MSE=0.1443, MRE=0.3123
2024-06-01 22:17:37 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:17:37 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:37 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_1/20240601_T221737
2024-06-01 22:17:37 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_1/20240601_T221737/tensorboard
2024-06-01 22:17:37 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=128
2024-06-01 22:17:37 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-01 22:17:37 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 23,723,056
2024-06-01 22:17:37 [INFO]: Epoch 001 - training loss: 1.3176, validation loss: 0.4459
2024-06-01 22:17:38 [INFO]: Epoch 002 - training loss: 0.9064, validation loss: 0.3073
2024-06-01 22:17:38 [INFO]: Epoch 003 - training loss: 0.7546, validation loss: 0.2725
2024-06-01 22:17:39 [INFO]: Epoch 004 - training loss: 0.6763, validation loss: 0.2120
2024-06-01 22:17:39 [INFO]: Epoch 005 - training loss: 0.6125, validation loss: 0.1788
2024-06-01 22:17:39 [INFO]: Epoch 006 - training loss: 0.5703, validation loss: 0.1556
2024-06-01 22:17:39 [INFO]: Epoch 007 - training loss: 0.5388, validation loss: 0.1459
2024-06-01 22:17:40 [INFO]: Epoch 008 - training loss: 0.5119, validation loss: 0.1279
2024-06-01 22:17:40 [INFO]: Epoch 009 - training loss: 0.4984, validation loss: 0.1199
2024-06-01 22:17:40 [INFO]: Epoch 010 - training loss: 0.4756, validation loss: 0.1169
2024-06-01 22:17:41 [INFO]: Epoch 011 - training loss: 0.4695, validation loss: 0.1162
2024-06-01 22:17:41 [INFO]: Epoch 012 - training loss: 0.4700, validation loss: 0.1140
2024-06-01 22:17:41 [INFO]: Epoch 013 - training loss: 0.4546, validation loss: 0.1076
2024-06-01 22:17:42 [INFO]: Epoch 014 - training loss: 0.4491, validation loss: 0.1087
2024-06-01 22:17:42 [INFO]: Epoch 015 - training loss: 0.4406, validation loss: 0.1075
2024-06-01 22:17:42 [INFO]: Epoch 016 - training loss: 0.4342, validation loss: 0.1015
2024-06-01 22:17:42 [INFO]: Epoch 017 - training loss: 0.4293, validation loss: 0.1005
2024-06-01 22:17:43 [INFO]: Epoch 018 - training loss: 0.4297, validation loss: 0.1032
2024-06-01 22:17:43 [INFO]: Epoch 019 - training loss: 0.4251, validation loss: 0.1046
2024-06-01 22:17:43 [INFO]: Epoch 020 - training loss: 0.4248, validation loss: 0.1052
2024-06-01 22:17:44 [INFO]: Epoch 021 - training loss: 0.4219, validation loss: 0.1013
2024-06-01 22:17:44 [INFO]: Epoch 022 - training loss: 0.4171, validation loss: 0.1005
2024-06-01 22:17:44 [INFO]: Epoch 023 - training loss: 0.4186, validation loss: 0.1001
2024-06-01 22:17:45 [INFO]: Epoch 024 - training loss: 0.4127, validation loss: 0.0964
2024-06-01 22:17:45 [INFO]: Epoch 025 - training loss: 0.4143, validation loss: 0.0990
2024-06-01 22:17:45 [INFO]: Epoch 026 - training loss: 0.4089, validation loss: 0.0959
2024-06-01 22:17:45 [INFO]: Epoch 027 - training loss: 0.4069, validation loss: 0.0993
2024-06-01 22:17:46 [INFO]: Epoch 028 - training loss: 0.4032, validation loss: 0.0971
2024-06-01 22:17:46 [INFO]: Epoch 029 - training loss: 0.4048, validation loss: 0.0973
2024-06-01 22:17:46 [INFO]: Epoch 030 - training loss: 0.4010, validation loss: 0.1010
2024-06-01 22:17:46 [INFO]: Epoch 031 - training loss: 0.3951, validation loss: 0.0984
2024-06-01 22:17:47 [INFO]: Epoch 032 - training loss: 0.4017, validation loss: 0.0983
2024-06-01 22:17:47 [INFO]: Epoch 033 - training loss: 0.3932, validation loss: 0.1002
2024-06-01 22:17:47 [INFO]: Epoch 034 - training loss: 0.3937, validation loss: 0.1024
2024-06-01 22:17:47 [INFO]: Epoch 035 - training loss: 0.3921, validation loss: 0.0956
2024-06-01 22:17:48 [INFO]: Epoch 036 - training loss: 0.3832, validation loss: 0.0938
2024-06-01 22:17:48 [INFO]: Epoch 037 - training loss: 0.3872, validation loss: 0.0958
2024-06-01 22:17:48 [INFO]: Epoch 038 - training loss: 0.3888, validation loss: 0.0963
2024-06-01 22:17:49 [INFO]: Epoch 039 - training loss: 0.3827, validation loss: 0.0948
2024-06-01 22:17:49 [INFO]: Epoch 040 - training loss: 0.3884, validation loss: 0.0954
2024-06-01 22:17:49 [INFO]: Epoch 041 - training loss: 0.3795, validation loss: 0.0966
2024-06-01 22:17:49 [INFO]: Epoch 042 - training loss: 0.3811, validation loss: 0.0962
2024-06-01 22:17:50 [INFO]: Epoch 043 - training loss: 0.3816, validation loss: 0.0990
2024-06-01 22:17:50 [INFO]: Epoch 044 - training loss: 0.3873, validation loss: 0.0961
2024-06-01 22:17:50 [INFO]: Epoch 045 - training loss: 0.3831, validation loss: 0.0984
2024-06-01 22:17:50 [INFO]: Epoch 046 - training loss: 0.3831, validation loss: 0.1003
2024-06-01 22:17:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:17:50 [INFO]: Finished training. The best model is from epoch#36.
2024-06-01 22:17:51 [INFO]: Saved the model to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_1/20240601_T221737/iTransformer.pypots
2024-06-01 22:17:51 [INFO]: Successfully saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:17:51 [INFO]: Round1 - iTransformer on ETT_h1: MAE=0.2682, MSE=0.1446, MRE=0.3165
2024-06-01 22:17:51 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:17:51 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:51 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_2/20240601_T221751
2024-06-01 22:17:51 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_2/20240601_T221751/tensorboard
2024-06-01 22:17:51 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=128
2024-06-01 22:17:51 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-01 22:17:51 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 23,723,056
2024-06-01 22:17:51 [INFO]: Epoch 001 - training loss: 1.3013, validation loss: 0.4542
2024-06-01 22:17:52 [INFO]: Epoch 002 - training loss: 0.8931, validation loss: 0.3236
2024-06-01 22:17:52 [INFO]: Epoch 003 - training loss: 0.7613, validation loss: 0.2679
2024-06-01 22:17:52 [INFO]: Epoch 004 - training loss: 0.6835, validation loss: 0.2178
2024-06-01 22:17:52 [INFO]: Epoch 005 - training loss: 0.6220, validation loss: 0.1902
2024-06-01 22:17:52 [INFO]: Epoch 006 - training loss: 0.5749, validation loss: 0.1580
2024-06-01 22:17:53 [INFO]: Epoch 007 - training loss: 0.5395, validation loss: 0.1444
2024-06-01 22:17:53 [INFO]: Epoch 008 - training loss: 0.5059, validation loss: 0.1231
2024-06-01 22:17:53 [INFO]: Epoch 009 - training loss: 0.4819, validation loss: 0.1149
2024-06-01 22:17:54 [INFO]: Epoch 010 - training loss: 0.4736, validation loss: 0.1084
2024-06-01 22:17:54 [INFO]: Epoch 011 - training loss: 0.4545, validation loss: 0.1086
2024-06-01 22:17:54 [INFO]: Epoch 012 - training loss: 0.4506, validation loss: 0.1071
2024-06-01 22:17:54 [INFO]: Epoch 013 - training loss: 0.4450, validation loss: 0.1028
2024-06-01 22:17:55 [INFO]: Epoch 014 - training loss: 0.4469, validation loss: 0.0990
2024-06-01 22:17:55 [INFO]: Epoch 015 - training loss: 0.4402, validation loss: 0.1021
2024-06-01 22:17:55 [INFO]: Epoch 016 - training loss: 0.4298, validation loss: 0.1021
2024-06-01 22:17:55 [INFO]: Epoch 017 - training loss: 0.4283, validation loss: 0.1007
2024-06-01 22:17:55 [INFO]: Epoch 018 - training loss: 0.4242, validation loss: 0.1020
2024-06-01 22:17:56 [INFO]: Epoch 019 - training loss: 0.4247, validation loss: 0.1020
2024-06-01 22:17:56 [INFO]: Epoch 020 - training loss: 0.4242, validation loss: 0.0989
2024-06-01 22:17:56 [INFO]: Epoch 021 - training loss: 0.4132, validation loss: 0.0968
2024-06-01 22:17:56 [INFO]: Epoch 022 - training loss: 0.4174, validation loss: 0.0972
2024-06-01 22:17:56 [INFO]: Epoch 023 - training loss: 0.4176, validation loss: 0.0980
2024-06-01 22:17:57 [INFO]: Epoch 024 - training loss: 0.4119, validation loss: 0.1011
2024-06-01 22:17:57 [INFO]: Epoch 025 - training loss: 0.4138, validation loss: 0.0955
2024-06-01 22:17:57 [INFO]: Epoch 026 - training loss: 0.4114, validation loss: 0.0952
2024-06-01 22:17:57 [INFO]: Epoch 027 - training loss: 0.4103, validation loss: 0.0954
2024-06-01 22:17:58 [INFO]: Epoch 028 - training loss: 0.4049, validation loss: 0.0954
2024-06-01 22:17:58 [INFO]: Epoch 029 - training loss: 0.4009, validation loss: 0.0935
2024-06-01 22:17:58 [INFO]: Epoch 030 - training loss: 0.3965, validation loss: 0.0938
2024-06-01 22:17:58 [INFO]: Epoch 031 - training loss: 0.3899, validation loss: 0.0922
2024-06-01 22:17:59 [INFO]: Epoch 032 - training loss: 0.3954, validation loss: 0.0944
2024-06-01 22:17:59 [INFO]: Epoch 033 - training loss: 0.3994, validation loss: 0.0926
2024-06-01 22:17:59 [INFO]: Epoch 034 - training loss: 0.3974, validation loss: 0.0946
2024-06-01 22:17:59 [INFO]: Epoch 035 - training loss: 0.3925, validation loss: 0.1012
2024-06-01 22:17:59 [INFO]: Epoch 036 - training loss: 0.3933, validation loss: 0.0938
2024-06-01 22:18:00 [INFO]: Epoch 037 - training loss: 0.3923, validation loss: 0.0914
2024-06-01 22:18:00 [INFO]: Epoch 038 - training loss: 0.3865, validation loss: 0.0920
2024-06-01 22:18:00 [INFO]: Epoch 039 - training loss: 0.3870, validation loss: 0.0921
2024-06-01 22:18:00 [INFO]: Epoch 040 - training loss: 0.3838, validation loss: 0.0933
2024-06-01 22:18:00 [INFO]: Epoch 041 - training loss: 0.3827, validation loss: 0.0941
2024-06-01 22:18:01 [INFO]: Epoch 042 - training loss: 0.3868, validation loss: 0.0902
2024-06-01 22:18:01 [INFO]: Epoch 043 - training loss: 0.3867, validation loss: 0.0956
2024-06-01 22:18:01 [INFO]: Epoch 044 - training loss: 0.3782, validation loss: 0.0931
2024-06-01 22:18:02 [INFO]: Epoch 045 - training loss: 0.3788, validation loss: 0.0922
2024-06-01 22:18:02 [INFO]: Epoch 046 - training loss: 0.3771, validation loss: 0.0901
2024-06-01 22:18:02 [INFO]: Epoch 047 - training loss: 0.3774, validation loss: 0.0924
2024-06-01 22:18:02 [INFO]: Epoch 048 - training loss: 0.3681, validation loss: 0.0900
2024-06-01 22:18:03 [INFO]: Epoch 049 - training loss: 0.3731, validation loss: 0.0903
2024-06-01 22:18:03 [INFO]: Epoch 050 - training loss: 0.3709, validation loss: 0.0922
2024-06-01 22:18:03 [INFO]: Epoch 051 - training loss: 0.3746, validation loss: 0.0939
2024-06-01 22:18:03 [INFO]: Epoch 052 - training loss: 0.3759, validation loss: 0.0958
2024-06-01 22:18:03 [INFO]: Epoch 053 - training loss: 0.3761, validation loss: 0.0953
2024-06-01 22:18:04 [INFO]: Epoch 054 - training loss: 0.3743, validation loss: 0.0916
2024-06-01 22:18:04 [INFO]: Epoch 055 - training loss: 0.3680, validation loss: 0.0961
2024-06-01 22:18:04 [INFO]: Epoch 056 - training loss: 0.3692, validation loss: 0.0932
2024-06-01 22:18:04 [INFO]: Epoch 057 - training loss: 0.3726, validation loss: 0.0932
2024-06-01 22:18:05 [INFO]: Epoch 058 - training loss: 0.3699, validation loss: 0.0934
2024-06-01 22:18:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:05 [INFO]: Finished training. The best model is from epoch#48.
2024-06-01 22:18:05 [INFO]: Saved the model to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_2/20240601_T221751/iTransformer.pypots
2024-06-01 22:18:05 [INFO]: Successfully saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:18:05 [INFO]: Round2 - iTransformer on ETT_h1: MAE=0.2574, MSE=0.1388, MRE=0.3037
2024-06-01 22:18:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:18:05 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:05 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_3/20240601_T221805
2024-06-01 22:18:05 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_3/20240601_T221805/tensorboard
2024-06-01 22:18:05 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=128
2024-06-01 22:18:05 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-01 22:18:05 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 23,723,056
2024-06-01 22:18:05 [INFO]: Epoch 001 - training loss: 1.2996, validation loss: 0.4127
2024-06-01 22:18:06 [INFO]: Epoch 002 - training loss: 0.8929, validation loss: 0.3094
2024-06-01 22:18:06 [INFO]: Epoch 003 - training loss: 0.7497, validation loss: 0.2659
2024-06-01 22:18:06 [INFO]: Epoch 004 - training loss: 0.6762, validation loss: 0.2119
2024-06-01 22:18:06 [INFO]: Epoch 005 - training loss: 0.6155, validation loss: 0.1882
2024-06-01 22:18:06 [INFO]: Epoch 006 - training loss: 0.5693, validation loss: 0.1547
2024-06-01 22:18:07 [INFO]: Epoch 007 - training loss: 0.5352, validation loss: 0.1416
2024-06-01 22:18:07 [INFO]: Epoch 008 - training loss: 0.5036, validation loss: 0.1244
2024-06-01 22:18:07 [INFO]: Epoch 009 - training loss: 0.4891, validation loss: 0.1169
2024-06-01 22:18:08 [INFO]: Epoch 010 - training loss: 0.4808, validation loss: 0.1141
2024-06-01 22:18:08 [INFO]: Epoch 011 - training loss: 0.4666, validation loss: 0.1107
2024-06-01 22:18:08 [INFO]: Epoch 012 - training loss: 0.4573, validation loss: 0.1019
2024-06-01 22:18:09 [INFO]: Epoch 013 - training loss: 0.4480, validation loss: 0.1080
2024-06-01 22:18:09 [INFO]: Epoch 014 - training loss: 0.4472, validation loss: 0.1034
2024-06-01 22:18:09 [INFO]: Epoch 015 - training loss: 0.4374, validation loss: 0.1058
2024-06-01 22:18:10 [INFO]: Epoch 016 - training loss: 0.4366, validation loss: 0.1034
2024-06-01 22:18:10 [INFO]: Epoch 017 - training loss: 0.4327, validation loss: 0.1015
2024-06-01 22:18:10 [INFO]: Epoch 018 - training loss: 0.4329, validation loss: 0.0994
2024-06-01 22:18:11 [INFO]: Epoch 019 - training loss: 0.4198, validation loss: 0.1003
2024-06-01 22:18:11 [INFO]: Epoch 020 - training loss: 0.4207, validation loss: 0.1011
2024-06-01 22:18:11 [INFO]: Epoch 021 - training loss: 0.4209, validation loss: 0.0986
2024-06-01 22:18:12 [INFO]: Epoch 022 - training loss: 0.4149, validation loss: 0.0979
2024-06-01 22:18:12 [INFO]: Epoch 023 - training loss: 0.4204, validation loss: 0.0955
2024-06-01 22:18:12 [INFO]: Epoch 024 - training loss: 0.4144, validation loss: 0.0960
2024-06-01 22:18:12 [INFO]: Epoch 025 - training loss: 0.4091, validation loss: 0.0980
2024-06-01 22:18:13 [INFO]: Epoch 026 - training loss: 0.4074, validation loss: 0.0977
2024-06-01 22:18:13 [INFO]: Epoch 027 - training loss: 0.4077, validation loss: 0.0934
2024-06-01 22:18:13 [INFO]: Epoch 028 - training loss: 0.4074, validation loss: 0.0947
2024-06-01 22:18:13 [INFO]: Epoch 029 - training loss: 0.4087, validation loss: 0.0949
2024-06-01 22:18:14 [INFO]: Epoch 030 - training loss: 0.3998, validation loss: 0.0933
2024-06-01 22:18:14 [INFO]: Epoch 031 - training loss: 0.4055, validation loss: 0.0996
2024-06-01 22:18:14 [INFO]: Epoch 032 - training loss: 0.3995, validation loss: 0.0945
2024-06-01 22:18:14 [INFO]: Epoch 033 - training loss: 0.3963, validation loss: 0.0937
2024-06-01 22:18:15 [INFO]: Epoch 034 - training loss: 0.3956, validation loss: 0.0949
2024-06-01 22:18:15 [INFO]: Epoch 035 - training loss: 0.3938, validation loss: 0.0939
2024-06-01 22:18:15 [INFO]: Epoch 036 - training loss: 0.3926, validation loss: 0.0938
2024-06-01 22:18:15 [INFO]: Epoch 037 - training loss: 0.3955, validation loss: 0.0945
2024-06-01 22:18:16 [INFO]: Epoch 038 - training loss: 0.3914, validation loss: 0.0959
2024-06-01 22:18:16 [INFO]: Epoch 039 - training loss: 0.3891, validation loss: 0.0914
2024-06-01 22:18:16 [INFO]: Epoch 040 - training loss: 0.3831, validation loss: 0.0936
2024-06-01 22:18:17 [INFO]: Epoch 041 - training loss: 0.3839, validation loss: 0.0945
2024-06-01 22:18:17 [INFO]: Epoch 042 - training loss: 0.3842, validation loss: 0.0929
2024-06-01 22:18:17 [INFO]: Epoch 043 - training loss: 0.3894, validation loss: 0.0931
2024-06-01 22:18:17 [INFO]: Epoch 044 - training loss: 0.3850, validation loss: 0.0935
2024-06-01 22:18:18 [INFO]: Epoch 045 - training loss: 0.3793, validation loss: 0.0914
2024-06-01 22:18:18 [INFO]: Epoch 046 - training loss: 0.3853, validation loss: 0.0912
2024-06-01 22:18:18 [INFO]: Epoch 047 - training loss: 0.3856, validation loss: 0.0905
2024-06-01 22:18:19 [INFO]: Epoch 048 - training loss: 0.3788, validation loss: 0.0916
2024-06-01 22:18:19 [INFO]: Epoch 049 - training loss: 0.3829, validation loss: 0.0925
2024-06-01 22:18:19 [INFO]: Epoch 050 - training loss: 0.3741, validation loss: 0.0962
2024-06-01 22:18:19 [INFO]: Epoch 051 - training loss: 0.3771, validation loss: 0.0937
2024-06-01 22:18:20 [INFO]: Epoch 052 - training loss: 0.3770, validation loss: 0.0910
2024-06-01 22:18:20 [INFO]: Epoch 053 - training loss: 0.3800, validation loss: 0.0897
2024-06-01 22:18:20 [INFO]: Epoch 054 - training loss: 0.3686, validation loss: 0.0949
2024-06-01 22:18:20 [INFO]: Epoch 055 - training loss: 0.3684, validation loss: 0.0963
2024-06-01 22:18:20 [INFO]: Epoch 056 - training loss: 0.3732, validation loss: 0.0937
2024-06-01 22:18:21 [INFO]: Epoch 057 - training loss: 0.3675, validation loss: 0.0932
2024-06-01 22:18:21 [INFO]: Epoch 058 - training loss: 0.3715, validation loss: 0.0964
2024-06-01 22:18:21 [INFO]: Epoch 059 - training loss: 0.3655, validation loss: 0.0939
2024-06-01 22:18:21 [INFO]: Epoch 060 - training loss: 0.3661, validation loss: 0.0912
2024-06-01 22:18:21 [INFO]: Epoch 061 - training loss: 0.3640, validation loss: 0.0926
2024-06-01 22:18:21 [INFO]: Epoch 062 - training loss: 0.3599, validation loss: 0.0922
2024-06-01 22:18:22 [INFO]: Epoch 063 - training loss: 0.3652, validation loss: 0.0965
2024-06-01 22:18:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:22 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:18:22 [INFO]: Saved the model to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_3/20240601_T221805/iTransformer.pypots
2024-06-01 22:18:22 [INFO]: Successfully saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:18:22 [INFO]: Round3 - iTransformer on ETT_h1: MAE=0.2642, MSE=0.1416, MRE=0.3117
2024-06-01 22:18:22 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:18:22 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:22 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_4/20240601_T221822
2024-06-01 22:18:22 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_4/20240601_T221822/tensorboard
2024-06-01 22:18:22 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=128
2024-06-01 22:18:22 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-01 22:18:22 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 23,723,056
2024-06-01 22:18:23 [INFO]: Epoch 001 - training loss: 1.3091, validation loss: 0.4262
2024-06-01 22:18:23 [INFO]: Epoch 002 - training loss: 0.8973, validation loss: 0.3011
2024-06-01 22:18:23 [INFO]: Epoch 003 - training loss: 0.7590, validation loss: 0.2519
2024-06-01 22:18:23 [INFO]: Epoch 004 - training loss: 0.6852, validation loss: 0.2054
2024-06-01 22:18:24 [INFO]: Epoch 005 - training loss: 0.6201, validation loss: 0.1802
2024-06-01 22:18:24 [INFO]: Epoch 006 - training loss: 0.5761, validation loss: 0.1529
2024-06-01 22:18:24 [INFO]: Epoch 007 - training loss: 0.5434, validation loss: 0.1374
2024-06-01 22:18:24 [INFO]: Epoch 008 - training loss: 0.5168, validation loss: 0.1208
2024-06-01 22:18:25 [INFO]: Epoch 009 - training loss: 0.5001, validation loss: 0.1125
2024-06-01 22:18:25 [INFO]: Epoch 010 - training loss: 0.4850, validation loss: 0.1141
2024-06-01 22:18:25 [INFO]: Epoch 011 - training loss: 0.4690, validation loss: 0.1057
2024-06-01 22:18:26 [INFO]: Epoch 012 - training loss: 0.4565, validation loss: 0.1031
2024-06-01 22:18:26 [INFO]: Epoch 013 - training loss: 0.4537, validation loss: 0.1023
2024-06-01 22:18:26 [INFO]: Epoch 014 - training loss: 0.4428, validation loss: 0.1019
2024-06-01 22:18:27 [INFO]: Epoch 015 - training loss: 0.4418, validation loss: 0.1026
2024-06-01 22:18:27 [INFO]: Epoch 016 - training loss: 0.4372, validation loss: 0.1004
2024-06-01 22:18:27 [INFO]: Epoch 017 - training loss: 0.4338, validation loss: 0.0997
2024-06-01 22:18:27 [INFO]: Epoch 018 - training loss: 0.4283, validation loss: 0.0994
2024-06-01 22:18:27 [INFO]: Epoch 019 - training loss: 0.4253, validation loss: 0.1002
2024-06-01 22:18:28 [INFO]: Epoch 020 - training loss: 0.4297, validation loss: 0.0979
2024-06-01 22:18:28 [INFO]: Epoch 021 - training loss: 0.4163, validation loss: 0.0984
2024-06-01 22:18:28 [INFO]: Epoch 022 - training loss: 0.4174, validation loss: 0.0967
2024-06-01 22:18:28 [INFO]: Epoch 023 - training loss: 0.4158, validation loss: 0.0979
2024-06-01 22:18:28 [INFO]: Epoch 024 - training loss: 0.4071, validation loss: 0.0923
2024-06-01 22:18:29 [INFO]: Epoch 025 - training loss: 0.4101, validation loss: 0.0976
2024-06-01 22:18:29 [INFO]: Epoch 026 - training loss: 0.4093, validation loss: 0.0944
2024-06-01 22:18:29 [INFO]: Epoch 027 - training loss: 0.4078, validation loss: 0.0957
2024-06-01 22:18:29 [INFO]: Epoch 028 - training loss: 0.4068, validation loss: 0.0963
2024-06-01 22:18:30 [INFO]: Epoch 029 - training loss: 0.3987, validation loss: 0.0978
2024-06-01 22:18:30 [INFO]: Epoch 030 - training loss: 0.3977, validation loss: 0.1013
2024-06-01 22:18:30 [INFO]: Epoch 031 - training loss: 0.3979, validation loss: 0.0929
2024-06-01 22:18:30 [INFO]: Epoch 032 - training loss: 0.4020, validation loss: 0.0955
2024-06-01 22:18:31 [INFO]: Epoch 033 - training loss: 0.3980, validation loss: 0.0983
2024-06-01 22:18:31 [INFO]: Epoch 034 - training loss: 0.3984, validation loss: 0.0970
2024-06-01 22:18:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:31 [INFO]: Finished training. The best model is from epoch#24.
2024-06-01 22:18:31 [INFO]: Saved the model to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_4/20240601_T221822/iTransformer.pypots
2024-06-01 22:18:31 [INFO]: Successfully saved to results_point_rate01/ETT_h1/iTransformer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:18:31 [INFO]: Round4 - iTransformer on ETT_h1: MAE=0.2623, MSE=0.1444, MRE=0.3095
2024-06-01 22:18:31 [INFO]: Done! Final results:
Averaged iTransformer (n params: 23,723,056) on ETT_h1: MAE=0.2633 ± 0.003531309384788668, MSE=0.1427 ± 0.0022662508351313335, MRE=0.3108 ± 0.004167266654367165, average inference time=0.03
