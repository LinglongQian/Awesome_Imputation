2024-06-01 22:17:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:17:23 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:24 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_0/20240601_T221724
2024-06-01 22:17:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_0/20240601_T221724/tensorboard
2024-06-01 22:17:24 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-01 22:17:27 [INFO]: Epoch 001 - training loss: 1.4125, validation loss: 0.7132
2024-06-01 22:17:28 [INFO]: Epoch 002 - training loss: 0.7965, validation loss: 0.3909
2024-06-01 22:17:28 [INFO]: Epoch 003 - training loss: 0.6350, validation loss: 0.1994
2024-06-01 22:17:28 [INFO]: Epoch 004 - training loss: 0.5333, validation loss: 0.1471
2024-06-01 22:17:29 [INFO]: Epoch 005 - training loss: 0.4844, validation loss: 0.1154
2024-06-01 22:17:29 [INFO]: Epoch 006 - training loss: 0.4542, validation loss: 0.1195
2024-06-01 22:17:30 [INFO]: Epoch 007 - training loss: 0.4288, validation loss: 0.1020
2024-06-01 22:17:30 [INFO]: Epoch 008 - training loss: 0.4228, validation loss: 0.1023
2024-06-01 22:17:30 [INFO]: Epoch 009 - training loss: 0.4165, validation loss: 0.0947
2024-06-01 22:17:31 [INFO]: Epoch 010 - training loss: 0.4033, validation loss: 0.0943
2024-06-01 22:17:31 [INFO]: Epoch 011 - training loss: 0.3968, validation loss: 0.0947
2024-06-01 22:17:32 [INFO]: Epoch 012 - training loss: 0.3728, validation loss: 0.0927
2024-06-01 22:17:32 [INFO]: Epoch 013 - training loss: 0.3616, validation loss: 0.0866
2024-06-01 22:17:32 [INFO]: Epoch 014 - training loss: 0.3484, validation loss: 0.0814
2024-06-01 22:17:33 [INFO]: Epoch 015 - training loss: 0.3366, validation loss: 0.0781
2024-06-01 22:17:33 [INFO]: Epoch 016 - training loss: 0.3333, validation loss: 0.0785
2024-06-01 22:17:34 [INFO]: Epoch 017 - training loss: 0.3202, validation loss: 0.0653
2024-06-01 22:17:34 [INFO]: Epoch 018 - training loss: 0.3205, validation loss: 0.0693
2024-06-01 22:17:35 [INFO]: Epoch 019 - training loss: 0.3161, validation loss: 0.0703
2024-06-01 22:17:35 [INFO]: Epoch 020 - training loss: 0.3079, validation loss: 0.0702
2024-06-01 22:17:36 [INFO]: Epoch 021 - training loss: 0.3136, validation loss: 0.0666
2024-06-01 22:17:36 [INFO]: Epoch 022 - training loss: 0.3114, validation loss: 0.0694
2024-06-01 22:17:36 [INFO]: Epoch 023 - training loss: 0.3069, validation loss: 0.0719
2024-06-01 22:17:37 [INFO]: Epoch 024 - training loss: 0.3083, validation loss: 0.0636
2024-06-01 22:17:37 [INFO]: Epoch 025 - training loss: 0.2869, validation loss: 0.0579
2024-06-01 22:17:37 [INFO]: Epoch 026 - training loss: 0.2761, validation loss: 0.0541
2024-06-01 22:17:38 [INFO]: Epoch 027 - training loss: 0.2692, validation loss: 0.0530
2024-06-01 22:17:38 [INFO]: Epoch 028 - training loss: 0.2616, validation loss: 0.0550
2024-06-01 22:17:39 [INFO]: Epoch 029 - training loss: 0.2618, validation loss: 0.0556
2024-06-01 22:17:39 [INFO]: Epoch 030 - training loss: 0.2539, validation loss: 0.0534
2024-06-01 22:17:40 [INFO]: Epoch 031 - training loss: 0.2574, validation loss: 0.0475
2024-06-01 22:17:40 [INFO]: Epoch 032 - training loss: 0.2504, validation loss: 0.0476
2024-06-01 22:17:41 [INFO]: Epoch 033 - training loss: 0.2490, validation loss: 0.0449
2024-06-01 22:17:41 [INFO]: Epoch 034 - training loss: 0.2509, validation loss: 0.0441
2024-06-01 22:17:41 [INFO]: Epoch 035 - training loss: 0.2525, validation loss: 0.0476
2024-06-01 22:17:41 [INFO]: Epoch 036 - training loss: 0.2679, validation loss: 0.0477
2024-06-01 22:17:42 [INFO]: Epoch 037 - training loss: 0.2711, validation loss: 0.0470
2024-06-01 22:17:42 [INFO]: Epoch 038 - training loss: 0.2499, validation loss: 0.0420
2024-06-01 22:17:42 [INFO]: Epoch 039 - training loss: 0.2459, validation loss: 0.0414
2024-06-01 22:17:42 [INFO]: Epoch 040 - training loss: 0.2516, validation loss: 0.0407
2024-06-01 22:17:43 [INFO]: Epoch 041 - training loss: 0.2382, validation loss: 0.0410
2024-06-01 22:17:43 [INFO]: Epoch 042 - training loss: 0.2451, validation loss: 0.0439
2024-06-01 22:17:43 [INFO]: Epoch 043 - training loss: 0.2419, validation loss: 0.0382
2024-06-01 22:17:44 [INFO]: Epoch 044 - training loss: 0.2413, validation loss: 0.0375
2024-06-01 22:17:44 [INFO]: Epoch 045 - training loss: 0.2279, validation loss: 0.0361
2024-06-01 22:17:45 [INFO]: Epoch 046 - training loss: 0.2370, validation loss: 0.0410
2024-06-01 22:17:45 [INFO]: Epoch 047 - training loss: 0.2368, validation loss: 0.0379
2024-06-01 22:17:45 [INFO]: Epoch 048 - training loss: 0.2284, validation loss: 0.0360
2024-06-01 22:17:46 [INFO]: Epoch 049 - training loss: 0.2294, validation loss: 0.0401
2024-06-01 22:17:46 [INFO]: Epoch 050 - training loss: 0.2321, validation loss: 0.0370
2024-06-01 22:17:46 [INFO]: Epoch 051 - training loss: 0.2263, validation loss: 0.0406
2024-06-01 22:17:47 [INFO]: Epoch 052 - training loss: 0.2229, validation loss: 0.0381
2024-06-01 22:17:47 [INFO]: Epoch 053 - training loss: 0.2202, validation loss: 0.0397
2024-06-01 22:17:47 [INFO]: Epoch 054 - training loss: 0.2179, validation loss: 0.0386
2024-06-01 22:17:48 [INFO]: Epoch 055 - training loss: 0.2149, validation loss: 0.0369
2024-06-01 22:17:48 [INFO]: Epoch 056 - training loss: 0.2078, validation loss: 0.0392
2024-06-01 22:17:49 [INFO]: Epoch 057 - training loss: 0.2120, validation loss: 0.0471
2024-06-01 22:17:49 [INFO]: Epoch 058 - training loss: 0.2186, validation loss: 0.0416
2024-06-01 22:17:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:17:49 [INFO]: Finished training. The best model is from epoch#48.
2024-06-01 22:17:49 [INFO]: Saved the model to results_point_rate01/ETT_h1/Informer_ETT_h1/round_0/20240601_T221724/Informer.pypots
2024-06-01 22:17:49 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:17:49 [INFO]: Round0 - Informer on ETT_h1: MAE=0.1697, MSE=0.0606, MRE=0.2003
2024-06-01 22:17:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:17:49 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:49 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_1/20240601_T221749
2024-06-01 22:17:49 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_1/20240601_T221749/tensorboard
2024-06-01 22:17:49 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-01 22:17:49 [INFO]: Epoch 001 - training loss: 1.4082, validation loss: 0.5988
2024-06-01 22:17:50 [INFO]: Epoch 002 - training loss: 0.8042, validation loss: 0.2967
2024-06-01 22:17:50 [INFO]: Epoch 003 - training loss: 0.6310, validation loss: 0.2088
2024-06-01 22:17:51 [INFO]: Epoch 004 - training loss: 0.5344, validation loss: 0.1523
2024-06-01 22:17:51 [INFO]: Epoch 005 - training loss: 0.4881, validation loss: 0.1267
2024-06-01 22:17:51 [INFO]: Epoch 006 - training loss: 0.4556, validation loss: 0.1275
2024-06-01 22:17:52 [INFO]: Epoch 007 - training loss: 0.4408, validation loss: 0.0956
2024-06-01 22:17:52 [INFO]: Epoch 008 - training loss: 0.4140, validation loss: 0.0944
2024-06-01 22:17:52 [INFO]: Epoch 009 - training loss: 0.4140, validation loss: 0.0924
2024-06-01 22:17:52 [INFO]: Epoch 010 - training loss: 0.4029, validation loss: 0.0907
2024-06-01 22:17:53 [INFO]: Epoch 011 - training loss: 0.3854, validation loss: 0.0727
2024-06-01 22:17:53 [INFO]: Epoch 012 - training loss: 0.3783, validation loss: 0.0830
2024-06-01 22:17:53 [INFO]: Epoch 013 - training loss: 0.3578, validation loss: 0.0756
2024-06-01 22:17:54 [INFO]: Epoch 014 - training loss: 0.3395, validation loss: 0.0723
2024-06-01 22:17:54 [INFO]: Epoch 015 - training loss: 0.3311, validation loss: 0.0629
2024-06-01 22:17:54 [INFO]: Epoch 016 - training loss: 0.3324, validation loss: 0.0627
2024-06-01 22:17:54 [INFO]: Epoch 017 - training loss: 0.3203, validation loss: 0.0627
2024-06-01 22:17:55 [INFO]: Epoch 018 - training loss: 0.3112, validation loss: 0.0594
2024-06-01 22:17:55 [INFO]: Epoch 019 - training loss: 0.3121, validation loss: 0.0625
2024-06-01 22:17:55 [INFO]: Epoch 020 - training loss: 0.3164, validation loss: 0.0620
2024-06-01 22:17:56 [INFO]: Epoch 021 - training loss: 0.3014, validation loss: 0.0524
2024-06-01 22:17:56 [INFO]: Epoch 022 - training loss: 0.3034, validation loss: 0.0487
2024-06-01 22:17:57 [INFO]: Epoch 023 - training loss: 0.2796, validation loss: 0.0467
2024-06-01 22:17:57 [INFO]: Epoch 024 - training loss: 0.2932, validation loss: 0.0481
2024-06-01 22:17:57 [INFO]: Epoch 025 - training loss: 0.2918, validation loss: 0.0477
2024-06-01 22:17:58 [INFO]: Epoch 026 - training loss: 0.2809, validation loss: 0.0468
2024-06-01 22:17:58 [INFO]: Epoch 027 - training loss: 0.2717, validation loss: 0.0515
2024-06-01 22:17:58 [INFO]: Epoch 028 - training loss: 0.2611, validation loss: 0.0451
2024-06-01 22:17:59 [INFO]: Epoch 029 - training loss: 0.2653, validation loss: 0.0476
2024-06-01 22:17:59 [INFO]: Epoch 030 - training loss: 0.2525, validation loss: 0.0421
2024-06-01 22:17:59 [INFO]: Epoch 031 - training loss: 0.2483, validation loss: 0.0459
2024-06-01 22:18:00 [INFO]: Epoch 032 - training loss: 0.2512, validation loss: 0.0438
2024-06-01 22:18:00 [INFO]: Epoch 033 - training loss: 0.2539, validation loss: 0.0431
2024-06-01 22:18:00 [INFO]: Epoch 034 - training loss: 0.2507, validation loss: 0.0429
2024-06-01 22:18:01 [INFO]: Epoch 035 - training loss: 0.2557, validation loss: 0.0426
2024-06-01 22:18:01 [INFO]: Epoch 036 - training loss: 0.2392, validation loss: 0.0365
2024-06-01 22:18:02 [INFO]: Epoch 037 - training loss: 0.2392, validation loss: 0.0435
2024-06-01 22:18:02 [INFO]: Epoch 038 - training loss: 0.2450, validation loss: 0.0427
2024-06-01 22:18:02 [INFO]: Epoch 039 - training loss: 0.2380, validation loss: 0.0393
2024-06-01 22:18:03 [INFO]: Epoch 040 - training loss: 0.2338, validation loss: 0.0417
2024-06-01 22:18:03 [INFO]: Epoch 041 - training loss: 0.2327, validation loss: 0.0375
2024-06-01 22:18:04 [INFO]: Epoch 042 - training loss: 0.2312, validation loss: 0.0386
2024-06-01 22:18:04 [INFO]: Epoch 043 - training loss: 0.2315, validation loss: 0.0445
2024-06-01 22:18:04 [INFO]: Epoch 044 - training loss: 0.2334, validation loss: 0.0423
2024-06-01 22:18:05 [INFO]: Epoch 045 - training loss: 0.2300, validation loss: 0.0427
2024-06-01 22:18:05 [INFO]: Epoch 046 - training loss: 0.2387, validation loss: 0.0438
2024-06-01 22:18:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:05 [INFO]: Finished training. The best model is from epoch#36.
2024-06-01 22:18:05 [INFO]: Saved the model to results_point_rate01/ETT_h1/Informer_ETT_h1/round_1/20240601_T221749/Informer.pypots
2024-06-01 22:18:05 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:18:05 [INFO]: Round1 - Informer on ETT_h1: MAE=0.1715, MSE=0.0660, MRE=0.2023
2024-06-01 22:18:05 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:18:05 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:05 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_2/20240601_T221805
2024-06-01 22:18:05 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_2/20240601_T221805/tensorboard
2024-06-01 22:18:05 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-01 22:18:05 [INFO]: Epoch 001 - training loss: 1.3755, validation loss: 0.5748
2024-06-01 22:18:05 [INFO]: Epoch 002 - training loss: 0.7958, validation loss: 0.2958
2024-06-01 22:18:06 [INFO]: Epoch 003 - training loss: 0.6237, validation loss: 0.2594
2024-06-01 22:18:06 [INFO]: Epoch 004 - training loss: 0.5456, validation loss: 0.1509
2024-06-01 22:18:06 [INFO]: Epoch 005 - training loss: 0.4995, validation loss: 0.1270
2024-06-01 22:18:07 [INFO]: Epoch 006 - training loss: 0.4641, validation loss: 0.1297
2024-06-01 22:18:07 [INFO]: Epoch 007 - training loss: 0.4437, validation loss: 0.1111
2024-06-01 22:18:08 [INFO]: Epoch 008 - training loss: 0.4162, validation loss: 0.1030
2024-06-01 22:18:08 [INFO]: Epoch 009 - training loss: 0.4032, validation loss: 0.0956
2024-06-01 22:18:09 [INFO]: Epoch 010 - training loss: 0.3908, validation loss: 0.0908
2024-06-01 22:18:09 [INFO]: Epoch 011 - training loss: 0.3805, validation loss: 0.0830
2024-06-01 22:18:09 [INFO]: Epoch 012 - training loss: 0.3700, validation loss: 0.0763
2024-06-01 22:18:10 [INFO]: Epoch 013 - training loss: 0.3640, validation loss: 0.0747
2024-06-01 22:18:10 [INFO]: Epoch 014 - training loss: 0.3575, validation loss: 0.0765
2024-06-01 22:18:11 [INFO]: Epoch 015 - training loss: 0.3497, validation loss: 0.0709
2024-06-01 22:18:11 [INFO]: Epoch 016 - training loss: 0.3302, validation loss: 0.0639
2024-06-01 22:18:12 [INFO]: Epoch 017 - training loss: 0.3149, validation loss: 0.0679
2024-06-01 22:18:12 [INFO]: Epoch 018 - training loss: 0.3246, validation loss: 0.0669
2024-06-01 22:18:12 [INFO]: Epoch 019 - training loss: 0.3095, validation loss: 0.0721
2024-06-01 22:18:13 [INFO]: Epoch 020 - training loss: 0.3014, validation loss: 0.0610
2024-06-01 22:18:13 [INFO]: Epoch 021 - training loss: 0.2911, validation loss: 0.0537
2024-06-01 22:18:13 [INFO]: Epoch 022 - training loss: 0.2890, validation loss: 0.0578
2024-06-01 22:18:14 [INFO]: Epoch 023 - training loss: 0.2900, validation loss: 0.0592
2024-06-01 22:18:14 [INFO]: Epoch 024 - training loss: 0.2761, validation loss: 0.0577
2024-06-01 22:18:14 [INFO]: Epoch 025 - training loss: 0.2737, validation loss: 0.0573
2024-06-01 22:18:15 [INFO]: Epoch 026 - training loss: 0.2685, validation loss: 0.0482
2024-06-01 22:18:15 [INFO]: Epoch 027 - training loss: 0.2692, validation loss: 0.0486
2024-06-01 22:18:15 [INFO]: Epoch 028 - training loss: 0.2856, validation loss: 0.0502
2024-06-01 22:18:16 [INFO]: Epoch 029 - training loss: 0.2683, validation loss: 0.0509
2024-06-01 22:18:16 [INFO]: Epoch 030 - training loss: 0.2637, validation loss: 0.0488
2024-06-01 22:18:16 [INFO]: Epoch 031 - training loss: 0.2630, validation loss: 0.0438
2024-06-01 22:18:17 [INFO]: Epoch 032 - training loss: 0.2584, validation loss: 0.0486
2024-06-01 22:18:17 [INFO]: Epoch 033 - training loss: 0.2620, validation loss: 0.0505
2024-06-01 22:18:17 [INFO]: Epoch 034 - training loss: 0.2567, validation loss: 0.0515
2024-06-01 22:18:18 [INFO]: Epoch 035 - training loss: 0.2526, validation loss: 0.0456
2024-06-01 22:18:18 [INFO]: Epoch 036 - training loss: 0.2483, validation loss: 0.0431
2024-06-01 22:18:19 [INFO]: Epoch 037 - training loss: 0.2414, validation loss: 0.0503
2024-06-01 22:18:19 [INFO]: Epoch 038 - training loss: 0.2422, validation loss: 0.0432
2024-06-01 22:18:19 [INFO]: Epoch 039 - training loss: 0.2353, validation loss: 0.0410
2024-06-01 22:18:19 [INFO]: Epoch 040 - training loss: 0.2424, validation loss: 0.0429
2024-06-01 22:18:20 [INFO]: Epoch 041 - training loss: 0.2360, validation loss: 0.0422
2024-06-01 22:18:20 [INFO]: Epoch 042 - training loss: 0.2339, validation loss: 0.0458
2024-06-01 22:18:20 [INFO]: Epoch 043 - training loss: 0.2441, validation loss: 0.0432
2024-06-01 22:18:21 [INFO]: Epoch 044 - training loss: 0.2342, validation loss: 0.0384
2024-06-01 22:18:21 [INFO]: Epoch 045 - training loss: 0.2247, validation loss: 0.0416
2024-06-01 22:18:21 [INFO]: Epoch 046 - training loss: 0.2279, validation loss: 0.0451
2024-06-01 22:18:22 [INFO]: Epoch 047 - training loss: 0.2404, validation loss: 0.0438
2024-06-01 22:18:22 [INFO]: Epoch 048 - training loss: 0.2385, validation loss: 0.0407
2024-06-01 22:18:22 [INFO]: Epoch 049 - training loss: 0.2243, validation loss: 0.0440
2024-06-01 22:18:22 [INFO]: Epoch 050 - training loss: 0.2173, validation loss: 0.0406
2024-06-01 22:18:23 [INFO]: Epoch 051 - training loss: 0.2182, validation loss: 0.0405
2024-06-01 22:18:23 [INFO]: Epoch 052 - training loss: 0.2236, validation loss: 0.0406
2024-06-01 22:18:23 [INFO]: Epoch 053 - training loss: 0.2150, validation loss: 0.0427
2024-06-01 22:18:24 [INFO]: Epoch 054 - training loss: 0.2095, validation loss: 0.0387
2024-06-01 22:18:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:24 [INFO]: Finished training. The best model is from epoch#44.
2024-06-01 22:18:24 [INFO]: Saved the model to results_point_rate01/ETT_h1/Informer_ETT_h1/round_2/20240601_T221805/Informer.pypots
2024-06-01 22:18:24 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:18:24 [INFO]: Round2 - Informer on ETT_h1: MAE=0.1640, MSE=0.0644, MRE=0.1935
2024-06-01 22:18:24 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:18:24 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:24 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_3/20240601_T221824
2024-06-01 22:18:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_3/20240601_T221824/tensorboard
2024-06-01 22:18:24 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-01 22:18:24 [INFO]: Epoch 001 - training loss: 1.4506, validation loss: 0.5642
2024-06-01 22:18:25 [INFO]: Epoch 002 - training loss: 0.8280, validation loss: 0.2773
2024-06-01 22:18:25 [INFO]: Epoch 003 - training loss: 0.6274, validation loss: 0.2671
2024-06-01 22:18:25 [INFO]: Epoch 004 - training loss: 0.5334, validation loss: 0.1326
2024-06-01 22:18:26 [INFO]: Epoch 005 - training loss: 0.4921, validation loss: 0.1206
2024-06-01 22:18:26 [INFO]: Epoch 006 - training loss: 0.4541, validation loss: 0.1109
2024-06-01 22:18:27 [INFO]: Epoch 007 - training loss: 0.4421, validation loss: 0.1052
2024-06-01 22:18:27 [INFO]: Epoch 008 - training loss: 0.4167, validation loss: 0.0882
2024-06-01 22:18:28 [INFO]: Epoch 009 - training loss: 0.4052, validation loss: 0.0862
2024-06-01 22:18:28 [INFO]: Epoch 010 - training loss: 0.3922, validation loss: 0.0823
2024-06-01 22:18:28 [INFO]: Epoch 011 - training loss: 0.3809, validation loss: 0.0797
2024-06-01 22:18:29 [INFO]: Epoch 012 - training loss: 0.3791, validation loss: 0.0723
2024-06-01 22:18:29 [INFO]: Epoch 013 - training loss: 0.3727, validation loss: 0.0679
2024-06-01 22:18:29 [INFO]: Epoch 014 - training loss: 0.3549, validation loss: 0.0650
2024-06-01 22:18:30 [INFO]: Epoch 015 - training loss: 0.3380, validation loss: 0.0634
2024-06-01 22:18:30 [INFO]: Epoch 016 - training loss: 0.3339, validation loss: 0.0646
2024-06-01 22:18:30 [INFO]: Epoch 017 - training loss: 0.3353, validation loss: 0.0750
2024-06-01 22:18:31 [INFO]: Epoch 018 - training loss: 0.3086, validation loss: 0.0575
2024-06-01 22:18:31 [INFO]: Epoch 019 - training loss: 0.3095, validation loss: 0.0684
2024-06-01 22:18:31 [INFO]: Epoch 020 - training loss: 0.3133, validation loss: 0.0662
2024-06-01 22:18:31 [INFO]: Epoch 021 - training loss: 0.3062, validation loss: 0.0635
2024-06-01 22:18:31 [INFO]: Epoch 022 - training loss: 0.2874, validation loss: 0.0591
2024-06-01 22:18:31 [INFO]: Epoch 023 - training loss: 0.2845, validation loss: 0.0541
2024-06-01 22:18:32 [INFO]: Epoch 024 - training loss: 0.2762, validation loss: 0.0640
2024-06-01 22:18:32 [INFO]: Epoch 025 - training loss: 0.2786, validation loss: 0.0514
2024-06-01 22:18:32 [INFO]: Epoch 026 - training loss: 0.2805, validation loss: 0.0593
2024-06-01 22:18:32 [INFO]: Epoch 027 - training loss: 0.2788, validation loss: 0.0493
2024-06-01 22:18:33 [INFO]: Epoch 028 - training loss: 0.2794, validation loss: 0.0532
2024-06-01 22:18:33 [INFO]: Epoch 029 - training loss: 0.2796, validation loss: 0.0627
2024-06-01 22:18:33 [INFO]: Epoch 030 - training loss: 0.2674, validation loss: 0.0517
2024-06-01 22:18:33 [INFO]: Epoch 031 - training loss: 0.2611, validation loss: 0.0480
2024-06-01 22:18:34 [INFO]: Epoch 032 - training loss: 0.2621, validation loss: 0.0481
2024-06-01 22:18:34 [INFO]: Epoch 033 - training loss: 0.2559, validation loss: 0.0470
2024-06-01 22:18:34 [INFO]: Epoch 034 - training loss: 0.2550, validation loss: 0.0458
2024-06-01 22:18:34 [INFO]: Epoch 035 - training loss: 0.2534, validation loss: 0.0459
2024-06-01 22:18:34 [INFO]: Epoch 036 - training loss: 0.2484, validation loss: 0.0493
2024-06-01 22:18:35 [INFO]: Epoch 037 - training loss: 0.2547, validation loss: 0.0617
2024-06-01 22:18:35 [INFO]: Epoch 038 - training loss: 0.2640, validation loss: 0.0446
2024-06-01 22:18:35 [INFO]: Epoch 039 - training loss: 0.2615, validation loss: 0.0459
2024-06-01 22:18:35 [INFO]: Epoch 040 - training loss: 0.2436, validation loss: 0.0494
2024-06-01 22:18:35 [INFO]: Epoch 041 - training loss: 0.2458, validation loss: 0.0455
2024-06-01 22:18:36 [INFO]: Epoch 042 - training loss: 0.2393, validation loss: 0.0476
2024-06-01 22:18:36 [INFO]: Epoch 043 - training loss: 0.2358, validation loss: 0.0436
2024-06-01 22:18:36 [INFO]: Epoch 044 - training loss: 0.2408, validation loss: 0.0406
2024-06-01 22:18:36 [INFO]: Epoch 045 - training loss: 0.2369, validation loss: 0.0380
2024-06-01 22:18:37 [INFO]: Epoch 046 - training loss: 0.2290, validation loss: 0.0420
2024-06-01 22:18:37 [INFO]: Epoch 047 - training loss: 0.2274, validation loss: 0.0406
2024-06-01 22:18:37 [INFO]: Epoch 048 - training loss: 0.2324, validation loss: 0.0428
2024-06-01 22:18:37 [INFO]: Epoch 049 - training loss: 0.2365, validation loss: 0.0411
2024-06-01 22:18:37 [INFO]: Epoch 050 - training loss: 0.2218, validation loss: 0.0375
2024-06-01 22:18:38 [INFO]: Epoch 051 - training loss: 0.2173, validation loss: 0.0374
2024-06-01 22:18:38 [INFO]: Epoch 052 - training loss: 0.2132, validation loss: 0.0374
2024-06-01 22:18:38 [INFO]: Epoch 053 - training loss: 0.2155, validation loss: 0.0343
2024-06-01 22:18:38 [INFO]: Epoch 054 - training loss: 0.2096, validation loss: 0.0388
2024-06-01 22:18:39 [INFO]: Epoch 055 - training loss: 0.2150, validation loss: 0.0396
2024-06-01 22:18:39 [INFO]: Epoch 056 - training loss: 0.2109, validation loss: 0.0378
2024-06-01 22:18:39 [INFO]: Epoch 057 - training loss: 0.2128, validation loss: 0.0381
2024-06-01 22:18:39 [INFO]: Epoch 058 - training loss: 0.2122, validation loss: 0.0362
2024-06-01 22:18:39 [INFO]: Epoch 059 - training loss: 0.2074, validation loss: 0.0401
2024-06-01 22:18:40 [INFO]: Epoch 060 - training loss: 0.2084, validation loss: 0.0374
2024-06-01 22:18:40 [INFO]: Epoch 061 - training loss: 0.2054, validation loss: 0.0374
2024-06-01 22:18:40 [INFO]: Epoch 062 - training loss: 0.2041, validation loss: 0.0373
2024-06-01 22:18:40 [INFO]: Epoch 063 - training loss: 0.2093, validation loss: 0.0387
2024-06-01 22:18:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:40 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:18:40 [INFO]: Saved the model to results_point_rate01/ETT_h1/Informer_ETT_h1/round_3/20240601_T221824/Informer.pypots
2024-06-01 22:18:41 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:18:41 [INFO]: Round3 - Informer on ETT_h1: MAE=0.1720, MSE=0.0697, MRE=0.2030
2024-06-01 22:18:41 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:18:41 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:41 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_4/20240601_T221841
2024-06-01 22:18:41 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_4/20240601_T221841/tensorboard
2024-06-01 22:18:41 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-01 22:18:41 [INFO]: Epoch 001 - training loss: 1.3895, validation loss: 0.5656
2024-06-01 22:18:41 [INFO]: Epoch 002 - training loss: 0.7679, validation loss: 0.2528
2024-06-01 22:18:41 [INFO]: Epoch 003 - training loss: 0.5827, validation loss: 0.1661
2024-06-01 22:18:41 [INFO]: Epoch 004 - training loss: 0.5196, validation loss: 0.1316
2024-06-01 22:18:42 [INFO]: Epoch 005 - training loss: 0.4729, validation loss: 0.1352
2024-06-01 22:18:42 [INFO]: Epoch 006 - training loss: 0.4497, validation loss: 0.1255
2024-06-01 22:18:42 [INFO]: Epoch 007 - training loss: 0.4398, validation loss: 0.1117
2024-06-01 22:18:42 [INFO]: Epoch 008 - training loss: 0.4238, validation loss: 0.0924
2024-06-01 22:18:42 [INFO]: Epoch 009 - training loss: 0.4150, validation loss: 0.1089
2024-06-01 22:18:42 [INFO]: Epoch 010 - training loss: 0.3981, validation loss: 0.0949
2024-06-01 22:18:43 [INFO]: Epoch 011 - training loss: 0.3837, validation loss: 0.0898
2024-06-01 22:18:43 [INFO]: Epoch 012 - training loss: 0.3745, validation loss: 0.0884
2024-06-01 22:18:43 [INFO]: Epoch 013 - training loss: 0.3635, validation loss: 0.0772
2024-06-01 22:18:43 [INFO]: Epoch 014 - training loss: 0.3500, validation loss: 0.0767
2024-06-01 22:18:43 [INFO]: Epoch 015 - training loss: 0.3357, validation loss: 0.0687
2024-06-01 22:18:44 [INFO]: Epoch 016 - training loss: 0.3305, validation loss: 0.0762
2024-06-01 22:18:44 [INFO]: Epoch 017 - training loss: 0.3276, validation loss: 0.0698
2024-06-01 22:18:44 [INFO]: Epoch 018 - training loss: 0.3307, validation loss: 0.0631
2024-06-01 22:18:44 [INFO]: Epoch 019 - training loss: 0.3127, validation loss: 0.0598
2024-06-01 22:18:45 [INFO]: Epoch 020 - training loss: 0.3101, validation loss: 0.0645
2024-06-01 22:18:45 [INFO]: Epoch 021 - training loss: 0.3062, validation loss: 0.0568
2024-06-01 22:18:45 [INFO]: Epoch 022 - training loss: 0.2965, validation loss: 0.0601
2024-06-01 22:18:45 [INFO]: Epoch 023 - training loss: 0.2990, validation loss: 0.0651
2024-06-01 22:18:45 [INFO]: Epoch 024 - training loss: 0.2952, validation loss: 0.0523
2024-06-01 22:18:46 [INFO]: Epoch 025 - training loss: 0.2846, validation loss: 0.0506
2024-06-01 22:18:46 [INFO]: Epoch 026 - training loss: 0.2935, validation loss: 0.0620
2024-06-01 22:18:46 [INFO]: Epoch 027 - training loss: 0.2927, validation loss: 0.0598
2024-06-01 22:18:46 [INFO]: Epoch 028 - training loss: 0.2875, validation loss: 0.0538
2024-06-01 22:18:47 [INFO]: Epoch 029 - training loss: 0.2831, validation loss: 0.0545
2024-06-01 22:18:47 [INFO]: Epoch 030 - training loss: 0.2758, validation loss: 0.0445
2024-06-01 22:18:47 [INFO]: Epoch 031 - training loss: 0.2658, validation loss: 0.0530
2024-06-01 22:18:47 [INFO]: Epoch 032 - training loss: 0.2590, validation loss: 0.0458
2024-06-01 22:18:47 [INFO]: Epoch 033 - training loss: 0.2675, validation loss: 0.0592
2024-06-01 22:18:48 [INFO]: Epoch 034 - training loss: 0.2608, validation loss: 0.0443
2024-06-01 22:18:48 [INFO]: Epoch 035 - training loss: 0.2566, validation loss: 0.0400
2024-06-01 22:18:48 [INFO]: Epoch 036 - training loss: 0.2469, validation loss: 0.0434
2024-06-01 22:18:48 [INFO]: Epoch 037 - training loss: 0.2478, validation loss: 0.0463
2024-06-01 22:18:48 [INFO]: Epoch 038 - training loss: 0.2498, validation loss: 0.0515
2024-06-01 22:18:49 [INFO]: Epoch 039 - training loss: 0.2486, validation loss: 0.0426
2024-06-01 22:18:49 [INFO]: Epoch 040 - training loss: 0.2397, validation loss: 0.0388
2024-06-01 22:18:49 [INFO]: Epoch 041 - training loss: 0.2360, validation loss: 0.0449
2024-06-01 22:18:49 [INFO]: Epoch 042 - training loss: 0.2415, validation loss: 0.0417
2024-06-01 22:18:50 [INFO]: Epoch 043 - training loss: 0.2427, validation loss: 0.0487
2024-06-01 22:18:50 [INFO]: Epoch 044 - training loss: 0.2715, validation loss: 0.0419
2024-06-01 22:18:50 [INFO]: Epoch 045 - training loss: 0.2661, validation loss: 0.0438
2024-06-01 22:18:50 [INFO]: Epoch 046 - training loss: 0.2518, validation loss: 0.0480
2024-06-01 22:18:50 [INFO]: Epoch 047 - training loss: 0.2421, validation loss: 0.0452
2024-06-01 22:18:51 [INFO]: Epoch 048 - training loss: 0.2347, validation loss: 0.0409
2024-06-01 22:18:51 [INFO]: Epoch 049 - training loss: 0.2318, validation loss: 0.0381
2024-06-01 22:18:51 [INFO]: Epoch 050 - training loss: 0.2262, validation loss: 0.0375
2024-06-01 22:18:51 [INFO]: Epoch 051 - training loss: 0.2215, validation loss: 0.0357
2024-06-01 22:18:52 [INFO]: Epoch 052 - training loss: 0.2213, validation loss: 0.0391
2024-06-01 22:18:52 [INFO]: Epoch 053 - training loss: 0.2222, validation loss: 0.0397
2024-06-01 22:18:52 [INFO]: Epoch 054 - training loss: 0.2194, validation loss: 0.0410
2024-06-01 22:18:52 [INFO]: Epoch 055 - training loss: 0.2166, validation loss: 0.0348
2024-06-01 22:18:52 [INFO]: Epoch 056 - training loss: 0.2117, validation loss: 0.0367
2024-06-01 22:18:53 [INFO]: Epoch 057 - training loss: 0.2215, validation loss: 0.0456
2024-06-01 22:18:53 [INFO]: Epoch 058 - training loss: 0.2281, validation loss: 0.0396
2024-06-01 22:18:53 [INFO]: Epoch 059 - training loss: 0.2212, validation loss: 0.0371
2024-06-01 22:18:53 [INFO]: Epoch 060 - training loss: 0.2189, validation loss: 0.0403
2024-06-01 22:18:54 [INFO]: Epoch 061 - training loss: 0.2138, validation loss: 0.0340
2024-06-01 22:18:54 [INFO]: Epoch 062 - training loss: 0.2119, validation loss: 0.0334
2024-06-01 22:18:54 [INFO]: Epoch 063 - training loss: 0.2092, validation loss: 0.0349
2024-06-01 22:18:54 [INFO]: Epoch 064 - training loss: 0.2081, validation loss: 0.0336
2024-06-01 22:18:54 [INFO]: Epoch 065 - training loss: 0.2039, validation loss: 0.0323
2024-06-01 22:18:55 [INFO]: Epoch 066 - training loss: 0.2010, validation loss: 0.0358
2024-06-01 22:18:55 [INFO]: Epoch 067 - training loss: 0.2025, validation loss: 0.0370
2024-06-01 22:18:55 [INFO]: Epoch 068 - training loss: 0.2078, validation loss: 0.0334
2024-06-01 22:18:55 [INFO]: Epoch 069 - training loss: 0.2077, validation loss: 0.0366
2024-06-01 22:18:56 [INFO]: Epoch 070 - training loss: 0.2025, validation loss: 0.0353
2024-06-01 22:18:56 [INFO]: Epoch 071 - training loss: 0.1965, validation loss: 0.0355
2024-06-01 22:18:56 [INFO]: Epoch 072 - training loss: 0.1980, validation loss: 0.0363
2024-06-01 22:18:56 [INFO]: Epoch 073 - training loss: 0.1988, validation loss: 0.0340
2024-06-01 22:18:56 [INFO]: Epoch 074 - training loss: 0.1942, validation loss: 0.0361
2024-06-01 22:18:57 [INFO]: Epoch 075 - training loss: 0.1904, validation loss: 0.0332
2024-06-01 22:18:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:57 [INFO]: Finished training. The best model is from epoch#65.
2024-06-01 22:18:57 [INFO]: Saved the model to results_point_rate01/ETT_h1/Informer_ETT_h1/round_4/20240601_T221841/Informer.pypots
2024-06-01 22:18:57 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Informer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:18:57 [INFO]: Round4 - Informer on ETT_h1: MAE=0.1572, MSE=0.0569, MRE=0.1855
2024-06-01 22:18:57 [INFO]: Done! Final results:
Averaged Informer (n params: 1,058,311) on ETT_h1: MAE=0.1669 ± 0.005620810285763416, MSE=0.0635 ± 0.0044203701039269745, MRE=0.1969 ± 0.006633067998879855, average inference time=0.05
