2024-06-01 22:15:33 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:15:33 [INFO]: Using the given device: cuda:0
2024-06-01 22:15:33 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_0/20240601_T221533
2024-06-01 22:15:33 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_0/20240601_T221533/tensorboard
2024-06-01 22:15:34 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 809,057
2024-06-01 22:15:38 [INFO]: Epoch 001 - training loss: 1.0482, validation loss: 0.4419
2024-06-01 22:15:38 [INFO]: Epoch 002 - training loss: 0.8559, validation loss: 0.3015
2024-06-01 22:15:39 [INFO]: Epoch 003 - training loss: 0.7500, validation loss: 0.2037
2024-06-01 22:15:40 [INFO]: Epoch 004 - training loss: 0.6633, validation loss: 0.1636
2024-06-01 22:15:40 [INFO]: Epoch 005 - training loss: 0.6148, validation loss: 0.1471
2024-06-01 22:15:41 [INFO]: Epoch 006 - training loss: 0.5785, validation loss: 0.1236
2024-06-01 22:15:42 [INFO]: Epoch 007 - training loss: 0.5492, validation loss: 0.1098
2024-06-01 22:15:42 [INFO]: Epoch 008 - training loss: 0.5340, validation loss: 0.1168
2024-06-01 22:15:43 [INFO]: Epoch 009 - training loss: 0.5194, validation loss: 0.1169
2024-06-01 22:15:44 [INFO]: Epoch 010 - training loss: 0.5209, validation loss: 0.1122
2024-06-01 22:15:44 [INFO]: Epoch 011 - training loss: 0.4988, validation loss: 0.1041
2024-06-01 22:15:45 [INFO]: Epoch 012 - training loss: 0.5040, validation loss: 0.0986
2024-06-01 22:15:45 [INFO]: Epoch 013 - training loss: 0.4947, validation loss: 0.0945
2024-06-01 22:15:46 [INFO]: Epoch 014 - training loss: 0.4928, validation loss: 0.0910
2024-06-01 22:15:47 [INFO]: Epoch 015 - training loss: 0.4971, validation loss: 0.0967
2024-06-01 22:15:47 [INFO]: Epoch 016 - training loss: 0.4877, validation loss: 0.0940
2024-06-01 22:15:48 [INFO]: Epoch 017 - training loss: 0.4840, validation loss: 0.0877
2024-06-01 22:15:49 [INFO]: Epoch 018 - training loss: 0.4841, validation loss: 0.0895
2024-06-01 22:15:49 [INFO]: Epoch 019 - training loss: 0.4806, validation loss: 0.0873
2024-06-01 22:15:50 [INFO]: Epoch 020 - training loss: 0.4765, validation loss: 0.0851
2024-06-01 22:15:50 [INFO]: Epoch 021 - training loss: 0.4720, validation loss: 0.0828
2024-06-01 22:15:51 [INFO]: Epoch 022 - training loss: 0.4766, validation loss: 0.0866
2024-06-01 22:15:52 [INFO]: Epoch 023 - training loss: 0.4683, validation loss: 0.0824
2024-06-01 22:15:52 [INFO]: Epoch 024 - training loss: 0.4774, validation loss: 0.0817
2024-06-01 22:15:53 [INFO]: Epoch 025 - training loss: 0.4714, validation loss: 0.0835
2024-06-01 22:15:54 [INFO]: Epoch 026 - training loss: 0.4677, validation loss: 0.0811
2024-06-01 22:15:54 [INFO]: Epoch 027 - training loss: 0.4649, validation loss: 0.0779
2024-06-01 22:15:55 [INFO]: Epoch 028 - training loss: 0.4602, validation loss: 0.0812
2024-06-01 22:15:56 [INFO]: Epoch 029 - training loss: 0.4647, validation loss: 0.0766
2024-06-01 22:15:56 [INFO]: Epoch 030 - training loss: 0.4661, validation loss: 0.0770
2024-06-01 22:15:57 [INFO]: Epoch 031 - training loss: 0.4631, validation loss: 0.0768
2024-06-01 22:15:57 [INFO]: Epoch 032 - training loss: 0.4594, validation loss: 0.0797
2024-06-01 22:15:58 [INFO]: Epoch 033 - training loss: 0.4585, validation loss: 0.0782
2024-06-01 22:15:59 [INFO]: Epoch 034 - training loss: 0.4645, validation loss: 0.0813
2024-06-01 22:16:00 [INFO]: Epoch 035 - training loss: 0.4599, validation loss: 0.0833
2024-06-01 22:16:00 [INFO]: Epoch 036 - training loss: 0.4562, validation loss: 0.0778
2024-06-01 22:16:01 [INFO]: Epoch 037 - training loss: 0.4574, validation loss: 0.0756
2024-06-01 22:16:01 [INFO]: Epoch 038 - training loss: 0.4548, validation loss: 0.0763
2024-06-01 22:16:02 [INFO]: Epoch 039 - training loss: 0.4568, validation loss: 0.0757
2024-06-01 22:16:03 [INFO]: Epoch 040 - training loss: 0.4529, validation loss: 0.0760
2024-06-01 22:16:03 [INFO]: Epoch 041 - training loss: 0.4623, validation loss: 0.0761
2024-06-01 22:16:04 [INFO]: Epoch 042 - training loss: 0.4507, validation loss: 0.0787
2024-06-01 22:16:04 [INFO]: Epoch 043 - training loss: 0.4498, validation loss: 0.0762
2024-06-01 22:16:05 [INFO]: Epoch 044 - training loss: 0.4532, validation loss: 0.0790
2024-06-01 22:16:06 [INFO]: Epoch 045 - training loss: 0.4484, validation loss: 0.0757
2024-06-01 22:16:06 [INFO]: Epoch 046 - training loss: 0.4481, validation loss: 0.0747
2024-06-01 22:16:07 [INFO]: Epoch 047 - training loss: 0.4431, validation loss: 0.0731
2024-06-01 22:16:07 [INFO]: Epoch 048 - training loss: 0.4459, validation loss: 0.0762
2024-06-01 22:16:08 [INFO]: Epoch 049 - training loss: 0.4454, validation loss: 0.0771
2024-06-01 22:16:09 [INFO]: Epoch 050 - training loss: 0.4496, validation loss: 0.0749
2024-06-01 22:16:09 [INFO]: Epoch 051 - training loss: 0.4487, validation loss: 0.0747
2024-06-01 22:16:10 [INFO]: Epoch 052 - training loss: 0.4472, validation loss: 0.0714
2024-06-01 22:16:11 [INFO]: Epoch 053 - training loss: 0.4473, validation loss: 0.0723
2024-06-01 22:16:11 [INFO]: Epoch 054 - training loss: 0.4473, validation loss: 0.0753
2024-06-01 22:16:12 [INFO]: Epoch 055 - training loss: 0.4399, validation loss: 0.0744
2024-06-01 22:16:13 [INFO]: Epoch 056 - training loss: 0.4419, validation loss: 0.0734
2024-06-01 22:16:13 [INFO]: Epoch 057 - training loss: 0.4405, validation loss: 0.0729
2024-06-01 22:16:14 [INFO]: Epoch 058 - training loss: 0.4421, validation loss: 0.0728
2024-06-01 22:16:14 [INFO]: Epoch 059 - training loss: 0.4397, validation loss: 0.0714
2024-06-01 22:16:15 [INFO]: Epoch 060 - training loss: 0.4422, validation loss: 0.0737
2024-06-01 22:16:16 [INFO]: Epoch 061 - training loss: 0.4349, validation loss: 0.0719
2024-06-01 22:16:16 [INFO]: Epoch 062 - training loss: 0.4364, validation loss: 0.0690
2024-06-01 22:16:17 [INFO]: Epoch 063 - training loss: 0.4367, validation loss: 0.0710
2024-06-01 22:16:18 [INFO]: Epoch 064 - training loss: 0.4464, validation loss: 0.0733
2024-06-01 22:16:18 [INFO]: Epoch 065 - training loss: 0.4339, validation loss: 0.0744
2024-06-01 22:16:19 [INFO]: Epoch 066 - training loss: 0.4346, validation loss: 0.0736
2024-06-01 22:16:19 [INFO]: Epoch 067 - training loss: 0.4306, validation loss: 0.0734
2024-06-01 22:16:20 [INFO]: Epoch 068 - training loss: 0.4319, validation loss: 0.0713
2024-06-01 22:16:21 [INFO]: Epoch 069 - training loss: 0.4336, validation loss: 0.0711
2024-06-01 22:16:21 [INFO]: Epoch 070 - training loss: 0.4418, validation loss: 0.0737
2024-06-01 22:16:22 [INFO]: Epoch 071 - training loss: 0.4271, validation loss: 0.0724
2024-06-01 22:16:23 [INFO]: Epoch 072 - training loss: 0.4334, validation loss: 0.0717
2024-06-01 22:16:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:23 [INFO]: Finished training. The best model is from epoch#62.
2024-06-01 22:16:23 [INFO]: Saved the model to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_0/20240601_T221533/ETSformer.pypots
2024-06-01 22:16:23 [INFO]: Successfully saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:16:23 [INFO]: Round0 - ETSformer on ETT_h1: MAE=0.2320, MSE=0.1116, MRE=0.2738
2024-06-01 22:16:23 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:16:23 [INFO]: Using the given device: cuda:0
2024-06-01 22:16:23 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_1/20240601_T221623
2024-06-01 22:16:23 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_1/20240601_T221623/tensorboard
2024-06-01 22:16:23 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 809,057
2024-06-01 22:16:23 [INFO]: Epoch 001 - training loss: 1.1020, validation loss: 0.4789
2024-06-01 22:16:24 [INFO]: Epoch 002 - training loss: 0.8790, validation loss: 0.3099
2024-06-01 22:16:25 [INFO]: Epoch 003 - training loss: 0.7609, validation loss: 0.2093
2024-06-01 22:16:25 [INFO]: Epoch 004 - training loss: 0.6775, validation loss: 0.1597
2024-06-01 22:16:26 [INFO]: Epoch 005 - training loss: 0.6232, validation loss: 0.1387
2024-06-01 22:16:27 [INFO]: Epoch 006 - training loss: 0.5910, validation loss: 0.1257
2024-06-01 22:16:27 [INFO]: Epoch 007 - training loss: 0.5607, validation loss: 0.1277
2024-06-01 22:16:28 [INFO]: Epoch 008 - training loss: 0.5404, validation loss: 0.1296
2024-06-01 22:16:28 [INFO]: Epoch 009 - training loss: 0.5265, validation loss: 0.1228
2024-06-01 22:16:29 [INFO]: Epoch 010 - training loss: 0.5127, validation loss: 0.1169
2024-06-01 22:16:29 [INFO]: Epoch 011 - training loss: 0.4976, validation loss: 0.1030
2024-06-01 22:16:30 [INFO]: Epoch 012 - training loss: 0.4944, validation loss: 0.1048
2024-06-01 22:16:30 [INFO]: Epoch 013 - training loss: 0.4883, validation loss: 0.0935
2024-06-01 22:16:31 [INFO]: Epoch 014 - training loss: 0.4800, validation loss: 0.0953
2024-06-01 22:16:31 [INFO]: Epoch 015 - training loss: 0.4723, validation loss: 0.0909
2024-06-01 22:16:32 [INFO]: Epoch 016 - training loss: 0.4745, validation loss: 0.0892
2024-06-01 22:16:32 [INFO]: Epoch 017 - training loss: 0.4686, validation loss: 0.0891
2024-06-01 22:16:32 [INFO]: Epoch 018 - training loss: 0.4668, validation loss: 0.0865
2024-06-01 22:16:33 [INFO]: Epoch 019 - training loss: 0.4662, validation loss: 0.0844
2024-06-01 22:16:33 [INFO]: Epoch 020 - training loss: 0.4605, validation loss: 0.0839
2024-06-01 22:16:33 [INFO]: Epoch 021 - training loss: 0.4631, validation loss: 0.0811
2024-06-01 22:16:34 [INFO]: Epoch 022 - training loss: 0.4583, validation loss: 0.0787
2024-06-01 22:16:34 [INFO]: Epoch 023 - training loss: 0.4571, validation loss: 0.0814
2024-06-01 22:16:35 [INFO]: Epoch 024 - training loss: 0.4567, validation loss: 0.0778
2024-06-01 22:16:35 [INFO]: Epoch 025 - training loss: 0.4560, validation loss: 0.0753
2024-06-01 22:16:35 [INFO]: Epoch 026 - training loss: 0.4543, validation loss: 0.0767
2024-06-01 22:16:36 [INFO]: Epoch 027 - training loss: 0.4642, validation loss: 0.0782
2024-06-01 22:16:36 [INFO]: Epoch 028 - training loss: 0.4466, validation loss: 0.0761
2024-06-01 22:16:37 [INFO]: Epoch 029 - training loss: 0.4549, validation loss: 0.0747
2024-06-01 22:16:37 [INFO]: Epoch 030 - training loss: 0.4476, validation loss: 0.0727
2024-06-01 22:16:37 [INFO]: Epoch 031 - training loss: 0.4511, validation loss: 0.0738
2024-06-01 22:16:38 [INFO]: Epoch 032 - training loss: 0.4470, validation loss: 0.0727
2024-06-01 22:16:38 [INFO]: Epoch 033 - training loss: 0.4457, validation loss: 0.0733
2024-06-01 22:16:38 [INFO]: Epoch 034 - training loss: 0.4483, validation loss: 0.0712
2024-06-01 22:16:39 [INFO]: Epoch 035 - training loss: 0.4411, validation loss: 0.0718
2024-06-01 22:16:39 [INFO]: Epoch 036 - training loss: 0.4393, validation loss: 0.0714
2024-06-01 22:16:39 [INFO]: Epoch 037 - training loss: 0.4355, validation loss: 0.0701
2024-06-01 22:16:39 [INFO]: Epoch 038 - training loss: 0.4438, validation loss: 0.0734
2024-06-01 22:16:39 [INFO]: Epoch 039 - training loss: 0.4442, validation loss: 0.0703
2024-06-01 22:16:39 [INFO]: Epoch 040 - training loss: 0.4428, validation loss: 0.0711
2024-06-01 22:16:40 [INFO]: Epoch 041 - training loss: 0.4393, validation loss: 0.0703
2024-06-01 22:16:40 [INFO]: Epoch 042 - training loss: 0.4420, validation loss: 0.0710
2024-06-01 22:16:40 [INFO]: Epoch 043 - training loss: 0.4377, validation loss: 0.0688
2024-06-01 22:16:40 [INFO]: Epoch 044 - training loss: 0.4365, validation loss: 0.0703
2024-06-01 22:16:40 [INFO]: Epoch 045 - training loss: 0.4330, validation loss: 0.0716
2024-06-01 22:16:40 [INFO]: Epoch 046 - training loss: 0.4280, validation loss: 0.0666
2024-06-01 22:16:41 [INFO]: Epoch 047 - training loss: 0.4313, validation loss: 0.0680
2024-06-01 22:16:41 [INFO]: Epoch 048 - training loss: 0.4328, validation loss: 0.0686
2024-06-01 22:16:41 [INFO]: Epoch 049 - training loss: 0.4276, validation loss: 0.0678
2024-06-01 22:16:41 [INFO]: Epoch 050 - training loss: 0.4292, validation loss: 0.0701
2024-06-01 22:16:41 [INFO]: Epoch 051 - training loss: 0.4299, validation loss: 0.0672
2024-06-01 22:16:41 [INFO]: Epoch 052 - training loss: 0.4227, validation loss: 0.0651
2024-06-01 22:16:41 [INFO]: Epoch 053 - training loss: 0.4188, validation loss: 0.0650
2024-06-01 22:16:42 [INFO]: Epoch 054 - training loss: 0.4237, validation loss: 0.0670
2024-06-01 22:16:42 [INFO]: Epoch 055 - training loss: 0.4205, validation loss: 0.0693
2024-06-01 22:16:42 [INFO]: Epoch 056 - training loss: 0.4207, validation loss: 0.0690
2024-06-01 22:16:42 [INFO]: Epoch 057 - training loss: 0.4175, validation loss: 0.0717
2024-06-01 22:16:42 [INFO]: Epoch 058 - training loss: 0.4202, validation loss: 0.0672
2024-06-01 22:16:42 [INFO]: Epoch 059 - training loss: 0.4199, validation loss: 0.0657
2024-06-01 22:16:42 [INFO]: Epoch 060 - training loss: 0.4173, validation loss: 0.0666
2024-06-01 22:16:43 [INFO]: Epoch 061 - training loss: 0.4152, validation loss: 0.0685
2024-06-01 22:16:43 [INFO]: Epoch 062 - training loss: 0.4160, validation loss: 0.0707
2024-06-01 22:16:43 [INFO]: Epoch 063 - training loss: 0.4093, validation loss: 0.0658
2024-06-01 22:16:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:43 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:16:43 [INFO]: Saved the model to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_1/20240601_T221623/ETSformer.pypots
2024-06-01 22:16:43 [INFO]: Successfully saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:16:43 [INFO]: Round1 - ETSformer on ETT_h1: MAE=0.2191, MSE=0.1005, MRE=0.2585
2024-06-01 22:16:43 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:16:43 [INFO]: Using the given device: cuda:0
2024-06-01 22:16:43 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_2/20240601_T221643
2024-06-01 22:16:43 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_2/20240601_T221643/tensorboard
2024-06-01 22:16:43 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 809,057
2024-06-01 22:16:43 [INFO]: Epoch 001 - training loss: 1.0816, validation loss: 0.4687
2024-06-01 22:16:43 [INFO]: Epoch 002 - training loss: 0.8835, validation loss: 0.3030
2024-06-01 22:16:43 [INFO]: Epoch 003 - training loss: 0.7722, validation loss: 0.2228
2024-06-01 22:16:43 [INFO]: Epoch 004 - training loss: 0.6765, validation loss: 0.1603
2024-06-01 22:16:44 [INFO]: Epoch 005 - training loss: 0.6183, validation loss: 0.1470
2024-06-01 22:16:44 [INFO]: Epoch 006 - training loss: 0.5846, validation loss: 0.1279
2024-06-01 22:16:44 [INFO]: Epoch 007 - training loss: 0.5502, validation loss: 0.1236
2024-06-01 22:16:44 [INFO]: Epoch 008 - training loss: 0.5414, validation loss: 0.1121
2024-06-01 22:16:44 [INFO]: Epoch 009 - training loss: 0.5321, validation loss: 0.1127
2024-06-01 22:16:44 [INFO]: Epoch 010 - training loss: 0.5200, validation loss: 0.1068
2024-06-01 22:16:45 [INFO]: Epoch 011 - training loss: 0.5057, validation loss: 0.1060
2024-06-01 22:16:45 [INFO]: Epoch 012 - training loss: 0.4947, validation loss: 0.0977
2024-06-01 22:16:45 [INFO]: Epoch 013 - training loss: 0.5009, validation loss: 0.1046
2024-06-01 22:16:45 [INFO]: Epoch 014 - training loss: 0.5073, validation loss: 0.1018
2024-06-01 22:16:45 [INFO]: Epoch 015 - training loss: 0.4967, validation loss: 0.1021
2024-06-01 22:16:46 [INFO]: Epoch 016 - training loss: 0.4880, validation loss: 0.0975
2024-06-01 22:16:46 [INFO]: Epoch 017 - training loss: 0.4830, validation loss: 0.0964
2024-06-01 22:16:46 [INFO]: Epoch 018 - training loss: 0.4801, validation loss: 0.0913
2024-06-01 22:16:46 [INFO]: Epoch 019 - training loss: 0.4751, validation loss: 0.0875
2024-06-01 22:16:46 [INFO]: Epoch 020 - training loss: 0.4706, validation loss: 0.0890
2024-06-01 22:16:46 [INFO]: Epoch 021 - training loss: 0.4732, validation loss: 0.0860
2024-06-01 22:16:46 [INFO]: Epoch 022 - training loss: 0.4779, validation loss: 0.0896
2024-06-01 22:16:47 [INFO]: Epoch 023 - training loss: 0.4788, validation loss: 0.0889
2024-06-01 22:16:47 [INFO]: Epoch 024 - training loss: 0.4740, validation loss: 0.0860
2024-06-01 22:16:47 [INFO]: Epoch 025 - training loss: 0.4677, validation loss: 0.0848
2024-06-01 22:16:47 [INFO]: Epoch 026 - training loss: 0.4657, validation loss: 0.0843
2024-06-01 22:16:47 [INFO]: Epoch 027 - training loss: 0.4699, validation loss: 0.0813
2024-06-01 22:16:47 [INFO]: Epoch 028 - training loss: 0.4622, validation loss: 0.0799
2024-06-01 22:16:48 [INFO]: Epoch 029 - training loss: 0.4614, validation loss: 0.0834
2024-06-01 22:16:48 [INFO]: Epoch 030 - training loss: 0.4532, validation loss: 0.0814
2024-06-01 22:16:48 [INFO]: Epoch 031 - training loss: 0.4553, validation loss: 0.0850
2024-06-01 22:16:48 [INFO]: Epoch 032 - training loss: 0.4576, validation loss: 0.0839
2024-06-01 22:16:48 [INFO]: Epoch 033 - training loss: 0.4603, validation loss: 0.0780
2024-06-01 22:16:48 [INFO]: Epoch 034 - training loss: 0.4515, validation loss: 0.0772
2024-06-01 22:16:48 [INFO]: Epoch 035 - training loss: 0.4579, validation loss: 0.0790
2024-06-01 22:16:49 [INFO]: Epoch 036 - training loss: 0.4574, validation loss: 0.0789
2024-06-01 22:16:49 [INFO]: Epoch 037 - training loss: 0.4509, validation loss: 0.0806
2024-06-01 22:16:49 [INFO]: Epoch 038 - training loss: 0.4567, validation loss: 0.0761
2024-06-01 22:16:49 [INFO]: Epoch 039 - training loss: 0.4482, validation loss: 0.0778
2024-06-01 22:16:49 [INFO]: Epoch 040 - training loss: 0.4494, validation loss: 0.0805
2024-06-01 22:16:49 [INFO]: Epoch 041 - training loss: 0.4477, validation loss: 0.0811
2024-06-01 22:16:49 [INFO]: Epoch 042 - training loss: 0.4486, validation loss: 0.0869
2024-06-01 22:16:50 [INFO]: Epoch 043 - training loss: 0.4502, validation loss: 0.0803
2024-06-01 22:16:50 [INFO]: Epoch 044 - training loss: 0.4552, validation loss: 0.0783
2024-06-01 22:16:50 [INFO]: Epoch 045 - training loss: 0.4420, validation loss: 0.0783
2024-06-01 22:16:50 [INFO]: Epoch 046 - training loss: 0.4463, validation loss: 0.0769
2024-06-01 22:16:50 [INFO]: Epoch 047 - training loss: 0.4472, validation loss: 0.0743
2024-06-01 22:16:50 [INFO]: Epoch 048 - training loss: 0.4432, validation loss: 0.0734
2024-06-01 22:16:50 [INFO]: Epoch 049 - training loss: 0.4437, validation loss: 0.0743
2024-06-01 22:16:51 [INFO]: Epoch 050 - training loss: 0.4514, validation loss: 0.0742
2024-06-01 22:16:51 [INFO]: Epoch 051 - training loss: 0.4410, validation loss: 0.0759
2024-06-01 22:16:51 [INFO]: Epoch 052 - training loss: 0.4379, validation loss: 0.0739
2024-06-01 22:16:51 [INFO]: Epoch 053 - training loss: 0.4443, validation loss: 0.0747
2024-06-01 22:16:51 [INFO]: Epoch 054 - training loss: 0.4388, validation loss: 0.0758
2024-06-01 22:16:51 [INFO]: Epoch 055 - training loss: 0.4381, validation loss: 0.0745
2024-06-01 22:16:52 [INFO]: Epoch 056 - training loss: 0.4351, validation loss: 0.0779
2024-06-01 22:16:52 [INFO]: Epoch 057 - training loss: 0.4349, validation loss: 0.0745
2024-06-01 22:16:52 [INFO]: Epoch 058 - training loss: 0.4344, validation loss: 0.0757
2024-06-01 22:16:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:52 [INFO]: Finished training. The best model is from epoch#48.
2024-06-01 22:16:52 [INFO]: Saved the model to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_2/20240601_T221643/ETSformer.pypots
2024-06-01 22:16:52 [INFO]: Successfully saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:16:52 [INFO]: Round2 - ETSformer on ETT_h1: MAE=0.2354, MSE=0.1137, MRE=0.2778
2024-06-01 22:16:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:16:52 [INFO]: Using the given device: cuda:0
2024-06-01 22:16:52 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_3/20240601_T221652
2024-06-01 22:16:52 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_3/20240601_T221652/tensorboard
2024-06-01 22:16:52 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 809,057
2024-06-01 22:16:52 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.4594
2024-06-01 22:16:52 [INFO]: Epoch 002 - training loss: 0.8712, validation loss: 0.3032
2024-06-01 22:16:52 [INFO]: Epoch 003 - training loss: 0.7426, validation loss: 0.2099
2024-06-01 22:16:52 [INFO]: Epoch 004 - training loss: 0.6750, validation loss: 0.1735
2024-06-01 22:16:53 [INFO]: Epoch 005 - training loss: 0.6284, validation loss: 0.1363
2024-06-01 22:16:53 [INFO]: Epoch 006 - training loss: 0.6046, validation loss: 0.1236
2024-06-01 22:16:53 [INFO]: Epoch 007 - training loss: 0.5733, validation loss: 0.1188
2024-06-01 22:16:53 [INFO]: Epoch 008 - training loss: 0.5466, validation loss: 0.1160
2024-06-01 22:16:53 [INFO]: Epoch 009 - training loss: 0.5311, validation loss: 0.1134
2024-06-01 22:16:53 [INFO]: Epoch 010 - training loss: 0.5159, validation loss: 0.1152
2024-06-01 22:16:53 [INFO]: Epoch 011 - training loss: 0.5012, validation loss: 0.1122
2024-06-01 22:16:54 [INFO]: Epoch 012 - training loss: 0.5052, validation loss: 0.1169
2024-06-01 22:16:54 [INFO]: Epoch 013 - training loss: 0.5068, validation loss: 0.1139
2024-06-01 22:16:54 [INFO]: Epoch 014 - training loss: 0.4898, validation loss: 0.1140
2024-06-01 22:16:54 [INFO]: Epoch 015 - training loss: 0.4841, validation loss: 0.1119
2024-06-01 22:16:54 [INFO]: Epoch 016 - training loss: 0.4760, validation loss: 0.1105
2024-06-01 22:16:54 [INFO]: Epoch 017 - training loss: 0.4724, validation loss: 0.0965
2024-06-01 22:16:55 [INFO]: Epoch 018 - training loss: 0.4822, validation loss: 0.0980
2024-06-01 22:16:55 [INFO]: Epoch 019 - training loss: 0.4726, validation loss: 0.1021
2024-06-01 22:16:55 [INFO]: Epoch 020 - training loss: 0.4710, validation loss: 0.0965
2024-06-01 22:16:55 [INFO]: Epoch 021 - training loss: 0.4623, validation loss: 0.0986
2024-06-01 22:16:55 [INFO]: Epoch 022 - training loss: 0.4685, validation loss: 0.0976
2024-06-01 22:16:55 [INFO]: Epoch 023 - training loss: 0.4590, validation loss: 0.0934
2024-06-01 22:16:55 [INFO]: Epoch 024 - training loss: 0.4561, validation loss: 0.0886
2024-06-01 22:16:56 [INFO]: Epoch 025 - training loss: 0.4524, validation loss: 0.0880
2024-06-01 22:16:56 [INFO]: Epoch 026 - training loss: 0.4541, validation loss: 0.0843
2024-06-01 22:16:56 [INFO]: Epoch 027 - training loss: 0.4545, validation loss: 0.0871
2024-06-01 22:16:56 [INFO]: Epoch 028 - training loss: 0.4509, validation loss: 0.0835
2024-06-01 22:16:56 [INFO]: Epoch 029 - training loss: 0.4488, validation loss: 0.0807
2024-06-01 22:16:56 [INFO]: Epoch 030 - training loss: 0.4456, validation loss: 0.0820
2024-06-01 22:16:57 [INFO]: Epoch 031 - training loss: 0.4503, validation loss: 0.0806
2024-06-01 22:16:57 [INFO]: Epoch 032 - training loss: 0.4509, validation loss: 0.0789
2024-06-01 22:16:57 [INFO]: Epoch 033 - training loss: 0.4521, validation loss: 0.0786
2024-06-01 22:16:57 [INFO]: Epoch 034 - training loss: 0.4455, validation loss: 0.0774
2024-06-01 22:16:57 [INFO]: Epoch 035 - training loss: 0.4433, validation loss: 0.0789
2024-06-01 22:16:57 [INFO]: Epoch 036 - training loss: 0.4378, validation loss: 0.0779
2024-06-01 22:16:57 [INFO]: Epoch 037 - training loss: 0.4424, validation loss: 0.0756
2024-06-01 22:16:58 [INFO]: Epoch 038 - training loss: 0.4404, validation loss: 0.0742
2024-06-01 22:16:58 [INFO]: Epoch 039 - training loss: 0.4425, validation loss: 0.0805
2024-06-01 22:16:58 [INFO]: Epoch 040 - training loss: 0.4433, validation loss: 0.0792
2024-06-01 22:16:58 [INFO]: Epoch 041 - training loss: 0.4378, validation loss: 0.0733
2024-06-01 22:16:58 [INFO]: Epoch 042 - training loss: 0.4391, validation loss: 0.0738
2024-06-01 22:16:58 [INFO]: Epoch 043 - training loss: 0.4353, validation loss: 0.0733
2024-06-01 22:16:58 [INFO]: Epoch 044 - training loss: 0.4328, validation loss: 0.0717
2024-06-01 22:16:59 [INFO]: Epoch 045 - training loss: 0.4354, validation loss: 0.0707
2024-06-01 22:16:59 [INFO]: Epoch 046 - training loss: 0.4350, validation loss: 0.0716
2024-06-01 22:16:59 [INFO]: Epoch 047 - training loss: 0.4273, validation loss: 0.0693
2024-06-01 22:16:59 [INFO]: Epoch 048 - training loss: 0.4308, validation loss: 0.0700
2024-06-01 22:16:59 [INFO]: Epoch 049 - training loss: 0.4272, validation loss: 0.0711
2024-06-01 22:16:59 [INFO]: Epoch 050 - training loss: 0.4301, validation loss: 0.0695
2024-06-01 22:16:59 [INFO]: Epoch 051 - training loss: 0.4262, validation loss: 0.0697
2024-06-01 22:17:00 [INFO]: Epoch 052 - training loss: 0.4260, validation loss: 0.0693
2024-06-01 22:17:00 [INFO]: Epoch 053 - training loss: 0.4245, validation loss: 0.0713
2024-06-01 22:17:00 [INFO]: Epoch 054 - training loss: 0.4232, validation loss: 0.0690
2024-06-01 22:17:00 [INFO]: Epoch 055 - training loss: 0.4286, validation loss: 0.0694
2024-06-01 22:17:00 [INFO]: Epoch 056 - training loss: 0.4215, validation loss: 0.0681
2024-06-01 22:17:00 [INFO]: Epoch 057 - training loss: 0.4178, validation loss: 0.0703
2024-06-01 22:17:00 [INFO]: Epoch 058 - training loss: 0.4207, validation loss: 0.0691
2024-06-01 22:17:01 [INFO]: Epoch 059 - training loss: 0.4134, validation loss: 0.0690
2024-06-01 22:17:01 [INFO]: Epoch 060 - training loss: 0.4192, validation loss: 0.0676
2024-06-01 22:17:01 [INFO]: Epoch 061 - training loss: 0.4174, validation loss: 0.0679
2024-06-01 22:17:01 [INFO]: Epoch 062 - training loss: 0.4120, validation loss: 0.0684
2024-06-01 22:17:01 [INFO]: Epoch 063 - training loss: 0.4200, validation loss: 0.0738
2024-06-01 22:17:01 [INFO]: Epoch 064 - training loss: 0.4145, validation loss: 0.0733
2024-06-01 22:17:02 [INFO]: Epoch 065 - training loss: 0.4104, validation loss: 0.0692
2024-06-01 22:17:02 [INFO]: Epoch 066 - training loss: 0.4082, validation loss: 0.0672
2024-06-01 22:17:02 [INFO]: Epoch 067 - training loss: 0.4026, validation loss: 0.0672
2024-06-01 22:17:02 [INFO]: Epoch 068 - training loss: 0.4021, validation loss: 0.0684
2024-06-01 22:17:02 [INFO]: Epoch 069 - training loss: 0.4027, validation loss: 0.0670
2024-06-01 22:17:02 [INFO]: Epoch 070 - training loss: 0.4059, validation loss: 0.0646
2024-06-01 22:17:02 [INFO]: Epoch 071 - training loss: 0.4009, validation loss: 0.0656
2024-06-01 22:17:03 [INFO]: Epoch 072 - training loss: 0.4014, validation loss: 0.0680
2024-06-01 22:17:03 [INFO]: Epoch 073 - training loss: 0.3982, validation loss: 0.0665
2024-06-01 22:17:03 [INFO]: Epoch 074 - training loss: 0.3975, validation loss: 0.0697
2024-06-01 22:17:03 [INFO]: Epoch 075 - training loss: 0.3922, validation loss: 0.0681
2024-06-01 22:17:03 [INFO]: Epoch 076 - training loss: 0.3919, validation loss: 0.0686
2024-06-01 22:17:03 [INFO]: Epoch 077 - training loss: 0.3916, validation loss: 0.0644
2024-06-01 22:17:03 [INFO]: Epoch 078 - training loss: 0.3936, validation loss: 0.0657
2024-06-01 22:17:04 [INFO]: Epoch 079 - training loss: 0.3959, validation loss: 0.0697
2024-06-01 22:17:04 [INFO]: Epoch 080 - training loss: 0.3913, validation loss: 0.0669
2024-06-01 22:17:04 [INFO]: Epoch 081 - training loss: 0.3911, validation loss: 0.0654
2024-06-01 22:17:04 [INFO]: Epoch 082 - training loss: 0.3830, validation loss: 0.0646
2024-06-01 22:17:04 [INFO]: Epoch 083 - training loss: 0.3921, validation loss: 0.0657
2024-06-01 22:17:04 [INFO]: Epoch 084 - training loss: 0.3863, validation loss: 0.0674
2024-06-01 22:17:04 [INFO]: Epoch 085 - training loss: 0.3856, validation loss: 0.0635
2024-06-01 22:17:05 [INFO]: Epoch 086 - training loss: 0.3874, validation loss: 0.0664
2024-06-01 22:17:05 [INFO]: Epoch 087 - training loss: 0.3787, validation loss: 0.0662
2024-06-01 22:17:05 [INFO]: Epoch 088 - training loss: 0.3777, validation loss: 0.0649
2024-06-01 22:17:05 [INFO]: Epoch 089 - training loss: 0.3753, validation loss: 0.0670
2024-06-01 22:17:05 [INFO]: Epoch 090 - training loss: 0.3763, validation loss: 0.0625
2024-06-01 22:17:05 [INFO]: Epoch 091 - training loss: 0.3788, validation loss: 0.0611
2024-06-01 22:17:06 [INFO]: Epoch 092 - training loss: 0.3792, validation loss: 0.0623
2024-06-01 22:17:06 [INFO]: Epoch 093 - training loss: 0.3773, validation loss: 0.0606
2024-06-01 22:17:06 [INFO]: Epoch 094 - training loss: 0.3810, validation loss: 0.0624
2024-06-01 22:17:06 [INFO]: Epoch 095 - training loss: 0.3756, validation loss: 0.0643
2024-06-01 22:17:06 [INFO]: Epoch 096 - training loss: 0.3725, validation loss: 0.0632
2024-06-01 22:17:06 [INFO]: Epoch 097 - training loss: 0.3662, validation loss: 0.0613
2024-06-01 22:17:06 [INFO]: Epoch 098 - training loss: 0.3647, validation loss: 0.0630
2024-06-01 22:17:07 [INFO]: Epoch 099 - training loss: 0.3657, validation loss: 0.0642
2024-06-01 22:17:07 [INFO]: Epoch 100 - training loss: 0.3697, validation loss: 0.0651
2024-06-01 22:17:07 [INFO]: Finished training. The best model is from epoch#93.
2024-06-01 22:17:07 [INFO]: Saved the model to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_3/20240601_T221652/ETSformer.pypots
2024-06-01 22:17:07 [INFO]: Successfully saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:17:07 [INFO]: Round3 - ETSformer on ETT_h1: MAE=0.2183, MSE=0.0971, MRE=0.2577
2024-06-01 22:17:07 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:17:07 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:07 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_4/20240601_T221707
2024-06-01 22:17:07 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_4/20240601_T221707/tensorboard
2024-06-01 22:17:07 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 809,057
2024-06-01 22:17:07 [INFO]: Epoch 001 - training loss: 1.0938, validation loss: 0.4424
2024-06-01 22:17:07 [INFO]: Epoch 002 - training loss: 0.8665, validation loss: 0.3045
2024-06-01 22:17:07 [INFO]: Epoch 003 - training loss: 0.7530, validation loss: 0.2175
2024-06-01 22:17:07 [INFO]: Epoch 004 - training loss: 0.6793, validation loss: 0.1624
2024-06-01 22:17:07 [INFO]: Epoch 005 - training loss: 0.6205, validation loss: 0.1339
2024-06-01 22:17:08 [INFO]: Epoch 006 - training loss: 0.5751, validation loss: 0.1312
2024-06-01 22:17:08 [INFO]: Epoch 007 - training loss: 0.5587, validation loss: 0.1220
2024-06-01 22:17:08 [INFO]: Epoch 008 - training loss: 0.5368, validation loss: 0.1201
2024-06-01 22:17:08 [INFO]: Epoch 009 - training loss: 0.5285, validation loss: 0.1164
2024-06-01 22:17:08 [INFO]: Epoch 010 - training loss: 0.5281, validation loss: 0.1110
2024-06-01 22:17:08 [INFO]: Epoch 011 - training loss: 0.5076, validation loss: 0.1107
2024-06-01 22:17:09 [INFO]: Epoch 012 - training loss: 0.4991, validation loss: 0.1107
2024-06-01 22:17:09 [INFO]: Epoch 013 - training loss: 0.4921, validation loss: 0.0999
2024-06-01 22:17:09 [INFO]: Epoch 014 - training loss: 0.4930, validation loss: 0.0939
2024-06-01 22:17:09 [INFO]: Epoch 015 - training loss: 0.4960, validation loss: 0.0961
2024-06-01 22:17:09 [INFO]: Epoch 016 - training loss: 0.4846, validation loss: 0.1000
2024-06-01 22:17:09 [INFO]: Epoch 017 - training loss: 0.4781, validation loss: 0.1024
2024-06-01 22:17:09 [INFO]: Epoch 018 - training loss: 0.4831, validation loss: 0.0938
2024-06-01 22:17:10 [INFO]: Epoch 019 - training loss: 0.4786, validation loss: 0.0955
2024-06-01 22:17:10 [INFO]: Epoch 020 - training loss: 0.4726, validation loss: 0.0949
2024-06-01 22:17:10 [INFO]: Epoch 021 - training loss: 0.4783, validation loss: 0.0878
2024-06-01 22:17:10 [INFO]: Epoch 022 - training loss: 0.4768, validation loss: 0.0862
2024-06-01 22:17:10 [INFO]: Epoch 023 - training loss: 0.4615, validation loss: 0.0922
2024-06-01 22:17:10 [INFO]: Epoch 024 - training loss: 0.4671, validation loss: 0.0913
2024-06-01 22:17:10 [INFO]: Epoch 025 - training loss: 0.4673, validation loss: 0.0893
2024-06-01 22:17:11 [INFO]: Epoch 026 - training loss: 0.4661, validation loss: 0.0875
2024-06-01 22:17:11 [INFO]: Epoch 027 - training loss: 0.4691, validation loss: 0.0896
2024-06-01 22:17:11 [INFO]: Epoch 028 - training loss: 0.4684, validation loss: 0.0887
2024-06-01 22:17:11 [INFO]: Epoch 029 - training loss: 0.4564, validation loss: 0.0893
2024-06-01 22:17:11 [INFO]: Epoch 030 - training loss: 0.4666, validation loss: 0.0862
2024-06-01 22:17:12 [INFO]: Epoch 031 - training loss: 0.4555, validation loss: 0.0812
2024-06-01 22:17:12 [INFO]: Epoch 032 - training loss: 0.4571, validation loss: 0.0799
2024-06-01 22:17:12 [INFO]: Epoch 033 - training loss: 0.4530, validation loss: 0.0832
2024-06-01 22:17:12 [INFO]: Epoch 034 - training loss: 0.4559, validation loss: 0.0866
2024-06-01 22:17:12 [INFO]: Epoch 035 - training loss: 0.4584, validation loss: 0.0803
2024-06-01 22:17:12 [INFO]: Epoch 036 - training loss: 0.4577, validation loss: 0.0795
2024-06-01 22:17:12 [INFO]: Epoch 037 - training loss: 0.4470, validation loss: 0.0824
2024-06-01 22:17:13 [INFO]: Epoch 038 - training loss: 0.4545, validation loss: 0.0837
2024-06-01 22:17:13 [INFO]: Epoch 039 - training loss: 0.4522, validation loss: 0.0812
2024-06-01 22:17:13 [INFO]: Epoch 040 - training loss: 0.4540, validation loss: 0.0827
2024-06-01 22:17:13 [INFO]: Epoch 041 - training loss: 0.4480, validation loss: 0.0849
2024-06-01 22:17:13 [INFO]: Epoch 042 - training loss: 0.4558, validation loss: 0.0841
2024-06-01 22:17:13 [INFO]: Epoch 043 - training loss: 0.4478, validation loss: 0.0797
2024-06-01 22:17:13 [INFO]: Epoch 044 - training loss: 0.4494, validation loss: 0.0795
2024-06-01 22:17:14 [INFO]: Epoch 045 - training loss: 0.4434, validation loss: 0.0790
2024-06-01 22:17:14 [INFO]: Epoch 046 - training loss: 0.4447, validation loss: 0.0795
2024-06-01 22:17:14 [INFO]: Epoch 047 - training loss: 0.4413, validation loss: 0.0789
2024-06-01 22:17:14 [INFO]: Epoch 048 - training loss: 0.4454, validation loss: 0.0805
2024-06-01 22:17:14 [INFO]: Epoch 049 - training loss: 0.4423, validation loss: 0.0816
2024-06-01 22:17:14 [INFO]: Epoch 050 - training loss: 0.4434, validation loss: 0.0786
2024-06-01 22:17:14 [INFO]: Epoch 051 - training loss: 0.4399, validation loss: 0.0761
2024-06-01 22:17:15 [INFO]: Epoch 052 - training loss: 0.4423, validation loss: 0.0737
2024-06-01 22:17:15 [INFO]: Epoch 053 - training loss: 0.4379, validation loss: 0.0721
2024-06-01 22:17:15 [INFO]: Epoch 054 - training loss: 0.4409, validation loss: 0.0750
2024-06-01 22:17:15 [INFO]: Epoch 055 - training loss: 0.4468, validation loss: 0.0832
2024-06-01 22:17:15 [INFO]: Epoch 056 - training loss: 0.4441, validation loss: 0.0781
2024-06-01 22:17:15 [INFO]: Epoch 057 - training loss: 0.4381, validation loss: 0.0750
2024-06-01 22:17:16 [INFO]: Epoch 058 - training loss: 0.4423, validation loss: 0.0759
2024-06-01 22:17:16 [INFO]: Epoch 059 - training loss: 0.4395, validation loss: 0.0742
2024-06-01 22:17:16 [INFO]: Epoch 060 - training loss: 0.4368, validation loss: 0.0758
2024-06-01 22:17:16 [INFO]: Epoch 061 - training loss: 0.4351, validation loss: 0.0778
2024-06-01 22:17:16 [INFO]: Epoch 062 - training loss: 0.4353, validation loss: 0.0753
2024-06-01 22:17:16 [INFO]: Epoch 063 - training loss: 0.4372, validation loss: 0.0759
2024-06-01 22:17:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:17:16 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:17:16 [INFO]: Saved the model to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_4/20240601_T221707/ETSformer.pypots
2024-06-01 22:17:16 [INFO]: Successfully saved to results_point_rate01/ETT_h1/ETSformer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:17:16 [INFO]: Round4 - ETSformer on ETT_h1: MAE=0.2321, MSE=0.1121, MRE=0.2739
2024-06-01 22:17:16 [INFO]: Done! Final results:
Averaged ETSformer (n params: 809,057) on ETT_h1: MAE=0.2274 ± 0.007194966718939881, MSE=0.1070 ± 0.006809269157686031, MRE=0.2683 ± 0.008490715941309122, average inference time=0.04
