2024-06-01 22:15:34 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:15:34 [INFO]: Using the given device: cuda:0
2024-06-01 22:15:34 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_0/20240601_T221534
2024-06-01 22:15:34 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_0/20240601_T221534/tensorboard
2024-06-01 22:15:35 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-01 22:15:36 [INFO]: Epoch 001 - training loss: 2.5132, validation loss: 1.7329
2024-06-01 22:15:36 [INFO]: Epoch 002 - training loss: 1.5995, validation loss: 0.8117
2024-06-01 22:15:36 [INFO]: Epoch 003 - training loss: 1.1017, validation loss: 0.6196
2024-06-01 22:15:36 [INFO]: Epoch 004 - training loss: 0.8186, validation loss: 0.3147
2024-06-01 22:15:37 [INFO]: Epoch 005 - training loss: 0.6883, validation loss: 0.2723
2024-06-01 22:15:37 [INFO]: Epoch 006 - training loss: 0.6245, validation loss: 0.1965
2024-06-01 22:15:37 [INFO]: Epoch 007 - training loss: 0.5699, validation loss: 0.1545
2024-06-01 22:15:37 [INFO]: Epoch 008 - training loss: 0.5337, validation loss: 0.1407
2024-06-01 22:15:38 [INFO]: Epoch 009 - training loss: 0.5169, validation loss: 0.1337
2024-06-01 22:15:38 [INFO]: Epoch 010 - training loss: 0.4992, validation loss: 0.1502
2024-06-01 22:15:38 [INFO]: Epoch 011 - training loss: 0.4902, validation loss: 0.1299
2024-06-01 22:15:39 [INFO]: Epoch 012 - training loss: 0.4828, validation loss: 0.1742
2024-06-01 22:15:39 [INFO]: Epoch 013 - training loss: 0.4763, validation loss: 0.1070
2024-06-01 22:15:39 [INFO]: Epoch 014 - training loss: 0.4667, validation loss: 0.1200
2024-06-01 22:15:39 [INFO]: Epoch 015 - training loss: 0.4745, validation loss: 0.1160
2024-06-01 22:15:40 [INFO]: Epoch 016 - training loss: 0.4736, validation loss: 0.1268
2024-06-01 22:15:40 [INFO]: Epoch 017 - training loss: 0.4702, validation loss: 0.1133
2024-06-01 22:15:40 [INFO]: Epoch 018 - training loss: 0.4857, validation loss: 0.1107
2024-06-01 22:15:41 [INFO]: Epoch 019 - training loss: 0.4706, validation loss: 0.1185
2024-06-01 22:15:41 [INFO]: Epoch 020 - training loss: 0.4562, validation loss: 0.1426
2024-06-01 22:15:41 [INFO]: Epoch 021 - training loss: 0.4629, validation loss: 0.1302
2024-06-01 22:15:41 [INFO]: Epoch 022 - training loss: 0.4585, validation loss: 0.1394
2024-06-01 22:15:42 [INFO]: Epoch 023 - training loss: 0.4613, validation loss: 0.1096
2024-06-01 22:15:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:15:42 [INFO]: Finished training. The best model is from epoch#13.
2024-06-01 22:15:42 [INFO]: Saved the model to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_0/20240601_T221534/FreTS.pypots
2024-06-01 22:15:42 [INFO]: Successfully saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_0/imputation.pkl
2024-06-01 22:15:42 [INFO]: Round0 - FreTS on ETT_h1: MAE=0.2792, MSE=0.1504, MRE=0.3295
2024-06-01 22:15:42 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:15:42 [INFO]: Using the given device: cuda:0
2024-06-01 22:15:42 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_1/20240601_T221542
2024-06-01 22:15:42 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_1/20240601_T221542/tensorboard
2024-06-01 22:15:42 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-01 22:15:42 [INFO]: Epoch 001 - training loss: 3.1512, validation loss: 2.4271
2024-06-01 22:15:42 [INFO]: Epoch 002 - training loss: 1.8289, validation loss: 1.2466
2024-06-01 22:15:43 [INFO]: Epoch 003 - training loss: 1.3673, validation loss: 0.6609
2024-06-01 22:15:43 [INFO]: Epoch 004 - training loss: 0.9783, validation loss: 0.4648
2024-06-01 22:15:43 [INFO]: Epoch 005 - training loss: 0.7934, validation loss: 0.3557
2024-06-01 22:15:43 [INFO]: Epoch 006 - training loss: 0.6877, validation loss: 0.2437
2024-06-01 22:15:44 [INFO]: Epoch 007 - training loss: 0.5966, validation loss: 0.2097
2024-06-01 22:15:44 [INFO]: Epoch 008 - training loss: 0.5545, validation loss: 0.1619
2024-06-01 22:15:44 [INFO]: Epoch 009 - training loss: 0.5288, validation loss: 0.1472
2024-06-01 22:15:45 [INFO]: Epoch 010 - training loss: 0.5189, validation loss: 0.1523
2024-06-01 22:15:45 [INFO]: Epoch 011 - training loss: 0.4927, validation loss: 0.1323
2024-06-01 22:15:45 [INFO]: Epoch 012 - training loss: 0.4973, validation loss: 0.1128
2024-06-01 22:15:45 [INFO]: Epoch 013 - training loss: 0.4999, validation loss: 0.1313
2024-06-01 22:15:46 [INFO]: Epoch 014 - training loss: 0.4872, validation loss: 0.1542
2024-06-01 22:15:46 [INFO]: Epoch 015 - training loss: 0.4754, validation loss: 0.1175
2024-06-01 22:15:46 [INFO]: Epoch 016 - training loss: 0.4651, validation loss: 0.1197
2024-06-01 22:15:47 [INFO]: Epoch 017 - training loss: 0.4610, validation loss: 0.1047
2024-06-01 22:15:47 [INFO]: Epoch 018 - training loss: 0.4520, validation loss: 0.1198
2024-06-01 22:15:47 [INFO]: Epoch 019 - training loss: 0.4443, validation loss: 0.1396
2024-06-01 22:15:47 [INFO]: Epoch 020 - training loss: 0.4525, validation loss: 0.0986
2024-06-01 22:15:48 [INFO]: Epoch 021 - training loss: 0.4525, validation loss: 0.1000
2024-06-01 22:15:48 [INFO]: Epoch 022 - training loss: 0.4394, validation loss: 0.1268
2024-06-01 22:15:48 [INFO]: Epoch 023 - training loss: 0.4575, validation loss: 0.1261
2024-06-01 22:15:49 [INFO]: Epoch 024 - training loss: 0.4463, validation loss: 0.1393
2024-06-01 22:15:49 [INFO]: Epoch 025 - training loss: 0.4521, validation loss: 0.1048
2024-06-01 22:15:49 [INFO]: Epoch 026 - training loss: 0.4315, validation loss: 0.1125
2024-06-01 22:15:49 [INFO]: Epoch 027 - training loss: 0.4372, validation loss: 0.1250
2024-06-01 22:15:50 [INFO]: Epoch 028 - training loss: 0.4244, validation loss: 0.1213
2024-06-01 22:15:50 [INFO]: Epoch 029 - training loss: 0.4291, validation loss: 0.1180
2024-06-01 22:15:50 [INFO]: Epoch 030 - training loss: 0.4132, validation loss: 0.1184
2024-06-01 22:15:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:15:50 [INFO]: Finished training. The best model is from epoch#20.
2024-06-01 22:15:50 [INFO]: Saved the model to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_1/20240601_T221542/FreTS.pypots
2024-06-01 22:15:50 [INFO]: Successfully saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_1/imputation.pkl
2024-06-01 22:15:50 [INFO]: Round1 - FreTS on ETT_h1: MAE=0.3090, MSE=0.1727, MRE=0.3647
2024-06-01 22:15:50 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:15:50 [INFO]: Using the given device: cuda:0
2024-06-01 22:15:50 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_2/20240601_T221550
2024-06-01 22:15:50 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_2/20240601_T221550/tensorboard
2024-06-01 22:15:50 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-01 22:15:51 [INFO]: Epoch 001 - training loss: 2.4510, validation loss: 1.7364
2024-06-01 22:15:51 [INFO]: Epoch 002 - training loss: 1.5816, validation loss: 1.0035
2024-06-01 22:15:51 [INFO]: Epoch 003 - training loss: 1.1104, validation loss: 0.5501
2024-06-01 22:15:51 [INFO]: Epoch 004 - training loss: 0.8797, validation loss: 0.4133
2024-06-01 22:15:52 [INFO]: Epoch 005 - training loss: 0.7314, validation loss: 0.2944
2024-06-01 22:15:52 [INFO]: Epoch 006 - training loss: 0.6358, validation loss: 0.2036
2024-06-01 22:15:52 [INFO]: Epoch 007 - training loss: 0.5948, validation loss: 0.2274
2024-06-01 22:15:53 [INFO]: Epoch 008 - training loss: 0.5373, validation loss: 0.1983
2024-06-01 22:15:53 [INFO]: Epoch 009 - training loss: 0.5253, validation loss: 0.1870
2024-06-01 22:15:53 [INFO]: Epoch 010 - training loss: 0.5098, validation loss: 0.1537
2024-06-01 22:15:53 [INFO]: Epoch 011 - training loss: 0.4844, validation loss: 0.1782
2024-06-01 22:15:54 [INFO]: Epoch 012 - training loss: 0.4859, validation loss: 0.1497
2024-06-01 22:15:54 [INFO]: Epoch 013 - training loss: 0.4771, validation loss: 0.1343
2024-06-01 22:15:54 [INFO]: Epoch 014 - training loss: 0.4712, validation loss: 0.1287
2024-06-01 22:15:55 [INFO]: Epoch 015 - training loss: 0.4618, validation loss: 0.1201
2024-06-01 22:15:55 [INFO]: Epoch 016 - training loss: 0.4475, validation loss: 0.1439
2024-06-01 22:15:55 [INFO]: Epoch 017 - training loss: 0.4459, validation loss: 0.1404
2024-06-01 22:15:55 [INFO]: Epoch 018 - training loss: 0.4577, validation loss: 0.1538
2024-06-01 22:15:56 [INFO]: Epoch 019 - training loss: 0.4549, validation loss: 0.1389
2024-06-01 22:15:56 [INFO]: Epoch 020 - training loss: 0.4446, validation loss: 0.1319
2024-06-01 22:15:56 [INFO]: Epoch 021 - training loss: 0.4305, validation loss: 0.1200
2024-06-01 22:15:56 [INFO]: Epoch 022 - training loss: 0.4192, validation loss: 0.1300
2024-06-01 22:15:57 [INFO]: Epoch 023 - training loss: 0.4205, validation loss: 0.1171
2024-06-01 22:15:57 [INFO]: Epoch 024 - training loss: 0.4147, validation loss: 0.1156
2024-06-01 22:15:57 [INFO]: Epoch 025 - training loss: 0.4171, validation loss: 0.1274
2024-06-01 22:15:58 [INFO]: Epoch 026 - training loss: 0.4093, validation loss: 0.1046
2024-06-01 22:15:58 [INFO]: Epoch 027 - training loss: 0.4183, validation loss: 0.0995
2024-06-01 22:15:58 [INFO]: Epoch 028 - training loss: 0.4199, validation loss: 0.1117
2024-06-01 22:15:58 [INFO]: Epoch 029 - training loss: 0.4130, validation loss: 0.1456
2024-06-01 22:15:59 [INFO]: Epoch 030 - training loss: 0.4194, validation loss: 0.1007
2024-06-01 22:15:59 [INFO]: Epoch 031 - training loss: 0.4133, validation loss: 0.1065
2024-06-01 22:15:59 [INFO]: Epoch 032 - training loss: 0.4018, validation loss: 0.1022
2024-06-01 22:16:00 [INFO]: Epoch 033 - training loss: 0.4006, validation loss: 0.0974
2024-06-01 22:16:00 [INFO]: Epoch 034 - training loss: 0.3894, validation loss: 0.1314
2024-06-01 22:16:00 [INFO]: Epoch 035 - training loss: 0.3906, validation loss: 0.0992
2024-06-01 22:16:00 [INFO]: Epoch 036 - training loss: 0.3857, validation loss: 0.1105
2024-06-01 22:16:01 [INFO]: Epoch 037 - training loss: 0.3920, validation loss: 0.1011
2024-06-01 22:16:01 [INFO]: Epoch 038 - training loss: 0.3887, validation loss: 0.0948
2024-06-01 22:16:01 [INFO]: Epoch 039 - training loss: 0.4057, validation loss: 0.1142
2024-06-01 22:16:02 [INFO]: Epoch 040 - training loss: 0.4024, validation loss: 0.0947
2024-06-01 22:16:02 [INFO]: Epoch 041 - training loss: 0.3826, validation loss: 0.0872
2024-06-01 22:16:02 [INFO]: Epoch 042 - training loss: 0.3842, validation loss: 0.1055
2024-06-01 22:16:02 [INFO]: Epoch 043 - training loss: 0.3795, validation loss: 0.0963
2024-06-01 22:16:03 [INFO]: Epoch 044 - training loss: 0.3770, validation loss: 0.1084
2024-06-01 22:16:03 [INFO]: Epoch 045 - training loss: 0.3802, validation loss: 0.0873
2024-06-01 22:16:03 [INFO]: Epoch 046 - training loss: 0.3860, validation loss: 0.0911
2024-06-01 22:16:04 [INFO]: Epoch 047 - training loss: 0.3776, validation loss: 0.1124
2024-06-01 22:16:04 [INFO]: Epoch 048 - training loss: 0.3732, validation loss: 0.0963
2024-06-01 22:16:04 [INFO]: Epoch 049 - training loss: 0.3684, validation loss: 0.0812
2024-06-01 22:16:04 [INFO]: Epoch 050 - training loss: 0.3642, validation loss: 0.1054
2024-06-01 22:16:05 [INFO]: Epoch 051 - training loss: 0.3673, validation loss: 0.0929
2024-06-01 22:16:05 [INFO]: Epoch 052 - training loss: 0.3639, validation loss: 0.0985
2024-06-01 22:16:05 [INFO]: Epoch 053 - training loss: 0.3581, validation loss: 0.0904
2024-06-01 22:16:05 [INFO]: Epoch 054 - training loss: 0.3730, validation loss: 0.0949
2024-06-01 22:16:06 [INFO]: Epoch 055 - training loss: 0.3700, validation loss: 0.0908
2024-06-01 22:16:06 [INFO]: Epoch 056 - training loss: 0.3646, validation loss: 0.0851
2024-06-01 22:16:06 [INFO]: Epoch 057 - training loss: 0.3605, validation loss: 0.1031
2024-06-01 22:16:07 [INFO]: Epoch 058 - training loss: 0.3769, validation loss: 0.0880
2024-06-01 22:16:07 [INFO]: Epoch 059 - training loss: 0.3727, validation loss: 0.0907
2024-06-01 22:16:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:07 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:16:07 [INFO]: Saved the model to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_2/20240601_T221550/FreTS.pypots
2024-06-01 22:16:07 [INFO]: Successfully saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_2/imputation.pkl
2024-06-01 22:16:07 [INFO]: Round2 - FreTS on ETT_h1: MAE=0.2514, MSE=0.1141, MRE=0.2967
2024-06-01 22:16:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:16:07 [INFO]: Using the given device: cuda:0
2024-06-01 22:16:07 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_3/20240601_T221607
2024-06-01 22:16:07 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_3/20240601_T221607/tensorboard
2024-06-01 22:16:07 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-01 22:16:07 [INFO]: Epoch 001 - training loss: 2.6317, validation loss: 1.6688
2024-06-01 22:16:07 [INFO]: Epoch 002 - training loss: 1.7345, validation loss: 1.5212
2024-06-01 22:16:08 [INFO]: Epoch 003 - training loss: 1.2262, validation loss: 0.5383
2024-06-01 22:16:08 [INFO]: Epoch 004 - training loss: 0.9225, validation loss: 0.4400
2024-06-01 22:16:08 [INFO]: Epoch 005 - training loss: 0.7345, validation loss: 0.2594
2024-06-01 22:16:09 [INFO]: Epoch 006 - training loss: 0.6508, validation loss: 0.2281
2024-06-01 22:16:09 [INFO]: Epoch 007 - training loss: 0.5825, validation loss: 0.1916
2024-06-01 22:16:09 [INFO]: Epoch 008 - training loss: 0.5410, validation loss: 0.1690
2024-06-01 22:16:09 [INFO]: Epoch 009 - training loss: 0.5050, validation loss: 0.1596
2024-06-01 22:16:10 [INFO]: Epoch 010 - training loss: 0.4923, validation loss: 0.1587
2024-06-01 22:16:10 [INFO]: Epoch 011 - training loss: 0.4766, validation loss: 0.1177
2024-06-01 22:16:10 [INFO]: Epoch 012 - training loss: 0.4669, validation loss: 0.1412
2024-06-01 22:16:11 [INFO]: Epoch 013 - training loss: 0.4746, validation loss: 0.1371
2024-06-01 22:16:11 [INFO]: Epoch 014 - training loss: 0.4683, validation loss: 0.1242
2024-06-01 22:16:11 [INFO]: Epoch 015 - training loss: 0.4474, validation loss: 0.1357
2024-06-01 22:16:11 [INFO]: Epoch 016 - training loss: 0.4485, validation loss: 0.1136
2024-06-01 22:16:12 [INFO]: Epoch 017 - training loss: 0.4375, validation loss: 0.1235
2024-06-01 22:16:12 [INFO]: Epoch 018 - training loss: 0.4368, validation loss: 0.1116
2024-06-01 22:16:12 [INFO]: Epoch 019 - training loss: 0.4406, validation loss: 0.1119
2024-06-01 22:16:13 [INFO]: Epoch 020 - training loss: 0.4334, validation loss: 0.1199
2024-06-01 22:16:13 [INFO]: Epoch 021 - training loss: 0.4300, validation loss: 0.1054
2024-06-01 22:16:13 [INFO]: Epoch 022 - training loss: 0.4306, validation loss: 0.1143
2024-06-01 22:16:13 [INFO]: Epoch 023 - training loss: 0.4224, validation loss: 0.0961
2024-06-01 22:16:14 [INFO]: Epoch 024 - training loss: 0.4288, validation loss: 0.0928
2024-06-01 22:16:14 [INFO]: Epoch 025 - training loss: 0.4146, validation loss: 0.1073
2024-06-01 22:16:14 [INFO]: Epoch 026 - training loss: 0.4213, validation loss: 0.1005
2024-06-01 22:16:15 [INFO]: Epoch 027 - training loss: 0.4111, validation loss: 0.1039
2024-06-01 22:16:15 [INFO]: Epoch 028 - training loss: 0.4109, validation loss: 0.0994
2024-06-01 22:16:15 [INFO]: Epoch 029 - training loss: 0.4190, validation loss: 0.1005
2024-06-01 22:16:15 [INFO]: Epoch 030 - training loss: 0.4075, validation loss: 0.1053
2024-06-01 22:16:16 [INFO]: Epoch 031 - training loss: 0.4019, validation loss: 0.0881
2024-06-01 22:16:16 [INFO]: Epoch 032 - training loss: 0.3971, validation loss: 0.1063
2024-06-01 22:16:16 [INFO]: Epoch 033 - training loss: 0.3957, validation loss: 0.0835
2024-06-01 22:16:17 [INFO]: Epoch 034 - training loss: 0.3933, validation loss: 0.0862
2024-06-01 22:16:17 [INFO]: Epoch 035 - training loss: 0.3868, validation loss: 0.0800
2024-06-01 22:16:17 [INFO]: Epoch 036 - training loss: 0.3861, validation loss: 0.0845
2024-06-01 22:16:17 [INFO]: Epoch 037 - training loss: 0.3883, validation loss: 0.0961
2024-06-01 22:16:18 [INFO]: Epoch 038 - training loss: 0.3944, validation loss: 0.0776
2024-06-01 22:16:18 [INFO]: Epoch 039 - training loss: 0.3846, validation loss: 0.0906
2024-06-01 22:16:18 [INFO]: Epoch 040 - training loss: 0.3753, validation loss: 0.0858
2024-06-01 22:16:19 [INFO]: Epoch 041 - training loss: 0.3824, validation loss: 0.0825
2024-06-01 22:16:19 [INFO]: Epoch 042 - training loss: 0.3836, validation loss: 0.1012
2024-06-01 22:16:19 [INFO]: Epoch 043 - training loss: 0.3898, validation loss: 0.0856
2024-06-01 22:16:19 [INFO]: Epoch 044 - training loss: 0.3929, validation loss: 0.0817
2024-06-01 22:16:20 [INFO]: Epoch 045 - training loss: 0.3863, validation loss: 0.0852
2024-06-01 22:16:20 [INFO]: Epoch 046 - training loss: 0.3739, validation loss: 0.0785
2024-06-01 22:16:20 [INFO]: Epoch 047 - training loss: 0.3801, validation loss: 0.0952
2024-06-01 22:16:21 [INFO]: Epoch 048 - training loss: 0.3712, validation loss: 0.0763
2024-06-01 22:16:21 [INFO]: Epoch 049 - training loss: 0.3681, validation loss: 0.0683
2024-06-01 22:16:21 [INFO]: Epoch 050 - training loss: 0.3671, validation loss: 0.0807
2024-06-01 22:16:21 [INFO]: Epoch 051 - training loss: 0.3790, validation loss: 0.0800
2024-06-01 22:16:22 [INFO]: Epoch 052 - training loss: 0.3791, validation loss: 0.0771
2024-06-01 22:16:22 [INFO]: Epoch 053 - training loss: 0.3658, validation loss: 0.0722
2024-06-01 22:16:22 [INFO]: Epoch 054 - training loss: 0.3611, validation loss: 0.0743
2024-06-01 22:16:23 [INFO]: Epoch 055 - training loss: 0.3621, validation loss: 0.0812
2024-06-01 22:16:23 [INFO]: Epoch 056 - training loss: 0.3671, validation loss: 0.0747
2024-06-01 22:16:23 [INFO]: Epoch 057 - training loss: 0.3646, validation loss: 0.0806
2024-06-01 22:16:23 [INFO]: Epoch 058 - training loss: 0.3598, validation loss: 0.0791
2024-06-01 22:16:24 [INFO]: Epoch 059 - training loss: 0.3573, validation loss: 0.0774
2024-06-01 22:16:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:24 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:16:24 [INFO]: Saved the model to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_3/20240601_T221607/FreTS.pypots
2024-06-01 22:16:24 [INFO]: Successfully saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_3/imputation.pkl
2024-06-01 22:16:24 [INFO]: Round3 - FreTS on ETT_h1: MAE=0.2381, MSE=0.1096, MRE=0.2809
2024-06-01 22:16:24 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:16:24 [INFO]: Using the given device: cuda:0
2024-06-01 22:16:24 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_4/20240601_T221624
2024-06-01 22:16:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_4/20240601_T221624/tensorboard
2024-06-01 22:16:24 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-01 22:16:24 [INFO]: Epoch 001 - training loss: 2.6798, validation loss: 1.5814
2024-06-01 22:16:24 [INFO]: Epoch 002 - training loss: 1.6542, validation loss: 1.4193
2024-06-01 22:16:25 [INFO]: Epoch 003 - training loss: 1.2380, validation loss: 0.9083
2024-06-01 22:16:25 [INFO]: Epoch 004 - training loss: 1.0516, validation loss: 0.5909
2024-06-01 22:16:25 [INFO]: Epoch 005 - training loss: 0.8464, validation loss: 0.4180
2024-06-01 22:16:25 [INFO]: Epoch 006 - training loss: 0.7100, validation loss: 0.2521
2024-06-01 22:16:26 [INFO]: Epoch 007 - training loss: 0.6215, validation loss: 0.2873
2024-06-01 22:16:26 [INFO]: Epoch 008 - training loss: 0.5869, validation loss: 0.1880
2024-06-01 22:16:26 [INFO]: Epoch 009 - training loss: 0.5618, validation loss: 0.1951
2024-06-01 22:16:27 [INFO]: Epoch 010 - training loss: 0.5353, validation loss: 0.1486
2024-06-01 22:16:27 [INFO]: Epoch 011 - training loss: 0.5117, validation loss: 0.1331
2024-06-01 22:16:27 [INFO]: Epoch 012 - training loss: 0.5065, validation loss: 0.1487
2024-06-01 22:16:27 [INFO]: Epoch 013 - training loss: 0.5100, validation loss: 0.1546
2024-06-01 22:16:28 [INFO]: Epoch 014 - training loss: 0.4725, validation loss: 0.1467
2024-06-01 22:16:28 [INFO]: Epoch 015 - training loss: 0.4550, validation loss: 0.1371
2024-06-01 22:16:28 [INFO]: Epoch 016 - training loss: 0.4597, validation loss: 0.1487
2024-06-01 22:16:29 [INFO]: Epoch 017 - training loss: 0.4656, validation loss: 0.1075
2024-06-01 22:16:29 [INFO]: Epoch 018 - training loss: 0.4488, validation loss: 0.1515
2024-06-01 22:16:29 [INFO]: Epoch 019 - training loss: 0.4504, validation loss: 0.1146
2024-06-01 22:16:29 [INFO]: Epoch 020 - training loss: 0.4377, validation loss: 0.1113
2024-06-01 22:16:30 [INFO]: Epoch 021 - training loss: 0.4531, validation loss: 0.1155
2024-06-01 22:16:30 [INFO]: Epoch 022 - training loss: 0.4637, validation loss: 0.1238
2024-06-01 22:16:30 [INFO]: Epoch 023 - training loss: 0.4284, validation loss: 0.1072
2024-06-01 22:16:30 [INFO]: Epoch 024 - training loss: 0.4252, validation loss: 0.1280
2024-06-01 22:16:31 [INFO]: Epoch 025 - training loss: 0.4167, validation loss: 0.0947
2024-06-01 22:16:31 [INFO]: Epoch 026 - training loss: 0.4027, validation loss: 0.0972
2024-06-01 22:16:31 [INFO]: Epoch 027 - training loss: 0.4068, validation loss: 0.0974
2024-06-01 22:16:31 [INFO]: Epoch 028 - training loss: 0.4096, validation loss: 0.1095
2024-06-01 22:16:31 [INFO]: Epoch 029 - training loss: 0.4180, validation loss: 0.0998
2024-06-01 22:16:32 [INFO]: Epoch 030 - training loss: 0.4081, validation loss: 0.1044
2024-06-01 22:16:32 [INFO]: Epoch 031 - training loss: 0.4011, validation loss: 0.0957
2024-06-01 22:16:32 [INFO]: Epoch 032 - training loss: 0.4064, validation loss: 0.1272
2024-06-01 22:16:32 [INFO]: Epoch 033 - training loss: 0.4085, validation loss: 0.0932
2024-06-01 22:16:32 [INFO]: Epoch 034 - training loss: 0.4129, validation loss: 0.0928
2024-06-01 22:16:32 [INFO]: Epoch 035 - training loss: 0.4139, validation loss: 0.0946
2024-06-01 22:16:33 [INFO]: Epoch 036 - training loss: 0.4045, validation loss: 0.0892
2024-06-01 22:16:33 [INFO]: Epoch 037 - training loss: 0.3992, validation loss: 0.0866
2024-06-01 22:16:33 [INFO]: Epoch 038 - training loss: 0.3953, validation loss: 0.0836
2024-06-01 22:16:33 [INFO]: Epoch 039 - training loss: 0.3841, validation loss: 0.0868
2024-06-01 22:16:33 [INFO]: Epoch 040 - training loss: 0.3796, validation loss: 0.0773
2024-06-01 22:16:33 [INFO]: Epoch 041 - training loss: 0.3970, validation loss: 0.0766
2024-06-01 22:16:33 [INFO]: Epoch 042 - training loss: 0.4061, validation loss: 0.0959
2024-06-01 22:16:33 [INFO]: Epoch 043 - training loss: 0.3995, validation loss: 0.0909
2024-06-01 22:16:34 [INFO]: Epoch 044 - training loss: 0.3864, validation loss: 0.0890
2024-06-01 22:16:34 [INFO]: Epoch 045 - training loss: 0.3825, validation loss: 0.0855
2024-06-01 22:16:34 [INFO]: Epoch 046 - training loss: 0.3785, validation loss: 0.0892
2024-06-01 22:16:34 [INFO]: Epoch 047 - training loss: 0.3724, validation loss: 0.0733
2024-06-01 22:16:34 [INFO]: Epoch 048 - training loss: 0.3675, validation loss: 0.0768
2024-06-01 22:16:34 [INFO]: Epoch 049 - training loss: 0.3631, validation loss: 0.0739
2024-06-01 22:16:34 [INFO]: Epoch 050 - training loss: 0.3615, validation loss: 0.0764
2024-06-01 22:16:35 [INFO]: Epoch 051 - training loss: 0.3526, validation loss: 0.0977
2024-06-01 22:16:35 [INFO]: Epoch 052 - training loss: 0.3561, validation loss: 0.0821
2024-06-01 22:16:35 [INFO]: Epoch 053 - training loss: 0.3581, validation loss: 0.0711
2024-06-01 22:16:35 [INFO]: Epoch 054 - training loss: 0.3595, validation loss: 0.0747
2024-06-01 22:16:35 [INFO]: Epoch 055 - training loss: 0.3614, validation loss: 0.0684
2024-06-01 22:16:35 [INFO]: Epoch 056 - training loss: 0.3567, validation loss: 0.0778
2024-06-01 22:16:35 [INFO]: Epoch 057 - training loss: 0.3544, validation loss: 0.0706
2024-06-01 22:16:35 [INFO]: Epoch 058 - training loss: 0.3545, validation loss: 0.0740
2024-06-01 22:16:36 [INFO]: Epoch 059 - training loss: 0.3555, validation loss: 0.0722
2024-06-01 22:16:36 [INFO]: Epoch 060 - training loss: 0.3553, validation loss: 0.0687
2024-06-01 22:16:36 [INFO]: Epoch 061 - training loss: 0.3645, validation loss: 0.0661
2024-06-01 22:16:36 [INFO]: Epoch 062 - training loss: 0.3609, validation loss: 0.0712
2024-06-01 22:16:36 [INFO]: Epoch 063 - training loss: 0.3503, validation loss: 0.0684
2024-06-01 22:16:36 [INFO]: Epoch 064 - training loss: 0.3454, validation loss: 0.0681
2024-06-01 22:16:36 [INFO]: Epoch 065 - training loss: 0.3453, validation loss: 0.0738
2024-06-01 22:16:37 [INFO]: Epoch 066 - training loss: 0.3629, validation loss: 0.0753
2024-06-01 22:16:37 [INFO]: Epoch 067 - training loss: 0.3593, validation loss: 0.0775
2024-06-01 22:16:37 [INFO]: Epoch 068 - training loss: 0.3575, validation loss: 0.0761
2024-06-01 22:16:37 [INFO]: Epoch 069 - training loss: 0.3450, validation loss: 0.0652
2024-06-01 22:16:37 [INFO]: Epoch 070 - training loss: 0.3369, validation loss: 0.0772
2024-06-01 22:16:37 [INFO]: Epoch 071 - training loss: 0.3460, validation loss: 0.0821
2024-06-01 22:16:37 [INFO]: Epoch 072 - training loss: 0.3416, validation loss: 0.0720
2024-06-01 22:16:37 [INFO]: Epoch 073 - training loss: 0.3488, validation loss: 0.0692
2024-06-01 22:16:38 [INFO]: Epoch 074 - training loss: 0.3481, validation loss: 0.0714
2024-06-01 22:16:38 [INFO]: Epoch 075 - training loss: 0.3521, validation loss: 0.0789
2024-06-01 22:16:38 [INFO]: Epoch 076 - training loss: 0.3488, validation loss: 0.0732
2024-06-01 22:16:38 [INFO]: Epoch 077 - training loss: 0.3445, validation loss: 0.0733
2024-06-01 22:16:38 [INFO]: Epoch 078 - training loss: 0.3479, validation loss: 0.0726
2024-06-01 22:16:38 [INFO]: Epoch 079 - training loss: 0.3464, validation loss: 0.0708
2024-06-01 22:16:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:16:38 [INFO]: Finished training. The best model is from epoch#69.
2024-06-01 22:16:38 [INFO]: Saved the model to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_4/20240601_T221624/FreTS.pypots
2024-06-01 22:16:38 [INFO]: Successfully saved to results_point_rate01/ETT_h1/FreTS_ETT_h1/round_4/imputation.pkl
2024-06-01 22:16:38 [INFO]: Round4 - FreTS on ETT_h1: MAE=0.2296, MSE=0.1012, MRE=0.2710
2024-06-01 22:16:38 [INFO]: Done! Final results:
Averaged FreTS (n params: 465,271) on ETT_h1: MAE=0.2615 ± 0.02911742160324504, MSE=0.1296 ± 0.027349590162228925, MRE=0.3086 ± 0.03436120908324629, average inference time=0.02
