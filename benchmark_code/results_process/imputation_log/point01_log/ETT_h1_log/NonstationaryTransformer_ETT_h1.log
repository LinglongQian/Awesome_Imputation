2024-06-01 22:19:19 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:19:19 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:19 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_0/20240601_T221919
2024-06-01 22:19:19 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_0/20240601_T221919/tensorboard
2024-06-01 22:19:19 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 589,927
2024-06-01 22:19:22 [INFO]: Epoch 001 - training loss: 1.0646, validation loss: 0.2939
2024-06-01 22:19:22 [INFO]: Epoch 002 - training loss: 0.7451, validation loss: 0.2390
2024-06-01 22:19:22 [INFO]: Epoch 003 - training loss: 0.6438, validation loss: 0.2199
2024-06-01 22:19:22 [INFO]: Epoch 004 - training loss: 0.6126, validation loss: 0.1883
2024-06-01 22:19:23 [INFO]: Epoch 005 - training loss: 0.5913, validation loss: 0.1734
2024-06-01 22:19:23 [INFO]: Epoch 006 - training loss: 0.5754, validation loss: 0.1782
2024-06-01 22:19:23 [INFO]: Epoch 007 - training loss: 0.5583, validation loss: 0.1770
2024-06-01 22:19:23 [INFO]: Epoch 008 - training loss: 0.5461, validation loss: 0.1770
2024-06-01 22:19:24 [INFO]: Epoch 009 - training loss: 0.5330, validation loss: 0.1810
2024-06-01 22:19:24 [INFO]: Epoch 010 - training loss: 0.5362, validation loss: 0.1663
2024-06-01 22:19:24 [INFO]: Epoch 011 - training loss: 0.5274, validation loss: 0.1877
2024-06-01 22:19:24 [INFO]: Epoch 012 - training loss: 0.5275, validation loss: 0.1859
2024-06-01 22:19:25 [INFO]: Epoch 013 - training loss: 0.5214, validation loss: 0.1572
2024-06-01 22:19:25 [INFO]: Epoch 014 - training loss: 0.5208, validation loss: 0.1670
2024-06-01 22:19:25 [INFO]: Epoch 015 - training loss: 0.5140, validation loss: 0.1632
2024-06-01 22:19:25 [INFO]: Epoch 016 - training loss: 0.5084, validation loss: 0.1609
2024-06-01 22:19:26 [INFO]: Epoch 017 - training loss: 0.5094, validation loss: 0.1619
2024-06-01 22:19:26 [INFO]: Epoch 018 - training loss: 0.5014, validation loss: 0.1576
2024-06-01 22:19:26 [INFO]: Epoch 019 - training loss: 0.4914, validation loss: 0.1445
2024-06-01 22:19:26 [INFO]: Epoch 020 - training loss: 0.4971, validation loss: 0.1504
2024-06-01 22:19:27 [INFO]: Epoch 021 - training loss: 0.4939, validation loss: 0.1755
2024-06-01 22:19:27 [INFO]: Epoch 022 - training loss: 0.4924, validation loss: 0.1733
2024-06-01 22:19:27 [INFO]: Epoch 023 - training loss: 0.4983, validation loss: 0.1673
2024-06-01 22:19:27 [INFO]: Epoch 024 - training loss: 0.4894, validation loss: 0.1545
2024-06-01 22:19:28 [INFO]: Epoch 025 - training loss: 0.4895, validation loss: 0.1615
2024-06-01 22:19:28 [INFO]: Epoch 026 - training loss: 0.4870, validation loss: 0.1852
2024-06-01 22:19:28 [INFO]: Epoch 027 - training loss: 0.4849, validation loss: 0.1493
2024-06-01 22:19:28 [INFO]: Epoch 028 - training loss: 0.4786, validation loss: 0.1682
2024-06-01 22:19:28 [INFO]: Epoch 029 - training loss: 0.4800, validation loss: 0.1672
2024-06-01 22:19:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:28 [INFO]: Finished training. The best model is from epoch#19.
2024-06-01 22:19:28 [INFO]: Saved the model to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_0/20240601_T221919/NonstationaryTransformer.pypots
2024-06-01 22:19:28 [INFO]: Successfully saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:19:28 [INFO]: Round0 - NonstationaryTransformer on ETT_h1: MAE=0.3688, MSE=0.2611, MRE=0.4352
2024-06-01 22:19:28 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:19:28 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:29 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_1/20240601_T221928
2024-06-01 22:19:29 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_1/20240601_T221928/tensorboard
2024-06-01 22:19:29 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 589,927
2024-06-01 22:19:29 [INFO]: Epoch 001 - training loss: 0.9271, validation loss: 0.2823
2024-06-01 22:19:29 [INFO]: Epoch 002 - training loss: 0.7042, validation loss: 0.2015
2024-06-01 22:19:29 [INFO]: Epoch 003 - training loss: 0.6359, validation loss: 0.1774
2024-06-01 22:19:29 [INFO]: Epoch 004 - training loss: 0.6004, validation loss: 0.1571
2024-06-01 22:19:30 [INFO]: Epoch 005 - training loss: 0.5761, validation loss: 0.1659
2024-06-01 22:19:30 [INFO]: Epoch 006 - training loss: 0.5613, validation loss: 0.1720
2024-06-01 22:19:30 [INFO]: Epoch 007 - training loss: 0.5569, validation loss: 0.1609
2024-06-01 22:19:30 [INFO]: Epoch 008 - training loss: 0.5406, validation loss: 0.1637
2024-06-01 22:19:31 [INFO]: Epoch 009 - training loss: 0.5332, validation loss: 0.1503
2024-06-01 22:19:31 [INFO]: Epoch 010 - training loss: 0.5301, validation loss: 0.1681
2024-06-01 22:19:31 [INFO]: Epoch 011 - training loss: 0.5275, validation loss: 0.1549
2024-06-01 22:19:31 [INFO]: Epoch 012 - training loss: 0.5241, validation loss: 0.1520
2024-06-01 22:19:32 [INFO]: Epoch 013 - training loss: 0.5259, validation loss: 0.1464
2024-06-01 22:19:32 [INFO]: Epoch 014 - training loss: 0.5171, validation loss: 0.1683
2024-06-01 22:19:32 [INFO]: Epoch 015 - training loss: 0.5130, validation loss: 0.1637
2024-06-01 22:19:32 [INFO]: Epoch 016 - training loss: 0.5048, validation loss: 0.1483
2024-06-01 22:19:32 [INFO]: Epoch 017 - training loss: 0.5063, validation loss: 0.1535
2024-06-01 22:19:33 [INFO]: Epoch 018 - training loss: 0.5023, validation loss: 0.1522
2024-06-01 22:19:33 [INFO]: Epoch 019 - training loss: 0.5020, validation loss: 0.1543
2024-06-01 22:19:33 [INFO]: Epoch 020 - training loss: 0.4969, validation loss: 0.1633
2024-06-01 22:19:33 [INFO]: Epoch 021 - training loss: 0.4966, validation loss: 0.1657
2024-06-01 22:19:34 [INFO]: Epoch 022 - training loss: 0.5010, validation loss: 0.1685
2024-06-01 22:19:34 [INFO]: Epoch 023 - training loss: 0.4927, validation loss: 0.1419
2024-06-01 22:19:34 [INFO]: Epoch 024 - training loss: 0.4901, validation loss: 0.1513
2024-06-01 22:19:34 [INFO]: Epoch 025 - training loss: 0.4992, validation loss: 0.1690
2024-06-01 22:19:34 [INFO]: Epoch 026 - training loss: 0.4902, validation loss: 0.1599
2024-06-01 22:19:35 [INFO]: Epoch 027 - training loss: 0.4901, validation loss: 0.1670
2024-06-01 22:19:35 [INFO]: Epoch 028 - training loss: 0.4810, validation loss: 0.1677
2024-06-01 22:19:35 [INFO]: Epoch 029 - training loss: 0.4866, validation loss: 0.1778
2024-06-01 22:19:35 [INFO]: Epoch 030 - training loss: 0.4804, validation loss: 0.1345
2024-06-01 22:19:36 [INFO]: Epoch 031 - training loss: 0.4838, validation loss: 0.1734
2024-06-01 22:19:36 [INFO]: Epoch 032 - training loss: 0.4778, validation loss: 0.1451
2024-06-01 22:19:36 [INFO]: Epoch 033 - training loss: 0.4801, validation loss: 0.1530
2024-06-01 22:19:36 [INFO]: Epoch 034 - training loss: 0.4780, validation loss: 0.1719
2024-06-01 22:19:37 [INFO]: Epoch 035 - training loss: 0.4733, validation loss: 0.1578
2024-06-01 22:19:37 [INFO]: Epoch 036 - training loss: 0.4787, validation loss: 0.1692
2024-06-01 22:19:37 [INFO]: Epoch 037 - training loss: 0.4704, validation loss: 0.1752
2024-06-01 22:19:37 [INFO]: Epoch 038 - training loss: 0.4735, validation loss: 0.1634
2024-06-01 22:19:37 [INFO]: Epoch 039 - training loss: 0.4775, validation loss: 0.1605
2024-06-01 22:19:38 [INFO]: Epoch 040 - training loss: 0.4766, validation loss: 0.1787
2024-06-01 22:19:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:38 [INFO]: Finished training. The best model is from epoch#30.
2024-06-01 22:19:38 [INFO]: Saved the model to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_1/20240601_T221928/NonstationaryTransformer.pypots
2024-06-01 22:19:38 [INFO]: Successfully saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:19:38 [INFO]: Round1 - NonstationaryTransformer on ETT_h1: MAE=0.3452, MSE=0.2227, MRE=0.4073
2024-06-01 22:19:38 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:19:38 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:38 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_2/20240601_T221938
2024-06-01 22:19:38 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_2/20240601_T221938/tensorboard
2024-06-01 22:19:38 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 589,927
2024-06-01 22:19:38 [INFO]: Epoch 001 - training loss: 1.1455, validation loss: 0.2426
2024-06-01 22:19:38 [INFO]: Epoch 002 - training loss: 0.7603, validation loss: 0.2816
2024-06-01 22:19:39 [INFO]: Epoch 003 - training loss: 0.6718, validation loss: 0.1977
2024-06-01 22:19:39 [INFO]: Epoch 004 - training loss: 0.6112, validation loss: 0.1697
2024-06-01 22:19:39 [INFO]: Epoch 005 - training loss: 0.5826, validation loss: 0.1740
2024-06-01 22:19:39 [INFO]: Epoch 006 - training loss: 0.5673, validation loss: 0.1890
2024-06-01 22:19:39 [INFO]: Epoch 007 - training loss: 0.5483, validation loss: 0.1736
2024-06-01 22:19:40 [INFO]: Epoch 008 - training loss: 0.5459, validation loss: 0.1783
2024-06-01 22:19:40 [INFO]: Epoch 009 - training loss: 0.5433, validation loss: 0.1714
2024-06-01 22:19:40 [INFO]: Epoch 010 - training loss: 0.5294, validation loss: 0.1784
2024-06-01 22:19:40 [INFO]: Epoch 011 - training loss: 0.5284, validation loss: 0.1716
2024-06-01 22:19:41 [INFO]: Epoch 012 - training loss: 0.5296, validation loss: 0.1571
2024-06-01 22:19:41 [INFO]: Epoch 013 - training loss: 0.5222, validation loss: 0.1690
2024-06-01 22:19:41 [INFO]: Epoch 014 - training loss: 0.5155, validation loss: 0.1713
2024-06-01 22:19:41 [INFO]: Epoch 015 - training loss: 0.5149, validation loss: 0.1690
2024-06-01 22:19:41 [INFO]: Epoch 016 - training loss: 0.5067, validation loss: 0.1733
2024-06-01 22:19:42 [INFO]: Epoch 017 - training loss: 0.5056, validation loss: 0.1692
2024-06-01 22:19:42 [INFO]: Epoch 018 - training loss: 0.5079, validation loss: 0.1625
2024-06-01 22:19:42 [INFO]: Epoch 019 - training loss: 0.4983, validation loss: 0.1750
2024-06-01 22:19:42 [INFO]: Epoch 020 - training loss: 0.4984, validation loss: 0.1648
2024-06-01 22:19:43 [INFO]: Epoch 021 - training loss: 0.4969, validation loss: 0.1590
2024-06-01 22:19:43 [INFO]: Epoch 022 - training loss: 0.4988, validation loss: 0.1719
2024-06-01 22:19:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:43 [INFO]: Finished training. The best model is from epoch#12.
2024-06-01 22:19:43 [INFO]: Saved the model to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_2/20240601_T221938/NonstationaryTransformer.pypots
2024-06-01 22:19:43 [INFO]: Successfully saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:19:43 [INFO]: Round2 - NonstationaryTransformer on ETT_h1: MAE=0.3744, MSE=0.2677, MRE=0.4418
2024-06-01 22:19:43 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:19:43 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:43 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_3/20240601_T221943
2024-06-01 22:19:43 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_3/20240601_T221943/tensorboard
2024-06-01 22:19:43 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 589,927
2024-06-01 22:19:43 [INFO]: Epoch 001 - training loss: 1.1999, validation loss: 0.3958
2024-06-01 22:19:43 [INFO]: Epoch 002 - training loss: 0.7526, validation loss: 0.3358
2024-06-01 22:19:44 [INFO]: Epoch 003 - training loss: 0.6801, validation loss: 0.2262
2024-06-01 22:19:44 [INFO]: Epoch 004 - training loss: 0.6397, validation loss: 0.2173
2024-06-01 22:19:44 [INFO]: Epoch 005 - training loss: 0.5969, validation loss: 0.2418
2024-06-01 22:19:44 [INFO]: Epoch 006 - training loss: 0.5713, validation loss: 0.1786
2024-06-01 22:19:45 [INFO]: Epoch 007 - training loss: 0.5579, validation loss: 0.1812
2024-06-01 22:19:45 [INFO]: Epoch 008 - training loss: 0.5438, validation loss: 0.2111
2024-06-01 22:19:45 [INFO]: Epoch 009 - training loss: 0.5389, validation loss: 0.1896
2024-06-01 22:19:45 [INFO]: Epoch 010 - training loss: 0.5371, validation loss: 0.1809
2024-06-01 22:19:46 [INFO]: Epoch 011 - training loss: 0.5304, validation loss: 0.2159
2024-06-01 22:19:46 [INFO]: Epoch 012 - training loss: 0.5307, validation loss: 0.1779
2024-06-01 22:19:46 [INFO]: Epoch 013 - training loss: 0.5189, validation loss: 0.1697
2024-06-01 22:19:46 [INFO]: Epoch 014 - training loss: 0.5230, validation loss: 0.1798
2024-06-01 22:19:47 [INFO]: Epoch 015 - training loss: 0.5184, validation loss: 0.1852
2024-06-01 22:19:47 [INFO]: Epoch 016 - training loss: 0.5118, validation loss: 0.1703
2024-06-01 22:19:47 [INFO]: Epoch 017 - training loss: 0.5188, validation loss: 0.1687
2024-06-01 22:19:47 [INFO]: Epoch 018 - training loss: 0.5071, validation loss: 0.1729
2024-06-01 22:19:47 [INFO]: Epoch 019 - training loss: 0.5069, validation loss: 0.1713
2024-06-01 22:19:48 [INFO]: Epoch 020 - training loss: 0.5015, validation loss: 0.1607
2024-06-01 22:19:48 [INFO]: Epoch 021 - training loss: 0.5051, validation loss: 0.1741
2024-06-01 22:19:48 [INFO]: Epoch 022 - training loss: 0.5028, validation loss: 0.1875
2024-06-01 22:19:48 [INFO]: Epoch 023 - training loss: 0.4991, validation loss: 0.2066
2024-06-01 22:19:49 [INFO]: Epoch 024 - training loss: 0.4967, validation loss: 0.1581
2024-06-01 22:19:49 [INFO]: Epoch 025 - training loss: 0.4921, validation loss: 0.1632
2024-06-01 22:19:49 [INFO]: Epoch 026 - training loss: 0.4863, validation loss: 0.1678
2024-06-01 22:19:49 [INFO]: Epoch 027 - training loss: 0.4886, validation loss: 0.1717
2024-06-01 22:19:49 [INFO]: Epoch 028 - training loss: 0.4922, validation loss: 0.1676
2024-06-01 22:19:50 [INFO]: Epoch 029 - training loss: 0.4852, validation loss: 0.1689
2024-06-01 22:19:50 [INFO]: Epoch 030 - training loss: 0.4935, validation loss: 0.1656
2024-06-01 22:19:50 [INFO]: Epoch 031 - training loss: 0.4865, validation loss: 0.1845
2024-06-01 22:19:50 [INFO]: Epoch 032 - training loss: 0.4878, validation loss: 0.1926
2024-06-01 22:19:51 [INFO]: Epoch 033 - training loss: 0.4840, validation loss: 0.2036
2024-06-01 22:19:51 [INFO]: Epoch 034 - training loss: 0.4794, validation loss: 0.1827
2024-06-01 22:19:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:51 [INFO]: Finished training. The best model is from epoch#24.
2024-06-01 22:19:51 [INFO]: Saved the model to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_3/20240601_T221943/NonstationaryTransformer.pypots
2024-06-01 22:19:51 [INFO]: Successfully saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:19:51 [INFO]: Round3 - NonstationaryTransformer on ETT_h1: MAE=0.3656, MSE=0.2546, MRE=0.4314
2024-06-01 22:19:51 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:19:51 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:51 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_4/20240601_T221951
2024-06-01 22:19:51 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_4/20240601_T221951/tensorboard
2024-06-01 22:19:51 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 589,927
2024-06-01 22:19:51 [INFO]: Epoch 001 - training loss: 1.0338, validation loss: 0.3527
2024-06-01 22:19:51 [INFO]: Epoch 002 - training loss: 0.7113, validation loss: 0.2203
2024-06-01 22:19:52 [INFO]: Epoch 003 - training loss: 0.6349, validation loss: 0.1905
2024-06-01 22:19:52 [INFO]: Epoch 004 - training loss: 0.6002, validation loss: 0.1842
2024-06-01 22:19:52 [INFO]: Epoch 005 - training loss: 0.5712, validation loss: 0.1632
2024-06-01 22:19:52 [INFO]: Epoch 006 - training loss: 0.5689, validation loss: 0.1741
2024-06-01 22:19:53 [INFO]: Epoch 007 - training loss: 0.5483, validation loss: 0.2022
2024-06-01 22:19:53 [INFO]: Epoch 008 - training loss: 0.5398, validation loss: 0.1644
2024-06-01 22:19:53 [INFO]: Epoch 009 - training loss: 0.5316, validation loss: 0.1683
2024-06-01 22:19:53 [INFO]: Epoch 010 - training loss: 0.5326, validation loss: 0.1755
2024-06-01 22:19:54 [INFO]: Epoch 011 - training loss: 0.5282, validation loss: 0.1680
2024-06-01 22:19:54 [INFO]: Epoch 012 - training loss: 0.5208, validation loss: 0.1678
2024-06-01 22:19:54 [INFO]: Epoch 013 - training loss: 0.5254, validation loss: 0.1540
2024-06-01 22:19:54 [INFO]: Epoch 014 - training loss: 0.5206, validation loss: 0.1505
2024-06-01 22:19:54 [INFO]: Epoch 015 - training loss: 0.5118, validation loss: 0.1618
2024-06-01 22:19:55 [INFO]: Epoch 016 - training loss: 0.5086, validation loss: 0.1647
2024-06-01 22:19:55 [INFO]: Epoch 017 - training loss: 0.5083, validation loss: 0.1521
2024-06-01 22:19:55 [INFO]: Epoch 018 - training loss: 0.5080, validation loss: 0.1571
2024-06-01 22:19:55 [INFO]: Epoch 019 - training loss: 0.5018, validation loss: 0.1580
2024-06-01 22:19:56 [INFO]: Epoch 020 - training loss: 0.4976, validation loss: 0.1468
2024-06-01 22:19:56 [INFO]: Epoch 021 - training loss: 0.4954, validation loss: 0.1451
2024-06-01 22:19:56 [INFO]: Epoch 022 - training loss: 0.4914, validation loss: 0.1480
2024-06-01 22:19:56 [INFO]: Epoch 023 - training loss: 0.4959, validation loss: 0.1554
2024-06-01 22:19:57 [INFO]: Epoch 024 - training loss: 0.4891, validation loss: 0.1594
2024-06-01 22:19:57 [INFO]: Epoch 025 - training loss: 0.4900, validation loss: 0.1747
2024-06-01 22:19:57 [INFO]: Epoch 026 - training loss: 0.4882, validation loss: 0.1775
2024-06-01 22:19:57 [INFO]: Epoch 027 - training loss: 0.4849, validation loss: 0.1804
2024-06-01 22:19:57 [INFO]: Epoch 028 - training loss: 0.4885, validation loss: 0.1722
2024-06-01 22:19:58 [INFO]: Epoch 029 - training loss: 0.4855, validation loss: 0.1612
2024-06-01 22:19:58 [INFO]: Epoch 030 - training loss: 0.4858, validation loss: 0.1802
2024-06-01 22:19:58 [INFO]: Epoch 031 - training loss: 0.4853, validation loss: 0.1635
2024-06-01 22:19:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:58 [INFO]: Finished training. The best model is from epoch#21.
2024-06-01 22:19:58 [INFO]: Saved the model to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_4/20240601_T221951/NonstationaryTransformer.pypots
2024-06-01 22:19:58 [INFO]: Successfully saved to results_point_rate01/ETT_h1/NonstationaryTransformer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:19:58 [INFO]: Round4 - NonstationaryTransformer on ETT_h1: MAE=0.3431, MSE=0.2270, MRE=0.4049
2024-06-01 22:19:58 [INFO]: Done! Final results:
Averaged NonstationaryTransformer (n params: 589,927) on ETT_h1: MAE=0.3594 ± 0.012806261391121483, MSE=0.2466 ± 0.018306646135511657, MRE=0.4241 ± 0.01511255464961873, average inference time=0.02
