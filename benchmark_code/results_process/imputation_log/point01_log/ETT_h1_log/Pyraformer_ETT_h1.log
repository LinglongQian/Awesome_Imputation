2024-06-01 22:22:12 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:22:12 [INFO]: Using the given device: cuda:0
2024-06-01 22:22:12 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_0/20240601_T222212
2024-06-01 22:22:12 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_0/20240601_T222212/tensorboard
2024-06-01 22:22:14 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-01 22:22:17 [INFO]: Epoch 001 - training loss: 1.9785, validation loss: 0.3440
2024-06-01 22:22:18 [INFO]: Epoch 002 - training loss: 1.0160, validation loss: 0.3438
2024-06-01 22:22:20 [INFO]: Epoch 003 - training loss: 0.7587, validation loss: 0.1794
2024-06-01 22:22:21 [INFO]: Epoch 004 - training loss: 0.6484, validation loss: 0.2008
2024-06-01 22:22:22 [INFO]: Epoch 005 - training loss: 0.6291, validation loss: 0.1754
2024-06-01 22:22:24 [INFO]: Epoch 006 - training loss: 0.6129, validation loss: 0.1264
2024-06-01 22:22:25 [INFO]: Epoch 007 - training loss: 0.6258, validation loss: 0.2027
2024-06-01 22:22:26 [INFO]: Epoch 008 - training loss: 0.5916, validation loss: 0.1616
2024-06-01 22:22:28 [INFO]: Epoch 009 - training loss: 0.5582, validation loss: 0.1309
2024-06-01 22:22:29 [INFO]: Epoch 010 - training loss: 0.5240, validation loss: 0.1446
2024-06-01 22:22:31 [INFO]: Epoch 011 - training loss: 0.5165, validation loss: 0.1195
2024-06-01 22:22:32 [INFO]: Epoch 012 - training loss: 0.5156, validation loss: 0.1112
2024-06-01 22:22:33 [INFO]: Epoch 013 - training loss: 0.4926, validation loss: 0.1391
2024-06-01 22:22:35 [INFO]: Epoch 014 - training loss: 0.4914, validation loss: 0.1129
2024-06-01 22:22:36 [INFO]: Epoch 015 - training loss: 0.4762, validation loss: 0.1049
2024-06-01 22:22:37 [INFO]: Epoch 016 - training loss: 0.4705, validation loss: 0.1215
2024-06-01 22:22:39 [INFO]: Epoch 017 - training loss: 0.4700, validation loss: 0.0978
2024-06-01 22:22:40 [INFO]: Epoch 018 - training loss: 0.4417, validation loss: 0.0930
2024-06-01 22:22:41 [INFO]: Epoch 019 - training loss: 0.4359, validation loss: 0.1027
2024-06-01 22:22:43 [INFO]: Epoch 020 - training loss: 0.4241, validation loss: 0.0872
2024-06-01 22:22:44 [INFO]: Epoch 021 - training loss: 0.4145, validation loss: 0.0848
2024-06-01 22:22:45 [INFO]: Epoch 022 - training loss: 0.3948, validation loss: 0.0800
2024-06-01 22:22:47 [INFO]: Epoch 023 - training loss: 0.4204, validation loss: 0.0889
2024-06-01 22:22:48 [INFO]: Epoch 024 - training loss: 0.4195, validation loss: 0.0998
2024-06-01 22:22:49 [INFO]: Epoch 025 - training loss: 0.4077, validation loss: 0.0865
2024-06-01 22:22:50 [INFO]: Epoch 026 - training loss: 0.3882, validation loss: 0.0755
2024-06-01 22:22:52 [INFO]: Epoch 027 - training loss: 0.3920, validation loss: 0.0721
2024-06-01 22:22:53 [INFO]: Epoch 028 - training loss: 0.3805, validation loss: 0.0940
2024-06-01 22:22:54 [INFO]: Epoch 029 - training loss: 0.3658, validation loss: 0.0641
2024-06-01 22:22:55 [INFO]: Epoch 030 - training loss: 0.3548, validation loss: 0.0655
2024-06-01 22:22:57 [INFO]: Epoch 031 - training loss: 0.3414, validation loss: 0.0748
2024-06-01 22:22:58 [INFO]: Epoch 032 - training loss: 0.3412, validation loss: 0.0656
2024-06-01 22:22:59 [INFO]: Epoch 033 - training loss: 0.3395, validation loss: 0.0640
2024-06-01 22:23:01 [INFO]: Epoch 034 - training loss: 0.3359, validation loss: 0.0564
2024-06-01 22:23:02 [INFO]: Epoch 035 - training loss: 0.3398, validation loss: 0.0646
2024-06-01 22:23:03 [INFO]: Epoch 036 - training loss: 0.3269, validation loss: 0.0570
2024-06-01 22:23:04 [INFO]: Epoch 037 - training loss: 0.3190, validation loss: 0.0618
2024-06-01 22:23:06 [INFO]: Epoch 038 - training loss: 0.3071, validation loss: 0.0556
2024-06-01 22:23:07 [INFO]: Epoch 039 - training loss: 0.3023, validation loss: 0.0718
2024-06-01 22:23:09 [INFO]: Epoch 040 - training loss: 0.3108, validation loss: 0.0623
2024-06-01 22:23:10 [INFO]: Epoch 041 - training loss: 0.2949, validation loss: 0.0557
2024-06-01 22:23:11 [INFO]: Epoch 042 - training loss: 0.3002, validation loss: 0.0554
2024-06-01 22:23:13 [INFO]: Epoch 043 - training loss: 0.2998, validation loss: 0.0490
2024-06-01 22:23:14 [INFO]: Epoch 044 - training loss: 0.2994, validation loss: 0.0534
2024-06-01 22:23:16 [INFO]: Epoch 045 - training loss: 0.3018, validation loss: 0.0521
2024-06-01 22:23:17 [INFO]: Epoch 046 - training loss: 0.3143, validation loss: 0.0478
2024-06-01 22:23:18 [INFO]: Epoch 047 - training loss: 0.3088, validation loss: 0.0485
2024-06-01 22:23:20 [INFO]: Epoch 048 - training loss: 0.2888, validation loss: 0.0537
2024-06-01 22:23:21 [INFO]: Epoch 049 - training loss: 0.2847, validation loss: 0.0548
2024-06-01 22:23:22 [INFO]: Epoch 050 - training loss: 0.2753, validation loss: 0.0503
2024-06-01 22:23:24 [INFO]: Epoch 051 - training loss: 0.2750, validation loss: 0.0458
2024-06-01 22:23:25 [INFO]: Epoch 052 - training loss: 0.2818, validation loss: 0.0454
2024-06-01 22:23:26 [INFO]: Epoch 053 - training loss: 0.2626, validation loss: 0.0437
2024-06-01 22:23:27 [INFO]: Epoch 054 - training loss: 0.2650, validation loss: 0.0445
2024-06-01 22:23:29 [INFO]: Epoch 055 - training loss: 0.2794, validation loss: 0.0461
2024-06-01 22:23:30 [INFO]: Epoch 056 - training loss: 0.3029, validation loss: 0.0546
2024-06-01 22:23:31 [INFO]: Epoch 057 - training loss: 0.2909, validation loss: 0.0514
2024-06-01 22:23:33 [INFO]: Epoch 058 - training loss: 0.2769, validation loss: 0.0485
2024-06-01 22:23:34 [INFO]: Epoch 059 - training loss: 0.2866, validation loss: 0.0441
2024-06-01 22:23:35 [INFO]: Epoch 060 - training loss: 0.2934, validation loss: 0.0545
2024-06-01 22:23:36 [INFO]: Epoch 061 - training loss: 0.3025, validation loss: 0.0538
2024-06-01 22:23:38 [INFO]: Epoch 062 - training loss: 0.2933, validation loss: 0.0515
2024-06-01 22:23:39 [INFO]: Epoch 063 - training loss: 0.2877, validation loss: 0.0522
2024-06-01 22:23:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:23:39 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:23:39 [INFO]: Saved the model to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_0/20240601_T222212/Pyraformer.pypots
2024-06-01 22:23:39 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:23:39 [INFO]: Round0 - Pyraformer on ETT_h1: MAE=0.1812, MSE=0.0669, MRE=0.2138
2024-06-01 22:23:39 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:23:39 [INFO]: Using the given device: cuda:0
2024-06-01 22:23:39 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_1/20240601_T222339
2024-06-01 22:23:39 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_1/20240601_T222339/tensorboard
2024-06-01 22:23:40 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-01 22:23:41 [INFO]: Epoch 001 - training loss: 1.9534, validation loss: 0.4188
2024-06-01 22:23:43 [INFO]: Epoch 002 - training loss: 0.9568, validation loss: 0.2834
2024-06-01 22:23:44 [INFO]: Epoch 003 - training loss: 0.8269, validation loss: 0.2491
2024-06-01 22:23:45 [INFO]: Epoch 004 - training loss: 0.6986, validation loss: 0.1558
2024-06-01 22:23:47 [INFO]: Epoch 005 - training loss: 0.5932, validation loss: 0.1477
2024-06-01 22:23:48 [INFO]: Epoch 006 - training loss: 0.6201, validation loss: 0.1503
2024-06-01 22:23:49 [INFO]: Epoch 007 - training loss: 0.6033, validation loss: 0.1307
2024-06-01 22:23:50 [INFO]: Epoch 008 - training loss: 0.5625, validation loss: 0.1201
2024-06-01 22:23:51 [INFO]: Epoch 009 - training loss: 0.5180, validation loss: 0.1116
2024-06-01 22:23:52 [INFO]: Epoch 010 - training loss: 0.5079, validation loss: 0.1150
2024-06-01 22:23:54 [INFO]: Epoch 011 - training loss: 0.4940, validation loss: 0.1032
2024-06-01 22:23:55 [INFO]: Epoch 012 - training loss: 0.4827, validation loss: 0.1059
2024-06-01 22:23:57 [INFO]: Epoch 013 - training loss: 0.5153, validation loss: 0.1078
2024-06-01 22:23:58 [INFO]: Epoch 014 - training loss: 0.5031, validation loss: 0.1132
2024-06-01 22:23:59 [INFO]: Epoch 015 - training loss: 0.4962, validation loss: 0.1020
2024-06-01 22:24:01 [INFO]: Epoch 016 - training loss: 0.4836, validation loss: 0.1091
2024-06-01 22:24:02 [INFO]: Epoch 017 - training loss: 0.4697, validation loss: 0.0884
2024-06-01 22:24:03 [INFO]: Epoch 018 - training loss: 0.4391, validation loss: 0.0955
2024-06-01 22:24:04 [INFO]: Epoch 019 - training loss: 0.4242, validation loss: 0.1020
2024-06-01 22:24:06 [INFO]: Epoch 020 - training loss: 0.4467, validation loss: 0.0981
2024-06-01 22:24:07 [INFO]: Epoch 021 - training loss: 0.4392, validation loss: 0.0881
2024-06-01 22:24:08 [INFO]: Epoch 022 - training loss: 0.4032, validation loss: 0.0772
2024-06-01 22:24:10 [INFO]: Epoch 023 - training loss: 0.3847, validation loss: 0.0742
2024-06-01 22:24:11 [INFO]: Epoch 024 - training loss: 0.3753, validation loss: 0.0857
2024-06-01 22:24:12 [INFO]: Epoch 025 - training loss: 0.3596, validation loss: 0.0664
2024-06-01 22:24:14 [INFO]: Epoch 026 - training loss: 0.3790, validation loss: 0.0753
2024-06-01 22:24:15 [INFO]: Epoch 027 - training loss: 0.3740, validation loss: 0.0701
2024-06-01 22:24:16 [INFO]: Epoch 028 - training loss: 0.3557, validation loss: 0.0737
2024-06-01 22:24:17 [INFO]: Epoch 029 - training loss: 0.3607, validation loss: 0.0744
2024-06-01 22:24:19 [INFO]: Epoch 030 - training loss: 0.3399, validation loss: 0.0793
2024-06-01 22:24:20 [INFO]: Epoch 031 - training loss: 0.3376, validation loss: 0.0658
2024-06-01 22:24:22 [INFO]: Epoch 032 - training loss: 0.3453, validation loss: 0.0742
2024-06-01 22:24:23 [INFO]: Epoch 033 - training loss: 0.3511, validation loss: 0.0575
2024-06-01 22:24:24 [INFO]: Epoch 034 - training loss: 0.3293, validation loss: 0.0674
2024-06-01 22:24:26 [INFO]: Epoch 035 - training loss: 0.3334, validation loss: 0.0728
2024-06-01 22:24:27 [INFO]: Epoch 036 - training loss: 0.3343, validation loss: 0.0591
2024-06-01 22:24:28 [INFO]: Epoch 037 - training loss: 0.3303, validation loss: 0.0601
2024-06-01 22:24:30 [INFO]: Epoch 038 - training loss: 0.3340, validation loss: 0.0595
2024-06-01 22:24:31 [INFO]: Epoch 039 - training loss: 0.3174, validation loss: 0.0592
2024-06-01 22:24:33 [INFO]: Epoch 040 - training loss: 0.3355, validation loss: 0.0560
2024-06-01 22:24:34 [INFO]: Epoch 041 - training loss: 0.3196, validation loss: 0.0634
2024-06-01 22:24:35 [INFO]: Epoch 042 - training loss: 0.3209, validation loss: 0.0584
2024-06-01 22:24:37 [INFO]: Epoch 043 - training loss: 0.3109, validation loss: 0.0615
2024-06-01 22:24:38 [INFO]: Epoch 044 - training loss: 0.3086, validation loss: 0.0574
2024-06-01 22:24:39 [INFO]: Epoch 045 - training loss: 0.3023, validation loss: 0.0576
2024-06-01 22:24:41 [INFO]: Epoch 046 - training loss: 0.3079, validation loss: 0.0540
2024-06-01 22:24:42 [INFO]: Epoch 047 - training loss: 0.2897, validation loss: 0.0565
2024-06-01 22:24:43 [INFO]: Epoch 048 - training loss: 0.2902, validation loss: 0.0615
2024-06-01 22:24:45 [INFO]: Epoch 049 - training loss: 0.2942, validation loss: 0.0498
2024-06-01 22:24:46 [INFO]: Epoch 050 - training loss: 0.2919, validation loss: 0.0539
2024-06-01 22:24:47 [INFO]: Epoch 051 - training loss: 0.2805, validation loss: 0.0539
2024-06-01 22:24:49 [INFO]: Epoch 052 - training loss: 0.2934, validation loss: 0.0562
2024-06-01 22:24:50 [INFO]: Epoch 053 - training loss: 0.2865, validation loss: 0.0598
2024-06-01 22:24:51 [INFO]: Epoch 054 - training loss: 0.2952, validation loss: 0.0493
2024-06-01 22:24:52 [INFO]: Epoch 055 - training loss: 0.2851, validation loss: 0.0482
2024-06-01 22:24:54 [INFO]: Epoch 056 - training loss: 0.2803, validation loss: 0.0506
2024-06-01 22:24:55 [INFO]: Epoch 057 - training loss: 0.2997, validation loss: 0.0579
2024-06-01 22:24:56 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.0605
2024-06-01 22:24:57 [INFO]: Epoch 059 - training loss: 0.2831, validation loss: 0.0533
2024-06-01 22:24:59 [INFO]: Epoch 060 - training loss: 0.2698, validation loss: 0.0480
2024-06-01 22:25:00 [INFO]: Epoch 061 - training loss: 0.2640, validation loss: 0.0417
2024-06-01 22:25:01 [INFO]: Epoch 062 - training loss: 0.2714, validation loss: 0.0487
2024-06-01 22:25:02 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.0455
2024-06-01 22:25:04 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.0464
2024-06-01 22:25:05 [INFO]: Epoch 065 - training loss: 0.2689, validation loss: 0.0461
2024-06-01 22:25:06 [INFO]: Epoch 066 - training loss: 0.2673, validation loss: 0.0542
2024-06-01 22:25:07 [INFO]: Epoch 067 - training loss: 0.2704, validation loss: 0.0427
2024-06-01 22:25:08 [INFO]: Epoch 068 - training loss: 0.2630, validation loss: 0.0429
2024-06-01 22:25:09 [INFO]: Epoch 069 - training loss: 0.2624, validation loss: 0.0465
2024-06-01 22:25:11 [INFO]: Epoch 070 - training loss: 0.2677, validation loss: 0.0515
2024-06-01 22:25:12 [INFO]: Epoch 071 - training loss: 0.2723, validation loss: 0.0535
2024-06-01 22:25:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:25:12 [INFO]: Finished training. The best model is from epoch#61.
2024-06-01 22:25:12 [INFO]: Saved the model to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_1/20240601_T222339/Pyraformer.pypots
2024-06-01 22:25:12 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:25:12 [INFO]: Round1 - Pyraformer on ETT_h1: MAE=0.1983, MSE=0.0790, MRE=0.2340
2024-06-01 22:25:12 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:25:12 [INFO]: Using the given device: cuda:0
2024-06-01 22:25:12 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_2/20240601_T222512
2024-06-01 22:25:12 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_2/20240601_T222512/tensorboard
2024-06-01 22:25:13 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-01 22:25:14 [INFO]: Epoch 001 - training loss: 2.0231, validation loss: 0.6579
2024-06-01 22:25:16 [INFO]: Epoch 002 - training loss: 1.1255, validation loss: 0.3916
2024-06-01 22:25:17 [INFO]: Epoch 003 - training loss: 0.8146, validation loss: 0.2592
2024-06-01 22:25:18 [INFO]: Epoch 004 - training loss: 0.7590, validation loss: 0.1812
2024-06-01 22:25:19 [INFO]: Epoch 005 - training loss: 0.6333, validation loss: 0.1554
2024-06-01 22:25:20 [INFO]: Epoch 006 - training loss: 0.5802, validation loss: 0.1419
2024-06-01 22:25:22 [INFO]: Epoch 007 - training loss: 0.5550, validation loss: 0.1278
2024-06-01 22:25:22 [INFO]: Epoch 008 - training loss: 0.5299, validation loss: 0.1106
2024-06-01 22:25:24 [INFO]: Epoch 009 - training loss: 0.4896, validation loss: 0.1102
2024-06-01 22:25:25 [INFO]: Epoch 010 - training loss: 0.4794, validation loss: 0.1246
2024-06-01 22:25:26 [INFO]: Epoch 011 - training loss: 0.4977, validation loss: 0.1080
2024-06-01 22:25:27 [INFO]: Epoch 012 - training loss: 0.4901, validation loss: 0.1025
2024-06-01 22:25:28 [INFO]: Epoch 013 - training loss: 0.5068, validation loss: 0.1351
2024-06-01 22:25:29 [INFO]: Epoch 014 - training loss: 0.4810, validation loss: 0.1056
2024-06-01 22:25:30 [INFO]: Epoch 015 - training loss: 0.4534, validation loss: 0.0971
2024-06-01 22:25:31 [INFO]: Epoch 016 - training loss: 0.4650, validation loss: 0.0833
2024-06-01 22:25:32 [INFO]: Epoch 017 - training loss: 0.4291, validation loss: 0.0885
2024-06-01 22:25:33 [INFO]: Epoch 018 - training loss: 0.4590, validation loss: 0.0878
2024-06-01 22:25:34 [INFO]: Epoch 019 - training loss: 0.4140, validation loss: 0.0772
2024-06-01 22:25:35 [INFO]: Epoch 020 - training loss: 0.4036, validation loss: 0.0882
2024-06-01 22:25:36 [INFO]: Epoch 021 - training loss: 0.4367, validation loss: 0.0763
2024-06-01 22:25:37 [INFO]: Epoch 022 - training loss: 0.3922, validation loss: 0.0874
2024-06-01 22:25:38 [INFO]: Epoch 023 - training loss: 0.3900, validation loss: 0.0843
2024-06-01 22:25:39 [INFO]: Epoch 024 - training loss: 0.3957, validation loss: 0.0823
2024-06-01 22:25:40 [INFO]: Epoch 025 - training loss: 0.3932, validation loss: 0.0726
2024-06-01 22:25:41 [INFO]: Epoch 026 - training loss: 0.3901, validation loss: 0.0775
2024-06-01 22:25:42 [INFO]: Epoch 027 - training loss: 0.3692, validation loss: 0.0749
2024-06-01 22:25:43 [INFO]: Epoch 028 - training loss: 0.3677, validation loss: 0.0694
2024-06-01 22:25:44 [INFO]: Epoch 029 - training loss: 0.3587, validation loss: 0.0686
2024-06-01 22:25:45 [INFO]: Epoch 030 - training loss: 0.3452, validation loss: 0.0784
2024-06-01 22:25:46 [INFO]: Epoch 031 - training loss: 0.3460, validation loss: 0.0598
2024-06-01 22:25:47 [INFO]: Epoch 032 - training loss: 0.3358, validation loss: 0.0647
2024-06-01 22:25:49 [INFO]: Epoch 033 - training loss: 0.3312, validation loss: 0.0622
2024-06-01 22:25:50 [INFO]: Epoch 034 - training loss: 0.3282, validation loss: 0.0617
2024-06-01 22:25:51 [INFO]: Epoch 035 - training loss: 0.3299, validation loss: 0.0677
2024-06-01 22:25:52 [INFO]: Epoch 036 - training loss: 0.3297, validation loss: 0.0609
2024-06-01 22:25:53 [INFO]: Epoch 037 - training loss: 0.3253, validation loss: 0.0614
2024-06-01 22:25:54 [INFO]: Epoch 038 - training loss: 0.3171, validation loss: 0.0549
2024-06-01 22:25:55 [INFO]: Epoch 039 - training loss: 0.3040, validation loss: 0.0563
2024-06-01 22:25:56 [INFO]: Epoch 040 - training loss: 0.3079, validation loss: 0.0646
2024-06-01 22:25:57 [INFO]: Epoch 041 - training loss: 0.3370, validation loss: 0.0611
2024-06-01 22:25:58 [INFO]: Epoch 042 - training loss: 0.3207, validation loss: 0.0545
2024-06-01 22:25:59 [INFO]: Epoch 043 - training loss: 0.3150, validation loss: 0.0593
2024-06-01 22:26:01 [INFO]: Epoch 044 - training loss: 0.3010, validation loss: 0.0588
2024-06-01 22:26:01 [INFO]: Epoch 045 - training loss: 0.3058, validation loss: 0.0596
2024-06-01 22:26:02 [INFO]: Epoch 046 - training loss: 0.3085, validation loss: 0.0529
2024-06-01 22:26:04 [INFO]: Epoch 047 - training loss: 0.2995, validation loss: 0.0649
2024-06-01 22:26:05 [INFO]: Epoch 048 - training loss: 0.2967, validation loss: 0.0514
2024-06-01 22:26:06 [INFO]: Epoch 049 - training loss: 0.2877, validation loss: 0.0563
2024-06-01 22:26:07 [INFO]: Epoch 050 - training loss: 0.3110, validation loss: 0.0560
2024-06-01 22:26:08 [INFO]: Epoch 051 - training loss: 0.3087, validation loss: 0.0597
2024-06-01 22:26:09 [INFO]: Epoch 052 - training loss: 0.2973, validation loss: 0.0496
2024-06-01 22:26:10 [INFO]: Epoch 053 - training loss: 0.2794, validation loss: 0.0555
2024-06-01 22:26:11 [INFO]: Epoch 054 - training loss: 0.2866, validation loss: 0.0553
2024-06-01 22:26:12 [INFO]: Epoch 055 - training loss: 0.2930, validation loss: 0.0510
2024-06-01 22:26:13 [INFO]: Epoch 056 - training loss: 0.3124, validation loss: 0.0590
2024-06-01 22:26:14 [INFO]: Epoch 057 - training loss: 0.3234, validation loss: 0.0544
2024-06-01 22:26:15 [INFO]: Epoch 058 - training loss: 0.2957, validation loss: 0.0666
2024-06-01 22:26:16 [INFO]: Epoch 059 - training loss: 0.2839, validation loss: 0.0532
2024-06-01 22:26:17 [INFO]: Epoch 060 - training loss: 0.2699, validation loss: 0.0450
2024-06-01 22:26:18 [INFO]: Epoch 061 - training loss: 0.2676, validation loss: 0.0491
2024-06-01 22:26:19 [INFO]: Epoch 062 - training loss: 0.2781, validation loss: 0.0597
2024-06-01 22:26:20 [INFO]: Epoch 063 - training loss: 0.3296, validation loss: 0.0909
2024-06-01 22:26:21 [INFO]: Epoch 064 - training loss: 0.3023, validation loss: 0.0669
2024-06-01 22:26:22 [INFO]: Epoch 065 - training loss: 0.2989, validation loss: 0.0647
2024-06-01 22:26:23 [INFO]: Epoch 066 - training loss: 0.2694, validation loss: 0.0512
2024-06-01 22:26:24 [INFO]: Epoch 067 - training loss: 0.2684, validation loss: 0.0463
2024-06-01 22:26:25 [INFO]: Epoch 068 - training loss: 0.2617, validation loss: 0.0570
2024-06-01 22:26:25 [INFO]: Epoch 069 - training loss: 0.2521, validation loss: 0.0538
2024-06-01 22:26:27 [INFO]: Epoch 070 - training loss: 0.2570, validation loss: 0.0471
2024-06-01 22:26:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:26:27 [INFO]: Finished training. The best model is from epoch#60.
2024-06-01 22:26:27 [INFO]: Saved the model to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_2/20240601_T222512/Pyraformer.pypots
2024-06-01 22:26:27 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:26:27 [INFO]: Round2 - Pyraformer on ETT_h1: MAE=0.1755, MSE=0.0693, MRE=0.2071
2024-06-01 22:26:27 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:26:27 [INFO]: Using the given device: cuda:0
2024-06-01 22:26:27 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_3/20240601_T222627
2024-06-01 22:26:27 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_3/20240601_T222627/tensorboard
2024-06-01 22:26:27 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-01 22:26:28 [INFO]: Epoch 001 - training loss: 1.9004, validation loss: 0.3937
2024-06-01 22:26:29 [INFO]: Epoch 002 - training loss: 0.9195, validation loss: 0.2026
2024-06-01 22:26:30 [INFO]: Epoch 003 - training loss: 0.7887, validation loss: 0.2619
2024-06-01 22:26:31 [INFO]: Epoch 004 - training loss: 0.7303, validation loss: 0.1791
2024-06-01 22:26:32 [INFO]: Epoch 005 - training loss: 0.6162, validation loss: 0.1349
2024-06-01 22:26:33 [INFO]: Epoch 006 - training loss: 0.6057, validation loss: 0.1197
2024-06-01 22:26:34 [INFO]: Epoch 007 - training loss: 0.5370, validation loss: 0.1161
2024-06-01 22:26:35 [INFO]: Epoch 008 - training loss: 0.5305, validation loss: 0.1449
2024-06-01 22:26:36 [INFO]: Epoch 009 - training loss: 0.5567, validation loss: 0.0986
2024-06-01 22:26:37 [INFO]: Epoch 010 - training loss: 0.4967, validation loss: 0.1230
2024-06-01 22:26:38 [INFO]: Epoch 011 - training loss: 0.4787, validation loss: 0.1064
2024-06-01 22:26:40 [INFO]: Epoch 012 - training loss: 0.4683, validation loss: 0.1017
2024-06-01 22:26:40 [INFO]: Epoch 013 - training loss: 0.4504, validation loss: 0.0998
2024-06-01 22:26:41 [INFO]: Epoch 014 - training loss: 0.4390, validation loss: 0.0875
2024-06-01 22:26:43 [INFO]: Epoch 015 - training loss: 0.4411, validation loss: 0.0968
2024-06-01 22:26:44 [INFO]: Epoch 016 - training loss: 0.4770, validation loss: 0.1186
2024-06-01 22:26:45 [INFO]: Epoch 017 - training loss: 0.4649, validation loss: 0.0912
2024-06-01 22:26:46 [INFO]: Epoch 018 - training loss: 0.4558, validation loss: 0.0996
2024-06-01 22:26:47 [INFO]: Epoch 019 - training loss: 0.4392, validation loss: 0.0771
2024-06-01 22:26:48 [INFO]: Epoch 020 - training loss: 0.4114, validation loss: 0.0858
2024-06-01 22:26:49 [INFO]: Epoch 021 - training loss: 0.3922, validation loss: 0.0691
2024-06-01 22:26:50 [INFO]: Epoch 022 - training loss: 0.3814, validation loss: 0.0951
2024-06-01 22:26:51 [INFO]: Epoch 023 - training loss: 0.4004, validation loss: 0.0778
2024-06-01 22:26:52 [INFO]: Epoch 024 - training loss: 0.3667, validation loss: 0.0685
2024-06-01 22:26:53 [INFO]: Epoch 025 - training loss: 0.3588, validation loss: 0.0694
2024-06-01 22:26:54 [INFO]: Epoch 026 - training loss: 0.3532, validation loss: 0.0693
2024-06-01 22:26:55 [INFO]: Epoch 027 - training loss: 0.3535, validation loss: 0.0700
2024-06-01 22:26:56 [INFO]: Epoch 028 - training loss: 0.3484, validation loss: 0.0669
2024-06-01 22:26:57 [INFO]: Epoch 029 - training loss: 0.3602, validation loss: 0.0681
2024-06-01 22:26:58 [INFO]: Epoch 030 - training loss: 0.3558, validation loss: 0.0800
2024-06-01 22:26:59 [INFO]: Epoch 031 - training loss: 0.3611, validation loss: 0.0781
2024-06-01 22:27:00 [INFO]: Epoch 032 - training loss: 0.3430, validation loss: 0.0645
2024-06-01 22:27:01 [INFO]: Epoch 033 - training loss: 0.3322, validation loss: 0.0669
2024-06-01 22:27:02 [INFO]: Epoch 034 - training loss: 0.3604, validation loss: 0.0739
2024-06-01 22:27:03 [INFO]: Epoch 035 - training loss: 0.3541, validation loss: 0.0680
2024-06-01 22:27:04 [INFO]: Epoch 036 - training loss: 0.3446, validation loss: 0.0649
2024-06-01 22:27:05 [INFO]: Epoch 037 - training loss: 0.3404, validation loss: 0.0728
2024-06-01 22:27:06 [INFO]: Epoch 038 - training loss: 0.3368, validation loss: 0.0573
2024-06-01 22:27:07 [INFO]: Epoch 039 - training loss: 0.3236, validation loss: 0.0710
2024-06-01 22:27:08 [INFO]: Epoch 040 - training loss: 0.3238, validation loss: 0.0568
2024-06-01 22:27:09 [INFO]: Epoch 041 - training loss: 0.3129, validation loss: 0.0576
2024-06-01 22:27:10 [INFO]: Epoch 042 - training loss: 0.3195, validation loss: 0.0611
2024-06-01 22:27:11 [INFO]: Epoch 043 - training loss: 0.3151, validation loss: 0.0611
2024-06-01 22:27:12 [INFO]: Epoch 044 - training loss: 0.3078, validation loss: 0.0644
2024-06-01 22:27:13 [INFO]: Epoch 045 - training loss: 0.3065, validation loss: 0.0612
2024-06-01 22:27:14 [INFO]: Epoch 046 - training loss: 0.3057, validation loss: 0.0548
2024-06-01 22:27:15 [INFO]: Epoch 047 - training loss: 0.3047, validation loss: 0.0522
2024-06-01 22:27:16 [INFO]: Epoch 048 - training loss: 0.2972, validation loss: 0.0524
2024-06-01 22:27:17 [INFO]: Epoch 049 - training loss: 0.2988, validation loss: 0.0522
2024-06-01 22:27:18 [INFO]: Epoch 050 - training loss: 0.2993, validation loss: 0.0607
2024-06-01 22:27:19 [INFO]: Epoch 051 - training loss: 0.2940, validation loss: 0.0618
2024-06-01 22:27:20 [INFO]: Epoch 052 - training loss: 0.2994, validation loss: 0.0687
2024-06-01 22:27:21 [INFO]: Epoch 053 - training loss: 0.3027, validation loss: 0.0601
2024-06-01 22:27:22 [INFO]: Epoch 054 - training loss: 0.2910, validation loss: 0.0517
2024-06-01 22:27:23 [INFO]: Epoch 055 - training loss: 0.2917, validation loss: 0.0579
2024-06-01 22:27:24 [INFO]: Epoch 056 - training loss: 0.2735, validation loss: 0.0611
2024-06-01 22:27:25 [INFO]: Epoch 057 - training loss: 0.2692, validation loss: 0.0567
2024-06-01 22:27:26 [INFO]: Epoch 058 - training loss: 0.2774, validation loss: 0.0538
2024-06-01 22:27:27 [INFO]: Epoch 059 - training loss: 0.2747, validation loss: 0.0500
2024-06-01 22:27:28 [INFO]: Epoch 060 - training loss: 0.2651, validation loss: 0.0464
2024-06-01 22:27:29 [INFO]: Epoch 061 - training loss: 0.2669, validation loss: 0.0487
2024-06-01 22:27:30 [INFO]: Epoch 062 - training loss: 0.2675, validation loss: 0.0472
2024-06-01 22:27:31 [INFO]: Epoch 063 - training loss: 0.2897, validation loss: 0.0485
2024-06-01 22:27:32 [INFO]: Epoch 064 - training loss: 0.2787, validation loss: 0.0505
2024-06-01 22:27:33 [INFO]: Epoch 065 - training loss: 0.2858, validation loss: 0.0464
2024-06-01 22:27:34 [INFO]: Epoch 066 - training loss: 0.2727, validation loss: 0.0497
2024-06-01 22:27:34 [INFO]: Epoch 067 - training loss: 0.2614, validation loss: 0.0599
2024-06-01 22:27:35 [INFO]: Epoch 068 - training loss: 0.2758, validation loss: 0.0462
2024-06-01 22:27:37 [INFO]: Epoch 069 - training loss: 0.2632, validation loss: 0.0630
2024-06-01 22:27:37 [INFO]: Epoch 070 - training loss: 0.2727, validation loss: 0.0468
2024-06-01 22:27:38 [INFO]: Epoch 071 - training loss: 0.2611, validation loss: 0.0484
2024-06-01 22:27:40 [INFO]: Epoch 072 - training loss: 0.2585, validation loss: 0.0493
2024-06-01 22:27:41 [INFO]: Epoch 073 - training loss: 0.2534, validation loss: 0.0462
2024-06-01 22:27:42 [INFO]: Epoch 074 - training loss: 0.2469, validation loss: 0.0474
2024-06-01 22:27:43 [INFO]: Epoch 075 - training loss: 0.2572, validation loss: 0.0441
2024-06-01 22:27:44 [INFO]: Epoch 076 - training loss: 0.2580, validation loss: 0.0413
2024-06-01 22:27:44 [INFO]: Epoch 077 - training loss: 0.2641, validation loss: 0.0457
2024-06-01 22:27:45 [INFO]: Epoch 078 - training loss: 0.2625, validation loss: 0.0459
2024-06-01 22:27:46 [INFO]: Epoch 079 - training loss: 0.2589, validation loss: 0.0503
2024-06-01 22:27:47 [INFO]: Epoch 080 - training loss: 0.2577, validation loss: 0.0412
2024-06-01 22:27:48 [INFO]: Epoch 081 - training loss: 0.2634, validation loss: 0.0550
2024-06-01 22:27:50 [INFO]: Epoch 082 - training loss: 0.2724, validation loss: 0.0633
2024-06-01 22:27:51 [INFO]: Epoch 083 - training loss: 0.2732, validation loss: 0.0619
2024-06-01 22:27:52 [INFO]: Epoch 084 - training loss: 0.2729, validation loss: 0.0507
2024-06-01 22:27:53 [INFO]: Epoch 085 - training loss: 0.2628, validation loss: 0.0557
2024-06-01 22:27:53 [INFO]: Epoch 086 - training loss: 0.2522, validation loss: 0.0444
2024-06-01 22:27:55 [INFO]: Epoch 087 - training loss: 0.2545, validation loss: 0.0422
2024-06-01 22:27:56 [INFO]: Epoch 088 - training loss: 0.2595, validation loss: 0.0421
2024-06-01 22:27:57 [INFO]: Epoch 089 - training loss: 0.2469, validation loss: 0.0414
2024-06-01 22:27:58 [INFO]: Epoch 090 - training loss: 0.2453, validation loss: 0.0399
2024-06-01 22:27:59 [INFO]: Epoch 091 - training loss: 0.2379, validation loss: 0.0443
2024-06-01 22:27:59 [INFO]: Epoch 092 - training loss: 0.2360, validation loss: 0.0460
2024-06-01 22:28:00 [INFO]: Epoch 093 - training loss: 0.2309, validation loss: 0.0424
2024-06-01 22:28:01 [INFO]: Epoch 094 - training loss: 0.2273, validation loss: 0.0397
2024-06-01 22:28:02 [INFO]: Epoch 095 - training loss: 0.2270, validation loss: 0.0442
2024-06-01 22:28:03 [INFO]: Epoch 096 - training loss: 0.2258, validation loss: 0.0418
2024-06-01 22:28:04 [INFO]: Epoch 097 - training loss: 0.2270, validation loss: 0.0469
2024-06-01 22:28:06 [INFO]: Epoch 098 - training loss: 0.2355, validation loss: 0.0428
2024-06-01 22:28:07 [INFO]: Epoch 099 - training loss: 0.2398, validation loss: 0.0459
2024-06-01 22:28:08 [INFO]: Epoch 100 - training loss: 0.2375, validation loss: 0.0394
2024-06-01 22:28:08 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 22:28:08 [INFO]: Saved the model to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_3/20240601_T222627/Pyraformer.pypots
2024-06-01 22:28:08 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:28:08 [INFO]: Round3 - Pyraformer on ETT_h1: MAE=0.1773, MSE=0.0669, MRE=0.2092
2024-06-01 22:28:08 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:28:08 [INFO]: Using the given device: cuda:0
2024-06-01 22:28:08 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_4/20240601_T222808
2024-06-01 22:28:08 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_4/20240601_T222808/tensorboard
2024-06-01 22:28:08 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-01 22:28:09 [INFO]: Epoch 001 - training loss: 1.9716, validation loss: 0.4133
2024-06-01 22:28:10 [INFO]: Epoch 002 - training loss: 0.9514, validation loss: 0.2388
2024-06-01 22:28:12 [INFO]: Epoch 003 - training loss: 0.7503, validation loss: 0.1944
2024-06-01 22:28:12 [INFO]: Epoch 004 - training loss: 0.7151, validation loss: 0.1454
2024-06-01 22:28:13 [INFO]: Epoch 005 - training loss: 0.5892, validation loss: 0.1541
2024-06-01 22:28:14 [INFO]: Epoch 006 - training loss: 0.5942, validation loss: 0.1434
2024-06-01 22:28:15 [INFO]: Epoch 007 - training loss: 0.5549, validation loss: 0.1185
2024-06-01 22:28:16 [INFO]: Epoch 008 - training loss: 0.5056, validation loss: 0.1214
2024-06-01 22:28:17 [INFO]: Epoch 009 - training loss: 0.5104, validation loss: 0.1124
2024-06-01 22:28:18 [INFO]: Epoch 010 - training loss: 0.4678, validation loss: 0.1149
2024-06-01 22:28:19 [INFO]: Epoch 011 - training loss: 0.4940, validation loss: 0.1058
2024-06-01 22:28:20 [INFO]: Epoch 012 - training loss: 0.4559, validation loss: 0.0894
2024-06-01 22:28:20 [INFO]: Epoch 013 - training loss: 0.4347, validation loss: 0.0916
2024-06-01 22:28:21 [INFO]: Epoch 014 - training loss: 0.4547, validation loss: 0.0965
2024-06-01 22:28:22 [INFO]: Epoch 015 - training loss: 0.4178, validation loss: 0.0949
2024-06-01 22:28:23 [INFO]: Epoch 016 - training loss: 0.4177, validation loss: 0.0867
2024-06-01 22:28:24 [INFO]: Epoch 017 - training loss: 0.4184, validation loss: 0.0870
2024-06-01 22:28:25 [INFO]: Epoch 018 - training loss: 0.4131, validation loss: 0.0864
2024-06-01 22:28:26 [INFO]: Epoch 019 - training loss: 0.3934, validation loss: 0.0730
2024-06-01 22:28:27 [INFO]: Epoch 020 - training loss: 0.3736, validation loss: 0.0804
2024-06-01 22:28:28 [INFO]: Epoch 021 - training loss: 0.3747, validation loss: 0.0790
2024-06-01 22:28:29 [INFO]: Epoch 022 - training loss: 0.3733, validation loss: 0.0707
2024-06-01 22:28:30 [INFO]: Epoch 023 - training loss: 0.3775, validation loss: 0.0706
2024-06-01 22:28:31 [INFO]: Epoch 024 - training loss: 0.3839, validation loss: 0.0783
2024-06-01 22:28:32 [INFO]: Epoch 025 - training loss: 0.3772, validation loss: 0.0716
2024-06-01 22:28:33 [INFO]: Epoch 026 - training loss: 0.3723, validation loss: 0.0810
2024-06-01 22:28:34 [INFO]: Epoch 027 - training loss: 0.3568, validation loss: 0.0732
2024-06-01 22:28:35 [INFO]: Epoch 028 - training loss: 0.3462, validation loss: 0.0682
2024-06-01 22:28:36 [INFO]: Epoch 029 - training loss: 0.3525, validation loss: 0.0719
2024-06-01 22:28:37 [INFO]: Epoch 030 - training loss: 0.3602, validation loss: 0.1007
2024-06-01 22:28:38 [INFO]: Epoch 031 - training loss: 0.3604, validation loss: 0.0912
2024-06-01 22:28:39 [INFO]: Epoch 032 - training loss: 0.3506, validation loss: 0.0655
2024-06-01 22:28:40 [INFO]: Epoch 033 - training loss: 0.3249, validation loss: 0.0620
2024-06-01 22:28:41 [INFO]: Epoch 034 - training loss: 0.3273, validation loss: 0.0647
2024-06-01 22:28:42 [INFO]: Epoch 035 - training loss: 0.3542, validation loss: 0.0725
2024-06-01 22:28:43 [INFO]: Epoch 036 - training loss: 0.3541, validation loss: 0.0624
2024-06-01 22:28:44 [INFO]: Epoch 037 - training loss: 0.3280, validation loss: 0.0713
2024-06-01 22:28:45 [INFO]: Epoch 038 - training loss: 0.3138, validation loss: 0.0584
2024-06-01 22:28:46 [INFO]: Epoch 039 - training loss: 0.3031, validation loss: 0.0572
2024-06-01 22:28:48 [INFO]: Epoch 040 - training loss: 0.3032, validation loss: 0.0544
2024-06-01 22:28:48 [INFO]: Epoch 041 - training loss: 0.2915, validation loss: 0.0580
2024-06-01 22:28:49 [INFO]: Epoch 042 - training loss: 0.2908, validation loss: 0.0618
2024-06-01 22:28:50 [INFO]: Epoch 043 - training loss: 0.3042, validation loss: 0.0517
2024-06-01 22:28:51 [INFO]: Epoch 044 - training loss: 0.2956, validation loss: 0.0533
2024-06-01 22:28:52 [INFO]: Epoch 045 - training loss: 0.2953, validation loss: 0.0643
2024-06-01 22:28:53 [INFO]: Epoch 046 - training loss: 0.3056, validation loss: 0.0555
2024-06-01 22:28:55 [INFO]: Epoch 047 - training loss: 0.2962, validation loss: 0.0574
2024-06-01 22:28:56 [INFO]: Epoch 048 - training loss: 0.2991, validation loss: 0.0512
2024-06-01 22:28:57 [INFO]: Epoch 049 - training loss: 0.2871, validation loss: 0.0531
2024-06-01 22:28:58 [INFO]: Epoch 050 - training loss: 0.2811, validation loss: 0.0555
2024-06-01 22:28:59 [INFO]: Epoch 051 - training loss: 0.2817, validation loss: 0.0534
2024-06-01 22:29:00 [INFO]: Epoch 052 - training loss: 0.2792, validation loss: 0.0534
2024-06-01 22:29:01 [INFO]: Epoch 053 - training loss: 0.2802, validation loss: 0.0574
2024-06-01 22:29:02 [INFO]: Epoch 054 - training loss: 0.2765, validation loss: 0.0517
2024-06-01 22:29:03 [INFO]: Epoch 055 - training loss: 0.2727, validation loss: 0.0601
2024-06-01 22:29:04 [INFO]: Epoch 056 - training loss: 0.2798, validation loss: 0.0530
2024-06-01 22:29:05 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.0472
2024-06-01 22:29:06 [INFO]: Epoch 058 - training loss: 0.2851, validation loss: 0.0477
2024-06-01 22:29:07 [INFO]: Epoch 059 - training loss: 0.2802, validation loss: 0.0585
2024-06-01 22:29:08 [INFO]: Epoch 060 - training loss: 0.2838, validation loss: 0.0453
2024-06-01 22:29:09 [INFO]: Epoch 061 - training loss: 0.2882, validation loss: 0.0482
2024-06-01 22:29:10 [INFO]: Epoch 062 - training loss: 0.2711, validation loss: 0.0482
2024-06-01 22:29:11 [INFO]: Epoch 063 - training loss: 0.2660, validation loss: 0.0493
2024-06-01 22:29:12 [INFO]: Epoch 064 - training loss: 0.2528, validation loss: 0.0462
2024-06-01 22:29:13 [INFO]: Epoch 065 - training loss: 0.2726, validation loss: 0.0486
2024-06-01 22:29:14 [INFO]: Epoch 066 - training loss: 0.2604, validation loss: 0.0537
2024-06-01 22:29:15 [INFO]: Epoch 067 - training loss: 0.2691, validation loss: 0.0450
2024-06-01 22:29:16 [INFO]: Epoch 068 - training loss: 0.2558, validation loss: 0.0524
2024-06-01 22:29:17 [INFO]: Epoch 069 - training loss: 0.2772, validation loss: 0.0495
2024-06-01 22:29:18 [INFO]: Epoch 070 - training loss: 0.2605, validation loss: 0.0482
2024-06-01 22:29:19 [INFO]: Epoch 071 - training loss: 0.2602, validation loss: 0.0536
2024-06-01 22:29:21 [INFO]: Epoch 072 - training loss: 0.2550, validation loss: 0.0479
2024-06-01 22:29:22 [INFO]: Epoch 073 - training loss: 0.2566, validation loss: 0.0462
2024-06-01 22:29:23 [INFO]: Epoch 074 - training loss: 0.2572, validation loss: 0.0478
2024-06-01 22:29:24 [INFO]: Epoch 075 - training loss: 0.2555, validation loss: 0.0414
2024-06-01 22:29:25 [INFO]: Epoch 076 - training loss: 0.2568, validation loss: 0.0476
2024-06-01 22:29:26 [INFO]: Epoch 077 - training loss: 0.2521, validation loss: 0.0467
2024-06-01 22:29:27 [INFO]: Epoch 078 - training loss: 0.2498, validation loss: 0.0405
2024-06-01 22:29:28 [INFO]: Epoch 079 - training loss: 0.2383, validation loss: 0.0431
2024-06-01 22:29:29 [INFO]: Epoch 080 - training loss: 0.2425, validation loss: 0.0387
2024-06-01 22:29:30 [INFO]: Epoch 081 - training loss: 0.2417, validation loss: 0.0508
2024-06-01 22:29:31 [INFO]: Epoch 082 - training loss: 0.2558, validation loss: 0.0432
2024-06-01 22:29:32 [INFO]: Epoch 083 - training loss: 0.2438, validation loss: 0.0434
2024-06-01 22:29:33 [INFO]: Epoch 084 - training loss: 0.2488, validation loss: 0.0468
2024-06-01 22:29:34 [INFO]: Epoch 085 - training loss: 0.2505, validation loss: 0.0492
2024-06-01 22:29:36 [INFO]: Epoch 086 - training loss: 0.2592, validation loss: 0.0471
2024-06-01 22:29:37 [INFO]: Epoch 087 - training loss: 0.2429, validation loss: 0.0424
2024-06-01 22:29:38 [INFO]: Epoch 088 - training loss: 0.2458, validation loss: 0.0436
2024-06-01 22:29:39 [INFO]: Epoch 089 - training loss: 0.2490, validation loss: 0.0400
2024-06-01 22:29:40 [INFO]: Epoch 090 - training loss: 0.2524, validation loss: 0.0467
2024-06-01 22:29:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:29:40 [INFO]: Finished training. The best model is from epoch#80.
2024-06-01 22:29:40 [INFO]: Saved the model to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_4/20240601_T222808/Pyraformer.pypots
2024-06-01 22:29:40 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Pyraformer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:29:40 [INFO]: Round4 - Pyraformer on ETT_h1: MAE=0.1781, MSE=0.0759, MRE=0.2102
2024-06-01 22:29:40 [INFO]: Done! Final results:
Averaged Pyraformer (n params: 15,262,215) on ETT_h1: MAE=0.1821 ± 0.008309051805620768, MSE=0.0716 ± 0.004942737517350185, MRE=0.2149 ± 0.009805437798264425, average inference time=0.14
