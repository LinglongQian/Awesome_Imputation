2024-06-01 22:01:33 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:01:33 [INFO]: Using the given device: cuda:0
2024-06-01 22:01:34 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_0/20240601_T220134
2024-06-01 22:01:34 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_0/20240601_T220134/tensorboard
2024-06-01 22:01:34 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 223,479
2024-06-01 22:01:35 [INFO]: Epoch 001 - training loss: 1.5275, validation loss: 0.9542
2024-06-01 22:01:36 [INFO]: Epoch 002 - training loss: 1.3279, validation loss: 0.9923
2024-06-01 22:01:36 [INFO]: Epoch 003 - training loss: 1.0565, validation loss: 0.4911
2024-06-01 22:01:36 [INFO]: Epoch 004 - training loss: 0.8416, validation loss: 0.3759
2024-06-01 22:01:36 [INFO]: Epoch 005 - training loss: 0.6828, validation loss: 0.1832
2024-06-01 22:01:36 [INFO]: Epoch 006 - training loss: 0.5912, validation loss: 0.1695
2024-06-01 22:01:36 [INFO]: Epoch 007 - training loss: 0.5540, validation loss: 0.1293
2024-06-01 22:01:36 [INFO]: Epoch 008 - training loss: 0.5017, validation loss: 0.1180
2024-06-01 22:01:37 [INFO]: Epoch 009 - training loss: 0.4704, validation loss: 0.1135
2024-06-01 22:01:37 [INFO]: Epoch 010 - training loss: 0.4676, validation loss: 0.1184
2024-06-01 22:01:37 [INFO]: Epoch 011 - training loss: 0.4558, validation loss: 0.1048
2024-06-01 22:01:38 [INFO]: Epoch 012 - training loss: 0.4469, validation loss: 0.1042
2024-06-01 22:01:38 [INFO]: Epoch 013 - training loss: 0.4375, validation loss: 0.1020
2024-06-01 22:01:38 [INFO]: Epoch 014 - training loss: 0.4234, validation loss: 0.1011
2024-06-01 22:01:39 [INFO]: Epoch 015 - training loss: 0.4158, validation loss: 0.1019
2024-06-01 22:01:39 [INFO]: Epoch 016 - training loss: 0.4154, validation loss: 0.0955
2024-06-01 22:01:39 [INFO]: Epoch 017 - training loss: 0.4076, validation loss: 0.0925
2024-06-01 22:01:40 [INFO]: Epoch 018 - training loss: 0.4120, validation loss: 0.0960
2024-06-01 22:01:40 [INFO]: Epoch 019 - training loss: 0.4041, validation loss: 0.0983
2024-06-01 22:01:40 [INFO]: Epoch 020 - training loss: 0.4008, validation loss: 0.0903
2024-06-01 22:01:40 [INFO]: Epoch 021 - training loss: 0.4138, validation loss: 0.0833
2024-06-01 22:01:41 [INFO]: Epoch 022 - training loss: 0.4068, validation loss: 0.0929
2024-06-01 22:01:41 [INFO]: Epoch 023 - training loss: 0.3992, validation loss: 0.0917
2024-06-01 22:01:42 [INFO]: Epoch 024 - training loss: 0.4006, validation loss: 0.0815
2024-06-01 22:01:42 [INFO]: Epoch 025 - training loss: 0.3889, validation loss: 0.0886
2024-06-01 22:01:42 [INFO]: Epoch 026 - training loss: 0.3849, validation loss: 0.0832
2024-06-01 22:01:43 [INFO]: Epoch 027 - training loss: 0.3908, validation loss: 0.0895
2024-06-01 22:01:43 [INFO]: Epoch 028 - training loss: 0.3858, validation loss: 0.0858
2024-06-01 22:01:43 [INFO]: Epoch 029 - training loss: 0.3842, validation loss: 0.0826
2024-06-01 22:01:44 [INFO]: Epoch 030 - training loss: 0.3842, validation loss: 0.0823
2024-06-01 22:01:44 [INFO]: Epoch 031 - training loss: 0.3728, validation loss: 0.0851
2024-06-01 22:01:44 [INFO]: Epoch 032 - training loss: 0.3737, validation loss: 0.0843
2024-06-01 22:01:45 [INFO]: Epoch 033 - training loss: 0.3745, validation loss: 0.0834
2024-06-01 22:01:45 [INFO]: Epoch 034 - training loss: 0.3763, validation loss: 0.0767
2024-06-01 22:01:45 [INFO]: Epoch 035 - training loss: 0.3769, validation loss: 0.0783
2024-06-01 22:01:45 [INFO]: Epoch 036 - training loss: 0.3764, validation loss: 0.0769
2024-06-01 22:01:46 [INFO]: Epoch 037 - training loss: 0.3788, validation loss: 0.0889
2024-06-01 22:01:46 [INFO]: Epoch 038 - training loss: 0.3844, validation loss: 0.0876
2024-06-01 22:01:46 [INFO]: Epoch 039 - training loss: 0.3779, validation loss: 0.0752
2024-06-01 22:01:47 [INFO]: Epoch 040 - training loss: 0.3727, validation loss: 0.0816
2024-06-01 22:01:47 [INFO]: Epoch 041 - training loss: 0.3705, validation loss: 0.0780
2024-06-01 22:01:47 [INFO]: Epoch 042 - training loss: 0.3607, validation loss: 0.0833
2024-06-01 22:01:47 [INFO]: Epoch 043 - training loss: 0.3605, validation loss: 0.0795
2024-06-01 22:01:48 [INFO]: Epoch 044 - training loss: 0.3530, validation loss: 0.0787
2024-06-01 22:01:48 [INFO]: Epoch 045 - training loss: 0.3550, validation loss: 0.0777
2024-06-01 22:01:49 [INFO]: Epoch 046 - training loss: 0.3530, validation loss: 0.0748
2024-06-01 22:01:49 [INFO]: Epoch 047 - training loss: 0.3496, validation loss: 0.0748
2024-06-01 22:01:49 [INFO]: Epoch 048 - training loss: 0.3520, validation loss: 0.0846
2024-06-01 22:01:50 [INFO]: Epoch 049 - training loss: 0.3535, validation loss: 0.0774
2024-06-01 22:01:50 [INFO]: Epoch 050 - training loss: 0.3425, validation loss: 0.0766
2024-06-01 22:01:50 [INFO]: Epoch 051 - training loss: 0.3554, validation loss: 0.0769
2024-06-01 22:01:51 [INFO]: Epoch 052 - training loss: 0.3540, validation loss: 0.0781
2024-06-01 22:01:51 [INFO]: Epoch 053 - training loss: 0.3482, validation loss: 0.0781
2024-06-01 22:01:51 [INFO]: Epoch 054 - training loss: 0.3477, validation loss: 0.0795
2024-06-01 22:01:52 [INFO]: Epoch 055 - training loss: 0.3463, validation loss: 0.0790
2024-06-01 22:01:52 [INFO]: Epoch 056 - training loss: 0.3463, validation loss: 0.0791
2024-06-01 22:01:52 [INFO]: Epoch 057 - training loss: 0.3524, validation loss: 0.0785
2024-06-01 22:01:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:01:52 [INFO]: Finished training. The best model is from epoch#47.
2024-06-01 22:01:52 [INFO]: Saved the model to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_0/20240601_T220134/Crossformer.pypots
2024-06-01 22:01:52 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_0/imputation.pkl
2024-06-01 22:01:52 [INFO]: Round0 - Crossformer on ETT_h1: MAE=0.2288, MSE=0.1115, MRE=0.2701
2024-06-01 22:01:52 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:01:52 [INFO]: Using the given device: cuda:0
2024-06-01 22:01:52 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_1/20240601_T220152
2024-06-01 22:01:52 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_1/20240601_T220152/tensorboard
2024-06-01 22:01:52 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 223,479
2024-06-01 22:01:53 [INFO]: Epoch 001 - training loss: 1.5109, validation loss: 0.9019
2024-06-01 22:01:53 [INFO]: Epoch 002 - training loss: 1.3333, validation loss: 0.6942
2024-06-01 22:01:54 [INFO]: Epoch 003 - training loss: 1.0211, validation loss: 0.5939
2024-06-01 22:01:54 [INFO]: Epoch 004 - training loss: 0.8720, validation loss: 0.3895
2024-06-01 22:01:54 [INFO]: Epoch 005 - training loss: 0.7352, validation loss: 0.2281
2024-06-01 22:01:55 [INFO]: Epoch 006 - training loss: 0.5996, validation loss: 0.1640
2024-06-01 22:01:55 [INFO]: Epoch 007 - training loss: 0.5382, validation loss: 0.1233
2024-06-01 22:01:55 [INFO]: Epoch 008 - training loss: 0.4923, validation loss: 0.1111
2024-06-01 22:01:56 [INFO]: Epoch 009 - training loss: 0.4818, validation loss: 0.1341
2024-06-01 22:01:56 [INFO]: Epoch 010 - training loss: 0.4763, validation loss: 0.1260
2024-06-01 22:01:56 [INFO]: Epoch 011 - training loss: 0.4526, validation loss: 0.1092
2024-06-01 22:01:57 [INFO]: Epoch 012 - training loss: 0.4437, validation loss: 0.0977
2024-06-01 22:01:57 [INFO]: Epoch 013 - training loss: 0.4331, validation loss: 0.1006
2024-06-01 22:01:57 [INFO]: Epoch 014 - training loss: 0.4350, validation loss: 0.0954
2024-06-01 22:01:58 [INFO]: Epoch 015 - training loss: 0.4335, validation loss: 0.0986
2024-06-01 22:01:58 [INFO]: Epoch 016 - training loss: 0.4203, validation loss: 0.1065
2024-06-01 22:01:58 [INFO]: Epoch 017 - training loss: 0.4153, validation loss: 0.0926
2024-06-01 22:01:59 [INFO]: Epoch 018 - training loss: 0.4057, validation loss: 0.0918
2024-06-01 22:01:59 [INFO]: Epoch 019 - training loss: 0.4025, validation loss: 0.0961
2024-06-01 22:01:59 [INFO]: Epoch 020 - training loss: 0.4037, validation loss: 0.0894
2024-06-01 22:02:00 [INFO]: Epoch 021 - training loss: 0.3984, validation loss: 0.0995
2024-06-01 22:02:00 [INFO]: Epoch 022 - training loss: 0.4045, validation loss: 0.1013
2024-06-01 22:02:00 [INFO]: Epoch 023 - training loss: 0.3971, validation loss: 0.0953
2024-06-01 22:02:01 [INFO]: Epoch 024 - training loss: 0.3969, validation loss: 0.0820
2024-06-01 22:02:01 [INFO]: Epoch 025 - training loss: 0.3988, validation loss: 0.0811
2024-06-01 22:02:02 [INFO]: Epoch 026 - training loss: 0.4019, validation loss: 0.0882
2024-06-01 22:02:02 [INFO]: Epoch 027 - training loss: 0.4019, validation loss: 0.1005
2024-06-01 22:02:02 [INFO]: Epoch 028 - training loss: 0.3996, validation loss: 0.0835
2024-06-01 22:02:03 [INFO]: Epoch 029 - training loss: 0.4043, validation loss: 0.0847
2024-06-01 22:02:03 [INFO]: Epoch 030 - training loss: 0.3961, validation loss: 0.0929
2024-06-01 22:02:04 [INFO]: Epoch 031 - training loss: 0.3936, validation loss: 0.0903
2024-06-01 22:02:04 [INFO]: Epoch 032 - training loss: 0.3960, validation loss: 0.0984
2024-06-01 22:02:04 [INFO]: Epoch 033 - training loss: 0.3843, validation loss: 0.0826
2024-06-01 22:02:04 [INFO]: Epoch 034 - training loss: 0.3761, validation loss: 0.0805
2024-06-01 22:02:05 [INFO]: Epoch 035 - training loss: 0.3780, validation loss: 0.0784
2024-06-01 22:02:05 [INFO]: Epoch 036 - training loss: 0.3764, validation loss: 0.0842
2024-06-01 22:02:06 [INFO]: Epoch 037 - training loss: 0.3742, validation loss: 0.0795
2024-06-01 22:02:06 [INFO]: Epoch 038 - training loss: 0.3721, validation loss: 0.0760
2024-06-01 22:02:06 [INFO]: Epoch 039 - training loss: 0.3663, validation loss: 0.0757
2024-06-01 22:02:07 [INFO]: Epoch 040 - training loss: 0.3613, validation loss: 0.0732
2024-06-01 22:02:07 [INFO]: Epoch 041 - training loss: 0.3637, validation loss: 0.0761
2024-06-01 22:02:07 [INFO]: Epoch 042 - training loss: 0.3773, validation loss: 0.0825
2024-06-01 22:02:07 [INFO]: Epoch 043 - training loss: 0.3748, validation loss: 0.0756
2024-06-01 22:02:08 [INFO]: Epoch 044 - training loss: 0.3647, validation loss: 0.0787
2024-06-01 22:02:08 [INFO]: Epoch 045 - training loss: 0.3624, validation loss: 0.0760
2024-06-01 22:02:09 [INFO]: Epoch 046 - training loss: 0.3614, validation loss: 0.0746
2024-06-01 22:02:09 [INFO]: Epoch 047 - training loss: 0.3625, validation loss: 0.0751
2024-06-01 22:02:09 [INFO]: Epoch 048 - training loss: 0.3588, validation loss: 0.0783
2024-06-01 22:02:10 [INFO]: Epoch 049 - training loss: 0.3498, validation loss: 0.0722
2024-06-01 22:02:10 [INFO]: Epoch 050 - training loss: 0.3478, validation loss: 0.0715
2024-06-01 22:02:10 [INFO]: Epoch 051 - training loss: 0.3487, validation loss: 0.0732
2024-06-01 22:02:11 [INFO]: Epoch 052 - training loss: 0.3573, validation loss: 0.0869
2024-06-01 22:02:11 [INFO]: Epoch 053 - training loss: 0.3565, validation loss: 0.0717
2024-06-01 22:02:11 [INFO]: Epoch 054 - training loss: 0.3579, validation loss: 0.0799
2024-06-01 22:02:12 [INFO]: Epoch 055 - training loss: 0.3574, validation loss: 0.0755
2024-06-01 22:02:12 [INFO]: Epoch 056 - training loss: 0.3472, validation loss: 0.0815
2024-06-01 22:02:13 [INFO]: Epoch 057 - training loss: 0.3445, validation loss: 0.0735
2024-06-01 22:02:13 [INFO]: Epoch 058 - training loss: 0.3417, validation loss: 0.0697
2024-06-01 22:02:13 [INFO]: Epoch 059 - training loss: 0.3368, validation loss: 0.0738
2024-06-01 22:02:14 [INFO]: Epoch 060 - training loss: 0.3394, validation loss: 0.0750
2024-06-01 22:02:14 [INFO]: Epoch 061 - training loss: 0.3405, validation loss: 0.0736
2024-06-01 22:02:14 [INFO]: Epoch 062 - training loss: 0.3338, validation loss: 0.0727
2024-06-01 22:02:15 [INFO]: Epoch 063 - training loss: 0.3332, validation loss: 0.0701
2024-06-01 22:02:15 [INFO]: Epoch 064 - training loss: 0.3324, validation loss: 0.0687
2024-06-01 22:02:15 [INFO]: Epoch 065 - training loss: 0.3289, validation loss: 0.0788
2024-06-01 22:02:16 [INFO]: Epoch 066 - training loss: 0.3309, validation loss: 0.0734
2024-06-01 22:02:16 [INFO]: Epoch 067 - training loss: 0.3241, validation loss: 0.0679
2024-06-01 22:02:16 [INFO]: Epoch 068 - training loss: 0.3274, validation loss: 0.0682
2024-06-01 22:02:17 [INFO]: Epoch 069 - training loss: 0.3240, validation loss: 0.0754
2024-06-01 22:02:17 [INFO]: Epoch 070 - training loss: 0.3242, validation loss: 0.0749
2024-06-01 22:02:17 [INFO]: Epoch 071 - training loss: 0.3317, validation loss: 0.0725
2024-06-01 22:02:18 [INFO]: Epoch 072 - training loss: 0.3257, validation loss: 0.0736
2024-06-01 22:02:18 [INFO]: Epoch 073 - training loss: 0.3254, validation loss: 0.0719
2024-06-01 22:02:18 [INFO]: Epoch 074 - training loss: 0.3201, validation loss: 0.0758
2024-06-01 22:02:19 [INFO]: Epoch 075 - training loss: 0.3288, validation loss: 0.0713
2024-06-01 22:02:19 [INFO]: Epoch 076 - training loss: 0.3221, validation loss: 0.0706
2024-06-01 22:02:19 [INFO]: Epoch 077 - training loss: 0.3247, validation loss: 0.0706
2024-06-01 22:02:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:02:19 [INFO]: Finished training. The best model is from epoch#67.
2024-06-01 22:02:19 [INFO]: Saved the model to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_1/20240601_T220152/Crossformer.pypots
2024-06-01 22:02:19 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_1/imputation.pkl
2024-06-01 22:02:19 [INFO]: Round1 - Crossformer on ETT_h1: MAE=0.2223, MSE=0.1050, MRE=0.2624
2024-06-01 22:02:19 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:02:19 [INFO]: Using the given device: cuda:0
2024-06-01 22:02:19 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_2/20240601_T220219
2024-06-01 22:02:19 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_2/20240601_T220219/tensorboard
2024-06-01 22:02:19 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 223,479
2024-06-01 22:02:20 [INFO]: Epoch 001 - training loss: 1.4723, validation loss: 0.9113
2024-06-01 22:02:20 [INFO]: Epoch 002 - training loss: 1.1539, validation loss: 0.6774
2024-06-01 22:02:20 [INFO]: Epoch 003 - training loss: 0.9313, validation loss: 0.3793
2024-06-01 22:02:21 [INFO]: Epoch 004 - training loss: 0.7564, validation loss: 0.2052
2024-06-01 22:02:21 [INFO]: Epoch 005 - training loss: 0.6049, validation loss: 0.1648
2024-06-01 22:02:21 [INFO]: Epoch 006 - training loss: 0.5536, validation loss: 0.1360
2024-06-01 22:02:22 [INFO]: Epoch 007 - training loss: 0.5101, validation loss: 0.1180
2024-06-01 22:02:22 [INFO]: Epoch 008 - training loss: 0.4956, validation loss: 0.1263
2024-06-01 22:02:22 [INFO]: Epoch 009 - training loss: 0.4709, validation loss: 0.1024
2024-06-01 22:02:22 [INFO]: Epoch 010 - training loss: 0.4563, validation loss: 0.1071
2024-06-01 22:02:23 [INFO]: Epoch 011 - training loss: 0.4533, validation loss: 0.1184
2024-06-01 22:02:23 [INFO]: Epoch 012 - training loss: 0.4365, validation loss: 0.1197
2024-06-01 22:02:23 [INFO]: Epoch 013 - training loss: 0.4311, validation loss: 0.0980
2024-06-01 22:02:24 [INFO]: Epoch 014 - training loss: 0.4194, validation loss: 0.1017
2024-06-01 22:02:24 [INFO]: Epoch 015 - training loss: 0.4178, validation loss: 0.0876
2024-06-01 22:02:24 [INFO]: Epoch 016 - training loss: 0.4105, validation loss: 0.0881
2024-06-01 22:02:25 [INFO]: Epoch 017 - training loss: 0.4135, validation loss: 0.0966
2024-06-01 22:02:25 [INFO]: Epoch 018 - training loss: 0.4151, validation loss: 0.0921
2024-06-01 22:02:25 [INFO]: Epoch 019 - training loss: 0.4011, validation loss: 0.1088
2024-06-01 22:02:26 [INFO]: Epoch 020 - training loss: 0.4068, validation loss: 0.1030
2024-06-01 22:02:26 [INFO]: Epoch 021 - training loss: 0.3963, validation loss: 0.0892
2024-06-01 22:02:26 [INFO]: Epoch 022 - training loss: 0.4097, validation loss: 0.0881
2024-06-01 22:02:27 [INFO]: Epoch 023 - training loss: 0.4022, validation loss: 0.1022
2024-06-01 22:02:27 [INFO]: Epoch 024 - training loss: 0.3879, validation loss: 0.0940
2024-06-01 22:02:27 [INFO]: Epoch 025 - training loss: 0.3864, validation loss: 0.0896
2024-06-01 22:02:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:02:27 [INFO]: Finished training. The best model is from epoch#15.
2024-06-01 22:02:28 [INFO]: Saved the model to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_2/20240601_T220219/Crossformer.pypots
2024-06-01 22:02:28 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_2/imputation.pkl
2024-06-01 22:02:28 [INFO]: Round2 - Crossformer on ETT_h1: MAE=0.2444, MSE=0.1186, MRE=0.2884
2024-06-01 22:02:28 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:02:28 [INFO]: Using the given device: cuda:0
2024-06-01 22:02:28 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_3/20240601_T220228
2024-06-01 22:02:28 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_3/20240601_T220228/tensorboard
2024-06-01 22:02:28 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 223,479
2024-06-01 22:02:28 [INFO]: Epoch 001 - training loss: 1.4680, validation loss: 0.6531
2024-06-01 22:02:28 [INFO]: Epoch 002 - training loss: 1.0946, validation loss: 0.5089
2024-06-01 22:02:29 [INFO]: Epoch 003 - training loss: 0.8641, validation loss: 0.2806
2024-06-01 22:02:29 [INFO]: Epoch 004 - training loss: 0.6897, validation loss: 0.1705
2024-06-01 22:02:30 [INFO]: Epoch 005 - training loss: 0.6050, validation loss: 0.1488
2024-06-01 22:02:30 [INFO]: Epoch 006 - training loss: 0.5480, validation loss: 0.1368
2024-06-01 22:02:30 [INFO]: Epoch 007 - training loss: 0.5078, validation loss: 0.1178
2024-06-01 22:02:30 [INFO]: Epoch 008 - training loss: 0.4881, validation loss: 0.1112
2024-06-01 22:02:31 [INFO]: Epoch 009 - training loss: 0.4769, validation loss: 0.1237
2024-06-01 22:02:31 [INFO]: Epoch 010 - training loss: 0.4606, validation loss: 0.1018
2024-06-01 22:02:31 [INFO]: Epoch 011 - training loss: 0.4500, validation loss: 0.1157
2024-06-01 22:02:32 [INFO]: Epoch 012 - training loss: 0.4494, validation loss: 0.0996
2024-06-01 22:02:32 [INFO]: Epoch 013 - training loss: 0.4476, validation loss: 0.0923
2024-06-01 22:02:32 [INFO]: Epoch 014 - training loss: 0.4289, validation loss: 0.1001
2024-06-01 22:02:32 [INFO]: Epoch 015 - training loss: 0.4206, validation loss: 0.0904
2024-06-01 22:02:33 [INFO]: Epoch 016 - training loss: 0.4170, validation loss: 0.0916
2024-06-01 22:02:33 [INFO]: Epoch 017 - training loss: 0.4143, validation loss: 0.0909
2024-06-01 22:02:33 [INFO]: Epoch 018 - training loss: 0.4091, validation loss: 0.0900
2024-06-01 22:02:34 [INFO]: Epoch 019 - training loss: 0.4038, validation loss: 0.0934
2024-06-01 22:02:34 [INFO]: Epoch 020 - training loss: 0.4042, validation loss: 0.0867
2024-06-01 22:02:34 [INFO]: Epoch 021 - training loss: 0.3962, validation loss: 0.0888
2024-06-01 22:02:34 [INFO]: Epoch 022 - training loss: 0.3940, validation loss: 0.0942
2024-06-01 22:02:35 [INFO]: Epoch 023 - training loss: 0.3882, validation loss: 0.0808
2024-06-01 22:02:35 [INFO]: Epoch 024 - training loss: 0.3924, validation loss: 0.0942
2024-06-01 22:02:35 [INFO]: Epoch 025 - training loss: 0.3920, validation loss: 0.0856
2024-06-01 22:02:35 [INFO]: Epoch 026 - training loss: 0.3901, validation loss: 0.0776
2024-06-01 22:02:36 [INFO]: Epoch 027 - training loss: 0.3834, validation loss: 0.0841
2024-06-01 22:02:36 [INFO]: Epoch 028 - training loss: 0.3837, validation loss: 0.0802
2024-06-01 22:02:36 [INFO]: Epoch 029 - training loss: 0.3876, validation loss: 0.0875
2024-06-01 22:02:37 [INFO]: Epoch 030 - training loss: 0.3852, validation loss: 0.0866
2024-06-01 22:02:37 [INFO]: Epoch 031 - training loss: 0.3799, validation loss: 0.0838
2024-06-01 22:02:37 [INFO]: Epoch 032 - training loss: 0.3740, validation loss: 0.0779
2024-06-01 22:02:37 [INFO]: Epoch 033 - training loss: 0.3708, validation loss: 0.0772
2024-06-01 22:02:38 [INFO]: Epoch 034 - training loss: 0.3661, validation loss: 0.0814
2024-06-01 22:02:38 [INFO]: Epoch 035 - training loss: 0.3737, validation loss: 0.0803
2024-06-01 22:02:38 [INFO]: Epoch 036 - training loss: 0.3642, validation loss: 0.0855
2024-06-01 22:02:38 [INFO]: Epoch 037 - training loss: 0.3589, validation loss: 0.0812
2024-06-01 22:02:39 [INFO]: Epoch 038 - training loss: 0.3601, validation loss: 0.0764
2024-06-01 22:02:39 [INFO]: Epoch 039 - training loss: 0.3569, validation loss: 0.0803
2024-06-01 22:02:39 [INFO]: Epoch 040 - training loss: 0.3645, validation loss: 0.0799
2024-06-01 22:02:39 [INFO]: Epoch 041 - training loss: 0.3520, validation loss: 0.0767
2024-06-01 22:02:40 [INFO]: Epoch 042 - training loss: 0.3462, validation loss: 0.0810
2024-06-01 22:02:40 [INFO]: Epoch 043 - training loss: 0.3533, validation loss: 0.0752
2024-06-01 22:02:40 [INFO]: Epoch 044 - training loss: 0.3482, validation loss: 0.0770
2024-06-01 22:02:41 [INFO]: Epoch 045 - training loss: 0.3456, validation loss: 0.0720
2024-06-01 22:02:41 [INFO]: Epoch 046 - training loss: 0.3472, validation loss: 0.0728
2024-06-01 22:02:41 [INFO]: Epoch 047 - training loss: 0.3475, validation loss: 0.0850
2024-06-01 22:02:41 [INFO]: Epoch 048 - training loss: 0.3448, validation loss: 0.0744
2024-06-01 22:02:42 [INFO]: Epoch 049 - training loss: 0.3476, validation loss: 0.0798
2024-06-01 22:02:42 [INFO]: Epoch 050 - training loss: 0.3419, validation loss: 0.0774
2024-06-01 22:02:42 [INFO]: Epoch 051 - training loss: 0.3403, validation loss: 0.0719
2024-06-01 22:02:43 [INFO]: Epoch 052 - training loss: 0.3375, validation loss: 0.0745
2024-06-01 22:02:43 [INFO]: Epoch 053 - training loss: 0.3376, validation loss: 0.0763
2024-06-01 22:02:43 [INFO]: Epoch 054 - training loss: 0.3387, validation loss: 0.0745
2024-06-01 22:02:43 [INFO]: Epoch 055 - training loss: 0.3378, validation loss: 0.0724
2024-06-01 22:02:44 [INFO]: Epoch 056 - training loss: 0.3417, validation loss: 0.0806
2024-06-01 22:02:44 [INFO]: Epoch 057 - training loss: 0.3473, validation loss: 0.0788
2024-06-01 22:02:44 [INFO]: Epoch 058 - training loss: 0.3351, validation loss: 0.0746
2024-06-01 22:02:44 [INFO]: Epoch 059 - training loss: 0.3327, validation loss: 0.0723
2024-06-01 22:02:45 [INFO]: Epoch 060 - training loss: 0.3366, validation loss: 0.0747
2024-06-01 22:02:45 [INFO]: Epoch 061 - training loss: 0.3275, validation loss: 0.0784
2024-06-01 22:02:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:02:45 [INFO]: Finished training. The best model is from epoch#51.
2024-06-01 22:02:45 [INFO]: Saved the model to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_3/20240601_T220228/Crossformer.pypots
2024-06-01 22:02:45 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_3/imputation.pkl
2024-06-01 22:02:45 [INFO]: Round3 - Crossformer on ETT_h1: MAE=0.2292, MSE=0.1126, MRE=0.2704
2024-06-01 22:02:45 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:02:45 [INFO]: Using the given device: cuda:0
2024-06-01 22:02:45 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_4/20240601_T220245
2024-06-01 22:02:45 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_4/20240601_T220245/tensorboard
2024-06-01 22:02:45 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 223,479
2024-06-01 22:02:45 [INFO]: Epoch 001 - training loss: 1.4712, validation loss: 0.8438
2024-06-01 22:02:46 [INFO]: Epoch 002 - training loss: 1.0662, validation loss: 0.5334
2024-06-01 22:02:46 [INFO]: Epoch 003 - training loss: 0.8421, validation loss: 0.3660
2024-06-01 22:02:46 [INFO]: Epoch 004 - training loss: 0.7281, validation loss: 0.2036
2024-06-01 22:02:47 [INFO]: Epoch 005 - training loss: 0.5991, validation loss: 0.1401
2024-06-01 22:02:47 [INFO]: Epoch 006 - training loss: 0.5377, validation loss: 0.1321
2024-06-01 22:02:47 [INFO]: Epoch 007 - training loss: 0.4932, validation loss: 0.1382
2024-06-01 22:02:48 [INFO]: Epoch 008 - training loss: 0.4748, validation loss: 0.1003
2024-06-01 22:02:48 [INFO]: Epoch 009 - training loss: 0.4613, validation loss: 0.1051
2024-06-01 22:02:48 [INFO]: Epoch 010 - training loss: 0.4604, validation loss: 0.0950
2024-06-01 22:02:49 [INFO]: Epoch 011 - training loss: 0.4481, validation loss: 0.1042
2024-06-01 22:02:49 [INFO]: Epoch 012 - training loss: 0.4416, validation loss: 0.0946
2024-06-01 22:02:49 [INFO]: Epoch 013 - training loss: 0.4394, validation loss: 0.0929
2024-06-01 22:02:50 [INFO]: Epoch 014 - training loss: 0.4261, validation loss: 0.1061
2024-06-01 22:02:50 [INFO]: Epoch 015 - training loss: 0.4219, validation loss: 0.1031
2024-06-01 22:02:50 [INFO]: Epoch 016 - training loss: 0.4161, validation loss: 0.0924
2024-06-01 22:02:50 [INFO]: Epoch 017 - training loss: 0.4137, validation loss: 0.0911
2024-06-01 22:02:51 [INFO]: Epoch 018 - training loss: 0.4085, validation loss: 0.0942
2024-06-01 22:02:51 [INFO]: Epoch 019 - training loss: 0.4205, validation loss: 0.1119
2024-06-01 22:02:51 [INFO]: Epoch 020 - training loss: 0.4183, validation loss: 0.0936
2024-06-01 22:02:52 [INFO]: Epoch 021 - training loss: 0.4021, validation loss: 0.0970
2024-06-01 22:02:52 [INFO]: Epoch 022 - training loss: 0.4007, validation loss: 0.0866
2024-06-01 22:02:53 [INFO]: Epoch 023 - training loss: 0.4073, validation loss: 0.0849
2024-06-01 22:02:53 [INFO]: Epoch 024 - training loss: 0.3978, validation loss: 0.0928
2024-06-01 22:02:53 [INFO]: Epoch 025 - training loss: 0.4041, validation loss: 0.0872
2024-06-01 22:02:53 [INFO]: Epoch 026 - training loss: 0.3917, validation loss: 0.0848
2024-06-01 22:02:54 [INFO]: Epoch 027 - training loss: 0.3914, validation loss: 0.0895
2024-06-01 22:02:54 [INFO]: Epoch 028 - training loss: 0.3884, validation loss: 0.0893
2024-06-01 22:02:54 [INFO]: Epoch 029 - training loss: 0.3843, validation loss: 0.0829
2024-06-01 22:02:55 [INFO]: Epoch 030 - training loss: 0.3871, validation loss: 0.0887
2024-06-01 22:02:55 [INFO]: Epoch 031 - training loss: 0.3918, validation loss: 0.0919
2024-06-01 22:02:56 [INFO]: Epoch 032 - training loss: 0.3910, validation loss: 0.0891
2024-06-01 22:02:56 [INFO]: Epoch 033 - training loss: 0.3884, validation loss: 0.0976
2024-06-01 22:02:56 [INFO]: Epoch 034 - training loss: 0.3840, validation loss: 0.0839
2024-06-01 22:02:57 [INFO]: Epoch 035 - training loss: 0.3760, validation loss: 0.0887
2024-06-01 22:02:57 [INFO]: Epoch 036 - training loss: 0.3715, validation loss: 0.0909
2024-06-01 22:02:57 [INFO]: Epoch 037 - training loss: 0.3774, validation loss: 0.0830
2024-06-01 22:02:58 [INFO]: Epoch 038 - training loss: 0.3679, validation loss: 0.0883
2024-06-01 22:02:58 [INFO]: Epoch 039 - training loss: 0.3670, validation loss: 0.0848
2024-06-01 22:02:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:02:58 [INFO]: Finished training. The best model is from epoch#29.
2024-06-01 22:02:58 [INFO]: Saved the model to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_4/20240601_T220245/Crossformer.pypots
2024-06-01 22:02:58 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Crossformer_ETT_h1/round_4/imputation.pkl
2024-06-01 22:02:58 [INFO]: Round4 - Crossformer on ETT_h1: MAE=0.2370, MSE=0.1156, MRE=0.2797
2024-06-01 22:02:58 [INFO]: Done! Final results:
Averaged Crossformer (n params: 223,479) on ETT_h1: MAE=0.2323 ± 0.007605686857030311, MSE=0.1127 ± 0.004542574226029725, MRE=0.2742 ± 0.008975403106674497, average inference time=0.03
