2024-06-01 22:01:33 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:01:33 [INFO]: Using the given device: cuda:0
2024-06-01 22:01:34 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_0/20240601_T220134
2024-06-01 22:01:34 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_0/20240601_T220134/tensorboard
2024-06-01 22:01:34 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-01 22:01:40 [INFO]: Epoch 001 - training loss: 0.7454, validation loss: 0.5006
2024-06-01 22:01:43 [INFO]: Epoch 002 - training loss: 0.4161, validation loss: 0.4591
2024-06-01 22:01:46 [INFO]: Epoch 003 - training loss: 0.4395, validation loss: 0.4054
2024-06-01 22:01:49 [INFO]: Epoch 004 - training loss: 0.3875, validation loss: 0.4115
2024-06-01 22:01:52 [INFO]: Epoch 005 - training loss: 0.3192, validation loss: 0.3865
2024-06-01 22:01:55 [INFO]: Epoch 006 - training loss: 0.3322, validation loss: 0.3810
2024-06-01 22:01:58 [INFO]: Epoch 007 - training loss: 0.2829, validation loss: 0.3664
2024-06-01 22:02:01 [INFO]: Epoch 008 - training loss: 0.2944, validation loss: 0.3571
2024-06-01 22:02:04 [INFO]: Epoch 009 - training loss: 0.2936, validation loss: 0.3545
2024-06-01 22:02:07 [INFO]: Epoch 010 - training loss: 0.3407, validation loss: 0.3254
2024-06-01 22:02:10 [INFO]: Epoch 011 - training loss: 0.3029, validation loss: 0.3367
2024-06-01 22:02:13 [INFO]: Epoch 012 - training loss: 0.3156, validation loss: 0.3206
2024-06-01 22:02:16 [INFO]: Epoch 013 - training loss: 0.2402, validation loss: 0.3021
2024-06-01 22:02:19 [INFO]: Epoch 014 - training loss: 0.2724, validation loss: 0.3083
2024-06-01 22:02:22 [INFO]: Epoch 015 - training loss: 0.3086, validation loss: 0.2929
2024-06-01 22:02:25 [INFO]: Epoch 016 - training loss: 0.2914, validation loss: 0.2722
2024-06-01 22:02:28 [INFO]: Epoch 017 - training loss: 0.2750, validation loss: 0.2742
2024-06-01 22:02:30 [INFO]: Epoch 018 - training loss: 0.2919, validation loss: 0.2598
2024-06-01 22:02:33 [INFO]: Epoch 019 - training loss: 0.2204, validation loss: 0.2560
2024-06-01 22:02:36 [INFO]: Epoch 020 - training loss: 0.2650, validation loss: 0.2416
2024-06-01 22:02:39 [INFO]: Epoch 021 - training loss: 0.2314, validation loss: 0.2300
2024-06-01 22:02:42 [INFO]: Epoch 022 - training loss: 0.2733, validation loss: 0.2268
2024-06-01 22:02:45 [INFO]: Epoch 023 - training loss: 0.2504, validation loss: 0.2280
2024-06-01 22:02:48 [INFO]: Epoch 024 - training loss: 0.2419, validation loss: 0.2186
2024-06-01 22:02:51 [INFO]: Epoch 025 - training loss: 0.2482, validation loss: 0.2164
2024-06-01 22:02:54 [INFO]: Epoch 026 - training loss: 0.1888, validation loss: 0.2334
2024-06-01 22:02:57 [INFO]: Epoch 027 - training loss: 0.2795, validation loss: 0.2081
2024-06-01 22:03:00 [INFO]: Epoch 028 - training loss: 0.1955, validation loss: 0.2039
2024-06-01 22:03:02 [INFO]: Epoch 029 - training loss: 0.2271, validation loss: 0.2050
2024-06-01 22:03:04 [INFO]: Epoch 030 - training loss: 0.1807, validation loss: 0.2055
2024-06-01 22:03:06 [INFO]: Epoch 031 - training loss: 0.2212, validation loss: 0.2106
2024-06-01 22:03:08 [INFO]: Epoch 032 - training loss: 0.2024, validation loss: 0.2107
2024-06-01 22:03:10 [INFO]: Epoch 033 - training loss: 0.1863, validation loss: 0.2036
2024-06-01 22:03:12 [INFO]: Epoch 034 - training loss: 0.2168, validation loss: 0.1922
2024-06-01 22:03:13 [INFO]: Epoch 035 - training loss: 0.2209, validation loss: 0.1981
2024-06-01 22:03:15 [INFO]: Epoch 036 - training loss: 0.2076, validation loss: 0.1876
2024-06-01 22:03:17 [INFO]: Epoch 037 - training loss: 0.1972, validation loss: 0.2055
2024-06-01 22:03:19 [INFO]: Epoch 038 - training loss: 0.1798, validation loss: 0.1982
2024-06-01 22:03:21 [INFO]: Epoch 039 - training loss: 0.1800, validation loss: 0.1976
2024-06-01 22:03:23 [INFO]: Epoch 040 - training loss: 0.1688, validation loss: 0.1861
2024-06-01 22:03:25 [INFO]: Epoch 041 - training loss: 0.2538, validation loss: 0.1783
2024-06-01 22:03:26 [INFO]: Epoch 042 - training loss: 0.2356, validation loss: 0.1802
2024-06-01 22:03:28 [INFO]: Epoch 043 - training loss: 0.1906, validation loss: 0.1806
2024-06-01 22:03:30 [INFO]: Epoch 044 - training loss: 0.2210, validation loss: 0.1874
2024-06-01 22:03:32 [INFO]: Epoch 045 - training loss: 0.2194, validation loss: 0.1848
2024-06-01 22:03:34 [INFO]: Epoch 046 - training loss: 0.1910, validation loss: 0.1813
2024-06-01 22:03:36 [INFO]: Epoch 047 - training loss: 0.1906, validation loss: 0.1763
2024-06-01 22:03:38 [INFO]: Epoch 048 - training loss: 0.2123, validation loss: 0.1746
2024-06-01 22:03:40 [INFO]: Epoch 049 - training loss: 0.2292, validation loss: 0.1737
2024-06-01 22:03:42 [INFO]: Epoch 050 - training loss: 0.1948, validation loss: 0.1725
2024-06-01 22:03:44 [INFO]: Epoch 051 - training loss: 0.1813, validation loss: 0.1680
2024-06-01 22:03:46 [INFO]: Epoch 052 - training loss: 0.2548, validation loss: 0.1655
2024-06-01 22:03:48 [INFO]: Epoch 053 - training loss: 0.1807, validation loss: 0.1633
2024-06-01 22:03:50 [INFO]: Epoch 054 - training loss: 0.2041, validation loss: 0.1688
2024-06-01 22:03:52 [INFO]: Epoch 055 - training loss: 0.1355, validation loss: 0.1648
2024-06-01 22:03:54 [INFO]: Epoch 056 - training loss: 0.1881, validation loss: 0.1645
2024-06-01 22:03:56 [INFO]: Epoch 057 - training loss: 0.1963, validation loss: 0.1765
2024-06-01 22:03:58 [INFO]: Epoch 058 - training loss: 0.1837, validation loss: 0.1728
2024-06-01 22:03:59 [INFO]: Epoch 059 - training loss: 0.2054, validation loss: 0.1745
2024-06-01 22:04:01 [INFO]: Epoch 060 - training loss: 0.2008, validation loss: 0.1754
2024-06-01 22:04:03 [INFO]: Epoch 061 - training loss: 0.2019, validation loss: 0.1711
2024-06-01 22:04:05 [INFO]: Epoch 062 - training loss: 0.1913, validation loss: 0.1752
2024-06-01 22:04:07 [INFO]: Epoch 063 - training loss: 0.1579, validation loss: 0.1645
2024-06-01 22:04:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:04:07 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:04:07 [INFO]: Saved the model to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_0/20240601_T220134/CSDI.pypots
2024-06-01 22:04:21 [INFO]: Successfully saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_0/imputation.pkl
2024-06-01 22:04:21 [INFO]: Round0 - CSDI on ETT_h1: MAE=0.1571, MSE=0.0584, MRE=0.1854
2024-06-01 22:04:21 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:04:21 [INFO]: Using the given device: cuda:0
2024-06-01 22:04:21 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_1/20240601_T220421
2024-06-01 22:04:21 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_1/20240601_T220421/tensorboard
2024-06-01 22:04:21 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-01 22:04:23 [INFO]: Epoch 001 - training loss: 0.7501, validation loss: 0.4892
2024-06-01 22:04:24 [INFO]: Epoch 002 - training loss: 0.3683, validation loss: 0.4534
2024-06-01 22:04:25 [INFO]: Epoch 003 - training loss: 0.3819, validation loss: 0.3997
2024-06-01 22:04:27 [INFO]: Epoch 004 - training loss: 0.3854, validation loss: 0.3846
2024-06-01 22:04:28 [INFO]: Epoch 005 - training loss: 0.3678, validation loss: 0.3866
2024-06-01 22:04:29 [INFO]: Epoch 006 - training loss: 0.2886, validation loss: 0.3705
2024-06-01 22:04:30 [INFO]: Epoch 007 - training loss: 0.3619, validation loss: 0.3677
2024-06-01 22:04:32 [INFO]: Epoch 008 - training loss: 0.3268, validation loss: 0.3556
2024-06-01 22:04:33 [INFO]: Epoch 009 - training loss: 0.2815, validation loss: 0.3436
2024-06-01 22:04:34 [INFO]: Epoch 010 - training loss: 0.2704, validation loss: 0.3281
2024-06-01 22:04:36 [INFO]: Epoch 011 - training loss: 0.2864, validation loss: 0.3188
2024-06-01 22:04:37 [INFO]: Epoch 012 - training loss: 0.2753, validation loss: 0.3205
2024-06-01 22:04:38 [INFO]: Epoch 013 - training loss: 0.3085, validation loss: 0.2937
2024-06-01 22:04:39 [INFO]: Epoch 014 - training loss: 0.2393, validation loss: 0.2893
2024-06-01 22:04:41 [INFO]: Epoch 015 - training loss: 0.2452, validation loss: 0.2698
2024-06-01 22:04:42 [INFO]: Epoch 016 - training loss: 0.2956, validation loss: 0.2591
2024-06-01 22:04:43 [INFO]: Epoch 017 - training loss: 0.2971, validation loss: 0.2618
2024-06-01 22:04:45 [INFO]: Epoch 018 - training loss: 0.2297, validation loss: 0.2562
2024-06-01 22:04:46 [INFO]: Epoch 019 - training loss: 0.2222, validation loss: 0.2539
2024-06-01 22:04:47 [INFO]: Epoch 020 - training loss: 0.2565, validation loss: 0.2435
2024-06-01 22:04:49 [INFO]: Epoch 021 - training loss: 0.2865, validation loss: 0.2397
2024-06-01 22:04:50 [INFO]: Epoch 022 - training loss: 0.2369, validation loss: 0.2385
2024-06-01 22:04:51 [INFO]: Epoch 023 - training loss: 0.2421, validation loss: 0.2314
2024-06-01 22:04:52 [INFO]: Epoch 024 - training loss: 0.2610, validation loss: 0.2445
2024-06-01 22:04:54 [INFO]: Epoch 025 - training loss: 0.2282, validation loss: 0.2278
2024-06-01 22:04:55 [INFO]: Epoch 026 - training loss: 0.2754, validation loss: 0.2149
2024-06-01 22:04:56 [INFO]: Epoch 027 - training loss: 0.2176, validation loss: 0.2204
2024-06-01 22:04:58 [INFO]: Epoch 028 - training loss: 0.2235, validation loss: 0.2260
2024-06-01 22:04:59 [INFO]: Epoch 029 - training loss: 0.2333, validation loss: 0.2247
2024-06-01 22:05:00 [INFO]: Epoch 030 - training loss: 0.2068, validation loss: 0.2337
2024-06-01 22:05:01 [INFO]: Epoch 031 - training loss: 0.1995, validation loss: 0.2034
2024-06-01 22:05:03 [INFO]: Epoch 032 - training loss: 0.2242, validation loss: 0.1948
2024-06-01 22:05:04 [INFO]: Epoch 033 - training loss: 0.2117, validation loss: 0.1980
2024-06-01 22:05:05 [INFO]: Epoch 034 - training loss: 0.1934, validation loss: 0.2009
2024-06-01 22:05:07 [INFO]: Epoch 035 - training loss: 0.2156, validation loss: 0.1951
2024-06-01 22:05:08 [INFO]: Epoch 036 - training loss: 0.2340, validation loss: 0.1920
2024-06-01 22:05:09 [INFO]: Epoch 037 - training loss: 0.1622, validation loss: 0.1908
2024-06-01 22:05:11 [INFO]: Epoch 038 - training loss: 0.2325, validation loss: 0.1932
2024-06-01 22:05:12 [INFO]: Epoch 039 - training loss: 0.1892, validation loss: 0.1783
2024-06-01 22:05:13 [INFO]: Epoch 040 - training loss: 0.2291, validation loss: 0.1799
2024-06-01 22:05:14 [INFO]: Epoch 041 - training loss: 0.2043, validation loss: 0.1878
2024-06-01 22:05:16 [INFO]: Epoch 042 - training loss: 0.1841, validation loss: 0.1903
2024-06-01 22:05:17 [INFO]: Epoch 043 - training loss: 0.1987, validation loss: 0.1787
2024-06-01 22:05:18 [INFO]: Epoch 044 - training loss: 0.2269, validation loss: 0.1964
2024-06-01 22:05:20 [INFO]: Epoch 045 - training loss: 0.2416, validation loss: 0.1838
2024-06-01 22:05:21 [INFO]: Epoch 046 - training loss: 0.2070, validation loss: 0.1834
2024-06-01 22:05:22 [INFO]: Epoch 047 - training loss: 0.1770, validation loss: 0.1812
2024-06-01 22:05:24 [INFO]: Epoch 048 - training loss: 0.2044, validation loss: 0.1749
2024-06-01 22:05:25 [INFO]: Epoch 049 - training loss: 0.2361, validation loss: 0.1789
2024-06-01 22:05:26 [INFO]: Epoch 050 - training loss: 0.2093, validation loss: 0.1799
2024-06-01 22:05:27 [INFO]: Epoch 051 - training loss: 0.1872, validation loss: 0.1735
2024-06-01 22:05:29 [INFO]: Epoch 052 - training loss: 0.1622, validation loss: 0.1711
2024-06-01 22:05:30 [INFO]: Epoch 053 - training loss: 0.1774, validation loss: 0.1914
2024-06-01 22:05:31 [INFO]: Epoch 054 - training loss: 0.2018, validation loss: 0.1700
2024-06-01 22:05:33 [INFO]: Epoch 055 - training loss: 0.2172, validation loss: 0.1688
2024-06-01 22:05:34 [INFO]: Epoch 056 - training loss: 0.1823, validation loss: 0.1637
2024-06-01 22:05:35 [INFO]: Epoch 057 - training loss: 0.1903, validation loss: 0.1658
2024-06-01 22:05:36 [INFO]: Epoch 058 - training loss: 0.1936, validation loss: 0.1620
2024-06-01 22:05:38 [INFO]: Epoch 059 - training loss: 0.1787, validation loss: 0.1762
2024-06-01 22:05:39 [INFO]: Epoch 060 - training loss: 0.1461, validation loss: 0.1704
2024-06-01 22:05:40 [INFO]: Epoch 061 - training loss: 0.1612, validation loss: 0.1661
2024-06-01 22:05:42 [INFO]: Epoch 062 - training loss: 0.1634, validation loss: 0.1618
2024-06-01 22:05:43 [INFO]: Epoch 063 - training loss: 0.1505, validation loss: 0.1626
2024-06-01 22:05:44 [INFO]: Epoch 064 - training loss: 0.1685, validation loss: 0.1598
2024-06-01 22:05:46 [INFO]: Epoch 065 - training loss: 0.1898, validation loss: 0.1684
2024-06-01 22:05:47 [INFO]: Epoch 066 - training loss: 0.1894, validation loss: 0.1644
2024-06-01 22:05:48 [INFO]: Epoch 067 - training loss: 0.1496, validation loss: 0.1633
2024-06-01 22:05:49 [INFO]: Epoch 068 - training loss: 0.1825, validation loss: 0.1597
2024-06-01 22:05:51 [INFO]: Epoch 069 - training loss: 0.2212, validation loss: 0.1650
2024-06-01 22:05:52 [INFO]: Epoch 070 - training loss: 0.1549, validation loss: 0.1573
2024-06-01 22:05:53 [INFO]: Epoch 071 - training loss: 0.1665, validation loss: 0.1660
2024-06-01 22:05:55 [INFO]: Epoch 072 - training loss: 0.1861, validation loss: 0.1531
2024-06-01 22:05:56 [INFO]: Epoch 073 - training loss: 0.1783, validation loss: 0.1687
2024-06-01 22:05:57 [INFO]: Epoch 074 - training loss: 0.2146, validation loss: 0.1661
2024-06-01 22:05:59 [INFO]: Epoch 075 - training loss: 0.1785, validation loss: 0.1620
2024-06-01 22:06:00 [INFO]: Epoch 076 - training loss: 0.2458, validation loss: 0.1561
2024-06-01 22:06:01 [INFO]: Epoch 077 - training loss: 0.1961, validation loss: 0.1525
2024-06-01 22:06:02 [INFO]: Epoch 078 - training loss: 0.1611, validation loss: 0.1575
2024-06-01 22:06:04 [INFO]: Epoch 079 - training loss: 0.1947, validation loss: 0.1618
2024-06-01 22:06:05 [INFO]: Epoch 080 - training loss: 0.2078, validation loss: 0.1662
2024-06-01 22:06:06 [INFO]: Epoch 081 - training loss: 0.2112, validation loss: 0.1619
2024-06-01 22:06:08 [INFO]: Epoch 082 - training loss: 0.1794, validation loss: 0.1586
2024-06-01 22:06:09 [INFO]: Epoch 083 - training loss: 0.1329, validation loss: 0.1615
2024-06-01 22:06:10 [INFO]: Epoch 084 - training loss: 0.1780, validation loss: 0.1524
2024-06-01 22:06:12 [INFO]: Epoch 085 - training loss: 0.2189, validation loss: 0.1565
2024-06-01 22:06:13 [INFO]: Epoch 086 - training loss: 0.1976, validation loss: 0.1501
2024-06-01 22:06:14 [INFO]: Epoch 087 - training loss: 0.2030, validation loss: 0.1499
2024-06-01 22:06:15 [INFO]: Epoch 088 - training loss: 0.1673, validation loss: 0.1528
2024-06-01 22:06:17 [INFO]: Epoch 089 - training loss: 0.2084, validation loss: 0.1532
2024-06-01 22:06:18 [INFO]: Epoch 090 - training loss: 0.1795, validation loss: 0.1560
2024-06-01 22:06:19 [INFO]: Epoch 091 - training loss: 0.1896, validation loss: 0.1520
2024-06-01 22:06:21 [INFO]: Epoch 092 - training loss: 0.1817, validation loss: 0.1534
2024-06-01 22:06:22 [INFO]: Epoch 093 - training loss: 0.1728, validation loss: 0.1552
2024-06-01 22:06:23 [INFO]: Epoch 094 - training loss: 0.1685, validation loss: 0.1541
2024-06-01 22:06:24 [INFO]: Epoch 095 - training loss: 0.2490, validation loss: 0.1508
2024-06-01 22:06:26 [INFO]: Epoch 096 - training loss: 0.1616, validation loss: 0.1506
2024-06-01 22:06:27 [INFO]: Epoch 097 - training loss: 0.2126, validation loss: 0.1486
2024-06-01 22:06:28 [INFO]: Epoch 098 - training loss: 0.1989, validation loss: 0.1523
2024-06-01 22:06:30 [INFO]: Epoch 099 - training loss: 0.1921, validation loss: 0.1570
2024-06-01 22:06:31 [INFO]: Epoch 100 - training loss: 0.1960, validation loss: 0.1543
2024-06-01 22:06:31 [INFO]: Finished training. The best model is from epoch#97.
2024-06-01 22:06:31 [INFO]: Saved the model to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_1/20240601_T220421/CSDI.pypots
2024-06-01 22:06:41 [INFO]: Successfully saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_1/imputation.pkl
2024-06-01 22:06:41 [INFO]: Round1 - CSDI on ETT_h1: MAE=0.1365, MSE=0.0510, MRE=0.1610
2024-06-01 22:06:41 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:06:41 [INFO]: Using the given device: cuda:0
2024-06-01 22:06:41 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_2/20240601_T220641
2024-06-01 22:06:41 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_2/20240601_T220641/tensorboard
2024-06-01 22:06:41 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-01 22:06:42 [INFO]: Epoch 001 - training loss: 0.7256, validation loss: 0.5280
2024-06-01 22:06:44 [INFO]: Epoch 002 - training loss: 0.4982, validation loss: 0.4241
2024-06-01 22:06:45 [INFO]: Epoch 003 - training loss: 0.3591, validation loss: 0.3931
2024-06-01 22:06:46 [INFO]: Epoch 004 - training loss: 0.3697, validation loss: 0.3795
2024-06-01 22:06:47 [INFO]: Epoch 005 - training loss: 0.3331, validation loss: 0.3672
2024-06-01 22:06:49 [INFO]: Epoch 006 - training loss: 0.3333, validation loss: 0.3676
2024-06-01 22:06:50 [INFO]: Epoch 007 - training loss: 0.3232, validation loss: 0.3457
2024-06-01 22:06:51 [INFO]: Epoch 008 - training loss: 0.3123, validation loss: 0.3445
2024-06-01 22:06:53 [INFO]: Epoch 009 - training loss: 0.3074, validation loss: 0.3356
2024-06-01 22:06:54 [INFO]: Epoch 010 - training loss: 0.2512, validation loss: 0.3521
2024-06-01 22:06:55 [INFO]: Epoch 011 - training loss: 0.3177, validation loss: 0.3225
2024-06-01 22:06:57 [INFO]: Epoch 012 - training loss: 0.3009, validation loss: 0.3264
2024-06-01 22:06:58 [INFO]: Epoch 013 - training loss: 0.3042, validation loss: 0.2856
2024-06-01 22:06:59 [INFO]: Epoch 014 - training loss: 0.2065, validation loss: 0.2849
2024-06-01 22:07:00 [INFO]: Epoch 015 - training loss: 0.2759, validation loss: 0.2822
2024-06-01 22:07:02 [INFO]: Epoch 016 - training loss: 0.2404, validation loss: 0.2629
2024-06-01 22:07:03 [INFO]: Epoch 017 - training loss: 0.2274, validation loss: 0.2598
2024-06-01 22:07:04 [INFO]: Epoch 018 - training loss: 0.2799, validation loss: 0.2644
2024-06-01 22:07:06 [INFO]: Epoch 019 - training loss: 0.2817, validation loss: 0.2498
2024-06-01 22:07:07 [INFO]: Epoch 020 - training loss: 0.2501, validation loss: 0.2386
2024-06-01 22:07:08 [INFO]: Epoch 021 - training loss: 0.2679, validation loss: 0.2361
2024-06-01 22:07:10 [INFO]: Epoch 022 - training loss: 0.2273, validation loss: 0.2271
2024-06-01 22:07:11 [INFO]: Epoch 023 - training loss: 0.2806, validation loss: 0.2238
2024-06-01 22:07:12 [INFO]: Epoch 024 - training loss: 0.2069, validation loss: 0.2239
2024-06-01 22:07:13 [INFO]: Epoch 025 - training loss: 0.2008, validation loss: 0.2146
2024-06-01 22:07:15 [INFO]: Epoch 026 - training loss: 0.2092, validation loss: 0.2127
2024-06-01 22:07:16 [INFO]: Epoch 027 - training loss: 0.1715, validation loss: 0.2014
2024-06-01 22:07:17 [INFO]: Epoch 028 - training loss: 0.2327, validation loss: 0.2050
2024-06-01 22:07:19 [INFO]: Epoch 029 - training loss: 0.2584, validation loss: 0.2114
2024-06-01 22:07:20 [INFO]: Epoch 030 - training loss: 0.1795, validation loss: 0.2008
2024-06-01 22:07:21 [INFO]: Epoch 031 - training loss: 0.2328, validation loss: 0.1993
2024-06-01 22:07:22 [INFO]: Epoch 032 - training loss: 0.2145, validation loss: 0.1958
2024-06-01 22:07:24 [INFO]: Epoch 033 - training loss: 0.2282, validation loss: 0.2007
2024-06-01 22:07:25 [INFO]: Epoch 034 - training loss: 0.2069, validation loss: 0.1963
2024-06-01 22:07:26 [INFO]: Epoch 035 - training loss: 0.1906, validation loss: 0.1895
2024-06-01 22:07:28 [INFO]: Epoch 036 - training loss: 0.2281, validation loss: 0.1960
2024-06-01 22:07:29 [INFO]: Epoch 037 - training loss: 0.2156, validation loss: 0.1840
2024-06-01 22:07:30 [INFO]: Epoch 038 - training loss: 0.2340, validation loss: 0.1797
2024-06-01 22:07:32 [INFO]: Epoch 039 - training loss: 0.2265, validation loss: 0.1850
2024-06-01 22:07:33 [INFO]: Epoch 040 - training loss: 0.2186, validation loss: 0.1838
2024-06-01 22:07:34 [INFO]: Epoch 041 - training loss: 0.1586, validation loss: 0.1846
2024-06-01 22:07:35 [INFO]: Epoch 042 - training loss: 0.1684, validation loss: 0.1902
2024-06-01 22:07:37 [INFO]: Epoch 043 - training loss: 0.2076, validation loss: 0.1747
2024-06-01 22:07:38 [INFO]: Epoch 044 - training loss: 0.1979, validation loss: 0.1855
2024-06-01 22:07:39 [INFO]: Epoch 045 - training loss: 0.2164, validation loss: 0.1741
2024-06-01 22:07:41 [INFO]: Epoch 046 - training loss: 0.2471, validation loss: 0.1763
2024-06-01 22:07:42 [INFO]: Epoch 047 - training loss: 0.1841, validation loss: 0.1793
2024-06-01 22:07:43 [INFO]: Epoch 048 - training loss: 0.1598, validation loss: 0.1684
2024-06-01 22:07:45 [INFO]: Epoch 049 - training loss: 0.1854, validation loss: 0.1721
2024-06-01 22:07:46 [INFO]: Epoch 050 - training loss: 0.1683, validation loss: 0.1729
2024-06-01 22:07:47 [INFO]: Epoch 051 - training loss: 0.1732, validation loss: 0.1704
2024-06-01 22:07:48 [INFO]: Epoch 052 - training loss: 0.2061, validation loss: 0.1702
2024-06-01 22:07:50 [INFO]: Epoch 053 - training loss: 0.1955, validation loss: 0.1703
2024-06-01 22:07:51 [INFO]: Epoch 054 - training loss: 0.2244, validation loss: 0.1653
2024-06-01 22:07:52 [INFO]: Epoch 055 - training loss: 0.1556, validation loss: 0.1797
2024-06-01 22:07:54 [INFO]: Epoch 056 - training loss: 0.2050, validation loss: 0.1795
2024-06-01 22:07:55 [INFO]: Epoch 057 - training loss: 0.1849, validation loss: 0.1668
2024-06-01 22:07:56 [INFO]: Epoch 058 - training loss: 0.1938, validation loss: 0.1643
2024-06-01 22:07:57 [INFO]: Epoch 059 - training loss: 0.1705, validation loss: 0.1579
2024-06-01 22:07:59 [INFO]: Epoch 060 - training loss: 0.1921, validation loss: 0.1638
2024-06-01 22:08:00 [INFO]: Epoch 061 - training loss: 0.1885, validation loss: 0.1630
2024-06-01 22:08:01 [INFO]: Epoch 062 - training loss: 0.2127, validation loss: 0.1625
2024-06-01 22:08:03 [INFO]: Epoch 063 - training loss: 0.1891, validation loss: 0.1661
2024-06-01 22:08:04 [INFO]: Epoch 064 - training loss: 0.1882, validation loss: 0.1656
2024-06-01 22:08:05 [INFO]: Epoch 065 - training loss: 0.1649, validation loss: 0.1702
2024-06-01 22:08:07 [INFO]: Epoch 066 - training loss: 0.1650, validation loss: 0.1616
2024-06-01 22:08:08 [INFO]: Epoch 067 - training loss: 0.2165, validation loss: 0.1626
2024-06-01 22:08:09 [INFO]: Epoch 068 - training loss: 0.1948, validation loss: 0.1552
2024-06-01 22:08:10 [INFO]: Epoch 069 - training loss: 0.2141, validation loss: 0.1601
2024-06-01 22:08:12 [INFO]: Epoch 070 - training loss: 0.2098, validation loss: 0.1568
2024-06-01 22:08:13 [INFO]: Epoch 071 - training loss: 0.1993, validation loss: 0.1582
2024-06-01 22:08:14 [INFO]: Epoch 072 - training loss: 0.1585, validation loss: 0.1619
2024-06-01 22:08:16 [INFO]: Epoch 073 - training loss: 0.1415, validation loss: 0.1568
2024-06-01 22:08:17 [INFO]: Epoch 074 - training loss: 0.1880, validation loss: 0.1601
2024-06-01 22:08:18 [INFO]: Epoch 075 - training loss: 0.1871, validation loss: 0.1592
2024-06-01 22:08:19 [INFO]: Epoch 076 - training loss: 0.1865, validation loss: 0.1655
2024-06-01 22:08:21 [INFO]: Epoch 077 - training loss: 0.1781, validation loss: 0.1619
2024-06-01 22:08:22 [INFO]: Epoch 078 - training loss: 0.1291, validation loss: 0.1568
2024-06-01 22:08:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:08:22 [INFO]: Finished training. The best model is from epoch#68.
2024-06-01 22:08:22 [INFO]: Saved the model to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_2/20240601_T220641/CSDI.pypots
2024-06-01 22:08:32 [INFO]: Successfully saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_2/imputation.pkl
2024-06-01 22:08:32 [INFO]: Round2 - CSDI on ETT_h1: MAE=0.1497, MSE=0.0532, MRE=0.1767
2024-06-01 22:08:32 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:08:32 [INFO]: Using the given device: cuda:0
2024-06-01 22:08:32 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_3/20240601_T220832
2024-06-01 22:08:32 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_3/20240601_T220832/tensorboard
2024-06-01 22:08:32 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-01 22:08:33 [INFO]: Epoch 001 - training loss: 0.7482, validation loss: 0.4832
2024-06-01 22:08:35 [INFO]: Epoch 002 - training loss: 0.5174, validation loss: 0.4258
2024-06-01 22:08:36 [INFO]: Epoch 003 - training loss: 0.3895, validation loss: 0.3886
2024-06-01 22:08:37 [INFO]: Epoch 004 - training loss: 0.3134, validation loss: 0.3880
2024-06-01 22:08:39 [INFO]: Epoch 005 - training loss: 0.3241, validation loss: 0.3670
2024-06-01 22:08:40 [INFO]: Epoch 006 - training loss: 0.3274, validation loss: 0.3520
2024-06-01 22:08:41 [INFO]: Epoch 007 - training loss: 0.3209, validation loss: 0.3454
2024-06-01 22:08:42 [INFO]: Epoch 008 - training loss: 0.3387, validation loss: 0.3407
2024-06-01 22:08:44 [INFO]: Epoch 009 - training loss: 0.2850, validation loss: 0.3204
2024-06-01 22:08:45 [INFO]: Epoch 010 - training loss: 0.2951, validation loss: 0.3394
2024-06-01 22:08:46 [INFO]: Epoch 011 - training loss: 0.3405, validation loss: 0.3186
2024-06-01 22:08:48 [INFO]: Epoch 012 - training loss: 0.2692, validation loss: 0.2885
2024-06-01 22:08:49 [INFO]: Epoch 013 - training loss: 0.2922, validation loss: 0.2871
2024-06-01 22:08:50 [INFO]: Epoch 014 - training loss: 0.2956, validation loss: 0.2764
2024-06-01 22:08:52 [INFO]: Epoch 015 - training loss: 0.2589, validation loss: 0.2655
2024-06-01 22:08:53 [INFO]: Epoch 016 - training loss: 0.2694, validation loss: 0.2717
2024-06-01 22:08:54 [INFO]: Epoch 017 - training loss: 0.2674, validation loss: 0.2675
2024-06-01 22:08:55 [INFO]: Epoch 018 - training loss: 0.2647, validation loss: 0.2680
2024-06-01 22:08:57 [INFO]: Epoch 019 - training loss: 0.2934, validation loss: 0.2752
2024-06-01 22:08:58 [INFO]: Epoch 020 - training loss: 0.2557, validation loss: 0.2306
2024-06-01 22:08:59 [INFO]: Epoch 021 - training loss: 0.2132, validation loss: 0.2272
2024-06-01 22:09:01 [INFO]: Epoch 022 - training loss: 0.2494, validation loss: 0.2246
2024-06-01 22:09:02 [INFO]: Epoch 023 - training loss: 0.1776, validation loss: 0.2233
2024-06-01 22:09:03 [INFO]: Epoch 024 - training loss: 0.2218, validation loss: 0.2150
2024-06-01 22:09:05 [INFO]: Epoch 025 - training loss: 0.1998, validation loss: 0.2210
2024-06-01 22:09:06 [INFO]: Epoch 026 - training loss: 0.1971, validation loss: 0.2112
2024-06-01 22:09:07 [INFO]: Epoch 027 - training loss: 0.2116, validation loss: 0.2060
2024-06-01 22:09:08 [INFO]: Epoch 028 - training loss: 0.2663, validation loss: 0.2059
2024-06-01 22:09:10 [INFO]: Epoch 029 - training loss: 0.1871, validation loss: 0.2181
2024-06-01 22:09:11 [INFO]: Epoch 030 - training loss: 0.2168, validation loss: 0.2048
2024-06-01 22:09:12 [INFO]: Epoch 031 - training loss: 0.1987, validation loss: 0.1957
2024-06-01 22:09:14 [INFO]: Epoch 032 - training loss: 0.2753, validation loss: 0.1901
2024-06-01 22:09:15 [INFO]: Epoch 033 - training loss: 0.2093, validation loss: 0.1967
2024-06-01 22:09:16 [INFO]: Epoch 034 - training loss: 0.1923, validation loss: 0.1984
2024-06-01 22:09:18 [INFO]: Epoch 035 - training loss: 0.1939, validation loss: 0.2004
2024-06-01 22:09:19 [INFO]: Epoch 036 - training loss: 0.2507, validation loss: 0.2092
2024-06-01 22:09:20 [INFO]: Epoch 037 - training loss: 0.2411, validation loss: 0.1881
2024-06-01 22:09:21 [INFO]: Epoch 038 - training loss: 0.1722, validation loss: 0.1810
2024-06-01 22:09:23 [INFO]: Epoch 039 - training loss: 0.1582, validation loss: 0.1747
2024-06-01 22:09:24 [INFO]: Epoch 040 - training loss: 0.2211, validation loss: 0.1868
2024-06-01 22:09:25 [INFO]: Epoch 041 - training loss: 0.1677, validation loss: 0.1846
2024-06-01 22:09:27 [INFO]: Epoch 042 - training loss: 0.1813, validation loss: 0.1867
2024-06-01 22:09:28 [INFO]: Epoch 043 - training loss: 0.1393, validation loss: 0.2062
2024-06-01 22:09:29 [INFO]: Epoch 044 - training loss: 0.1853, validation loss: 0.1944
2024-06-01 22:09:31 [INFO]: Epoch 045 - training loss: 0.1890, validation loss: 0.1742
2024-06-01 22:09:32 [INFO]: Epoch 046 - training loss: 0.2154, validation loss: 0.1789
2024-06-01 22:09:33 [INFO]: Epoch 047 - training loss: 0.2120, validation loss: 0.1841
2024-06-01 22:09:34 [INFO]: Epoch 048 - training loss: 0.1998, validation loss: 0.1811
2024-06-01 22:09:36 [INFO]: Epoch 049 - training loss: 0.2043, validation loss: 0.1714
2024-06-01 22:09:37 [INFO]: Epoch 050 - training loss: 0.1785, validation loss: 0.1854
2024-06-01 22:09:38 [INFO]: Epoch 051 - training loss: 0.2119, validation loss: 0.1786
2024-06-01 22:09:40 [INFO]: Epoch 052 - training loss: 0.2020, validation loss: 0.1757
2024-06-01 22:09:41 [INFO]: Epoch 053 - training loss: 0.2050, validation loss: 0.1670
2024-06-01 22:09:42 [INFO]: Epoch 054 - training loss: 0.2135, validation loss: 0.1654
2024-06-01 22:09:44 [INFO]: Epoch 055 - training loss: 0.1719, validation loss: 0.1688
2024-06-01 22:09:45 [INFO]: Epoch 056 - training loss: 0.2042, validation loss: 0.1687
2024-06-01 22:09:46 [INFO]: Epoch 057 - training loss: 0.1959, validation loss: 0.1667
2024-06-01 22:09:47 [INFO]: Epoch 058 - training loss: 0.2160, validation loss: 0.1689
2024-06-01 22:09:49 [INFO]: Epoch 059 - training loss: 0.1806, validation loss: 0.1727
2024-06-01 22:09:50 [INFO]: Epoch 060 - training loss: 0.2039, validation loss: 0.1686
2024-06-01 22:09:51 [INFO]: Epoch 061 - training loss: 0.1880, validation loss: 0.1859
2024-06-01 22:09:53 [INFO]: Epoch 062 - training loss: 0.2195, validation loss: 0.1741
2024-06-01 22:09:54 [INFO]: Epoch 063 - training loss: 0.1990, validation loss: 0.1721
2024-06-01 22:09:55 [INFO]: Epoch 064 - training loss: 0.1862, validation loss: 0.1709
2024-06-01 22:09:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:09:55 [INFO]: Finished training. The best model is from epoch#54.
2024-06-01 22:09:55 [INFO]: Saved the model to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_3/20240601_T220832/CSDI.pypots
2024-06-01 22:10:05 [INFO]: Successfully saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_3/imputation.pkl
2024-06-01 22:10:05 [INFO]: Round3 - CSDI on ETT_h1: MAE=0.1615, MSE=0.0656, MRE=0.1906
2024-06-01 22:10:05 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:10:05 [INFO]: Using the given device: cuda:0
2024-06-01 22:10:05 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_4/20240601_T221005
2024-06-01 22:10:05 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_4/20240601_T221005/tensorboard
2024-06-01 22:10:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-01 22:10:07 [INFO]: Epoch 001 - training loss: 0.7455, validation loss: 0.5116
2024-06-01 22:10:08 [INFO]: Epoch 002 - training loss: 0.4531, validation loss: 0.4446
2024-06-01 22:10:09 [INFO]: Epoch 003 - training loss: 0.4083, validation loss: 0.4394
2024-06-01 22:10:10 [INFO]: Epoch 004 - training loss: 0.3482, validation loss: 0.3922
2024-06-01 22:10:12 [INFO]: Epoch 005 - training loss: 0.3604, validation loss: 0.3830
2024-06-01 22:10:13 [INFO]: Epoch 006 - training loss: 0.2957, validation loss: 0.3650
2024-06-01 22:10:14 [INFO]: Epoch 007 - training loss: 0.2843, validation loss: 0.3537
2024-06-01 22:10:16 [INFO]: Epoch 008 - training loss: 0.2908, validation loss: 0.3507
2024-06-01 22:10:17 [INFO]: Epoch 009 - training loss: 0.3279, validation loss: 0.3408
2024-06-01 22:10:18 [INFO]: Epoch 010 - training loss: 0.3198, validation loss: 0.3443
2024-06-01 22:10:19 [INFO]: Epoch 011 - training loss: 0.3190, validation loss: 0.3371
2024-06-01 22:10:21 [INFO]: Epoch 012 - training loss: 0.3046, validation loss: 0.3139
2024-06-01 22:10:22 [INFO]: Epoch 013 - training loss: 0.3132, validation loss: 0.3107
2024-06-01 22:10:23 [INFO]: Epoch 014 - training loss: 0.2511, validation loss: 0.2894
2024-06-01 22:10:25 [INFO]: Epoch 015 - training loss: 0.2746, validation loss: 0.2870
2024-06-01 22:10:26 [INFO]: Epoch 016 - training loss: 0.3171, validation loss: 0.2858
2024-06-01 22:10:27 [INFO]: Epoch 017 - training loss: 0.2750, validation loss: 0.2754
2024-06-01 22:10:29 [INFO]: Epoch 018 - training loss: 0.2841, validation loss: 0.2585
2024-06-01 22:10:30 [INFO]: Epoch 019 - training loss: 0.2206, validation loss: 0.2509
2024-06-01 22:10:31 [INFO]: Epoch 020 - training loss: 0.2877, validation loss: 0.2514
2024-06-01 22:10:32 [INFO]: Epoch 021 - training loss: 0.2601, validation loss: 0.2511
2024-06-01 22:10:34 [INFO]: Epoch 022 - training loss: 0.2521, validation loss: 0.2318
2024-06-01 22:10:35 [INFO]: Epoch 023 - training loss: 0.2203, validation loss: 0.2249
2024-06-01 22:10:36 [INFO]: Epoch 024 - training loss: 0.2509, validation loss: 0.2173
2024-06-01 22:10:38 [INFO]: Epoch 025 - training loss: 0.2505, validation loss: 0.2147
2024-06-01 22:10:39 [INFO]: Epoch 026 - training loss: 0.1715, validation loss: 0.2071
2024-06-01 22:10:40 [INFO]: Epoch 027 - training loss: 0.2766, validation loss: 0.2245
2024-06-01 22:10:42 [INFO]: Epoch 028 - training loss: 0.2284, validation loss: 0.2213
2024-06-01 22:10:43 [INFO]: Epoch 029 - training loss: 0.2670, validation loss: 0.2131
2024-06-01 22:10:44 [INFO]: Epoch 030 - training loss: 0.2181, validation loss: 0.1990
2024-06-01 22:10:45 [INFO]: Epoch 031 - training loss: 0.2342, validation loss: 0.2035
2024-06-01 22:10:47 [INFO]: Epoch 032 - training loss: 0.2125, validation loss: 0.1943
2024-06-01 22:10:48 [INFO]: Epoch 033 - training loss: 0.2073, validation loss: 0.1883
2024-06-01 22:10:49 [INFO]: Epoch 034 - training loss: 0.2124, validation loss: 0.1928
2024-06-01 22:10:51 [INFO]: Epoch 035 - training loss: 0.2272, validation loss: 0.1851
2024-06-01 22:10:52 [INFO]: Epoch 036 - training loss: 0.2110, validation loss: 0.1872
2024-06-01 22:10:53 [INFO]: Epoch 037 - training loss: 0.1908, validation loss: 0.1828
2024-06-01 22:10:54 [INFO]: Epoch 038 - training loss: 0.2240, validation loss: 0.1892
2024-06-01 22:10:56 [INFO]: Epoch 039 - training loss: 0.1905, validation loss: 0.1791
2024-06-01 22:10:57 [INFO]: Epoch 040 - training loss: 0.2116, validation loss: 0.1758
2024-06-01 22:10:58 [INFO]: Epoch 041 - training loss: 0.2040, validation loss: 0.1805
2024-06-01 22:11:00 [INFO]: Epoch 042 - training loss: 0.2690, validation loss: 0.1747
2024-06-01 22:11:01 [INFO]: Epoch 043 - training loss: 0.1761, validation loss: 0.1754
2024-06-01 22:11:02 [INFO]: Epoch 044 - training loss: 0.1926, validation loss: 0.1675
2024-06-01 22:11:04 [INFO]: Epoch 045 - training loss: 0.2302, validation loss: 0.1729
2024-06-01 22:11:05 [INFO]: Epoch 046 - training loss: 0.2179, validation loss: 0.1736
2024-06-01 22:11:06 [INFO]: Epoch 047 - training loss: 0.2157, validation loss: 0.1686
2024-06-01 22:11:07 [INFO]: Epoch 048 - training loss: 0.2230, validation loss: 0.1725
2024-06-01 22:11:09 [INFO]: Epoch 049 - training loss: 0.1856, validation loss: 0.1707
2024-06-01 22:11:10 [INFO]: Epoch 050 - training loss: 0.2070, validation loss: 0.1716
2024-06-01 22:11:11 [INFO]: Epoch 051 - training loss: 0.2150, validation loss: 0.1693
2024-06-01 22:11:13 [INFO]: Epoch 052 - training loss: 0.1522, validation loss: 0.1615
2024-06-01 22:11:14 [INFO]: Epoch 053 - training loss: 0.2116, validation loss: 0.1678
2024-06-01 22:11:15 [INFO]: Epoch 054 - training loss: 0.1813, validation loss: 0.1586
2024-06-01 22:11:17 [INFO]: Epoch 055 - training loss: 0.1700, validation loss: 0.1666
2024-06-01 22:11:18 [INFO]: Epoch 056 - training loss: 0.1799, validation loss: 0.1709
2024-06-01 22:11:19 [INFO]: Epoch 057 - training loss: 0.1844, validation loss: 0.1686
2024-06-01 22:11:20 [INFO]: Epoch 058 - training loss: 0.1643, validation loss: 0.1701
2024-06-01 22:11:22 [INFO]: Epoch 059 - training loss: 0.2437, validation loss: 0.1750
2024-06-01 22:11:23 [INFO]: Epoch 060 - training loss: 0.2326, validation loss: 0.1741
2024-06-01 22:11:24 [INFO]: Epoch 061 - training loss: 0.2092, validation loss: 0.1814
2024-06-01 22:11:26 [INFO]: Epoch 062 - training loss: 0.2201, validation loss: 0.1649
2024-06-01 22:11:27 [INFO]: Epoch 063 - training loss: 0.2073, validation loss: 0.1646
2024-06-01 22:11:28 [INFO]: Epoch 064 - training loss: 0.1960, validation loss: 0.1596
2024-06-01 22:11:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:11:28 [INFO]: Finished training. The best model is from epoch#54.
2024-06-01 22:11:28 [INFO]: Saved the model to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_4/20240601_T221005/CSDI.pypots
2024-06-01 22:11:38 [INFO]: Successfully saved to results_point_rate01/ETT_h1/CSDI_ETT_h1/round_4/imputation.pkl
2024-06-01 22:11:38 [INFO]: Round4 - CSDI on ETT_h1: MAE=0.1504, MSE=0.0566, MRE=0.1775
2024-06-01 22:11:38 [INFO]: Done! Final results:
Averaged CSDI (n params: 1,194,993) on ETT_h1: MAE=0.1510 ± 0.00849590271089862, MSE=0.0570 ± 0.005013932293382639, MRE=0.1782 ± 0.010025938882156091, average inference time=10.71
