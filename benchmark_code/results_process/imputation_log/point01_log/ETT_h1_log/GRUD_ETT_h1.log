2024-06-01 22:17:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:17:23 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:24 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_0/20240601_T221724
2024-06-01 22:17:24 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_0/20240601_T221724/tensorboard
2024-06-01 22:17:24 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-01 22:17:26 [INFO]: Epoch 001 - training loss: 0.6772, validation loss: 0.5866
2024-06-01 22:17:27 [INFO]: Epoch 002 - training loss: 0.3307, validation loss: 0.3908
2024-06-01 22:17:27 [INFO]: Epoch 003 - training loss: 0.2380, validation loss: 0.2566
2024-06-01 22:17:28 [INFO]: Epoch 004 - training loss: 0.1983, validation loss: 0.2503
2024-06-01 22:17:29 [INFO]: Epoch 005 - training loss: 0.1787, validation loss: 0.2229
2024-06-01 22:17:30 [INFO]: Epoch 006 - training loss: 0.1655, validation loss: 0.2162
2024-06-01 22:17:30 [INFO]: Epoch 007 - training loss: 0.1587, validation loss: 0.2124
2024-06-01 22:17:31 [INFO]: Epoch 008 - training loss: 0.1535, validation loss: 0.1902
2024-06-01 22:17:32 [INFO]: Epoch 009 - training loss: 0.1477, validation loss: 0.1979
2024-06-01 22:17:32 [INFO]: Epoch 010 - training loss: 0.1436, validation loss: 0.1842
2024-06-01 22:17:33 [INFO]: Epoch 011 - training loss: 0.1395, validation loss: 0.1762
2024-06-01 22:17:34 [INFO]: Epoch 012 - training loss: 0.1351, validation loss: 0.1832
2024-06-01 22:17:34 [INFO]: Epoch 013 - training loss: 0.1321, validation loss: 0.1776
2024-06-01 22:17:35 [INFO]: Epoch 014 - training loss: 0.1305, validation loss: 0.1822
2024-06-01 22:17:35 [INFO]: Epoch 015 - training loss: 0.1279, validation loss: 0.1806
2024-06-01 22:17:36 [INFO]: Epoch 016 - training loss: 0.1258, validation loss: 0.1763
2024-06-01 22:17:37 [INFO]: Epoch 017 - training loss: 0.1270, validation loss: 0.1865
2024-06-01 22:17:37 [INFO]: Epoch 018 - training loss: 0.1285, validation loss: 0.1720
2024-06-01 22:17:38 [INFO]: Epoch 019 - training loss: 0.1274, validation loss: 0.1741
2024-06-01 22:17:39 [INFO]: Epoch 020 - training loss: 0.1232, validation loss: 0.1703
2024-06-01 22:17:39 [INFO]: Epoch 021 - training loss: 0.1208, validation loss: 0.1745
2024-06-01 22:17:40 [INFO]: Epoch 022 - training loss: 0.1199, validation loss: 0.1681
2024-06-01 22:17:41 [INFO]: Epoch 023 - training loss: 0.1175, validation loss: 0.1680
2024-06-01 22:17:41 [INFO]: Epoch 024 - training loss: 0.1173, validation loss: 0.1717
2024-06-01 22:17:42 [INFO]: Epoch 025 - training loss: 0.1179, validation loss: 0.1868
2024-06-01 22:17:43 [INFO]: Epoch 026 - training loss: 0.1146, validation loss: 0.1753
2024-06-01 22:17:43 [INFO]: Epoch 027 - training loss: 0.1132, validation loss: 0.1726
2024-06-01 22:17:44 [INFO]: Epoch 028 - training loss: 0.1108, validation loss: 0.1653
2024-06-01 22:17:44 [INFO]: Epoch 029 - training loss: 0.1092, validation loss: 0.1703
2024-06-01 22:17:44 [INFO]: Epoch 030 - training loss: 0.1102, validation loss: 0.1750
2024-06-01 22:17:45 [INFO]: Epoch 031 - training loss: 0.1098, validation loss: 0.1731
2024-06-01 22:17:45 [INFO]: Epoch 032 - training loss: 0.1083, validation loss: 0.1746
2024-06-01 22:17:46 [INFO]: Epoch 033 - training loss: 0.1066, validation loss: 0.1668
2024-06-01 22:17:46 [INFO]: Epoch 034 - training loss: 0.1044, validation loss: 0.1686
2024-06-01 22:17:47 [INFO]: Epoch 035 - training loss: 0.1027, validation loss: 0.1596
2024-06-01 22:17:47 [INFO]: Epoch 036 - training loss: 0.1024, validation loss: 0.1679
2024-06-01 22:17:48 [INFO]: Epoch 037 - training loss: 0.0988, validation loss: 0.1674
2024-06-01 22:17:48 [INFO]: Epoch 038 - training loss: 0.0994, validation loss: 0.1636
2024-06-01 22:17:49 [INFO]: Epoch 039 - training loss: 0.0976, validation loss: 0.1669
2024-06-01 22:17:49 [INFO]: Epoch 040 - training loss: 0.0990, validation loss: 0.1675
2024-06-01 22:17:50 [INFO]: Epoch 041 - training loss: 0.0982, validation loss: 0.1810
2024-06-01 22:17:50 [INFO]: Epoch 042 - training loss: 0.0968, validation loss: 0.1671
2024-06-01 22:17:51 [INFO]: Epoch 043 - training loss: 0.0954, validation loss: 0.1686
2024-06-01 22:17:51 [INFO]: Epoch 044 - training loss: 0.0943, validation loss: 0.1612
2024-06-01 22:17:51 [INFO]: Epoch 045 - training loss: 0.0955, validation loss: 0.1817
2024-06-01 22:17:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:17:51 [INFO]: Finished training. The best model is from epoch#35.
2024-06-01 22:17:51 [INFO]: Saved the model to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_0/20240601_T221724/GRUD.pypots
2024-06-01 22:17:51 [INFO]: Successfully saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_0/imputation.pkl
2024-06-01 22:17:51 [INFO]: Round0 - GRUD on ETT_h1: MAE=0.3319, MSE=0.2316, MRE=0.3916
2024-06-01 22:17:51 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:17:51 [INFO]: Using the given device: cuda:0
2024-06-01 22:17:52 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_1/20240601_T221751
2024-06-01 22:17:52 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_1/20240601_T221751/tensorboard
2024-06-01 22:17:52 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-01 22:17:53 [INFO]: Epoch 001 - training loss: 0.7010, validation loss: 0.6138
2024-06-01 22:17:53 [INFO]: Epoch 002 - training loss: 0.3494, validation loss: 0.3370
2024-06-01 22:17:54 [INFO]: Epoch 003 - training loss: 0.2418, validation loss: 0.2525
2024-06-01 22:17:54 [INFO]: Epoch 004 - training loss: 0.2069, validation loss: 0.2687
2024-06-01 22:17:55 [INFO]: Epoch 005 - training loss: 0.1822, validation loss: 0.2263
2024-06-01 22:17:56 [INFO]: Epoch 006 - training loss: 0.1693, validation loss: 0.2276
2024-06-01 22:17:56 [INFO]: Epoch 007 - training loss: 0.1605, validation loss: 0.2080
2024-06-01 22:17:57 [INFO]: Epoch 008 - training loss: 0.1558, validation loss: 0.2220
2024-06-01 22:17:57 [INFO]: Epoch 009 - training loss: 0.1494, validation loss: 0.1960
2024-06-01 22:17:58 [INFO]: Epoch 010 - training loss: 0.1457, validation loss: 0.1988
2024-06-01 22:17:58 [INFO]: Epoch 011 - training loss: 0.1411, validation loss: 0.1919
2024-06-01 22:17:59 [INFO]: Epoch 012 - training loss: 0.1389, validation loss: 0.1868
2024-06-01 22:18:00 [INFO]: Epoch 013 - training loss: 0.1369, validation loss: 0.1880
2024-06-01 22:18:01 [INFO]: Epoch 014 - training loss: 0.1337, validation loss: 0.1840
2024-06-01 22:18:01 [INFO]: Epoch 015 - training loss: 0.1322, validation loss: 0.1826
2024-06-01 22:18:01 [INFO]: Epoch 016 - training loss: 0.1300, validation loss: 0.1800
2024-06-01 22:18:02 [INFO]: Epoch 017 - training loss: 0.1301, validation loss: 0.1841
2024-06-01 22:18:02 [INFO]: Epoch 018 - training loss: 0.1261, validation loss: 0.1817
2024-06-01 22:18:03 [INFO]: Epoch 019 - training loss: 0.1242, validation loss: 0.1874
2024-06-01 22:18:03 [INFO]: Epoch 020 - training loss: 0.1221, validation loss: 0.1812
2024-06-01 22:18:04 [INFO]: Epoch 021 - training loss: 0.1214, validation loss: 0.1755
2024-06-01 22:18:05 [INFO]: Epoch 022 - training loss: 0.1203, validation loss: 0.1906
2024-06-01 22:18:05 [INFO]: Epoch 023 - training loss: 0.1193, validation loss: 0.1962
2024-06-01 22:18:06 [INFO]: Epoch 024 - training loss: 0.1181, validation loss: 0.1689
2024-06-01 22:18:06 [INFO]: Epoch 025 - training loss: 0.1147, validation loss: 0.1764
2024-06-01 22:18:07 [INFO]: Epoch 026 - training loss: 0.1141, validation loss: 0.1683
2024-06-01 22:18:07 [INFO]: Epoch 027 - training loss: 0.1128, validation loss: 0.1809
2024-06-01 22:18:08 [INFO]: Epoch 028 - training loss: 0.1118, validation loss: 0.1662
2024-06-01 22:18:08 [INFO]: Epoch 029 - training loss: 0.1099, validation loss: 0.1781
2024-06-01 22:18:08 [INFO]: Epoch 030 - training loss: 0.1080, validation loss: 0.1705
2024-06-01 22:18:09 [INFO]: Epoch 031 - training loss: 0.1086, validation loss: 0.1618
2024-06-01 22:18:09 [INFO]: Epoch 032 - training loss: 0.1110, validation loss: 0.1671
2024-06-01 22:18:10 [INFO]: Epoch 033 - training loss: 0.1090, validation loss: 0.1733
2024-06-01 22:18:10 [INFO]: Epoch 034 - training loss: 0.1078, validation loss: 0.1789
2024-06-01 22:18:10 [INFO]: Epoch 035 - training loss: 0.1052, validation loss: 0.1687
2024-06-01 22:18:11 [INFO]: Epoch 036 - training loss: 0.1041, validation loss: 0.1604
2024-06-01 22:18:11 [INFO]: Epoch 037 - training loss: 0.1008, validation loss: 0.1665
2024-06-01 22:18:12 [INFO]: Epoch 038 - training loss: 0.1003, validation loss: 0.1621
2024-06-01 22:18:12 [INFO]: Epoch 039 - training loss: 0.0988, validation loss: 0.1680
2024-06-01 22:18:13 [INFO]: Epoch 040 - training loss: 0.0992, validation loss: 0.1627
2024-06-01 22:18:13 [INFO]: Epoch 041 - training loss: 0.0990, validation loss: 0.1629
2024-06-01 22:18:14 [INFO]: Epoch 042 - training loss: 0.0984, validation loss: 0.1630
2024-06-01 22:18:14 [INFO]: Epoch 043 - training loss: 0.0976, validation loss: 0.1524
2024-06-01 22:18:15 [INFO]: Epoch 044 - training loss: 0.0984, validation loss: 0.1584
2024-06-01 22:18:15 [INFO]: Epoch 045 - training loss: 0.0967, validation loss: 0.1728
2024-06-01 22:18:16 [INFO]: Epoch 046 - training loss: 0.0964, validation loss: 0.1739
2024-06-01 22:18:17 [INFO]: Epoch 047 - training loss: 0.0951, validation loss: 0.1566
2024-06-01 22:18:17 [INFO]: Epoch 048 - training loss: 0.0931, validation loss: 0.1645
2024-06-01 22:18:18 [INFO]: Epoch 049 - training loss: 0.0928, validation loss: 0.1611
2024-06-01 22:18:18 [INFO]: Epoch 050 - training loss: 0.0914, validation loss: 0.1583
2024-06-01 22:18:18 [INFO]: Epoch 051 - training loss: 0.0886, validation loss: 0.1594
2024-06-01 22:18:19 [INFO]: Epoch 052 - training loss: 0.0877, validation loss: 0.1662
2024-06-01 22:18:19 [INFO]: Epoch 053 - training loss: 0.0878, validation loss: 0.1649
2024-06-01 22:18:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:19 [INFO]: Finished training. The best model is from epoch#43.
2024-06-01 22:18:19 [INFO]: Saved the model to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_1/20240601_T221751/GRUD.pypots
2024-06-01 22:18:20 [INFO]: Successfully saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_1/imputation.pkl
2024-06-01 22:18:20 [INFO]: Round1 - GRUD on ETT_h1: MAE=0.3208, MSE=0.2232, MRE=0.3786
2024-06-01 22:18:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:18:20 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:20 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_2/20240601_T221820
2024-06-01 22:18:20 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_2/20240601_T221820/tensorboard
2024-06-01 22:18:20 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-01 22:18:21 [INFO]: Epoch 001 - training loss: 0.6264, validation loss: 0.5468
2024-06-01 22:18:21 [INFO]: Epoch 002 - training loss: 0.3366, validation loss: 0.3272
2024-06-01 22:18:22 [INFO]: Epoch 003 - training loss: 0.2305, validation loss: 0.2811
2024-06-01 22:18:22 [INFO]: Epoch 004 - training loss: 0.1941, validation loss: 0.2471
2024-06-01 22:18:23 [INFO]: Epoch 005 - training loss: 0.1716, validation loss: 0.2049
2024-06-01 22:18:24 [INFO]: Epoch 006 - training loss: 0.1605, validation loss: 0.2163
2024-06-01 22:18:24 [INFO]: Epoch 007 - training loss: 0.1546, validation loss: 0.2086
2024-06-01 22:18:24 [INFO]: Epoch 008 - training loss: 0.1475, validation loss: 0.1874
2024-06-01 22:18:25 [INFO]: Epoch 009 - training loss: 0.1430, validation loss: 0.1974
2024-06-01 22:18:25 [INFO]: Epoch 010 - training loss: 0.1408, validation loss: 0.1807
2024-06-01 22:18:26 [INFO]: Epoch 011 - training loss: 0.1378, validation loss: 0.1897
2024-06-01 22:18:26 [INFO]: Epoch 012 - training loss: 0.1369, validation loss: 0.1794
2024-06-01 22:18:27 [INFO]: Epoch 013 - training loss: 0.1333, validation loss: 0.1772
2024-06-01 22:18:27 [INFO]: Epoch 014 - training loss: 0.1304, validation loss: 0.1909
2024-06-01 22:18:28 [INFO]: Epoch 015 - training loss: 0.1277, validation loss: 0.1769
2024-06-01 22:18:28 [INFO]: Epoch 016 - training loss: 0.1250, validation loss: 0.1757
2024-06-01 22:18:29 [INFO]: Epoch 017 - training loss: 0.1236, validation loss: 0.1735
2024-06-01 22:18:30 [INFO]: Epoch 018 - training loss: 0.1211, validation loss: 0.1674
2024-06-01 22:18:30 [INFO]: Epoch 019 - training loss: 0.1213, validation loss: 0.1788
2024-06-01 22:18:31 [INFO]: Epoch 020 - training loss: 0.1214, validation loss: 0.1721
2024-06-01 22:18:31 [INFO]: Epoch 021 - training loss: 0.1174, validation loss: 0.1647
2024-06-01 22:18:32 [INFO]: Epoch 022 - training loss: 0.1151, validation loss: 0.1658
2024-06-01 22:18:32 [INFO]: Epoch 023 - training loss: 0.1138, validation loss: 0.1667
2024-06-01 22:18:33 [INFO]: Epoch 024 - training loss: 0.1131, validation loss: 0.1609
2024-06-01 22:18:33 [INFO]: Epoch 025 - training loss: 0.1137, validation loss: 0.1608
2024-06-01 22:18:33 [INFO]: Epoch 026 - training loss: 0.1105, validation loss: 0.1634
2024-06-01 22:18:34 [INFO]: Epoch 027 - training loss: 0.1101, validation loss: 0.1667
2024-06-01 22:18:34 [INFO]: Epoch 028 - training loss: 0.1104, validation loss: 0.1615
2024-06-01 22:18:34 [INFO]: Epoch 029 - training loss: 0.1065, validation loss: 0.1687
2024-06-01 22:18:35 [INFO]: Epoch 030 - training loss: 0.1080, validation loss: 0.1616
2024-06-01 22:18:35 [INFO]: Epoch 031 - training loss: 0.1086, validation loss: 0.1616
2024-06-01 22:18:35 [INFO]: Epoch 032 - training loss: 0.1061, validation loss: 0.1671
2024-06-01 22:18:36 [INFO]: Epoch 033 - training loss: 0.1034, validation loss: 0.1602
2024-06-01 22:18:36 [INFO]: Epoch 034 - training loss: 0.1019, validation loss: 0.1528
2024-06-01 22:18:36 [INFO]: Epoch 035 - training loss: 0.1007, validation loss: 0.1608
2024-06-01 22:18:37 [INFO]: Epoch 036 - training loss: 0.1000, validation loss: 0.1561
2024-06-01 22:18:37 [INFO]: Epoch 037 - training loss: 0.0998, validation loss: 0.1524
2024-06-01 22:18:37 [INFO]: Epoch 038 - training loss: 0.0989, validation loss: 0.1544
2024-06-01 22:18:38 [INFO]: Epoch 039 - training loss: 0.0959, validation loss: 0.1546
2024-06-01 22:18:38 [INFO]: Epoch 040 - training loss: 0.0964, validation loss: 0.1490
2024-06-01 22:18:39 [INFO]: Epoch 041 - training loss: 0.0944, validation loss: 0.1590
2024-06-01 22:18:39 [INFO]: Epoch 042 - training loss: 0.0950, validation loss: 0.1603
2024-06-01 22:18:39 [INFO]: Epoch 043 - training loss: 0.0966, validation loss: 0.1678
2024-06-01 22:18:40 [INFO]: Epoch 044 - training loss: 0.0994, validation loss: 0.1587
2024-06-01 22:18:40 [INFO]: Epoch 045 - training loss: 0.0979, validation loss: 0.1625
2024-06-01 22:18:40 [INFO]: Epoch 046 - training loss: 0.0956, validation loss: 0.1500
2024-06-01 22:18:41 [INFO]: Epoch 047 - training loss: 0.0926, validation loss: 0.1493
2024-06-01 22:18:41 [INFO]: Epoch 048 - training loss: 0.0912, validation loss: 0.1545
2024-06-01 22:18:41 [INFO]: Epoch 049 - training loss: 0.0912, validation loss: 0.1522
2024-06-01 22:18:42 [INFO]: Epoch 050 - training loss: 0.0903, validation loss: 0.1579
2024-06-01 22:18:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:18:42 [INFO]: Finished training. The best model is from epoch#40.
2024-06-01 22:18:42 [INFO]: Saved the model to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_2/20240601_T221820/GRUD.pypots
2024-06-01 22:18:42 [INFO]: Successfully saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_2/imputation.pkl
2024-06-01 22:18:42 [INFO]: Round2 - GRUD on ETT_h1: MAE=0.3243, MSE=0.2196, MRE=0.3826
2024-06-01 22:18:42 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:18:42 [INFO]: Using the given device: cuda:0
2024-06-01 22:18:42 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_3/20240601_T221842
2024-06-01 22:18:42 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_3/20240601_T221842/tensorboard
2024-06-01 22:18:42 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-01 22:18:42 [INFO]: Epoch 001 - training loss: 0.6335, validation loss: 0.5364
2024-06-01 22:18:43 [INFO]: Epoch 002 - training loss: 0.2906, validation loss: 0.2959
2024-06-01 22:18:43 [INFO]: Epoch 003 - training loss: 0.2221, validation loss: 0.2783
2024-06-01 22:18:43 [INFO]: Epoch 004 - training loss: 0.1878, validation loss: 0.2567
2024-06-01 22:18:44 [INFO]: Epoch 005 - training loss: 0.1710, validation loss: 0.2185
2024-06-01 22:18:44 [INFO]: Epoch 006 - training loss: 0.1598, validation loss: 0.2096
2024-06-01 22:18:44 [INFO]: Epoch 007 - training loss: 0.1543, validation loss: 0.1978
2024-06-01 22:18:45 [INFO]: Epoch 008 - training loss: 0.1488, validation loss: 0.1900
2024-06-01 22:18:45 [INFO]: Epoch 009 - training loss: 0.1443, validation loss: 0.1852
2024-06-01 22:18:45 [INFO]: Epoch 010 - training loss: 0.1405, validation loss: 0.1780
2024-06-01 22:18:46 [INFO]: Epoch 011 - training loss: 0.1365, validation loss: 0.1827
2024-06-01 22:18:46 [INFO]: Epoch 012 - training loss: 0.1339, validation loss: 0.1769
2024-06-01 22:18:46 [INFO]: Epoch 013 - training loss: 0.1315, validation loss: 0.1812
2024-06-01 22:18:47 [INFO]: Epoch 014 - training loss: 0.1295, validation loss: 0.1849
2024-06-01 22:18:47 [INFO]: Epoch 015 - training loss: 0.1280, validation loss: 0.1715
2024-06-01 22:18:48 [INFO]: Epoch 016 - training loss: 0.1278, validation loss: 0.1704
2024-06-01 22:18:48 [INFO]: Epoch 017 - training loss: 0.1243, validation loss: 0.1719
2024-06-01 22:18:48 [INFO]: Epoch 018 - training loss: 0.1199, validation loss: 0.1825
2024-06-01 22:18:49 [INFO]: Epoch 019 - training loss: 0.1200, validation loss: 0.1767
2024-06-01 22:18:49 [INFO]: Epoch 020 - training loss: 0.1185, validation loss: 0.1849
2024-06-01 22:18:49 [INFO]: Epoch 021 - training loss: 0.1184, validation loss: 0.1650
2024-06-01 22:18:50 [INFO]: Epoch 022 - training loss: 0.1165, validation loss: 0.1768
2024-06-01 22:18:50 [INFO]: Epoch 023 - training loss: 0.1139, validation loss: 0.1654
2024-06-01 22:18:50 [INFO]: Epoch 024 - training loss: 0.1127, validation loss: 0.1627
2024-06-01 22:18:51 [INFO]: Epoch 025 - training loss: 0.1136, validation loss: 0.1625
2024-06-01 22:18:51 [INFO]: Epoch 026 - training loss: 0.1117, validation loss: 0.1902
2024-06-01 22:18:51 [INFO]: Epoch 027 - training loss: 0.1121, validation loss: 0.1743
2024-06-01 22:18:52 [INFO]: Epoch 028 - training loss: 0.1094, validation loss: 0.1637
2024-06-01 22:18:52 [INFO]: Epoch 029 - training loss: 0.1058, validation loss: 0.1614
2024-06-01 22:18:52 [INFO]: Epoch 030 - training loss: 0.1063, validation loss: 0.1671
2024-06-01 22:18:53 [INFO]: Epoch 031 - training loss: 0.1035, validation loss: 0.1653
2024-06-01 22:18:53 [INFO]: Epoch 032 - training loss: 0.1025, validation loss: 0.1682
2024-06-01 22:18:53 [INFO]: Epoch 033 - training loss: 0.1015, validation loss: 0.1600
2024-06-01 22:18:54 [INFO]: Epoch 034 - training loss: 0.1022, validation loss: 0.1563
2024-06-01 22:18:54 [INFO]: Epoch 035 - training loss: 0.1012, validation loss: 0.1642
2024-06-01 22:18:55 [INFO]: Epoch 036 - training loss: 0.1016, validation loss: 0.1592
2024-06-01 22:18:55 [INFO]: Epoch 037 - training loss: 0.1013, validation loss: 0.1583
2024-06-01 22:18:55 [INFO]: Epoch 038 - training loss: 0.1004, validation loss: 0.1529
2024-06-01 22:18:56 [INFO]: Epoch 039 - training loss: 0.1014, validation loss: 0.1636
2024-06-01 22:18:56 [INFO]: Epoch 040 - training loss: 0.0988, validation loss: 0.1565
2024-06-01 22:18:56 [INFO]: Epoch 041 - training loss: 0.0964, validation loss: 0.1621
2024-06-01 22:18:57 [INFO]: Epoch 042 - training loss: 0.0948, validation loss: 0.1529
2024-06-01 22:18:57 [INFO]: Epoch 043 - training loss: 0.0936, validation loss: 0.1493
2024-06-01 22:18:57 [INFO]: Epoch 044 - training loss: 0.0931, validation loss: 0.1612
2024-06-01 22:18:58 [INFO]: Epoch 045 - training loss: 0.0919, validation loss: 0.1585
2024-06-01 22:18:58 [INFO]: Epoch 046 - training loss: 0.0905, validation loss: 0.1656
2024-06-01 22:18:58 [INFO]: Epoch 047 - training loss: 0.0892, validation loss: 0.1590
2024-06-01 22:18:58 [INFO]: Epoch 048 - training loss: 0.0898, validation loss: 0.1580
2024-06-01 22:18:58 [INFO]: Epoch 049 - training loss: 0.0905, validation loss: 0.1618
2024-06-01 22:18:59 [INFO]: Epoch 050 - training loss: 0.0904, validation loss: 0.1492
2024-06-01 22:18:59 [INFO]: Epoch 051 - training loss: 0.0905, validation loss: 0.1599
2024-06-01 22:18:59 [INFO]: Epoch 052 - training loss: 0.0877, validation loss: 0.1575
2024-06-01 22:18:59 [INFO]: Epoch 053 - training loss: 0.0852, validation loss: 0.1539
2024-06-01 22:18:59 [INFO]: Epoch 054 - training loss: 0.0831, validation loss: 0.1626
2024-06-01 22:19:00 [INFO]: Epoch 055 - training loss: 0.0836, validation loss: 0.1554
2024-06-01 22:19:00 [INFO]: Epoch 056 - training loss: 0.0841, validation loss: 0.1698
2024-06-01 22:19:00 [INFO]: Epoch 057 - training loss: 0.0861, validation loss: 0.1561
2024-06-01 22:19:00 [INFO]: Epoch 058 - training loss: 0.0831, validation loss: 0.1506
2024-06-01 22:19:00 [INFO]: Epoch 059 - training loss: 0.0804, validation loss: 0.1574
2024-06-01 22:19:01 [INFO]: Epoch 060 - training loss: 0.0789, validation loss: 0.1537
2024-06-01 22:19:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:01 [INFO]: Finished training. The best model is from epoch#50.
2024-06-01 22:19:01 [INFO]: Saved the model to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_3/20240601_T221842/GRUD.pypots
2024-06-01 22:19:01 [INFO]: Successfully saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_3/imputation.pkl
2024-06-01 22:19:01 [INFO]: Round3 - GRUD on ETT_h1: MAE=0.3237, MSE=0.2233, MRE=0.3820
2024-06-01 22:19:01 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:19:01 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:01 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_4/20240601_T221901
2024-06-01 22:19:01 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_4/20240601_T221901/tensorboard
2024-06-01 22:19:01 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-01 22:19:01 [INFO]: Epoch 001 - training loss: 0.6804, validation loss: 0.6037
2024-06-01 22:19:01 [INFO]: Epoch 002 - training loss: 0.3373, validation loss: 0.3206
2024-06-01 22:19:01 [INFO]: Epoch 003 - training loss: 0.2322, validation loss: 0.2964
2024-06-01 22:19:02 [INFO]: Epoch 004 - training loss: 0.1955, validation loss: 0.2416
2024-06-01 22:19:02 [INFO]: Epoch 005 - training loss: 0.1773, validation loss: 0.2278
2024-06-01 22:19:02 [INFO]: Epoch 006 - training loss: 0.1642, validation loss: 0.2124
2024-06-01 22:19:02 [INFO]: Epoch 007 - training loss: 0.1573, validation loss: 0.2151
2024-06-01 22:19:02 [INFO]: Epoch 008 - training loss: 0.1510, validation loss: 0.1954
2024-06-01 22:19:03 [INFO]: Epoch 009 - training loss: 0.1474, validation loss: 0.1987
2024-06-01 22:19:03 [INFO]: Epoch 010 - training loss: 0.1437, validation loss: 0.1901
2024-06-01 22:19:03 [INFO]: Epoch 011 - training loss: 0.1399, validation loss: 0.2001
2024-06-01 22:19:03 [INFO]: Epoch 012 - training loss: 0.1384, validation loss: 0.1924
2024-06-01 22:19:03 [INFO]: Epoch 013 - training loss: 0.1358, validation loss: 0.1837
2024-06-01 22:19:04 [INFO]: Epoch 014 - training loss: 0.1323, validation loss: 0.1799
2024-06-01 22:19:04 [INFO]: Epoch 015 - training loss: 0.1295, validation loss: 0.1763
2024-06-01 22:19:04 [INFO]: Epoch 016 - training loss: 0.1275, validation loss: 0.1828
2024-06-01 22:19:04 [INFO]: Epoch 017 - training loss: 0.1285, validation loss: 0.1767
2024-06-01 22:19:04 [INFO]: Epoch 018 - training loss: 0.1276, validation loss: 0.1818
2024-06-01 22:19:05 [INFO]: Epoch 019 - training loss: 0.1251, validation loss: 0.1763
2024-06-01 22:19:05 [INFO]: Epoch 020 - training loss: 0.1219, validation loss: 0.1760
2024-06-01 22:19:05 [INFO]: Epoch 021 - training loss: 0.1201, validation loss: 0.1710
2024-06-01 22:19:05 [INFO]: Epoch 022 - training loss: 0.1182, validation loss: 0.1709
2024-06-01 22:19:05 [INFO]: Epoch 023 - training loss: 0.1180, validation loss: 0.1760
2024-06-01 22:19:06 [INFO]: Epoch 024 - training loss: 0.1175, validation loss: 0.1809
2024-06-01 22:19:06 [INFO]: Epoch 025 - training loss: 0.1164, validation loss: 0.1747
2024-06-01 22:19:06 [INFO]: Epoch 026 - training loss: 0.1157, validation loss: 0.1746
2024-06-01 22:19:06 [INFO]: Epoch 027 - training loss: 0.1142, validation loss: 0.1740
2024-06-01 22:19:06 [INFO]: Epoch 028 - training loss: 0.1132, validation loss: 0.1678
2024-06-01 22:19:07 [INFO]: Epoch 029 - training loss: 0.1090, validation loss: 0.1687
2024-06-01 22:19:07 [INFO]: Epoch 030 - training loss: 0.1072, validation loss: 0.1674
2024-06-01 22:19:07 [INFO]: Epoch 031 - training loss: 0.1054, validation loss: 0.1670
2024-06-01 22:19:07 [INFO]: Epoch 032 - training loss: 0.1042, validation loss: 0.1702
2024-06-01 22:19:07 [INFO]: Epoch 033 - training loss: 0.1026, validation loss: 0.1758
2024-06-01 22:19:08 [INFO]: Epoch 034 - training loss: 0.1019, validation loss: 0.1655
2024-06-01 22:19:08 [INFO]: Epoch 035 - training loss: 0.1017, validation loss: 0.1768
2024-06-01 22:19:08 [INFO]: Epoch 036 - training loss: 0.1018, validation loss: 0.1607
2024-06-01 22:19:08 [INFO]: Epoch 037 - training loss: 0.1027, validation loss: 0.1725
2024-06-01 22:19:08 [INFO]: Epoch 038 - training loss: 0.1011, validation loss: 0.1819
2024-06-01 22:19:09 [INFO]: Epoch 039 - training loss: 0.1002, validation loss: 0.1607
2024-06-01 22:19:09 [INFO]: Epoch 040 - training loss: 0.0983, validation loss: 0.1683
2024-06-01 22:19:09 [INFO]: Epoch 041 - training loss: 0.0959, validation loss: 0.1663
2024-06-01 22:19:09 [INFO]: Epoch 042 - training loss: 0.0970, validation loss: 0.1625
2024-06-01 22:19:10 [INFO]: Epoch 043 - training loss: 0.0941, validation loss: 0.1740
2024-06-01 22:19:10 [INFO]: Epoch 044 - training loss: 0.0936, validation loss: 0.1696
2024-06-01 22:19:10 [INFO]: Epoch 045 - training loss: 0.0975, validation loss: 0.1856
2024-06-01 22:19:10 [INFO]: Epoch 046 - training loss: 0.0973, validation loss: 0.1695
2024-06-01 22:19:10 [INFO]: Epoch 047 - training loss: 0.0939, validation loss: 0.1795
2024-06-01 22:19:11 [INFO]: Epoch 048 - training loss: 0.0916, validation loss: 0.1744
2024-06-01 22:19:11 [INFO]: Epoch 049 - training loss: 0.0895, validation loss: 0.1757
2024-06-01 22:19:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:19:11 [INFO]: Finished training. The best model is from epoch#39.
2024-06-01 22:19:11 [INFO]: Saved the model to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_4/20240601_T221901/GRUD.pypots
2024-06-01 22:19:11 [INFO]: Successfully saved to results_point_rate01/ETT_h1/GRUD_ETT_h1/round_4/imputation.pkl
2024-06-01 22:19:11 [INFO]: Round4 - GRUD on ETT_h1: MAE=0.3230, MSE=0.2273, MRE=0.3812
2024-06-01 22:19:11 [INFO]: Done! Final results:
Averaged GRUD (n params: 409,407) on ETT_h1: MAE=0.3247 ± 0.003752845317086076, MSE=0.2250 ± 0.004084319267555887, MRE=0.3832 ± 0.004428699228749858, average inference time=0.14
