2024-06-01 22:22:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:22:13 [INFO]: Using the given device: cuda:0
2024-06-01 22:22:13 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_0/20240601_T222213
2024-06-01 22:22:13 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_0/20240601_T222213/tensorboard
2024-06-01 22:22:14 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-01 22:22:17 [INFO]: Epoch 001 - training loss: 1.5212, validation loss: 1.0456
2024-06-01 22:22:19 [INFO]: Epoch 002 - training loss: 1.4094, validation loss: 0.9502
2024-06-01 22:22:21 [INFO]: Epoch 003 - training loss: 1.1799, validation loss: 0.6063
2024-06-01 22:22:23 [INFO]: Epoch 004 - training loss: 0.8793, validation loss: 0.4509
2024-06-01 22:22:25 [INFO]: Epoch 005 - training loss: 0.7820, validation loss: 0.3893
2024-06-01 22:22:27 [INFO]: Epoch 006 - training loss: 0.7354, validation loss: 0.3228
2024-06-01 22:22:29 [INFO]: Epoch 007 - training loss: 0.7041, validation loss: 0.2692
2024-06-01 22:22:31 [INFO]: Epoch 008 - training loss: 0.6538, validation loss: 0.2579
2024-06-01 22:22:33 [INFO]: Epoch 009 - training loss: 0.6331, validation loss: 0.2326
2024-06-01 22:22:35 [INFO]: Epoch 010 - training loss: 0.6043, validation loss: 0.2449
2024-06-01 22:22:37 [INFO]: Epoch 011 - training loss: 0.5998, validation loss: 0.2144
2024-06-01 22:22:39 [INFO]: Epoch 012 - training loss: 0.5803, validation loss: 0.1958
2024-06-01 22:22:41 [INFO]: Epoch 013 - training loss: 0.5746, validation loss: 0.2183
2024-06-01 22:22:44 [INFO]: Epoch 014 - training loss: 0.5670, validation loss: 0.2037
2024-06-01 22:22:46 [INFO]: Epoch 015 - training loss: 0.5751, validation loss: 0.2029
2024-06-01 22:22:48 [INFO]: Epoch 016 - training loss: 0.5629, validation loss: 0.1933
2024-06-01 22:22:50 [INFO]: Epoch 017 - training loss: 0.5562, validation loss: 0.2062
2024-06-01 22:22:52 [INFO]: Epoch 018 - training loss: 0.5501, validation loss: 0.1793
2024-06-01 22:22:54 [INFO]: Epoch 019 - training loss: 0.5472, validation loss: 0.1884
2024-06-01 22:22:56 [INFO]: Epoch 020 - training loss: 0.5398, validation loss: 0.2055
2024-06-01 22:22:58 [INFO]: Epoch 021 - training loss: 0.5380, validation loss: 0.1874
2024-06-01 22:23:00 [INFO]: Epoch 022 - training loss: 0.5294, validation loss: 0.1652
2024-06-01 22:23:02 [INFO]: Epoch 023 - training loss: 0.5162, validation loss: 0.1635
2024-06-01 22:23:04 [INFO]: Epoch 024 - training loss: 0.5021, validation loss: 0.1669
2024-06-01 22:23:06 [INFO]: Epoch 025 - training loss: 0.4782, validation loss: 0.1595
2024-06-01 22:23:08 [INFO]: Epoch 026 - training loss: 0.4677, validation loss: 0.1550
2024-06-01 22:23:11 [INFO]: Epoch 027 - training loss: 0.4574, validation loss: 0.1522
2024-06-01 22:23:13 [INFO]: Epoch 028 - training loss: 0.4540, validation loss: 0.1628
2024-06-01 22:23:15 [INFO]: Epoch 029 - training loss: 0.4526, validation loss: 0.1453
2024-06-01 22:23:17 [INFO]: Epoch 030 - training loss: 0.4496, validation loss: 0.1599
2024-06-01 22:23:19 [INFO]: Epoch 031 - training loss: 0.4418, validation loss: 0.1429
2024-06-01 22:23:21 [INFO]: Epoch 032 - training loss: 0.4365, validation loss: 0.1498
2024-06-01 22:23:23 [INFO]: Epoch 033 - training loss: 0.4322, validation loss: 0.1454
2024-06-01 22:23:25 [INFO]: Epoch 034 - training loss: 0.4357, validation loss: 0.1400
2024-06-01 22:23:27 [INFO]: Epoch 035 - training loss: 0.4297, validation loss: 0.1341
2024-06-01 22:23:29 [INFO]: Epoch 036 - training loss: 0.4270, validation loss: 0.1338
2024-06-01 22:23:31 [INFO]: Epoch 037 - training loss: 0.4184, validation loss: 0.1411
2024-06-01 22:23:33 [INFO]: Epoch 038 - training loss: 0.4223, validation loss: 0.1464
2024-06-01 22:23:35 [INFO]: Epoch 039 - training loss: 0.4122, validation loss: 0.1332
2024-06-01 22:23:37 [INFO]: Epoch 040 - training loss: 0.4118, validation loss: 0.1327
2024-06-01 22:23:39 [INFO]: Epoch 041 - training loss: 0.4122, validation loss: 0.1285
2024-06-01 22:23:41 [INFO]: Epoch 042 - training loss: 0.4065, validation loss: 0.1322
2024-06-01 22:23:43 [INFO]: Epoch 043 - training loss: 0.4000, validation loss: 0.1275
2024-06-01 22:23:45 [INFO]: Epoch 044 - training loss: 0.3927, validation loss: 0.1218
2024-06-01 22:23:47 [INFO]: Epoch 045 - training loss: 0.3913, validation loss: 0.1163
2024-06-01 22:23:49 [INFO]: Epoch 046 - training loss: 0.3902, validation loss: 0.1283
2024-06-01 22:23:51 [INFO]: Epoch 047 - training loss: 0.3923, validation loss: 0.1115
2024-06-01 22:23:53 [INFO]: Epoch 048 - training loss: 0.3905, validation loss: 0.1250
2024-06-01 22:23:55 [INFO]: Epoch 049 - training loss: 0.3856, validation loss: 0.1108
2024-06-01 22:23:57 [INFO]: Epoch 050 - training loss: 0.3863, validation loss: 0.1257
2024-06-01 22:23:59 [INFO]: Epoch 051 - training loss: 0.3838, validation loss: 0.1154
2024-06-01 22:24:01 [INFO]: Epoch 052 - training loss: 0.3872, validation loss: 0.1141
2024-06-01 22:24:03 [INFO]: Epoch 053 - training loss: 0.3832, validation loss: 0.1196
2024-06-01 22:24:05 [INFO]: Epoch 054 - training loss: 0.3784, validation loss: 0.1239
2024-06-01 22:24:07 [INFO]: Epoch 055 - training loss: 0.3740, validation loss: 0.1121
2024-06-01 22:24:09 [INFO]: Epoch 056 - training loss: 0.3803, validation loss: 0.1240
2024-06-01 22:24:11 [INFO]: Epoch 057 - training loss: 0.3743, validation loss: 0.1165
2024-06-01 22:24:13 [INFO]: Epoch 058 - training loss: 0.3767, validation loss: 0.1203
2024-06-01 22:24:15 [INFO]: Epoch 059 - training loss: 0.3692, validation loss: 0.1131
2024-06-01 22:24:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:24:15 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:24:15 [INFO]: Saved the model to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_0/20240601_T222213/StemGNN.pypots
2024-06-01 22:24:16 [INFO]: Successfully saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_0/imputation.pkl
2024-06-01 22:24:16 [INFO]: Round0 - StemGNN on ETT_h1: MAE=0.2624, MSE=0.1432, MRE=0.3096
2024-06-01 22:24:16 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:24:16 [INFO]: Using the given device: cuda:0
2024-06-01 22:24:16 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_1/20240601_T222416
2024-06-01 22:24:16 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_1/20240601_T222416/tensorboard
2024-06-01 22:24:16 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-01 22:24:18 [INFO]: Epoch 001 - training loss: 1.5210, validation loss: 1.0321
2024-06-01 22:24:20 [INFO]: Epoch 002 - training loss: 1.3728, validation loss: 0.8615
2024-06-01 22:24:22 [INFO]: Epoch 003 - training loss: 1.0599, validation loss: 0.6033
2024-06-01 22:24:24 [INFO]: Epoch 004 - training loss: 0.8713, validation loss: 0.4250
2024-06-01 22:24:26 [INFO]: Epoch 005 - training loss: 0.7911, validation loss: 0.3533
2024-06-01 22:24:28 [INFO]: Epoch 006 - training loss: 0.7332, validation loss: 0.2797
2024-06-01 22:24:30 [INFO]: Epoch 007 - training loss: 0.6741, validation loss: 0.2168
2024-06-01 22:24:32 [INFO]: Epoch 008 - training loss: 0.6379, validation loss: 0.2185
2024-06-01 22:24:34 [INFO]: Epoch 009 - training loss: 0.6180, validation loss: 0.1931
2024-06-01 22:24:36 [INFO]: Epoch 010 - training loss: 0.6089, validation loss: 0.1816
2024-06-01 22:24:38 [INFO]: Epoch 011 - training loss: 0.5844, validation loss: 0.1825
2024-06-01 22:24:40 [INFO]: Epoch 012 - training loss: 0.5696, validation loss: 0.1701
2024-06-01 22:24:43 [INFO]: Epoch 013 - training loss: 0.5639, validation loss: 0.1816
2024-06-01 22:24:45 [INFO]: Epoch 014 - training loss: 0.5583, validation loss: 0.1653
2024-06-01 22:24:47 [INFO]: Epoch 015 - training loss: 0.5439, validation loss: 0.1655
2024-06-01 22:24:49 [INFO]: Epoch 016 - training loss: 0.5363, validation loss: 0.1684
2024-06-01 22:24:51 [INFO]: Epoch 017 - training loss: 0.5184, validation loss: 0.1580
2024-06-01 22:24:53 [INFO]: Epoch 018 - training loss: 0.5106, validation loss: 0.1474
2024-06-01 22:24:55 [INFO]: Epoch 019 - training loss: 0.4902, validation loss: 0.1456
2024-06-01 22:24:57 [INFO]: Epoch 020 - training loss: 0.4868, validation loss: 0.1426
2024-06-01 22:24:59 [INFO]: Epoch 021 - training loss: 0.4706, validation loss: 0.1411
2024-06-01 22:25:01 [INFO]: Epoch 022 - training loss: 0.4629, validation loss: 0.1311
2024-06-01 22:25:04 [INFO]: Epoch 023 - training loss: 0.4547, validation loss: 0.1284
2024-06-01 22:25:06 [INFO]: Epoch 024 - training loss: 0.4470, validation loss: 0.1284
2024-06-01 22:25:08 [INFO]: Epoch 025 - training loss: 0.4432, validation loss: 0.1233
2024-06-01 22:25:09 [INFO]: Epoch 026 - training loss: 0.4338, validation loss: 0.1209
2024-06-01 22:25:11 [INFO]: Epoch 027 - training loss: 0.4328, validation loss: 0.1197
2024-06-01 22:25:13 [INFO]: Epoch 028 - training loss: 0.4313, validation loss: 0.1212
2024-06-01 22:25:15 [INFO]: Epoch 029 - training loss: 0.4277, validation loss: 0.1138
2024-06-01 22:25:17 [INFO]: Epoch 030 - training loss: 0.4201, validation loss: 0.1222
2024-06-01 22:25:19 [INFO]: Epoch 031 - training loss: 0.4189, validation loss: 0.1204
2024-06-01 22:25:21 [INFO]: Epoch 032 - training loss: 0.4231, validation loss: 0.1114
2024-06-01 22:25:23 [INFO]: Epoch 033 - training loss: 0.4206, validation loss: 0.1155
2024-06-01 22:25:25 [INFO]: Epoch 034 - training loss: 0.4122, validation loss: 0.1155
2024-06-01 22:25:27 [INFO]: Epoch 035 - training loss: 0.4071, validation loss: 0.1060
2024-06-01 22:25:29 [INFO]: Epoch 036 - training loss: 0.4067, validation loss: 0.1178
2024-06-01 22:25:31 [INFO]: Epoch 037 - training loss: 0.3981, validation loss: 0.1003
2024-06-01 22:25:33 [INFO]: Epoch 038 - training loss: 0.3938, validation loss: 0.1003
2024-06-01 22:25:35 [INFO]: Epoch 039 - training loss: 0.3954, validation loss: 0.1152
2024-06-01 22:25:38 [INFO]: Epoch 040 - training loss: 0.3912, validation loss: 0.1020
2024-06-01 22:25:40 [INFO]: Epoch 041 - training loss: 0.3912, validation loss: 0.1040
2024-06-01 22:25:42 [INFO]: Epoch 042 - training loss: 0.3866, validation loss: 0.1126
2024-06-01 22:25:44 [INFO]: Epoch 043 - training loss: 0.3827, validation loss: 0.0998
2024-06-01 22:25:46 [INFO]: Epoch 044 - training loss: 0.3788, validation loss: 0.0983
2024-06-01 22:25:48 [INFO]: Epoch 045 - training loss: 0.3790, validation loss: 0.0923
2024-06-01 22:25:50 [INFO]: Epoch 046 - training loss: 0.3651, validation loss: 0.0951
2024-06-01 22:25:52 [INFO]: Epoch 047 - training loss: 0.3761, validation loss: 0.0929
2024-06-01 22:25:54 [INFO]: Epoch 048 - training loss: 0.3699, validation loss: 0.0959
2024-06-01 22:25:56 [INFO]: Epoch 049 - training loss: 0.3727, validation loss: 0.1016
2024-06-01 22:25:58 [INFO]: Epoch 050 - training loss: 0.3692, validation loss: 0.0949
2024-06-01 22:26:00 [INFO]: Epoch 051 - training loss: 0.3674, validation loss: 0.0949
2024-06-01 22:26:02 [INFO]: Epoch 052 - training loss: 0.3677, validation loss: 0.0982
2024-06-01 22:26:04 [INFO]: Epoch 053 - training loss: 0.3655, validation loss: 0.0903
2024-06-01 22:26:06 [INFO]: Epoch 054 - training loss: 0.3634, validation loss: 0.0905
2024-06-01 22:26:08 [INFO]: Epoch 055 - training loss: 0.3695, validation loss: 0.0933
2024-06-01 22:26:10 [INFO]: Epoch 056 - training loss: 0.3633, validation loss: 0.1013
2024-06-01 22:26:12 [INFO]: Epoch 057 - training loss: 0.3630, validation loss: 0.0883
2024-06-01 22:26:14 [INFO]: Epoch 058 - training loss: 0.3605, validation loss: 0.0883
2024-06-01 22:26:16 [INFO]: Epoch 059 - training loss: 0.3579, validation loss: 0.0928
2024-06-01 22:26:18 [INFO]: Epoch 060 - training loss: 0.3517, validation loss: 0.0884
2024-06-01 22:26:20 [INFO]: Epoch 061 - training loss: 0.3580, validation loss: 0.0982
2024-06-01 22:26:22 [INFO]: Epoch 062 - training loss: 0.3551, validation loss: 0.0951
2024-06-01 22:26:24 [INFO]: Epoch 063 - training loss: 0.3558, validation loss: 0.0857
2024-06-01 22:26:26 [INFO]: Epoch 064 - training loss: 0.3534, validation loss: 0.0900
2024-06-01 22:26:28 [INFO]: Epoch 065 - training loss: 0.3564, validation loss: 0.0887
2024-06-01 22:26:30 [INFO]: Epoch 066 - training loss: 0.3524, validation loss: 0.0851
2024-06-01 22:26:32 [INFO]: Epoch 067 - training loss: 0.3497, validation loss: 0.0913
2024-06-01 22:26:34 [INFO]: Epoch 068 - training loss: 0.3499, validation loss: 0.0889
2024-06-01 22:26:36 [INFO]: Epoch 069 - training loss: 0.3482, validation loss: 0.0956
2024-06-01 22:26:38 [INFO]: Epoch 070 - training loss: 0.3601, validation loss: 0.1049
2024-06-01 22:26:40 [INFO]: Epoch 071 - training loss: 0.4494, validation loss: 0.1076
2024-06-01 22:26:42 [INFO]: Epoch 072 - training loss: 0.4454, validation loss: 0.1165
2024-06-01 22:26:44 [INFO]: Epoch 073 - training loss: 0.4098, validation loss: 0.1045
2024-06-01 22:26:46 [INFO]: Epoch 074 - training loss: 0.3881, validation loss: 0.0998
2024-06-01 22:26:48 [INFO]: Epoch 075 - training loss: 0.3757, validation loss: 0.0953
2024-06-01 22:26:51 [INFO]: Epoch 076 - training loss: 0.3743, validation loss: 0.0913
2024-06-01 22:26:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:26:51 [INFO]: Finished training. The best model is from epoch#66.
2024-06-01 22:26:51 [INFO]: Saved the model to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_1/20240601_T222416/StemGNN.pypots
2024-06-01 22:26:51 [INFO]: Successfully saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_1/imputation.pkl
2024-06-01 22:26:51 [INFO]: Round1 - StemGNN on ETT_h1: MAE=0.2452, MSE=0.1216, MRE=0.2893
2024-06-01 22:26:51 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:26:51 [INFO]: Using the given device: cuda:0
2024-06-01 22:26:51 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_2/20240601_T222651
2024-06-01 22:26:51 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_2/20240601_T222651/tensorboard
2024-06-01 22:26:51 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-01 22:26:53 [INFO]: Epoch 001 - training loss: 1.5053, validation loss: 0.9583
2024-06-01 22:26:55 [INFO]: Epoch 002 - training loss: 1.1471, validation loss: 0.5953
2024-06-01 22:26:57 [INFO]: Epoch 003 - training loss: 0.8974, validation loss: 0.4163
2024-06-01 22:26:59 [INFO]: Epoch 004 - training loss: 0.8201, validation loss: 0.3960
2024-06-01 22:27:01 [INFO]: Epoch 005 - training loss: 0.7597, validation loss: 0.3278
2024-06-01 22:27:03 [INFO]: Epoch 006 - training loss: 0.7207, validation loss: 0.2605
2024-06-01 22:27:05 [INFO]: Epoch 007 - training loss: 0.6702, validation loss: 0.2503
2024-06-01 22:27:08 [INFO]: Epoch 008 - training loss: 0.6627, validation loss: 0.2160
2024-06-01 22:27:10 [INFO]: Epoch 009 - training loss: 0.6522, validation loss: 0.2008
2024-06-01 22:27:12 [INFO]: Epoch 010 - training loss: 0.6394, validation loss: 0.2098
2024-06-01 22:27:14 [INFO]: Epoch 011 - training loss: 0.6165, validation loss: 0.1809
2024-06-01 22:27:16 [INFO]: Epoch 012 - training loss: 0.6041, validation loss: 0.1797
2024-06-01 22:27:18 [INFO]: Epoch 013 - training loss: 0.5780, validation loss: 0.1875
2024-06-01 22:27:20 [INFO]: Epoch 014 - training loss: 0.5652, validation loss: 0.1691
2024-06-01 22:27:22 [INFO]: Epoch 015 - training loss: 0.5392, validation loss: 0.1657
2024-06-01 22:27:24 [INFO]: Epoch 016 - training loss: 0.5257, validation loss: 0.1528
2024-06-01 22:27:26 [INFO]: Epoch 017 - training loss: 0.5200, validation loss: 0.1454
2024-06-01 22:27:28 [INFO]: Epoch 018 - training loss: 0.5013, validation loss: 0.1521
2024-06-01 22:27:30 [INFO]: Epoch 019 - training loss: 0.4943, validation loss: 0.1474
2024-06-01 22:27:32 [INFO]: Epoch 020 - training loss: 0.4870, validation loss: 0.1501
2024-06-01 22:27:34 [INFO]: Epoch 021 - training loss: 0.4829, validation loss: 0.1428
2024-06-01 22:27:36 [INFO]: Epoch 022 - training loss: 0.4855, validation loss: 0.1388
2024-06-01 22:27:38 [INFO]: Epoch 023 - training loss: 0.4770, validation loss: 0.1362
2024-06-01 22:27:40 [INFO]: Epoch 024 - training loss: 0.4661, validation loss: 0.1297
2024-06-01 22:27:42 [INFO]: Epoch 025 - training loss: 0.4528, validation loss: 0.1277
2024-06-01 22:27:45 [INFO]: Epoch 026 - training loss: 0.4549, validation loss: 0.1305
2024-06-01 22:27:47 [INFO]: Epoch 027 - training loss: 0.4496, validation loss: 0.1312
2024-06-01 22:27:49 [INFO]: Epoch 028 - training loss: 0.4432, validation loss: 0.1225
2024-06-01 22:27:51 [INFO]: Epoch 029 - training loss: 0.4376, validation loss: 0.1258
2024-06-01 22:27:53 [INFO]: Epoch 030 - training loss: 0.4332, validation loss: 0.1193
2024-06-01 22:27:55 [INFO]: Epoch 031 - training loss: 0.4281, validation loss: 0.1243
2024-06-01 22:27:57 [INFO]: Epoch 032 - training loss: 0.4203, validation loss: 0.1248
2024-06-01 22:27:59 [INFO]: Epoch 033 - training loss: 0.4191, validation loss: 0.1191
2024-06-01 22:28:01 [INFO]: Epoch 034 - training loss: 0.4133, validation loss: 0.1195
2024-06-01 22:28:03 [INFO]: Epoch 035 - training loss: 0.4180, validation loss: 0.1087
2024-06-01 22:28:05 [INFO]: Epoch 036 - training loss: 0.4183, validation loss: 0.1209
2024-06-01 22:28:07 [INFO]: Epoch 037 - training loss: 0.4138, validation loss: 0.1296
2024-06-01 22:28:09 [INFO]: Epoch 038 - training loss: 0.4148, validation loss: 0.1091
2024-06-01 22:28:11 [INFO]: Epoch 039 - training loss: 0.4045, validation loss: 0.1211
2024-06-01 22:28:13 [INFO]: Epoch 040 - training loss: 0.4088, validation loss: 0.1111
2024-06-01 22:28:16 [INFO]: Epoch 041 - training loss: 0.3984, validation loss: 0.1088
2024-06-01 22:28:18 [INFO]: Epoch 042 - training loss: 0.4024, validation loss: 0.1227
2024-06-01 22:28:19 [INFO]: Epoch 043 - training loss: 0.4053, validation loss: 0.1073
2024-06-01 22:28:21 [INFO]: Epoch 044 - training loss: 0.3938, validation loss: 0.1132
2024-06-01 22:28:23 [INFO]: Epoch 045 - training loss: 0.3998, validation loss: 0.1118
2024-06-01 22:28:25 [INFO]: Epoch 046 - training loss: 0.3976, validation loss: 0.1099
2024-06-01 22:28:27 [INFO]: Epoch 047 - training loss: 0.3921, validation loss: 0.1173
2024-06-01 22:28:29 [INFO]: Epoch 048 - training loss: 0.3931, validation loss: 0.1012
2024-06-01 22:28:31 [INFO]: Epoch 049 - training loss: 0.3943, validation loss: 0.1056
2024-06-01 22:28:33 [INFO]: Epoch 050 - training loss: 0.3940, validation loss: 0.1023
2024-06-01 22:28:35 [INFO]: Epoch 051 - training loss: 0.4003, validation loss: 0.1224
2024-06-01 22:28:37 [INFO]: Epoch 052 - training loss: 0.3927, validation loss: 0.1129
2024-06-01 22:28:39 [INFO]: Epoch 053 - training loss: 0.3922, validation loss: 0.1069
2024-06-01 22:28:41 [INFO]: Epoch 054 - training loss: 0.3841, validation loss: 0.1175
2024-06-01 22:28:44 [INFO]: Epoch 055 - training loss: 0.3811, validation loss: 0.1053
2024-06-01 22:28:46 [INFO]: Epoch 056 - training loss: 0.3832, validation loss: 0.1064
2024-06-01 22:28:48 [INFO]: Epoch 057 - training loss: 0.3785, validation loss: 0.1086
2024-06-01 22:28:50 [INFO]: Epoch 058 - training loss: 0.3799, validation loss: 0.0998
2024-06-01 22:28:52 [INFO]: Epoch 059 - training loss: 0.3768, validation loss: 0.1104
2024-06-01 22:28:54 [INFO]: Epoch 060 - training loss: 0.3796, validation loss: 0.1001
2024-06-01 22:28:56 [INFO]: Epoch 061 - training loss: 0.3815, validation loss: 0.1011
2024-06-01 22:28:58 [INFO]: Epoch 062 - training loss: 0.3748, validation loss: 0.1055
2024-06-01 22:29:00 [INFO]: Epoch 063 - training loss: 0.3718, validation loss: 0.1032
2024-06-01 22:29:02 [INFO]: Epoch 064 - training loss: 0.3702, validation loss: 0.1005
2024-06-01 22:29:04 [INFO]: Epoch 065 - training loss: 0.3715, validation loss: 0.1030
2024-06-01 22:29:06 [INFO]: Epoch 066 - training loss: 0.3737, validation loss: 0.1044
2024-06-01 22:29:09 [INFO]: Epoch 067 - training loss: 0.3689, validation loss: 0.1009
2024-06-01 22:29:11 [INFO]: Epoch 068 - training loss: 0.3660, validation loss: 0.0991
2024-06-01 22:29:13 [INFO]: Epoch 069 - training loss: 0.3638, validation loss: 0.1032
2024-06-01 22:29:15 [INFO]: Epoch 070 - training loss: 0.3682, validation loss: 0.1042
2024-06-01 22:29:17 [INFO]: Epoch 071 - training loss: 0.3695, validation loss: 0.1040
2024-06-01 22:29:19 [INFO]: Epoch 072 - training loss: 0.3679, validation loss: 0.1022
2024-06-01 22:29:21 [INFO]: Epoch 073 - training loss: 0.3623, validation loss: 0.1004
2024-06-01 22:29:23 [INFO]: Epoch 074 - training loss: 0.3683, validation loss: 0.0999
2024-06-01 22:29:25 [INFO]: Epoch 075 - training loss: 0.3609, validation loss: 0.1001
2024-06-01 22:29:27 [INFO]: Epoch 076 - training loss: 0.3632, validation loss: 0.1030
2024-06-01 22:29:29 [INFO]: Epoch 077 - training loss: 0.3669, validation loss: 0.1079
2024-06-01 22:29:31 [INFO]: Epoch 078 - training loss: 0.3602, validation loss: 0.1011
2024-06-01 22:29:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:29:31 [INFO]: Finished training. The best model is from epoch#68.
2024-06-01 22:29:31 [INFO]: Saved the model to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_2/20240601_T222651/StemGNN.pypots
2024-06-01 22:29:32 [INFO]: Successfully saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_2/imputation.pkl
2024-06-01 22:29:32 [INFO]: Round2 - StemGNN on ETT_h1: MAE=0.2543, MSE=0.1272, MRE=0.3000
2024-06-01 22:29:32 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:29:32 [INFO]: Using the given device: cuda:0
2024-06-01 22:29:32 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_3/20240601_T222932
2024-06-01 22:29:32 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_3/20240601_T222932/tensorboard
2024-06-01 22:29:32 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-01 22:29:34 [INFO]: Epoch 001 - training loss: 1.5169, validation loss: 1.0780
2024-06-01 22:29:36 [INFO]: Epoch 002 - training loss: 1.4240, validation loss: 1.0555
2024-06-01 22:29:38 [INFO]: Epoch 003 - training loss: 1.1572, validation loss: 0.6490
2024-06-01 22:29:40 [INFO]: Epoch 004 - training loss: 0.9014, validation loss: 0.4600
2024-06-01 22:29:42 [INFO]: Epoch 005 - training loss: 0.8345, validation loss: 0.4303
2024-06-01 22:29:43 [INFO]: Epoch 006 - training loss: 0.8040, validation loss: 0.4331
2024-06-01 22:29:45 [INFO]: Epoch 007 - training loss: 0.7827, validation loss: 0.4432
2024-06-01 22:29:47 [INFO]: Epoch 008 - training loss: 0.7760, validation loss: 0.4017
2024-06-01 22:29:49 [INFO]: Epoch 009 - training loss: 0.7672, validation loss: 0.3819
2024-06-01 22:29:51 [INFO]: Epoch 010 - training loss: 0.7333, validation loss: 0.3641
2024-06-01 22:29:52 [INFO]: Epoch 011 - training loss: 0.7097, validation loss: 0.3033
2024-06-01 22:29:54 [INFO]: Epoch 012 - training loss: 0.6841, validation loss: 0.2585
2024-06-01 22:29:56 [INFO]: Epoch 013 - training loss: 0.6690, validation loss: 0.2234
2024-06-01 22:29:58 [INFO]: Epoch 014 - training loss: 0.6457, validation loss: 0.2139
2024-06-01 22:30:00 [INFO]: Epoch 015 - training loss: 0.6221, validation loss: 0.1988
2024-06-01 22:30:01 [INFO]: Epoch 016 - training loss: 0.5858, validation loss: 0.1801
2024-06-01 22:30:03 [INFO]: Epoch 017 - training loss: 0.5706, validation loss: 0.1706
2024-06-01 22:30:05 [INFO]: Epoch 018 - training loss: 0.5510, validation loss: 0.1571
2024-06-01 22:30:07 [INFO]: Epoch 019 - training loss: 0.5329, validation loss: 0.1530
2024-06-01 22:30:08 [INFO]: Epoch 020 - training loss: 0.5203, validation loss: 0.1627
2024-06-01 22:30:09 [INFO]: Epoch 021 - training loss: 0.5103, validation loss: 0.1499
2024-06-01 22:30:10 [INFO]: Epoch 022 - training loss: 0.5084, validation loss: 0.1604
2024-06-01 22:30:11 [INFO]: Epoch 023 - training loss: 0.5056, validation loss: 0.1553
2024-06-01 22:30:12 [INFO]: Epoch 024 - training loss: 0.5005, validation loss: 0.1441
2024-06-01 22:30:13 [INFO]: Epoch 025 - training loss: 0.4920, validation loss: 0.1452
2024-06-01 22:30:14 [INFO]: Epoch 026 - training loss: 0.4861, validation loss: 0.1552
2024-06-01 22:30:15 [INFO]: Epoch 027 - training loss: 0.4843, validation loss: 0.1670
2024-06-01 22:30:16 [INFO]: Epoch 028 - training loss: 0.5021, validation loss: 0.1547
2024-06-01 22:30:17 [INFO]: Epoch 029 - training loss: 0.4844, validation loss: 0.1502
2024-06-01 22:30:18 [INFO]: Epoch 030 - training loss: 0.4758, validation loss: 0.1335
2024-06-01 22:30:19 [INFO]: Epoch 031 - training loss: 0.4725, validation loss: 0.1360
2024-06-01 22:30:20 [INFO]: Epoch 032 - training loss: 0.4696, validation loss: 0.1360
2024-06-01 22:30:21 [INFO]: Epoch 033 - training loss: 0.4631, validation loss: 0.1390
2024-06-01 22:30:22 [INFO]: Epoch 034 - training loss: 0.4610, validation loss: 0.1378
2024-06-01 22:30:23 [INFO]: Epoch 035 - training loss: 0.4504, validation loss: 0.1298
2024-06-01 22:30:24 [INFO]: Epoch 036 - training loss: 0.4487, validation loss: 0.1217
2024-06-01 22:30:25 [INFO]: Epoch 037 - training loss: 0.4381, validation loss: 0.1232
2024-06-01 22:30:25 [INFO]: Epoch 038 - training loss: 0.4371, validation loss: 0.1206
2024-06-01 22:30:26 [INFO]: Epoch 039 - training loss: 0.4296, validation loss: 0.1160
2024-06-01 22:30:27 [INFO]: Epoch 040 - training loss: 0.4278, validation loss: 0.1120
2024-06-01 22:30:28 [INFO]: Epoch 041 - training loss: 0.4226, validation loss: 0.1125
2024-06-01 22:30:29 [INFO]: Epoch 042 - training loss: 0.4255, validation loss: 0.1074
2024-06-01 22:30:30 [INFO]: Epoch 043 - training loss: 0.4242, validation loss: 0.1138
2024-06-01 22:30:31 [INFO]: Epoch 044 - training loss: 0.4228, validation loss: 0.1129
2024-06-01 22:30:32 [INFO]: Epoch 045 - training loss: 0.4170, validation loss: 0.1165
2024-06-01 22:30:33 [INFO]: Epoch 046 - training loss: 0.4144, validation loss: 0.1134
2024-06-01 22:30:34 [INFO]: Epoch 047 - training loss: 0.4079, validation loss: 0.1091
2024-06-01 22:30:35 [INFO]: Epoch 048 - training loss: 0.4062, validation loss: 0.1104
2024-06-01 22:30:36 [INFO]: Epoch 049 - training loss: 0.4064, validation loss: 0.1048
2024-06-01 22:30:37 [INFO]: Epoch 050 - training loss: 0.4055, validation loss: 0.1043
2024-06-01 22:30:38 [INFO]: Epoch 051 - training loss: 0.4029, validation loss: 0.1071
2024-06-01 22:30:39 [INFO]: Epoch 052 - training loss: 0.4062, validation loss: 0.1074
2024-06-01 22:30:40 [INFO]: Epoch 053 - training loss: 0.3987, validation loss: 0.1049
2024-06-01 22:30:41 [INFO]: Epoch 054 - training loss: 0.4045, validation loss: 0.1049
2024-06-01 22:30:42 [INFO]: Epoch 055 - training loss: 0.3952, validation loss: 0.0995
2024-06-01 22:30:43 [INFO]: Epoch 056 - training loss: 0.3990, validation loss: 0.1018
2024-06-01 22:30:43 [INFO]: Epoch 057 - training loss: 0.3955, validation loss: 0.1084
2024-06-01 22:30:44 [INFO]: Epoch 058 - training loss: 0.3911, validation loss: 0.1071
2024-06-01 22:30:45 [INFO]: Epoch 059 - training loss: 0.3984, validation loss: 0.1043
2024-06-01 22:30:46 [INFO]: Epoch 060 - training loss: 0.3965, validation loss: 0.1036
2024-06-01 22:30:47 [INFO]: Epoch 061 - training loss: 0.3914, validation loss: 0.0982
2024-06-01 22:30:48 [INFO]: Epoch 062 - training loss: 0.3955, validation loss: 0.1078
2024-06-01 22:30:49 [INFO]: Epoch 063 - training loss: 0.3931, validation loss: 0.1083
2024-06-01 22:30:50 [INFO]: Epoch 064 - training loss: 0.3971, validation loss: 0.1044
2024-06-01 22:30:51 [INFO]: Epoch 065 - training loss: 0.3897, validation loss: 0.1019
2024-06-01 22:30:52 [INFO]: Epoch 066 - training loss: 0.3930, validation loss: 0.1018
2024-06-01 22:30:53 [INFO]: Epoch 067 - training loss: 0.3871, validation loss: 0.1018
2024-06-01 22:30:54 [INFO]: Epoch 068 - training loss: 0.3846, validation loss: 0.0959
2024-06-01 22:30:55 [INFO]: Epoch 069 - training loss: 0.3875, validation loss: 0.0966
2024-06-01 22:30:56 [INFO]: Epoch 070 - training loss: 0.3864, validation loss: 0.1001
2024-06-01 22:30:57 [INFO]: Epoch 071 - training loss: 0.3848, validation loss: 0.0991
2024-06-01 22:30:58 [INFO]: Epoch 072 - training loss: 0.3796, validation loss: 0.0922
2024-06-01 22:30:59 [INFO]: Epoch 073 - training loss: 0.3847, validation loss: 0.0946
2024-06-01 22:31:00 [INFO]: Epoch 074 - training loss: 0.3798, validation loss: 0.1033
2024-06-01 22:31:01 [INFO]: Epoch 075 - training loss: 0.3847, validation loss: 0.0939
2024-06-01 22:31:02 [INFO]: Epoch 076 - training loss: 0.3810, validation loss: 0.0946
2024-06-01 22:31:03 [INFO]: Epoch 077 - training loss: 0.3709, validation loss: 0.0982
2024-06-01 22:31:03 [INFO]: Epoch 078 - training loss: 0.3745, validation loss: 0.0973
2024-06-01 22:31:04 [INFO]: Epoch 079 - training loss: 0.3752, validation loss: 0.0987
2024-06-01 22:31:05 [INFO]: Epoch 080 - training loss: 0.3786, validation loss: 0.0944
2024-06-01 22:31:06 [INFO]: Epoch 081 - training loss: 0.3705, validation loss: 0.0948
2024-06-01 22:31:07 [INFO]: Epoch 082 - training loss: 0.3713, validation loss: 0.1020
2024-06-01 22:31:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:31:07 [INFO]: Finished training. The best model is from epoch#72.
2024-06-01 22:31:07 [INFO]: Saved the model to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_3/20240601_T222932/StemGNN.pypots
2024-06-01 22:31:07 [INFO]: Successfully saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_3/imputation.pkl
2024-06-01 22:31:07 [INFO]: Round3 - StemGNN on ETT_h1: MAE=0.2542, MSE=0.1276, MRE=0.3000
2024-06-01 22:31:07 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:31:07 [INFO]: Using the given device: cuda:0
2024-06-01 22:31:07 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_4/20240601_T223107
2024-06-01 22:31:07 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_4/20240601_T223107/tensorboard
2024-06-01 22:31:07 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-01 22:31:08 [INFO]: Epoch 001 - training loss: 1.5184, validation loss: 0.9975
2024-06-01 22:31:09 [INFO]: Epoch 002 - training loss: 1.4456, validation loss: 0.9182
2024-06-01 22:31:10 [INFO]: Epoch 003 - training loss: 1.1962, validation loss: 0.6540
2024-06-01 22:31:11 [INFO]: Epoch 004 - training loss: 0.9287, validation loss: 0.4633
2024-06-01 22:31:12 [INFO]: Epoch 005 - training loss: 0.8465, validation loss: 0.4013
2024-06-01 22:31:13 [INFO]: Epoch 006 - training loss: 0.7805, validation loss: 0.3253
2024-06-01 22:31:14 [INFO]: Epoch 007 - training loss: 0.7223, validation loss: 0.2659
2024-06-01 22:31:15 [INFO]: Epoch 008 - training loss: 0.6558, validation loss: 0.2258
2024-06-01 22:31:16 [INFO]: Epoch 009 - training loss: 0.6115, validation loss: 0.1964
2024-06-01 22:31:17 [INFO]: Epoch 010 - training loss: 0.5956, validation loss: 0.1916
2024-06-01 22:31:18 [INFO]: Epoch 011 - training loss: 0.5840, validation loss: 0.1997
2024-06-01 22:31:19 [INFO]: Epoch 012 - training loss: 0.5689, validation loss: 0.1872
2024-06-01 22:31:20 [INFO]: Epoch 013 - training loss: 0.5548, validation loss: 0.1753
2024-06-01 22:31:21 [INFO]: Epoch 014 - training loss: 0.5321, validation loss: 0.1606
2024-06-01 22:31:22 [INFO]: Epoch 015 - training loss: 0.5141, validation loss: 0.1612
2024-06-01 22:31:23 [INFO]: Epoch 016 - training loss: 0.4929, validation loss: 0.1591
2024-06-01 22:31:24 [INFO]: Epoch 017 - training loss: 0.4821, validation loss: 0.1618
2024-06-01 22:31:25 [INFO]: Epoch 018 - training loss: 0.4687, validation loss: 0.1570
2024-06-01 22:31:26 [INFO]: Epoch 019 - training loss: 0.4623, validation loss: 0.1364
2024-06-01 22:31:26 [INFO]: Epoch 020 - training loss: 0.4538, validation loss: 0.1419
2024-06-01 22:31:27 [INFO]: Epoch 021 - training loss: 0.4466, validation loss: 0.1322
2024-06-01 22:31:28 [INFO]: Epoch 022 - training loss: 0.4443, validation loss: 0.1348
2024-06-01 22:31:29 [INFO]: Epoch 023 - training loss: 0.4343, validation loss: 0.1284
2024-06-01 22:31:30 [INFO]: Epoch 024 - training loss: 0.4243, validation loss: 0.1236
2024-06-01 22:31:31 [INFO]: Epoch 025 - training loss: 0.4170, validation loss: 0.1231
2024-06-01 22:31:32 [INFO]: Epoch 026 - training loss: 0.4082, validation loss: 0.1215
2024-06-01 22:31:33 [INFO]: Epoch 027 - training loss: 0.4074, validation loss: 0.1192
2024-06-01 22:31:34 [INFO]: Epoch 028 - training loss: 0.4098, validation loss: 0.1151
2024-06-01 22:31:35 [INFO]: Epoch 029 - training loss: 0.4063, validation loss: 0.1135
2024-06-01 22:31:36 [INFO]: Epoch 030 - training loss: 0.4104, validation loss: 0.1266
2024-06-01 22:31:37 [INFO]: Epoch 031 - training loss: 0.4406, validation loss: 0.1338
2024-06-01 22:31:38 [INFO]: Epoch 032 - training loss: 0.4322, validation loss: 0.1328
2024-06-01 22:31:39 [INFO]: Epoch 033 - training loss: 0.4234, validation loss: 0.1185
2024-06-01 22:31:40 [INFO]: Epoch 034 - training loss: 0.4190, validation loss: 0.1102
2024-06-01 22:31:41 [INFO]: Epoch 035 - training loss: 0.4104, validation loss: 0.1128
2024-06-01 22:31:42 [INFO]: Epoch 036 - training loss: 0.4106, validation loss: 0.1166
2024-06-01 22:31:43 [INFO]: Epoch 037 - training loss: 0.4033, validation loss: 0.1134
2024-06-01 22:31:44 [INFO]: Epoch 038 - training loss: 0.3986, validation loss: 0.1073
2024-06-01 22:31:45 [INFO]: Epoch 039 - training loss: 0.3984, validation loss: 0.1048
2024-06-01 22:31:45 [INFO]: Epoch 040 - training loss: 0.3895, validation loss: 0.1082
2024-06-01 22:31:46 [INFO]: Epoch 041 - training loss: 0.3895, validation loss: 0.1092
2024-06-01 22:31:47 [INFO]: Epoch 042 - training loss: 0.3889, validation loss: 0.1103
2024-06-01 22:31:48 [INFO]: Epoch 043 - training loss: 0.3847, validation loss: 0.1119
2024-06-01 22:31:49 [INFO]: Epoch 044 - training loss: 0.3813, validation loss: 0.1064
2024-06-01 22:31:50 [INFO]: Epoch 045 - training loss: 0.3805, validation loss: 0.1089
2024-06-01 22:31:51 [INFO]: Epoch 046 - training loss: 0.3728, validation loss: 0.1059
2024-06-01 22:31:52 [INFO]: Epoch 047 - training loss: 0.3741, validation loss: 0.1017
2024-06-01 22:31:53 [INFO]: Epoch 048 - training loss: 0.3786, validation loss: 0.1019
2024-06-01 22:31:54 [INFO]: Epoch 049 - training loss: 0.3749, validation loss: 0.1114
2024-06-01 22:31:55 [INFO]: Epoch 050 - training loss: 0.3768, validation loss: 0.1000
2024-06-01 22:31:56 [INFO]: Epoch 051 - training loss: 0.3694, validation loss: 0.1020
2024-06-01 22:31:57 [INFO]: Epoch 052 - training loss: 0.3660, validation loss: 0.0997
2024-06-01 22:31:58 [INFO]: Epoch 053 - training loss: 0.3634, validation loss: 0.1041
2024-06-01 22:31:59 [INFO]: Epoch 054 - training loss: 0.3615, validation loss: 0.0984
2024-06-01 22:32:00 [INFO]: Epoch 055 - training loss: 0.3584, validation loss: 0.0995
2024-06-01 22:32:01 [INFO]: Epoch 056 - training loss: 0.3575, validation loss: 0.0983
2024-06-01 22:32:02 [INFO]: Epoch 057 - training loss: 0.3580, validation loss: 0.0975
2024-06-01 22:32:03 [INFO]: Epoch 058 - training loss: 0.3547, validation loss: 0.0942
2024-06-01 22:32:04 [INFO]: Epoch 059 - training loss: 0.3549, validation loss: 0.1018
2024-06-01 22:32:04 [INFO]: Epoch 060 - training loss: 0.3570, validation loss: 0.0970
2024-06-01 22:32:05 [INFO]: Epoch 061 - training loss: 0.3587, validation loss: 0.0984
2024-06-01 22:32:06 [INFO]: Epoch 062 - training loss: 0.3602, validation loss: 0.0960
2024-06-01 22:32:07 [INFO]: Epoch 063 - training loss: 0.3589, validation loss: 0.0941
2024-06-01 22:32:08 [INFO]: Epoch 064 - training loss: 0.3592, validation loss: 0.0931
2024-06-01 22:32:09 [INFO]: Epoch 065 - training loss: 0.3557, validation loss: 0.0956
2024-06-01 22:32:10 [INFO]: Epoch 066 - training loss: 0.3558, validation loss: 0.0935
2024-06-01 22:32:11 [INFO]: Epoch 067 - training loss: 0.3515, validation loss: 0.0938
2024-06-01 22:32:12 [INFO]: Epoch 068 - training loss: 0.3480, validation loss: 0.0980
2024-06-01 22:32:13 [INFO]: Epoch 069 - training loss: 0.3498, validation loss: 0.1000
2024-06-01 22:32:14 [INFO]: Epoch 070 - training loss: 0.3512, validation loss: 0.0905
2024-06-01 22:32:15 [INFO]: Epoch 071 - training loss: 0.3491, validation loss: 0.0951
2024-06-01 22:32:16 [INFO]: Epoch 072 - training loss: 0.3455, validation loss: 0.0878
2024-06-01 22:32:17 [INFO]: Epoch 073 - training loss: 0.3446, validation loss: 0.0898
2024-06-01 22:32:18 [INFO]: Epoch 074 - training loss: 0.3452, validation loss: 0.0885
2024-06-01 22:32:19 [INFO]: Epoch 075 - training loss: 0.3413, validation loss: 0.0894
2024-06-01 22:32:20 [INFO]: Epoch 076 - training loss: 0.3445, validation loss: 0.0930
2024-06-01 22:32:21 [INFO]: Epoch 077 - training loss: 0.3405, validation loss: 0.0917
2024-06-01 22:32:22 [INFO]: Epoch 078 - training loss: 0.3414, validation loss: 0.0855
2024-06-01 22:32:23 [INFO]: Epoch 079 - training loss: 0.3448, validation loss: 0.0955
2024-06-01 22:32:23 [INFO]: Epoch 080 - training loss: 0.3481, validation loss: 0.0954
2024-06-01 22:32:24 [INFO]: Epoch 081 - training loss: 0.3421, validation loss: 0.0867
2024-06-01 22:32:25 [INFO]: Epoch 082 - training loss: 0.3332, validation loss: 0.0894
2024-06-01 22:32:26 [INFO]: Epoch 083 - training loss: 0.3283, validation loss: 0.0862
2024-06-01 22:32:27 [INFO]: Epoch 084 - training loss: 0.3296, validation loss: 0.0863
2024-06-01 22:32:28 [INFO]: Epoch 085 - training loss: 0.3275, validation loss: 0.0830
2024-06-01 22:32:29 [INFO]: Epoch 086 - training loss: 0.3258, validation loss: 0.0862
2024-06-01 22:32:30 [INFO]: Epoch 087 - training loss: 0.3329, validation loss: 0.0936
2024-06-01 22:32:31 [INFO]: Epoch 088 - training loss: 0.3356, validation loss: 0.0835
2024-06-01 22:32:32 [INFO]: Epoch 089 - training loss: 0.3377, validation loss: 0.0917
2024-06-01 22:32:33 [INFO]: Epoch 090 - training loss: 0.3379, validation loss: 0.0883
2024-06-01 22:32:34 [INFO]: Epoch 091 - training loss: 0.3335, validation loss: 0.0841
2024-06-01 22:32:35 [INFO]: Epoch 092 - training loss: 0.3300, validation loss: 0.0852
2024-06-01 22:32:36 [INFO]: Epoch 093 - training loss: 0.3307, validation loss: 0.0839
2024-06-01 22:32:37 [INFO]: Epoch 094 - training loss: 0.3256, validation loss: 0.0810
2024-06-01 22:32:38 [INFO]: Epoch 095 - training loss: 0.3265, validation loss: 0.0867
2024-06-01 22:32:39 [INFO]: Epoch 096 - training loss: 0.3251, validation loss: 0.0871
2024-06-01 22:32:40 [INFO]: Epoch 097 - training loss: 0.3239, validation loss: 0.0845
2024-06-01 22:32:41 [INFO]: Epoch 098 - training loss: 0.3224, validation loss: 0.0792
2024-06-01 22:32:42 [INFO]: Epoch 099 - training loss: 0.3178, validation loss: 0.0791
2024-06-01 22:32:42 [INFO]: Epoch 100 - training loss: 0.3167, validation loss: 0.0785
2024-06-01 22:32:42 [INFO]: Finished training. The best model is from epoch#100.
2024-06-01 22:32:42 [INFO]: Saved the model to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_4/20240601_T223107/StemGNN.pypots
2024-06-01 22:32:43 [INFO]: Successfully saved to results_point_rate01/ETT_h1/StemGNN_ETT_h1/round_4/imputation.pkl
2024-06-01 22:32:43 [INFO]: Round4 - StemGNN on ETT_h1: MAE=0.2261, MSE=0.1078, MRE=0.2668
2024-06-01 22:32:43 [INFO]: Done! Final results:
Averaged StemGNN (n params: 6,397,975) on ETT_h1: MAE=0.2484 ± 0.012414202334092735, MSE=0.1255 ± 0.011398735168158482, MRE=0.2932 ± 0.014649889259286095, average inference time=0.21
