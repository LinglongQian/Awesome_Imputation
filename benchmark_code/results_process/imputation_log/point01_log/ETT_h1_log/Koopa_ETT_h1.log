2024-06-01 22:19:18 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:19:18 [INFO]: Using the given device: cuda:0
2024-06-01 22:19:19 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_0/20240601_T221919
2024-06-01 22:19:19 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_0/20240601_T221919/tensorboard
2024-06-01 22:19:19 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-01 22:19:26 [INFO]: Epoch 001 - training loss: 4.4580, validation loss: 2.9526
2024-06-01 22:19:28 [INFO]: Epoch 002 - training loss: 1.8760, validation loss: 1.4017
2024-06-01 22:19:31 [INFO]: Epoch 003 - training loss: 1.5666, validation loss: 1.2059
2024-06-01 22:19:33 [INFO]: Epoch 004 - training loss: 1.4721, validation loss: 1.0287
2024-06-01 22:19:36 [INFO]: Epoch 005 - training loss: 1.3546, validation loss: 0.9631
2024-06-01 22:19:39 [INFO]: Epoch 006 - training loss: 1.2517, validation loss: 0.8559
2024-06-01 22:19:41 [INFO]: Epoch 007 - training loss: 1.1356, validation loss: 0.7108
2024-06-01 22:19:44 [INFO]: Epoch 008 - training loss: 1.0357, validation loss: 0.6419
2024-06-01 22:19:46 [INFO]: Epoch 009 - training loss: 0.9458, validation loss: 0.5248
2024-06-01 22:19:49 [INFO]: Epoch 010 - training loss: 0.8880, validation loss: 0.4965
2024-06-01 22:19:51 [INFO]: Epoch 011 - training loss: 0.8449, validation loss: 0.4117
2024-06-01 22:19:54 [INFO]: Epoch 012 - training loss: 0.7931, validation loss: 0.3390
2024-06-01 22:19:56 [INFO]: Epoch 013 - training loss: 0.7502, validation loss: 0.2653
2024-06-01 22:19:59 [INFO]: Epoch 014 - training loss: 0.7312, validation loss: 0.2673
2024-06-01 22:20:01 [INFO]: Epoch 015 - training loss: 0.6997, validation loss: 0.2518
2024-06-01 22:20:03 [INFO]: Epoch 016 - training loss: 0.6902, validation loss: 0.2001
2024-06-01 22:20:06 [INFO]: Epoch 017 - training loss: 0.6693, validation loss: 0.2558
2024-06-01 22:20:08 [INFO]: Epoch 018 - training loss: 0.6638, validation loss: 0.2144
2024-06-01 22:20:10 [INFO]: Epoch 019 - training loss: 0.6607, validation loss: 0.2366
2024-06-01 22:20:12 [INFO]: Epoch 020 - training loss: 0.6220, validation loss: 0.2055
2024-06-01 22:20:13 [INFO]: Epoch 021 - training loss: 0.6197, validation loss: 0.1762
2024-06-01 22:20:13 [INFO]: Epoch 022 - training loss: 0.6075, validation loss: 0.1905
2024-06-01 22:20:15 [INFO]: Epoch 023 - training loss: 0.6018, validation loss: 0.1626
2024-06-01 22:20:16 [INFO]: Epoch 024 - training loss: 0.5800, validation loss: 0.1680
2024-06-01 22:20:16 [INFO]: Epoch 025 - training loss: 0.5660, validation loss: 0.1548
2024-06-01 22:20:18 [INFO]: Epoch 026 - training loss: 0.5500, validation loss: 0.1600
2024-06-01 22:20:19 [INFO]: Epoch 027 - training loss: 0.5578, validation loss: 0.1897
2024-06-01 22:20:21 [INFO]: Epoch 028 - training loss: 0.5660, validation loss: 0.2070
2024-06-01 22:20:22 [INFO]: Epoch 029 - training loss: 0.5652, validation loss: 0.1514
2024-06-01 22:20:24 [INFO]: Epoch 030 - training loss: 0.5541, validation loss: 0.1623
2024-06-01 22:20:25 [INFO]: Epoch 031 - training loss: 0.5459, validation loss: 0.1667
2024-06-01 22:20:27 [INFO]: Epoch 032 - training loss: 0.5468, validation loss: 0.2284
2024-06-01 22:20:28 [INFO]: Epoch 033 - training loss: 0.5476, validation loss: 0.1563
2024-06-01 22:20:30 [INFO]: Epoch 034 - training loss: 0.5524, validation loss: 0.1605
2024-06-01 22:20:30 [INFO]: Epoch 035 - training loss: 0.5401, validation loss: 0.1525
2024-06-01 22:20:31 [INFO]: Epoch 036 - training loss: 0.5171, validation loss: 0.1524
2024-06-01 22:20:33 [INFO]: Epoch 037 - training loss: 0.5035, validation loss: 0.1276
2024-06-01 22:20:34 [INFO]: Epoch 038 - training loss: 0.4931, validation loss: 0.1246
2024-06-01 22:20:36 [INFO]: Epoch 039 - training loss: 0.4958, validation loss: 0.1312
2024-06-01 22:20:37 [INFO]: Epoch 040 - training loss: 0.5028, validation loss: 0.1246
2024-06-01 22:20:38 [INFO]: Epoch 041 - training loss: 0.4988, validation loss: 0.1365
2024-06-01 22:20:40 [INFO]: Epoch 042 - training loss: 0.4991, validation loss: 0.1193
2024-06-01 22:20:40 [INFO]: Epoch 043 - training loss: 0.5028, validation loss: 0.1194
2024-06-01 22:20:41 [INFO]: Epoch 044 - training loss: 0.5184, validation loss: 0.1288
2024-06-01 22:20:41 [INFO]: Epoch 045 - training loss: 0.5055, validation loss: 0.1249
2024-06-01 22:20:41 [INFO]: Epoch 046 - training loss: 0.4993, validation loss: 0.1209
2024-06-01 22:20:42 [INFO]: Epoch 047 - training loss: 0.4821, validation loss: 0.1296
2024-06-01 22:20:42 [INFO]: Epoch 048 - training loss: 0.4904, validation loss: 0.1271
2024-06-01 22:20:43 [INFO]: Epoch 049 - training loss: 0.5025, validation loss: 0.1122
2024-06-01 22:20:43 [INFO]: Epoch 050 - training loss: 0.4773, validation loss: 0.1183
2024-06-01 22:20:43 [INFO]: Epoch 051 - training loss: 0.5152, validation loss: 0.1093
2024-06-01 22:20:44 [INFO]: Epoch 052 - training loss: 0.5099, validation loss: 0.1181
2024-06-01 22:20:44 [INFO]: Epoch 053 - training loss: 0.4992, validation loss: 0.1275
2024-06-01 22:20:44 [INFO]: Epoch 054 - training loss: 0.4743, validation loss: 0.1205
2024-06-01 22:20:45 [INFO]: Epoch 055 - training loss: 0.4812, validation loss: 0.1557
2024-06-01 22:20:45 [INFO]: Epoch 056 - training loss: 0.5041, validation loss: 0.1049
2024-06-01 22:20:45 [INFO]: Epoch 057 - training loss: 0.4897, validation loss: 0.1247
2024-06-01 22:20:46 [INFO]: Epoch 058 - training loss: 0.5129, validation loss: 0.1399
2024-06-01 22:20:46 [INFO]: Epoch 059 - training loss: 0.5106, validation loss: 0.1228
2024-06-01 22:20:47 [INFO]: Epoch 060 - training loss: 0.4946, validation loss: 0.1348
2024-06-01 22:20:47 [INFO]: Epoch 061 - training loss: 0.4889, validation loss: 0.1005
2024-06-01 22:20:47 [INFO]: Epoch 062 - training loss: 0.4701, validation loss: 0.1246
2024-06-01 22:20:48 [INFO]: Epoch 063 - training loss: 0.4842, validation loss: 0.1576
2024-06-01 22:20:48 [INFO]: Epoch 064 - training loss: 0.4732, validation loss: 0.1328
2024-06-01 22:20:48 [INFO]: Epoch 065 - training loss: 0.4782, validation loss: 0.1398
2024-06-01 22:20:49 [INFO]: Epoch 066 - training loss: 0.4636, validation loss: 0.1127
2024-06-01 22:20:49 [INFO]: Epoch 067 - training loss: 0.4593, validation loss: 0.1167
2024-06-01 22:20:50 [INFO]: Epoch 068 - training loss: 0.4624, validation loss: 0.1291
2024-06-01 22:20:50 [INFO]: Epoch 069 - training loss: 0.4670, validation loss: 0.1046
2024-06-01 22:20:50 [INFO]: Epoch 070 - training loss: 0.4594, validation loss: 0.1024
2024-06-01 22:20:51 [INFO]: Epoch 071 - training loss: 0.4532, validation loss: 0.1035
2024-06-01 22:20:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:20:51 [INFO]: Finished training. The best model is from epoch#61.
2024-06-01 22:20:51 [INFO]: Saved the model to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_0/20240601_T221919/Koopa.pypots
2024-06-01 22:20:51 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_0/imputation.pkl
2024-06-01 22:20:51 [INFO]: Round0 - Koopa on ETT_h1: MAE=0.2592, MSE=0.1401, MRE=0.3059
2024-06-01 22:20:51 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:20:51 [INFO]: Using the given device: cuda:0
2024-06-01 22:20:51 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_1/20240601_T222051
2024-06-01 22:20:51 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_1/20240601_T222051/tensorboard
2024-06-01 22:20:51 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-01 22:20:51 [INFO]: Epoch 001 - training loss: 5.3682, validation loss: 4.8501
2024-06-01 22:20:51 [INFO]: Epoch 002 - training loss: 2.0731, validation loss: 1.4218
2024-06-01 22:20:52 [INFO]: Epoch 003 - training loss: 1.6821, validation loss: 1.0599
2024-06-01 22:20:52 [INFO]: Epoch 004 - training loss: 1.4792, validation loss: 1.0394
2024-06-01 22:20:53 [INFO]: Epoch 005 - training loss: 1.4475, validation loss: 1.0596
2024-06-01 22:20:53 [INFO]: Epoch 006 - training loss: 1.3893, validation loss: 0.9798
2024-06-01 22:20:53 [INFO]: Epoch 007 - training loss: 1.2690, validation loss: 0.9382
2024-06-01 22:20:54 [INFO]: Epoch 008 - training loss: 1.2205, validation loss: 0.8357
2024-06-01 22:20:54 [INFO]: Epoch 009 - training loss: 1.1245, validation loss: 0.7166
2024-06-01 22:20:54 [INFO]: Epoch 010 - training loss: 1.1677, validation loss: 0.7250
2024-06-01 22:20:55 [INFO]: Epoch 011 - training loss: 1.1307, validation loss: 0.6552
2024-06-01 22:20:55 [INFO]: Epoch 012 - training loss: 1.0486, validation loss: 0.6363
2024-06-01 22:20:55 [INFO]: Epoch 013 - training loss: 1.0226, validation loss: 0.6174
2024-06-01 22:20:56 [INFO]: Epoch 014 - training loss: 0.9930, validation loss: 0.5766
2024-06-01 22:20:56 [INFO]: Epoch 015 - training loss: 0.9803, validation loss: 0.5871
2024-06-01 22:20:57 [INFO]: Epoch 016 - training loss: 0.9511, validation loss: 0.5526
2024-06-01 22:20:57 [INFO]: Epoch 017 - training loss: 0.9415, validation loss: 0.5322
2024-06-01 22:20:57 [INFO]: Epoch 018 - training loss: 0.9684, validation loss: 0.5158
2024-06-01 22:20:58 [INFO]: Epoch 019 - training loss: 0.9665, validation loss: 0.5889
2024-06-01 22:20:58 [INFO]: Epoch 020 - training loss: 0.9333, validation loss: 0.5770
2024-06-01 22:20:58 [INFO]: Epoch 021 - training loss: 0.9196, validation loss: 0.6341
2024-06-01 22:20:59 [INFO]: Epoch 022 - training loss: 0.9183, validation loss: 0.5321
2024-06-01 22:20:59 [INFO]: Epoch 023 - training loss: 0.9386, validation loss: 0.5258
2024-06-01 22:21:00 [INFO]: Epoch 024 - training loss: 1.0014, validation loss: 0.7750
2024-06-01 22:21:00 [INFO]: Epoch 025 - training loss: 0.9649, validation loss: 0.5368
2024-06-01 22:21:00 [INFO]: Epoch 026 - training loss: 0.9882, validation loss: 0.7652
2024-06-01 22:21:01 [INFO]: Epoch 027 - training loss: 0.9284, validation loss: 0.5422
2024-06-01 22:21:01 [INFO]: Epoch 028 - training loss: 0.9021, validation loss: 0.5606
2024-06-01 22:21:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:21:01 [INFO]: Finished training. The best model is from epoch#18.
2024-06-01 22:21:01 [INFO]: Saved the model to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_1/20240601_T222051/Koopa.pypots
2024-06-01 22:21:01 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_1/imputation.pkl
2024-06-01 22:21:01 [INFO]: Round1 - Koopa on ETT_h1: MAE=0.5814, MSE=0.7699, MRE=0.6861
2024-06-01 22:21:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:21:01 [INFO]: Using the given device: cuda:0
2024-06-01 22:21:01 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_2/20240601_T222101
2024-06-01 22:21:01 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_2/20240601_T222101/tensorboard
2024-06-01 22:21:01 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-01 22:21:01 [INFO]: Epoch 001 - training loss: 4.2966, validation loss: 1.7682
2024-06-01 22:21:02 [INFO]: Epoch 002 - training loss: 1.9667, validation loss: 1.3124
2024-06-01 22:21:02 [INFO]: Epoch 003 - training loss: 1.6565, validation loss: 1.0625
2024-06-01 22:21:02 [INFO]: Epoch 004 - training loss: 1.3861, validation loss: 0.9642
2024-06-01 22:21:03 [INFO]: Epoch 005 - training loss: 1.3258, validation loss: 0.9098
2024-06-01 22:21:03 [INFO]: Epoch 006 - training loss: 1.4930, validation loss: 1.0610
2024-06-01 22:21:04 [INFO]: Epoch 007 - training loss: 1.4678, validation loss: 0.9991
2024-06-01 22:21:04 [INFO]: Epoch 008 - training loss: 1.4318, validation loss: 1.0064
2024-06-01 22:21:04 [INFO]: Epoch 009 - training loss: 1.3353, validation loss: 0.8763
2024-06-01 22:21:05 [INFO]: Epoch 010 - training loss: 1.2078, validation loss: 0.7851
2024-06-01 22:21:05 [INFO]: Epoch 011 - training loss: 1.1172, validation loss: 0.7661
2024-06-01 22:21:05 [INFO]: Epoch 012 - training loss: 1.1149, validation loss: 0.7304
2024-06-01 22:21:06 [INFO]: Epoch 013 - training loss: 1.1026, validation loss: 0.6903
2024-06-01 22:21:06 [INFO]: Epoch 014 - training loss: 1.0063, validation loss: 0.6483
2024-06-01 22:21:07 [INFO]: Epoch 015 - training loss: 0.9936, validation loss: 0.6069
2024-06-01 22:21:07 [INFO]: Epoch 016 - training loss: 0.9599, validation loss: 0.5756
2024-06-01 22:21:07 [INFO]: Epoch 017 - training loss: 0.9381, validation loss: 0.5189
2024-06-01 22:21:08 [INFO]: Epoch 018 - training loss: 0.9389, validation loss: 0.5738
2024-06-01 22:21:08 [INFO]: Epoch 019 - training loss: 0.9699, validation loss: 0.5491
2024-06-01 22:21:08 [INFO]: Epoch 020 - training loss: 0.9449, validation loss: 0.5892
2024-06-01 22:21:09 [INFO]: Epoch 021 - training loss: 0.9291, validation loss: 0.5207
2024-06-01 22:21:09 [INFO]: Epoch 022 - training loss: 0.9272, validation loss: 0.5148
2024-06-01 22:21:10 [INFO]: Epoch 023 - training loss: 0.9134, validation loss: 0.5070
2024-06-01 22:21:10 [INFO]: Epoch 024 - training loss: 0.8963, validation loss: 0.4951
2024-06-01 22:21:10 [INFO]: Epoch 025 - training loss: 0.9094, validation loss: 0.4944
2024-06-01 22:21:11 [INFO]: Epoch 026 - training loss: 0.8952, validation loss: 0.4997
2024-06-01 22:21:11 [INFO]: Epoch 027 - training loss: 0.9110, validation loss: 0.5291
2024-06-01 22:21:11 [INFO]: Epoch 028 - training loss: 0.9512, validation loss: 0.5089
2024-06-01 22:21:12 [INFO]: Epoch 029 - training loss: 0.9246, validation loss: 0.5299
2024-06-01 22:21:12 [INFO]: Epoch 030 - training loss: 0.9143, validation loss: 0.4903
2024-06-01 22:21:12 [INFO]: Epoch 031 - training loss: 0.9131, validation loss: 0.4800
2024-06-01 22:21:13 [INFO]: Epoch 032 - training loss: 0.8830, validation loss: 0.4704
2024-06-01 22:21:13 [INFO]: Epoch 033 - training loss: 0.8871, validation loss: 0.4495
2024-06-01 22:21:14 [INFO]: Epoch 034 - training loss: 0.8797, validation loss: 0.4774
2024-06-01 22:21:14 [INFO]: Epoch 035 - training loss: 0.9066, validation loss: 0.4724
2024-06-01 22:21:14 [INFO]: Epoch 036 - training loss: 0.8926, validation loss: 0.4800
2024-06-01 22:21:15 [INFO]: Epoch 037 - training loss: 0.8841, validation loss: 0.4655
2024-06-01 22:21:15 [INFO]: Epoch 038 - training loss: 0.9069, validation loss: 0.4788
2024-06-01 22:21:15 [INFO]: Epoch 039 - training loss: 0.8976, validation loss: 0.4687
2024-06-01 22:21:16 [INFO]: Epoch 040 - training loss: 0.8794, validation loss: 0.4619
2024-06-01 22:21:16 [INFO]: Epoch 041 - training loss: 0.9010, validation loss: 0.4520
2024-06-01 22:21:17 [INFO]: Epoch 042 - training loss: 0.8934, validation loss: 0.4694
2024-06-01 22:21:17 [INFO]: Epoch 043 - training loss: 0.8889, validation loss: 0.4756
2024-06-01 22:21:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:21:17 [INFO]: Finished training. The best model is from epoch#33.
2024-06-01 22:21:17 [INFO]: Saved the model to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_2/20240601_T222101/Koopa.pypots
2024-06-01 22:21:17 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_2/imputation.pkl
2024-06-01 22:21:17 [INFO]: Round2 - Koopa on ETT_h1: MAE=0.5764, MSE=0.7620, MRE=0.6802
2024-06-01 22:21:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:21:17 [INFO]: Using the given device: cuda:0
2024-06-01 22:21:17 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_3/20240601_T222117
2024-06-01 22:21:17 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_3/20240601_T222117/tensorboard
2024-06-01 22:21:17 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-01 22:21:17 [INFO]: Epoch 001 - training loss: 5.8893, validation loss: 3.6021
2024-06-01 22:21:18 [INFO]: Epoch 002 - training loss: 2.0911, validation loss: 1.5364
2024-06-01 22:21:18 [INFO]: Epoch 003 - training loss: 1.7784, validation loss: 1.0976
2024-06-01 22:21:18 [INFO]: Epoch 004 - training loss: 1.5415, validation loss: 1.0127
2024-06-01 22:21:19 [INFO]: Epoch 005 - training loss: 1.4862, validation loss: 0.9622
2024-06-01 22:21:19 [INFO]: Epoch 006 - training loss: 1.4028, validation loss: 0.9683
2024-06-01 22:21:20 [INFO]: Epoch 007 - training loss: 1.2226, validation loss: 0.9283
2024-06-01 22:21:20 [INFO]: Epoch 008 - training loss: 1.2140, validation loss: 0.8353
2024-06-01 22:21:20 [INFO]: Epoch 009 - training loss: 1.1210, validation loss: 0.7369
2024-06-01 22:21:21 [INFO]: Epoch 010 - training loss: 1.0532, validation loss: 0.5684
2024-06-01 22:21:21 [INFO]: Epoch 011 - training loss: 0.9633, validation loss: 0.5865
2024-06-01 22:21:21 [INFO]: Epoch 012 - training loss: 0.9460, validation loss: 0.5837
2024-06-01 22:21:22 [INFO]: Epoch 013 - training loss: 0.9230, validation loss: 0.4707
2024-06-01 22:21:22 [INFO]: Epoch 014 - training loss: 0.8833, validation loss: 0.5893
2024-06-01 22:21:22 [INFO]: Epoch 015 - training loss: 0.8634, validation loss: 0.4537
2024-06-01 22:21:23 [INFO]: Epoch 016 - training loss: 0.8355, validation loss: 0.5079
2024-06-01 22:21:23 [INFO]: Epoch 017 - training loss: 0.8400, validation loss: 0.4560
2024-06-01 22:21:24 [INFO]: Epoch 018 - training loss: 0.8015, validation loss: 0.3932
2024-06-01 22:21:24 [INFO]: Epoch 019 - training loss: 0.8266, validation loss: 0.3219
2024-06-01 22:21:24 [INFO]: Epoch 020 - training loss: 0.7665, validation loss: 0.2433
2024-06-01 22:21:25 [INFO]: Epoch 021 - training loss: 0.7213, validation loss: 0.2149
2024-06-01 22:21:25 [INFO]: Epoch 022 - training loss: 0.7084, validation loss: 0.2555
2024-06-01 22:21:25 [INFO]: Epoch 023 - training loss: 0.6880, validation loss: 0.2233
2024-06-01 22:21:26 [INFO]: Epoch 024 - training loss: 0.6678, validation loss: 0.2347
2024-06-01 22:21:26 [INFO]: Epoch 025 - training loss: 0.6723, validation loss: 0.2028
2024-06-01 22:21:27 [INFO]: Epoch 026 - training loss: 0.6672, validation loss: 0.2073
2024-06-01 22:21:27 [INFO]: Epoch 027 - training loss: 0.6670, validation loss: 0.2196
2024-06-01 22:21:27 [INFO]: Epoch 028 - training loss: 0.6733, validation loss: 0.2318
2024-06-01 22:21:28 [INFO]: Epoch 029 - training loss: 0.7153, validation loss: 0.2062
2024-06-01 22:21:28 [INFO]: Epoch 030 - training loss: 0.7151, validation loss: 0.2974
2024-06-01 22:21:28 [INFO]: Epoch 031 - training loss: 0.6911, validation loss: 0.2173
2024-06-01 22:21:29 [INFO]: Epoch 032 - training loss: 0.6685, validation loss: 0.2205
2024-06-01 22:21:29 [INFO]: Epoch 033 - training loss: 0.6434, validation loss: 0.2695
2024-06-01 22:21:29 [INFO]: Epoch 034 - training loss: 0.6472, validation loss: 0.1927
2024-06-01 22:21:30 [INFO]: Epoch 035 - training loss: 0.6451, validation loss: 0.1913
2024-06-01 22:21:30 [INFO]: Epoch 036 - training loss: 0.6459, validation loss: 0.2212
2024-06-01 22:21:31 [INFO]: Epoch 037 - training loss: 0.6434, validation loss: 0.2047
2024-06-01 22:21:31 [INFO]: Epoch 038 - training loss: 0.6263, validation loss: 0.1940
2024-06-01 22:21:31 [INFO]: Epoch 039 - training loss: 0.6273, validation loss: 0.1895
2024-06-01 22:21:32 [INFO]: Epoch 040 - training loss: 0.6137, validation loss: 0.1860
2024-06-01 22:21:32 [INFO]: Epoch 041 - training loss: 0.6218, validation loss: 0.2304
2024-06-01 22:21:32 [INFO]: Epoch 042 - training loss: 0.6186, validation loss: 0.1872
2024-06-01 22:21:33 [INFO]: Epoch 043 - training loss: 0.6060, validation loss: 0.2130
2024-06-01 22:21:33 [INFO]: Epoch 044 - training loss: 0.6033, validation loss: 0.1758
2024-06-01 22:21:33 [INFO]: Epoch 045 - training loss: 0.6015, validation loss: 0.1705
2024-06-01 22:21:34 [INFO]: Epoch 046 - training loss: 0.5885, validation loss: 0.1791
2024-06-01 22:21:34 [INFO]: Epoch 047 - training loss: 0.5671, validation loss: 0.1645
2024-06-01 22:21:35 [INFO]: Epoch 048 - training loss: 0.5734, validation loss: 0.1699
2024-06-01 22:21:35 [INFO]: Epoch 049 - training loss: 0.5541, validation loss: 0.1441
2024-06-01 22:21:35 [INFO]: Epoch 050 - training loss: 0.5529, validation loss: 0.1452
2024-06-01 22:21:36 [INFO]: Epoch 051 - training loss: 0.5440, validation loss: 0.1629
2024-06-01 22:21:36 [INFO]: Epoch 052 - training loss: 0.5622, validation loss: 0.1267
2024-06-01 22:21:36 [INFO]: Epoch 053 - training loss: 0.5363, validation loss: 0.1643
2024-06-01 22:21:37 [INFO]: Epoch 054 - training loss: 0.5388, validation loss: 0.1395
2024-06-01 22:21:37 [INFO]: Epoch 055 - training loss: 0.5201, validation loss: 0.1324
2024-06-01 22:21:38 [INFO]: Epoch 056 - training loss: 0.5426, validation loss: 0.1426
2024-06-01 22:21:38 [INFO]: Epoch 057 - training loss: 0.5664, validation loss: 0.1451
2024-06-01 22:21:38 [INFO]: Epoch 058 - training loss: 0.5516, validation loss: 0.1791
2024-06-01 22:21:39 [INFO]: Epoch 059 - training loss: 0.5381, validation loss: 0.1311
2024-06-01 22:21:39 [INFO]: Epoch 060 - training loss: 0.5209, validation loss: 0.1657
2024-06-01 22:21:39 [INFO]: Epoch 061 - training loss: 0.5186, validation loss: 0.1220
2024-06-01 22:21:40 [INFO]: Epoch 062 - training loss: 0.5040, validation loss: 0.1425
2024-06-01 22:21:40 [INFO]: Epoch 063 - training loss: 0.4981, validation loss: 0.1420
2024-06-01 22:21:40 [INFO]: Epoch 064 - training loss: 0.5068, validation loss: 0.1250
2024-06-01 22:21:41 [INFO]: Epoch 065 - training loss: 0.5056, validation loss: 0.1175
2024-06-01 22:21:41 [INFO]: Epoch 066 - training loss: 0.5117, validation loss: 0.1219
2024-06-01 22:21:42 [INFO]: Epoch 067 - training loss: 0.5101, validation loss: 0.1300
2024-06-01 22:21:42 [INFO]: Epoch 068 - training loss: 0.5012, validation loss: 0.1296
2024-06-01 22:21:42 [INFO]: Epoch 069 - training loss: 0.5077, validation loss: 0.1539
2024-06-01 22:21:43 [INFO]: Epoch 070 - training loss: 0.5053, validation loss: 0.1389
2024-06-01 22:21:43 [INFO]: Epoch 071 - training loss: 0.4902, validation loss: 0.1182
2024-06-01 22:21:43 [INFO]: Epoch 072 - training loss: 0.5042, validation loss: 0.1405
2024-06-01 22:21:44 [INFO]: Epoch 073 - training loss: 0.4992, validation loss: 0.1286
2024-06-01 22:21:44 [INFO]: Epoch 074 - training loss: 0.5787, validation loss: 0.1516
2024-06-01 22:21:45 [INFO]: Epoch 075 - training loss: 0.5687, validation loss: 0.1354
2024-06-01 22:21:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:21:45 [INFO]: Finished training. The best model is from epoch#65.
2024-06-01 22:21:45 [INFO]: Saved the model to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_3/20240601_T222117/Koopa.pypots
2024-06-01 22:21:45 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_3/imputation.pkl
2024-06-01 22:21:45 [INFO]: Round3 - Koopa on ETT_h1: MAE=0.3123, MSE=0.1864, MRE=0.3685
2024-06-01 22:21:45 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:21:45 [INFO]: Using the given device: cuda:0
2024-06-01 22:21:45 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_4/20240601_T222145
2024-06-01 22:21:45 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_4/20240601_T222145/tensorboard
2024-06-01 22:21:45 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-01 22:21:45 [INFO]: Epoch 001 - training loss: 6.2624, validation loss: 6.1197
2024-06-01 22:21:45 [INFO]: Epoch 002 - training loss: 2.3779, validation loss: 2.2611
2024-06-01 22:21:46 [INFO]: Epoch 003 - training loss: 1.8397, validation loss: 1.3022
2024-06-01 22:21:46 [INFO]: Epoch 004 - training loss: 1.5770, validation loss: 1.3029
2024-06-01 22:21:46 [INFO]: Epoch 005 - training loss: 1.4963, validation loss: 1.0314
2024-06-01 22:21:47 [INFO]: Epoch 006 - training loss: 1.4755, validation loss: 1.0914
2024-06-01 22:21:47 [INFO]: Epoch 007 - training loss: 1.3888, validation loss: 0.7769
2024-06-01 22:21:48 [INFO]: Epoch 008 - training loss: 1.2575, validation loss: 0.8521
2024-06-01 22:21:48 [INFO]: Epoch 009 - training loss: 1.1385, validation loss: 0.6427
2024-06-01 22:21:48 [INFO]: Epoch 010 - training loss: 1.0895, validation loss: 0.7208
2024-06-01 22:21:49 [INFO]: Epoch 011 - training loss: 1.0555, validation loss: 0.6616
2024-06-01 22:21:49 [INFO]: Epoch 012 - training loss: 1.0849, validation loss: 0.7139
2024-06-01 22:21:49 [INFO]: Epoch 013 - training loss: 1.0161, validation loss: 0.5913
2024-06-01 22:21:50 [INFO]: Epoch 014 - training loss: 0.9771, validation loss: 0.5725
2024-06-01 22:21:50 [INFO]: Epoch 015 - training loss: 0.9779, validation loss: 0.6685
2024-06-01 22:21:50 [INFO]: Epoch 016 - training loss: 0.9323, validation loss: 0.5805
2024-06-01 22:21:51 [INFO]: Epoch 017 - training loss: 0.9217, validation loss: 0.6020
2024-06-01 22:21:51 [INFO]: Epoch 018 - training loss: 0.9182, validation loss: 0.5486
2024-06-01 22:21:52 [INFO]: Epoch 019 - training loss: 0.9034, validation loss: 0.5485
2024-06-01 22:21:52 [INFO]: Epoch 020 - training loss: 0.8998, validation loss: 0.5290
2024-06-01 22:21:52 [INFO]: Epoch 021 - training loss: 0.8712, validation loss: 0.5038
2024-06-01 22:21:53 [INFO]: Epoch 022 - training loss: 0.8562, validation loss: 0.4282
2024-06-01 22:21:53 [INFO]: Epoch 023 - training loss: 0.8985, validation loss: 0.4483
2024-06-01 22:21:53 [INFO]: Epoch 024 - training loss: 0.8956, validation loss: 0.4777
2024-06-01 22:21:54 [INFO]: Epoch 025 - training loss: 0.8609, validation loss: 0.3648
2024-06-01 22:21:54 [INFO]: Epoch 026 - training loss: 1.1019, validation loss: 0.6678
2024-06-01 22:21:55 [INFO]: Epoch 027 - training loss: 1.0106, validation loss: 0.6925
2024-06-01 22:21:55 [INFO]: Epoch 028 - training loss: 0.9338, validation loss: 0.4712
2024-06-01 22:21:55 [INFO]: Epoch 029 - training loss: 0.8889, validation loss: 0.3924
2024-06-01 22:21:56 [INFO]: Epoch 030 - training loss: 0.7937, validation loss: 0.3571
2024-06-01 22:21:56 [INFO]: Epoch 031 - training loss: 0.7772, validation loss: 0.4167
2024-06-01 22:21:56 [INFO]: Epoch 032 - training loss: 0.8113, validation loss: 0.3948
2024-06-01 22:21:57 [INFO]: Epoch 033 - training loss: 0.7910, validation loss: 0.4037
2024-06-01 22:21:57 [INFO]: Epoch 034 - training loss: 0.7710, validation loss: 0.2747
2024-06-01 22:21:57 [INFO]: Epoch 035 - training loss: 0.7586, validation loss: 0.3936
2024-06-01 22:21:58 [INFO]: Epoch 036 - training loss: 0.7454, validation loss: 0.4149
2024-06-01 22:21:58 [INFO]: Epoch 037 - training loss: 0.7278, validation loss: 0.3733
2024-06-01 22:21:59 [INFO]: Epoch 038 - training loss: 0.7188, validation loss: 0.3815
2024-06-01 22:21:59 [INFO]: Epoch 039 - training loss: 0.7227, validation loss: 0.3152
2024-06-01 22:21:59 [INFO]: Epoch 040 - training loss: 0.7060, validation loss: 0.2806
2024-06-01 22:22:00 [INFO]: Epoch 041 - training loss: 0.7144, validation loss: 0.3586
2024-06-01 22:22:00 [INFO]: Epoch 042 - training loss: 0.7268, validation loss: 0.2577
2024-06-01 22:22:00 [INFO]: Epoch 043 - training loss: 0.7170, validation loss: 0.3236
2024-06-01 22:22:01 [INFO]: Epoch 044 - training loss: 0.7056, validation loss: 0.2697
2024-06-01 22:22:01 [INFO]: Epoch 045 - training loss: 0.6974, validation loss: 0.2638
2024-06-01 22:22:02 [INFO]: Epoch 046 - training loss: 0.6927, validation loss: 0.2427
2024-06-01 22:22:02 [INFO]: Epoch 047 - training loss: 0.6771, validation loss: 0.2621
2024-06-01 22:22:02 [INFO]: Epoch 048 - training loss: 0.6653, validation loss: 0.2976
2024-06-01 22:22:03 [INFO]: Epoch 049 - training loss: 0.6699, validation loss: 0.2568
2024-06-01 22:22:03 [INFO]: Epoch 050 - training loss: 0.6683, validation loss: 0.3632
2024-06-01 22:22:03 [INFO]: Epoch 051 - training loss: 0.6414, validation loss: 0.2718
2024-06-01 22:22:04 [INFO]: Epoch 052 - training loss: 0.6434, validation loss: 0.3317
2024-06-01 22:22:04 [INFO]: Epoch 053 - training loss: 0.6416, validation loss: 0.3100
2024-06-01 22:22:04 [INFO]: Epoch 054 - training loss: 0.6446, validation loss: 0.3538
2024-06-01 22:22:05 [INFO]: Epoch 055 - training loss: 0.6379, validation loss: 0.3544
2024-06-01 22:22:05 [INFO]: Epoch 056 - training loss: 0.6585, validation loss: 0.3323
2024-06-01 22:22:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:22:05 [INFO]: Finished training. The best model is from epoch#46.
2024-06-01 22:22:05 [INFO]: Saved the model to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_4/20240601_T222145/Koopa.pypots
2024-06-01 22:22:05 [INFO]: Successfully saved to results_point_rate01/ETT_h1/Koopa_ETT_h1/round_4/imputation.pkl
2024-06-01 22:22:05 [INFO]: Round4 - Koopa on ETT_h1: MAE=0.4451, MSE=0.3535, MRE=0.5253
2024-06-01 22:22:05 [INFO]: Done! Final results:
Averaged Koopa (n params: 465,389) on ETT_h1: MAE=0.4349 ± 0.13226822814325975, MSE=0.4424 ± 0.2736044604788327, MRE=0.5132 ± 0.15608855427619847, average inference time=0.02
