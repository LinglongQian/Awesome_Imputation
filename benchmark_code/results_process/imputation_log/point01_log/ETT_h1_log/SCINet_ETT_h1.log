2024-06-01 22:22:12 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:22:12 [INFO]: Using the given device: cuda:0
2024-06-01 22:22:12 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_0/20240601_T222212
2024-06-01 22:22:12 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_0/20240601_T222212/tensorboard
2024-06-01 22:22:14 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-01 22:22:16 [INFO]: Epoch 001 - training loss: 1.5945, validation loss: 1.1396
2024-06-01 22:22:16 [INFO]: Epoch 002 - training loss: 1.4919, validation loss: 1.0871
2024-06-01 22:22:17 [INFO]: Epoch 003 - training loss: 1.3385, validation loss: 0.9730
2024-06-01 22:22:18 [INFO]: Epoch 004 - training loss: 1.1254, validation loss: 0.8096
2024-06-01 22:22:18 [INFO]: Epoch 005 - training loss: 0.9868, validation loss: 0.7109
2024-06-01 22:22:19 [INFO]: Epoch 006 - training loss: 0.8559, validation loss: 0.4890
2024-06-01 22:22:20 [INFO]: Epoch 007 - training loss: 0.7527, validation loss: 0.2920
2024-06-01 22:22:21 [INFO]: Epoch 008 - training loss: 0.6500, validation loss: 0.1965
2024-06-01 22:22:21 [INFO]: Epoch 009 - training loss: 0.5847, validation loss: 0.1559
2024-06-01 22:22:22 [INFO]: Epoch 010 - training loss: 0.5399, validation loss: 0.1511
2024-06-01 22:22:22 [INFO]: Epoch 011 - training loss: 0.5155, validation loss: 0.1299
2024-06-01 22:22:23 [INFO]: Epoch 012 - training loss: 0.4798, validation loss: 0.1183
2024-06-01 22:22:24 [INFO]: Epoch 013 - training loss: 0.4590, validation loss: 0.1160
2024-06-01 22:22:25 [INFO]: Epoch 014 - training loss: 0.4402, validation loss: 0.1040
2024-06-01 22:22:25 [INFO]: Epoch 015 - training loss: 0.4306, validation loss: 0.0999
2024-06-01 22:22:26 [INFO]: Epoch 016 - training loss: 0.4291, validation loss: 0.0962
2024-06-01 22:22:27 [INFO]: Epoch 017 - training loss: 0.4196, validation loss: 0.0952
2024-06-01 22:22:27 [INFO]: Epoch 018 - training loss: 0.4211, validation loss: 0.0829
2024-06-01 22:22:28 [INFO]: Epoch 019 - training loss: 0.4041, validation loss: 0.0928
2024-06-01 22:22:29 [INFO]: Epoch 020 - training loss: 0.4055, validation loss: 0.0857
2024-06-01 22:22:30 [INFO]: Epoch 021 - training loss: 0.4011, validation loss: 0.0821
2024-06-01 22:22:30 [INFO]: Epoch 022 - training loss: 0.3941, validation loss: 0.0812
2024-06-01 22:22:31 [INFO]: Epoch 023 - training loss: 0.3990, validation loss: 0.0847
2024-06-01 22:22:32 [INFO]: Epoch 024 - training loss: 0.3900, validation loss: 0.0811
2024-06-01 22:22:32 [INFO]: Epoch 025 - training loss: 0.3966, validation loss: 0.0823
2024-06-01 22:22:33 [INFO]: Epoch 026 - training loss: 0.3919, validation loss: 0.0766
2024-06-01 22:22:34 [INFO]: Epoch 027 - training loss: 0.3873, validation loss: 0.0820
2024-06-01 22:22:35 [INFO]: Epoch 028 - training loss: 0.3851, validation loss: 0.0754
2024-06-01 22:22:35 [INFO]: Epoch 029 - training loss: 0.3846, validation loss: 0.0772
2024-06-01 22:22:36 [INFO]: Epoch 030 - training loss: 0.3807, validation loss: 0.0773
2024-06-01 22:22:36 [INFO]: Epoch 031 - training loss: 0.3886, validation loss: 0.0779
2024-06-01 22:22:37 [INFO]: Epoch 032 - training loss: 0.3813, validation loss: 0.0756
2024-06-01 22:22:38 [INFO]: Epoch 033 - training loss: 0.3821, validation loss: 0.0792
2024-06-01 22:22:39 [INFO]: Epoch 034 - training loss: 0.3865, validation loss: 0.0815
2024-06-01 22:22:39 [INFO]: Epoch 035 - training loss: 0.3808, validation loss: 0.0706
2024-06-01 22:22:40 [INFO]: Epoch 036 - training loss: 0.3783, validation loss: 0.0774
2024-06-01 22:22:41 [INFO]: Epoch 037 - training loss: 0.3793, validation loss: 0.0803
2024-06-01 22:22:42 [INFO]: Epoch 038 - training loss: 0.3848, validation loss: 0.0814
2024-06-01 22:22:42 [INFO]: Epoch 039 - training loss: 0.3829, validation loss: 0.0731
2024-06-01 22:22:43 [INFO]: Epoch 040 - training loss: 0.3856, validation loss: 0.0812
2024-06-01 22:22:44 [INFO]: Epoch 041 - training loss: 0.3814, validation loss: 0.0818
2024-06-01 22:22:44 [INFO]: Epoch 042 - training loss: 0.3747, validation loss: 0.0742
2024-06-01 22:22:45 [INFO]: Epoch 043 - training loss: 0.3758, validation loss: 0.0742
2024-06-01 22:22:46 [INFO]: Epoch 044 - training loss: 0.3773, validation loss: 0.0760
2024-06-01 22:22:47 [INFO]: Epoch 045 - training loss: 0.3744, validation loss: 0.0775
2024-06-01 22:22:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:22:47 [INFO]: Finished training. The best model is from epoch#35.
2024-06-01 22:22:47 [INFO]: Saved the model to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_0/20240601_T222212/SCINet.pypots
2024-06-01 22:22:47 [INFO]: Successfully saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_0/imputation.pkl
2024-06-01 22:22:47 [INFO]: Round0 - SCINet on ETT_h1: MAE=0.2313, MSE=0.1047, MRE=0.2729
2024-06-01 22:22:47 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:22:47 [INFO]: Using the given device: cuda:0
2024-06-01 22:22:47 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_1/20240601_T222247
2024-06-01 22:22:47 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_1/20240601_T222247/tensorboard
2024-06-01 22:22:47 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-01 22:22:48 [INFO]: Epoch 001 - training loss: 1.6116, validation loss: 1.0276
2024-06-01 22:22:48 [INFO]: Epoch 002 - training loss: 1.4601, validation loss: 0.9015
2024-06-01 22:22:49 [INFO]: Epoch 003 - training loss: 1.2121, validation loss: 0.8819
2024-06-01 22:22:50 [INFO]: Epoch 004 - training loss: 0.9623, validation loss: 0.5189
2024-06-01 22:22:51 [INFO]: Epoch 005 - training loss: 0.8016, validation loss: 0.3466
2024-06-01 22:22:51 [INFO]: Epoch 006 - training loss: 0.7057, validation loss: 0.2647
2024-06-01 22:22:52 [INFO]: Epoch 007 - training loss: 0.6298, validation loss: 0.2070
2024-06-01 22:22:53 [INFO]: Epoch 008 - training loss: 0.5673, validation loss: 0.1897
2024-06-01 22:22:54 [INFO]: Epoch 009 - training loss: 0.5337, validation loss: 0.1678
2024-06-01 22:22:54 [INFO]: Epoch 010 - training loss: 0.5038, validation loss: 0.1503
2024-06-01 22:22:55 [INFO]: Epoch 011 - training loss: 0.4767, validation loss: 0.1292
2024-06-01 22:22:56 [INFO]: Epoch 012 - training loss: 0.4563, validation loss: 0.1315
2024-06-01 22:22:57 [INFO]: Epoch 013 - training loss: 0.4459, validation loss: 0.1172
2024-06-01 22:22:57 [INFO]: Epoch 014 - training loss: 0.4436, validation loss: 0.1163
2024-06-01 22:22:58 [INFO]: Epoch 015 - training loss: 0.4297, validation loss: 0.1076
2024-06-01 22:22:59 [INFO]: Epoch 016 - training loss: 0.4163, validation loss: 0.1173
2024-06-01 22:22:59 [INFO]: Epoch 017 - training loss: 0.4097, validation loss: 0.1088
2024-06-01 22:23:00 [INFO]: Epoch 018 - training loss: 0.4065, validation loss: 0.1065
2024-06-01 22:23:01 [INFO]: Epoch 019 - training loss: 0.4102, validation loss: 0.1061
2024-06-01 22:23:02 [INFO]: Epoch 020 - training loss: 0.4120, validation loss: 0.1061
2024-06-01 22:23:02 [INFO]: Epoch 021 - training loss: 0.4015, validation loss: 0.1065
2024-06-01 22:23:03 [INFO]: Epoch 022 - training loss: 0.3919, validation loss: 0.1015
2024-06-01 22:23:04 [INFO]: Epoch 023 - training loss: 0.3962, validation loss: 0.0977
2024-06-01 22:23:04 [INFO]: Epoch 024 - training loss: 0.3953, validation loss: 0.1038
2024-06-01 22:23:05 [INFO]: Epoch 025 - training loss: 0.3973, validation loss: 0.1000
2024-06-01 22:23:06 [INFO]: Epoch 026 - training loss: 0.3904, validation loss: 0.1063
2024-06-01 22:23:06 [INFO]: Epoch 027 - training loss: 0.3992, validation loss: 0.1007
2024-06-01 22:23:07 [INFO]: Epoch 028 - training loss: 0.3949, validation loss: 0.0982
2024-06-01 22:23:08 [INFO]: Epoch 029 - training loss: 0.3951, validation loss: 0.0907
2024-06-01 22:23:08 [INFO]: Epoch 030 - training loss: 0.3873, validation loss: 0.0891
2024-06-01 22:23:09 [INFO]: Epoch 031 - training loss: 0.3862, validation loss: 0.0950
2024-06-01 22:23:10 [INFO]: Epoch 032 - training loss: 0.3819, validation loss: 0.0911
2024-06-01 22:23:11 [INFO]: Epoch 033 - training loss: 0.3881, validation loss: 0.0989
2024-06-01 22:23:11 [INFO]: Epoch 034 - training loss: 0.3837, validation loss: 0.0863
2024-06-01 22:23:12 [INFO]: Epoch 035 - training loss: 0.3835, validation loss: 0.0995
2024-06-01 22:23:13 [INFO]: Epoch 036 - training loss: 0.3804, validation loss: 0.0908
2024-06-01 22:23:14 [INFO]: Epoch 037 - training loss: 0.3785, validation loss: 0.0909
2024-06-01 22:23:14 [INFO]: Epoch 038 - training loss: 0.3769, validation loss: 0.0879
2024-06-01 22:23:15 [INFO]: Epoch 039 - training loss: 0.3749, validation loss: 0.0940
2024-06-01 22:23:16 [INFO]: Epoch 040 - training loss: 0.3710, validation loss: 0.0864
2024-06-01 22:23:16 [INFO]: Epoch 041 - training loss: 0.3686, validation loss: 0.0922
2024-06-01 22:23:17 [INFO]: Epoch 042 - training loss: 0.3728, validation loss: 0.0895
2024-06-01 22:23:18 [INFO]: Epoch 043 - training loss: 0.3697, validation loss: 0.0874
2024-06-01 22:23:18 [INFO]: Epoch 044 - training loss: 0.3676, validation loss: 0.0847
2024-06-01 22:23:19 [INFO]: Epoch 045 - training loss: 0.3669, validation loss: 0.0826
2024-06-01 22:23:20 [INFO]: Epoch 046 - training loss: 0.3722, validation loss: 0.0892
2024-06-01 22:23:20 [INFO]: Epoch 047 - training loss: 0.3714, validation loss: 0.0865
2024-06-01 22:23:21 [INFO]: Epoch 048 - training loss: 0.3742, validation loss: 0.0849
2024-06-01 22:23:22 [INFO]: Epoch 049 - training loss: 0.3656, validation loss: 0.0891
2024-06-01 22:23:22 [INFO]: Epoch 050 - training loss: 0.3652, validation loss: 0.0921
2024-06-01 22:23:23 [INFO]: Epoch 051 - training loss: 0.3660, validation loss: 0.0815
2024-06-01 22:23:24 [INFO]: Epoch 052 - training loss: 0.3627, validation loss: 0.0826
2024-06-01 22:23:25 [INFO]: Epoch 053 - training loss: 0.3597, validation loss: 0.0777
2024-06-01 22:23:25 [INFO]: Epoch 054 - training loss: 0.3601, validation loss: 0.0869
2024-06-01 22:23:26 [INFO]: Epoch 055 - training loss: 0.3592, validation loss: 0.0816
2024-06-01 22:23:27 [INFO]: Epoch 056 - training loss: 0.3594, validation loss: 0.0844
2024-06-01 22:23:27 [INFO]: Epoch 057 - training loss: 0.3541, validation loss: 0.0819
2024-06-01 22:23:28 [INFO]: Epoch 058 - training loss: 0.3512, validation loss: 0.0828
2024-06-01 22:23:29 [INFO]: Epoch 059 - training loss: 0.3522, validation loss: 0.0792
2024-06-01 22:23:29 [INFO]: Epoch 060 - training loss: 0.3549, validation loss: 0.0914
2024-06-01 22:23:30 [INFO]: Epoch 061 - training loss: 0.3540, validation loss: 0.0810
2024-06-01 22:23:31 [INFO]: Epoch 062 - training loss: 0.3572, validation loss: 0.0840
2024-06-01 22:23:31 [INFO]: Epoch 063 - training loss: 0.3585, validation loss: 0.0866
2024-06-01 22:23:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:23:31 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 22:23:31 [INFO]: Saved the model to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_1/20240601_T222247/SCINet.pypots
2024-06-01 22:23:32 [INFO]: Successfully saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_1/imputation.pkl
2024-06-01 22:23:32 [INFO]: Round1 - SCINet on ETT_h1: MAE=0.2379, MSE=0.1082, MRE=0.2807
2024-06-01 22:23:32 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:23:32 [INFO]: Using the given device: cuda:0
2024-06-01 22:23:32 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_2/20240601_T222332
2024-06-01 22:23:32 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_2/20240601_T222332/tensorboard
2024-06-01 22:23:32 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-01 22:23:32 [INFO]: Epoch 001 - training loss: 1.4848, validation loss: 0.8958
2024-06-01 22:23:33 [INFO]: Epoch 002 - training loss: 1.1601, validation loss: 0.6898
2024-06-01 22:23:34 [INFO]: Epoch 003 - training loss: 0.9707, validation loss: 0.4321
2024-06-01 22:23:35 [INFO]: Epoch 004 - training loss: 0.8126, validation loss: 0.3354
2024-06-01 22:23:35 [INFO]: Epoch 005 - training loss: 0.7374, validation loss: 0.2425
2024-06-01 22:23:36 [INFO]: Epoch 006 - training loss: 0.6865, validation loss: 0.2233
2024-06-01 22:23:37 [INFO]: Epoch 007 - training loss: 0.6430, validation loss: 0.1987
2024-06-01 22:23:37 [INFO]: Epoch 008 - training loss: 0.6019, validation loss: 0.1919
2024-06-01 22:23:38 [INFO]: Epoch 009 - training loss: 0.5729, validation loss: 0.1694
2024-06-01 22:23:39 [INFO]: Epoch 010 - training loss: 0.5468, validation loss: 0.1568
2024-06-01 22:23:39 [INFO]: Epoch 011 - training loss: 0.5368, validation loss: 0.1690
2024-06-01 22:23:40 [INFO]: Epoch 012 - training loss: 0.5238, validation loss: 0.1918
2024-06-01 22:23:41 [INFO]: Epoch 013 - training loss: 0.5062, validation loss: 0.1351
2024-06-01 22:23:42 [INFO]: Epoch 014 - training loss: 0.4995, validation loss: 0.1774
2024-06-01 22:23:42 [INFO]: Epoch 015 - training loss: 0.4933, validation loss: 0.1587
2024-06-01 22:23:43 [INFO]: Epoch 016 - training loss: 0.4790, validation loss: 0.1348
2024-06-01 22:23:44 [INFO]: Epoch 017 - training loss: 0.4760, validation loss: 0.1636
2024-06-01 22:23:44 [INFO]: Epoch 018 - training loss: 0.4730, validation loss: 0.1386
2024-06-01 22:23:45 [INFO]: Epoch 019 - training loss: 0.4663, validation loss: 0.1350
2024-06-01 22:23:46 [INFO]: Epoch 020 - training loss: 0.4639, validation loss: 0.1472
2024-06-01 22:23:46 [INFO]: Epoch 021 - training loss: 0.4588, validation loss: 0.1240
2024-06-01 22:23:47 [INFO]: Epoch 022 - training loss: 0.4643, validation loss: 0.1700
2024-06-01 22:23:47 [INFO]: Epoch 023 - training loss: 0.4567, validation loss: 0.1180
2024-06-01 22:23:48 [INFO]: Epoch 024 - training loss: 0.4558, validation loss: 0.1448
2024-06-01 22:23:48 [INFO]: Epoch 025 - training loss: 0.4456, validation loss: 0.1209
2024-06-01 22:23:49 [INFO]: Epoch 026 - training loss: 0.4374, validation loss: 0.1439
2024-06-01 22:23:49 [INFO]: Epoch 027 - training loss: 0.4309, validation loss: 0.1117
2024-06-01 22:23:50 [INFO]: Epoch 028 - training loss: 0.4364, validation loss: 0.1507
2024-06-01 22:23:51 [INFO]: Epoch 029 - training loss: 0.4280, validation loss: 0.1290
2024-06-01 22:23:51 [INFO]: Epoch 030 - training loss: 0.4299, validation loss: 0.1406
2024-06-01 22:23:52 [INFO]: Epoch 031 - training loss: 0.4186, validation loss: 0.1160
2024-06-01 22:23:53 [INFO]: Epoch 032 - training loss: 0.4136, validation loss: 0.1204
2024-06-01 22:23:54 [INFO]: Epoch 033 - training loss: 0.4135, validation loss: 0.1142
2024-06-01 22:23:54 [INFO]: Epoch 034 - training loss: 0.4163, validation loss: 0.1357
2024-06-01 22:23:55 [INFO]: Epoch 035 - training loss: 0.4198, validation loss: 0.1068
2024-06-01 22:23:56 [INFO]: Epoch 036 - training loss: 0.4205, validation loss: 0.1202
2024-06-01 22:23:56 [INFO]: Epoch 037 - training loss: 0.4162, validation loss: 0.1157
2024-06-01 22:23:57 [INFO]: Epoch 038 - training loss: 0.4029, validation loss: 0.1245
2024-06-01 22:23:58 [INFO]: Epoch 039 - training loss: 0.4094, validation loss: 0.1259
2024-06-01 22:23:58 [INFO]: Epoch 040 - training loss: 0.4218, validation loss: 0.1169
2024-06-01 22:23:59 [INFO]: Epoch 041 - training loss: 0.4106, validation loss: 0.1088
2024-06-01 22:24:00 [INFO]: Epoch 042 - training loss: 0.4086, validation loss: 0.1207
2024-06-01 22:24:01 [INFO]: Epoch 043 - training loss: 0.4060, validation loss: 0.1118
2024-06-01 22:24:01 [INFO]: Epoch 044 - training loss: 0.3907, validation loss: 0.1183
2024-06-01 22:24:02 [INFO]: Epoch 045 - training loss: 0.3908, validation loss: 0.1117
2024-06-01 22:24:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:24:02 [INFO]: Finished training. The best model is from epoch#35.
2024-06-01 22:24:02 [INFO]: Saved the model to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_2/20240601_T222332/SCINet.pypots
2024-06-01 22:24:02 [INFO]: Successfully saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_2/imputation.pkl
2024-06-01 22:24:02 [INFO]: Round2 - SCINet on ETT_h1: MAE=0.2738, MSE=0.1406, MRE=0.3231
2024-06-01 22:24:02 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:24:02 [INFO]: Using the given device: cuda:0
2024-06-01 22:24:02 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_3/20240601_T222402
2024-06-01 22:24:02 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_3/20240601_T222402/tensorboard
2024-06-01 22:24:02 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-01 22:24:03 [INFO]: Epoch 001 - training loss: 1.5868, validation loss: 1.1451
2024-06-01 22:24:04 [INFO]: Epoch 002 - training loss: 1.3962, validation loss: 0.9284
2024-06-01 22:24:04 [INFO]: Epoch 003 - training loss: 1.0994, validation loss: 0.7004
2024-06-01 22:24:05 [INFO]: Epoch 004 - training loss: 0.9252, validation loss: 0.5202
2024-06-01 22:24:06 [INFO]: Epoch 005 - training loss: 0.7883, validation loss: 0.4055
2024-06-01 22:24:07 [INFO]: Epoch 006 - training loss: 0.7023, validation loss: 0.2458
2024-06-01 22:24:07 [INFO]: Epoch 007 - training loss: 0.6252, validation loss: 0.1959
2024-06-01 22:24:08 [INFO]: Epoch 008 - training loss: 0.5715, validation loss: 0.1782
2024-06-01 22:24:08 [INFO]: Epoch 009 - training loss: 0.5246, validation loss: 0.1579
2024-06-01 22:24:09 [INFO]: Epoch 010 - training loss: 0.5034, validation loss: 0.1405
2024-06-01 22:24:10 [INFO]: Epoch 011 - training loss: 0.4791, validation loss: 0.1499
2024-06-01 22:24:11 [INFO]: Epoch 012 - training loss: 0.4611, validation loss: 0.1007
2024-06-01 22:24:11 [INFO]: Epoch 013 - training loss: 0.4543, validation loss: 0.1204
2024-06-01 22:24:12 [INFO]: Epoch 014 - training loss: 0.4404, validation loss: 0.1147
2024-06-01 22:24:13 [INFO]: Epoch 015 - training loss: 0.4266, validation loss: 0.1088
2024-06-01 22:24:13 [INFO]: Epoch 016 - training loss: 0.4219, validation loss: 0.0943
2024-06-01 22:24:14 [INFO]: Epoch 017 - training loss: 0.4142, validation loss: 0.0979
2024-06-01 22:24:15 [INFO]: Epoch 018 - training loss: 0.4091, validation loss: 0.0933
2024-06-01 22:24:15 [INFO]: Epoch 019 - training loss: 0.4104, validation loss: 0.0922
2024-06-01 22:24:16 [INFO]: Epoch 020 - training loss: 0.4022, validation loss: 0.0945
2024-06-01 22:24:16 [INFO]: Epoch 021 - training loss: 0.4039, validation loss: 0.0870
2024-06-01 22:24:17 [INFO]: Epoch 022 - training loss: 0.3974, validation loss: 0.0827
2024-06-01 22:24:18 [INFO]: Epoch 023 - training loss: 0.3989, validation loss: 0.0947
2024-06-01 22:24:18 [INFO]: Epoch 024 - training loss: 0.3912, validation loss: 0.0754
2024-06-01 22:24:19 [INFO]: Epoch 025 - training loss: 0.3872, validation loss: 0.0793
2024-06-01 22:24:20 [INFO]: Epoch 026 - training loss: 0.3918, validation loss: 0.0738
2024-06-01 22:24:21 [INFO]: Epoch 027 - training loss: 0.3893, validation loss: 0.0927
2024-06-01 22:24:21 [INFO]: Epoch 028 - training loss: 0.3895, validation loss: 0.0757
2024-06-01 22:24:22 [INFO]: Epoch 029 - training loss: 0.3846, validation loss: 0.0704
2024-06-01 22:24:23 [INFO]: Epoch 030 - training loss: 0.3786, validation loss: 0.0845
2024-06-01 22:24:23 [INFO]: Epoch 031 - training loss: 0.3822, validation loss: 0.0690
2024-06-01 22:24:24 [INFO]: Epoch 032 - training loss: 0.3798, validation loss: 0.0821
2024-06-01 22:24:24 [INFO]: Epoch 033 - training loss: 0.3722, validation loss: 0.0717
2024-06-01 22:24:25 [INFO]: Epoch 034 - training loss: 0.3728, validation loss: 0.0761
2024-06-01 22:24:26 [INFO]: Epoch 035 - training loss: 0.3771, validation loss: 0.0759
2024-06-01 22:24:27 [INFO]: Epoch 036 - training loss: 0.3701, validation loss: 0.0732
2024-06-01 22:24:27 [INFO]: Epoch 037 - training loss: 0.3669, validation loss: 0.0716
2024-06-01 22:24:28 [INFO]: Epoch 038 - training loss: 0.3700, validation loss: 0.0766
2024-06-01 22:24:29 [INFO]: Epoch 039 - training loss: 0.3718, validation loss: 0.0716
2024-06-01 22:24:29 [INFO]: Epoch 040 - training loss: 0.3680, validation loss: 0.0712
2024-06-01 22:24:30 [INFO]: Epoch 041 - training loss: 0.3659, validation loss: 0.0724
2024-06-01 22:24:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:24:30 [INFO]: Finished training. The best model is from epoch#31.
2024-06-01 22:24:30 [INFO]: Saved the model to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_3/20240601_T222402/SCINet.pypots
2024-06-01 22:24:30 [INFO]: Successfully saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_3/imputation.pkl
2024-06-01 22:24:30 [INFO]: Round3 - SCINet on ETT_h1: MAE=0.2241, MSE=0.1012, MRE=0.2645
2024-06-01 22:24:30 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:24:30 [INFO]: Using the given device: cuda:0
2024-06-01 22:24:30 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_4/20240601_T222430
2024-06-01 22:24:30 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_4/20240601_T222430/tensorboard
2024-06-01 22:24:30 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-01 22:24:31 [INFO]: Epoch 001 - training loss: 1.5424, validation loss: 1.0360
2024-06-01 22:24:32 [INFO]: Epoch 002 - training loss: 1.2869, validation loss: 0.8576
2024-06-01 22:24:32 [INFO]: Epoch 003 - training loss: 1.0678, validation loss: 0.6488
2024-06-01 22:24:33 [INFO]: Epoch 004 - training loss: 0.9349, validation loss: 0.5960
2024-06-01 22:24:34 [INFO]: Epoch 005 - training loss: 0.8249, validation loss: 0.3713
2024-06-01 22:24:34 [INFO]: Epoch 006 - training loss: 0.7404, validation loss: 0.2700
2024-06-01 22:24:35 [INFO]: Epoch 007 - training loss: 0.6896, validation loss: 0.2247
2024-06-01 22:24:36 [INFO]: Epoch 008 - training loss: 0.6527, validation loss: 0.2028
2024-06-01 22:24:36 [INFO]: Epoch 009 - training loss: 0.6090, validation loss: 0.1926
2024-06-01 22:24:37 [INFO]: Epoch 010 - training loss: 0.5735, validation loss: 0.1877
2024-06-01 22:24:38 [INFO]: Epoch 011 - training loss: 0.5569, validation loss: 0.1852
2024-06-01 22:24:38 [INFO]: Epoch 012 - training loss: 0.5367, validation loss: 0.1742
2024-06-01 22:24:39 [INFO]: Epoch 013 - training loss: 0.5248, validation loss: 0.1527
2024-06-01 22:24:40 [INFO]: Epoch 014 - training loss: 0.5232, validation loss: 0.1615
2024-06-01 22:24:40 [INFO]: Epoch 015 - training loss: 0.5220, validation loss: 0.1706
2024-06-01 22:24:41 [INFO]: Epoch 016 - training loss: 0.5145, validation loss: 0.1462
2024-06-01 22:24:42 [INFO]: Epoch 017 - training loss: 0.5047, validation loss: 0.1536
2024-06-01 22:24:42 [INFO]: Epoch 018 - training loss: 0.5044, validation loss: 0.1714
2024-06-01 22:24:43 [INFO]: Epoch 019 - training loss: 0.5111, validation loss: 0.1585
2024-06-01 22:24:44 [INFO]: Epoch 020 - training loss: 0.5095, validation loss: 0.1568
2024-06-01 22:24:44 [INFO]: Epoch 021 - training loss: 0.4973, validation loss: 0.1490
2024-06-01 22:24:45 [INFO]: Epoch 022 - training loss: 0.4840, validation loss: 0.1508
2024-06-01 22:24:46 [INFO]: Epoch 023 - training loss: 0.4713, validation loss: 0.1489
2024-06-01 22:24:46 [INFO]: Epoch 024 - training loss: 0.4690, validation loss: 0.1530
2024-06-01 22:24:47 [INFO]: Epoch 025 - training loss: 0.4618, validation loss: 0.1491
2024-06-01 22:24:48 [INFO]: Epoch 026 - training loss: 0.4512, validation loss: 0.1260
2024-06-01 22:24:49 [INFO]: Epoch 027 - training loss: 0.4496, validation loss: 0.1299
2024-06-01 22:24:49 [INFO]: Epoch 028 - training loss: 0.4473, validation loss: 0.1345
2024-06-01 22:24:50 [INFO]: Epoch 029 - training loss: 0.4401, validation loss: 0.1266
2024-06-01 22:24:51 [INFO]: Epoch 030 - training loss: 0.4445, validation loss: 0.1350
2024-06-01 22:24:52 [INFO]: Epoch 031 - training loss: 0.4407, validation loss: 0.1238
2024-06-01 22:24:52 [INFO]: Epoch 032 - training loss: 0.4417, validation loss: 0.1306
2024-06-01 22:24:53 [INFO]: Epoch 033 - training loss: 0.4481, validation loss: 0.1184
2024-06-01 22:24:54 [INFO]: Epoch 034 - training loss: 0.4351, validation loss: 0.1259
2024-06-01 22:24:55 [INFO]: Epoch 035 - training loss: 0.4310, validation loss: 0.1167
2024-06-01 22:24:55 [INFO]: Epoch 036 - training loss: 0.4206, validation loss: 0.1143
2024-06-01 22:24:56 [INFO]: Epoch 037 - training loss: 0.4264, validation loss: 0.1121
2024-06-01 22:24:57 [INFO]: Epoch 038 - training loss: 0.4221, validation loss: 0.1237
2024-06-01 22:24:57 [INFO]: Epoch 039 - training loss: 0.4287, validation loss: 0.1122
2024-06-01 22:24:58 [INFO]: Epoch 040 - training loss: 0.4173, validation loss: 0.1211
2024-06-01 22:24:59 [INFO]: Epoch 041 - training loss: 0.4117, validation loss: 0.1138
2024-06-01 22:25:00 [INFO]: Epoch 042 - training loss: 0.4083, validation loss: 0.1171
2024-06-01 22:25:00 [INFO]: Epoch 043 - training loss: 0.4130, validation loss: 0.1189
2024-06-01 22:25:01 [INFO]: Epoch 044 - training loss: 0.4181, validation loss: 0.1098
2024-06-01 22:25:02 [INFO]: Epoch 045 - training loss: 0.4114, validation loss: 0.1158
2024-06-01 22:25:02 [INFO]: Epoch 046 - training loss: 0.4010, validation loss: 0.1035
2024-06-01 22:25:03 [INFO]: Epoch 047 - training loss: 0.4055, validation loss: 0.1024
2024-06-01 22:25:04 [INFO]: Epoch 048 - training loss: 0.4137, validation loss: 0.1066
2024-06-01 22:25:05 [INFO]: Epoch 049 - training loss: 0.4010, validation loss: 0.1147
2024-06-01 22:25:05 [INFO]: Epoch 050 - training loss: 0.4190, validation loss: 0.1049
2024-06-01 22:25:06 [INFO]: Epoch 051 - training loss: 0.4155, validation loss: 0.1214
2024-06-01 22:25:07 [INFO]: Epoch 052 - training loss: 0.4070, validation loss: 0.1043
2024-06-01 22:25:07 [INFO]: Epoch 053 - training loss: 0.4035, validation loss: 0.0978
2024-06-01 22:25:08 [INFO]: Epoch 054 - training loss: 0.3988, validation loss: 0.1102
2024-06-01 22:25:08 [INFO]: Epoch 055 - training loss: 0.3988, validation loss: 0.1124
2024-06-01 22:25:09 [INFO]: Epoch 056 - training loss: 0.4012, validation loss: 0.1010
2024-06-01 22:25:09 [INFO]: Epoch 057 - training loss: 0.4136, validation loss: 0.1198
2024-06-01 22:25:10 [INFO]: Epoch 058 - training loss: 0.3976, validation loss: 0.1090
2024-06-01 22:25:11 [INFO]: Epoch 059 - training loss: 0.3949, validation loss: 0.1060
2024-06-01 22:25:11 [INFO]: Epoch 060 - training loss: 0.3980, validation loss: 0.1040
2024-06-01 22:25:12 [INFO]: Epoch 061 - training loss: 0.3959, validation loss: 0.0943
2024-06-01 22:25:13 [INFO]: Epoch 062 - training loss: 0.3924, validation loss: 0.1002
2024-06-01 22:25:13 [INFO]: Epoch 063 - training loss: 0.3921, validation loss: 0.1126
2024-06-01 22:25:14 [INFO]: Epoch 064 - training loss: 0.3995, validation loss: 0.1144
2024-06-01 22:25:15 [INFO]: Epoch 065 - training loss: 0.4013, validation loss: 0.1072
2024-06-01 22:25:15 [INFO]: Epoch 066 - training loss: 0.4172, validation loss: 0.1260
2024-06-01 22:25:16 [INFO]: Epoch 067 - training loss: 0.4193, validation loss: 0.1109
2024-06-01 22:25:17 [INFO]: Epoch 068 - training loss: 0.4113, validation loss: 0.0999
2024-06-01 22:25:17 [INFO]: Epoch 069 - training loss: 0.4044, validation loss: 0.1164
2024-06-01 22:25:18 [INFO]: Epoch 070 - training loss: 0.3997, validation loss: 0.1001
2024-06-01 22:25:19 [INFO]: Epoch 071 - training loss: 0.3944, validation loss: 0.0987
2024-06-01 22:25:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:25:19 [INFO]: Finished training. The best model is from epoch#61.
2024-06-01 22:25:19 [INFO]: Saved the model to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_4/20240601_T222430/SCINet.pypots
2024-06-01 22:25:19 [INFO]: Successfully saved to results_point_rate01/ETT_h1/SCINet_ETT_h1/round_4/imputation.pkl
2024-06-01 22:25:19 [INFO]: Round4 - SCINet on ETT_h1: MAE=0.2630, MSE=0.1294, MRE=0.3104
2024-06-01 22:25:19 [INFO]: Done! Final results:
Averaged SCINet (n params: 79,493) on ETT_h1: MAE=0.2460 ± 0.019089415835693537, MSE=0.1168 ± 0.015426090270084488, MRE=0.2903 ± 0.022527249072568846, average inference time=0.05
