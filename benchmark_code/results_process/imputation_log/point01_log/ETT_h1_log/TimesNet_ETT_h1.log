2024-06-01 22:32:49 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 22:32:49 [INFO]: Using the given device: cuda:0
2024-06-01 22:32:49 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_0/20240601_T223249
2024-06-01 22:32:49 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_0/20240601_T223249/tensorboard
2024-06-01 22:32:49 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-01 22:32:52 [INFO]: Epoch 001 - training loss: 0.6048, validation loss: 0.3224
2024-06-01 22:32:52 [INFO]: Epoch 002 - training loss: 0.2904, validation loss: 0.2034
2024-06-01 22:32:52 [INFO]: Epoch 003 - training loss: 0.1957, validation loss: 0.1605
2024-06-01 22:32:53 [INFO]: Epoch 004 - training loss: 0.1471, validation loss: 0.1375
2024-06-01 22:32:53 [INFO]: Epoch 005 - training loss: 0.1307, validation loss: 0.1047
2024-06-01 22:32:53 [INFO]: Epoch 006 - training loss: 0.1182, validation loss: 0.1021
2024-06-01 22:32:53 [INFO]: Epoch 007 - training loss: 0.1107, validation loss: 0.0940
2024-06-01 22:32:53 [INFO]: Epoch 008 - training loss: 0.1059, validation loss: 0.0920
2024-06-01 22:32:53 [INFO]: Epoch 009 - training loss: 0.1037, validation loss: 0.0992
2024-06-01 22:32:53 [INFO]: Epoch 010 - training loss: 0.0980, validation loss: 0.0883
2024-06-01 22:32:53 [INFO]: Epoch 011 - training loss: 0.0956, validation loss: 0.0918
2024-06-01 22:32:54 [INFO]: Epoch 012 - training loss: 0.0927, validation loss: 0.0896
2024-06-01 22:32:54 [INFO]: Epoch 013 - training loss: 0.0924, validation loss: 0.0864
2024-06-01 22:32:54 [INFO]: Epoch 014 - training loss: 0.0924, validation loss: 0.0905
2024-06-01 22:32:54 [INFO]: Epoch 015 - training loss: 0.0901, validation loss: 0.0906
2024-06-01 22:32:54 [INFO]: Epoch 016 - training loss: 0.0912, validation loss: 0.0872
2024-06-01 22:32:54 [INFO]: Epoch 017 - training loss: 0.0895, validation loss: 0.0757
2024-06-01 22:32:55 [INFO]: Epoch 018 - training loss: 0.0922, validation loss: 0.0971
2024-06-01 22:32:55 [INFO]: Epoch 019 - training loss: 0.0877, validation loss: 0.0822
2024-06-01 22:32:55 [INFO]: Epoch 020 - training loss: 0.0889, validation loss: 0.0804
2024-06-01 22:32:55 [INFO]: Epoch 021 - training loss: 0.0874, validation loss: 0.0883
2024-06-01 22:32:55 [INFO]: Epoch 022 - training loss: 0.0860, validation loss: 0.0821
2024-06-01 22:32:55 [INFO]: Epoch 023 - training loss: 0.0864, validation loss: 0.0838
2024-06-01 22:32:55 [INFO]: Epoch 024 - training loss: 0.0806, validation loss: 0.0796
2024-06-01 22:32:56 [INFO]: Epoch 025 - training loss: 0.0809, validation loss: 0.0810
2024-06-01 22:32:56 [INFO]: Epoch 026 - training loss: 0.0864, validation loss: 0.0800
2024-06-01 22:32:56 [INFO]: Epoch 027 - training loss: 0.0837, validation loss: 0.0835
2024-06-01 22:32:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:32:56 [INFO]: Finished training. The best model is from epoch#17.
2024-06-01 22:32:56 [INFO]: Saved the model to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_0/20240601_T223249/TimesNet.pypots
2024-06-01 22:32:56 [INFO]: Successfully saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_0/imputation.pkl
2024-06-01 22:32:56 [INFO]: Round0 - TimesNet on ETT_h1: MAE=0.2667, MSE=0.1284, MRE=0.3148
2024-06-01 22:32:56 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:32:56 [INFO]: Using the given device: cuda:0
2024-06-01 22:32:56 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_1/20240601_T223256
2024-06-01 22:32:56 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_1/20240601_T223256/tensorboard
2024-06-01 22:32:56 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-01 22:32:57 [INFO]: Epoch 001 - training loss: 0.6429, validation loss: 0.4745
2024-06-01 22:32:57 [INFO]: Epoch 002 - training loss: 0.2795, validation loss: 0.2043
2024-06-01 22:32:57 [INFO]: Epoch 003 - training loss: 0.1785, validation loss: 0.1570
2024-06-01 22:32:57 [INFO]: Epoch 004 - training loss: 0.1411, validation loss: 0.1220
2024-06-01 22:32:57 [INFO]: Epoch 005 - training loss: 0.1230, validation loss: 0.0986
2024-06-01 22:32:57 [INFO]: Epoch 006 - training loss: 0.1156, validation loss: 0.0973
2024-06-01 22:32:57 [INFO]: Epoch 007 - training loss: 0.1113, validation loss: 0.1075
2024-06-01 22:32:58 [INFO]: Epoch 008 - training loss: 0.1013, validation loss: 0.0912
2024-06-01 22:32:58 [INFO]: Epoch 009 - training loss: 0.0979, validation loss: 0.0877
2024-06-01 22:32:58 [INFO]: Epoch 010 - training loss: 0.0951, validation loss: 0.0881
2024-06-01 22:32:58 [INFO]: Epoch 011 - training loss: 0.0947, validation loss: 0.0877
2024-06-01 22:32:58 [INFO]: Epoch 012 - training loss: 0.0991, validation loss: 0.0853
2024-06-01 22:32:58 [INFO]: Epoch 013 - training loss: 0.0915, validation loss: 0.0784
2024-06-01 22:32:59 [INFO]: Epoch 014 - training loss: 0.0948, validation loss: 0.0904
2024-06-01 22:32:59 [INFO]: Epoch 015 - training loss: 0.0913, validation loss: 0.0809
2024-06-01 22:32:59 [INFO]: Epoch 016 - training loss: 0.0899, validation loss: 0.0919
2024-06-01 22:32:59 [INFO]: Epoch 017 - training loss: 0.0926, validation loss: 0.0802
2024-06-01 22:32:59 [INFO]: Epoch 018 - training loss: 0.0922, validation loss: 0.0817
2024-06-01 22:32:59 [INFO]: Epoch 019 - training loss: 0.0910, validation loss: 0.0992
2024-06-01 22:33:00 [INFO]: Epoch 020 - training loss: 0.0850, validation loss: 0.0864
2024-06-01 22:33:00 [INFO]: Epoch 021 - training loss: 0.0849, validation loss: 0.0842
2024-06-01 22:33:00 [INFO]: Epoch 022 - training loss: 0.0848, validation loss: 0.0835
2024-06-01 22:33:00 [INFO]: Epoch 023 - training loss: 0.0844, validation loss: 0.0818
2024-06-01 22:33:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:33:00 [INFO]: Finished training. The best model is from epoch#13.
2024-06-01 22:33:00 [INFO]: Saved the model to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_1/20240601_T223256/TimesNet.pypots
2024-06-01 22:33:00 [INFO]: Successfully saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_1/imputation.pkl
2024-06-01 22:33:00 [INFO]: Round1 - TimesNet on ETT_h1: MAE=0.2579, MSE=0.1243, MRE=0.3044
2024-06-01 22:33:00 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 22:33:00 [INFO]: Using the given device: cuda:0
2024-06-01 22:33:00 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_2/20240601_T223300
2024-06-01 22:33:00 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_2/20240601_T223300/tensorboard
2024-06-01 22:33:00 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-01 22:33:00 [INFO]: Epoch 001 - training loss: 0.6606, validation loss: 0.3404
2024-06-01 22:33:01 [INFO]: Epoch 002 - training loss: 0.2717, validation loss: 0.2014
2024-06-01 22:33:01 [INFO]: Epoch 003 - training loss: 0.1802, validation loss: 0.1603
2024-06-01 22:33:01 [INFO]: Epoch 004 - training loss: 0.1482, validation loss: 0.1229
2024-06-01 22:33:01 [INFO]: Epoch 005 - training loss: 0.1266, validation loss: 0.1065
2024-06-01 22:33:01 [INFO]: Epoch 006 - training loss: 0.1225, validation loss: 0.1027
2024-06-01 22:33:01 [INFO]: Epoch 007 - training loss: 0.1099, validation loss: 0.1037
2024-06-01 22:33:01 [INFO]: Epoch 008 - training loss: 0.1032, validation loss: 0.0941
2024-06-01 22:33:01 [INFO]: Epoch 009 - training loss: 0.1007, validation loss: 0.0961
2024-06-01 22:33:01 [INFO]: Epoch 010 - training loss: 0.1037, validation loss: 0.0892
2024-06-01 22:33:02 [INFO]: Epoch 011 - training loss: 0.0983, validation loss: 0.0935
2024-06-01 22:33:02 [INFO]: Epoch 012 - training loss: 0.0955, validation loss: 0.0953
2024-06-01 22:33:02 [INFO]: Epoch 013 - training loss: 0.0935, validation loss: 0.0842
2024-06-01 22:33:02 [INFO]: Epoch 014 - training loss: 0.0909, validation loss: 0.0896
2024-06-01 22:33:02 [INFO]: Epoch 015 - training loss: 0.0942, validation loss: 0.0949
2024-06-01 22:33:02 [INFO]: Epoch 016 - training loss: 0.0871, validation loss: 0.0831
2024-06-01 22:33:02 [INFO]: Epoch 017 - training loss: 0.0898, validation loss: 0.0823
2024-06-01 22:33:03 [INFO]: Epoch 018 - training loss: 0.0895, validation loss: 0.0840
2024-06-01 22:33:03 [INFO]: Epoch 019 - training loss: 0.0923, validation loss: 0.0808
2024-06-01 22:33:03 [INFO]: Epoch 020 - training loss: 0.0945, validation loss: 0.0937
2024-06-01 22:33:03 [INFO]: Epoch 021 - training loss: 0.0894, validation loss: 0.0789
2024-06-01 22:33:03 [INFO]: Epoch 022 - training loss: 0.0833, validation loss: 0.0832
2024-06-01 22:33:03 [INFO]: Epoch 023 - training loss: 0.0903, validation loss: 0.0777
2024-06-01 22:33:03 [INFO]: Epoch 024 - training loss: 0.0889, validation loss: 0.0841
2024-06-01 22:33:04 [INFO]: Epoch 025 - training loss: 0.0870, validation loss: 0.0817
2024-06-01 22:33:04 [INFO]: Epoch 026 - training loss: 0.0863, validation loss: 0.0786
2024-06-01 22:33:04 [INFO]: Epoch 027 - training loss: 0.0823, validation loss: 0.0841
2024-06-01 22:33:04 [INFO]: Epoch 028 - training loss: 0.0831, validation loss: 0.0794
2024-06-01 22:33:04 [INFO]: Epoch 029 - training loss: 0.0811, validation loss: 0.0781
2024-06-01 22:33:04 [INFO]: Epoch 030 - training loss: 0.0794, validation loss: 0.0797
2024-06-01 22:33:04 [INFO]: Epoch 031 - training loss: 0.0773, validation loss: 0.0781
2024-06-01 22:33:05 [INFO]: Epoch 032 - training loss: 0.0780, validation loss: 0.0739
2024-06-01 22:33:05 [INFO]: Epoch 033 - training loss: 0.0779, validation loss: 0.0762
2024-06-01 22:33:05 [INFO]: Epoch 034 - training loss: 0.0816, validation loss: 0.0812
2024-06-01 22:33:05 [INFO]: Epoch 035 - training loss: 0.0806, validation loss: 0.0765
2024-06-01 22:33:05 [INFO]: Epoch 036 - training loss: 0.0792, validation loss: 0.0805
2024-06-01 22:33:05 [INFO]: Epoch 037 - training loss: 0.0783, validation loss: 0.0758
2024-06-01 22:33:05 [INFO]: Epoch 038 - training loss: 0.0759, validation loss: 0.0735
2024-06-01 22:33:06 [INFO]: Epoch 039 - training loss: 0.0771, validation loss: 0.0823
2024-06-01 22:33:06 [INFO]: Epoch 040 - training loss: 0.0783, validation loss: 0.0763
2024-06-01 22:33:06 [INFO]: Epoch 041 - training loss: 0.0801, validation loss: 0.0759
2024-06-01 22:33:06 [INFO]: Epoch 042 - training loss: 0.0756, validation loss: 0.0808
2024-06-01 22:33:06 [INFO]: Epoch 043 - training loss: 0.0818, validation loss: 0.0804
2024-06-01 22:33:06 [INFO]: Epoch 044 - training loss: 0.0771, validation loss: 0.0815
2024-06-01 22:33:06 [INFO]: Epoch 045 - training loss: 0.0738, validation loss: 0.0742
2024-06-01 22:33:07 [INFO]: Epoch 046 - training loss: 0.0750, validation loss: 0.0836
2024-06-01 22:33:07 [INFO]: Epoch 047 - training loss: 0.0777, validation loss: 0.0743
2024-06-01 22:33:07 [INFO]: Epoch 048 - training loss: 0.0758, validation loss: 0.0722
2024-06-01 22:33:07 [INFO]: Epoch 049 - training loss: 0.0715, validation loss: 0.0710
2024-06-01 22:33:07 [INFO]: Epoch 050 - training loss: 0.0766, validation loss: 0.0771
2024-06-01 22:33:07 [INFO]: Epoch 051 - training loss: 0.0779, validation loss: 0.0748
2024-06-01 22:33:07 [INFO]: Epoch 052 - training loss: 0.0752, validation loss: 0.0740
2024-06-01 22:33:08 [INFO]: Epoch 053 - training loss: 0.0751, validation loss: 0.0780
2024-06-01 22:33:08 [INFO]: Epoch 054 - training loss: 0.0756, validation loss: 0.0768
2024-06-01 22:33:08 [INFO]: Epoch 055 - training loss: 0.0732, validation loss: 0.0726
2024-06-01 22:33:08 [INFO]: Epoch 056 - training loss: 0.0716, validation loss: 0.0729
2024-06-01 22:33:08 [INFO]: Epoch 057 - training loss: 0.0780, validation loss: 0.0753
2024-06-01 22:33:08 [INFO]: Epoch 058 - training loss: 0.0727, validation loss: 0.0794
2024-06-01 22:33:09 [INFO]: Epoch 059 - training loss: 0.0762, validation loss: 0.0748
2024-06-01 22:33:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:33:09 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:33:09 [INFO]: Saved the model to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_2/20240601_T223300/TimesNet.pypots
2024-06-01 22:33:09 [INFO]: Successfully saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_2/imputation.pkl
2024-06-01 22:33:09 [INFO]: Round2 - TimesNet on ETT_h1: MAE=0.2474, MSE=0.1153, MRE=0.2919
2024-06-01 22:33:09 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:33:09 [INFO]: Using the given device: cuda:0
2024-06-01 22:33:09 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_3/20240601_T223309
2024-06-01 22:33:09 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_3/20240601_T223309/tensorboard
2024-06-01 22:33:09 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-01 22:33:09 [INFO]: Epoch 001 - training loss: 0.7076, validation loss: 0.4186
2024-06-01 22:33:09 [INFO]: Epoch 002 - training loss: 0.2894, validation loss: 0.2296
2024-06-01 22:33:09 [INFO]: Epoch 003 - training loss: 0.2052, validation loss: 0.1676
2024-06-01 22:33:09 [INFO]: Epoch 004 - training loss: 0.1589, validation loss: 0.1321
2024-06-01 22:33:10 [INFO]: Epoch 005 - training loss: 0.1339, validation loss: 0.1185
2024-06-01 22:33:10 [INFO]: Epoch 006 - training loss: 0.1228, validation loss: 0.0962
2024-06-01 22:33:10 [INFO]: Epoch 007 - training loss: 0.1135, validation loss: 0.0966
2024-06-01 22:33:10 [INFO]: Epoch 008 - training loss: 0.1099, validation loss: 0.0946
2024-06-01 22:33:10 [INFO]: Epoch 009 - training loss: 0.0969, validation loss: 0.0839
2024-06-01 22:33:10 [INFO]: Epoch 010 - training loss: 0.0946, validation loss: 0.0829
2024-06-01 22:33:11 [INFO]: Epoch 011 - training loss: 0.0966, validation loss: 0.0902
2024-06-01 22:33:11 [INFO]: Epoch 012 - training loss: 0.1006, validation loss: 0.0842
2024-06-01 22:33:11 [INFO]: Epoch 013 - training loss: 0.0895, validation loss: 0.0794
2024-06-01 22:33:11 [INFO]: Epoch 014 - training loss: 0.0931, validation loss: 0.0876
2024-06-01 22:33:11 [INFO]: Epoch 015 - training loss: 0.0964, validation loss: 0.0943
2024-06-01 22:33:11 [INFO]: Epoch 016 - training loss: 0.0939, validation loss: 0.0843
2024-06-01 22:33:12 [INFO]: Epoch 017 - training loss: 0.0875, validation loss: 0.0831
2024-06-01 22:33:12 [INFO]: Epoch 018 - training loss: 0.0929, validation loss: 0.0849
2024-06-01 22:33:12 [INFO]: Epoch 019 - training loss: 0.0924, validation loss: 0.0878
2024-06-01 22:33:12 [INFO]: Epoch 020 - training loss: 0.0837, validation loss: 0.0818
2024-06-01 22:33:12 [INFO]: Epoch 021 - training loss: 0.0890, validation loss: 0.0807
2024-06-01 22:33:12 [INFO]: Epoch 022 - training loss: 0.0841, validation loss: 0.0804
2024-06-01 22:33:12 [INFO]: Epoch 023 - training loss: 0.0848, validation loss: 0.0770
2024-06-01 22:33:13 [INFO]: Epoch 024 - training loss: 0.0876, validation loss: 0.0854
2024-06-01 22:33:13 [INFO]: Epoch 025 - training loss: 0.0859, validation loss: 0.0828
2024-06-01 22:33:13 [INFO]: Epoch 026 - training loss: 0.0859, validation loss: 0.0825
2024-06-01 22:33:13 [INFO]: Epoch 027 - training loss: 0.0793, validation loss: 0.0783
2024-06-01 22:33:13 [INFO]: Epoch 028 - training loss: 0.0871, validation loss: 0.0881
2024-06-01 22:33:13 [INFO]: Epoch 029 - training loss: 0.0825, validation loss: 0.0695
2024-06-01 22:33:13 [INFO]: Epoch 030 - training loss: 0.0827, validation loss: 0.0783
2024-06-01 22:33:13 [INFO]: Epoch 031 - training loss: 0.0862, validation loss: 0.0825
2024-06-01 22:33:14 [INFO]: Epoch 032 - training loss: 0.0819, validation loss: 0.0796
2024-06-01 22:33:14 [INFO]: Epoch 033 - training loss: 0.0794, validation loss: 0.0761
2024-06-01 22:33:14 [INFO]: Epoch 034 - training loss: 0.0801, validation loss: 0.0835
2024-06-01 22:33:14 [INFO]: Epoch 035 - training loss: 0.0772, validation loss: 0.0735
2024-06-01 22:33:14 [INFO]: Epoch 036 - training loss: 0.0810, validation loss: 0.0786
2024-06-01 22:33:14 [INFO]: Epoch 037 - training loss: 0.0807, validation loss: 0.0758
2024-06-01 22:33:15 [INFO]: Epoch 038 - training loss: 0.0789, validation loss: 0.0752
2024-06-01 22:33:15 [INFO]: Epoch 039 - training loss: 0.0786, validation loss: 0.0789
2024-06-01 22:33:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:33:15 [INFO]: Finished training. The best model is from epoch#29.
2024-06-01 22:33:15 [INFO]: Saved the model to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_3/20240601_T223309/TimesNet.pypots
2024-06-01 22:33:15 [INFO]: Successfully saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_3/imputation.pkl
2024-06-01 22:33:15 [INFO]: Round3 - TimesNet on ETT_h1: MAE=0.2510, MSE=0.1184, MRE=0.2963
2024-06-01 22:33:15 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:33:15 [INFO]: Using the given device: cuda:0
2024-06-01 22:33:15 [INFO]: Model files will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_4/20240601_T223315
2024-06-01 22:33:15 [INFO]: Tensorboard file will be saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_4/20240601_T223315/tensorboard
2024-06-01 22:33:15 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-01 22:33:15 [INFO]: Epoch 001 - training loss: 0.6246, validation loss: 0.3686
2024-06-01 22:33:15 [INFO]: Epoch 002 - training loss: 0.2776, validation loss: 0.2046
2024-06-01 22:33:16 [INFO]: Epoch 003 - training loss: 0.1908, validation loss: 0.1483
2024-06-01 22:33:16 [INFO]: Epoch 004 - training loss: 0.1531, validation loss: 0.1316
2024-06-01 22:33:16 [INFO]: Epoch 005 - training loss: 0.1308, validation loss: 0.1060
2024-06-01 22:33:16 [INFO]: Epoch 006 - training loss: 0.1129, validation loss: 0.0940
2024-06-01 22:33:16 [INFO]: Epoch 007 - training loss: 0.1111, validation loss: 0.0953
2024-06-01 22:33:16 [INFO]: Epoch 008 - training loss: 0.1013, validation loss: 0.0952
2024-06-01 22:33:16 [INFO]: Epoch 009 - training loss: 0.1007, validation loss: 0.0922
2024-06-01 22:33:16 [INFO]: Epoch 010 - training loss: 0.0977, validation loss: 0.0903
2024-06-01 22:33:17 [INFO]: Epoch 011 - training loss: 0.1016, validation loss: 0.0913
2024-06-01 22:33:17 [INFO]: Epoch 012 - training loss: 0.0940, validation loss: 0.0852
2024-06-01 22:33:17 [INFO]: Epoch 013 - training loss: 0.0961, validation loss: 0.0849
2024-06-01 22:33:17 [INFO]: Epoch 014 - training loss: 0.0968, validation loss: 0.0824
2024-06-01 22:33:17 [INFO]: Epoch 015 - training loss: 0.0923, validation loss: 0.0871
2024-06-01 22:33:18 [INFO]: Epoch 016 - training loss: 0.0904, validation loss: 0.0851
2024-06-01 22:33:18 [INFO]: Epoch 017 - training loss: 0.0878, validation loss: 0.0821
2024-06-01 22:33:18 [INFO]: Epoch 018 - training loss: 0.0875, validation loss: 0.0812
2024-06-01 22:33:18 [INFO]: Epoch 019 - training loss: 0.0890, validation loss: 0.0852
2024-06-01 22:33:18 [INFO]: Epoch 020 - training loss: 0.0835, validation loss: 0.0908
2024-06-01 22:33:18 [INFO]: Epoch 021 - training loss: 0.0881, validation loss: 0.0819
2024-06-01 22:33:18 [INFO]: Epoch 022 - training loss: 0.0859, validation loss: 0.0844
2024-06-01 22:33:19 [INFO]: Epoch 023 - training loss: 0.0839, validation loss: 0.0843
2024-06-01 22:33:19 [INFO]: Epoch 024 - training loss: 0.0799, validation loss: 0.0806
2024-06-01 22:33:19 [INFO]: Epoch 025 - training loss: 0.0812, validation loss: 0.0913
2024-06-01 22:33:19 [INFO]: Epoch 026 - training loss: 0.0864, validation loss: 0.0784
2024-06-01 22:33:19 [INFO]: Epoch 027 - training loss: 0.0824, validation loss: 0.0768
2024-06-01 22:33:19 [INFO]: Epoch 028 - training loss: 0.0810, validation loss: 0.0784
2024-06-01 22:33:19 [INFO]: Epoch 029 - training loss: 0.0812, validation loss: 0.0831
2024-06-01 22:33:20 [INFO]: Epoch 030 - training loss: 0.0822, validation loss: 0.0758
2024-06-01 22:33:20 [INFO]: Epoch 031 - training loss: 0.0822, validation loss: 0.0756
2024-06-01 22:33:20 [INFO]: Epoch 032 - training loss: 0.0780, validation loss: 0.0760
2024-06-01 22:33:20 [INFO]: Epoch 033 - training loss: 0.0814, validation loss: 0.0814
2024-06-01 22:33:20 [INFO]: Epoch 034 - training loss: 0.0795, validation loss: 0.0808
2024-06-01 22:33:20 [INFO]: Epoch 035 - training loss: 0.0842, validation loss: 0.0784
2024-06-01 22:33:20 [INFO]: Epoch 036 - training loss: 0.0796, validation loss: 0.0787
2024-06-01 22:33:20 [INFO]: Epoch 037 - training loss: 0.0739, validation loss: 0.0742
2024-06-01 22:33:21 [INFO]: Epoch 038 - training loss: 0.0814, validation loss: 0.0788
2024-06-01 22:33:21 [INFO]: Epoch 039 - training loss: 0.0797, validation loss: 0.0748
2024-06-01 22:33:21 [INFO]: Epoch 040 - training loss: 0.0770, validation loss: 0.0747
2024-06-01 22:33:21 [INFO]: Epoch 041 - training loss: 0.0776, validation loss: 0.0874
2024-06-01 22:33:21 [INFO]: Epoch 042 - training loss: 0.0779, validation loss: 0.0781
2024-06-01 22:33:21 [INFO]: Epoch 043 - training loss: 0.0765, validation loss: 0.0774
2024-06-01 22:33:22 [INFO]: Epoch 044 - training loss: 0.0774, validation loss: 0.0721
2024-06-01 22:33:22 [INFO]: Epoch 045 - training loss: 0.0759, validation loss: 0.0718
2024-06-01 22:33:22 [INFO]: Epoch 046 - training loss: 0.0760, validation loss: 0.0822
2024-06-01 22:33:22 [INFO]: Epoch 047 - training loss: 0.0799, validation loss: 0.0748
2024-06-01 22:33:22 [INFO]: Epoch 048 - training loss: 0.0845, validation loss: 0.0826
2024-06-01 22:33:22 [INFO]: Epoch 049 - training loss: 0.0748, validation loss: 0.0712
2024-06-01 22:33:23 [INFO]: Epoch 050 - training loss: 0.0771, validation loss: 0.0777
2024-06-01 22:33:23 [INFO]: Epoch 051 - training loss: 0.0721, validation loss: 0.0717
2024-06-01 22:33:23 [INFO]: Epoch 052 - training loss: 0.0732, validation loss: 0.0740
2024-06-01 22:33:23 [INFO]: Epoch 053 - training loss: 0.0743, validation loss: 0.0747
2024-06-01 22:33:23 [INFO]: Epoch 054 - training loss: 0.0753, validation loss: 0.0737
2024-06-01 22:33:23 [INFO]: Epoch 055 - training loss: 0.0742, validation loss: 0.0766
2024-06-01 22:33:23 [INFO]: Epoch 056 - training loss: 0.0749, validation loss: 0.0818
2024-06-01 22:33:23 [INFO]: Epoch 057 - training loss: 0.0763, validation loss: 0.0788
2024-06-01 22:33:24 [INFO]: Epoch 058 - training loss: 0.0766, validation loss: 0.0760
2024-06-01 22:33:24 [INFO]: Epoch 059 - training loss: 0.0777, validation loss: 0.0754
2024-06-01 22:33:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:33:24 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:33:24 [INFO]: Saved the model to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_4/20240601_T223315/TimesNet.pypots
2024-06-01 22:33:24 [INFO]: Successfully saved to results_point_rate01/ETT_h1/TimesNet_ETT_h1/round_4/imputation.pkl
2024-06-01 22:33:24 [INFO]: Round4 - TimesNet on ETT_h1: MAE=0.2459, MSE=0.1152, MRE=0.2902
2024-06-01 22:33:24 [INFO]: Done! Final results:
Averaged TimesNet (n params: 5,510,663) on ETT_h1: MAE=0.2538 ± 0.007692603113199173, MSE=0.1203 ± 0.00520322228407814, MRE=0.2995 ± 0.009077972204022672, average inference time=0.08
