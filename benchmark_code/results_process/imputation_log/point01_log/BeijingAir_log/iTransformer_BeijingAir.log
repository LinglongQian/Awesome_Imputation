2024-06-04 02:49:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:49:23 [INFO]: Using the given device: cuda:0
2024-06-04 02:49:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_0/20240604_T024924
2024-06-04 02:49:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_0/20240604_T024924/tensorboard
2024-06-04 02:49:25 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-04 02:49:38 [INFO]: Epoch 001 - training loss: 0.8260, validation loss: 0.2709
2024-06-04 02:49:45 [INFO]: Epoch 002 - training loss: 0.4849, validation loss: 0.2371
2024-06-04 02:49:52 [INFO]: Epoch 003 - training loss: 0.4307, validation loss: 0.2312
2024-06-04 02:49:59 [INFO]: Epoch 004 - training loss: 0.4162, validation loss: 0.2326
2024-06-04 02:50:06 [INFO]: Epoch 005 - training loss: 0.4029, validation loss: 0.2206
2024-06-04 02:50:14 [INFO]: Epoch 006 - training loss: 0.3983, validation loss: 0.2217
2024-06-04 02:50:21 [INFO]: Epoch 007 - training loss: 0.3926, validation loss: 0.2212
2024-06-04 02:50:28 [INFO]: Epoch 008 - training loss: 0.3823, validation loss: 0.2144
2024-06-04 02:50:34 [INFO]: Epoch 009 - training loss: 0.3803, validation loss: 0.2083
2024-06-04 02:50:41 [INFO]: Epoch 010 - training loss: 0.3718, validation loss: 0.2047
2024-06-04 02:50:49 [INFO]: Epoch 011 - training loss: 0.3589, validation loss: 0.1964
2024-06-04 02:50:55 [INFO]: Epoch 012 - training loss: 0.3559, validation loss: 0.1960
2024-06-04 02:51:02 [INFO]: Epoch 013 - training loss: 0.3375, validation loss: 0.1921
2024-06-04 02:51:09 [INFO]: Epoch 014 - training loss: 0.3444, validation loss: 0.1910
2024-06-04 02:51:15 [INFO]: Epoch 015 - training loss: 0.3295, validation loss: 0.1842
2024-06-04 02:51:23 [INFO]: Epoch 016 - training loss: 0.3297, validation loss: 0.1873
2024-06-04 02:51:29 [INFO]: Epoch 017 - training loss: 0.3163, validation loss: 0.1814
2024-06-04 02:51:36 [INFO]: Epoch 018 - training loss: 0.3122, validation loss: 0.1811
2024-06-04 02:51:43 [INFO]: Epoch 019 - training loss: 0.3006, validation loss: 0.1796
2024-06-04 02:51:50 [INFO]: Epoch 020 - training loss: 0.2944, validation loss: 0.1770
2024-06-04 02:51:57 [INFO]: Epoch 021 - training loss: 0.2979, validation loss: 0.1759
2024-06-04 02:52:04 [INFO]: Epoch 022 - training loss: 0.2885, validation loss: 0.1730
2024-06-04 02:52:11 [INFO]: Epoch 023 - training loss: 0.2909, validation loss: 0.1749
2024-06-04 02:52:18 [INFO]: Epoch 024 - training loss: 0.2802, validation loss: 0.1754
2024-06-04 02:52:25 [INFO]: Epoch 025 - training loss: 0.2828, validation loss: 0.1757
2024-06-04 02:52:32 [INFO]: Epoch 026 - training loss: 0.2833, validation loss: 0.1734
2024-06-04 02:52:39 [INFO]: Epoch 027 - training loss: 0.2709, validation loss: 0.1706
2024-06-04 02:52:46 [INFO]: Epoch 028 - training loss: 0.2702, validation loss: 0.1688
2024-06-04 02:52:53 [INFO]: Epoch 029 - training loss: 0.2705, validation loss: 0.1725
2024-06-04 02:53:00 [INFO]: Epoch 030 - training loss: 0.2676, validation loss: 0.1683
2024-06-04 02:53:07 [INFO]: Epoch 031 - training loss: 0.2635, validation loss: 0.1669
2024-06-04 02:53:14 [INFO]: Epoch 032 - training loss: 0.2597, validation loss: 0.1670
2024-06-04 02:53:21 [INFO]: Epoch 033 - training loss: 0.2581, validation loss: 0.1682
2024-06-04 02:53:28 [INFO]: Epoch 034 - training loss: 0.2566, validation loss: 0.1652
2024-06-04 02:53:35 [INFO]: Epoch 035 - training loss: 0.2508, validation loss: 0.1643
2024-06-04 02:53:42 [INFO]: Epoch 036 - training loss: 0.2719, validation loss: 0.1676
2024-06-04 02:53:49 [INFO]: Epoch 037 - training loss: 0.2619, validation loss: 0.1662
2024-06-04 02:53:56 [INFO]: Epoch 038 - training loss: 0.2482, validation loss: 0.1638
2024-06-04 02:54:02 [INFO]: Epoch 039 - training loss: 0.2422, validation loss: 0.1652
2024-06-04 02:54:10 [INFO]: Epoch 040 - training loss: 0.2425, validation loss: 0.1651
2024-06-04 02:54:17 [INFO]: Epoch 041 - training loss: 0.2416, validation loss: 0.1628
2024-06-04 02:54:23 [INFO]: Epoch 042 - training loss: 0.2430, validation loss: 0.1631
2024-06-04 02:54:31 [INFO]: Epoch 043 - training loss: 0.2435, validation loss: 0.1624
2024-06-04 02:54:38 [INFO]: Epoch 044 - training loss: 0.2364, validation loss: 0.1618
2024-06-04 02:54:45 [INFO]: Epoch 045 - training loss: 0.2329, validation loss: 0.1622
2024-06-04 02:54:52 [INFO]: Epoch 046 - training loss: 0.2411, validation loss: 0.1617
2024-06-04 02:54:59 [INFO]: Epoch 047 - training loss: 0.2367, validation loss: 0.1598
2024-06-04 02:55:06 [INFO]: Epoch 048 - training loss: 0.2356, validation loss: 0.1602
2024-06-04 02:55:13 [INFO]: Epoch 049 - training loss: 0.2264, validation loss: 0.1579
2024-06-04 02:55:19 [INFO]: Epoch 050 - training loss: 0.2251, validation loss: 0.1594
2024-06-04 02:55:26 [INFO]: Epoch 051 - training loss: 0.2280, validation loss: 0.1588
2024-06-04 02:55:33 [INFO]: Epoch 052 - training loss: 0.2310, validation loss: 0.1599
2024-06-04 02:55:40 [INFO]: Epoch 053 - training loss: 0.2274, validation loss: 0.1575
2024-06-04 02:55:47 [INFO]: Epoch 054 - training loss: 0.2259, validation loss: 0.1577
2024-06-04 02:55:54 [INFO]: Epoch 055 - training loss: 0.2237, validation loss: 0.1569
2024-06-04 02:56:01 [INFO]: Epoch 056 - training loss: 0.2332, validation loss: 0.1576
2024-06-04 02:56:08 [INFO]: Epoch 057 - training loss: 0.2208, validation loss: 0.1580
2024-06-04 02:56:15 [INFO]: Epoch 058 - training loss: 0.2185, validation loss: 0.1557
2024-06-04 02:56:21 [INFO]: Epoch 059 - training loss: 0.2161, validation loss: 0.1580
2024-06-04 02:56:28 [INFO]: Epoch 060 - training loss: 0.2143, validation loss: 0.1547
2024-06-04 02:56:35 [INFO]: Epoch 061 - training loss: 0.2129, validation loss: 0.1574
2024-06-04 02:56:42 [INFO]: Epoch 062 - training loss: 0.2148, validation loss: 0.1568
2024-06-04 02:56:49 [INFO]: Epoch 063 - training loss: 0.2151, validation loss: 0.1569
2024-06-04 02:56:56 [INFO]: Epoch 064 - training loss: 0.2142, validation loss: 0.1552
2024-06-04 02:57:03 [INFO]: Epoch 065 - training loss: 0.2111, validation loss: 0.1564
2024-06-04 02:57:10 [INFO]: Epoch 066 - training loss: 0.2089, validation loss: 0.1551
2024-06-04 02:57:17 [INFO]: Epoch 067 - training loss: 0.2144, validation loss: 0.1550
2024-06-04 02:57:24 [INFO]: Epoch 068 - training loss: 0.2117, validation loss: 0.1549
2024-06-04 02:57:31 [INFO]: Epoch 069 - training loss: 0.2053, validation loss: 0.1553
2024-06-04 02:57:38 [INFO]: Epoch 070 - training loss: 0.2101, validation loss: 0.1545
2024-06-04 02:57:45 [INFO]: Epoch 071 - training loss: 0.2070, validation loss: 0.1549
2024-06-04 02:57:51 [INFO]: Epoch 072 - training loss: 0.2038, validation loss: 0.1538
2024-06-04 02:57:58 [INFO]: Epoch 073 - training loss: 0.2067, validation loss: 0.1534
2024-06-04 02:58:05 [INFO]: Epoch 074 - training loss: 0.2034, validation loss: 0.1515
2024-06-04 02:58:12 [INFO]: Epoch 075 - training loss: 0.2041, validation loss: 0.1546
2024-06-04 02:58:19 [INFO]: Epoch 076 - training loss: 0.2033, validation loss: 0.1538
2024-06-04 02:58:26 [INFO]: Epoch 077 - training loss: 0.1989, validation loss: 0.1520
2024-06-04 02:58:32 [INFO]: Epoch 078 - training loss: 0.2036, validation loss: 0.1548
2024-06-04 02:58:39 [INFO]: Epoch 079 - training loss: 0.2017, validation loss: 0.1550
2024-06-04 02:58:46 [INFO]: Epoch 080 - training loss: 0.1964, validation loss: 0.1535
2024-06-04 02:58:53 [INFO]: Epoch 081 - training loss: 0.1972, validation loss: 0.1529
2024-06-04 02:59:01 [INFO]: Epoch 082 - training loss: 0.1992, validation loss: 0.1553
2024-06-04 02:59:08 [INFO]: Epoch 083 - training loss: 0.1999, validation loss: 0.1536
2024-06-04 02:59:15 [INFO]: Epoch 084 - training loss: 0.2013, validation loss: 0.1522
2024-06-04 02:59:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:59:15 [INFO]: Finished training. The best model is from epoch#74.
2024-06-04 02:59:15 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_0/20240604_T024924/iTransformer.pypots
2024-06-04 02:59:17 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_0/imputation.pkl
2024-06-04 02:59:17 [INFO]: Round0 - iTransformer on BeijingAir: MAE=0.1556, MSE=0.1700, MRE=0.2350
2024-06-04 02:59:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 02:59:17 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:17 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_1/20240604_T025917
2024-06-04 02:59:17 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_1/20240604_T025917/tensorboard
2024-06-04 02:59:17 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-04 02:59:25 [INFO]: Epoch 001 - training loss: 0.8057, validation loss: 0.2686
2024-06-04 02:59:32 [INFO]: Epoch 002 - training loss: 0.4681, validation loss: 0.2444
2024-06-04 02:59:39 [INFO]: Epoch 003 - training loss: 0.4337, validation loss: 0.2324
2024-06-04 02:59:46 [INFO]: Epoch 004 - training loss: 0.4148, validation loss: 0.2298
2024-06-04 02:59:53 [INFO]: Epoch 005 - training loss: 0.4033, validation loss: 0.2200
2024-06-04 03:00:00 [INFO]: Epoch 006 - training loss: 0.3958, validation loss: 0.2165
2024-06-04 03:00:07 [INFO]: Epoch 007 - training loss: 0.3964, validation loss: 0.2154
2024-06-04 03:00:15 [INFO]: Epoch 008 - training loss: 0.3810, validation loss: 0.2130
2024-06-04 03:00:22 [INFO]: Epoch 009 - training loss: 0.3697, validation loss: 0.2064
2024-06-04 03:00:29 [INFO]: Epoch 010 - training loss: 0.3654, validation loss: 0.2007
2024-06-04 03:00:36 [INFO]: Epoch 011 - training loss: 0.3561, validation loss: 0.1986
2024-06-04 03:00:43 [INFO]: Epoch 012 - training loss: 0.3435, validation loss: 0.1917
2024-06-04 03:00:49 [INFO]: Epoch 013 - training loss: 0.3554, validation loss: 0.1970
2024-06-04 03:00:55 [INFO]: Epoch 014 - training loss: 0.3368, validation loss: 0.1888
2024-06-04 03:01:02 [INFO]: Epoch 015 - training loss: 0.3264, validation loss: 0.1875
2024-06-04 03:01:08 [INFO]: Epoch 016 - training loss: 0.3181, validation loss: 0.1843
2024-06-04 03:01:14 [INFO]: Epoch 017 - training loss: 0.3173, validation loss: 0.1839
2024-06-04 03:01:21 [INFO]: Epoch 018 - training loss: 0.3110, validation loss: 0.1823
2024-06-04 03:01:27 [INFO]: Epoch 019 - training loss: 0.3086, validation loss: 0.1817
2024-06-04 03:01:33 [INFO]: Epoch 020 - training loss: 0.3061, validation loss: 0.1779
2024-06-04 03:01:39 [INFO]: Epoch 021 - training loss: 0.2944, validation loss: 0.1756
2024-06-04 03:01:45 [INFO]: Epoch 022 - training loss: 0.2939, validation loss: 0.1731
2024-06-04 03:01:51 [INFO]: Epoch 023 - training loss: 0.2908, validation loss: 0.1745
2024-06-04 03:01:57 [INFO]: Epoch 024 - training loss: 0.2836, validation loss: 0.1747
2024-06-04 03:02:04 [INFO]: Epoch 025 - training loss: 0.2760, validation loss: 0.1736
2024-06-04 03:02:10 [INFO]: Epoch 026 - training loss: 0.2747, validation loss: 0.1683
2024-06-04 03:02:16 [INFO]: Epoch 027 - training loss: 0.2727, validation loss: 0.1680
2024-06-04 03:02:23 [INFO]: Epoch 028 - training loss: 0.2699, validation loss: 0.1676
2024-06-04 03:02:29 [INFO]: Epoch 029 - training loss: 0.2662, validation loss: 0.1678
2024-06-04 03:02:35 [INFO]: Epoch 030 - training loss: 0.2639, validation loss: 0.1696
2024-06-04 03:02:42 [INFO]: Epoch 031 - training loss: 0.2658, validation loss: 0.1661
2024-06-04 03:02:48 [INFO]: Epoch 032 - training loss: 0.2616, validation loss: 0.1645
2024-06-04 03:02:54 [INFO]: Epoch 033 - training loss: 0.2603, validation loss: 0.1682
2024-06-04 03:03:00 [INFO]: Epoch 034 - training loss: 0.2658, validation loss: 0.1650
2024-06-04 03:03:06 [INFO]: Epoch 035 - training loss: 0.2596, validation loss: 0.1655
2024-06-04 03:03:13 [INFO]: Epoch 036 - training loss: 0.2533, validation loss: 0.1627
2024-06-04 03:03:19 [INFO]: Epoch 037 - training loss: 0.2508, validation loss: 0.1613
2024-06-04 03:03:25 [INFO]: Epoch 038 - training loss: 0.2466, validation loss: 0.1633
2024-06-04 03:03:31 [INFO]: Epoch 039 - training loss: 0.2493, validation loss: 0.1651
2024-06-04 03:03:37 [INFO]: Epoch 040 - training loss: 0.2542, validation loss: 0.1652
2024-06-04 03:03:43 [INFO]: Epoch 041 - training loss: 0.2445, validation loss: 0.1610
2024-06-04 03:03:49 [INFO]: Epoch 042 - training loss: 0.2471, validation loss: 0.1607
2024-06-04 03:03:55 [INFO]: Epoch 043 - training loss: 0.2416, validation loss: 0.1594
2024-06-04 03:04:02 [INFO]: Epoch 044 - training loss: 0.2373, validation loss: 0.1593
2024-06-04 03:04:08 [INFO]: Epoch 045 - training loss: 0.2341, validation loss: 0.1608
2024-06-04 03:04:14 [INFO]: Epoch 046 - training loss: 0.2413, validation loss: 0.1589
2024-06-04 03:04:20 [INFO]: Epoch 047 - training loss: 0.2333, validation loss: 0.1602
2024-06-04 03:04:27 [INFO]: Epoch 048 - training loss: 0.2345, validation loss: 0.1587
2024-06-04 03:04:33 [INFO]: Epoch 049 - training loss: 0.2326, validation loss: 0.1612
2024-06-04 03:04:39 [INFO]: Epoch 050 - training loss: 0.2353, validation loss: 0.1585
2024-06-04 03:04:45 [INFO]: Epoch 051 - training loss: 0.2284, validation loss: 0.1596
2024-06-04 03:04:51 [INFO]: Epoch 052 - training loss: 0.2319, validation loss: 0.1585
2024-06-04 03:04:58 [INFO]: Epoch 053 - training loss: 0.2245, validation loss: 0.1568
2024-06-04 03:05:04 [INFO]: Epoch 054 - training loss: 0.2203, validation loss: 0.1585
2024-06-04 03:05:10 [INFO]: Epoch 055 - training loss: 0.2199, validation loss: 0.1605
2024-06-04 03:05:16 [INFO]: Epoch 056 - training loss: 0.2251, validation loss: 0.1580
2024-06-04 03:05:22 [INFO]: Epoch 057 - training loss: 0.2232, validation loss: 0.1526
2024-06-04 03:05:29 [INFO]: Epoch 058 - training loss: 0.2169, validation loss: 0.1572
2024-06-04 03:05:35 [INFO]: Epoch 059 - training loss: 0.2219, validation loss: 0.1571
2024-06-04 03:05:41 [INFO]: Epoch 060 - training loss: 0.2172, validation loss: 0.1540
2024-06-04 03:05:47 [INFO]: Epoch 061 - training loss: 0.2137, validation loss: 0.1543
2024-06-04 03:05:54 [INFO]: Epoch 062 - training loss: 0.2113, validation loss: 0.1536
2024-06-04 03:06:00 [INFO]: Epoch 063 - training loss: 0.2115, validation loss: 0.1556
2024-06-04 03:06:06 [INFO]: Epoch 064 - training loss: 0.2135, validation loss: 0.1561
2024-06-04 03:06:12 [INFO]: Epoch 065 - training loss: 0.2119, validation loss: 0.1546
2024-06-04 03:06:18 [INFO]: Epoch 066 - training loss: 0.2106, validation loss: 0.1519
2024-06-04 03:06:24 [INFO]: Epoch 067 - training loss: 0.2128, validation loss: 0.1552
2024-06-04 03:06:30 [INFO]: Epoch 068 - training loss: 0.2261, validation loss: 0.1536
2024-06-04 03:06:37 [INFO]: Epoch 069 - training loss: 0.2125, validation loss: 0.1561
2024-06-04 03:06:43 [INFO]: Epoch 070 - training loss: 0.2073, validation loss: 0.1566
2024-06-04 03:06:49 [INFO]: Epoch 071 - training loss: 0.2119, validation loss: 0.1599
2024-06-04 03:06:56 [INFO]: Epoch 072 - training loss: 0.2092, validation loss: 0.1544
2024-06-04 03:07:02 [INFO]: Epoch 073 - training loss: 0.2068, validation loss: 0.1532
2024-06-04 03:07:08 [INFO]: Epoch 074 - training loss: 0.2034, validation loss: 0.1528
2024-06-04 03:07:14 [INFO]: Epoch 075 - training loss: 0.1989, validation loss: 0.1515
2024-06-04 03:07:20 [INFO]: Epoch 076 - training loss: 0.1997, validation loss: 0.1505
2024-06-04 03:07:26 [INFO]: Epoch 077 - training loss: 0.2000, validation loss: 0.1507
2024-06-04 03:07:33 [INFO]: Epoch 078 - training loss: 0.2112, validation loss: 0.1521
2024-06-04 03:07:39 [INFO]: Epoch 079 - training loss: 0.2074, validation loss: 0.1555
2024-06-04 03:07:45 [INFO]: Epoch 080 - training loss: 0.2100, validation loss: 0.1519
2024-06-04 03:07:51 [INFO]: Epoch 081 - training loss: 0.2009, validation loss: 0.1538
2024-06-04 03:07:57 [INFO]: Epoch 082 - training loss: 0.1978, validation loss: 0.1504
2024-06-04 03:08:03 [INFO]: Epoch 083 - training loss: 0.1968, validation loss: 0.1515
2024-06-04 03:08:10 [INFO]: Epoch 084 - training loss: 0.1936, validation loss: 0.1538
2024-06-04 03:08:16 [INFO]: Epoch 085 - training loss: 0.1957, validation loss: 0.1526
2024-06-04 03:08:22 [INFO]: Epoch 086 - training loss: 0.1930, validation loss: 0.1489
2024-06-04 03:08:27 [INFO]: Epoch 087 - training loss: 0.1946, validation loss: 0.1500
2024-06-04 03:08:33 [INFO]: Epoch 088 - training loss: 0.1929, validation loss: 0.1467
2024-06-04 03:08:39 [INFO]: Epoch 089 - training loss: 0.1925, validation loss: 0.1499
2024-06-04 03:08:46 [INFO]: Epoch 090 - training loss: 0.1929, validation loss: 0.1486
2024-06-04 03:08:51 [INFO]: Epoch 091 - training loss: 0.1940, validation loss: 0.1505
2024-06-04 03:08:57 [INFO]: Epoch 092 - training loss: 0.1960, validation loss: 0.1504
2024-06-04 03:09:03 [INFO]: Epoch 093 - training loss: 0.1960, validation loss: 0.1502
2024-06-04 03:09:09 [INFO]: Epoch 094 - training loss: 0.1979, validation loss: 0.1528
2024-06-04 03:09:15 [INFO]: Epoch 095 - training loss: 0.2029, validation loss: 0.1487
2024-06-04 03:09:20 [INFO]: Epoch 096 - training loss: 0.1945, validation loss: 0.1486
2024-06-04 03:09:27 [INFO]: Epoch 097 - training loss: 0.1925, validation loss: 0.1495
2024-06-04 03:09:33 [INFO]: Epoch 098 - training loss: 0.1887, validation loss: 0.1489
2024-06-04 03:09:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:09:33 [INFO]: Finished training. The best model is from epoch#88.
2024-06-04 03:09:33 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_1/20240604_T025917/iTransformer.pypots
2024-06-04 03:09:35 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_1/imputation.pkl
2024-06-04 03:09:35 [INFO]: Round1 - iTransformer on BeijingAir: MAE=0.1518, MSE=0.1679, MRE=0.2294
2024-06-04 03:09:35 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:09:35 [INFO]: Using the given device: cuda:0
2024-06-04 03:09:35 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_2/20240604_T030935
2024-06-04 03:09:35 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_2/20240604_T030935/tensorboard
2024-06-04 03:09:35 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-04 03:09:41 [INFO]: Epoch 001 - training loss: 0.8234, validation loss: 0.2768
2024-06-04 03:09:47 [INFO]: Epoch 002 - training loss: 0.4847, validation loss: 0.2487
2024-06-04 03:09:53 [INFO]: Epoch 003 - training loss: 0.4323, validation loss: 0.2302
2024-06-04 03:09:59 [INFO]: Epoch 004 - training loss: 0.4139, validation loss: 0.2261
2024-06-04 03:10:04 [INFO]: Epoch 005 - training loss: 0.4059, validation loss: 0.2203
2024-06-04 03:10:10 [INFO]: Epoch 006 - training loss: 0.4002, validation loss: 0.2175
2024-06-04 03:10:16 [INFO]: Epoch 007 - training loss: 0.3935, validation loss: 0.2167
2024-06-04 03:10:22 [INFO]: Epoch 008 - training loss: 0.3785, validation loss: 0.2086
2024-06-04 03:10:28 [INFO]: Epoch 009 - training loss: 0.3805, validation loss: 0.2176
2024-06-04 03:10:34 [INFO]: Epoch 010 - training loss: 0.3691, validation loss: 0.2014
2024-06-04 03:10:40 [INFO]: Epoch 011 - training loss: 0.3572, validation loss: 0.1980
2024-06-04 03:10:46 [INFO]: Epoch 012 - training loss: 0.3423, validation loss: 0.1925
2024-06-04 03:10:52 [INFO]: Epoch 013 - training loss: 0.3368, validation loss: 0.1901
2024-06-04 03:10:58 [INFO]: Epoch 014 - training loss: 0.3324, validation loss: 0.1869
2024-06-04 03:11:03 [INFO]: Epoch 015 - training loss: 0.3232, validation loss: 0.1853
2024-06-04 03:11:09 [INFO]: Epoch 016 - training loss: 0.3156, validation loss: 0.1820
2024-06-04 03:11:15 [INFO]: Epoch 017 - training loss: 0.3134, validation loss: 0.1837
2024-06-04 03:11:21 [INFO]: Epoch 018 - training loss: 0.3065, validation loss: 0.1812
2024-06-04 03:11:27 [INFO]: Epoch 019 - training loss: 0.3015, validation loss: 0.1803
2024-06-04 03:11:33 [INFO]: Epoch 020 - training loss: 0.2957, validation loss: 0.1761
2024-06-04 03:11:39 [INFO]: Epoch 021 - training loss: 0.2969, validation loss: 0.1799
2024-06-04 03:11:45 [INFO]: Epoch 022 - training loss: 0.2855, validation loss: 0.1758
2024-06-04 03:11:50 [INFO]: Epoch 023 - training loss: 0.2817, validation loss: 0.1711
2024-06-04 03:11:56 [INFO]: Epoch 024 - training loss: 0.2790, validation loss: 0.1744
2024-06-04 03:12:03 [INFO]: Epoch 025 - training loss: 0.2812, validation loss: 0.1702
2024-06-04 03:12:09 [INFO]: Epoch 026 - training loss: 0.2880, validation loss: 0.1705
2024-06-04 03:12:14 [INFO]: Epoch 027 - training loss: 0.2823, validation loss: 0.1715
2024-06-04 03:12:20 [INFO]: Epoch 028 - training loss: 0.2710, validation loss: 0.1695
2024-06-04 03:12:26 [INFO]: Epoch 029 - training loss: 0.2632, validation loss: 0.1701
2024-06-04 03:12:32 [INFO]: Epoch 030 - training loss: 0.2663, validation loss: 0.1692
2024-06-04 03:12:38 [INFO]: Epoch 031 - training loss: 0.2583, validation loss: 0.1684
2024-06-04 03:12:44 [INFO]: Epoch 032 - training loss: 0.2609, validation loss: 0.1678
2024-06-04 03:12:49 [INFO]: Epoch 033 - training loss: 0.2560, validation loss: 0.1727
2024-06-04 03:12:54 [INFO]: Epoch 034 - training loss: 0.2605, validation loss: 0.1665
2024-06-04 03:12:59 [INFO]: Epoch 035 - training loss: 0.2530, validation loss: 0.1688
2024-06-04 03:13:05 [INFO]: Epoch 036 - training loss: 0.2462, validation loss: 0.1638
2024-06-04 03:13:10 [INFO]: Epoch 037 - training loss: 0.2491, validation loss: 0.1656
2024-06-04 03:13:15 [INFO]: Epoch 038 - training loss: 0.2495, validation loss: 0.1640
2024-06-04 03:13:21 [INFO]: Epoch 039 - training loss: 0.2423, validation loss: 0.1628
2024-06-04 03:13:27 [INFO]: Epoch 040 - training loss: 0.2558, validation loss: 0.1640
2024-06-04 03:13:32 [INFO]: Epoch 041 - training loss: 0.2526, validation loss: 0.1638
2024-06-04 03:13:38 [INFO]: Epoch 042 - training loss: 0.2391, validation loss: 0.1633
2024-06-04 03:13:43 [INFO]: Epoch 043 - training loss: 0.2343, validation loss: 0.1624
2024-06-04 03:13:49 [INFO]: Epoch 044 - training loss: 0.2347, validation loss: 0.1603
2024-06-04 03:13:54 [INFO]: Epoch 045 - training loss: 0.2322, validation loss: 0.1619
2024-06-04 03:14:00 [INFO]: Epoch 046 - training loss: 0.2312, validation loss: 0.1589
2024-06-04 03:14:05 [INFO]: Epoch 047 - training loss: 0.2310, validation loss: 0.1633
2024-06-04 03:14:11 [INFO]: Epoch 048 - training loss: 0.2312, validation loss: 0.1628
2024-06-04 03:14:16 [INFO]: Epoch 049 - training loss: 0.2346, validation loss: 0.1603
2024-06-04 03:14:22 [INFO]: Epoch 050 - training loss: 0.2283, validation loss: 0.1608
2024-06-04 03:14:27 [INFO]: Epoch 051 - training loss: 0.2350, validation loss: 0.1596
2024-06-04 03:14:33 [INFO]: Epoch 052 - training loss: 0.2320, validation loss: 0.1595
2024-06-04 03:14:38 [INFO]: Epoch 053 - training loss: 0.2230, validation loss: 0.1566
2024-06-04 03:14:44 [INFO]: Epoch 054 - training loss: 0.2235, validation loss: 0.1569
2024-06-04 03:14:49 [INFO]: Epoch 055 - training loss: 0.2217, validation loss: 0.1570
2024-06-04 03:14:55 [INFO]: Epoch 056 - training loss: 0.2177, validation loss: 0.1572
2024-06-04 03:15:00 [INFO]: Epoch 057 - training loss: 0.2151, validation loss: 0.1565
2024-06-04 03:15:05 [INFO]: Epoch 058 - training loss: 0.2195, validation loss: 0.1578
2024-06-04 03:15:11 [INFO]: Epoch 059 - training loss: 0.2138, validation loss: 0.1561
2024-06-04 03:15:16 [INFO]: Epoch 060 - training loss: 0.2157, validation loss: 0.1552
2024-06-04 03:15:22 [INFO]: Epoch 061 - training loss: 0.2170, validation loss: 0.1554
2024-06-04 03:15:27 [INFO]: Epoch 062 - training loss: 0.2200, validation loss: 0.1616
2024-06-04 03:15:33 [INFO]: Epoch 063 - training loss: 0.2255, validation loss: 0.1567
2024-06-04 03:15:38 [INFO]: Epoch 064 - training loss: 0.2101, validation loss: 0.1539
2024-06-04 03:15:44 [INFO]: Epoch 065 - training loss: 0.2117, validation loss: 0.1568
2024-06-04 03:15:49 [INFO]: Epoch 066 - training loss: 0.2099, validation loss: 0.1535
2024-06-04 03:15:55 [INFO]: Epoch 067 - training loss: 0.2099, validation loss: 0.1537
2024-06-04 03:16:01 [INFO]: Epoch 068 - training loss: 0.2117, validation loss: 0.1581
2024-06-04 03:16:06 [INFO]: Epoch 069 - training loss: 0.2089, validation loss: 0.1552
2024-06-04 03:16:11 [INFO]: Epoch 070 - training loss: 0.2066, validation loss: 0.1544
2024-06-04 03:16:17 [INFO]: Epoch 071 - training loss: 0.2095, validation loss: 0.1552
2024-06-04 03:16:22 [INFO]: Epoch 072 - training loss: 0.2046, validation loss: 0.1545
2024-06-04 03:16:28 [INFO]: Epoch 073 - training loss: 0.1996, validation loss: 0.1541
2024-06-04 03:16:33 [INFO]: Epoch 074 - training loss: 0.2025, validation loss: 0.1531
2024-06-04 03:16:38 [INFO]: Epoch 075 - training loss: 0.2016, validation loss: 0.1539
2024-06-04 03:16:44 [INFO]: Epoch 076 - training loss: 0.2075, validation loss: 0.1553
2024-06-04 03:16:49 [INFO]: Epoch 077 - training loss: 0.2072, validation loss: 0.1545
2024-06-04 03:16:55 [INFO]: Epoch 078 - training loss: 0.2070, validation loss: 0.1532
2024-06-04 03:17:00 [INFO]: Epoch 079 - training loss: 0.1982, validation loss: 0.1511
2024-06-04 03:17:05 [INFO]: Epoch 080 - training loss: 0.1967, validation loss: 0.1534
2024-06-04 03:17:11 [INFO]: Epoch 081 - training loss: 0.2000, validation loss: 0.1527
2024-06-04 03:17:16 [INFO]: Epoch 082 - training loss: 0.2050, validation loss: 0.1533
2024-06-04 03:17:22 [INFO]: Epoch 083 - training loss: 0.2030, validation loss: 0.1521
2024-06-04 03:17:28 [INFO]: Epoch 084 - training loss: 0.1954, validation loss: 0.1526
2024-06-04 03:17:33 [INFO]: Epoch 085 - training loss: 0.1957, validation loss: 0.1544
2024-06-04 03:17:39 [INFO]: Epoch 086 - training loss: 0.1944, validation loss: 0.1537
2024-06-04 03:17:44 [INFO]: Epoch 087 - training loss: 0.1988, validation loss: 0.1550
2024-06-04 03:17:49 [INFO]: Epoch 088 - training loss: 0.1990, validation loss: 0.1539
2024-06-04 03:17:55 [INFO]: Epoch 089 - training loss: 0.1919, validation loss: 0.1520
2024-06-04 03:17:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:17:55 [INFO]: Finished training. The best model is from epoch#79.
2024-06-04 03:17:55 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_2/20240604_T030935/iTransformer.pypots
2024-06-04 03:17:57 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_2/imputation.pkl
2024-06-04 03:17:57 [INFO]: Round2 - iTransformer on BeijingAir: MAE=0.1553, MSE=0.1715, MRE=0.2347
2024-06-04 03:17:57 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:17:57 [INFO]: Using the given device: cuda:0
2024-06-04 03:17:57 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_3/20240604_T031757
2024-06-04 03:17:57 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_3/20240604_T031757/tensorboard
2024-06-04 03:17:58 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-04 03:18:03 [INFO]: Epoch 001 - training loss: 0.8064, validation loss: 0.2704
2024-06-04 03:18:08 [INFO]: Epoch 002 - training loss: 0.4722, validation loss: 0.2401
2024-06-04 03:18:14 [INFO]: Epoch 003 - training loss: 0.4359, validation loss: 0.2325
2024-06-04 03:18:20 [INFO]: Epoch 004 - training loss: 0.4175, validation loss: 0.2232
2024-06-04 03:18:25 [INFO]: Epoch 005 - training loss: 0.4067, validation loss: 0.2180
2024-06-04 03:18:30 [INFO]: Epoch 006 - training loss: 0.4009, validation loss: 0.2181
2024-06-04 03:18:36 [INFO]: Epoch 007 - training loss: 0.3876, validation loss: 0.2148
2024-06-04 03:18:41 [INFO]: Epoch 008 - training loss: 0.3746, validation loss: 0.2134
2024-06-04 03:18:46 [INFO]: Epoch 009 - training loss: 0.3777, validation loss: 0.2032
2024-06-04 03:18:51 [INFO]: Epoch 010 - training loss: 0.3615, validation loss: 0.2001
2024-06-04 03:18:57 [INFO]: Epoch 011 - training loss: 0.3544, validation loss: 0.1939
2024-06-04 03:19:02 [INFO]: Epoch 012 - training loss: 0.3494, validation loss: 0.2040
2024-06-04 03:19:08 [INFO]: Epoch 013 - training loss: 0.3513, validation loss: 0.1904
2024-06-04 03:19:13 [INFO]: Epoch 014 - training loss: 0.3383, validation loss: 0.1882
2024-06-04 03:19:19 [INFO]: Epoch 015 - training loss: 0.3288, validation loss: 0.1867
2024-06-04 03:19:24 [INFO]: Epoch 016 - training loss: 0.3135, validation loss: 0.1830
2024-06-04 03:19:30 [INFO]: Epoch 017 - training loss: 0.3031, validation loss: 0.1812
2024-06-04 03:19:35 [INFO]: Epoch 018 - training loss: 0.3031, validation loss: 0.1793
2024-06-04 03:19:41 [INFO]: Epoch 019 - training loss: 0.2987, validation loss: 0.1784
2024-06-04 03:19:46 [INFO]: Epoch 020 - training loss: 0.2949, validation loss: 0.1781
2024-06-04 03:19:51 [INFO]: Epoch 021 - training loss: 0.2978, validation loss: 0.1757
2024-06-04 03:19:57 [INFO]: Epoch 022 - training loss: 0.2925, validation loss: 0.1749
2024-06-04 03:20:02 [INFO]: Epoch 023 - training loss: 0.2840, validation loss: 0.1749
2024-06-04 03:20:08 [INFO]: Epoch 024 - training loss: 0.2822, validation loss: 0.1699
2024-06-04 03:20:13 [INFO]: Epoch 025 - training loss: 0.2781, validation loss: 0.1706
2024-06-04 03:20:18 [INFO]: Epoch 026 - training loss: 0.2718, validation loss: 0.1686
2024-06-04 03:20:24 [INFO]: Epoch 027 - training loss: 0.2801, validation loss: 0.1734
2024-06-04 03:20:30 [INFO]: Epoch 028 - training loss: 0.2960, validation loss: 0.1739
2024-06-04 03:20:35 [INFO]: Epoch 029 - training loss: 0.2765, validation loss: 0.1686
2024-06-04 03:20:40 [INFO]: Epoch 030 - training loss: 0.2599, validation loss: 0.1680
2024-06-04 03:20:46 [INFO]: Epoch 031 - training loss: 0.2543, validation loss: 0.1667
2024-06-04 03:20:52 [INFO]: Epoch 032 - training loss: 0.2609, validation loss: 0.1713
2024-06-04 03:20:57 [INFO]: Epoch 033 - training loss: 0.2619, validation loss: 0.1663
2024-06-04 03:21:02 [INFO]: Epoch 034 - training loss: 0.2548, validation loss: 0.1679
2024-06-04 03:21:08 [INFO]: Epoch 035 - training loss: 0.2495, validation loss: 0.1641
2024-06-04 03:21:13 [INFO]: Epoch 036 - training loss: 0.2442, validation loss: 0.1644
2024-06-04 03:21:19 [INFO]: Epoch 037 - training loss: 0.2501, validation loss: 0.1672
2024-06-04 03:21:24 [INFO]: Epoch 038 - training loss: 0.2506, validation loss: 0.1647
2024-06-04 03:21:30 [INFO]: Epoch 039 - training loss: 0.2441, validation loss: 0.1627
2024-06-04 03:21:35 [INFO]: Epoch 040 - training loss: 0.2412, validation loss: 0.1613
2024-06-04 03:21:41 [INFO]: Epoch 041 - training loss: 0.2378, validation loss: 0.1625
2024-06-04 03:21:46 [INFO]: Epoch 042 - training loss: 0.2416, validation loss: 0.1611
2024-06-04 03:21:52 [INFO]: Epoch 043 - training loss: 0.2376, validation loss: 0.1645
2024-06-04 03:21:57 [INFO]: Epoch 044 - training loss: 0.2353, validation loss: 0.1620
2024-06-04 03:22:03 [INFO]: Epoch 045 - training loss: 0.2348, validation loss: 0.1593
2024-06-04 03:22:08 [INFO]: Epoch 046 - training loss: 0.2344, validation loss: 0.1616
2024-06-04 03:22:14 [INFO]: Epoch 047 - training loss: 0.2297, validation loss: 0.1593
2024-06-04 03:22:19 [INFO]: Epoch 048 - training loss: 0.2296, validation loss: 0.1599
2024-06-04 03:22:25 [INFO]: Epoch 049 - training loss: 0.2280, validation loss: 0.1588
2024-06-04 03:22:30 [INFO]: Epoch 050 - training loss: 0.2263, validation loss: 0.1579
2024-06-04 03:22:36 [INFO]: Epoch 051 - training loss: 0.2266, validation loss: 0.1559
2024-06-04 03:22:41 [INFO]: Epoch 052 - training loss: 0.2241, validation loss: 0.1554
2024-06-04 03:22:46 [INFO]: Epoch 053 - training loss: 0.2229, validation loss: 0.1556
2024-06-04 03:22:52 [INFO]: Epoch 054 - training loss: 0.2192, validation loss: 0.1569
2024-06-04 03:22:57 [INFO]: Epoch 055 - training loss: 0.2203, validation loss: 0.1572
2024-06-04 03:23:03 [INFO]: Epoch 056 - training loss: 0.2202, validation loss: 0.1572
2024-06-04 03:23:08 [INFO]: Epoch 057 - training loss: 0.2200, validation loss: 0.1563
2024-06-04 03:23:14 [INFO]: Epoch 058 - training loss: 0.2180, validation loss: 0.1530
2024-06-04 03:23:19 [INFO]: Epoch 059 - training loss: 0.2185, validation loss: 0.1556
2024-06-04 03:23:25 [INFO]: Epoch 060 - training loss: 0.2182, validation loss: 0.1563
2024-06-04 03:23:30 [INFO]: Epoch 061 - training loss: 0.2208, validation loss: 0.1585
2024-06-04 03:23:36 [INFO]: Epoch 062 - training loss: 0.2156, validation loss: 0.1548
2024-06-04 03:23:41 [INFO]: Epoch 063 - training loss: 0.2093, validation loss: 0.1554
2024-06-04 03:23:47 [INFO]: Epoch 064 - training loss: 0.2099, validation loss: 0.1540
2024-06-04 03:23:52 [INFO]: Epoch 065 - training loss: 0.2106, validation loss: 0.1550
2024-06-04 03:23:58 [INFO]: Epoch 066 - training loss: 0.2080, validation loss: 0.1566
2024-06-04 03:24:03 [INFO]: Epoch 067 - training loss: 0.2077, validation loss: 0.1541
2024-06-04 03:24:09 [INFO]: Epoch 068 - training loss: 0.2159, validation loss: 0.1586
2024-06-04 03:24:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:24:09 [INFO]: Finished training. The best model is from epoch#58.
2024-06-04 03:24:09 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_3/20240604_T031757/iTransformer.pypots
2024-06-04 03:24:11 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_3/imputation.pkl
2024-06-04 03:24:11 [INFO]: Round3 - iTransformer on BeijingAir: MAE=0.1662, MSE=0.1739, MRE=0.2512
2024-06-04 03:24:11 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:24:11 [INFO]: Using the given device: cuda:0
2024-06-04 03:24:11 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_4/20240604_T032411
2024-06-04 03:24:11 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_4/20240604_T032411/tensorboard
2024-06-04 03:24:11 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-04 03:24:17 [INFO]: Epoch 001 - training loss: 0.8087, validation loss: 0.2720
2024-06-04 03:24:22 [INFO]: Epoch 002 - training loss: 0.4786, validation loss: 0.2426
2024-06-04 03:24:28 [INFO]: Epoch 003 - training loss: 0.4322, validation loss: 0.2313
2024-06-04 03:24:33 [INFO]: Epoch 004 - training loss: 0.4132, validation loss: 0.2242
2024-06-04 03:24:38 [INFO]: Epoch 005 - training loss: 0.4036, validation loss: 0.2206
2024-06-04 03:24:44 [INFO]: Epoch 006 - training loss: 0.3951, validation loss: 0.2175
2024-06-04 03:24:50 [INFO]: Epoch 007 - training loss: 0.3944, validation loss: 0.2179
2024-06-04 03:24:55 [INFO]: Epoch 008 - training loss: 0.3769, validation loss: 0.2065
2024-06-04 03:25:00 [INFO]: Epoch 009 - training loss: 0.3715, validation loss: 0.2034
2024-06-04 03:25:06 [INFO]: Epoch 010 - training loss: 0.3631, validation loss: 0.2005
2024-06-04 03:25:11 [INFO]: Epoch 011 - training loss: 0.3622, validation loss: 0.2021
2024-06-04 03:25:17 [INFO]: Epoch 012 - training loss: 0.3538, validation loss: 0.1977
2024-06-04 03:25:22 [INFO]: Epoch 013 - training loss: 0.3460, validation loss: 0.1953
2024-06-04 03:25:28 [INFO]: Epoch 014 - training loss: 0.3355, validation loss: 0.1895
2024-06-04 03:25:33 [INFO]: Epoch 015 - training loss: 0.3252, validation loss: 0.1850
2024-06-04 03:25:38 [INFO]: Epoch 016 - training loss: 0.3157, validation loss: 0.1821
2024-06-04 03:25:43 [INFO]: Epoch 017 - training loss: 0.3152, validation loss: 0.1828
2024-06-04 03:25:48 [INFO]: Epoch 018 - training loss: 0.3172, validation loss: 0.1819
2024-06-04 03:25:53 [INFO]: Epoch 019 - training loss: 0.3143, validation loss: 0.1786
2024-06-04 03:25:57 [INFO]: Epoch 020 - training loss: 0.2993, validation loss: 0.1763
2024-06-04 03:26:02 [INFO]: Epoch 021 - training loss: 0.2941, validation loss: 0.1736
2024-06-04 03:26:06 [INFO]: Epoch 022 - training loss: 0.2882, validation loss: 0.1717
2024-06-04 03:26:11 [INFO]: Epoch 023 - training loss: 0.2863, validation loss: 0.1740
2024-06-04 03:26:15 [INFO]: Epoch 024 - training loss: 0.2881, validation loss: 0.1722
2024-06-04 03:26:20 [INFO]: Epoch 025 - training loss: 0.2800, validation loss: 0.1718
2024-06-04 03:26:24 [INFO]: Epoch 026 - training loss: 0.2727, validation loss: 0.1710
2024-06-04 03:26:29 [INFO]: Epoch 027 - training loss: 0.2822, validation loss: 0.1725
2024-06-04 03:26:33 [INFO]: Epoch 028 - training loss: 0.2686, validation loss: 0.1691
2024-06-04 03:26:38 [INFO]: Epoch 029 - training loss: 0.2669, validation loss: 0.1693
2024-06-04 03:26:42 [INFO]: Epoch 030 - training loss: 0.2768, validation loss: 0.1706
2024-06-04 03:26:47 [INFO]: Epoch 031 - training loss: 0.2646, validation loss: 0.1675
2024-06-04 03:26:51 [INFO]: Epoch 032 - training loss: 0.2622, validation loss: 0.1684
2024-06-04 03:26:56 [INFO]: Epoch 033 - training loss: 0.2588, validation loss: 0.1651
2024-06-04 03:27:00 [INFO]: Epoch 034 - training loss: 0.2548, validation loss: 0.1650
2024-06-04 03:27:04 [INFO]: Epoch 035 - training loss: 0.2550, validation loss: 0.1647
2024-06-04 03:27:09 [INFO]: Epoch 036 - training loss: 0.2505, validation loss: 0.1656
2024-06-04 03:27:13 [INFO]: Epoch 037 - training loss: 0.2531, validation loss: 0.1646
2024-06-04 03:27:18 [INFO]: Epoch 038 - training loss: 0.2517, validation loss: 0.1631
2024-06-04 03:27:22 [INFO]: Epoch 039 - training loss: 0.2455, validation loss: 0.1634
2024-06-04 03:27:27 [INFO]: Epoch 040 - training loss: 0.2422, validation loss: 0.1620
2024-06-04 03:27:31 [INFO]: Epoch 041 - training loss: 0.2434, validation loss: 0.1627
2024-06-04 03:27:36 [INFO]: Epoch 042 - training loss: 0.2491, validation loss: 0.1606
2024-06-04 03:27:40 [INFO]: Epoch 043 - training loss: 0.2373, validation loss: 0.1606
2024-06-04 03:27:45 [INFO]: Epoch 044 - training loss: 0.2359, validation loss: 0.1612
2024-06-04 03:27:49 [INFO]: Epoch 045 - training loss: 0.2397, validation loss: 0.1601
2024-06-04 03:27:54 [INFO]: Epoch 046 - training loss: 0.2393, validation loss: 0.1603
2024-06-04 03:27:58 [INFO]: Epoch 047 - training loss: 0.2371, validation loss: 0.1592
2024-06-04 03:28:02 [INFO]: Epoch 048 - training loss: 0.2372, validation loss: 0.1569
2024-06-04 03:28:07 [INFO]: Epoch 049 - training loss: 0.2286, validation loss: 0.1585
2024-06-04 03:28:11 [INFO]: Epoch 050 - training loss: 0.2288, validation loss: 0.1606
2024-06-04 03:28:16 [INFO]: Epoch 051 - training loss: 0.2294, validation loss: 0.1582
2024-06-04 03:28:20 [INFO]: Epoch 052 - training loss: 0.2220, validation loss: 0.1560
2024-06-04 03:28:25 [INFO]: Epoch 053 - training loss: 0.2271, validation loss: 0.1589
2024-06-04 03:28:29 [INFO]: Epoch 054 - training loss: 0.2210, validation loss: 0.1571
2024-06-04 03:28:34 [INFO]: Epoch 055 - training loss: 0.2218, validation loss: 0.1571
2024-06-04 03:28:38 [INFO]: Epoch 056 - training loss: 0.2247, validation loss: 0.1573
2024-06-04 03:28:42 [INFO]: Epoch 057 - training loss: 0.2179, validation loss: 0.1572
2024-06-04 03:28:47 [INFO]: Epoch 058 - training loss: 0.2201, validation loss: 0.1588
2024-06-04 03:28:51 [INFO]: Epoch 059 - training loss: 0.2212, validation loss: 0.1562
2024-06-04 03:28:56 [INFO]: Epoch 060 - training loss: 0.2189, validation loss: 0.1569
2024-06-04 03:29:00 [INFO]: Epoch 061 - training loss: 0.2177, validation loss: 0.1559
2024-06-04 03:29:04 [INFO]: Epoch 062 - training loss: 0.2162, validation loss: 0.1550
2024-06-04 03:29:09 [INFO]: Epoch 063 - training loss: 0.2141, validation loss: 0.1542
2024-06-04 03:29:13 [INFO]: Epoch 064 - training loss: 0.2157, validation loss: 0.1547
2024-06-04 03:29:18 [INFO]: Epoch 065 - training loss: 0.2115, validation loss: 0.1545
2024-06-04 03:29:22 [INFO]: Epoch 066 - training loss: 0.2091, validation loss: 0.1557
2024-06-04 03:29:27 [INFO]: Epoch 067 - training loss: 0.2087, validation loss: 0.1526
2024-06-04 03:29:31 [INFO]: Epoch 068 - training loss: 0.2132, validation loss: 0.1624
2024-06-04 03:29:36 [INFO]: Epoch 069 - training loss: 0.2206, validation loss: 0.1532
2024-06-04 03:29:40 [INFO]: Epoch 070 - training loss: 0.2090, validation loss: 0.1504
2024-06-04 03:29:45 [INFO]: Epoch 071 - training loss: 0.2085, validation loss: 0.1536
2024-06-04 03:29:49 [INFO]: Epoch 072 - training loss: 0.2059, validation loss: 0.1507
2024-06-04 03:29:54 [INFO]: Epoch 073 - training loss: 0.2030, validation loss: 0.1518
2024-06-04 03:29:58 [INFO]: Epoch 074 - training loss: 0.2025, validation loss: 0.1532
2024-06-04 03:30:02 [INFO]: Epoch 075 - training loss: 0.2064, validation loss: 0.1516
2024-06-04 03:30:07 [INFO]: Epoch 076 - training loss: 0.2072, validation loss: 0.1524
2024-06-04 03:30:11 [INFO]: Epoch 077 - training loss: 0.2054, validation loss: 0.1503
2024-06-04 03:30:16 [INFO]: Epoch 078 - training loss: 0.1993, validation loss: 0.1504
2024-06-04 03:30:20 [INFO]: Epoch 079 - training loss: 0.2015, validation loss: 0.1529
2024-06-04 03:30:25 [INFO]: Epoch 080 - training loss: 0.2031, validation loss: 0.1489
2024-06-04 03:30:29 [INFO]: Epoch 081 - training loss: 0.1989, validation loss: 0.1498
2024-06-04 03:30:33 [INFO]: Epoch 082 - training loss: 0.1956, validation loss: 0.1492
2024-06-04 03:30:38 [INFO]: Epoch 083 - training loss: 0.1965, validation loss: 0.1504
2024-06-04 03:30:42 [INFO]: Epoch 084 - training loss: 0.1954, validation loss: 0.1487
2024-06-04 03:30:47 [INFO]: Epoch 085 - training loss: 0.2050, validation loss: 0.1507
2024-06-04 03:30:51 [INFO]: Epoch 086 - training loss: 0.1966, validation loss: 0.1493
2024-06-04 03:30:56 [INFO]: Epoch 087 - training loss: 0.1949, validation loss: 0.1485
2024-06-04 03:31:00 [INFO]: Epoch 088 - training loss: 0.1943, validation loss: 0.1475
2024-06-04 03:31:05 [INFO]: Epoch 089 - training loss: 0.1967, validation loss: 0.1489
2024-06-04 03:31:09 [INFO]: Epoch 090 - training loss: 0.1940, validation loss: 0.1463
2024-06-04 03:31:14 [INFO]: Epoch 091 - training loss: 0.1926, validation loss: 0.1474
2024-06-04 03:31:18 [INFO]: Epoch 092 - training loss: 0.1926, validation loss: 0.1490
2024-06-04 03:31:22 [INFO]: Epoch 093 - training loss: 0.1959, validation loss: 0.1479
2024-06-04 03:31:27 [INFO]: Epoch 094 - training loss: 0.1939, validation loss: 0.1462
2024-06-04 03:31:31 [INFO]: Epoch 095 - training loss: 0.1904, validation loss: 0.1471
2024-06-04 03:31:36 [INFO]: Epoch 096 - training loss: 0.1893, validation loss: 0.1456
2024-06-04 03:31:40 [INFO]: Epoch 097 - training loss: 0.1883, validation loss: 0.1462
2024-06-04 03:31:45 [INFO]: Epoch 098 - training loss: 0.1864, validation loss: 0.1453
2024-06-04 03:31:49 [INFO]: Epoch 099 - training loss: 0.1872, validation loss: 0.1461
2024-06-04 03:31:54 [INFO]: Epoch 100 - training loss: 0.1876, validation loss: 0.1479
2024-06-04 03:31:54 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 03:31:54 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_4/20240604_T032411/iTransformer.pypots
2024-06-04 03:31:56 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/iTransformer_BeijingAir/round_4/imputation.pkl
2024-06-04 03:31:56 [INFO]: Round4 - iTransformer on BeijingAir: MAE=0.1560, MSE=0.1711, MRE=0.2357
2024-06-04 03:31:56 [INFO]: Done! Final results:
Averaged iTransformer (8,286,232 params) on BeijingAir: MAE=0.1226 ± 0.00505031661992431, MSE=0.1266 ± 0.0027834430604603308, MRE=0.1631 ± 0.0067172746072919455, average inference time=0.37