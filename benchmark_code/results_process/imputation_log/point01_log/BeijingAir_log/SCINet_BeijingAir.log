2024-06-04 02:49:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:49:23 [INFO]: Using the given device: cuda:0
2024-06-04 02:49:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_0/20240604_T024924
2024-06-04 02:49:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_0/20240604_T024924/tensorboard
2024-06-04 02:49:26 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-04 02:49:39 [INFO]: Epoch 001 - training loss: 1.3929, validation loss: 0.7393
2024-06-04 02:49:44 [INFO]: Epoch 002 - training loss: 0.9608, validation loss: 0.4702
2024-06-04 02:49:49 [INFO]: Epoch 003 - training loss: 0.7652, validation loss: 0.3566
2024-06-04 02:49:54 [INFO]: Epoch 004 - training loss: 0.6538, validation loss: 0.3091
2024-06-04 02:49:59 [INFO]: Epoch 005 - training loss: 0.5861, validation loss: 0.2789
2024-06-04 02:50:05 [INFO]: Epoch 006 - training loss: 0.5379, validation loss: 0.2561
2024-06-04 02:50:10 [INFO]: Epoch 007 - training loss: 0.5011, validation loss: 0.2472
2024-06-04 02:50:15 [INFO]: Epoch 008 - training loss: 0.4742, validation loss: 0.2333
2024-06-04 02:50:21 [INFO]: Epoch 009 - training loss: 0.4522, validation loss: 0.2275
2024-06-04 02:50:26 [INFO]: Epoch 010 - training loss: 0.4370, validation loss: 0.2185
2024-06-04 02:50:31 [INFO]: Epoch 011 - training loss: 0.4244, validation loss: 0.2174
2024-06-04 02:50:36 [INFO]: Epoch 012 - training loss: 0.4111, validation loss: 0.2095
2024-06-04 02:50:41 [INFO]: Epoch 013 - training loss: 0.4064, validation loss: 0.1978
2024-06-04 02:50:47 [INFO]: Epoch 014 - training loss: 0.3979, validation loss: 0.2063
2024-06-04 02:50:52 [INFO]: Epoch 015 - training loss: 0.3890, validation loss: 0.1933
2024-06-04 02:50:57 [INFO]: Epoch 016 - training loss: 0.3818, validation loss: 0.1882
2024-06-04 02:51:03 [INFO]: Epoch 017 - training loss: 0.3748, validation loss: 0.1803
2024-06-04 02:51:08 [INFO]: Epoch 018 - training loss: 0.3697, validation loss: 0.1820
2024-06-04 02:51:14 [INFO]: Epoch 019 - training loss: 0.3669, validation loss: 0.1789
2024-06-04 02:51:19 [INFO]: Epoch 020 - training loss: 0.3648, validation loss: 0.1730
2024-06-04 02:51:24 [INFO]: Epoch 021 - training loss: 0.3620, validation loss: 0.1730
2024-06-04 02:51:30 [INFO]: Epoch 022 - training loss: 0.3589, validation loss: 0.1662
2024-06-04 02:51:35 [INFO]: Epoch 023 - training loss: 0.3567, validation loss: 0.1657
2024-06-04 02:51:40 [INFO]: Epoch 024 - training loss: 0.3539, validation loss: 0.1679
2024-06-04 02:51:45 [INFO]: Epoch 025 - training loss: 0.3546, validation loss: 0.1624
2024-06-04 02:51:51 [INFO]: Epoch 026 - training loss: 0.3491, validation loss: 0.1622
2024-06-04 02:51:56 [INFO]: Epoch 027 - training loss: 0.3509, validation loss: 0.1623
2024-06-04 02:52:01 [INFO]: Epoch 028 - training loss: 0.3476, validation loss: 0.1611
2024-06-04 02:52:06 [INFO]: Epoch 029 - training loss: 0.3480, validation loss: 0.1556
2024-06-04 02:52:12 [INFO]: Epoch 030 - training loss: 0.3477, validation loss: 0.1565
2024-06-04 02:52:17 [INFO]: Epoch 031 - training loss: 0.3479, validation loss: 0.1598
2024-06-04 02:52:22 [INFO]: Epoch 032 - training loss: 0.3444, validation loss: 0.1568
2024-06-04 02:52:27 [INFO]: Epoch 033 - training loss: 0.3435, validation loss: 0.1559
2024-06-04 02:52:32 [INFO]: Epoch 034 - training loss: 0.3404, validation loss: 0.1565
2024-06-04 02:52:38 [INFO]: Epoch 035 - training loss: 0.3408, validation loss: 0.1563
2024-06-04 02:52:43 [INFO]: Epoch 036 - training loss: 0.3407, validation loss: 0.1548
2024-06-04 02:52:49 [INFO]: Epoch 037 - training loss: 0.3434, validation loss: 0.1506
2024-06-04 02:52:54 [INFO]: Epoch 038 - training loss: 0.3417, validation loss: 0.1538
2024-06-04 02:52:59 [INFO]: Epoch 039 - training loss: 0.3391, validation loss: 0.1529
2024-06-04 02:53:04 [INFO]: Epoch 040 - training loss: 0.3367, validation loss: 0.1530
2024-06-04 02:53:09 [INFO]: Epoch 041 - training loss: 0.3379, validation loss: 0.1504
2024-06-04 02:53:15 [INFO]: Epoch 042 - training loss: 0.3343, validation loss: 0.1465
2024-06-04 02:53:20 [INFO]: Epoch 043 - training loss: 0.3383, validation loss: 0.1503
2024-06-04 02:53:25 [INFO]: Epoch 044 - training loss: 0.3348, validation loss: 0.1505
2024-06-04 02:53:30 [INFO]: Epoch 045 - training loss: 0.3355, validation loss: 0.1504
2024-06-04 02:53:36 [INFO]: Epoch 046 - training loss: 0.3371, validation loss: 0.1474
2024-06-04 02:53:41 [INFO]: Epoch 047 - training loss: 0.3323, validation loss: 0.1479
2024-06-04 02:53:47 [INFO]: Epoch 048 - training loss: 0.3441, validation loss: 0.1462
2024-06-04 02:53:52 [INFO]: Epoch 049 - training loss: 0.3346, validation loss: 0.1480
2024-06-04 02:53:57 [INFO]: Epoch 050 - training loss: 0.3343, validation loss: 0.1448
2024-06-04 02:54:03 [INFO]: Epoch 051 - training loss: 0.3310, validation loss: 0.1475
2024-06-04 02:54:08 [INFO]: Epoch 052 - training loss: 0.3316, validation loss: 0.1476
2024-06-04 02:54:13 [INFO]: Epoch 053 - training loss: 0.3326, validation loss: 0.1474
2024-06-04 02:54:19 [INFO]: Epoch 054 - training loss: 0.3294, validation loss: 0.1454
2024-06-04 02:54:24 [INFO]: Epoch 055 - training loss: 0.3291, validation loss: 0.1458
2024-06-04 02:54:30 [INFO]: Epoch 056 - training loss: 0.3296, validation loss: 0.1465
2024-06-04 02:54:35 [INFO]: Epoch 057 - training loss: 0.3301, validation loss: 0.1452
2024-06-04 02:54:40 [INFO]: Epoch 058 - training loss: 0.3308, validation loss: 0.1446
2024-06-04 02:54:46 [INFO]: Epoch 059 - training loss: 0.3303, validation loss: 0.1461
2024-06-04 02:54:51 [INFO]: Epoch 060 - training loss: 0.3274, validation loss: 0.1463
2024-06-04 02:54:57 [INFO]: Epoch 061 - training loss: 0.3264, validation loss: 0.1431
2024-06-04 02:55:02 [INFO]: Epoch 062 - training loss: 0.3258, validation loss: 0.1436
2024-06-04 02:55:08 [INFO]: Epoch 063 - training loss: 0.3260, validation loss: 0.1437
2024-06-04 02:55:13 [INFO]: Epoch 064 - training loss: 0.3306, validation loss: 0.1495
2024-06-04 02:55:19 [INFO]: Epoch 065 - training loss: 0.3372, validation loss: 0.1415
2024-06-04 02:55:24 [INFO]: Epoch 066 - training loss: 0.3303, validation loss: 0.1462
2024-06-04 02:55:29 [INFO]: Epoch 067 - training loss: 0.3246, validation loss: 0.1469
2024-06-04 02:55:35 [INFO]: Epoch 068 - training loss: 0.3255, validation loss: 0.1442
2024-06-04 02:55:40 [INFO]: Epoch 069 - training loss: 0.3234, validation loss: 0.1459
2024-06-04 02:55:45 [INFO]: Epoch 070 - training loss: 0.3228, validation loss: 0.1423
2024-06-04 02:55:50 [INFO]: Epoch 071 - training loss: 0.3226, validation loss: 0.1426
2024-06-04 02:55:55 [INFO]: Epoch 072 - training loss: 0.3225, validation loss: 0.1445
2024-06-04 02:56:00 [INFO]: Epoch 073 - training loss: 0.3202, validation loss: 0.1454
2024-06-04 02:56:05 [INFO]: Epoch 074 - training loss: 0.3214, validation loss: 0.1478
2024-06-04 02:56:10 [INFO]: Epoch 075 - training loss: 0.3209, validation loss: 0.1422
2024-06-04 02:56:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:56:10 [INFO]: Finished training. The best model is from epoch#65.
2024-06-04 02:56:11 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_0/20240604_T024924/SCINet.pypots
2024-06-04 02:56:13 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_0/imputation.pkl
2024-06-04 02:56:13 [INFO]: Round0 - SCINet on BeijingAir: MAE=0.2298, MSE=0.1860, MRE=0.3472
2024-06-04 02:56:13 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 02:56:13 [INFO]: Using the given device: cuda:0
2024-06-04 02:56:13 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_1/20240604_T025613
2024-06-04 02:56:13 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_1/20240604_T025613/tensorboard
2024-06-04 02:56:14 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-04 02:56:19 [INFO]: Epoch 001 - training loss: 1.4070, validation loss: 0.7249
2024-06-04 02:56:25 [INFO]: Epoch 002 - training loss: 0.9639, validation loss: 0.4772
2024-06-04 02:56:30 [INFO]: Epoch 003 - training loss: 0.7808, validation loss: 0.3749
2024-06-04 02:56:35 [INFO]: Epoch 004 - training loss: 0.6820, validation loss: 0.3293
2024-06-04 02:56:40 [INFO]: Epoch 005 - training loss: 0.6192, validation loss: 0.3031
2024-06-04 02:56:45 [INFO]: Epoch 006 - training loss: 0.5644, validation loss: 0.2781
2024-06-04 02:56:50 [INFO]: Epoch 007 - training loss: 0.5277, validation loss: 0.2634
2024-06-04 02:56:55 [INFO]: Epoch 008 - training loss: 0.4963, validation loss: 0.2566
2024-06-04 02:57:01 [INFO]: Epoch 009 - training loss: 0.4792, validation loss: 0.2416
2024-06-04 02:57:06 [INFO]: Epoch 010 - training loss: 0.4554, validation loss: 0.2416
2024-06-04 02:57:11 [INFO]: Epoch 011 - training loss: 0.4402, validation loss: 0.2286
2024-06-04 02:57:16 [INFO]: Epoch 012 - training loss: 0.4260, validation loss: 0.2263
2024-06-04 02:57:21 [INFO]: Epoch 013 - training loss: 0.4160, validation loss: 0.2227
2024-06-04 02:57:26 [INFO]: Epoch 014 - training loss: 0.4073, validation loss: 0.2159
2024-06-04 02:57:32 [INFO]: Epoch 015 - training loss: 0.4030, validation loss: 0.2030
2024-06-04 02:57:37 [INFO]: Epoch 016 - training loss: 0.3916, validation loss: 0.2010
2024-06-04 02:57:43 [INFO]: Epoch 017 - training loss: 0.3868, validation loss: 0.1991
2024-06-04 02:57:48 [INFO]: Epoch 018 - training loss: 0.3823, validation loss: 0.1959
2024-06-04 02:57:54 [INFO]: Epoch 019 - training loss: 0.3762, validation loss: 0.1903
2024-06-04 02:57:59 [INFO]: Epoch 020 - training loss: 0.3723, validation loss: 0.1900
2024-06-04 02:58:04 [INFO]: Epoch 021 - training loss: 0.3724, validation loss: 0.1836
2024-06-04 02:58:09 [INFO]: Epoch 022 - training loss: 0.3663, validation loss: 0.1798
2024-06-04 02:58:15 [INFO]: Epoch 023 - training loss: 0.3612, validation loss: 0.1778
2024-06-04 02:58:20 [INFO]: Epoch 024 - training loss: 0.3632, validation loss: 0.1840
2024-06-04 02:58:26 [INFO]: Epoch 025 - training loss: 0.3622, validation loss: 0.1709
2024-06-04 02:58:31 [INFO]: Epoch 026 - training loss: 0.3561, validation loss: 0.1741
2024-06-04 02:58:36 [INFO]: Epoch 027 - training loss: 0.3524, validation loss: 0.1684
2024-06-04 02:58:42 [INFO]: Epoch 028 - training loss: 0.3497, validation loss: 0.1671
2024-06-04 02:58:47 [INFO]: Epoch 029 - training loss: 0.3500, validation loss: 0.1687
2024-06-04 02:58:53 [INFO]: Epoch 030 - training loss: 0.3480, validation loss: 0.1639
2024-06-04 02:58:58 [INFO]: Epoch 031 - training loss: 0.3453, validation loss: 0.1599
2024-06-04 02:59:04 [INFO]: Epoch 032 - training loss: 0.3461, validation loss: 0.1626
2024-06-04 02:59:09 [INFO]: Epoch 033 - training loss: 0.3462, validation loss: 0.1633
2024-06-04 02:59:14 [INFO]: Epoch 034 - training loss: 0.3473, validation loss: 0.1574
2024-06-04 02:59:20 [INFO]: Epoch 035 - training loss: 0.3433, validation loss: 0.1571
2024-06-04 02:59:25 [INFO]: Epoch 036 - training loss: 0.3422, validation loss: 0.1551
2024-06-04 02:59:31 [INFO]: Epoch 037 - training loss: 0.3391, validation loss: 0.1563
2024-06-04 02:59:36 [INFO]: Epoch 038 - training loss: 0.3408, validation loss: 0.1565
2024-06-04 02:59:41 [INFO]: Epoch 039 - training loss: 0.3392, validation loss: 0.1555
2024-06-04 02:59:47 [INFO]: Epoch 040 - training loss: 0.3417, validation loss: 0.1576
2024-06-04 02:59:52 [INFO]: Epoch 041 - training loss: 0.3424, validation loss: 0.1504
2024-06-04 02:59:57 [INFO]: Epoch 042 - training loss: 0.3384, validation loss: 0.1549
2024-06-04 03:00:03 [INFO]: Epoch 043 - training loss: 0.3381, validation loss: 0.1531
2024-06-04 03:00:08 [INFO]: Epoch 044 - training loss: 0.3390, validation loss: 0.1589
2024-06-04 03:00:13 [INFO]: Epoch 045 - training loss: 0.3412, validation loss: 0.1485
2024-06-04 03:00:19 [INFO]: Epoch 046 - training loss: 0.3382, validation loss: 0.1506
2024-06-04 03:00:24 [INFO]: Epoch 047 - training loss: 0.3369, validation loss: 0.1476
2024-06-04 03:00:30 [INFO]: Epoch 048 - training loss: 0.3334, validation loss: 0.1507
2024-06-04 03:00:35 [INFO]: Epoch 049 - training loss: 0.3333, validation loss: 0.1514
2024-06-04 03:00:41 [INFO]: Epoch 050 - training loss: 0.3316, validation loss: 0.1501
2024-06-04 03:00:47 [INFO]: Epoch 051 - training loss: 0.3314, validation loss: 0.1461
2024-06-04 03:00:52 [INFO]: Epoch 052 - training loss: 0.3327, validation loss: 0.1490
2024-06-04 03:00:58 [INFO]: Epoch 053 - training loss: 0.3363, validation loss: 0.1467
2024-06-04 03:01:03 [INFO]: Epoch 054 - training loss: 0.3312, validation loss: 0.1463
2024-06-04 03:01:08 [INFO]: Epoch 055 - training loss: 0.3302, validation loss: 0.1440
2024-06-04 03:01:13 [INFO]: Epoch 056 - training loss: 0.3296, validation loss: 0.1456
2024-06-04 03:01:19 [INFO]: Epoch 057 - training loss: 0.3309, validation loss: 0.1496
2024-06-04 03:01:24 [INFO]: Epoch 058 - training loss: 0.3317, validation loss: 0.1474
2024-06-04 03:01:29 [INFO]: Epoch 059 - training loss: 0.3320, validation loss: 0.1511
2024-06-04 03:01:33 [INFO]: Epoch 060 - training loss: 0.3354, validation loss: 0.1468
2024-06-04 03:01:38 [INFO]: Epoch 061 - training loss: 0.3309, validation loss: 0.1450
2024-06-04 03:01:42 [INFO]: Epoch 062 - training loss: 0.3298, validation loss: 0.1441
2024-06-04 03:01:46 [INFO]: Epoch 063 - training loss: 0.3286, validation loss: 0.1458
2024-06-04 03:01:51 [INFO]: Epoch 064 - training loss: 0.3289, validation loss: 0.1469
2024-06-04 03:01:56 [INFO]: Epoch 065 - training loss: 0.3291, validation loss: 0.1418
2024-06-04 03:02:02 [INFO]: Epoch 066 - training loss: 0.3273, validation loss: 0.1471
2024-06-04 03:02:07 [INFO]: Epoch 067 - training loss: 0.3265, validation loss: 0.1455
2024-06-04 03:02:13 [INFO]: Epoch 068 - training loss: 0.3306, validation loss: 0.1448
2024-06-04 03:02:18 [INFO]: Epoch 069 - training loss: 0.3314, validation loss: 0.1472
2024-06-04 03:02:24 [INFO]: Epoch 070 - training loss: 0.3249, validation loss: 0.1400
2024-06-04 03:02:29 [INFO]: Epoch 071 - training loss: 0.3229, validation loss: 0.1435
2024-06-04 03:02:34 [INFO]: Epoch 072 - training loss: 0.3256, validation loss: 0.1436
2024-06-04 03:02:40 [INFO]: Epoch 073 - training loss: 0.3249, validation loss: 0.1425
2024-06-04 03:02:45 [INFO]: Epoch 074 - training loss: 0.3246, validation loss: 0.1427
2024-06-04 03:02:51 [INFO]: Epoch 075 - training loss: 0.3231, validation loss: 0.1428
2024-06-04 03:02:56 [INFO]: Epoch 076 - training loss: 0.3227, validation loss: 0.1409
2024-06-04 03:03:01 [INFO]: Epoch 077 - training loss: 0.3236, validation loss: 0.1412
2024-06-04 03:03:07 [INFO]: Epoch 078 - training loss: 0.3256, validation loss: 0.1403
2024-06-04 03:03:12 [INFO]: Epoch 079 - training loss: 0.3225, validation loss: 0.1421
2024-06-04 03:03:17 [INFO]: Epoch 080 - training loss: 0.3232, validation loss: 0.1418
2024-06-04 03:03:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:03:17 [INFO]: Finished training. The best model is from epoch#70.
2024-06-04 03:03:18 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_1/20240604_T025613/SCINet.pypots
2024-06-04 03:03:19 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_1/imputation.pkl
2024-06-04 03:03:19 [INFO]: Round1 - SCINet on BeijingAir: MAE=0.2301, MSE=0.1869, MRE=0.3477
2024-06-04 03:03:19 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:03:19 [INFO]: Using the given device: cuda:0
2024-06-04 03:03:19 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_2/20240604_T030319
2024-06-04 03:03:19 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_2/20240604_T030319/tensorboard
2024-06-04 03:03:20 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-04 03:03:25 [INFO]: Epoch 001 - training loss: 1.3565, validation loss: 0.7340
2024-06-04 03:03:31 [INFO]: Epoch 002 - training loss: 0.9759, validation loss: 0.5374
2024-06-04 03:03:36 [INFO]: Epoch 003 - training loss: 0.8292, validation loss: 0.4696
2024-06-04 03:03:41 [INFO]: Epoch 004 - training loss: 0.7622, validation loss: 0.4354
2024-06-04 03:03:47 [INFO]: Epoch 005 - training loss: 0.7172, validation loss: 0.4141
2024-06-04 03:03:52 [INFO]: Epoch 006 - training loss: 0.6814, validation loss: 0.3939
2024-06-04 03:03:58 [INFO]: Epoch 007 - training loss: 0.6487, validation loss: 0.3998
2024-06-04 03:04:03 [INFO]: Epoch 008 - training loss: 0.6276, validation loss: 0.3719
2024-06-04 03:04:08 [INFO]: Epoch 009 - training loss: 0.6078, validation loss: 0.3621
2024-06-04 03:04:14 [INFO]: Epoch 010 - training loss: 0.5920, validation loss: 0.3542
2024-06-04 03:04:19 [INFO]: Epoch 011 - training loss: 0.5721, validation loss: 0.3538
2024-06-04 03:04:24 [INFO]: Epoch 012 - training loss: 0.5642, validation loss: 0.3471
2024-06-04 03:04:30 [INFO]: Epoch 013 - training loss: 0.5617, validation loss: 0.3418
2024-06-04 03:04:35 [INFO]: Epoch 014 - training loss: 0.5366, validation loss: 0.3322
2024-06-04 03:04:41 [INFO]: Epoch 015 - training loss: 0.5283, validation loss: 0.3341
2024-06-04 03:04:46 [INFO]: Epoch 016 - training loss: 0.5212, validation loss: 0.3258
2024-06-04 03:04:52 [INFO]: Epoch 017 - training loss: 0.5174, validation loss: 0.3277
2024-06-04 03:04:57 [INFO]: Epoch 018 - training loss: 0.5043, validation loss: 0.3172
2024-06-04 03:05:02 [INFO]: Epoch 019 - training loss: 0.4937, validation loss: 0.3098
2024-06-04 03:05:07 [INFO]: Epoch 020 - training loss: 0.4863, validation loss: 0.3051
2024-06-04 03:05:12 [INFO]: Epoch 021 - training loss: 0.4907, validation loss: 0.3147
2024-06-04 03:05:18 [INFO]: Epoch 022 - training loss: 0.4826, validation loss: 0.3052
2024-06-04 03:05:23 [INFO]: Epoch 023 - training loss: 0.4724, validation loss: 0.2966
2024-06-04 03:05:28 [INFO]: Epoch 024 - training loss: 0.4630, validation loss: 0.2964
2024-06-04 03:05:33 [INFO]: Epoch 025 - training loss: 0.4597, validation loss: 0.2908
2024-06-04 03:05:38 [INFO]: Epoch 026 - training loss: 0.4609, validation loss: 0.2950
2024-06-04 03:05:43 [INFO]: Epoch 027 - training loss: 0.4588, validation loss: 0.2884
2024-06-04 03:05:48 [INFO]: Epoch 028 - training loss: 0.4531, validation loss: 0.2869
2024-06-04 03:05:53 [INFO]: Epoch 029 - training loss: 0.4477, validation loss: 0.2884
2024-06-04 03:05:58 [INFO]: Epoch 030 - training loss: 0.4352, validation loss: 0.2832
2024-06-04 03:06:03 [INFO]: Epoch 031 - training loss: 0.4390, validation loss: 0.2778
2024-06-04 03:06:09 [INFO]: Epoch 032 - training loss: 0.4399, validation loss: 0.2814
2024-06-04 03:06:13 [INFO]: Epoch 033 - training loss: 0.4397, validation loss: 0.2742
2024-06-04 03:06:18 [INFO]: Epoch 034 - training loss: 0.4290, validation loss: 0.2710
2024-06-04 03:06:23 [INFO]: Epoch 035 - training loss: 0.4235, validation loss: 0.2711
2024-06-04 03:06:28 [INFO]: Epoch 036 - training loss: 0.4214, validation loss: 0.2664
2024-06-04 03:06:33 [INFO]: Epoch 037 - training loss: 0.4200, validation loss: 0.2661
2024-06-04 03:06:38 [INFO]: Epoch 038 - training loss: 0.4198, validation loss: 0.2593
2024-06-04 03:06:43 [INFO]: Epoch 039 - training loss: 0.4134, validation loss: 0.2657
2024-06-04 03:06:48 [INFO]: Epoch 040 - training loss: 0.4069, validation loss: 0.2574
2024-06-04 03:06:52 [INFO]: Epoch 041 - training loss: 0.4065, validation loss: 0.2610
2024-06-04 03:06:57 [INFO]: Epoch 042 - training loss: 0.4086, validation loss: 0.2603
2024-06-04 03:07:02 [INFO]: Epoch 043 - training loss: 0.4020, validation loss: 0.2555
2024-06-04 03:07:07 [INFO]: Epoch 044 - training loss: 0.4058, validation loss: 0.2519
2024-06-04 03:07:12 [INFO]: Epoch 045 - training loss: 0.4025, validation loss: 0.2570
2024-06-04 03:07:16 [INFO]: Epoch 046 - training loss: 0.3985, validation loss: 0.2476
2024-06-04 03:07:21 [INFO]: Epoch 047 - training loss: 0.4018, validation loss: 0.2571
2024-06-04 03:07:26 [INFO]: Epoch 048 - training loss: 0.4048, validation loss: 0.2495
2024-06-04 03:07:31 [INFO]: Epoch 049 - training loss: 0.3937, validation loss: 0.2500
2024-06-04 03:07:36 [INFO]: Epoch 050 - training loss: 0.3891, validation loss: 0.2492
2024-06-04 03:07:41 [INFO]: Epoch 051 - training loss: 0.3938, validation loss: 0.2423
2024-06-04 03:07:45 [INFO]: Epoch 052 - training loss: 0.3924, validation loss: 0.2470
2024-06-04 03:07:50 [INFO]: Epoch 053 - training loss: 0.3912, validation loss: 0.2451
2024-06-04 03:07:55 [INFO]: Epoch 054 - training loss: 0.3877, validation loss: 0.2388
2024-06-04 03:08:00 [INFO]: Epoch 055 - training loss: 0.3921, validation loss: 0.2500
2024-06-04 03:08:05 [INFO]: Epoch 056 - training loss: 0.3926, validation loss: 0.2525
2024-06-04 03:08:10 [INFO]: Epoch 057 - training loss: 0.3912, validation loss: 0.2418
2024-06-04 03:08:15 [INFO]: Epoch 058 - training loss: 0.3838, validation loss: 0.2427
2024-06-04 03:08:20 [INFO]: Epoch 059 - training loss: 0.3925, validation loss: 0.2429
2024-06-04 03:08:25 [INFO]: Epoch 060 - training loss: 0.3871, validation loss: 0.2592
2024-06-04 03:08:30 [INFO]: Epoch 061 - training loss: 0.3845, validation loss: 0.2418
2024-06-04 03:08:35 [INFO]: Epoch 062 - training loss: 0.3819, validation loss: 0.2409
2024-06-04 03:08:39 [INFO]: Epoch 063 - training loss: 0.3761, validation loss: 0.2398
2024-06-04 03:08:44 [INFO]: Epoch 064 - training loss: 0.3765, validation loss: 0.2315
2024-06-04 03:08:50 [INFO]: Epoch 065 - training loss: 0.3733, validation loss: 0.2375
2024-06-04 03:08:54 [INFO]: Epoch 066 - training loss: 0.3768, validation loss: 0.2326
2024-06-04 03:08:59 [INFO]: Epoch 067 - training loss: 0.3750, validation loss: 0.2355
2024-06-04 03:09:04 [INFO]: Epoch 068 - training loss: 0.3745, validation loss: 0.2356
2024-06-04 03:09:10 [INFO]: Epoch 069 - training loss: 0.3720, validation loss: 0.2324
2024-06-04 03:09:14 [INFO]: Epoch 070 - training loss: 0.3695, validation loss: 0.2416
2024-06-04 03:09:19 [INFO]: Epoch 071 - training loss: 0.3712, validation loss: 0.2332
2024-06-04 03:09:24 [INFO]: Epoch 072 - training loss: 0.3696, validation loss: 0.2295
2024-06-04 03:09:29 [INFO]: Epoch 073 - training loss: 0.3702, validation loss: 0.2352
2024-06-04 03:09:33 [INFO]: Epoch 074 - training loss: 0.3728, validation loss: 0.2339
2024-06-04 03:09:38 [INFO]: Epoch 075 - training loss: 0.3666, validation loss: 0.2308
2024-06-04 03:09:43 [INFO]: Epoch 076 - training loss: 0.3658, validation loss: 0.2253
2024-06-04 03:09:48 [INFO]: Epoch 077 - training loss: 0.3681, validation loss: 0.2313
2024-06-04 03:09:53 [INFO]: Epoch 078 - training loss: 0.3643, validation loss: 0.2276
2024-06-04 03:09:58 [INFO]: Epoch 079 - training loss: 0.3664, validation loss: 0.2324
2024-06-04 03:10:03 [INFO]: Epoch 080 - training loss: 0.3628, validation loss: 0.2266
2024-06-04 03:10:08 [INFO]: Epoch 081 - training loss: 0.3619, validation loss: 0.2214
2024-06-04 03:10:13 [INFO]: Epoch 082 - training loss: 0.3660, validation loss: 0.2268
2024-06-04 03:10:18 [INFO]: Epoch 083 - training loss: 0.3652, validation loss: 0.2309
2024-06-04 03:10:22 [INFO]: Epoch 084 - training loss: 0.3594, validation loss: 0.2184
2024-06-04 03:10:27 [INFO]: Epoch 085 - training loss: 0.3617, validation loss: 0.2330
2024-06-04 03:10:32 [INFO]: Epoch 086 - training loss: 0.3650, validation loss: 0.2273
2024-06-04 03:10:37 [INFO]: Epoch 087 - training loss: 0.3567, validation loss: 0.2231
2024-06-04 03:10:42 [INFO]: Epoch 088 - training loss: 0.3572, validation loss: 0.2198
2024-06-04 03:10:47 [INFO]: Epoch 089 - training loss: 0.3539, validation loss: 0.2224
2024-06-04 03:10:52 [INFO]: Epoch 090 - training loss: 0.3540, validation loss: 0.2221
2024-06-04 03:10:57 [INFO]: Epoch 091 - training loss: 0.3555, validation loss: 0.2239
2024-06-04 03:11:02 [INFO]: Epoch 092 - training loss: 0.3636, validation loss: 0.2254
2024-06-04 03:11:07 [INFO]: Epoch 093 - training loss: 0.3596, validation loss: 0.2257
2024-06-04 03:11:12 [INFO]: Epoch 094 - training loss: 0.3625, validation loss: 0.2228
2024-06-04 03:11:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:11:12 [INFO]: Finished training. The best model is from epoch#84.
2024-06-04 03:11:12 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_2/20240604_T030319/SCINet.pypots
2024-06-04 03:11:13 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_2/imputation.pkl
2024-06-04 03:11:13 [INFO]: Round2 - SCINet on BeijingAir: MAE=0.2654, MSE=0.2603, MRE=0.4010
2024-06-04 03:11:13 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:11:13 [INFO]: Using the given device: cuda:0
2024-06-04 03:11:14 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_3/20240604_T031113
2024-06-04 03:11:14 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_3/20240604_T031113/tensorboard
2024-06-04 03:11:14 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-04 03:11:19 [INFO]: Epoch 001 - training loss: 1.3172, validation loss: 0.6239
2024-06-04 03:11:24 [INFO]: Epoch 002 - training loss: 0.9288, validation loss: 0.4649
2024-06-04 03:11:28 [INFO]: Epoch 003 - training loss: 0.7786, validation loss: 0.3717
2024-06-04 03:11:33 [INFO]: Epoch 004 - training loss: 0.6666, validation loss: 0.3101
2024-06-04 03:11:38 [INFO]: Epoch 005 - training loss: 0.5933, validation loss: 0.2832
2024-06-04 03:11:43 [INFO]: Epoch 006 - training loss: 0.5511, validation loss: 0.2708
2024-06-04 03:11:48 [INFO]: Epoch 007 - training loss: 0.5137, validation loss: 0.2541
2024-06-04 03:11:53 [INFO]: Epoch 008 - training loss: 0.4879, validation loss: 0.2445
2024-06-04 03:11:58 [INFO]: Epoch 009 - training loss: 0.4626, validation loss: 0.2343
2024-06-04 03:12:03 [INFO]: Epoch 010 - training loss: 0.4474, validation loss: 0.2231
2024-06-04 03:12:08 [INFO]: Epoch 011 - training loss: 0.4309, validation loss: 0.2190
2024-06-04 03:12:13 [INFO]: Epoch 012 - training loss: 0.4172, validation loss: 0.2124
2024-06-04 03:12:18 [INFO]: Epoch 013 - training loss: 0.4088, validation loss: 0.2016
2024-06-04 03:12:23 [INFO]: Epoch 014 - training loss: 0.3984, validation loss: 0.2007
2024-06-04 03:12:28 [INFO]: Epoch 015 - training loss: 0.3917, validation loss: 0.1945
2024-06-04 03:12:33 [INFO]: Epoch 016 - training loss: 0.3860, validation loss: 0.1924
2024-06-04 03:12:37 [INFO]: Epoch 017 - training loss: 0.3820, validation loss: 0.1878
2024-06-04 03:12:42 [INFO]: Epoch 018 - training loss: 0.3754, validation loss: 0.1861
2024-06-04 03:12:47 [INFO]: Epoch 019 - training loss: 0.3711, validation loss: 0.1802
2024-06-04 03:12:52 [INFO]: Epoch 020 - training loss: 0.3656, validation loss: 0.1804
2024-06-04 03:12:57 [INFO]: Epoch 021 - training loss: 0.3620, validation loss: 0.1760
2024-06-04 03:13:02 [INFO]: Epoch 022 - training loss: 0.3596, validation loss: 0.1767
2024-06-04 03:13:07 [INFO]: Epoch 023 - training loss: 0.3582, validation loss: 0.1723
2024-06-04 03:13:12 [INFO]: Epoch 024 - training loss: 0.3627, validation loss: 0.1670
2024-06-04 03:13:16 [INFO]: Epoch 025 - training loss: 0.3554, validation loss: 0.1721
2024-06-04 03:13:20 [INFO]: Epoch 026 - training loss: 0.3522, validation loss: 0.1649
2024-06-04 03:13:24 [INFO]: Epoch 027 - training loss: 0.3506, validation loss: 0.1647
2024-06-04 03:13:27 [INFO]: Epoch 028 - training loss: 0.3539, validation loss: 0.1639
2024-06-04 03:13:32 [INFO]: Epoch 029 - training loss: 0.3508, validation loss: 0.1602
2024-06-04 03:13:37 [INFO]: Epoch 030 - training loss: 0.3490, validation loss: 0.1590
2024-06-04 03:13:42 [INFO]: Epoch 031 - training loss: 0.3455, validation loss: 0.1571
2024-06-04 03:13:47 [INFO]: Epoch 032 - training loss: 0.3440, validation loss: 0.1552
2024-06-04 03:13:52 [INFO]: Epoch 033 - training loss: 0.3468, validation loss: 0.1612
2024-06-04 03:13:57 [INFO]: Epoch 034 - training loss: 0.3426, validation loss: 0.1571
2024-06-04 03:14:02 [INFO]: Epoch 035 - training loss: 0.3389, validation loss: 0.1541
2024-06-04 03:14:07 [INFO]: Epoch 036 - training loss: 0.3384, validation loss: 0.1523
2024-06-04 03:14:11 [INFO]: Epoch 037 - training loss: 0.3401, validation loss: 0.1558
2024-06-04 03:14:16 [INFO]: Epoch 038 - training loss: 0.3416, validation loss: 0.1579
2024-06-04 03:14:21 [INFO]: Epoch 039 - training loss: 0.3403, validation loss: 0.1510
2024-06-04 03:14:26 [INFO]: Epoch 040 - training loss: 0.3408, validation loss: 0.1520
2024-06-04 03:14:31 [INFO]: Epoch 041 - training loss: 0.3374, validation loss: 0.1518
2024-06-04 03:14:36 [INFO]: Epoch 042 - training loss: 0.3374, validation loss: 0.1496
2024-06-04 03:14:40 [INFO]: Epoch 043 - training loss: 0.3358, validation loss: 0.1497
2024-06-04 03:14:45 [INFO]: Epoch 044 - training loss: 0.3360, validation loss: 0.1523
2024-06-04 03:14:50 [INFO]: Epoch 045 - training loss: 0.3356, validation loss: 0.1474
2024-06-04 03:14:55 [INFO]: Epoch 046 - training loss: 0.3343, validation loss: 0.1446
2024-06-04 03:15:00 [INFO]: Epoch 047 - training loss: 0.3362, validation loss: 0.1512
2024-06-04 03:15:05 [INFO]: Epoch 048 - training loss: 0.3325, validation loss: 0.1484
2024-06-04 03:15:09 [INFO]: Epoch 049 - training loss: 0.3311, validation loss: 0.1431
2024-06-04 03:15:13 [INFO]: Epoch 050 - training loss: 0.3360, validation loss: 0.1465
2024-06-04 03:15:18 [INFO]: Epoch 051 - training loss: 0.3301, validation loss: 0.1494
2024-06-04 03:15:22 [INFO]: Epoch 052 - training loss: 0.3303, validation loss: 0.1449
2024-06-04 03:15:26 [INFO]: Epoch 053 - training loss: 0.3296, validation loss: 0.1459
2024-06-04 03:15:31 [INFO]: Epoch 054 - training loss: 0.3312, validation loss: 0.1459
2024-06-04 03:15:35 [INFO]: Epoch 055 - training loss: 0.3299, validation loss: 0.1435
2024-06-04 03:15:39 [INFO]: Epoch 056 - training loss: 0.3297, validation loss: 0.1445
2024-06-04 03:15:44 [INFO]: Epoch 057 - training loss: 0.3269, validation loss: 0.1463
2024-06-04 03:15:48 [INFO]: Epoch 058 - training loss: 0.3268, validation loss: 0.1449
2024-06-04 03:15:52 [INFO]: Epoch 059 - training loss: 0.3248, validation loss: 0.1496
2024-06-04 03:15:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:15:52 [INFO]: Finished training. The best model is from epoch#49.
2024-06-04 03:15:53 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_3/20240604_T031113/SCINet.pypots
2024-06-04 03:15:54 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_3/imputation.pkl
2024-06-04 03:15:54 [INFO]: Round3 - SCINet on BeijingAir: MAE=0.2363, MSE=0.1900, MRE=0.3571
2024-06-04 03:15:54 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:15:54 [INFO]: Using the given device: cuda:0
2024-06-04 03:15:54 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_4/20240604_T031554
2024-06-04 03:15:54 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_4/20240604_T031554/tensorboard
2024-06-04 03:15:55 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-04 03:15:59 [INFO]: Epoch 001 - training loss: 1.2781, validation loss: 0.5609
2024-06-04 03:16:04 [INFO]: Epoch 002 - training loss: 0.8597, validation loss: 0.3995
2024-06-04 03:16:08 [INFO]: Epoch 003 - training loss: 0.7234, validation loss: 0.3394
2024-06-04 03:16:12 [INFO]: Epoch 004 - training loss: 0.6405, validation loss: 0.3016
2024-06-04 03:16:17 [INFO]: Epoch 005 - training loss: 0.5831, validation loss: 0.2796
2024-06-04 03:16:21 [INFO]: Epoch 006 - training loss: 0.5473, validation loss: 0.2682
2024-06-04 03:16:25 [INFO]: Epoch 007 - training loss: 0.5122, validation loss: 0.2553
2024-06-04 03:16:29 [INFO]: Epoch 008 - training loss: 0.4884, validation loss: 0.2447
2024-06-04 03:16:34 [INFO]: Epoch 009 - training loss: 0.4715, validation loss: 0.2332
2024-06-04 03:16:38 [INFO]: Epoch 010 - training loss: 0.4576, validation loss: 0.2320
2024-06-04 03:16:42 [INFO]: Epoch 011 - training loss: 0.4381, validation loss: 0.2159
2024-06-04 03:16:46 [INFO]: Epoch 012 - training loss: 0.4237, validation loss: 0.2113
2024-06-04 03:16:50 [INFO]: Epoch 013 - training loss: 0.4142, validation loss: 0.2093
2024-06-04 03:16:55 [INFO]: Epoch 014 - training loss: 0.4072, validation loss: 0.2023
2024-06-04 03:16:59 [INFO]: Epoch 015 - training loss: 0.3967, validation loss: 0.2001
2024-06-04 03:17:03 [INFO]: Epoch 016 - training loss: 0.3880, validation loss: 0.1900
2024-06-04 03:17:07 [INFO]: Epoch 017 - training loss: 0.3831, validation loss: 0.1887
2024-06-04 03:17:12 [INFO]: Epoch 018 - training loss: 0.3809, validation loss: 0.1855
2024-06-04 03:17:16 [INFO]: Epoch 019 - training loss: 0.3762, validation loss: 0.1798
2024-06-04 03:17:20 [INFO]: Epoch 020 - training loss: 0.3712, validation loss: 0.1828
2024-06-04 03:17:24 [INFO]: Epoch 021 - training loss: 0.3704, validation loss: 0.1780
2024-06-04 03:17:28 [INFO]: Epoch 022 - training loss: 0.3728, validation loss: 0.1716
2024-06-04 03:17:33 [INFO]: Epoch 023 - training loss: 0.3594, validation loss: 0.1701
2024-06-04 03:17:37 [INFO]: Epoch 024 - training loss: 0.3577, validation loss: 0.1711
2024-06-04 03:17:41 [INFO]: Epoch 025 - training loss: 0.3552, validation loss: 0.1680
2024-06-04 03:17:45 [INFO]: Epoch 026 - training loss: 0.3518, validation loss: 0.1689
2024-06-04 03:17:49 [INFO]: Epoch 027 - training loss: 0.3506, validation loss: 0.1674
2024-06-04 03:17:54 [INFO]: Epoch 028 - training loss: 0.3503, validation loss: 0.1615
2024-06-04 03:17:58 [INFO]: Epoch 029 - training loss: 0.3476, validation loss: 0.1662
2024-06-04 03:18:02 [INFO]: Epoch 030 - training loss: 0.3535, validation loss: 0.1647
2024-06-04 03:18:06 [INFO]: Epoch 031 - training loss: 0.3459, validation loss: 0.1616
2024-06-04 03:18:10 [INFO]: Epoch 032 - training loss: 0.3461, validation loss: 0.1597
2024-06-04 03:18:14 [INFO]: Epoch 033 - training loss: 0.3409, validation loss: 0.1555
2024-06-04 03:18:19 [INFO]: Epoch 034 - training loss: 0.3422, validation loss: 0.1540
2024-06-04 03:18:23 [INFO]: Epoch 035 - training loss: 0.3434, validation loss: 0.1511
2024-06-04 03:18:28 [INFO]: Epoch 036 - training loss: 0.3426, validation loss: 0.1560
2024-06-04 03:18:32 [INFO]: Epoch 037 - training loss: 0.3392, validation loss: 0.1578
2024-06-04 03:18:36 [INFO]: Epoch 038 - training loss: 0.3386, validation loss: 0.1544
2024-06-04 03:18:40 [INFO]: Epoch 039 - training loss: 0.3382, validation loss: 0.1522
2024-06-04 03:18:44 [INFO]: Epoch 040 - training loss: 0.3409, validation loss: 0.1535
2024-06-04 03:18:48 [INFO]: Epoch 041 - training loss: 0.3349, validation loss: 0.1476
2024-06-04 03:18:53 [INFO]: Epoch 042 - training loss: 0.3345, validation loss: 0.1535
2024-06-04 03:18:57 [INFO]: Epoch 043 - training loss: 0.3354, validation loss: 0.1517
2024-06-04 03:19:01 [INFO]: Epoch 044 - training loss: 0.3336, validation loss: 0.1485
2024-06-04 03:19:06 [INFO]: Epoch 045 - training loss: 0.3347, validation loss: 0.1539
2024-06-04 03:19:10 [INFO]: Epoch 046 - training loss: 0.3367, validation loss: 0.1462
2024-06-04 03:19:14 [INFO]: Epoch 047 - training loss: 0.3342, validation loss: 0.1468
2024-06-04 03:19:19 [INFO]: Epoch 048 - training loss: 0.3364, validation loss: 0.1530
2024-06-04 03:19:23 [INFO]: Epoch 049 - training loss: 0.3332, validation loss: 0.1460
2024-06-04 03:19:27 [INFO]: Epoch 050 - training loss: 0.3335, validation loss: 0.1483
2024-06-04 03:19:31 [INFO]: Epoch 051 - training loss: 0.3320, validation loss: 0.1443
2024-06-04 03:19:36 [INFO]: Epoch 052 - training loss: 0.3301, validation loss: 0.1450
2024-06-04 03:19:40 [INFO]: Epoch 053 - training loss: 0.3284, validation loss: 0.1463
2024-06-04 03:19:44 [INFO]: Epoch 054 - training loss: 0.3287, validation loss: 0.1442
2024-06-04 03:19:48 [INFO]: Epoch 055 - training loss: 0.3280, validation loss: 0.1440
2024-06-04 03:19:53 [INFO]: Epoch 056 - training loss: 0.3300, validation loss: 0.1471
2024-06-04 03:19:57 [INFO]: Epoch 057 - training loss: 0.3277, validation loss: 0.1489
2024-06-04 03:20:01 [INFO]: Epoch 058 - training loss: 0.3267, validation loss: 0.1492
2024-06-04 03:20:06 [INFO]: Epoch 059 - training loss: 0.3301, validation loss: 0.1448
2024-06-04 03:20:10 [INFO]: Epoch 060 - training loss: 0.3272, validation loss: 0.1413
2024-06-04 03:20:14 [INFO]: Epoch 061 - training loss: 0.3283, validation loss: 0.1425
2024-06-04 03:20:18 [INFO]: Epoch 062 - training loss: 0.3269, validation loss: 0.1421
2024-06-04 03:20:23 [INFO]: Epoch 063 - training loss: 0.3258, validation loss: 0.1438
2024-06-04 03:20:27 [INFO]: Epoch 064 - training loss: 0.3262, validation loss: 0.1467
2024-06-04 03:20:31 [INFO]: Epoch 065 - training loss: 0.3256, validation loss: 0.1417
2024-06-04 03:20:35 [INFO]: Epoch 066 - training loss: 0.3278, validation loss: 0.1451
2024-06-04 03:20:40 [INFO]: Epoch 067 - training loss: 0.3233, validation loss: 0.1493
2024-06-04 03:20:44 [INFO]: Epoch 068 - training loss: 0.3252, validation loss: 0.1421
2024-06-04 03:20:48 [INFO]: Epoch 069 - training loss: 0.3250, validation loss: 0.1402
2024-06-04 03:20:52 [INFO]: Epoch 070 - training loss: 0.3241, validation loss: 0.1434
2024-06-04 03:20:57 [INFO]: Epoch 071 - training loss: 0.3261, validation loss: 0.1397
2024-06-04 03:21:01 [INFO]: Epoch 072 - training loss: 0.3271, validation loss: 0.1409
2024-06-04 03:21:05 [INFO]: Epoch 073 - training loss: 0.3227, validation loss: 0.1432
2024-06-04 03:21:09 [INFO]: Epoch 074 - training loss: 0.3210, validation loss: 0.1417
2024-06-04 03:21:13 [INFO]: Epoch 075 - training loss: 0.3216, validation loss: 0.1389
2024-06-04 03:21:18 [INFO]: Epoch 076 - training loss: 0.3238, validation loss: 0.1467
2024-06-04 03:21:22 [INFO]: Epoch 077 - training loss: 0.3245, validation loss: 0.1404
2024-06-04 03:21:26 [INFO]: Epoch 078 - training loss: 0.3204, validation loss: 0.1387
2024-06-04 03:21:30 [INFO]: Epoch 079 - training loss: 0.3202, validation loss: 0.1394
2024-06-04 03:21:35 [INFO]: Epoch 080 - training loss: 0.3179, validation loss: 0.1465
2024-06-04 03:21:39 [INFO]: Epoch 081 - training loss: 0.3221, validation loss: 0.1395
2024-06-04 03:21:43 [INFO]: Epoch 082 - training loss: 0.3205, validation loss: 0.1409
2024-06-04 03:21:47 [INFO]: Epoch 083 - training loss: 0.3219, validation loss: 0.1423
2024-06-04 03:21:51 [INFO]: Epoch 084 - training loss: 0.3196, validation loss: 0.1408
2024-06-04 03:21:56 [INFO]: Epoch 085 - training loss: 0.3170, validation loss: 0.1419
2024-06-04 03:22:00 [INFO]: Epoch 086 - training loss: 0.3162, validation loss: 0.1370
2024-06-04 03:22:05 [INFO]: Epoch 087 - training loss: 0.3165, validation loss: 0.1387
2024-06-04 03:22:09 [INFO]: Epoch 088 - training loss: 0.3182, validation loss: 0.1418
2024-06-04 03:22:13 [INFO]: Epoch 089 - training loss: 0.3188, validation loss: 0.1388
2024-06-04 03:22:18 [INFO]: Epoch 090 - training loss: 0.3177, validation loss: 0.1428
2024-06-04 03:22:22 [INFO]: Epoch 091 - training loss: 0.3185, validation loss: 0.1433
2024-06-04 03:22:26 [INFO]: Epoch 092 - training loss: 0.3157, validation loss: 0.1355
2024-06-04 03:22:31 [INFO]: Epoch 093 - training loss: 0.3195, validation loss: 0.1412
2024-06-04 03:22:35 [INFO]: Epoch 094 - training loss: 0.3168, validation loss: 0.1431
2024-06-04 03:22:39 [INFO]: Epoch 095 - training loss: 0.3182, validation loss: 0.1395
2024-06-04 03:22:43 [INFO]: Epoch 096 - training loss: 0.3226, validation loss: 0.1465
2024-06-04 03:22:48 [INFO]: Epoch 097 - training loss: 0.3185, validation loss: 0.1416
2024-06-04 03:22:52 [INFO]: Epoch 098 - training loss: 0.3129, validation loss: 0.1426
2024-06-04 03:22:56 [INFO]: Epoch 099 - training loss: 0.3136, validation loss: 0.1435
2024-06-04 03:23:01 [INFO]: Epoch 100 - training loss: 0.3126, validation loss: 0.1391
2024-06-04 03:23:01 [INFO]: Finished training. The best model is from epoch#92.
2024-06-04 03:23:01 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_4/20240604_T031554/SCINet.pypots
2024-06-04 03:23:03 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/SCINet_BeijingAir/round_4/imputation.pkl
2024-06-04 03:23:03 [INFO]: Round4 - SCINet on BeijingAir: MAE=0.2343, MSE=0.1894, MRE=0.3540
2024-06-04 03:23:03 [INFO]: Done! Final results:
Averaged SCINet (26,833,140 params) on BeijingAir: MAE=0.1907 ± 0.010968163188016978, MSE=0.1395 ± 0.0273871825565662, MRE=0.2536 ± 0.014588424769416738, average inference time=0.30