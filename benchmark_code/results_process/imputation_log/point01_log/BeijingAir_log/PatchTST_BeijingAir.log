2024-06-04 02:49:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:49:23 [INFO]: Using the given device: cuda:0
2024-06-04 02:49:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_0/20240604_T024924
2024-06-04 02:49:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_0/20240604_T024924/tensorboard
2024-06-04 02:49:24 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 02:49:24 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 02:49:26 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 30,342,300
2024-06-04 02:51:04 [INFO]: Epoch 001 - training loss: 1.1343, validation loss: 0.4420
2024-06-04 02:52:37 [INFO]: Epoch 002 - training loss: 0.6194, validation loss: 0.3039
2024-06-04 02:54:09 [INFO]: Epoch 003 - training loss: 0.5031, validation loss: 0.2784
2024-06-04 02:55:43 [INFO]: Epoch 004 - training loss: 0.4576, validation loss: 0.2426
2024-06-04 02:57:15 [INFO]: Epoch 005 - training loss: 0.4302, validation loss: 0.2467
2024-06-04 02:58:47 [INFO]: Epoch 006 - training loss: 0.4144, validation loss: 0.2236
2024-06-04 03:00:20 [INFO]: Epoch 007 - training loss: 0.3995, validation loss: 0.2049
2024-06-04 03:01:49 [INFO]: Epoch 008 - training loss: 0.3881, validation loss: 0.2063
2024-06-04 03:03:18 [INFO]: Epoch 009 - training loss: 0.3774, validation loss: 0.2002
2024-06-04 03:04:47 [INFO]: Epoch 010 - training loss: 0.3699, validation loss: 0.1889
2024-06-04 03:06:15 [INFO]: Epoch 011 - training loss: 0.3664, validation loss: 0.1727
2024-06-04 03:07:43 [INFO]: Epoch 012 - training loss: 0.3629, validation loss: 0.1644
2024-06-04 03:09:12 [INFO]: Epoch 013 - training loss: 0.3598, validation loss: 0.1757
2024-06-04 03:10:43 [INFO]: Epoch 014 - training loss: 0.3516, validation loss: 0.1764
2024-06-04 03:12:14 [INFO]: Epoch 015 - training loss: 0.3475, validation loss: 0.1688
2024-06-04 03:13:43 [INFO]: Epoch 016 - training loss: 0.3524, validation loss: 0.1532
2024-06-04 03:15:15 [INFO]: Epoch 017 - training loss: 0.3479, validation loss: 0.1646
2024-06-04 03:16:46 [INFO]: Epoch 018 - training loss: 0.3438, validation loss: 0.1516
2024-06-04 03:18:17 [INFO]: Epoch 019 - training loss: 0.3408, validation loss: 0.1566
2024-06-04 03:19:47 [INFO]: Epoch 020 - training loss: 0.3435, validation loss: 0.1473
2024-06-04 03:21:18 [INFO]: Epoch 021 - training loss: 0.3382, validation loss: 0.1543
2024-06-04 03:22:49 [INFO]: Epoch 022 - training loss: 0.3368, validation loss: 0.1579
2024-06-04 03:24:20 [INFO]: Epoch 023 - training loss: 0.3346, validation loss: 0.1451
2024-06-04 03:25:50 [INFO]: Epoch 024 - training loss: 0.3351, validation loss: 0.1553
2024-06-04 03:27:12 [INFO]: Epoch 025 - training loss: 0.3332, validation loss: 0.1468
2024-06-04 03:28:34 [INFO]: Epoch 026 - training loss: 0.3325, validation loss: 0.1533
2024-06-04 03:29:57 [INFO]: Epoch 027 - training loss: 0.3335, validation loss: 0.1411
2024-06-04 03:31:19 [INFO]: Epoch 028 - training loss: 0.3327, validation loss: 0.1485
2024-06-04 03:32:28 [INFO]: Epoch 029 - training loss: 0.3307, validation loss: 0.1403
2024-06-04 03:33:27 [INFO]: Epoch 030 - training loss: 0.3330, validation loss: 0.1523
2024-06-04 03:34:25 [INFO]: Epoch 031 - training loss: 0.3320, validation loss: 0.1522
2024-06-04 03:35:24 [INFO]: Epoch 032 - training loss: 0.3313, validation loss: 0.1529
2024-06-04 03:36:22 [INFO]: Epoch 033 - training loss: 0.3302, validation loss: 0.1535
2024-06-04 03:37:21 [INFO]: Epoch 034 - training loss: 0.3313, validation loss: 0.1325
2024-06-04 03:38:19 [INFO]: Epoch 035 - training loss: 0.3328, validation loss: 0.1385
2024-06-04 03:39:15 [INFO]: Epoch 036 - training loss: 0.3279, validation loss: 0.1340
2024-06-04 03:40:10 [INFO]: Epoch 037 - training loss: 0.3303, validation loss: 0.1305
2024-06-04 03:41:05 [INFO]: Epoch 038 - training loss: 0.3290, validation loss: 0.1358
2024-06-04 03:42:01 [INFO]: Epoch 039 - training loss: 0.3310, validation loss: 0.1375
2024-06-04 03:42:56 [INFO]: Epoch 040 - training loss: 0.3269, validation loss: 0.1390
2024-06-04 03:43:51 [INFO]: Epoch 041 - training loss: 0.3273, validation loss: 0.1394
2024-06-04 03:44:47 [INFO]: Epoch 042 - training loss: 0.3291, validation loss: 0.1415
2024-06-04 03:45:42 [INFO]: Epoch 043 - training loss: 0.3281, validation loss: 0.1343
2024-06-04 03:46:37 [INFO]: Epoch 044 - training loss: 0.3263, validation loss: 0.1321
2024-06-04 03:47:33 [INFO]: Epoch 045 - training loss: 0.3280, validation loss: 0.1312
2024-06-04 03:48:28 [INFO]: Epoch 046 - training loss: 0.3261, validation loss: 0.1395
2024-06-04 03:49:23 [INFO]: Epoch 047 - training loss: 0.3288, validation loss: 0.1330
2024-06-04 03:49:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:49:23 [INFO]: Finished training. The best model is from epoch#37.
2024-06-04 03:49:23 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_0/20240604_T024924/PatchTST.pypots
2024-06-04 03:49:49 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_0/imputation.pkl
2024-06-04 03:49:49 [INFO]: Round0 - PatchTST on BeijingAir: MAE=0.2353, MSE=0.1865, MRE=0.3556
2024-06-04 03:49:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:49:49 [INFO]: Using the given device: cuda:0
2024-06-04 03:49:49 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_1/20240604_T034949
2024-06-04 03:49:49 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_1/20240604_T034949/tensorboard
2024-06-04 03:49:49 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 03:49:49 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 03:49:49 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 30,342,300
2024-06-04 03:50:45 [INFO]: Epoch 001 - training loss: 1.0375, validation loss: 0.3827
2024-06-04 03:51:40 [INFO]: Epoch 002 - training loss: 0.6065, validation loss: 0.3056
2024-06-04 03:52:35 [INFO]: Epoch 003 - training loss: 0.5036, validation loss: 0.2881
2024-06-04 03:53:31 [INFO]: Epoch 004 - training loss: 0.4570, validation loss: 0.2375
2024-06-04 03:54:26 [INFO]: Epoch 005 - training loss: 0.4316, validation loss: 0.2381
2024-06-04 03:55:21 [INFO]: Epoch 006 - training loss: 0.4146, validation loss: 0.2390
2024-06-04 03:56:17 [INFO]: Epoch 007 - training loss: 0.4006, validation loss: 0.2169
2024-06-04 03:57:12 [INFO]: Epoch 008 - training loss: 0.3890, validation loss: 0.1971
2024-06-04 03:58:07 [INFO]: Epoch 009 - training loss: 0.3787, validation loss: 0.1899
2024-06-04 03:58:56 [INFO]: Epoch 010 - training loss: 0.3710, validation loss: 0.1840
2024-06-04 03:59:43 [INFO]: Epoch 011 - training loss: 0.3671, validation loss: 0.1931
2024-06-04 04:00:29 [INFO]: Epoch 012 - training loss: 0.3597, validation loss: 0.1684
2024-06-04 04:01:16 [INFO]: Epoch 013 - training loss: 0.3574, validation loss: 0.1784
2024-06-04 04:02:02 [INFO]: Epoch 014 - training loss: 0.3513, validation loss: 0.1701
2024-06-04 04:02:49 [INFO]: Epoch 015 - training loss: 0.3484, validation loss: 0.1583
2024-06-04 04:03:35 [INFO]: Epoch 016 - training loss: 0.3476, validation loss: 0.1610
2024-06-04 04:04:21 [INFO]: Epoch 017 - training loss: 0.3440, validation loss: 0.1728
2024-06-04 04:05:08 [INFO]: Epoch 018 - training loss: 0.3436, validation loss: 0.1760
2024-06-04 04:05:54 [INFO]: Epoch 019 - training loss: 0.3441, validation loss: 0.1615
2024-06-04 04:06:41 [INFO]: Epoch 020 - training loss: 0.3399, validation loss: 0.1507
2024-06-04 04:07:27 [INFO]: Epoch 021 - training loss: 0.3384, validation loss: 0.1580
2024-06-04 04:08:14 [INFO]: Epoch 022 - training loss: 0.3364, validation loss: 0.1514
2024-06-04 04:09:00 [INFO]: Epoch 023 - training loss: 0.3345, validation loss: 0.1544
2024-06-04 04:09:46 [INFO]: Epoch 024 - training loss: 0.3346, validation loss: 0.1427
2024-06-04 04:10:33 [INFO]: Epoch 025 - training loss: 0.3339, validation loss: 0.1514
2024-06-04 04:11:19 [INFO]: Epoch 026 - training loss: 0.3367, validation loss: 0.1548
2024-06-04 04:12:06 [INFO]: Epoch 027 - training loss: 0.3358, validation loss: 0.1432
2024-06-04 04:12:52 [INFO]: Epoch 028 - training loss: 0.3329, validation loss: 0.1441
2024-06-04 04:13:39 [INFO]: Epoch 029 - training loss: 0.3315, validation loss: 0.1468
2024-06-04 04:14:25 [INFO]: Epoch 030 - training loss: 0.3334, validation loss: 0.1433
2024-06-04 04:15:12 [INFO]: Epoch 031 - training loss: 0.3307, validation loss: 0.1557
2024-06-04 04:15:58 [INFO]: Epoch 032 - training loss: 0.3310, validation loss: 0.1376
2024-06-04 04:16:45 [INFO]: Epoch 033 - training loss: 0.3294, validation loss: 0.1421
2024-06-04 04:17:31 [INFO]: Epoch 034 - training loss: 0.3296, validation loss: 0.1430
2024-06-04 04:18:17 [INFO]: Epoch 035 - training loss: 0.3280, validation loss: 0.1405
2024-06-04 04:19:04 [INFO]: Epoch 036 - training loss: 0.3267, validation loss: 0.1456
2024-06-04 04:19:50 [INFO]: Epoch 037 - training loss: 0.3297, validation loss: 0.1453
2024-06-04 04:20:37 [INFO]: Epoch 038 - training loss: 0.3307, validation loss: 0.1319
2024-06-04 04:21:23 [INFO]: Epoch 039 - training loss: 0.3332, validation loss: 0.1334
2024-06-04 04:22:10 [INFO]: Epoch 040 - training loss: 0.3279, validation loss: 0.1410
2024-06-04 04:22:56 [INFO]: Epoch 041 - training loss: 0.3280, validation loss: 0.1344
2024-06-04 04:23:42 [INFO]: Epoch 042 - training loss: 0.3259, validation loss: 0.1388
2024-06-04 04:24:29 [INFO]: Epoch 043 - training loss: 0.3259, validation loss: 0.1406
2024-06-04 04:25:15 [INFO]: Epoch 044 - training loss: 0.3278, validation loss: 0.1310
2024-06-04 04:26:02 [INFO]: Epoch 045 - training loss: 0.3279, validation loss: 0.1380
2024-06-04 04:26:48 [INFO]: Epoch 046 - training loss: 0.3264, validation loss: 0.1419
2024-06-04 04:27:35 [INFO]: Epoch 047 - training loss: 0.3246, validation loss: 0.1388
2024-06-04 04:28:21 [INFO]: Epoch 048 - training loss: 0.3244, validation loss: 0.1376
2024-06-04 04:29:07 [INFO]: Epoch 049 - training loss: 0.3247, validation loss: 0.1346
2024-06-04 04:29:54 [INFO]: Epoch 050 - training loss: 0.3239, validation loss: 0.1346
2024-06-04 04:30:40 [INFO]: Epoch 051 - training loss: 0.3252, validation loss: 0.1314
2024-06-04 04:31:27 [INFO]: Epoch 052 - training loss: 0.3241, validation loss: 0.1301
2024-06-04 04:32:13 [INFO]: Epoch 053 - training loss: 0.3239, validation loss: 0.1301
2024-06-04 04:32:59 [INFO]: Epoch 054 - training loss: 0.3233, validation loss: 0.1335
2024-06-04 04:33:46 [INFO]: Epoch 055 - training loss: 0.3254, validation loss: 0.1258
2024-06-04 04:34:32 [INFO]: Epoch 056 - training loss: 0.3248, validation loss: 0.1262
2024-06-04 04:35:19 [INFO]: Epoch 057 - training loss: 0.3243, validation loss: 0.1315
2024-06-04 04:36:05 [INFO]: Epoch 058 - training loss: 0.3237, validation loss: 0.1311
2024-06-04 04:36:51 [INFO]: Epoch 059 - training loss: 0.3239, validation loss: 0.1328
2024-06-04 04:37:38 [INFO]: Epoch 060 - training loss: 0.3230, validation loss: 0.1304
2024-06-04 04:38:24 [INFO]: Epoch 061 - training loss: 0.3215, validation loss: 0.1233
2024-06-04 04:39:11 [INFO]: Epoch 062 - training loss: 0.3229, validation loss: 0.1311
2024-06-04 04:39:57 [INFO]: Epoch 063 - training loss: 0.3223, validation loss: 0.1260
2024-06-04 04:40:44 [INFO]: Epoch 064 - training loss: 0.3205, validation loss: 0.1248
2024-06-04 04:41:30 [INFO]: Epoch 065 - training loss: 0.3235, validation loss: 0.1296
2024-06-04 04:42:16 [INFO]: Epoch 066 - training loss: 0.3204, validation loss: 0.1223
2024-06-04 04:43:03 [INFO]: Epoch 067 - training loss: 0.3212, validation loss: 0.1221
2024-06-04 04:43:49 [INFO]: Epoch 068 - training loss: 0.3198, validation loss: 0.1233
2024-06-04 04:44:36 [INFO]: Epoch 069 - training loss: 0.3200, validation loss: 0.1217
2024-06-04 04:45:22 [INFO]: Epoch 070 - training loss: 0.3209, validation loss: 0.1227
2024-06-04 04:46:09 [INFO]: Epoch 071 - training loss: 0.3192, validation loss: 0.1250
2024-06-04 04:46:55 [INFO]: Epoch 072 - training loss: 0.3193, validation loss: 0.1208
2024-06-04 04:47:41 [INFO]: Epoch 073 - training loss: 0.3203, validation loss: 0.1162
2024-06-04 04:48:28 [INFO]: Epoch 074 - training loss: 0.3190, validation loss: 0.1187
2024-06-04 04:49:14 [INFO]: Epoch 075 - training loss: 0.3183, validation loss: 0.1187
2024-06-04 04:50:01 [INFO]: Epoch 076 - training loss: 0.3187, validation loss: 0.1207
2024-06-04 04:50:47 [INFO]: Epoch 077 - training loss: 0.3199, validation loss: 0.1150
2024-06-04 04:51:34 [INFO]: Epoch 078 - training loss: 0.3191, validation loss: 0.1174
2024-06-04 04:52:20 [INFO]: Epoch 079 - training loss: 0.3170, validation loss: 0.1173
2024-06-04 04:53:06 [INFO]: Epoch 080 - training loss: 0.3177, validation loss: 0.1144
2024-06-04 04:53:53 [INFO]: Epoch 081 - training loss: 0.3169, validation loss: 0.1167
2024-06-04 04:54:39 [INFO]: Epoch 082 - training loss: 0.3161, validation loss: 0.1140
2024-06-04 04:55:26 [INFO]: Epoch 083 - training loss: 0.3158, validation loss: 0.1120
2024-06-04 04:56:12 [INFO]: Epoch 084 - training loss: 0.3167, validation loss: 0.1155
2024-06-04 04:56:59 [INFO]: Epoch 085 - training loss: 0.3150, validation loss: 0.1129
2024-06-04 04:57:45 [INFO]: Epoch 086 - training loss: 0.3155, validation loss: 0.1161
2024-06-04 04:58:31 [INFO]: Epoch 087 - training loss: 0.3159, validation loss: 0.1180
2024-06-04 04:59:18 [INFO]: Epoch 088 - training loss: 0.3150, validation loss: 0.1128
2024-06-04 05:00:04 [INFO]: Epoch 089 - training loss: 0.3142, validation loss: 0.1111
2024-06-04 05:00:51 [INFO]: Epoch 090 - training loss: 0.3150, validation loss: 0.1116
2024-06-04 05:01:37 [INFO]: Epoch 091 - training loss: 0.3137, validation loss: 0.1130
2024-06-04 05:02:24 [INFO]: Epoch 092 - training loss: 0.3132, validation loss: 0.1095
2024-06-04 05:03:10 [INFO]: Epoch 093 - training loss: 0.3124, validation loss: 0.1092
2024-06-04 05:03:56 [INFO]: Epoch 094 - training loss: 0.3146, validation loss: 0.1080
2024-06-04 05:04:43 [INFO]: Epoch 095 - training loss: 0.3130, validation loss: 0.1101
2024-06-04 05:05:29 [INFO]: Epoch 096 - training loss: 0.3119, validation loss: 0.1077
2024-06-04 05:06:16 [INFO]: Epoch 097 - training loss: 0.3132, validation loss: 0.1105
2024-06-04 05:07:02 [INFO]: Epoch 098 - training loss: 0.3112, validation loss: 0.1150
2024-06-04 05:07:49 [INFO]: Epoch 099 - training loss: 0.3117, validation loss: 0.1085
2024-06-04 05:08:35 [INFO]: Epoch 100 - training loss: 0.3112, validation loss: 0.1098
2024-06-04 05:08:35 [INFO]: Finished training. The best model is from epoch#96.
2024-06-04 05:08:35 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_1/20240604_T034949/PatchTST.pypots
2024-06-04 05:08:57 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_1/imputation.pkl
2024-06-04 05:08:57 [INFO]: Round1 - PatchTST on BeijingAir: MAE=0.2240, MSE=0.1812, MRE=0.3385
2024-06-04 05:08:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 05:08:57 [INFO]: Using the given device: cuda:0
2024-06-04 05:08:57 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_2/20240604_T050857
2024-06-04 05:08:57 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_2/20240604_T050857/tensorboard
2024-06-04 05:08:57 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 05:08:57 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 05:08:57 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 30,342,300
2024-06-04 05:09:44 [INFO]: Epoch 001 - training loss: 1.0740, validation loss: 0.4152
2024-06-04 05:10:30 [INFO]: Epoch 002 - training loss: 0.6208, validation loss: 0.3139
2024-06-04 05:11:17 [INFO]: Epoch 003 - training loss: 0.5080, validation loss: 0.2897
2024-06-04 05:12:03 [INFO]: Epoch 004 - training loss: 0.4599, validation loss: 0.2462
2024-06-04 05:12:50 [INFO]: Epoch 005 - training loss: 0.4313, validation loss: 0.2261
2024-06-04 05:13:36 [INFO]: Epoch 006 - training loss: 0.4141, validation loss: 0.2116
2024-06-04 05:14:23 [INFO]: Epoch 007 - training loss: 0.4033, validation loss: 0.2112
2024-06-04 05:15:09 [INFO]: Epoch 008 - training loss: 0.3909, validation loss: 0.2026
2024-06-04 05:15:55 [INFO]: Epoch 009 - training loss: 0.3795, validation loss: 0.2026
2024-06-04 05:16:42 [INFO]: Epoch 010 - training loss: 0.3736, validation loss: 0.2052
2024-06-04 05:17:28 [INFO]: Epoch 011 - training loss: 0.3670, validation loss: 0.1766
2024-06-04 05:18:15 [INFO]: Epoch 012 - training loss: 0.3615, validation loss: 0.1821
2024-06-04 05:19:01 [INFO]: Epoch 013 - training loss: 0.3553, validation loss: 0.1850
2024-06-04 05:19:48 [INFO]: Epoch 014 - training loss: 0.3526, validation loss: 0.1845
2024-06-04 05:20:34 [INFO]: Epoch 015 - training loss: 0.3537, validation loss: 0.1719
2024-06-04 05:21:21 [INFO]: Epoch 016 - training loss: 0.3479, validation loss: 0.1605
2024-06-04 05:22:07 [INFO]: Epoch 017 - training loss: 0.3428, validation loss: 0.1553
2024-06-04 05:22:54 [INFO]: Epoch 018 - training loss: 0.3444, validation loss: 0.1597
2024-06-04 05:23:40 [INFO]: Epoch 019 - training loss: 0.3402, validation loss: 0.1474
2024-06-04 05:24:26 [INFO]: Epoch 020 - training loss: 0.3398, validation loss: 0.1507
2024-06-04 05:25:13 [INFO]: Epoch 021 - training loss: 0.3397, validation loss: 0.1464
2024-06-04 05:25:59 [INFO]: Epoch 022 - training loss: 0.3363, validation loss: 0.1454
2024-06-04 05:26:46 [INFO]: Epoch 023 - training loss: 0.3377, validation loss: 0.1675
2024-06-04 05:27:32 [INFO]: Epoch 024 - training loss: 0.3380, validation loss: 0.1500
2024-06-04 05:28:19 [INFO]: Epoch 025 - training loss: 0.3352, validation loss: 0.1489
2024-06-04 05:29:05 [INFO]: Epoch 026 - training loss: 0.3336, validation loss: 0.1538
2024-06-04 05:29:52 [INFO]: Epoch 027 - training loss: 0.3339, validation loss: 0.1539
2024-06-04 05:30:38 [INFO]: Epoch 028 - training loss: 0.3338, validation loss: 0.1403
2024-06-04 05:31:25 [INFO]: Epoch 029 - training loss: 0.3333, validation loss: 0.1379
2024-06-04 05:32:11 [INFO]: Epoch 030 - training loss: 0.3310, validation loss: 0.1369
2024-06-04 05:32:58 [INFO]: Epoch 031 - training loss: 0.3324, validation loss: 0.1418
2024-06-04 05:33:44 [INFO]: Epoch 032 - training loss: 0.3296, validation loss: 0.1458
2024-06-04 05:34:31 [INFO]: Epoch 033 - training loss: 0.3288, validation loss: 0.1459
2024-06-04 05:35:17 [INFO]: Epoch 034 - training loss: 0.3297, validation loss: 0.1357
2024-06-04 05:36:04 [INFO]: Epoch 035 - training loss: 0.3295, validation loss: 0.1316
2024-06-04 05:36:50 [INFO]: Epoch 036 - training loss: 0.3291, validation loss: 0.1376
2024-06-04 05:37:37 [INFO]: Epoch 037 - training loss: 0.3281, validation loss: 0.1357
2024-06-04 05:38:23 [INFO]: Epoch 038 - training loss: 0.3283, validation loss: 0.1322
2024-06-04 05:39:09 [INFO]: Epoch 039 - training loss: 0.3301, validation loss: 0.1429
2024-06-04 05:39:56 [INFO]: Epoch 040 - training loss: 0.3280, validation loss: 0.1369
2024-06-04 05:40:42 [INFO]: Epoch 041 - training loss: 0.3284, validation loss: 0.1312
2024-06-04 05:41:29 [INFO]: Epoch 042 - training loss: 0.3292, validation loss: 0.1401
2024-06-04 05:42:15 [INFO]: Epoch 043 - training loss: 0.3288, validation loss: 0.1368
2024-06-04 05:43:02 [INFO]: Epoch 044 - training loss: 0.3262, validation loss: 0.1342
2024-06-04 05:43:48 [INFO]: Epoch 045 - training loss: 0.3260, validation loss: 0.1311
2024-06-04 05:44:35 [INFO]: Epoch 046 - training loss: 0.3254, validation loss: 0.1362
2024-06-04 05:45:21 [INFO]: Epoch 047 - training loss: 0.3243, validation loss: 0.1292
2024-06-04 05:46:08 [INFO]: Epoch 048 - training loss: 0.3287, validation loss: 0.1349
2024-06-04 05:46:54 [INFO]: Epoch 049 - training loss: 0.3251, validation loss: 0.1323
2024-06-04 05:47:41 [INFO]: Epoch 050 - training loss: 0.3256, validation loss: 0.1314
2024-06-04 05:48:27 [INFO]: Epoch 051 - training loss: 0.3245, validation loss: 0.1359
2024-06-04 05:49:13 [INFO]: Epoch 052 - training loss: 0.3239, validation loss: 0.1342
2024-06-04 05:50:00 [INFO]: Epoch 053 - training loss: 0.3262, validation loss: 0.1389
2024-06-04 05:50:46 [INFO]: Epoch 054 - training loss: 0.3254, validation loss: 0.1327
2024-06-04 05:51:33 [INFO]: Epoch 055 - training loss: 0.3243, validation loss: 0.1269
2024-06-04 05:52:19 [INFO]: Epoch 056 - training loss: 0.3236, validation loss: 0.1316
2024-06-04 05:53:06 [INFO]: Epoch 057 - training loss: 0.3215, validation loss: 0.1297
2024-06-04 05:53:52 [INFO]: Epoch 058 - training loss: 0.3227, validation loss: 0.1320
2024-06-04 05:54:39 [INFO]: Epoch 059 - training loss: 0.3234, validation loss: 0.1286
2024-06-04 05:55:25 [INFO]: Epoch 060 - training loss: 0.3205, validation loss: 0.1308
2024-06-04 05:56:11 [INFO]: Epoch 061 - training loss: 0.3221, validation loss: 0.1297
2024-06-04 05:56:58 [INFO]: Epoch 062 - training loss: 0.3216, validation loss: 0.1285
2024-06-04 05:57:44 [INFO]: Epoch 063 - training loss: 0.3220, validation loss: 0.1297
2024-06-04 05:58:31 [INFO]: Epoch 064 - training loss: 0.3222, validation loss: 0.1300
2024-06-04 05:59:17 [INFO]: Epoch 065 - training loss: 0.3204, validation loss: 0.1307
2024-06-04 05:59:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 05:59:17 [INFO]: Finished training. The best model is from epoch#55.
2024-06-04 05:59:17 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_2/20240604_T050857/PatchTST.pypots
2024-06-04 05:59:39 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_2/imputation.pkl
2024-06-04 05:59:39 [INFO]: Round2 - PatchTST on BeijingAir: MAE=0.2462, MSE=0.1980, MRE=0.3719
2024-06-04 05:59:39 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 05:59:39 [INFO]: Using the given device: cuda:0
2024-06-04 05:59:39 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_3/20240604_T055939
2024-06-04 05:59:39 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_3/20240604_T055939/tensorboard
2024-06-04 05:59:39 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 05:59:39 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 05:59:39 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 30,342,300
2024-06-04 06:00:26 [INFO]: Epoch 001 - training loss: 1.0544, validation loss: 0.4188
2024-06-04 06:01:12 [INFO]: Epoch 002 - training loss: 0.6076, validation loss: 0.3035
2024-06-04 06:01:58 [INFO]: Epoch 003 - training loss: 0.5006, validation loss: 0.2556
2024-06-04 06:02:45 [INFO]: Epoch 004 - training loss: 0.4546, validation loss: 0.2377
2024-06-04 06:03:31 [INFO]: Epoch 005 - training loss: 0.4286, validation loss: 0.2477
2024-06-04 06:04:18 [INFO]: Epoch 006 - training loss: 0.4124, validation loss: 0.2362
2024-06-04 06:05:04 [INFO]: Epoch 007 - training loss: 0.3964, validation loss: 0.2042
2024-06-04 06:05:51 [INFO]: Epoch 008 - training loss: 0.3849, validation loss: 0.2083
2024-06-04 06:06:37 [INFO]: Epoch 009 - training loss: 0.3767, validation loss: 0.1884
2024-06-04 06:07:23 [INFO]: Epoch 010 - training loss: 0.3681, validation loss: 0.1844
2024-06-04 06:08:10 [INFO]: Epoch 011 - training loss: 0.3636, validation loss: 0.1969
2024-06-04 06:08:56 [INFO]: Epoch 012 - training loss: 0.3572, validation loss: 0.1730
2024-06-04 06:09:43 [INFO]: Epoch 013 - training loss: 0.3520, validation loss: 0.1670
2024-06-04 06:10:29 [INFO]: Epoch 014 - training loss: 0.3481, validation loss: 0.1687
2024-06-04 06:11:16 [INFO]: Epoch 015 - training loss: 0.3460, validation loss: 0.1812
2024-06-04 06:12:02 [INFO]: Epoch 016 - training loss: 0.3504, validation loss: 0.1692
2024-06-04 06:12:48 [INFO]: Epoch 017 - training loss: 0.3462, validation loss: 0.1571
2024-06-04 06:13:35 [INFO]: Epoch 018 - training loss: 0.3424, validation loss: 0.1561
2024-06-04 06:14:21 [INFO]: Epoch 019 - training loss: 0.3430, validation loss: 0.1512
2024-06-04 06:15:08 [INFO]: Epoch 020 - training loss: 0.3381, validation loss: 0.1527
2024-06-04 06:15:54 [INFO]: Epoch 021 - training loss: 0.3371, validation loss: 0.1513
2024-06-04 06:16:41 [INFO]: Epoch 022 - training loss: 0.3356, validation loss: 0.1461
2024-06-04 06:17:27 [INFO]: Epoch 023 - training loss: 0.3347, validation loss: 0.1537
2024-06-04 06:18:13 [INFO]: Epoch 024 - training loss: 0.3346, validation loss: 0.1401
2024-06-04 06:19:00 [INFO]: Epoch 025 - training loss: 0.3334, validation loss: 0.1529
2024-06-04 06:19:46 [INFO]: Epoch 026 - training loss: 0.3329, validation loss: 0.1355
2024-06-04 06:20:33 [INFO]: Epoch 027 - training loss: 0.3328, validation loss: 0.1535
2024-06-04 06:21:19 [INFO]: Epoch 028 - training loss: 0.3322, validation loss: 0.1429
2024-06-04 06:22:05 [INFO]: Epoch 029 - training loss: 0.3319, validation loss: 0.1474
2024-06-04 06:22:52 [INFO]: Epoch 030 - training loss: 0.3339, validation loss: 0.1370
2024-06-04 06:23:38 [INFO]: Epoch 031 - training loss: 0.3311, validation loss: 0.1417
2024-06-04 06:24:25 [INFO]: Epoch 032 - training loss: 0.3298, validation loss: 0.1478
2024-06-04 06:25:11 [INFO]: Epoch 033 - training loss: 0.3307, validation loss: 0.1422
2024-06-04 06:25:58 [INFO]: Epoch 034 - training loss: 0.3296, validation loss: 0.1410
2024-06-04 06:26:44 [INFO]: Epoch 035 - training loss: 0.3307, validation loss: 0.1532
2024-06-04 06:27:30 [INFO]: Epoch 036 - training loss: 0.3293, validation loss: 0.1382
2024-06-04 06:27:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 06:27:30 [INFO]: Finished training. The best model is from epoch#26.
2024-06-04 06:27:31 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_3/20240604_T055939/PatchTST.pypots
2024-06-04 06:27:52 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_3/imputation.pkl
2024-06-04 06:27:52 [INFO]: Round3 - PatchTST on BeijingAir: MAE=0.2433, MSE=0.1902, MRE=0.3677
2024-06-04 06:27:52 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 06:27:52 [INFO]: Using the given device: cuda:0
2024-06-04 06:27:52 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_4/20240604_T062752
2024-06-04 06:27:52 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_4/20240604_T062752/tensorboard
2024-06-04 06:27:52 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 06:27:52 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 06:27:52 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 30,342,300
2024-06-04 06:28:39 [INFO]: Epoch 001 - training loss: 1.2227, validation loss: 0.4397
2024-06-04 06:29:25 [INFO]: Epoch 002 - training loss: 0.6469, validation loss: 0.3063
2024-06-04 06:30:12 [INFO]: Epoch 003 - training loss: 0.5158, validation loss: 0.2737
2024-06-04 06:30:58 [INFO]: Epoch 004 - training loss: 0.4689, validation loss: 0.2299
2024-06-04 06:31:45 [INFO]: Epoch 005 - training loss: 0.4379, validation loss: 0.2347
2024-06-04 06:32:31 [INFO]: Epoch 006 - training loss: 0.4160, validation loss: 0.2150
2024-06-04 06:33:17 [INFO]: Epoch 007 - training loss: 0.4015, validation loss: 0.2127
2024-06-04 06:34:04 [INFO]: Epoch 008 - training loss: 0.3899, validation loss: 0.2103
2024-06-04 06:34:50 [INFO]: Epoch 009 - training loss: 0.3821, validation loss: 0.1800
2024-06-04 06:35:37 [INFO]: Epoch 010 - training loss: 0.3754, validation loss: 0.1875
2024-06-04 06:36:23 [INFO]: Epoch 011 - training loss: 0.3658, validation loss: 0.1768
2024-06-04 06:37:09 [INFO]: Epoch 012 - training loss: 0.3600, validation loss: 0.1777
2024-06-04 06:37:56 [INFO]: Epoch 013 - training loss: 0.3546, validation loss: 0.1840
2024-06-04 06:38:42 [INFO]: Epoch 014 - training loss: 0.3514, validation loss: 0.1625
2024-06-04 06:39:29 [INFO]: Epoch 015 - training loss: 0.3488, validation loss: 0.1668
2024-06-04 06:40:15 [INFO]: Epoch 016 - training loss: 0.3452, validation loss: 0.1611
2024-06-04 06:41:01 [INFO]: Epoch 017 - training loss: 0.3456, validation loss: 0.1487
2024-06-04 06:41:48 [INFO]: Epoch 018 - training loss: 0.3448, validation loss: 0.1567
2024-06-04 06:42:34 [INFO]: Epoch 019 - training loss: 0.3414, validation loss: 0.1523
2024-06-04 06:43:21 [INFO]: Epoch 020 - training loss: 0.3385, validation loss: 0.1508
2024-06-04 06:44:07 [INFO]: Epoch 021 - training loss: 0.3376, validation loss: 0.1456
2024-06-04 06:44:53 [INFO]: Epoch 022 - training loss: 0.3388, validation loss: 0.1452
2024-06-04 06:45:40 [INFO]: Epoch 023 - training loss: 0.3379, validation loss: 0.1508
2024-06-04 06:46:26 [INFO]: Epoch 024 - training loss: 0.3351, validation loss: 0.1447
2024-06-04 06:47:13 [INFO]: Epoch 025 - training loss: 0.3335, validation loss: 0.1418
2024-06-04 06:47:59 [INFO]: Epoch 026 - training loss: 0.3343, validation loss: 0.1441
2024-06-04 06:48:46 [INFO]: Epoch 027 - training loss: 0.3323, validation loss: 0.1377
2024-06-04 06:49:32 [INFO]: Epoch 028 - training loss: 0.3319, validation loss: 0.1515
2024-06-04 06:50:18 [INFO]: Epoch 029 - training loss: 0.3366, validation loss: 0.1433
2024-06-04 06:51:05 [INFO]: Epoch 030 - training loss: 0.3319, validation loss: 0.1388
2024-06-04 06:51:51 [INFO]: Epoch 031 - training loss: 0.3297, validation loss: 0.1421
2024-06-04 06:52:38 [INFO]: Epoch 032 - training loss: 0.3299, validation loss: 0.1381
2024-06-04 06:53:24 [INFO]: Epoch 033 - training loss: 0.3286, validation loss: 0.1366
2024-06-04 06:54:11 [INFO]: Epoch 034 - training loss: 0.3311, validation loss: 0.1430
2024-06-04 06:54:57 [INFO]: Epoch 035 - training loss: 0.3313, validation loss: 0.1387
2024-06-04 06:55:43 [INFO]: Epoch 036 - training loss: 0.3321, validation loss: 0.1419
2024-06-04 06:56:30 [INFO]: Epoch 037 - training loss: 0.3313, validation loss: 0.1345
2024-06-04 06:57:16 [INFO]: Epoch 038 - training loss: 0.3285, validation loss: 0.1327
2024-06-04 06:58:03 [INFO]: Epoch 039 - training loss: 0.3302, validation loss: 0.1412
2024-06-04 06:58:49 [INFO]: Epoch 040 - training loss: 0.3281, validation loss: 0.1356
2024-06-04 06:59:36 [INFO]: Epoch 041 - training loss: 0.3258, validation loss: 0.1370
2024-06-04 07:00:22 [INFO]: Epoch 042 - training loss: 0.3258, validation loss: 0.1368
2024-06-04 07:01:08 [INFO]: Epoch 043 - training loss: 0.3266, validation loss: 0.1383
2024-06-04 07:01:55 [INFO]: Epoch 044 - training loss: 0.3266, validation loss: 0.1369
2024-06-04 07:02:41 [INFO]: Epoch 045 - training loss: 0.3259, validation loss: 0.1346
2024-06-04 07:03:28 [INFO]: Epoch 046 - training loss: 0.3256, validation loss: 0.1473
2024-06-04 07:04:14 [INFO]: Epoch 047 - training loss: 0.3252, validation loss: 0.1337
2024-06-04 07:05:01 [INFO]: Epoch 048 - training loss: 0.3262, validation loss: 0.1414
2024-06-04 07:05:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 07:05:01 [INFO]: Finished training. The best model is from epoch#38.
2024-06-04 07:05:01 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_4/20240604_T062752/PatchTST.pypots
2024-06-04 07:05:22 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/PatchTST_BeijingAir/round_4/imputation.pkl
2024-06-04 07:05:22 [INFO]: Round4 - PatchTST on BeijingAir: MAE=0.2575, MSE=0.2026, MRE=0.3891
2024-06-04 07:05:22 [INFO]: Done! Final results:
Averaged PatchTST (30,342,300 params) on BeijingAir: MAE=0.1982 ± 0.011159872179257745, MSE=0.1307 ± 0.005020062235115143, MRE=0.2636 ± 0.014843411146661033, average inference time=4.67