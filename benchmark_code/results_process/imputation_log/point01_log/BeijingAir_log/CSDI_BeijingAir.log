2024-06-04 02:44:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:45 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_0/20240604_T024445/tensorboard
/scratch/users/k1814348/.conda/envs/pypots/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2024-06-04 02:44:45 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-04 02:46:12 [INFO]: Epoch 001 - training loss: 0.5290, validation loss: 0.3566
2024-06-04 02:47:32 [INFO]: Epoch 002 - training loss: 0.3447, validation loss: 0.3347
2024-06-04 02:48:53 [INFO]: Epoch 003 - training loss: 0.2899, validation loss: 0.3008
2024-06-04 02:50:13 [INFO]: Epoch 004 - training loss: 0.2956, validation loss: 0.2627
2024-06-04 02:51:33 [INFO]: Epoch 005 - training loss: 0.2457, validation loss: 0.2144
2024-06-04 02:52:54 [INFO]: Epoch 006 - training loss: 0.2387, validation loss: 0.2171
2024-06-04 02:54:14 [INFO]: Epoch 007 - training loss: 0.2151, validation loss: 0.1783
2024-06-04 02:55:34 [INFO]: Epoch 008 - training loss: 0.2119, validation loss: 0.1837
2024-06-04 02:56:54 [INFO]: Epoch 009 - training loss: 0.1983, validation loss: 0.1536
2024-06-04 02:58:14 [INFO]: Epoch 010 - training loss: 0.2054, validation loss: 0.1494
2024-06-04 02:59:35 [INFO]: Epoch 011 - training loss: 0.1959, validation loss: 0.1488
2024-06-04 03:00:56 [INFO]: Epoch 012 - training loss: 0.1834, validation loss: 0.1453
2024-06-04 03:02:14 [INFO]: Epoch 013 - training loss: 0.1907, validation loss: 0.1385
2024-06-04 03:03:26 [INFO]: Epoch 014 - training loss: 0.1859, validation loss: 0.1326
2024-06-04 03:04:37 [INFO]: Epoch 015 - training loss: 0.1736, validation loss: 0.1354
2024-06-04 03:05:49 [INFO]: Epoch 016 - training loss: 0.1664, validation loss: 0.1392
2024-06-04 03:07:01 [INFO]: Epoch 017 - training loss: 0.1787, validation loss: 0.1353
2024-06-04 03:08:13 [INFO]: Epoch 018 - training loss: 0.1842, validation loss: 0.1273
2024-06-04 03:09:25 [INFO]: Epoch 019 - training loss: 0.1856, validation loss: 0.1287
2024-06-04 03:10:36 [INFO]: Epoch 020 - training loss: 0.1626, validation loss: 0.1284
2024-06-04 03:11:48 [INFO]: Epoch 021 - training loss: 0.1706, validation loss: 0.1271
2024-06-04 03:13:00 [INFO]: Epoch 022 - training loss: 0.1544, validation loss: 0.1253
2024-06-04 03:14:12 [INFO]: Epoch 023 - training loss: 0.1652, validation loss: 0.1249
2024-06-04 03:15:24 [INFO]: Epoch 024 - training loss: 0.1641, validation loss: 0.1293
2024-06-04 03:16:36 [INFO]: Epoch 025 - training loss: 0.1724, validation loss: 0.1283
2024-06-04 03:17:49 [INFO]: Epoch 026 - training loss: 0.1580, validation loss: 0.1240
2024-06-04 03:19:01 [INFO]: Epoch 027 - training loss: 0.1729, validation loss: 0.1245
2024-06-04 03:20:12 [INFO]: Epoch 028 - training loss: 0.1802, validation loss: 0.1219
2024-06-04 03:21:25 [INFO]: Epoch 029 - training loss: 0.1628, validation loss: 0.1218
2024-06-04 03:22:37 [INFO]: Epoch 030 - training loss: 0.1625, validation loss: 0.1205
2024-06-04 03:23:49 [INFO]: Epoch 031 - training loss: 0.1695, validation loss: 0.1174
2024-06-04 03:25:01 [INFO]: Epoch 032 - training loss: 0.1583, validation loss: 0.1194
2024-06-04 03:26:13 [INFO]: Epoch 033 - training loss: 0.1500, validation loss: 0.1156
2024-06-04 03:27:26 [INFO]: Epoch 034 - training loss: 0.1574, validation loss: 0.1149
2024-06-04 03:28:38 [INFO]: Epoch 035 - training loss: 0.1465, validation loss: 0.1221
2024-06-04 03:29:48 [INFO]: Epoch 036 - training loss: 0.1540, validation loss: 0.1177
2024-06-04 03:30:57 [INFO]: Epoch 037 - training loss: 0.1497, validation loss: 0.1108
2024-06-04 03:32:06 [INFO]: Epoch 038 - training loss: 0.1559, validation loss: 0.1104
2024-06-04 03:33:15 [INFO]: Epoch 039 - training loss: 0.1472, validation loss: 0.1121
2024-06-04 03:34:24 [INFO]: Epoch 040 - training loss: 0.1385, validation loss: 0.1108
2024-06-04 03:35:32 [INFO]: Epoch 041 - training loss: 0.1405, validation loss: 0.1087
2024-06-04 03:36:41 [INFO]: Epoch 042 - training loss: 0.1481, validation loss: 0.1060
2024-06-04 03:37:50 [INFO]: Epoch 043 - training loss: 0.1524, validation loss: 0.1059
2024-06-04 03:38:59 [INFO]: Epoch 044 - training loss: 0.1319, validation loss: 0.1088
2024-06-04 03:40:08 [INFO]: Epoch 045 - training loss: 0.1557, validation loss: 0.1058
2024-06-04 03:41:18 [INFO]: Epoch 046 - training loss: 0.1558, validation loss: 0.1051
2024-06-04 03:42:27 [INFO]: Epoch 047 - training loss: 0.1487, validation loss: 0.1033
2024-06-04 03:43:36 [INFO]: Epoch 048 - training loss: 0.1517, validation loss: 0.1130
2024-06-04 03:44:45 [INFO]: Epoch 049 - training loss: 0.1442, validation loss: 0.1033
2024-06-04 03:45:54 [INFO]: Epoch 050 - training loss: 0.1507, validation loss: 0.1080
2024-06-04 03:47:03 [INFO]: Epoch 051 - training loss: 0.1374, validation loss: 0.1015
2024-06-04 03:48:11 [INFO]: Epoch 052 - training loss: 0.1473, validation loss: 0.1018
2024-06-04 03:49:20 [INFO]: Epoch 053 - training loss: 0.1357, validation loss: 0.1015
2024-06-04 03:50:29 [INFO]: Epoch 054 - training loss: 0.1452, validation loss: 0.1019
2024-06-04 03:51:37 [INFO]: Epoch 055 - training loss: 0.1315, validation loss: 0.1017
2024-06-04 03:52:47 [INFO]: Epoch 056 - training loss: 0.1440, validation loss: 0.1008
2024-06-04 03:53:55 [INFO]: Epoch 057 - training loss: 0.1425, validation loss: 0.1017
2024-06-04 03:55:04 [INFO]: Epoch 058 - training loss: 0.1262, validation loss: 0.0996
2024-06-04 03:56:12 [INFO]: Epoch 059 - training loss: 0.1349, validation loss: 0.0995
2024-06-04 03:57:22 [INFO]: Epoch 060 - training loss: 0.1495, validation loss: 0.1008
2024-06-04 03:58:30 [INFO]: Epoch 061 - training loss: 0.1392, validation loss: 0.1024
2024-06-04 03:59:39 [INFO]: Epoch 062 - training loss: 0.1345, validation loss: 0.0989
2024-06-04 04:00:48 [INFO]: Epoch 063 - training loss: 0.1505, validation loss: 0.0976
2024-06-04 04:01:57 [INFO]: Epoch 064 - training loss: 0.1442, validation loss: 0.1031
2024-06-04 04:03:05 [INFO]: Epoch 065 - training loss: 0.1350, validation loss: 0.0999
2024-06-04 04:04:14 [INFO]: Epoch 066 - training loss: 0.1140, validation loss: 0.0947
2024-06-04 04:05:23 [INFO]: Epoch 067 - training loss: 0.1351, validation loss: 0.0960
2024-06-04 04:06:32 [INFO]: Epoch 068 - training loss: 0.1294, validation loss: 0.0967
2024-06-04 04:07:41 [INFO]: Epoch 069 - training loss: 0.1386, validation loss: 0.0948
2024-06-04 04:08:49 [INFO]: Epoch 070 - training loss: 0.1388, validation loss: 0.0939
2024-06-04 04:09:58 [INFO]: Epoch 071 - training loss: 0.1341, validation loss: 0.0959
2024-06-04 04:11:07 [INFO]: Epoch 072 - training loss: 0.1379, validation loss: 0.0952
2024-06-04 04:12:16 [INFO]: Epoch 073 - training loss: 0.1348, validation loss: 0.0973
2024-06-04 04:13:25 [INFO]: Epoch 074 - training loss: 0.1266, validation loss: 0.0933
2024-06-04 04:14:34 [INFO]: Epoch 075 - training loss: 0.1322, validation loss: 0.0974
2024-06-04 04:15:43 [INFO]: Epoch 076 - training loss: 0.1438, validation loss: 0.0951
2024-06-04 04:16:52 [INFO]: Epoch 077 - training loss: 0.1368, validation loss: 0.0953
2024-06-04 04:17:56 [INFO]: Epoch 078 - training loss: 0.1325, validation loss: 0.0927
2024-06-04 04:19:00 [INFO]: Epoch 079 - training loss: 0.1326, validation loss: 0.0966
2024-06-04 04:20:04 [INFO]: Epoch 080 - training loss: 0.1269, validation loss: 0.0949
2024-06-04 04:21:09 [INFO]: Epoch 081 - training loss: 0.1122, validation loss: 0.0957
2024-06-04 04:22:13 [INFO]: Epoch 082 - training loss: 0.1103, validation loss: 0.0911
2024-06-04 04:23:17 [INFO]: Epoch 083 - training loss: 0.1386, validation loss: 0.0941
2024-06-04 04:24:22 [INFO]: Epoch 084 - training loss: 0.1367, validation loss: 0.0969
2024-06-04 04:25:26 [INFO]: Epoch 085 - training loss: 0.1223, validation loss: 0.0977
2024-06-04 04:26:30 [INFO]: Epoch 086 - training loss: 0.1317, validation loss: 0.0916
2024-06-04 04:27:34 [INFO]: Epoch 087 - training loss: 0.1261, validation loss: 0.0921
2024-06-04 04:28:38 [INFO]: Epoch 088 - training loss: 0.1263, validation loss: 0.0940
2024-06-04 04:29:42 [INFO]: Epoch 089 - training loss: 0.1293, validation loss: 0.0894
2024-06-04 04:30:45 [INFO]: Epoch 090 - training loss: 0.1222, validation loss: 0.0904
2024-06-04 04:31:49 [INFO]: Epoch 091 - training loss: 0.1360, validation loss: 0.0897
2024-06-04 04:32:53 [INFO]: Epoch 092 - training loss: 0.1222, validation loss: 0.0912
2024-06-04 04:33:57 [INFO]: Epoch 093 - training loss: 0.1197, validation loss: 0.0987
2024-06-04 04:35:01 [INFO]: Epoch 094 - training loss: 0.1251, validation loss: 0.0924
2024-06-04 04:36:05 [INFO]: Epoch 095 - training loss: 0.1207, validation loss: 0.0896
2024-06-04 04:37:09 [INFO]: Epoch 096 - training loss: 0.1158, validation loss: 0.0912
2024-06-04 04:38:13 [INFO]: Epoch 097 - training loss: 0.1215, validation loss: 0.0888
2024-06-04 04:39:17 [INFO]: Epoch 098 - training loss: 0.1228, validation loss: 0.0935
2024-06-04 04:40:21 [INFO]: Epoch 099 - training loss: 0.1287, validation loss: 0.0892
2024-06-04 04:41:25 [INFO]: Epoch 100 - training loss: 0.1192, validation loss: 0.0915
2024-06-04 04:41:25 [INFO]: Finished training. The best model is from epoch#97.
2024-06-04 04:41:25 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_0/20240604_T024445/CSDI.pypots
2024-06-04 05:22:54 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_0/imputation.pkl
2024-06-04 05:22:54 [INFO]: Round0 - CSDI on BeijingAir: MAE=0.2033, MSE=1.1499, MRE=0.3071
2024-06-04 05:22:54 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 05:22:54 [INFO]: Using the given device: cuda:0
2024-06-04 05:22:54 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_1/20240604_T052254
2024-06-04 05:22:54 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_1/20240604_T052254/tensorboard
/scratch/users/k1814348/.conda/envs/pypots/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2024-06-04 05:22:54 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-04 05:23:58 [INFO]: Epoch 001 - training loss: 0.5063, validation loss: 0.3639
2024-06-04 05:25:03 [INFO]: Epoch 002 - training loss: 0.3345, validation loss: 0.3241
2024-06-04 05:26:07 [INFO]: Epoch 003 - training loss: 0.3136, validation loss: 0.2902
2024-06-04 05:27:11 [INFO]: Epoch 004 - training loss: 0.2776, validation loss: 0.2362
2024-06-04 05:28:16 [INFO]: Epoch 005 - training loss: 0.2465, validation loss: 0.2222
2024-06-04 05:29:20 [INFO]: Epoch 006 - training loss: 0.2255, validation loss: 0.1986
2024-06-04 05:30:25 [INFO]: Epoch 007 - training loss: 0.2242, validation loss: 0.1777
2024-06-04 05:31:29 [INFO]: Epoch 008 - training loss: 0.2000, validation loss: 0.1564
2024-06-04 05:32:33 [INFO]: Epoch 009 - training loss: 0.1957, validation loss: 0.1629
2024-06-04 05:33:37 [INFO]: Epoch 010 - training loss: 0.1897, validation loss: 0.1483
2024-06-04 05:34:41 [INFO]: Epoch 011 - training loss: 0.1953, validation loss: 0.1461
2024-06-04 05:35:46 [INFO]: Epoch 012 - training loss: 0.1707, validation loss: 0.1447
2024-06-04 05:36:50 [INFO]: Epoch 013 - training loss: 0.1726, validation loss: 0.1480
2024-06-04 05:37:54 [INFO]: Epoch 014 - training loss: 0.1873, validation loss: 0.1382
2024-06-04 05:38:58 [INFO]: Epoch 015 - training loss: 0.1776, validation loss: 0.1357
2024-06-04 05:40:02 [INFO]: Epoch 016 - training loss: 0.1700, validation loss: 0.1340
2024-06-04 05:41:06 [INFO]: Epoch 017 - training loss: 0.1730, validation loss: 0.1299
2024-06-04 05:42:10 [INFO]: Epoch 018 - training loss: 0.1658, validation loss: 0.1318
2024-06-04 05:43:14 [INFO]: Epoch 019 - training loss: 0.1676, validation loss: 0.1299
2024-06-04 05:44:18 [INFO]: Epoch 020 - training loss: 0.1715, validation loss: 0.1406
2024-06-04 05:45:22 [INFO]: Epoch 021 - training loss: 0.1767, validation loss: 0.1268
2024-06-04 05:46:26 [INFO]: Epoch 022 - training loss: 0.1726, validation loss: 0.1260
2024-06-04 05:47:30 [INFO]: Epoch 023 - training loss: 0.1545, validation loss: 0.1222
2024-06-04 05:48:34 [INFO]: Epoch 024 - training loss: 0.1479, validation loss: 0.1285
2024-06-04 05:49:39 [INFO]: Epoch 025 - training loss: 0.1550, validation loss: 0.1227
2024-06-04 05:50:43 [INFO]: Epoch 026 - training loss: 0.1626, validation loss: 0.1247
2024-06-04 05:51:47 [INFO]: Epoch 027 - training loss: 0.1569, validation loss: 0.1241
2024-06-04 05:52:51 [INFO]: Epoch 028 - training loss: 0.1419, validation loss: 0.1190
2024-06-04 05:53:55 [INFO]: Epoch 029 - training loss: 0.1582, validation loss: 0.1184
2024-06-04 05:54:59 [INFO]: Epoch 030 - training loss: 0.1796, validation loss: 0.1315
2024-06-04 05:56:03 [INFO]: Epoch 031 - training loss: 0.1715, validation loss: 0.1269
2024-06-04 05:57:07 [INFO]: Epoch 032 - training loss: 0.1557, validation loss: 0.1171
2024-06-04 05:58:11 [INFO]: Epoch 033 - training loss: 0.1570, validation loss: 0.1144
2024-06-04 05:59:15 [INFO]: Epoch 034 - training loss: 0.1458, validation loss: 0.1147
2024-06-04 06:00:19 [INFO]: Epoch 035 - training loss: 0.1424, validation loss: 0.1129
2024-06-04 06:01:23 [INFO]: Epoch 036 - training loss: 0.1637, validation loss: 0.1131
2024-06-04 06:02:27 [INFO]: Epoch 037 - training loss: 0.1466, validation loss: 0.1144
2024-06-04 06:03:31 [INFO]: Epoch 038 - training loss: 0.1459, validation loss: 0.1146
2024-06-04 06:04:35 [INFO]: Epoch 039 - training loss: 0.1558, validation loss: 0.1131
2024-06-04 06:05:39 [INFO]: Epoch 040 - training loss: 0.1414, validation loss: 0.1101
2024-06-04 06:06:44 [INFO]: Epoch 041 - training loss: 0.1575, validation loss: 0.1200
2024-06-04 06:07:48 [INFO]: Epoch 042 - training loss: 0.1536, validation loss: 0.1071
2024-06-04 06:08:51 [INFO]: Epoch 043 - training loss: 0.1451, validation loss: 0.1074
2024-06-04 06:09:55 [INFO]: Epoch 044 - training loss: 0.1526, validation loss: 0.1073
2024-06-04 06:10:59 [INFO]: Epoch 045 - training loss: 0.1304, validation loss: 0.1085
2024-06-04 06:12:04 [INFO]: Epoch 046 - training loss: 0.1271, validation loss: 0.1073
2024-06-04 06:13:07 [INFO]: Epoch 047 - training loss: 0.1382, validation loss: 0.1114
2024-06-04 06:14:12 [INFO]: Epoch 048 - training loss: 0.1490, validation loss: 0.1098
2024-06-04 06:15:16 [INFO]: Epoch 049 - training loss: 0.1377, validation loss: 0.1069
2024-06-04 06:16:20 [INFO]: Epoch 050 - training loss: 0.1372, validation loss: 0.1052
2024-06-04 06:17:24 [INFO]: Epoch 051 - training loss: 0.1349, validation loss: 0.1106
2024-06-04 06:18:29 [INFO]: Epoch 052 - training loss: 0.1429, validation loss: 0.1086
2024-06-04 06:19:33 [INFO]: Epoch 053 - training loss: 0.1341, validation loss: 0.1114
2024-06-04 06:20:37 [INFO]: Epoch 054 - training loss: 0.1361, validation loss: 0.1052
2024-06-04 06:21:41 [INFO]: Epoch 055 - training loss: 0.1417, validation loss: 0.1037
2024-06-04 06:22:45 [INFO]: Epoch 056 - training loss: 0.1316, validation loss: 0.1017
2024-06-04 06:23:49 [INFO]: Epoch 057 - training loss: 0.1478, validation loss: 0.1052
2024-06-04 06:24:53 [INFO]: Epoch 058 - training loss: 0.1397, validation loss: 0.1028
2024-06-04 06:25:57 [INFO]: Epoch 059 - training loss: 0.1498, validation loss: 0.1015
2024-06-04 06:27:01 [INFO]: Epoch 060 - training loss: 0.1400, validation loss: 0.1032
2024-06-04 06:28:05 [INFO]: Epoch 061 - training loss: 0.1410, validation loss: 0.1048
2024-06-04 06:29:09 [INFO]: Epoch 062 - training loss: 0.1388, validation loss: 0.1048
2024-06-04 06:30:13 [INFO]: Epoch 063 - training loss: 0.1464, validation loss: 0.1020
2024-06-04 06:31:17 [INFO]: Epoch 064 - training loss: 0.1465, validation loss: 0.0994
2024-06-04 06:32:21 [INFO]: Epoch 065 - training loss: 0.1448, validation loss: 0.1023
2024-06-04 06:33:25 [INFO]: Epoch 066 - training loss: 0.1472, validation loss: 0.1007
2024-06-04 06:34:29 [INFO]: Epoch 067 - training loss: 0.1377, validation loss: 0.0999
2024-06-04 06:35:33 [INFO]: Epoch 068 - training loss: 0.1292, validation loss: 0.0991
2024-06-04 06:36:37 [INFO]: Epoch 069 - training loss: 0.1453, validation loss: 0.0978
2024-06-04 06:37:41 [INFO]: Epoch 070 - training loss: 0.1310, validation loss: 0.0961
2024-06-04 06:38:46 [INFO]: Epoch 071 - training loss: 0.1426, validation loss: 0.0962
2024-06-04 06:39:50 [INFO]: Epoch 072 - training loss: 0.1253, validation loss: 0.0952
2024-06-04 06:40:54 [INFO]: Epoch 073 - training loss: 0.1435, validation loss: 0.1004
2024-06-04 06:41:58 [INFO]: Epoch 074 - training loss: 0.1425, validation loss: 0.0999
2024-06-04 06:43:03 [INFO]: Epoch 075 - training loss: 0.1408, validation loss: 0.0957
2024-06-04 06:44:07 [INFO]: Epoch 076 - training loss: 0.1353, validation loss: 0.0977
2024-06-04 06:45:11 [INFO]: Epoch 077 - training loss: 0.1279, validation loss: 0.1072
2024-06-04 06:46:16 [INFO]: Epoch 078 - training loss: 0.1482, validation loss: 0.0991
2024-06-04 06:47:20 [INFO]: Epoch 079 - training loss: 0.1485, validation loss: 0.1074
2024-06-04 06:48:24 [INFO]: Epoch 080 - training loss: 0.1477, validation loss: 0.0971
2024-06-04 06:49:28 [INFO]: Epoch 081 - training loss: 0.1438, validation loss: 0.0972
2024-06-04 06:50:31 [INFO]: Epoch 082 - training loss: 0.1304, validation loss: 0.0950
2024-06-04 06:51:35 [INFO]: Epoch 083 - training loss: 0.1319, validation loss: 0.0941
2024-06-04 06:52:40 [INFO]: Epoch 084 - training loss: 0.1307, validation loss: 0.0944
2024-06-04 06:53:44 [INFO]: Epoch 085 - training loss: 0.1407, validation loss: 0.0930
2024-06-04 06:54:48 [INFO]: Epoch 086 - training loss: 0.1263, validation loss: 0.0962
2024-06-04 06:55:51 [INFO]: Epoch 087 - training loss: 0.1348, validation loss: 0.0947
2024-06-04 06:56:55 [INFO]: Epoch 088 - training loss: 0.1381, validation loss: 0.0973
2024-06-04 06:57:59 [INFO]: Epoch 089 - training loss: 0.1396, validation loss: 0.0966
2024-06-04 06:59:03 [INFO]: Epoch 090 - training loss: 0.1427, validation loss: 0.1024
2024-06-04 07:00:07 [INFO]: Epoch 091 - training loss: 0.1315, validation loss: 0.0935
2024-06-04 07:01:12 [INFO]: Epoch 092 - training loss: 0.1291, validation loss: 0.0941
2024-06-04 07:02:16 [INFO]: Epoch 093 - training loss: 0.1322, validation loss: 0.0921
2024-06-04 07:03:20 [INFO]: Epoch 094 - training loss: 0.1346, validation loss: 0.0936
2024-06-04 07:04:24 [INFO]: Epoch 095 - training loss: 0.1298, validation loss: 0.0929
2024-06-04 07:05:28 [INFO]: Epoch 096 - training loss: 0.1329, validation loss: 0.0912
2024-06-04 07:06:31 [INFO]: Epoch 097 - training loss: 0.1409, validation loss: 0.0941
2024-06-04 07:07:36 [INFO]: Epoch 098 - training loss: 0.1264, validation loss: 0.0941
2024-06-04 07:08:40 [INFO]: Epoch 099 - training loss: 0.1453, validation loss: 0.0919
2024-06-04 07:09:44 [INFO]: Epoch 100 - training loss: 0.1256, validation loss: 0.0896
2024-06-04 07:09:44 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 07:09:44 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_1/20240604_T052254/CSDI.pypots
2024-06-04 07:51:14 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_1/imputation.pkl
2024-06-04 07:51:14 [INFO]: Round1 - CSDI on BeijingAir: MAE=0.1702, MSE=0.4427, MRE=0.2572
2024-06-04 07:51:14 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 07:51:14 [INFO]: Using the given device: cuda:0
2024-06-04 07:51:14 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_2/20240604_T075114
2024-06-04 07:51:14 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_2/20240604_T075114/tensorboard
2024-06-04 07:51:14 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-04 07:52:19 [INFO]: Epoch 001 - training loss: 0.5009, validation loss: 0.3564
2024-06-04 07:53:24 [INFO]: Epoch 002 - training loss: 0.3304, validation loss: 0.3225
2024-06-04 07:54:28 [INFO]: Epoch 003 - training loss: 0.3045, validation loss: 0.3035
2024-06-04 07:55:32 [INFO]: Epoch 004 - training loss: 0.2591, validation loss: 0.2695
2024-06-04 07:56:36 [INFO]: Epoch 005 - training loss: 0.2629, validation loss: 0.2251
2024-06-04 07:57:41 [INFO]: Epoch 006 - training loss: 0.2647, validation loss: 0.2244
2024-06-04 07:58:45 [INFO]: Epoch 007 - training loss: 0.2081, validation loss: 0.1990
2024-06-04 07:59:49 [INFO]: Epoch 008 - training loss: 0.2175, validation loss: 0.1744
2024-06-04 08:00:53 [INFO]: Epoch 009 - training loss: 0.2014, validation loss: 0.1628
2024-06-04 08:01:57 [INFO]: Epoch 010 - training loss: 0.2030, validation loss: 0.1593
2024-06-04 08:03:01 [INFO]: Epoch 011 - training loss: 0.1944, validation loss: 0.1504
2024-06-04 08:04:05 [INFO]: Epoch 012 - training loss: 0.1787, validation loss: 0.1449
2024-06-04 08:05:09 [INFO]: Epoch 013 - training loss: 0.1813, validation loss: 0.1440
2024-06-04 08:06:13 [INFO]: Epoch 014 - training loss: 0.1798, validation loss: 0.1427
2024-06-04 08:07:17 [INFO]: Epoch 015 - training loss: 0.1769, validation loss: 0.1375
2024-06-04 08:08:21 [INFO]: Epoch 016 - training loss: 0.1845, validation loss: 0.1326
2024-06-04 08:09:25 [INFO]: Epoch 017 - training loss: 0.1780, validation loss: 0.1324
2024-06-04 08:10:29 [INFO]: Epoch 018 - training loss: 0.1845, validation loss: 0.1353
2024-06-04 08:11:33 [INFO]: Epoch 019 - training loss: 0.1703, validation loss: 0.1301
2024-06-04 08:12:37 [INFO]: Epoch 020 - training loss: 0.1683, validation loss: 0.1281
2024-06-04 08:13:41 [INFO]: Epoch 021 - training loss: 0.1831, validation loss: 0.1317
2024-06-04 08:14:46 [INFO]: Epoch 022 - training loss: 0.1634, validation loss: 0.1293
2024-06-04 08:15:50 [INFO]: Epoch 023 - training loss: 0.1734, validation loss: 0.1273
2024-06-04 08:16:54 [INFO]: Epoch 024 - training loss: 0.1765, validation loss: 0.1334
2024-06-04 08:17:57 [INFO]: Epoch 025 - training loss: 0.1813, validation loss: 0.1265
2024-06-04 08:19:02 [INFO]: Epoch 026 - training loss: 0.1658, validation loss: 0.1217
2024-06-04 08:20:05 [INFO]: Epoch 027 - training loss: 0.1572, validation loss: 0.1240
2024-06-04 08:21:09 [INFO]: Epoch 028 - training loss: 0.1560, validation loss: 0.1231
2024-06-04 08:22:13 [INFO]: Epoch 029 - training loss: 0.1668, validation loss: 0.1217
2024-06-04 08:23:17 [INFO]: Epoch 030 - training loss: 0.1643, validation loss: 0.1204
2024-06-04 08:24:21 [INFO]: Epoch 031 - training loss: 0.1765, validation loss: 0.1209
2024-06-04 08:25:25 [INFO]: Epoch 032 - training loss: 0.1629, validation loss: 0.1192
2024-06-04 08:26:30 [INFO]: Epoch 033 - training loss: 0.1647, validation loss: 0.1178
2024-06-04 08:27:34 [INFO]: Epoch 034 - training loss: 0.1614, validation loss: 0.1160
2024-06-04 08:28:39 [INFO]: Epoch 035 - training loss: 0.1566, validation loss: 0.1278
2024-06-04 08:29:43 [INFO]: Epoch 036 - training loss: 0.1458, validation loss: 0.1157
2024-06-04 08:30:48 [INFO]: Epoch 037 - training loss: 0.1550, validation loss: 0.1126
2024-06-04 08:31:51 [INFO]: Epoch 038 - training loss: 0.1363, validation loss: 0.1126
2024-06-04 08:32:56 [INFO]: Epoch 039 - training loss: 0.1603, validation loss: 0.1178
2024-06-04 08:34:00 [INFO]: Epoch 040 - training loss: 0.1406, validation loss: 0.1105
2024-06-04 08:35:04 [INFO]: Epoch 041 - training loss: 0.1614, validation loss: 0.1205
2024-06-04 08:36:08 [INFO]: Epoch 042 - training loss: 0.1573, validation loss: 0.1139
2024-06-04 08:37:12 [INFO]: Epoch 043 - training loss: 0.1414, validation loss: 0.1117
2024-06-04 08:38:16 [INFO]: Epoch 044 - training loss: 0.1360, validation loss: 0.1136
2024-06-04 08:39:20 [INFO]: Epoch 045 - training loss: 0.1589, validation loss: 0.1166
2024-06-04 08:40:24 [INFO]: Epoch 046 - training loss: 0.1604, validation loss: 0.1076
2024-06-04 08:41:28 [INFO]: Epoch 047 - training loss: 0.1405, validation loss: 0.1112
2024-06-04 08:42:32 [INFO]: Epoch 048 - training loss: 0.1321, validation loss: 0.1067
2024-06-04 08:43:36 [INFO]: Epoch 049 - training loss: 0.1401, validation loss: 0.1078
2024-06-04 08:44:40 [INFO]: Epoch 050 - training loss: 0.1722, validation loss: 0.1128
2024-06-04 08:45:45 [INFO]: Epoch 051 - training loss: 0.1435, validation loss: 0.1077
2024-06-04 08:46:50 [INFO]: Epoch 052 - training loss: 0.1505, validation loss: 0.1082
2024-06-04 08:47:54 [INFO]: Epoch 053 - training loss: 0.1377, validation loss: 0.1076
2024-06-04 08:48:58 [INFO]: Epoch 054 - training loss: 0.1461, validation loss: 0.1058
2024-06-04 08:50:02 [INFO]: Epoch 055 - training loss: 0.1513, validation loss: 0.1103
2024-06-04 08:51:06 [INFO]: Epoch 056 - training loss: 0.1561, validation loss: 0.1093
2024-06-04 08:52:10 [INFO]: Epoch 057 - training loss: 0.1339, validation loss: 0.1057
2024-06-04 08:53:14 [INFO]: Epoch 058 - training loss: 0.1613, validation loss: 0.1057
2024-06-04 08:54:19 [INFO]: Epoch 059 - training loss: 0.1400, validation loss: 0.1025
2024-06-04 08:55:23 [INFO]: Epoch 060 - training loss: 0.1443, validation loss: 0.1014
2024-06-04 08:56:27 [INFO]: Epoch 061 - training loss: 0.1172, validation loss: 0.1011
2024-06-04 08:57:31 [INFO]: Epoch 062 - training loss: 0.1282, validation loss: 0.1039
2024-06-04 08:58:36 [INFO]: Epoch 063 - training loss: 0.1352, validation loss: 0.1072
2024-06-04 08:59:40 [INFO]: Epoch 064 - training loss: 0.1312, validation loss: 0.1016
2024-06-04 09:00:44 [INFO]: Epoch 065 - training loss: 0.1266, validation loss: 0.1023
2024-06-04 09:01:48 [INFO]: Epoch 066 - training loss: 0.1425, validation loss: 0.1004
2024-06-04 09:02:53 [INFO]: Epoch 067 - training loss: 0.1308, validation loss: 0.0990
2024-06-04 09:03:57 [INFO]: Epoch 068 - training loss: 0.1303, validation loss: 0.1022
2024-06-04 09:05:01 [INFO]: Epoch 069 - training loss: 0.1621, validation loss: 0.1072
2024-06-04 09:06:05 [INFO]: Epoch 070 - training loss: 0.1252, validation loss: 0.1029
2024-06-04 09:07:09 [INFO]: Epoch 071 - training loss: 0.1372, validation loss: 0.1006
2024-06-04 09:08:13 [INFO]: Epoch 072 - training loss: 0.1174, validation loss: 0.1032
2024-06-04 09:09:17 [INFO]: Epoch 073 - training loss: 0.1374, validation loss: 0.1019
2024-06-04 09:10:21 [INFO]: Epoch 074 - training loss: 0.1284, validation loss: 0.1018
2024-06-04 09:11:25 [INFO]: Epoch 075 - training loss: 0.1379, validation loss: 0.0965
2024-06-04 09:12:29 [INFO]: Epoch 076 - training loss: 0.1296, validation loss: 0.0958
2024-06-04 09:13:33 [INFO]: Epoch 077 - training loss: 0.1383, validation loss: 0.0953
2024-06-04 09:14:38 [INFO]: Epoch 078 - training loss: 0.1374, validation loss: 0.0990
2024-06-04 09:15:42 [INFO]: Epoch 079 - training loss: 0.1350, validation loss: 0.0991
2024-06-04 09:16:46 [INFO]: Epoch 080 - training loss: 0.1230, validation loss: 0.0951
2024-06-04 09:17:50 [INFO]: Epoch 081 - training loss: 0.1569, validation loss: 0.1057
2024-06-04 09:18:54 [INFO]: Epoch 082 - training loss: 0.1493, validation loss: 0.0992
2024-06-04 09:19:59 [INFO]: Epoch 083 - training loss: 0.1295, validation loss: 0.1011
2024-06-04 09:21:03 [INFO]: Epoch 084 - training loss: 0.1457, validation loss: 0.0964
2024-06-04 09:22:07 [INFO]: Epoch 085 - training loss: 0.1295, validation loss: 0.0932
2024-06-04 09:23:11 [INFO]: Epoch 086 - training loss: 0.1405, validation loss: 0.0964
2024-06-04 09:24:15 [INFO]: Epoch 087 - training loss: 0.1208, validation loss: 0.0937
2024-06-04 09:25:19 [INFO]: Epoch 088 - training loss: 0.1296, validation loss: 0.0958
2024-06-04 09:26:24 [INFO]: Epoch 089 - training loss: 0.1411, validation loss: 0.0970
2024-06-04 09:27:28 [INFO]: Epoch 090 - training loss: 0.1424, validation loss: 0.0961
2024-06-04 09:28:33 [INFO]: Epoch 091 - training loss: 0.1317, validation loss: 0.0929
2024-06-04 09:29:37 [INFO]: Epoch 092 - training loss: 0.1247, validation loss: 0.0922
2024-06-04 09:30:42 [INFO]: Epoch 093 - training loss: 0.1272, validation loss: 0.0941
2024-06-04 09:31:46 [INFO]: Epoch 094 - training loss: 0.1319, validation loss: 0.0950
2024-06-04 09:32:50 [INFO]: Epoch 095 - training loss: 0.1218, validation loss: 0.0924
2024-06-04 09:33:54 [INFO]: Epoch 096 - training loss: 0.1445, validation loss: 0.0968
2024-06-04 09:34:59 [INFO]: Epoch 097 - training loss: 0.1220, validation loss: 0.0953
2024-06-04 09:36:03 [INFO]: Epoch 098 - training loss: 0.1254, validation loss: 0.0935
2024-06-04 09:37:07 [INFO]: Epoch 099 - training loss: 0.1152, validation loss: 0.0901
2024-06-04 09:38:12 [INFO]: Epoch 100 - training loss: 0.1290, validation loss: 0.0935
2024-06-04 09:38:12 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 09:38:12 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_2/20240604_T075114/CSDI.pypots
2024-06-04 10:19:02 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_2/imputation.pkl
2024-06-04 10:19:02 [INFO]: Round2 - CSDI on BeijingAir: MAE=0.1663, MSE=0.2830, MRE=0.2513
2024-06-04 10:19:02 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 10:19:02 [INFO]: Using the given device: cuda:0
2024-06-04 10:19:02 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_3/20240604_T101902
2024-06-04 10:19:02 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_3/20240604_T101902/tensorboard
2024-06-04 10:19:02 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-04 10:19:34 [INFO]: Epoch 001 - training loss: 0.5223, validation loss: 0.3690
2024-06-04 10:20:07 [INFO]: Epoch 002 - training loss: 0.3406, validation loss: 0.3524
2024-06-04 10:20:39 [INFO]: Epoch 003 - training loss: 0.3058, validation loss: 0.2807
2024-06-04 10:21:12 [INFO]: Epoch 004 - training loss: 0.2787, validation loss: 0.2404
2024-06-04 10:21:44 [INFO]: Epoch 005 - training loss: 0.2382, validation loss: 0.2224
2024-06-04 10:22:17 [INFO]: Epoch 006 - training loss: 0.2291, validation loss: 0.1885
2024-06-04 10:22:49 [INFO]: Epoch 007 - training loss: 0.2233, validation loss: 0.1843
2024-06-04 10:23:22 [INFO]: Epoch 008 - training loss: 0.2043, validation loss: 0.1682
2024-06-04 10:23:54 [INFO]: Epoch 009 - training loss: 0.1892, validation loss: 0.1611
2024-06-04 10:24:27 [INFO]: Epoch 010 - training loss: 0.1939, validation loss: 0.1724
2024-06-04 10:24:59 [INFO]: Epoch 011 - training loss: 0.1847, validation loss: 0.1463
2024-06-04 10:25:31 [INFO]: Epoch 012 - training loss: 0.1673, validation loss: 0.1415
2024-06-04 10:26:04 [INFO]: Epoch 013 - training loss: 0.1922, validation loss: 0.1448
2024-06-04 10:26:36 [INFO]: Epoch 014 - training loss: 0.1921, validation loss: 0.1552
2024-06-04 10:27:09 [INFO]: Epoch 015 - training loss: 0.1838, validation loss: 0.1425
2024-06-04 10:27:41 [INFO]: Epoch 016 - training loss: 0.1792, validation loss: 0.1457
2024-06-04 10:28:14 [INFO]: Epoch 017 - training loss: 0.1754, validation loss: 0.1357
2024-06-04 10:28:46 [INFO]: Epoch 018 - training loss: 0.1591, validation loss: 0.1446
2024-06-04 10:29:19 [INFO]: Epoch 019 - training loss: 0.1700, validation loss: 0.1383
2024-06-04 10:29:51 [INFO]: Epoch 020 - training loss: 0.1721, validation loss: 0.1356
2024-06-04 10:30:23 [INFO]: Epoch 021 - training loss: 0.1600, validation loss: 0.1280
2024-06-04 10:30:56 [INFO]: Epoch 022 - training loss: 0.1495, validation loss: 0.1307
2024-06-04 10:31:28 [INFO]: Epoch 023 - training loss: 0.1755, validation loss: 0.1273
2024-06-04 10:32:01 [INFO]: Epoch 024 - training loss: 0.1599, validation loss: 0.1296
2024-06-04 10:32:33 [INFO]: Epoch 025 - training loss: 0.1425, validation loss: 0.1224
2024-06-04 10:33:06 [INFO]: Epoch 026 - training loss: 0.1469, validation loss: 0.1205
2024-06-04 10:33:38 [INFO]: Epoch 027 - training loss: 0.1580, validation loss: 0.1186
2024-06-04 10:34:11 [INFO]: Epoch 028 - training loss: 0.1567, validation loss: 0.1240
2024-06-04 10:34:43 [INFO]: Epoch 029 - training loss: 0.1491, validation loss: 0.1205
2024-06-04 10:35:16 [INFO]: Epoch 030 - training loss: 0.1576, validation loss: 0.1149
2024-06-04 10:35:48 [INFO]: Epoch 031 - training loss: 0.1571, validation loss: 0.1180
2024-06-04 10:36:20 [INFO]: Epoch 032 - training loss: 0.1668, validation loss: 0.1123
2024-06-04 10:36:53 [INFO]: Epoch 033 - training loss: 0.1537, validation loss: 0.1153
2024-06-04 10:37:25 [INFO]: Epoch 034 - training loss: 0.1490, validation loss: 0.1152
2024-06-04 10:37:58 [INFO]: Epoch 035 - training loss: 0.1536, validation loss: 0.1124
2024-06-04 10:38:30 [INFO]: Epoch 036 - training loss: 0.1548, validation loss: 0.1113
2024-06-04 10:39:03 [INFO]: Epoch 037 - training loss: 0.1516, validation loss: 0.1081
2024-06-04 10:39:35 [INFO]: Epoch 038 - training loss: 0.1431, validation loss: 0.1100
2024-06-04 10:40:08 [INFO]: Epoch 039 - training loss: 0.1340, validation loss: 0.1073
2024-06-04 10:40:40 [INFO]: Epoch 040 - training loss: 0.1519, validation loss: 0.1146
2024-06-04 10:41:13 [INFO]: Epoch 041 - training loss: 0.1604, validation loss: 0.1204
2024-06-04 10:41:45 [INFO]: Epoch 042 - training loss: 0.1221, validation loss: 0.1096
2024-06-04 10:42:18 [INFO]: Epoch 043 - training loss: 0.1515, validation loss: 0.1042
2024-06-04 10:42:50 [INFO]: Epoch 044 - training loss: 0.1363, validation loss: 0.1071
2024-06-04 10:43:22 [INFO]: Epoch 045 - training loss: 0.1460, validation loss: 0.1078
2024-06-04 10:43:55 [INFO]: Epoch 046 - training loss: 0.1423, validation loss: 0.1056
2024-06-04 10:44:27 [INFO]: Epoch 047 - training loss: 0.1497, validation loss: 0.1063
2024-06-04 10:44:59 [INFO]: Epoch 048 - training loss: 0.1215, validation loss: 0.1038
2024-06-04 10:45:31 [INFO]: Epoch 049 - training loss: 0.1472, validation loss: 0.1023
2024-06-04 10:46:04 [INFO]: Epoch 050 - training loss: 0.1379, validation loss: 0.1059
2024-06-04 10:46:36 [INFO]: Epoch 051 - training loss: 0.1175, validation loss: 0.1052
2024-06-04 10:47:09 [INFO]: Epoch 052 - training loss: 0.1529, validation loss: 0.1050
2024-06-04 10:47:41 [INFO]: Epoch 053 - training loss: 0.1292, validation loss: 0.1021
2024-06-04 10:48:13 [INFO]: Epoch 054 - training loss: 0.1353, validation loss: 0.1018
2024-06-04 10:48:46 [INFO]: Epoch 055 - training loss: 0.1444, validation loss: 0.1019
2024-06-04 10:49:18 [INFO]: Epoch 056 - training loss: 0.1166, validation loss: 0.1005
2024-06-04 10:49:50 [INFO]: Epoch 057 - training loss: 0.1347, validation loss: 0.1003
2024-06-04 10:50:23 [INFO]: Epoch 058 - training loss: 0.1280, validation loss: 0.1029
2024-06-04 10:50:55 [INFO]: Epoch 059 - training loss: 0.1535, validation loss: 0.1014
2024-06-04 10:51:28 [INFO]: Epoch 060 - training loss: 0.1340, validation loss: 0.1080
2024-06-04 10:52:00 [INFO]: Epoch 061 - training loss: 0.1456, validation loss: 0.1046
2024-06-04 10:52:32 [INFO]: Epoch 062 - training loss: 0.1584, validation loss: 0.1004
2024-06-04 10:53:05 [INFO]: Epoch 063 - training loss: 0.1393, validation loss: 0.1011
2024-06-04 10:53:37 [INFO]: Epoch 064 - training loss: 0.1364, validation loss: 0.0989
2024-06-04 10:54:10 [INFO]: Epoch 065 - training loss: 0.1388, validation loss: 0.1006
2024-06-04 10:54:42 [INFO]: Epoch 066 - training loss: 0.1450, validation loss: 0.1029
2024-06-04 10:55:14 [INFO]: Epoch 067 - training loss: 0.1397, validation loss: 0.1003
2024-06-04 10:55:47 [INFO]: Epoch 068 - training loss: 0.1378, validation loss: 0.0970
2024-06-04 10:56:19 [INFO]: Epoch 069 - training loss: 0.1222, validation loss: 0.0973
2024-06-04 10:56:52 [INFO]: Epoch 070 - training loss: 0.1359, validation loss: 0.1086
2024-06-04 10:57:24 [INFO]: Epoch 071 - training loss: 0.1529, validation loss: 0.0994
2024-06-04 10:57:56 [INFO]: Epoch 072 - training loss: 0.1287, validation loss: 0.0985
2024-06-04 10:58:29 [INFO]: Epoch 073 - training loss: 0.1353, validation loss: 0.0996
2024-06-04 10:59:01 [INFO]: Epoch 074 - training loss: 0.1361, validation loss: 0.0976
2024-06-04 10:59:34 [INFO]: Epoch 075 - training loss: 0.1443, validation loss: 0.0947
2024-06-04 11:00:06 [INFO]: Epoch 076 - training loss: 0.1344, validation loss: 0.0974
2024-06-04 11:00:39 [INFO]: Epoch 077 - training loss: 0.1339, validation loss: 0.0978
2024-06-04 11:01:11 [INFO]: Epoch 078 - training loss: 0.1254, validation loss: 0.1017
2024-06-04 11:01:43 [INFO]: Epoch 079 - training loss: 0.1503, validation loss: 0.1046
2024-06-04 11:02:16 [INFO]: Epoch 080 - training loss: 0.1356, validation loss: 0.0992
2024-06-04 11:02:48 [INFO]: Epoch 081 - training loss: 0.1232, validation loss: 0.0949
2024-06-04 11:03:21 [INFO]: Epoch 082 - training loss: 0.1269, validation loss: 0.0979
2024-06-04 11:03:53 [INFO]: Epoch 083 - training loss: 0.1209, validation loss: 0.0929
2024-06-04 11:04:26 [INFO]: Epoch 084 - training loss: 0.1440, validation loss: 0.0946
2024-06-04 11:04:58 [INFO]: Epoch 085 - training loss: 0.1275, validation loss: 0.0946
2024-06-04 11:05:30 [INFO]: Epoch 086 - training loss: 0.1237, validation loss: 0.0926
2024-06-04 11:06:03 [INFO]: Epoch 087 - training loss: 0.1437, validation loss: 0.0991
2024-06-04 11:06:35 [INFO]: Epoch 088 - training loss: 0.1263, validation loss: 0.0936
2024-06-04 11:07:08 [INFO]: Epoch 089 - training loss: 0.1404, validation loss: 0.0913
2024-06-04 11:07:40 [INFO]: Epoch 090 - training loss: 0.1329, validation loss: 0.0960
2024-06-04 11:08:13 [INFO]: Epoch 091 - training loss: 0.1196, validation loss: 0.0931
2024-06-04 11:08:45 [INFO]: Epoch 092 - training loss: 0.1347, validation loss: 0.0945
2024-06-04 11:09:17 [INFO]: Epoch 093 - training loss: 0.1186, validation loss: 0.0928
2024-06-04 11:09:50 [INFO]: Epoch 094 - training loss: 0.1426, validation loss: 0.0946
2024-06-04 11:10:22 [INFO]: Epoch 095 - training loss: 0.1216, validation loss: 0.0931
2024-06-04 11:10:54 [INFO]: Epoch 096 - training loss: 0.1235, validation loss: 0.0916
2024-06-04 11:11:27 [INFO]: Epoch 097 - training loss: 0.1243, validation loss: 0.0913
2024-06-04 11:11:59 [INFO]: Epoch 098 - training loss: 0.1344, validation loss: 0.0942
2024-06-04 11:12:32 [INFO]: Epoch 099 - training loss: 0.1318, validation loss: 0.0941
2024-06-04 11:13:04 [INFO]: Epoch 100 - training loss: 0.1442, validation loss: 0.0923
2024-06-04 11:13:04 [INFO]: Finished training. The best model is from epoch#97.
2024-06-04 11:13:04 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_3/20240604_T101902/CSDI.pypots
2024-06-04 11:31:16 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_3/imputation.pkl
2024-06-04 11:31:16 [INFO]: Round3 - CSDI on BeijingAir: MAE=0.1762, MSE=0.6466, MRE=0.2663
2024-06-04 11:31:16 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 11:31:16 [INFO]: Using the given device: cuda:0
2024-06-04 11:31:16 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_4/20240604_T113116
2024-06-04 11:31:16 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_4/20240604_T113116/tensorboard
2024-06-04 11:31:16 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-04 11:31:43 [INFO]: Epoch 001 - training loss: 0.5004, validation loss: 0.3608
2024-06-04 11:32:09 [INFO]: Epoch 002 - training loss: 0.3276, validation loss: 0.3117
2024-06-04 11:32:35 [INFO]: Epoch 003 - training loss: 0.3022, validation loss: 0.2684
2024-06-04 11:33:01 [INFO]: Epoch 004 - training loss: 0.2628, validation loss: 0.2402
2024-06-04 11:33:27 [INFO]: Epoch 005 - training loss: 0.2342, validation loss: 0.1970
2024-06-04 11:33:53 [INFO]: Epoch 006 - training loss: 0.2144, validation loss: 0.1772
2024-06-04 11:34:19 [INFO]: Epoch 007 - training loss: 0.1966, validation loss: 0.1574
2024-06-04 11:34:45 [INFO]: Epoch 008 - training loss: 0.2191, validation loss: 0.1585
2024-06-04 11:35:12 [INFO]: Epoch 009 - training loss: 0.1890, validation loss: 0.1479
2024-06-04 11:35:38 [INFO]: Epoch 010 - training loss: 0.1854, validation loss: 0.1532
2024-06-04 11:36:04 [INFO]: Epoch 011 - training loss: 0.1781, validation loss: 0.1536
2024-06-04 11:36:30 [INFO]: Epoch 012 - training loss: 0.1752, validation loss: 0.1432
2024-06-04 11:36:56 [INFO]: Epoch 013 - training loss: 0.1745, validation loss: 0.1351
2024-06-04 11:37:22 [INFO]: Epoch 014 - training loss: 0.1759, validation loss: 0.1381
2024-06-04 11:37:48 [INFO]: Epoch 015 - training loss: 0.1757, validation loss: 0.1405
2024-06-04 11:38:14 [INFO]: Epoch 016 - training loss: 0.1787, validation loss: 0.1351
2024-06-04 11:38:40 [INFO]: Epoch 017 - training loss: 0.1901, validation loss: 0.1300
2024-06-04 11:39:07 [INFO]: Epoch 018 - training loss: 0.1745, validation loss: 0.1343
2024-06-04 11:39:33 [INFO]: Epoch 019 - training loss: 0.1711, validation loss: 0.1269
2024-06-04 11:39:59 [INFO]: Epoch 020 - training loss: 0.1717, validation loss: 0.1339
2024-06-04 11:40:25 [INFO]: Epoch 021 - training loss: 0.1704, validation loss: 0.1293
2024-06-04 11:40:51 [INFO]: Epoch 022 - training loss: 0.1623, validation loss: 0.1282
2024-06-04 11:41:17 [INFO]: Epoch 023 - training loss: 0.1682, validation loss: 0.1267
2024-06-04 11:41:43 [INFO]: Epoch 024 - training loss: 0.1791, validation loss: 0.1372
2024-06-04 11:42:09 [INFO]: Epoch 025 - training loss: 0.1716, validation loss: 0.1246
2024-06-04 11:42:35 [INFO]: Epoch 026 - training loss: 0.1758, validation loss: 0.1524
2024-06-04 11:43:02 [INFO]: Epoch 027 - training loss: 0.1740, validation loss: 0.1213
2024-06-04 11:43:28 [INFO]: Epoch 028 - training loss: 0.1620, validation loss: 0.1187
2024-06-04 11:43:54 [INFO]: Epoch 029 - training loss: 0.1572, validation loss: 0.1225
2024-06-04 11:44:20 [INFO]: Epoch 030 - training loss: 0.1755, validation loss: 0.1228
2024-06-04 11:44:46 [INFO]: Epoch 031 - training loss: 0.1684, validation loss: 0.1196
2024-06-04 11:45:12 [INFO]: Epoch 032 - training loss: 0.1475, validation loss: 0.1181
2024-06-04 11:45:38 [INFO]: Epoch 033 - training loss: 0.1393, validation loss: 0.1120
2024-06-04 11:46:04 [INFO]: Epoch 034 - training loss: 0.1461, validation loss: 0.1120
2024-06-04 11:46:31 [INFO]: Epoch 035 - training loss: 0.1519, validation loss: 0.1110
2024-06-04 11:46:57 [INFO]: Epoch 036 - training loss: 0.1482, validation loss: 0.1091
2024-06-04 11:47:23 [INFO]: Epoch 037 - training loss: 0.1483, validation loss: 0.1101
2024-06-04 11:47:49 [INFO]: Epoch 038 - training loss: 0.1519, validation loss: 0.1137
2024-06-04 11:48:15 [INFO]: Epoch 039 - training loss: 0.1529, validation loss: 0.1073
2024-06-04 11:48:41 [INFO]: Epoch 040 - training loss: 0.1492, validation loss: 0.1062
2024-06-04 11:49:07 [INFO]: Epoch 041 - training loss: 0.1477, validation loss: 0.1072
2024-06-04 11:49:33 [INFO]: Epoch 042 - training loss: 0.1599, validation loss: 0.1088
2024-06-04 11:49:59 [INFO]: Epoch 043 - training loss: 0.1608, validation loss: 0.1066
2024-06-04 11:50:26 [INFO]: Epoch 044 - training loss: 0.1303, validation loss: 0.1046
2024-06-04 11:50:52 [INFO]: Epoch 045 - training loss: 0.1508, validation loss: 0.1089
2024-06-04 11:51:18 [INFO]: Epoch 046 - training loss: 0.1310, validation loss: 0.1033
2024-06-04 11:51:44 [INFO]: Epoch 047 - training loss: 0.1301, validation loss: 0.1057
2024-06-04 11:52:10 [INFO]: Epoch 048 - training loss: 0.1375, validation loss: 0.1038
2024-06-04 11:52:36 [INFO]: Epoch 049 - training loss: 0.1450, validation loss: 0.1063
2024-06-04 11:53:02 [INFO]: Epoch 050 - training loss: 0.1539, validation loss: 0.1054
2024-06-04 11:53:28 [INFO]: Epoch 051 - training loss: 0.1326, validation loss: 0.1027
2024-06-04 11:53:54 [INFO]: Epoch 052 - training loss: 0.1479, validation loss: 0.1028
2024-06-04 11:54:21 [INFO]: Epoch 053 - training loss: 0.1374, validation loss: 0.1021
2024-06-04 11:54:47 [INFO]: Epoch 054 - training loss: 0.1527, validation loss: 0.1010
2024-06-04 11:55:13 [INFO]: Epoch 055 - training loss: 0.1566, validation loss: 0.1098
2024-06-04 11:55:39 [INFO]: Epoch 056 - training loss: 0.1422, validation loss: 0.1039
2024-06-04 11:56:05 [INFO]: Epoch 057 - training loss: 0.1304, validation loss: 0.1033
2024-06-04 11:56:31 [INFO]: Epoch 058 - training loss: 0.1340, validation loss: 0.0987
2024-06-04 11:56:57 [INFO]: Epoch 059 - training loss: 0.1466, validation loss: 0.1034
2024-06-04 11:57:23 [INFO]: Epoch 060 - training loss: 0.1345, validation loss: 0.1034
2024-06-04 11:57:49 [INFO]: Epoch 061 - training loss: 0.1426, validation loss: 0.1039
2024-06-04 11:58:16 [INFO]: Epoch 062 - training loss: 0.1502, validation loss: 0.1014
2024-06-04 11:58:42 [INFO]: Epoch 063 - training loss: 0.1255, validation loss: 0.0973
2024-06-04 11:59:08 [INFO]: Epoch 064 - training loss: 0.1272, validation loss: 0.0971
2024-06-04 11:59:34 [INFO]: Epoch 065 - training loss: 0.1225, validation loss: 0.1005
2024-06-04 12:00:00 [INFO]: Epoch 066 - training loss: 0.1182, validation loss: 0.0985
2024-06-04 12:00:26 [INFO]: Epoch 067 - training loss: 0.1329, validation loss: 0.0959
2024-06-04 12:00:52 [INFO]: Epoch 068 - training loss: 0.1390, validation loss: 0.0964
2024-06-04 12:01:18 [INFO]: Epoch 069 - training loss: 0.1420, validation loss: 0.1014
2024-06-04 12:01:44 [INFO]: Epoch 070 - training loss: 0.1379, validation loss: 0.0994
2024-06-04 12:02:11 [INFO]: Epoch 071 - training loss: 0.1404, validation loss: 0.1012
2024-06-04 12:02:37 [INFO]: Epoch 072 - training loss: 0.1306, validation loss: 0.0977
2024-06-04 12:03:03 [INFO]: Epoch 073 - training loss: 0.1280, validation loss: 0.0968
2024-06-04 12:03:29 [INFO]: Epoch 074 - training loss: 0.1452, validation loss: 0.0993
2024-06-04 12:03:55 [INFO]: Epoch 075 - training loss: 0.1548, validation loss: 0.0982
2024-06-04 12:04:21 [INFO]: Epoch 076 - training loss: 0.1435, validation loss: 0.1032
2024-06-04 12:04:47 [INFO]: Epoch 077 - training loss: 0.1351, validation loss: 0.0969
2024-06-04 12:04:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 12:04:47 [INFO]: Finished training. The best model is from epoch#67.
2024-06-04 12:04:47 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_4/20240604_T113116/CSDI.pypots
2024-06-04 12:22:10 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/CSDI_BeijingAir/round_4/imputation.pkl
2024-06-04 12:22:10 [INFO]: Round4 - CSDI on BeijingAir: MAE=0.1865, MSE=0.6046, MRE=0.2818
2024-06-04 12:22:10 [INFO]: Done! Final results:
Averaged CSDI (244,833 params) on BeijingAir: MAE=0.1015 ± 0.010349100467417665, MSE=0.5074 ± 0.2348004400934806, MRE=0.1351 ± 0.013765028019003657, average inference time=407.64