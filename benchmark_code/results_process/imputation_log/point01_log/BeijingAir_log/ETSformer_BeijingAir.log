2024-06-04 02:44:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:45 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_0/20240604_T024445/tensorboard
2024-06-04 02:44:47 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
/scratch/users/k1814348/.conda/envs/pypots/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2024-06-04 02:45:07 [INFO]: Epoch 001 - training loss: 0.8672, validation loss: 0.3540
2024-06-04 02:45:23 [INFO]: Epoch 002 - training loss: 0.6622, validation loss: 0.3025
2024-06-04 02:45:40 [INFO]: Epoch 003 - training loss: 0.5964, validation loss: 0.2689
2024-06-04 02:45:56 [INFO]: Epoch 004 - training loss: 0.5566, validation loss: 0.2476
2024-06-04 02:46:12 [INFO]: Epoch 005 - training loss: 0.5291, validation loss: 0.2312
2024-06-04 02:46:28 [INFO]: Epoch 006 - training loss: 0.5089, validation loss: 0.2196
2024-06-04 02:46:44 [INFO]: Epoch 007 - training loss: 0.4912, validation loss: 0.2090
2024-06-04 02:47:01 [INFO]: Epoch 008 - training loss: 0.4779, validation loss: 0.2005
2024-06-04 02:47:16 [INFO]: Epoch 009 - training loss: 0.4684, validation loss: 0.1943
2024-06-04 02:47:32 [INFO]: Epoch 010 - training loss: 0.4600, validation loss: 0.1887
2024-06-04 02:47:48 [INFO]: Epoch 011 - training loss: 0.4542, validation loss: 0.1832
2024-06-04 02:48:05 [INFO]: Epoch 012 - training loss: 0.4467, validation loss: 0.1791
2024-06-04 02:48:21 [INFO]: Epoch 013 - training loss: 0.4414, validation loss: 0.1766
2024-06-04 02:48:37 [INFO]: Epoch 014 - training loss: 0.4371, validation loss: 0.1726
2024-06-04 02:48:53 [INFO]: Epoch 015 - training loss: 0.4333, validation loss: 0.1712
2024-06-04 02:49:09 [INFO]: Epoch 016 - training loss: 0.4294, validation loss: 0.1675
2024-06-04 02:49:25 [INFO]: Epoch 017 - training loss: 0.4259, validation loss: 0.1659
2024-06-04 02:49:41 [INFO]: Epoch 018 - training loss: 0.4211, validation loss: 0.1625
2024-06-04 02:49:58 [INFO]: Epoch 019 - training loss: 0.4202, validation loss: 0.1625
2024-06-04 02:50:14 [INFO]: Epoch 020 - training loss: 0.4169, validation loss: 0.1610
2024-06-04 02:50:29 [INFO]: Epoch 021 - training loss: 0.4152, validation loss: 0.1587
2024-06-04 02:50:45 [INFO]: Epoch 022 - training loss: 0.4126, validation loss: 0.1584
2024-06-04 02:51:02 [INFO]: Epoch 023 - training loss: 0.4104, validation loss: 0.1564
2024-06-04 02:51:18 [INFO]: Epoch 024 - training loss: 0.4089, validation loss: 0.1558
2024-06-04 02:51:33 [INFO]: Epoch 025 - training loss: 0.4065, validation loss: 0.1546
2024-06-04 02:51:49 [INFO]: Epoch 026 - training loss: 0.4053, validation loss: 0.1547
2024-06-04 02:52:05 [INFO]: Epoch 027 - training loss: 0.4022, validation loss: 0.1545
2024-06-04 02:52:22 [INFO]: Epoch 028 - training loss: 0.4014, validation loss: 0.1538
2024-06-04 02:52:39 [INFO]: Epoch 029 - training loss: 0.3996, validation loss: 0.1523
2024-06-04 02:52:55 [INFO]: Epoch 030 - training loss: 0.3979, validation loss: 0.1532
2024-06-04 02:53:11 [INFO]: Epoch 031 - training loss: 0.3987, validation loss: 0.1516
2024-06-04 02:53:28 [INFO]: Epoch 032 - training loss: 0.3965, validation loss: 0.1501
2024-06-04 02:53:44 [INFO]: Epoch 033 - training loss: 0.3965, validation loss: 0.1520
2024-06-04 02:54:00 [INFO]: Epoch 034 - training loss: 0.3938, validation loss: 0.1522
2024-06-04 02:54:16 [INFO]: Epoch 035 - training loss: 0.3926, validation loss: 0.1505
2024-06-04 02:54:32 [INFO]: Epoch 036 - training loss: 0.3922, validation loss: 0.1490
2024-06-04 02:54:49 [INFO]: Epoch 037 - training loss: 0.3912, validation loss: 0.1497
2024-06-04 02:55:06 [INFO]: Epoch 038 - training loss: 0.3897, validation loss: 0.1475
2024-06-04 02:55:22 [INFO]: Epoch 039 - training loss: 0.3884, validation loss: 0.1497
2024-06-04 02:55:38 [INFO]: Epoch 040 - training loss: 0.3887, validation loss: 0.1499
2024-06-04 02:55:55 [INFO]: Epoch 041 - training loss: 0.3871, validation loss: 0.1478
2024-06-04 02:56:11 [INFO]: Epoch 042 - training loss: 0.3863, validation loss: 0.1472
2024-06-04 02:56:28 [INFO]: Epoch 043 - training loss: 0.3852, validation loss: 0.1481
2024-06-04 02:56:44 [INFO]: Epoch 044 - training loss: 0.3849, validation loss: 0.1467
2024-06-04 02:57:00 [INFO]: Epoch 045 - training loss: 0.3842, validation loss: 0.1456
2024-06-04 02:57:16 [INFO]: Epoch 046 - training loss: 0.3831, validation loss: 0.1459
2024-06-04 02:57:33 [INFO]: Epoch 047 - training loss: 0.3821, validation loss: 0.1455
2024-06-04 02:57:49 [INFO]: Epoch 048 - training loss: 0.3826, validation loss: 0.1454
2024-06-04 02:58:06 [INFO]: Epoch 049 - training loss: 0.3815, validation loss: 0.1442
2024-06-04 02:58:22 [INFO]: Epoch 050 - training loss: 0.3803, validation loss: 0.1450
2024-06-04 02:58:38 [INFO]: Epoch 051 - training loss: 0.3789, validation loss: 0.1455
2024-06-04 02:58:55 [INFO]: Epoch 052 - training loss: 0.3798, validation loss: 0.1448
2024-06-04 02:59:12 [INFO]: Epoch 053 - training loss: 0.3792, validation loss: 0.1448
2024-06-04 02:59:28 [INFO]: Epoch 054 - training loss: 0.3776, validation loss: 0.1441
2024-06-04 02:59:44 [INFO]: Epoch 055 - training loss: 0.3767, validation loss: 0.1444
2024-06-04 03:00:01 [INFO]: Epoch 056 - training loss: 0.3768, validation loss: 0.1444
2024-06-04 03:00:17 [INFO]: Epoch 057 - training loss: 0.3771, validation loss: 0.1430
2024-06-04 03:00:33 [INFO]: Epoch 058 - training loss: 0.3764, validation loss: 0.1429
2024-06-04 03:00:50 [INFO]: Epoch 059 - training loss: 0.3765, validation loss: 0.1423
2024-06-04 03:01:05 [INFO]: Epoch 060 - training loss: 0.3744, validation loss: 0.1421
2024-06-04 03:01:21 [INFO]: Epoch 061 - training loss: 0.3744, validation loss: 0.1411
2024-06-04 03:01:38 [INFO]: Epoch 062 - training loss: 0.3748, validation loss: 0.1412
2024-06-04 03:01:52 [INFO]: Epoch 063 - training loss: 0.3729, validation loss: 0.1412
2024-06-04 03:02:06 [INFO]: Epoch 064 - training loss: 0.3741, validation loss: 0.1412
2024-06-04 03:02:18 [INFO]: Epoch 065 - training loss: 0.3737, validation loss: 0.1405
2024-06-04 03:02:30 [INFO]: Epoch 066 - training loss: 0.3730, validation loss: 0.1406
2024-06-04 03:02:43 [INFO]: Epoch 067 - training loss: 0.3719, validation loss: 0.1405
2024-06-04 03:02:54 [INFO]: Epoch 068 - training loss: 0.3715, validation loss: 0.1408
2024-06-04 03:03:06 [INFO]: Epoch 069 - training loss: 0.3702, validation loss: 0.1414
2024-06-04 03:03:18 [INFO]: Epoch 070 - training loss: 0.3705, validation loss: 0.1406
2024-06-04 03:03:30 [INFO]: Epoch 071 - training loss: 0.3713, validation loss: 0.1396
2024-06-04 03:03:41 [INFO]: Epoch 072 - training loss: 0.3709, validation loss: 0.1400
2024-06-04 03:03:54 [INFO]: Epoch 073 - training loss: 0.3702, validation loss: 0.1390
2024-06-04 03:04:06 [INFO]: Epoch 074 - training loss: 0.3695, validation loss: 0.1406
2024-06-04 03:04:17 [INFO]: Epoch 075 - training loss: 0.3696, validation loss: 0.1381
2024-06-04 03:04:30 [INFO]: Epoch 076 - training loss: 0.3692, validation loss: 0.1384
2024-06-04 03:04:41 [INFO]: Epoch 077 - training loss: 0.3690, validation loss: 0.1387
2024-06-04 03:04:53 [INFO]: Epoch 078 - training loss: 0.3681, validation loss: 0.1385
2024-06-04 03:05:05 [INFO]: Epoch 079 - training loss: 0.3664, validation loss: 0.1374
2024-06-04 03:05:17 [INFO]: Epoch 080 - training loss: 0.3676, validation loss: 0.1370
2024-06-04 03:05:29 [INFO]: Epoch 081 - training loss: 0.3684, validation loss: 0.1388
2024-06-04 03:05:41 [INFO]: Epoch 082 - training loss: 0.3673, validation loss: 0.1369
2024-06-04 03:05:53 [INFO]: Epoch 083 - training loss: 0.3661, validation loss: 0.1374
2024-06-04 03:06:05 [INFO]: Epoch 084 - training loss: 0.3667, validation loss: 0.1368
2024-06-04 03:06:17 [INFO]: Epoch 085 - training loss: 0.3658, validation loss: 0.1373
2024-06-04 03:06:29 [INFO]: Epoch 086 - training loss: 0.3666, validation loss: 0.1369
2024-06-04 03:06:40 [INFO]: Epoch 087 - training loss: 0.3659, validation loss: 0.1365
2024-06-04 03:06:52 [INFO]: Epoch 088 - training loss: 0.3659, validation loss: 0.1359
2024-06-04 03:07:04 [INFO]: Epoch 089 - training loss: 0.3652, validation loss: 0.1364
2024-06-04 03:07:16 [INFO]: Epoch 090 - training loss: 0.3651, validation loss: 0.1365
2024-06-04 03:07:28 [INFO]: Epoch 091 - training loss: 0.3648, validation loss: 0.1360
2024-06-04 03:07:39 [INFO]: Epoch 092 - training loss: 0.3646, validation loss: 0.1355
2024-06-04 03:07:51 [INFO]: Epoch 093 - training loss: 0.3624, validation loss: 0.1356
2024-06-04 03:08:03 [INFO]: Epoch 094 - training loss: 0.3639, validation loss: 0.1349
2024-06-04 03:08:14 [INFO]: Epoch 095 - training loss: 0.3633, validation loss: 0.1367
2024-06-04 03:08:26 [INFO]: Epoch 096 - training loss: 0.3629, validation loss: 0.1358
2024-06-04 03:08:38 [INFO]: Epoch 097 - training loss: 0.3632, validation loss: 0.1358
2024-06-04 03:08:50 [INFO]: Epoch 098 - training loss: 0.3627, validation loss: 0.1363
2024-06-04 03:09:03 [INFO]: Epoch 099 - training loss: 0.3631, validation loss: 0.1356
2024-06-04 03:09:15 [INFO]: Epoch 100 - training loss: 0.3621, validation loss: 0.1359
2024-06-04 03:09:15 [INFO]: Finished training. The best model is from epoch#94.
2024-06-04 03:09:15 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_0/20240604_T024445/ETSformer.pypots
2024-06-04 03:09:24 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_0/imputation.pkl
2024-06-04 03:09:24 [INFO]: Round0 - ETSformer on BeijingAir: MAE=0.2257, MSE=0.1791, MRE=0.3411
2024-06-04 03:09:24 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:09:24 [INFO]: Using the given device: cuda:0
2024-06-04 03:09:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_1/20240604_T030924
2024-06-04 03:09:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_1/20240604_T030924/tensorboard
2024-06-04 03:09:25 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-04 03:09:37 [INFO]: Epoch 001 - training loss: 0.8429, validation loss: 0.3271
2024-06-04 03:09:49 [INFO]: Epoch 002 - training loss: 0.6510, validation loss: 0.2743
2024-06-04 03:10:01 [INFO]: Epoch 003 - training loss: 0.5681, validation loss: 0.2428
2024-06-04 03:10:13 [INFO]: Epoch 004 - training loss: 0.5286, validation loss: 0.2233
2024-06-04 03:10:25 [INFO]: Epoch 005 - training loss: 0.5045, validation loss: 0.2090
2024-06-04 03:10:37 [INFO]: Epoch 006 - training loss: 0.4863, validation loss: 0.1989
2024-06-04 03:10:48 [INFO]: Epoch 007 - training loss: 0.4730, validation loss: 0.1905
2024-06-04 03:11:00 [INFO]: Epoch 008 - training loss: 0.4616, validation loss: 0.1844
2024-06-04 03:11:12 [INFO]: Epoch 009 - training loss: 0.4518, validation loss: 0.1805
2024-06-04 03:11:24 [INFO]: Epoch 010 - training loss: 0.4449, validation loss: 0.1767
2024-06-04 03:11:36 [INFO]: Epoch 011 - training loss: 0.4391, validation loss: 0.1726
2024-06-04 03:11:47 [INFO]: Epoch 012 - training loss: 0.4334, validation loss: 0.1696
2024-06-04 03:11:59 [INFO]: Epoch 013 - training loss: 0.4312, validation loss: 0.1674
2024-06-04 03:12:11 [INFO]: Epoch 014 - training loss: 0.4247, validation loss: 0.1648
2024-06-04 03:12:23 [INFO]: Epoch 015 - training loss: 0.4220, validation loss: 0.1626
2024-06-04 03:12:35 [INFO]: Epoch 016 - training loss: 0.4193, validation loss: 0.1623
2024-06-04 03:12:46 [INFO]: Epoch 017 - training loss: 0.4165, validation loss: 0.1593
2024-06-04 03:12:58 [INFO]: Epoch 018 - training loss: 0.4139, validation loss: 0.1597
2024-06-04 03:13:09 [INFO]: Epoch 019 - training loss: 0.4121, validation loss: 0.1590
2024-06-04 03:13:22 [INFO]: Epoch 020 - training loss: 0.4086, validation loss: 0.1566
2024-06-04 03:13:34 [INFO]: Epoch 021 - training loss: 0.4071, validation loss: 0.1566
2024-06-04 03:13:45 [INFO]: Epoch 022 - training loss: 0.4052, validation loss: 0.1566
2024-06-04 03:13:57 [INFO]: Epoch 023 - training loss: 0.4039, validation loss: 0.1550
2024-06-04 03:14:09 [INFO]: Epoch 024 - training loss: 0.4015, validation loss: 0.1541
2024-06-04 03:14:20 [INFO]: Epoch 025 - training loss: 0.4002, validation loss: 0.1548
2024-06-04 03:14:32 [INFO]: Epoch 026 - training loss: 0.3983, validation loss: 0.1519
2024-06-04 03:14:44 [INFO]: Epoch 027 - training loss: 0.3967, validation loss: 0.1536
2024-06-04 03:14:55 [INFO]: Epoch 028 - training loss: 0.3953, validation loss: 0.1512
2024-06-04 03:15:07 [INFO]: Epoch 029 - training loss: 0.3957, validation loss: 0.1492
2024-06-04 03:15:19 [INFO]: Epoch 030 - training loss: 0.3941, validation loss: 0.1511
2024-06-04 03:15:31 [INFO]: Epoch 031 - training loss: 0.3931, validation loss: 0.1504
2024-06-04 03:15:43 [INFO]: Epoch 032 - training loss: 0.3916, validation loss: 0.1490
2024-06-04 03:15:55 [INFO]: Epoch 033 - training loss: 0.3918, validation loss: 0.1481
2024-06-04 03:16:07 [INFO]: Epoch 034 - training loss: 0.3889, validation loss: 0.1493
2024-06-04 03:16:18 [INFO]: Epoch 035 - training loss: 0.3892, validation loss: 0.1487
2024-06-04 03:16:30 [INFO]: Epoch 036 - training loss: 0.3891, validation loss: 0.1482
2024-06-04 03:16:41 [INFO]: Epoch 037 - training loss: 0.3863, validation loss: 0.1466
2024-06-04 03:16:53 [INFO]: Epoch 038 - training loss: 0.3851, validation loss: 0.1459
2024-06-04 03:17:05 [INFO]: Epoch 039 - training loss: 0.3863, validation loss: 0.1450
2024-06-04 03:17:17 [INFO]: Epoch 040 - training loss: 0.3844, validation loss: 0.1448
2024-06-04 03:17:28 [INFO]: Epoch 041 - training loss: 0.3840, validation loss: 0.1455
2024-06-04 03:17:40 [INFO]: Epoch 042 - training loss: 0.3827, validation loss: 0.1449
2024-06-04 03:17:52 [INFO]: Epoch 043 - training loss: 0.3829, validation loss: 0.1443
2024-06-04 03:18:04 [INFO]: Epoch 044 - training loss: 0.3814, validation loss: 0.1444
2024-06-04 03:18:15 [INFO]: Epoch 045 - training loss: 0.3817, validation loss: 0.1430
2024-06-04 03:18:27 [INFO]: Epoch 046 - training loss: 0.3804, validation loss: 0.1447
2024-06-04 03:18:39 [INFO]: Epoch 047 - training loss: 0.3798, validation loss: 0.1431
2024-06-04 03:18:51 [INFO]: Epoch 048 - training loss: 0.3802, validation loss: 0.1426
2024-06-04 03:19:02 [INFO]: Epoch 049 - training loss: 0.3791, validation loss: 0.1423
2024-06-04 03:19:13 [INFO]: Epoch 050 - training loss: 0.3779, validation loss: 0.1424
2024-06-04 03:19:25 [INFO]: Epoch 051 - training loss: 0.3773, validation loss: 0.1429
2024-06-04 03:19:37 [INFO]: Epoch 052 - training loss: 0.3784, validation loss: 0.1429
2024-06-04 03:19:48 [INFO]: Epoch 053 - training loss: 0.3766, validation loss: 0.1426
2024-06-04 03:20:01 [INFO]: Epoch 054 - training loss: 0.3755, validation loss: 0.1417
2024-06-04 03:20:12 [INFO]: Epoch 055 - training loss: 0.3757, validation loss: 0.1413
2024-06-04 03:20:24 [INFO]: Epoch 056 - training loss: 0.3745, validation loss: 0.1422
2024-06-04 03:20:35 [INFO]: Epoch 057 - training loss: 0.3749, validation loss: 0.1409
2024-06-04 03:20:47 [INFO]: Epoch 058 - training loss: 0.3737, validation loss: 0.1414
2024-06-04 03:20:59 [INFO]: Epoch 059 - training loss: 0.3730, validation loss: 0.1422
2024-06-04 03:21:11 [INFO]: Epoch 060 - training loss: 0.3733, validation loss: 0.1410
2024-06-04 03:21:22 [INFO]: Epoch 061 - training loss: 0.3717, validation loss: 0.1415
2024-06-04 03:21:34 [INFO]: Epoch 062 - training loss: 0.3712, validation loss: 0.1414
2024-06-04 03:21:46 [INFO]: Epoch 063 - training loss: 0.3726, validation loss: 0.1408
2024-06-04 03:21:57 [INFO]: Epoch 064 - training loss: 0.3717, validation loss: 0.1394
2024-06-04 03:22:09 [INFO]: Epoch 065 - training loss: 0.3713, validation loss: 0.1392
2024-06-04 03:22:21 [INFO]: Epoch 066 - training loss: 0.3717, validation loss: 0.1399
2024-06-04 03:22:33 [INFO]: Epoch 067 - training loss: 0.3706, validation loss: 0.1397
2024-06-04 03:22:44 [INFO]: Epoch 068 - training loss: 0.3708, validation loss: 0.1397
2024-06-04 03:22:56 [INFO]: Epoch 069 - training loss: 0.3707, validation loss: 0.1387
2024-06-04 03:23:08 [INFO]: Epoch 070 - training loss: 0.3699, validation loss: 0.1385
2024-06-04 03:23:19 [INFO]: Epoch 071 - training loss: 0.3689, validation loss: 0.1383
2024-06-04 03:23:31 [INFO]: Epoch 072 - training loss: 0.3700, validation loss: 0.1386
2024-06-04 03:23:43 [INFO]: Epoch 073 - training loss: 0.3693, validation loss: 0.1383
2024-06-04 03:23:55 [INFO]: Epoch 074 - training loss: 0.3689, validation loss: 0.1370
2024-06-04 03:24:06 [INFO]: Epoch 075 - training loss: 0.3686, validation loss: 0.1367
2024-06-04 03:24:17 [INFO]: Epoch 076 - training loss: 0.3670, validation loss: 0.1370
2024-06-04 03:24:29 [INFO]: Epoch 077 - training loss: 0.3663, validation loss: 0.1375
2024-06-04 03:24:41 [INFO]: Epoch 078 - training loss: 0.3670, validation loss: 0.1384
2024-06-04 03:24:52 [INFO]: Epoch 079 - training loss: 0.3671, validation loss: 0.1367
2024-06-04 03:25:04 [INFO]: Epoch 080 - training loss: 0.3660, validation loss: 0.1358
2024-06-04 03:25:16 [INFO]: Epoch 081 - training loss: 0.3668, validation loss: 0.1360
2024-06-04 03:25:27 [INFO]: Epoch 082 - training loss: 0.3653, validation loss: 0.1358
2024-06-04 03:25:39 [INFO]: Epoch 083 - training loss: 0.3664, validation loss: 0.1369
2024-06-04 03:25:51 [INFO]: Epoch 084 - training loss: 0.3662, validation loss: 0.1346
2024-06-04 03:26:03 [INFO]: Epoch 085 - training loss: 0.3655, validation loss: 0.1371
2024-06-04 03:26:14 [INFO]: Epoch 086 - training loss: 0.3654, validation loss: 0.1364
2024-06-04 03:26:26 [INFO]: Epoch 087 - training loss: 0.3651, validation loss: 0.1358
2024-06-04 03:26:37 [INFO]: Epoch 088 - training loss: 0.3640, validation loss: 0.1358
2024-06-04 03:26:49 [INFO]: Epoch 089 - training loss: 0.3640, validation loss: 0.1354
2024-06-04 03:27:01 [INFO]: Epoch 090 - training loss: 0.3652, validation loss: 0.1338
2024-06-04 03:27:12 [INFO]: Epoch 091 - training loss: 0.3629, validation loss: 0.1345
2024-06-04 03:27:24 [INFO]: Epoch 092 - training loss: 0.3632, validation loss: 0.1347
2024-06-04 03:27:36 [INFO]: Epoch 093 - training loss: 0.3633, validation loss: 0.1343
2024-06-04 03:27:48 [INFO]: Epoch 094 - training loss: 0.3632, validation loss: 0.1349
2024-06-04 03:27:59 [INFO]: Epoch 095 - training loss: 0.3642, validation loss: 0.1338
2024-06-04 03:28:11 [INFO]: Epoch 096 - training loss: 0.3629, validation loss: 0.1362
2024-06-04 03:28:23 [INFO]: Epoch 097 - training loss: 0.3613, validation loss: 0.1350
2024-06-04 03:28:35 [INFO]: Epoch 098 - training loss: 0.3622, validation loss: 0.1336
2024-06-04 03:28:46 [INFO]: Epoch 099 - training loss: 0.3620, validation loss: 0.1346
2024-06-04 03:28:58 [INFO]: Epoch 100 - training loss: 0.3612, validation loss: 0.1344
2024-06-04 03:28:58 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 03:28:58 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_1/20240604_T030924/ETSformer.pypots
2024-06-04 03:29:07 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_1/imputation.pkl
2024-06-04 03:29:07 [INFO]: Round1 - ETSformer on BeijingAir: MAE=0.2219, MSE=0.1772, MRE=0.3353
2024-06-04 03:29:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:29:07 [INFO]: Using the given device: cuda:0
2024-06-04 03:29:07 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_2/20240604_T032907
2024-06-04 03:29:07 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_2/20240604_T032907/tensorboard
2024-06-04 03:29:08 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-04 03:29:18 [INFO]: Epoch 001 - training loss: 0.8458, validation loss: 0.3424
2024-06-04 03:29:27 [INFO]: Epoch 002 - training loss: 0.6565, validation loss: 0.2884
2024-06-04 03:29:37 [INFO]: Epoch 003 - training loss: 0.5736, validation loss: 0.2545
2024-06-04 03:29:47 [INFO]: Epoch 004 - training loss: 0.5337, validation loss: 0.2365
2024-06-04 03:29:56 [INFO]: Epoch 005 - training loss: 0.5075, validation loss: 0.2227
2024-06-04 03:30:06 [INFO]: Epoch 006 - training loss: 0.4890, validation loss: 0.2089
2024-06-04 03:30:16 [INFO]: Epoch 007 - training loss: 0.4749, validation loss: 0.1998
2024-06-04 03:30:26 [INFO]: Epoch 008 - training loss: 0.4652, validation loss: 0.1918
2024-06-04 03:30:35 [INFO]: Epoch 009 - training loss: 0.4566, validation loss: 0.1867
2024-06-04 03:30:45 [INFO]: Epoch 010 - training loss: 0.4483, validation loss: 0.1827
2024-06-04 03:30:55 [INFO]: Epoch 011 - training loss: 0.4415, validation loss: 0.1762
2024-06-04 03:31:05 [INFO]: Epoch 012 - training loss: 0.4375, validation loss: 0.1740
2024-06-04 03:31:14 [INFO]: Epoch 013 - training loss: 0.4320, validation loss: 0.1713
2024-06-04 03:31:24 [INFO]: Epoch 014 - training loss: 0.4282, validation loss: 0.1692
2024-06-04 03:31:34 [INFO]: Epoch 015 - training loss: 0.4244, validation loss: 0.1668
2024-06-04 03:31:44 [INFO]: Epoch 016 - training loss: 0.4232, validation loss: 0.1657
2024-06-04 03:31:53 [INFO]: Epoch 017 - training loss: 0.4193, validation loss: 0.1631
2024-06-04 03:32:03 [INFO]: Epoch 018 - training loss: 0.4145, validation loss: 0.1631
2024-06-04 03:32:12 [INFO]: Epoch 019 - training loss: 0.4132, validation loss: 0.1622
2024-06-04 03:32:22 [INFO]: Epoch 020 - training loss: 0.4117, validation loss: 0.1608
2024-06-04 03:32:32 [INFO]: Epoch 021 - training loss: 0.4086, validation loss: 0.1599
2024-06-04 03:32:41 [INFO]: Epoch 022 - training loss: 0.4073, validation loss: 0.1592
2024-06-04 03:32:51 [INFO]: Epoch 023 - training loss: 0.4056, validation loss: 0.1583
2024-06-04 03:33:00 [INFO]: Epoch 024 - training loss: 0.4041, validation loss: 0.1566
2024-06-04 03:33:10 [INFO]: Epoch 025 - training loss: 0.4018, validation loss: 0.1558
2024-06-04 03:33:19 [INFO]: Epoch 026 - training loss: 0.4003, validation loss: 0.1554
2024-06-04 03:33:29 [INFO]: Epoch 027 - training loss: 0.3983, validation loss: 0.1544
2024-06-04 03:33:39 [INFO]: Epoch 028 - training loss: 0.3979, validation loss: 0.1542
2024-06-04 03:33:49 [INFO]: Epoch 029 - training loss: 0.3951, validation loss: 0.1542
2024-06-04 03:33:58 [INFO]: Epoch 030 - training loss: 0.3953, validation loss: 0.1537
2024-06-04 03:34:08 [INFO]: Epoch 031 - training loss: 0.3940, validation loss: 0.1523
2024-06-04 03:34:18 [INFO]: Epoch 032 - training loss: 0.3914, validation loss: 0.1538
2024-06-04 03:34:27 [INFO]: Epoch 033 - training loss: 0.3910, validation loss: 0.1513
2024-06-04 03:34:37 [INFO]: Epoch 034 - training loss: 0.3902, validation loss: 0.1512
2024-06-04 03:34:46 [INFO]: Epoch 035 - training loss: 0.3898, validation loss: 0.1521
2024-06-04 03:34:56 [INFO]: Epoch 036 - training loss: 0.3887, validation loss: 0.1515
2024-06-04 03:35:06 [INFO]: Epoch 037 - training loss: 0.3884, validation loss: 0.1501
2024-06-04 03:35:16 [INFO]: Epoch 038 - training loss: 0.3878, validation loss: 0.1493
2024-06-04 03:35:25 [INFO]: Epoch 039 - training loss: 0.3874, validation loss: 0.1498
2024-06-04 03:35:35 [INFO]: Epoch 040 - training loss: 0.3863, validation loss: 0.1487
2024-06-04 03:35:45 [INFO]: Epoch 041 - training loss: 0.3847, validation loss: 0.1476
2024-06-04 03:35:54 [INFO]: Epoch 042 - training loss: 0.3847, validation loss: 0.1466
2024-06-04 03:36:05 [INFO]: Epoch 043 - training loss: 0.3834, validation loss: 0.1460
2024-06-04 03:36:14 [INFO]: Epoch 044 - training loss: 0.3823, validation loss: 0.1468
2024-06-04 03:36:24 [INFO]: Epoch 045 - training loss: 0.3820, validation loss: 0.1461
2024-06-04 03:36:34 [INFO]: Epoch 046 - training loss: 0.3819, validation loss: 0.1449
2024-06-04 03:36:43 [INFO]: Epoch 047 - training loss: 0.3799, validation loss: 0.1459
2024-06-04 03:36:52 [INFO]: Epoch 048 - training loss: 0.3810, validation loss: 0.1457
2024-06-04 03:37:02 [INFO]: Epoch 049 - training loss: 0.3802, validation loss: 0.1460
2024-06-04 03:37:12 [INFO]: Epoch 050 - training loss: 0.3806, validation loss: 0.1455
2024-06-04 03:37:22 [INFO]: Epoch 051 - training loss: 0.3777, validation loss: 0.1453
2024-06-04 03:37:31 [INFO]: Epoch 052 - training loss: 0.3796, validation loss: 0.1427
2024-06-04 03:37:41 [INFO]: Epoch 053 - training loss: 0.3774, validation loss: 0.1441
2024-06-04 03:37:51 [INFO]: Epoch 054 - training loss: 0.3790, validation loss: 0.1428
2024-06-04 03:38:00 [INFO]: Epoch 055 - training loss: 0.3758, validation loss: 0.1447
2024-06-04 03:38:10 [INFO]: Epoch 056 - training loss: 0.3750, validation loss: 0.1436
2024-06-04 03:38:20 [INFO]: Epoch 057 - training loss: 0.3773, validation loss: 0.1432
2024-06-04 03:38:30 [INFO]: Epoch 058 - training loss: 0.3741, validation loss: 0.1426
2024-06-04 03:38:39 [INFO]: Epoch 059 - training loss: 0.3742, validation loss: 0.1420
2024-06-04 03:38:49 [INFO]: Epoch 060 - training loss: 0.3744, validation loss: 0.1435
2024-06-04 03:38:58 [INFO]: Epoch 061 - training loss: 0.3738, validation loss: 0.1424
2024-06-04 03:39:08 [INFO]: Epoch 062 - training loss: 0.3738, validation loss: 0.1423
2024-06-04 03:39:18 [INFO]: Epoch 063 - training loss: 0.3728, validation loss: 0.1414
2024-06-04 03:39:28 [INFO]: Epoch 064 - training loss: 0.3712, validation loss: 0.1423
2024-06-04 03:39:37 [INFO]: Epoch 065 - training loss: 0.3738, validation loss: 0.1424
2024-06-04 03:39:47 [INFO]: Epoch 066 - training loss: 0.3726, validation loss: 0.1413
2024-06-04 03:39:57 [INFO]: Epoch 067 - training loss: 0.3717, validation loss: 0.1408
2024-06-04 03:40:07 [INFO]: Epoch 068 - training loss: 0.3717, validation loss: 0.1420
2024-06-04 03:40:16 [INFO]: Epoch 069 - training loss: 0.3710, validation loss: 0.1405
2024-06-04 03:40:26 [INFO]: Epoch 070 - training loss: 0.3699, validation loss: 0.1413
2024-06-04 03:40:36 [INFO]: Epoch 071 - training loss: 0.3710, validation loss: 0.1403
2024-06-04 03:40:46 [INFO]: Epoch 072 - training loss: 0.3702, validation loss: 0.1413
2024-06-04 03:40:55 [INFO]: Epoch 073 - training loss: 0.3696, validation loss: 0.1411
2024-06-04 03:41:05 [INFO]: Epoch 074 - training loss: 0.3695, validation loss: 0.1408
2024-06-04 03:41:15 [INFO]: Epoch 075 - training loss: 0.3691, validation loss: 0.1408
2024-06-04 03:41:24 [INFO]: Epoch 076 - training loss: 0.3682, validation loss: 0.1404
2024-06-04 03:41:34 [INFO]: Epoch 077 - training loss: 0.3684, validation loss: 0.1405
2024-06-04 03:41:44 [INFO]: Epoch 078 - training loss: 0.3678, validation loss: 0.1396
2024-06-04 03:41:53 [INFO]: Epoch 079 - training loss: 0.3676, validation loss: 0.1392
2024-06-04 03:42:03 [INFO]: Epoch 080 - training loss: 0.3676, validation loss: 0.1391
2024-06-04 03:42:13 [INFO]: Epoch 081 - training loss: 0.3675, validation loss: 0.1397
2024-06-04 03:42:23 [INFO]: Epoch 082 - training loss: 0.3673, validation loss: 0.1400
2024-06-04 03:42:32 [INFO]: Epoch 083 - training loss: 0.3658, validation loss: 0.1402
2024-06-04 03:42:41 [INFO]: Epoch 084 - training loss: 0.3666, validation loss: 0.1395
2024-06-04 03:42:51 [INFO]: Epoch 085 - training loss: 0.3647, validation loss: 0.1391
2024-06-04 03:43:01 [INFO]: Epoch 086 - training loss: 0.3657, validation loss: 0.1393
2024-06-04 03:43:11 [INFO]: Epoch 087 - training loss: 0.3650, validation loss: 0.1396
2024-06-04 03:43:21 [INFO]: Epoch 088 - training loss: 0.3671, validation loss: 0.1391
2024-06-04 03:43:30 [INFO]: Epoch 089 - training loss: 0.3661, validation loss: 0.1387
2024-06-04 03:43:40 [INFO]: Epoch 090 - training loss: 0.3647, validation loss: 0.1393
2024-06-04 03:43:50 [INFO]: Epoch 091 - training loss: 0.3635, validation loss: 0.1389
2024-06-04 03:44:00 [INFO]: Epoch 092 - training loss: 0.3657, validation loss: 0.1384
2024-06-04 03:44:09 [INFO]: Epoch 093 - training loss: 0.3654, validation loss: 0.1379
2024-06-04 03:44:19 [INFO]: Epoch 094 - training loss: 0.3646, validation loss: 0.1398
2024-06-04 03:44:29 [INFO]: Epoch 095 - training loss: 0.3634, validation loss: 0.1387
2024-06-04 03:44:38 [INFO]: Epoch 096 - training loss: 0.3637, validation loss: 0.1375
2024-06-04 03:44:48 [INFO]: Epoch 097 - training loss: 0.3629, validation loss: 0.1385
2024-06-04 03:44:58 [INFO]: Epoch 098 - training loss: 0.3628, validation loss: 0.1381
2024-06-04 03:45:07 [INFO]: Epoch 099 - training loss: 0.3623, validation loss: 0.1381
2024-06-04 03:45:17 [INFO]: Epoch 100 - training loss: 0.3624, validation loss: 0.1381
2024-06-04 03:45:17 [INFO]: Finished training. The best model is from epoch#96.
2024-06-04 03:45:17 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_2/20240604_T032907/ETSformer.pypots
2024-06-04 03:45:24 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_2/imputation.pkl
2024-06-04 03:45:24 [INFO]: Round2 - ETSformer on BeijingAir: MAE=0.2263, MSE=0.1797, MRE=0.3419
2024-06-04 03:45:24 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:45:24 [INFO]: Using the given device: cuda:0
2024-06-04 03:45:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_3/20240604_T034524
2024-06-04 03:45:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_3/20240604_T034524/tensorboard
2024-06-04 03:45:25 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-04 03:45:35 [INFO]: Epoch 001 - training loss: 0.8645, validation loss: 0.3407
2024-06-04 03:45:45 [INFO]: Epoch 002 - training loss: 0.6765, validation loss: 0.2907
2024-06-04 03:45:54 [INFO]: Epoch 003 - training loss: 0.5963, validation loss: 0.2604
2024-06-04 03:46:04 [INFO]: Epoch 004 - training loss: 0.5496, validation loss: 0.2403
2024-06-04 03:46:14 [INFO]: Epoch 005 - training loss: 0.5243, validation loss: 0.2271
2024-06-04 03:46:23 [INFO]: Epoch 006 - training loss: 0.5023, validation loss: 0.2164
2024-06-04 03:46:33 [INFO]: Epoch 007 - training loss: 0.4883, validation loss: 0.2075
2024-06-04 03:46:43 [INFO]: Epoch 008 - training loss: 0.4773, validation loss: 0.2004
2024-06-04 03:46:53 [INFO]: Epoch 009 - training loss: 0.4647, validation loss: 0.1936
2024-06-04 03:47:02 [INFO]: Epoch 010 - training loss: 0.4577, validation loss: 0.1871
2024-06-04 03:47:11 [INFO]: Epoch 011 - training loss: 0.4502, validation loss: 0.1840
2024-06-04 03:47:21 [INFO]: Epoch 012 - training loss: 0.4447, validation loss: 0.1789
2024-06-04 03:47:31 [INFO]: Epoch 013 - training loss: 0.4399, validation loss: 0.1751
2024-06-04 03:47:41 [INFO]: Epoch 014 - training loss: 0.4346, validation loss: 0.1742
2024-06-04 03:47:51 [INFO]: Epoch 015 - training loss: 0.4309, validation loss: 0.1703
2024-06-04 03:48:00 [INFO]: Epoch 016 - training loss: 0.4265, validation loss: 0.1691
2024-06-04 03:48:10 [INFO]: Epoch 017 - training loss: 0.4234, validation loss: 0.1662
2024-06-04 03:48:19 [INFO]: Epoch 018 - training loss: 0.4204, validation loss: 0.1648
2024-06-04 03:48:29 [INFO]: Epoch 019 - training loss: 0.4178, validation loss: 0.1630
2024-06-04 03:48:39 [INFO]: Epoch 020 - training loss: 0.4163, validation loss: 0.1634
2024-06-04 03:48:49 [INFO]: Epoch 021 - training loss: 0.4127, validation loss: 0.1614
2024-06-04 03:48:59 [INFO]: Epoch 022 - training loss: 0.4111, validation loss: 0.1599
2024-06-04 03:49:08 [INFO]: Epoch 023 - training loss: 0.4086, validation loss: 0.1592
2024-06-04 03:49:18 [INFO]: Epoch 024 - training loss: 0.4066, validation loss: 0.1578
2024-06-04 03:49:28 [INFO]: Epoch 025 - training loss: 0.4059, validation loss: 0.1568
2024-06-04 03:49:37 [INFO]: Epoch 026 - training loss: 0.4047, validation loss: 0.1566
2024-06-04 03:49:47 [INFO]: Epoch 027 - training loss: 0.4030, validation loss: 0.1549
2024-06-04 03:49:57 [INFO]: Epoch 028 - training loss: 0.4006, validation loss: 0.1543
2024-06-04 03:50:07 [INFO]: Epoch 029 - training loss: 0.3998, validation loss: 0.1554
2024-06-04 03:50:17 [INFO]: Epoch 030 - training loss: 0.3982, validation loss: 0.1544
2024-06-04 03:50:27 [INFO]: Epoch 031 - training loss: 0.3977, validation loss: 0.1544
2024-06-04 03:50:36 [INFO]: Epoch 032 - training loss: 0.3972, validation loss: 0.1525
2024-06-04 03:50:46 [INFO]: Epoch 033 - training loss: 0.3958, validation loss: 0.1520
2024-06-04 03:50:55 [INFO]: Epoch 034 - training loss: 0.3948, validation loss: 0.1517
2024-06-04 03:51:05 [INFO]: Epoch 035 - training loss: 0.3929, validation loss: 0.1508
2024-06-04 03:51:15 [INFO]: Epoch 036 - training loss: 0.3916, validation loss: 0.1515
2024-06-04 03:51:24 [INFO]: Epoch 037 - training loss: 0.3913, validation loss: 0.1509
2024-06-04 03:51:34 [INFO]: Epoch 038 - training loss: 0.3892, validation loss: 0.1500
2024-06-04 03:51:44 [INFO]: Epoch 039 - training loss: 0.3894, validation loss: 0.1509
2024-06-04 03:51:53 [INFO]: Epoch 040 - training loss: 0.3888, validation loss: 0.1491
2024-06-04 03:52:03 [INFO]: Epoch 041 - training loss: 0.3871, validation loss: 0.1499
2024-06-04 03:52:13 [INFO]: Epoch 042 - training loss: 0.3870, validation loss: 0.1488
2024-06-04 03:52:22 [INFO]: Epoch 043 - training loss: 0.3859, validation loss: 0.1478
2024-06-04 03:52:32 [INFO]: Epoch 044 - training loss: 0.3848, validation loss: 0.1487
2024-06-04 03:52:41 [INFO]: Epoch 045 - training loss: 0.3845, validation loss: 0.1473
2024-06-04 03:52:51 [INFO]: Epoch 046 - training loss: 0.3840, validation loss: 0.1468
2024-06-04 03:53:00 [INFO]: Epoch 047 - training loss: 0.3827, validation loss: 0.1482
2024-06-04 03:53:10 [INFO]: Epoch 048 - training loss: 0.3832, validation loss: 0.1471
2024-06-04 03:53:20 [INFO]: Epoch 049 - training loss: 0.3820, validation loss: 0.1469
2024-06-04 03:53:29 [INFO]: Epoch 050 - training loss: 0.3816, validation loss: 0.1452
2024-06-04 03:53:39 [INFO]: Epoch 051 - training loss: 0.3811, validation loss: 0.1463
2024-06-04 03:53:49 [INFO]: Epoch 052 - training loss: 0.3806, validation loss: 0.1437
2024-06-04 03:53:58 [INFO]: Epoch 053 - training loss: 0.3794, validation loss: 0.1439
2024-06-04 03:54:08 [INFO]: Epoch 054 - training loss: 0.3794, validation loss: 0.1429
2024-06-04 03:54:18 [INFO]: Epoch 055 - training loss: 0.3790, validation loss: 0.1442
2024-06-04 03:54:28 [INFO]: Epoch 056 - training loss: 0.3806, validation loss: 0.1440
2024-06-04 03:54:38 [INFO]: Epoch 057 - training loss: 0.3785, validation loss: 0.1423
2024-06-04 03:54:47 [INFO]: Epoch 058 - training loss: 0.3782, validation loss: 0.1435
2024-06-04 03:54:57 [INFO]: Epoch 059 - training loss: 0.3776, validation loss: 0.1422
2024-06-04 03:55:07 [INFO]: Epoch 060 - training loss: 0.3777, validation loss: 0.1428
2024-06-04 03:55:17 [INFO]: Epoch 061 - training loss: 0.3763, validation loss: 0.1421
2024-06-04 03:55:26 [INFO]: Epoch 062 - training loss: 0.3751, validation loss: 0.1431
2024-06-04 03:55:36 [INFO]: Epoch 063 - training loss: 0.3750, validation loss: 0.1429
2024-06-04 03:55:46 [INFO]: Epoch 064 - training loss: 0.3737, validation loss: 0.1426
2024-06-04 03:55:56 [INFO]: Epoch 065 - training loss: 0.3734, validation loss: 0.1423
2024-06-04 03:56:06 [INFO]: Epoch 066 - training loss: 0.3748, validation loss: 0.1424
2024-06-04 03:56:15 [INFO]: Epoch 067 - training loss: 0.3742, validation loss: 0.1425
2024-06-04 03:56:25 [INFO]: Epoch 068 - training loss: 0.3738, validation loss: 0.1435
2024-06-04 03:56:35 [INFO]: Epoch 069 - training loss: 0.3736, validation loss: 0.1409
2024-06-04 03:56:45 [INFO]: Epoch 070 - training loss: 0.3741, validation loss: 0.1409
2024-06-04 03:56:54 [INFO]: Epoch 071 - training loss: 0.3730, validation loss: 0.1406
2024-06-04 03:57:04 [INFO]: Epoch 072 - training loss: 0.3724, validation loss: 0.1407
2024-06-04 03:57:13 [INFO]: Epoch 073 - training loss: 0.3718, validation loss: 0.1406
2024-06-04 03:57:23 [INFO]: Epoch 074 - training loss: 0.3723, validation loss: 0.1400
2024-06-04 03:57:33 [INFO]: Epoch 075 - training loss: 0.3706, validation loss: 0.1404
2024-06-04 03:57:42 [INFO]: Epoch 076 - training loss: 0.3706, validation loss: 0.1402
2024-06-04 03:57:52 [INFO]: Epoch 077 - training loss: 0.3710, validation loss: 0.1399
2024-06-04 03:58:02 [INFO]: Epoch 078 - training loss: 0.3703, validation loss: 0.1390
2024-06-04 03:58:12 [INFO]: Epoch 079 - training loss: 0.3706, validation loss: 0.1399
2024-06-04 03:58:22 [INFO]: Epoch 080 - training loss: 0.3694, validation loss: 0.1398
2024-06-04 03:58:32 [INFO]: Epoch 081 - training loss: 0.3693, validation loss: 0.1393
2024-06-04 03:58:41 [INFO]: Epoch 082 - training loss: 0.3697, validation loss: 0.1385
2024-06-04 03:58:51 [INFO]: Epoch 083 - training loss: 0.3690, validation loss: 0.1381
2024-06-04 03:59:01 [INFO]: Epoch 084 - training loss: 0.3693, validation loss: 0.1383
2024-06-04 03:59:11 [INFO]: Epoch 085 - training loss: 0.3682, validation loss: 0.1385
2024-06-04 03:59:20 [INFO]: Epoch 086 - training loss: 0.3684, validation loss: 0.1395
2024-06-04 03:59:30 [INFO]: Epoch 087 - training loss: 0.3670, validation loss: 0.1391
2024-06-04 03:59:40 [INFO]: Epoch 088 - training loss: 0.3677, validation loss: 0.1382
2024-06-04 03:59:49 [INFO]: Epoch 089 - training loss: 0.3669, validation loss: 0.1382
2024-06-04 03:59:59 [INFO]: Epoch 090 - training loss: 0.3677, validation loss: 0.1387
2024-06-04 04:00:08 [INFO]: Epoch 091 - training loss: 0.3664, validation loss: 0.1387
2024-06-04 04:00:18 [INFO]: Epoch 092 - training loss: 0.3660, validation loss: 0.1399
2024-06-04 04:00:28 [INFO]: Epoch 093 - training loss: 0.3670, validation loss: 0.1394
2024-06-04 04:00:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:00:28 [INFO]: Finished training. The best model is from epoch#83.
2024-06-04 04:00:28 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_3/20240604_T034524/ETSformer.pypots
2024-06-04 04:00:36 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_3/imputation.pkl
2024-06-04 04:00:36 [INFO]: Round3 - ETSformer on BeijingAir: MAE=0.2275, MSE=0.1814, MRE=0.3438
2024-06-04 04:00:36 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:00:36 [INFO]: Using the given device: cuda:0
2024-06-04 04:00:36 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_4/20240604_T040036
2024-06-04 04:00:36 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_4/20240604_T040036/tensorboard
2024-06-04 04:00:36 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-04 04:00:45 [INFO]: Epoch 001 - training loss: 0.8556, validation loss: 0.3491
2024-06-04 04:00:55 [INFO]: Epoch 002 - training loss: 0.6702, validation loss: 0.2943
2024-06-04 04:01:04 [INFO]: Epoch 003 - training loss: 0.5862, validation loss: 0.2629
2024-06-04 04:01:14 [INFO]: Epoch 004 - training loss: 0.5420, validation loss: 0.2419
2024-06-04 04:01:24 [INFO]: Epoch 005 - training loss: 0.5157, validation loss: 0.2293
2024-06-04 04:01:34 [INFO]: Epoch 006 - training loss: 0.4961, validation loss: 0.2173
2024-06-04 04:01:44 [INFO]: Epoch 007 - training loss: 0.4825, validation loss: 0.2080
2024-06-04 04:01:53 [INFO]: Epoch 008 - training loss: 0.4694, validation loss: 0.1992
2024-06-04 04:02:03 [INFO]: Epoch 009 - training loss: 0.4602, validation loss: 0.1953
2024-06-04 04:02:12 [INFO]: Epoch 010 - training loss: 0.4545, validation loss: 0.1886
2024-06-04 04:02:22 [INFO]: Epoch 011 - training loss: 0.4457, validation loss: 0.1818
2024-06-04 04:02:32 [INFO]: Epoch 012 - training loss: 0.4411, validation loss: 0.1797
2024-06-04 04:02:41 [INFO]: Epoch 013 - training loss: 0.4348, validation loss: 0.1748
2024-06-04 04:02:51 [INFO]: Epoch 014 - training loss: 0.4303, validation loss: 0.1714
2024-06-04 04:03:01 [INFO]: Epoch 015 - training loss: 0.4272, validation loss: 0.1698
2024-06-04 04:03:11 [INFO]: Epoch 016 - training loss: 0.4227, validation loss: 0.1666
2024-06-04 04:03:20 [INFO]: Epoch 017 - training loss: 0.4196, validation loss: 0.1648
2024-06-04 04:03:30 [INFO]: Epoch 018 - training loss: 0.4176, validation loss: 0.1632
2024-06-04 04:03:40 [INFO]: Epoch 019 - training loss: 0.4156, validation loss: 0.1620
2024-06-04 04:03:50 [INFO]: Epoch 020 - training loss: 0.4126, validation loss: 0.1596
2024-06-04 04:03:59 [INFO]: Epoch 021 - training loss: 0.4090, validation loss: 0.1583
2024-06-04 04:04:09 [INFO]: Epoch 022 - training loss: 0.4078, validation loss: 0.1572
2024-06-04 04:04:19 [INFO]: Epoch 023 - training loss: 0.4067, validation loss: 0.1571
2024-06-04 04:04:29 [INFO]: Epoch 024 - training loss: 0.4052, validation loss: 0.1563
2024-06-04 04:04:38 [INFO]: Epoch 025 - training loss: 0.4019, validation loss: 0.1548
2024-06-04 04:04:48 [INFO]: Epoch 026 - training loss: 0.4014, validation loss: 0.1542
2024-06-04 04:04:58 [INFO]: Epoch 027 - training loss: 0.3991, validation loss: 0.1531
2024-06-04 04:05:07 [INFO]: Epoch 028 - training loss: 0.3999, validation loss: 0.1534
2024-06-04 04:05:17 [INFO]: Epoch 029 - training loss: 0.3970, validation loss: 0.1525
2024-06-04 04:05:26 [INFO]: Epoch 030 - training loss: 0.3952, validation loss: 0.1506
2024-06-04 04:05:36 [INFO]: Epoch 031 - training loss: 0.3948, validation loss: 0.1524
2024-06-04 04:05:45 [INFO]: Epoch 032 - training loss: 0.3942, validation loss: 0.1493
2024-06-04 04:05:55 [INFO]: Epoch 033 - training loss: 0.3917, validation loss: 0.1504
2024-06-04 04:06:04 [INFO]: Epoch 034 - training loss: 0.3909, validation loss: 0.1492
2024-06-04 04:06:14 [INFO]: Epoch 035 - training loss: 0.3911, validation loss: 0.1501
2024-06-04 04:06:24 [INFO]: Epoch 036 - training loss: 0.3890, validation loss: 0.1478
2024-06-04 04:06:33 [INFO]: Epoch 037 - training loss: 0.3882, validation loss: 0.1499
2024-06-04 04:06:43 [INFO]: Epoch 038 - training loss: 0.3874, validation loss: 0.1479
2024-06-04 04:06:53 [INFO]: Epoch 039 - training loss: 0.3865, validation loss: 0.1467
2024-06-04 04:07:02 [INFO]: Epoch 040 - training loss: 0.3858, validation loss: 0.1474
2024-06-04 04:07:12 [INFO]: Epoch 041 - training loss: 0.3855, validation loss: 0.1469
2024-06-04 04:07:22 [INFO]: Epoch 042 - training loss: 0.3843, validation loss: 0.1453
2024-06-04 04:07:32 [INFO]: Epoch 043 - training loss: 0.3857, validation loss: 0.1461
2024-06-04 04:07:42 [INFO]: Epoch 044 - training loss: 0.3844, validation loss: 0.1461
2024-06-04 04:07:51 [INFO]: Epoch 045 - training loss: 0.3829, validation loss: 0.1456
2024-06-04 04:08:01 [INFO]: Epoch 046 - training loss: 0.3821, validation loss: 0.1448
2024-06-04 04:08:11 [INFO]: Epoch 047 - training loss: 0.3802, validation loss: 0.1452
2024-06-04 04:08:20 [INFO]: Epoch 048 - training loss: 0.3798, validation loss: 0.1453
2024-06-04 04:08:30 [INFO]: Epoch 049 - training loss: 0.3813, validation loss: 0.1447
2024-06-04 04:08:40 [INFO]: Epoch 050 - training loss: 0.3798, validation loss: 0.1448
2024-06-04 04:08:50 [INFO]: Epoch 051 - training loss: 0.3793, validation loss: 0.1444
2024-06-04 04:08:59 [INFO]: Epoch 052 - training loss: 0.3788, validation loss: 0.1430
2024-06-04 04:09:09 [INFO]: Epoch 053 - training loss: 0.3786, validation loss: 0.1434
2024-06-04 04:09:19 [INFO]: Epoch 054 - training loss: 0.3771, validation loss: 0.1429
2024-06-04 04:09:29 [INFO]: Epoch 055 - training loss: 0.3763, validation loss: 0.1427
2024-06-04 04:09:38 [INFO]: Epoch 056 - training loss: 0.3779, validation loss: 0.1419
2024-06-04 04:09:48 [INFO]: Epoch 057 - training loss: 0.3768, validation loss: 0.1437
2024-06-04 04:09:58 [INFO]: Epoch 058 - training loss: 0.3756, validation loss: 0.1425
2024-06-04 04:10:08 [INFO]: Epoch 059 - training loss: 0.3751, validation loss: 0.1423
2024-06-04 04:10:17 [INFO]: Epoch 060 - training loss: 0.3768, validation loss: 0.1424
2024-06-04 04:10:27 [INFO]: Epoch 061 - training loss: 0.3752, validation loss: 0.1425
2024-06-04 04:10:37 [INFO]: Epoch 062 - training loss: 0.3752, validation loss: 0.1424
2024-06-04 04:10:47 [INFO]: Epoch 063 - training loss: 0.3748, validation loss: 0.1413
2024-06-04 04:10:56 [INFO]: Epoch 064 - training loss: 0.3742, validation loss: 0.1416
2024-06-04 04:11:06 [INFO]: Epoch 065 - training loss: 0.3726, validation loss: 0.1423
2024-06-04 04:11:16 [INFO]: Epoch 066 - training loss: 0.3732, validation loss: 0.1416
2024-06-04 04:11:26 [INFO]: Epoch 067 - training loss: 0.3724, validation loss: 0.1411
2024-06-04 04:11:36 [INFO]: Epoch 068 - training loss: 0.3716, validation loss: 0.1420
2024-06-04 04:11:46 [INFO]: Epoch 069 - training loss: 0.3728, validation loss: 0.1411
2024-06-04 04:11:56 [INFO]: Epoch 070 - training loss: 0.3720, validation loss: 0.1411
2024-06-04 04:12:05 [INFO]: Epoch 071 - training loss: 0.3715, validation loss: 0.1393
2024-06-04 04:12:15 [INFO]: Epoch 072 - training loss: 0.3707, validation loss: 0.1408
2024-06-04 04:12:25 [INFO]: Epoch 073 - training loss: 0.3715, validation loss: 0.1402
2024-06-04 04:12:34 [INFO]: Epoch 074 - training loss: 0.3705, validation loss: 0.1402
2024-06-04 04:12:44 [INFO]: Epoch 075 - training loss: 0.3699, validation loss: 0.1400
2024-06-04 04:12:54 [INFO]: Epoch 076 - training loss: 0.3703, validation loss: 0.1400
2024-06-04 04:13:03 [INFO]: Epoch 077 - training loss: 0.3699, validation loss: 0.1391
2024-06-04 04:13:13 [INFO]: Epoch 078 - training loss: 0.3689, validation loss: 0.1397
2024-06-04 04:13:23 [INFO]: Epoch 079 - training loss: 0.3683, validation loss: 0.1388
2024-06-04 04:13:32 [INFO]: Epoch 080 - training loss: 0.3683, validation loss: 0.1385
2024-06-04 04:13:42 [INFO]: Epoch 081 - training loss: 0.3689, validation loss: 0.1390
2024-06-04 04:13:52 [INFO]: Epoch 082 - training loss: 0.3680, validation loss: 0.1380
2024-06-04 04:14:01 [INFO]: Epoch 083 - training loss: 0.3676, validation loss: 0.1385
2024-06-04 04:14:11 [INFO]: Epoch 084 - training loss: 0.3672, validation loss: 0.1387
2024-06-04 04:14:21 [INFO]: Epoch 085 - training loss: 0.3688, validation loss: 0.1370
2024-06-04 04:14:31 [INFO]: Epoch 086 - training loss: 0.3664, validation loss: 0.1379
2024-06-04 04:14:40 [INFO]: Epoch 087 - training loss: 0.3663, validation loss: 0.1374
2024-06-04 04:14:50 [INFO]: Epoch 088 - training loss: 0.3647, validation loss: 0.1371
2024-06-04 04:15:00 [INFO]: Epoch 089 - training loss: 0.3661, validation loss: 0.1375
2024-06-04 04:15:09 [INFO]: Epoch 090 - training loss: 0.3659, validation loss: 0.1378
2024-06-04 04:15:19 [INFO]: Epoch 091 - training loss: 0.3660, validation loss: 0.1380
2024-06-04 04:15:29 [INFO]: Epoch 092 - training loss: 0.3650, validation loss: 0.1370
2024-06-04 04:15:39 [INFO]: Epoch 093 - training loss: 0.3659, validation loss: 0.1372
2024-06-04 04:15:48 [INFO]: Epoch 094 - training loss: 0.3643, validation loss: 0.1376
2024-06-04 04:15:58 [INFO]: Epoch 095 - training loss: 0.3651, validation loss: 0.1363
2024-06-04 04:16:08 [INFO]: Epoch 096 - training loss: 0.3645, validation loss: 0.1353
2024-06-04 04:16:18 [INFO]: Epoch 097 - training loss: 0.3644, validation loss: 0.1361
2024-06-04 04:16:28 [INFO]: Epoch 098 - training loss: 0.3643, validation loss: 0.1365
2024-06-04 04:16:37 [INFO]: Epoch 099 - training loss: 0.3648, validation loss: 0.1350
2024-06-04 04:16:46 [INFO]: Epoch 100 - training loss: 0.3635, validation loss: 0.1346
2024-06-04 04:16:46 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 04:16:47 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_4/20240604_T040036/ETSformer.pypots
2024-06-04 04:16:54 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/ETSformer_BeijingAir/round_4/imputation.pkl
2024-06-04 04:16:54 [INFO]: Round4 - ETSformer on BeijingAir: MAE=0.2232, MSE=0.1787, MRE=0.3372
2024-06-04 04:16:54 [INFO]: Done! Final results:
Averaged ETSformer (7,928,510 params) on BeijingAir: MAE=0.1868 ± 0.0023223464884059323, MSE=0.1300 ± 0.0015801200303786028, MRE=0.2484 ± 0.0030888833849265925, average inference time=1.79