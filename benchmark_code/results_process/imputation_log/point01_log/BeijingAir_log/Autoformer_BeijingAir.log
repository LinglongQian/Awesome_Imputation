2024-06-04 02:44:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:45 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_0/20240604_T024445/tensorboard
2024-06-04 02:44:47 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-04 02:44:57 [INFO]: Epoch 001 - training loss: 1.6978, validation loss: 1.1679
2024-06-04 02:45:05 [INFO]: Epoch 002 - training loss: 1.6405, validation loss: 1.0018
2024-06-04 02:45:14 [INFO]: Epoch 003 - training loss: 1.5849, validation loss: 0.9714
2024-06-04 02:45:22 [INFO]: Epoch 004 - training loss: 1.5441, validation loss: 0.9898
2024-06-04 02:45:31 [INFO]: Epoch 005 - training loss: 1.5212, validation loss: 0.9984
2024-06-04 02:45:40 [INFO]: Epoch 006 - training loss: 1.5068, validation loss: 0.9980
2024-06-04 02:45:48 [INFO]: Epoch 007 - training loss: 1.4995, validation loss: 0.9874
2024-06-04 02:45:56 [INFO]: Epoch 008 - training loss: 1.4876, validation loss: 0.9643
2024-06-04 02:46:04 [INFO]: Epoch 009 - training loss: 1.4794, validation loss: 0.9260
2024-06-04 02:46:13 [INFO]: Epoch 010 - training loss: 1.4704, validation loss: 0.8656
2024-06-04 02:46:22 [INFO]: Epoch 011 - training loss: 1.4597, validation loss: 0.7985
2024-06-04 02:46:30 [INFO]: Epoch 012 - training loss: 1.4457, validation loss: 0.7337
2024-06-04 02:46:39 [INFO]: Epoch 013 - training loss: 1.4362, validation loss: 0.6731
2024-06-04 02:46:47 [INFO]: Epoch 014 - training loss: 1.4248, validation loss: 0.6131
2024-06-04 02:46:56 [INFO]: Epoch 015 - training loss: 1.4109, validation loss: 0.5693
2024-06-04 02:47:05 [INFO]: Epoch 016 - training loss: 1.4008, validation loss: 0.5283
2024-06-04 02:47:13 [INFO]: Epoch 017 - training loss: 1.3906, validation loss: 0.5024
2024-06-04 02:47:22 [INFO]: Epoch 018 - training loss: 1.3777, validation loss: 0.4716
2024-06-04 02:47:30 [INFO]: Epoch 019 - training loss: 1.3676, validation loss: 0.4550
2024-06-04 02:47:38 [INFO]: Epoch 020 - training loss: 1.3578, validation loss: 0.4310
2024-06-04 02:47:46 [INFO]: Epoch 021 - training loss: 1.3509, validation loss: 0.4129
2024-06-04 02:47:55 [INFO]: Epoch 022 - training loss: 1.3436, validation loss: 0.4037
2024-06-04 02:48:04 [INFO]: Epoch 023 - training loss: 1.3386, validation loss: 0.3933
2024-06-04 02:48:13 [INFO]: Epoch 024 - training loss: 1.3337, validation loss: 0.3806
2024-06-04 02:48:21 [INFO]: Epoch 025 - training loss: 1.3260, validation loss: 0.3703
2024-06-04 02:48:31 [INFO]: Epoch 026 - training loss: 1.3232, validation loss: 0.3648
2024-06-04 02:48:39 [INFO]: Epoch 027 - training loss: 1.3167, validation loss: 0.3560
2024-06-04 02:48:47 [INFO]: Epoch 028 - training loss: 1.3139, validation loss: 0.3499
2024-06-04 02:48:55 [INFO]: Epoch 029 - training loss: 1.3132, validation loss: 0.3468
2024-06-04 02:49:04 [INFO]: Epoch 030 - training loss: 1.3070, validation loss: 0.3415
2024-06-04 02:49:12 [INFO]: Epoch 031 - training loss: 1.3013, validation loss: 0.3375
2024-06-04 02:49:20 [INFO]: Epoch 032 - training loss: 1.3008, validation loss: 0.3351
2024-06-04 02:49:29 [INFO]: Epoch 033 - training loss: 1.2972, validation loss: 0.3326
2024-06-04 02:49:38 [INFO]: Epoch 034 - training loss: 1.2957, validation loss: 0.3282
2024-06-04 02:49:46 [INFO]: Epoch 035 - training loss: 1.2940, validation loss: 0.3274
2024-06-04 02:49:55 [INFO]: Epoch 036 - training loss: 1.2896, validation loss: 0.3249
2024-06-04 02:50:03 [INFO]: Epoch 037 - training loss: 1.2881, validation loss: 0.3245
2024-06-04 02:50:12 [INFO]: Epoch 038 - training loss: 1.2875, validation loss: 0.3217
2024-06-04 02:50:20 [INFO]: Epoch 039 - training loss: 1.2880, validation loss: 0.3213
2024-06-04 02:50:28 [INFO]: Epoch 040 - training loss: 1.2832, validation loss: 0.3198
2024-06-04 02:50:37 [INFO]: Epoch 041 - training loss: 1.2804, validation loss: 0.3188
2024-06-04 02:50:45 [INFO]: Epoch 042 - training loss: 1.2786, validation loss: 0.3199
2024-06-04 02:50:54 [INFO]: Epoch 043 - training loss: 1.2781, validation loss: 0.3184
2024-06-04 02:51:02 [INFO]: Epoch 044 - training loss: 1.2759, validation loss: 0.3163
2024-06-04 02:51:11 [INFO]: Epoch 045 - training loss: 1.2756, validation loss: 0.3194
2024-06-04 02:51:19 [INFO]: Epoch 046 - training loss: 1.2730, validation loss: 0.3153
2024-06-04 02:51:28 [INFO]: Epoch 047 - training loss: 1.2731, validation loss: 0.3151
2024-06-04 02:51:36 [INFO]: Epoch 048 - training loss: 1.2688, validation loss: 0.3156
2024-06-04 02:51:45 [INFO]: Epoch 049 - training loss: 1.2706, validation loss: 0.3153
2024-06-04 02:51:54 [INFO]: Epoch 050 - training loss: 1.2689, validation loss: 0.3147
2024-06-04 02:52:02 [INFO]: Epoch 051 - training loss: 1.2695, validation loss: 0.3143
2024-06-04 02:52:11 [INFO]: Epoch 052 - training loss: 1.2674, validation loss: 0.3168
2024-06-04 02:52:20 [INFO]: Epoch 053 - training loss: 1.2656, validation loss: 0.3152
2024-06-04 02:52:29 [INFO]: Epoch 054 - training loss: 1.2645, validation loss: 0.3170
2024-06-04 02:52:37 [INFO]: Epoch 055 - training loss: 1.2631, validation loss: 0.3169
2024-06-04 02:52:46 [INFO]: Epoch 056 - training loss: 1.2628, validation loss: 0.3173
2024-06-04 02:52:55 [INFO]: Epoch 057 - training loss: 1.2602, validation loss: 0.3134
2024-06-04 02:53:03 [INFO]: Epoch 058 - training loss: 1.2594, validation loss: 0.3181
2024-06-04 02:53:11 [INFO]: Epoch 059 - training loss: 1.2617, validation loss: 0.3149
2024-06-04 02:53:19 [INFO]: Epoch 060 - training loss: 1.2587, validation loss: 0.3206
2024-06-04 02:53:27 [INFO]: Epoch 061 - training loss: 1.2573, validation loss: 0.3220
2024-06-04 02:53:36 [INFO]: Epoch 062 - training loss: 1.2574, validation loss: 0.3185
2024-06-04 02:53:45 [INFO]: Epoch 063 - training loss: 1.2583, validation loss: 0.3169
2024-06-04 02:53:54 [INFO]: Epoch 064 - training loss: 1.2552, validation loss: 0.3187
2024-06-04 02:54:02 [INFO]: Epoch 065 - training loss: 1.2552, validation loss: 0.3216
2024-06-04 02:54:11 [INFO]: Epoch 066 - training loss: 1.2569, validation loss: 0.3161
2024-06-04 02:54:19 [INFO]: Epoch 067 - training loss: 1.2570, validation loss: 0.3176
2024-06-04 02:54:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:54:19 [INFO]: Finished training. The best model is from epoch#57.
2024-06-04 02:54:19 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_0/20240604_T024445/Autoformer.pypots
2024-06-04 02:54:21 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_0/imputation.pkl
2024-06-04 02:54:21 [INFO]: Round0 - Autoformer on BeijingAir: MAE=0.2700, MSE=0.2763, MRE=0.4080
2024-06-04 02:54:21 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 02:54:21 [INFO]: Using the given device: cuda:0
2024-06-04 02:54:21 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_1/20240604_T025421
2024-06-04 02:54:21 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_1/20240604_T025421/tensorboard
2024-06-04 02:54:21 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-04 02:54:29 [INFO]: Epoch 001 - training loss: 1.7020, validation loss: 1.1916
2024-06-04 02:54:37 [INFO]: Epoch 002 - training loss: 1.6448, validation loss: 1.0169
2024-06-04 02:54:46 [INFO]: Epoch 003 - training loss: 1.5898, validation loss: 0.9672
2024-06-04 02:54:54 [INFO]: Epoch 004 - training loss: 1.5472, validation loss: 0.9797
2024-06-04 02:55:03 [INFO]: Epoch 005 - training loss: 1.5242, validation loss: 0.9919
2024-06-04 02:55:12 [INFO]: Epoch 006 - training loss: 1.5053, validation loss: 0.9918
2024-06-04 02:55:20 [INFO]: Epoch 007 - training loss: 1.4967, validation loss: 0.9813
2024-06-04 02:55:28 [INFO]: Epoch 008 - training loss: 1.4870, validation loss: 0.9600
2024-06-04 02:55:36 [INFO]: Epoch 009 - training loss: 1.4770, validation loss: 0.9244
2024-06-04 02:55:45 [INFO]: Epoch 010 - training loss: 1.4682, validation loss: 0.8660
2024-06-04 02:55:54 [INFO]: Epoch 011 - training loss: 1.4570, validation loss: 0.8034
2024-06-04 02:56:02 [INFO]: Epoch 012 - training loss: 1.4461, validation loss: 0.7389
2024-06-04 02:56:11 [INFO]: Epoch 013 - training loss: 1.4337, validation loss: 0.6802
2024-06-04 02:56:19 [INFO]: Epoch 014 - training loss: 1.4201, validation loss: 0.6285
2024-06-04 02:56:28 [INFO]: Epoch 015 - training loss: 1.4077, validation loss: 0.5710
2024-06-04 02:56:37 [INFO]: Epoch 016 - training loss: 1.3973, validation loss: 0.5294
2024-06-04 02:56:45 [INFO]: Epoch 017 - training loss: 1.3875, validation loss: 0.5066
2024-06-04 02:56:54 [INFO]: Epoch 018 - training loss: 1.3772, validation loss: 0.4689
2024-06-04 02:57:03 [INFO]: Epoch 019 - training loss: 1.3684, validation loss: 0.4468
2024-06-04 02:57:11 [INFO]: Epoch 020 - training loss: 1.3603, validation loss: 0.4267
2024-06-04 02:57:20 [INFO]: Epoch 021 - training loss: 1.3507, validation loss: 0.4113
2024-06-04 02:57:29 [INFO]: Epoch 022 - training loss: 1.3455, validation loss: 0.3985
2024-06-04 02:57:38 [INFO]: Epoch 023 - training loss: 1.3395, validation loss: 0.3796
2024-06-04 02:57:46 [INFO]: Epoch 024 - training loss: 1.3316, validation loss: 0.3715
2024-06-04 02:57:55 [INFO]: Epoch 025 - training loss: 1.3262, validation loss: 0.3650
2024-06-04 02:58:03 [INFO]: Epoch 026 - training loss: 1.3225, validation loss: 0.3533
2024-06-04 02:58:12 [INFO]: Epoch 027 - training loss: 1.3146, validation loss: 0.3483
2024-06-04 02:58:20 [INFO]: Epoch 028 - training loss: 1.3161, validation loss: 0.3433
2024-06-04 02:58:28 [INFO]: Epoch 029 - training loss: 1.3107, validation loss: 0.3423
2024-06-04 02:58:37 [INFO]: Epoch 030 - training loss: 1.3094, validation loss: 0.3345
2024-06-04 02:58:46 [INFO]: Epoch 031 - training loss: 1.3025, validation loss: 0.3307
2024-06-04 02:58:54 [INFO]: Epoch 032 - training loss: 1.2985, validation loss: 0.3288
2024-06-04 02:59:02 [INFO]: Epoch 033 - training loss: 1.2975, validation loss: 0.3275
2024-06-04 02:59:10 [INFO]: Epoch 034 - training loss: 1.2945, validation loss: 0.3247
2024-06-04 02:59:18 [INFO]: Epoch 035 - training loss: 1.2937, validation loss: 0.3225
2024-06-04 02:59:27 [INFO]: Epoch 036 - training loss: 1.2912, validation loss: 0.3205
2024-06-04 02:59:35 [INFO]: Epoch 037 - training loss: 1.2905, validation loss: 0.3199
2024-06-04 02:59:44 [INFO]: Epoch 038 - training loss: 1.2882, validation loss: 0.3190
2024-06-04 02:59:53 [INFO]: Epoch 039 - training loss: 1.2857, validation loss: 0.3173
2024-06-04 03:00:01 [INFO]: Epoch 040 - training loss: 1.2855, validation loss: 0.3162
2024-06-04 03:00:10 [INFO]: Epoch 041 - training loss: 1.2816, validation loss: 0.3153
2024-06-04 03:00:19 [INFO]: Epoch 042 - training loss: 1.2808, validation loss: 0.3139
2024-06-04 03:00:27 [INFO]: Epoch 043 - training loss: 1.2792, validation loss: 0.3140
2024-06-04 03:00:36 [INFO]: Epoch 044 - training loss: 1.2785, validation loss: 0.3130
2024-06-04 03:00:45 [INFO]: Epoch 045 - training loss: 1.2789, validation loss: 0.3133
2024-06-04 03:00:53 [INFO]: Epoch 046 - training loss: 1.2732, validation loss: 0.3127
2024-06-04 03:01:02 [INFO]: Epoch 047 - training loss: 1.2749, validation loss: 0.3135
2024-06-04 03:01:10 [INFO]: Epoch 048 - training loss: 1.2723, validation loss: 0.3125
2024-06-04 03:01:19 [INFO]: Epoch 049 - training loss: 1.2700, validation loss: 0.3139
2024-06-04 03:01:27 [INFO]: Epoch 050 - training loss: 1.2714, validation loss: 0.3113
2024-06-04 03:01:35 [INFO]: Epoch 051 - training loss: 1.2675, validation loss: 0.3129
2024-06-04 03:01:43 [INFO]: Epoch 052 - training loss: 1.2675, validation loss: 0.3115
2024-06-04 03:01:51 [INFO]: Epoch 053 - training loss: 1.2658, validation loss: 0.3137
2024-06-04 03:01:58 [INFO]: Epoch 054 - training loss: 1.2660, validation loss: 0.3127
2024-06-04 03:02:04 [INFO]: Epoch 055 - training loss: 1.2652, validation loss: 0.3123
2024-06-04 03:02:11 [INFO]: Epoch 056 - training loss: 1.2635, validation loss: 0.3115
2024-06-04 03:02:17 [INFO]: Epoch 057 - training loss: 1.2610, validation loss: 0.3116
2024-06-04 03:02:22 [INFO]: Epoch 058 - training loss: 1.2609, validation loss: 0.3140
2024-06-04 03:02:29 [INFO]: Epoch 059 - training loss: 1.2595, validation loss: 0.3124
2024-06-04 03:02:35 [INFO]: Epoch 060 - training loss: 1.2597, validation loss: 0.3148
2024-06-04 03:02:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:02:35 [INFO]: Finished training. The best model is from epoch#50.
2024-06-04 03:02:35 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_1/20240604_T025421/Autoformer.pypots
2024-06-04 03:02:36 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_1/imputation.pkl
2024-06-04 03:02:36 [INFO]: Round1 - Autoformer on BeijingAir: MAE=0.2679, MSE=0.2738, MRE=0.4048
2024-06-04 03:02:36 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:02:36 [INFO]: Using the given device: cuda:0
2024-06-04 03:02:36 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_2/20240604_T030236
2024-06-04 03:02:36 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_2/20240604_T030236/tensorboard
2024-06-04 03:02:36 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-04 03:02:42 [INFO]: Epoch 001 - training loss: 1.7022, validation loss: 1.1702
2024-06-04 03:02:49 [INFO]: Epoch 002 - training loss: 1.6444, validation loss: 1.0056
2024-06-04 03:02:55 [INFO]: Epoch 003 - training loss: 1.5918, validation loss: 0.9692
2024-06-04 03:03:00 [INFO]: Epoch 004 - training loss: 1.5491, validation loss: 0.9865
2024-06-04 03:03:06 [INFO]: Epoch 005 - training loss: 1.5246, validation loss: 1.0011
2024-06-04 03:03:12 [INFO]: Epoch 006 - training loss: 1.5068, validation loss: 1.0043
2024-06-04 03:03:18 [INFO]: Epoch 007 - training loss: 1.4981, validation loss: 0.9960
2024-06-04 03:03:24 [INFO]: Epoch 008 - training loss: 1.4873, validation loss: 0.9766
2024-06-04 03:03:30 [INFO]: Epoch 009 - training loss: 1.4847, validation loss: 0.9454
2024-06-04 03:03:36 [INFO]: Epoch 010 - training loss: 1.4727, validation loss: 0.8926
2024-06-04 03:03:42 [INFO]: Epoch 011 - training loss: 1.4603, validation loss: 0.8307
2024-06-04 03:03:48 [INFO]: Epoch 012 - training loss: 1.4536, validation loss: 0.7592
2024-06-04 03:03:54 [INFO]: Epoch 013 - training loss: 1.4370, validation loss: 0.6952
2024-06-04 03:04:00 [INFO]: Epoch 014 - training loss: 1.4255, validation loss: 0.6423
2024-06-04 03:04:06 [INFO]: Epoch 015 - training loss: 1.4096, validation loss: 0.5897
2024-06-04 03:04:11 [INFO]: Epoch 016 - training loss: 1.3993, validation loss: 0.5469
2024-06-04 03:04:18 [INFO]: Epoch 017 - training loss: 1.3868, validation loss: 0.5128
2024-06-04 03:04:24 [INFO]: Epoch 018 - training loss: 1.3767, validation loss: 0.4740
2024-06-04 03:04:29 [INFO]: Epoch 019 - training loss: 1.3646, validation loss: 0.4455
2024-06-04 03:04:35 [INFO]: Epoch 020 - training loss: 1.3557, validation loss: 0.4331
2024-06-04 03:04:41 [INFO]: Epoch 021 - training loss: 1.3490, validation loss: 0.4140
2024-06-04 03:04:47 [INFO]: Epoch 022 - training loss: 1.3395, validation loss: 0.3926
2024-06-04 03:04:53 [INFO]: Epoch 023 - training loss: 1.3333, validation loss: 0.3806
2024-06-04 03:04:59 [INFO]: Epoch 024 - training loss: 1.3290, validation loss: 0.3677
2024-06-04 03:05:05 [INFO]: Epoch 025 - training loss: 1.3252, validation loss: 0.3581
2024-06-04 03:05:11 [INFO]: Epoch 026 - training loss: 1.3203, validation loss: 0.3486
2024-06-04 03:05:17 [INFO]: Epoch 027 - training loss: 1.3146, validation loss: 0.3411
2024-06-04 03:05:24 [INFO]: Epoch 028 - training loss: 1.3093, validation loss: 0.3370
2024-06-04 03:05:29 [INFO]: Epoch 029 - training loss: 1.3074, validation loss: 0.3287
2024-06-04 03:05:35 [INFO]: Epoch 030 - training loss: 1.3051, validation loss: 0.3271
2024-06-04 03:05:41 [INFO]: Epoch 031 - training loss: 1.3023, validation loss: 0.3215
2024-06-04 03:05:47 [INFO]: Epoch 032 - training loss: 1.3001, validation loss: 0.3189
2024-06-04 03:05:53 [INFO]: Epoch 033 - training loss: 1.2952, validation loss: 0.3154
2024-06-04 03:05:59 [INFO]: Epoch 034 - training loss: 1.2947, validation loss: 0.3122
2024-06-04 03:06:05 [INFO]: Epoch 035 - training loss: 1.2924, validation loss: 0.3108
2024-06-04 03:06:11 [INFO]: Epoch 036 - training loss: 1.2877, validation loss: 0.3100
2024-06-04 03:06:17 [INFO]: Epoch 037 - training loss: 1.2860, validation loss: 0.3061
2024-06-04 03:06:23 [INFO]: Epoch 038 - training loss: 1.2867, validation loss: 0.3044
2024-06-04 03:06:29 [INFO]: Epoch 039 - training loss: 1.2855, validation loss: 0.3036
2024-06-04 03:06:35 [INFO]: Epoch 040 - training loss: 1.2809, validation loss: 0.3023
2024-06-04 03:06:41 [INFO]: Epoch 041 - training loss: 1.2832, validation loss: 0.3014
2024-06-04 03:06:47 [INFO]: Epoch 042 - training loss: 1.2791, validation loss: 0.2998
2024-06-04 03:06:54 [INFO]: Epoch 043 - training loss: 1.2790, validation loss: 0.2989
2024-06-04 03:07:00 [INFO]: Epoch 044 - training loss: 1.2782, validation loss: 0.2982
2024-06-04 03:07:05 [INFO]: Epoch 045 - training loss: 1.2755, validation loss: 0.2976
2024-06-04 03:07:11 [INFO]: Epoch 046 - training loss: 1.2720, validation loss: 0.2977
2024-06-04 03:07:17 [INFO]: Epoch 047 - training loss: 1.2742, validation loss: 0.2963
2024-06-04 03:07:23 [INFO]: Epoch 048 - training loss: 1.2716, validation loss: 0.2960
2024-06-04 03:07:29 [INFO]: Epoch 049 - training loss: 1.2682, validation loss: 0.2954
2024-06-04 03:07:35 [INFO]: Epoch 050 - training loss: 1.2708, validation loss: 0.2956
2024-06-04 03:07:41 [INFO]: Epoch 051 - training loss: 1.2661, validation loss: 0.2957
2024-06-04 03:07:47 [INFO]: Epoch 052 - training loss: 1.2661, validation loss: 0.2943
2024-06-04 03:07:53 [INFO]: Epoch 053 - training loss: 1.2653, validation loss: 0.2949
2024-06-04 03:07:59 [INFO]: Epoch 054 - training loss: 1.2629, validation loss: 0.2923
2024-06-04 03:08:05 [INFO]: Epoch 055 - training loss: 1.2632, validation loss: 0.2932
2024-06-04 03:08:11 [INFO]: Epoch 056 - training loss: 1.2634, validation loss: 0.2929
2024-06-04 03:08:16 [INFO]: Epoch 057 - training loss: 1.2611, validation loss: 0.2922
2024-06-04 03:08:22 [INFO]: Epoch 058 - training loss: 1.2618, validation loss: 0.2926
2024-06-04 03:08:28 [INFO]: Epoch 059 - training loss: 1.2594, validation loss: 0.2913
2024-06-04 03:08:34 [INFO]: Epoch 060 - training loss: 1.2567, validation loss: 0.2906
2024-06-04 03:08:40 [INFO]: Epoch 061 - training loss: 1.2580, validation loss: 0.2907
2024-06-04 03:08:46 [INFO]: Epoch 062 - training loss: 1.2567, validation loss: 0.2895
2024-06-04 03:08:52 [INFO]: Epoch 063 - training loss: 1.2540, validation loss: 0.2896
2024-06-04 03:08:58 [INFO]: Epoch 064 - training loss: 1.2558, validation loss: 0.2906
2024-06-04 03:09:05 [INFO]: Epoch 065 - training loss: 1.2547, validation loss: 0.2896
2024-06-04 03:09:11 [INFO]: Epoch 066 - training loss: 1.2588, validation loss: 0.2897
2024-06-04 03:09:17 [INFO]: Epoch 067 - training loss: 1.2543, validation loss: 0.2900
2024-06-04 03:09:23 [INFO]: Epoch 068 - training loss: 1.2577, validation loss: 0.2913
2024-06-04 03:09:29 [INFO]: Epoch 069 - training loss: 1.2507, validation loss: 0.2899
2024-06-04 03:09:35 [INFO]: Epoch 070 - training loss: 1.2543, validation loss: 0.2896
2024-06-04 03:09:41 [INFO]: Epoch 071 - training loss: 1.2539, validation loss: 0.2903
2024-06-04 03:09:47 [INFO]: Epoch 072 - training loss: 1.2520, validation loss: 0.2887
2024-06-04 03:09:53 [INFO]: Epoch 073 - training loss: 1.2492, validation loss: 0.2889
2024-06-04 03:09:58 [INFO]: Epoch 074 - training loss: 1.2520, validation loss: 0.2888
2024-06-04 03:10:05 [INFO]: Epoch 075 - training loss: 1.2500, validation loss: 0.2881
2024-06-04 03:10:10 [INFO]: Epoch 076 - training loss: 1.2520, validation loss: 0.2914
2024-06-04 03:10:16 [INFO]: Epoch 077 - training loss: 1.2505, validation loss: 0.2891
2024-06-04 03:10:22 [INFO]: Epoch 078 - training loss: 1.2514, validation loss: 0.2881
2024-06-04 03:10:28 [INFO]: Epoch 079 - training loss: 1.2488, validation loss: 0.2892
2024-06-04 03:10:34 [INFO]: Epoch 080 - training loss: 1.2479, validation loss: 0.2877
2024-06-04 03:10:40 [INFO]: Epoch 081 - training loss: 1.2471, validation loss: 0.2869
2024-06-04 03:10:46 [INFO]: Epoch 082 - training loss: 1.2493, validation loss: 0.2898
2024-06-04 03:10:52 [INFO]: Epoch 083 - training loss: 1.2462, validation loss: 0.2867
2024-06-04 03:10:58 [INFO]: Epoch 084 - training loss: 1.2446, validation loss: 0.2867
2024-06-04 03:11:04 [INFO]: Epoch 085 - training loss: 1.2474, validation loss: 0.2882
2024-06-04 03:11:10 [INFO]: Epoch 086 - training loss: 1.2487, validation loss: 0.2877
2024-06-04 03:11:16 [INFO]: Epoch 087 - training loss: 1.2485, validation loss: 0.2900
2024-06-04 03:11:22 [INFO]: Epoch 088 - training loss: 1.2453, validation loss: 0.2873
2024-06-04 03:11:28 [INFO]: Epoch 089 - training loss: 1.2430, validation loss: 0.2874
2024-06-04 03:11:34 [INFO]: Epoch 090 - training loss: 1.2424, validation loss: 0.2866
2024-06-04 03:11:40 [INFO]: Epoch 091 - training loss: 1.2431, validation loss: 0.2882
2024-06-04 03:11:45 [INFO]: Epoch 092 - training loss: 1.2430, validation loss: 0.2862
2024-06-04 03:11:51 [INFO]: Epoch 093 - training loss: 1.2423, validation loss: 0.2868
2024-06-04 03:11:57 [INFO]: Epoch 094 - training loss: 1.2400, validation loss: 0.2854
2024-06-04 03:12:03 [INFO]: Epoch 095 - training loss: 1.2455, validation loss: 0.2873
2024-06-04 03:12:09 [INFO]: Epoch 096 - training loss: 1.2423, validation loss: 0.2867
2024-06-04 03:12:15 [INFO]: Epoch 097 - training loss: 1.2432, validation loss: 0.2871
2024-06-04 03:12:21 [INFO]: Epoch 098 - training loss: 1.2394, validation loss: 0.2919
2024-06-04 03:12:27 [INFO]: Epoch 099 - training loss: 1.2436, validation loss: 0.2870
2024-06-04 03:12:33 [INFO]: Epoch 100 - training loss: 1.2410, validation loss: 0.2852
2024-06-04 03:12:33 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 03:12:33 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_2/20240604_T030236/Autoformer.pypots
2024-06-04 03:12:34 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_2/imputation.pkl
2024-06-04 03:12:34 [INFO]: Round2 - Autoformer on BeijingAir: MAE=0.2462, MSE=0.2505, MRE=0.3720
2024-06-04 03:12:34 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:12:34 [INFO]: Using the given device: cuda:0
2024-06-04 03:12:34 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_3/20240604_T031234
2024-06-04 03:12:34 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_3/20240604_T031234/tensorboard
2024-06-04 03:12:34 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-04 03:12:40 [INFO]: Epoch 001 - training loss: 1.7016, validation loss: 1.1700
2024-06-04 03:12:46 [INFO]: Epoch 002 - training loss: 1.6425, validation loss: 1.0085
2024-06-04 03:12:52 [INFO]: Epoch 003 - training loss: 1.5875, validation loss: 0.9769
2024-06-04 03:12:58 [INFO]: Epoch 004 - training loss: 1.5447, validation loss: 0.9951
2024-06-04 03:13:04 [INFO]: Epoch 005 - training loss: 1.5221, validation loss: 1.0047
2024-06-04 03:13:10 [INFO]: Epoch 006 - training loss: 1.5086, validation loss: 1.0030
2024-06-04 03:13:15 [INFO]: Epoch 007 - training loss: 1.4970, validation loss: 0.9934
2024-06-04 03:13:22 [INFO]: Epoch 008 - training loss: 1.4880, validation loss: 0.9737
2024-06-04 03:13:28 [INFO]: Epoch 009 - training loss: 1.4810, validation loss: 0.9413
2024-06-04 03:13:33 [INFO]: Epoch 010 - training loss: 1.4738, validation loss: 0.8927
2024-06-04 03:13:39 [INFO]: Epoch 011 - training loss: 1.4636, validation loss: 0.8306
2024-06-04 03:13:45 [INFO]: Epoch 012 - training loss: 1.4503, validation loss: 0.7641
2024-06-04 03:13:52 [INFO]: Epoch 013 - training loss: 1.4409, validation loss: 0.7006
2024-06-04 03:13:58 [INFO]: Epoch 014 - training loss: 1.4297, validation loss: 0.6439
2024-06-04 03:14:04 [INFO]: Epoch 015 - training loss: 1.4160, validation loss: 0.5921
2024-06-04 03:14:09 [INFO]: Epoch 016 - training loss: 1.4061, validation loss: 0.5411
2024-06-04 03:14:15 [INFO]: Epoch 017 - training loss: 1.3953, validation loss: 0.4941
2024-06-04 03:14:21 [INFO]: Epoch 018 - training loss: 1.3821, validation loss: 0.4642
2024-06-04 03:14:27 [INFO]: Epoch 019 - training loss: 1.3711, validation loss: 0.4464
2024-06-04 03:14:33 [INFO]: Epoch 020 - training loss: 1.3617, validation loss: 0.4247
2024-06-04 03:14:39 [INFO]: Epoch 021 - training loss: 1.3519, validation loss: 0.4081
2024-06-04 03:14:45 [INFO]: Epoch 022 - training loss: 1.3487, validation loss: 0.3945
2024-06-04 03:14:51 [INFO]: Epoch 023 - training loss: 1.3403, validation loss: 0.3866
2024-06-04 03:14:57 [INFO]: Epoch 024 - training loss: 1.3376, validation loss: 0.3745
2024-06-04 03:15:03 [INFO]: Epoch 025 - training loss: 1.3314, validation loss: 0.3670
2024-06-04 03:15:09 [INFO]: Epoch 026 - training loss: 1.3255, validation loss: 0.3592
2024-06-04 03:15:15 [INFO]: Epoch 027 - training loss: 1.3238, validation loss: 0.3519
2024-06-04 03:15:21 [INFO]: Epoch 028 - training loss: 1.3183, validation loss: 0.3494
2024-06-04 03:15:27 [INFO]: Epoch 029 - training loss: 1.3135, validation loss: 0.3420
2024-06-04 03:15:33 [INFO]: Epoch 030 - training loss: 1.3069, validation loss: 0.3393
2024-06-04 03:15:39 [INFO]: Epoch 031 - training loss: 1.3054, validation loss: 0.3370
2024-06-04 03:15:45 [INFO]: Epoch 032 - training loss: 1.3027, validation loss: 0.3332
2024-06-04 03:15:51 [INFO]: Epoch 033 - training loss: 1.3015, validation loss: 0.3297
2024-06-04 03:15:57 [INFO]: Epoch 034 - training loss: 1.3007, validation loss: 0.3279
2024-06-04 03:16:03 [INFO]: Epoch 035 - training loss: 1.2957, validation loss: 0.3255
2024-06-04 03:16:09 [INFO]: Epoch 036 - training loss: 1.2940, validation loss: 0.3251
2024-06-04 03:16:15 [INFO]: Epoch 037 - training loss: 1.2924, validation loss: 0.3218
2024-06-04 03:16:21 [INFO]: Epoch 038 - training loss: 1.2872, validation loss: 0.3201
2024-06-04 03:16:27 [INFO]: Epoch 039 - training loss: 1.2854, validation loss: 0.3183
2024-06-04 03:16:33 [INFO]: Epoch 040 - training loss: 1.2841, validation loss: 0.3168
2024-06-04 03:16:39 [INFO]: Epoch 041 - training loss: 1.2820, validation loss: 0.3163
2024-06-04 03:16:45 [INFO]: Epoch 042 - training loss: 1.2820, validation loss: 0.3156
2024-06-04 03:16:51 [INFO]: Epoch 043 - training loss: 1.2797, validation loss: 0.3147
2024-06-04 03:16:57 [INFO]: Epoch 044 - training loss: 1.2776, validation loss: 0.3139
2024-06-04 03:17:03 [INFO]: Epoch 045 - training loss: 1.2783, validation loss: 0.3133
2024-06-04 03:17:09 [INFO]: Epoch 046 - training loss: 1.2767, validation loss: 0.3110
2024-06-04 03:17:14 [INFO]: Epoch 047 - training loss: 1.2741, validation loss: 0.3111
2024-06-04 03:17:20 [INFO]: Epoch 048 - training loss: 1.2752, validation loss: 0.3095
2024-06-04 03:17:26 [INFO]: Epoch 049 - training loss: 1.2715, validation loss: 0.3080
2024-06-04 03:17:32 [INFO]: Epoch 050 - training loss: 1.2697, validation loss: 0.3068
2024-06-04 03:17:38 [INFO]: Epoch 051 - training loss: 1.2696, validation loss: 0.3065
2024-06-04 03:17:45 [INFO]: Epoch 052 - training loss: 1.2707, validation loss: 0.3062
2024-06-04 03:17:50 [INFO]: Epoch 053 - training loss: 1.2657, validation loss: 0.3059
2024-06-04 03:17:56 [INFO]: Epoch 054 - training loss: 1.2637, validation loss: 0.3053
2024-06-04 03:18:02 [INFO]: Epoch 055 - training loss: 1.2649, validation loss: 0.3049
2024-06-04 03:18:08 [INFO]: Epoch 056 - training loss: 1.2636, validation loss: 0.3043
2024-06-04 03:18:14 [INFO]: Epoch 057 - training loss: 1.2616, validation loss: 0.3036
2024-06-04 03:18:20 [INFO]: Epoch 058 - training loss: 1.2609, validation loss: 0.3030
2024-06-04 03:18:26 [INFO]: Epoch 059 - training loss: 1.2609, validation loss: 0.3041
2024-06-04 03:18:32 [INFO]: Epoch 060 - training loss: 1.2608, validation loss: 0.3015
2024-06-04 03:18:38 [INFO]: Epoch 061 - training loss: 1.2599, validation loss: 0.3028
2024-06-04 03:18:44 [INFO]: Epoch 062 - training loss: 1.2588, validation loss: 0.3009
2024-06-04 03:18:50 [INFO]: Epoch 063 - training loss: 1.2579, validation loss: 0.3017
2024-06-04 03:18:56 [INFO]: Epoch 064 - training loss: 1.2569, validation loss: 0.3009
2024-06-04 03:19:02 [INFO]: Epoch 065 - training loss: 1.2548, validation loss: 0.3006
2024-06-04 03:19:08 [INFO]: Epoch 066 - training loss: 1.2559, validation loss: 0.2997
2024-06-04 03:19:14 [INFO]: Epoch 067 - training loss: 1.2554, validation loss: 0.2999
2024-06-04 03:19:20 [INFO]: Epoch 068 - training loss: 1.2552, validation loss: 0.2990
2024-06-04 03:19:26 [INFO]: Epoch 069 - training loss: 1.2538, validation loss: 0.2981
2024-06-04 03:19:32 [INFO]: Epoch 070 - training loss: 1.2546, validation loss: 0.2987
2024-06-04 03:19:38 [INFO]: Epoch 071 - training loss: 1.2547, validation loss: 0.2984
2024-06-04 03:19:44 [INFO]: Epoch 072 - training loss: 1.2522, validation loss: 0.2986
2024-06-04 03:19:50 [INFO]: Epoch 073 - training loss: 1.2514, validation loss: 0.2966
2024-06-04 03:19:56 [INFO]: Epoch 074 - training loss: 1.2535, validation loss: 0.2992
2024-06-04 03:20:02 [INFO]: Epoch 075 - training loss: 1.2523, validation loss: 0.2980
2024-06-04 03:20:08 [INFO]: Epoch 076 - training loss: 1.2512, validation loss: 0.2978
2024-06-04 03:20:13 [INFO]: Epoch 077 - training loss: 1.2488, validation loss: 0.2985
2024-06-04 03:20:19 [INFO]: Epoch 078 - training loss: 1.2497, validation loss: 0.2981
2024-06-04 03:20:25 [INFO]: Epoch 079 - training loss: 1.2511, validation loss: 0.2960
2024-06-04 03:20:31 [INFO]: Epoch 080 - training loss: 1.2477, validation loss: 0.2946
2024-06-04 03:20:37 [INFO]: Epoch 081 - training loss: 1.2516, validation loss: 0.2976
2024-06-04 03:20:43 [INFO]: Epoch 082 - training loss: 1.2477, validation loss: 0.2937
2024-06-04 03:20:49 [INFO]: Epoch 083 - training loss: 1.2456, validation loss: 0.2946
2024-06-04 03:20:55 [INFO]: Epoch 084 - training loss: 1.2455, validation loss: 0.2929
2024-06-04 03:21:01 [INFO]: Epoch 085 - training loss: 1.2427, validation loss: 0.2954
2024-06-04 03:21:07 [INFO]: Epoch 086 - training loss: 1.2448, validation loss: 0.2942
2024-06-04 03:21:12 [INFO]: Epoch 087 - training loss: 1.2475, validation loss: 0.2959
2024-06-04 03:21:18 [INFO]: Epoch 088 - training loss: 1.2436, validation loss: 0.2964
2024-06-04 03:21:24 [INFO]: Epoch 089 - training loss: 1.2446, validation loss: 0.2954
2024-06-04 03:21:30 [INFO]: Epoch 090 - training loss: 1.2450, validation loss: 0.2943
2024-06-04 03:21:36 [INFO]: Epoch 091 - training loss: 1.2486, validation loss: 0.2932
2024-06-04 03:21:42 [INFO]: Epoch 092 - training loss: 1.2432, validation loss: 0.2937
2024-06-04 03:21:48 [INFO]: Epoch 093 - training loss: 1.2458, validation loss: 0.2933
2024-06-04 03:21:54 [INFO]: Epoch 094 - training loss: 1.2434, validation loss: 0.2929
2024-06-04 03:22:00 [INFO]: Epoch 095 - training loss: 1.2414, validation loss: 0.2925
2024-06-04 03:22:06 [INFO]: Epoch 096 - training loss: 1.2407, validation loss: 0.2953
2024-06-04 03:22:12 [INFO]: Epoch 097 - training loss: 1.2423, validation loss: 0.2940
2024-06-04 03:22:18 [INFO]: Epoch 098 - training loss: 1.2408, validation loss: 0.2916
2024-06-04 03:22:24 [INFO]: Epoch 099 - training loss: 1.2385, validation loss: 0.2935
2024-06-04 03:22:30 [INFO]: Epoch 100 - training loss: 1.2404, validation loss: 0.2950
2024-06-04 03:22:30 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 03:22:30 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_3/20240604_T031234/Autoformer.pypots
2024-06-04 03:22:31 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_3/imputation.pkl
2024-06-04 03:22:31 [INFO]: Round3 - Autoformer on BeijingAir: MAE=0.2535, MSE=0.2576, MRE=0.3830
2024-06-04 03:22:31 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:22:31 [INFO]: Using the given device: cuda:0
2024-06-04 03:22:31 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_4/20240604_T032231
2024-06-04 03:22:31 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_4/20240604_T032231/tensorboard
2024-06-04 03:22:31 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-04 03:22:37 [INFO]: Epoch 001 - training loss: 1.7032, validation loss: 1.1797
2024-06-04 03:22:43 [INFO]: Epoch 002 - training loss: 1.6463, validation loss: 1.0094
2024-06-04 03:22:49 [INFO]: Epoch 003 - training loss: 1.5965, validation loss: 0.9584
2024-06-04 03:22:55 [INFO]: Epoch 004 - training loss: 1.5533, validation loss: 0.9691
2024-06-04 03:23:01 [INFO]: Epoch 005 - training loss: 1.5274, validation loss: 0.9793
2024-06-04 03:23:07 [INFO]: Epoch 006 - training loss: 1.5109, validation loss: 0.9813
2024-06-04 03:23:13 [INFO]: Epoch 007 - training loss: 1.4969, validation loss: 0.9727
2024-06-04 03:23:19 [INFO]: Epoch 008 - training loss: 1.4881, validation loss: 0.9510
2024-06-04 03:23:25 [INFO]: Epoch 009 - training loss: 1.4770, validation loss: 0.9104
2024-06-04 03:23:31 [INFO]: Epoch 010 - training loss: 1.4659, validation loss: 0.8543
2024-06-04 03:23:37 [INFO]: Epoch 011 - training loss: 1.4543, validation loss: 0.7828
2024-06-04 03:23:43 [INFO]: Epoch 012 - training loss: 1.4416, validation loss: 0.7310
2024-06-04 03:23:49 [INFO]: Epoch 013 - training loss: 1.4297, validation loss: 0.6723
2024-06-04 03:23:55 [INFO]: Epoch 014 - training loss: 1.4199, validation loss: 0.6207
2024-06-04 03:24:01 [INFO]: Epoch 015 - training loss: 1.4065, validation loss: 0.5749
2024-06-04 03:24:07 [INFO]: Epoch 016 - training loss: 1.3947, validation loss: 0.5365
2024-06-04 03:24:13 [INFO]: Epoch 017 - training loss: 1.3857, validation loss: 0.4980
2024-06-04 03:24:19 [INFO]: Epoch 018 - training loss: 1.3736, validation loss: 0.4700
2024-06-04 03:24:25 [INFO]: Epoch 019 - training loss: 1.3672, validation loss: 0.4472
2024-06-04 03:24:31 [INFO]: Epoch 020 - training loss: 1.3569, validation loss: 0.4249
2024-06-04 03:24:37 [INFO]: Epoch 021 - training loss: 1.3501, validation loss: 0.4111
2024-06-04 03:24:43 [INFO]: Epoch 022 - training loss: 1.3434, validation loss: 0.3999
2024-06-04 03:24:48 [INFO]: Epoch 023 - training loss: 1.3368, validation loss: 0.3879
2024-06-04 03:24:54 [INFO]: Epoch 024 - training loss: 1.3304, validation loss: 0.3748
2024-06-04 03:25:00 [INFO]: Epoch 025 - training loss: 1.3252, validation loss: 0.3660
2024-06-04 03:25:06 [INFO]: Epoch 026 - training loss: 1.3241, validation loss: 0.3593
2024-06-04 03:25:12 [INFO]: Epoch 027 - training loss: 1.3170, validation loss: 0.3521
2024-06-04 03:25:18 [INFO]: Epoch 028 - training loss: 1.3150, validation loss: 0.3459
2024-06-04 03:25:25 [INFO]: Epoch 029 - training loss: 1.3098, validation loss: 0.3423
2024-06-04 03:25:31 [INFO]: Epoch 030 - training loss: 1.3079, validation loss: 0.3377
2024-06-04 03:25:37 [INFO]: Epoch 031 - training loss: 1.3030, validation loss: 0.3332
2024-06-04 03:25:43 [INFO]: Epoch 032 - training loss: 1.3001, validation loss: 0.3300
2024-06-04 03:25:49 [INFO]: Epoch 033 - training loss: 1.2981, validation loss: 0.3272
2024-06-04 03:25:55 [INFO]: Epoch 034 - training loss: 1.2947, validation loss: 0.3250
2024-06-04 03:26:01 [INFO]: Epoch 035 - training loss: 1.2915, validation loss: 0.3235
2024-06-04 03:26:07 [INFO]: Epoch 036 - training loss: 1.2926, validation loss: 0.3218
2024-06-04 03:26:13 [INFO]: Epoch 037 - training loss: 1.2911, validation loss: 0.3202
2024-06-04 03:26:19 [INFO]: Epoch 038 - training loss: 1.2904, validation loss: 0.3185
2024-06-04 03:26:24 [INFO]: Epoch 039 - training loss: 1.2860, validation loss: 0.3191
2024-06-04 03:26:31 [INFO]: Epoch 040 - training loss: 1.2851, validation loss: 0.3166
2024-06-04 03:26:37 [INFO]: Epoch 041 - training loss: 1.2809, validation loss: 0.3169
2024-06-04 03:26:43 [INFO]: Epoch 042 - training loss: 1.2808, validation loss: 0.3167
2024-06-04 03:26:49 [INFO]: Epoch 043 - training loss: 1.2802, validation loss: 0.3162
2024-06-04 03:26:55 [INFO]: Epoch 044 - training loss: 1.2783, validation loss: 0.3151
2024-06-04 03:27:01 [INFO]: Epoch 045 - training loss: 1.2785, validation loss: 0.3154
2024-06-04 03:27:07 [INFO]: Epoch 046 - training loss: 1.2745, validation loss: 0.3141
2024-06-04 03:27:13 [INFO]: Epoch 047 - training loss: 1.2701, validation loss: 0.3132
2024-06-04 03:27:20 [INFO]: Epoch 048 - training loss: 1.2696, validation loss: 0.3150
2024-06-04 03:27:25 [INFO]: Epoch 049 - training loss: 1.2695, validation loss: 0.3137
2024-06-04 03:27:31 [INFO]: Epoch 050 - training loss: 1.2697, validation loss: 0.3139
2024-06-04 03:27:37 [INFO]: Epoch 051 - training loss: 1.2675, validation loss: 0.3141
2024-06-04 03:27:43 [INFO]: Epoch 052 - training loss: 1.2687, validation loss: 0.3123
2024-06-04 03:27:49 [INFO]: Epoch 053 - training loss: 1.2681, validation loss: 0.3134
2024-06-04 03:27:55 [INFO]: Epoch 054 - training loss: 1.2650, validation loss: 0.3151
2024-06-04 03:28:01 [INFO]: Epoch 055 - training loss: 1.2641, validation loss: 0.3149
2024-06-04 03:28:07 [INFO]: Epoch 056 - training loss: 1.2627, validation loss: 0.3119
2024-06-04 03:28:13 [INFO]: Epoch 057 - training loss: 1.2620, validation loss: 0.3136
2024-06-04 03:28:19 [INFO]: Epoch 058 - training loss: 1.2611, validation loss: 0.3160
2024-06-04 03:28:25 [INFO]: Epoch 059 - training loss: 1.2620, validation loss: 0.3148
2024-06-04 03:28:31 [INFO]: Epoch 060 - training loss: 1.2594, validation loss: 0.3139
2024-06-04 03:28:37 [INFO]: Epoch 061 - training loss: 1.2579, validation loss: 0.3152
2024-06-04 03:28:43 [INFO]: Epoch 062 - training loss: 1.2583, validation loss: 0.3158
2024-06-04 03:28:49 [INFO]: Epoch 063 - training loss: 1.2583, validation loss: 0.3132
2024-06-04 03:28:55 [INFO]: Epoch 064 - training loss: 1.2570, validation loss: 0.3139
2024-06-04 03:29:01 [INFO]: Epoch 065 - training loss: 1.2586, validation loss: 0.3189
2024-06-04 03:29:06 [INFO]: Epoch 066 - training loss: 1.2578, validation loss: 0.3148
2024-06-04 03:29:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:29:06 [INFO]: Finished training. The best model is from epoch#56.
2024-06-04 03:29:07 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_4/20240604_T032231/Autoformer.pypots
2024-06-04 03:29:08 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Autoformer_BeijingAir/round_4/imputation.pkl
2024-06-04 03:29:08 [INFO]: Round4 - Autoformer on BeijingAir: MAE=0.2736, MSE=0.2839, MRE=0.4134
2024-06-04 03:29:08 [INFO]: Done! Final results:
Averaged Autoformer (6,700,164 params) on BeijingAir: MAE=0.2573 ± 0.012353884930149805, MSE=0.2716 ± 0.013689091571646963, MRE=0.3422 ± 0.016431531681660314, average inference time=0.26