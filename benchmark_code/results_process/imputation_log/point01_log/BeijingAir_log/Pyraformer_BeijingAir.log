2024-06-04 02:49:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:49:23 [INFO]: Using the given device: cuda:0
2024-06-04 02:49:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_0/20240604_T024924
2024-06-04 02:49:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_0/20240604_T024924/tensorboard
2024-06-04 02:49:26 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-04 02:49:39 [INFO]: Epoch 001 - training loss: 0.9655, validation loss: 0.3736
2024-06-04 02:49:43 [INFO]: Epoch 002 - training loss: 0.6685, validation loss: 0.2927
2024-06-04 02:49:48 [INFO]: Epoch 003 - training loss: 0.5755, validation loss: 0.2749
2024-06-04 02:49:53 [INFO]: Epoch 004 - training loss: 0.5368, validation loss: 0.2548
2024-06-04 02:49:58 [INFO]: Epoch 005 - training loss: 0.4953, validation loss: 0.2424
2024-06-04 02:50:02 [INFO]: Epoch 006 - training loss: 0.4662, validation loss: 0.2325
2024-06-04 02:50:07 [INFO]: Epoch 007 - training loss: 0.4400, validation loss: 0.2271
2024-06-04 02:50:12 [INFO]: Epoch 008 - training loss: 0.4368, validation loss: 0.2239
2024-06-04 02:50:17 [INFO]: Epoch 009 - training loss: 0.4343, validation loss: 0.2276
2024-06-04 02:50:21 [INFO]: Epoch 010 - training loss: 0.4230, validation loss: 0.2119
2024-06-04 02:50:26 [INFO]: Epoch 011 - training loss: 0.4173, validation loss: 0.2065
2024-06-04 02:50:31 [INFO]: Epoch 012 - training loss: 0.4025, validation loss: 0.2075
2024-06-04 02:50:36 [INFO]: Epoch 013 - training loss: 0.4032, validation loss: 0.1984
2024-06-04 02:50:41 [INFO]: Epoch 014 - training loss: 0.3881, validation loss: 0.2078
2024-06-04 02:50:46 [INFO]: Epoch 015 - training loss: 0.3896, validation loss: 0.1942
2024-06-04 02:50:51 [INFO]: Epoch 016 - training loss: 0.3796, validation loss: 0.1978
2024-06-04 02:50:56 [INFO]: Epoch 017 - training loss: 0.3754, validation loss: 0.1963
2024-06-04 02:51:01 [INFO]: Epoch 018 - training loss: 0.3856, validation loss: 0.1980
2024-06-04 02:51:05 [INFO]: Epoch 019 - training loss: 0.3752, validation loss: 0.1908
2024-06-04 02:51:10 [INFO]: Epoch 020 - training loss: 0.3706, validation loss: 0.1874
2024-06-04 02:51:15 [INFO]: Epoch 021 - training loss: 0.3661, validation loss: 0.1851
2024-06-04 02:51:20 [INFO]: Epoch 022 - training loss: 0.3633, validation loss: 0.1894
2024-06-04 02:51:25 [INFO]: Epoch 023 - training loss: 0.3622, validation loss: 0.1846
2024-06-04 02:51:30 [INFO]: Epoch 024 - training loss: 0.3643, validation loss: 0.1858
2024-06-04 02:51:34 [INFO]: Epoch 025 - training loss: 0.3609, validation loss: 0.1924
2024-06-04 02:51:39 [INFO]: Epoch 026 - training loss: 0.3614, validation loss: 0.1825
2024-06-04 02:51:44 [INFO]: Epoch 027 - training loss: 0.3574, validation loss: 0.1996
2024-06-04 02:51:49 [INFO]: Epoch 028 - training loss: 0.3668, validation loss: 0.1885
2024-06-04 02:51:54 [INFO]: Epoch 029 - training loss: 0.3615, validation loss: 0.1858
2024-06-04 02:51:58 [INFO]: Epoch 030 - training loss: 0.3539, validation loss: 0.1938
2024-06-04 02:52:03 [INFO]: Epoch 031 - training loss: 0.3553, validation loss: 0.1919
2024-06-04 02:52:08 [INFO]: Epoch 032 - training loss: 0.3484, validation loss: 0.1797
2024-06-04 02:52:12 [INFO]: Epoch 033 - training loss: 0.3445, validation loss: 0.1815
2024-06-04 02:52:17 [INFO]: Epoch 034 - training loss: 0.3416, validation loss: 0.1854
2024-06-04 02:52:22 [INFO]: Epoch 035 - training loss: 0.3360, validation loss: 0.1790
2024-06-04 02:52:27 [INFO]: Epoch 036 - training loss: 0.3386, validation loss: 0.1830
2024-06-04 02:52:32 [INFO]: Epoch 037 - training loss: 0.3454, validation loss: 0.1823
2024-06-04 02:52:37 [INFO]: Epoch 038 - training loss: 0.3352, validation loss: 0.1763
2024-06-04 02:52:41 [INFO]: Epoch 039 - training loss: 0.3329, validation loss: 0.1804
2024-06-04 02:52:46 [INFO]: Epoch 040 - training loss: 0.3326, validation loss: 0.1786
2024-06-04 02:52:51 [INFO]: Epoch 041 - training loss: 0.3409, validation loss: 0.1776
2024-06-04 02:52:56 [INFO]: Epoch 042 - training loss: 0.3332, validation loss: 0.1766
2024-06-04 02:53:01 [INFO]: Epoch 043 - training loss: 0.3313, validation loss: 0.1787
2024-06-04 02:53:06 [INFO]: Epoch 044 - training loss: 0.3267, validation loss: 0.1712
2024-06-04 02:53:11 [INFO]: Epoch 045 - training loss: 0.3279, validation loss: 0.1745
2024-06-04 02:53:15 [INFO]: Epoch 046 - training loss: 0.3299, validation loss: 0.1731
2024-06-04 02:53:20 [INFO]: Epoch 047 - training loss: 0.3250, validation loss: 0.1729
2024-06-04 02:53:25 [INFO]: Epoch 048 - training loss: 0.3236, validation loss: 0.1725
2024-06-04 02:53:30 [INFO]: Epoch 049 - training loss: 0.3248, validation loss: 0.1740
2024-06-04 02:53:34 [INFO]: Epoch 050 - training loss: 0.3220, validation loss: 0.1722
2024-06-04 02:53:39 [INFO]: Epoch 051 - training loss: 0.3215, validation loss: 0.1683
2024-06-04 02:53:44 [INFO]: Epoch 052 - training loss: 0.3284, validation loss: 0.1742
2024-06-04 02:53:49 [INFO]: Epoch 053 - training loss: 0.3213, validation loss: 0.1697
2024-06-04 02:53:54 [INFO]: Epoch 054 - training loss: 0.3177, validation loss: 0.1670
2024-06-04 02:53:58 [INFO]: Epoch 055 - training loss: 0.3137, validation loss: 0.1716
2024-06-04 02:54:03 [INFO]: Epoch 056 - training loss: 0.3169, validation loss: 0.1678
2024-06-04 02:54:08 [INFO]: Epoch 057 - training loss: 0.3164, validation loss: 0.1700
2024-06-04 02:54:13 [INFO]: Epoch 058 - training loss: 0.3109, validation loss: 0.1661
2024-06-04 02:54:18 [INFO]: Epoch 059 - training loss: 0.3098, validation loss: 0.1669
2024-06-04 02:54:23 [INFO]: Epoch 060 - training loss: 0.3076, validation loss: 0.1683
2024-06-04 02:54:28 [INFO]: Epoch 061 - training loss: 0.3129, validation loss: 0.1673
2024-06-04 02:54:32 [INFO]: Epoch 062 - training loss: 0.3121, validation loss: 0.1642
2024-06-04 02:54:37 [INFO]: Epoch 063 - training loss: 0.3142, validation loss: 0.1642
2024-06-04 02:54:41 [INFO]: Epoch 064 - training loss: 0.3094, validation loss: 0.1666
2024-06-04 02:54:46 [INFO]: Epoch 065 - training loss: 0.3062, validation loss: 0.1638
2024-06-04 02:54:51 [INFO]: Epoch 066 - training loss: 0.3062, validation loss: 0.1617
2024-06-04 02:54:55 [INFO]: Epoch 067 - training loss: 0.3062, validation loss: 0.1588
2024-06-04 02:55:00 [INFO]: Epoch 068 - training loss: 0.3044, validation loss: 0.1589
2024-06-04 02:55:05 [INFO]: Epoch 069 - training loss: 0.3105, validation loss: 0.1595
2024-06-04 02:55:10 [INFO]: Epoch 070 - training loss: 0.3072, validation loss: 0.1633
2024-06-04 02:55:14 [INFO]: Epoch 071 - training loss: 0.3067, validation loss: 0.1579
2024-06-04 02:55:19 [INFO]: Epoch 072 - training loss: 0.3054, validation loss: 0.1605
2024-06-04 02:55:24 [INFO]: Epoch 073 - training loss: 0.3053, validation loss: 0.1600
2024-06-04 02:55:29 [INFO]: Epoch 074 - training loss: 0.3003, validation loss: 0.1632
2024-06-04 02:55:34 [INFO]: Epoch 075 - training loss: 0.3014, validation loss: 0.1564
2024-06-04 02:55:39 [INFO]: Epoch 076 - training loss: 0.2971, validation loss: 0.1571
2024-06-04 02:55:44 [INFO]: Epoch 077 - training loss: 0.2994, validation loss: 0.1604
2024-06-04 02:55:49 [INFO]: Epoch 078 - training loss: 0.2960, validation loss: 0.1540
2024-06-04 02:55:54 [INFO]: Epoch 079 - training loss: 0.2983, validation loss: 0.1545
2024-06-04 02:55:58 [INFO]: Epoch 080 - training loss: 0.2978, validation loss: 0.1547
2024-06-04 02:56:03 [INFO]: Epoch 081 - training loss: 0.2976, validation loss: 0.1526
2024-06-04 02:56:08 [INFO]: Epoch 082 - training loss: 0.2931, validation loss: 0.1540
2024-06-04 02:56:13 [INFO]: Epoch 083 - training loss: 0.2930, validation loss: 0.1543
2024-06-04 02:56:18 [INFO]: Epoch 084 - training loss: 0.2933, validation loss: 0.1490
2024-06-04 02:56:22 [INFO]: Epoch 085 - training loss: 0.2929, validation loss: 0.1478
2024-06-04 02:56:28 [INFO]: Epoch 086 - training loss: 0.2887, validation loss: 0.1503
2024-06-04 02:56:33 [INFO]: Epoch 087 - training loss: 0.2931, validation loss: 0.1497
2024-06-04 02:56:38 [INFO]: Epoch 088 - training loss: 0.2960, validation loss: 0.1491
2024-06-04 02:56:43 [INFO]: Epoch 089 - training loss: 0.2947, validation loss: 0.1477
2024-06-04 02:56:48 [INFO]: Epoch 090 - training loss: 0.2912, validation loss: 0.1503
2024-06-04 02:56:53 [INFO]: Epoch 091 - training loss: 0.2914, validation loss: 0.1517
2024-06-04 02:56:58 [INFO]: Epoch 092 - training loss: 0.2882, validation loss: 0.1482
2024-06-04 02:57:03 [INFO]: Epoch 093 - training loss: 0.2891, validation loss: 0.1494
2024-06-04 02:57:08 [INFO]: Epoch 094 - training loss: 0.2910, validation loss: 0.1470
2024-06-04 02:57:13 [INFO]: Epoch 095 - training loss: 0.2900, validation loss: 0.1479
2024-06-04 02:57:18 [INFO]: Epoch 096 - training loss: 0.2884, validation loss: 0.1469
2024-06-04 02:57:23 [INFO]: Epoch 097 - training loss: 0.2858, validation loss: 0.1493
2024-06-04 02:57:27 [INFO]: Epoch 098 - training loss: 0.2879, validation loss: 0.1444
2024-06-04 02:57:32 [INFO]: Epoch 099 - training loss: 0.2873, validation loss: 0.1456
2024-06-04 02:57:37 [INFO]: Epoch 100 - training loss: 0.2853, validation loss: 0.1431
2024-06-04 02:57:37 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 02:57:37 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_0/20240604_T024924/Pyraformer.pypots
2024-06-04 02:57:39 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_0/imputation.pkl
2024-06-04 02:57:39 [INFO]: Round0 - Pyraformer on BeijingAir: MAE=0.2172, MSE=0.2070, MRE=0.3282
2024-06-04 02:57:39 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 02:57:39 [INFO]: Using the given device: cuda:0
2024-06-04 02:57:39 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_1/20240604_T025739
2024-06-04 02:57:39 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_1/20240604_T025739/tensorboard
2024-06-04 02:57:39 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-04 02:57:44 [INFO]: Epoch 001 - training loss: 0.9944, validation loss: 0.3739
2024-06-04 02:57:49 [INFO]: Epoch 002 - training loss: 0.6523, validation loss: 0.3251
2024-06-04 02:57:54 [INFO]: Epoch 003 - training loss: 0.5699, validation loss: 0.2691
2024-06-04 02:57:58 [INFO]: Epoch 004 - training loss: 0.5227, validation loss: 0.2512
2024-06-04 02:58:03 [INFO]: Epoch 005 - training loss: 0.5066, validation loss: 0.2495
2024-06-04 02:58:07 [INFO]: Epoch 006 - training loss: 0.4848, validation loss: 0.2298
2024-06-04 02:58:12 [INFO]: Epoch 007 - training loss: 0.4596, validation loss: 0.2284
2024-06-04 02:58:17 [INFO]: Epoch 008 - training loss: 0.4540, validation loss: 0.2226
2024-06-04 02:58:22 [INFO]: Epoch 009 - training loss: 0.4397, validation loss: 0.2233
2024-06-04 02:58:27 [INFO]: Epoch 010 - training loss: 0.4250, validation loss: 0.2083
2024-06-04 02:58:32 [INFO]: Epoch 011 - training loss: 0.4189, validation loss: 0.2069
2024-06-04 02:58:37 [INFO]: Epoch 012 - training loss: 0.4095, validation loss: 0.2033
2024-06-04 02:58:42 [INFO]: Epoch 013 - training loss: 0.4058, validation loss: 0.2072
2024-06-04 02:58:47 [INFO]: Epoch 014 - training loss: 0.4047, validation loss: 0.1998
2024-06-04 02:58:51 [INFO]: Epoch 015 - training loss: 0.3977, validation loss: 0.1965
2024-06-04 02:58:56 [INFO]: Epoch 016 - training loss: 0.3869, validation loss: 0.1913
2024-06-04 02:59:01 [INFO]: Epoch 017 - training loss: 0.3841, validation loss: 0.1919
2024-06-04 02:59:05 [INFO]: Epoch 018 - training loss: 0.3915, validation loss: 0.1877
2024-06-04 02:59:10 [INFO]: Epoch 019 - training loss: 0.3814, validation loss: 0.1922
2024-06-04 02:59:15 [INFO]: Epoch 020 - training loss: 0.3755, validation loss: 0.1850
2024-06-04 02:59:20 [INFO]: Epoch 021 - training loss: 0.3684, validation loss: 0.1837
2024-06-04 02:59:25 [INFO]: Epoch 022 - training loss: 0.3658, validation loss: 0.1862
2024-06-04 02:59:30 [INFO]: Epoch 023 - training loss: 0.3599, validation loss: 0.1842
2024-06-04 02:59:34 [INFO]: Epoch 024 - training loss: 0.3760, validation loss: 0.1948
2024-06-04 02:59:39 [INFO]: Epoch 025 - training loss: 0.3727, validation loss: 0.1842
2024-06-04 02:59:44 [INFO]: Epoch 026 - training loss: 0.3723, validation loss: 0.1938
2024-06-04 02:59:48 [INFO]: Epoch 027 - training loss: 0.3657, validation loss: 0.1873
2024-06-04 02:59:53 [INFO]: Epoch 028 - training loss: 0.3713, validation loss: 0.1874
2024-06-04 02:59:58 [INFO]: Epoch 029 - training loss: 0.3623, validation loss: 0.1908
2024-06-04 03:00:03 [INFO]: Epoch 030 - training loss: 0.3706, validation loss: 0.1874
2024-06-04 03:00:08 [INFO]: Epoch 031 - training loss: 0.3588, validation loss: 0.1804
2024-06-04 03:00:13 [INFO]: Epoch 032 - training loss: 0.3569, validation loss: 0.1787
2024-06-04 03:00:18 [INFO]: Epoch 033 - training loss: 0.3472, validation loss: 0.1810
2024-06-04 03:00:23 [INFO]: Epoch 034 - training loss: 0.3419, validation loss: 0.1827
2024-06-04 03:00:27 [INFO]: Epoch 035 - training loss: 0.3408, validation loss: 0.1745
2024-06-04 03:00:32 [INFO]: Epoch 036 - training loss: 0.3499, validation loss: 0.1837
2024-06-04 03:00:37 [INFO]: Epoch 037 - training loss: 0.3384, validation loss: 0.1752
2024-06-04 03:00:42 [INFO]: Epoch 038 - training loss: 0.3383, validation loss: 0.1801
2024-06-04 03:00:46 [INFO]: Epoch 039 - training loss: 0.3319, validation loss: 0.1775
2024-06-04 03:00:51 [INFO]: Epoch 040 - training loss: 0.3343, validation loss: 0.1816
2024-06-04 03:00:56 [INFO]: Epoch 041 - training loss: 0.3368, validation loss: 0.1781
2024-06-04 03:01:00 [INFO]: Epoch 042 - training loss: 0.3321, validation loss: 0.1774
2024-06-04 03:01:05 [INFO]: Epoch 043 - training loss: 0.3383, validation loss: 0.1806
2024-06-04 03:01:10 [INFO]: Epoch 044 - training loss: 0.3364, validation loss: 0.1781
2024-06-04 03:01:14 [INFO]: Epoch 045 - training loss: 0.3323, validation loss: 0.1854
2024-06-04 03:01:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:01:14 [INFO]: Finished training. The best model is from epoch#35.
2024-06-04 03:01:14 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_1/20240604_T025739/Pyraformer.pypots
2024-06-04 03:01:16 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_1/imputation.pkl
2024-06-04 03:01:16 [INFO]: Round1 - Pyraformer on BeijingAir: MAE=0.2315, MSE=0.2256, MRE=0.3498
2024-06-04 03:01:16 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:01:16 [INFO]: Using the given device: cuda:0
2024-06-04 03:01:16 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_2/20240604_T030116
2024-06-04 03:01:16 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_2/20240604_T030116/tensorboard
2024-06-04 03:01:17 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-04 03:01:21 [INFO]: Epoch 001 - training loss: 0.9874, validation loss: 0.3618
2024-06-04 03:01:26 [INFO]: Epoch 002 - training loss: 0.6619, validation loss: 0.2942
2024-06-04 03:01:30 [INFO]: Epoch 003 - training loss: 0.5549, validation loss: 0.2619
2024-06-04 03:01:34 [INFO]: Epoch 004 - training loss: 0.5345, validation loss: 0.2464
2024-06-04 03:01:38 [INFO]: Epoch 005 - training loss: 0.4960, validation loss: 0.2400
2024-06-04 03:01:42 [INFO]: Epoch 006 - training loss: 0.4706, validation loss: 0.2272
2024-06-04 03:01:45 [INFO]: Epoch 007 - training loss: 0.4585, validation loss: 0.2300
2024-06-04 03:01:50 [INFO]: Epoch 008 - training loss: 0.4421, validation loss: 0.2206
2024-06-04 03:01:55 [INFO]: Epoch 009 - training loss: 0.4358, validation loss: 0.2119
2024-06-04 03:01:59 [INFO]: Epoch 010 - training loss: 0.4229, validation loss: 0.2103
2024-06-04 03:02:04 [INFO]: Epoch 011 - training loss: 0.4050, validation loss: 0.2207
2024-06-04 03:02:10 [INFO]: Epoch 012 - training loss: 0.4052, validation loss: 0.2055
2024-06-04 03:02:15 [INFO]: Epoch 013 - training loss: 0.4001, validation loss: 0.1941
2024-06-04 03:02:20 [INFO]: Epoch 014 - training loss: 0.3985, validation loss: 0.2001
2024-06-04 03:02:25 [INFO]: Epoch 015 - training loss: 0.4024, validation loss: 0.2019
2024-06-04 03:02:30 [INFO]: Epoch 016 - training loss: 0.3980, validation loss: 0.1918
2024-06-04 03:02:35 [INFO]: Epoch 017 - training loss: 0.3852, validation loss: 0.1930
2024-06-04 03:02:40 [INFO]: Epoch 018 - training loss: 0.3838, validation loss: 0.1923
2024-06-04 03:02:45 [INFO]: Epoch 019 - training loss: 0.3698, validation loss: 0.1839
2024-06-04 03:02:49 [INFO]: Epoch 020 - training loss: 0.3736, validation loss: 0.1829
2024-06-04 03:02:54 [INFO]: Epoch 021 - training loss: 0.3754, validation loss: 0.1885
2024-06-04 03:02:59 [INFO]: Epoch 022 - training loss: 0.3693, validation loss: 0.1814
2024-06-04 03:03:04 [INFO]: Epoch 023 - training loss: 0.3614, validation loss: 0.1846
2024-06-04 03:03:09 [INFO]: Epoch 024 - training loss: 0.3675, validation loss: 0.1871
2024-06-04 03:03:13 [INFO]: Epoch 025 - training loss: 0.3605, validation loss: 0.1829
2024-06-04 03:03:18 [INFO]: Epoch 026 - training loss: 0.3554, validation loss: 0.1821
2024-06-04 03:03:22 [INFO]: Epoch 027 - training loss: 0.3554, validation loss: 0.1834
2024-06-04 03:03:27 [INFO]: Epoch 028 - training loss: 0.3545, validation loss: 0.1830
2024-06-04 03:03:32 [INFO]: Epoch 029 - training loss: 0.3489, validation loss: 0.1825
2024-06-04 03:03:37 [INFO]: Epoch 030 - training loss: 0.3491, validation loss: 0.1811
2024-06-04 03:03:42 [INFO]: Epoch 031 - training loss: 0.3499, validation loss: 0.1807
2024-06-04 03:03:47 [INFO]: Epoch 032 - training loss: 0.3539, validation loss: 0.1806
2024-06-04 03:03:52 [INFO]: Epoch 033 - training loss: 0.3493, validation loss: 0.1804
2024-06-04 03:03:56 [INFO]: Epoch 034 - training loss: 0.3441, validation loss: 0.1794
2024-06-04 03:04:01 [INFO]: Epoch 035 - training loss: 0.3405, validation loss: 0.1807
2024-06-04 03:04:06 [INFO]: Epoch 036 - training loss: 0.3446, validation loss: 0.1819
2024-06-04 03:04:11 [INFO]: Epoch 037 - training loss: 0.3476, validation loss: 0.1850
2024-06-04 03:04:16 [INFO]: Epoch 038 - training loss: 0.3415, validation loss: 0.1755
2024-06-04 03:04:21 [INFO]: Epoch 039 - training loss: 0.3360, validation loss: 0.1768
2024-06-04 03:04:26 [INFO]: Epoch 040 - training loss: 0.3426, validation loss: 0.1818
2024-06-04 03:04:31 [INFO]: Epoch 041 - training loss: 0.3470, validation loss: 0.1817
2024-06-04 03:04:35 [INFO]: Epoch 042 - training loss: 0.3358, validation loss: 0.1840
2024-06-04 03:04:40 [INFO]: Epoch 043 - training loss: 0.3353, validation loss: 0.1770
2024-06-04 03:04:45 [INFO]: Epoch 044 - training loss: 0.3323, validation loss: 0.1802
2024-06-04 03:04:50 [INFO]: Epoch 045 - training loss: 0.3300, validation loss: 0.1787
2024-06-04 03:04:55 [INFO]: Epoch 046 - training loss: 0.3385, validation loss: 0.1773
2024-06-04 03:04:59 [INFO]: Epoch 047 - training loss: 0.3347, validation loss: 0.1749
2024-06-04 03:05:04 [INFO]: Epoch 048 - training loss: 0.3300, validation loss: 0.1793
2024-06-04 03:05:09 [INFO]: Epoch 049 - training loss: 0.3332, validation loss: 0.1796
2024-06-04 03:05:13 [INFO]: Epoch 050 - training loss: 0.3291, validation loss: 0.1735
2024-06-04 03:05:18 [INFO]: Epoch 051 - training loss: 0.3297, validation loss: 0.1754
2024-06-04 03:05:23 [INFO]: Epoch 052 - training loss: 0.3258, validation loss: 0.1737
2024-06-04 03:05:28 [INFO]: Epoch 053 - training loss: 0.3203, validation loss: 0.1701
2024-06-04 03:05:33 [INFO]: Epoch 054 - training loss: 0.3199, validation loss: 0.1730
2024-06-04 03:05:37 [INFO]: Epoch 055 - training loss: 0.3168, validation loss: 0.1734
2024-06-04 03:05:42 [INFO]: Epoch 056 - training loss: 0.3173, validation loss: 0.1732
2024-06-04 03:05:46 [INFO]: Epoch 057 - training loss: 0.3182, validation loss: 0.1708
2024-06-04 03:05:51 [INFO]: Epoch 058 - training loss: 0.3181, validation loss: 0.1730
2024-06-04 03:05:55 [INFO]: Epoch 059 - training loss: 0.3183, validation loss: 0.1723
2024-06-04 03:05:59 [INFO]: Epoch 060 - training loss: 0.3161, validation loss: 0.1701
2024-06-04 03:06:03 [INFO]: Epoch 061 - training loss: 0.3160, validation loss: 0.1664
2024-06-04 03:06:08 [INFO]: Epoch 062 - training loss: 0.3162, validation loss: 0.1679
2024-06-04 03:06:12 [INFO]: Epoch 063 - training loss: 0.3137, validation loss: 0.1691
2024-06-04 03:06:16 [INFO]: Epoch 064 - training loss: 0.3166, validation loss: 0.1681
2024-06-04 03:06:20 [INFO]: Epoch 065 - training loss: 0.3092, validation loss: 0.1666
2024-06-04 03:06:25 [INFO]: Epoch 066 - training loss: 0.3086, validation loss: 0.1680
2024-06-04 03:06:30 [INFO]: Epoch 067 - training loss: 0.3133, validation loss: 0.1628
2024-06-04 03:06:34 [INFO]: Epoch 068 - training loss: 0.3079, validation loss: 0.1619
2024-06-04 03:06:38 [INFO]: Epoch 069 - training loss: 0.3034, validation loss: 0.1629
2024-06-04 03:06:42 [INFO]: Epoch 070 - training loss: 0.3009, validation loss: 0.1635
2024-06-04 03:06:47 [INFO]: Epoch 071 - training loss: 0.3040, validation loss: 0.1649
2024-06-04 03:06:51 [INFO]: Epoch 072 - training loss: 0.3114, validation loss: 0.1636
2024-06-04 03:06:55 [INFO]: Epoch 073 - training loss: 0.3089, validation loss: 0.1628
2024-06-04 03:07:00 [INFO]: Epoch 074 - training loss: 0.3092, validation loss: 0.1645
2024-06-04 03:07:04 [INFO]: Epoch 075 - training loss: 0.3047, validation loss: 0.1574
2024-06-04 03:07:09 [INFO]: Epoch 076 - training loss: 0.3012, validation loss: 0.1617
2024-06-04 03:07:13 [INFO]: Epoch 077 - training loss: 0.3013, validation loss: 0.1589
2024-06-04 03:07:17 [INFO]: Epoch 078 - training loss: 0.3031, validation loss: 0.1567
2024-06-04 03:07:21 [INFO]: Epoch 079 - training loss: 0.3007, validation loss: 0.1549
2024-06-04 03:07:26 [INFO]: Epoch 080 - training loss: 0.3014, validation loss: 0.1553
2024-06-04 03:07:31 [INFO]: Epoch 081 - training loss: 0.3031, validation loss: 0.1553
2024-06-04 03:07:35 [INFO]: Epoch 082 - training loss: 0.3052, validation loss: 0.1573
2024-06-04 03:07:39 [INFO]: Epoch 083 - training loss: 0.3001, validation loss: 0.1537
2024-06-04 03:07:43 [INFO]: Epoch 084 - training loss: 0.3005, validation loss: 0.1497
2024-06-04 03:07:48 [INFO]: Epoch 085 - training loss: 0.2981, validation loss: 0.1569
2024-06-04 03:07:52 [INFO]: Epoch 086 - training loss: 0.2950, validation loss: 0.1530
2024-06-04 03:07:56 [INFO]: Epoch 087 - training loss: 0.2976, validation loss: 0.1512
2024-06-04 03:08:00 [INFO]: Epoch 088 - training loss: 0.2970, validation loss: 0.1522
2024-06-04 03:08:04 [INFO]: Epoch 089 - training loss: 0.2945, validation loss: 0.1533
2024-06-04 03:08:09 [INFO]: Epoch 090 - training loss: 0.2927, validation loss: 0.1508
2024-06-04 03:08:13 [INFO]: Epoch 091 - training loss: 0.2954, validation loss: 0.1532
2024-06-04 03:08:17 [INFO]: Epoch 092 - training loss: 0.2936, validation loss: 0.1517
2024-06-04 03:08:22 [INFO]: Epoch 093 - training loss: 0.2927, validation loss: 0.1533
2024-06-04 03:08:26 [INFO]: Epoch 094 - training loss: 0.2934, validation loss: 0.1504
2024-06-04 03:08:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:08:26 [INFO]: Finished training. The best model is from epoch#84.
2024-06-04 03:08:27 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_2/20240604_T030116/Pyraformer.pypots
2024-06-04 03:08:28 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_2/imputation.pkl
2024-06-04 03:08:28 [INFO]: Round2 - Pyraformer on BeijingAir: MAE=0.2253, MSE=0.2106, MRE=0.3404
2024-06-04 03:08:28 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:08:28 [INFO]: Using the given device: cuda:0
2024-06-04 03:08:28 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_3/20240604_T030828
2024-06-04 03:08:28 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_3/20240604_T030828/tensorboard
2024-06-04 03:08:29 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-04 03:08:33 [INFO]: Epoch 001 - training loss: 0.9688, validation loss: 0.3553
2024-06-04 03:08:37 [INFO]: Epoch 002 - training loss: 0.6454, validation loss: 0.3034
2024-06-04 03:08:41 [INFO]: Epoch 003 - training loss: 0.5795, validation loss: 0.2948
2024-06-04 03:08:46 [INFO]: Epoch 004 - training loss: 0.5353, validation loss: 0.2594
2024-06-04 03:08:50 [INFO]: Epoch 005 - training loss: 0.4988, validation loss: 0.2334
2024-06-04 03:08:54 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2286
2024-06-04 03:08:58 [INFO]: Epoch 007 - training loss: 0.4556, validation loss: 0.2266
2024-06-04 03:09:02 [INFO]: Epoch 008 - training loss: 0.4421, validation loss: 0.2236
2024-06-04 03:09:06 [INFO]: Epoch 009 - training loss: 0.4269, validation loss: 0.2170
2024-06-04 03:09:10 [INFO]: Epoch 010 - training loss: 0.4163, validation loss: 0.2123
2024-06-04 03:09:14 [INFO]: Epoch 011 - training loss: 0.4124, validation loss: 0.2152
2024-06-04 03:09:19 [INFO]: Epoch 012 - training loss: 0.4103, validation loss: 0.1981
2024-06-04 03:09:23 [INFO]: Epoch 013 - training loss: 0.3940, validation loss: 0.1993
2024-06-04 03:09:27 [INFO]: Epoch 014 - training loss: 0.3931, validation loss: 0.2021
2024-06-04 03:09:31 [INFO]: Epoch 015 - training loss: 0.3896, validation loss: 0.1917
2024-06-04 03:09:35 [INFO]: Epoch 016 - training loss: 0.3802, validation loss: 0.1887
2024-06-04 03:09:39 [INFO]: Epoch 017 - training loss: 0.3773, validation loss: 0.1956
2024-06-04 03:09:44 [INFO]: Epoch 018 - training loss: 0.3800, validation loss: 0.1859
2024-06-04 03:09:48 [INFO]: Epoch 019 - training loss: 0.3707, validation loss: 0.1803
2024-06-04 03:09:53 [INFO]: Epoch 020 - training loss: 0.3675, validation loss: 0.1857
2024-06-04 03:09:57 [INFO]: Epoch 021 - training loss: 0.3789, validation loss: 0.2061
2024-06-04 03:10:02 [INFO]: Epoch 022 - training loss: 0.3750, validation loss: 0.1867
2024-06-04 03:10:06 [INFO]: Epoch 023 - training loss: 0.3656, validation loss: 0.1814
2024-06-04 03:10:10 [INFO]: Epoch 024 - training loss: 0.3629, validation loss: 0.1855
2024-06-04 03:10:14 [INFO]: Epoch 025 - training loss: 0.3590, validation loss: 0.1835
2024-06-04 03:10:18 [INFO]: Epoch 026 - training loss: 0.3537, validation loss: 0.1842
2024-06-04 03:10:23 [INFO]: Epoch 027 - training loss: 0.3568, validation loss: 0.1793
2024-06-04 03:10:27 [INFO]: Epoch 028 - training loss: 0.3499, validation loss: 0.1775
2024-06-04 03:10:31 [INFO]: Epoch 029 - training loss: 0.3458, validation loss: 0.1778
2024-06-04 03:10:35 [INFO]: Epoch 030 - training loss: 0.3495, validation loss: 0.1866
2024-06-04 03:10:39 [INFO]: Epoch 031 - training loss: 0.3524, validation loss: 0.1842
2024-06-04 03:10:44 [INFO]: Epoch 032 - training loss: 0.3534, validation loss: 0.1794
2024-06-04 03:10:48 [INFO]: Epoch 033 - training loss: 0.3429, validation loss: 0.1820
2024-06-04 03:10:52 [INFO]: Epoch 034 - training loss: 0.3428, validation loss: 0.1813
2024-06-04 03:10:56 [INFO]: Epoch 035 - training loss: 0.3449, validation loss: 0.1771
2024-06-04 03:11:00 [INFO]: Epoch 036 - training loss: 0.3468, validation loss: 0.1789
2024-06-04 03:11:04 [INFO]: Epoch 037 - training loss: 0.3336, validation loss: 0.1732
2024-06-04 03:11:09 [INFO]: Epoch 038 - training loss: 0.3319, validation loss: 0.1774
2024-06-04 03:11:13 [INFO]: Epoch 039 - training loss: 0.3343, validation loss: 0.1724
2024-06-04 03:11:18 [INFO]: Epoch 040 - training loss: 0.3346, validation loss: 0.1750
2024-06-04 03:11:22 [INFO]: Epoch 041 - training loss: 0.3363, validation loss: 0.1790
2024-06-04 03:11:27 [INFO]: Epoch 042 - training loss: 0.3295, validation loss: 0.1788
2024-06-04 03:11:31 [INFO]: Epoch 043 - training loss: 0.3307, validation loss: 0.1748
2024-06-04 03:11:35 [INFO]: Epoch 044 - training loss: 0.3297, validation loss: 0.1729
2024-06-04 03:11:39 [INFO]: Epoch 045 - training loss: 0.3272, validation loss: 0.1728
2024-06-04 03:11:43 [INFO]: Epoch 046 - training loss: 0.3262, validation loss: 0.1773
2024-06-04 03:11:48 [INFO]: Epoch 047 - training loss: 0.3384, validation loss: 0.1738
2024-06-04 03:11:52 [INFO]: Epoch 048 - training loss: 0.3276, validation loss: 0.1725
2024-06-04 03:11:56 [INFO]: Epoch 049 - training loss: 0.3238, validation loss: 0.1734
2024-06-04 03:11:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:11:56 [INFO]: Finished training. The best model is from epoch#39.
2024-06-04 03:11:56 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_3/20240604_T030828/Pyraformer.pypots
2024-06-04 03:11:58 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_3/imputation.pkl
2024-06-04 03:11:58 [INFO]: Round3 - Pyraformer on BeijingAir: MAE=0.2296, MSE=0.2191, MRE=0.3470
2024-06-04 03:11:58 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:11:58 [INFO]: Using the given device: cuda:0
2024-06-04 03:11:58 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_4/20240604_T031158
2024-06-04 03:11:58 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_4/20240604_T031158/tensorboard
2024-06-04 03:11:58 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-04 03:12:03 [INFO]: Epoch 001 - training loss: 1.0021, validation loss: 0.3622
2024-06-04 03:12:07 [INFO]: Epoch 002 - training loss: 0.6602, validation loss: 0.2997
2024-06-04 03:12:11 [INFO]: Epoch 003 - training loss: 0.5936, validation loss: 0.2815
2024-06-04 03:12:16 [INFO]: Epoch 004 - training loss: 0.5567, validation loss: 0.2433
2024-06-04 03:12:20 [INFO]: Epoch 005 - training loss: 0.5056, validation loss: 0.2446
2024-06-04 03:12:25 [INFO]: Epoch 006 - training loss: 0.4775, validation loss: 0.2369
2024-06-04 03:12:29 [INFO]: Epoch 007 - training loss: 0.4557, validation loss: 0.2232
2024-06-04 03:12:33 [INFO]: Epoch 008 - training loss: 0.4470, validation loss: 0.2215
2024-06-04 03:12:37 [INFO]: Epoch 009 - training loss: 0.4328, validation loss: 0.2153
2024-06-04 03:12:41 [INFO]: Epoch 010 - training loss: 0.4253, validation loss: 0.2126
2024-06-04 03:12:46 [INFO]: Epoch 011 - training loss: 0.4196, validation loss: 0.2073
2024-06-04 03:12:50 [INFO]: Epoch 012 - training loss: 0.4071, validation loss: 0.2058
2024-06-04 03:12:54 [INFO]: Epoch 013 - training loss: 0.4034, validation loss: 0.1979
2024-06-04 03:12:59 [INFO]: Epoch 014 - training loss: 0.3924, validation loss: 0.2009
2024-06-04 03:13:03 [INFO]: Epoch 015 - training loss: 0.4018, validation loss: 0.1961
2024-06-04 03:13:07 [INFO]: Epoch 016 - training loss: 0.3872, validation loss: 0.1924
2024-06-04 03:13:12 [INFO]: Epoch 017 - training loss: 0.3827, validation loss: 0.1894
2024-06-04 03:13:15 [INFO]: Epoch 018 - training loss: 0.3732, validation loss: 0.1887
2024-06-04 03:13:19 [INFO]: Epoch 019 - training loss: 0.3730, validation loss: 0.1903
2024-06-04 03:13:23 [INFO]: Epoch 020 - training loss: 0.3756, validation loss: 0.1883
2024-06-04 03:13:25 [INFO]: Epoch 021 - training loss: 0.3700, validation loss: 0.1848
2024-06-04 03:13:29 [INFO]: Epoch 022 - training loss: 0.3620, validation loss: 0.1839
2024-06-04 03:13:33 [INFO]: Epoch 023 - training loss: 0.3654, validation loss: 0.1808
2024-06-04 03:13:37 [INFO]: Epoch 024 - training loss: 0.3611, validation loss: 0.1842
2024-06-04 03:13:42 [INFO]: Epoch 025 - training loss: 0.3622, validation loss: 0.1822
2024-06-04 03:13:46 [INFO]: Epoch 026 - training loss: 0.3585, validation loss: 0.1815
2024-06-04 03:13:51 [INFO]: Epoch 027 - training loss: 0.3534, validation loss: 0.1837
2024-06-04 03:13:55 [INFO]: Epoch 028 - training loss: 0.3488, validation loss: 0.1837
2024-06-04 03:14:00 [INFO]: Epoch 029 - training loss: 0.3492, validation loss: 0.1765
2024-06-04 03:14:04 [INFO]: Epoch 030 - training loss: 0.3475, validation loss: 0.1830
2024-06-04 03:14:08 [INFO]: Epoch 031 - training loss: 0.3436, validation loss: 0.1797
2024-06-04 03:14:12 [INFO]: Epoch 032 - training loss: 0.3494, validation loss: 0.1814
2024-06-04 03:14:16 [INFO]: Epoch 033 - training loss: 0.3423, validation loss: 0.1737
2024-06-04 03:14:21 [INFO]: Epoch 034 - training loss: 0.3375, validation loss: 0.1808
2024-06-04 03:14:25 [INFO]: Epoch 035 - training loss: 0.3406, validation loss: 0.1781
2024-06-04 03:14:29 [INFO]: Epoch 036 - training loss: 0.3371, validation loss: 0.1750
2024-06-04 03:14:33 [INFO]: Epoch 037 - training loss: 0.3350, validation loss: 0.1754
2024-06-04 03:14:38 [INFO]: Epoch 038 - training loss: 0.3339, validation loss: 0.1748
2024-06-04 03:14:42 [INFO]: Epoch 039 - training loss: 0.3315, validation loss: 0.1783
2024-06-04 03:14:46 [INFO]: Epoch 040 - training loss: 0.3374, validation loss: 0.1771
2024-06-04 03:14:50 [INFO]: Epoch 041 - training loss: 0.3353, validation loss: 0.1814
2024-06-04 03:14:54 [INFO]: Epoch 042 - training loss: 0.3353, validation loss: 0.1756
2024-06-04 03:14:58 [INFO]: Epoch 043 - training loss: 0.3327, validation loss: 0.1768
2024-06-04 03:14:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:14:58 [INFO]: Finished training. The best model is from epoch#33.
2024-06-04 03:14:58 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_4/20240604_T031158/Pyraformer.pypots
2024-06-04 03:15:00 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Pyraformer_BeijingAir/round_4/imputation.pkl
2024-06-04 03:15:00 [INFO]: Round4 - Pyraformer on BeijingAir: MAE=0.2280, MSE=0.2227, MRE=0.3445
2024-06-04 03:15:00 [INFO]: Done! Final results:
Averaged Pyraformer (3,230,212 params) on BeijingAir: MAE=0.1779 ± 0.003996293655612839, MSE=0.1505 ± 0.012175686361807018, MRE=0.2366 ± 0.005315350287192963, average inference time=0.39