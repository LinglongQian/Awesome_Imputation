2024-06-04 02:49:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:49:23 [INFO]: Using the given device: cuda:0
2024-06-04 02:49:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_0/20240604_T024924
2024-06-04 02:49:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_0/20240604_T024924/tensorboard
2024-06-04 02:49:25 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-04 02:49:38 [INFO]: Epoch 001 - training loss: 1.0739, validation loss: 0.4630
2024-06-04 02:49:44 [INFO]: Epoch 002 - training loss: 0.6773, validation loss: 0.3470
2024-06-04 02:49:50 [INFO]: Epoch 003 - training loss: 0.5545, validation loss: 0.2965
2024-06-04 02:49:57 [INFO]: Epoch 004 - training loss: 0.5072, validation loss: 0.2764
2024-06-04 02:50:03 [INFO]: Epoch 005 - training loss: 0.4733, validation loss: 0.2567
2024-06-04 02:50:10 [INFO]: Epoch 006 - training loss: 0.4391, validation loss: 0.2476
2024-06-04 02:50:17 [INFO]: Epoch 007 - training loss: 0.4239, validation loss: 0.2405
2024-06-04 02:50:23 [INFO]: Epoch 008 - training loss: 0.4098, validation loss: 0.2303
2024-06-04 02:50:30 [INFO]: Epoch 009 - training loss: 0.3989, validation loss: 0.2233
2024-06-04 02:50:36 [INFO]: Epoch 010 - training loss: 0.3882, validation loss: 0.2195
2024-06-04 02:50:42 [INFO]: Epoch 011 - training loss: 0.3818, validation loss: 0.2147
2024-06-04 02:50:49 [INFO]: Epoch 012 - training loss: 0.3719, validation loss: 0.2123
2024-06-04 02:50:55 [INFO]: Epoch 013 - training loss: 0.3695, validation loss: 0.2094
2024-06-04 02:51:02 [INFO]: Epoch 014 - training loss: 0.3655, validation loss: 0.2075
2024-06-04 02:51:08 [INFO]: Epoch 015 - training loss: 0.3654, validation loss: 0.2068
2024-06-04 02:51:14 [INFO]: Epoch 016 - training loss: 0.3559, validation loss: 0.2021
2024-06-04 02:51:21 [INFO]: Epoch 017 - training loss: 0.3520, validation loss: 0.2032
2024-06-04 02:51:27 [INFO]: Epoch 018 - training loss: 0.3500, validation loss: 0.1996
2024-06-04 02:51:34 [INFO]: Epoch 019 - training loss: 0.3495, validation loss: 0.2013
2024-06-04 02:51:40 [INFO]: Epoch 020 - training loss: 0.3487, validation loss: 0.1987
2024-06-04 02:51:47 [INFO]: Epoch 021 - training loss: 0.3449, validation loss: 0.1970
2024-06-04 02:51:53 [INFO]: Epoch 022 - training loss: 0.3416, validation loss: 0.1973
2024-06-04 02:52:00 [INFO]: Epoch 023 - training loss: 0.3471, validation loss: 0.1987
2024-06-04 02:52:06 [INFO]: Epoch 024 - training loss: 0.3448, validation loss: 0.1976
2024-06-04 02:52:13 [INFO]: Epoch 025 - training loss: 0.3407, validation loss: 0.1956
2024-06-04 02:52:19 [INFO]: Epoch 026 - training loss: 0.3365, validation loss: 0.1961
2024-06-04 02:52:25 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.1917
2024-06-04 02:52:32 [INFO]: Epoch 028 - training loss: 0.3282, validation loss: 0.1930
2024-06-04 02:52:38 [INFO]: Epoch 029 - training loss: 0.3292, validation loss: 0.1906
2024-06-04 02:52:44 [INFO]: Epoch 030 - training loss: 0.3281, validation loss: 0.1917
2024-06-04 02:52:51 [INFO]: Epoch 031 - training loss: 0.3293, validation loss: 0.1897
2024-06-04 02:52:57 [INFO]: Epoch 032 - training loss: 0.3261, validation loss: 0.1882
2024-06-04 02:53:03 [INFO]: Epoch 033 - training loss: 0.3257, validation loss: 0.1905
2024-06-04 02:53:10 [INFO]: Epoch 034 - training loss: 0.3242, validation loss: 0.1864
2024-06-04 02:53:17 [INFO]: Epoch 035 - training loss: 0.3274, validation loss: 0.1884
2024-06-04 02:53:23 [INFO]: Epoch 036 - training loss: 0.3267, validation loss: 0.1891
2024-06-04 02:53:29 [INFO]: Epoch 037 - training loss: 0.3229, validation loss: 0.1884
2024-06-04 02:53:35 [INFO]: Epoch 038 - training loss: 0.3186, validation loss: 0.1874
2024-06-04 02:53:41 [INFO]: Epoch 039 - training loss: 0.3188, validation loss: 0.1845
2024-06-04 02:53:48 [INFO]: Epoch 040 - training loss: 0.3176, validation loss: 0.1860
2024-06-04 02:53:54 [INFO]: Epoch 041 - training loss: 0.3163, validation loss: 0.1850
2024-06-04 02:54:01 [INFO]: Epoch 042 - training loss: 0.3111, validation loss: 0.1841
2024-06-04 02:54:08 [INFO]: Epoch 043 - training loss: 0.3143, validation loss: 0.1858
2024-06-04 02:54:14 [INFO]: Epoch 044 - training loss: 0.3113, validation loss: 0.1843
2024-06-04 02:54:20 [INFO]: Epoch 045 - training loss: 0.3097, validation loss: 0.1832
2024-06-04 02:54:26 [INFO]: Epoch 046 - training loss: 0.3089, validation loss: 0.1837
2024-06-04 02:54:33 [INFO]: Epoch 047 - training loss: 0.3118, validation loss: 0.1832
2024-06-04 02:54:39 [INFO]: Epoch 048 - training loss: 0.3119, validation loss: 0.1852
2024-06-04 02:54:45 [INFO]: Epoch 049 - training loss: 0.3085, validation loss: 0.1825
2024-06-04 02:54:51 [INFO]: Epoch 050 - training loss: 0.3095, validation loss: 0.1856
2024-06-04 02:54:57 [INFO]: Epoch 051 - training loss: 0.3117, validation loss: 0.1842
2024-06-04 02:55:04 [INFO]: Epoch 052 - training loss: 0.3082, validation loss: 0.1839
2024-06-04 02:55:11 [INFO]: Epoch 053 - training loss: 0.3071, validation loss: 0.1820
2024-06-04 02:55:17 [INFO]: Epoch 054 - training loss: 0.3079, validation loss: 0.1825
2024-06-04 02:55:24 [INFO]: Epoch 055 - training loss: 0.3036, validation loss: 0.1797
2024-06-04 02:55:30 [INFO]: Epoch 056 - training loss: 0.3029, validation loss: 0.1798
2024-06-04 02:55:37 [INFO]: Epoch 057 - training loss: 0.2999, validation loss: 0.1802
2024-06-04 02:55:43 [INFO]: Epoch 058 - training loss: 0.3019, validation loss: 0.1807
2024-06-04 02:55:49 [INFO]: Epoch 059 - training loss: 0.3013, validation loss: 0.1814
2024-06-04 02:55:56 [INFO]: Epoch 060 - training loss: 0.2987, validation loss: 0.1794
2024-06-04 02:56:02 [INFO]: Epoch 061 - training loss: 0.2992, validation loss: 0.1798
2024-06-04 02:56:08 [INFO]: Epoch 062 - training loss: 0.2991, validation loss: 0.1795
2024-06-04 02:56:14 [INFO]: Epoch 063 - training loss: 0.2969, validation loss: 0.1780
2024-06-04 02:56:21 [INFO]: Epoch 064 - training loss: 0.2968, validation loss: 0.1789
2024-06-04 02:56:27 [INFO]: Epoch 065 - training loss: 0.2952, validation loss: 0.1761
2024-06-04 02:56:33 [INFO]: Epoch 066 - training loss: 0.2966, validation loss: 0.1786
2024-06-04 02:56:40 [INFO]: Epoch 067 - training loss: 0.2973, validation loss: 0.1783
2024-06-04 02:56:46 [INFO]: Epoch 068 - training loss: 0.2961, validation loss: 0.1773
2024-06-04 02:56:52 [INFO]: Epoch 069 - training loss: 0.2947, validation loss: 0.1777
2024-06-04 02:56:59 [INFO]: Epoch 070 - training loss: 0.2944, validation loss: 0.1761
2024-06-04 02:57:05 [INFO]: Epoch 071 - training loss: 0.2917, validation loss: 0.1766
2024-06-04 02:57:11 [INFO]: Epoch 072 - training loss: 0.2905, validation loss: 0.1765
2024-06-04 02:57:18 [INFO]: Epoch 073 - training loss: 0.2904, validation loss: 0.1770
2024-06-04 02:57:24 [INFO]: Epoch 074 - training loss: 0.2921, validation loss: 0.1770
2024-06-04 02:57:30 [INFO]: Epoch 075 - training loss: 0.2928, validation loss: 0.1797
2024-06-04 02:57:37 [INFO]: Epoch 076 - training loss: 0.2936, validation loss: 0.1756
2024-06-04 02:57:43 [INFO]: Epoch 077 - training loss: 0.2896, validation loss: 0.1775
2024-06-04 02:57:50 [INFO]: Epoch 078 - training loss: 0.2936, validation loss: 0.1784
2024-06-04 02:57:56 [INFO]: Epoch 079 - training loss: 0.2989, validation loss: 0.1765
2024-06-04 02:58:03 [INFO]: Epoch 080 - training loss: 0.2966, validation loss: 0.1810
2024-06-04 02:58:09 [INFO]: Epoch 081 - training loss: 0.2946, validation loss: 0.1760
2024-06-04 02:58:16 [INFO]: Epoch 082 - training loss: 0.2899, validation loss: 0.1769
2024-06-04 02:58:22 [INFO]: Epoch 083 - training loss: 0.2887, validation loss: 0.1755
2024-06-04 02:58:28 [INFO]: Epoch 084 - training loss: 0.2869, validation loss: 0.1739
2024-06-04 02:58:34 [INFO]: Epoch 085 - training loss: 0.2856, validation loss: 0.1757
2024-06-04 02:58:41 [INFO]: Epoch 086 - training loss: 0.2865, validation loss: 0.1734
2024-06-04 02:58:47 [INFO]: Epoch 087 - training loss: 0.2865, validation loss: 0.1738
2024-06-04 02:58:54 [INFO]: Epoch 088 - training loss: 0.2849, validation loss: 0.1732
2024-06-04 02:59:00 [INFO]: Epoch 089 - training loss: 0.2857, validation loss: 0.1737
2024-06-04 02:59:06 [INFO]: Epoch 090 - training loss: 0.2839, validation loss: 0.1745
2024-06-04 02:59:13 [INFO]: Epoch 091 - training loss: 0.2825, validation loss: 0.1731
2024-06-04 02:59:19 [INFO]: Epoch 092 - training loss: 0.2839, validation loss: 0.1731
2024-06-04 02:59:26 [INFO]: Epoch 093 - training loss: 0.2824, validation loss: 0.1719
2024-06-04 02:59:32 [INFO]: Epoch 094 - training loss: 0.2816, validation loss: 0.1719
2024-06-04 02:59:38 [INFO]: Epoch 095 - training loss: 0.2808, validation loss: 0.1721
2024-06-04 02:59:45 [INFO]: Epoch 096 - training loss: 0.2819, validation loss: 0.1740
2024-06-04 02:59:51 [INFO]: Epoch 097 - training loss: 0.2843, validation loss: 0.1735
2024-06-04 02:59:58 [INFO]: Epoch 098 - training loss: 0.2806, validation loss: 0.1716
2024-06-04 03:00:04 [INFO]: Epoch 099 - training loss: 0.2775, validation loss: 0.1710
2024-06-04 03:00:10 [INFO]: Epoch 100 - training loss: 0.2783, validation loss: 0.1706
2024-06-04 03:00:10 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 03:00:10 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_0/20240604_T024924/StemGNN.pypots
2024-06-04 03:00:14 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_0/imputation.pkl
2024-06-04 03:00:14 [INFO]: Round0 - StemGNN on BeijingAir: MAE=0.2059, MSE=0.2108, MRE=0.3110
2024-06-04 03:00:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:00:14 [INFO]: Using the given device: cuda:0
2024-06-04 03:00:14 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_1/20240604_T030014
2024-06-04 03:00:14 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_1/20240604_T030014/tensorboard
2024-06-04 03:00:14 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-04 03:00:21 [INFO]: Epoch 001 - training loss: 1.1003, validation loss: 0.4846
2024-06-04 03:00:27 [INFO]: Epoch 002 - training loss: 0.6938, validation loss: 0.3479
2024-06-04 03:00:34 [INFO]: Epoch 003 - training loss: 0.5557, validation loss: 0.2954
2024-06-04 03:00:40 [INFO]: Epoch 004 - training loss: 0.4987, validation loss: 0.2750
2024-06-04 03:00:47 [INFO]: Epoch 005 - training loss: 0.4678, validation loss: 0.2546
2024-06-04 03:00:53 [INFO]: Epoch 006 - training loss: 0.4389, validation loss: 0.2410
2024-06-04 03:01:00 [INFO]: Epoch 007 - training loss: 0.4279, validation loss: 0.2368
2024-06-04 03:01:06 [INFO]: Epoch 008 - training loss: 0.4117, validation loss: 0.2301
2024-06-04 03:01:13 [INFO]: Epoch 009 - training loss: 0.4041, validation loss: 0.2262
2024-06-04 03:01:19 [INFO]: Epoch 010 - training loss: 0.3958, validation loss: 0.2212
2024-06-04 03:01:25 [INFO]: Epoch 011 - training loss: 0.3882, validation loss: 0.2174
2024-06-04 03:01:31 [INFO]: Epoch 012 - training loss: 0.3846, validation loss: 0.2146
2024-06-04 03:01:36 [INFO]: Epoch 013 - training loss: 0.3771, validation loss: 0.2135
2024-06-04 03:01:41 [INFO]: Epoch 014 - training loss: 0.3703, validation loss: 0.2090
2024-06-04 03:01:46 [INFO]: Epoch 015 - training loss: 0.3670, validation loss: 0.2121
2024-06-04 03:01:52 [INFO]: Epoch 016 - training loss: 0.3668, validation loss: 0.2075
2024-06-04 03:01:59 [INFO]: Epoch 017 - training loss: 0.3600, validation loss: 0.2051
2024-06-04 03:02:05 [INFO]: Epoch 018 - training loss: 0.3575, validation loss: 0.2027
2024-06-04 03:02:11 [INFO]: Epoch 019 - training loss: 0.3541, validation loss: 0.2044
2024-06-04 03:02:18 [INFO]: Epoch 020 - training loss: 0.3510, validation loss: 0.2014
2024-06-04 03:02:24 [INFO]: Epoch 021 - training loss: 0.3483, validation loss: 0.1977
2024-06-04 03:02:30 [INFO]: Epoch 022 - training loss: 0.3461, validation loss: 0.1983
2024-06-04 03:02:37 [INFO]: Epoch 023 - training loss: 0.3482, validation loss: 0.1982
2024-06-04 03:02:43 [INFO]: Epoch 024 - training loss: 0.3437, validation loss: 0.1969
2024-06-04 03:02:49 [INFO]: Epoch 025 - training loss: 0.3447, validation loss: 0.1947
2024-06-04 03:02:55 [INFO]: Epoch 026 - training loss: 0.3401, validation loss: 0.1961
2024-06-04 03:03:02 [INFO]: Epoch 027 - training loss: 0.3360, validation loss: 0.1956
2024-06-04 03:03:09 [INFO]: Epoch 028 - training loss: 0.3343, validation loss: 0.1927
2024-06-04 03:03:15 [INFO]: Epoch 029 - training loss: 0.3346, validation loss: 0.1912
2024-06-04 03:03:21 [INFO]: Epoch 030 - training loss: 0.3344, validation loss: 0.1920
2024-06-04 03:03:28 [INFO]: Epoch 031 - training loss: 0.3339, validation loss: 0.1920
2024-06-04 03:03:34 [INFO]: Epoch 032 - training loss: 0.3342, validation loss: 0.1918
2024-06-04 03:03:40 [INFO]: Epoch 033 - training loss: 0.3278, validation loss: 0.1906
2024-06-04 03:03:47 [INFO]: Epoch 034 - training loss: 0.3281, validation loss: 0.1918
2024-06-04 03:03:53 [INFO]: Epoch 035 - training loss: 0.3267, validation loss: 0.1899
2024-06-04 03:04:00 [INFO]: Epoch 036 - training loss: 0.3242, validation loss: 0.1898
2024-06-04 03:04:06 [INFO]: Epoch 037 - training loss: 0.3240, validation loss: 0.1890
2024-06-04 03:04:12 [INFO]: Epoch 038 - training loss: 0.3247, validation loss: 0.1878
2024-06-04 03:04:19 [INFO]: Epoch 039 - training loss: 0.3210, validation loss: 0.1886
2024-06-04 03:04:25 [INFO]: Epoch 040 - training loss: 0.3174, validation loss: 0.1872
2024-06-04 03:04:32 [INFO]: Epoch 041 - training loss: 0.3187, validation loss: 0.1875
2024-06-04 03:04:38 [INFO]: Epoch 042 - training loss: 0.3206, validation loss: 0.1841
2024-06-04 03:04:44 [INFO]: Epoch 043 - training loss: 0.3160, validation loss: 0.1867
2024-06-04 03:04:50 [INFO]: Epoch 044 - training loss: 0.3159, validation loss: 0.1864
2024-06-04 03:04:57 [INFO]: Epoch 045 - training loss: 0.3146, validation loss: 0.1872
2024-06-04 03:05:03 [INFO]: Epoch 046 - training loss: 0.3165, validation loss: 0.1847
2024-06-04 03:05:10 [INFO]: Epoch 047 - training loss: 0.3166, validation loss: 0.1840
2024-06-04 03:05:16 [INFO]: Epoch 048 - training loss: 0.3177, validation loss: 0.1863
2024-06-04 03:05:22 [INFO]: Epoch 049 - training loss: 0.3153, validation loss: 0.1856
2024-06-04 03:05:29 [INFO]: Epoch 050 - training loss: 0.3117, validation loss: 0.1828
2024-06-04 03:05:35 [INFO]: Epoch 051 - training loss: 0.3069, validation loss: 0.1832
2024-06-04 03:05:42 [INFO]: Epoch 052 - training loss: 0.3116, validation loss: 0.1835
2024-06-04 03:05:48 [INFO]: Epoch 053 - training loss: 0.3107, validation loss: 0.1815
2024-06-04 03:05:54 [INFO]: Epoch 054 - training loss: 0.3092, validation loss: 0.1829
2024-06-04 03:06:00 [INFO]: Epoch 055 - training loss: 0.3093, validation loss: 0.1831
2024-06-04 03:06:06 [INFO]: Epoch 056 - training loss: 0.3084, validation loss: 0.1812
2024-06-04 03:06:11 [INFO]: Epoch 057 - training loss: 0.3088, validation loss: 0.1818
2024-06-04 03:06:17 [INFO]: Epoch 058 - training loss: 0.3101, validation loss: 0.1827
2024-06-04 03:06:23 [INFO]: Epoch 059 - training loss: 0.3046, validation loss: 0.1815
2024-06-04 03:06:28 [INFO]: Epoch 060 - training loss: 0.3042, validation loss: 0.1817
2024-06-04 03:06:34 [INFO]: Epoch 061 - training loss: 0.3040, validation loss: 0.1820
2024-06-04 03:06:40 [INFO]: Epoch 062 - training loss: 0.3010, validation loss: 0.1801
2024-06-04 03:06:46 [INFO]: Epoch 063 - training loss: 0.3014, validation loss: 0.1786
2024-06-04 03:06:52 [INFO]: Epoch 064 - training loss: 0.2996, validation loss: 0.1812
2024-06-04 03:06:57 [INFO]: Epoch 065 - training loss: 0.3004, validation loss: 0.1807
2024-06-04 03:07:03 [INFO]: Epoch 066 - training loss: 0.3008, validation loss: 0.1807
2024-06-04 03:07:09 [INFO]: Epoch 067 - training loss: 0.2993, validation loss: 0.1807
2024-06-04 03:07:14 [INFO]: Epoch 068 - training loss: 0.3031, validation loss: 0.1814
2024-06-04 03:07:20 [INFO]: Epoch 069 - training loss: 0.3001, validation loss: 0.1815
2024-06-04 03:07:26 [INFO]: Epoch 070 - training loss: 0.3013, validation loss: 0.1798
2024-06-04 03:07:32 [INFO]: Epoch 071 - training loss: 0.2961, validation loss: 0.1788
2024-06-04 03:07:38 [INFO]: Epoch 072 - training loss: 0.2950, validation loss: 0.1792
2024-06-04 03:07:44 [INFO]: Epoch 073 - training loss: 0.2964, validation loss: 0.1807
2024-06-04 03:07:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:07:44 [INFO]: Finished training. The best model is from epoch#63.
2024-06-04 03:07:44 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_1/20240604_T030014/StemGNN.pypots
2024-06-04 03:07:46 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_1/imputation.pkl
2024-06-04 03:07:46 [INFO]: Round1 - StemGNN on BeijingAir: MAE=0.2085, MSE=0.2123, MRE=0.3150
2024-06-04 03:07:46 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:07:46 [INFO]: Using the given device: cuda:0
2024-06-04 03:07:47 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_2/20240604_T030746
2024-06-04 03:07:47 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_2/20240604_T030746/tensorboard
2024-06-04 03:07:47 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-04 03:07:53 [INFO]: Epoch 001 - training loss: 1.1009, validation loss: 0.4838
2024-06-04 03:07:59 [INFO]: Epoch 002 - training loss: 0.6928, validation loss: 0.3529
2024-06-04 03:08:04 [INFO]: Epoch 003 - training loss: 0.5685, validation loss: 0.3046
2024-06-04 03:08:10 [INFO]: Epoch 004 - training loss: 0.5018, validation loss: 0.2740
2024-06-04 03:08:16 [INFO]: Epoch 005 - training loss: 0.4626, validation loss: 0.2529
2024-06-04 03:08:22 [INFO]: Epoch 006 - training loss: 0.4411, validation loss: 0.2445
2024-06-04 03:08:27 [INFO]: Epoch 007 - training loss: 0.4250, validation loss: 0.2340
2024-06-04 03:08:33 [INFO]: Epoch 008 - training loss: 0.4074, validation loss: 0.2287
2024-06-04 03:08:39 [INFO]: Epoch 009 - training loss: 0.4009, validation loss: 0.2242
2024-06-04 03:08:45 [INFO]: Epoch 010 - training loss: 0.3877, validation loss: 0.2201
2024-06-04 03:08:50 [INFO]: Epoch 011 - training loss: 0.3815, validation loss: 0.2152
2024-06-04 03:08:56 [INFO]: Epoch 012 - training loss: 0.3752, validation loss: 0.2133
2024-06-04 03:09:02 [INFO]: Epoch 013 - training loss: 0.3739, validation loss: 0.2119
2024-06-04 03:09:08 [INFO]: Epoch 014 - training loss: 0.3671, validation loss: 0.2062
2024-06-04 03:09:13 [INFO]: Epoch 015 - training loss: 0.3665, validation loss: 0.2070
2024-06-04 03:09:19 [INFO]: Epoch 016 - training loss: 0.3611, validation loss: 0.2054
2024-06-04 03:09:25 [INFO]: Epoch 017 - training loss: 0.3569, validation loss: 0.2005
2024-06-04 03:09:31 [INFO]: Epoch 018 - training loss: 0.3530, validation loss: 0.2024
2024-06-04 03:09:37 [INFO]: Epoch 019 - training loss: 0.3507, validation loss: 0.2004
2024-06-04 03:09:42 [INFO]: Epoch 020 - training loss: 0.3495, validation loss: 0.1984
2024-06-04 03:09:48 [INFO]: Epoch 021 - training loss: 0.3487, validation loss: 0.1974
2024-06-04 03:09:54 [INFO]: Epoch 022 - training loss: 0.3475, validation loss: 0.1977
2024-06-04 03:10:00 [INFO]: Epoch 023 - training loss: 0.3421, validation loss: 0.1947
2024-06-04 03:10:06 [INFO]: Epoch 024 - training loss: 0.3388, validation loss: 0.1935
2024-06-04 03:10:12 [INFO]: Epoch 025 - training loss: 0.3372, validation loss: 0.1928
2024-06-04 03:10:18 [INFO]: Epoch 026 - training loss: 0.3338, validation loss: 0.1919
2024-06-04 03:10:23 [INFO]: Epoch 027 - training loss: 0.3363, validation loss: 0.1932
2024-06-04 03:10:29 [INFO]: Epoch 028 - training loss: 0.3319, validation loss: 0.1901
2024-06-04 03:10:35 [INFO]: Epoch 029 - training loss: 0.3299, validation loss: 0.1900
2024-06-04 03:10:41 [INFO]: Epoch 030 - training loss: 0.3322, validation loss: 0.1891
2024-06-04 03:10:46 [INFO]: Epoch 031 - training loss: 0.3299, validation loss: 0.1927
2024-06-04 03:10:53 [INFO]: Epoch 032 - training loss: 0.3332, validation loss: 0.1877
2024-06-04 03:10:58 [INFO]: Epoch 033 - training loss: 0.3262, validation loss: 0.1891
2024-06-04 03:11:05 [INFO]: Epoch 034 - training loss: 0.3246, validation loss: 0.1862
2024-06-04 03:11:10 [INFO]: Epoch 035 - training loss: 0.3229, validation loss: 0.1859
2024-06-04 03:11:16 [INFO]: Epoch 036 - training loss: 0.3213, validation loss: 0.1866
2024-06-04 03:11:22 [INFO]: Epoch 037 - training loss: 0.3225, validation loss: 0.1867
2024-06-04 03:11:27 [INFO]: Epoch 038 - training loss: 0.3229, validation loss: 0.1863
2024-06-04 03:11:33 [INFO]: Epoch 039 - training loss: 0.3216, validation loss: 0.1849
2024-06-04 03:11:39 [INFO]: Epoch 040 - training loss: 0.3191, validation loss: 0.1867
2024-06-04 03:11:45 [INFO]: Epoch 041 - training loss: 0.3190, validation loss: 0.1844
2024-06-04 03:11:51 [INFO]: Epoch 042 - training loss: 0.3193, validation loss: 0.1865
2024-06-04 03:11:56 [INFO]: Epoch 043 - training loss: 0.3159, validation loss: 0.1861
2024-06-04 03:12:02 [INFO]: Epoch 044 - training loss: 0.3161, validation loss: 0.1822
2024-06-04 03:12:08 [INFO]: Epoch 045 - training loss: 0.3155, validation loss: 0.1834
2024-06-04 03:12:14 [INFO]: Epoch 046 - training loss: 0.3148, validation loss: 0.1838
2024-06-04 03:12:19 [INFO]: Epoch 047 - training loss: 0.3171, validation loss: 0.1850
2024-06-04 03:12:25 [INFO]: Epoch 048 - training loss: 0.3137, validation loss: 0.1818
2024-06-04 03:12:31 [INFO]: Epoch 049 - training loss: 0.3116, validation loss: 0.1811
2024-06-04 03:12:36 [INFO]: Epoch 050 - training loss: 0.3097, validation loss: 0.1834
2024-06-04 03:12:42 [INFO]: Epoch 051 - training loss: 0.3122, validation loss: 0.1823
2024-06-04 03:12:48 [INFO]: Epoch 052 - training loss: 0.3125, validation loss: 0.1817
2024-06-04 03:12:54 [INFO]: Epoch 053 - training loss: 0.3083, validation loss: 0.1827
2024-06-04 03:12:59 [INFO]: Epoch 054 - training loss: 0.3080, validation loss: 0.1818
2024-06-04 03:13:05 [INFO]: Epoch 055 - training loss: 0.3104, validation loss: 0.1834
2024-06-04 03:13:11 [INFO]: Epoch 056 - training loss: 0.3058, validation loss: 0.1815
2024-06-04 03:13:16 [INFO]: Epoch 057 - training loss: 0.3072, validation loss: 0.1818
2024-06-04 03:13:20 [INFO]: Epoch 058 - training loss: 0.3064, validation loss: 0.1801
2024-06-04 03:13:25 [INFO]: Epoch 059 - training loss: 0.3059, validation loss: 0.1828
2024-06-04 03:13:29 [INFO]: Epoch 060 - training loss: 0.3048, validation loss: 0.1827
2024-06-04 03:13:35 [INFO]: Epoch 061 - training loss: 0.3045, validation loss: 0.1802
2024-06-04 03:13:41 [INFO]: Epoch 062 - training loss: 0.3017, validation loss: 0.1796
2024-06-04 03:13:46 [INFO]: Epoch 063 - training loss: 0.3012, validation loss: 0.1776
2024-06-04 03:13:52 [INFO]: Epoch 064 - training loss: 0.3012, validation loss: 0.1767
2024-06-04 03:13:58 [INFO]: Epoch 065 - training loss: 0.3005, validation loss: 0.1769
2024-06-04 03:14:04 [INFO]: Epoch 066 - training loss: 0.3004, validation loss: 0.1785
2024-06-04 03:14:09 [INFO]: Epoch 067 - training loss: 0.2981, validation loss: 0.1792
2024-06-04 03:14:15 [INFO]: Epoch 068 - training loss: 0.2990, validation loss: 0.1789
2024-06-04 03:14:21 [INFO]: Epoch 069 - training loss: 0.3005, validation loss: 0.1782
2024-06-04 03:14:27 [INFO]: Epoch 070 - training loss: 0.3011, validation loss: 0.1777
2024-06-04 03:14:33 [INFO]: Epoch 071 - training loss: 0.2983, validation loss: 0.1801
2024-06-04 03:14:39 [INFO]: Epoch 072 - training loss: 0.2986, validation loss: 0.1772
2024-06-04 03:14:45 [INFO]: Epoch 073 - training loss: 0.2959, validation loss: 0.1760
2024-06-04 03:14:50 [INFO]: Epoch 074 - training loss: 0.2961, validation loss: 0.1789
2024-06-04 03:14:56 [INFO]: Epoch 075 - training loss: 0.2960, validation loss: 0.1772
2024-06-04 03:15:02 [INFO]: Epoch 076 - training loss: 0.2955, validation loss: 0.1779
2024-06-04 03:15:07 [INFO]: Epoch 077 - training loss: 0.2944, validation loss: 0.1748
2024-06-04 03:15:12 [INFO]: Epoch 078 - training loss: 0.2966, validation loss: 0.1782
2024-06-04 03:15:18 [INFO]: Epoch 079 - training loss: 0.2938, validation loss: 0.1776
2024-06-04 03:15:23 [INFO]: Epoch 080 - training loss: 0.2919, validation loss: 0.1758
2024-06-04 03:15:28 [INFO]: Epoch 081 - training loss: 0.2906, validation loss: 0.1760
2024-06-04 03:15:34 [INFO]: Epoch 082 - training loss: 0.2941, validation loss: 0.1800
2024-06-04 03:15:38 [INFO]: Epoch 083 - training loss: 0.2955, validation loss: 0.1747
2024-06-04 03:15:43 [INFO]: Epoch 084 - training loss: 0.2897, validation loss: 0.1775
2024-06-04 03:15:48 [INFO]: Epoch 085 - training loss: 0.2900, validation loss: 0.1766
2024-06-04 03:15:53 [INFO]: Epoch 086 - training loss: 0.2870, validation loss: 0.1755
2024-06-04 03:15:58 [INFO]: Epoch 087 - training loss: 0.2895, validation loss: 0.1753
2024-06-04 03:16:03 [INFO]: Epoch 088 - training loss: 0.2906, validation loss: 0.1760
2024-06-04 03:16:08 [INFO]: Epoch 089 - training loss: 0.2888, validation loss: 0.1741
2024-06-04 03:16:14 [INFO]: Epoch 090 - training loss: 0.2905, validation loss: 0.1749
2024-06-04 03:16:19 [INFO]: Epoch 091 - training loss: 0.2875, validation loss: 0.1746
2024-06-04 03:16:24 [INFO]: Epoch 092 - training loss: 0.2865, validation loss: 0.1764
2024-06-04 03:16:29 [INFO]: Epoch 093 - training loss: 0.2856, validation loss: 0.1731
2024-06-04 03:16:34 [INFO]: Epoch 094 - training loss: 0.2870, validation loss: 0.1746
2024-06-04 03:16:39 [INFO]: Epoch 095 - training loss: 0.2893, validation loss: 0.1771
2024-06-04 03:16:45 [INFO]: Epoch 096 - training loss: 0.2861, validation loss: 0.1740
2024-06-04 03:16:50 [INFO]: Epoch 097 - training loss: 0.2845, validation loss: 0.1750
2024-06-04 03:16:55 [INFO]: Epoch 098 - training loss: 0.2825, validation loss: 0.1732
2024-06-04 03:17:00 [INFO]: Epoch 099 - training loss: 0.2823, validation loss: 0.1721
2024-06-04 03:17:05 [INFO]: Epoch 100 - training loss: 0.2843, validation loss: 0.1758
2024-06-04 03:17:05 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 03:17:05 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_2/20240604_T030746/StemGNN.pypots
2024-06-04 03:17:08 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_2/imputation.pkl
2024-06-04 03:17:08 [INFO]: Round2 - StemGNN on BeijingAir: MAE=0.2062, MSE=0.2079, MRE=0.3116
2024-06-04 03:17:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:17:08 [INFO]: Using the given device: cuda:0
2024-06-04 03:17:08 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_3/20240604_T031708
2024-06-04 03:17:08 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_3/20240604_T031708/tensorboard
2024-06-04 03:17:08 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-04 03:17:13 [INFO]: Epoch 001 - training loss: 1.1577, validation loss: 0.5069
2024-06-04 03:17:18 [INFO]: Epoch 002 - training loss: 0.7259, validation loss: 0.3734
2024-06-04 03:17:23 [INFO]: Epoch 003 - training loss: 0.5946, validation loss: 0.3148
2024-06-04 03:17:28 [INFO]: Epoch 004 - training loss: 0.5095, validation loss: 0.2686
2024-06-04 03:17:33 [INFO]: Epoch 005 - training loss: 0.4664, validation loss: 0.2555
2024-06-04 03:17:38 [INFO]: Epoch 006 - training loss: 0.4399, validation loss: 0.2431
2024-06-04 03:17:43 [INFO]: Epoch 007 - training loss: 0.4212, validation loss: 0.2362
2024-06-04 03:17:48 [INFO]: Epoch 008 - training loss: 0.4143, validation loss: 0.2306
2024-06-04 03:17:53 [INFO]: Epoch 009 - training loss: 0.4092, validation loss: 0.2247
2024-06-04 03:17:58 [INFO]: Epoch 010 - training loss: 0.3983, validation loss: 0.2252
2024-06-04 03:18:03 [INFO]: Epoch 011 - training loss: 0.3867, validation loss: 0.2169
2024-06-04 03:18:08 [INFO]: Epoch 012 - training loss: 0.3806, validation loss: 0.2154
2024-06-04 03:18:14 [INFO]: Epoch 013 - training loss: 0.3759, validation loss: 0.2109
2024-06-04 03:18:18 [INFO]: Epoch 014 - training loss: 0.3715, validation loss: 0.2095
2024-06-04 03:18:23 [INFO]: Epoch 015 - training loss: 0.3652, validation loss: 0.2077
2024-06-04 03:18:28 [INFO]: Epoch 016 - training loss: 0.3662, validation loss: 0.2085
2024-06-04 03:18:34 [INFO]: Epoch 017 - training loss: 0.3624, validation loss: 0.2058
2024-06-04 03:18:39 [INFO]: Epoch 018 - training loss: 0.3562, validation loss: 0.2027
2024-06-04 03:18:44 [INFO]: Epoch 019 - training loss: 0.3503, validation loss: 0.2006
2024-06-04 03:18:49 [INFO]: Epoch 020 - training loss: 0.3475, validation loss: 0.2009
2024-06-04 03:18:54 [INFO]: Epoch 021 - training loss: 0.3479, validation loss: 0.1986
2024-06-04 03:18:59 [INFO]: Epoch 022 - training loss: 0.3455, validation loss: 0.1994
2024-06-04 03:19:04 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.1973
2024-06-04 03:19:09 [INFO]: Epoch 024 - training loss: 0.3399, validation loss: 0.1967
2024-06-04 03:19:13 [INFO]: Epoch 025 - training loss: 0.3412, validation loss: 0.1977
2024-06-04 03:19:19 [INFO]: Epoch 026 - training loss: 0.3374, validation loss: 0.1943
2024-06-04 03:19:24 [INFO]: Epoch 027 - training loss: 0.3332, validation loss: 0.1925
2024-06-04 03:19:29 [INFO]: Epoch 028 - training loss: 0.3339, validation loss: 0.1929
2024-06-04 03:19:34 [INFO]: Epoch 029 - training loss: 0.3332, validation loss: 0.1952
2024-06-04 03:19:39 [INFO]: Epoch 030 - training loss: 0.3322, validation loss: 0.1932
2024-06-04 03:19:44 [INFO]: Epoch 031 - training loss: 0.3295, validation loss: 0.1928
2024-06-04 03:19:49 [INFO]: Epoch 032 - training loss: 0.3268, validation loss: 0.1913
2024-06-04 03:19:54 [INFO]: Epoch 033 - training loss: 0.3283, validation loss: 0.1894
2024-06-04 03:19:59 [INFO]: Epoch 034 - training loss: 0.3248, validation loss: 0.1893
2024-06-04 03:20:04 [INFO]: Epoch 035 - training loss: 0.3225, validation loss: 0.1899
2024-06-04 03:20:09 [INFO]: Epoch 036 - training loss: 0.3262, validation loss: 0.1892
2024-06-04 03:20:14 [INFO]: Epoch 037 - training loss: 0.3250, validation loss: 0.1886
2024-06-04 03:20:19 [INFO]: Epoch 038 - training loss: 0.3226, validation loss: 0.1877
2024-06-04 03:20:24 [INFO]: Epoch 039 - training loss: 0.3229, validation loss: 0.1863
2024-06-04 03:20:29 [INFO]: Epoch 040 - training loss: 0.3222, validation loss: 0.1869
2024-06-04 03:20:34 [INFO]: Epoch 041 - training loss: 0.3198, validation loss: 0.1849
2024-06-04 03:20:39 [INFO]: Epoch 042 - training loss: 0.3200, validation loss: 0.1881
2024-06-04 03:20:44 [INFO]: Epoch 043 - training loss: 0.3179, validation loss: 0.1850
2024-06-04 03:20:49 [INFO]: Epoch 044 - training loss: 0.3168, validation loss: 0.1863
2024-06-04 03:20:55 [INFO]: Epoch 045 - training loss: 0.3148, validation loss: 0.1859
2024-06-04 03:21:00 [INFO]: Epoch 046 - training loss: 0.3130, validation loss: 0.1852
2024-06-04 03:21:05 [INFO]: Epoch 047 - training loss: 0.3153, validation loss: 0.1856
2024-06-04 03:21:10 [INFO]: Epoch 048 - training loss: 0.3131, validation loss: 0.1843
2024-06-04 03:21:15 [INFO]: Epoch 049 - training loss: 0.3110, validation loss: 0.1865
2024-06-04 03:21:20 [INFO]: Epoch 050 - training loss: 0.3138, validation loss: 0.1851
2024-06-04 03:21:25 [INFO]: Epoch 051 - training loss: 0.3106, validation loss: 0.1841
2024-06-04 03:21:31 [INFO]: Epoch 052 - training loss: 0.3123, validation loss: 0.1848
2024-06-04 03:21:35 [INFO]: Epoch 053 - training loss: 0.3085, validation loss: 0.1832
2024-06-04 03:21:40 [INFO]: Epoch 054 - training loss: 0.3088, validation loss: 0.1835
2024-06-04 03:21:46 [INFO]: Epoch 055 - training loss: 0.3088, validation loss: 0.1814
2024-06-04 03:21:51 [INFO]: Epoch 056 - training loss: 0.3133, validation loss: 0.1842
2024-06-04 03:21:56 [INFO]: Epoch 057 - training loss: 0.3085, validation loss: 0.1830
2024-06-04 03:22:00 [INFO]: Epoch 058 - training loss: 0.3023, validation loss: 0.1847
2024-06-04 03:22:05 [INFO]: Epoch 059 - training loss: 0.3018, validation loss: 0.1811
2024-06-04 03:22:11 [INFO]: Epoch 060 - training loss: 0.2986, validation loss: 0.1822
2024-06-04 03:22:16 [INFO]: Epoch 061 - training loss: 0.2995, validation loss: 0.1813
2024-06-04 03:22:21 [INFO]: Epoch 062 - training loss: 0.2998, validation loss: 0.1800
2024-06-04 03:22:26 [INFO]: Epoch 063 - training loss: 0.2960, validation loss: 0.1786
2024-06-04 03:22:31 [INFO]: Epoch 064 - training loss: 0.2969, validation loss: 0.1792
2024-06-04 03:22:36 [INFO]: Epoch 065 - training loss: 0.2982, validation loss: 0.1816
2024-06-04 03:22:41 [INFO]: Epoch 066 - training loss: 0.2987, validation loss: 0.1810
2024-06-04 03:22:46 [INFO]: Epoch 067 - training loss: 0.2974, validation loss: 0.1834
2024-06-04 03:22:51 [INFO]: Epoch 068 - training loss: 0.2998, validation loss: 0.1792
2024-06-04 03:22:56 [INFO]: Epoch 069 - training loss: 0.2956, validation loss: 0.1773
2024-06-04 03:23:01 [INFO]: Epoch 070 - training loss: 0.2937, validation loss: 0.1789
2024-06-04 03:23:05 [INFO]: Epoch 071 - training loss: 0.2916, validation loss: 0.1793
2024-06-04 03:23:10 [INFO]: Epoch 072 - training loss: 0.2951, validation loss: 0.1780
2024-06-04 03:23:14 [INFO]: Epoch 073 - training loss: 0.2923, validation loss: 0.1777
2024-06-04 03:23:17 [INFO]: Epoch 074 - training loss: 0.2923, validation loss: 0.1766
2024-06-04 03:23:21 [INFO]: Epoch 075 - training loss: 0.2912, validation loss: 0.1813
2024-06-04 03:23:25 [INFO]: Epoch 076 - training loss: 0.2912, validation loss: 0.1780
2024-06-04 03:23:29 [INFO]: Epoch 077 - training loss: 0.2922, validation loss: 0.1769
2024-06-04 03:23:33 [INFO]: Epoch 078 - training loss: 0.2910, validation loss: 0.1749
2024-06-04 03:23:37 [INFO]: Epoch 079 - training loss: 0.2937, validation loss: 0.1746
2024-06-04 03:23:40 [INFO]: Epoch 080 - training loss: 0.2907, validation loss: 0.1784
2024-06-04 03:23:44 [INFO]: Epoch 081 - training loss: 0.2894, validation loss: 0.1761
2024-06-04 03:23:47 [INFO]: Epoch 082 - training loss: 0.2892, validation loss: 0.1750
2024-06-04 03:23:51 [INFO]: Epoch 083 - training loss: 0.2865, validation loss: 0.1746
2024-06-04 03:23:55 [INFO]: Epoch 084 - training loss: 0.2848, validation loss: 0.1760
2024-06-04 03:23:58 [INFO]: Epoch 085 - training loss: 0.2837, validation loss: 0.1781
2024-06-04 03:24:01 [INFO]: Epoch 086 - training loss: 0.2872, validation loss: 0.1746
2024-06-04 03:24:04 [INFO]: Epoch 087 - training loss: 0.2856, validation loss: 0.1744
2024-06-04 03:24:06 [INFO]: Epoch 088 - training loss: 0.2837, validation loss: 0.1739
2024-06-04 03:24:09 [INFO]: Epoch 089 - training loss: 0.2851, validation loss: 0.1768
2024-06-04 03:24:13 [INFO]: Epoch 090 - training loss: 0.2835, validation loss: 0.1729
2024-06-04 03:24:16 [INFO]: Epoch 091 - training loss: 0.2831, validation loss: 0.1759
2024-06-04 03:24:20 [INFO]: Epoch 092 - training loss: 0.2795, validation loss: 0.1721
2024-06-04 03:24:23 [INFO]: Epoch 093 - training loss: 0.2816, validation loss: 0.1744
2024-06-04 03:24:27 [INFO]: Epoch 094 - training loss: 0.2852, validation loss: 0.1756
2024-06-04 03:24:30 [INFO]: Epoch 095 - training loss: 0.2813, validation loss: 0.1748
2024-06-04 03:24:34 [INFO]: Epoch 096 - training loss: 0.2800, validation loss: 0.1724
2024-06-04 03:24:37 [INFO]: Epoch 097 - training loss: 0.2804, validation loss: 0.1738
2024-06-04 03:24:41 [INFO]: Epoch 098 - training loss: 0.2823, validation loss: 0.1742
2024-06-04 03:24:45 [INFO]: Epoch 099 - training loss: 0.2831, validation loss: 0.1733
2024-06-04 03:24:48 [INFO]: Epoch 100 - training loss: 0.2819, validation loss: 0.1732
2024-06-04 03:24:48 [INFO]: Finished training. The best model is from epoch#92.
2024-06-04 03:24:48 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_3/20240604_T031708/StemGNN.pypots
2024-06-04 03:24:50 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_3/imputation.pkl
2024-06-04 03:24:50 [INFO]: Round3 - StemGNN on BeijingAir: MAE=0.2064, MSE=0.2093, MRE=0.3119
2024-06-04 03:24:50 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:24:50 [INFO]: Using the given device: cuda:0
2024-06-04 03:24:50 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_4/20240604_T032450
2024-06-04 03:24:50 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_4/20240604_T032450/tensorboard
2024-06-04 03:24:50 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-04 03:24:54 [INFO]: Epoch 001 - training loss: 1.1685, validation loss: 0.5038
2024-06-04 03:24:57 [INFO]: Epoch 002 - training loss: 0.7179, validation loss: 0.3633
2024-06-04 03:25:01 [INFO]: Epoch 003 - training loss: 0.5632, validation loss: 0.2932
2024-06-04 03:25:04 [INFO]: Epoch 004 - training loss: 0.4808, validation loss: 0.2598
2024-06-04 03:25:08 [INFO]: Epoch 005 - training loss: 0.4487, validation loss: 0.2470
2024-06-04 03:25:11 [INFO]: Epoch 006 - training loss: 0.4340, validation loss: 0.2390
2024-06-04 03:25:15 [INFO]: Epoch 007 - training loss: 0.4177, validation loss: 0.2320
2024-06-04 03:25:18 [INFO]: Epoch 008 - training loss: 0.4085, validation loss: 0.2292
2024-06-04 03:25:22 [INFO]: Epoch 009 - training loss: 0.3977, validation loss: 0.2200
2024-06-04 03:25:25 [INFO]: Epoch 010 - training loss: 0.3895, validation loss: 0.2171
2024-06-04 03:25:29 [INFO]: Epoch 011 - training loss: 0.3805, validation loss: 0.2160
2024-06-04 03:25:32 [INFO]: Epoch 012 - training loss: 0.3787, validation loss: 0.2123
2024-06-04 03:25:36 [INFO]: Epoch 013 - training loss: 0.3689, validation loss: 0.2082
2024-06-04 03:25:39 [INFO]: Epoch 014 - training loss: 0.3663, validation loss: 0.2052
2024-06-04 03:25:42 [INFO]: Epoch 015 - training loss: 0.3655, validation loss: 0.2059
2024-06-04 03:25:46 [INFO]: Epoch 016 - training loss: 0.3591, validation loss: 0.2049
2024-06-04 03:25:49 [INFO]: Epoch 017 - training loss: 0.3590, validation loss: 0.2028
2024-06-04 03:25:53 [INFO]: Epoch 018 - training loss: 0.3542, validation loss: 0.1998
2024-06-04 03:25:56 [INFO]: Epoch 019 - training loss: 0.3486, validation loss: 0.1989
2024-06-04 03:26:00 [INFO]: Epoch 020 - training loss: 0.3460, validation loss: 0.1976
2024-06-04 03:26:03 [INFO]: Epoch 021 - training loss: 0.3449, validation loss: 0.1968
2024-06-04 03:26:07 [INFO]: Epoch 022 - training loss: 0.3405, validation loss: 0.1948
2024-06-04 03:26:10 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1943
2024-06-04 03:26:14 [INFO]: Epoch 024 - training loss: 0.3391, validation loss: 0.1938
2024-06-04 03:26:17 [INFO]: Epoch 025 - training loss: 0.3388, validation loss: 0.1923
2024-06-04 03:26:21 [INFO]: Epoch 026 - training loss: 0.3360, validation loss: 0.1924
2024-06-04 03:26:24 [INFO]: Epoch 027 - training loss: 0.3352, validation loss: 0.1923
2024-06-04 03:26:28 [INFO]: Epoch 028 - training loss: 0.3326, validation loss: 0.1914
2024-06-04 03:26:31 [INFO]: Epoch 029 - training loss: 0.3299, validation loss: 0.1906
2024-06-04 03:26:35 [INFO]: Epoch 030 - training loss: 0.3293, validation loss: 0.1916
2024-06-04 03:26:38 [INFO]: Epoch 031 - training loss: 0.3278, validation loss: 0.1898
2024-06-04 03:26:42 [INFO]: Epoch 032 - training loss: 0.3277, validation loss: 0.1903
2024-06-04 03:26:45 [INFO]: Epoch 033 - training loss: 0.3246, validation loss: 0.1893
2024-06-04 03:26:49 [INFO]: Epoch 034 - training loss: 0.3232, validation loss: 0.1884
2024-06-04 03:26:52 [INFO]: Epoch 035 - training loss: 0.3251, validation loss: 0.1889
2024-06-04 03:26:56 [INFO]: Epoch 036 - training loss: 0.3230, validation loss: 0.1872
2024-06-04 03:26:59 [INFO]: Epoch 037 - training loss: 0.3216, validation loss: 0.1874
2024-06-04 03:27:03 [INFO]: Epoch 038 - training loss: 0.3203, validation loss: 0.1878
2024-06-04 03:27:06 [INFO]: Epoch 039 - training loss: 0.3224, validation loss: 0.1877
2024-06-04 03:27:10 [INFO]: Epoch 040 - training loss: 0.3249, validation loss: 0.1868
2024-06-04 03:27:13 [INFO]: Epoch 041 - training loss: 0.3189, validation loss: 0.1861
2024-06-04 03:27:16 [INFO]: Epoch 042 - training loss: 0.3147, validation loss: 0.1851
2024-06-04 03:27:20 [INFO]: Epoch 043 - training loss: 0.3166, validation loss: 0.1865
2024-06-04 03:27:23 [INFO]: Epoch 044 - training loss: 0.3163, validation loss: 0.1846
2024-06-04 03:27:27 [INFO]: Epoch 045 - training loss: 0.3142, validation loss: 0.1821
2024-06-04 03:27:31 [INFO]: Epoch 046 - training loss: 0.3146, validation loss: 0.1873
2024-06-04 03:27:34 [INFO]: Epoch 047 - training loss: 0.3154, validation loss: 0.1833
2024-06-04 03:27:38 [INFO]: Epoch 048 - training loss: 0.3097, validation loss: 0.1813
2024-06-04 03:27:41 [INFO]: Epoch 049 - training loss: 0.3085, validation loss: 0.1798
2024-06-04 03:27:45 [INFO]: Epoch 050 - training loss: 0.3098, validation loss: 0.1821
2024-06-04 03:27:48 [INFO]: Epoch 051 - training loss: 0.3087, validation loss: 0.1819
2024-06-04 03:27:52 [INFO]: Epoch 052 - training loss: 0.3047, validation loss: 0.1809
2024-06-04 03:27:55 [INFO]: Epoch 053 - training loss: 0.3064, validation loss: 0.1817
2024-06-04 03:27:59 [INFO]: Epoch 054 - training loss: 0.3094, validation loss: 0.1810
2024-06-04 03:28:02 [INFO]: Epoch 055 - training loss: 0.3068, validation loss: 0.1809
2024-06-04 03:28:05 [INFO]: Epoch 056 - training loss: 0.3035, validation loss: 0.1787
2024-06-04 03:28:09 [INFO]: Epoch 057 - training loss: 0.3046, validation loss: 0.1806
2024-06-04 03:28:12 [INFO]: Epoch 058 - training loss: 0.3026, validation loss: 0.1790
2024-06-04 03:28:16 [INFO]: Epoch 059 - training loss: 0.3009, validation loss: 0.1799
2024-06-04 03:28:19 [INFO]: Epoch 060 - training loss: 0.3015, validation loss: 0.1788
2024-06-04 03:28:23 [INFO]: Epoch 061 - training loss: 0.3013, validation loss: 0.1802
2024-06-04 03:28:26 [INFO]: Epoch 062 - training loss: 0.2998, validation loss: 0.1789
2024-06-04 03:28:30 [INFO]: Epoch 063 - training loss: 0.2999, validation loss: 0.1789
2024-06-04 03:28:33 [INFO]: Epoch 064 - training loss: 0.2973, validation loss: 0.1764
2024-06-04 03:28:36 [INFO]: Epoch 065 - training loss: 0.2975, validation loss: 0.1776
2024-06-04 03:28:40 [INFO]: Epoch 066 - training loss: 0.2975, validation loss: 0.1770
2024-06-04 03:28:43 [INFO]: Epoch 067 - training loss: 0.3011, validation loss: 0.1781
2024-06-04 03:28:47 [INFO]: Epoch 068 - training loss: 0.2987, validation loss: 0.1774
2024-06-04 03:28:50 [INFO]: Epoch 069 - training loss: 0.2963, validation loss: 0.1774
2024-06-04 03:28:54 [INFO]: Epoch 070 - training loss: 0.2950, validation loss: 0.1765
2024-06-04 03:28:57 [INFO]: Epoch 071 - training loss: 0.2964, validation loss: 0.1754
2024-06-04 03:29:01 [INFO]: Epoch 072 - training loss: 0.2923, validation loss: 0.1758
2024-06-04 03:29:04 [INFO]: Epoch 073 - training loss: 0.2922, validation loss: 0.1733
2024-06-04 03:29:08 [INFO]: Epoch 074 - training loss: 0.2933, validation loss: 0.1763
2024-06-04 03:29:11 [INFO]: Epoch 075 - training loss: 0.2923, validation loss: 0.1758
2024-06-04 03:29:15 [INFO]: Epoch 076 - training loss: 0.2937, validation loss: 0.1751
2024-06-04 03:29:18 [INFO]: Epoch 077 - training loss: 0.2913, validation loss: 0.1740
2024-06-04 03:29:22 [INFO]: Epoch 078 - training loss: 0.2904, validation loss: 0.1740
2024-06-04 03:29:25 [INFO]: Epoch 079 - training loss: 0.2917, validation loss: 0.1767
2024-06-04 03:29:29 [INFO]: Epoch 080 - training loss: 0.2915, validation loss: 0.1748
2024-06-04 03:29:32 [INFO]: Epoch 081 - training loss: 0.2918, validation loss: 0.1749
2024-06-04 03:29:36 [INFO]: Epoch 082 - training loss: 0.2928, validation loss: 0.1750
2024-06-04 03:29:39 [INFO]: Epoch 083 - training loss: 0.2890, validation loss: 0.1749
2024-06-04 03:29:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:29:39 [INFO]: Finished training. The best model is from epoch#73.
2024-06-04 03:29:39 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_4/20240604_T032450/StemGNN.pypots
2024-06-04 03:29:41 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/StemGNN_BeijingAir/round_4/imputation.pkl
2024-06-04 03:29:41 [INFO]: Round4 - StemGNN on BeijingAir: MAE=0.2080, MSE=0.2093, MRE=0.3142
2024-06-04 03:29:41 [INFO]: Done! Final results:
Averaged StemGNN (2,645,628 params) on BeijingAir: MAE=0.1607 ± 0.0022221586929550728, MSE=0.1618 ± 0.00271922934993176, MRE=0.2137 ± 0.002955626604215531, average inference time=0.51