2024-06-04 02:44:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:45 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_0/20240604_T024445/tensorboard
2024-06-04 02:44:47 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-04 02:46:07 [INFO]: Epoch 001 - training loss: 1.1477, validation loss: 0.4461
2024-06-04 02:47:28 [INFO]: Epoch 002 - training loss: 0.7211, validation loss: 0.3404
2024-06-04 02:48:48 [INFO]: Epoch 003 - training loss: 0.6074, validation loss: 0.2980
2024-06-04 02:50:08 [INFO]: Epoch 004 - training loss: 0.5478, validation loss: 0.2654
2024-06-04 02:51:28 [INFO]: Epoch 005 - training loss: 0.5088, validation loss: 0.2640
2024-06-04 02:52:48 [INFO]: Epoch 006 - training loss: 0.4801, validation loss: 0.2303
2024-06-04 02:54:08 [INFO]: Epoch 007 - training loss: 0.4607, validation loss: 0.2325
2024-06-04 02:55:29 [INFO]: Epoch 008 - training loss: 0.4456, validation loss: 0.2076
2024-06-04 02:56:49 [INFO]: Epoch 009 - training loss: 0.4274, validation loss: 0.2224
2024-06-04 02:58:09 [INFO]: Epoch 010 - training loss: 0.4126, validation loss: 0.2196
2024-06-04 02:59:29 [INFO]: Epoch 011 - training loss: 0.4021, validation loss: 0.2059
2024-06-04 03:00:49 [INFO]: Epoch 012 - training loss: 0.3938, validation loss: 0.2074
2024-06-04 03:02:08 [INFO]: Epoch 013 - training loss: 0.3878, validation loss: 0.2161
2024-06-04 03:03:22 [INFO]: Epoch 014 - training loss: 0.3817, validation loss: 0.1982
2024-06-04 03:04:36 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.1924
2024-06-04 03:05:50 [INFO]: Epoch 016 - training loss: 0.3780, validation loss: 0.1838
2024-06-04 03:07:04 [INFO]: Epoch 017 - training loss: 0.3732, validation loss: 0.2012
2024-06-04 03:08:18 [INFO]: Epoch 018 - training loss: 0.3654, validation loss: 0.1859
2024-06-04 03:09:32 [INFO]: Epoch 019 - training loss: 0.3602, validation loss: 0.1879
2024-06-04 03:10:46 [INFO]: Epoch 020 - training loss: 0.3585, validation loss: 0.1879
2024-06-04 03:12:00 [INFO]: Epoch 021 - training loss: 0.3527, validation loss: 0.1780
2024-06-04 03:13:14 [INFO]: Epoch 022 - training loss: 0.3493, validation loss: 0.1759
2024-06-04 03:14:28 [INFO]: Epoch 023 - training loss: 0.3503, validation loss: 0.1783
2024-06-04 03:15:42 [INFO]: Epoch 024 - training loss: 0.3463, validation loss: 0.1650
2024-06-04 03:16:56 [INFO]: Epoch 025 - training loss: 0.3468, validation loss: 0.1762
2024-06-04 03:18:10 [INFO]: Epoch 026 - training loss: 0.3428, validation loss: 0.1668
2024-06-04 03:19:24 [INFO]: Epoch 027 - training loss: 0.3395, validation loss: 0.1651
2024-06-04 03:20:38 [INFO]: Epoch 028 - training loss: 0.3396, validation loss: 0.1629
2024-06-04 03:21:52 [INFO]: Epoch 029 - training loss: 0.3368, validation loss: 0.1641
2024-06-04 03:23:06 [INFO]: Epoch 030 - training loss: 0.3360, validation loss: 0.1672
2024-06-04 03:24:20 [INFO]: Epoch 031 - training loss: 0.3334, validation loss: 0.1634
2024-06-04 03:25:34 [INFO]: Epoch 032 - training loss: 0.3328, validation loss: 0.1563
2024-06-04 03:26:47 [INFO]: Epoch 033 - training loss: 0.3309, validation loss: 0.1658
2024-06-04 03:28:01 [INFO]: Epoch 034 - training loss: 0.3360, validation loss: 0.1539
2024-06-04 03:29:15 [INFO]: Epoch 035 - training loss: 0.3317, validation loss: 0.1584
2024-06-04 03:30:28 [INFO]: Epoch 036 - training loss: 0.3279, validation loss: 0.1594
2024-06-04 03:31:41 [INFO]: Epoch 037 - training loss: 0.3264, validation loss: 0.1513
2024-06-04 03:32:54 [INFO]: Epoch 038 - training loss: 0.3265, validation loss: 0.1585
2024-06-04 03:34:07 [INFO]: Epoch 039 - training loss: 0.3248, validation loss: 0.1563
2024-06-04 03:35:21 [INFO]: Epoch 040 - training loss: 0.3250, validation loss: 0.1564
2024-06-04 03:36:33 [INFO]: Epoch 041 - training loss: 0.3253, validation loss: 0.1568
2024-06-04 03:37:46 [INFO]: Epoch 042 - training loss: 0.3226, validation loss: 0.1490
2024-06-04 03:39:00 [INFO]: Epoch 043 - training loss: 0.3216, validation loss: 0.1509
2024-06-04 03:40:13 [INFO]: Epoch 044 - training loss: 0.3219, validation loss: 0.1479
2024-06-04 03:41:25 [INFO]: Epoch 045 - training loss: 0.3222, validation loss: 0.1546
2024-06-04 03:42:39 [INFO]: Epoch 046 - training loss: 0.3221, validation loss: 0.1502
2024-06-04 03:43:52 [INFO]: Epoch 047 - training loss: 0.3199, validation loss: 0.1486
2024-06-04 03:45:05 [INFO]: Epoch 048 - training loss: 0.3183, validation loss: 0.1431
2024-06-04 03:46:18 [INFO]: Epoch 049 - training loss: 0.3196, validation loss: 0.1477
2024-06-04 03:47:31 [INFO]: Epoch 050 - training loss: 0.3185, validation loss: 0.1469
2024-06-04 03:48:44 [INFO]: Epoch 051 - training loss: 0.3164, validation loss: 0.1434
2024-06-04 03:49:58 [INFO]: Epoch 052 - training loss: 0.3181, validation loss: 0.1470
2024-06-04 03:51:11 [INFO]: Epoch 053 - training loss: 0.3179, validation loss: 0.1427
2024-06-04 03:52:24 [INFO]: Epoch 054 - training loss: 0.3159, validation loss: 0.1465
2024-06-04 03:53:37 [INFO]: Epoch 055 - training loss: 0.3153, validation loss: 0.1435
2024-06-04 03:54:51 [INFO]: Epoch 056 - training loss: 0.3158, validation loss: 0.1461
2024-06-04 03:56:04 [INFO]: Epoch 057 - training loss: 0.3161, validation loss: 0.1402
2024-06-04 03:57:17 [INFO]: Epoch 058 - training loss: 0.3162, validation loss: 0.1376
2024-06-04 03:58:30 [INFO]: Epoch 059 - training loss: 0.3155, validation loss: 0.1376
2024-06-04 03:59:43 [INFO]: Epoch 060 - training loss: 0.3149, validation loss: 0.1389
2024-06-04 04:00:56 [INFO]: Epoch 061 - training loss: 0.3138, validation loss: 0.1425
2024-06-04 04:02:09 [INFO]: Epoch 062 - training loss: 0.3128, validation loss: 0.1377
2024-06-04 04:03:22 [INFO]: Epoch 063 - training loss: 0.3115, validation loss: 0.1393
2024-06-04 04:04:36 [INFO]: Epoch 064 - training loss: 0.3109, validation loss: 0.1397
2024-06-04 04:05:49 [INFO]: Epoch 065 - training loss: 0.3096, validation loss: 0.1411
2024-06-04 04:07:02 [INFO]: Epoch 066 - training loss: 0.3094, validation loss: 0.1421
2024-06-04 04:08:15 [INFO]: Epoch 067 - training loss: 0.3113, validation loss: 0.1364
2024-06-04 04:09:28 [INFO]: Epoch 068 - training loss: 0.3091, validation loss: 0.1397
2024-06-04 04:10:42 [INFO]: Epoch 069 - training loss: 0.3092, validation loss: 0.1363
2024-06-04 04:11:54 [INFO]: Epoch 070 - training loss: 0.3096, validation loss: 0.1402
2024-06-04 04:13:08 [INFO]: Epoch 071 - training loss: 0.3087, validation loss: 0.1349
2024-06-04 04:14:20 [INFO]: Epoch 072 - training loss: 0.3086, validation loss: 0.1396
2024-06-04 04:15:34 [INFO]: Epoch 073 - training loss: 0.3085, validation loss: 0.1392
2024-06-04 04:16:47 [INFO]: Epoch 074 - training loss: 0.3092, validation loss: 0.1339
2024-06-04 04:17:57 [INFO]: Epoch 075 - training loss: 0.3089, validation loss: 0.1313
2024-06-04 04:19:06 [INFO]: Epoch 076 - training loss: 0.3074, validation loss: 0.1357
2024-06-04 04:20:16 [INFO]: Epoch 077 - training loss: 0.3095, validation loss: 0.1483
2024-06-04 04:21:26 [INFO]: Epoch 078 - training loss: 0.3095, validation loss: 0.1411
2024-06-04 04:22:36 [INFO]: Epoch 079 - training loss: 0.3062, validation loss: 0.1380
2024-06-04 04:23:46 [INFO]: Epoch 080 - training loss: 0.3050, validation loss: 0.1324
2024-06-04 04:24:56 [INFO]: Epoch 081 - training loss: 0.3055, validation loss: 0.1322
2024-06-04 04:26:06 [INFO]: Epoch 082 - training loss: 0.3041, validation loss: 0.1313
2024-06-04 04:27:16 [INFO]: Epoch 083 - training loss: 0.3040, validation loss: 0.1342
2024-06-04 04:28:25 [INFO]: Epoch 084 - training loss: 0.3041, validation loss: 0.1318
2024-06-04 04:29:35 [INFO]: Epoch 085 - training loss: 0.3056, validation loss: 0.1358
2024-06-04 04:29:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:29:35 [INFO]: Finished training. The best model is from epoch#75.
2024-06-04 04:29:36 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_0/20240604_T024445/Crossformer.pypots
2024-06-04 04:30:08 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_0/imputation.pkl
2024-06-04 04:30:08 [INFO]: Round0 - Crossformer on BeijingAir: MAE=0.2293, MSE=0.1864, MRE=0.3464
2024-06-04 04:30:08 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 04:30:08 [INFO]: Using the given device: cuda:0
2024-06-04 04:30:08 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_1/20240604_T043008
2024-06-04 04:30:08 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_1/20240604_T043008/tensorboard
2024-06-04 04:30:09 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-04 04:31:19 [INFO]: Epoch 001 - training loss: 1.3003, validation loss: 0.5108
2024-06-04 04:32:29 [INFO]: Epoch 002 - training loss: 0.7636, validation loss: 0.3903
2024-06-04 04:33:39 [INFO]: Epoch 003 - training loss: 0.6276, validation loss: 0.3069
2024-06-04 04:34:48 [INFO]: Epoch 004 - training loss: 0.5522, validation loss: 0.2854
2024-06-04 04:35:58 [INFO]: Epoch 005 - training loss: 0.5241, validation loss: 0.3091
2024-06-04 04:37:08 [INFO]: Epoch 006 - training loss: 0.4873, validation loss: 0.2477
2024-06-04 04:38:18 [INFO]: Epoch 007 - training loss: 0.4542, validation loss: 0.2471
2024-06-04 04:39:28 [INFO]: Epoch 008 - training loss: 0.4388, validation loss: 0.2385
2024-06-04 04:40:38 [INFO]: Epoch 009 - training loss: 0.4235, validation loss: 0.2064
2024-06-04 04:41:48 [INFO]: Epoch 010 - training loss: 0.4149, validation loss: 0.2352
2024-06-04 04:43:00 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2246
2024-06-04 04:44:12 [INFO]: Epoch 012 - training loss: 0.3949, validation loss: 0.1949
2024-06-04 04:45:24 [INFO]: Epoch 013 - training loss: 0.3938, validation loss: 0.2052
2024-06-04 04:46:37 [INFO]: Epoch 014 - training loss: 0.3848, validation loss: 0.1896
2024-06-04 04:47:49 [INFO]: Epoch 015 - training loss: 0.3788, validation loss: 0.2066
2024-06-04 04:49:01 [INFO]: Epoch 016 - training loss: 0.3715, validation loss: 0.1810
2024-06-04 04:50:11 [INFO]: Epoch 017 - training loss: 0.3679, validation loss: 0.1933
2024-06-04 04:51:24 [INFO]: Epoch 018 - training loss: 0.3674, validation loss: 0.1997
2024-06-04 04:52:36 [INFO]: Epoch 019 - training loss: 0.3611, validation loss: 0.1810
2024-06-04 04:53:48 [INFO]: Epoch 020 - training loss: 0.3556, validation loss: 0.1932
2024-06-04 04:55:00 [INFO]: Epoch 021 - training loss: 0.3514, validation loss: 0.1786
2024-06-04 04:56:12 [INFO]: Epoch 022 - training loss: 0.3502, validation loss: 0.1758
2024-06-04 04:57:24 [INFO]: Epoch 023 - training loss: 0.3491, validation loss: 0.1775
2024-06-04 04:58:36 [INFO]: Epoch 024 - training loss: 0.3471, validation loss: 0.1787
2024-06-04 04:59:49 [INFO]: Epoch 025 - training loss: 0.3443, validation loss: 0.1832
2024-06-04 05:01:00 [INFO]: Epoch 026 - training loss: 0.3416, validation loss: 0.1686
2024-06-04 05:02:12 [INFO]: Epoch 027 - training loss: 0.3392, validation loss: 0.1712
2024-06-04 05:03:25 [INFO]: Epoch 028 - training loss: 0.3391, validation loss: 0.1728
2024-06-04 05:04:37 [INFO]: Epoch 029 - training loss: 0.3381, validation loss: 0.1866
2024-06-04 05:05:49 [INFO]: Epoch 030 - training loss: 0.3409, validation loss: 0.1719
2024-06-04 05:07:01 [INFO]: Epoch 031 - training loss: 0.3343, validation loss: 0.1713
2024-06-04 05:08:13 [INFO]: Epoch 032 - training loss: 0.3314, validation loss: 0.1570
2024-06-04 05:09:25 [INFO]: Epoch 033 - training loss: 0.3299, validation loss: 0.1576
2024-06-04 05:10:38 [INFO]: Epoch 034 - training loss: 0.3306, validation loss: 0.1525
2024-06-04 05:11:50 [INFO]: Epoch 035 - training loss: 0.3326, validation loss: 0.1608
2024-06-04 05:13:02 [INFO]: Epoch 036 - training loss: 0.3273, validation loss: 0.1625
2024-06-04 05:14:14 [INFO]: Epoch 037 - training loss: 0.3275, validation loss: 0.1513
2024-06-04 05:15:25 [INFO]: Epoch 038 - training loss: 0.3252, validation loss: 0.1575
2024-06-04 05:16:38 [INFO]: Epoch 039 - training loss: 0.3236, validation loss: 0.1519
2024-06-04 05:17:50 [INFO]: Epoch 040 - training loss: 0.3223, validation loss: 0.1561
2024-06-04 05:19:02 [INFO]: Epoch 041 - training loss: 0.3225, validation loss: 0.1523
2024-06-04 05:20:14 [INFO]: Epoch 042 - training loss: 0.3222, validation loss: 0.1483
2024-06-04 05:21:26 [INFO]: Epoch 043 - training loss: 0.3213, validation loss: 0.1504
2024-06-04 05:22:37 [INFO]: Epoch 044 - training loss: 0.3203, validation loss: 0.1537
2024-06-04 05:23:46 [INFO]: Epoch 045 - training loss: 0.3207, validation loss: 0.1464
2024-06-04 05:24:56 [INFO]: Epoch 046 - training loss: 0.3191, validation loss: 0.1526
2024-06-04 05:26:06 [INFO]: Epoch 047 - training loss: 0.3184, validation loss: 0.1502
2024-06-04 05:27:15 [INFO]: Epoch 048 - training loss: 0.3199, validation loss: 0.1606
2024-06-04 05:28:25 [INFO]: Epoch 049 - training loss: 0.3235, validation loss: 0.1567
2024-06-04 05:29:34 [INFO]: Epoch 050 - training loss: 0.3189, validation loss: 0.1458
2024-06-04 05:30:44 [INFO]: Epoch 051 - training loss: 0.3201, validation loss: 0.1412
2024-06-04 05:31:53 [INFO]: Epoch 052 - training loss: 0.3173, validation loss: 0.1422
2024-06-04 05:33:03 [INFO]: Epoch 053 - training loss: 0.3158, validation loss: 0.1444
2024-06-04 05:34:13 [INFO]: Epoch 054 - training loss: 0.3152, validation loss: 0.1489
2024-06-04 05:35:23 [INFO]: Epoch 055 - training loss: 0.3180, validation loss: 0.1392
2024-06-04 05:36:33 [INFO]: Epoch 056 - training loss: 0.3154, validation loss: 0.1523
2024-06-04 05:37:42 [INFO]: Epoch 057 - training loss: 0.3136, validation loss: 0.1403
2024-06-04 05:38:52 [INFO]: Epoch 058 - training loss: 0.3139, validation loss: 0.1421
2024-06-04 05:40:02 [INFO]: Epoch 059 - training loss: 0.3134, validation loss: 0.1484
2024-06-04 05:41:12 [INFO]: Epoch 060 - training loss: 0.3146, validation loss: 0.1504
2024-06-04 05:42:21 [INFO]: Epoch 061 - training loss: 0.3120, validation loss: 0.1342
2024-06-04 05:43:31 [INFO]: Epoch 062 - training loss: 0.3123, validation loss: 0.1396
2024-06-04 05:44:41 [INFO]: Epoch 063 - training loss: 0.3107, validation loss: 0.1390
2024-06-04 05:45:51 [INFO]: Epoch 064 - training loss: 0.3107, validation loss: 0.1407
2024-06-04 05:47:01 [INFO]: Epoch 065 - training loss: 0.3086, validation loss: 0.1424
2024-06-04 05:48:11 [INFO]: Epoch 066 - training loss: 0.3095, validation loss: 0.1332
2024-06-04 05:49:20 [INFO]: Epoch 067 - training loss: 0.3100, validation loss: 0.1380
2024-06-04 05:50:30 [INFO]: Epoch 068 - training loss: 0.3106, validation loss: 0.1386
2024-06-04 05:51:40 [INFO]: Epoch 069 - training loss: 0.3079, validation loss: 0.1383
2024-06-04 05:52:50 [INFO]: Epoch 070 - training loss: 0.3087, validation loss: 0.1336
2024-06-04 05:53:59 [INFO]: Epoch 071 - training loss: 0.3083, validation loss: 0.1385
2024-06-04 05:55:09 [INFO]: Epoch 072 - training loss: 0.3076, validation loss: 0.1401
2024-06-04 05:56:19 [INFO]: Epoch 073 - training loss: 0.3084, validation loss: 0.1316
2024-06-04 05:57:29 [INFO]: Epoch 074 - training loss: 0.3058, validation loss: 0.1399
2024-06-04 05:58:39 [INFO]: Epoch 075 - training loss: 0.3063, validation loss: 0.1321
2024-06-04 05:59:49 [INFO]: Epoch 076 - training loss: 0.3068, validation loss: 0.1350
2024-06-04 06:00:58 [INFO]: Epoch 077 - training loss: 0.3053, validation loss: 0.1378
2024-06-04 06:02:08 [INFO]: Epoch 078 - training loss: 0.3077, validation loss: 0.1320
2024-06-04 06:03:18 [INFO]: Epoch 079 - training loss: 0.3056, validation loss: 0.1384
2024-06-04 06:04:28 [INFO]: Epoch 080 - training loss: 0.3046, validation loss: 0.1401
2024-06-04 06:05:38 [INFO]: Epoch 081 - training loss: 0.3054, validation loss: 0.1324
2024-06-04 06:06:48 [INFO]: Epoch 082 - training loss: 0.3035, validation loss: 0.1453
2024-06-04 06:07:57 [INFO]: Epoch 083 - training loss: 0.3056, validation loss: 0.1330
2024-06-04 06:07:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 06:07:57 [INFO]: Finished training. The best model is from epoch#73.
2024-06-04 06:07:57 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_1/20240604_T043008/Crossformer.pypots
2024-06-04 06:08:31 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_1/imputation.pkl
2024-06-04 06:08:31 [INFO]: Round1 - Crossformer on BeijingAir: MAE=0.2262, MSE=0.1817, MRE=0.3418
2024-06-04 06:08:31 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 06:08:31 [INFO]: Using the given device: cuda:0
2024-06-04 06:08:31 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_2/20240604_T060831
2024-06-04 06:08:31 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_2/20240604_T060831/tensorboard
2024-06-04 06:08:31 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-04 06:09:41 [INFO]: Epoch 001 - training loss: 1.2067, validation loss: 0.4613
2024-06-04 06:10:51 [INFO]: Epoch 002 - training loss: 0.7362, validation loss: 0.3558
2024-06-04 06:12:01 [INFO]: Epoch 003 - training loss: 0.6076, validation loss: 0.3082
2024-06-04 06:13:11 [INFO]: Epoch 004 - training loss: 0.5557, validation loss: 0.3336
2024-06-04 06:14:20 [INFO]: Epoch 005 - training loss: 0.5171, validation loss: 0.2751
2024-06-04 06:15:30 [INFO]: Epoch 006 - training loss: 0.4839, validation loss: 0.2455
2024-06-04 06:16:40 [INFO]: Epoch 007 - training loss: 0.4593, validation loss: 0.2335
2024-06-04 06:17:49 [INFO]: Epoch 008 - training loss: 0.4448, validation loss: 0.2348
2024-06-04 06:18:59 [INFO]: Epoch 009 - training loss: 0.4250, validation loss: 0.2303
2024-06-04 06:20:09 [INFO]: Epoch 010 - training loss: 0.4126, validation loss: 0.2188
2024-06-04 06:21:19 [INFO]: Epoch 011 - training loss: 0.4092, validation loss: 0.2161
2024-06-04 06:22:29 [INFO]: Epoch 012 - training loss: 0.3962, validation loss: 0.2040
2024-06-04 06:23:38 [INFO]: Epoch 013 - training loss: 0.3959, validation loss: 0.1887
2024-06-04 06:24:48 [INFO]: Epoch 014 - training loss: 0.3957, validation loss: 0.1872
2024-06-04 06:25:58 [INFO]: Epoch 015 - training loss: 0.3818, validation loss: 0.2007
2024-06-04 06:27:08 [INFO]: Epoch 016 - training loss: 0.3749, validation loss: 0.2054
2024-06-04 06:28:17 [INFO]: Epoch 017 - training loss: 0.3694, validation loss: 0.1872
2024-06-04 06:29:27 [INFO]: Epoch 018 - training loss: 0.3689, validation loss: 0.1919
2024-06-04 06:30:37 [INFO]: Epoch 019 - training loss: 0.3614, validation loss: 0.1809
2024-06-04 06:31:47 [INFO]: Epoch 020 - training loss: 0.3579, validation loss: 0.1896
2024-06-04 06:32:57 [INFO]: Epoch 021 - training loss: 0.3541, validation loss: 0.1848
2024-06-04 06:34:07 [INFO]: Epoch 022 - training loss: 0.3500, validation loss: 0.1772
2024-06-04 06:35:17 [INFO]: Epoch 023 - training loss: 0.3479, validation loss: 0.1687
2024-06-04 06:36:27 [INFO]: Epoch 024 - training loss: 0.3459, validation loss: 0.1737
2024-06-04 06:37:36 [INFO]: Epoch 025 - training loss: 0.3446, validation loss: 0.1669
2024-06-04 06:38:46 [INFO]: Epoch 026 - training loss: 0.3425, validation loss: 0.1771
2024-06-04 06:39:56 [INFO]: Epoch 027 - training loss: 0.3416, validation loss: 0.1825
2024-06-04 06:41:05 [INFO]: Epoch 028 - training loss: 0.3374, validation loss: 0.1652
2024-06-04 06:42:15 [INFO]: Epoch 029 - training loss: 0.3364, validation loss: 0.1617
2024-06-04 06:43:25 [INFO]: Epoch 030 - training loss: 0.3351, validation loss: 0.1658
2024-06-04 06:44:34 [INFO]: Epoch 031 - training loss: 0.3346, validation loss: 0.1677
2024-06-04 06:45:44 [INFO]: Epoch 032 - training loss: 0.3361, validation loss: 0.1625
2024-06-04 06:46:54 [INFO]: Epoch 033 - training loss: 0.3337, validation loss: 0.1620
2024-06-04 06:48:04 [INFO]: Epoch 034 - training loss: 0.3303, validation loss: 0.1616
2024-06-04 06:49:14 [INFO]: Epoch 035 - training loss: 0.3301, validation loss: 0.1586
2024-06-04 06:50:24 [INFO]: Epoch 036 - training loss: 0.3283, validation loss: 0.1641
2024-06-04 06:51:34 [INFO]: Epoch 037 - training loss: 0.3277, validation loss: 0.1666
2024-06-04 06:52:43 [INFO]: Epoch 038 - training loss: 0.3292, validation loss: 0.1506
2024-06-04 06:53:53 [INFO]: Epoch 039 - training loss: 0.3265, validation loss: 0.1563
2024-06-04 06:55:03 [INFO]: Epoch 040 - training loss: 0.3237, validation loss: 0.1560
2024-06-04 06:56:13 [INFO]: Epoch 041 - training loss: 0.3237, validation loss: 0.1485
2024-06-04 06:57:23 [INFO]: Epoch 042 - training loss: 0.3221, validation loss: 0.1582
2024-06-04 06:58:33 [INFO]: Epoch 043 - training loss: 0.3223, validation loss: 0.1502
2024-06-04 06:59:43 [INFO]: Epoch 044 - training loss: 0.3230, validation loss: 0.1542
2024-06-04 07:00:52 [INFO]: Epoch 045 - training loss: 0.3212, validation loss: 0.1509
2024-06-04 07:02:02 [INFO]: Epoch 046 - training loss: 0.3190, validation loss: 0.1555
2024-06-04 07:03:12 [INFO]: Epoch 047 - training loss: 0.3180, validation loss: 0.1500
2024-06-04 07:04:22 [INFO]: Epoch 048 - training loss: 0.3171, validation loss: 0.1489
2024-06-04 07:05:32 [INFO]: Epoch 049 - training loss: 0.3182, validation loss: 0.1490
2024-06-04 07:06:41 [INFO]: Epoch 050 - training loss: 0.3161, validation loss: 0.1427
2024-06-04 07:07:51 [INFO]: Epoch 051 - training loss: 0.3160, validation loss: 0.1427
2024-06-04 07:09:01 [INFO]: Epoch 052 - training loss: 0.3176, validation loss: 0.1466
2024-06-04 07:10:11 [INFO]: Epoch 053 - training loss: 0.3182, validation loss: 0.1408
2024-06-04 07:11:23 [INFO]: Epoch 054 - training loss: 0.3170, validation loss: 0.1527
2024-06-04 07:12:35 [INFO]: Epoch 055 - training loss: 0.3166, validation loss: 0.1389
2024-06-04 07:13:48 [INFO]: Epoch 056 - training loss: 0.3152, validation loss: 0.1442
2024-06-04 07:14:59 [INFO]: Epoch 057 - training loss: 0.3134, validation loss: 0.1432
2024-06-04 07:16:11 [INFO]: Epoch 058 - training loss: 0.3134, validation loss: 0.1413
2024-06-04 07:17:24 [INFO]: Epoch 059 - training loss: 0.3132, validation loss: 0.1389
2024-06-04 07:18:34 [INFO]: Epoch 060 - training loss: 0.3129, validation loss: 0.1417
2024-06-04 07:19:46 [INFO]: Epoch 061 - training loss: 0.3131, validation loss: 0.1435
2024-06-04 07:20:58 [INFO]: Epoch 062 - training loss: 0.3112, validation loss: 0.1417
2024-06-04 07:22:11 [INFO]: Epoch 063 - training loss: 0.3109, validation loss: 0.1424
2024-06-04 07:23:23 [INFO]: Epoch 064 - training loss: 0.3103, validation loss: 0.1503
2024-06-04 07:24:35 [INFO]: Epoch 065 - training loss: 0.3113, validation loss: 0.1430
2024-06-04 07:24:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 07:24:35 [INFO]: Finished training. The best model is from epoch#55.
2024-06-04 07:24:35 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_2/20240604_T060831/Crossformer.pypots
2024-06-04 07:25:09 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_2/imputation.pkl
2024-06-04 07:25:09 [INFO]: Round2 - Crossformer on BeijingAir: MAE=0.2302, MSE=0.1881, MRE=0.3479
2024-06-04 07:25:09 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 07:25:09 [INFO]: Using the given device: cuda:0
2024-06-04 07:25:09 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_3/20240604_T072509
2024-06-04 07:25:09 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_3/20240604_T072509/tensorboard
2024-06-04 07:25:10 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-04 07:26:22 [INFO]: Epoch 001 - training loss: 1.2435, validation loss: 0.4969
2024-06-04 07:27:34 [INFO]: Epoch 002 - training loss: 0.7557, validation loss: 0.3475
2024-06-04 07:28:46 [INFO]: Epoch 003 - training loss: 0.6160, validation loss: 0.3025
2024-06-04 07:29:58 [INFO]: Epoch 004 - training loss: 0.5555, validation loss: 0.2792
2024-06-04 07:31:10 [INFO]: Epoch 005 - training loss: 0.5172, validation loss: 0.2743
2024-06-04 07:32:22 [INFO]: Epoch 006 - training loss: 0.4885, validation loss: 0.2432
2024-06-04 07:33:34 [INFO]: Epoch 007 - training loss: 0.4593, validation loss: 0.2286
2024-06-04 07:34:46 [INFO]: Epoch 008 - training loss: 0.4380, validation loss: 0.2195
2024-06-04 07:35:58 [INFO]: Epoch 009 - training loss: 0.4292, validation loss: 0.2185
2024-06-04 07:37:10 [INFO]: Epoch 010 - training loss: 0.4201, validation loss: 0.2111
2024-06-04 07:38:22 [INFO]: Epoch 011 - training loss: 0.4057, validation loss: 0.2180
2024-06-04 07:39:34 [INFO]: Epoch 012 - training loss: 0.3960, validation loss: 0.2061
2024-06-04 07:40:46 [INFO]: Epoch 013 - training loss: 0.3899, validation loss: 0.2088
2024-06-04 07:41:58 [INFO]: Epoch 014 - training loss: 0.3851, validation loss: 0.1967
2024-06-04 07:43:10 [INFO]: Epoch 015 - training loss: 0.3794, validation loss: 0.1908
2024-06-04 07:44:22 [INFO]: Epoch 016 - training loss: 0.3760, validation loss: 0.1864
2024-06-04 07:45:34 [INFO]: Epoch 017 - training loss: 0.3719, validation loss: 0.1836
2024-06-04 07:46:46 [INFO]: Epoch 018 - training loss: 0.3658, validation loss: 0.1787
2024-06-04 07:47:57 [INFO]: Epoch 019 - training loss: 0.3600, validation loss: 0.1878
2024-06-04 07:49:09 [INFO]: Epoch 020 - training loss: 0.3582, validation loss: 0.1786
2024-06-04 07:50:21 [INFO]: Epoch 021 - training loss: 0.3554, validation loss: 0.1802
2024-06-04 07:51:31 [INFO]: Epoch 022 - training loss: 0.3553, validation loss: 0.1919
2024-06-04 07:52:41 [INFO]: Epoch 023 - training loss: 0.3487, validation loss: 0.1711
2024-06-04 07:53:50 [INFO]: Epoch 024 - training loss: 0.3452, validation loss: 0.1776
2024-06-04 07:55:00 [INFO]: Epoch 025 - training loss: 0.3430, validation loss: 0.1712
2024-06-04 07:56:10 [INFO]: Epoch 026 - training loss: 0.3410, validation loss: 0.1807
2024-06-04 07:57:19 [INFO]: Epoch 027 - training loss: 0.3426, validation loss: 0.1611
2024-06-04 07:58:29 [INFO]: Epoch 028 - training loss: 0.3380, validation loss: 0.1657
2024-06-04 07:59:39 [INFO]: Epoch 029 - training loss: 0.3351, validation loss: 0.1575
2024-06-04 08:00:48 [INFO]: Epoch 030 - training loss: 0.3345, validation loss: 0.1605
2024-06-04 08:01:58 [INFO]: Epoch 031 - training loss: 0.3333, validation loss: 0.1583
2024-06-04 08:03:08 [INFO]: Epoch 032 - training loss: 0.3330, validation loss: 0.1530
2024-06-04 08:04:18 [INFO]: Epoch 033 - training loss: 0.3301, validation loss: 0.1598
2024-06-04 08:05:28 [INFO]: Epoch 034 - training loss: 0.3305, validation loss: 0.1506
2024-06-04 08:06:38 [INFO]: Epoch 035 - training loss: 0.3278, validation loss: 0.1554
2024-06-04 08:07:48 [INFO]: Epoch 036 - training loss: 0.3284, validation loss: 0.1474
2024-06-04 08:08:58 [INFO]: Epoch 037 - training loss: 0.3271, validation loss: 0.1517
2024-06-04 08:10:08 [INFO]: Epoch 038 - training loss: 0.3270, validation loss: 0.1498
2024-06-04 08:11:18 [INFO]: Epoch 039 - training loss: 0.3261, validation loss: 0.1504
2024-06-04 08:12:28 [INFO]: Epoch 040 - training loss: 0.3223, validation loss: 0.1499
2024-06-04 08:13:37 [INFO]: Epoch 041 - training loss: 0.3227, validation loss: 0.1498
2024-06-04 08:14:47 [INFO]: Epoch 042 - training loss: 0.3219, validation loss: 0.1524
2024-06-04 08:15:57 [INFO]: Epoch 043 - training loss: 0.3244, validation loss: 0.1723
2024-06-04 08:17:07 [INFO]: Epoch 044 - training loss: 0.3328, validation loss: 0.1529
2024-06-04 08:18:17 [INFO]: Epoch 045 - training loss: 0.3211, validation loss: 0.1511
2024-06-04 08:19:26 [INFO]: Epoch 046 - training loss: 0.3202, validation loss: 0.1502
2024-06-04 08:19:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 08:19:26 [INFO]: Finished training. The best model is from epoch#36.
2024-06-04 08:19:27 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_3/20240604_T072509/Crossformer.pypots
2024-06-04 08:20:00 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_3/imputation.pkl
2024-06-04 08:20:00 [INFO]: Round3 - Crossformer on BeijingAir: MAE=0.2362, MSE=0.1997, MRE=0.3569
2024-06-04 08:20:00 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 08:20:00 [INFO]: Using the given device: cuda:0
2024-06-04 08:20:00 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_4/20240604_T082000
2024-06-04 08:20:00 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_4/20240604_T082000/tensorboard
2024-06-04 08:20:01 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-04 08:21:10 [INFO]: Epoch 001 - training loss: 1.1961, validation loss: 0.4936
2024-06-04 08:22:20 [INFO]: Epoch 002 - training loss: 0.7261, validation loss: 0.3720
2024-06-04 08:23:30 [INFO]: Epoch 003 - training loss: 0.6046, validation loss: 0.2949
2024-06-04 08:24:40 [INFO]: Epoch 004 - training loss: 0.5421, validation loss: 0.2929
2024-06-04 08:25:49 [INFO]: Epoch 005 - training loss: 0.5048, validation loss: 0.2453
2024-06-04 08:26:59 [INFO]: Epoch 006 - training loss: 0.4717, validation loss: 0.2417
2024-06-04 08:28:08 [INFO]: Epoch 007 - training loss: 0.4495, validation loss: 0.2194
2024-06-04 08:29:18 [INFO]: Epoch 008 - training loss: 0.4369, validation loss: 0.2079
2024-06-04 08:30:27 [INFO]: Epoch 009 - training loss: 0.4235, validation loss: 0.2292
2024-06-04 08:31:37 [INFO]: Epoch 010 - training loss: 0.4089, validation loss: 0.2220
2024-06-04 08:32:47 [INFO]: Epoch 011 - training loss: 0.4056, validation loss: 0.2083
2024-06-04 08:33:57 [INFO]: Epoch 012 - training loss: 0.3959, validation loss: 0.2045
2024-06-04 08:35:07 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.1905
2024-06-04 08:36:16 [INFO]: Epoch 014 - training loss: 0.3851, validation loss: 0.1920
2024-06-04 08:37:26 [INFO]: Epoch 015 - training loss: 0.3793, validation loss: 0.1953
2024-06-04 08:38:36 [INFO]: Epoch 016 - training loss: 0.3721, validation loss: 0.1871
2024-06-04 08:39:46 [INFO]: Epoch 017 - training loss: 0.3672, validation loss: 0.1900
2024-06-04 08:40:56 [INFO]: Epoch 018 - training loss: 0.3629, validation loss: 0.2060
2024-06-04 08:42:06 [INFO]: Epoch 019 - training loss: 0.3591, validation loss: 0.1762
2024-06-04 08:43:16 [INFO]: Epoch 020 - training loss: 0.3569, validation loss: 0.1727
2024-06-04 08:44:26 [INFO]: Epoch 021 - training loss: 0.3561, validation loss: 0.1900
2024-06-04 08:45:36 [INFO]: Epoch 022 - training loss: 0.3502, validation loss: 0.1851
2024-06-04 08:46:45 [INFO]: Epoch 023 - training loss: 0.3492, validation loss: 0.1709
2024-06-04 08:47:55 [INFO]: Epoch 024 - training loss: 0.3486, validation loss: 0.1714
2024-06-04 08:49:05 [INFO]: Epoch 025 - training loss: 0.3425, validation loss: 0.1715
2024-06-04 08:50:15 [INFO]: Epoch 026 - training loss: 0.3414, validation loss: 0.1634
2024-06-04 08:51:25 [INFO]: Epoch 027 - training loss: 0.3395, validation loss: 0.1579
2024-06-04 08:52:35 [INFO]: Epoch 028 - training loss: 0.3392, validation loss: 0.1747
2024-06-04 08:53:45 [INFO]: Epoch 029 - training loss: 0.3362, validation loss: 0.1576
2024-06-04 08:54:55 [INFO]: Epoch 030 - training loss: 0.3337, validation loss: 0.1630
2024-06-04 08:56:04 [INFO]: Epoch 031 - training loss: 0.3337, validation loss: 0.1635
2024-06-04 08:57:14 [INFO]: Epoch 032 - training loss: 0.3319, validation loss: 0.1626
2024-06-04 08:58:24 [INFO]: Epoch 033 - training loss: 0.3299, validation loss: 0.1570
2024-06-04 08:59:34 [INFO]: Epoch 034 - training loss: 0.3311, validation loss: 0.1515
2024-06-04 09:00:44 [INFO]: Epoch 035 - training loss: 0.3298, validation loss: 0.1568
2024-06-04 09:01:53 [INFO]: Epoch 036 - training loss: 0.3266, validation loss: 0.1568
2024-06-04 09:03:03 [INFO]: Epoch 037 - training loss: 0.3274, validation loss: 0.1514
2024-06-04 09:04:13 [INFO]: Epoch 038 - training loss: 0.3250, validation loss: 0.1564
2024-06-04 09:05:23 [INFO]: Epoch 039 - training loss: 0.3250, validation loss: 0.1534
2024-06-04 09:06:33 [INFO]: Epoch 040 - training loss: 0.3217, validation loss: 0.1609
2024-06-04 09:07:44 [INFO]: Epoch 041 - training loss: 0.3219, validation loss: 0.1457
2024-06-04 09:08:53 [INFO]: Epoch 042 - training loss: 0.3230, validation loss: 0.1483
2024-06-04 09:10:04 [INFO]: Epoch 043 - training loss: 0.3219, validation loss: 0.1429
2024-06-04 09:11:14 [INFO]: Epoch 044 - training loss: 0.3203, validation loss: 0.1500
2024-06-04 09:12:24 [INFO]: Epoch 045 - training loss: 0.3183, validation loss: 0.1513
2024-06-04 09:13:34 [INFO]: Epoch 046 - training loss: 0.3189, validation loss: 0.1527
2024-06-04 09:14:44 [INFO]: Epoch 047 - training loss: 0.3229, validation loss: 0.1560
2024-06-04 09:15:54 [INFO]: Epoch 048 - training loss: 0.3186, validation loss: 0.1442
2024-06-04 09:17:04 [INFO]: Epoch 049 - training loss: 0.3179, validation loss: 0.1486
2024-06-04 09:18:14 [INFO]: Epoch 050 - training loss: 0.3174, validation loss: 0.1460
2024-06-04 09:19:24 [INFO]: Epoch 051 - training loss: 0.3164, validation loss: 0.1452
2024-06-04 09:20:34 [INFO]: Epoch 052 - training loss: 0.3172, validation loss: 0.1448
2024-06-04 09:21:44 [INFO]: Epoch 053 - training loss: 0.3160, validation loss: 0.1405
2024-06-04 09:22:54 [INFO]: Epoch 054 - training loss: 0.3153, validation loss: 0.1501
2024-06-04 09:24:04 [INFO]: Epoch 055 - training loss: 0.3141, validation loss: 0.1458
2024-06-04 09:25:14 [INFO]: Epoch 056 - training loss: 0.3137, validation loss: 0.1418
2024-06-04 09:26:24 [INFO]: Epoch 057 - training loss: 0.3134, validation loss: 0.1376
2024-06-04 09:27:33 [INFO]: Epoch 058 - training loss: 0.3119, validation loss: 0.1407
2024-06-04 09:28:43 [INFO]: Epoch 059 - training loss: 0.3124, validation loss: 0.1425
2024-06-04 09:29:53 [INFO]: Epoch 060 - training loss: 0.3116, validation loss: 0.1404
2024-06-04 09:31:02 [INFO]: Epoch 061 - training loss: 0.3117, validation loss: 0.1438
2024-06-04 09:32:12 [INFO]: Epoch 062 - training loss: 0.3128, validation loss: 0.1401
2024-06-04 09:33:22 [INFO]: Epoch 063 - training loss: 0.3103, validation loss: 0.1364
2024-06-04 09:34:33 [INFO]: Epoch 064 - training loss: 0.3095, validation loss: 0.1380
2024-06-04 09:35:42 [INFO]: Epoch 065 - training loss: 0.3095, validation loss: 0.1410
2024-06-04 09:36:52 [INFO]: Epoch 066 - training loss: 0.3116, validation loss: 0.1374
2024-06-04 09:38:02 [INFO]: Epoch 067 - training loss: 0.3091, validation loss: 0.1418
2024-06-04 09:39:14 [INFO]: Epoch 068 - training loss: 0.3097, validation loss: 0.1409
2024-06-04 09:40:26 [INFO]: Epoch 069 - training loss: 0.3085, validation loss: 0.1350
2024-06-04 09:41:39 [INFO]: Epoch 070 - training loss: 0.3092, validation loss: 0.1374
2024-06-04 09:42:51 [INFO]: Epoch 071 - training loss: 0.3077, validation loss: 0.1426
2024-06-04 09:44:03 [INFO]: Epoch 072 - training loss: 0.3080, validation loss: 0.1452
2024-06-04 09:45:15 [INFO]: Epoch 073 - training loss: 0.3083, validation loss: 0.1336
2024-06-04 09:46:28 [INFO]: Epoch 074 - training loss: 0.3098, validation loss: 0.1367
2024-06-04 09:47:39 [INFO]: Epoch 075 - training loss: 0.3072, validation loss: 0.1379
2024-06-04 09:48:51 [INFO]: Epoch 076 - training loss: 0.3054, validation loss: 0.1335
2024-06-04 09:50:04 [INFO]: Epoch 077 - training loss: 0.3078, validation loss: 0.1405
2024-06-04 09:51:16 [INFO]: Epoch 078 - training loss: 0.3045, validation loss: 0.1382
2024-06-04 09:52:28 [INFO]: Epoch 079 - training loss: 0.3070, validation loss: 0.1461
2024-06-04 09:53:40 [INFO]: Epoch 080 - training loss: 0.3087, validation loss: 0.1358
2024-06-04 09:54:52 [INFO]: Epoch 081 - training loss: 0.3047, validation loss: 0.1393
2024-06-04 09:56:05 [INFO]: Epoch 082 - training loss: 0.3067, validation loss: 0.1322
2024-06-04 09:57:17 [INFO]: Epoch 083 - training loss: 0.3048, validation loss: 0.1341
2024-06-04 09:58:30 [INFO]: Epoch 084 - training loss: 0.3045, validation loss: 0.1304
2024-06-04 09:59:42 [INFO]: Epoch 085 - training loss: 0.3030, validation loss: 0.1372
2024-06-04 10:00:55 [INFO]: Epoch 086 - training loss: 0.3027, validation loss: 0.1341
2024-06-04 10:02:07 [INFO]: Epoch 087 - training loss: 0.3026, validation loss: 0.1342
2024-06-04 10:03:19 [INFO]: Epoch 088 - training loss: 0.3023, validation loss: 0.1349
2024-06-04 10:04:31 [INFO]: Epoch 089 - training loss: 0.3031, validation loss: 0.1327
2024-06-04 10:05:43 [INFO]: Epoch 090 - training loss: 0.3016, validation loss: 0.1327
2024-06-04 10:06:56 [INFO]: Epoch 091 - training loss: 0.3017, validation loss: 0.1285
2024-06-04 10:08:08 [INFO]: Epoch 092 - training loss: 0.3034, validation loss: 0.1351
2024-06-04 10:09:20 [INFO]: Epoch 093 - training loss: 0.3016, validation loss: 0.1399
2024-06-04 10:10:32 [INFO]: Epoch 094 - training loss: 0.3005, validation loss: 0.1398
2024-06-04 10:11:43 [INFO]: Epoch 095 - training loss: 0.3014, validation loss: 0.1413
2024-06-04 10:12:55 [INFO]: Epoch 096 - training loss: 0.3050, validation loss: 0.1344
2024-06-04 10:14:08 [INFO]: Epoch 097 - training loss: 0.3027, validation loss: 0.1297
2024-06-04 10:15:20 [INFO]: Epoch 098 - training loss: 0.2997, validation loss: 0.1319
2024-06-04 10:16:32 [INFO]: Epoch 099 - training loss: 0.2981, validation loss: 0.1260
2024-06-04 10:17:44 [INFO]: Epoch 100 - training loss: 0.2986, validation loss: 0.1320
2024-06-04 10:17:44 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 10:17:45 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_4/20240604_T082000/Crossformer.pypots
2024-06-04 10:18:18 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/Crossformer_BeijingAir/round_4/imputation.pkl
2024-06-04 10:18:18 [INFO]: Round4 - Crossformer on BeijingAir: MAE=0.2242, MSE=0.1843, MRE=0.3388
2024-06-04 10:18:18 [INFO]: Done! Final results:
Averaged Crossformer (52,933,788 params) on BeijingAir: MAE=0.1845 ± 0.0043883350326740156, MSE=0.1265 ± 0.004113437932004998, MRE=0.2454 ± 0.005836792760077027, average inference time=6.87