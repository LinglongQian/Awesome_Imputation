2024-06-04 02:44:44 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:44 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_0/20240604_T024445/tensorboard
2024-06-04 02:44:47 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,598,496
2024-06-04 02:48:06 [INFO]: Epoch 001 - training loss: 0.7816, validation loss: 0.2171
2024-06-04 02:51:20 [INFO]: Epoch 002 - training loss: 0.4904, validation loss: 0.1497
2024-06-04 02:54:38 [INFO]: Epoch 003 - training loss: 0.4134, validation loss: 0.1193
2024-06-04 02:57:57 [INFO]: Epoch 004 - training loss: 0.3822, validation loss: 0.1137
2024-06-04 03:01:12 [INFO]: Epoch 005 - training loss: 0.3701, validation loss: 0.1110
2024-06-04 03:03:45 [INFO]: Epoch 006 - training loss: 0.3578, validation loss: 0.1014
2024-06-04 03:06:05 [INFO]: Epoch 007 - training loss: 0.3485, validation loss: 0.1004
2024-06-04 03:08:25 [INFO]: Epoch 008 - training loss: 0.3445, validation loss: 0.0966
2024-06-04 03:10:45 [INFO]: Epoch 009 - training loss: 0.3352, validation loss: 0.0956
2024-06-04 03:13:08 [INFO]: Epoch 010 - training loss: 0.3309, validation loss: 0.0904
2024-06-04 03:15:28 [INFO]: Epoch 011 - training loss: 0.3263, validation loss: 0.0891
2024-06-04 03:17:48 [INFO]: Epoch 012 - training loss: 0.3248, validation loss: 0.0886
2024-06-04 03:20:09 [INFO]: Epoch 013 - training loss: 0.3221, validation loss: 0.0879
2024-06-04 03:22:31 [INFO]: Epoch 014 - training loss: 0.3178, validation loss: 0.0841
2024-06-04 03:24:53 [INFO]: Epoch 015 - training loss: 0.3171, validation loss: 0.0854
2024-06-04 03:27:12 [INFO]: Epoch 016 - training loss: 0.3145, validation loss: 0.0854
2024-06-04 03:29:29 [INFO]: Epoch 017 - training loss: 0.3115, validation loss: 0.0844
2024-06-04 03:31:28 [INFO]: Epoch 018 - training loss: 0.3096, validation loss: 0.0828
2024-06-04 03:33:27 [INFO]: Epoch 019 - training loss: 0.3079, validation loss: 0.0803
2024-06-04 03:35:27 [INFO]: Epoch 020 - training loss: 0.3094, validation loss: 0.0799
2024-06-04 03:37:25 [INFO]: Epoch 021 - training loss: 0.3059, validation loss: 0.0797
2024-06-04 03:39:24 [INFO]: Epoch 022 - training loss: 0.3026, validation loss: 0.0790
2024-06-04 03:41:23 [INFO]: Epoch 023 - training loss: 0.3021, validation loss: 0.0794
2024-06-04 03:43:21 [INFO]: Epoch 024 - training loss: 0.3049, validation loss: 0.0781
2024-06-04 03:45:19 [INFO]: Epoch 025 - training loss: 0.3058, validation loss: 0.0779
2024-06-04 03:47:18 [INFO]: Epoch 026 - training loss: 0.3003, validation loss: 0.0797
2024-06-04 03:49:18 [INFO]: Epoch 027 - training loss: 0.2975, validation loss: 0.0762
2024-06-04 03:51:16 [INFO]: Epoch 028 - training loss: 0.3006, validation loss: 0.0782
2024-06-04 03:53:14 [INFO]: Epoch 029 - training loss: 0.2972, validation loss: 0.0799
2024-06-04 03:55:14 [INFO]: Epoch 030 - training loss: 0.2963, validation loss: 0.0753
2024-06-04 03:57:14 [INFO]: Epoch 031 - training loss: 0.2948, validation loss: 0.0750
2024-06-04 03:59:11 [INFO]: Epoch 032 - training loss: 0.2945, validation loss: 0.0753
2024-06-04 04:01:09 [INFO]: Epoch 033 - training loss: 0.2972, validation loss: 0.0761
2024-06-04 04:03:09 [INFO]: Epoch 034 - training loss: 0.2933, validation loss: 0.0766
2024-06-04 04:05:09 [INFO]: Epoch 035 - training loss: 0.2923, validation loss: 0.0726
2024-06-04 04:07:06 [INFO]: Epoch 036 - training loss: 0.2905, validation loss: 0.0758
2024-06-04 04:09:04 [INFO]: Epoch 037 - training loss: 0.2903, validation loss: 0.0734
2024-06-04 04:11:03 [INFO]: Epoch 038 - training loss: 0.2922, validation loss: 0.0725
2024-06-04 04:13:02 [INFO]: Epoch 039 - training loss: 0.2895, validation loss: 0.0718
2024-06-04 04:15:01 [INFO]: Epoch 040 - training loss: 0.2879, validation loss: 0.0728
2024-06-04 04:16:59 [INFO]: Epoch 041 - training loss: 0.2896, validation loss: 0.0725
2024-06-04 04:18:35 [INFO]: Epoch 042 - training loss: 0.2875, validation loss: 0.0714
2024-06-04 04:20:11 [INFO]: Epoch 043 - training loss: 0.2880, validation loss: 0.0716
2024-06-04 04:21:46 [INFO]: Epoch 044 - training loss: 0.2863, validation loss: 0.0717
2024-06-04 04:23:22 [INFO]: Epoch 045 - training loss: 0.2836, validation loss: 0.0718
2024-06-04 04:24:58 [INFO]: Epoch 046 - training loss: 0.2840, validation loss: 0.0736
2024-06-04 04:26:30 [INFO]: Epoch 047 - training loss: 0.2831, validation loss: 0.0713
2024-06-04 04:28:06 [INFO]: Epoch 048 - training loss: 0.2821, validation loss: 0.0704
2024-06-04 04:29:41 [INFO]: Epoch 049 - training loss: 0.2824, validation loss: 0.0708
2024-06-04 04:31:14 [INFO]: Epoch 050 - training loss: 0.2813, validation loss: 0.0699
2024-06-04 04:32:50 [INFO]: Epoch 051 - training loss: 0.2816, validation loss: 0.0709
2024-06-04 04:34:24 [INFO]: Epoch 052 - training loss: 0.2820, validation loss: 0.0708
2024-06-04 04:35:57 [INFO]: Epoch 053 - training loss: 0.2816, validation loss: 0.0706
2024-06-04 04:37:31 [INFO]: Epoch 054 - training loss: 0.2810, validation loss: 0.0692
2024-06-04 04:39:06 [INFO]: Epoch 055 - training loss: 0.2808, validation loss: 0.0694
2024-06-04 04:40:40 [INFO]: Epoch 056 - training loss: 0.2830, validation loss: 0.0706
2024-06-04 04:42:16 [INFO]: Epoch 057 - training loss: 0.2829, validation loss: 0.0698
2024-06-04 04:43:55 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.0712
2024-06-04 04:45:33 [INFO]: Epoch 059 - training loss: 0.2796, validation loss: 0.0698
2024-06-04 04:47:13 [INFO]: Epoch 060 - training loss: 0.2781, validation loss: 0.0691
2024-06-04 04:48:51 [INFO]: Epoch 061 - training loss: 0.2781, validation loss: 0.0694
2024-06-04 04:50:27 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.0695
2024-06-04 04:52:04 [INFO]: Epoch 063 - training loss: 0.2845, validation loss: 0.0703
2024-06-04 04:53:42 [INFO]: Epoch 064 - training loss: 0.2798, validation loss: 0.0707
2024-06-04 04:55:21 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.0695
2024-06-04 04:56:59 [INFO]: Epoch 066 - training loss: 0.2753, validation loss: 0.0681
2024-06-04 04:58:37 [INFO]: Epoch 067 - training loss: 0.2779, validation loss: 0.0708
2024-06-04 05:00:16 [INFO]: Epoch 068 - training loss: 0.2756, validation loss: 0.0704
2024-06-04 05:01:55 [INFO]: Epoch 069 - training loss: 0.2774, validation loss: 0.0697
2024-06-04 05:03:33 [INFO]: Epoch 070 - training loss: 0.2776, validation loss: 0.0699
2024-06-04 05:05:11 [INFO]: Epoch 071 - training loss: 0.2758, validation loss: 0.0692
2024-06-04 05:06:50 [INFO]: Epoch 072 - training loss: 0.2768, validation loss: 0.0694
2024-06-04 05:08:27 [INFO]: Epoch 073 - training loss: 0.2740, validation loss: 0.0688
2024-06-04 05:10:05 [INFO]: Epoch 074 - training loss: 0.2720, validation loss: 0.0698
2024-06-04 05:11:44 [INFO]: Epoch 075 - training loss: 0.2739, validation loss: 0.0708
2024-06-04 05:13:22 [INFO]: Epoch 076 - training loss: 0.2755, validation loss: 0.0686
2024-06-04 05:13:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 05:13:22 [INFO]: Finished training. The best model is from epoch#66.
2024-06-04 05:13:22 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_0/20240604_T024445/BRITS.pypots
2024-06-04 05:15:23 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_0/imputation.pkl
2024-06-04 05:15:23 [INFO]: Round0 - BRITS on BeijingAir: MAE=0.1951, MSE=0.2038, MRE=0.2948
2024-06-04 05:15:23 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 05:15:23 [INFO]: Using the given device: cuda:0
2024-06-04 05:15:24 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_1/20240604_T051523
2024-06-04 05:15:24 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_1/20240604_T051523/tensorboard
2024-06-04 05:15:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,598,496
2024-06-04 05:17:02 [INFO]: Epoch 001 - training loss: 0.8005, validation loss: 0.2325
2024-06-04 05:18:41 [INFO]: Epoch 002 - training loss: 0.4932, validation loss: 0.1370
2024-06-04 05:20:20 [INFO]: Epoch 003 - training loss: 0.4113, validation loss: 0.1195
2024-06-04 05:21:58 [INFO]: Epoch 004 - training loss: 0.3787, validation loss: 0.1103
2024-06-04 05:23:32 [INFO]: Epoch 005 - training loss: 0.3648, validation loss: 0.1049
2024-06-04 05:25:06 [INFO]: Epoch 006 - training loss: 0.3570, validation loss: 0.1020
2024-06-04 05:26:41 [INFO]: Epoch 007 - training loss: 0.3451, validation loss: 0.0994
2024-06-04 05:28:15 [INFO]: Epoch 008 - training loss: 0.3382, validation loss: 0.0950
2024-06-04 05:29:48 [INFO]: Epoch 009 - training loss: 0.3335, validation loss: 0.0949
2024-06-04 05:31:24 [INFO]: Epoch 010 - training loss: 0.3309, validation loss: 0.0928
2024-06-04 05:33:01 [INFO]: Epoch 011 - training loss: 0.3246, validation loss: 0.0930
2024-06-04 05:34:35 [INFO]: Epoch 012 - training loss: 0.3237, validation loss: 0.0900
2024-06-04 05:36:10 [INFO]: Epoch 013 - training loss: 0.3207, validation loss: 0.0903
2024-06-04 05:37:45 [INFO]: Epoch 014 - training loss: 0.3164, validation loss: 0.0892
2024-06-04 05:39:21 [INFO]: Epoch 015 - training loss: 0.3123, validation loss: 0.0844
2024-06-04 05:40:56 [INFO]: Epoch 016 - training loss: 0.3115, validation loss: 0.0844
2024-06-04 05:42:31 [INFO]: Epoch 017 - training loss: 0.3124, validation loss: 0.0839
2024-06-04 05:44:07 [INFO]: Epoch 018 - training loss: 0.3103, validation loss: 0.0800
2024-06-04 05:45:42 [INFO]: Epoch 019 - training loss: 0.3087, validation loss: 0.0841
2024-06-04 05:47:17 [INFO]: Epoch 020 - training loss: 0.3073, validation loss: 0.0799
2024-06-04 05:48:51 [INFO]: Epoch 021 - training loss: 0.3056, validation loss: 0.0798
2024-06-04 05:50:27 [INFO]: Epoch 022 - training loss: 0.3034, validation loss: 0.0798
2024-06-04 05:52:00 [INFO]: Epoch 023 - training loss: 0.3058, validation loss: 0.0796
2024-06-04 05:53:38 [INFO]: Epoch 024 - training loss: 0.3005, validation loss: 0.0776
2024-06-04 05:55:13 [INFO]: Epoch 025 - training loss: 0.2998, validation loss: 0.0786
2024-06-04 05:56:49 [INFO]: Epoch 026 - training loss: 0.2973, validation loss: 0.0769
2024-06-04 05:58:23 [INFO]: Epoch 027 - training loss: 0.2967, validation loss: 0.0780
2024-06-04 05:59:57 [INFO]: Epoch 028 - training loss: 0.2973, validation loss: 0.0771
2024-06-04 06:01:31 [INFO]: Epoch 029 - training loss: 0.2970, validation loss: 0.0759
2024-06-04 06:03:07 [INFO]: Epoch 030 - training loss: 0.2967, validation loss: 0.0766
2024-06-04 06:04:42 [INFO]: Epoch 031 - training loss: 0.2958, validation loss: 0.0754
2024-06-04 06:06:16 [INFO]: Epoch 032 - training loss: 0.2922, validation loss: 0.0742
2024-06-04 06:07:50 [INFO]: Epoch 033 - training loss: 0.2902, validation loss: 0.0738
2024-06-04 06:09:21 [INFO]: Epoch 034 - training loss: 0.2917, validation loss: 0.0731
2024-06-04 06:10:56 [INFO]: Epoch 035 - training loss: 0.2907, validation loss: 0.0748
2024-06-04 06:12:31 [INFO]: Epoch 036 - training loss: 0.2887, validation loss: 0.0738
2024-06-04 06:14:07 [INFO]: Epoch 037 - training loss: 0.2882, validation loss: 0.0722
2024-06-04 06:15:41 [INFO]: Epoch 038 - training loss: 0.2884, validation loss: 0.0733
2024-06-04 06:17:16 [INFO]: Epoch 039 - training loss: 0.2887, validation loss: 0.0731
2024-06-04 06:18:50 [INFO]: Epoch 040 - training loss: 0.2884, validation loss: 0.0720
2024-06-04 06:20:25 [INFO]: Epoch 041 - training loss: 0.2876, validation loss: 0.0711
2024-06-04 06:21:58 [INFO]: Epoch 042 - training loss: 0.2883, validation loss: 0.0700
2024-06-04 06:23:34 [INFO]: Epoch 043 - training loss: 0.2843, validation loss: 0.0713
2024-06-04 06:25:08 [INFO]: Epoch 044 - training loss: 0.2870, validation loss: 0.0712
2024-06-04 06:26:43 [INFO]: Epoch 045 - training loss: 0.2837, validation loss: 0.0736
2024-06-04 06:28:18 [INFO]: Epoch 046 - training loss: 0.2826, validation loss: 0.0716
2024-06-04 06:29:54 [INFO]: Epoch 047 - training loss: 0.2829, validation loss: 0.0717
2024-06-04 06:31:27 [INFO]: Epoch 048 - training loss: 0.2843, validation loss: 0.0707
2024-06-04 06:33:03 [INFO]: Epoch 049 - training loss: 0.2860, validation loss: 0.0714
2024-06-04 06:34:38 [INFO]: Epoch 050 - training loss: 0.2802, validation loss: 0.0700
2024-06-04 06:36:13 [INFO]: Epoch 051 - training loss: 0.2797, validation loss: 0.0700
2024-06-04 06:37:47 [INFO]: Epoch 052 - training loss: 0.2832, validation loss: 0.0698
2024-06-04 06:39:21 [INFO]: Epoch 053 - training loss: 0.2803, validation loss: 0.0690
2024-06-04 06:40:55 [INFO]: Epoch 054 - training loss: 0.2827, validation loss: 0.0698
2024-06-04 06:42:29 [INFO]: Epoch 055 - training loss: 0.2795, validation loss: 0.0698
2024-06-04 06:44:04 [INFO]: Epoch 056 - training loss: 0.2796, validation loss: 0.0689
2024-06-04 06:45:37 [INFO]: Epoch 057 - training loss: 0.2795, validation loss: 0.0698
2024-06-04 06:47:11 [INFO]: Epoch 058 - training loss: 0.2776, validation loss: 0.0704
2024-06-04 06:48:48 [INFO]: Epoch 059 - training loss: 0.2789, validation loss: 0.0705
2024-06-04 06:50:23 [INFO]: Epoch 060 - training loss: 0.2765, validation loss: 0.0687
2024-06-04 06:51:59 [INFO]: Epoch 061 - training loss: 0.2774, validation loss: 0.0696
2024-06-04 06:53:35 [INFO]: Epoch 062 - training loss: 0.2774, validation loss: 0.0690
2024-06-04 06:55:10 [INFO]: Epoch 063 - training loss: 0.2769, validation loss: 0.0684
2024-06-04 06:56:46 [INFO]: Epoch 064 - training loss: 0.2774, validation loss: 0.0696
2024-06-04 06:58:21 [INFO]: Epoch 065 - training loss: 0.2794, validation loss: 0.0692
2024-06-04 06:59:56 [INFO]: Epoch 066 - training loss: 0.2756, validation loss: 0.0680
2024-06-04 07:01:30 [INFO]: Epoch 067 - training loss: 0.2743, validation loss: 0.0680
2024-06-04 07:03:06 [INFO]: Epoch 068 - training loss: 0.2742, validation loss: 0.0697
2024-06-04 07:04:41 [INFO]: Epoch 069 - training loss: 0.2744, validation loss: 0.0684
2024-06-04 07:06:17 [INFO]: Epoch 070 - training loss: 0.2745, validation loss: 0.0693
2024-06-04 07:07:52 [INFO]: Epoch 071 - training loss: 0.2731, validation loss: 0.0692
2024-06-04 07:09:26 [INFO]: Epoch 072 - training loss: 0.2728, validation loss: 0.0692
2024-06-04 07:11:03 [INFO]: Epoch 073 - training loss: 0.2753, validation loss: 0.0686
2024-06-04 07:12:43 [INFO]: Epoch 074 - training loss: 0.2729, validation loss: 0.0680
2024-06-04 07:14:21 [INFO]: Epoch 075 - training loss: 0.2720, validation loss: 0.0689
2024-06-04 07:16:00 [INFO]: Epoch 076 - training loss: 0.2716, validation loss: 0.0678
2024-06-04 07:17:42 [INFO]: Epoch 077 - training loss: 0.2699, validation loss: 0.0681
2024-06-04 07:19:16 [INFO]: Epoch 078 - training loss: 0.2710, validation loss: 0.0687
2024-06-04 07:20:55 [INFO]: Epoch 079 - training loss: 0.2715, validation loss: 0.0679
2024-06-04 07:22:34 [INFO]: Epoch 080 - training loss: 0.2727, validation loss: 0.0686
2024-06-04 07:24:13 [INFO]: Epoch 081 - training loss: 0.2732, validation loss: 0.0684
2024-06-04 07:25:47 [INFO]: Epoch 082 - training loss: 0.2708, validation loss: 0.0689
2024-06-04 07:27:27 [INFO]: Epoch 083 - training loss: 0.2715, validation loss: 0.0689
2024-06-04 07:29:06 [INFO]: Epoch 084 - training loss: 0.2709, validation loss: 0.0686
2024-06-04 07:30:44 [INFO]: Epoch 085 - training loss: 0.2713, validation loss: 0.0689
2024-06-04 07:32:23 [INFO]: Epoch 086 - training loss: 0.2711, validation loss: 0.0696
2024-06-04 07:32:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 07:32:23 [INFO]: Finished training. The best model is from epoch#76.
2024-06-04 07:32:23 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_1/20240604_T051523/BRITS.pypots
2024-06-04 07:34:26 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_1/imputation.pkl
2024-06-04 07:34:26 [INFO]: Round1 - BRITS on BeijingAir: MAE=0.1958, MSE=0.2096, MRE=0.2959
2024-06-04 07:34:26 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 07:34:26 [INFO]: Using the given device: cuda:0
2024-06-04 07:34:26 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_2/20240604_T073426
2024-06-04 07:34:26 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_2/20240604_T073426/tensorboard
2024-06-04 07:34:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,598,496
2024-06-04 07:36:04 [INFO]: Epoch 001 - training loss: 0.7903, validation loss: 0.2366
2024-06-04 07:37:41 [INFO]: Epoch 002 - training loss: 0.4890, validation loss: 0.1529
2024-06-04 07:39:19 [INFO]: Epoch 003 - training loss: 0.4156, validation loss: 0.1229
2024-06-04 07:40:57 [INFO]: Epoch 004 - training loss: 0.3892, validation loss: 0.1167
2024-06-04 07:42:36 [INFO]: Epoch 005 - training loss: 0.3684, validation loss: 0.1064
2024-06-04 07:44:16 [INFO]: Epoch 006 - training loss: 0.3545, validation loss: 0.1004
2024-06-04 07:45:54 [INFO]: Epoch 007 - training loss: 0.3437, validation loss: 0.0976
2024-06-04 07:47:32 [INFO]: Epoch 008 - training loss: 0.3404, validation loss: 0.1023
2024-06-04 07:49:10 [INFO]: Epoch 009 - training loss: 0.3361, validation loss: 0.0949
2024-06-04 07:50:49 [INFO]: Epoch 010 - training loss: 0.3316, validation loss: 0.0925
2024-06-04 07:52:23 [INFO]: Epoch 011 - training loss: 0.3294, validation loss: 0.0921
2024-06-04 07:53:58 [INFO]: Epoch 012 - training loss: 0.3246, validation loss: 0.0874
2024-06-04 07:55:32 [INFO]: Epoch 013 - training loss: 0.3191, validation loss: 0.0870
2024-06-04 07:57:06 [INFO]: Epoch 014 - training loss: 0.3192, validation loss: 0.0878
2024-06-04 07:58:41 [INFO]: Epoch 015 - training loss: 0.3165, validation loss: 0.0872
2024-06-04 08:00:16 [INFO]: Epoch 016 - training loss: 0.3198, validation loss: 0.0899
2024-06-04 08:01:52 [INFO]: Epoch 017 - training loss: 0.3132, validation loss: 0.0828
2024-06-04 08:03:26 [INFO]: Epoch 018 - training loss: 0.3103, validation loss: 0.0872
2024-06-04 08:05:01 [INFO]: Epoch 019 - training loss: 0.3095, validation loss: 0.0842
2024-06-04 08:06:35 [INFO]: Epoch 020 - training loss: 0.3063, validation loss: 0.0820
2024-06-04 08:08:11 [INFO]: Epoch 021 - training loss: 0.3040, validation loss: 0.0824
2024-06-04 08:09:46 [INFO]: Epoch 022 - training loss: 0.3036, validation loss: 0.0795
2024-06-04 08:11:21 [INFO]: Epoch 023 - training loss: 0.3023, validation loss: 0.0803
2024-06-04 08:12:55 [INFO]: Epoch 024 - training loss: 0.3018, validation loss: 0.0789
2024-06-04 08:14:30 [INFO]: Epoch 025 - training loss: 0.3020, validation loss: 0.0786
2024-06-04 08:16:04 [INFO]: Epoch 026 - training loss: 0.3000, validation loss: 0.0775
2024-06-04 08:17:40 [INFO]: Epoch 027 - training loss: 0.2971, validation loss: 0.0778
2024-06-04 08:19:16 [INFO]: Epoch 028 - training loss: 0.2977, validation loss: 0.0825
2024-06-04 08:20:47 [INFO]: Epoch 029 - training loss: 0.2968, validation loss: 0.0766
2024-06-04 08:22:22 [INFO]: Epoch 030 - training loss: 0.2937, validation loss: 0.0769
2024-06-04 08:23:59 [INFO]: Epoch 031 - training loss: 0.2938, validation loss: 0.0772
2024-06-04 08:25:33 [INFO]: Epoch 032 - training loss: 0.2944, validation loss: 0.0754
2024-06-04 08:27:08 [INFO]: Epoch 033 - training loss: 0.2933, validation loss: 0.0768
2024-06-04 08:28:43 [INFO]: Epoch 034 - training loss: 0.2940, validation loss: 0.0743
2024-06-04 08:30:19 [INFO]: Epoch 035 - training loss: 0.2915, validation loss: 0.0749
2024-06-04 08:31:54 [INFO]: Epoch 036 - training loss: 0.2905, validation loss: 0.0728
2024-06-04 08:33:27 [INFO]: Epoch 037 - training loss: 0.2882, validation loss: 0.0730
2024-06-04 08:35:02 [INFO]: Epoch 038 - training loss: 0.2890, validation loss: 0.0739
2024-06-04 08:36:37 [INFO]: Epoch 039 - training loss: 0.2905, validation loss: 0.0737
2024-06-04 08:38:12 [INFO]: Epoch 040 - training loss: 0.2880, validation loss: 0.0730
2024-06-04 08:39:47 [INFO]: Epoch 041 - training loss: 0.2883, validation loss: 0.0730
2024-06-04 08:41:23 [INFO]: Epoch 042 - training loss: 0.2883, validation loss: 0.0726
2024-06-04 08:42:56 [INFO]: Epoch 043 - training loss: 0.2853, validation loss: 0.0733
2024-06-04 08:44:32 [INFO]: Epoch 044 - training loss: 0.2846, validation loss: 0.0715
2024-06-04 08:46:06 [INFO]: Epoch 045 - training loss: 0.2836, validation loss: 0.0714
2024-06-04 08:47:41 [INFO]: Epoch 046 - training loss: 0.2844, validation loss: 0.0712
2024-06-04 08:49:16 [INFO]: Epoch 047 - training loss: 0.2833, validation loss: 0.0726
2024-06-04 08:50:52 [INFO]: Epoch 048 - training loss: 0.2837, validation loss: 0.0718
2024-06-04 08:52:27 [INFO]: Epoch 049 - training loss: 0.2838, validation loss: 0.0716
2024-06-04 08:54:03 [INFO]: Epoch 050 - training loss: 0.2841, validation loss: 0.0704
2024-06-04 08:55:38 [INFO]: Epoch 051 - training loss: 0.2802, validation loss: 0.0717
2024-06-04 08:57:13 [INFO]: Epoch 052 - training loss: 0.2800, validation loss: 0.0733
2024-06-04 08:58:46 [INFO]: Epoch 053 - training loss: 0.2785, validation loss: 0.0703
2024-06-04 09:00:21 [INFO]: Epoch 054 - training loss: 0.2788, validation loss: 0.0716
2024-06-04 09:01:57 [INFO]: Epoch 055 - training loss: 0.2759, validation loss: 0.0700
2024-06-04 09:03:32 [INFO]: Epoch 056 - training loss: 0.2774, validation loss: 0.0706
2024-06-04 09:05:06 [INFO]: Epoch 057 - training loss: 0.2789, validation loss: 0.0699
2024-06-04 09:06:42 [INFO]: Epoch 058 - training loss: 0.2777, validation loss: 0.0700
2024-06-04 09:08:18 [INFO]: Epoch 059 - training loss: 0.2768, validation loss: 0.0696
2024-06-04 09:09:54 [INFO]: Epoch 060 - training loss: 0.2779, validation loss: 0.0699
2024-06-04 09:11:29 [INFO]: Epoch 061 - training loss: 0.2777, validation loss: 0.0699
2024-06-04 09:13:04 [INFO]: Epoch 062 - training loss: 0.2805, validation loss: 0.0703
2024-06-04 09:14:39 [INFO]: Epoch 063 - training loss: 0.2781, validation loss: 0.0694
2024-06-04 09:16:14 [INFO]: Epoch 064 - training loss: 0.2777, validation loss: 0.0693
2024-06-04 09:17:49 [INFO]: Epoch 065 - training loss: 0.2781, validation loss: 0.0726
2024-06-04 09:19:23 [INFO]: Epoch 066 - training loss: 0.2768, validation loss: 0.0701
2024-06-04 09:20:59 [INFO]: Epoch 067 - training loss: 0.2737, validation loss: 0.0695
2024-06-04 09:22:34 [INFO]: Epoch 068 - training loss: 0.2729, validation loss: 0.0695
2024-06-04 09:24:09 [INFO]: Epoch 069 - training loss: 0.2732, validation loss: 0.0699
2024-06-04 09:25:41 [INFO]: Epoch 070 - training loss: 0.2772, validation loss: 0.0689
2024-06-04 09:27:14 [INFO]: Epoch 071 - training loss: 0.2745, validation loss: 0.0692
2024-06-04 09:28:48 [INFO]: Epoch 072 - training loss: 0.2762, validation loss: 0.0701
2024-06-04 09:30:21 [INFO]: Epoch 073 - training loss: 0.2740, validation loss: 0.0705
2024-06-04 09:31:54 [INFO]: Epoch 074 - training loss: 0.2730, validation loss: 0.0707
2024-06-04 09:33:29 [INFO]: Epoch 075 - training loss: 0.2733, validation loss: 0.0700
2024-06-04 09:35:01 [INFO]: Epoch 076 - training loss: 0.2740, validation loss: 0.0685
2024-06-04 09:36:35 [INFO]: Epoch 077 - training loss: 0.2722, validation loss: 0.0691
2024-06-04 09:38:11 [INFO]: Epoch 078 - training loss: 0.2723, validation loss: 0.0701
2024-06-04 09:39:50 [INFO]: Epoch 079 - training loss: 0.2758, validation loss: 0.0693
2024-06-04 09:41:29 [INFO]: Epoch 080 - training loss: 0.2715, validation loss: 0.0692
2024-06-04 09:43:07 [INFO]: Epoch 081 - training loss: 0.2716, validation loss: 0.0693
2024-06-04 09:44:45 [INFO]: Epoch 082 - training loss: 0.2700, validation loss: 0.0693
2024-06-04 09:46:23 [INFO]: Epoch 083 - training loss: 0.2687, validation loss: 0.0687
2024-06-04 09:48:01 [INFO]: Epoch 084 - training loss: 0.2692, validation loss: 0.0706
2024-06-04 09:49:38 [INFO]: Epoch 085 - training loss: 0.2694, validation loss: 0.0698
2024-06-04 09:51:16 [INFO]: Epoch 086 - training loss: 0.2701, validation loss: 0.0703
2024-06-04 09:51:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 09:51:16 [INFO]: Finished training. The best model is from epoch#76.
2024-06-04 09:51:16 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_2/20240604_T073426/BRITS.pypots
2024-06-04 09:53:20 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_2/imputation.pkl
2024-06-04 09:53:20 [INFO]: Round2 - BRITS on BeijingAir: MAE=0.1949, MSE=0.2094, MRE=0.2945
2024-06-04 09:53:20 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 09:53:20 [INFO]: Using the given device: cuda:0
2024-06-04 09:53:20 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_3/20240604_T095320
2024-06-04 09:53:20 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_3/20240604_T095320/tensorboard
2024-06-04 09:53:20 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,598,496
2024-06-04 09:55:01 [INFO]: Epoch 001 - training loss: 0.7873, validation loss: 0.2227
2024-06-04 09:56:42 [INFO]: Epoch 002 - training loss: 0.4903, validation loss: 0.1333
2024-06-04 09:58:20 [INFO]: Epoch 003 - training loss: 0.4118, validation loss: 0.1156
2024-06-04 10:00:00 [INFO]: Epoch 004 - training loss: 0.3812, validation loss: 0.1103
2024-06-04 10:01:37 [INFO]: Epoch 005 - training loss: 0.3623, validation loss: 0.1030
2024-06-04 10:03:15 [INFO]: Epoch 006 - training loss: 0.3530, validation loss: 0.0991
2024-06-04 10:04:54 [INFO]: Epoch 007 - training loss: 0.3462, validation loss: 0.0967
2024-06-04 10:06:32 [INFO]: Epoch 008 - training loss: 0.3395, validation loss: 0.0933
2024-06-04 10:08:12 [INFO]: Epoch 009 - training loss: 0.3360, validation loss: 0.0934
2024-06-04 10:09:49 [INFO]: Epoch 010 - training loss: 0.3298, validation loss: 0.0916
2024-06-04 10:11:25 [INFO]: Epoch 011 - training loss: 0.3281, validation loss: 0.0953
2024-06-04 10:13:04 [INFO]: Epoch 012 - training loss: 0.3240, validation loss: 0.0888
2024-06-04 10:14:42 [INFO]: Epoch 013 - training loss: 0.3202, validation loss: 0.0886
2024-06-04 10:16:20 [INFO]: Epoch 014 - training loss: 0.3155, validation loss: 0.0865
2024-06-04 10:17:55 [INFO]: Epoch 015 - training loss: 0.3167, validation loss: 0.0909
2024-06-04 10:18:47 [INFO]: Epoch 016 - training loss: 0.3137, validation loss: 0.0852
2024-06-04 10:19:19 [INFO]: Epoch 017 - training loss: 0.3141, validation loss: 0.0822
2024-06-04 10:19:52 [INFO]: Epoch 018 - training loss: 0.3093, validation loss: 0.0822
2024-06-04 10:20:26 [INFO]: Epoch 019 - training loss: 0.3090, validation loss: 0.0823
2024-06-04 10:20:59 [INFO]: Epoch 020 - training loss: 0.3086, validation loss: 0.0826
2024-06-04 10:21:33 [INFO]: Epoch 021 - training loss: 0.3043, validation loss: 0.0819
2024-06-04 10:22:06 [INFO]: Epoch 022 - training loss: 0.3034, validation loss: 0.0828
2024-06-04 10:22:40 [INFO]: Epoch 023 - training loss: 0.3014, validation loss: 0.0792
2024-06-04 10:23:13 [INFO]: Epoch 024 - training loss: 0.3088, validation loss: 0.0777
2024-06-04 10:23:47 [INFO]: Epoch 025 - training loss: 0.3002, validation loss: 0.0768
2024-06-04 10:24:20 [INFO]: Epoch 026 - training loss: 0.2972, validation loss: 0.0764
2024-06-04 10:24:54 [INFO]: Epoch 027 - training loss: 0.2991, validation loss: 0.0754
2024-06-04 10:25:27 [INFO]: Epoch 028 - training loss: 0.2975, validation loss: 0.0766
2024-06-04 10:26:01 [INFO]: Epoch 029 - training loss: 0.2965, validation loss: 0.0756
2024-06-04 10:26:34 [INFO]: Epoch 030 - training loss: 0.2944, validation loss: 0.0778
2024-06-04 10:27:08 [INFO]: Epoch 031 - training loss: 0.2938, validation loss: 0.0760
2024-06-04 10:27:41 [INFO]: Epoch 032 - training loss: 0.2948, validation loss: 0.0757
2024-06-04 10:28:14 [INFO]: Epoch 033 - training loss: 0.2967, validation loss: 0.0767
2024-06-04 10:28:47 [INFO]: Epoch 034 - training loss: 0.2936, validation loss: 0.0743
2024-06-04 10:29:20 [INFO]: Epoch 035 - training loss: 0.2901, validation loss: 0.0736
2024-06-04 10:29:53 [INFO]: Epoch 036 - training loss: 0.2907, validation loss: 0.0737
2024-06-04 10:30:25 [INFO]: Epoch 037 - training loss: 0.2900, validation loss: 0.0742
2024-06-04 10:30:58 [INFO]: Epoch 038 - training loss: 0.2897, validation loss: 0.0746
2024-06-04 10:31:31 [INFO]: Epoch 039 - training loss: 0.2885, validation loss: 0.0731
2024-06-04 10:32:04 [INFO]: Epoch 040 - training loss: 0.2874, validation loss: 0.0726
2024-06-04 10:32:36 [INFO]: Epoch 041 - training loss: 0.2855, validation loss: 0.0719
2024-06-04 10:33:09 [INFO]: Epoch 042 - training loss: 0.2847, validation loss: 0.0715
2024-06-04 10:33:42 [INFO]: Epoch 043 - training loss: 0.2855, validation loss: 0.0716
2024-06-04 10:34:14 [INFO]: Epoch 044 - training loss: 0.2848, validation loss: 0.0720
2024-06-04 10:34:47 [INFO]: Epoch 045 - training loss: 0.2880, validation loss: 0.0730
2024-06-04 10:35:19 [INFO]: Epoch 046 - training loss: 0.2859, validation loss: 0.0725
2024-06-04 10:35:52 [INFO]: Epoch 047 - training loss: 0.2833, validation loss: 0.0717
2024-06-04 10:36:25 [INFO]: Epoch 048 - training loss: 0.2814, validation loss: 0.0719
2024-06-04 10:36:57 [INFO]: Epoch 049 - training loss: 0.2844, validation loss: 0.0724
2024-06-04 10:37:30 [INFO]: Epoch 050 - training loss: 0.2841, validation loss: 0.0711
2024-06-04 10:38:02 [INFO]: Epoch 051 - training loss: 0.2825, validation loss: 0.0718
2024-06-04 10:38:35 [INFO]: Epoch 052 - training loss: 0.2821, validation loss: 0.0695
2024-06-04 10:39:07 [INFO]: Epoch 053 - training loss: 0.2799, validation loss: 0.0708
2024-06-04 10:39:39 [INFO]: Epoch 054 - training loss: 0.2812, validation loss: 0.0721
2024-06-04 10:40:12 [INFO]: Epoch 055 - training loss: 0.2796, validation loss: 0.0695
2024-06-04 10:40:45 [INFO]: Epoch 056 - training loss: 0.2792, validation loss: 0.0716
2024-06-04 10:41:17 [INFO]: Epoch 057 - training loss: 0.2822, validation loss: 0.0725
2024-06-04 10:41:50 [INFO]: Epoch 058 - training loss: 0.2820, validation loss: 0.0711
2024-06-04 10:42:22 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.0695
2024-06-04 10:42:55 [INFO]: Epoch 060 - training loss: 0.2799, validation loss: 0.0705
2024-06-04 10:43:27 [INFO]: Epoch 061 - training loss: 0.2810, validation loss: 0.0709
2024-06-04 10:44:00 [INFO]: Epoch 062 - training loss: 0.2754, validation loss: 0.0699
2024-06-04 10:44:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 10:44:00 [INFO]: Finished training. The best model is from epoch#52.
2024-06-04 10:44:00 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_3/20240604_T095320/BRITS.pypots
2024-06-04 10:44:41 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_3/imputation.pkl
2024-06-04 10:44:41 [INFO]: Round3 - BRITS on BeijingAir: MAE=0.1961, MSE=0.2060, MRE=0.2963
2024-06-04 10:44:41 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 10:44:41 [INFO]: Using the given device: cuda:0
2024-06-04 10:44:41 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_4/20240604_T104441
2024-06-04 10:44:41 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_4/20240604_T104441/tensorboard
2024-06-04 10:44:41 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,598,496
2024-06-04 10:45:16 [INFO]: Epoch 001 - training loss: 0.8384, validation loss: 0.2291
2024-06-04 10:45:49 [INFO]: Epoch 002 - training loss: 0.5048, validation loss: 0.1379
2024-06-04 10:46:23 [INFO]: Epoch 003 - training loss: 0.4218, validation loss: 0.1139
2024-06-04 10:46:56 [INFO]: Epoch 004 - training loss: 0.3855, validation loss: 0.1114
2024-06-04 10:47:30 [INFO]: Epoch 005 - training loss: 0.3671, validation loss: 0.1032
2024-06-04 10:48:04 [INFO]: Epoch 006 - training loss: 0.3543, validation loss: 0.0997
2024-06-04 10:48:37 [INFO]: Epoch 007 - training loss: 0.3474, validation loss: 0.0971
2024-06-04 10:49:11 [INFO]: Epoch 008 - training loss: 0.3428, validation loss: 0.0951
2024-06-04 10:49:44 [INFO]: Epoch 009 - training loss: 0.3384, validation loss: 0.0957
2024-06-04 10:50:18 [INFO]: Epoch 010 - training loss: 0.3318, validation loss: 0.0960
2024-06-04 10:50:52 [INFO]: Epoch 011 - training loss: 0.3287, validation loss: 0.0923
2024-06-04 10:51:25 [INFO]: Epoch 012 - training loss: 0.3240, validation loss: 0.0898
2024-06-04 10:51:59 [INFO]: Epoch 013 - training loss: 0.3234, validation loss: 0.0898
2024-06-04 10:52:32 [INFO]: Epoch 014 - training loss: 0.3193, validation loss: 0.0895
2024-06-04 10:53:05 [INFO]: Epoch 015 - training loss: 0.3168, validation loss: 0.0914
2024-06-04 10:53:38 [INFO]: Epoch 016 - training loss: 0.3142, validation loss: 0.0848
2024-06-04 10:54:11 [INFO]: Epoch 017 - training loss: 0.3135, validation loss: 0.0861
2024-06-04 10:54:44 [INFO]: Epoch 018 - training loss: 0.3108, validation loss: 0.0846
2024-06-04 10:55:17 [INFO]: Epoch 019 - training loss: 0.3098, validation loss: 0.0826
2024-06-04 10:55:49 [INFO]: Epoch 020 - training loss: 0.3064, validation loss: 0.0804
2024-06-04 10:56:22 [INFO]: Epoch 021 - training loss: 0.3057, validation loss: 0.0796
2024-06-04 10:56:55 [INFO]: Epoch 022 - training loss: 0.3031, validation loss: 0.0781
2024-06-04 10:57:28 [INFO]: Epoch 023 - training loss: 0.3016, validation loss: 0.0783
2024-06-04 10:58:00 [INFO]: Epoch 024 - training loss: 0.3002, validation loss: 0.0801
2024-06-04 10:58:33 [INFO]: Epoch 025 - training loss: 0.3011, validation loss: 0.0838
2024-06-04 10:59:05 [INFO]: Epoch 026 - training loss: 0.3023, validation loss: 0.0780
2024-06-04 10:59:38 [INFO]: Epoch 027 - training loss: 0.2984, validation loss: 0.0775
2024-06-04 11:00:10 [INFO]: Epoch 028 - training loss: 0.2964, validation loss: 0.0767
2024-06-04 11:00:43 [INFO]: Epoch 029 - training loss: 0.2941, validation loss: 0.0751
2024-06-04 11:01:16 [INFO]: Epoch 030 - training loss: 0.2969, validation loss: 0.0752
2024-06-04 11:01:48 [INFO]: Epoch 031 - training loss: 0.2977, validation loss: 0.0751
2024-06-04 11:02:21 [INFO]: Epoch 032 - training loss: 0.2956, validation loss: 0.0749
2024-06-04 11:02:53 [INFO]: Epoch 033 - training loss: 0.2921, validation loss: 0.0739
2024-06-04 11:03:26 [INFO]: Epoch 034 - training loss: 0.2922, validation loss: 0.0762
2024-06-04 11:03:58 [INFO]: Epoch 035 - training loss: 0.2936, validation loss: 0.0756
2024-06-04 11:04:31 [INFO]: Epoch 036 - training loss: 0.2909, validation loss: 0.0733
2024-06-04 11:05:03 [INFO]: Epoch 037 - training loss: 0.2897, validation loss: 0.0731
2024-06-04 11:05:36 [INFO]: Epoch 038 - training loss: 0.2890, validation loss: 0.0723
2024-06-04 11:06:09 [INFO]: Epoch 039 - training loss: 0.2905, validation loss: 0.0745
2024-06-04 11:06:42 [INFO]: Epoch 040 - training loss: 0.2893, validation loss: 0.0723
2024-06-04 11:07:14 [INFO]: Epoch 041 - training loss: 0.2869, validation loss: 0.0738
2024-06-04 11:07:47 [INFO]: Epoch 042 - training loss: 0.2863, validation loss: 0.0725
2024-06-04 11:08:20 [INFO]: Epoch 043 - training loss: 0.2869, validation loss: 0.0720
2024-06-04 11:08:54 [INFO]: Epoch 044 - training loss: 0.2877, validation loss: 0.0723
2024-06-04 11:09:27 [INFO]: Epoch 045 - training loss: 0.2855, validation loss: 0.0728
2024-06-04 11:10:00 [INFO]: Epoch 046 - training loss: 0.2843, validation loss: 0.0723
2024-06-04 11:10:33 [INFO]: Epoch 047 - training loss: 0.2835, validation loss: 0.0694
2024-06-04 11:11:07 [INFO]: Epoch 048 - training loss: 0.2810, validation loss: 0.0698
2024-06-04 11:11:40 [INFO]: Epoch 049 - training loss: 0.2837, validation loss: 0.0717
2024-06-04 11:12:14 [INFO]: Epoch 050 - training loss: 0.2826, validation loss: 0.0707
2024-06-04 11:12:47 [INFO]: Epoch 051 - training loss: 0.2838, validation loss: 0.0707
2024-06-04 11:13:23 [INFO]: Epoch 052 - training loss: 0.2811, validation loss: 0.0696
2024-06-04 11:14:02 [INFO]: Epoch 053 - training loss: 0.2813, validation loss: 0.0705
2024-06-04 11:14:41 [INFO]: Epoch 054 - training loss: 0.2804, validation loss: 0.0704
2024-06-04 11:15:21 [INFO]: Epoch 055 - training loss: 0.2817, validation loss: 0.0703
2024-06-04 11:16:00 [INFO]: Epoch 056 - training loss: 0.2788, validation loss: 0.0710
2024-06-04 11:16:39 [INFO]: Epoch 057 - training loss: 0.2803, validation loss: 0.0709
2024-06-04 11:16:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 11:16:39 [INFO]: Finished training. The best model is from epoch#47.
2024-06-04 11:16:39 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_4/20240604_T104441/BRITS.pypots
2024-06-04 11:17:28 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/BRITS_BeijingAir/round_4/imputation.pkl
2024-06-04 11:17:28 [INFO]: Round4 - BRITS on BeijingAir: MAE=0.1955, MSE=0.2079, MRE=0.2953
2024-06-04 11:17:28 [INFO]: Done! Final results:
Averaged BRITS (3,598,496 params) on BeijingAir: MAE=0.1270 ± 0.0008854403106398193, MSE=0.1014 ± 0.002199914327427759, MRE=0.1689 ± 0.0011776975905765474, average inference time=19.62