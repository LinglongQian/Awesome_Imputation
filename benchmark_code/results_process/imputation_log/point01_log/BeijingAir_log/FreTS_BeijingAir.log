2024-06-04 02:44:44 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:44:44 [INFO]: Using the given device: cuda:0
2024-06-04 02:44:45 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_0/20240604_T024445
2024-06-04 02:44:45 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_0/20240604_T024445/tensorboard
2024-06-04 02:44:46 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-04 02:44:50 [INFO]: Epoch 001 - training loss: 0.9904, validation loss: 0.3792
2024-06-04 02:44:54 [INFO]: Epoch 002 - training loss: 0.5924, validation loss: 0.3003
2024-06-04 02:44:59 [INFO]: Epoch 003 - training loss: 0.5084, validation loss: 0.2733
2024-06-04 02:45:04 [INFO]: Epoch 004 - training loss: 0.4599, validation loss: 0.2515
2024-06-04 02:45:09 [INFO]: Epoch 005 - training loss: 0.4377, validation loss: 0.2884
2024-06-04 02:45:14 [INFO]: Epoch 006 - training loss: 0.4261, validation loss: 0.2224
2024-06-04 02:45:19 [INFO]: Epoch 007 - training loss: 0.4093, validation loss: 0.2418
2024-06-04 02:45:24 [INFO]: Epoch 008 - training loss: 0.4029, validation loss: 0.2125
2024-06-04 02:45:29 [INFO]: Epoch 009 - training loss: 0.3932, validation loss: 0.2152
2024-06-04 02:45:34 [INFO]: Epoch 010 - training loss: 0.3829, validation loss: 0.2346
2024-06-04 02:45:39 [INFO]: Epoch 011 - training loss: 0.3814, validation loss: 0.1968
2024-06-04 02:45:44 [INFO]: Epoch 012 - training loss: 0.3803, validation loss: 0.1943
2024-06-04 02:45:49 [INFO]: Epoch 013 - training loss: 0.3746, validation loss: 0.1889
2024-06-04 02:45:54 [INFO]: Epoch 014 - training loss: 0.3688, validation loss: 0.1939
2024-06-04 02:46:00 [INFO]: Epoch 015 - training loss: 0.3650, validation loss: 0.1873
2024-06-04 02:46:04 [INFO]: Epoch 016 - training loss: 0.3642, validation loss: 0.1857
2024-06-04 02:46:10 [INFO]: Epoch 017 - training loss: 0.3603, validation loss: 0.2019
2024-06-04 02:46:15 [INFO]: Epoch 018 - training loss: 0.3614, validation loss: 0.1943
2024-06-04 02:46:20 [INFO]: Epoch 019 - training loss: 0.3589, validation loss: 0.1769
2024-06-04 02:46:25 [INFO]: Epoch 020 - training loss: 0.3554, validation loss: 0.1784
2024-06-04 02:46:30 [INFO]: Epoch 021 - training loss: 0.3542, validation loss: 0.1783
2024-06-04 02:46:35 [INFO]: Epoch 022 - training loss: 0.3573, validation loss: 0.1657
2024-06-04 02:46:40 [INFO]: Epoch 023 - training loss: 0.3532, validation loss: 0.1579
2024-06-04 02:46:45 [INFO]: Epoch 024 - training loss: 0.3529, validation loss: 0.1774
2024-06-04 02:46:51 [INFO]: Epoch 025 - training loss: 0.3485, validation loss: 0.1684
2024-06-04 02:46:56 [INFO]: Epoch 026 - training loss: 0.3483, validation loss: 0.1672
2024-06-04 02:47:01 [INFO]: Epoch 027 - training loss: 0.3551, validation loss: 0.1784
2024-06-04 02:47:06 [INFO]: Epoch 028 - training loss: 0.3505, validation loss: 0.1611
2024-06-04 02:47:11 [INFO]: Epoch 029 - training loss: 0.3471, validation loss: 0.1768
2024-06-04 02:47:16 [INFO]: Epoch 030 - training loss: 0.3529, validation loss: 0.1677
2024-06-04 02:47:21 [INFO]: Epoch 031 - training loss: 0.3463, validation loss: 0.1644
2024-06-04 02:47:26 [INFO]: Epoch 032 - training loss: 0.3447, validation loss: 0.1502
2024-06-04 02:47:31 [INFO]: Epoch 033 - training loss: 0.3468, validation loss: 0.1519
2024-06-04 02:47:36 [INFO]: Epoch 034 - training loss: 0.3449, validation loss: 0.1584
2024-06-04 02:47:41 [INFO]: Epoch 035 - training loss: 0.3441, validation loss: 0.1697
2024-06-04 02:47:46 [INFO]: Epoch 036 - training loss: 0.3442, validation loss: 0.1499
2024-06-04 02:47:52 [INFO]: Epoch 037 - training loss: 0.3458, validation loss: 0.1525
2024-06-04 02:47:57 [INFO]: Epoch 038 - training loss: 0.3434, validation loss: 0.1514
2024-06-04 02:48:02 [INFO]: Epoch 039 - training loss: 0.3425, validation loss: 0.1407
2024-06-04 02:48:07 [INFO]: Epoch 040 - training loss: 0.3456, validation loss: 0.1442
2024-06-04 02:48:13 [INFO]: Epoch 041 - training loss: 0.3466, validation loss: 0.1475
2024-06-04 02:48:18 [INFO]: Epoch 042 - training loss: 0.3423, validation loss: 0.1546
2024-06-04 02:48:23 [INFO]: Epoch 043 - training loss: 0.3411, validation loss: 0.1532
2024-06-04 02:48:28 [INFO]: Epoch 044 - training loss: 0.3385, validation loss: 0.1555
2024-06-04 02:48:33 [INFO]: Epoch 045 - training loss: 0.3391, validation loss: 0.1617
2024-06-04 02:48:38 [INFO]: Epoch 046 - training loss: 0.3388, validation loss: 0.1562
2024-06-04 02:48:43 [INFO]: Epoch 047 - training loss: 0.3394, validation loss: 0.1508
2024-06-04 02:48:49 [INFO]: Epoch 048 - training loss: 0.3388, validation loss: 0.1457
2024-06-04 02:48:54 [INFO]: Epoch 049 - training loss: 0.3377, validation loss: 0.1428
2024-06-04 02:48:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:48:54 [INFO]: Finished training. The best model is from epoch#39.
2024-06-04 02:48:54 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_0/20240604_T024445/FreTS.pypots
2024-06-04 02:48:55 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_0/imputation.pkl
2024-06-04 02:48:55 [INFO]: Round0 - FreTS on BeijingAir: MAE=0.2419, MSE=0.2062, MRE=0.3655
2024-06-04 02:48:55 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 02:48:55 [INFO]: Using the given device: cuda:0
2024-06-04 02:48:55 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_1/20240604_T024855
2024-06-04 02:48:55 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_1/20240604_T024855/tensorboard
2024-06-04 02:48:55 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-04 02:49:00 [INFO]: Epoch 001 - training loss: 1.0045, validation loss: 0.3966
2024-06-04 02:49:05 [INFO]: Epoch 002 - training loss: 0.5908, validation loss: 0.3113
2024-06-04 02:49:10 [INFO]: Epoch 003 - training loss: 0.5129, validation loss: 0.2784
2024-06-04 02:49:15 [INFO]: Epoch 004 - training loss: 0.4652, validation loss: 0.2687
2024-06-04 02:49:20 [INFO]: Epoch 005 - training loss: 0.4424, validation loss: 0.2248
2024-06-04 02:49:25 [INFO]: Epoch 006 - training loss: 0.4246, validation loss: 0.2282
2024-06-04 02:49:31 [INFO]: Epoch 007 - training loss: 0.4104, validation loss: 0.2308
2024-06-04 02:49:36 [INFO]: Epoch 008 - training loss: 0.3952, validation loss: 0.2229
2024-06-04 02:49:41 [INFO]: Epoch 009 - training loss: 0.3851, validation loss: 0.2331
2024-06-04 02:49:46 [INFO]: Epoch 010 - training loss: 0.3828, validation loss: 0.2172
2024-06-04 02:49:52 [INFO]: Epoch 011 - training loss: 0.3799, validation loss: 0.1876
2024-06-04 02:49:57 [INFO]: Epoch 012 - training loss: 0.3745, validation loss: 0.2095
2024-06-04 02:50:02 [INFO]: Epoch 013 - training loss: 0.3676, validation loss: 0.1944
2024-06-04 02:50:07 [INFO]: Epoch 014 - training loss: 0.3673, validation loss: 0.1876
2024-06-04 02:50:12 [INFO]: Epoch 015 - training loss: 0.3633, validation loss: 0.1933
2024-06-04 02:50:17 [INFO]: Epoch 016 - training loss: 0.3605, validation loss: 0.1799
2024-06-04 02:50:22 [INFO]: Epoch 017 - training loss: 0.3564, validation loss: 0.1682
2024-06-04 02:50:27 [INFO]: Epoch 018 - training loss: 0.3566, validation loss: 0.1763
2024-06-04 02:50:32 [INFO]: Epoch 019 - training loss: 0.3609, validation loss: 0.1840
2024-06-04 02:50:38 [INFO]: Epoch 020 - training loss: 0.3544, validation loss: 0.1681
2024-06-04 02:50:43 [INFO]: Epoch 021 - training loss: 0.3544, validation loss: 0.1773
2024-06-04 02:50:49 [INFO]: Epoch 022 - training loss: 0.3554, validation loss: 0.1728
2024-06-04 02:50:54 [INFO]: Epoch 023 - training loss: 0.3511, validation loss: 0.1679
2024-06-04 02:50:59 [INFO]: Epoch 024 - training loss: 0.3472, validation loss: 0.1554
2024-06-04 02:51:04 [INFO]: Epoch 025 - training loss: 0.3504, validation loss: 0.1613
2024-06-04 02:51:09 [INFO]: Epoch 026 - training loss: 0.3491, validation loss: 0.1540
2024-06-04 02:51:14 [INFO]: Epoch 027 - training loss: 0.3464, validation loss: 0.1591
2024-06-04 02:51:19 [INFO]: Epoch 028 - training loss: 0.3457, validation loss: 0.1445
2024-06-04 02:51:24 [INFO]: Epoch 029 - training loss: 0.3492, validation loss: 0.1533
2024-06-04 02:51:29 [INFO]: Epoch 030 - training loss: 0.3454, validation loss: 0.1606
2024-06-04 02:51:34 [INFO]: Epoch 031 - training loss: 0.3411, validation loss: 0.1551
2024-06-04 02:51:40 [INFO]: Epoch 032 - training loss: 0.3422, validation loss: 0.1575
2024-06-04 02:51:45 [INFO]: Epoch 033 - training loss: 0.3443, validation loss: 0.1619
2024-06-04 02:51:50 [INFO]: Epoch 034 - training loss: 0.3437, validation loss: 0.1552
2024-06-04 02:51:55 [INFO]: Epoch 035 - training loss: 0.3419, validation loss: 0.1499
2024-06-04 02:52:01 [INFO]: Epoch 036 - training loss: 0.3405, validation loss: 0.1535
2024-06-04 02:52:06 [INFO]: Epoch 037 - training loss: 0.3425, validation loss: 0.1492
2024-06-04 02:52:11 [INFO]: Epoch 038 - training loss: 0.3422, validation loss: 0.1574
2024-06-04 02:52:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:52:11 [INFO]: Finished training. The best model is from epoch#28.
2024-06-04 02:52:11 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_1/20240604_T024855/FreTS.pypots
2024-06-04 02:52:12 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_1/imputation.pkl
2024-06-04 02:52:12 [INFO]: Round1 - FreTS on BeijingAir: MAE=0.2662, MSE=0.2243, MRE=0.4022
2024-06-04 02:52:12 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 02:52:12 [INFO]: Using the given device: cuda:0
2024-06-04 02:52:12 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_2/20240604_T025212
2024-06-04 02:52:12 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_2/20240604_T025212/tensorboard
2024-06-04 02:52:13 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-04 02:52:18 [INFO]: Epoch 001 - training loss: 0.9962, validation loss: 0.4226
2024-06-04 02:52:23 [INFO]: Epoch 002 - training loss: 0.5985, validation loss: 0.2929
2024-06-04 02:52:28 [INFO]: Epoch 003 - training loss: 0.5079, validation loss: 0.2959
2024-06-04 02:52:33 [INFO]: Epoch 004 - training loss: 0.4690, validation loss: 0.2445
2024-06-04 02:52:38 [INFO]: Epoch 005 - training loss: 0.4385, validation loss: 0.2593
2024-06-04 02:52:43 [INFO]: Epoch 006 - training loss: 0.4215, validation loss: 0.2363
2024-06-04 02:52:48 [INFO]: Epoch 007 - training loss: 0.4131, validation loss: 0.2355
2024-06-04 02:52:53 [INFO]: Epoch 008 - training loss: 0.4058, validation loss: 0.2197
2024-06-04 02:52:58 [INFO]: Epoch 009 - training loss: 0.3961, validation loss: 0.1961
2024-06-04 02:53:03 [INFO]: Epoch 010 - training loss: 0.3899, validation loss: 0.1988
2024-06-04 02:53:08 [INFO]: Epoch 011 - training loss: 0.3796, validation loss: 0.1900
2024-06-04 02:53:13 [INFO]: Epoch 012 - training loss: 0.3753, validation loss: 0.1971
2024-06-04 02:53:18 [INFO]: Epoch 013 - training loss: 0.3743, validation loss: 0.2153
2024-06-04 02:53:23 [INFO]: Epoch 014 - training loss: 0.3682, validation loss: 0.1777
2024-06-04 02:53:28 [INFO]: Epoch 015 - training loss: 0.3633, validation loss: 0.1797
2024-06-04 02:53:33 [INFO]: Epoch 016 - training loss: 0.3617, validation loss: 0.1801
2024-06-04 02:53:38 [INFO]: Epoch 017 - training loss: 0.3602, validation loss: 0.1822
2024-06-04 02:53:44 [INFO]: Epoch 018 - training loss: 0.3587, validation loss: 0.1819
2024-06-04 02:53:49 [INFO]: Epoch 019 - training loss: 0.3563, validation loss: 0.1710
2024-06-04 02:53:54 [INFO]: Epoch 020 - training loss: 0.3574, validation loss: 0.1799
2024-06-04 02:53:59 [INFO]: Epoch 021 - training loss: 0.3548, validation loss: 0.1649
2024-06-04 02:54:05 [INFO]: Epoch 022 - training loss: 0.3539, validation loss: 0.1621
2024-06-04 02:54:10 [INFO]: Epoch 023 - training loss: 0.3538, validation loss: 0.1574
2024-06-04 02:54:15 [INFO]: Epoch 024 - training loss: 0.3493, validation loss: 0.1678
2024-06-04 02:54:20 [INFO]: Epoch 025 - training loss: 0.3505, validation loss: 0.1611
2024-06-04 02:54:25 [INFO]: Epoch 026 - training loss: 0.3485, validation loss: 0.1506
2024-06-04 02:54:30 [INFO]: Epoch 027 - training loss: 0.3515, validation loss: 0.1613
2024-06-04 02:54:35 [INFO]: Epoch 028 - training loss: 0.3495, validation loss: 0.1585
2024-06-04 02:54:41 [INFO]: Epoch 029 - training loss: 0.3502, validation loss: 0.1753
2024-06-04 02:54:46 [INFO]: Epoch 030 - training loss: 0.3516, validation loss: 0.1656
2024-06-04 02:54:51 [INFO]: Epoch 031 - training loss: 0.3458, validation loss: 0.1557
2024-06-04 02:54:56 [INFO]: Epoch 032 - training loss: 0.3447, validation loss: 0.1659
2024-06-04 02:55:00 [INFO]: Epoch 033 - training loss: 0.3440, validation loss: 0.1599
2024-06-04 02:55:05 [INFO]: Epoch 034 - training loss: 0.3441, validation loss: 0.1559
2024-06-04 02:55:10 [INFO]: Epoch 035 - training loss: 0.3441, validation loss: 0.1524
2024-06-04 02:55:15 [INFO]: Epoch 036 - training loss: 0.3434, validation loss: 0.1597
2024-06-04 02:55:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:55:15 [INFO]: Finished training. The best model is from epoch#26.
2024-06-04 02:55:16 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_2/20240604_T025212/FreTS.pypots
2024-06-04 02:55:17 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_2/imputation.pkl
2024-06-04 02:55:17 [INFO]: Round2 - FreTS on BeijingAir: MAE=0.2612, MSE=0.2195, MRE=0.3947
2024-06-04 02:55:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 02:55:17 [INFO]: Using the given device: cuda:0
2024-06-04 02:55:17 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_3/20240604_T025517
2024-06-04 02:55:17 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_3/20240604_T025517/tensorboard
2024-06-04 02:55:17 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-04 02:55:22 [INFO]: Epoch 001 - training loss: 1.0032, validation loss: 0.4255
2024-06-04 02:55:27 [INFO]: Epoch 002 - training loss: 0.5950, validation loss: 0.3379
2024-06-04 02:55:32 [INFO]: Epoch 003 - training loss: 0.5090, validation loss: 0.2628
2024-06-04 02:55:37 [INFO]: Epoch 004 - training loss: 0.4706, validation loss: 0.2488
2024-06-04 02:55:42 [INFO]: Epoch 005 - training loss: 0.4408, validation loss: 0.2440
2024-06-04 02:55:47 [INFO]: Epoch 006 - training loss: 0.4247, validation loss: 0.2319
2024-06-04 02:55:53 [INFO]: Epoch 007 - training loss: 0.4204, validation loss: 0.2127
2024-06-04 02:55:58 [INFO]: Epoch 008 - training loss: 0.4037, validation loss: 0.2258
2024-06-04 02:56:03 [INFO]: Epoch 009 - training loss: 0.3888, validation loss: 0.2116
2024-06-04 02:56:08 [INFO]: Epoch 010 - training loss: 0.3837, validation loss: 0.2008
2024-06-04 02:56:14 [INFO]: Epoch 011 - training loss: 0.3796, validation loss: 0.1990
2024-06-04 02:56:19 [INFO]: Epoch 012 - training loss: 0.3741, validation loss: 0.2100
2024-06-04 02:56:25 [INFO]: Epoch 013 - training loss: 0.3708, validation loss: 0.1835
2024-06-04 02:56:30 [INFO]: Epoch 014 - training loss: 0.3657, validation loss: 0.1854
2024-06-04 02:56:36 [INFO]: Epoch 015 - training loss: 0.3632, validation loss: 0.1783
2024-06-04 02:56:41 [INFO]: Epoch 016 - training loss: 0.3645, validation loss: 0.1904
2024-06-04 02:56:46 [INFO]: Epoch 017 - training loss: 0.3602, validation loss: 0.2011
2024-06-04 02:56:51 [INFO]: Epoch 018 - training loss: 0.3624, validation loss: 0.1571
2024-06-04 02:56:56 [INFO]: Epoch 019 - training loss: 0.3646, validation loss: 0.1698
2024-06-04 02:57:02 [INFO]: Epoch 020 - training loss: 0.3554, validation loss: 0.1597
2024-06-04 02:57:07 [INFO]: Epoch 021 - training loss: 0.3519, validation loss: 0.1626
2024-06-04 02:57:12 [INFO]: Epoch 022 - training loss: 0.3549, validation loss: 0.1612
2024-06-04 02:57:17 [INFO]: Epoch 023 - training loss: 0.3503, validation loss: 0.1655
2024-06-04 02:57:22 [INFO]: Epoch 024 - training loss: 0.3518, validation loss: 0.1648
2024-06-04 02:57:27 [INFO]: Epoch 025 - training loss: 0.3507, validation loss: 0.1634
2024-06-04 02:57:32 [INFO]: Epoch 026 - training loss: 0.3508, validation loss: 0.1533
2024-06-04 02:57:37 [INFO]: Epoch 027 - training loss: 0.3538, validation loss: 0.1591
2024-06-04 02:57:42 [INFO]: Epoch 028 - training loss: 0.3481, validation loss: 0.1603
2024-06-04 02:57:47 [INFO]: Epoch 029 - training loss: 0.3469, validation loss: 0.1575
2024-06-04 02:57:52 [INFO]: Epoch 030 - training loss: 0.3489, validation loss: 0.1607
2024-06-04 02:57:57 [INFO]: Epoch 031 - training loss: 0.3463, validation loss: 0.1585
2024-06-04 02:58:02 [INFO]: Epoch 032 - training loss: 0.3464, validation loss: 0.1425
2024-06-04 02:58:07 [INFO]: Epoch 033 - training loss: 0.3433, validation loss: 0.1517
2024-06-04 02:58:12 [INFO]: Epoch 034 - training loss: 0.3430, validation loss: 0.1632
2024-06-04 02:58:17 [INFO]: Epoch 035 - training loss: 0.3451, validation loss: 0.1512
2024-06-04 02:58:22 [INFO]: Epoch 036 - training loss: 0.3422, validation loss: 0.1489
2024-06-04 02:58:27 [INFO]: Epoch 037 - training loss: 0.3424, validation loss: 0.1629
2024-06-04 02:58:32 [INFO]: Epoch 038 - training loss: 0.3437, validation loss: 0.1502
2024-06-04 02:58:38 [INFO]: Epoch 039 - training loss: 0.3399, validation loss: 0.1535
2024-06-04 02:58:43 [INFO]: Epoch 040 - training loss: 0.3402, validation loss: 0.1384
2024-06-04 02:58:48 [INFO]: Epoch 041 - training loss: 0.3425, validation loss: 0.1474
2024-06-04 02:58:53 [INFO]: Epoch 042 - training loss: 0.3433, validation loss: 0.1445
2024-06-04 02:58:58 [INFO]: Epoch 043 - training loss: 0.3437, validation loss: 0.1398
2024-06-04 02:59:03 [INFO]: Epoch 044 - training loss: 0.3405, validation loss: 0.1563
2024-06-04 02:59:09 [INFO]: Epoch 045 - training loss: 0.3370, validation loss: 0.1473
2024-06-04 02:59:14 [INFO]: Epoch 046 - training loss: 0.3385, validation loss: 0.1401
2024-06-04 02:59:19 [INFO]: Epoch 047 - training loss: 0.3422, validation loss: 0.1488
2024-06-04 02:59:24 [INFO]: Epoch 048 - training loss: 0.3414, validation loss: 0.1662
2024-06-04 02:59:29 [INFO]: Epoch 049 - training loss: 0.3422, validation loss: 0.1475
2024-06-04 02:59:34 [INFO]: Epoch 050 - training loss: 0.3373, validation loss: 0.1443
2024-06-04 02:59:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 02:59:34 [INFO]: Finished training. The best model is from epoch#40.
2024-06-04 02:59:34 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_3/20240604_T025517/FreTS.pypots
2024-06-04 02:59:35 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_3/imputation.pkl
2024-06-04 02:59:35 [INFO]: Round3 - FreTS on BeijingAir: MAE=0.2500, MSE=0.2101, MRE=0.3777
2024-06-04 02:59:35 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 02:59:35 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:35 [INFO]: Model files will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_4/20240604_T025935
2024-06-04 02:59:35 [INFO]: Tensorboard file will be saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_4/20240604_T025935/tensorboard
2024-06-04 02:59:35 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-04 02:59:40 [INFO]: Epoch 001 - training loss: 1.0356, validation loss: 0.4492
2024-06-04 02:59:45 [INFO]: Epoch 002 - training loss: 0.6201, validation loss: 0.3074
2024-06-04 02:59:50 [INFO]: Epoch 003 - training loss: 0.5111, validation loss: 0.2789
2024-06-04 02:59:56 [INFO]: Epoch 004 - training loss: 0.4734, validation loss: 0.2697
2024-06-04 03:00:00 [INFO]: Epoch 005 - training loss: 0.4436, validation loss: 0.2485
2024-06-04 03:00:06 [INFO]: Epoch 006 - training loss: 0.4214, validation loss: 0.2291
2024-06-04 03:00:11 [INFO]: Epoch 007 - training loss: 0.4077, validation loss: 0.2361
2024-06-04 03:00:16 [INFO]: Epoch 008 - training loss: 0.4017, validation loss: 0.2265
2024-06-04 03:00:21 [INFO]: Epoch 009 - training loss: 0.3891, validation loss: 0.2101
2024-06-04 03:00:27 [INFO]: Epoch 010 - training loss: 0.3840, validation loss: 0.2306
2024-06-04 03:00:32 [INFO]: Epoch 011 - training loss: 0.3823, validation loss: 0.2004
2024-06-04 03:00:37 [INFO]: Epoch 012 - training loss: 0.3766, validation loss: 0.1941
2024-06-04 03:00:42 [INFO]: Epoch 013 - training loss: 0.3684, validation loss: 0.1991
2024-06-04 03:00:47 [INFO]: Epoch 014 - training loss: 0.3662, validation loss: 0.1841
2024-06-04 03:00:52 [INFO]: Epoch 015 - training loss: 0.3635, validation loss: 0.1875
2024-06-04 03:00:57 [INFO]: Epoch 016 - training loss: 0.3650, validation loss: 0.1753
2024-06-04 03:01:02 [INFO]: Epoch 017 - training loss: 0.3655, validation loss: 0.1649
2024-06-04 03:01:07 [INFO]: Epoch 018 - training loss: 0.3638, validation loss: 0.1786
2024-06-04 03:01:12 [INFO]: Epoch 019 - training loss: 0.3573, validation loss: 0.1842
2024-06-04 03:01:17 [INFO]: Epoch 020 - training loss: 0.3542, validation loss: 0.1594
2024-06-04 03:01:22 [INFO]: Epoch 021 - training loss: 0.3563, validation loss: 0.1521
2024-06-04 03:01:27 [INFO]: Epoch 022 - training loss: 0.3543, validation loss: 0.1650
2024-06-04 03:01:32 [INFO]: Epoch 023 - training loss: 0.3495, validation loss: 0.1602
2024-06-04 03:01:37 [INFO]: Epoch 024 - training loss: 0.3499, validation loss: 0.1642
2024-06-04 03:01:41 [INFO]: Epoch 025 - training loss: 0.3471, validation loss: 0.1648
2024-06-04 03:01:46 [INFO]: Epoch 026 - training loss: 0.3471, validation loss: 0.1624
2024-06-04 03:01:51 [INFO]: Epoch 027 - training loss: 0.3477, validation loss: 0.1568
2024-06-04 03:01:55 [INFO]: Epoch 028 - training loss: 0.3467, validation loss: 0.1564
2024-06-04 03:01:59 [INFO]: Epoch 029 - training loss: 0.3457, validation loss: 0.1726
2024-06-04 03:02:03 [INFO]: Epoch 030 - training loss: 0.3462, validation loss: 0.1555
2024-06-04 03:02:07 [INFO]: Epoch 031 - training loss: 0.3461, validation loss: 0.1556
2024-06-04 03:02:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:02:07 [INFO]: Finished training. The best model is from epoch#21.
2024-06-04 03:02:07 [INFO]: Saved the model to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_4/20240604_T025935/FreTS.pypots
2024-06-04 03:02:08 [INFO]: Successfully saved to new_results_point_rate01/BeijingAir/FreTS_BeijingAir/round_4/imputation.pkl
2024-06-04 03:02:08 [INFO]: Round4 - FreTS on BeijingAir: MAE=0.2524, MSE=0.2172, MRE=0.3814
2024-06-04 03:02:08 [INFO]: Done! Final results:
Averaged FreTS (909,852 params) on BeijingAir: MAE=0.2109 ± 0.008123544795575926, MSE=0.1459 ± 0.004955926432180425, MRE=0.2805 ± 0.010804883195093347, average inference time=0.20