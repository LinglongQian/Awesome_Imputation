2024-06-02 03:50:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 03:50:58 [INFO]: Using the given device: cuda:0
2024-06-02 03:50:59 [INFO]: Model files will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_0/20240602_T035059
2024-06-02 03:50:59 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_0/20240602_T035059/tensorboard
2024-06-02 03:51:01 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-02 03:51:05 [INFO]: Epoch 001 - training loss: 0.4365, validation loss: 0.4821
2024-06-02 03:51:07 [INFO]: Epoch 002 - training loss: 0.2495, validation loss: 0.4612
2024-06-02 03:51:08 [INFO]: Epoch 003 - training loss: 0.2290, validation loss: 0.4547
2024-06-02 03:51:09 [INFO]: Epoch 004 - training loss: 0.2250, validation loss: 0.4493
2024-06-02 03:51:10 [INFO]: Epoch 005 - training loss: 0.2220, validation loss: 0.4444
2024-06-02 03:51:11 [INFO]: Epoch 006 - training loss: 0.2059, validation loss: 0.4433
2024-06-02 03:51:12 [INFO]: Epoch 007 - training loss: 0.2038, validation loss: 0.4498
2024-06-02 03:51:14 [INFO]: Epoch 008 - training loss: 0.2059, validation loss: 0.4321
2024-06-02 03:51:15 [INFO]: Epoch 009 - training loss: 0.1915, validation loss: 0.4340
2024-06-02 03:51:16 [INFO]: Epoch 010 - training loss: 0.1909, validation loss: 0.4298
2024-06-02 03:51:17 [INFO]: Epoch 011 - training loss: 0.1812, validation loss: 0.4277
2024-06-02 03:51:18 [INFO]: Epoch 012 - training loss: 0.1839, validation loss: 0.4250
2024-06-02 03:51:20 [INFO]: Epoch 013 - training loss: 0.1737, validation loss: 0.4147
2024-06-02 03:51:21 [INFO]: Epoch 014 - training loss: 0.1681, validation loss: 0.4106
2024-06-02 03:51:22 [INFO]: Epoch 015 - training loss: 0.1657, validation loss: 0.4066
2024-06-02 03:51:23 [INFO]: Epoch 016 - training loss: 0.1605, validation loss: 0.4033
2024-06-02 03:51:24 [INFO]: Epoch 017 - training loss: 0.1566, validation loss: 0.4110
2024-06-02 03:51:25 [INFO]: Epoch 018 - training loss: 0.1536, validation loss: 0.3917
2024-06-02 03:51:26 [INFO]: Epoch 019 - training loss: 0.1492, validation loss: 0.3938
2024-06-02 03:51:28 [INFO]: Epoch 020 - training loss: 0.1442, validation loss: 0.3837
2024-06-02 03:51:29 [INFO]: Epoch 021 - training loss: 0.1401, validation loss: 0.3806
2024-06-02 03:51:30 [INFO]: Epoch 022 - training loss: 0.1398, validation loss: 0.3845
2024-06-02 03:51:31 [INFO]: Epoch 023 - training loss: 0.1350, validation loss: 0.3782
2024-06-02 03:51:33 [INFO]: Epoch 024 - training loss: 0.1346, validation loss: 0.3763
2024-06-02 03:51:34 [INFO]: Epoch 025 - training loss: 0.1316, validation loss: 0.3694
2024-06-02 03:51:35 [INFO]: Epoch 026 - training loss: 0.1262, validation loss: 0.3680
2024-06-02 03:51:36 [INFO]: Epoch 027 - training loss: 0.1275, validation loss: 0.3726
2024-06-02 03:51:38 [INFO]: Epoch 028 - training loss: 0.1260, validation loss: 0.3634
2024-06-02 03:51:39 [INFO]: Epoch 029 - training loss: 0.1225, validation loss: 0.3645
2024-06-02 03:51:40 [INFO]: Epoch 030 - training loss: 0.1212, validation loss: 0.3577
2024-06-02 03:51:41 [INFO]: Epoch 031 - training loss: 0.1184, validation loss: 0.3584
2024-06-02 03:51:42 [INFO]: Epoch 032 - training loss: 0.1164, validation loss: 0.3603
2024-06-02 03:51:44 [INFO]: Epoch 033 - training loss: 0.1152, validation loss: 0.3540
2024-06-02 03:51:45 [INFO]: Epoch 034 - training loss: 0.1140, validation loss: 0.3528
2024-06-02 03:51:46 [INFO]: Epoch 035 - training loss: 0.1108, validation loss: 0.3550
2024-06-02 03:51:47 [INFO]: Epoch 036 - training loss: 0.1088, validation loss: 0.3553
2024-06-02 03:51:48 [INFO]: Epoch 037 - training loss: 0.1079, validation loss: 0.3497
2024-06-02 03:51:49 [INFO]: Epoch 038 - training loss: 0.1061, validation loss: 0.3476
2024-06-02 03:51:51 [INFO]: Epoch 039 - training loss: 0.1063, validation loss: 0.3470
2024-06-02 03:51:52 [INFO]: Epoch 040 - training loss: 0.1075, validation loss: 0.3402
2024-06-02 03:51:53 [INFO]: Epoch 041 - training loss: 0.1060, validation loss: 0.3430
2024-06-02 03:51:54 [INFO]: Epoch 042 - training loss: 0.1043, validation loss: 0.3515
2024-06-02 03:51:55 [INFO]: Epoch 043 - training loss: 0.1054, validation loss: 0.3363
2024-06-02 03:51:56 [INFO]: Epoch 044 - training loss: 0.1026, validation loss: 0.3387
2024-06-02 03:51:58 [INFO]: Epoch 045 - training loss: 0.0996, validation loss: 0.3369
2024-06-02 03:51:59 [INFO]: Epoch 046 - training loss: 0.0991, validation loss: 0.3381
2024-06-02 03:52:00 [INFO]: Epoch 047 - training loss: 0.0977, validation loss: 0.3339
2024-06-02 03:52:01 [INFO]: Epoch 048 - training loss: 0.0933, validation loss: 0.3382
2024-06-02 03:52:02 [INFO]: Epoch 049 - training loss: 0.0930, validation loss: 0.3330
2024-06-02 03:52:03 [INFO]: Epoch 050 - training loss: 0.0946, validation loss: 0.3314
2024-06-02 03:52:05 [INFO]: Epoch 051 - training loss: 0.0917, validation loss: 0.3346
2024-06-02 03:52:06 [INFO]: Epoch 052 - training loss: 0.0898, validation loss: 0.3322
2024-06-02 03:52:07 [INFO]: Epoch 053 - training loss: 0.0905, validation loss: 0.3301
2024-06-02 03:52:08 [INFO]: Epoch 054 - training loss: 0.0891, validation loss: 0.3296
2024-06-02 03:52:10 [INFO]: Epoch 055 - training loss: 0.0877, validation loss: 0.3303
2024-06-02 03:52:11 [INFO]: Epoch 056 - training loss: 0.0875, validation loss: 0.3287
2024-06-02 03:52:12 [INFO]: Epoch 057 - training loss: 0.0853, validation loss: 0.3287
2024-06-02 03:52:13 [INFO]: Epoch 058 - training loss: 0.0841, validation loss: 0.3290
2024-06-02 03:52:15 [INFO]: Epoch 059 - training loss: 0.0848, validation loss: 0.3258
2024-06-02 03:52:16 [INFO]: Epoch 060 - training loss: 0.0858, validation loss: 0.3274
2024-06-02 03:52:17 [INFO]: Epoch 061 - training loss: 0.0854, validation loss: 0.3255
2024-06-02 03:52:18 [INFO]: Epoch 062 - training loss: 0.0891, validation loss: 0.3271
2024-06-02 03:52:19 [INFO]: Epoch 063 - training loss: 0.0826, validation loss: 0.3274
2024-06-02 03:52:21 [INFO]: Epoch 064 - training loss: 0.0824, validation loss: 0.3248
2024-06-02 03:52:22 [INFO]: Epoch 065 - training loss: 0.0810, validation loss: 0.3248
2024-06-02 03:52:23 [INFO]: Epoch 066 - training loss: 0.0801, validation loss: 0.3251
2024-06-02 03:52:24 [INFO]: Epoch 067 - training loss: 0.0789, validation loss: 0.3253
2024-06-02 03:52:25 [INFO]: Epoch 068 - training loss: 0.0787, validation loss: 0.3219
2024-06-02 03:52:26 [INFO]: Epoch 069 - training loss: 0.0765, validation loss: 0.3210
2024-06-02 03:52:28 [INFO]: Epoch 070 - training loss: 0.0748, validation loss: 0.3284
2024-06-02 03:52:29 [INFO]: Epoch 071 - training loss: 0.0744, validation loss: 0.3242
2024-06-02 03:52:30 [INFO]: Epoch 072 - training loss: 0.0758, validation loss: 0.3254
2024-06-02 03:52:31 [INFO]: Epoch 073 - training loss: 0.0739, validation loss: 0.3226
2024-06-02 03:52:33 [INFO]: Epoch 074 - training loss: 0.0740, validation loss: 0.3246
2024-06-02 03:52:34 [INFO]: Epoch 075 - training loss: 0.0724, validation loss: 0.3234
2024-06-02 03:52:35 [INFO]: Epoch 076 - training loss: 0.0714, validation loss: 0.3235
2024-06-02 03:52:36 [INFO]: Epoch 077 - training loss: 0.0698, validation loss: 0.3312
2024-06-02 03:52:37 [INFO]: Epoch 078 - training loss: 0.0689, validation loss: 0.3217
2024-06-02 03:52:39 [INFO]: Epoch 079 - training loss: 0.0676, validation loss: 0.3237
2024-06-02 03:52:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:52:39 [INFO]: Finished training. The best model is from epoch#69.
2024-06-02 03:52:40 [INFO]: Saved the model to results_point_rate01/PeMS/TimesNet_PeMS/round_0/20240602_T035059/TimesNet.pypots
2024-06-02 03:52:40 [INFO]: Successfully saved to results_point_rate01/PeMS/TimesNet_PeMS/round_0/imputation.pkl
2024-06-02 03:52:40 [INFO]: Round0 - TimesNet on PeMS: MAE=0.3120, MSE=0.5020, MRE=0.3867
2024-06-02 03:52:40 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 03:52:40 [INFO]: Using the given device: cuda:0
2024-06-02 03:52:40 [INFO]: Model files will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_1/20240602_T035240
2024-06-02 03:52:40 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_1/20240602_T035240/tensorboard
2024-06-02 03:52:42 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-02 03:52:43 [INFO]: Epoch 001 - training loss: 0.4402, validation loss: 0.4950
2024-06-02 03:52:45 [INFO]: Epoch 002 - training loss: 0.2491, validation loss: 0.4647
2024-06-02 03:52:46 [INFO]: Epoch 003 - training loss: 0.2329, validation loss: 0.4515
2024-06-02 03:52:47 [INFO]: Epoch 004 - training loss: 0.2267, validation loss: 0.4485
2024-06-02 03:52:48 [INFO]: Epoch 005 - training loss: 0.2191, validation loss: 0.4465
2024-06-02 03:52:49 [INFO]: Epoch 006 - training loss: 0.2129, validation loss: 0.4379
2024-06-02 03:52:51 [INFO]: Epoch 007 - training loss: 0.2053, validation loss: 0.4393
2024-06-02 03:52:52 [INFO]: Epoch 008 - training loss: 0.2027, validation loss: 0.4321
2024-06-02 03:52:53 [INFO]: Epoch 009 - training loss: 0.1935, validation loss: 0.4306
2024-06-02 03:52:54 [INFO]: Epoch 010 - training loss: 0.1837, validation loss: 0.4234
2024-06-02 03:52:56 [INFO]: Epoch 011 - training loss: 0.1839, validation loss: 0.4103
2024-06-02 03:52:57 [INFO]: Epoch 012 - training loss: 0.1779, validation loss: 0.4148
2024-06-02 03:52:58 [INFO]: Epoch 013 - training loss: 0.1707, validation loss: 0.4091
2024-06-02 03:52:59 [INFO]: Epoch 014 - training loss: 0.1653, validation loss: 0.4005
2024-06-02 03:53:00 [INFO]: Epoch 015 - training loss: 0.1621, validation loss: 0.3990
2024-06-02 03:53:01 [INFO]: Epoch 016 - training loss: 0.1576, validation loss: 0.4005
2024-06-02 03:53:03 [INFO]: Epoch 017 - training loss: 0.1521, validation loss: 0.3913
2024-06-02 03:53:04 [INFO]: Epoch 018 - training loss: 0.1512, validation loss: 0.3882
2024-06-02 03:53:05 [INFO]: Epoch 019 - training loss: 0.1448, validation loss: 0.3851
2024-06-02 03:53:06 [INFO]: Epoch 020 - training loss: 0.1398, validation loss: 0.3801
2024-06-02 03:53:08 [INFO]: Epoch 021 - training loss: 0.1410, validation loss: 0.3800
2024-06-02 03:53:09 [INFO]: Epoch 022 - training loss: 0.1355, validation loss: 0.3790
2024-06-02 03:53:10 [INFO]: Epoch 023 - training loss: 0.1347, validation loss: 0.3749
2024-06-02 03:53:11 [INFO]: Epoch 024 - training loss: 0.1346, validation loss: 0.3774
2024-06-02 03:53:12 [INFO]: Epoch 025 - training loss: 0.1302, validation loss: 0.3659
2024-06-02 03:53:14 [INFO]: Epoch 026 - training loss: 0.1277, validation loss: 0.3634
2024-06-02 03:53:15 [INFO]: Epoch 027 - training loss: 0.1261, validation loss: 0.3612
2024-06-02 03:53:16 [INFO]: Epoch 028 - training loss: 0.1260, validation loss: 0.3640
2024-06-02 03:53:18 [INFO]: Epoch 029 - training loss: 0.1228, validation loss: 0.3589
2024-06-02 03:53:19 [INFO]: Epoch 030 - training loss: 0.1208, validation loss: 0.3597
2024-06-02 03:53:20 [INFO]: Epoch 031 - training loss: 0.1169, validation loss: 0.3563
2024-06-02 03:53:21 [INFO]: Epoch 032 - training loss: 0.1153, validation loss: 0.3563
2024-06-02 03:53:22 [INFO]: Epoch 033 - training loss: 0.1142, validation loss: 0.3539
2024-06-02 03:53:24 [INFO]: Epoch 034 - training loss: 0.1138, validation loss: 0.3492
2024-06-02 03:53:25 [INFO]: Epoch 035 - training loss: 0.1103, validation loss: 0.3496
2024-06-02 03:53:26 [INFO]: Epoch 036 - training loss: 0.1081, validation loss: 0.3494
2024-06-02 03:53:27 [INFO]: Epoch 037 - training loss: 0.1099, validation loss: 0.3429
2024-06-02 03:53:28 [INFO]: Epoch 038 - training loss: 0.1063, validation loss: 0.3436
2024-06-02 03:53:29 [INFO]: Epoch 039 - training loss: 0.1047, validation loss: 0.3496
2024-06-02 03:53:31 [INFO]: Epoch 040 - training loss: 0.1035, validation loss: 0.3360
2024-06-02 03:53:32 [INFO]: Epoch 041 - training loss: 0.1028, validation loss: 0.3415
2024-06-02 03:53:33 [INFO]: Epoch 042 - training loss: 0.1049, validation loss: 0.3387
2024-06-02 03:53:34 [INFO]: Epoch 043 - training loss: 0.1007, validation loss: 0.3337
2024-06-02 03:53:35 [INFO]: Epoch 044 - training loss: 0.1006, validation loss: 0.3377
2024-06-02 03:53:37 [INFO]: Epoch 045 - training loss: 0.1002, validation loss: 0.3403
2024-06-02 03:53:38 [INFO]: Epoch 046 - training loss: 0.0975, validation loss: 0.3356
2024-06-02 03:53:39 [INFO]: Epoch 047 - training loss: 0.0962, validation loss: 0.3309
2024-06-02 03:53:40 [INFO]: Epoch 048 - training loss: 0.0957, validation loss: 0.3329
2024-06-02 03:53:41 [INFO]: Epoch 049 - training loss: 0.0939, validation loss: 0.3284
2024-06-02 03:53:43 [INFO]: Epoch 050 - training loss: 0.0947, validation loss: 0.3334
2024-06-02 03:53:44 [INFO]: Epoch 051 - training loss: 0.0929, validation loss: 0.3279
2024-06-02 03:53:45 [INFO]: Epoch 052 - training loss: 0.0909, validation loss: 0.3249
2024-06-02 03:53:46 [INFO]: Epoch 053 - training loss: 0.0923, validation loss: 0.3260
2024-06-02 03:53:47 [INFO]: Epoch 054 - training loss: 0.0897, validation loss: 0.3266
2024-06-02 03:53:48 [INFO]: Epoch 055 - training loss: 0.0885, validation loss: 0.3237
2024-06-02 03:53:50 [INFO]: Epoch 056 - training loss: 0.0874, validation loss: 0.3267
2024-06-02 03:53:51 [INFO]: Epoch 057 - training loss: 0.0862, validation loss: 0.3243
2024-06-02 03:53:52 [INFO]: Epoch 058 - training loss: 0.0846, validation loss: 0.3222
2024-06-02 03:53:53 [INFO]: Epoch 059 - training loss: 0.0838, validation loss: 0.3246
2024-06-02 03:53:54 [INFO]: Epoch 060 - training loss: 0.0836, validation loss: 0.3222
2024-06-02 03:53:55 [INFO]: Epoch 061 - training loss: 0.0848, validation loss: 0.3268
2024-06-02 03:53:57 [INFO]: Epoch 062 - training loss: 0.0830, validation loss: 0.3209
2024-06-02 03:53:58 [INFO]: Epoch 063 - training loss: 0.0816, validation loss: 0.3225
2024-06-02 03:53:59 [INFO]: Epoch 064 - training loss: 0.0813, validation loss: 0.3229
2024-06-02 03:54:00 [INFO]: Epoch 065 - training loss: 0.0815, validation loss: 0.3216
2024-06-02 03:54:01 [INFO]: Epoch 066 - training loss: 0.0805, validation loss: 0.3189
2024-06-02 03:54:02 [INFO]: Epoch 067 - training loss: 0.0782, validation loss: 0.3193
2024-06-02 03:54:04 [INFO]: Epoch 068 - training loss: 0.0778, validation loss: 0.3209
2024-06-02 03:54:05 [INFO]: Epoch 069 - training loss: 0.0765, validation loss: 0.3190
2024-06-02 03:54:06 [INFO]: Epoch 070 - training loss: 0.0753, validation loss: 0.3167
2024-06-02 03:54:07 [INFO]: Epoch 071 - training loss: 0.0743, validation loss: 0.3198
2024-06-02 03:54:08 [INFO]: Epoch 072 - training loss: 0.0722, validation loss: 0.3172
2024-06-02 03:54:10 [INFO]: Epoch 073 - training loss: 0.0718, validation loss: 0.3178
2024-06-02 03:54:11 [INFO]: Epoch 074 - training loss: 0.0737, validation loss: 0.3151
2024-06-02 03:54:12 [INFO]: Epoch 075 - training loss: 0.0716, validation loss: 0.3183
2024-06-02 03:54:13 [INFO]: Epoch 076 - training loss: 0.0721, validation loss: 0.3232
2024-06-02 03:54:14 [INFO]: Epoch 077 - training loss: 0.0699, validation loss: 0.3173
2024-06-02 03:54:15 [INFO]: Epoch 078 - training loss: 0.0688, validation loss: 0.3189
2024-06-02 03:54:17 [INFO]: Epoch 079 - training loss: 0.0689, validation loss: 0.3190
2024-06-02 03:54:18 [INFO]: Epoch 080 - training loss: 0.0677, validation loss: 0.3218
2024-06-02 03:54:19 [INFO]: Epoch 081 - training loss: 0.0686, validation loss: 0.3153
2024-06-02 03:54:20 [INFO]: Epoch 082 - training loss: 0.0672, validation loss: 0.3210
2024-06-02 03:54:21 [INFO]: Epoch 083 - training loss: 0.0676, validation loss: 0.3186
2024-06-02 03:54:22 [INFO]: Epoch 084 - training loss: 0.0645, validation loss: 0.3220
2024-06-02 03:54:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:54:22 [INFO]: Finished training. The best model is from epoch#74.
2024-06-02 03:54:23 [INFO]: Saved the model to results_point_rate01/PeMS/TimesNet_PeMS/round_1/20240602_T035240/TimesNet.pypots
2024-06-02 03:54:24 [INFO]: Successfully saved to results_point_rate01/PeMS/TimesNet_PeMS/round_1/imputation.pkl
2024-06-02 03:54:24 [INFO]: Round1 - TimesNet on PeMS: MAE=0.3131, MSE=0.5018, MRE=0.3881
2024-06-02 03:54:24 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 03:54:24 [INFO]: Using the given device: cuda:0
2024-06-02 03:54:24 [INFO]: Model files will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_2/20240602_T035424
2024-06-02 03:54:24 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_2/20240602_T035424/tensorboard
2024-06-02 03:54:26 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-02 03:54:27 [INFO]: Epoch 001 - training loss: 0.4340, validation loss: 0.4997
2024-06-02 03:54:28 [INFO]: Epoch 002 - training loss: 0.2529, validation loss: 0.4660
2024-06-02 03:54:29 [INFO]: Epoch 003 - training loss: 0.2345, validation loss: 0.4573
2024-06-02 03:54:31 [INFO]: Epoch 004 - training loss: 0.2281, validation loss: 0.4481
2024-06-02 03:54:32 [INFO]: Epoch 005 - training loss: 0.2200, validation loss: 0.4468
2024-06-02 03:54:33 [INFO]: Epoch 006 - training loss: 0.2149, validation loss: 0.4407
2024-06-02 03:54:35 [INFO]: Epoch 007 - training loss: 0.2021, validation loss: 0.4343
2024-06-02 03:54:36 [INFO]: Epoch 008 - training loss: 0.2006, validation loss: 0.4332
2024-06-02 03:54:37 [INFO]: Epoch 009 - training loss: 0.1932, validation loss: 0.4321
2024-06-02 03:54:38 [INFO]: Epoch 010 - training loss: 0.1887, validation loss: 0.4274
2024-06-02 03:54:39 [INFO]: Epoch 011 - training loss: 0.1898, validation loss: 0.4194
2024-06-02 03:54:41 [INFO]: Epoch 012 - training loss: 0.1772, validation loss: 0.4167
2024-06-02 03:54:42 [INFO]: Epoch 013 - training loss: 0.1722, validation loss: 0.4130
2024-06-02 03:54:43 [INFO]: Epoch 014 - training loss: 0.1664, validation loss: 0.4053
2024-06-02 03:54:44 [INFO]: Epoch 015 - training loss: 0.1662, validation loss: 0.4036
2024-06-02 03:54:45 [INFO]: Epoch 016 - training loss: 0.1608, validation loss: 0.3967
2024-06-02 03:54:47 [INFO]: Epoch 017 - training loss: 0.1560, validation loss: 0.3951
2024-06-02 03:54:48 [INFO]: Epoch 018 - training loss: 0.1499, validation loss: 0.3886
2024-06-02 03:54:49 [INFO]: Epoch 019 - training loss: 0.1460, validation loss: 0.3881
2024-06-02 03:54:50 [INFO]: Epoch 020 - training loss: 0.1395, validation loss: 0.3851
2024-06-02 03:54:52 [INFO]: Epoch 021 - training loss: 0.1385, validation loss: 0.3774
2024-06-02 03:54:53 [INFO]: Epoch 022 - training loss: 0.1369, validation loss: 0.3768
2024-06-02 03:54:54 [INFO]: Epoch 023 - training loss: 0.1348, validation loss: 0.3742
2024-06-02 03:54:55 [INFO]: Epoch 024 - training loss: 0.1342, validation loss: 0.3739
2024-06-02 03:54:56 [INFO]: Epoch 025 - training loss: 0.1307, validation loss: 0.3703
2024-06-02 03:54:57 [INFO]: Epoch 026 - training loss: 0.1272, validation loss: 0.3690
2024-06-02 03:54:59 [INFO]: Epoch 027 - training loss: 0.1252, validation loss: 0.3666
2024-06-02 03:55:00 [INFO]: Epoch 028 - training loss: 0.1226, validation loss: 0.3588
2024-06-02 03:55:01 [INFO]: Epoch 029 - training loss: 0.1207, validation loss: 0.3633
2024-06-02 03:55:02 [INFO]: Epoch 030 - training loss: 0.1196, validation loss: 0.3542
2024-06-02 03:55:03 [INFO]: Epoch 031 - training loss: 0.1190, validation loss: 0.3671
2024-06-02 03:55:04 [INFO]: Epoch 032 - training loss: 0.1169, validation loss: 0.3535
2024-06-02 03:55:06 [INFO]: Epoch 033 - training loss: 0.1158, validation loss: 0.3531
2024-06-02 03:55:07 [INFO]: Epoch 034 - training loss: 0.1136, validation loss: 0.3500
2024-06-02 03:55:08 [INFO]: Epoch 035 - training loss: 0.1111, validation loss: 0.3484
2024-06-02 03:55:09 [INFO]: Epoch 036 - training loss: 0.1091, validation loss: 0.3450
2024-06-02 03:55:10 [INFO]: Epoch 037 - training loss: 0.1090, validation loss: 0.3446
2024-06-02 03:55:12 [INFO]: Epoch 038 - training loss: 0.1094, validation loss: 0.3514
2024-06-02 03:55:13 [INFO]: Epoch 039 - training loss: 0.1078, validation loss: 0.3400
2024-06-02 03:55:14 [INFO]: Epoch 040 - training loss: 0.1066, validation loss: 0.3418
2024-06-02 03:55:15 [INFO]: Epoch 041 - training loss: 0.1061, validation loss: 0.3403
2024-06-02 03:55:16 [INFO]: Epoch 042 - training loss: 0.1039, validation loss: 0.3375
2024-06-02 03:55:17 [INFO]: Epoch 043 - training loss: 0.1025, validation loss: 0.3395
2024-06-02 03:55:18 [INFO]: Epoch 044 - training loss: 0.1004, validation loss: 0.3362
2024-06-02 03:55:20 [INFO]: Epoch 045 - training loss: 0.0988, validation loss: 0.3313
2024-06-02 03:55:21 [INFO]: Epoch 046 - training loss: 0.0979, validation loss: 0.3362
2024-06-02 03:55:22 [INFO]: Epoch 047 - training loss: 0.0968, validation loss: 0.3323
2024-06-02 03:55:23 [INFO]: Epoch 048 - training loss: 0.0973, validation loss: 0.3354
2024-06-02 03:55:24 [INFO]: Epoch 049 - training loss: 0.0968, validation loss: 0.3363
2024-06-02 03:55:26 [INFO]: Epoch 050 - training loss: 0.0941, validation loss: 0.3274
2024-06-02 03:55:27 [INFO]: Epoch 051 - training loss: 0.0926, validation loss: 0.3295
2024-06-02 03:55:28 [INFO]: Epoch 052 - training loss: 0.0917, validation loss: 0.3269
2024-06-02 03:55:29 [INFO]: Epoch 053 - training loss: 0.0899, validation loss: 0.3282
2024-06-02 03:55:30 [INFO]: Epoch 054 - training loss: 0.0900, validation loss: 0.3274
2024-06-02 03:55:31 [INFO]: Epoch 055 - training loss: 0.0879, validation loss: 0.3327
2024-06-02 03:55:33 [INFO]: Epoch 056 - training loss: 0.0899, validation loss: 0.3232
2024-06-02 03:55:34 [INFO]: Epoch 057 - training loss: 0.0860, validation loss: 0.3240
2024-06-02 03:55:35 [INFO]: Epoch 058 - training loss: 0.0871, validation loss: 0.3243
2024-06-02 03:55:36 [INFO]: Epoch 059 - training loss: 0.0845, validation loss: 0.3220
2024-06-02 03:55:37 [INFO]: Epoch 060 - training loss: 0.0845, validation loss: 0.3234
2024-06-02 03:55:39 [INFO]: Epoch 061 - training loss: 0.0850, validation loss: 0.3240
2024-06-02 03:55:40 [INFO]: Epoch 062 - training loss: 0.0849, validation loss: 0.3401
2024-06-02 03:55:41 [INFO]: Epoch 063 - training loss: 0.0923, validation loss: 0.3379
2024-06-02 03:55:42 [INFO]: Epoch 064 - training loss: 0.0950, validation loss: 0.3275
2024-06-02 03:55:43 [INFO]: Epoch 065 - training loss: 0.0857, validation loss: 0.3242
2024-06-02 03:55:44 [INFO]: Epoch 066 - training loss: 0.0820, validation loss: 0.3213
2024-06-02 03:55:45 [INFO]: Epoch 067 - training loss: 0.0805, validation loss: 0.3201
2024-06-02 03:55:47 [INFO]: Epoch 068 - training loss: 0.0790, validation loss: 0.3178
2024-06-02 03:55:48 [INFO]: Epoch 069 - training loss: 0.0780, validation loss: 0.3175
2024-06-02 03:55:49 [INFO]: Epoch 070 - training loss: 0.0771, validation loss: 0.3190
2024-06-02 03:55:50 [INFO]: Epoch 071 - training loss: 0.0760, validation loss: 0.3199
2024-06-02 03:55:51 [INFO]: Epoch 072 - training loss: 0.0744, validation loss: 0.3181
2024-06-02 03:55:53 [INFO]: Epoch 073 - training loss: 0.0745, validation loss: 0.3184
2024-06-02 03:55:54 [INFO]: Epoch 074 - training loss: 0.0742, validation loss: 0.3182
2024-06-02 03:55:55 [INFO]: Epoch 075 - training loss: 0.0729, validation loss: 0.3217
2024-06-02 03:55:56 [INFO]: Epoch 076 - training loss: 0.0732, validation loss: 0.3203
2024-06-02 03:55:57 [INFO]: Epoch 077 - training loss: 0.0711, validation loss: 0.3167
2024-06-02 03:55:58 [INFO]: Epoch 078 - training loss: 0.0708, validation loss: 0.3241
2024-06-02 03:56:00 [INFO]: Epoch 079 - training loss: 0.0693, validation loss: 0.3208
2024-06-02 03:56:01 [INFO]: Epoch 080 - training loss: 0.0672, validation loss: 0.3235
2024-06-02 03:56:02 [INFO]: Epoch 081 - training loss: 0.0681, validation loss: 0.3208
2024-06-02 03:56:03 [INFO]: Epoch 082 - training loss: 0.0677, validation loss: 0.3226
2024-06-02 03:56:05 [INFO]: Epoch 083 - training loss: 0.0669, validation loss: 0.3177
2024-06-02 03:56:06 [INFO]: Epoch 084 - training loss: 0.0671, validation loss: 0.3179
2024-06-02 03:56:07 [INFO]: Epoch 085 - training loss: 0.0647, validation loss: 0.3210
2024-06-02 03:56:08 [INFO]: Epoch 086 - training loss: 0.0652, validation loss: 0.3198
2024-06-02 03:56:09 [INFO]: Epoch 087 - training loss: 0.0638, validation loss: 0.3218
2024-06-02 03:56:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:56:09 [INFO]: Finished training. The best model is from epoch#77.
2024-06-02 03:56:10 [INFO]: Saved the model to results_point_rate01/PeMS/TimesNet_PeMS/round_2/20240602_T035424/TimesNet.pypots
2024-06-02 03:56:11 [INFO]: Successfully saved to results_point_rate01/PeMS/TimesNet_PeMS/round_2/imputation.pkl
2024-06-02 03:56:11 [INFO]: Round2 - TimesNet on PeMS: MAE=0.3132, MSE=0.4994, MRE=0.3883
2024-06-02 03:56:11 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 03:56:11 [INFO]: Using the given device: cuda:0
2024-06-02 03:56:11 [INFO]: Model files will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_3/20240602_T035611
2024-06-02 03:56:11 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_3/20240602_T035611/tensorboard
2024-06-02 03:56:13 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-02 03:56:14 [INFO]: Epoch 001 - training loss: 0.4445, validation loss: 0.4892
2024-06-02 03:56:15 [INFO]: Epoch 002 - training loss: 0.2528, validation loss: 0.4623
2024-06-02 03:56:16 [INFO]: Epoch 003 - training loss: 0.2324, validation loss: 0.4603
2024-06-02 03:56:17 [INFO]: Epoch 004 - training loss: 0.2294, validation loss: 0.4495
2024-06-02 03:56:18 [INFO]: Epoch 005 - training loss: 0.2202, validation loss: 0.4491
2024-06-02 03:56:20 [INFO]: Epoch 006 - training loss: 0.2161, validation loss: 0.4383
2024-06-02 03:56:21 [INFO]: Epoch 007 - training loss: 0.2036, validation loss: 0.4319
2024-06-02 03:56:22 [INFO]: Epoch 008 - training loss: 0.2009, validation loss: 0.4295
2024-06-02 03:56:23 [INFO]: Epoch 009 - training loss: 0.1937, validation loss: 0.4265
2024-06-02 03:56:25 [INFO]: Epoch 010 - training loss: 0.1890, validation loss: 0.4170
2024-06-02 03:56:26 [INFO]: Epoch 011 - training loss: 0.1787, validation loss: 0.4150
2024-06-02 03:56:27 [INFO]: Epoch 012 - training loss: 0.1767, validation loss: 0.4103
2024-06-02 03:56:28 [INFO]: Epoch 013 - training loss: 0.1710, validation loss: 0.4096
2024-06-02 03:56:29 [INFO]: Epoch 014 - training loss: 0.1685, validation loss: 0.4051
2024-06-02 03:56:30 [INFO]: Epoch 015 - training loss: 0.1610, validation loss: 0.3984
2024-06-02 03:56:32 [INFO]: Epoch 016 - training loss: 0.1590, validation loss: 0.3930
2024-06-02 03:56:33 [INFO]: Epoch 017 - training loss: 0.1508, validation loss: 0.3899
2024-06-02 03:56:34 [INFO]: Epoch 018 - training loss: 0.1514, validation loss: 0.3957
2024-06-02 03:56:35 [INFO]: Epoch 019 - training loss: 0.1482, validation loss: 0.3842
2024-06-02 03:56:37 [INFO]: Epoch 020 - training loss: 0.1428, validation loss: 0.3841
2024-06-02 03:56:38 [INFO]: Epoch 021 - training loss: 0.1415, validation loss: 0.3776
2024-06-02 03:56:39 [INFO]: Epoch 022 - training loss: 0.1366, validation loss: 0.3726
2024-06-02 03:56:40 [INFO]: Epoch 023 - training loss: 0.1321, validation loss: 0.3706
2024-06-02 03:56:42 [INFO]: Epoch 024 - training loss: 0.1324, validation loss: 0.3732
2024-06-02 03:56:43 [INFO]: Epoch 025 - training loss: 0.1304, validation loss: 0.3703
2024-06-02 03:56:44 [INFO]: Epoch 026 - training loss: 0.1296, validation loss: 0.3625
2024-06-02 03:56:45 [INFO]: Epoch 027 - training loss: 0.1271, validation loss: 0.3627
2024-06-02 03:56:46 [INFO]: Epoch 028 - training loss: 0.1259, validation loss: 0.3581
2024-06-02 03:56:47 [INFO]: Epoch 029 - training loss: 0.1234, validation loss: 0.3588
2024-06-02 03:56:49 [INFO]: Epoch 030 - training loss: 0.1176, validation loss: 0.3559
2024-06-02 03:56:50 [INFO]: Epoch 031 - training loss: 0.1198, validation loss: 0.3522
2024-06-02 03:56:51 [INFO]: Epoch 032 - training loss: 0.1175, validation loss: 0.3601
2024-06-02 03:56:52 [INFO]: Epoch 033 - training loss: 0.1188, validation loss: 0.3458
2024-06-02 03:56:54 [INFO]: Epoch 034 - training loss: 0.1130, validation loss: 0.3498
2024-06-02 03:56:55 [INFO]: Epoch 035 - training loss: 0.1116, validation loss: 0.3482
2024-06-02 03:56:56 [INFO]: Epoch 036 - training loss: 0.1119, validation loss: 0.3466
2024-06-02 03:56:57 [INFO]: Epoch 037 - training loss: 0.1101, validation loss: 0.3421
2024-06-02 03:56:58 [INFO]: Epoch 038 - training loss: 0.1060, validation loss: 0.3400
2024-06-02 03:56:59 [INFO]: Epoch 039 - training loss: 0.1043, validation loss: 0.3378
2024-06-02 03:57:01 [INFO]: Epoch 040 - training loss: 0.1042, validation loss: 0.3394
2024-06-02 03:57:02 [INFO]: Epoch 041 - training loss: 0.1031, validation loss: 0.3406
2024-06-02 03:57:03 [INFO]: Epoch 042 - training loss: 0.1011, validation loss: 0.3357
2024-06-02 03:57:04 [INFO]: Epoch 043 - training loss: 0.1005, validation loss: 0.3348
2024-06-02 03:57:05 [INFO]: Epoch 044 - training loss: 0.1000, validation loss: 0.3342
2024-06-02 03:57:07 [INFO]: Epoch 045 - training loss: 0.1030, validation loss: 0.3365
2024-06-02 03:57:08 [INFO]: Epoch 046 - training loss: 0.0977, validation loss: 0.3292
2024-06-02 03:57:09 [INFO]: Epoch 047 - training loss: 0.0958, validation loss: 0.3301
2024-06-02 03:57:10 [INFO]: Epoch 048 - training loss: 0.0953, validation loss: 0.3281
2024-06-02 03:57:12 [INFO]: Epoch 049 - training loss: 0.0973, validation loss: 0.3304
2024-06-02 03:57:13 [INFO]: Epoch 050 - training loss: 0.0944, validation loss: 0.3281
2024-06-02 03:57:14 [INFO]: Epoch 051 - training loss: 0.0930, validation loss: 0.3257
2024-06-02 03:57:15 [INFO]: Epoch 052 - training loss: 0.0926, validation loss: 0.3250
2024-06-02 03:57:16 [INFO]: Epoch 053 - training loss: 0.0888, validation loss: 0.3270
2024-06-02 03:57:18 [INFO]: Epoch 054 - training loss: 0.0901, validation loss: 0.3262
2024-06-02 03:57:19 [INFO]: Epoch 055 - training loss: 0.0876, validation loss: 0.3262
2024-06-02 03:57:20 [INFO]: Epoch 056 - training loss: 0.0884, validation loss: 0.3234
2024-06-02 03:57:21 [INFO]: Epoch 057 - training loss: 0.0853, validation loss: 0.3233
2024-06-02 03:57:22 [INFO]: Epoch 058 - training loss: 0.0836, validation loss: 0.3261
2024-06-02 03:57:23 [INFO]: Epoch 059 - training loss: 0.0859, validation loss: 0.3257
2024-06-02 03:57:25 [INFO]: Epoch 060 - training loss: 0.0851, validation loss: 0.3268
2024-06-02 03:57:26 [INFO]: Epoch 061 - training loss: 0.0833, validation loss: 0.3241
2024-06-02 03:57:27 [INFO]: Epoch 062 - training loss: 0.0876, validation loss: 0.3240
2024-06-02 03:57:28 [INFO]: Epoch 063 - training loss: 0.0864, validation loss: 0.3223
2024-06-02 03:57:29 [INFO]: Epoch 064 - training loss: 0.0842, validation loss: 0.3212
2024-06-02 03:57:31 [INFO]: Epoch 065 - training loss: 0.0827, validation loss: 0.3178
2024-06-02 03:57:32 [INFO]: Epoch 066 - training loss: 0.0824, validation loss: 0.3169
2024-06-02 03:57:33 [INFO]: Epoch 067 - training loss: 0.0805, validation loss: 0.3195
2024-06-02 03:57:34 [INFO]: Epoch 068 - training loss: 0.0785, validation loss: 0.3230
2024-06-02 03:57:35 [INFO]: Epoch 069 - training loss: 0.0786, validation loss: 0.3196
2024-06-02 03:57:36 [INFO]: Epoch 070 - training loss: 0.0771, validation loss: 0.3265
2024-06-02 03:57:37 [INFO]: Epoch 071 - training loss: 0.0763, validation loss: 0.3186
2024-06-02 03:57:38 [INFO]: Epoch 072 - training loss: 0.0766, validation loss: 0.3180
2024-06-02 03:57:39 [INFO]: Epoch 073 - training loss: 0.0748, validation loss: 0.3144
2024-06-02 03:57:40 [INFO]: Epoch 074 - training loss: 0.0748, validation loss: 0.3206
2024-06-02 03:57:41 [INFO]: Epoch 075 - training loss: 0.0720, validation loss: 0.3158
2024-06-02 03:57:42 [INFO]: Epoch 076 - training loss: 0.0736, validation loss: 0.3155
2024-06-02 03:57:43 [INFO]: Epoch 077 - training loss: 0.0717, validation loss: 0.3153
2024-06-02 03:57:43 [INFO]: Epoch 078 - training loss: 0.0704, validation loss: 0.3145
2024-06-02 03:57:44 [INFO]: Epoch 079 - training loss: 0.0709, validation loss: 0.3190
2024-06-02 03:57:45 [INFO]: Epoch 080 - training loss: 0.0689, validation loss: 0.3160
2024-06-02 03:57:46 [INFO]: Epoch 081 - training loss: 0.0682, validation loss: 0.3177
2024-06-02 03:57:47 [INFO]: Epoch 082 - training loss: 0.0676, validation loss: 0.3134
2024-06-02 03:57:48 [INFO]: Epoch 083 - training loss: 0.0661, validation loss: 0.3154
2024-06-02 03:57:49 [INFO]: Epoch 084 - training loss: 0.0649, validation loss: 0.3157
2024-06-02 03:57:49 [INFO]: Epoch 085 - training loss: 0.0641, validation loss: 0.3140
2024-06-02 03:57:50 [INFO]: Epoch 086 - training loss: 0.0637, validation loss: 0.3158
2024-06-02 03:57:51 [INFO]: Epoch 087 - training loss: 0.0622, validation loss: 0.3131
2024-06-02 03:57:52 [INFO]: Epoch 088 - training loss: 0.0624, validation loss: 0.3210
2024-06-02 03:57:53 [INFO]: Epoch 089 - training loss: 0.0624, validation loss: 0.3160
2024-06-02 03:57:54 [INFO]: Epoch 090 - training loss: 0.0611, validation loss: 0.3211
2024-06-02 03:57:55 [INFO]: Epoch 091 - training loss: 0.0600, validation loss: 0.3132
2024-06-02 03:57:56 [INFO]: Epoch 092 - training loss: 0.0596, validation loss: 0.3172
2024-06-02 03:57:56 [INFO]: Epoch 093 - training loss: 0.0594, validation loss: 0.3215
2024-06-02 03:57:57 [INFO]: Epoch 094 - training loss: 0.0593, validation loss: 0.3181
2024-06-02 03:57:58 [INFO]: Epoch 095 - training loss: 0.0597, validation loss: 0.3154
2024-06-02 03:57:59 [INFO]: Epoch 096 - training loss: 0.0583, validation loss: 0.3185
2024-06-02 03:58:00 [INFO]: Epoch 097 - training loss: 0.0570, validation loss: 0.3203
2024-06-02 03:58:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:58:00 [INFO]: Finished training. The best model is from epoch#87.
2024-06-02 03:58:01 [INFO]: Saved the model to results_point_rate01/PeMS/TimesNet_PeMS/round_3/20240602_T035611/TimesNet.pypots
2024-06-02 03:58:01 [INFO]: Successfully saved to results_point_rate01/PeMS/TimesNet_PeMS/round_3/imputation.pkl
2024-06-02 03:58:01 [INFO]: Round3 - TimesNet on PeMS: MAE=0.3109, MSE=0.4983, MRE=0.3854
2024-06-02 03:58:01 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 03:58:01 [INFO]: Using the given device: cuda:0
2024-06-02 03:58:01 [INFO]: Model files will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_4/20240602_T035801
2024-06-02 03:58:01 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/TimesNet_PeMS/round_4/20240602_T035801/tensorboard
2024-06-02 03:58:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-02 03:58:03 [INFO]: Epoch 001 - training loss: 0.4321, validation loss: 0.4930
2024-06-02 03:58:04 [INFO]: Epoch 002 - training loss: 0.2501, validation loss: 0.4688
2024-06-02 03:58:05 [INFO]: Epoch 003 - training loss: 0.2348, validation loss: 0.4583
2024-06-02 03:58:05 [INFO]: Epoch 004 - training loss: 0.2276, validation loss: 0.4485
2024-06-02 03:58:06 [INFO]: Epoch 005 - training loss: 0.2222, validation loss: 0.4549
2024-06-02 03:58:07 [INFO]: Epoch 006 - training loss: 0.2153, validation loss: 0.4456
2024-06-02 03:58:08 [INFO]: Epoch 007 - training loss: 0.2127, validation loss: 0.4371
2024-06-02 03:58:09 [INFO]: Epoch 008 - training loss: 0.2041, validation loss: 0.4338
2024-06-02 03:58:10 [INFO]: Epoch 009 - training loss: 0.1935, validation loss: 0.4286
2024-06-02 03:58:11 [INFO]: Epoch 010 - training loss: 0.1848, validation loss: 0.4300
2024-06-02 03:58:12 [INFO]: Epoch 011 - training loss: 0.1796, validation loss: 0.4226
2024-06-02 03:58:12 [INFO]: Epoch 012 - training loss: 0.1758, validation loss: 0.4139
2024-06-02 03:58:13 [INFO]: Epoch 013 - training loss: 0.1696, validation loss: 0.4079
2024-06-02 03:58:14 [INFO]: Epoch 014 - training loss: 0.1652, validation loss: 0.4042
2024-06-02 03:58:15 [INFO]: Epoch 015 - training loss: 0.1658, validation loss: 0.4010
2024-06-02 03:58:16 [INFO]: Epoch 016 - training loss: 0.1631, validation loss: 0.4107
2024-06-02 03:58:17 [INFO]: Epoch 017 - training loss: 0.1529, validation loss: 0.3967
2024-06-02 03:58:18 [INFO]: Epoch 018 - training loss: 0.1529, validation loss: 0.3900
2024-06-02 03:58:19 [INFO]: Epoch 019 - training loss: 0.1495, validation loss: 0.3853
2024-06-02 03:58:19 [INFO]: Epoch 020 - training loss: 0.1437, validation loss: 0.3833
2024-06-02 03:58:20 [INFO]: Epoch 021 - training loss: 0.1415, validation loss: 0.3782
2024-06-02 03:58:21 [INFO]: Epoch 022 - training loss: 0.1358, validation loss: 0.3777
2024-06-02 03:58:22 [INFO]: Epoch 023 - training loss: 0.1371, validation loss: 0.3807
2024-06-02 03:58:23 [INFO]: Epoch 024 - training loss: 0.1328, validation loss: 0.3739
2024-06-02 03:58:24 [INFO]: Epoch 025 - training loss: 0.1316, validation loss: 0.3737
2024-06-02 03:58:25 [INFO]: Epoch 026 - training loss: 0.1263, validation loss: 0.3675
2024-06-02 03:58:26 [INFO]: Epoch 027 - training loss: 0.1260, validation loss: 0.3747
2024-06-02 03:58:26 [INFO]: Epoch 028 - training loss: 0.1253, validation loss: 0.3643
2024-06-02 03:58:27 [INFO]: Epoch 029 - training loss: 0.1232, validation loss: 0.3571
2024-06-02 03:58:28 [INFO]: Epoch 030 - training loss: 0.1194, validation loss: 0.3610
2024-06-02 03:58:29 [INFO]: Epoch 031 - training loss: 0.1192, validation loss: 0.3599
2024-06-02 03:58:30 [INFO]: Epoch 032 - training loss: 0.1172, validation loss: 0.3630
2024-06-02 03:58:31 [INFO]: Epoch 033 - training loss: 0.1151, validation loss: 0.3548
2024-06-02 03:58:32 [INFO]: Epoch 034 - training loss: 0.1116, validation loss: 0.3513
2024-06-02 03:58:33 [INFO]: Epoch 035 - training loss: 0.1146, validation loss: 0.3484
2024-06-02 03:58:33 [INFO]: Epoch 036 - training loss: 0.1097, validation loss: 0.3487
2024-06-02 03:58:34 [INFO]: Epoch 037 - training loss: 0.1068, validation loss: 0.3487
2024-06-02 03:58:35 [INFO]: Epoch 038 - training loss: 0.1069, validation loss: 0.3474
2024-06-02 03:58:36 [INFO]: Epoch 039 - training loss: 0.1050, validation loss: 0.3421
2024-06-02 03:58:37 [INFO]: Epoch 040 - training loss: 0.1048, validation loss: 0.3432
2024-06-02 03:58:38 [INFO]: Epoch 041 - training loss: 0.1023, validation loss: 0.3421
2024-06-02 03:58:39 [INFO]: Epoch 042 - training loss: 0.1019, validation loss: 0.3437
2024-06-02 03:58:40 [INFO]: Epoch 043 - training loss: 0.1019, validation loss: 0.3411
2024-06-02 03:58:40 [INFO]: Epoch 044 - training loss: 0.1003, validation loss: 0.3449
2024-06-02 03:58:41 [INFO]: Epoch 045 - training loss: 0.0984, validation loss: 0.3349
2024-06-02 03:58:42 [INFO]: Epoch 046 - training loss: 0.0987, validation loss: 0.3399
2024-06-02 03:58:43 [INFO]: Epoch 047 - training loss: 0.0958, validation loss: 0.3378
2024-06-02 03:58:44 [INFO]: Epoch 048 - training loss: 0.0955, validation loss: 0.3396
2024-06-02 03:58:45 [INFO]: Epoch 049 - training loss: 0.0945, validation loss: 0.3326
2024-06-02 03:58:46 [INFO]: Epoch 050 - training loss: 0.0949, validation loss: 0.3371
2024-06-02 03:58:47 [INFO]: Epoch 051 - training loss: 0.0931, validation loss: 0.3329
2024-06-02 03:58:47 [INFO]: Epoch 052 - training loss: 0.0908, validation loss: 0.3300
2024-06-02 03:58:48 [INFO]: Epoch 053 - training loss: 0.0893, validation loss: 0.3283
2024-06-02 03:58:49 [INFO]: Epoch 054 - training loss: 0.0896, validation loss: 0.3292
2024-06-02 03:58:50 [INFO]: Epoch 055 - training loss: 0.0892, validation loss: 0.3319
2024-06-02 03:58:51 [INFO]: Epoch 056 - training loss: 0.0877, validation loss: 0.3286
2024-06-02 03:58:52 [INFO]: Epoch 057 - training loss: 0.0859, validation loss: 0.3271
2024-06-02 03:58:53 [INFO]: Epoch 058 - training loss: 0.0868, validation loss: 0.3245
2024-06-02 03:58:53 [INFO]: Epoch 059 - training loss: 0.0859, validation loss: 0.3331
2024-06-02 03:58:54 [INFO]: Epoch 060 - training loss: 0.0861, validation loss: 0.3271
2024-06-02 03:58:55 [INFO]: Epoch 061 - training loss: 0.0846, validation loss: 0.3260
2024-06-02 03:58:56 [INFO]: Epoch 062 - training loss: 0.0834, validation loss: 0.3280
2024-06-02 03:58:57 [INFO]: Epoch 063 - training loss: 0.0823, validation loss: 0.3271
2024-06-02 03:58:58 [INFO]: Epoch 064 - training loss: 0.0835, validation loss: 0.3339
2024-06-02 03:58:59 [INFO]: Epoch 065 - training loss: 0.0820, validation loss: 0.3254
2024-06-02 03:59:00 [INFO]: Epoch 066 - training loss: 0.0816, validation loss: 0.3383
2024-06-02 03:59:00 [INFO]: Epoch 067 - training loss: 0.0821, validation loss: 0.3265
2024-06-02 03:59:01 [INFO]: Epoch 068 - training loss: 0.0796, validation loss: 0.3233
2024-06-02 03:59:02 [INFO]: Epoch 069 - training loss: 0.0769, validation loss: 0.3210
2024-06-02 03:59:03 [INFO]: Epoch 070 - training loss: 0.0763, validation loss: 0.3248
2024-06-02 03:59:04 [INFO]: Epoch 071 - training loss: 0.0763, validation loss: 0.3215
2024-06-02 03:59:05 [INFO]: Epoch 072 - training loss: 0.0763, validation loss: 0.3236
2024-06-02 03:59:06 [INFO]: Epoch 073 - training loss: 0.0730, validation loss: 0.3224
2024-06-02 03:59:07 [INFO]: Epoch 074 - training loss: 0.0717, validation loss: 0.3217
2024-06-02 03:59:07 [INFO]: Epoch 075 - training loss: 0.0714, validation loss: 0.3226
2024-06-02 03:59:08 [INFO]: Epoch 076 - training loss: 0.0714, validation loss: 0.3211
2024-06-02 03:59:09 [INFO]: Epoch 077 - training loss: 0.0701, validation loss: 0.3198
2024-06-02 03:59:10 [INFO]: Epoch 078 - training loss: 0.0687, validation loss: 0.3201
2024-06-02 03:59:11 [INFO]: Epoch 079 - training loss: 0.0678, validation loss: 0.3226
2024-06-02 03:59:12 [INFO]: Epoch 080 - training loss: 0.0674, validation loss: 0.3187
2024-06-02 03:59:13 [INFO]: Epoch 081 - training loss: 0.0655, validation loss: 0.3232
2024-06-02 03:59:14 [INFO]: Epoch 082 - training loss: 0.0664, validation loss: 0.3230
2024-06-02 03:59:14 [INFO]: Epoch 083 - training loss: 0.0665, validation loss: 0.3280
2024-06-02 03:59:15 [INFO]: Epoch 084 - training loss: 0.0653, validation loss: 0.3227
2024-06-02 03:59:16 [INFO]: Epoch 085 - training loss: 0.0644, validation loss: 0.3214
2024-06-02 03:59:17 [INFO]: Epoch 086 - training loss: 0.0654, validation loss: 0.3240
2024-06-02 03:59:18 [INFO]: Epoch 087 - training loss: 0.0616, validation loss: 0.3218
2024-06-02 03:59:19 [INFO]: Epoch 088 - training loss: 0.0613, validation loss: 0.3251
2024-06-02 03:59:20 [INFO]: Epoch 089 - training loss: 0.0618, validation loss: 0.3186
2024-06-02 03:59:20 [INFO]: Epoch 090 - training loss: 0.0611, validation loss: 0.3230
2024-06-02 03:59:21 [INFO]: Epoch 091 - training loss: 0.0605, validation loss: 0.3259
2024-06-02 03:59:22 [INFO]: Epoch 092 - training loss: 0.0603, validation loss: 0.3237
2024-06-02 03:59:23 [INFO]: Epoch 093 - training loss: 0.0586, validation loss: 0.3263
2024-06-02 03:59:24 [INFO]: Epoch 094 - training loss: 0.0585, validation loss: 0.3279
2024-06-02 03:59:25 [INFO]: Epoch 095 - training loss: 0.0580, validation loss: 0.3232
2024-06-02 03:59:26 [INFO]: Epoch 096 - training loss: 0.0581, validation loss: 0.3246
2024-06-02 03:59:27 [INFO]: Epoch 097 - training loss: 0.0572, validation loss: 0.3278
2024-06-02 03:59:28 [INFO]: Epoch 098 - training loss: 0.0564, validation loss: 0.3264
2024-06-02 03:59:28 [INFO]: Epoch 099 - training loss: 0.0568, validation loss: 0.3266
2024-06-02 03:59:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:59:28 [INFO]: Finished training. The best model is from epoch#89.
2024-06-02 03:59:29 [INFO]: Saved the model to results_point_rate01/PeMS/TimesNet_PeMS/round_4/20240602_T035801/TimesNet.pypots
2024-06-02 03:59:29 [INFO]: Successfully saved to results_point_rate01/PeMS/TimesNet_PeMS/round_4/imputation.pkl
2024-06-02 03:59:29 [INFO]: Round4 - TimesNet on PeMS: MAE=0.3124, MSE=0.5026, MRE=0.3872
2024-06-02 03:59:29 [INFO]: Done! Final results:
Averaged TimesNet (n params: 91,622,238) on PeMS: MAE=0.3123 ± 0.0008510034337533709, MSE=0.5008 ± 0.0016718528201978941, MRE=0.3871 ± 0.0010549035426150174, average inference time=0.11
