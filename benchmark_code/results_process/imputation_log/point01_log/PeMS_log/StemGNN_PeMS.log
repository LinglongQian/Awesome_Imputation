2024-06-02 03:23:55 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 03:23:55 [INFO]: Using the given device: cuda:0
2024-06-02 03:23:56 [INFO]: Model files will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_0/20240602_T032356
2024-06-02 03:23:56 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_0/20240602_T032356/tensorboard
2024-06-02 03:23:56 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-02 03:24:04 [INFO]: Epoch 001 - training loss: 1.2094, validation loss: 1.0134
2024-06-02 03:24:05 [INFO]: Epoch 002 - training loss: 0.8617, validation loss: 0.8891
2024-06-02 03:24:07 [INFO]: Epoch 003 - training loss: 0.7971, validation loss: 0.9009
2024-06-02 03:24:09 [INFO]: Epoch 004 - training loss: 0.7721, validation loss: 0.8923
2024-06-02 03:24:12 [INFO]: Epoch 005 - training loss: 0.7593, validation loss: 0.8724
2024-06-02 03:24:14 [INFO]: Epoch 006 - training loss: 0.7289, validation loss: 0.8626
2024-06-02 03:24:16 [INFO]: Epoch 007 - training loss: 0.7065, validation loss: 0.8340
2024-06-02 03:24:19 [INFO]: Epoch 008 - training loss: 0.6747, validation loss: 0.8226
2024-06-02 03:24:21 [INFO]: Epoch 009 - training loss: 0.6545, validation loss: 0.8146
2024-06-02 03:24:23 [INFO]: Epoch 010 - training loss: 0.6342, validation loss: 0.8159
2024-06-02 03:24:25 [INFO]: Epoch 011 - training loss: 0.6238, validation loss: 0.8570
2024-06-02 03:24:28 [INFO]: Epoch 012 - training loss: 0.6268, validation loss: 0.8497
2024-06-02 03:24:30 [INFO]: Epoch 013 - training loss: 0.6150, validation loss: 0.8327
2024-06-02 03:24:32 [INFO]: Epoch 014 - training loss: 0.6071, validation loss: 0.7931
2024-06-02 03:24:35 [INFO]: Epoch 015 - training loss: 0.5947, validation loss: 0.7614
2024-06-02 03:24:37 [INFO]: Epoch 016 - training loss: 0.5925, validation loss: 0.7325
2024-06-02 03:24:40 [INFO]: Epoch 017 - training loss: 0.5883, validation loss: 0.7156
2024-06-02 03:24:42 [INFO]: Epoch 018 - training loss: 0.5894, validation loss: 0.7363
2024-06-02 03:24:44 [INFO]: Epoch 019 - training loss: 0.5864, validation loss: 0.7604
2024-06-02 03:24:47 [INFO]: Epoch 020 - training loss: 0.5823, validation loss: 0.7241
2024-06-02 03:24:49 [INFO]: Epoch 021 - training loss: 0.5857, validation loss: 0.8325
2024-06-02 03:24:51 [INFO]: Epoch 022 - training loss: 0.5820, validation loss: 0.8345
2024-06-02 03:24:54 [INFO]: Epoch 023 - training loss: 0.5882, validation loss: 0.7688
2024-06-02 03:24:56 [INFO]: Epoch 024 - training loss: 0.5877, validation loss: 0.7349
2024-06-02 03:24:58 [INFO]: Epoch 025 - training loss: 0.5819, validation loss: 0.8022
2024-06-02 03:25:01 [INFO]: Epoch 026 - training loss: 0.5930, validation loss: 0.8282
2024-06-02 03:25:03 [INFO]: Epoch 027 - training loss: 0.5857, validation loss: 0.8473
2024-06-02 03:25:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:25:03 [INFO]: Finished training. The best model is from epoch#17.
2024-06-02 03:25:03 [INFO]: Saved the model to results_point_rate01/PeMS/StemGNN_PeMS/round_0/20240602_T032356/StemGNN.pypots
2024-06-02 03:25:03 [INFO]: Successfully saved to results_point_rate01/PeMS/StemGNN_PeMS/round_0/imputation.pkl
2024-06-02 03:25:03 [INFO]: Round0 - StemGNN on PeMS: MAE=0.5257, MSE=1.1060, MRE=0.6516
2024-06-02 03:25:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 03:25:03 [INFO]: Using the given device: cuda:0
2024-06-02 03:25:03 [INFO]: Model files will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_1/20240602_T032503
2024-06-02 03:25:03 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_1/20240602_T032503/tensorboard
2024-06-02 03:25:03 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-02 03:25:06 [INFO]: Epoch 001 - training loss: 1.2193, validation loss: 0.9678
2024-06-02 03:25:08 [INFO]: Epoch 002 - training loss: 0.9097, validation loss: 0.9309
2024-06-02 03:25:11 [INFO]: Epoch 003 - training loss: 0.8342, validation loss: 0.8946
2024-06-02 03:25:13 [INFO]: Epoch 004 - training loss: 0.7873, validation loss: 0.8761
2024-06-02 03:25:15 [INFO]: Epoch 005 - training loss: 0.7399, validation loss: 0.8816
2024-06-02 03:25:18 [INFO]: Epoch 006 - training loss: 0.7122, validation loss: 0.8674
2024-06-02 03:25:20 [INFO]: Epoch 007 - training loss: 0.6888, validation loss: 0.8215
2024-06-02 03:25:22 [INFO]: Epoch 008 - training loss: 0.6489, validation loss: 0.7928
2024-06-02 03:25:25 [INFO]: Epoch 009 - training loss: 0.6212, validation loss: 0.7872
2024-06-02 03:25:27 [INFO]: Epoch 010 - training loss: 0.6065, validation loss: 0.7607
2024-06-02 03:25:29 [INFO]: Epoch 011 - training loss: 0.6066, validation loss: 0.7676
2024-06-02 03:25:32 [INFO]: Epoch 012 - training loss: 0.6022, validation loss: 0.7535
2024-06-02 03:25:34 [INFO]: Epoch 013 - training loss: 0.5903, validation loss: 0.7413
2024-06-02 03:25:37 [INFO]: Epoch 014 - training loss: 0.5943, validation loss: 0.7368
2024-06-02 03:25:39 [INFO]: Epoch 015 - training loss: 0.5912, validation loss: 0.7316
2024-06-02 03:25:41 [INFO]: Epoch 016 - training loss: 0.5930, validation loss: 0.7641
2024-06-02 03:25:44 [INFO]: Epoch 017 - training loss: 0.5910, validation loss: 0.7203
2024-06-02 03:25:46 [INFO]: Epoch 018 - training loss: 0.5867, validation loss: 0.7375
2024-06-02 03:25:48 [INFO]: Epoch 019 - training loss: 0.5794, validation loss: 0.7333
2024-06-02 03:25:50 [INFO]: Epoch 020 - training loss: 0.5827, validation loss: 0.7361
2024-06-02 03:25:53 [INFO]: Epoch 021 - training loss: 0.5776, validation loss: 0.7364
2024-06-02 03:25:55 [INFO]: Epoch 022 - training loss: 0.5683, validation loss: 0.7387
2024-06-02 03:25:57 [INFO]: Epoch 023 - training loss: 0.5623, validation loss: 0.7475
2024-06-02 03:26:00 [INFO]: Epoch 024 - training loss: 0.5517, validation loss: 0.7672
2024-06-02 03:26:02 [INFO]: Epoch 025 - training loss: 0.5458, validation loss: 0.7433
2024-06-02 03:26:05 [INFO]: Epoch 026 - training loss: 0.5456, validation loss: 0.7438
2024-06-02 03:26:07 [INFO]: Epoch 027 - training loss: 0.5375, validation loss: 0.7405
2024-06-02 03:26:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:26:07 [INFO]: Finished training. The best model is from epoch#17.
2024-06-02 03:26:07 [INFO]: Saved the model to results_point_rate01/PeMS/StemGNN_PeMS/round_1/20240602_T032503/StemGNN.pypots
2024-06-02 03:26:07 [INFO]: Successfully saved to results_point_rate01/PeMS/StemGNN_PeMS/round_1/imputation.pkl
2024-06-02 03:26:07 [INFO]: Round1 - StemGNN on PeMS: MAE=0.5028, MSE=1.0383, MRE=0.6233
2024-06-02 03:26:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 03:26:07 [INFO]: Using the given device: cuda:0
2024-06-02 03:26:07 [INFO]: Model files will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_2/20240602_T032607
2024-06-02 03:26:07 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_2/20240602_T032607/tensorboard
2024-06-02 03:26:07 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-02 03:26:10 [INFO]: Epoch 001 - training loss: 1.2335, validation loss: 0.9129
2024-06-02 03:26:12 [INFO]: Epoch 002 - training loss: 0.8893, validation loss: 0.9252
2024-06-02 03:26:14 [INFO]: Epoch 003 - training loss: 0.8560, validation loss: 0.9339
2024-06-02 03:26:17 [INFO]: Epoch 004 - training loss: 0.8463, validation loss: 0.9202
2024-06-02 03:26:19 [INFO]: Epoch 005 - training loss: 0.8336, validation loss: 0.9197
2024-06-02 03:26:21 [INFO]: Epoch 006 - training loss: 0.8248, validation loss: 0.9395
2024-06-02 03:26:24 [INFO]: Epoch 007 - training loss: 0.8210, validation loss: 0.9100
2024-06-02 03:26:26 [INFO]: Epoch 008 - training loss: 0.8075, validation loss: 0.9339
2024-06-02 03:26:28 [INFO]: Epoch 009 - training loss: 0.7972, validation loss: 0.8805
2024-06-02 03:26:31 [INFO]: Epoch 010 - training loss: 0.7587, validation loss: 0.8812
2024-06-02 03:26:33 [INFO]: Epoch 011 - training loss: 0.7738, validation loss: 0.8988
2024-06-02 03:26:36 [INFO]: Epoch 012 - training loss: 0.8658, validation loss: 0.9652
2024-06-02 03:26:38 [INFO]: Epoch 013 - training loss: 0.8512, validation loss: 0.9267
2024-06-02 03:26:40 [INFO]: Epoch 014 - training loss: 0.8255, validation loss: 0.9367
2024-06-02 03:26:43 [INFO]: Epoch 015 - training loss: 0.8146, validation loss: 0.9118
2024-06-02 03:26:45 [INFO]: Epoch 016 - training loss: 0.7966, validation loss: 0.9123
2024-06-02 03:26:47 [INFO]: Epoch 017 - training loss: 0.7854, validation loss: 0.8993
2024-06-02 03:26:50 [INFO]: Epoch 018 - training loss: 0.7814, validation loss: 0.8941
2024-06-02 03:26:52 [INFO]: Epoch 019 - training loss: 0.7721, validation loss: 0.8980
2024-06-02 03:26:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:26:52 [INFO]: Finished training. The best model is from epoch#9.
2024-06-02 03:26:52 [INFO]: Saved the model to results_point_rate01/PeMS/StemGNN_PeMS/round_2/20240602_T032607/StemGNN.pypots
2024-06-02 03:26:52 [INFO]: Successfully saved to results_point_rate01/PeMS/StemGNN_PeMS/round_2/imputation.pkl
2024-06-02 03:26:52 [INFO]: Round2 - StemGNN on PeMS: MAE=0.6139, MSE=1.1966, MRE=0.7610
2024-06-02 03:26:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 03:26:52 [INFO]: Using the given device: cuda:0
2024-06-02 03:26:52 [INFO]: Model files will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_3/20240602_T032652
2024-06-02 03:26:52 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_3/20240602_T032652/tensorboard
2024-06-02 03:26:52 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-02 03:26:55 [INFO]: Epoch 001 - training loss: 1.2753, validation loss: 0.9935
2024-06-02 03:26:57 [INFO]: Epoch 002 - training loss: 0.9516, validation loss: 0.8685
2024-06-02 03:27:00 [INFO]: Epoch 003 - training loss: 0.7894, validation loss: 0.8343
2024-06-02 03:27:02 [INFO]: Epoch 004 - training loss: 0.7086, validation loss: 0.7755
2024-06-02 03:27:04 [INFO]: Epoch 005 - training loss: 0.6459, validation loss: 0.7887
2024-06-02 03:27:06 [INFO]: Epoch 006 - training loss: 0.6067, validation loss: 0.7394
2024-06-02 03:27:09 [INFO]: Epoch 007 - training loss: 0.5724, validation loss: 0.6779
2024-06-02 03:27:11 [INFO]: Epoch 008 - training loss: 0.5454, validation loss: 0.6531
2024-06-02 03:27:13 [INFO]: Epoch 009 - training loss: 0.5301, validation loss: 0.6411
2024-06-02 03:27:16 [INFO]: Epoch 010 - training loss: 0.5112, validation loss: 0.6521
2024-06-02 03:27:18 [INFO]: Epoch 011 - training loss: 0.5134, validation loss: 0.6443
2024-06-02 03:27:20 [INFO]: Epoch 012 - training loss: 0.5064, validation loss: 0.6386
2024-06-02 03:27:23 [INFO]: Epoch 013 - training loss: 0.5014, validation loss: 0.6211
2024-06-02 03:27:25 [INFO]: Epoch 014 - training loss: 0.5155, validation loss: 0.6344
2024-06-02 03:27:27 [INFO]: Epoch 015 - training loss: 0.5042, validation loss: 0.6252
2024-06-02 03:27:30 [INFO]: Epoch 016 - training loss: 0.4931, validation loss: 0.6198
2024-06-02 03:27:32 [INFO]: Epoch 017 - training loss: 0.4871, validation loss: 0.6208
2024-06-02 03:27:34 [INFO]: Epoch 018 - training loss: 0.4843, validation loss: 0.6388
2024-06-02 03:27:37 [INFO]: Epoch 019 - training loss: 0.4814, validation loss: 0.6266
2024-06-02 03:27:39 [INFO]: Epoch 020 - training loss: 0.4760, validation loss: 0.6303
2024-06-02 03:27:41 [INFO]: Epoch 021 - training loss: 0.4703, validation loss: 0.6014
2024-06-02 03:27:44 [INFO]: Epoch 022 - training loss: 0.4633, validation loss: 0.6076
2024-06-02 03:27:46 [INFO]: Epoch 023 - training loss: 0.4599, validation loss: 0.6040
2024-06-02 03:27:48 [INFO]: Epoch 024 - training loss: 0.4570, validation loss: 0.5979
2024-06-02 03:27:50 [INFO]: Epoch 025 - training loss: 0.4496, validation loss: 0.5893
2024-06-02 03:27:53 [INFO]: Epoch 026 - training loss: 0.4452, validation loss: 0.5897
2024-06-02 03:27:55 [INFO]: Epoch 027 - training loss: 0.4447, validation loss: 0.6002
2024-06-02 03:27:57 [INFO]: Epoch 028 - training loss: 0.4436, validation loss: 0.6064
2024-06-02 03:28:00 [INFO]: Epoch 029 - training loss: 0.4398, validation loss: 0.6129
2024-06-02 03:28:02 [INFO]: Epoch 030 - training loss: 0.4293, validation loss: 0.6182
2024-06-02 03:28:04 [INFO]: Epoch 031 - training loss: 0.4336, validation loss: 0.6002
2024-06-02 03:28:07 [INFO]: Epoch 032 - training loss: 0.4231, validation loss: 0.5985
2024-06-02 03:28:09 [INFO]: Epoch 033 - training loss: 0.4225, validation loss: 0.6081
2024-06-02 03:28:12 [INFO]: Epoch 034 - training loss: 0.4257, validation loss: 0.5930
2024-06-02 03:28:14 [INFO]: Epoch 035 - training loss: 0.4203, validation loss: 0.6031
2024-06-02 03:28:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 03:28:14 [INFO]: Finished training. The best model is from epoch#25.
2024-06-02 03:28:14 [INFO]: Saved the model to results_point_rate01/PeMS/StemGNN_PeMS/round_3/20240602_T032652/StemGNN.pypots
2024-06-02 03:28:14 [INFO]: Successfully saved to results_point_rate01/PeMS/StemGNN_PeMS/round_3/imputation.pkl
2024-06-02 03:28:14 [INFO]: Round3 - StemGNN on PeMS: MAE=0.4399, MSE=0.8942, MRE=0.5453
2024-06-02 03:28:14 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 03:28:14 [INFO]: Using the given device: cuda:0
2024-06-02 03:28:14 [INFO]: Model files will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_4/20240602_T032814
2024-06-02 03:28:14 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/StemGNN_PeMS/round_4/20240602_T032814/tensorboard
2024-06-02 03:28:14 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-02 03:28:17 [INFO]: Epoch 001 - training loss: 1.1746, validation loss: 0.9560
2024-06-02 03:28:19 [INFO]: Epoch 002 - training loss: 0.8923, validation loss: 0.8939
2024-06-02 03:28:21 [INFO]: Epoch 003 - training loss: 0.8125, validation loss: 0.8811
2024-06-02 03:28:23 [INFO]: Epoch 004 - training loss: 0.7099, validation loss: 0.8216
2024-06-02 03:28:26 [INFO]: Epoch 005 - training loss: 0.6319, validation loss: 0.7613
2024-06-02 03:28:28 [INFO]: Epoch 006 - training loss: 0.5808, validation loss: 0.7235
2024-06-02 03:28:30 [INFO]: Epoch 007 - training loss: 0.5544, validation loss: 0.6953
2024-06-02 03:28:33 [INFO]: Epoch 008 - training loss: 0.5370, validation loss: 0.6785
2024-06-02 03:28:35 [INFO]: Epoch 009 - training loss: 0.5208, validation loss: 0.6572
2024-06-02 03:28:37 [INFO]: Epoch 010 - training loss: 0.5083, validation loss: 0.6341
2024-06-02 03:28:40 [INFO]: Epoch 011 - training loss: 0.4948, validation loss: 0.6366
2024-06-02 03:28:42 [INFO]: Epoch 012 - training loss: 0.4879, validation loss: 0.6246
2024-06-02 03:28:45 [INFO]: Epoch 013 - training loss: 0.4745, validation loss: 0.6183
2024-06-02 03:28:47 [INFO]: Epoch 014 - training loss: 0.4670, validation loss: 0.6041
2024-06-02 03:28:49 [INFO]: Epoch 015 - training loss: 0.4591, validation loss: 0.5971
2024-06-02 03:28:51 [INFO]: Epoch 016 - training loss: 0.4493, validation loss: 0.5859
2024-06-02 03:28:54 [INFO]: Epoch 017 - training loss: 0.4418, validation loss: 0.5739
2024-06-02 03:28:56 [INFO]: Epoch 018 - training loss: 0.4371, validation loss: 0.5719
2024-06-02 03:28:59 [INFO]: Epoch 019 - training loss: 0.4346, validation loss: 0.5772
2024-06-02 03:29:01 [INFO]: Epoch 020 - training loss: 0.4291, validation loss: 0.5772
2024-06-02 03:29:03 [INFO]: Epoch 021 - training loss: 0.4235, validation loss: 0.5743
2024-06-02 03:29:06 [INFO]: Epoch 022 - training loss: 0.4189, validation loss: 0.5643
2024-06-02 03:29:08 [INFO]: Epoch 023 - training loss: 0.4158, validation loss: 0.5666
2024-06-02 03:29:11 [INFO]: Epoch 024 - training loss: 0.4094, validation loss: 0.5732
2024-06-02 03:29:13 [INFO]: Epoch 025 - training loss: 0.4037, validation loss: 0.5572
2024-06-02 03:29:15 [INFO]: Epoch 026 - training loss: 0.4051, validation loss: 0.5585
2024-06-02 03:29:18 [INFO]: Epoch 027 - training loss: 0.3965, validation loss: 0.5589
2024-06-02 03:29:20 [INFO]: Epoch 028 - training loss: 0.4008, validation loss: 0.5553
2024-06-02 03:29:22 [INFO]: Epoch 029 - training loss: 0.3963, validation loss: 0.5536
2024-06-02 03:29:25 [INFO]: Epoch 030 - training loss: 0.3944, validation loss: 0.5334
2024-06-02 03:29:27 [INFO]: Epoch 031 - training loss: 0.3915, validation loss: 0.5438
2024-06-02 03:29:29 [INFO]: Epoch 032 - training loss: 0.3839, validation loss: 0.5437
2024-06-02 03:29:32 [INFO]: Epoch 033 - training loss: 0.3827, validation loss: 0.5344
2024-06-02 03:29:34 [INFO]: Epoch 034 - training loss: 0.3857, validation loss: 0.5459
2024-06-02 03:29:36 [INFO]: Epoch 035 - training loss: 0.3782, validation loss: 0.5267
2024-06-02 03:29:39 [INFO]: Epoch 036 - training loss: 0.3834, validation loss: 0.5354
2024-06-02 03:29:41 [INFO]: Epoch 037 - training loss: 0.3762, validation loss: 0.5349
2024-06-02 03:29:43 [INFO]: Epoch 038 - training loss: 0.3731, validation loss: 0.5312
2024-06-02 03:29:46 [INFO]: Epoch 039 - training loss: 0.3713, validation loss: 0.5171
2024-06-02 03:29:48 [INFO]: Epoch 040 - training loss: 0.3689, validation loss: 0.5213
2024-06-02 03:29:50 [INFO]: Epoch 041 - training loss: 0.3647, validation loss: 0.5347
2024-06-02 03:29:53 [INFO]: Epoch 042 - training loss: 0.3672, validation loss: 0.5337
2024-06-02 03:29:55 [INFO]: Epoch 043 - training loss: 0.3638, validation loss: 0.5158
2024-06-02 03:29:57 [INFO]: Epoch 044 - training loss: 0.3597, validation loss: 0.5039
2024-06-02 03:30:00 [INFO]: Epoch 045 - training loss: 0.3636, validation loss: 0.5235
2024-06-02 03:30:02 [INFO]: Epoch 046 - training loss: 0.3585, validation loss: 0.5133
2024-06-02 03:30:04 [INFO]: Epoch 047 - training loss: 0.3561, validation loss: 0.5124
2024-06-02 03:30:07 [INFO]: Epoch 048 - training loss: 0.3575, validation loss: 0.5029
2024-06-02 03:30:09 [INFO]: Epoch 049 - training loss: 0.3576, validation loss: 0.5159
2024-06-02 03:30:11 [INFO]: Epoch 050 - training loss: 0.3500, validation loss: 0.5065
2024-06-02 03:30:14 [INFO]: Epoch 051 - training loss: 0.3503, validation loss: 0.5115
2024-06-02 03:30:16 [INFO]: Epoch 052 - training loss: 0.3548, validation loss: 0.4988
2024-06-02 03:30:18 [INFO]: Epoch 053 - training loss: 0.3554, validation loss: 0.4946
2024-06-02 03:30:21 [INFO]: Epoch 054 - training loss: 0.3529, validation loss: 0.5100
2024-06-02 03:30:23 [INFO]: Epoch 055 - training loss: 0.3505, validation loss: 0.5031
2024-06-02 03:30:26 [INFO]: Epoch 056 - training loss: 0.3440, validation loss: 0.4968
2024-06-02 03:30:28 [INFO]: Epoch 057 - training loss: 0.3429, validation loss: 0.4949
2024-06-02 03:30:30 [INFO]: Epoch 058 - training loss: 0.3412, validation loss: 0.4995
2024-06-02 03:30:33 [INFO]: Epoch 059 - training loss: 0.3448, validation loss: 0.4970
2024-06-02 03:30:35 [INFO]: Epoch 060 - training loss: 0.3393, validation loss: 0.4957
2024-06-02 03:30:37 [INFO]: Epoch 061 - training loss: 0.3375, validation loss: 0.4885
2024-06-02 03:30:40 [INFO]: Epoch 062 - training loss: 0.3384, validation loss: 0.4975
2024-06-02 03:30:42 [INFO]: Epoch 063 - training loss: 0.3412, validation loss: 0.4915
2024-06-02 03:30:44 [INFO]: Epoch 064 - training loss: 0.3363, validation loss: 0.4933
2024-06-02 03:30:47 [INFO]: Epoch 065 - training loss: 0.3357, validation loss: 0.4926
2024-06-02 03:30:49 [INFO]: Epoch 066 - training loss: 0.3367, validation loss: 0.4957
2024-06-02 03:30:51 [INFO]: Epoch 067 - training loss: 0.3340, validation loss: 0.4861
2024-06-02 03:30:54 [INFO]: Epoch 068 - training loss: 0.3297, validation loss: 0.5036
2024-06-02 03:30:56 [INFO]: Epoch 069 - training loss: 0.3344, validation loss: 0.4892
2024-06-02 03:30:58 [INFO]: Epoch 070 - training loss: 0.3344, validation loss: 0.4917
2024-06-02 03:31:01 [INFO]: Epoch 071 - training loss: 0.3303, validation loss: 0.4907
2024-06-02 03:31:03 [INFO]: Epoch 072 - training loss: 0.3278, validation loss: 0.4866
2024-06-02 03:31:05 [INFO]: Epoch 073 - training loss: 0.3279, validation loss: 0.4887
2024-06-02 03:31:07 [INFO]: Epoch 074 - training loss: 0.3274, validation loss: 0.4902
2024-06-02 03:31:10 [INFO]: Epoch 075 - training loss: 0.3264, validation loss: 0.4929
2024-06-02 03:31:12 [INFO]: Epoch 076 - training loss: 0.3278, validation loss: 0.4832
2024-06-02 03:31:14 [INFO]: Epoch 077 - training loss: 0.3268, validation loss: 0.4890
2024-06-02 03:31:17 [INFO]: Epoch 078 - training loss: 0.3227, validation loss: 0.4851
2024-06-02 03:31:19 [INFO]: Epoch 079 - training loss: 0.3227, validation loss: 0.4807
2024-06-02 03:31:21 [INFO]: Epoch 080 - training loss: 0.3204, validation loss: 0.4906
2024-06-02 03:31:24 [INFO]: Epoch 081 - training loss: 0.3226, validation loss: 0.4878
2024-06-02 03:31:26 [INFO]: Epoch 082 - training loss: 0.3210, validation loss: 0.4797
2024-06-02 03:31:29 [INFO]: Epoch 083 - training loss: 0.3204, validation loss: 0.4796
2024-06-02 03:31:31 [INFO]: Epoch 084 - training loss: 0.3198, validation loss: 0.4764
2024-06-02 03:31:33 [INFO]: Epoch 085 - training loss: 0.3221, validation loss: 0.4805
2024-06-02 03:31:36 [INFO]: Epoch 086 - training loss: 0.3200, validation loss: 0.4848
2024-06-02 03:31:38 [INFO]: Epoch 087 - training loss: 0.3182, validation loss: 0.4817
2024-06-02 03:31:41 [INFO]: Epoch 088 - training loss: 0.3174, validation loss: 0.4835
2024-06-02 03:31:43 [INFO]: Epoch 089 - training loss: 0.3175, validation loss: 0.4756
2024-06-02 03:31:45 [INFO]: Epoch 090 - training loss: 0.3171, validation loss: 0.4784
2024-06-02 03:31:47 [INFO]: Epoch 091 - training loss: 0.3133, validation loss: 0.4850
2024-06-02 03:31:50 [INFO]: Epoch 092 - training loss: 0.3168, validation loss: 0.4846
2024-06-02 03:31:52 [INFO]: Epoch 093 - training loss: 0.3130, validation loss: 0.4752
2024-06-02 03:31:54 [INFO]: Epoch 094 - training loss: 0.3126, validation loss: 0.4741
2024-06-02 03:31:57 [INFO]: Epoch 095 - training loss: 0.3140, validation loss: 0.4783
2024-06-02 03:31:59 [INFO]: Epoch 096 - training loss: 0.3112, validation loss: 0.4825
2024-06-02 03:32:01 [INFO]: Epoch 097 - training loss: 0.3101, validation loss: 0.4736
2024-06-02 03:32:04 [INFO]: Epoch 098 - training loss: 0.3123, validation loss: 0.4775
2024-06-02 03:32:06 [INFO]: Epoch 099 - training loss: 0.3120, validation loss: 0.4783
2024-06-02 03:32:08 [INFO]: Epoch 100 - training loss: 0.3092, validation loss: 0.4708
2024-06-02 03:32:08 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 03:32:09 [INFO]: Saved the model to results_point_rate01/PeMS/StemGNN_PeMS/round_4/20240602_T032814/StemGNN.pypots
2024-06-02 03:32:09 [INFO]: Successfully saved to results_point_rate01/PeMS/StemGNN_PeMS/round_4/imputation.pkl
2024-06-02 03:32:09 [INFO]: Round4 - StemGNN on PeMS: MAE=0.3823, MSE=0.7195, MRE=0.4740
2024-06-02 03:32:09 [INFO]: Done! Final results:
Averaged StemGNN (n params: 2,386,294) on PeMS: MAE=0.4929 ± 0.07853583726135466, MSE=0.9909 ± 0.16782177052286443, MRE=0.6110 ± 0.09735299490371815, average inference time=0.21
