2024-06-01 21:52:20 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:52:20 [INFO]: Using the given device: cuda:0
2024-06-01 21:52:20 [INFO]: Model files will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_0/20240601_T215220
2024-06-01 21:52:20 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_0/20240601_T215220/tensorboard
2024-06-01 21:52:21 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-01 21:52:25 [INFO]: Epoch 001 - training loss: 1.6914, validation loss: 1.4452
2024-06-01 21:52:28 [INFO]: Epoch 002 - training loss: 1.5884, validation loss: 1.3765
2024-06-01 21:52:32 [INFO]: Epoch 003 - training loss: 1.5356, validation loss: 1.3339
2024-06-01 21:52:37 [INFO]: Epoch 004 - training loss: 1.4972, validation loss: 1.3265
2024-06-01 21:52:41 [INFO]: Epoch 005 - training loss: 1.4702, validation loss: 1.2947
2024-06-01 21:52:45 [INFO]: Epoch 006 - training loss: 1.4484, validation loss: 1.2752
2024-06-01 21:52:50 [INFO]: Epoch 007 - training loss: 1.4162, validation loss: 1.2596
2024-06-01 21:52:54 [INFO]: Epoch 008 - training loss: 1.3664, validation loss: 1.2100
2024-06-01 21:52:59 [INFO]: Epoch 009 - training loss: 1.2579, validation loss: 1.1554
2024-06-01 21:53:03 [INFO]: Epoch 010 - training loss: 1.1155, validation loss: 1.0690
2024-06-01 21:53:07 [INFO]: Epoch 011 - training loss: 1.0059, validation loss: 1.0094
2024-06-01 21:53:11 [INFO]: Epoch 012 - training loss: 0.9420, validation loss: 0.9687
2024-06-01 21:53:15 [INFO]: Epoch 013 - training loss: 0.9057, validation loss: 0.9150
2024-06-01 21:53:18 [INFO]: Epoch 014 - training loss: 0.8869, validation loss: 0.9068
2024-06-01 21:53:23 [INFO]: Epoch 015 - training loss: 0.8668, validation loss: 0.8989
2024-06-01 21:53:27 [INFO]: Epoch 016 - training loss: 0.8467, validation loss: 0.8693
2024-06-01 21:53:31 [INFO]: Epoch 017 - training loss: 0.8354, validation loss: 0.8637
2024-06-01 21:53:35 [INFO]: Epoch 018 - training loss: 0.8294, validation loss: 0.8542
2024-06-01 21:53:39 [INFO]: Epoch 019 - training loss: 0.8259, validation loss: 0.8414
2024-06-01 21:53:44 [INFO]: Epoch 020 - training loss: 0.8240, validation loss: 0.8296
2024-06-01 21:53:48 [INFO]: Epoch 021 - training loss: 0.8238, validation loss: 0.8356
2024-06-01 21:53:52 [INFO]: Epoch 022 - training loss: 0.8143, validation loss: 0.8392
2024-06-01 21:53:56 [INFO]: Epoch 023 - training loss: 0.8126, validation loss: 0.8283
2024-06-01 21:54:00 [INFO]: Epoch 024 - training loss: 0.8155, validation loss: 0.8286
2024-06-01 21:54:03 [INFO]: Epoch 025 - training loss: 0.8128, validation loss: 0.8234
2024-06-01 21:54:07 [INFO]: Epoch 026 - training loss: 0.8091, validation loss: 0.8158
2024-06-01 21:54:12 [INFO]: Epoch 027 - training loss: 0.8103, validation loss: 0.8111
2024-06-01 21:54:16 [INFO]: Epoch 028 - training loss: 0.8049, validation loss: 0.8100
2024-06-01 21:54:20 [INFO]: Epoch 029 - training loss: 0.8043, validation loss: 0.8105
2024-06-01 21:54:25 [INFO]: Epoch 030 - training loss: 0.8020, validation loss: 0.8011
2024-06-01 21:54:29 [INFO]: Epoch 031 - training loss: 0.8026, validation loss: 0.8095
2024-06-01 21:54:34 [INFO]: Epoch 032 - training loss: 0.7958, validation loss: 0.8168
2024-06-01 21:54:38 [INFO]: Epoch 033 - training loss: 0.7975, validation loss: 0.8137
2024-06-01 21:54:42 [INFO]: Epoch 034 - training loss: 0.8019, validation loss: 0.8014
2024-06-01 21:54:46 [INFO]: Epoch 035 - training loss: 0.7978, validation loss: 0.8096
2024-06-01 21:54:49 [INFO]: Epoch 036 - training loss: 0.7972, validation loss: 0.8067
2024-06-01 21:54:53 [INFO]: Epoch 037 - training loss: 0.7938, validation loss: 0.8059
2024-06-01 21:54:58 [INFO]: Epoch 038 - training loss: 0.7926, validation loss: 0.7989
2024-06-01 21:55:02 [INFO]: Epoch 039 - training loss: 0.7889, validation loss: 0.8022
2024-06-01 21:55:07 [INFO]: Epoch 040 - training loss: 0.7871, validation loss: 0.8022
2024-06-01 21:55:11 [INFO]: Epoch 041 - training loss: 0.7923, validation loss: 0.8007
2024-06-01 21:55:16 [INFO]: Epoch 042 - training loss: 0.7876, validation loss: 0.7930
2024-06-01 21:55:20 [INFO]: Epoch 043 - training loss: 0.7947, validation loss: 0.8139
2024-06-01 21:55:24 [INFO]: Epoch 044 - training loss: 0.7922, validation loss: 0.8042
2024-06-01 21:55:29 [INFO]: Epoch 045 - training loss: 0.7833, validation loss: 0.7993
2024-06-01 21:55:32 [INFO]: Epoch 046 - training loss: 0.7828, validation loss: 0.7989
2024-06-01 21:55:35 [INFO]: Epoch 047 - training loss: 0.7854, validation loss: 0.8168
2024-06-01 21:55:39 [INFO]: Epoch 048 - training loss: 0.7828, validation loss: 0.7933
2024-06-01 21:55:44 [INFO]: Epoch 049 - training loss: 0.7861, validation loss: 0.7994
2024-06-01 21:55:48 [INFO]: Epoch 050 - training loss: 0.7784, validation loss: 0.7997
2024-06-01 21:55:52 [INFO]: Epoch 051 - training loss: 0.7853, validation loss: 0.7926
2024-06-01 21:55:57 [INFO]: Epoch 052 - training loss: 0.7830, validation loss: 0.8023
2024-06-01 21:56:01 [INFO]: Epoch 053 - training loss: 0.7807, validation loss: 0.7967
2024-06-01 21:56:05 [INFO]: Epoch 054 - training loss: 0.7823, validation loss: 0.7964
2024-06-01 21:56:09 [INFO]: Epoch 055 - training loss: 0.7768, validation loss: 0.7965
2024-06-01 21:56:14 [INFO]: Epoch 056 - training loss: 0.7810, validation loss: 0.7940
2024-06-01 21:56:17 [INFO]: Epoch 057 - training loss: 0.7774, validation loss: 0.8053
2024-06-01 21:56:21 [INFO]: Epoch 058 - training loss: 0.7814, validation loss: 0.8004
2024-06-01 21:56:25 [INFO]: Epoch 059 - training loss: 0.7720, validation loss: 0.7946
2024-06-01 21:56:29 [INFO]: Epoch 060 - training loss: 0.7774, validation loss: 0.8072
2024-06-01 21:56:33 [INFO]: Epoch 061 - training loss: 0.7806, validation loss: 0.7936
2024-06-01 21:56:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:56:33 [INFO]: Finished training. The best model is from epoch#51.
2024-06-01 21:56:34 [INFO]: Saved the model to results_point_rate01/PeMS/Autoformer_PeMS/round_0/20240601_T215220/Autoformer.pypots
2024-06-01 21:56:34 [INFO]: Successfully saved to results_point_rate01/PeMS/Autoformer_PeMS/round_0/imputation.pkl
2024-06-01 21:56:34 [INFO]: Round0 - Autoformer on PeMS: MAE=0.5303, MSE=1.0572, MRE=0.6573
2024-06-01 21:56:34 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 21:56:34 [INFO]: Using the given device: cuda:0
2024-06-01 21:56:34 [INFO]: Model files will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_1/20240601_T215634
2024-06-01 21:56:34 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_1/20240601_T215634/tensorboard
2024-06-01 21:56:34 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-01 21:56:38 [INFO]: Epoch 001 - training loss: 1.6955, validation loss: 1.4495
2024-06-01 21:56:43 [INFO]: Epoch 002 - training loss: 1.5893, validation loss: 1.3742
2024-06-01 21:56:47 [INFO]: Epoch 003 - training loss: 1.5334, validation loss: 1.3200
2024-06-01 21:56:52 [INFO]: Epoch 004 - training loss: 1.4898, validation loss: 1.2911
2024-06-01 21:56:56 [INFO]: Epoch 005 - training loss: 1.4782, validation loss: 1.2848
2024-06-01 21:57:00 [INFO]: Epoch 006 - training loss: 1.4588, validation loss: 1.2809
2024-06-01 21:57:04 [INFO]: Epoch 007 - training loss: 1.4546, validation loss: 1.2827
2024-06-01 21:57:07 [INFO]: Epoch 008 - training loss: 1.4504, validation loss: 1.2785
2024-06-01 21:57:11 [INFO]: Epoch 009 - training loss: 1.4269, validation loss: 1.2651
2024-06-01 21:57:15 [INFO]: Epoch 010 - training loss: 1.4062, validation loss: 1.2508
2024-06-01 21:57:20 [INFO]: Epoch 011 - training loss: 1.3770, validation loss: 1.2430
2024-06-01 21:57:24 [INFO]: Epoch 012 - training loss: 1.3340, validation loss: 1.2416
2024-06-01 21:57:29 [INFO]: Epoch 013 - training loss: 1.2540, validation loss: 1.1821
2024-06-01 21:57:33 [INFO]: Epoch 014 - training loss: 1.1469, validation loss: 1.3280
2024-06-01 21:57:37 [INFO]: Epoch 015 - training loss: 1.1904, validation loss: 1.2106
2024-06-01 21:57:42 [INFO]: Epoch 016 - training loss: 1.0810, validation loss: 1.2121
2024-06-01 21:57:46 [INFO]: Epoch 017 - training loss: 1.0365, validation loss: 1.2256
2024-06-01 21:57:50 [INFO]: Epoch 018 - training loss: 1.0216, validation loss: 1.2373
2024-06-01 21:57:54 [INFO]: Epoch 019 - training loss: 1.0202, validation loss: 1.2301
2024-06-01 21:57:58 [INFO]: Epoch 020 - training loss: 1.0073, validation loss: 1.2353
2024-06-01 21:58:02 [INFO]: Epoch 021 - training loss: 1.0029, validation loss: 1.2293
2024-06-01 21:58:07 [INFO]: Epoch 022 - training loss: 1.0020, validation loss: 1.2322
2024-06-01 21:58:11 [INFO]: Epoch 023 - training loss: 0.9923, validation loss: 1.2313
2024-06-01 21:58:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 21:58:11 [INFO]: Finished training. The best model is from epoch#13.
2024-06-01 21:58:11 [INFO]: Saved the model to results_point_rate01/PeMS/Autoformer_PeMS/round_1/20240601_T215634/Autoformer.pypots
2024-06-01 21:58:11 [INFO]: Successfully saved to results_point_rate01/PeMS/Autoformer_PeMS/round_1/imputation.pkl
2024-06-01 21:58:11 [INFO]: Round1 - Autoformer on PeMS: MAE=0.7008, MSE=1.5198, MRE=0.8687
2024-06-01 21:58:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 21:58:11 [INFO]: Using the given device: cuda:0
2024-06-01 21:58:11 [INFO]: Model files will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_2/20240601_T215811
2024-06-01 21:58:11 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_2/20240601_T215811/tensorboard
2024-06-01 21:58:11 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-01 21:58:15 [INFO]: Epoch 001 - training loss: 1.6882, validation loss: 1.4314
2024-06-01 21:58:19 [INFO]: Epoch 002 - training loss: 1.5761, validation loss: 1.3447
2024-06-01 21:58:24 [INFO]: Epoch 003 - training loss: 1.5047, validation loss: 1.3020
2024-06-01 21:58:28 [INFO]: Epoch 004 - training loss: 1.4814, validation loss: 1.2792
2024-06-01 21:58:32 [INFO]: Epoch 005 - training loss: 1.4609, validation loss: 1.2630
2024-06-01 21:58:36 [INFO]: Epoch 006 - training loss: 1.4211, validation loss: 1.2582
2024-06-01 21:58:40 [INFO]: Epoch 007 - training loss: 1.3505, validation loss: 1.2021
2024-06-01 21:58:43 [INFO]: Epoch 008 - training loss: 1.2356, validation loss: 1.1538
2024-06-01 21:58:48 [INFO]: Epoch 009 - training loss: 1.1232, validation loss: 1.0947
2024-06-01 21:58:52 [INFO]: Epoch 010 - training loss: 1.0309, validation loss: 1.0280
2024-06-01 21:58:56 [INFO]: Epoch 011 - training loss: 0.9640, validation loss: 0.9458
2024-06-01 21:59:00 [INFO]: Epoch 012 - training loss: 0.9233, validation loss: 0.9275
2024-06-01 21:59:05 [INFO]: Epoch 013 - training loss: 0.8862, validation loss: 0.8805
2024-06-01 21:59:09 [INFO]: Epoch 014 - training loss: 0.8654, validation loss: 0.8690
2024-06-01 21:59:14 [INFO]: Epoch 015 - training loss: 0.8522, validation loss: 0.8658
2024-06-01 21:59:18 [INFO]: Epoch 016 - training loss: 0.8473, validation loss: 0.8595
2024-06-01 21:59:22 [INFO]: Epoch 017 - training loss: 0.8358, validation loss: 0.8699
2024-06-01 21:59:26 [INFO]: Epoch 018 - training loss: 0.8261, validation loss: 0.8662
2024-06-01 21:59:29 [INFO]: Epoch 019 - training loss: 0.8321, validation loss: 0.8415
2024-06-01 21:59:33 [INFO]: Epoch 020 - training loss: 0.8242, validation loss: 0.8442
2024-06-01 21:59:38 [INFO]: Epoch 021 - training loss: 0.8225, validation loss: 0.8455
2024-06-01 21:59:42 [INFO]: Epoch 022 - training loss: 0.8128, validation loss: 0.8574
2024-06-01 21:59:46 [INFO]: Epoch 023 - training loss: 0.8124, validation loss: 0.8291
2024-06-01 21:59:50 [INFO]: Epoch 024 - training loss: 0.8040, validation loss: 0.8628
2024-06-01 21:59:54 [INFO]: Epoch 025 - training loss: 0.8120, validation loss: 0.8475
2024-06-01 21:59:58 [INFO]: Epoch 026 - training loss: 0.8005, validation loss: 0.8441
2024-06-01 22:00:02 [INFO]: Epoch 027 - training loss: 0.8048, validation loss: 0.8421
2024-06-01 22:00:06 [INFO]: Epoch 028 - training loss: 0.8028, validation loss: 0.8349
2024-06-01 22:00:10 [INFO]: Epoch 029 - training loss: 0.7975, validation loss: 0.8160
2024-06-01 22:00:14 [INFO]: Epoch 030 - training loss: 0.7995, validation loss: 0.8287
2024-06-01 22:00:18 [INFO]: Epoch 031 - training loss: 0.7959, validation loss: 0.8477
2024-06-01 22:00:22 [INFO]: Epoch 032 - training loss: 0.7994, validation loss: 0.8249
2024-06-01 22:00:26 [INFO]: Epoch 033 - training loss: 0.7945, validation loss: 0.8385
2024-06-01 22:00:31 [INFO]: Epoch 034 - training loss: 0.7969, validation loss: 0.8260
2024-06-01 22:00:35 [INFO]: Epoch 035 - training loss: 0.7995, validation loss: 0.8213
2024-06-01 22:00:39 [INFO]: Epoch 036 - training loss: 0.7927, validation loss: 0.8320
2024-06-01 22:00:43 [INFO]: Epoch 037 - training loss: 0.7928, validation loss: 0.8497
2024-06-01 22:00:47 [INFO]: Epoch 038 - training loss: 0.7887, validation loss: 0.8319
2024-06-01 22:00:51 [INFO]: Epoch 039 - training loss: 0.7856, validation loss: 0.8443
2024-06-01 22:00:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:00:51 [INFO]: Finished training. The best model is from epoch#29.
2024-06-01 22:00:51 [INFO]: Saved the model to results_point_rate01/PeMS/Autoformer_PeMS/round_2/20240601_T215811/Autoformer.pypots
2024-06-01 22:00:52 [INFO]: Successfully saved to results_point_rate01/PeMS/Autoformer_PeMS/round_2/imputation.pkl
2024-06-01 22:00:52 [INFO]: Round2 - Autoformer on PeMS: MAE=0.5839, MSE=1.1257, MRE=0.7238
2024-06-01 22:00:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 22:00:52 [INFO]: Using the given device: cuda:0
2024-06-01 22:00:52 [INFO]: Model files will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_3/20240601_T220052
2024-06-01 22:00:52 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_3/20240601_T220052/tensorboard
2024-06-01 22:00:52 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-01 22:00:56 [INFO]: Epoch 001 - training loss: 1.7060, validation loss: 1.4634
2024-06-01 22:00:59 [INFO]: Epoch 002 - training loss: 1.5936, validation loss: 1.3813
2024-06-01 22:01:03 [INFO]: Epoch 003 - training loss: 1.5284, validation loss: 1.3300
2024-06-01 22:01:07 [INFO]: Epoch 004 - training loss: 1.4850, validation loss: 1.3032
2024-06-01 22:01:12 [INFO]: Epoch 005 - training loss: 1.4612, validation loss: 1.2893
2024-06-01 22:01:16 [INFO]: Epoch 006 - training loss: 1.4541, validation loss: 1.2809
2024-06-01 22:01:20 [INFO]: Epoch 007 - training loss: 1.4220, validation loss: 1.2799
2024-06-01 22:01:24 [INFO]: Epoch 008 - training loss: 1.3964, validation loss: 1.2690
2024-06-01 22:01:29 [INFO]: Epoch 009 - training loss: 1.3886, validation loss: 1.2799
2024-06-01 22:01:33 [INFO]: Epoch 010 - training loss: 1.3559, validation loss: 1.2679
2024-06-01 22:01:37 [INFO]: Epoch 011 - training loss: 1.3211, validation loss: 1.2851
2024-06-01 22:01:41 [INFO]: Epoch 012 - training loss: 1.3005, validation loss: 1.2924
2024-06-01 22:01:45 [INFO]: Epoch 013 - training loss: 1.2778, validation loss: 1.2743
2024-06-01 22:01:48 [INFO]: Epoch 014 - training loss: 1.2435, validation loss: 1.2149
2024-06-01 22:01:53 [INFO]: Epoch 015 - training loss: 1.2216, validation loss: 1.1973
2024-06-01 22:01:57 [INFO]: Epoch 016 - training loss: 1.1867, validation loss: 1.1706
2024-06-01 22:02:01 [INFO]: Epoch 017 - training loss: 1.1646, validation loss: 1.1723
2024-06-01 22:02:06 [INFO]: Epoch 018 - training loss: 1.1469, validation loss: 1.1629
2024-06-01 22:02:10 [INFO]: Epoch 019 - training loss: 1.1251, validation loss: 1.1535
2024-06-01 22:02:14 [INFO]: Epoch 020 - training loss: 1.1163, validation loss: 1.1536
2024-06-01 22:02:18 [INFO]: Epoch 021 - training loss: 1.1064, validation loss: 1.1478
2024-06-01 22:02:23 [INFO]: Epoch 022 - training loss: 1.1020, validation loss: 1.1492
2024-06-01 22:02:27 [INFO]: Epoch 023 - training loss: 1.0885, validation loss: 1.1319
2024-06-01 22:02:30 [INFO]: Epoch 024 - training loss: 1.0827, validation loss: 1.1487
2024-06-01 22:02:34 [INFO]: Epoch 025 - training loss: 1.0795, validation loss: 1.1429
2024-06-01 22:02:38 [INFO]: Epoch 026 - training loss: 1.0661, validation loss: 1.1455
2024-06-01 22:02:42 [INFO]: Epoch 027 - training loss: 1.0602, validation loss: 1.1352
2024-06-01 22:02:47 [INFO]: Epoch 028 - training loss: 1.0569, validation loss: 1.1516
2024-06-01 22:02:51 [INFO]: Epoch 029 - training loss: 1.0499, validation loss: 1.1319
2024-06-01 22:02:56 [INFO]: Epoch 030 - training loss: 1.0490, validation loss: 1.1446
2024-06-01 22:03:00 [INFO]: Epoch 031 - training loss: 1.0442, validation loss: 1.1364
2024-06-01 22:03:04 [INFO]: Epoch 032 - training loss: 1.0399, validation loss: 1.1381
2024-06-01 22:03:09 [INFO]: Epoch 033 - training loss: 1.0349, validation loss: 1.1442
2024-06-01 22:03:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:03:09 [INFO]: Finished training. The best model is from epoch#23.
2024-06-01 22:03:09 [INFO]: Saved the model to results_point_rate01/PeMS/Autoformer_PeMS/round_3/20240601_T220052/Autoformer.pypots
2024-06-01 22:03:09 [INFO]: Successfully saved to results_point_rate01/PeMS/Autoformer_PeMS/round_3/imputation.pkl
2024-06-01 22:03:09 [INFO]: Round3 - Autoformer on PeMS: MAE=0.6645, MSE=1.4147, MRE=0.8237
2024-06-01 22:03:09 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-01 22:03:09 [INFO]: Using the given device: cuda:0
2024-06-01 22:03:09 [INFO]: Model files will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_4/20240601_T220309
2024-06-01 22:03:09 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Autoformer_PeMS/round_4/20240601_T220309/tensorboard
2024-06-01 22:03:09 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-01 22:03:13 [INFO]: Epoch 001 - training loss: 1.7047, validation loss: 1.4458
2024-06-01 22:03:17 [INFO]: Epoch 002 - training loss: 1.5744, validation loss: 1.3486
2024-06-01 22:03:21 [INFO]: Epoch 003 - training loss: 1.5208, validation loss: 1.3067
2024-06-01 22:03:25 [INFO]: Epoch 004 - training loss: 1.4774, validation loss: 1.2813
2024-06-01 22:03:29 [INFO]: Epoch 005 - training loss: 1.4508, validation loss: 1.2649
2024-06-01 22:03:33 [INFO]: Epoch 006 - training loss: 1.4172, validation loss: 1.2503
2024-06-01 22:03:38 [INFO]: Epoch 007 - training loss: 1.3625, validation loss: 1.2091
2024-06-01 22:03:42 [INFO]: Epoch 008 - training loss: 1.2514, validation loss: 1.1486
2024-06-01 22:03:46 [INFO]: Epoch 009 - training loss: 1.1214, validation loss: 1.0931
2024-06-01 22:03:50 [INFO]: Epoch 010 - training loss: 1.0522, validation loss: 1.0340
2024-06-01 22:03:55 [INFO]: Epoch 011 - training loss: 0.9797, validation loss: 0.9869
2024-06-01 22:03:59 [INFO]: Epoch 012 - training loss: 0.9357, validation loss: 0.9550
2024-06-01 22:04:02 [INFO]: Epoch 013 - training loss: 0.9044, validation loss: 0.9321
2024-06-01 22:04:06 [INFO]: Epoch 014 - training loss: 0.8879, validation loss: 0.8987
2024-06-01 22:04:09 [INFO]: Epoch 015 - training loss: 0.8569, validation loss: 0.8833
2024-06-01 22:04:13 [INFO]: Epoch 016 - training loss: 0.8441, validation loss: 0.8684
2024-06-01 22:04:18 [INFO]: Epoch 017 - training loss: 0.8362, validation loss: 0.8494
2024-06-01 22:04:22 [INFO]: Epoch 018 - training loss: 0.8340, validation loss: 0.8449
2024-06-01 22:04:26 [INFO]: Epoch 019 - training loss: 0.8312, validation loss: 0.8474
2024-06-01 22:04:31 [INFO]: Epoch 020 - training loss: 0.8264, validation loss: 0.8422
2024-06-01 22:04:35 [INFO]: Epoch 021 - training loss: 0.8224, validation loss: 0.8297
2024-06-01 22:04:39 [INFO]: Epoch 022 - training loss: 0.8178, validation loss: 0.8289
2024-06-01 22:04:44 [INFO]: Epoch 023 - training loss: 0.8162, validation loss: 0.8298
2024-06-01 22:04:47 [INFO]: Epoch 024 - training loss: 0.8103, validation loss: 0.8145
2024-06-01 22:04:51 [INFO]: Epoch 025 - training loss: 0.8061, validation loss: 0.8175
2024-06-01 22:04:54 [INFO]: Epoch 026 - training loss: 0.8077, validation loss: 0.8163
2024-06-01 22:04:59 [INFO]: Epoch 027 - training loss: 0.8048, validation loss: 0.8142
2024-06-01 22:05:03 [INFO]: Epoch 028 - training loss: 0.8049, validation loss: 0.8082
2024-06-01 22:05:07 [INFO]: Epoch 029 - training loss: 0.8022, validation loss: 0.8101
2024-06-01 22:05:11 [INFO]: Epoch 030 - training loss: 0.7964, validation loss: 0.8064
2024-06-01 22:05:16 [INFO]: Epoch 031 - training loss: 0.8015, validation loss: 0.8083
2024-06-01 22:05:20 [INFO]: Epoch 032 - training loss: 0.7979, validation loss: 0.8035
2024-06-01 22:05:25 [INFO]: Epoch 033 - training loss: 0.7997, validation loss: 0.8019
2024-06-01 22:05:29 [INFO]: Epoch 034 - training loss: 0.7966, validation loss: 0.8049
2024-06-01 22:05:33 [INFO]: Epoch 035 - training loss: 0.7889, validation loss: 0.8019
2024-06-01 22:05:36 [INFO]: Epoch 036 - training loss: 0.7948, validation loss: 0.7992
2024-06-01 22:05:40 [INFO]: Epoch 037 - training loss: 0.7860, validation loss: 0.8059
2024-06-01 22:05:44 [INFO]: Epoch 038 - training loss: 0.7973, validation loss: 0.7984
2024-06-01 22:05:48 [INFO]: Epoch 039 - training loss: 0.7858, validation loss: 0.7992
2024-06-01 22:05:53 [INFO]: Epoch 040 - training loss: 0.7913, validation loss: 0.8001
2024-06-01 22:05:57 [INFO]: Epoch 041 - training loss: 0.7879, validation loss: 0.7982
2024-06-01 22:06:01 [INFO]: Epoch 042 - training loss: 0.7884, validation loss: 0.7983
2024-06-01 22:06:05 [INFO]: Epoch 043 - training loss: 0.7861, validation loss: 0.7979
2024-06-01 22:06:10 [INFO]: Epoch 044 - training loss: 0.7850, validation loss: 0.7956
2024-06-01 22:06:14 [INFO]: Epoch 045 - training loss: 0.7861, validation loss: 0.7953
2024-06-01 22:06:18 [INFO]: Epoch 046 - training loss: 0.7862, validation loss: 0.7933
2024-06-01 22:06:22 [INFO]: Epoch 047 - training loss: 0.7787, validation loss: 0.7988
2024-06-01 22:06:26 [INFO]: Epoch 048 - training loss: 0.7768, validation loss: 0.7978
2024-06-01 22:06:29 [INFO]: Epoch 049 - training loss: 0.7837, validation loss: 0.7956
2024-06-01 22:06:34 [INFO]: Epoch 050 - training loss: 0.7783, validation loss: 0.7902
2024-06-01 22:06:38 [INFO]: Epoch 051 - training loss: 0.7792, validation loss: 0.7937
2024-06-01 22:06:43 [INFO]: Epoch 052 - training loss: 0.7813, validation loss: 0.7964
2024-06-01 22:06:47 [INFO]: Epoch 053 - training loss: 0.7809, validation loss: 0.7920
2024-06-01 22:06:51 [INFO]: Epoch 054 - training loss: 0.7757, validation loss: 0.7933
2024-06-01 22:06:56 [INFO]: Epoch 055 - training loss: 0.7734, validation loss: 0.7890
2024-06-01 22:07:00 [INFO]: Epoch 056 - training loss: 0.7803, validation loss: 0.7899
2024-06-01 22:07:04 [INFO]: Epoch 057 - training loss: 0.7737, validation loss: 0.7916
2024-06-01 22:07:08 [INFO]: Epoch 058 - training loss: 0.7792, validation loss: 0.7947
2024-06-01 22:07:11 [INFO]: Epoch 059 - training loss: 0.7727, validation loss: 0.7931
2024-06-01 22:07:15 [INFO]: Epoch 060 - training loss: 0.7718, validation loss: 0.7920
2024-06-01 22:07:20 [INFO]: Epoch 061 - training loss: 0.7725, validation loss: 0.7916
2024-06-01 22:07:24 [INFO]: Epoch 062 - training loss: 0.7722, validation loss: 0.7921
2024-06-01 22:07:28 [INFO]: Epoch 063 - training loss: 0.7704, validation loss: 0.7933
2024-06-01 22:07:33 [INFO]: Epoch 064 - training loss: 0.7766, validation loss: 0.7966
2024-06-01 22:07:37 [INFO]: Epoch 065 - training loss: 0.7715, validation loss: 0.7924
2024-06-01 22:07:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:07:37 [INFO]: Finished training. The best model is from epoch#55.
2024-06-01 22:07:37 [INFO]: Saved the model to results_point_rate01/PeMS/Autoformer_PeMS/round_4/20240601_T220309/Autoformer.pypots
2024-06-01 22:07:38 [INFO]: Successfully saved to results_point_rate01/PeMS/Autoformer_PeMS/round_4/imputation.pkl
2024-06-01 22:07:38 [INFO]: Round4 - Autoformer on PeMS: MAE=0.5128, MSE=1.0469, MRE=0.6357
2024-06-01 22:07:38 [INFO]: Done! Final results:
Averaged Autoformer (n params: 608,926) on PeMS: MAE=0.5984 ± 0.07353390211624458, MSE=1.2329 ± 0.1961050499468714, MRE=0.7418 ± 0.09115259794264516, average inference time=0.17
