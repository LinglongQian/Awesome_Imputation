2024-06-02 01:50:20 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 01:50:20 [INFO]: Using the given device: cuda:0
2024-06-02 01:50:20 [INFO]: Model files will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_0/20240602_T015020
2024-06-02 01:50:20 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_0/20240602_T015020/tensorboard
2024-06-02 01:50:20 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-02 01:50:26 [INFO]: Epoch 001 - training loss: 1.2647, validation loss: 0.9946
2024-06-02 01:50:29 [INFO]: Epoch 002 - training loss: 0.8453, validation loss: 0.9422
2024-06-02 01:50:33 [INFO]: Epoch 003 - training loss: 0.7943, validation loss: 0.9426
2024-06-02 01:50:37 [INFO]: Epoch 004 - training loss: 0.7243, validation loss: 0.9189
2024-06-02 01:50:41 [INFO]: Epoch 005 - training loss: 0.6728, validation loss: 0.7505
2024-06-02 01:50:45 [INFO]: Epoch 006 - training loss: 0.6178, validation loss: 0.6992
2024-06-02 01:50:49 [INFO]: Epoch 007 - training loss: 0.5807, validation loss: 0.6732
2024-06-02 01:50:53 [INFO]: Epoch 008 - training loss: 0.5559, validation loss: 0.6690
2024-06-02 01:50:57 [INFO]: Epoch 009 - training loss: 0.5472, validation loss: 0.6289
2024-06-02 01:51:00 [INFO]: Epoch 010 - training loss: 0.5265, validation loss: 0.5968
2024-06-02 01:51:04 [INFO]: Epoch 011 - training loss: 0.5097, validation loss: 0.5932
2024-06-02 01:51:07 [INFO]: Epoch 012 - training loss: 0.4918, validation loss: 0.6031
2024-06-02 01:51:10 [INFO]: Epoch 013 - training loss: 0.4843, validation loss: 0.5589
2024-06-02 01:51:14 [INFO]: Epoch 014 - training loss: 0.4727, validation loss: 0.5714
2024-06-02 01:51:17 [INFO]: Epoch 015 - training loss: 0.4714, validation loss: 0.5365
2024-06-02 01:51:21 [INFO]: Epoch 016 - training loss: 0.4639, validation loss: 0.5371
2024-06-02 01:51:26 [INFO]: Epoch 017 - training loss: 0.4509, validation loss: 0.5209
2024-06-02 01:51:29 [INFO]: Epoch 018 - training loss: 0.4424, validation loss: 0.5176
2024-06-02 01:51:33 [INFO]: Epoch 019 - training loss: 0.4397, validation loss: 0.5194
2024-06-02 01:51:36 [INFO]: Epoch 020 - training loss: 0.4307, validation loss: 0.5037
2024-06-02 01:51:40 [INFO]: Epoch 021 - training loss: 0.4303, validation loss: 0.5055
2024-06-02 01:51:44 [INFO]: Epoch 022 - training loss: 0.4278, validation loss: 0.4970
2024-06-02 01:51:48 [INFO]: Epoch 023 - training loss: 0.4210, validation loss: 0.4900
2024-06-02 01:51:52 [INFO]: Epoch 024 - training loss: 0.4207, validation loss: 0.4930
2024-06-02 01:51:56 [INFO]: Epoch 025 - training loss: 0.4153, validation loss: 0.4871
2024-06-02 01:52:00 [INFO]: Epoch 026 - training loss: 0.4100, validation loss: 0.4973
2024-06-02 01:52:03 [INFO]: Epoch 027 - training loss: 0.4063, validation loss: 0.4826
2024-06-02 01:52:07 [INFO]: Epoch 028 - training loss: 0.4048, validation loss: 0.4700
2024-06-02 01:52:12 [INFO]: Epoch 029 - training loss: 0.4060, validation loss: 0.4697
2024-06-02 01:52:16 [INFO]: Epoch 030 - training loss: 0.3964, validation loss: 0.4631
2024-06-02 01:52:19 [INFO]: Epoch 031 - training loss: 0.4108, validation loss: 0.4668
2024-06-02 01:52:23 [INFO]: Epoch 032 - training loss: 1.2149, validation loss: 36.4968
2024-06-02 01:52:28 [INFO]: Epoch 033 - training loss: 4.4393, validation loss: 1.9194
2024-06-02 01:52:32 [INFO]: Epoch 034 - training loss: 1.5002, validation loss: 0.7964
2024-06-02 01:52:36 [INFO]: Epoch 035 - training loss: 0.6223, validation loss: 0.5109
2024-06-02 01:52:40 [INFO]: Epoch 036 - training loss: 0.4797, validation loss: 0.4859
2024-06-02 01:52:44 [INFO]: Epoch 037 - training loss: 0.4197, validation loss: 0.4734
2024-06-02 01:52:48 [INFO]: Epoch 038 - training loss: 0.4025, validation loss: 0.4558
2024-06-02 01:52:53 [INFO]: Epoch 039 - training loss: 0.3944, validation loss: 0.4561
2024-06-02 01:52:57 [INFO]: Epoch 040 - training loss: 0.3918, validation loss: 0.4530
2024-06-02 01:53:01 [INFO]: Epoch 041 - training loss: 0.3860, validation loss: 0.4480
2024-06-02 01:53:05 [INFO]: Epoch 042 - training loss: 0.3879, validation loss: 0.4552
2024-06-02 01:53:09 [INFO]: Epoch 043 - training loss: 0.3945, validation loss: 0.4533
2024-06-02 01:53:13 [INFO]: Epoch 044 - training loss: 0.3797, validation loss: 0.4534
2024-06-02 01:53:17 [INFO]: Epoch 045 - training loss: 0.3726, validation loss: 0.4326
2024-06-02 01:53:21 [INFO]: Epoch 046 - training loss: 0.3670, validation loss: 0.4414
2024-06-02 01:53:24 [INFO]: Epoch 047 - training loss: 0.3685, validation loss: 0.4370
2024-06-02 01:53:27 [INFO]: Epoch 048 - training loss: 0.3675, validation loss: 0.4328
2024-06-02 01:53:31 [INFO]: Epoch 049 - training loss: 0.3740, validation loss: 0.4333
2024-06-02 01:53:35 [INFO]: Epoch 050 - training loss: 0.3627, validation loss: 0.4503
2024-06-02 01:53:40 [INFO]: Epoch 051 - training loss: 0.3611, validation loss: 0.4333
2024-06-02 01:53:44 [INFO]: Epoch 052 - training loss: 0.3635, validation loss: 0.4323
2024-06-02 01:53:48 [INFO]: Epoch 053 - training loss: 0.3621, validation loss: 0.4360
2024-06-02 01:53:52 [INFO]: Epoch 054 - training loss: 0.3536, validation loss: 0.4334
2024-06-02 01:53:55 [INFO]: Epoch 055 - training loss: 0.3521, validation loss: 0.4124
2024-06-02 01:53:59 [INFO]: Epoch 056 - training loss: 0.3501, validation loss: 0.4434
2024-06-02 01:54:03 [INFO]: Epoch 057 - training loss: 0.3526, validation loss: 0.4273
2024-06-02 01:54:07 [INFO]: Epoch 058 - training loss: 0.3533, validation loss: 0.4213
2024-06-02 01:54:11 [INFO]: Epoch 059 - training loss: 0.3490, validation loss: 0.4207
2024-06-02 01:54:15 [INFO]: Epoch 060 - training loss: 0.3520, validation loss: 0.4200
2024-06-02 01:54:18 [INFO]: Epoch 061 - training loss: 0.3472, validation loss: 0.4252
2024-06-02 01:54:22 [INFO]: Epoch 062 - training loss: 0.3484, validation loss: 0.4368
2024-06-02 01:54:26 [INFO]: Epoch 063 - training loss: 0.3408, validation loss: 0.4312
2024-06-02 01:54:30 [INFO]: Epoch 064 - training loss: 0.3457, validation loss: 0.4412
2024-06-02 01:54:33 [INFO]: Epoch 065 - training loss: 0.3455, validation loss: 0.4412
2024-06-02 01:54:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:54:33 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 01:54:34 [INFO]: Saved the model to results_point_rate01/PeMS/Koopa_PeMS/round_0/20240602_T015020/Koopa.pypots
2024-06-02 01:54:34 [INFO]: Successfully saved to results_point_rate01/PeMS/Koopa_PeMS/round_0/imputation.pkl
2024-06-02 01:54:34 [INFO]: Round0 - Koopa on PeMS: MAE=0.4353, MSE=0.6781, MRE=0.5396
2024-06-02 01:54:34 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 01:54:34 [INFO]: Using the given device: cuda:0
2024-06-02 01:54:34 [INFO]: Model files will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_1/20240602_T015434
2024-06-02 01:54:34 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_1/20240602_T015434/tensorboard
2024-06-02 01:54:34 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-02 01:54:38 [INFO]: Epoch 001 - training loss: 1.4239, validation loss: 0.9953
2024-06-02 01:54:41 [INFO]: Epoch 002 - training loss: 0.8690, validation loss: 0.8936
2024-06-02 01:54:46 [INFO]: Epoch 003 - training loss: 0.7885, validation loss: 0.8736
2024-06-02 01:54:51 [INFO]: Epoch 004 - training loss: 0.7066, validation loss: 0.7825
2024-06-02 01:54:55 [INFO]: Epoch 005 - training loss: 0.6357, validation loss: 0.7488
2024-06-02 01:54:59 [INFO]: Epoch 006 - training loss: 0.5997, validation loss: 0.7205
2024-06-02 01:55:03 [INFO]: Epoch 007 - training loss: 0.5768, validation loss: 0.6629
2024-06-02 01:55:08 [INFO]: Epoch 008 - training loss: 0.5506, validation loss: 0.6374
2024-06-02 01:55:12 [INFO]: Epoch 009 - training loss: 0.5324, validation loss: 0.6230
2024-06-02 01:55:17 [INFO]: Epoch 010 - training loss: 0.5088, validation loss: 0.6060
2024-06-02 01:55:21 [INFO]: Epoch 011 - training loss: 0.5100, validation loss: 0.6142
2024-06-02 01:55:25 [INFO]: Epoch 012 - training loss: 0.4837, validation loss: 0.5979
2024-06-02 01:55:30 [INFO]: Epoch 013 - training loss: 0.4820, validation loss: 0.5721
2024-06-02 01:55:34 [INFO]: Epoch 014 - training loss: 0.4728, validation loss: 0.5721
2024-06-02 01:55:38 [INFO]: Epoch 015 - training loss: 0.4625, validation loss: 0.5627
2024-06-02 01:55:43 [INFO]: Epoch 016 - training loss: 0.4552, validation loss: 0.5563
2024-06-02 01:55:47 [INFO]: Epoch 017 - training loss: 0.4469, validation loss: 0.5466
2024-06-02 01:55:51 [INFO]: Epoch 018 - training loss: 0.4425, validation loss: 0.5566
2024-06-02 01:55:55 [INFO]: Epoch 019 - training loss: 0.4429, validation loss: 0.5368
2024-06-02 01:56:00 [INFO]: Epoch 020 - training loss: 0.4337, validation loss: 0.5418
2024-06-02 01:56:04 [INFO]: Epoch 021 - training loss: 0.4292, validation loss: 0.5202
2024-06-02 01:56:08 [INFO]: Epoch 022 - training loss: 0.4307, validation loss: 0.5329
2024-06-02 01:56:13 [INFO]: Epoch 023 - training loss: 0.4267, validation loss: 0.5214
2024-06-02 01:56:17 [INFO]: Epoch 024 - training loss: 0.4174, validation loss: 0.5175
2024-06-02 01:56:22 [INFO]: Epoch 025 - training loss: 0.4124, validation loss: 0.5069
2024-06-02 01:56:26 [INFO]: Epoch 026 - training loss: 0.4064, validation loss: 0.5050
2024-06-02 01:56:30 [INFO]: Epoch 027 - training loss: 0.4033, validation loss: 0.4991
2024-06-02 01:56:34 [INFO]: Epoch 028 - training loss: 0.4069, validation loss: 0.4943
2024-06-02 01:56:39 [INFO]: Epoch 029 - training loss: 0.3938, validation loss: 0.5027
2024-06-02 01:56:43 [INFO]: Epoch 030 - training loss: 0.3955, validation loss: 0.4943
2024-06-02 01:56:48 [INFO]: Epoch 031 - training loss: 0.3924, validation loss: 0.4788
2024-06-02 01:56:51 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.4943
2024-06-02 01:56:55 [INFO]: Epoch 033 - training loss: 0.3915, validation loss: 0.4817
2024-06-02 01:57:00 [INFO]: Epoch 034 - training loss: 0.3866, validation loss: 0.4769
2024-06-02 01:57:04 [INFO]: Epoch 035 - training loss: 0.3849, validation loss: 0.4819
2024-06-02 01:57:10 [INFO]: Epoch 036 - training loss: 0.3865, validation loss: 0.4704
2024-06-02 01:57:13 [INFO]: Epoch 037 - training loss: 0.3899, validation loss: 0.4610
2024-06-02 01:57:18 [INFO]: Epoch 038 - training loss: 0.3755, validation loss: 0.4811
2024-06-02 01:57:23 [INFO]: Epoch 039 - training loss: 0.3764, validation loss: 0.4640
2024-06-02 01:57:27 [INFO]: Epoch 040 - training loss: 0.3737, validation loss: 0.4677
2024-06-02 01:57:33 [INFO]: Epoch 041 - training loss: 0.3728, validation loss: 0.4608
2024-06-02 01:57:38 [INFO]: Epoch 042 - training loss: 0.3676, validation loss: 0.4462
2024-06-02 01:57:43 [INFO]: Epoch 043 - training loss: 0.3774, validation loss: 0.4487
2024-06-02 01:57:48 [INFO]: Epoch 044 - training loss: 0.3779, validation loss: 0.4455
2024-06-02 01:57:52 [INFO]: Epoch 045 - training loss: 0.3692, validation loss: 0.4504
2024-06-02 01:57:56 [INFO]: Epoch 046 - training loss: 0.3650, validation loss: 0.4449
2024-06-02 01:58:01 [INFO]: Epoch 047 - training loss: 0.3622, validation loss: 0.4463
2024-06-02 01:58:05 [INFO]: Epoch 048 - training loss: 0.3586, validation loss: 0.4455
2024-06-02 01:58:10 [INFO]: Epoch 049 - training loss: 0.3548, validation loss: 0.4307
2024-06-02 01:58:13 [INFO]: Epoch 050 - training loss: 0.3589, validation loss: 0.4444
2024-06-02 01:58:18 [INFO]: Epoch 051 - training loss: 0.3579, validation loss: 0.4192
2024-06-02 01:58:23 [INFO]: Epoch 052 - training loss: 0.3545, validation loss: 0.4354
2024-06-02 01:58:27 [INFO]: Epoch 053 - training loss: 0.3562, validation loss: 0.4236
2024-06-02 01:58:32 [INFO]: Epoch 054 - training loss: 0.3571, validation loss: 0.4235
2024-06-02 01:58:36 [INFO]: Epoch 055 - training loss: 0.3601, validation loss: 0.4390
2024-06-02 01:58:40 [INFO]: Epoch 056 - training loss: 0.3526, validation loss: 0.4434
2024-06-02 01:58:44 [INFO]: Epoch 057 - training loss: 0.3499, validation loss: 0.4391
2024-06-02 01:58:49 [INFO]: Epoch 058 - training loss: 0.3478, validation loss: 0.4503
2024-06-02 01:58:52 [INFO]: Epoch 059 - training loss: 0.3489, validation loss: 0.4274
2024-06-02 01:58:57 [INFO]: Epoch 060 - training loss: 0.3408, validation loss: 0.4403
2024-06-02 01:59:02 [INFO]: Epoch 061 - training loss: 0.3443, validation loss: 0.4265
2024-06-02 01:59:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:59:02 [INFO]: Finished training. The best model is from epoch#51.
2024-06-02 01:59:02 [INFO]: Saved the model to results_point_rate01/PeMS/Koopa_PeMS/round_1/20240602_T015434/Koopa.pypots
2024-06-02 01:59:02 [INFO]: Successfully saved to results_point_rate01/PeMS/Koopa_PeMS/round_1/imputation.pkl
2024-06-02 01:59:02 [INFO]: Round1 - Koopa on PeMS: MAE=0.4286, MSE=0.6655, MRE=0.5313
2024-06-02 01:59:02 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 01:59:02 [INFO]: Using the given device: cuda:0
2024-06-02 01:59:02 [INFO]: Model files will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_2/20240602_T015902
2024-06-02 01:59:02 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_2/20240602_T015902/tensorboard
2024-06-02 01:59:02 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-02 01:59:07 [INFO]: Epoch 001 - training loss: 1.2962, validation loss: 0.9841
2024-06-02 01:59:11 [INFO]: Epoch 002 - training loss: 0.8520, validation loss: 0.9156
2024-06-02 01:59:15 [INFO]: Epoch 003 - training loss: 0.7725, validation loss: 0.9000
2024-06-02 01:59:19 [INFO]: Epoch 004 - training loss: 0.7371, validation loss: 0.9293
2024-06-02 01:59:24 [INFO]: Epoch 005 - training loss: 0.7098, validation loss: 0.8939
2024-06-02 01:59:29 [INFO]: Epoch 006 - training loss: 0.6588, validation loss: 0.7867
2024-06-02 01:59:34 [INFO]: Epoch 007 - training loss: 0.6225, validation loss: 0.8016
2024-06-02 01:59:37 [INFO]: Epoch 008 - training loss: 0.6021, validation loss: 0.7293
2024-06-02 01:59:42 [INFO]: Epoch 009 - training loss: 0.5816, validation loss: 0.6971
2024-06-02 01:59:46 [INFO]: Epoch 010 - training loss: 0.5612, validation loss: 0.7253
2024-06-02 01:59:51 [INFO]: Epoch 011 - training loss: 0.5516, validation loss: 0.6475
2024-06-02 01:59:56 [INFO]: Epoch 012 - training loss: 0.5337, validation loss: 0.6795
2024-06-02 02:00:00 [INFO]: Epoch 013 - training loss: 0.5219, validation loss: 0.6251
2024-06-02 02:00:05 [INFO]: Epoch 014 - training loss: 0.5028, validation loss: 0.6001
2024-06-02 02:00:09 [INFO]: Epoch 015 - training loss: 0.4943, validation loss: 0.5869
2024-06-02 02:00:14 [INFO]: Epoch 016 - training loss: 0.4809, validation loss: 0.5733
2024-06-02 02:00:19 [INFO]: Epoch 017 - training loss: 0.4741, validation loss: 0.5570
2024-06-02 02:00:23 [INFO]: Epoch 018 - training loss: 0.4765, validation loss: 0.5629
2024-06-02 02:00:28 [INFO]: Epoch 019 - training loss: 0.4649, validation loss: 0.5575
2024-06-02 02:00:32 [INFO]: Epoch 020 - training loss: 0.4588, validation loss: 0.5432
2024-06-02 02:00:36 [INFO]: Epoch 021 - training loss: 0.4478, validation loss: 0.5530
2024-06-02 02:00:41 [INFO]: Epoch 022 - training loss: 0.4619, validation loss: 0.5326
2024-06-02 02:00:45 [INFO]: Epoch 023 - training loss: 0.4534, validation loss: 0.5276
2024-06-02 02:00:50 [INFO]: Epoch 024 - training loss: 0.4483, validation loss: 0.5279
2024-06-02 02:00:55 [INFO]: Epoch 025 - training loss: 0.4383, validation loss: 0.5255
2024-06-02 02:01:00 [INFO]: Epoch 026 - training loss: 0.4274, validation loss: 0.5101
2024-06-02 02:01:04 [INFO]: Epoch 027 - training loss: 0.4226, validation loss: 0.5044
2024-06-02 02:01:08 [INFO]: Epoch 028 - training loss: 0.4285, validation loss: 0.4990
2024-06-02 02:01:13 [INFO]: Epoch 029 - training loss: 0.4180, validation loss: 0.4867
2024-06-02 02:01:17 [INFO]: Epoch 030 - training loss: 0.4119, validation loss: 0.4974
2024-06-02 02:01:22 [INFO]: Epoch 031 - training loss: 0.4090, validation loss: 0.4887
2024-06-02 02:01:26 [INFO]: Epoch 032 - training loss: 0.4127, validation loss: 0.4831
2024-06-02 02:01:31 [INFO]: Epoch 033 - training loss: 0.4131, validation loss: 0.4795
2024-06-02 02:01:36 [INFO]: Epoch 034 - training loss: 0.4100, validation loss: 0.4765
2024-06-02 02:01:40 [INFO]: Epoch 035 - training loss: 0.4003, validation loss: 0.4771
2024-06-02 02:01:45 [INFO]: Epoch 036 - training loss: 0.3956, validation loss: 0.4672
2024-06-02 02:01:49 [INFO]: Epoch 037 - training loss: 0.3914, validation loss: 0.4688
2024-06-02 02:01:53 [INFO]: Epoch 038 - training loss: 0.3883, validation loss: 0.4821
2024-06-02 02:01:58 [INFO]: Epoch 039 - training loss: 0.3886, validation loss: 0.4534
2024-06-02 02:02:04 [INFO]: Epoch 040 - training loss: 0.3855, validation loss: 0.4687
2024-06-02 02:02:08 [INFO]: Epoch 041 - training loss: 0.3815, validation loss: 0.4636
2024-06-02 02:02:12 [INFO]: Epoch 042 - training loss: 0.3789, validation loss: 0.4682
2024-06-02 02:02:17 [INFO]: Epoch 043 - training loss: 0.3796, validation loss: 0.4531
2024-06-02 02:02:21 [INFO]: Epoch 044 - training loss: 0.3848, validation loss: 0.4710
2024-06-02 02:02:27 [INFO]: Epoch 045 - training loss: 0.3752, validation loss: 0.4430
2024-06-02 02:02:32 [INFO]: Epoch 046 - training loss: 0.3751, validation loss: 0.4554
2024-06-02 02:02:36 [INFO]: Epoch 047 - training loss: 0.3722, validation loss: 0.4515
2024-06-02 02:02:40 [INFO]: Epoch 048 - training loss: 0.3665, validation loss: 0.4458
2024-06-02 02:02:45 [INFO]: Epoch 049 - training loss: 0.3630, validation loss: 0.4430
2024-06-02 02:02:49 [INFO]: Epoch 050 - training loss: 0.3664, validation loss: 0.4515
2024-06-02 02:02:53 [INFO]: Epoch 051 - training loss: 0.3622, validation loss: 0.4567
2024-06-02 02:02:58 [INFO]: Epoch 052 - training loss: 0.3602, validation loss: 0.4312
2024-06-02 02:03:03 [INFO]: Epoch 053 - training loss: 0.3639, validation loss: 0.4620
2024-06-02 02:03:07 [INFO]: Epoch 054 - training loss: 0.3660, validation loss: 0.4552
2024-06-02 02:03:12 [INFO]: Epoch 055 - training loss: 0.3636, validation loss: 0.4521
2024-06-02 02:03:16 [INFO]: Epoch 056 - training loss: 0.3594, validation loss: 0.4572
2024-06-02 02:03:22 [INFO]: Epoch 057 - training loss: 0.3548, validation loss: 0.4577
2024-06-02 02:03:26 [INFO]: Epoch 058 - training loss: 0.3588, validation loss: 0.4481
2024-06-02 02:03:31 [INFO]: Epoch 059 - training loss: 0.3711, validation loss: 0.4309
2024-06-02 02:03:36 [INFO]: Epoch 060 - training loss: 0.3614, validation loss: 0.4282
2024-06-02 02:03:39 [INFO]: Epoch 061 - training loss: 0.3610, validation loss: 0.4347
2024-06-02 02:03:44 [INFO]: Epoch 062 - training loss: 0.3539, validation loss: 0.4404
2024-06-02 02:03:48 [INFO]: Epoch 063 - training loss: 0.3499, validation loss: 0.4255
2024-06-02 02:03:52 [INFO]: Epoch 064 - training loss: 0.3518, validation loss: 0.4326
2024-06-02 02:03:57 [INFO]: Epoch 065 - training loss: 0.3516, validation loss: 0.4114
2024-06-02 02:04:00 [INFO]: Epoch 066 - training loss: 0.3525, validation loss: 0.4056
2024-06-02 02:04:06 [INFO]: Epoch 067 - training loss: 0.3480, validation loss: 0.4252
2024-06-02 02:04:10 [INFO]: Epoch 068 - training loss: 0.3417, validation loss: 0.4135
2024-06-02 02:04:14 [INFO]: Epoch 069 - training loss: 0.3453, validation loss: 0.4239
2024-06-02 02:04:18 [INFO]: Epoch 070 - training loss: 0.3455, validation loss: 0.4171
2024-06-02 02:04:23 [INFO]: Epoch 071 - training loss: 0.3450, validation loss: 0.4280
2024-06-02 02:04:27 [INFO]: Epoch 072 - training loss: 0.3420, validation loss: 0.4444
2024-06-02 02:04:32 [INFO]: Epoch 073 - training loss: 0.3445, validation loss: 0.4166
2024-06-02 02:04:37 [INFO]: Epoch 074 - training loss: 0.3440, validation loss: 0.4250
2024-06-02 02:04:40 [INFO]: Epoch 075 - training loss: 0.3387, validation loss: 0.4201
2024-06-02 02:04:45 [INFO]: Epoch 076 - training loss: 0.3376, validation loss: 0.4308
2024-06-02 02:04:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 02:04:45 [INFO]: Finished training. The best model is from epoch#66.
2024-06-02 02:04:45 [INFO]: Saved the model to results_point_rate01/PeMS/Koopa_PeMS/round_2/20240602_T015902/Koopa.pypots
2024-06-02 02:04:45 [INFO]: Successfully saved to results_point_rate01/PeMS/Koopa_PeMS/round_2/imputation.pkl
2024-06-02 02:04:45 [INFO]: Round2 - Koopa on PeMS: MAE=0.4336, MSE=0.6725, MRE=0.5374
2024-06-02 02:04:45 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 02:04:45 [INFO]: Using the given device: cuda:0
2024-06-02 02:04:45 [INFO]: Model files will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_3/20240602_T020445
2024-06-02 02:04:45 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_3/20240602_T020445/tensorboard
2024-06-02 02:04:45 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-02 02:04:50 [INFO]: Epoch 001 - training loss: 1.3313, validation loss: 1.0991
2024-06-02 02:04:54 [INFO]: Epoch 002 - training loss: 0.8268, validation loss: 1.0471
2024-06-02 02:04:59 [INFO]: Epoch 003 - training loss: 0.7655, validation loss: 0.9760
2024-06-02 02:05:04 [INFO]: Epoch 004 - training loss: 0.7098, validation loss: 0.9439
2024-06-02 02:05:09 [INFO]: Epoch 005 - training loss: 0.6523, validation loss: 0.7521
2024-06-02 02:05:12 [INFO]: Epoch 006 - training loss: 0.6013, validation loss: 0.7247
2024-06-02 02:05:17 [INFO]: Epoch 007 - training loss: 0.5708, validation loss: 0.8755
2024-06-02 02:05:21 [INFO]: Epoch 008 - training loss: 0.5583, validation loss: 0.7192
2024-06-02 02:05:26 [INFO]: Epoch 009 - training loss: 0.5400, validation loss: 0.7036
2024-06-02 02:05:30 [INFO]: Epoch 010 - training loss: 0.5240, validation loss: 0.6810
2024-06-02 02:05:34 [INFO]: Epoch 011 - training loss: 0.5116, validation loss: 0.6504
2024-06-02 02:05:39 [INFO]: Epoch 012 - training loss: 0.5065, validation loss: 0.6533
2024-06-02 02:05:44 [INFO]: Epoch 013 - training loss: 0.4876, validation loss: 0.6240
2024-06-02 02:05:48 [INFO]: Epoch 014 - training loss: 0.4779, validation loss: 0.5824
2024-06-02 02:05:53 [INFO]: Epoch 015 - training loss: 0.4757, validation loss: 0.6398
2024-06-02 02:05:57 [INFO]: Epoch 016 - training loss: 0.4688, validation loss: 0.5899
2024-06-02 02:06:02 [INFO]: Epoch 017 - training loss: 0.4633, validation loss: 0.5439
2024-06-02 02:06:07 [INFO]: Epoch 018 - training loss: 0.4616, validation loss: 0.5449
2024-06-02 02:06:11 [INFO]: Epoch 019 - training loss: 0.4596, validation loss: 0.5343
2024-06-02 02:06:15 [INFO]: Epoch 020 - training loss: 0.4420, validation loss: 0.5329
2024-06-02 02:06:20 [INFO]: Epoch 021 - training loss: 0.4430, validation loss: 0.5256
2024-06-02 02:06:24 [INFO]: Epoch 022 - training loss: 0.4322, validation loss: 0.5187
2024-06-02 02:06:29 [INFO]: Epoch 023 - training loss: 0.4304, validation loss: 0.5089
2024-06-02 02:06:33 [INFO]: Epoch 024 - training loss: 0.4196, validation loss: 0.5105
2024-06-02 02:06:37 [INFO]: Epoch 025 - training loss: 0.4276, validation loss: 0.5159
2024-06-02 02:06:42 [INFO]: Epoch 026 - training loss: 0.5033, validation loss: 0.5159
2024-06-02 02:06:47 [INFO]: Epoch 027 - training loss: 4.7277, validation loss: 13.4732
2024-06-02 02:06:52 [INFO]: Epoch 028 - training loss: 3.4969, validation loss: 3.5743
2024-06-02 02:06:57 [INFO]: Epoch 029 - training loss: 2.3770, validation loss: 2.0509
2024-06-02 02:07:02 [INFO]: Epoch 030 - training loss: 1.8035, validation loss: 1.4057
2024-06-02 02:07:06 [INFO]: Epoch 031 - training loss: 1.4584, validation loss: 1.0742
2024-06-02 02:07:11 [INFO]: Epoch 032 - training loss: 1.2615, validation loss: 0.9092
2024-06-02 02:07:15 [INFO]: Epoch 033 - training loss: 1.1249, validation loss: 0.8497
2024-06-02 02:07:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 02:07:15 [INFO]: Finished training. The best model is from epoch#23.
2024-06-02 02:07:15 [INFO]: Saved the model to results_point_rate01/PeMS/Koopa_PeMS/round_3/20240602_T020445/Koopa.pypots
2024-06-02 02:07:15 [INFO]: Successfully saved to results_point_rate01/PeMS/Koopa_PeMS/round_3/imputation.pkl
2024-06-02 02:07:15 [INFO]: Round3 - Koopa on PeMS: MAE=0.6743, MSE=1.1166, MRE=0.8359
2024-06-02 02:07:15 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 02:07:15 [INFO]: Using the given device: cuda:0
2024-06-02 02:07:15 [INFO]: Model files will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_4/20240602_T020715
2024-06-02 02:07:15 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/Koopa_PeMS/round_4/20240602_T020715/tensorboard
2024-06-02 02:07:15 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-02 02:07:20 [INFO]: Epoch 001 - training loss: 1.2298, validation loss: 0.9107
2024-06-02 02:07:24 [INFO]: Epoch 002 - training loss: 0.8706, validation loss: 0.9059
2024-06-02 02:07:29 [INFO]: Epoch 003 - training loss: 0.7472, validation loss: 0.9058
2024-06-02 02:07:33 [INFO]: Epoch 004 - training loss: 0.6933, validation loss: 0.8337
2024-06-02 02:07:37 [INFO]: Epoch 005 - training loss: 0.6484, validation loss: 0.7850
2024-06-02 02:07:42 [INFO]: Epoch 006 - training loss: 0.6063, validation loss: 0.7261
2024-06-02 02:07:47 [INFO]: Epoch 007 - training loss: 0.5854, validation loss: 0.6931
2024-06-02 02:07:52 [INFO]: Epoch 008 - training loss: 0.5545, validation loss: 0.6562
2024-06-02 02:07:56 [INFO]: Epoch 009 - training loss: 0.5337, validation loss: 0.6483
2024-06-02 02:08:00 [INFO]: Epoch 010 - training loss: 0.5248, validation loss: 0.6340
2024-06-02 02:08:05 [INFO]: Epoch 011 - training loss: 0.5062, validation loss: 0.6193
2024-06-02 02:08:09 [INFO]: Epoch 012 - training loss: 0.4921, validation loss: 0.6007
2024-06-02 02:08:13 [INFO]: Epoch 013 - training loss: 0.4833, validation loss: 0.6028
2024-06-02 02:08:17 [INFO]: Epoch 014 - training loss: 0.4766, validation loss: 0.5818
2024-06-02 02:08:22 [INFO]: Epoch 015 - training loss: 0.4608, validation loss: 0.5681
2024-06-02 02:08:27 [INFO]: Epoch 016 - training loss: 0.4644, validation loss: 0.5491
2024-06-02 02:08:31 [INFO]: Epoch 017 - training loss: 0.4568, validation loss: 0.5471
2024-06-02 02:08:36 [INFO]: Epoch 018 - training loss: 0.4473, validation loss: 0.5324
2024-06-02 02:08:41 [INFO]: Epoch 019 - training loss: 0.4369, validation loss: 0.5191
2024-06-02 02:08:45 [INFO]: Epoch 020 - training loss: 0.4326, validation loss: 0.5255
2024-06-02 02:08:49 [INFO]: Epoch 021 - training loss: 0.4319, validation loss: 0.5195
2024-06-02 02:08:53 [INFO]: Epoch 022 - training loss: 0.4288, validation loss: 0.5071
2024-06-02 02:08:58 [INFO]: Epoch 023 - training loss: 0.4205, validation loss: 0.5103
2024-06-02 02:09:03 [INFO]: Epoch 024 - training loss: 0.4151, validation loss: 0.4972
2024-06-02 02:09:07 [INFO]: Epoch 025 - training loss: 0.4148, validation loss: 0.4864
2024-06-02 02:09:12 [INFO]: Epoch 026 - training loss: 0.4163, validation loss: 0.4866
2024-06-02 02:09:17 [INFO]: Epoch 027 - training loss: 0.4080, validation loss: 0.4815
2024-06-02 02:09:21 [INFO]: Epoch 028 - training loss: 0.4046, validation loss: 0.4894
2024-06-02 02:09:26 [INFO]: Epoch 029 - training loss: 0.4053, validation loss: 0.4832
2024-06-02 02:09:30 [INFO]: Epoch 030 - training loss: 0.3974, validation loss: 0.4691
2024-06-02 02:09:34 [INFO]: Epoch 031 - training loss: 0.3945, validation loss: 0.4674
2024-06-02 02:09:39 [INFO]: Epoch 032 - training loss: 0.3880, validation loss: 0.4644
2024-06-02 02:09:44 [INFO]: Epoch 033 - training loss: 0.3851, validation loss: 0.4674
2024-06-02 02:09:49 [INFO]: Epoch 034 - training loss: 0.4000, validation loss: 0.4711
2024-06-02 02:09:53 [INFO]: Epoch 035 - training loss: 0.3893, validation loss: 0.4544
2024-06-02 02:09:57 [INFO]: Epoch 036 - training loss: 0.3824, validation loss: 0.4704
2024-06-02 02:10:02 [INFO]: Epoch 037 - training loss: 0.3812, validation loss: 0.4513
2024-06-02 02:10:06 [INFO]: Epoch 038 - training loss: 0.3808, validation loss: 0.4501
2024-06-02 02:10:10 [INFO]: Epoch 039 - training loss: 0.3988, validation loss: 0.4499
2024-06-02 02:10:14 [INFO]: Epoch 040 - training loss: 0.3879, validation loss: 0.4540
2024-06-02 02:10:19 [INFO]: Epoch 041 - training loss: 0.4025, validation loss: 0.4604
2024-06-02 02:10:23 [INFO]: Epoch 042 - training loss: 2.4891, validation loss: 77.8469
2024-06-02 02:10:28 [INFO]: Epoch 043 - training loss: 6.3380, validation loss: 7.3258
2024-06-02 02:10:32 [INFO]: Epoch 044 - training loss: 3.0713, validation loss: 2.7228
2024-06-02 02:10:36 [INFO]: Epoch 045 - training loss: 2.0221, validation loss: 1.5513
2024-06-02 02:10:40 [INFO]: Epoch 046 - training loss: 1.5491, validation loss: 1.1353
2024-06-02 02:10:44 [INFO]: Epoch 047 - training loss: 1.3460, validation loss: 0.9513
2024-06-02 02:10:49 [INFO]: Epoch 048 - training loss: 1.2144, validation loss: 0.8727
2024-06-02 02:10:54 [INFO]: Epoch 049 - training loss: 1.1469, validation loss: 0.8180
2024-06-02 02:10:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 02:10:54 [INFO]: Finished training. The best model is from epoch#39.
2024-06-02 02:10:54 [INFO]: Saved the model to results_point_rate01/PeMS/Koopa_PeMS/round_4/20240602_T020715/Koopa.pypots
2024-06-02 02:10:54 [INFO]: Successfully saved to results_point_rate01/PeMS/Koopa_PeMS/round_4/imputation.pkl
2024-06-02 02:10:54 [INFO]: Round4 - Koopa on PeMS: MAE=0.6886, MSE=1.1043, MRE=0.8536
2024-06-02 02:10:54 [INFO]: Done! Final results:
Averaged Koopa (n params: 13,306,214) on PeMS: MAE=0.5321 ± 0.12208785594032365, MSE=0.8474 ± 0.21485446801669167, MRE=0.6596 ± 0.15134006119538496, average inference time=0.19
