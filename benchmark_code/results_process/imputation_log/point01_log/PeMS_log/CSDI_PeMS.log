2024-06-01 21:52:20 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-01 21:52:20 [INFO]: Using the given device: cuda:0
2024-06-01 21:52:20 [INFO]: Model files will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_0/20240601_T215220
2024-06-01 21:52:20 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_0/20240601_T215220/tensorboard
2024-06-01 21:52:20 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-01 21:53:10 [INFO]: Epoch 001 - training loss: 0.7295, validation loss: 0.5294
2024-06-01 21:53:56 [INFO]: Epoch 002 - training loss: 0.3753, validation loss: 0.3748
2024-06-01 21:54:42 [INFO]: Epoch 003 - training loss: 0.3170, validation loss: 0.3525
2024-06-01 21:55:29 [INFO]: Epoch 004 - training loss: 0.2878, validation loss: 0.3484
2024-06-01 21:56:15 [INFO]: Epoch 005 - training loss: 0.2905, validation loss: 0.3226
2024-06-01 21:57:01 [INFO]: Epoch 006 - training loss: 0.3150, validation loss: 0.3082
2024-06-01 21:57:48 [INFO]: Epoch 007 - training loss: 0.2469, validation loss: 0.3120
2024-06-01 21:58:34 [INFO]: Epoch 008 - training loss: 0.2786, validation loss: 0.3015
2024-06-01 21:59:20 [INFO]: Epoch 009 - training loss: 0.2593, validation loss: 0.2841
2024-06-01 22:00:07 [INFO]: Epoch 010 - training loss: 0.2511, validation loss: 0.2777
2024-06-01 22:00:54 [INFO]: Epoch 011 - training loss: 0.2446, validation loss: 0.2502
2024-06-01 22:01:40 [INFO]: Epoch 012 - training loss: 0.2217, validation loss: 0.2386
2024-06-01 22:02:27 [INFO]: Epoch 013 - training loss: 0.2194, validation loss: 0.2245
2024-06-01 22:03:13 [INFO]: Epoch 014 - training loss: 0.2061, validation loss: 0.2459
2024-06-01 22:04:00 [INFO]: Epoch 015 - training loss: 0.2443, validation loss: 0.2174
2024-06-01 22:04:46 [INFO]: Epoch 016 - training loss: 0.2056, validation loss: 0.2154
2024-06-01 22:05:33 [INFO]: Epoch 017 - training loss: 0.1667, validation loss: 0.2033
2024-06-01 22:06:19 [INFO]: Epoch 018 - training loss: 0.1597, validation loss: 0.2052
2024-06-01 22:07:05 [INFO]: Epoch 019 - training loss: 0.1813, validation loss: 0.2019
2024-06-01 22:07:51 [INFO]: Epoch 020 - training loss: 0.1661, validation loss: 0.1942
2024-06-01 22:08:37 [INFO]: Epoch 021 - training loss: 0.1754, validation loss: 0.1964
2024-06-01 22:09:23 [INFO]: Epoch 022 - training loss: 0.2097, validation loss: 0.1889
2024-06-01 22:10:09 [INFO]: Epoch 023 - training loss: 0.2074, validation loss: 0.1827
2024-06-01 22:10:55 [INFO]: Epoch 024 - training loss: 0.1663, validation loss: 0.1828
2024-06-01 22:11:41 [INFO]: Epoch 025 - training loss: 0.1675, validation loss: 0.1726
2024-06-01 22:12:27 [INFO]: Epoch 026 - training loss: 0.1569, validation loss: 0.1716
2024-06-01 22:13:13 [INFO]: Epoch 027 - training loss: 0.1597, validation loss: 0.1761
2024-06-01 22:13:59 [INFO]: Epoch 028 - training loss: 0.1598, validation loss: 0.1693
2024-06-01 22:14:45 [INFO]: Epoch 029 - training loss: 0.1619, validation loss: 0.1712
2024-06-01 22:15:31 [INFO]: Epoch 030 - training loss: 0.1477, validation loss: 0.1696
2024-06-01 22:16:17 [INFO]: Epoch 031 - training loss: 0.1775, validation loss: 0.1714
2024-06-01 22:17:03 [INFO]: Epoch 032 - training loss: 0.1547, validation loss: 0.1695
2024-06-01 22:17:49 [INFO]: Epoch 033 - training loss: 0.1845, validation loss: 0.1802
2024-06-01 22:18:35 [INFO]: Epoch 034 - training loss: 0.1971, validation loss: 0.1697
2024-06-01 22:19:22 [INFO]: Epoch 035 - training loss: 0.1809, validation loss: 0.1693
2024-06-01 22:20:01 [INFO]: Epoch 036 - training loss: 0.1368, validation loss: 0.1615
2024-06-01 22:20:31 [INFO]: Epoch 037 - training loss: 0.1638, validation loss: 0.1722
2024-06-01 22:21:02 [INFO]: Epoch 038 - training loss: 0.1524, validation loss: 0.1707
2024-06-01 22:21:32 [INFO]: Epoch 039 - training loss: 0.1643, validation loss: 0.1822
2024-06-01 22:22:02 [INFO]: Epoch 040 - training loss: 0.1761, validation loss: 0.1685
2024-06-01 22:22:33 [INFO]: Epoch 041 - training loss: 0.1823, validation loss: 0.1698
2024-06-01 22:23:03 [INFO]: Epoch 042 - training loss: 0.1608, validation loss: 0.1696
2024-06-01 22:23:33 [INFO]: Epoch 043 - training loss: 0.1663, validation loss: 0.1701
2024-06-01 22:24:04 [INFO]: Epoch 044 - training loss: 0.1496, validation loss: 0.1609
2024-06-01 22:24:34 [INFO]: Epoch 045 - training loss: 0.1443, validation loss: 0.1670
2024-06-01 22:25:05 [INFO]: Epoch 046 - training loss: 0.1914, validation loss: 0.1813
2024-06-01 22:25:35 [INFO]: Epoch 047 - training loss: 0.1420, validation loss: 0.1622
2024-06-01 22:26:05 [INFO]: Epoch 048 - training loss: 0.1569, validation loss: 0.1569
2024-06-01 22:26:36 [INFO]: Epoch 049 - training loss: 0.1908, validation loss: 0.1550
2024-06-01 22:27:06 [INFO]: Epoch 050 - training loss: 0.1199, validation loss: 0.1554
2024-06-01 22:27:37 [INFO]: Epoch 051 - training loss: 0.1567, validation loss: 0.1638
2024-06-01 22:28:07 [INFO]: Epoch 052 - training loss: 0.1648, validation loss: 0.1789
2024-06-01 22:28:37 [INFO]: Epoch 053 - training loss: 0.1596, validation loss: 0.1669
2024-06-01 22:29:08 [INFO]: Epoch 054 - training loss: 0.1304, validation loss: 0.1602
2024-06-01 22:29:38 [INFO]: Epoch 055 - training loss: 0.1599, validation loss: 0.1604
2024-06-01 22:30:08 [INFO]: Epoch 056 - training loss: 0.1513, validation loss: 0.1620
2024-06-01 22:30:39 [INFO]: Epoch 057 - training loss: 0.1566, validation loss: 0.1631
2024-06-01 22:31:09 [INFO]: Epoch 058 - training loss: 0.1542, validation loss: 0.1625
2024-06-01 22:31:40 [INFO]: Epoch 059 - training loss: 0.1574, validation loss: 0.1580
2024-06-01 22:31:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 22:31:40 [INFO]: Finished training. The best model is from epoch#49.
2024-06-01 22:31:40 [INFO]: Saved the model to results_point_rate01/PeMS/CSDI_PeMS/round_0/20240601_T215220/CSDI.pypots
2024-06-01 22:36:41 [INFO]: Successfully saved to results_point_rate01/PeMS/CSDI_PeMS/round_0/imputation.pkl
2024-06-01 22:36:41 [INFO]: Round0 - CSDI on PeMS: MAE=0.3226, MSE=2.9149, MRE=0.3999
2024-06-01 22:36:41 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-01 22:36:41 [INFO]: Using the given device: cuda:0
2024-06-01 22:36:41 [INFO]: Model files will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_1/20240601_T223641
2024-06-01 22:36:41 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_1/20240601_T223641/tensorboard
2024-06-01 22:36:41 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-01 22:37:11 [INFO]: Epoch 001 - training loss: 0.7249, validation loss: 0.7168
2024-06-01 22:37:42 [INFO]: Epoch 002 - training loss: 0.4033, validation loss: 0.4018
2024-06-01 22:38:12 [INFO]: Epoch 003 - training loss: 0.3166, validation loss: 0.3293
2024-06-01 22:38:42 [INFO]: Epoch 004 - training loss: 0.2952, validation loss: 0.3400
2024-06-01 22:39:13 [INFO]: Epoch 005 - training loss: 0.2934, validation loss: 0.3182
2024-06-01 22:39:43 [INFO]: Epoch 006 - training loss: 0.2719, validation loss: 0.3033
2024-06-01 22:40:13 [INFO]: Epoch 007 - training loss: 0.2832, validation loss: 0.2849
2024-06-01 22:40:44 [INFO]: Epoch 008 - training loss: 0.2677, validation loss: 0.2953
2024-06-01 22:41:14 [INFO]: Epoch 009 - training loss: 0.2773, validation loss: 0.2730
2024-06-01 22:41:44 [INFO]: Epoch 010 - training loss: 0.2258, validation loss: 0.2509
2024-06-01 22:42:15 [INFO]: Epoch 011 - training loss: 0.1951, validation loss: 0.2470
2024-06-01 22:42:45 [INFO]: Epoch 012 - training loss: 0.2350, validation loss: 0.2580
2024-06-01 22:43:15 [INFO]: Epoch 013 - training loss: 0.2051, validation loss: 0.2262
2024-06-01 22:43:46 [INFO]: Epoch 014 - training loss: 0.2263, validation loss: 0.2072
2024-06-01 22:44:16 [INFO]: Epoch 015 - training loss: 0.1861, validation loss: 0.2182
2024-06-01 22:44:47 [INFO]: Epoch 016 - training loss: 0.1927, validation loss: 0.2082
2024-06-01 22:45:17 [INFO]: Epoch 017 - training loss: 0.1741, validation loss: 0.1999
2024-06-01 22:45:47 [INFO]: Epoch 018 - training loss: 0.1890, validation loss: 0.1982
2024-06-01 22:46:18 [INFO]: Epoch 019 - training loss: 0.1919, validation loss: 0.2055
2024-06-01 22:46:48 [INFO]: Epoch 020 - training loss: 0.1791, validation loss: 0.1886
2024-06-01 22:47:18 [INFO]: Epoch 021 - training loss: 0.2112, validation loss: 0.1877
2024-06-01 22:47:49 [INFO]: Epoch 022 - training loss: 0.1458, validation loss: 0.1856
2024-06-01 22:48:19 [INFO]: Epoch 023 - training loss: 0.2083, validation loss: 0.1873
2024-06-01 22:48:49 [INFO]: Epoch 024 - training loss: 0.1937, validation loss: 0.2016
2024-06-01 22:49:20 [INFO]: Epoch 025 - training loss: 0.2081, validation loss: 0.2069
2024-06-01 22:49:50 [INFO]: Epoch 026 - training loss: 0.2062, validation loss: 0.1829
2024-06-01 22:50:20 [INFO]: Epoch 027 - training loss: 0.1574, validation loss: 0.1755
2024-06-01 22:50:51 [INFO]: Epoch 028 - training loss: 0.1719, validation loss: 0.1845
2024-06-01 22:51:21 [INFO]: Epoch 029 - training loss: 0.1618, validation loss: 0.1792
2024-06-01 22:51:51 [INFO]: Epoch 030 - training loss: 0.1778, validation loss: 0.1862
2024-06-01 22:52:22 [INFO]: Epoch 031 - training loss: 0.1558, validation loss: 0.1750
2024-06-01 22:52:52 [INFO]: Epoch 032 - training loss: 0.1857, validation loss: 0.1818
2024-06-01 22:53:22 [INFO]: Epoch 033 - training loss: 0.1648, validation loss: 0.1735
2024-06-01 22:53:53 [INFO]: Epoch 034 - training loss: 0.1691, validation loss: 0.1663
2024-06-01 22:54:23 [INFO]: Epoch 035 - training loss: 0.1416, validation loss: 0.1664
2024-06-01 22:54:53 [INFO]: Epoch 036 - training loss: 0.1710, validation loss: 0.1787
2024-06-01 22:55:24 [INFO]: Epoch 037 - training loss: 0.1718, validation loss: 0.1705
2024-06-01 22:55:54 [INFO]: Epoch 038 - training loss: 0.1791, validation loss: 0.1704
2024-06-01 22:56:24 [INFO]: Epoch 039 - training loss: 0.1467, validation loss: 0.1599
2024-06-01 22:56:55 [INFO]: Epoch 040 - training loss: 0.1807, validation loss: 0.1689
2024-06-01 22:57:25 [INFO]: Epoch 041 - training loss: 0.2096, validation loss: 0.1985
2024-06-01 22:57:55 [INFO]: Epoch 042 - training loss: 0.1859, validation loss: 0.2104
2024-06-01 22:58:26 [INFO]: Epoch 043 - training loss: 0.1978, validation loss: 0.1830
2024-06-01 22:58:56 [INFO]: Epoch 044 - training loss: 0.1724, validation loss: 0.1763
2024-06-01 22:59:26 [INFO]: Epoch 045 - training loss: 0.1682, validation loss: 0.1681
2024-06-01 22:59:57 [INFO]: Epoch 046 - training loss: 0.1674, validation loss: 0.1743
2024-06-01 23:00:27 [INFO]: Epoch 047 - training loss: 0.1632, validation loss: 0.1642
2024-06-01 23:00:57 [INFO]: Epoch 048 - training loss: 0.1630, validation loss: 0.1648
2024-06-01 23:01:28 [INFO]: Epoch 049 - training loss: 0.1773, validation loss: 0.1603
2024-06-01 23:01:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 23:01:28 [INFO]: Finished training. The best model is from epoch#39.
2024-06-01 23:01:28 [INFO]: Saved the model to results_point_rate01/PeMS/CSDI_PeMS/round_1/20240601_T223641/CSDI.pypots
2024-06-01 23:06:28 [INFO]: Successfully saved to results_point_rate01/PeMS/CSDI_PeMS/round_1/imputation.pkl
2024-06-01 23:06:28 [INFO]: Round1 - CSDI on PeMS: MAE=0.2302, MSE=0.5306, MRE=0.2854
2024-06-01 23:06:28 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-01 23:06:28 [INFO]: Using the given device: cuda:0
2024-06-01 23:06:28 [INFO]: Model files will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_2/20240601_T230628
2024-06-01 23:06:28 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_2/20240601_T230628/tensorboard
2024-06-01 23:06:28 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-01 23:06:59 [INFO]: Epoch 001 - training loss: 0.8034, validation loss: 0.5115
2024-06-01 23:07:29 [INFO]: Epoch 002 - training loss: 0.4445, validation loss: 0.4065
2024-06-01 23:07:59 [INFO]: Epoch 003 - training loss: 0.3474, validation loss: 0.3586
2024-06-01 23:08:30 [INFO]: Epoch 004 - training loss: 0.2857, validation loss: 0.3524
2024-06-01 23:09:00 [INFO]: Epoch 005 - training loss: 0.3065, validation loss: 0.3094
2024-06-01 23:09:30 [INFO]: Epoch 006 - training loss: 0.2695, validation loss: 0.3066
2024-06-01 23:10:00 [INFO]: Epoch 007 - training loss: 0.2756, validation loss: 0.2908
2024-06-01 23:10:31 [INFO]: Epoch 008 - training loss: 0.2663, validation loss: 0.2923
2024-06-01 23:11:01 [INFO]: Epoch 009 - training loss: 0.2552, validation loss: 0.2595
2024-06-01 23:11:31 [INFO]: Epoch 010 - training loss: 0.2444, validation loss: 0.2620
2024-06-01 23:12:02 [INFO]: Epoch 011 - training loss: 0.2656, validation loss: 0.2882
2024-06-01 23:12:32 [INFO]: Epoch 012 - training loss: 0.2622, validation loss: 0.2470
2024-06-01 23:13:02 [INFO]: Epoch 013 - training loss: 0.2006, validation loss: 0.2444
2024-06-01 23:13:33 [INFO]: Epoch 014 - training loss: 0.2355, validation loss: 0.2168
2024-06-01 23:14:03 [INFO]: Epoch 015 - training loss: 0.2155, validation loss: 0.2127
2024-06-01 23:14:33 [INFO]: Epoch 016 - training loss: 0.2268, validation loss: 0.2170
2024-06-01 23:15:04 [INFO]: Epoch 017 - training loss: 0.1915, validation loss: 0.1987
2024-06-01 23:15:34 [INFO]: Epoch 018 - training loss: 0.1836, validation loss: 0.1945
2024-06-01 23:16:04 [INFO]: Epoch 019 - training loss: 0.1647, validation loss: 0.1964
2024-06-01 23:16:34 [INFO]: Epoch 020 - training loss: 0.1756, validation loss: 0.1892
2024-06-01 23:17:05 [INFO]: Epoch 021 - training loss: 0.1832, validation loss: 0.1822
2024-06-01 23:17:35 [INFO]: Epoch 022 - training loss: 0.1780, validation loss: 0.2018
2024-06-01 23:18:05 [INFO]: Epoch 023 - training loss: 0.1818, validation loss: 0.1889
2024-06-01 23:18:36 [INFO]: Epoch 024 - training loss: 0.2216, validation loss: 0.1803
2024-06-01 23:19:06 [INFO]: Epoch 025 - training loss: 0.1605, validation loss: 0.2035
2024-06-01 23:19:36 [INFO]: Epoch 026 - training loss: 0.1760, validation loss: 0.1854
2024-06-01 23:20:07 [INFO]: Epoch 027 - training loss: 0.1576, validation loss: 0.1743
2024-06-01 23:20:37 [INFO]: Epoch 028 - training loss: 0.1871, validation loss: 0.1781
2024-06-01 23:21:07 [INFO]: Epoch 029 - training loss: 0.2070, validation loss: 0.1765
2024-06-01 23:21:38 [INFO]: Epoch 030 - training loss: 0.2081, validation loss: 0.1734
2024-06-01 23:22:08 [INFO]: Epoch 031 - training loss: 0.1547, validation loss: 0.1866
2024-06-01 23:22:38 [INFO]: Epoch 032 - training loss: 0.1695, validation loss: 0.1780
2024-06-01 23:23:09 [INFO]: Epoch 033 - training loss: 0.1623, validation loss: 0.1778
2024-06-01 23:23:39 [INFO]: Epoch 034 - training loss: 0.1832, validation loss: 0.1776
2024-06-01 23:24:09 [INFO]: Epoch 035 - training loss: 0.1503, validation loss: 0.1625
2024-06-01 23:24:40 [INFO]: Epoch 036 - training loss: 0.1589, validation loss: 0.1650
2024-06-01 23:25:10 [INFO]: Epoch 037 - training loss: 0.1518, validation loss: 0.1845
2024-06-01 23:25:40 [INFO]: Epoch 038 - training loss: 0.1854, validation loss: 0.1678
2024-06-01 23:26:11 [INFO]: Epoch 039 - training loss: 0.1486, validation loss: 0.1726
2024-06-01 23:26:41 [INFO]: Epoch 040 - training loss: 0.1626, validation loss: 0.1914
2024-06-01 23:27:11 [INFO]: Epoch 041 - training loss: 0.1846, validation loss: 0.1852
2024-06-01 23:27:42 [INFO]: Epoch 042 - training loss: 0.1714, validation loss: 0.1668
2024-06-01 23:28:12 [INFO]: Epoch 043 - training loss: 0.1345, validation loss: 0.1632
2024-06-01 23:28:42 [INFO]: Epoch 044 - training loss: 0.1675, validation loss: 0.1622
2024-06-01 23:29:13 [INFO]: Epoch 045 - training loss: 0.1805, validation loss: 0.1710
2024-06-01 23:29:43 [INFO]: Epoch 046 - training loss: 0.1313, validation loss: 0.1625
2024-06-01 23:30:13 [INFO]: Epoch 047 - training loss: 0.1728, validation loss: 0.1617
2024-06-01 23:30:43 [INFO]: Epoch 048 - training loss: 0.1354, validation loss: 0.1568
2024-06-01 23:31:14 [INFO]: Epoch 049 - training loss: 0.1558, validation loss: 0.1550
2024-06-01 23:31:44 [INFO]: Epoch 050 - training loss: 0.1570, validation loss: 0.1723
2024-06-01 23:32:14 [INFO]: Epoch 051 - training loss: 0.1687, validation loss: 0.1568
2024-06-01 23:32:45 [INFO]: Epoch 052 - training loss: 0.1462, validation loss: 0.1554
2024-06-01 23:33:15 [INFO]: Epoch 053 - training loss: 0.1231, validation loss: 0.1520
2024-06-01 23:33:45 [INFO]: Epoch 054 - training loss: 0.1602, validation loss: 0.1561
2024-06-01 23:34:16 [INFO]: Epoch 055 - training loss: 0.1665, validation loss: 0.1522
2024-06-01 23:34:46 [INFO]: Epoch 056 - training loss: 0.1513, validation loss: 0.1532
2024-06-01 23:35:16 [INFO]: Epoch 057 - training loss: 0.1407, validation loss: 0.1532
2024-06-01 23:35:47 [INFO]: Epoch 058 - training loss: 0.1463, validation loss: 0.1546
2024-06-01 23:36:17 [INFO]: Epoch 059 - training loss: 0.1690, validation loss: 0.1545
2024-06-01 23:36:48 [INFO]: Epoch 060 - training loss: 0.1954, validation loss: 0.1598
2024-06-01 23:37:18 [INFO]: Epoch 061 - training loss: 0.1712, validation loss: 0.1625
2024-06-01 23:37:48 [INFO]: Epoch 062 - training loss: 0.1594, validation loss: 0.1564
2024-06-01 23:38:18 [INFO]: Epoch 063 - training loss: 0.1485, validation loss: 0.1533
2024-06-01 23:38:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-01 23:38:18 [INFO]: Finished training. The best model is from epoch#53.
2024-06-01 23:38:18 [INFO]: Saved the model to results_point_rate01/PeMS/CSDI_PeMS/round_2/20240601_T230628/CSDI.pypots
2024-06-01 23:43:19 [INFO]: Successfully saved to results_point_rate01/PeMS/CSDI_PeMS/round_2/imputation.pkl
2024-06-01 23:43:19 [INFO]: Round2 - CSDI on PeMS: MAE=0.2255, MSE=0.6522, MRE=0.2796
2024-06-01 23:43:19 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-01 23:43:19 [INFO]: Using the given device: cuda:0
2024-06-01 23:43:19 [INFO]: Model files will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_3/20240601_T234319
2024-06-01 23:43:19 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_3/20240601_T234319/tensorboard
2024-06-01 23:43:19 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-01 23:43:49 [INFO]: Epoch 001 - training loss: 0.6788, validation loss: 0.4764
2024-06-01 23:44:20 [INFO]: Epoch 002 - training loss: 0.4166, validation loss: 0.4298
2024-06-01 23:44:50 [INFO]: Epoch 003 - training loss: 0.3312, validation loss: 0.3623
2024-06-01 23:45:21 [INFO]: Epoch 004 - training loss: 0.3243, validation loss: 0.3219
2024-06-01 23:45:51 [INFO]: Epoch 005 - training loss: 0.2735, validation loss: 0.3297
2024-06-01 23:46:21 [INFO]: Epoch 006 - training loss: 0.2817, validation loss: 0.3010
2024-06-01 23:46:52 [INFO]: Epoch 007 - training loss: 0.2688, validation loss: 0.2902
2024-06-01 23:47:22 [INFO]: Epoch 008 - training loss: 0.2728, validation loss: 0.2844
2024-06-01 23:47:53 [INFO]: Epoch 009 - training loss: 0.2422, validation loss: 0.2635
2024-06-01 23:48:23 [INFO]: Epoch 010 - training loss: 0.2140, validation loss: 0.2534
2024-06-01 23:48:54 [INFO]: Epoch 011 - training loss: 0.2203, validation loss: 0.2386
2024-06-01 23:49:24 [INFO]: Epoch 012 - training loss: 0.2080, validation loss: 0.2198
2024-06-01 23:49:54 [INFO]: Epoch 013 - training loss: 0.1987, validation loss: 0.2195
2024-06-01 23:50:25 [INFO]: Epoch 014 - training loss: 0.1845, validation loss: 0.2154
2024-06-01 23:50:55 [INFO]: Epoch 015 - training loss: 0.1993, validation loss: 0.2105
2024-06-01 23:51:26 [INFO]: Epoch 016 - training loss: 0.1957, validation loss: 0.1908
2024-06-01 23:51:56 [INFO]: Epoch 017 - training loss: 0.2019, validation loss: 0.1975
2024-06-01 23:52:27 [INFO]: Epoch 018 - training loss: 0.2135, validation loss: 0.1949
2024-06-01 23:52:57 [INFO]: Epoch 019 - training loss: 0.1756, validation loss: 0.1846
2024-06-01 23:53:28 [INFO]: Epoch 020 - training loss: 0.1788, validation loss: 0.1865
2024-06-01 23:53:58 [INFO]: Epoch 021 - training loss: 0.1638, validation loss: 0.1862
2024-06-01 23:54:28 [INFO]: Epoch 022 - training loss: 0.1536, validation loss: 0.1832
2024-06-01 23:54:59 [INFO]: Epoch 023 - training loss: 0.1858, validation loss: 0.1706
2024-06-01 23:55:29 [INFO]: Epoch 024 - training loss: 0.1738, validation loss: 0.1743
2024-06-01 23:56:00 [INFO]: Epoch 025 - training loss: 0.1520, validation loss: 0.1742
2024-06-01 23:56:30 [INFO]: Epoch 026 - training loss: 0.1720, validation loss: 0.1668
2024-06-01 23:57:00 [INFO]: Epoch 027 - training loss: 0.1686, validation loss: 0.1716
2024-06-01 23:57:31 [INFO]: Epoch 028 - training loss: 0.1542, validation loss: 0.1835
2024-06-01 23:58:01 [INFO]: Epoch 029 - training loss: 0.1659, validation loss: 0.1659
2024-06-01 23:58:32 [INFO]: Epoch 030 - training loss: 0.1694, validation loss: 0.1663
2024-06-01 23:59:02 [INFO]: Epoch 031 - training loss: 0.1780, validation loss: 0.1686
2024-06-01 23:59:32 [INFO]: Epoch 032 - training loss: 0.1661, validation loss: 0.1657
2024-06-02 00:00:03 [INFO]: Epoch 033 - training loss: 0.1779, validation loss: 0.1609
2024-06-02 00:00:33 [INFO]: Epoch 034 - training loss: 0.1406, validation loss: 0.1690
2024-06-02 00:01:03 [INFO]: Epoch 035 - training loss: 0.1426, validation loss: 0.1614
2024-06-02 00:01:34 [INFO]: Epoch 036 - training loss: 0.1931, validation loss: 0.1617
2024-06-02 00:02:04 [INFO]: Epoch 037 - training loss: 0.1711, validation loss: 0.1682
2024-06-02 00:02:35 [INFO]: Epoch 038 - training loss: 0.1584, validation loss: 0.1700
2024-06-02 00:03:05 [INFO]: Epoch 039 - training loss: 0.1725, validation loss: 0.1636
2024-06-02 00:03:35 [INFO]: Epoch 040 - training loss: 0.1459, validation loss: 0.1620
2024-06-02 00:04:06 [INFO]: Epoch 041 - training loss: 0.1764, validation loss: 0.1566
2024-06-02 00:04:36 [INFO]: Epoch 042 - training loss: 0.1664, validation loss: 0.1664
2024-06-02 00:05:07 [INFO]: Epoch 043 - training loss: 0.1422, validation loss: 0.1580
2024-06-02 00:05:37 [INFO]: Epoch 044 - training loss: 0.1532, validation loss: 0.1556
2024-06-02 00:06:07 [INFO]: Epoch 045 - training loss: 0.1597, validation loss: 0.1521
2024-06-02 00:06:38 [INFO]: Epoch 046 - training loss: 0.1493, validation loss: 0.1560
2024-06-02 00:07:08 [INFO]: Epoch 047 - training loss: 0.1372, validation loss: 0.1524
2024-06-02 00:07:39 [INFO]: Epoch 048 - training loss: 0.1357, validation loss: 0.1589
2024-06-02 00:08:09 [INFO]: Epoch 049 - training loss: 0.1747, validation loss: 0.1632
2024-06-02 00:08:40 [INFO]: Epoch 050 - training loss: 0.1519, validation loss: 0.1619
2024-06-02 00:09:10 [INFO]: Epoch 051 - training loss: 0.1526, validation loss: 0.1555
2024-06-02 00:09:40 [INFO]: Epoch 052 - training loss: 0.1342, validation loss: 0.1541
2024-06-02 00:10:11 [INFO]: Epoch 053 - training loss: 0.1517, validation loss: 0.1562
2024-06-02 00:10:41 [INFO]: Epoch 054 - training loss: 0.1303, validation loss: 0.1546
2024-06-02 00:11:12 [INFO]: Epoch 055 - training loss: 0.1544, validation loss: 0.1508
2024-06-02 00:11:42 [INFO]: Epoch 056 - training loss: 0.1649, validation loss: 0.1547
2024-06-02 00:12:12 [INFO]: Epoch 057 - training loss: 0.1564, validation loss: 0.1568
2024-06-02 00:12:43 [INFO]: Epoch 058 - training loss: 0.1580, validation loss: 0.1663
2024-06-02 00:13:13 [INFO]: Epoch 059 - training loss: 0.1714, validation loss: 0.1542
2024-06-02 00:13:44 [INFO]: Epoch 060 - training loss: 0.1552, validation loss: 0.1491
2024-06-02 00:14:14 [INFO]: Epoch 061 - training loss: 0.1537, validation loss: 0.1497
2024-06-02 00:14:45 [INFO]: Epoch 062 - training loss: 0.1864, validation loss: 0.1495
2024-06-02 00:15:15 [INFO]: Epoch 063 - training loss: 0.1352, validation loss: 0.1482
2024-06-02 00:15:45 [INFO]: Epoch 064 - training loss: 0.1787, validation loss: 0.1566
2024-06-02 00:16:16 [INFO]: Epoch 065 - training loss: 0.1553, validation loss: 0.1560
2024-06-02 00:16:46 [INFO]: Epoch 066 - training loss: 0.1667, validation loss: 0.1509
2024-06-02 00:17:17 [INFO]: Epoch 067 - training loss: 0.1579, validation loss: 0.1505
2024-06-02 00:17:47 [INFO]: Epoch 068 - training loss: 0.1611, validation loss: 0.1536
2024-06-02 00:18:18 [INFO]: Epoch 069 - training loss: 0.1550, validation loss: 0.1479
2024-06-02 00:18:48 [INFO]: Epoch 070 - training loss: 0.1592, validation loss: 0.1477
2024-06-02 00:19:18 [INFO]: Epoch 071 - training loss: 0.1467, validation loss: 0.1523
2024-06-02 00:19:49 [INFO]: Epoch 072 - training loss: 0.1464, validation loss: 0.1527
2024-06-02 00:20:19 [INFO]: Epoch 073 - training loss: 0.1491, validation loss: 0.1510
2024-06-02 00:20:50 [INFO]: Epoch 074 - training loss: 0.1271, validation loss: 0.1453
2024-06-02 00:21:20 [INFO]: Epoch 075 - training loss: 0.1409, validation loss: 0.1429
2024-06-02 00:21:50 [INFO]: Epoch 076 - training loss: 0.1444, validation loss: 0.1659
2024-06-02 00:22:21 [INFO]: Epoch 077 - training loss: 0.1612, validation loss: 0.1551
2024-06-02 00:22:51 [INFO]: Epoch 078 - training loss: 0.1436, validation loss: 0.1485
2024-06-02 00:23:22 [INFO]: Epoch 079 - training loss: 0.1574, validation loss: 0.1430
2024-06-02 00:23:52 [INFO]: Epoch 080 - training loss: 0.1480, validation loss: 0.1433
2024-06-02 00:24:23 [INFO]: Epoch 081 - training loss: 0.1318, validation loss: 0.1456
2024-06-02 00:24:53 [INFO]: Epoch 082 - training loss: 0.1210, validation loss: 0.1431
2024-06-02 00:25:22 [INFO]: Epoch 083 - training loss: 0.1337, validation loss: 0.1415
2024-06-02 00:25:47 [INFO]: Epoch 084 - training loss: 0.1254, validation loss: 0.1391
2024-06-02 00:26:11 [INFO]: Epoch 085 - training loss: 0.1425, validation loss: 0.1398
2024-06-02 00:26:35 [INFO]: Epoch 086 - training loss: 0.1246, validation loss: 0.1366
2024-06-02 00:26:59 [INFO]: Epoch 087 - training loss: 0.1421, validation loss: 0.1337
2024-06-02 00:27:24 [INFO]: Epoch 088 - training loss: 0.1237, validation loss: 0.1375
2024-06-02 00:27:48 [INFO]: Epoch 089 - training loss: 0.1315, validation loss: 0.1396
2024-06-02 00:28:12 [INFO]: Epoch 090 - training loss: 0.1680, validation loss: 0.1354
2024-06-02 00:28:37 [INFO]: Epoch 091 - training loss: 0.1100, validation loss: 0.1355
2024-06-02 00:29:01 [INFO]: Epoch 092 - training loss: 0.1244, validation loss: 0.1352
2024-06-02 00:29:25 [INFO]: Epoch 093 - training loss: 0.1340, validation loss: 0.1502
2024-06-02 00:29:49 [INFO]: Epoch 094 - training loss: 0.1314, validation loss: 0.1445
2024-06-02 00:30:14 [INFO]: Epoch 095 - training loss: 0.1262, validation loss: 0.1387
2024-06-02 00:30:38 [INFO]: Epoch 096 - training loss: 0.1217, validation loss: 0.1409
2024-06-02 00:31:02 [INFO]: Epoch 097 - training loss: 0.1480, validation loss: 0.1406
2024-06-02 00:31:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 00:31:02 [INFO]: Finished training. The best model is from epoch#87.
2024-06-02 00:31:02 [INFO]: Saved the model to results_point_rate01/PeMS/CSDI_PeMS/round_3/20240601_T234319/CSDI.pypots
2024-06-02 00:35:04 [INFO]: Successfully saved to results_point_rate01/PeMS/CSDI_PeMS/round_3/imputation.pkl
2024-06-02 00:35:04 [INFO]: Round3 - CSDI on PeMS: MAE=0.2335, MSE=3.4007, MRE=0.2894
2024-06-02 00:35:04 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 00:35:04 [INFO]: Using the given device: cuda:0
2024-06-02 00:35:04 [INFO]: Model files will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_4/20240602_T003504
2024-06-02 00:35:04 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/CSDI_PeMS/round_4/20240602_T003504/tensorboard
2024-06-02 00:35:04 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-02 00:35:29 [INFO]: Epoch 001 - training loss: 0.8443, validation loss: 0.5855
2024-06-02 00:35:53 [INFO]: Epoch 002 - training loss: 0.4592, validation loss: 0.3787
2024-06-02 00:36:17 [INFO]: Epoch 003 - training loss: 0.3102, validation loss: 0.3381
2024-06-02 00:36:41 [INFO]: Epoch 004 - training loss: 0.2811, validation loss: 0.3131
2024-06-02 00:37:05 [INFO]: Epoch 005 - training loss: 0.3085, validation loss: 0.2953
2024-06-02 00:37:30 [INFO]: Epoch 006 - training loss: 0.3011, validation loss: 0.2903
2024-06-02 00:37:54 [INFO]: Epoch 007 - training loss: 0.2650, validation loss: 0.2829
2024-06-02 00:38:18 [INFO]: Epoch 008 - training loss: 0.2623, validation loss: 0.2871
2024-06-02 00:38:42 [INFO]: Epoch 009 - training loss: 0.2725, validation loss: 0.2622
2024-06-02 00:39:07 [INFO]: Epoch 010 - training loss: 0.2331, validation loss: 0.2397
2024-06-02 00:39:31 [INFO]: Epoch 011 - training loss: 0.2307, validation loss: 0.2274
2024-06-02 00:39:55 [INFO]: Epoch 012 - training loss: 0.2275, validation loss: 0.2334
2024-06-02 00:40:19 [INFO]: Epoch 013 - training loss: 0.2417, validation loss: 0.2082
2024-06-02 00:40:43 [INFO]: Epoch 014 - training loss: 0.1855, validation loss: 0.2178
2024-06-02 00:41:08 [INFO]: Epoch 015 - training loss: 0.1984, validation loss: 0.2057
2024-06-02 00:41:32 [INFO]: Epoch 016 - training loss: 0.1766, validation loss: 0.1937
2024-06-02 00:41:56 [INFO]: Epoch 017 - training loss: 0.2222, validation loss: 0.1940
2024-06-02 00:42:20 [INFO]: Epoch 018 - training loss: 0.1986, validation loss: 0.2716
2024-06-02 00:42:45 [INFO]: Epoch 019 - training loss: 0.2399, validation loss: 0.2132
2024-06-02 00:43:09 [INFO]: Epoch 020 - training loss: 0.2251, validation loss: 0.2042
2024-06-02 00:43:33 [INFO]: Epoch 021 - training loss: 0.1742, validation loss: 0.1997
2024-06-02 00:43:57 [INFO]: Epoch 022 - training loss: 0.1814, validation loss: 0.1825
2024-06-02 00:44:22 [INFO]: Epoch 023 - training loss: 0.1991, validation loss: 0.1857
2024-06-02 00:44:46 [INFO]: Epoch 024 - training loss: 0.1853, validation loss: 0.1759
2024-06-02 00:45:10 [INFO]: Epoch 025 - training loss: 0.2002, validation loss: 0.1730
2024-06-02 00:45:34 [INFO]: Epoch 026 - training loss: 0.1767, validation loss: 0.1735
2024-06-02 00:45:59 [INFO]: Epoch 027 - training loss: 0.1669, validation loss: 0.1747
2024-06-02 00:46:23 [INFO]: Epoch 028 - training loss: 0.1599, validation loss: 0.1742
2024-06-02 00:46:47 [INFO]: Epoch 029 - training loss: 0.1722, validation loss: 0.1708
2024-06-02 00:47:11 [INFO]: Epoch 030 - training loss: 0.1594, validation loss: 0.1688
2024-06-02 00:47:35 [INFO]: Epoch 031 - training loss: 0.1584, validation loss: 0.1662
2024-06-02 00:48:00 [INFO]: Epoch 032 - training loss: 0.2057, validation loss: 0.1700
2024-06-02 00:48:24 [INFO]: Epoch 033 - training loss: 0.1895, validation loss: 0.1707
2024-06-02 00:48:48 [INFO]: Epoch 034 - training loss: 0.1620, validation loss: 0.1678
2024-06-02 00:49:12 [INFO]: Epoch 035 - training loss: 0.1672, validation loss: 0.1744
2024-06-02 00:49:36 [INFO]: Epoch 036 - training loss: 0.1848, validation loss: 0.1665
2024-06-02 00:50:01 [INFO]: Epoch 037 - training loss: 0.1572, validation loss: 0.1643
2024-06-02 00:50:25 [INFO]: Epoch 038 - training loss: 0.1684, validation loss: 0.1639
2024-06-02 00:50:49 [INFO]: Epoch 039 - training loss: 0.1686, validation loss: 0.1636
2024-06-02 00:51:13 [INFO]: Epoch 040 - training loss: 0.1769, validation loss: 0.1618
2024-06-02 00:51:37 [INFO]: Epoch 041 - training loss: 0.1465, validation loss: 0.1608
2024-06-02 00:52:02 [INFO]: Epoch 042 - training loss: 0.1681, validation loss: 0.1591
2024-06-02 00:52:26 [INFO]: Epoch 043 - training loss: 0.1671, validation loss: 0.1641
2024-06-02 00:52:50 [INFO]: Epoch 044 - training loss: 0.1816, validation loss: 0.1643
2024-06-02 00:53:14 [INFO]: Epoch 045 - training loss: 0.1812, validation loss: 0.1785
2024-06-02 00:53:39 [INFO]: Epoch 046 - training loss: 0.1650, validation loss: 0.1692
2024-06-02 00:54:03 [INFO]: Epoch 047 - training loss: 0.1422, validation loss: 0.1628
2024-06-02 00:54:27 [INFO]: Epoch 048 - training loss: 0.1656, validation loss: 0.1574
2024-06-02 00:54:51 [INFO]: Epoch 049 - training loss: 0.1635, validation loss: 0.1553
2024-06-02 00:55:15 [INFO]: Epoch 050 - training loss: 0.1460, validation loss: 0.1567
2024-06-02 00:55:40 [INFO]: Epoch 051 - training loss: 0.1705, validation loss: 0.1574
2024-06-02 00:56:04 [INFO]: Epoch 052 - training loss: 0.1696, validation loss: 0.1572
2024-06-02 00:56:28 [INFO]: Epoch 053 - training loss: 0.1738, validation loss: 0.1554
2024-06-02 00:56:52 [INFO]: Epoch 054 - training loss: 0.1493, validation loss: 0.1540
2024-06-02 00:57:16 [INFO]: Epoch 055 - training loss: 0.1703, validation loss: 0.1576
2024-06-02 00:57:41 [INFO]: Epoch 056 - training loss: 0.1796, validation loss: 0.1613
2024-06-02 00:58:05 [INFO]: Epoch 057 - training loss: 0.1620, validation loss: 0.1568
2024-06-02 00:58:29 [INFO]: Epoch 058 - training loss: 0.1685, validation loss: 0.1568
2024-06-02 00:58:53 [INFO]: Epoch 059 - training loss: 0.1619, validation loss: 0.1584
2024-06-02 00:59:18 [INFO]: Epoch 060 - training loss: 0.1346, validation loss: 0.1531
2024-06-02 00:59:42 [INFO]: Epoch 061 - training loss: 0.1562, validation loss: 0.1704
2024-06-02 01:00:06 [INFO]: Epoch 062 - training loss: 0.1354, validation loss: 0.1626
2024-06-02 01:00:30 [INFO]: Epoch 063 - training loss: 0.1438, validation loss: 0.1532
2024-06-02 01:00:54 [INFO]: Epoch 064 - training loss: 0.1559, validation loss: 0.1659
2024-06-02 01:01:19 [INFO]: Epoch 065 - training loss: 0.1653, validation loss: 0.1850
2024-06-02 01:01:43 [INFO]: Epoch 066 - training loss: 0.1363, validation loss: 0.1587
2024-06-02 01:02:07 [INFO]: Epoch 067 - training loss: 0.1541, validation loss: 0.1544
2024-06-02 01:02:31 [INFO]: Epoch 068 - training loss: 0.1616, validation loss: 0.1625
2024-06-02 01:02:55 [INFO]: Epoch 069 - training loss: 0.1439, validation loss: 0.1512
2024-06-02 01:03:20 [INFO]: Epoch 070 - training loss: 0.1503, validation loss: 0.1532
2024-06-02 01:03:44 [INFO]: Epoch 071 - training loss: 0.1710, validation loss: 0.1512
2024-06-02 01:04:08 [INFO]: Epoch 072 - training loss: 0.1265, validation loss: 0.1511
2024-06-02 01:04:32 [INFO]: Epoch 073 - training loss: 0.1530, validation loss: 0.1456
2024-06-02 01:04:57 [INFO]: Epoch 074 - training loss: 0.1437, validation loss: 0.1470
2024-06-02 01:05:21 [INFO]: Epoch 075 - training loss: 0.1416, validation loss: 0.1475
2024-06-02 01:05:45 [INFO]: Epoch 076 - training loss: 0.1460, validation loss: 0.1517
2024-06-02 01:06:09 [INFO]: Epoch 077 - training loss: 0.1499, validation loss: 0.1520
2024-06-02 01:06:33 [INFO]: Epoch 078 - training loss: 0.1550, validation loss: 0.1566
2024-06-02 01:06:58 [INFO]: Epoch 079 - training loss: 0.1236, validation loss: 0.1462
2024-06-02 01:07:22 [INFO]: Epoch 080 - training loss: 0.1247, validation loss: 0.1444
2024-06-02 01:07:46 [INFO]: Epoch 081 - training loss: 0.1388, validation loss: 0.1581
2024-06-02 01:08:10 [INFO]: Epoch 082 - training loss: 0.1548, validation loss: 0.1496
2024-06-02 01:08:34 [INFO]: Epoch 083 - training loss: 0.1467, validation loss: 0.1434
2024-06-02 01:08:59 [INFO]: Epoch 084 - training loss: 0.1441, validation loss: 0.1408
2024-06-02 01:09:23 [INFO]: Epoch 085 - training loss: 0.1508, validation loss: 0.1441
2024-06-02 01:09:47 [INFO]: Epoch 086 - training loss: 0.1577, validation loss: 0.1443
2024-06-02 01:10:11 [INFO]: Epoch 087 - training loss: 0.1529, validation loss: 0.1424
2024-06-02 01:10:35 [INFO]: Epoch 088 - training loss: 0.1258, validation loss: 0.1392
2024-06-02 01:11:00 [INFO]: Epoch 089 - training loss: 0.1420, validation loss: 0.1374
2024-06-02 01:11:24 [INFO]: Epoch 090 - training loss: 0.1404, validation loss: 0.1422
2024-06-02 01:11:48 [INFO]: Epoch 091 - training loss: 0.1352, validation loss: 0.1533
2024-06-02 01:12:12 [INFO]: Epoch 092 - training loss: 0.1412, validation loss: 0.1527
2024-06-02 01:12:36 [INFO]: Epoch 093 - training loss: 0.1306, validation loss: 0.1735
2024-06-02 01:13:01 [INFO]: Epoch 094 - training loss: 0.1561, validation loss: 0.1428
2024-06-02 01:13:25 [INFO]: Epoch 095 - training loss: 0.1454, validation loss: 0.1404
2024-06-02 01:13:49 [INFO]: Epoch 096 - training loss: 0.1251, validation loss: 0.1361
2024-06-02 01:14:13 [INFO]: Epoch 097 - training loss: 0.1127, validation loss: 0.1379
2024-06-02 01:14:38 [INFO]: Epoch 098 - training loss: 0.1269, validation loss: 0.1354
2024-06-02 01:15:02 [INFO]: Epoch 099 - training loss: 0.1385, validation loss: 0.1343
2024-06-02 01:15:26 [INFO]: Epoch 100 - training loss: 0.1192, validation loss: 0.1348
2024-06-02 01:15:26 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 01:15:26 [INFO]: Saved the model to results_point_rate01/PeMS/CSDI_PeMS/round_4/20240602_T003504/CSDI.pypots
2024-06-02 01:19:28 [INFO]: Successfully saved to results_point_rate01/PeMS/CSDI_PeMS/round_4/imputation.pkl
2024-06-02 01:19:28 [INFO]: Round4 - CSDI on PeMS: MAE=0.1785, MSE=0.5202, MRE=0.2212
2024-06-02 01:19:28 [INFO]: Done! Final results:
Averaged CSDI (n params: 207,873) on PeMS: MAE=0.2381 ± 0.046764148734972075, MSE=1.6037 ± 1.2790127388577228, MRE=0.2951 ± 0.05796882152439571, average inference time=277.12
