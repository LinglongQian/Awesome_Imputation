2024-06-02 01:26:44 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 01:26:44 [INFO]: Using the given device: cuda:0
2024-06-02 01:26:45 [INFO]: Model files will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_0/20240602_T012645
2024-06-02 01:26:45 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_0/20240602_T012645/tensorboard
2024-06-02 01:26:45 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 14,104,896
2024-06-02 01:26:49 [INFO]: Epoch 001 - training loss: 0.4955, validation loss: 0.5218
2024-06-02 01:26:50 [INFO]: Epoch 002 - training loss: 0.3004, validation loss: 0.4802
2024-06-02 01:26:51 [INFO]: Epoch 003 - training loss: 0.2735, validation loss: 0.4648
2024-06-02 01:26:52 [INFO]: Epoch 004 - training loss: 0.2563, validation loss: 0.4565
2024-06-02 01:26:53 [INFO]: Epoch 005 - training loss: 0.2477, validation loss: 0.4504
2024-06-02 01:26:54 [INFO]: Epoch 006 - training loss: 0.2381, validation loss: 0.4465
2024-06-02 01:26:56 [INFO]: Epoch 007 - training loss: 0.2283, validation loss: 0.4384
2024-06-02 01:26:57 [INFO]: Epoch 008 - training loss: 0.2198, validation loss: 0.4310
2024-06-02 01:26:58 [INFO]: Epoch 009 - training loss: 0.2127, validation loss: 0.4289
2024-06-02 01:26:59 [INFO]: Epoch 010 - training loss: 0.2088, validation loss: 0.4223
2024-06-02 01:27:00 [INFO]: Epoch 011 - training loss: 0.2034, validation loss: 0.4206
2024-06-02 01:27:01 [INFO]: Epoch 012 - training loss: 0.1999, validation loss: 0.4158
2024-06-02 01:27:03 [INFO]: Epoch 013 - training loss: 0.1946, validation loss: 0.4141
2024-06-02 01:27:04 [INFO]: Epoch 014 - training loss: 0.1882, validation loss: 0.4120
2024-06-02 01:27:05 [INFO]: Epoch 015 - training loss: 0.1853, validation loss: 0.4095
2024-06-02 01:27:06 [INFO]: Epoch 016 - training loss: 0.1817, validation loss: 0.4079
2024-06-02 01:27:07 [INFO]: Epoch 017 - training loss: 0.1801, validation loss: 0.4055
2024-06-02 01:27:08 [INFO]: Epoch 018 - training loss: 0.1742, validation loss: 0.4034
2024-06-02 01:27:09 [INFO]: Epoch 019 - training loss: 0.1727, validation loss: 0.4017
2024-06-02 01:27:11 [INFO]: Epoch 020 - training loss: 0.1676, validation loss: 0.4003
2024-06-02 01:27:12 [INFO]: Epoch 021 - training loss: 0.1657, validation loss: 0.3999
2024-06-02 01:27:13 [INFO]: Epoch 022 - training loss: 0.1617, validation loss: 0.3955
2024-06-02 01:27:14 [INFO]: Epoch 023 - training loss: 0.1585, validation loss: 0.3949
2024-06-02 01:27:15 [INFO]: Epoch 024 - training loss: 0.1564, validation loss: 0.3934
2024-06-02 01:27:16 [INFO]: Epoch 025 - training loss: 0.1548, validation loss: 0.3904
2024-06-02 01:27:18 [INFO]: Epoch 026 - training loss: 0.1513, validation loss: 0.3897
2024-06-02 01:27:19 [INFO]: Epoch 027 - training loss: 0.1498, validation loss: 0.3904
2024-06-02 01:27:20 [INFO]: Epoch 028 - training loss: 0.1471, validation loss: 0.3900
2024-06-02 01:27:21 [INFO]: Epoch 029 - training loss: 0.1454, validation loss: 0.3878
2024-06-02 01:27:22 [INFO]: Epoch 030 - training loss: 0.1434, validation loss: 0.3863
2024-06-02 01:27:23 [INFO]: Epoch 031 - training loss: 0.1388, validation loss: 0.3857
2024-06-02 01:27:24 [INFO]: Epoch 032 - training loss: 0.1382, validation loss: 0.3865
2024-06-02 01:27:26 [INFO]: Epoch 033 - training loss: 0.1349, validation loss: 0.3848
2024-06-02 01:27:27 [INFO]: Epoch 034 - training loss: 0.1334, validation loss: 0.3838
2024-06-02 01:27:28 [INFO]: Epoch 035 - training loss: 0.1314, validation loss: 0.3832
2024-06-02 01:27:29 [INFO]: Epoch 036 - training loss: 0.1311, validation loss: 0.3848
2024-06-02 01:27:30 [INFO]: Epoch 037 - training loss: 0.1282, validation loss: 0.3833
2024-06-02 01:27:31 [INFO]: Epoch 038 - training loss: 0.1255, validation loss: 0.3812
2024-06-02 01:27:32 [INFO]: Epoch 039 - training loss: 0.1250, validation loss: 0.3818
2024-06-02 01:27:34 [INFO]: Epoch 040 - training loss: 0.1234, validation loss: 0.3831
2024-06-02 01:27:35 [INFO]: Epoch 041 - training loss: 0.1223, validation loss: 0.3806
2024-06-02 01:27:36 [INFO]: Epoch 042 - training loss: 0.1202, validation loss: 0.3835
2024-06-02 01:27:37 [INFO]: Epoch 043 - training loss: 0.1197, validation loss: 0.3823
2024-06-02 01:27:38 [INFO]: Epoch 044 - training loss: 0.1163, validation loss: 0.3811
2024-06-02 01:27:39 [INFO]: Epoch 045 - training loss: 0.1150, validation loss: 0.3823
2024-06-02 01:27:40 [INFO]: Epoch 046 - training loss: 0.1149, validation loss: 0.3808
2024-06-02 01:27:41 [INFO]: Epoch 047 - training loss: 0.1139, validation loss: 0.3816
2024-06-02 01:27:43 [INFO]: Epoch 048 - training loss: 0.1114, validation loss: 0.3816
2024-06-02 01:27:44 [INFO]: Epoch 049 - training loss: 0.1099, validation loss: 0.3810
2024-06-02 01:27:45 [INFO]: Epoch 050 - training loss: 0.1099, validation loss: 0.3796
2024-06-02 01:27:46 [INFO]: Epoch 051 - training loss: 0.1079, validation loss: 0.3818
2024-06-02 01:27:47 [INFO]: Epoch 052 - training loss: 0.1059, validation loss: 0.3821
2024-06-02 01:27:48 [INFO]: Epoch 053 - training loss: 0.1052, validation loss: 0.3809
2024-06-02 01:27:49 [INFO]: Epoch 054 - training loss: 0.1034, validation loss: 0.3822
2024-06-02 01:27:50 [INFO]: Epoch 055 - training loss: 0.1030, validation loss: 0.3804
2024-06-02 01:27:52 [INFO]: Epoch 056 - training loss: 0.1019, validation loss: 0.3819
2024-06-02 01:27:53 [INFO]: Epoch 057 - training loss: 0.1005, validation loss: 0.3813
2024-06-02 01:27:54 [INFO]: Epoch 058 - training loss: 0.1005, validation loss: 0.3826
2024-06-02 01:27:55 [INFO]: Epoch 059 - training loss: 0.0988, validation loss: 0.3813
2024-06-02 01:27:56 [INFO]: Epoch 060 - training loss: 0.0972, validation loss: 0.3802
2024-06-02 01:27:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:27:56 [INFO]: Finished training. The best model is from epoch#50.
2024-06-02 01:27:56 [INFO]: Saved the model to results_point_rate01/PeMS/GRUD_PeMS/round_0/20240602_T012645/GRUD.pypots
2024-06-02 01:27:57 [INFO]: Successfully saved to results_point_rate01/PeMS/GRUD_PeMS/round_0/imputation.pkl
2024-06-02 01:27:57 [INFO]: Round0 - GRUD on PeMS: MAE=0.3562, MSE=0.5740, MRE=0.4415
2024-06-02 01:27:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 01:27:57 [INFO]: Using the given device: cuda:0
2024-06-02 01:27:57 [INFO]: Model files will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_1/20240602_T012757
2024-06-02 01:27:57 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_1/20240602_T012757/tensorboard
2024-06-02 01:27:57 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 14,104,896
2024-06-02 01:27:59 [INFO]: Epoch 001 - training loss: 0.4895, validation loss: 0.5211
2024-06-02 01:28:01 [INFO]: Epoch 002 - training loss: 0.3042, validation loss: 0.4804
2024-06-02 01:28:02 [INFO]: Epoch 003 - training loss: 0.2733, validation loss: 0.4633
2024-06-02 01:28:03 [INFO]: Epoch 004 - training loss: 0.2614, validation loss: 0.4553
2024-06-02 01:28:04 [INFO]: Epoch 005 - training loss: 0.2457, validation loss: 0.4474
2024-06-02 01:28:05 [INFO]: Epoch 006 - training loss: 0.2362, validation loss: 0.4419
2024-06-02 01:28:06 [INFO]: Epoch 007 - training loss: 0.2299, validation loss: 0.4409
2024-06-02 01:28:08 [INFO]: Epoch 008 - training loss: 0.2207, validation loss: 0.4352
2024-06-02 01:28:09 [INFO]: Epoch 009 - training loss: 0.2172, validation loss: 0.4298
2024-06-02 01:28:10 [INFO]: Epoch 010 - training loss: 0.2079, validation loss: 0.4262
2024-06-02 01:28:11 [INFO]: Epoch 011 - training loss: 0.2015, validation loss: 0.4243
2024-06-02 01:28:12 [INFO]: Epoch 012 - training loss: 0.2033, validation loss: 0.4208
2024-06-02 01:28:13 [INFO]: Epoch 013 - training loss: 0.1959, validation loss: 0.4172
2024-06-02 01:28:14 [INFO]: Epoch 014 - training loss: 0.1905, validation loss: 0.4141
2024-06-02 01:28:15 [INFO]: Epoch 015 - training loss: 0.1876, validation loss: 0.4121
2024-06-02 01:28:17 [INFO]: Epoch 016 - training loss: 0.1827, validation loss: 0.4111
2024-06-02 01:28:18 [INFO]: Epoch 017 - training loss: 0.1828, validation loss: 0.4091
2024-06-02 01:28:19 [INFO]: Epoch 018 - training loss: 0.1766, validation loss: 0.4066
2024-06-02 01:28:20 [INFO]: Epoch 019 - training loss: 0.1749, validation loss: 0.4043
2024-06-02 01:28:21 [INFO]: Epoch 020 - training loss: 0.1699, validation loss: 0.4035
2024-06-02 01:28:22 [INFO]: Epoch 021 - training loss: 0.1680, validation loss: 0.4012
2024-06-02 01:28:23 [INFO]: Epoch 022 - training loss: 0.1650, validation loss: 0.3995
2024-06-02 01:28:24 [INFO]: Epoch 023 - training loss: 0.1611, validation loss: 0.3981
2024-06-02 01:28:26 [INFO]: Epoch 024 - training loss: 0.1584, validation loss: 0.3981
2024-06-02 01:28:27 [INFO]: Epoch 025 - training loss: 0.1556, validation loss: 0.3957
2024-06-02 01:28:28 [INFO]: Epoch 026 - training loss: 0.1531, validation loss: 0.3947
2024-06-02 01:28:29 [INFO]: Epoch 027 - training loss: 0.1522, validation loss: 0.3964
2024-06-02 01:28:30 [INFO]: Epoch 028 - training loss: 0.1500, validation loss: 0.3944
2024-06-02 01:28:31 [INFO]: Epoch 029 - training loss: 0.1467, validation loss: 0.3951
2024-06-02 01:28:32 [INFO]: Epoch 030 - training loss: 0.1459, validation loss: 0.3915
2024-06-02 01:28:34 [INFO]: Epoch 031 - training loss: 0.1413, validation loss: 0.3916
2024-06-02 01:28:35 [INFO]: Epoch 032 - training loss: 0.1410, validation loss: 0.3890
2024-06-02 01:28:36 [INFO]: Epoch 033 - training loss: 0.1371, validation loss: 0.3905
2024-06-02 01:28:37 [INFO]: Epoch 034 - training loss: 0.1377, validation loss: 0.3881
2024-06-02 01:28:38 [INFO]: Epoch 035 - training loss: 0.1329, validation loss: 0.3886
2024-06-02 01:28:39 [INFO]: Epoch 036 - training loss: 0.1333, validation loss: 0.3885
2024-06-02 01:28:40 [INFO]: Epoch 037 - training loss: 0.1317, validation loss: 0.3890
2024-06-02 01:28:41 [INFO]: Epoch 038 - training loss: 0.1287, validation loss: 0.3879
2024-06-02 01:28:43 [INFO]: Epoch 039 - training loss: 0.1267, validation loss: 0.3889
2024-06-02 01:28:44 [INFO]: Epoch 040 - training loss: 0.1266, validation loss: 0.3887
2024-06-02 01:28:45 [INFO]: Epoch 041 - training loss: 0.1248, validation loss: 0.3889
2024-06-02 01:28:46 [INFO]: Epoch 042 - training loss: 0.1228, validation loss: 0.3894
2024-06-02 01:28:47 [INFO]: Epoch 043 - training loss: 0.1222, validation loss: 0.3860
2024-06-02 01:28:48 [INFO]: Epoch 044 - training loss: 0.1190, validation loss: 0.3869
2024-06-02 01:28:49 [INFO]: Epoch 045 - training loss: 0.1176, validation loss: 0.3869
2024-06-02 01:28:50 [INFO]: Epoch 046 - training loss: 0.1168, validation loss: 0.3873
2024-06-02 01:28:52 [INFO]: Epoch 047 - training loss: 0.1146, validation loss: 0.3857
2024-06-02 01:28:53 [INFO]: Epoch 048 - training loss: 0.1137, validation loss: 0.3868
2024-06-02 01:28:54 [INFO]: Epoch 049 - training loss: 0.1118, validation loss: 0.3852
2024-06-02 01:28:55 [INFO]: Epoch 050 - training loss: 0.1104, validation loss: 0.3844
2024-06-02 01:28:56 [INFO]: Epoch 051 - training loss: 0.1077, validation loss: 0.3895
2024-06-02 01:28:57 [INFO]: Epoch 052 - training loss: 0.1097, validation loss: 0.3867
2024-06-02 01:28:58 [INFO]: Epoch 053 - training loss: 0.1071, validation loss: 0.3876
2024-06-02 01:28:59 [INFO]: Epoch 054 - training loss: 0.1065, validation loss: 0.3899
2024-06-02 01:29:01 [INFO]: Epoch 055 - training loss: 0.1054, validation loss: 0.3874
2024-06-02 01:29:02 [INFO]: Epoch 056 - training loss: 0.1035, validation loss: 0.3868
2024-06-02 01:29:03 [INFO]: Epoch 057 - training loss: 0.1030, validation loss: 0.3846
2024-06-02 01:29:04 [INFO]: Epoch 058 - training loss: 0.1017, validation loss: 0.3857
2024-06-02 01:29:05 [INFO]: Epoch 059 - training loss: 0.1011, validation loss: 0.3862
2024-06-02 01:29:06 [INFO]: Epoch 060 - training loss: 0.0989, validation loss: 0.3880
2024-06-02 01:29:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:29:06 [INFO]: Finished training. The best model is from epoch#50.
2024-06-02 01:29:06 [INFO]: Saved the model to results_point_rate01/PeMS/GRUD_PeMS/round_1/20240602_T012757/GRUD.pypots
2024-06-02 01:29:07 [INFO]: Successfully saved to results_point_rate01/PeMS/GRUD_PeMS/round_1/imputation.pkl
2024-06-02 01:29:07 [INFO]: Round1 - GRUD on PeMS: MAE=0.3552, MSE=0.5809, MRE=0.4404
2024-06-02 01:29:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 01:29:07 [INFO]: Using the given device: cuda:0
2024-06-02 01:29:07 [INFO]: Model files will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_2/20240602_T012907
2024-06-02 01:29:07 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_2/20240602_T012907/tensorboard
2024-06-02 01:29:07 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 14,104,896
2024-06-02 01:29:10 [INFO]: Epoch 001 - training loss: 0.4865, validation loss: 0.5150
2024-06-02 01:29:11 [INFO]: Epoch 002 - training loss: 0.3009, validation loss: 0.4839
2024-06-02 01:29:12 [INFO]: Epoch 003 - training loss: 0.2745, validation loss: 0.4647
2024-06-02 01:29:13 [INFO]: Epoch 004 - training loss: 0.2569, validation loss: 0.4570
2024-06-02 01:29:14 [INFO]: Epoch 005 - training loss: 0.2454, validation loss: 0.4486
2024-06-02 01:29:15 [INFO]: Epoch 006 - training loss: 0.2353, validation loss: 0.4435
2024-06-02 01:29:17 [INFO]: Epoch 007 - training loss: 0.2290, validation loss: 0.4403
2024-06-02 01:29:18 [INFO]: Epoch 008 - training loss: 0.2214, validation loss: 0.4356
2024-06-02 01:29:19 [INFO]: Epoch 009 - training loss: 0.2157, validation loss: 0.4305
2024-06-02 01:29:20 [INFO]: Epoch 010 - training loss: 0.2082, validation loss: 0.4242
2024-06-02 01:29:21 [INFO]: Epoch 011 - training loss: 0.2062, validation loss: 0.4209
2024-06-02 01:29:22 [INFO]: Epoch 012 - training loss: 0.1967, validation loss: 0.4197
2024-06-02 01:29:23 [INFO]: Epoch 013 - training loss: 0.1964, validation loss: 0.4168
2024-06-02 01:29:24 [INFO]: Epoch 014 - training loss: 0.1909, validation loss: 0.4115
2024-06-02 01:29:26 [INFO]: Epoch 015 - training loss: 0.1849, validation loss: 0.4110
2024-06-02 01:29:27 [INFO]: Epoch 016 - training loss: 0.1830, validation loss: 0.4087
2024-06-02 01:29:28 [INFO]: Epoch 017 - training loss: 0.1806, validation loss: 0.4075
2024-06-02 01:29:29 [INFO]: Epoch 018 - training loss: 0.1735, validation loss: 0.4053
2024-06-02 01:29:30 [INFO]: Epoch 019 - training loss: 0.1727, validation loss: 0.4025
2024-06-02 01:29:31 [INFO]: Epoch 020 - training loss: 0.1694, validation loss: 0.4031
2024-06-02 01:29:33 [INFO]: Epoch 021 - training loss: 0.1696, validation loss: 0.4005
2024-06-02 01:29:34 [INFO]: Epoch 022 - training loss: 0.1641, validation loss: 0.3981
2024-06-02 01:29:35 [INFO]: Epoch 023 - training loss: 0.1619, validation loss: 0.3997
2024-06-02 01:29:36 [INFO]: Epoch 024 - training loss: 0.1599, validation loss: 0.3964
2024-06-02 01:29:37 [INFO]: Epoch 025 - training loss: 0.1571, validation loss: 0.3967
2024-06-02 01:29:38 [INFO]: Epoch 026 - training loss: 0.1551, validation loss: 0.3972
2024-06-02 01:29:39 [INFO]: Epoch 027 - training loss: 0.1525, validation loss: 0.3948
2024-06-02 01:29:41 [INFO]: Epoch 028 - training loss: 0.1508, validation loss: 0.3918
2024-06-02 01:29:41 [INFO]: Epoch 029 - training loss: 0.1476, validation loss: 0.3915
2024-06-02 01:29:42 [INFO]: Epoch 030 - training loss: 0.1437, validation loss: 0.3902
2024-06-02 01:29:43 [INFO]: Epoch 031 - training loss: 0.1392, validation loss: 0.3884
2024-06-02 01:29:44 [INFO]: Epoch 032 - training loss: 0.1398, validation loss: 0.3876
2024-06-02 01:29:45 [INFO]: Epoch 033 - training loss: 0.1378, validation loss: 0.3896
2024-06-02 01:29:46 [INFO]: Epoch 034 - training loss: 0.1341, validation loss: 0.3881
2024-06-02 01:29:47 [INFO]: Epoch 035 - training loss: 0.1337, validation loss: 0.3870
2024-06-02 01:29:48 [INFO]: Epoch 036 - training loss: 0.1329, validation loss: 0.3864
2024-06-02 01:29:49 [INFO]: Epoch 037 - training loss: 0.1310, validation loss: 0.3880
2024-06-02 01:29:50 [INFO]: Epoch 038 - training loss: 0.1284, validation loss: 0.3872
2024-06-02 01:29:50 [INFO]: Epoch 039 - training loss: 0.1276, validation loss: 0.3875
2024-06-02 01:29:51 [INFO]: Epoch 040 - training loss: 0.1239, validation loss: 0.3866
2024-06-02 01:29:52 [INFO]: Epoch 041 - training loss: 0.1234, validation loss: 0.3857
2024-06-02 01:29:53 [INFO]: Epoch 042 - training loss: 0.1222, validation loss: 0.3855
2024-06-02 01:29:54 [INFO]: Epoch 043 - training loss: 0.1189, validation loss: 0.3863
2024-06-02 01:29:55 [INFO]: Epoch 044 - training loss: 0.1188, validation loss: 0.3843
2024-06-02 01:29:56 [INFO]: Epoch 045 - training loss: 0.1186, validation loss: 0.3856
2024-06-02 01:29:57 [INFO]: Epoch 046 - training loss: 0.1165, validation loss: 0.3856
2024-06-02 01:29:58 [INFO]: Epoch 047 - training loss: 0.1148, validation loss: 0.3837
2024-06-02 01:29:59 [INFO]: Epoch 048 - training loss: 0.1121, validation loss: 0.3840
2024-06-02 01:30:00 [INFO]: Epoch 049 - training loss: 0.1120, validation loss: 0.3854
2024-06-02 01:30:01 [INFO]: Epoch 050 - training loss: 0.1104, validation loss: 0.3854
2024-06-02 01:30:02 [INFO]: Epoch 051 - training loss: 0.1096, validation loss: 0.3866
2024-06-02 01:30:02 [INFO]: Epoch 052 - training loss: 0.1084, validation loss: 0.3852
2024-06-02 01:30:03 [INFO]: Epoch 053 - training loss: 0.1064, validation loss: 0.3860
2024-06-02 01:30:04 [INFO]: Epoch 054 - training loss: 0.1052, validation loss: 0.3856
2024-06-02 01:30:05 [INFO]: Epoch 055 - training loss: 0.1050, validation loss: 0.3845
2024-06-02 01:30:06 [INFO]: Epoch 056 - training loss: 0.1026, validation loss: 0.3847
2024-06-02 01:30:07 [INFO]: Epoch 057 - training loss: 0.1019, validation loss: 0.3839
2024-06-02 01:30:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:30:07 [INFO]: Finished training. The best model is from epoch#47.
2024-06-02 01:30:07 [INFO]: Saved the model to results_point_rate01/PeMS/GRUD_PeMS/round_2/20240602_T012907/GRUD.pypots
2024-06-02 01:30:07 [INFO]: Successfully saved to results_point_rate01/PeMS/GRUD_PeMS/round_2/imputation.pkl
2024-06-02 01:30:07 [INFO]: Round2 - GRUD on PeMS: MAE=0.3514, MSE=0.5762, MRE=0.4356
2024-06-02 01:30:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 01:30:07 [INFO]: Using the given device: cuda:0
2024-06-02 01:30:08 [INFO]: Model files will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_3/20240602_T013007
2024-06-02 01:30:08 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_3/20240602_T013007/tensorboard
2024-06-02 01:30:08 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 14,104,896
2024-06-02 01:30:10 [INFO]: Epoch 001 - training loss: 0.4889, validation loss: 0.5177
2024-06-02 01:30:11 [INFO]: Epoch 002 - training loss: 0.3033, validation loss: 0.4865
2024-06-02 01:30:11 [INFO]: Epoch 003 - training loss: 0.2708, validation loss: 0.4669
2024-06-02 01:30:12 [INFO]: Epoch 004 - training loss: 0.2572, validation loss: 0.4551
2024-06-02 01:30:13 [INFO]: Epoch 005 - training loss: 0.2435, validation loss: 0.4495
2024-06-02 01:30:14 [INFO]: Epoch 006 - training loss: 0.2350, validation loss: 0.4422
2024-06-02 01:30:15 [INFO]: Epoch 007 - training loss: 0.2258, validation loss: 0.4383
2024-06-02 01:30:16 [INFO]: Epoch 008 - training loss: 0.2204, validation loss: 0.4317
2024-06-02 01:30:17 [INFO]: Epoch 009 - training loss: 0.2142, validation loss: 0.4286
2024-06-02 01:30:18 [INFO]: Epoch 010 - training loss: 0.2070, validation loss: 0.4247
2024-06-02 01:30:19 [INFO]: Epoch 011 - training loss: 0.2005, validation loss: 0.4184
2024-06-02 01:30:19 [INFO]: Epoch 012 - training loss: 0.1999, validation loss: 0.4157
2024-06-02 01:30:21 [INFO]: Epoch 013 - training loss: 0.1953, validation loss: 0.4173
2024-06-02 01:30:21 [INFO]: Epoch 014 - training loss: 0.1884, validation loss: 0.4125
2024-06-02 01:30:22 [INFO]: Epoch 015 - training loss: 0.1868, validation loss: 0.4105
2024-06-02 01:30:23 [INFO]: Epoch 016 - training loss: 0.1834, validation loss: 0.4081
2024-06-02 01:30:24 [INFO]: Epoch 017 - training loss: 0.1779, validation loss: 0.4092
2024-06-02 01:30:25 [INFO]: Epoch 018 - training loss: 0.1734, validation loss: 0.4036
2024-06-02 01:30:26 [INFO]: Epoch 019 - training loss: 0.1698, validation loss: 0.4024
2024-06-02 01:30:27 [INFO]: Epoch 020 - training loss: 0.1697, validation loss: 0.4018
2024-06-02 01:30:28 [INFO]: Epoch 021 - training loss: 0.1653, validation loss: 0.4005
2024-06-02 01:30:29 [INFO]: Epoch 022 - training loss: 0.1639, validation loss: 0.3966
2024-06-02 01:30:30 [INFO]: Epoch 023 - training loss: 0.1590, validation loss: 0.3948
2024-06-02 01:30:31 [INFO]: Epoch 024 - training loss: 0.1549, validation loss: 0.3961
2024-06-02 01:30:32 [INFO]: Epoch 025 - training loss: 0.1533, validation loss: 0.3949
2024-06-02 01:30:32 [INFO]: Epoch 026 - training loss: 0.1516, validation loss: 0.3931
2024-06-02 01:30:33 [INFO]: Epoch 027 - training loss: 0.1504, validation loss: 0.3935
2024-06-02 01:30:34 [INFO]: Epoch 028 - training loss: 0.1474, validation loss: 0.3935
2024-06-02 01:30:35 [INFO]: Epoch 029 - training loss: 0.1464, validation loss: 0.3892
2024-06-02 01:30:36 [INFO]: Epoch 030 - training loss: 0.1421, validation loss: 0.3912
2024-06-02 01:30:37 [INFO]: Epoch 031 - training loss: 0.1414, validation loss: 0.3890
2024-06-02 01:30:38 [INFO]: Epoch 032 - training loss: 0.1396, validation loss: 0.3894
2024-06-02 01:30:39 [INFO]: Epoch 033 - training loss: 0.1359, validation loss: 0.3889
2024-06-02 01:30:40 [INFO]: Epoch 034 - training loss: 0.1335, validation loss: 0.3883
2024-06-02 01:30:41 [INFO]: Epoch 035 - training loss: 0.1303, validation loss: 0.3877
2024-06-02 01:30:42 [INFO]: Epoch 036 - training loss: 0.1303, validation loss: 0.3862
2024-06-02 01:30:43 [INFO]: Epoch 037 - training loss: 0.1282, validation loss: 0.3869
2024-06-02 01:30:44 [INFO]: Epoch 038 - training loss: 0.1262, validation loss: 0.3884
2024-06-02 01:30:45 [INFO]: Epoch 039 - training loss: 0.1252, validation loss: 0.3876
2024-06-02 01:30:46 [INFO]: Epoch 040 - training loss: 0.1236, validation loss: 0.3838
2024-06-02 01:30:46 [INFO]: Epoch 041 - training loss: 0.1214, validation loss: 0.3834
2024-06-02 01:30:47 [INFO]: Epoch 042 - training loss: 0.1199, validation loss: 0.3846
2024-06-02 01:30:48 [INFO]: Epoch 043 - training loss: 0.1186, validation loss: 0.3854
2024-06-02 01:30:49 [INFO]: Epoch 044 - training loss: 0.1154, validation loss: 0.3850
2024-06-02 01:30:50 [INFO]: Epoch 045 - training loss: 0.1147, validation loss: 0.3855
2024-06-02 01:30:51 [INFO]: Epoch 046 - training loss: 0.1141, validation loss: 0.3847
2024-06-02 01:30:52 [INFO]: Epoch 047 - training loss: 0.1142, validation loss: 0.3869
2024-06-02 01:30:53 [INFO]: Epoch 048 - training loss: 0.1112, validation loss: 0.3846
2024-06-02 01:30:54 [INFO]: Epoch 049 - training loss: 0.1106, validation loss: 0.3857
2024-06-02 01:30:55 [INFO]: Epoch 050 - training loss: 0.1084, validation loss: 0.3848
2024-06-02 01:30:56 [INFO]: Epoch 051 - training loss: 0.1071, validation loss: 0.3849
2024-06-02 01:30:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:30:56 [INFO]: Finished training. The best model is from epoch#41.
2024-06-02 01:30:56 [INFO]: Saved the model to results_point_rate01/PeMS/GRUD_PeMS/round_3/20240602_T013007/GRUD.pypots
2024-06-02 01:30:56 [INFO]: Successfully saved to results_point_rate01/PeMS/GRUD_PeMS/round_3/imputation.pkl
2024-06-02 01:30:56 [INFO]: Round3 - GRUD on PeMS: MAE=0.3548, MSE=0.5776, MRE=0.4399
2024-06-02 01:30:56 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 01:30:56 [INFO]: Using the given device: cuda:0
2024-06-02 01:30:56 [INFO]: Model files will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_4/20240602_T013056
2024-06-02 01:30:56 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GRUD_PeMS/round_4/20240602_T013056/tensorboard
2024-06-02 01:30:57 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 14,104,896
2024-06-02 01:30:58 [INFO]: Epoch 001 - training loss: 0.4825, validation loss: 0.5134
2024-06-02 01:30:59 [INFO]: Epoch 002 - training loss: 0.2970, validation loss: 0.4794
2024-06-02 01:31:00 [INFO]: Epoch 003 - training loss: 0.2731, validation loss: 0.4646
2024-06-02 01:31:01 [INFO]: Epoch 004 - training loss: 0.2553, validation loss: 0.4555
2024-06-02 01:31:02 [INFO]: Epoch 005 - training loss: 0.2397, validation loss: 0.4503
2024-06-02 01:31:03 [INFO]: Epoch 006 - training loss: 0.2353, validation loss: 0.4415
2024-06-02 01:31:04 [INFO]: Epoch 007 - training loss: 0.2245, validation loss: 0.4372
2024-06-02 01:31:05 [INFO]: Epoch 008 - training loss: 0.2183, validation loss: 0.4319
2024-06-02 01:31:06 [INFO]: Epoch 009 - training loss: 0.2133, validation loss: 0.4274
2024-06-02 01:31:07 [INFO]: Epoch 010 - training loss: 0.2047, validation loss: 0.4231
2024-06-02 01:31:08 [INFO]: Epoch 011 - training loss: 0.2000, validation loss: 0.4225
2024-06-02 01:31:09 [INFO]: Epoch 012 - training loss: 0.1966, validation loss: 0.4176
2024-06-02 01:31:10 [INFO]: Epoch 013 - training loss: 0.1921, validation loss: 0.4132
2024-06-02 01:31:11 [INFO]: Epoch 014 - training loss: 0.1908, validation loss: 0.4115
2024-06-02 01:31:12 [INFO]: Epoch 015 - training loss: 0.1849, validation loss: 0.4075
2024-06-02 01:31:13 [INFO]: Epoch 016 - training loss: 0.1792, validation loss: 0.4046
2024-06-02 01:31:14 [INFO]: Epoch 017 - training loss: 0.1781, validation loss: 0.4052
2024-06-02 01:31:15 [INFO]: Epoch 018 - training loss: 0.1747, validation loss: 0.4010
2024-06-02 01:31:16 [INFO]: Epoch 019 - training loss: 0.1701, validation loss: 0.3996
2024-06-02 01:31:17 [INFO]: Epoch 020 - training loss: 0.1670, validation loss: 0.4003
2024-06-02 01:31:18 [INFO]: Epoch 021 - training loss: 0.1657, validation loss: 0.3984
2024-06-02 01:31:19 [INFO]: Epoch 022 - training loss: 0.1602, validation loss: 0.3953
2024-06-02 01:31:20 [INFO]: Epoch 023 - training loss: 0.1591, validation loss: 0.3946
2024-06-02 01:31:21 [INFO]: Epoch 024 - training loss: 0.1532, validation loss: 0.3947
2024-06-02 01:31:22 [INFO]: Epoch 025 - training loss: 0.1524, validation loss: 0.3926
2024-06-02 01:31:23 [INFO]: Epoch 026 - training loss: 0.1504, validation loss: 0.3903
2024-06-02 01:31:23 [INFO]: Epoch 027 - training loss: 0.1499, validation loss: 0.3883
2024-06-02 01:31:24 [INFO]: Epoch 028 - training loss: 0.1451, validation loss: 0.3886
2024-06-02 01:31:25 [INFO]: Epoch 029 - training loss: 0.1423, validation loss: 0.3902
2024-06-02 01:31:26 [INFO]: Epoch 030 - training loss: 0.1412, validation loss: 0.3868
2024-06-02 01:31:27 [INFO]: Epoch 031 - training loss: 0.1380, validation loss: 0.3881
2024-06-02 01:31:28 [INFO]: Epoch 032 - training loss: 0.1379, validation loss: 0.3882
2024-06-02 01:31:29 [INFO]: Epoch 033 - training loss: 0.1351, validation loss: 0.3865
2024-06-02 01:31:30 [INFO]: Epoch 034 - training loss: 0.1350, validation loss: 0.3866
2024-06-02 01:31:31 [INFO]: Epoch 035 - training loss: 0.1311, validation loss: 0.3868
2024-06-02 01:31:32 [INFO]: Epoch 036 - training loss: 0.1294, validation loss: 0.3881
2024-06-02 01:31:33 [INFO]: Epoch 037 - training loss: 0.1277, validation loss: 0.3875
2024-06-02 01:31:33 [INFO]: Epoch 038 - training loss: 0.1255, validation loss: 0.3843
2024-06-02 01:31:34 [INFO]: Epoch 039 - training loss: 0.1257, validation loss: 0.3860
2024-06-02 01:31:35 [INFO]: Epoch 040 - training loss: 0.1212, validation loss: 0.3854
2024-06-02 01:31:36 [INFO]: Epoch 041 - training loss: 0.1213, validation loss: 0.3839
2024-06-02 01:31:37 [INFO]: Epoch 042 - training loss: 0.1188, validation loss: 0.3854
2024-06-02 01:31:38 [INFO]: Epoch 043 - training loss: 0.1177, validation loss: 0.3854
2024-06-02 01:31:39 [INFO]: Epoch 044 - training loss: 0.1171, validation loss: 0.3845
2024-06-02 01:31:40 [INFO]: Epoch 045 - training loss: 0.1155, validation loss: 0.3832
2024-06-02 01:31:41 [INFO]: Epoch 046 - training loss: 0.1141, validation loss: 0.3847
2024-06-02 01:31:42 [INFO]: Epoch 047 - training loss: 0.1113, validation loss: 0.3841
2024-06-02 01:31:43 [INFO]: Epoch 048 - training loss: 0.1099, validation loss: 0.3832
2024-06-02 01:31:44 [INFO]: Epoch 049 - training loss: 0.1087, validation loss: 0.3835
2024-06-02 01:31:44 [INFO]: Epoch 050 - training loss: 0.1078, validation loss: 0.3860
2024-06-02 01:31:45 [INFO]: Epoch 051 - training loss: 0.1063, validation loss: 0.3839
2024-06-02 01:31:46 [INFO]: Epoch 052 - training loss: 0.1036, validation loss: 0.3838
2024-06-02 01:31:47 [INFO]: Epoch 053 - training loss: 0.1034, validation loss: 0.3845
2024-06-02 01:31:48 [INFO]: Epoch 054 - training loss: 0.1032, validation loss: 0.3856
2024-06-02 01:31:49 [INFO]: Epoch 055 - training loss: 0.1017, validation loss: 0.3863
2024-06-02 01:31:50 [INFO]: Epoch 056 - training loss: 0.1005, validation loss: 0.3859
2024-06-02 01:31:51 [INFO]: Epoch 057 - training loss: 0.0987, validation loss: 0.3861
2024-06-02 01:31:52 [INFO]: Epoch 058 - training loss: 0.0977, validation loss: 0.3856
2024-06-02 01:31:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:31:52 [INFO]: Finished training. The best model is from epoch#48.
2024-06-02 01:31:52 [INFO]: Saved the model to results_point_rate01/PeMS/GRUD_PeMS/round_4/20240602_T013056/GRUD.pypots
2024-06-02 01:31:52 [INFO]: Successfully saved to results_point_rate01/PeMS/GRUD_PeMS/round_4/imputation.pkl
2024-06-02 01:31:52 [INFO]: Round4 - GRUD on PeMS: MAE=0.3567, MSE=0.5813, MRE=0.4422
2024-06-02 01:31:52 [INFO]: Done! Final results:
Averaged GRUD (n params: 14,104,896) on PeMS: MAE=0.3549 ± 0.0018533028821663851, MSE=0.5780 ± 0.0027909465596130663, MRE=0.4399 ± 0.0022973535692013603, average inference time=0.31
