2024-06-02 09:56:32 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 09:56:32 [INFO]: Using the given device: cuda:0
2024-06-02 09:56:32 [INFO]: Model files will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_0/20240602_T095632
2024-06-02 09:56:32 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_0/20240602_T095632/tensorboard
2024-06-02 09:56:33 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-02 09:56:40 [INFO]: Epoch 001 - training loss: 679531.8917, validation loss: 1.1718
2024-06-02 09:56:44 [INFO]: Epoch 002 - training loss: 420822.8146, validation loss: 0.7226
2024-06-02 09:56:49 [INFO]: Epoch 003 - training loss: 301060.4750, validation loss: 0.5637
2024-06-02 09:56:53 [INFO]: Epoch 004 - training loss: 277200.2521, validation loss: 0.5365
2024-06-02 09:56:58 [INFO]: Epoch 005 - training loss: 271549.9437, validation loss: 0.5167
2024-06-02 09:57:02 [INFO]: Epoch 006 - training loss: 269900.4938, validation loss: 0.4943
2024-06-02 09:57:07 [INFO]: Epoch 007 - training loss: 269155.9604, validation loss: 0.4884
2024-06-02 09:57:11 [INFO]: Epoch 008 - training loss: 268773.8208, validation loss: 0.4773
2024-06-02 09:57:16 [INFO]: Epoch 009 - training loss: 268494.1875, validation loss: 0.4903
2024-06-02 09:57:20 [INFO]: Epoch 010 - training loss: 268371.4708, validation loss: 0.4673
2024-06-02 09:57:25 [INFO]: Epoch 011 - training loss: 268167.1833, validation loss: 0.4661
2024-06-02 09:57:29 [INFO]: Epoch 012 - training loss: 268061.8542, validation loss: 0.4623
2024-06-02 09:57:34 [INFO]: Epoch 013 - training loss: 268001.5979, validation loss: 0.4689
2024-06-02 09:57:38 [INFO]: Epoch 014 - training loss: 267919.7417, validation loss: 0.4587
2024-06-02 09:57:43 [INFO]: Epoch 015 - training loss: 267853.3688, validation loss: 0.4597
2024-06-02 09:57:48 [INFO]: Epoch 016 - training loss: 267778.2771, validation loss: 0.4531
2024-06-02 09:57:52 [INFO]: Epoch 017 - training loss: 267708.6146, validation loss: 0.4693
2024-06-02 09:57:57 [INFO]: Epoch 018 - training loss: 267730.3625, validation loss: 0.4568
2024-06-02 09:58:01 [INFO]: Epoch 019 - training loss: 267709.4646, validation loss: 0.4536
2024-06-02 09:58:05 [INFO]: Epoch 020 - training loss: 267627.1417, validation loss: 0.4529
2024-06-02 09:58:09 [INFO]: Epoch 021 - training loss: 267609.5208, validation loss: 0.4552
2024-06-02 09:58:12 [INFO]: Epoch 022 - training loss: 267540.1417, validation loss: 0.4497
2024-06-02 09:58:15 [INFO]: Epoch 023 - training loss: 267529.0812, validation loss: 0.4449
2024-06-02 09:58:18 [INFO]: Epoch 024 - training loss: 267486.1479, validation loss: 0.4555
2024-06-02 09:58:21 [INFO]: Epoch 025 - training loss: 267566.6521, validation loss: 0.4774
2024-06-02 09:58:25 [INFO]: Epoch 026 - training loss: 267580.5250, validation loss: 0.4489
2024-06-02 09:58:28 [INFO]: Epoch 027 - training loss: 267488.0646, validation loss: 0.4434
2024-06-02 09:58:31 [INFO]: Epoch 028 - training loss: 267443.5708, validation loss: 0.4578
2024-06-02 09:58:34 [INFO]: Epoch 029 - training loss: 267441.9125, validation loss: 0.4430
2024-06-02 09:58:37 [INFO]: Epoch 030 - training loss: 267406.3458, validation loss: 0.4427
2024-06-02 09:58:40 [INFO]: Epoch 031 - training loss: 267330.6042, validation loss: 0.4422
2024-06-02 09:58:43 [INFO]: Epoch 032 - training loss: 267338.0833, validation loss: 0.4386
2024-06-02 09:58:47 [INFO]: Epoch 033 - training loss: 267317.7771, validation loss: 0.4471
2024-06-02 09:58:50 [INFO]: Epoch 034 - training loss: 267318.5604, validation loss: 0.4332
2024-06-02 09:58:53 [INFO]: Epoch 035 - training loss: 267275.2667, validation loss: 0.4369
2024-06-02 09:58:56 [INFO]: Epoch 036 - training loss: 267281.6521, validation loss: 0.4353
2024-06-02 09:58:59 [INFO]: Epoch 037 - training loss: 267240.6229, validation loss: 0.4391
2024-06-02 09:59:02 [INFO]: Epoch 038 - training loss: 267241.9208, validation loss: 0.4426
2024-06-02 09:59:05 [INFO]: Epoch 039 - training loss: 267264.7021, validation loss: 0.4559
2024-06-02 09:59:08 [INFO]: Epoch 040 - training loss: 267300.9146, validation loss: 0.4491
2024-06-02 09:59:11 [INFO]: Epoch 041 - training loss: 267220.2687, validation loss: 0.4374
2024-06-02 09:59:14 [INFO]: Epoch 042 - training loss: 267182.3417, validation loss: 0.4332
2024-06-02 09:59:18 [INFO]: Epoch 043 - training loss: 267181.3083, validation loss: 0.4333
2024-06-02 09:59:21 [INFO]: Epoch 044 - training loss: 267222.2146, validation loss: 0.4411
2024-06-02 09:59:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 09:59:21 [INFO]: Finished training. The best model is from epoch#34.
2024-06-02 09:59:21 [INFO]: Saved the model to results_point_rate01/PeMS/GPVAE_PeMS/round_0/20240602_T095632/GPVAE.pypots
2024-06-02 09:59:27 [INFO]: Successfully saved to results_point_rate01/PeMS/GPVAE_PeMS/round_0/imputation.pkl
2024-06-02 09:59:27 [INFO]: Round0 - GPVAE on PeMS: MAE=0.3444, MSE=0.6284, MRE=0.4269
2024-06-02 09:59:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 09:59:27 [INFO]: Using the given device: cuda:0
2024-06-02 09:59:27 [INFO]: Model files will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_1/20240602_T095927
2024-06-02 09:59:27 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_1/20240602_T095927/tensorboard
2024-06-02 09:59:27 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-02 09:59:30 [INFO]: Epoch 001 - training loss: 684483.4292, validation loss: 1.1963
2024-06-02 09:59:33 [INFO]: Epoch 002 - training loss: 422012.2562, validation loss: 0.7965
2024-06-02 09:59:36 [INFO]: Epoch 003 - training loss: 297515.6813, validation loss: 0.6229
2024-06-02 09:59:39 [INFO]: Epoch 004 - training loss: 275603.2208, validation loss: 0.5475
2024-06-02 09:59:42 [INFO]: Epoch 005 - training loss: 271495.5438, validation loss: 0.5488
2024-06-02 09:59:45 [INFO]: Epoch 006 - training loss: 269932.2417, validation loss: 0.5146
2024-06-02 09:59:48 [INFO]: Epoch 007 - training loss: 269161.1042, validation loss: 0.4836
2024-06-02 09:59:51 [INFO]: Epoch 008 - training loss: 268719.3354, validation loss: 0.4791
2024-06-02 09:59:54 [INFO]: Epoch 009 - training loss: 268462.1083, validation loss: 0.4731
2024-06-02 09:59:57 [INFO]: Epoch 010 - training loss: 268329.7792, validation loss: 0.4649
2024-06-02 10:00:00 [INFO]: Epoch 011 - training loss: 268159.7771, validation loss: 0.4740
2024-06-02 10:00:03 [INFO]: Epoch 012 - training loss: 268070.8875, validation loss: 0.4535
2024-06-02 10:00:06 [INFO]: Epoch 013 - training loss: 267942.7458, validation loss: 0.4592
2024-06-02 10:00:10 [INFO]: Epoch 014 - training loss: 267839.7062, validation loss: 0.4687
2024-06-02 10:00:13 [INFO]: Epoch 015 - training loss: 267810.5125, validation loss: 0.4508
2024-06-02 10:00:16 [INFO]: Epoch 016 - training loss: 267763.1083, validation loss: 0.4535
2024-06-02 10:00:19 [INFO]: Epoch 017 - training loss: 267687.8896, validation loss: 0.4577
2024-06-02 10:00:22 [INFO]: Epoch 018 - training loss: 267653.6125, validation loss: 0.4678
2024-06-02 10:00:25 [INFO]: Epoch 019 - training loss: 267664.5667, validation loss: 0.5007
2024-06-02 10:00:28 [INFO]: Epoch 020 - training loss: 267732.7250, validation loss: 0.4542
2024-06-02 10:00:31 [INFO]: Epoch 021 - training loss: 267642.9271, validation loss: 0.4517
2024-06-02 10:00:35 [INFO]: Epoch 022 - training loss: 267554.1250, validation loss: 0.4525
2024-06-02 10:00:38 [INFO]: Epoch 023 - training loss: 267510.7083, validation loss: 0.4477
2024-06-02 10:00:41 [INFO]: Epoch 024 - training loss: 267469.2250, validation loss: 0.4482
2024-06-02 10:00:44 [INFO]: Epoch 025 - training loss: 267443.5438, validation loss: 0.4475
2024-06-02 10:00:47 [INFO]: Epoch 026 - training loss: 267416.5812, validation loss: 0.4464
2024-06-02 10:00:50 [INFO]: Epoch 027 - training loss: 267408.1063, validation loss: 0.4489
2024-06-02 10:00:53 [INFO]: Epoch 028 - training loss: 267381.5292, validation loss: 0.4438
2024-06-02 10:00:57 [INFO]: Epoch 029 - training loss: 267320.3083, validation loss: 0.4439
2024-06-02 10:01:00 [INFO]: Epoch 030 - training loss: 267366.0625, validation loss: 0.4526
2024-06-02 10:01:03 [INFO]: Epoch 031 - training loss: 267352.0646, validation loss: 0.4403
2024-06-02 10:01:06 [INFO]: Epoch 032 - training loss: 267304.9229, validation loss: 0.4425
2024-06-02 10:01:09 [INFO]: Epoch 033 - training loss: 267277.4917, validation loss: 0.4396
2024-06-02 10:01:12 [INFO]: Epoch 034 - training loss: 267304.6688, validation loss: 0.4795
2024-06-02 10:01:16 [INFO]: Epoch 035 - training loss: 267309.4396, validation loss: 0.4443
2024-06-02 10:01:19 [INFO]: Epoch 036 - training loss: 267233.3792, validation loss: 0.4383
2024-06-02 10:01:22 [INFO]: Epoch 037 - training loss: 267232.7604, validation loss: 0.4419
2024-06-02 10:01:25 [INFO]: Epoch 038 - training loss: 267253.1625, validation loss: 0.4375
2024-06-02 10:01:28 [INFO]: Epoch 039 - training loss: 267219.3667, validation loss: 0.4321
2024-06-02 10:01:31 [INFO]: Epoch 040 - training loss: 267172.1375, validation loss: 0.4361
2024-06-02 10:01:34 [INFO]: Epoch 041 - training loss: 267179.7500, validation loss: 0.4346
2024-06-02 10:01:37 [INFO]: Epoch 042 - training loss: 267238.3083, validation loss: 0.4420
2024-06-02 10:01:41 [INFO]: Epoch 043 - training loss: 267181.4979, validation loss: 0.4407
2024-06-02 10:01:44 [INFO]: Epoch 044 - training loss: 267210.1417, validation loss: 0.4346
2024-06-02 10:01:47 [INFO]: Epoch 045 - training loss: 267201.3250, validation loss: 0.4343
2024-06-02 10:01:50 [INFO]: Epoch 046 - training loss: 267224.2646, validation loss: 0.4331
2024-06-02 10:01:53 [INFO]: Epoch 047 - training loss: 267221.2042, validation loss: 0.4399
2024-06-02 10:01:56 [INFO]: Epoch 048 - training loss: 267205.1667, validation loss: 0.4289
2024-06-02 10:01:59 [INFO]: Epoch 049 - training loss: 267303.1833, validation loss: 0.4304
2024-06-02 10:02:02 [INFO]: Epoch 050 - training loss: 267314.6063, validation loss: 0.4366
2024-06-02 10:02:05 [INFO]: Epoch 051 - training loss: 267315.5542, validation loss: 0.4367
2024-06-02 10:02:08 [INFO]: Epoch 052 - training loss: 267212.2771, validation loss: 0.4274
2024-06-02 10:02:11 [INFO]: Epoch 053 - training loss: 267203.4792, validation loss: 0.4326
2024-06-02 10:02:14 [INFO]: Epoch 054 - training loss: 267188.3167, validation loss: 0.4256
2024-06-02 10:02:17 [INFO]: Epoch 055 - training loss: 267138.2146, validation loss: 0.4306
2024-06-02 10:02:20 [INFO]: Epoch 056 - training loss: 267121.9333, validation loss: 0.4300
2024-06-02 10:02:24 [INFO]: Epoch 057 - training loss: 267104.0792, validation loss: 0.4290
2024-06-02 10:02:27 [INFO]: Epoch 058 - training loss: 267090.0208, validation loss: 0.4297
2024-06-02 10:02:30 [INFO]: Epoch 059 - training loss: 267097.4188, validation loss: 0.4292
2024-06-02 10:02:33 [INFO]: Epoch 060 - training loss: 267080.2771, validation loss: 0.4322
2024-06-02 10:02:36 [INFO]: Epoch 061 - training loss: 267129.4958, validation loss: 0.4535
2024-06-02 10:02:39 [INFO]: Epoch 062 - training loss: 267113.5938, validation loss: 0.4275
2024-06-02 10:02:42 [INFO]: Epoch 063 - training loss: 267022.7687, validation loss: 0.4263
2024-06-02 10:02:45 [INFO]: Epoch 064 - training loss: 267079.7229, validation loss: 0.4409
2024-06-02 10:02:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 10:02:45 [INFO]: Finished training. The best model is from epoch#54.
2024-06-02 10:02:45 [INFO]: Saved the model to results_point_rate01/PeMS/GPVAE_PeMS/round_1/20240602_T095927/GPVAE.pypots
2024-06-02 10:02:52 [INFO]: Successfully saved to results_point_rate01/PeMS/GPVAE_PeMS/round_1/imputation.pkl
2024-06-02 10:02:52 [INFO]: Round1 - GPVAE on PeMS: MAE=0.3479, MSE=0.6358, MRE=0.4312
2024-06-02 10:02:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 10:02:52 [INFO]: Using the given device: cuda:0
2024-06-02 10:02:52 [INFO]: Model files will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_2/20240602_T100252
2024-06-02 10:02:52 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_2/20240602_T100252/tensorboard
2024-06-02 10:02:52 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-02 10:02:55 [INFO]: Epoch 001 - training loss: 673353.8083, validation loss: 1.1674
2024-06-02 10:02:58 [INFO]: Epoch 002 - training loss: 421074.0396, validation loss: 0.6961
2024-06-02 10:03:01 [INFO]: Epoch 003 - training loss: 299137.2979, validation loss: 0.5626
2024-06-02 10:03:04 [INFO]: Epoch 004 - training loss: 277297.6937, validation loss: 0.5179
2024-06-02 10:03:07 [INFO]: Epoch 005 - training loss: 271821.6479, validation loss: 0.4974
2024-06-02 10:03:10 [INFO]: Epoch 006 - training loss: 270047.3646, validation loss: 0.4908
2024-06-02 10:03:13 [INFO]: Epoch 007 - training loss: 269255.2792, validation loss: 0.4849
2024-06-02 10:03:16 [INFO]: Epoch 008 - training loss: 268795.9021, validation loss: 0.4771
2024-06-02 10:03:20 [INFO]: Epoch 009 - training loss: 268515.3000, validation loss: 0.4883
2024-06-02 10:03:23 [INFO]: Epoch 010 - training loss: 268325.9708, validation loss: 0.4705
2024-06-02 10:03:26 [INFO]: Epoch 011 - training loss: 268151.2062, validation loss: 0.4703
2024-06-02 10:03:29 [INFO]: Epoch 012 - training loss: 268083.6042, validation loss: 0.4637
2024-06-02 10:03:32 [INFO]: Epoch 013 - training loss: 268047.2333, validation loss: 0.4537
2024-06-02 10:03:35 [INFO]: Epoch 014 - training loss: 267930.5958, validation loss: 0.4666
2024-06-02 10:03:38 [INFO]: Epoch 015 - training loss: 267813.8479, validation loss: 0.4590
2024-06-02 10:03:41 [INFO]: Epoch 016 - training loss: 267780.2021, validation loss: 0.4615
2024-06-02 10:03:44 [INFO]: Epoch 017 - training loss: 267710.0938, validation loss: 0.4707
2024-06-02 10:03:48 [INFO]: Epoch 018 - training loss: 267722.1708, validation loss: 0.4488
2024-06-02 10:03:51 [INFO]: Epoch 019 - training loss: 267699.3187, validation loss: 0.4547
2024-06-02 10:03:54 [INFO]: Epoch 020 - training loss: 267660.8646, validation loss: 0.4519
2024-06-02 10:03:57 [INFO]: Epoch 021 - training loss: 267617.2979, validation loss: 0.4629
2024-06-02 10:04:00 [INFO]: Epoch 022 - training loss: 267596.9667, validation loss: 0.4537
2024-06-02 10:04:03 [INFO]: Epoch 023 - training loss: 267599.1250, validation loss: 0.4493
2024-06-02 10:04:06 [INFO]: Epoch 024 - training loss: 267551.0021, validation loss: 0.4457
2024-06-02 10:04:09 [INFO]: Epoch 025 - training loss: 267491.4250, validation loss: 0.4484
2024-06-02 10:04:12 [INFO]: Epoch 026 - training loss: 267541.3937, validation loss: 0.4541
2024-06-02 10:04:15 [INFO]: Epoch 027 - training loss: 267521.1292, validation loss: 0.4498
2024-06-02 10:04:18 [INFO]: Epoch 028 - training loss: 267478.1333, validation loss: 0.4437
2024-06-02 10:04:22 [INFO]: Epoch 029 - training loss: 267454.5354, validation loss: 0.4444
2024-06-02 10:04:25 [INFO]: Epoch 030 - training loss: 267456.8521, validation loss: 0.4410
2024-06-02 10:04:28 [INFO]: Epoch 031 - training loss: 267447.5042, validation loss: 0.4528
2024-06-02 10:04:31 [INFO]: Epoch 032 - training loss: 267397.4917, validation loss: 0.4392
2024-06-02 10:04:34 [INFO]: Epoch 033 - training loss: 267402.3271, validation loss: 0.4453
2024-06-02 10:04:37 [INFO]: Epoch 034 - training loss: 267396.0667, validation loss: 0.4372
2024-06-02 10:04:40 [INFO]: Epoch 035 - training loss: 267335.0417, validation loss: 0.4388
2024-06-02 10:04:43 [INFO]: Epoch 036 - training loss: 267341.8250, validation loss: 0.4419
2024-06-02 10:04:46 [INFO]: Epoch 037 - training loss: 267314.0938, validation loss: 0.4411
2024-06-02 10:04:49 [INFO]: Epoch 038 - training loss: 267308.9750, validation loss: 0.4350
2024-06-02 10:04:52 [INFO]: Epoch 039 - training loss: 267260.8854, validation loss: 0.4348
2024-06-02 10:04:55 [INFO]: Epoch 040 - training loss: 267278.6167, validation loss: 0.4334
2024-06-02 10:04:58 [INFO]: Epoch 041 - training loss: 267374.9062, validation loss: 0.4401
2024-06-02 10:05:01 [INFO]: Epoch 042 - training loss: 267681.8146, validation loss: 0.4401
2024-06-02 10:05:04 [INFO]: Epoch 043 - training loss: 267597.0312, validation loss: 0.4353
2024-06-02 10:05:08 [INFO]: Epoch 044 - training loss: 267432.0312, validation loss: 0.4378
2024-06-02 10:05:11 [INFO]: Epoch 045 - training loss: 267359.0312, validation loss: 0.4398
2024-06-02 10:05:14 [INFO]: Epoch 046 - training loss: 267264.7333, validation loss: 0.4303
2024-06-02 10:05:17 [INFO]: Epoch 047 - training loss: 267233.0479, validation loss: 0.4290
2024-06-02 10:05:20 [INFO]: Epoch 048 - training loss: 267210.2208, validation loss: 0.4305
2024-06-02 10:05:23 [INFO]: Epoch 049 - training loss: 267187.0500, validation loss: 0.4301
2024-06-02 10:05:26 [INFO]: Epoch 050 - training loss: 267177.4729, validation loss: 0.4491
2024-06-02 10:05:30 [INFO]: Epoch 051 - training loss: 267242.1458, validation loss: 0.4496
2024-06-02 10:05:33 [INFO]: Epoch 052 - training loss: 267214.7229, validation loss: 0.4256
2024-06-02 10:05:36 [INFO]: Epoch 053 - training loss: 267153.5312, validation loss: 0.4291
2024-06-02 10:05:39 [INFO]: Epoch 054 - training loss: 267175.3792, validation loss: 0.4266
2024-06-02 10:05:42 [INFO]: Epoch 055 - training loss: 267173.9562, validation loss: 0.4304
2024-06-02 10:05:45 [INFO]: Epoch 056 - training loss: 267176.4458, validation loss: 0.4436
2024-06-02 10:05:48 [INFO]: Epoch 057 - training loss: 267224.6188, validation loss: 0.4298
2024-06-02 10:05:51 [INFO]: Epoch 058 - training loss: 267153.9875, validation loss: 0.4342
2024-06-02 10:05:54 [INFO]: Epoch 059 - training loss: 267123.9979, validation loss: 0.4423
2024-06-02 10:05:57 [INFO]: Epoch 060 - training loss: 267116.1146, validation loss: 0.4291
2024-06-02 10:06:00 [INFO]: Epoch 061 - training loss: 267125.5292, validation loss: 0.4262
2024-06-02 10:06:03 [INFO]: Epoch 062 - training loss: 267102.6917, validation loss: 0.4276
2024-06-02 10:06:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 10:06:03 [INFO]: Finished training. The best model is from epoch#52.
2024-06-02 10:06:03 [INFO]: Saved the model to results_point_rate01/PeMS/GPVAE_PeMS/round_2/20240602_T100252/GPVAE.pypots
2024-06-02 10:06:10 [INFO]: Successfully saved to results_point_rate01/PeMS/GPVAE_PeMS/round_2/imputation.pkl
2024-06-02 10:06:10 [INFO]: Round2 - GPVAE on PeMS: MAE=0.3294, MSE=0.6165, MRE=0.4083
2024-06-02 10:06:10 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 10:06:10 [INFO]: Using the given device: cuda:0
2024-06-02 10:06:10 [INFO]: Model files will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_3/20240602_T100610
2024-06-02 10:06:10 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_3/20240602_T100610/tensorboard
2024-06-02 10:06:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-02 10:06:13 [INFO]: Epoch 001 - training loss: 682415.6875, validation loss: 1.1592
2024-06-02 10:06:16 [INFO]: Epoch 002 - training loss: 429156.7000, validation loss: 0.7505
2024-06-02 10:06:19 [INFO]: Epoch 003 - training loss: 299967.1312, validation loss: 0.5956
2024-06-02 10:06:22 [INFO]: Epoch 004 - training loss: 275752.7104, validation loss: 0.5372
2024-06-02 10:06:25 [INFO]: Epoch 005 - training loss: 270844.3729, validation loss: 0.5060
2024-06-02 10:06:28 [INFO]: Epoch 006 - training loss: 269446.7271, validation loss: 0.4922
2024-06-02 10:06:31 [INFO]: Epoch 007 - training loss: 268920.0667, validation loss: 0.5317
2024-06-02 10:06:34 [INFO]: Epoch 008 - training loss: 268643.3333, validation loss: 0.4942
2024-06-02 10:06:37 [INFO]: Epoch 009 - training loss: 268372.7938, validation loss: 0.4851
2024-06-02 10:06:40 [INFO]: Epoch 010 - training loss: 268237.8208, validation loss: 0.5164
2024-06-02 10:06:43 [INFO]: Epoch 011 - training loss: 268326.5000, validation loss: 0.4642
2024-06-02 10:06:46 [INFO]: Epoch 012 - training loss: 268023.2938, validation loss: 0.4614
2024-06-02 10:06:49 [INFO]: Epoch 013 - training loss: 267855.3979, validation loss: 0.4608
2024-06-02 10:06:52 [INFO]: Epoch 014 - training loss: 267790.2354, validation loss: 0.4608
2024-06-02 10:06:55 [INFO]: Epoch 015 - training loss: 267837.7771, validation loss: 0.4612
2024-06-02 10:06:58 [INFO]: Epoch 016 - training loss: 267724.0833, validation loss: 0.4566
2024-06-02 10:07:01 [INFO]: Epoch 017 - training loss: 267780.2542, validation loss: 0.4574
2024-06-02 10:07:04 [INFO]: Epoch 018 - training loss: 267701.5938, validation loss: 0.4550
2024-06-02 10:07:07 [INFO]: Epoch 019 - training loss: 267628.4542, validation loss: 0.4543
2024-06-02 10:07:10 [INFO]: Epoch 020 - training loss: 267586.6104, validation loss: 0.4515
2024-06-02 10:07:13 [INFO]: Epoch 021 - training loss: 267633.5292, validation loss: 0.4625
2024-06-02 10:07:16 [INFO]: Epoch 022 - training loss: 267631.5958, validation loss: 0.4520
2024-06-02 10:07:19 [INFO]: Epoch 023 - training loss: 267618.2438, validation loss: 0.4476
2024-06-02 10:07:22 [INFO]: Epoch 024 - training loss: 267508.3063, validation loss: 0.4492
2024-06-02 10:07:25 [INFO]: Epoch 025 - training loss: 267486.2542, validation loss: 0.4470
2024-06-02 10:07:28 [INFO]: Epoch 026 - training loss: 267438.0125, validation loss: 0.4491
2024-06-02 10:07:31 [INFO]: Epoch 027 - training loss: 267458.4583, validation loss: 0.4516
2024-06-02 10:07:35 [INFO]: Epoch 028 - training loss: 267452.1708, validation loss: 0.4546
2024-06-02 10:07:38 [INFO]: Epoch 029 - training loss: 267454.2896, validation loss: 0.4520
2024-06-02 10:07:41 [INFO]: Epoch 030 - training loss: 267403.1875, validation loss: 0.4558
2024-06-02 10:07:44 [INFO]: Epoch 031 - training loss: 267469.8167, validation loss: 0.4580
2024-06-02 10:07:47 [INFO]: Epoch 032 - training loss: 267354.8937, validation loss: 0.4393
2024-06-02 10:07:50 [INFO]: Epoch 033 - training loss: 267315.2208, validation loss: 0.4480
2024-06-02 10:07:53 [INFO]: Epoch 034 - training loss: 267328.0812, validation loss: 0.4425
2024-06-02 10:07:56 [INFO]: Epoch 035 - training loss: 267317.9583, validation loss: 0.4420
2024-06-02 10:07:59 [INFO]: Epoch 036 - training loss: 267303.4813, validation loss: 0.4493
2024-06-02 10:08:02 [INFO]: Epoch 037 - training loss: 267241.3521, validation loss: 0.4450
2024-06-02 10:08:05 [INFO]: Epoch 038 - training loss: 267250.3917, validation loss: 0.4397
2024-06-02 10:08:08 [INFO]: Epoch 039 - training loss: 267235.9229, validation loss: 0.4386
2024-06-02 10:08:11 [INFO]: Epoch 040 - training loss: 267208.3896, validation loss: 0.4332
2024-06-02 10:08:14 [INFO]: Epoch 041 - training loss: 267181.6625, validation loss: 0.4349
2024-06-02 10:08:17 [INFO]: Epoch 042 - training loss: 267253.0458, validation loss: 0.4461
2024-06-02 10:08:20 [INFO]: Epoch 043 - training loss: 267251.6063, validation loss: 0.4416
2024-06-02 10:08:23 [INFO]: Epoch 044 - training loss: 267227.9521, validation loss: 0.4352
2024-06-02 10:08:26 [INFO]: Epoch 045 - training loss: 267193.8021, validation loss: 0.4341
2024-06-02 10:08:29 [INFO]: Epoch 046 - training loss: 267180.3563, validation loss: 0.4277
2024-06-02 10:08:33 [INFO]: Epoch 047 - training loss: 267218.6000, validation loss: 0.4379
2024-06-02 10:08:35 [INFO]: Epoch 048 - training loss: 267196.9437, validation loss: 0.4455
2024-06-02 10:08:39 [INFO]: Epoch 049 - training loss: 267224.3854, validation loss: 0.4463
2024-06-02 10:08:42 [INFO]: Epoch 050 - training loss: 267285.9333, validation loss: 0.4297
2024-06-02 10:08:45 [INFO]: Epoch 051 - training loss: 267320.0687, validation loss: 0.4341
2024-06-02 10:08:48 [INFO]: Epoch 052 - training loss: 267283.0938, validation loss: 0.4304
2024-06-02 10:08:51 [INFO]: Epoch 053 - training loss: 267276.6833, validation loss: 0.4345
2024-06-02 10:08:54 [INFO]: Epoch 054 - training loss: 267299.8187, validation loss: 0.4357
2024-06-02 10:08:57 [INFO]: Epoch 055 - training loss: 267338.4188, validation loss: 0.4571
2024-06-02 10:09:00 [INFO]: Epoch 056 - training loss: 267361.2750, validation loss: 0.4380
2024-06-02 10:09:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 10:09:00 [INFO]: Finished training. The best model is from epoch#46.
2024-06-02 10:09:00 [INFO]: Saved the model to results_point_rate01/PeMS/GPVAE_PeMS/round_3/20240602_T100610/GPVAE.pypots
2024-06-02 10:09:06 [INFO]: Successfully saved to results_point_rate01/PeMS/GPVAE_PeMS/round_3/imputation.pkl
2024-06-02 10:09:06 [INFO]: Round3 - GPVAE on PeMS: MAE=0.3348, MSE=0.6284, MRE=0.4150
2024-06-02 10:09:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 10:09:06 [INFO]: Using the given device: cuda:0
2024-06-02 10:09:06 [INFO]: Model files will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_4/20240602_T100906
2024-06-02 10:09:06 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/GPVAE_PeMS/round_4/20240602_T100906/tensorboard
2024-06-02 10:09:06 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-02 10:09:09 [INFO]: Epoch 001 - training loss: 687696.0167, validation loss: 1.1893
2024-06-02 10:09:12 [INFO]: Epoch 002 - training loss: 444342.7562, validation loss: 0.7520
2024-06-02 10:09:14 [INFO]: Epoch 003 - training loss: 305852.1146, validation loss: 0.5860
2024-06-02 10:09:17 [INFO]: Epoch 004 - training loss: 277033.9917, validation loss: 0.5489
2024-06-02 10:09:19 [INFO]: Epoch 005 - training loss: 271379.8187, validation loss: 0.5084
2024-06-02 10:09:21 [INFO]: Epoch 006 - training loss: 269755.2771, validation loss: 0.5071
2024-06-02 10:09:23 [INFO]: Epoch 007 - training loss: 269071.4250, validation loss: 0.4985
2024-06-02 10:09:25 [INFO]: Epoch 008 - training loss: 268718.8937, validation loss: 0.4791
2024-06-02 10:09:28 [INFO]: Epoch 009 - training loss: 268467.2917, validation loss: 0.4750
2024-06-02 10:09:30 [INFO]: Epoch 010 - training loss: 268269.3063, validation loss: 0.4724
2024-06-02 10:09:32 [INFO]: Epoch 011 - training loss: 268122.9458, validation loss: 0.4640
2024-06-02 10:09:34 [INFO]: Epoch 012 - training loss: 268013.7896, validation loss: 0.4642
2024-06-02 10:09:36 [INFO]: Epoch 013 - training loss: 267911.4833, validation loss: 0.4562
2024-06-02 10:09:38 [INFO]: Epoch 014 - training loss: 267909.2438, validation loss: 0.4654
2024-06-02 10:09:40 [INFO]: Epoch 015 - training loss: 267819.1646, validation loss: 0.4533
2024-06-02 10:09:42 [INFO]: Epoch 016 - training loss: 267775.1479, validation loss: 0.4542
2024-06-02 10:09:44 [INFO]: Epoch 017 - training loss: 267737.9458, validation loss: 0.4529
2024-06-02 10:09:46 [INFO]: Epoch 018 - training loss: 267693.5250, validation loss: 0.4530
2024-06-02 10:09:48 [INFO]: Epoch 019 - training loss: 267629.5354, validation loss: 0.4493
2024-06-02 10:09:50 [INFO]: Epoch 020 - training loss: 267634.2708, validation loss: 0.4536
2024-06-02 10:09:52 [INFO]: Epoch 021 - training loss: 267592.4000, validation loss: 0.4545
2024-06-02 10:09:54 [INFO]: Epoch 022 - training loss: 267586.2875, validation loss: 0.4578
2024-06-02 10:09:56 [INFO]: Epoch 023 - training loss: 267564.6250, validation loss: 0.4524
2024-06-02 10:09:58 [INFO]: Epoch 024 - training loss: 267556.1167, validation loss: 0.4485
2024-06-02 10:10:01 [INFO]: Epoch 025 - training loss: 267539.4875, validation loss: 0.4472
2024-06-02 10:10:03 [INFO]: Epoch 026 - training loss: 267513.3063, validation loss: 0.4613
2024-06-02 10:10:05 [INFO]: Epoch 027 - training loss: 267509.7271, validation loss: 0.4517
2024-06-02 10:10:07 [INFO]: Epoch 028 - training loss: 267494.4146, validation loss: 0.4454
2024-06-02 10:10:09 [INFO]: Epoch 029 - training loss: 267456.8854, validation loss: 0.4542
2024-06-02 10:10:11 [INFO]: Epoch 030 - training loss: 267441.4833, validation loss: 0.4464
2024-06-02 10:10:13 [INFO]: Epoch 031 - training loss: 267409.3187, validation loss: 0.4415
2024-06-02 10:10:15 [INFO]: Epoch 032 - training loss: 267357.9562, validation loss: 0.4560
2024-06-02 10:10:17 [INFO]: Epoch 033 - training loss: 267349.0687, validation loss: 0.4397
2024-06-02 10:10:20 [INFO]: Epoch 034 - training loss: 267297.6021, validation loss: 0.4449
2024-06-02 10:10:22 [INFO]: Epoch 035 - training loss: 267314.0479, validation loss: 0.4436
2024-06-02 10:10:24 [INFO]: Epoch 036 - training loss: 267300.5458, validation loss: 0.4451
2024-06-02 10:10:26 [INFO]: Epoch 037 - training loss: 267256.2667, validation loss: 0.4417
2024-06-02 10:10:28 [INFO]: Epoch 038 - training loss: 267276.9229, validation loss: 0.4677
2024-06-02 10:10:30 [INFO]: Epoch 039 - training loss: 267309.9958, validation loss: 0.4453
2024-06-02 10:10:32 [INFO]: Epoch 040 - training loss: 267287.9146, validation loss: 0.4553
2024-06-02 10:10:34 [INFO]: Epoch 041 - training loss: 267253.2354, validation loss: 0.4466
2024-06-02 10:10:37 [INFO]: Epoch 042 - training loss: 267199.0979, validation loss: 0.4419
2024-06-02 10:10:39 [INFO]: Epoch 043 - training loss: 267246.1521, validation loss: 0.4357
2024-06-02 10:10:41 [INFO]: Epoch 044 - training loss: 267196.7021, validation loss: 0.4367
2024-06-02 10:10:44 [INFO]: Epoch 045 - training loss: 267159.3896, validation loss: 0.4330
2024-06-02 10:10:46 [INFO]: Epoch 046 - training loss: 267152.0875, validation loss: 0.4419
2024-06-02 10:10:48 [INFO]: Epoch 047 - training loss: 267169.7729, validation loss: 0.4353
2024-06-02 10:10:50 [INFO]: Epoch 048 - training loss: 267192.8625, validation loss: 0.4354
2024-06-02 10:10:52 [INFO]: Epoch 049 - training loss: 267164.8833, validation loss: 0.4331
2024-06-02 10:10:54 [INFO]: Epoch 050 - training loss: 267169.1250, validation loss: 0.4414
2024-06-02 10:10:56 [INFO]: Epoch 051 - training loss: 267184.1396, validation loss: 0.4449
2024-06-02 10:10:58 [INFO]: Epoch 052 - training loss: 267257.2208, validation loss: 0.4376
2024-06-02 10:11:00 [INFO]: Epoch 053 - training loss: 267224.1896, validation loss: 0.4330
2024-06-02 10:11:02 [INFO]: Epoch 054 - training loss: 267216.4979, validation loss: 0.4355
2024-06-02 10:11:04 [INFO]: Epoch 055 - training loss: 267255.8458, validation loss: 0.4382
2024-06-02 10:11:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 10:11:04 [INFO]: Finished training. The best model is from epoch#45.
2024-06-02 10:11:04 [INFO]: Saved the model to results_point_rate01/PeMS/GPVAE_PeMS/round_4/20240602_T100906/GPVAE.pypots
2024-06-02 10:11:09 [INFO]: Successfully saved to results_point_rate01/PeMS/GPVAE_PeMS/round_4/imputation.pkl
2024-06-02 10:11:09 [INFO]: Round4 - GPVAE on PeMS: MAE=0.3470, MSE=0.6234, MRE=0.4302
2024-06-02 10:11:09 [INFO]: Done! Final results:
Averaged GPVAE (2,396,536 params) on PeMS: MAE=0.3407 ± 0.007318954036752093, MSE=0.6265 ± 0.006364425450091085, MRE=0.4223 ± 0.009072572724593416, average inference time=5.85
