2024-06-02 01:21:15 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 01:21:15 [INFO]: Using the given device: cuda:0
2024-06-02 01:21:16 [INFO]: Model files will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_0/20240602_T012116
2024-06-02 01:21:16 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_0/20240602_T012116/tensorboard
2024-06-02 01:21:16 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-02 01:21:28 [INFO]: Epoch 001 - training loss: 1.7086, validation loss: 0.9269
2024-06-02 01:21:29 [INFO]: Epoch 002 - training loss: 0.8223, validation loss: 0.5929
2024-06-02 01:21:31 [INFO]: Epoch 003 - training loss: 0.6696, validation loss: 0.4888
2024-06-02 01:21:32 [INFO]: Epoch 004 - training loss: 0.5982, validation loss: 0.5011
2024-06-02 01:21:34 [INFO]: Epoch 005 - training loss: 0.5662, validation loss: 0.5550
2024-06-02 01:21:35 [INFO]: Epoch 006 - training loss: 0.5460, validation loss: 0.4737
2024-06-02 01:21:36 [INFO]: Epoch 007 - training loss: 0.5291, validation loss: 0.4525
2024-06-02 01:21:38 [INFO]: Epoch 008 - training loss: 0.5049, validation loss: 0.4240
2024-06-02 01:21:40 [INFO]: Epoch 009 - training loss: 0.4886, validation loss: 0.4658
2024-06-02 01:21:41 [INFO]: Epoch 010 - training loss: 0.4806, validation loss: 0.4246
2024-06-02 01:21:43 [INFO]: Epoch 011 - training loss: 0.4656, validation loss: 0.4228
2024-06-02 01:21:44 [INFO]: Epoch 012 - training loss: 0.4560, validation loss: 0.4113
2024-06-02 01:21:46 [INFO]: Epoch 013 - training loss: 0.4512, validation loss: 0.3992
2024-06-02 01:21:47 [INFO]: Epoch 014 - training loss: 0.4459, validation loss: 0.4138
2024-06-02 01:21:49 [INFO]: Epoch 015 - training loss: 0.4395, validation loss: 0.4103
2024-06-02 01:21:50 [INFO]: Epoch 016 - training loss: 0.4318, validation loss: 0.3951
2024-06-02 01:21:51 [INFO]: Epoch 017 - training loss: 0.4268, validation loss: 0.3977
2024-06-02 01:21:53 [INFO]: Epoch 018 - training loss: 0.4193, validation loss: 0.3869
2024-06-02 01:21:54 [INFO]: Epoch 019 - training loss: 0.4172, validation loss: 0.3886
2024-06-02 01:21:56 [INFO]: Epoch 020 - training loss: 0.4133, validation loss: 0.3881
2024-06-02 01:21:57 [INFO]: Epoch 021 - training loss: 0.4112, validation loss: 0.3980
2024-06-02 01:21:58 [INFO]: Epoch 022 - training loss: 0.4086, validation loss: 0.3769
2024-06-02 01:22:00 [INFO]: Epoch 023 - training loss: 0.4046, validation loss: 0.3871
2024-06-02 01:22:01 [INFO]: Epoch 024 - training loss: 0.4046, validation loss: 0.3714
2024-06-02 01:22:03 [INFO]: Epoch 025 - training loss: 0.4021, validation loss: 0.3710
2024-06-02 01:22:04 [INFO]: Epoch 026 - training loss: 0.4000, validation loss: 0.3650
2024-06-02 01:22:05 [INFO]: Epoch 027 - training loss: 0.3945, validation loss: 0.3767
2024-06-02 01:22:07 [INFO]: Epoch 028 - training loss: 0.3913, validation loss: 0.3658
2024-06-02 01:22:08 [INFO]: Epoch 029 - training loss: 0.3941, validation loss: 0.3747
2024-06-02 01:22:10 [INFO]: Epoch 030 - training loss: 0.3901, validation loss: 0.3742
2024-06-02 01:22:11 [INFO]: Epoch 031 - training loss: 0.3908, validation loss: 0.3674
2024-06-02 01:22:13 [INFO]: Epoch 032 - training loss: 0.3861, validation loss: 0.3689
2024-06-02 01:22:15 [INFO]: Epoch 033 - training loss: 0.3869, validation loss: 0.3580
2024-06-02 01:22:16 [INFO]: Epoch 034 - training loss: 0.3822, validation loss: 0.3556
2024-06-02 01:22:17 [INFO]: Epoch 035 - training loss: 0.3850, validation loss: 0.3616
2024-06-02 01:22:19 [INFO]: Epoch 036 - training loss: 0.3842, validation loss: 0.3610
2024-06-02 01:22:21 [INFO]: Epoch 037 - training loss: 0.3830, validation loss: 0.3597
2024-06-02 01:22:22 [INFO]: Epoch 038 - training loss: 0.3832, validation loss: 0.3649
2024-06-02 01:22:24 [INFO]: Epoch 039 - training loss: 0.3854, validation loss: 0.3576
2024-06-02 01:22:25 [INFO]: Epoch 040 - training loss: 0.3821, validation loss: 0.3639
2024-06-02 01:22:27 [INFO]: Epoch 041 - training loss: 0.3847, validation loss: 0.3535
2024-06-02 01:22:28 [INFO]: Epoch 042 - training loss: 0.3800, validation loss: 0.3624
2024-06-02 01:22:29 [INFO]: Epoch 043 - training loss: 0.3819, validation loss: 0.3606
2024-06-02 01:22:31 [INFO]: Epoch 044 - training loss: 0.3805, validation loss: 0.3520
2024-06-02 01:22:32 [INFO]: Epoch 045 - training loss: 0.3784, validation loss: 0.3536
2024-06-02 01:22:34 [INFO]: Epoch 046 - training loss: 0.3802, validation loss: 0.3589
2024-06-02 01:22:35 [INFO]: Epoch 047 - training loss: 0.3788, validation loss: 0.3521
2024-06-02 01:22:36 [INFO]: Epoch 048 - training loss: 0.3791, validation loss: 0.3537
2024-06-02 01:22:38 [INFO]: Epoch 049 - training loss: 0.3749, validation loss: 0.3523
2024-06-02 01:22:39 [INFO]: Epoch 050 - training loss: 0.3755, validation loss: 0.3494
2024-06-02 01:22:41 [INFO]: Epoch 051 - training loss: 0.3781, validation loss: 0.3548
2024-06-02 01:22:42 [INFO]: Epoch 052 - training loss: 0.3775, validation loss: 0.3516
2024-06-02 01:22:43 [INFO]: Epoch 053 - training loss: 0.3788, validation loss: 0.3532
2024-06-02 01:22:44 [INFO]: Epoch 054 - training loss: 0.3763, validation loss: 0.3519
2024-06-02 01:22:45 [INFO]: Epoch 055 - training loss: 0.3742, validation loss: 0.3461
2024-06-02 01:22:46 [INFO]: Epoch 056 - training loss: 0.3757, validation loss: 0.3474
2024-06-02 01:22:47 [INFO]: Epoch 057 - training loss: 0.3769, validation loss: 0.3535
2024-06-02 01:22:48 [INFO]: Epoch 058 - training loss: 0.3810, validation loss: 0.3450
2024-06-02 01:22:49 [INFO]: Epoch 059 - training loss: 0.3775, validation loss: 0.3507
2024-06-02 01:22:50 [INFO]: Epoch 060 - training loss: 0.3731, validation loss: 0.3494
2024-06-02 01:22:51 [INFO]: Epoch 061 - training loss: 0.3731, validation loss: 0.3431
2024-06-02 01:22:52 [INFO]: Epoch 062 - training loss: 0.3738, validation loss: 0.3474
2024-06-02 01:22:53 [INFO]: Epoch 063 - training loss: 0.3741, validation loss: 0.3471
2024-06-02 01:22:54 [INFO]: Epoch 064 - training loss: 0.3703, validation loss: 0.3416
2024-06-02 01:22:55 [INFO]: Epoch 065 - training loss: 0.3716, validation loss: 0.3394
2024-06-02 01:22:56 [INFO]: Epoch 066 - training loss: 0.3726, validation loss: 0.3441
2024-06-02 01:22:57 [INFO]: Epoch 067 - training loss: 0.3744, validation loss: 0.3415
2024-06-02 01:22:58 [INFO]: Epoch 068 - training loss: 0.3738, validation loss: 0.3430
2024-06-02 01:22:59 [INFO]: Epoch 069 - training loss: 0.3715, validation loss: 0.3459
2024-06-02 01:23:00 [INFO]: Epoch 070 - training loss: 0.3732, validation loss: 0.3459
2024-06-02 01:23:01 [INFO]: Epoch 071 - training loss: 0.3734, validation loss: 0.3464
2024-06-02 01:23:02 [INFO]: Epoch 072 - training loss: 0.3735, validation loss: 0.3453
2024-06-02 01:23:03 [INFO]: Epoch 073 - training loss: 0.3722, validation loss: 0.3514
2024-06-02 01:23:04 [INFO]: Epoch 074 - training loss: 0.3691, validation loss: 0.3455
2024-06-02 01:23:05 [INFO]: Epoch 075 - training loss: 0.3706, validation loss: 0.3454
2024-06-02 01:23:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:23:05 [INFO]: Finished training. The best model is from epoch#65.
2024-06-02 01:23:05 [INFO]: Saved the model to results_point_rate01/PeMS/ETSformer_PeMS/round_0/20240602_T012116/ETSformer.pypots
2024-06-02 01:23:05 [INFO]: Successfully saved to results_point_rate01/PeMS/ETSformer_PeMS/round_0/imputation.pkl
2024-06-02 01:23:05 [INFO]: Round0 - ETSformer on PeMS: MAE=0.3457, MSE=0.5037, MRE=0.4286
2024-06-02 01:23:05 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 01:23:05 [INFO]: Using the given device: cuda:0
2024-06-02 01:23:05 [INFO]: Model files will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_1/20240602_T012305
2024-06-02 01:23:05 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_1/20240602_T012305/tensorboard
2024-06-02 01:23:05 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-02 01:23:07 [INFO]: Epoch 001 - training loss: 1.6112, validation loss: 0.7638
2024-06-02 01:23:08 [INFO]: Epoch 002 - training loss: 0.8775, validation loss: 0.5731
2024-06-02 01:23:09 [INFO]: Epoch 003 - training loss: 0.7142, validation loss: 0.5048
2024-06-02 01:23:10 [INFO]: Epoch 004 - training loss: 0.6330, validation loss: 0.4691
2024-06-02 01:23:11 [INFO]: Epoch 005 - training loss: 0.6052, validation loss: 0.4692
2024-06-02 01:23:12 [INFO]: Epoch 006 - training loss: 0.5754, validation loss: 0.4781
2024-06-02 01:23:13 [INFO]: Epoch 007 - training loss: 0.5343, validation loss: 0.4303
2024-06-02 01:23:14 [INFO]: Epoch 008 - training loss: 0.5148, validation loss: 0.4297
2024-06-02 01:23:15 [INFO]: Epoch 009 - training loss: 0.4943, validation loss: 0.4073
2024-06-02 01:23:16 [INFO]: Epoch 010 - training loss: 0.4781, validation loss: 0.4301
2024-06-02 01:23:17 [INFO]: Epoch 011 - training loss: 0.4784, validation loss: 0.4100
2024-06-02 01:23:17 [INFO]: Epoch 012 - training loss: 0.4684, validation loss: 0.4051
2024-06-02 01:23:19 [INFO]: Epoch 013 - training loss: 0.4524, validation loss: 0.4093
2024-06-02 01:23:19 [INFO]: Epoch 014 - training loss: 0.4375, validation loss: 0.3963
2024-06-02 01:23:20 [INFO]: Epoch 015 - training loss: 0.4349, validation loss: 0.3801
2024-06-02 01:23:21 [INFO]: Epoch 016 - training loss: 0.4320, validation loss: 0.3715
2024-06-02 01:23:22 [INFO]: Epoch 017 - training loss: 0.4294, validation loss: 0.4011
2024-06-02 01:23:23 [INFO]: Epoch 018 - training loss: 0.4192, validation loss: 0.3716
2024-06-02 01:23:24 [INFO]: Epoch 019 - training loss: 0.4172, validation loss: 0.3781
2024-06-02 01:23:24 [INFO]: Epoch 020 - training loss: 0.4132, validation loss: 0.3839
2024-06-02 01:23:25 [INFO]: Epoch 021 - training loss: 0.4076, validation loss: 0.3883
2024-06-02 01:23:26 [INFO]: Epoch 022 - training loss: 0.4050, validation loss: 0.3960
2024-06-02 01:23:27 [INFO]: Epoch 023 - training loss: 0.4036, validation loss: 0.3683
2024-06-02 01:23:29 [INFO]: Epoch 024 - training loss: 0.3970, validation loss: 0.3698
2024-06-02 01:23:30 [INFO]: Epoch 025 - training loss: 0.3941, validation loss: 0.3638
2024-06-02 01:23:31 [INFO]: Epoch 026 - training loss: 0.3949, validation loss: 0.3789
2024-06-02 01:23:32 [INFO]: Epoch 027 - training loss: 0.3937, validation loss: 0.3776
2024-06-02 01:23:33 [INFO]: Epoch 028 - training loss: 0.3956, validation loss: 0.3633
2024-06-02 01:23:34 [INFO]: Epoch 029 - training loss: 0.3905, validation loss: 0.3655
2024-06-02 01:23:35 [INFO]: Epoch 030 - training loss: 0.3924, validation loss: 0.3586
2024-06-02 01:23:36 [INFO]: Epoch 031 - training loss: 0.3893, validation loss: 0.3660
2024-06-02 01:23:37 [INFO]: Epoch 032 - training loss: 0.3902, validation loss: 0.3700
2024-06-02 01:23:38 [INFO]: Epoch 033 - training loss: 0.3882, validation loss: 0.3584
2024-06-02 01:23:39 [INFO]: Epoch 034 - training loss: 0.3872, validation loss: 0.3682
2024-06-02 01:23:41 [INFO]: Epoch 035 - training loss: 0.3835, validation loss: 0.3632
2024-06-02 01:23:42 [INFO]: Epoch 036 - training loss: 0.3795, validation loss: 0.3548
2024-06-02 01:23:43 [INFO]: Epoch 037 - training loss: 0.3802, validation loss: 0.3598
2024-06-02 01:23:44 [INFO]: Epoch 038 - training loss: 0.3829, validation loss: 0.3624
2024-06-02 01:23:45 [INFO]: Epoch 039 - training loss: 0.3793, validation loss: 0.3515
2024-06-02 01:23:45 [INFO]: Epoch 040 - training loss: 0.3804, validation loss: 0.3497
2024-06-02 01:23:46 [INFO]: Epoch 041 - training loss: 0.3811, validation loss: 0.3512
2024-06-02 01:23:47 [INFO]: Epoch 042 - training loss: 0.3803, validation loss: 0.3562
2024-06-02 01:23:48 [INFO]: Epoch 043 - training loss: 0.3755, validation loss: 0.3556
2024-06-02 01:23:49 [INFO]: Epoch 044 - training loss: 0.3775, validation loss: 0.3547
2024-06-02 01:23:50 [INFO]: Epoch 045 - training loss: 0.3765, validation loss: 0.3568
2024-06-02 01:23:51 [INFO]: Epoch 046 - training loss: 0.3757, validation loss: 0.3529
2024-06-02 01:23:53 [INFO]: Epoch 047 - training loss: 0.3807, validation loss: 0.3421
2024-06-02 01:23:54 [INFO]: Epoch 048 - training loss: 0.3799, validation loss: 0.3456
2024-06-02 01:23:55 [INFO]: Epoch 049 - training loss: 0.3776, validation loss: 0.3473
2024-06-02 01:23:56 [INFO]: Epoch 050 - training loss: 0.3775, validation loss: 0.3494
2024-06-02 01:23:57 [INFO]: Epoch 051 - training loss: 0.3765, validation loss: 0.3421
2024-06-02 01:23:58 [INFO]: Epoch 052 - training loss: 0.3771, validation loss: 0.3483
2024-06-02 01:23:59 [INFO]: Epoch 053 - training loss: 0.3779, validation loss: 0.3501
2024-06-02 01:24:00 [INFO]: Epoch 054 - training loss: 0.3753, validation loss: 0.3468
2024-06-02 01:24:01 [INFO]: Epoch 055 - training loss: 0.3769, validation loss: 0.3530
2024-06-02 01:24:02 [INFO]: Epoch 056 - training loss: 0.3770, validation loss: 0.3478
2024-06-02 01:24:03 [INFO]: Epoch 057 - training loss: 0.3750, validation loss: 0.3469
2024-06-02 01:24:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:24:03 [INFO]: Finished training. The best model is from epoch#47.
2024-06-02 01:24:03 [INFO]: Saved the model to results_point_rate01/PeMS/ETSformer_PeMS/round_1/20240602_T012305/ETSformer.pypots
2024-06-02 01:24:03 [INFO]: Successfully saved to results_point_rate01/PeMS/ETSformer_PeMS/round_1/imputation.pkl
2024-06-02 01:24:03 [INFO]: Round1 - ETSformer on PeMS: MAE=0.3461, MSE=0.5052, MRE=0.4291
2024-06-02 01:24:03 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 01:24:03 [INFO]: Using the given device: cuda:0
2024-06-02 01:24:03 [INFO]: Model files will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_2/20240602_T012403
2024-06-02 01:24:03 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_2/20240602_T012403/tensorboard
2024-06-02 01:24:03 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-02 01:24:04 [INFO]: Epoch 001 - training loss: 1.6264, validation loss: 0.7514
2024-06-02 01:24:05 [INFO]: Epoch 002 - training loss: 0.8543, validation loss: 0.5662
2024-06-02 01:24:06 [INFO]: Epoch 003 - training loss: 0.6999, validation loss: 0.5367
2024-06-02 01:24:07 [INFO]: Epoch 004 - training loss: 0.6303, validation loss: 0.4675
2024-06-02 01:24:08 [INFO]: Epoch 005 - training loss: 0.5631, validation loss: 0.4960
2024-06-02 01:24:09 [INFO]: Epoch 006 - training loss: 0.5346, validation loss: 0.4532
2024-06-02 01:24:10 [INFO]: Epoch 007 - training loss: 0.5181, validation loss: 0.4515
2024-06-02 01:24:11 [INFO]: Epoch 008 - training loss: 0.5094, validation loss: 0.5910
2024-06-02 01:24:11 [INFO]: Epoch 009 - training loss: 0.5175, validation loss: 0.4282
2024-06-02 01:24:12 [INFO]: Epoch 010 - training loss: 0.4767, validation loss: 0.4207
2024-06-02 01:24:13 [INFO]: Epoch 011 - training loss: 0.4635, validation loss: 0.4221
2024-06-02 01:24:14 [INFO]: Epoch 012 - training loss: 0.4539, validation loss: 0.4088
2024-06-02 01:24:15 [INFO]: Epoch 013 - training loss: 0.4461, validation loss: 0.4013
2024-06-02 01:24:17 [INFO]: Epoch 014 - training loss: 0.4463, validation loss: 0.4143
2024-06-02 01:24:18 [INFO]: Epoch 015 - training loss: 0.4487, validation loss: 0.4024
2024-06-02 01:24:19 [INFO]: Epoch 016 - training loss: 0.4324, validation loss: 0.3893
2024-06-02 01:24:20 [INFO]: Epoch 017 - training loss: 0.4266, validation loss: 0.3948
2024-06-02 01:24:21 [INFO]: Epoch 018 - training loss: 0.4209, validation loss: 0.3783
2024-06-02 01:24:22 [INFO]: Epoch 019 - training loss: 0.4167, validation loss: 0.3969
2024-06-02 01:24:22 [INFO]: Epoch 020 - training loss: 0.4172, validation loss: 0.3895
2024-06-02 01:24:23 [INFO]: Epoch 021 - training loss: 0.4125, validation loss: 0.3866
2024-06-02 01:24:24 [INFO]: Epoch 022 - training loss: 0.4109, validation loss: 0.3766
2024-06-02 01:24:25 [INFO]: Epoch 023 - training loss: 0.4067, validation loss: 0.3652
2024-06-02 01:24:26 [INFO]: Epoch 024 - training loss: 0.4031, validation loss: 0.3617
2024-06-02 01:24:27 [INFO]: Epoch 025 - training loss: 0.3996, validation loss: 0.3859
2024-06-02 01:24:28 [INFO]: Epoch 026 - training loss: 0.4014, validation loss: 0.3753
2024-06-02 01:24:29 [INFO]: Epoch 027 - training loss: 0.3981, validation loss: 0.3674
2024-06-02 01:24:30 [INFO]: Epoch 028 - training loss: 0.3933, validation loss: 0.3677
2024-06-02 01:24:31 [INFO]: Epoch 029 - training loss: 0.3962, validation loss: 0.3604
2024-06-02 01:24:31 [INFO]: Epoch 030 - training loss: 0.3938, validation loss: 0.3798
2024-06-02 01:24:33 [INFO]: Epoch 031 - training loss: 0.3881, validation loss: 0.3593
2024-06-02 01:24:33 [INFO]: Epoch 032 - training loss: 0.3916, validation loss: 0.3700
2024-06-02 01:24:34 [INFO]: Epoch 033 - training loss: 0.3927, validation loss: 0.3618
2024-06-02 01:24:35 [INFO]: Epoch 034 - training loss: 0.3885, validation loss: 0.3624
2024-06-02 01:24:36 [INFO]: Epoch 035 - training loss: 0.3835, validation loss: 0.3640
2024-06-02 01:24:37 [INFO]: Epoch 036 - training loss: 0.3923, validation loss: 0.3549
2024-06-02 01:24:38 [INFO]: Epoch 037 - training loss: 0.3891, validation loss: 0.3585
2024-06-02 01:24:39 [INFO]: Epoch 038 - training loss: 0.3896, validation loss: 0.3552
2024-06-02 01:24:40 [INFO]: Epoch 039 - training loss: 0.3848, validation loss: 0.3536
2024-06-02 01:24:41 [INFO]: Epoch 040 - training loss: 0.3832, validation loss: 0.3473
2024-06-02 01:24:42 [INFO]: Epoch 041 - training loss: 0.3837, validation loss: 0.3431
2024-06-02 01:24:43 [INFO]: Epoch 042 - training loss: 0.3821, validation loss: 0.3564
2024-06-02 01:24:44 [INFO]: Epoch 043 - training loss: 0.3809, validation loss: 0.3555
2024-06-02 01:24:45 [INFO]: Epoch 044 - training loss: 0.3837, validation loss: 0.3515
2024-06-02 01:24:47 [INFO]: Epoch 045 - training loss: 0.3809, validation loss: 0.3508
2024-06-02 01:24:48 [INFO]: Epoch 046 - training loss: 0.3807, validation loss: 0.3453
2024-06-02 01:24:49 [INFO]: Epoch 047 - training loss: 0.3815, validation loss: 0.3466
2024-06-02 01:24:50 [INFO]: Epoch 048 - training loss: 0.3788, validation loss: 0.3433
2024-06-02 01:24:50 [INFO]: Epoch 049 - training loss: 0.3778, validation loss: 0.3507
2024-06-02 01:24:51 [INFO]: Epoch 050 - training loss: 0.3770, validation loss: 0.3531
2024-06-02 01:24:52 [INFO]: Epoch 051 - training loss: 0.3802, validation loss: 0.3500
2024-06-02 01:24:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:24:52 [INFO]: Finished training. The best model is from epoch#41.
2024-06-02 01:24:52 [INFO]: Saved the model to results_point_rate01/PeMS/ETSformer_PeMS/round_2/20240602_T012403/ETSformer.pypots
2024-06-02 01:24:52 [INFO]: Successfully saved to results_point_rate01/PeMS/ETSformer_PeMS/round_2/imputation.pkl
2024-06-02 01:24:52 [INFO]: Round2 - ETSformer on PeMS: MAE=0.3508, MSE=0.5087, MRE=0.4349
2024-06-02 01:24:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 01:24:52 [INFO]: Using the given device: cuda:0
2024-06-02 01:24:52 [INFO]: Model files will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_3/20240602_T012452
2024-06-02 01:24:52 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_3/20240602_T012452/tensorboard
2024-06-02 01:24:52 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-02 01:24:53 [INFO]: Epoch 001 - training loss: 1.6181, validation loss: 0.8768
2024-06-02 01:24:54 [INFO]: Epoch 002 - training loss: 0.8017, validation loss: 0.5431
2024-06-02 01:24:56 [INFO]: Epoch 003 - training loss: 0.6548, validation loss: 0.5072
2024-06-02 01:24:56 [INFO]: Epoch 004 - training loss: 0.5905, validation loss: 0.4961
2024-06-02 01:24:58 [INFO]: Epoch 005 - training loss: 0.5592, validation loss: 0.4444
2024-06-02 01:24:59 [INFO]: Epoch 006 - training loss: 0.5403, validation loss: 0.4543
2024-06-02 01:25:00 [INFO]: Epoch 007 - training loss: 0.5149, validation loss: 0.4449
2024-06-02 01:25:01 [INFO]: Epoch 008 - training loss: 0.5058, validation loss: 0.4172
2024-06-02 01:25:02 [INFO]: Epoch 009 - training loss: 0.4876, validation loss: 0.4446
2024-06-02 01:25:03 [INFO]: Epoch 010 - training loss: 0.4764, validation loss: 0.4453
2024-06-02 01:25:04 [INFO]: Epoch 011 - training loss: 0.4701, validation loss: 0.4179
2024-06-02 01:25:05 [INFO]: Epoch 012 - training loss: 0.4550, validation loss: 0.4103
2024-06-02 01:25:06 [INFO]: Epoch 013 - training loss: 0.4497, validation loss: 0.4184
2024-06-02 01:25:07 [INFO]: Epoch 014 - training loss: 0.4512, validation loss: 0.3916
2024-06-02 01:25:07 [INFO]: Epoch 015 - training loss: 0.4391, validation loss: 0.3942
2024-06-02 01:25:08 [INFO]: Epoch 016 - training loss: 0.4312, validation loss: 0.4062
2024-06-02 01:25:09 [INFO]: Epoch 017 - training loss: 0.4255, validation loss: 0.3906
2024-06-02 01:25:10 [INFO]: Epoch 018 - training loss: 0.4225, validation loss: 0.3951
2024-06-02 01:25:11 [INFO]: Epoch 019 - training loss: 0.4222, validation loss: 0.3917
2024-06-02 01:25:11 [INFO]: Epoch 020 - training loss: 0.4218, validation loss: 0.3696
2024-06-02 01:25:12 [INFO]: Epoch 021 - training loss: 0.4101, validation loss: 0.3840
2024-06-02 01:25:13 [INFO]: Epoch 022 - training loss: 0.4062, validation loss: 0.3708
2024-06-02 01:25:14 [INFO]: Epoch 023 - training loss: 0.4022, validation loss: 0.3718
2024-06-02 01:25:15 [INFO]: Epoch 024 - training loss: 0.4037, validation loss: 0.3696
2024-06-02 01:25:16 [INFO]: Epoch 025 - training loss: 0.3991, validation loss: 0.3720
2024-06-02 01:25:17 [INFO]: Epoch 026 - training loss: 0.3981, validation loss: 0.3618
2024-06-02 01:25:18 [INFO]: Epoch 027 - training loss: 0.3993, validation loss: 0.3636
2024-06-02 01:25:20 [INFO]: Epoch 028 - training loss: 0.3904, validation loss: 0.3696
2024-06-02 01:25:21 [INFO]: Epoch 029 - training loss: 0.3913, validation loss: 0.3690
2024-06-02 01:25:22 [INFO]: Epoch 030 - training loss: 0.3908, validation loss: 0.3702
2024-06-02 01:25:23 [INFO]: Epoch 031 - training loss: 0.3916, validation loss: 0.3581
2024-06-02 01:25:24 [INFO]: Epoch 032 - training loss: 0.3893, validation loss: 0.3595
2024-06-02 01:25:24 [INFO]: Epoch 033 - training loss: 0.3867, validation loss: 0.3556
2024-06-02 01:25:26 [INFO]: Epoch 034 - training loss: 0.3877, validation loss: 0.3663
2024-06-02 01:25:27 [INFO]: Epoch 035 - training loss: 0.3853, validation loss: 0.3562
2024-06-02 01:25:28 [INFO]: Epoch 036 - training loss: 0.3843, validation loss: 0.3603
2024-06-02 01:25:29 [INFO]: Epoch 037 - training loss: 0.3799, validation loss: 0.3618
2024-06-02 01:25:30 [INFO]: Epoch 038 - training loss: 0.3856, validation loss: 0.3657
2024-06-02 01:25:31 [INFO]: Epoch 039 - training loss: 0.3849, validation loss: 0.3564
2024-06-02 01:25:32 [INFO]: Epoch 040 - training loss: 0.3825, validation loss: 0.3537
2024-06-02 01:25:33 [INFO]: Epoch 041 - training loss: 0.3792, validation loss: 0.3542
2024-06-02 01:25:34 [INFO]: Epoch 042 - training loss: 0.3790, validation loss: 0.3496
2024-06-02 01:25:35 [INFO]: Epoch 043 - training loss: 0.3813, validation loss: 0.3645
2024-06-02 01:25:36 [INFO]: Epoch 044 - training loss: 0.3807, validation loss: 0.3521
2024-06-02 01:25:37 [INFO]: Epoch 045 - training loss: 0.3783, validation loss: 0.3567
2024-06-02 01:25:38 [INFO]: Epoch 046 - training loss: 0.3814, validation loss: 0.3504
2024-06-02 01:25:39 [INFO]: Epoch 047 - training loss: 0.3799, validation loss: 0.3589
2024-06-02 01:25:40 [INFO]: Epoch 048 - training loss: 0.3795, validation loss: 0.3489
2024-06-02 01:25:41 [INFO]: Epoch 049 - training loss: 0.3826, validation loss: 0.3447
2024-06-02 01:25:42 [INFO]: Epoch 050 - training loss: 0.3819, validation loss: 0.3481
2024-06-02 01:25:43 [INFO]: Epoch 051 - training loss: 0.3778, validation loss: 0.3590
2024-06-02 01:25:44 [INFO]: Epoch 052 - training loss: 0.3777, validation loss: 0.3491
2024-06-02 01:25:45 [INFO]: Epoch 053 - training loss: 0.3749, validation loss: 0.3540
2024-06-02 01:25:46 [INFO]: Epoch 054 - training loss: 0.3767, validation loss: 0.3540
2024-06-02 01:25:46 [INFO]: Epoch 055 - training loss: 0.3742, validation loss: 0.3481
2024-06-02 01:25:47 [INFO]: Epoch 056 - training loss: 0.3752, validation loss: 0.3585
2024-06-02 01:25:48 [INFO]: Epoch 057 - training loss: 0.3733, validation loss: 0.3429
2024-06-02 01:25:49 [INFO]: Epoch 058 - training loss: 0.3739, validation loss: 0.3522
2024-06-02 01:25:50 [INFO]: Epoch 059 - training loss: 0.3724, validation loss: 0.3478
2024-06-02 01:25:51 [INFO]: Epoch 060 - training loss: 0.3744, validation loss: 0.3576
2024-06-02 01:25:52 [INFO]: Epoch 061 - training loss: 0.3773, validation loss: 0.3390
2024-06-02 01:25:53 [INFO]: Epoch 062 - training loss: 0.3767, validation loss: 0.3575
2024-06-02 01:25:54 [INFO]: Epoch 063 - training loss: 0.3775, validation loss: 0.3458
2024-06-02 01:25:55 [INFO]: Epoch 064 - training loss: 0.3755, validation loss: 0.3438
2024-06-02 01:25:56 [INFO]: Epoch 065 - training loss: 0.3757, validation loss: 0.3483
2024-06-02 01:25:57 [INFO]: Epoch 066 - training loss: 0.3695, validation loss: 0.3495
2024-06-02 01:25:58 [INFO]: Epoch 067 - training loss: 0.3742, validation loss: 0.3374
2024-06-02 01:25:59 [INFO]: Epoch 068 - training loss: 0.3769, validation loss: 0.3472
2024-06-02 01:26:00 [INFO]: Epoch 069 - training loss: 0.3719, validation loss: 0.3476
2024-06-02 01:26:01 [INFO]: Epoch 070 - training loss: 0.3748, validation loss: 0.3440
2024-06-02 01:26:01 [INFO]: Epoch 071 - training loss: 0.3754, validation loss: 0.3517
2024-06-02 01:26:02 [INFO]: Epoch 072 - training loss: 0.3779, validation loss: 0.3539
2024-06-02 01:26:03 [INFO]: Epoch 073 - training loss: 0.3771, validation loss: 0.3416
2024-06-02 01:26:04 [INFO]: Epoch 074 - training loss: 0.3766, validation loss: 0.3518
2024-06-02 01:26:05 [INFO]: Epoch 075 - training loss: 0.3769, validation loss: 0.3566
2024-06-02 01:26:06 [INFO]: Epoch 076 - training loss: 0.3762, validation loss: 0.3459
2024-06-02 01:26:07 [INFO]: Epoch 077 - training loss: 0.3765, validation loss: 0.3402
2024-06-02 01:26:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:26:07 [INFO]: Finished training. The best model is from epoch#67.
2024-06-02 01:26:07 [INFO]: Saved the model to results_point_rate01/PeMS/ETSformer_PeMS/round_3/20240602_T012452/ETSformer.pypots
2024-06-02 01:26:07 [INFO]: Successfully saved to results_point_rate01/PeMS/ETSformer_PeMS/round_3/imputation.pkl
2024-06-02 01:26:07 [INFO]: Round3 - ETSformer on PeMS: MAE=0.3381, MSE=0.4975, MRE=0.4191
2024-06-02 01:26:07 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 01:26:07 [INFO]: Using the given device: cuda:0
2024-06-02 01:26:07 [INFO]: Model files will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_4/20240602_T012607
2024-06-02 01:26:07 [INFO]: Tensorboard file will be saved to results_point_rate01/PeMS/ETSformer_PeMS/round_4/20240602_T012607/tensorboard
2024-06-02 01:26:07 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-02 01:26:08 [INFO]: Epoch 001 - training loss: 1.5363, validation loss: 0.7784
2024-06-02 01:26:09 [INFO]: Epoch 002 - training loss: 0.7978, validation loss: 0.5582
2024-06-02 01:26:10 [INFO]: Epoch 003 - training loss: 0.6779, validation loss: 0.5109
2024-06-02 01:26:11 [INFO]: Epoch 004 - training loss: 0.6061, validation loss: 0.5101
2024-06-02 01:26:12 [INFO]: Epoch 005 - training loss: 0.5589, validation loss: 0.4639
2024-06-02 01:26:13 [INFO]: Epoch 006 - training loss: 0.5528, validation loss: 0.4733
2024-06-02 01:26:14 [INFO]: Epoch 007 - training loss: 0.5190, validation loss: 0.4624
2024-06-02 01:26:15 [INFO]: Epoch 008 - training loss: 0.4962, validation loss: 0.4480
2024-06-02 01:26:16 [INFO]: Epoch 009 - training loss: 0.4878, validation loss: 0.4341
2024-06-02 01:26:17 [INFO]: Epoch 010 - training loss: 0.4917, validation loss: 0.4207
2024-06-02 01:26:18 [INFO]: Epoch 011 - training loss: 0.4842, validation loss: 0.4360
2024-06-02 01:26:18 [INFO]: Epoch 012 - training loss: 0.4599, validation loss: 0.4322
2024-06-02 01:26:19 [INFO]: Epoch 013 - training loss: 0.4478, validation loss: 0.4304
2024-06-02 01:26:19 [INFO]: Epoch 014 - training loss: 0.4451, validation loss: 0.4387
2024-06-02 01:26:19 [INFO]: Epoch 015 - training loss: 0.4479, validation loss: 0.4184
2024-06-02 01:26:20 [INFO]: Epoch 016 - training loss: 0.4317, validation loss: 0.3948
2024-06-02 01:26:20 [INFO]: Epoch 017 - training loss: 0.4329, validation loss: 0.4085
2024-06-02 01:26:21 [INFO]: Epoch 018 - training loss: 0.4243, validation loss: 0.3970
2024-06-02 01:26:21 [INFO]: Epoch 019 - training loss: 0.4181, validation loss: 0.3945
2024-06-02 01:26:21 [INFO]: Epoch 020 - training loss: 0.4173, validation loss: 0.4052
2024-06-02 01:26:22 [INFO]: Epoch 021 - training loss: 0.4115, validation loss: 0.4073
2024-06-02 01:26:22 [INFO]: Epoch 022 - training loss: 0.4169, validation loss: 0.3818
2024-06-02 01:26:23 [INFO]: Epoch 023 - training loss: 0.4048, validation loss: 0.3845
2024-06-02 01:26:23 [INFO]: Epoch 024 - training loss: 0.4063, validation loss: 0.3909
2024-06-02 01:26:24 [INFO]: Epoch 025 - training loss: 0.4045, validation loss: 0.3888
2024-06-02 01:26:24 [INFO]: Epoch 026 - training loss: 0.3987, validation loss: 0.3734
2024-06-02 01:26:24 [INFO]: Epoch 027 - training loss: 0.3997, validation loss: 0.3808
2024-06-02 01:26:25 [INFO]: Epoch 028 - training loss: 0.4003, validation loss: 0.3738
2024-06-02 01:26:25 [INFO]: Epoch 029 - training loss: 0.3966, validation loss: 0.3724
2024-06-02 01:26:26 [INFO]: Epoch 030 - training loss: 0.3920, validation loss: 0.3828
2024-06-02 01:26:26 [INFO]: Epoch 031 - training loss: 0.3939, validation loss: 0.3710
2024-06-02 01:26:26 [INFO]: Epoch 032 - training loss: 0.3949, validation loss: 0.3578
2024-06-02 01:26:27 [INFO]: Epoch 033 - training loss: 0.3939, validation loss: 0.3650
2024-06-02 01:26:27 [INFO]: Epoch 034 - training loss: 0.3923, validation loss: 0.3575
2024-06-02 01:26:28 [INFO]: Epoch 035 - training loss: 0.3927, validation loss: 0.3640
2024-06-02 01:26:28 [INFO]: Epoch 036 - training loss: 0.3870, validation loss: 0.3610
2024-06-02 01:26:28 [INFO]: Epoch 037 - training loss: 0.3838, validation loss: 0.3572
2024-06-02 01:26:29 [INFO]: Epoch 038 - training loss: 0.3824, validation loss: 0.3613
2024-06-02 01:26:29 [INFO]: Epoch 039 - training loss: 0.3860, validation loss: 0.3663
2024-06-02 01:26:30 [INFO]: Epoch 040 - training loss: 0.3848, validation loss: 0.3616
2024-06-02 01:26:30 [INFO]: Epoch 041 - training loss: 0.3800, validation loss: 0.3579
2024-06-02 01:26:31 [INFO]: Epoch 042 - training loss: 0.3841, validation loss: 0.3556
2024-06-02 01:26:31 [INFO]: Epoch 043 - training loss: 0.3813, validation loss: 0.3635
2024-06-02 01:26:31 [INFO]: Epoch 044 - training loss: 0.3827, validation loss: 0.3584
2024-06-02 01:26:32 [INFO]: Epoch 045 - training loss: 0.3787, validation loss: 0.3579
2024-06-02 01:26:32 [INFO]: Epoch 046 - training loss: 0.3795, validation loss: 0.3616
2024-06-02 01:26:33 [INFO]: Epoch 047 - training loss: 0.3819, validation loss: 0.3467
2024-06-02 01:26:33 [INFO]: Epoch 048 - training loss: 0.3796, validation loss: 0.3516
2024-06-02 01:26:33 [INFO]: Epoch 049 - training loss: 0.3746, validation loss: 0.3604
2024-06-02 01:26:34 [INFO]: Epoch 050 - training loss: 0.3838, validation loss: 0.3500
2024-06-02 01:26:34 [INFO]: Epoch 051 - training loss: 0.3814, validation loss: 0.3507
2024-06-02 01:26:35 [INFO]: Epoch 052 - training loss: 0.3818, validation loss: 0.3576
2024-06-02 01:26:35 [INFO]: Epoch 053 - training loss: 0.3794, validation loss: 0.3536
2024-06-02 01:26:36 [INFO]: Epoch 054 - training loss: 0.3739, validation loss: 0.3565
2024-06-02 01:26:36 [INFO]: Epoch 055 - training loss: 0.3762, validation loss: 0.3564
2024-06-02 01:26:36 [INFO]: Epoch 056 - training loss: 0.3757, validation loss: 0.3566
2024-06-02 01:26:37 [INFO]: Epoch 057 - training loss: 0.3789, validation loss: 0.3557
2024-06-02 01:26:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 01:26:37 [INFO]: Finished training. The best model is from epoch#47.
2024-06-02 01:26:37 [INFO]: Saved the model to results_point_rate01/PeMS/ETSformer_PeMS/round_4/20240602_T012607/ETSformer.pypots
2024-06-02 01:26:37 [INFO]: Successfully saved to results_point_rate01/PeMS/ETSformer_PeMS/round_4/imputation.pkl
2024-06-02 01:26:37 [INFO]: Round4 - ETSformer on PeMS: MAE=0.3563, MSE=0.5120, MRE=0.4417
2024-06-02 01:26:37 [INFO]: Done! Final results:
Averaged ETSformer (n params: 5,962,188) on PeMS: MAE=0.3474 ± 0.006029061809290718, MSE=0.5054 ± 0.004881458644367183, MRE=0.4307 ± 0.007473622795168203, average inference time=0.10
