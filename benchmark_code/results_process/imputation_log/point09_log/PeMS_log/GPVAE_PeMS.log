2024-06-03 03:53:27 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:53:27 [INFO]: Using the given device: cuda:0
2024-06-03 03:53:27 [INFO]: Model files will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_0/20240603_T035327
2024-06-03 03:53:27 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_0/20240603_T035327/tensorboard
2024-06-03 03:53:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 03:53:49 [INFO]: Epoch 001 - training loss: 624744.1646, validation loss: 1.1411
2024-06-03 03:53:57 [INFO]: Epoch 002 - training loss: 384066.0083, validation loss: 0.7019
2024-06-03 03:54:05 [INFO]: Epoch 003 - training loss: 277010.8646, validation loss: 0.5681
2024-06-03 03:54:12 [INFO]: Epoch 004 - training loss: 258255.0135, validation loss: 0.5427
2024-06-03 03:54:20 [INFO]: Epoch 005 - training loss: 253925.5562, validation loss: 0.5484
2024-06-03 03:54:28 [INFO]: Epoch 006 - training loss: 252349.6323, validation loss: 0.5073
2024-06-03 03:54:35 [INFO]: Epoch 007 - training loss: 251629.0594, validation loss: 0.5119
2024-06-03 03:54:43 [INFO]: Epoch 008 - training loss: 251258.0573, validation loss: 0.4947
2024-06-03 03:54:51 [INFO]: Epoch 009 - training loss: 251012.8427, validation loss: 0.5032
2024-06-03 03:54:59 [INFO]: Epoch 010 - training loss: 250865.3771, validation loss: 0.4903
2024-06-03 03:55:06 [INFO]: Epoch 011 - training loss: 250745.7323, validation loss: 0.5038
2024-06-03 03:55:14 [INFO]: Epoch 012 - training loss: 250666.8115, validation loss: 0.4979
2024-06-03 03:55:21 [INFO]: Epoch 013 - training loss: 250599.7188, validation loss: 0.5148
2024-06-03 03:55:29 [INFO]: Epoch 014 - training loss: 250556.6927, validation loss: 0.4784
2024-06-03 03:55:37 [INFO]: Epoch 015 - training loss: 250519.4542, validation loss: 0.4811
2024-06-03 03:55:44 [INFO]: Epoch 016 - training loss: 250475.9073, validation loss: 0.4852
2024-06-03 03:55:52 [INFO]: Epoch 017 - training loss: 250451.4427, validation loss: 0.4759
2024-06-03 03:56:00 [INFO]: Epoch 018 - training loss: 250433.6552, validation loss: 0.4820
2024-06-03 03:56:07 [INFO]: Epoch 019 - training loss: 250407.0479, validation loss: 0.4853
2024-06-03 03:56:15 [INFO]: Epoch 020 - training loss: 250388.9052, validation loss: 0.4835
2024-06-03 03:56:22 [INFO]: Epoch 021 - training loss: 250378.4375, validation loss: 0.4911
2024-06-03 03:56:30 [INFO]: Epoch 022 - training loss: 250363.7750, validation loss: 0.4767
2024-06-03 03:56:38 [INFO]: Epoch 023 - training loss: 250351.9010, validation loss: 0.4932
2024-06-03 03:56:46 [INFO]: Epoch 024 - training loss: 250347.6250, validation loss: 0.4864
2024-06-03 03:56:53 [INFO]: Epoch 025 - training loss: 250335.5625, validation loss: 0.4734
2024-06-03 03:57:01 [INFO]: Epoch 026 - training loss: 250326.1729, validation loss: 0.4656
2024-06-03 03:57:08 [INFO]: Epoch 027 - training loss: 250327.9958, validation loss: 0.4702
2024-06-03 03:57:16 [INFO]: Epoch 028 - training loss: 250351.0146, validation loss: 0.4684
2024-06-03 03:57:23 [INFO]: Epoch 029 - training loss: 250349.4823, validation loss: 0.4806
2024-06-03 03:57:31 [INFO]: Epoch 030 - training loss: 250399.0417, validation loss: 0.4941
2024-06-03 03:57:39 [INFO]: Epoch 031 - training loss: 250374.2875, validation loss: 0.4644
2024-06-03 03:57:46 [INFO]: Epoch 032 - training loss: 250420.3094, validation loss: 0.4845
2024-06-03 03:57:54 [INFO]: Epoch 033 - training loss: 250407.5104, validation loss: 0.4833
2024-06-03 03:58:02 [INFO]: Epoch 034 - training loss: 250392.9427, validation loss: 0.4704
2024-06-03 03:58:09 [INFO]: Epoch 035 - training loss: 250428.0083, validation loss: 0.4624
2024-06-03 03:58:16 [INFO]: Epoch 036 - training loss: 250500.5344, validation loss: 0.4780
2024-06-03 03:58:23 [INFO]: Epoch 037 - training loss: 250409.6917, validation loss: 0.4783
2024-06-03 03:58:30 [INFO]: Epoch 038 - training loss: 250420.5104, validation loss: 0.4659
2024-06-03 03:58:37 [INFO]: Epoch 039 - training loss: 250360.6854, validation loss: 0.4705
2024-06-03 03:58:43 [INFO]: Epoch 040 - training loss: 250348.0812, validation loss: 0.4648
2024-06-03 03:58:50 [INFO]: Epoch 041 - training loss: 250326.0438, validation loss: 0.4655
2024-06-03 03:58:57 [INFO]: Epoch 042 - training loss: 250303.3104, validation loss: 0.4939
2024-06-03 03:59:04 [INFO]: Epoch 043 - training loss: 250280.4438, validation loss: 0.4726
2024-06-03 03:59:11 [INFO]: Epoch 044 - training loss: 250275.6073, validation loss: 0.4707
2024-06-03 03:59:18 [INFO]: Epoch 045 - training loss: 250272.7531, validation loss: 0.4657
2024-06-03 03:59:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:59:18 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 03:59:18 [INFO]: Saved the model to results_point_rate09/PeMS/GPVAE_PeMS/round_0/20240603_T035327/GPVAE.pypots
2024-06-03 04:00:08 [INFO]: Successfully saved to results_point_rate09/PeMS/GPVAE_PeMS/round_0/imputation.pkl
2024-06-03 04:00:08 [INFO]: Round0 - GPVAE on PeMS: MAE=0.3481, MSE=0.6442, MRE=0.4319
2024-06-03 04:00:08 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:00:08 [INFO]: Using the given device: cuda:0
2024-06-03 04:00:08 [INFO]: Model files will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_1/20240603_T040008
2024-06-03 04:00:08 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_1/20240603_T040008/tensorboard
2024-06-03 04:00:09 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 04:00:15 [INFO]: Epoch 001 - training loss: 629815.7979, validation loss: 1.1346
2024-06-03 04:00:21 [INFO]: Epoch 002 - training loss: 383226.8896, validation loss: 0.7384
2024-06-03 04:00:27 [INFO]: Epoch 003 - training loss: 276343.0083, validation loss: 0.5835
2024-06-03 04:00:34 [INFO]: Epoch 004 - training loss: 257921.2521, validation loss: 0.5499
2024-06-03 04:00:40 [INFO]: Epoch 005 - training loss: 253679.5573, validation loss: 0.5208
2024-06-03 04:00:46 [INFO]: Epoch 006 - training loss: 252183.6521, validation loss: 0.5127
2024-06-03 04:00:51 [INFO]: Epoch 007 - training loss: 251549.0479, validation loss: 0.5122
2024-06-03 04:00:57 [INFO]: Epoch 008 - training loss: 251253.1271, validation loss: 0.5021
2024-06-03 04:01:02 [INFO]: Epoch 009 - training loss: 251011.4115, validation loss: 0.4893
2024-06-03 04:01:08 [INFO]: Epoch 010 - training loss: 250877.1406, validation loss: 0.4993
2024-06-03 04:01:14 [INFO]: Epoch 011 - training loss: 250727.7729, validation loss: 0.4891
2024-06-03 04:01:19 [INFO]: Epoch 012 - training loss: 250642.2250, validation loss: 0.4899
2024-06-03 04:01:25 [INFO]: Epoch 013 - training loss: 250584.8312, validation loss: 0.4918
2024-06-03 04:01:31 [INFO]: Epoch 014 - training loss: 250536.0594, validation loss: 0.4807
2024-06-03 04:01:36 [INFO]: Epoch 015 - training loss: 250487.0021, validation loss: 0.5009
2024-06-03 04:01:42 [INFO]: Epoch 016 - training loss: 250459.8302, validation loss: 0.4848
2024-06-03 04:01:47 [INFO]: Epoch 017 - training loss: 250430.1896, validation loss: 0.4838
2024-06-03 04:01:53 [INFO]: Epoch 018 - training loss: 250402.4146, validation loss: 0.4895
2024-06-03 04:01:58 [INFO]: Epoch 019 - training loss: 250387.9062, validation loss: 0.4745
2024-06-03 04:02:04 [INFO]: Epoch 020 - training loss: 250369.1896, validation loss: 0.4698
2024-06-03 04:02:09 [INFO]: Epoch 021 - training loss: 250356.4323, validation loss: 0.5067
2024-06-03 04:02:15 [INFO]: Epoch 022 - training loss: 250345.9708, validation loss: 0.4769
2024-06-03 04:02:20 [INFO]: Epoch 023 - training loss: 250333.6823, validation loss: 0.5020
2024-06-03 04:02:26 [INFO]: Epoch 024 - training loss: 250334.2094, validation loss: 0.4787
2024-06-03 04:02:31 [INFO]: Epoch 025 - training loss: 250325.7125, validation loss: 0.4722
2024-06-03 04:02:36 [INFO]: Epoch 026 - training loss: 250334.2500, validation loss: 0.4818
2024-06-03 04:02:42 [INFO]: Epoch 027 - training loss: 250365.9646, validation loss: 0.4761
2024-06-03 04:02:47 [INFO]: Epoch 028 - training loss: 250404.7052, validation loss: 0.4717
2024-06-03 04:02:53 [INFO]: Epoch 029 - training loss: 250415.1313, validation loss: 0.4645
2024-06-03 04:02:59 [INFO]: Epoch 030 - training loss: 250424.1375, validation loss: 0.4720
2024-06-03 04:03:04 [INFO]: Epoch 031 - training loss: 250486.9417, validation loss: 0.5303
2024-06-03 04:03:09 [INFO]: Epoch 032 - training loss: 250751.2906, validation loss: 0.4974
2024-06-03 04:03:14 [INFO]: Epoch 033 - training loss: 250538.9198, validation loss: 0.4661
2024-06-03 04:03:20 [INFO]: Epoch 034 - training loss: 250464.5333, validation loss: 0.4783
2024-06-03 04:03:25 [INFO]: Epoch 035 - training loss: 250433.9771, validation loss: 0.4668
2024-06-03 04:03:31 [INFO]: Epoch 036 - training loss: 250411.0427, validation loss: 0.4665
2024-06-03 04:03:36 [INFO]: Epoch 037 - training loss: 250484.6490, validation loss: 0.4660
2024-06-03 04:03:42 [INFO]: Epoch 038 - training loss: 250598.2563, validation loss: 0.4747
2024-06-03 04:03:47 [INFO]: Epoch 039 - training loss: 250355.2333, validation loss: 0.4961
2024-06-03 04:03:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:03:47 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 04:03:48 [INFO]: Saved the model to results_point_rate09/PeMS/GPVAE_PeMS/round_1/20240603_T040008/GPVAE.pypots
2024-06-03 04:04:30 [INFO]: Successfully saved to results_point_rate09/PeMS/GPVAE_PeMS/round_1/imputation.pkl
2024-06-03 04:04:30 [INFO]: Round1 - GPVAE on PeMS: MAE=0.3822, MSE=0.6711, MRE=0.4743
2024-06-03 04:04:30 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:04:30 [INFO]: Using the given device: cuda:0
2024-06-03 04:04:30 [INFO]: Model files will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_2/20240603_T040430
2024-06-03 04:04:30 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_2/20240603_T040430/tensorboard
2024-06-03 04:04:30 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 04:04:36 [INFO]: Epoch 001 - training loss: 618011.6083, validation loss: 1.0970
2024-06-03 04:04:41 [INFO]: Epoch 002 - training loss: 373255.1250, validation loss: 0.7014
2024-06-03 04:04:47 [INFO]: Epoch 003 - training loss: 274050.8271, validation loss: 0.5763
2024-06-03 04:04:52 [INFO]: Epoch 004 - training loss: 257278.9375, validation loss: 0.5422
2024-06-03 04:04:57 [INFO]: Epoch 005 - training loss: 253540.4990, validation loss: 0.5392
2024-06-03 04:05:02 [INFO]: Epoch 006 - training loss: 252155.9167, validation loss: 0.5172
2024-06-03 04:05:08 [INFO]: Epoch 007 - training loss: 251525.9031, validation loss: 0.5096
2024-06-03 04:05:13 [INFO]: Epoch 008 - training loss: 251122.1969, validation loss: 0.5041
2024-06-03 04:05:19 [INFO]: Epoch 009 - training loss: 250924.2854, validation loss: 0.5000
2024-06-03 04:05:24 [INFO]: Epoch 010 - training loss: 250777.4833, validation loss: 0.5256
2024-06-03 04:05:30 [INFO]: Epoch 011 - training loss: 250689.5698, validation loss: 0.5153
2024-06-03 04:05:35 [INFO]: Epoch 012 - training loss: 250612.1406, validation loss: 0.5015
2024-06-03 04:05:40 [INFO]: Epoch 013 - training loss: 250553.6521, validation loss: 0.5081
2024-06-03 04:05:46 [INFO]: Epoch 014 - training loss: 250516.7677, validation loss: 0.5291
2024-06-03 04:05:51 [INFO]: Epoch 015 - training loss: 250483.0708, validation loss: 0.5089
2024-06-03 04:05:57 [INFO]: Epoch 016 - training loss: 250447.7719, validation loss: 0.4916
2024-06-03 04:06:03 [INFO]: Epoch 017 - training loss: 250412.9417, validation loss: 0.4911
2024-06-03 04:06:08 [INFO]: Epoch 018 - training loss: 250392.4510, validation loss: 0.4778
2024-06-03 04:06:14 [INFO]: Epoch 019 - training loss: 250377.6865, validation loss: 0.4929
2024-06-03 04:06:20 [INFO]: Epoch 020 - training loss: 250375.8896, validation loss: 0.4727
2024-06-03 04:06:25 [INFO]: Epoch 021 - training loss: 250377.6990, validation loss: 0.4796
2024-06-03 04:06:30 [INFO]: Epoch 022 - training loss: 250410.9885, validation loss: 0.4812
2024-06-03 04:06:36 [INFO]: Epoch 023 - training loss: 250425.6812, validation loss: 0.4782
2024-06-03 04:06:41 [INFO]: Epoch 024 - training loss: 250406.1094, validation loss: 0.4720
2024-06-03 04:06:46 [INFO]: Epoch 025 - training loss: 250393.9312, validation loss: 0.4794
2024-06-03 04:06:51 [INFO]: Epoch 026 - training loss: 250401.9531, validation loss: 0.4710
2024-06-03 04:06:56 [INFO]: Epoch 027 - training loss: 250393.1656, validation loss: 0.4726
2024-06-03 04:07:00 [INFO]: Epoch 028 - training loss: 250414.2708, validation loss: 0.4775
2024-06-03 04:07:05 [INFO]: Epoch 029 - training loss: 250422.6917, validation loss: 0.4823
2024-06-03 04:07:09 [INFO]: Epoch 030 - training loss: 250453.3823, validation loss: 0.4735
2024-06-03 04:07:14 [INFO]: Epoch 031 - training loss: 250516.8135, validation loss: 0.4689
2024-06-03 04:07:19 [INFO]: Epoch 032 - training loss: 250422.4656, validation loss: 0.4688
2024-06-03 04:07:23 [INFO]: Epoch 033 - training loss: 250448.8062, validation loss: 0.4893
2024-06-03 04:07:28 [INFO]: Epoch 034 - training loss: 250400.0344, validation loss: 0.4689
2024-06-03 04:07:33 [INFO]: Epoch 035 - training loss: 250394.9427, validation loss: 0.4729
2024-06-03 04:07:37 [INFO]: Epoch 036 - training loss: 250392.9250, validation loss: 0.4615
2024-06-03 04:07:42 [INFO]: Epoch 037 - training loss: 250333.6052, validation loss: 0.4704
2024-06-03 04:07:47 [INFO]: Epoch 038 - training loss: 250312.3448, validation loss: 0.4697
2024-06-03 04:07:51 [INFO]: Epoch 039 - training loss: 250274.7500, validation loss: 0.4771
2024-06-03 04:07:56 [INFO]: Epoch 040 - training loss: 250263.9969, validation loss: 0.4671
2024-06-03 04:08:01 [INFO]: Epoch 041 - training loss: 250302.5167, validation loss: 0.4705
2024-06-03 04:08:05 [INFO]: Epoch 042 - training loss: 250358.2583, validation loss: 0.4655
2024-06-03 04:08:10 [INFO]: Epoch 043 - training loss: 250286.1969, validation loss: 0.4670
2024-06-03 04:08:15 [INFO]: Epoch 044 - training loss: 250257.6510, validation loss: 0.4634
2024-06-03 04:08:19 [INFO]: Epoch 045 - training loss: 250243.8958, validation loss: 0.4681
2024-06-03 04:08:24 [INFO]: Epoch 046 - training loss: 250237.9323, validation loss: 0.4690
2024-06-03 04:08:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:08:24 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 04:08:24 [INFO]: Saved the model to results_point_rate09/PeMS/GPVAE_PeMS/round_2/20240603_T040430/GPVAE.pypots
2024-06-03 04:08:59 [INFO]: Successfully saved to results_point_rate09/PeMS/GPVAE_PeMS/round_2/imputation.pkl
2024-06-03 04:08:59 [INFO]: Round2 - GPVAE on PeMS: MAE=0.3443, MSE=0.6444, MRE=0.4273
2024-06-03 04:08:59 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:08:59 [INFO]: Using the given device: cuda:0
2024-06-03 04:08:59 [INFO]: Model files will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_3/20240603_T040859
2024-06-03 04:08:59 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_3/20240603_T040859/tensorboard
2024-06-03 04:08:59 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 04:09:04 [INFO]: Epoch 001 - training loss: 624657.6792, validation loss: 1.1078
2024-06-03 04:09:09 [INFO]: Epoch 002 - training loss: 382649.2750, validation loss: 0.7236
2024-06-03 04:09:13 [INFO]: Epoch 003 - training loss: 278470.9458, validation loss: 0.5973
2024-06-03 04:09:18 [INFO]: Epoch 004 - training loss: 258376.7948, validation loss: 0.5459
2024-06-03 04:09:22 [INFO]: Epoch 005 - training loss: 254440.5865, validation loss: 0.5233
2024-06-03 04:09:27 [INFO]: Epoch 006 - training loss: 252511.1854, validation loss: 0.5149
2024-06-03 04:09:32 [INFO]: Epoch 007 - training loss: 251791.3896, validation loss: 0.5128
2024-06-03 04:09:36 [INFO]: Epoch 008 - training loss: 251333.2635, validation loss: 0.5076
2024-06-03 04:09:41 [INFO]: Epoch 009 - training loss: 251075.9604, validation loss: 0.4935
2024-06-03 04:09:45 [INFO]: Epoch 010 - training loss: 250900.6385, validation loss: 0.4923
2024-06-03 04:09:50 [INFO]: Epoch 011 - training loss: 250793.5031, validation loss: 0.4801
2024-06-03 04:09:54 [INFO]: Epoch 012 - training loss: 250704.5490, validation loss: 0.4820
2024-06-03 04:09:59 [INFO]: Epoch 013 - training loss: 250631.3281, validation loss: 0.4939
2024-06-03 04:10:03 [INFO]: Epoch 014 - training loss: 250577.8312, validation loss: 0.4859
2024-06-03 04:10:08 [INFO]: Epoch 015 - training loss: 250531.6375, validation loss: 0.4808
2024-06-03 04:10:13 [INFO]: Epoch 016 - training loss: 250496.6208, validation loss: 0.4882
2024-06-03 04:10:17 [INFO]: Epoch 017 - training loss: 250516.7167, validation loss: 0.4809
2024-06-03 04:10:22 [INFO]: Epoch 018 - training loss: 250470.2979, validation loss: 0.4825
2024-06-03 04:10:26 [INFO]: Epoch 019 - training loss: 250428.1406, validation loss: 0.4735
2024-06-03 04:10:31 [INFO]: Epoch 020 - training loss: 250405.5844, validation loss: 0.4765
2024-06-03 04:10:36 [INFO]: Epoch 021 - training loss: 250389.1719, validation loss: 0.4901
2024-06-03 04:10:41 [INFO]: Epoch 022 - training loss: 250380.4198, validation loss: 0.4749
2024-06-03 04:10:45 [INFO]: Epoch 023 - training loss: 250366.2021, validation loss: 0.4970
2024-06-03 04:10:50 [INFO]: Epoch 024 - training loss: 250366.9292, validation loss: 0.4855
2024-06-03 04:10:54 [INFO]: Epoch 025 - training loss: 250363.1354, validation loss: 0.4781
2024-06-03 04:10:59 [INFO]: Epoch 026 - training loss: 250355.9104, validation loss: 0.4793
2024-06-03 04:11:04 [INFO]: Epoch 027 - training loss: 250366.6063, validation loss: 0.5262
2024-06-03 04:11:08 [INFO]: Epoch 028 - training loss: 250375.5542, validation loss: 0.4758
2024-06-03 04:11:13 [INFO]: Epoch 029 - training loss: 250391.3469, validation loss: 0.4658
2024-06-03 04:11:17 [INFO]: Epoch 030 - training loss: 250419.1177, validation loss: 0.4842
2024-06-03 04:11:22 [INFO]: Epoch 031 - training loss: 250433.0729, validation loss: 0.4727
2024-06-03 04:11:26 [INFO]: Epoch 032 - training loss: 250401.2917, validation loss: 0.4768
2024-06-03 04:11:31 [INFO]: Epoch 033 - training loss: 250375.0531, validation loss: 0.4684
2024-06-03 04:11:36 [INFO]: Epoch 034 - training loss: 250362.7490, validation loss: 0.4685
2024-06-03 04:11:41 [INFO]: Epoch 035 - training loss: 250341.5302, validation loss: 0.4674
2024-06-03 04:11:45 [INFO]: Epoch 036 - training loss: 250337.0896, validation loss: 0.4734
2024-06-03 04:11:50 [INFO]: Epoch 037 - training loss: 250315.1260, validation loss: 0.4800
2024-06-03 04:11:55 [INFO]: Epoch 038 - training loss: 250314.3573, validation loss: 0.4741
2024-06-03 04:11:59 [INFO]: Epoch 039 - training loss: 250309.1781, validation loss: 0.4712
2024-06-03 04:11:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:11:59 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 04:11:59 [INFO]: Saved the model to results_point_rate09/PeMS/GPVAE_PeMS/round_3/20240603_T040859/GPVAE.pypots
2024-06-03 04:12:34 [INFO]: Successfully saved to results_point_rate09/PeMS/GPVAE_PeMS/round_3/imputation.pkl
2024-06-03 04:12:34 [INFO]: Round3 - GPVAE on PeMS: MAE=0.3586, MSE=0.6468, MRE=0.4450
2024-06-03 04:12:34 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:12:34 [INFO]: Using the given device: cuda:0
2024-06-03 04:12:34 [INFO]: Model files will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_4/20240603_T041234
2024-06-03 04:12:34 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/GPVAE_PeMS/round_4/20240603_T041234/tensorboard
2024-06-03 04:12:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 04:12:39 [INFO]: Epoch 001 - training loss: 629792.9167, validation loss: 1.1222
2024-06-03 04:12:44 [INFO]: Epoch 002 - training loss: 388327.1792, validation loss: 0.7075
2024-06-03 04:12:49 [INFO]: Epoch 003 - training loss: 277826.5104, validation loss: 0.5815
2024-06-03 04:12:53 [INFO]: Epoch 004 - training loss: 258223.9354, validation loss: 0.5474
2024-06-03 04:12:58 [INFO]: Epoch 005 - training loss: 253944.3417, validation loss: 0.5364
2024-06-03 04:13:02 [INFO]: Epoch 006 - training loss: 252518.8323, validation loss: 0.5175
2024-06-03 04:13:07 [INFO]: Epoch 007 - training loss: 251637.4813, validation loss: 0.5085
2024-06-03 04:13:12 [INFO]: Epoch 008 - training loss: 251244.0865, validation loss: 0.5029
2024-06-03 04:13:16 [INFO]: Epoch 009 - training loss: 251009.8104, validation loss: 0.5206
2024-06-03 04:13:21 [INFO]: Epoch 010 - training loss: 250862.2823, validation loss: 0.5028
2024-06-03 04:13:26 [INFO]: Epoch 011 - training loss: 250739.1719, validation loss: 0.4930
2024-06-03 04:13:30 [INFO]: Epoch 012 - training loss: 250650.1990, validation loss: 0.4851
2024-06-03 04:13:35 [INFO]: Epoch 013 - training loss: 250582.9052, validation loss: 0.4933
2024-06-03 04:13:39 [INFO]: Epoch 014 - training loss: 250538.5604, validation loss: 0.5178
2024-06-03 04:13:44 [INFO]: Epoch 015 - training loss: 250491.0490, validation loss: 0.4895
2024-06-03 04:13:48 [INFO]: Epoch 016 - training loss: 250462.1542, validation loss: 0.4912
2024-06-03 04:13:53 [INFO]: Epoch 017 - training loss: 250435.5281, validation loss: 0.4860
2024-06-03 04:13:58 [INFO]: Epoch 018 - training loss: 250410.3354, validation loss: 0.4792
2024-06-03 04:14:02 [INFO]: Epoch 019 - training loss: 250389.3896, validation loss: 0.4864
2024-06-03 04:14:07 [INFO]: Epoch 020 - training loss: 250373.1510, validation loss: 0.4840
2024-06-03 04:14:12 [INFO]: Epoch 021 - training loss: 250354.3323, validation loss: 0.4849
2024-06-03 04:14:16 [INFO]: Epoch 022 - training loss: 250341.6792, validation loss: 0.4765
2024-06-03 04:14:21 [INFO]: Epoch 023 - training loss: 250343.3979, validation loss: 0.4760
2024-06-03 04:14:26 [INFO]: Epoch 024 - training loss: 250360.2396, validation loss: 0.4951
2024-06-03 04:14:31 [INFO]: Epoch 025 - training loss: 250391.8146, validation loss: 0.4681
2024-06-03 04:14:35 [INFO]: Epoch 026 - training loss: 250431.8854, validation loss: 0.4794
2024-06-03 04:14:39 [INFO]: Epoch 027 - training loss: 250487.5094, validation loss: 0.4693
2024-06-03 04:14:44 [INFO]: Epoch 028 - training loss: 250402.6708, validation loss: 0.4699
2024-06-03 04:14:48 [INFO]: Epoch 029 - training loss: 250377.9917, validation loss: 0.4804
2024-06-03 04:14:53 [INFO]: Epoch 030 - training loss: 250365.8729, validation loss: 0.4822
2024-06-03 04:14:57 [INFO]: Epoch 031 - training loss: 250488.6177, validation loss: 0.4887
2024-06-03 04:15:02 [INFO]: Epoch 032 - training loss: 251070.9948, validation loss: 0.4755
2024-06-03 04:15:06 [INFO]: Epoch 033 - training loss: 250399.3021, validation loss: 0.4906
2024-06-03 04:15:11 [INFO]: Epoch 034 - training loss: 250359.7531, validation loss: 0.4634
2024-06-03 04:15:15 [INFO]: Epoch 035 - training loss: 250314.0042, validation loss: 0.4644
2024-06-03 04:15:20 [INFO]: Epoch 036 - training loss: 250297.6812, validation loss: 0.4861
2024-06-03 04:15:25 [INFO]: Epoch 037 - training loss: 250289.5896, validation loss: 0.4659
2024-06-03 04:15:29 [INFO]: Epoch 038 - training loss: 250281.9760, validation loss: 0.4692
2024-06-03 04:15:33 [INFO]: Epoch 039 - training loss: 250289.3594, validation loss: 0.4666
2024-06-03 04:15:38 [INFO]: Epoch 040 - training loss: 250285.8156, validation loss: 0.4817
2024-06-03 04:15:43 [INFO]: Epoch 041 - training loss: 250278.4625, validation loss: 0.4807
2024-06-03 04:15:47 [INFO]: Epoch 042 - training loss: 250261.1094, validation loss: 0.4676
2024-06-03 04:15:52 [INFO]: Epoch 043 - training loss: 250259.8531, validation loss: 0.4843
2024-06-03 04:15:57 [INFO]: Epoch 044 - training loss: 250256.9958, validation loss: 0.4725
2024-06-03 04:15:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:15:57 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 04:15:57 [INFO]: Saved the model to results_point_rate09/PeMS/GPVAE_PeMS/round_4/20240603_T041234/GPVAE.pypots
2024-06-03 04:16:32 [INFO]: Successfully saved to results_point_rate09/PeMS/GPVAE_PeMS/round_4/imputation.pkl
2024-06-03 04:16:32 [INFO]: Round4 - GPVAE on PeMS: MAE=0.3579, MSE=0.6513, MRE=0.4441
2024-06-03 04:16:32 [INFO]: Done! Final results:
Averaged GPVAE (2,396,536 params) on PeMS: MAE=0.3582 ± 0.01320710787410656, MSE=0.6515 ± 0.010102868747015695, MRE=0.4445 ± 0.01638778753596515, average inference time=8.21
