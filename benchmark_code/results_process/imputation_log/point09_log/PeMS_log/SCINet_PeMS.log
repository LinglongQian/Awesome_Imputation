2024-06-03 04:32:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:32:41 [INFO]: Using the given device: cuda:0
2024-06-03 04:32:42 [INFO]: Model files will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_0/20240603_T043242
2024-06-03 04:32:42 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_0/20240603_T043242/tensorboard
2024-06-03 04:33:23 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 04:33:36 [INFO]: Epoch 001 - training loss: 1.4682, validation loss: 1.2010
2024-06-03 04:33:44 [INFO]: Epoch 002 - training loss: 1.1219, validation loss: 1.0320
2024-06-03 04:33:53 [INFO]: Epoch 003 - training loss: 0.9899, validation loss: 0.9430
2024-06-03 04:34:00 [INFO]: Epoch 004 - training loss: 0.9117, validation loss: 0.8774
2024-06-03 04:34:08 [INFO]: Epoch 005 - training loss: 0.8370, validation loss: 0.8096
2024-06-03 04:34:17 [INFO]: Epoch 006 - training loss: 0.7794, validation loss: 0.7639
2024-06-03 04:34:25 [INFO]: Epoch 007 - training loss: 0.7337, validation loss: 0.7281
2024-06-03 04:34:34 [INFO]: Epoch 008 - training loss: 0.7003, validation loss: 0.7018
2024-06-03 04:34:42 [INFO]: Epoch 009 - training loss: 0.6768, validation loss: 0.6890
2024-06-03 04:34:50 [INFO]: Epoch 010 - training loss: 0.6595, validation loss: 0.6796
2024-06-03 04:34:59 [INFO]: Epoch 011 - training loss: 0.6476, validation loss: 0.6555
2024-06-03 04:35:08 [INFO]: Epoch 012 - training loss: 0.6426, validation loss: 0.6564
2024-06-03 04:35:16 [INFO]: Epoch 013 - training loss: 0.6315, validation loss: 0.6424
2024-06-03 04:35:23 [INFO]: Epoch 014 - training loss: 0.6274, validation loss: 0.6360
2024-06-03 04:35:32 [INFO]: Epoch 015 - training loss: 0.6162, validation loss: 0.6318
2024-06-03 04:35:40 [INFO]: Epoch 016 - training loss: 0.6096, validation loss: 0.6233
2024-06-03 04:35:49 [INFO]: Epoch 017 - training loss: 0.6065, validation loss: 0.6179
2024-06-03 04:35:57 [INFO]: Epoch 018 - training loss: 0.6032, validation loss: 0.6182
2024-06-03 04:36:05 [INFO]: Epoch 019 - training loss: 0.5933, validation loss: 0.6000
2024-06-03 04:36:14 [INFO]: Epoch 020 - training loss: 0.5908, validation loss: 0.5980
2024-06-03 04:36:22 [INFO]: Epoch 021 - training loss: 0.5900, validation loss: 0.5993
2024-06-03 04:36:31 [INFO]: Epoch 022 - training loss: 0.5824, validation loss: 0.5944
2024-06-03 04:36:39 [INFO]: Epoch 023 - training loss: 0.5794, validation loss: 0.5854
2024-06-03 04:36:47 [INFO]: Epoch 024 - training loss: 0.5777, validation loss: 0.5866
2024-06-03 04:36:55 [INFO]: Epoch 025 - training loss: 0.5724, validation loss: 0.5832
2024-06-03 04:37:04 [INFO]: Epoch 026 - training loss: 0.5713, validation loss: 0.5774
2024-06-03 04:37:12 [INFO]: Epoch 027 - training loss: 0.5660, validation loss: 0.5784
2024-06-03 04:37:21 [INFO]: Epoch 028 - training loss: 0.5665, validation loss: 0.5830
2024-06-03 04:37:29 [INFO]: Epoch 029 - training loss: 0.5683, validation loss: 0.5733
2024-06-03 04:37:37 [INFO]: Epoch 030 - training loss: 0.5598, validation loss: 0.5728
2024-06-03 04:37:46 [INFO]: Epoch 031 - training loss: 0.5582, validation loss: 0.5698
2024-06-03 04:37:54 [INFO]: Epoch 032 - training loss: 0.5587, validation loss: 0.5667
2024-06-03 04:38:03 [INFO]: Epoch 033 - training loss: 0.5538, validation loss: 0.5661
2024-06-03 04:38:11 [INFO]: Epoch 034 - training loss: 0.5535, validation loss: 0.5679
2024-06-03 04:38:18 [INFO]: Epoch 035 - training loss: 0.5501, validation loss: 0.5658
2024-06-03 04:38:27 [INFO]: Epoch 036 - training loss: 0.5500, validation loss: 0.5625
2024-06-03 04:38:35 [INFO]: Epoch 037 - training loss: 0.5507, validation loss: 0.5661
2024-06-03 04:38:43 [INFO]: Epoch 038 - training loss: 0.5454, validation loss: 0.5633
2024-06-03 04:38:52 [INFO]: Epoch 039 - training loss: 0.5493, validation loss: 0.5622
2024-06-03 04:39:00 [INFO]: Epoch 040 - training loss: 0.5440, validation loss: 0.5550
2024-06-03 04:39:09 [INFO]: Epoch 041 - training loss: 0.5419, validation loss: 0.5549
2024-06-03 04:39:18 [INFO]: Epoch 042 - training loss: 0.5387, validation loss: 0.5554
2024-06-03 04:39:26 [INFO]: Epoch 043 - training loss: 0.5419, validation loss: 0.5596
2024-06-03 04:39:34 [INFO]: Epoch 044 - training loss: 0.5406, validation loss: 0.5586
2024-06-03 04:39:42 [INFO]: Epoch 045 - training loss: 0.5376, validation loss: 0.5586
2024-06-03 04:39:49 [INFO]: Epoch 046 - training loss: 0.5415, validation loss: 0.5574
2024-06-03 04:39:56 [INFO]: Epoch 047 - training loss: 0.5408, validation loss: 0.5565
2024-06-03 04:40:04 [INFO]: Epoch 048 - training loss: 0.5353, validation loss: 0.5539
2024-06-03 04:40:10 [INFO]: Epoch 049 - training loss: 0.5370, validation loss: 0.5583
2024-06-03 04:40:18 [INFO]: Epoch 050 - training loss: 0.5327, validation loss: 0.5568
2024-06-03 04:40:25 [INFO]: Epoch 051 - training loss: 0.5323, validation loss: 0.5585
2024-06-03 04:40:33 [INFO]: Epoch 052 - training loss: 0.5339, validation loss: 0.5592
2024-06-03 04:40:40 [INFO]: Epoch 053 - training loss: 0.5315, validation loss: 0.5572
2024-06-03 04:40:47 [INFO]: Epoch 054 - training loss: 0.5316, validation loss: 0.5560
2024-06-03 04:40:54 [INFO]: Epoch 055 - training loss: 0.5291, validation loss: 0.5575
2024-06-03 04:41:02 [INFO]: Epoch 056 - training loss: 0.5313, validation loss: 0.5562
2024-06-03 04:41:09 [INFO]: Epoch 057 - training loss: 0.5288, validation loss: 0.5592
2024-06-03 04:41:16 [INFO]: Epoch 058 - training loss: 0.5333, validation loss: 0.5535
2024-06-03 04:41:24 [INFO]: Epoch 059 - training loss: 0.5291, validation loss: 0.5520
2024-06-03 04:41:31 [INFO]: Epoch 060 - training loss: 0.5276, validation loss: 0.5484
2024-06-03 04:41:38 [INFO]: Epoch 061 - training loss: 0.5260, validation loss: 0.5538
2024-06-03 04:41:45 [INFO]: Epoch 062 - training loss: 0.5268, validation loss: 0.5526
2024-06-03 04:41:52 [INFO]: Epoch 063 - training loss: 0.5277, validation loss: 0.5567
2024-06-03 04:41:59 [INFO]: Epoch 064 - training loss: 0.5258, validation loss: 0.5606
2024-06-03 04:42:06 [INFO]: Epoch 065 - training loss: 0.5212, validation loss: 0.5507
2024-06-03 04:42:13 [INFO]: Epoch 066 - training loss: 0.5223, validation loss: 0.5527
2024-06-03 04:42:20 [INFO]: Epoch 067 - training loss: 0.5254, validation loss: 0.5520
2024-06-03 04:42:27 [INFO]: Epoch 068 - training loss: 0.5197, validation loss: 0.5539
2024-06-03 04:42:33 [INFO]: Epoch 069 - training loss: 0.5219, validation loss: 0.5512
2024-06-03 04:42:40 [INFO]: Epoch 070 - training loss: 0.5210, validation loss: 0.5610
2024-06-03 04:42:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:42:40 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 04:42:58 [INFO]: Saved the model to results_point_rate09/PeMS/SCINet_PeMS/round_0/20240603_T043242/SCINet.pypots
2024-06-03 04:43:01 [INFO]: Successfully saved to results_point_rate09/PeMS/SCINet_PeMS/round_0/imputation.pkl
2024-06-03 04:43:01 [INFO]: Round0 - SCINet on PeMS: MAE=0.4466, MSE=0.7740, MRE=0.5541
2024-06-03 04:43:01 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:43:01 [INFO]: Using the given device: cuda:0
2024-06-03 04:43:01 [INFO]: Model files will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_1/20240603_T044301
2024-06-03 04:43:01 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_1/20240603_T044301/tensorboard
2024-06-03 04:43:22 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 04:43:29 [INFO]: Epoch 001 - training loss: 1.3214, validation loss: 1.0189
2024-06-03 04:43:35 [INFO]: Epoch 002 - training loss: 1.0177, validation loss: 1.0056
2024-06-03 04:43:42 [INFO]: Epoch 003 - training loss: 0.9132, validation loss: 0.9773
2024-06-03 04:43:49 [INFO]: Epoch 004 - training loss: 0.8548, validation loss: 0.9681
2024-06-03 04:43:56 [INFO]: Epoch 005 - training loss: 0.8064, validation loss: 0.9536
2024-06-03 04:44:02 [INFO]: Epoch 006 - training loss: 0.7743, validation loss: 0.9458
2024-06-03 04:44:10 [INFO]: Epoch 007 - training loss: 0.7476, validation loss: 0.9318
2024-06-03 04:44:17 [INFO]: Epoch 008 - training loss: 0.7229, validation loss: 0.9161
2024-06-03 04:44:24 [INFO]: Epoch 009 - training loss: 0.7030, validation loss: 0.9154
2024-06-03 04:44:31 [INFO]: Epoch 010 - training loss: 0.6904, validation loss: 0.8984
2024-06-03 04:44:38 [INFO]: Epoch 011 - training loss: 0.6759, validation loss: 0.8946
2024-06-03 04:44:45 [INFO]: Epoch 012 - training loss: 0.6671, validation loss: 0.8891
2024-06-03 04:44:52 [INFO]: Epoch 013 - training loss: 0.6494, validation loss: 0.8666
2024-06-03 04:44:58 [INFO]: Epoch 014 - training loss: 0.6486, validation loss: 0.8611
2024-06-03 04:45:05 [INFO]: Epoch 015 - training loss: 0.6370, validation loss: 0.8460
2024-06-03 04:45:12 [INFO]: Epoch 016 - training loss: 0.6325, validation loss: 0.8390
2024-06-03 04:45:19 [INFO]: Epoch 017 - training loss: 0.6194, validation loss: 0.8295
2024-06-03 04:45:25 [INFO]: Epoch 018 - training loss: 0.6145, validation loss: 0.8126
2024-06-03 04:45:32 [INFO]: Epoch 019 - training loss: 0.6117, validation loss: 0.7948
2024-06-03 04:45:39 [INFO]: Epoch 020 - training loss: 0.6036, validation loss: 0.7894
2024-06-03 04:45:47 [INFO]: Epoch 021 - training loss: 0.6034, validation loss: 0.7726
2024-06-03 04:45:53 [INFO]: Epoch 022 - training loss: 0.5926, validation loss: 0.7587
2024-06-03 04:46:00 [INFO]: Epoch 023 - training loss: 0.5895, validation loss: 0.7541
2024-06-03 04:46:05 [INFO]: Epoch 024 - training loss: 0.5843, validation loss: 0.7402
2024-06-03 04:46:11 [INFO]: Epoch 025 - training loss: 0.5775, validation loss: 0.7303
2024-06-03 04:46:16 [INFO]: Epoch 026 - training loss: 0.5813, validation loss: 0.7246
2024-06-03 04:46:22 [INFO]: Epoch 027 - training loss: 0.5761, validation loss: 0.7163
2024-06-03 04:46:28 [INFO]: Epoch 028 - training loss: 0.5694, validation loss: 0.7129
2024-06-03 04:46:33 [INFO]: Epoch 029 - training loss: 0.5675, validation loss: 0.7011
2024-06-03 04:46:39 [INFO]: Epoch 030 - training loss: 0.5641, validation loss: 0.6952
2024-06-03 04:46:44 [INFO]: Epoch 031 - training loss: 0.5584, validation loss: 0.6900
2024-06-03 04:46:50 [INFO]: Epoch 032 - training loss: 0.5570, validation loss: 0.6891
2024-06-03 04:46:56 [INFO]: Epoch 033 - training loss: 0.5573, validation loss: 0.6796
2024-06-03 04:47:01 [INFO]: Epoch 034 - training loss: 0.5550, validation loss: 0.6752
2024-06-03 04:47:07 [INFO]: Epoch 035 - training loss: 0.5529, validation loss: 0.6667
2024-06-03 04:47:13 [INFO]: Epoch 036 - training loss: 0.5519, validation loss: 0.6650
2024-06-03 04:47:18 [INFO]: Epoch 037 - training loss: 0.5510, validation loss: 0.6623
2024-06-03 04:47:24 [INFO]: Epoch 038 - training loss: 0.5456, validation loss: 0.6605
2024-06-03 04:47:30 [INFO]: Epoch 039 - training loss: 0.5439, validation loss: 0.6508
2024-06-03 04:47:35 [INFO]: Epoch 040 - training loss: 0.5390, validation loss: 0.6541
2024-06-03 04:47:40 [INFO]: Epoch 041 - training loss: 0.5433, validation loss: 0.6435
2024-06-03 04:47:44 [INFO]: Epoch 042 - training loss: 0.5396, validation loss: 0.6406
2024-06-03 04:47:49 [INFO]: Epoch 043 - training loss: 0.5400, validation loss: 0.6422
2024-06-03 04:47:53 [INFO]: Epoch 044 - training loss: 0.5376, validation loss: 0.6379
2024-06-03 04:47:57 [INFO]: Epoch 045 - training loss: 0.5353, validation loss: 0.6381
2024-06-03 04:48:01 [INFO]: Epoch 046 - training loss: 0.5358, validation loss: 0.6345
2024-06-03 04:48:05 [INFO]: Epoch 047 - training loss: 0.5335, validation loss: 0.6375
2024-06-03 04:48:09 [INFO]: Epoch 048 - training loss: 0.5311, validation loss: 0.6323
2024-06-03 04:48:13 [INFO]: Epoch 049 - training loss: 0.5329, validation loss: 0.6228
2024-06-03 04:48:17 [INFO]: Epoch 050 - training loss: 0.5295, validation loss: 0.6214
2024-06-03 04:48:21 [INFO]: Epoch 051 - training loss: 0.5289, validation loss: 0.6258
2024-06-03 04:48:26 [INFO]: Epoch 052 - training loss: 0.5264, validation loss: 0.6239
2024-06-03 04:48:30 [INFO]: Epoch 053 - training loss: 0.5267, validation loss: 0.6122
2024-06-03 04:48:34 [INFO]: Epoch 054 - training loss: 0.5266, validation loss: 0.6111
2024-06-03 04:48:38 [INFO]: Epoch 055 - training loss: 0.5198, validation loss: 0.6150
2024-06-03 04:48:42 [INFO]: Epoch 056 - training loss: 0.5245, validation loss: 0.6093
2024-06-03 04:48:46 [INFO]: Epoch 057 - training loss: 0.5218, validation loss: 0.6118
2024-06-03 04:48:50 [INFO]: Epoch 058 - training loss: 0.5245, validation loss: 0.6096
2024-06-03 04:48:54 [INFO]: Epoch 059 - training loss: 0.5192, validation loss: 0.6055
2024-06-03 04:48:58 [INFO]: Epoch 060 - training loss: 0.5204, validation loss: 0.6059
2024-06-03 04:49:03 [INFO]: Epoch 061 - training loss: 0.5206, validation loss: 0.6055
2024-06-03 04:49:07 [INFO]: Epoch 062 - training loss: 0.5182, validation loss: 0.6063
2024-06-03 04:49:11 [INFO]: Epoch 063 - training loss: 0.5173, validation loss: 0.6032
2024-06-03 04:49:15 [INFO]: Epoch 064 - training loss: 0.5167, validation loss: 0.6028
2024-06-03 04:49:19 [INFO]: Epoch 065 - training loss: 0.5189, validation loss: 0.6006
2024-06-03 04:49:23 [INFO]: Epoch 066 - training loss: 0.5193, validation loss: 0.5983
2024-06-03 04:49:27 [INFO]: Epoch 067 - training loss: 0.5165, validation loss: 0.6010
2024-06-03 04:49:31 [INFO]: Epoch 068 - training loss: 0.5138, validation loss: 0.5976
2024-06-03 04:49:35 [INFO]: Epoch 069 - training loss: 0.5137, validation loss: 0.5973
2024-06-03 04:49:40 [INFO]: Epoch 070 - training loss: 0.5137, validation loss: 0.5939
2024-06-03 04:49:44 [INFO]: Epoch 071 - training loss: 0.5101, validation loss: 0.5937
2024-06-03 04:49:48 [INFO]: Epoch 072 - training loss: 0.5129, validation loss: 0.5976
2024-06-03 04:49:52 [INFO]: Epoch 073 - training loss: 0.5127, validation loss: 0.5927
2024-06-03 04:49:56 [INFO]: Epoch 074 - training loss: 0.5146, validation loss: 0.5867
2024-06-03 04:50:00 [INFO]: Epoch 075 - training loss: 0.5107, validation loss: 0.5868
2024-06-03 04:50:04 [INFO]: Epoch 076 - training loss: 0.5119, validation loss: 0.5880
2024-06-03 04:50:08 [INFO]: Epoch 077 - training loss: 0.5120, validation loss: 0.5860
2024-06-03 04:50:12 [INFO]: Epoch 078 - training loss: 0.5066, validation loss: 0.5871
2024-06-03 04:50:17 [INFO]: Epoch 079 - training loss: 0.5078, validation loss: 0.5866
2024-06-03 04:50:21 [INFO]: Epoch 080 - training loss: 0.5113, validation loss: 0.5775
2024-06-03 04:50:25 [INFO]: Epoch 081 - training loss: 0.5138, validation loss: 0.5791
2024-06-03 04:50:29 [INFO]: Epoch 082 - training loss: 0.5131, validation loss: 0.5832
2024-06-03 04:50:33 [INFO]: Epoch 083 - training loss: 0.5096, validation loss: 0.5825
2024-06-03 04:50:37 [INFO]: Epoch 084 - training loss: 0.5104, validation loss: 0.5807
2024-06-03 04:50:41 [INFO]: Epoch 085 - training loss: 0.5066, validation loss: 0.5817
2024-06-03 04:50:45 [INFO]: Epoch 086 - training loss: 0.5087, validation loss: 0.5820
2024-06-03 04:50:49 [INFO]: Epoch 087 - training loss: 0.5085, validation loss: 0.5799
2024-06-03 04:50:54 [INFO]: Epoch 088 - training loss: 0.5099, validation loss: 0.5787
2024-06-03 04:50:58 [INFO]: Epoch 089 - training loss: 0.5103, validation loss: 0.5785
2024-06-03 04:51:02 [INFO]: Epoch 090 - training loss: 0.5098, validation loss: 0.5870
2024-06-03 04:51:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:51:02 [INFO]: Finished training. The best model is from epoch#80.
2024-06-03 04:51:10 [INFO]: Saved the model to results_point_rate09/PeMS/SCINet_PeMS/round_1/20240603_T044301/SCINet.pypots
2024-06-03 04:51:11 [INFO]: Successfully saved to results_point_rate09/PeMS/SCINet_PeMS/round_1/imputation.pkl
2024-06-03 04:51:11 [INFO]: Round1 - SCINet on PeMS: MAE=0.4690, MSE=0.8204, MRE=0.5820
2024-06-03 04:51:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:51:11 [INFO]: Using the given device: cuda:0
2024-06-03 04:51:11 [INFO]: Model files will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_2/20240603_T045111
2024-06-03 04:51:11 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_2/20240603_T045111/tensorboard
2024-06-03 04:51:20 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 04:51:25 [INFO]: Epoch 001 - training loss: 1.4093, validation loss: 1.0891
2024-06-03 04:51:29 [INFO]: Epoch 002 - training loss: 1.0662, validation loss: 1.0001
2024-06-03 04:51:33 [INFO]: Epoch 003 - training loss: 0.9574, validation loss: 0.9808
2024-06-03 04:51:37 [INFO]: Epoch 004 - training loss: 0.8909, validation loss: 0.9638
2024-06-03 04:51:41 [INFO]: Epoch 005 - training loss: 0.8423, validation loss: 0.9440
2024-06-03 04:51:45 [INFO]: Epoch 006 - training loss: 0.7941, validation loss: 0.9180
2024-06-03 04:51:49 [INFO]: Epoch 007 - training loss: 0.7572, validation loss: 0.9039
2024-06-03 04:51:53 [INFO]: Epoch 008 - training loss: 0.7221, validation loss: 0.8928
2024-06-03 04:51:57 [INFO]: Epoch 009 - training loss: 0.6973, validation loss: 0.8559
2024-06-03 04:52:02 [INFO]: Epoch 010 - training loss: 0.6750, validation loss: 0.8601
2024-06-03 04:52:06 [INFO]: Epoch 011 - training loss: 0.6622, validation loss: 0.8481
2024-06-03 04:52:10 [INFO]: Epoch 012 - training loss: 0.6502, validation loss: 0.8324
2024-06-03 04:52:14 [INFO]: Epoch 013 - training loss: 0.6379, validation loss: 0.8229
2024-06-03 04:52:18 [INFO]: Epoch 014 - training loss: 0.6245, validation loss: 0.8248
2024-06-03 04:52:22 [INFO]: Epoch 015 - training loss: 0.6268, validation loss: 0.8071
2024-06-03 04:52:26 [INFO]: Epoch 016 - training loss: 0.6188, validation loss: 0.8119
2024-06-03 04:52:30 [INFO]: Epoch 017 - training loss: 0.6107, validation loss: 0.8051
2024-06-03 04:52:34 [INFO]: Epoch 018 - training loss: 0.6070, validation loss: 0.7967
2024-06-03 04:52:38 [INFO]: Epoch 019 - training loss: 0.6014, validation loss: 0.7891
2024-06-03 04:52:43 [INFO]: Epoch 020 - training loss: 0.5969, validation loss: 0.8044
2024-06-03 04:52:47 [INFO]: Epoch 021 - training loss: 0.5934, validation loss: 0.7950
2024-06-03 04:52:51 [INFO]: Epoch 022 - training loss: 0.5910, validation loss: 0.7902
2024-06-03 04:52:55 [INFO]: Epoch 023 - training loss: 0.5884, validation loss: 0.7934
2024-06-03 04:52:59 [INFO]: Epoch 024 - training loss: 0.5823, validation loss: 0.7808
2024-06-03 04:53:03 [INFO]: Epoch 025 - training loss: 0.5826, validation loss: 0.7777
2024-06-03 04:53:07 [INFO]: Epoch 026 - training loss: 0.5794, validation loss: 0.7818
2024-06-03 04:53:11 [INFO]: Epoch 027 - training loss: 0.5747, validation loss: 0.7924
2024-06-03 04:53:15 [INFO]: Epoch 028 - training loss: 0.5763, validation loss: 0.7833
2024-06-03 04:53:20 [INFO]: Epoch 029 - training loss: 0.5736, validation loss: 0.7800
2024-06-03 04:53:24 [INFO]: Epoch 030 - training loss: 0.5697, validation loss: 0.7863
2024-06-03 04:53:28 [INFO]: Epoch 031 - training loss: 0.5701, validation loss: 0.7771
2024-06-03 04:53:32 [INFO]: Epoch 032 - training loss: 0.5726, validation loss: 0.7807
2024-06-03 04:53:36 [INFO]: Epoch 033 - training loss: 0.5666, validation loss: 0.7830
2024-06-03 04:53:40 [INFO]: Epoch 034 - training loss: 0.5657, validation loss: 0.7792
2024-06-03 04:53:44 [INFO]: Epoch 035 - training loss: 0.5635, validation loss: 0.7779
2024-06-03 04:53:48 [INFO]: Epoch 036 - training loss: 0.5612, validation loss: 0.7671
2024-06-03 04:53:52 [INFO]: Epoch 037 - training loss: 0.5636, validation loss: 0.7724
2024-06-03 04:53:57 [INFO]: Epoch 038 - training loss: 0.5634, validation loss: 0.7801
2024-06-03 04:54:01 [INFO]: Epoch 039 - training loss: 0.5583, validation loss: 0.7783
2024-06-03 04:54:05 [INFO]: Epoch 040 - training loss: 0.5619, validation loss: 0.7678
2024-06-03 04:54:09 [INFO]: Epoch 041 - training loss: 0.5572, validation loss: 0.7760
2024-06-03 04:54:13 [INFO]: Epoch 042 - training loss: 0.5577, validation loss: 0.7682
2024-06-03 04:54:17 [INFO]: Epoch 043 - training loss: 0.5543, validation loss: 0.7602
2024-06-03 04:54:21 [INFO]: Epoch 044 - training loss: 0.5557, validation loss: 0.7739
2024-06-03 04:54:25 [INFO]: Epoch 045 - training loss: 0.5518, validation loss: 0.7552
2024-06-03 04:54:29 [INFO]: Epoch 046 - training loss: 0.5518, validation loss: 0.7682
2024-06-03 04:54:34 [INFO]: Epoch 047 - training loss: 0.5536, validation loss: 0.7682
2024-06-03 04:54:38 [INFO]: Epoch 048 - training loss: 0.5544, validation loss: 0.7657
2024-06-03 04:54:42 [INFO]: Epoch 049 - training loss: 0.5498, validation loss: 0.7600
2024-06-03 04:54:46 [INFO]: Epoch 050 - training loss: 0.5527, validation loss: 0.7563
2024-06-03 04:54:50 [INFO]: Epoch 051 - training loss: 0.5468, validation loss: 0.7789
2024-06-03 04:54:54 [INFO]: Epoch 052 - training loss: 0.5466, validation loss: 0.7731
2024-06-03 04:54:58 [INFO]: Epoch 053 - training loss: 0.5495, validation loss: 0.7565
2024-06-03 04:55:02 [INFO]: Epoch 054 - training loss: 0.5513, validation loss: 0.7602
2024-06-03 04:55:06 [INFO]: Epoch 055 - training loss: 0.5486, validation loss: 0.7633
2024-06-03 04:55:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:55:06 [INFO]: Finished training. The best model is from epoch#45.
2024-06-03 04:55:14 [INFO]: Saved the model to results_point_rate09/PeMS/SCINet_PeMS/round_2/20240603_T045111/SCINet.pypots
2024-06-03 04:55:16 [INFO]: Successfully saved to results_point_rate09/PeMS/SCINet_PeMS/round_2/imputation.pkl
2024-06-03 04:55:16 [INFO]: Round2 - SCINet on PeMS: MAE=0.5905, MSE=1.0584, MRE=0.7327
2024-06-03 04:55:16 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:55:16 [INFO]: Using the given device: cuda:0
2024-06-03 04:55:16 [INFO]: Model files will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_3/20240603_T045516
2024-06-03 04:55:16 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_3/20240603_T045516/tensorboard
2024-06-03 04:55:25 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 04:55:29 [INFO]: Epoch 001 - training loss: 1.3342, validation loss: 1.0206
2024-06-03 04:55:33 [INFO]: Epoch 002 - training loss: 1.0195, validation loss: 0.9711
2024-06-03 04:55:37 [INFO]: Epoch 003 - training loss: 0.9203, validation loss: 0.9502
2024-06-03 04:55:41 [INFO]: Epoch 004 - training loss: 0.8497, validation loss: 0.9074
2024-06-03 04:55:45 [INFO]: Epoch 005 - training loss: 0.8007, validation loss: 0.8836
2024-06-03 04:55:49 [INFO]: Epoch 006 - training loss: 0.7583, validation loss: 0.8711
2024-06-03 04:55:54 [INFO]: Epoch 007 - training loss: 0.7268, validation loss: 0.8629
2024-06-03 04:55:58 [INFO]: Epoch 008 - training loss: 0.7130, validation loss: 0.8540
2024-06-03 04:56:02 [INFO]: Epoch 009 - training loss: 0.6955, validation loss: 0.8298
2024-06-03 04:56:06 [INFO]: Epoch 010 - training loss: 0.6789, validation loss: 0.8303
2024-06-03 04:56:10 [INFO]: Epoch 011 - training loss: 0.6657, validation loss: 0.8291
2024-06-03 04:56:14 [INFO]: Epoch 012 - training loss: 0.6584, validation loss: 0.8183
2024-06-03 04:56:18 [INFO]: Epoch 013 - training loss: 0.6509, validation loss: 0.8144
2024-06-03 04:56:22 [INFO]: Epoch 014 - training loss: 0.6452, validation loss: 0.8173
2024-06-03 04:56:26 [INFO]: Epoch 015 - training loss: 0.6370, validation loss: 0.8244
2024-06-03 04:56:31 [INFO]: Epoch 016 - training loss: 0.6386, validation loss: 0.8087
2024-06-03 04:56:35 [INFO]: Epoch 017 - training loss: 0.6310, validation loss: 0.8202
2024-06-03 04:56:39 [INFO]: Epoch 018 - training loss: 0.6276, validation loss: 0.8125
2024-06-03 04:56:43 [INFO]: Epoch 019 - training loss: 0.6230, validation loss: 0.8231
2024-06-03 04:56:47 [INFO]: Epoch 020 - training loss: 0.6228, validation loss: 0.8005
2024-06-03 04:56:51 [INFO]: Epoch 021 - training loss: 0.6183, validation loss: 0.8198
2024-06-03 04:56:55 [INFO]: Epoch 022 - training loss: 0.6122, validation loss: 0.8086
2024-06-03 04:56:59 [INFO]: Epoch 023 - training loss: 0.6118, validation loss: 0.8162
2024-06-03 04:57:03 [INFO]: Epoch 024 - training loss: 0.6104, validation loss: 0.7936
2024-06-03 04:57:07 [INFO]: Epoch 025 - training loss: 0.6099, validation loss: 0.8145
2024-06-03 04:57:12 [INFO]: Epoch 026 - training loss: 0.6065, validation loss: 0.8109
2024-06-03 04:57:16 [INFO]: Epoch 027 - training loss: 0.6077, validation loss: 0.7978
2024-06-03 04:57:20 [INFO]: Epoch 028 - training loss: 0.6029, validation loss: 0.7994
2024-06-03 04:57:24 [INFO]: Epoch 029 - training loss: 0.5983, validation loss: 0.8052
2024-06-03 04:57:28 [INFO]: Epoch 030 - training loss: 0.5974, validation loss: 0.7873
2024-06-03 04:57:32 [INFO]: Epoch 031 - training loss: 0.5966, validation loss: 0.8088
2024-06-03 04:57:35 [INFO]: Epoch 032 - training loss: 0.5910, validation loss: 0.7912
2024-06-03 04:57:39 [INFO]: Epoch 033 - training loss: 0.5881, validation loss: 0.7902
2024-06-03 04:57:44 [INFO]: Epoch 034 - training loss: 0.5905, validation loss: 0.7866
2024-06-03 04:57:48 [INFO]: Epoch 035 - training loss: 0.5921, validation loss: 0.7953
2024-06-03 04:57:52 [INFO]: Epoch 036 - training loss: 0.5864, validation loss: 0.7877
2024-06-03 04:57:56 [INFO]: Epoch 037 - training loss: 0.5871, validation loss: 0.7847
2024-06-03 04:58:00 [INFO]: Epoch 038 - training loss: 0.5850, validation loss: 0.7916
2024-06-03 04:58:04 [INFO]: Epoch 039 - training loss: 0.5818, validation loss: 0.7928
2024-06-03 04:58:08 [INFO]: Epoch 040 - training loss: 0.5797, validation loss: 0.7840
2024-06-03 04:58:12 [INFO]: Epoch 041 - training loss: 0.5773, validation loss: 0.7781
2024-06-03 04:58:16 [INFO]: Epoch 042 - training loss: 0.5827, validation loss: 0.7802
2024-06-03 04:58:21 [INFO]: Epoch 043 - training loss: 0.5793, validation loss: 0.7738
2024-06-03 04:58:25 [INFO]: Epoch 044 - training loss: 0.5766, validation loss: 0.7924
2024-06-03 04:58:29 [INFO]: Epoch 045 - training loss: 0.5753, validation loss: 0.7757
2024-06-03 04:58:33 [INFO]: Epoch 046 - training loss: 0.5750, validation loss: 0.7794
2024-06-03 04:58:37 [INFO]: Epoch 047 - training loss: 0.5747, validation loss: 0.7761
2024-06-03 04:58:41 [INFO]: Epoch 048 - training loss: 0.5735, validation loss: 0.7706
2024-06-03 04:58:45 [INFO]: Epoch 049 - training loss: 0.5687, validation loss: 0.7757
2024-06-03 04:58:49 [INFO]: Epoch 050 - training loss: 0.5741, validation loss: 0.7747
2024-06-03 04:58:53 [INFO]: Epoch 051 - training loss: 0.5707, validation loss: 0.7748
2024-06-03 04:58:58 [INFO]: Epoch 052 - training loss: 0.5706, validation loss: 0.7608
2024-06-03 04:59:02 [INFO]: Epoch 053 - training loss: 0.5720, validation loss: 0.7626
2024-06-03 04:59:06 [INFO]: Epoch 054 - training loss: 0.5659, validation loss: 0.7686
2024-06-03 04:59:10 [INFO]: Epoch 055 - training loss: 0.5687, validation loss: 0.7707
2024-06-03 04:59:14 [INFO]: Epoch 056 - training loss: 0.5678, validation loss: 0.7654
2024-06-03 04:59:18 [INFO]: Epoch 057 - training loss: 0.5638, validation loss: 0.7728
2024-06-03 04:59:22 [INFO]: Epoch 058 - training loss: 0.5660, validation loss: 0.7769
2024-06-03 04:59:26 [INFO]: Epoch 059 - training loss: 0.5649, validation loss: 0.7564
2024-06-03 04:59:31 [INFO]: Epoch 060 - training loss: 0.5648, validation loss: 0.7838
2024-06-03 04:59:35 [INFO]: Epoch 061 - training loss: 0.5643, validation loss: 0.7738
2024-06-03 04:59:39 [INFO]: Epoch 062 - training loss: 0.5633, validation loss: 0.7622
2024-06-03 04:59:43 [INFO]: Epoch 063 - training loss: 0.5623, validation loss: 0.7584
2024-06-03 04:59:47 [INFO]: Epoch 064 - training loss: 0.5612, validation loss: 0.7742
2024-06-03 04:59:51 [INFO]: Epoch 065 - training loss: 0.5631, validation loss: 0.7631
2024-06-03 04:59:55 [INFO]: Epoch 066 - training loss: 0.5602, validation loss: 0.7601
2024-06-03 04:59:59 [INFO]: Epoch 067 - training loss: 0.5597, validation loss: 0.7686
2024-06-03 05:00:03 [INFO]: Epoch 068 - training loss: 0.5606, validation loss: 0.7649
2024-06-03 05:00:07 [INFO]: Epoch 069 - training loss: 0.5628, validation loss: 0.7614
2024-06-03 05:00:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:00:07 [INFO]: Finished training. The best model is from epoch#59.
2024-06-03 05:00:15 [INFO]: Saved the model to results_point_rate09/PeMS/SCINet_PeMS/round_3/20240603_T045516/SCINet.pypots
2024-06-03 05:00:17 [INFO]: Successfully saved to results_point_rate09/PeMS/SCINet_PeMS/round_3/imputation.pkl
2024-06-03 05:00:17 [INFO]: Round3 - SCINet on PeMS: MAE=0.6015, MSE=1.0581, MRE=0.7464
2024-06-03 05:00:17 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 05:00:17 [INFO]: Using the given device: cuda:0
2024-06-03 05:00:17 [INFO]: Model files will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_4/20240603_T050017
2024-06-03 05:00:17 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SCINet_PeMS/round_4/20240603_T050017/tensorboard
2024-06-03 05:00:26 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 05:00:30 [INFO]: Epoch 001 - training loss: 1.4092, validation loss: 1.1152
2024-06-03 05:00:34 [INFO]: Epoch 002 - training loss: 1.1014, validation loss: 1.0023
2024-06-03 05:00:38 [INFO]: Epoch 003 - training loss: 0.9558, validation loss: 0.9497
2024-06-03 05:00:43 [INFO]: Epoch 004 - training loss: 0.8693, validation loss: 0.8865
2024-06-03 05:00:47 [INFO]: Epoch 005 - training loss: 0.8176, validation loss: 0.8651
2024-06-03 05:00:51 [INFO]: Epoch 006 - training loss: 0.7638, validation loss: 0.8417
2024-06-03 05:00:55 [INFO]: Epoch 007 - training loss: 0.7352, validation loss: 0.8061
2024-06-03 05:00:59 [INFO]: Epoch 008 - training loss: 0.7071, validation loss: 0.7984
2024-06-03 05:01:03 [INFO]: Epoch 009 - training loss: 0.6905, validation loss: 0.7891
2024-06-03 05:01:07 [INFO]: Epoch 010 - training loss: 0.6719, validation loss: 0.7720
2024-06-03 05:01:11 [INFO]: Epoch 011 - training loss: 0.6557, validation loss: 0.7775
2024-06-03 05:01:15 [INFO]: Epoch 012 - training loss: 0.6443, validation loss: 0.7836
2024-06-03 05:01:20 [INFO]: Epoch 013 - training loss: 0.6348, validation loss: 0.7565
2024-06-03 05:01:24 [INFO]: Epoch 014 - training loss: 0.6296, validation loss: 0.7515
2024-06-03 05:01:28 [INFO]: Epoch 015 - training loss: 0.6218, validation loss: 0.7504
2024-06-03 05:01:32 [INFO]: Epoch 016 - training loss: 0.6126, validation loss: 0.7577
2024-06-03 05:01:36 [INFO]: Epoch 017 - training loss: 0.6072, validation loss: 0.7511
2024-06-03 05:01:40 [INFO]: Epoch 018 - training loss: 0.6039, validation loss: 0.7397
2024-06-03 05:01:44 [INFO]: Epoch 019 - training loss: 0.6001, validation loss: 0.7463
2024-06-03 05:01:48 [INFO]: Epoch 020 - training loss: 0.5972, validation loss: 0.7500
2024-06-03 05:01:52 [INFO]: Epoch 021 - training loss: 0.5912, validation loss: 0.7526
2024-06-03 05:01:56 [INFO]: Epoch 022 - training loss: 0.5915, validation loss: 0.7471
2024-06-03 05:02:01 [INFO]: Epoch 023 - training loss: 0.5847, validation loss: 0.7440
2024-06-03 05:02:05 [INFO]: Epoch 024 - training loss: 0.5855, validation loss: 0.7370
2024-06-03 05:02:09 [INFO]: Epoch 025 - training loss: 0.5823, validation loss: 0.7343
2024-06-03 05:02:13 [INFO]: Epoch 026 - training loss: 0.5832, validation loss: 0.7384
2024-06-03 05:02:17 [INFO]: Epoch 027 - training loss: 0.5744, validation loss: 0.7555
2024-06-03 05:02:21 [INFO]: Epoch 028 - training loss: 0.5782, validation loss: 0.7158
2024-06-03 05:02:25 [INFO]: Epoch 029 - training loss: 0.5740, validation loss: 0.7317
2024-06-03 05:02:29 [INFO]: Epoch 030 - training loss: 0.5734, validation loss: 0.7267
2024-06-03 05:02:33 [INFO]: Epoch 031 - training loss: 0.5660, validation loss: 0.7290
2024-06-03 05:02:38 [INFO]: Epoch 032 - training loss: 0.5684, validation loss: 0.7327
2024-06-03 05:02:42 [INFO]: Epoch 033 - training loss: 0.5641, validation loss: 0.7163
2024-06-03 05:02:46 [INFO]: Epoch 034 - training loss: 0.5656, validation loss: 0.7298
2024-06-03 05:02:50 [INFO]: Epoch 035 - training loss: 0.5666, validation loss: 0.7286
2024-06-03 05:02:54 [INFO]: Epoch 036 - training loss: 0.5630, validation loss: 0.7283
2024-06-03 05:02:58 [INFO]: Epoch 037 - training loss: 0.5624, validation loss: 0.7364
2024-06-03 05:03:02 [INFO]: Epoch 038 - training loss: 0.5598, validation loss: 0.7255
2024-06-03 05:03:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:03:02 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 05:03:10 [INFO]: Saved the model to results_point_rate09/PeMS/SCINet_PeMS/round_4/20240603_T050017/SCINet.pypots
2024-06-03 05:03:12 [INFO]: Successfully saved to results_point_rate09/PeMS/SCINet_PeMS/round_4/imputation.pkl
2024-06-03 05:03:12 [INFO]: Round4 - SCINet on PeMS: MAE=0.5819, MSE=1.0252, MRE=0.7220
2024-06-03 05:03:12 [INFO]: Done! Final results:
Averaged SCINet (1,143,027,230 params) on PeMS: MAE=0.5379 ± 0.0660815787695447, MSE=0.9472 ± 0.12395562118176862, MRE=0.6674 ± 0.0819960647886888, average inference time=0.37
