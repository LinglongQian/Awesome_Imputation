2024-06-03 04:32:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:32:41 [INFO]: Using the given device: cuda:0
2024-06-03 04:32:42 [INFO]: Model files will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_0/20240603_T043242
2024-06-03 04:32:42 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_0/20240603_T043242/tensorboard
2024-06-03 04:32:42 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-03 04:32:42 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:32:44 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 78,229,072
2024-06-03 04:32:52 [INFO]: Epoch 001 - training loss: 1.1811, validation loss: 0.8180
2024-06-03 04:32:54 [INFO]: Epoch 002 - training loss: 0.7525, validation loss: 0.6710
2024-06-03 04:32:57 [INFO]: Epoch 003 - training loss: 0.6265, validation loss: 0.6131
2024-06-03 04:33:00 [INFO]: Epoch 004 - training loss: 0.5648, validation loss: 0.5568
2024-06-03 04:33:03 [INFO]: Epoch 005 - training loss: 0.5363, validation loss: 0.5470
2024-06-03 04:33:06 [INFO]: Epoch 006 - training loss: 0.5113, validation loss: 0.5254
2024-06-03 04:33:09 [INFO]: Epoch 007 - training loss: 0.4907, validation loss: 0.5162
2024-06-03 04:33:12 [INFO]: Epoch 008 - training loss: 0.4786, validation loss: 0.5199
2024-06-03 04:33:15 [INFO]: Epoch 009 - training loss: 0.4741, validation loss: 0.5113
2024-06-03 04:33:18 [INFO]: Epoch 010 - training loss: 0.4691, validation loss: 0.5042
2024-06-03 04:33:21 [INFO]: Epoch 011 - training loss: 0.4643, validation loss: 0.5057
2024-06-03 04:33:24 [INFO]: Epoch 012 - training loss: 0.4574, validation loss: 0.5041
2024-06-03 04:33:27 [INFO]: Epoch 013 - training loss: 0.4536, validation loss: 0.4986
2024-06-03 04:33:31 [INFO]: Epoch 014 - training loss: 0.4463, validation loss: 0.4988
2024-06-03 04:33:36 [INFO]: Epoch 015 - training loss: 0.4448, validation loss: 0.4920
2024-06-03 04:33:41 [INFO]: Epoch 016 - training loss: 0.4394, validation loss: 0.4915
2024-06-03 04:33:45 [INFO]: Epoch 017 - training loss: 0.4337, validation loss: 0.4997
2024-06-03 04:33:50 [INFO]: Epoch 018 - training loss: 0.4310, validation loss: 0.4908
2024-06-03 04:33:54 [INFO]: Epoch 019 - training loss: 0.4247, validation loss: 0.4931
2024-06-03 04:33:58 [INFO]: Epoch 020 - training loss: 0.4187, validation loss: 0.4981
2024-06-03 04:34:02 [INFO]: Epoch 021 - training loss: 0.4182, validation loss: 0.4891
2024-06-03 04:34:07 [INFO]: Epoch 022 - training loss: 0.4094, validation loss: 0.4829
2024-06-03 04:34:11 [INFO]: Epoch 023 - training loss: 0.4135, validation loss: 0.4840
2024-06-03 04:34:16 [INFO]: Epoch 024 - training loss: 0.4036, validation loss: 0.4901
2024-06-03 04:34:21 [INFO]: Epoch 025 - training loss: 0.3976, validation loss: 0.4883
2024-06-03 04:34:25 [INFO]: Epoch 026 - training loss: 0.3955, validation loss: 0.4816
2024-06-03 04:34:30 [INFO]: Epoch 027 - training loss: 0.3946, validation loss: 0.4839
2024-06-03 04:34:34 [INFO]: Epoch 028 - training loss: 0.3912, validation loss: 0.4852
2024-06-03 04:34:38 [INFO]: Epoch 029 - training loss: 0.3883, validation loss: 0.4874
2024-06-03 04:34:43 [INFO]: Epoch 030 - training loss: 0.3860, validation loss: 0.4861
2024-06-03 04:34:47 [INFO]: Epoch 031 - training loss: 0.3820, validation loss: 0.4870
2024-06-03 04:34:52 [INFO]: Epoch 032 - training loss: 0.3786, validation loss: 0.4826
2024-06-03 04:34:56 [INFO]: Epoch 033 - training loss: 0.3744, validation loss: 0.4848
2024-06-03 04:35:01 [INFO]: Epoch 034 - training loss: 0.3727, validation loss: 0.4854
2024-06-03 04:35:06 [INFO]: Epoch 035 - training loss: 0.3706, validation loss: 0.4837
2024-06-03 04:35:10 [INFO]: Epoch 036 - training loss: 0.3661, validation loss: 0.4811
2024-06-03 04:35:14 [INFO]: Epoch 037 - training loss: 0.3712, validation loss: 0.4848
2024-06-03 04:35:18 [INFO]: Epoch 038 - training loss: 0.3646, validation loss: 0.4820
2024-06-03 04:35:22 [INFO]: Epoch 039 - training loss: 0.3616, validation loss: 0.4876
2024-06-03 04:35:26 [INFO]: Epoch 040 - training loss: 0.3536, validation loss: 0.4832
2024-06-03 04:35:31 [INFO]: Epoch 041 - training loss: 0.3488, validation loss: 0.4898
2024-06-03 04:35:36 [INFO]: Epoch 042 - training loss: 0.3454, validation loss: 0.4842
2024-06-03 04:35:40 [INFO]: Epoch 043 - training loss: 0.3488, validation loss: 0.4840
2024-06-03 04:35:44 [INFO]: Epoch 044 - training loss: 0.3410, validation loss: 0.4876
2024-06-03 04:35:49 [INFO]: Epoch 045 - training loss: 0.3427, validation loss: 0.4849
2024-06-03 04:35:53 [INFO]: Epoch 046 - training loss: 0.3362, validation loss: 0.4866
2024-06-03 04:35:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:35:53 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 04:35:55 [INFO]: Saved the model to results_point_rate09/PeMS/SAITS_PeMS/round_0/20240603_T043242/SAITS.pypots
2024-06-03 04:35:57 [INFO]: Successfully saved to results_point_rate09/PeMS/SAITS_PeMS/round_0/imputation.pkl
2024-06-03 04:35:57 [INFO]: Round0 - SAITS on PeMS: MAE=0.3515, MSE=0.6923, MRE=0.4361
2024-06-03 04:35:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:35:57 [INFO]: Using the given device: cuda:0
2024-06-03 04:35:57 [INFO]: Model files will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_1/20240603_T043557
2024-06-03 04:35:57 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_1/20240603_T043557/tensorboard
2024-06-03 04:35:57 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-03 04:35:57 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:35:59 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 78,229,072
2024-06-03 04:36:04 [INFO]: Epoch 001 - training loss: 1.1940, validation loss: 0.7714
2024-06-03 04:36:08 [INFO]: Epoch 002 - training loss: 0.7541, validation loss: 0.6760
2024-06-03 04:36:12 [INFO]: Epoch 003 - training loss: 0.6231, validation loss: 0.5950
2024-06-03 04:36:17 [INFO]: Epoch 004 - training loss: 0.5590, validation loss: 0.5442
2024-06-03 04:36:22 [INFO]: Epoch 005 - training loss: 0.5319, validation loss: 0.5491
2024-06-03 04:36:27 [INFO]: Epoch 006 - training loss: 0.5064, validation loss: 0.5236
2024-06-03 04:36:31 [INFO]: Epoch 007 - training loss: 0.4906, validation loss: 0.5244
2024-06-03 04:36:35 [INFO]: Epoch 008 - training loss: 0.4799, validation loss: 0.5126
2024-06-03 04:36:40 [INFO]: Epoch 009 - training loss: 0.4703, validation loss: 0.5098
2024-06-03 04:36:44 [INFO]: Epoch 010 - training loss: 0.4684, validation loss: 0.5090
2024-06-03 04:36:49 [INFO]: Epoch 011 - training loss: 0.4637, validation loss: 0.5076
2024-06-03 04:36:53 [INFO]: Epoch 012 - training loss: 0.4556, validation loss: 0.5004
2024-06-03 04:36:57 [INFO]: Epoch 013 - training loss: 0.4581, validation loss: 0.5014
2024-06-03 04:37:02 [INFO]: Epoch 014 - training loss: 0.4532, validation loss: 0.4964
2024-06-03 04:37:06 [INFO]: Epoch 015 - training loss: 0.4454, validation loss: 0.4982
2024-06-03 04:37:11 [INFO]: Epoch 016 - training loss: 0.4388, validation loss: 0.4964
2024-06-03 04:37:16 [INFO]: Epoch 017 - training loss: 0.4315, validation loss: 0.4976
2024-06-03 04:37:20 [INFO]: Epoch 018 - training loss: 0.4305, validation loss: 0.4940
2024-06-03 04:37:25 [INFO]: Epoch 019 - training loss: 0.4275, validation loss: 0.4991
2024-06-03 04:37:29 [INFO]: Epoch 020 - training loss: 0.4245, validation loss: 0.4915
2024-06-03 04:37:33 [INFO]: Epoch 021 - training loss: 0.4189, validation loss: 0.4945
2024-06-03 04:37:38 [INFO]: Epoch 022 - training loss: 0.4140, validation loss: 0.4930
2024-06-03 04:37:42 [INFO]: Epoch 023 - training loss: 0.4082, validation loss: 0.4867
2024-06-03 04:37:47 [INFO]: Epoch 024 - training loss: 0.4057, validation loss: 0.4877
2024-06-03 04:37:51 [INFO]: Epoch 025 - training loss: 0.4031, validation loss: 0.4860
2024-06-03 04:37:56 [INFO]: Epoch 026 - training loss: 0.4015, validation loss: 0.4845
2024-06-03 04:38:00 [INFO]: Epoch 027 - training loss: 0.3947, validation loss: 0.4941
2024-06-03 04:38:05 [INFO]: Epoch 028 - training loss: 0.3921, validation loss: 0.4960
2024-06-03 04:38:09 [INFO]: Epoch 029 - training loss: 0.3901, validation loss: 0.4903
2024-06-03 04:38:13 [INFO]: Epoch 030 - training loss: 0.3861, validation loss: 0.4914
2024-06-03 04:38:17 [INFO]: Epoch 031 - training loss: 0.3802, validation loss: 0.4888
2024-06-03 04:38:21 [INFO]: Epoch 032 - training loss: 0.3804, validation loss: 0.4896
2024-06-03 04:38:26 [INFO]: Epoch 033 - training loss: 0.3752, validation loss: 0.4876
2024-06-03 04:38:31 [INFO]: Epoch 034 - training loss: 0.3730, validation loss: 0.4880
2024-06-03 04:38:35 [INFO]: Epoch 035 - training loss: 0.3721, validation loss: 0.4871
2024-06-03 04:38:40 [INFO]: Epoch 036 - training loss: 0.3651, validation loss: 0.4844
2024-06-03 04:38:44 [INFO]: Epoch 037 - training loss: 0.3620, validation loss: 0.4903
2024-06-03 04:38:48 [INFO]: Epoch 038 - training loss: 0.3576, validation loss: 0.4847
2024-06-03 04:38:53 [INFO]: Epoch 039 - training loss: 0.3556, validation loss: 0.4891
2024-06-03 04:38:57 [INFO]: Epoch 040 - training loss: 0.3585, validation loss: 0.4875
2024-06-03 04:39:02 [INFO]: Epoch 041 - training loss: 0.3508, validation loss: 0.4887
2024-06-03 04:39:06 [INFO]: Epoch 042 - training loss: 0.3487, validation loss: 0.4890
2024-06-03 04:39:11 [INFO]: Epoch 043 - training loss: 0.3473, validation loss: 0.4890
2024-06-03 04:39:16 [INFO]: Epoch 044 - training loss: 0.3487, validation loss: 0.4894
2024-06-03 04:39:20 [INFO]: Epoch 045 - training loss: 0.3435, validation loss: 0.4894
2024-06-03 04:39:25 [INFO]: Epoch 046 - training loss: 0.3400, validation loss: 0.4839
2024-06-03 04:39:29 [INFO]: Epoch 047 - training loss: 0.3353, validation loss: 0.4888
2024-06-03 04:39:34 [INFO]: Epoch 048 - training loss: 0.3354, validation loss: 0.4896
2024-06-03 04:39:38 [INFO]: Epoch 049 - training loss: 0.3334, validation loss: 0.4890
2024-06-03 04:39:42 [INFO]: Epoch 050 - training loss: 0.3318, validation loss: 0.4875
2024-06-03 04:39:45 [INFO]: Epoch 051 - training loss: 0.3319, validation loss: 0.4878
2024-06-03 04:39:49 [INFO]: Epoch 052 - training loss: 0.3251, validation loss: 0.4903
2024-06-03 04:39:53 [INFO]: Epoch 053 - training loss: 0.3246, validation loss: 0.4918
2024-06-03 04:39:57 [INFO]: Epoch 054 - training loss: 0.3220, validation loss: 0.4886
2024-06-03 04:40:01 [INFO]: Epoch 055 - training loss: 0.3170, validation loss: 0.4887
2024-06-03 04:40:05 [INFO]: Epoch 056 - training loss: 0.3177, validation loss: 0.4854
2024-06-03 04:40:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:40:05 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 04:40:06 [INFO]: Saved the model to results_point_rate09/PeMS/SAITS_PeMS/round_1/20240603_T043557/SAITS.pypots
2024-06-03 04:40:07 [INFO]: Successfully saved to results_point_rate09/PeMS/SAITS_PeMS/round_1/imputation.pkl
2024-06-03 04:40:07 [INFO]: Round1 - SAITS on PeMS: MAE=0.3555, MSE=0.6975, MRE=0.4411
2024-06-03 04:40:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:40:07 [INFO]: Using the given device: cuda:0
2024-06-03 04:40:07 [INFO]: Model files will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_2/20240603_T044007
2024-06-03 04:40:07 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_2/20240603_T044007/tensorboard
2024-06-03 04:40:07 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-03 04:40:07 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:40:09 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 78,229,072
2024-06-03 04:40:13 [INFO]: Epoch 001 - training loss: 1.1875, validation loss: 0.8326
2024-06-03 04:40:17 [INFO]: Epoch 002 - training loss: 0.7626, validation loss: 0.7017
2024-06-03 04:40:21 [INFO]: Epoch 003 - training loss: 0.6299, validation loss: 0.6084
2024-06-03 04:40:25 [INFO]: Epoch 004 - training loss: 0.5677, validation loss: 0.5575
2024-06-03 04:40:29 [INFO]: Epoch 005 - training loss: 0.5304, validation loss: 0.5501
2024-06-03 04:40:33 [INFO]: Epoch 006 - training loss: 0.5074, validation loss: 0.5170
2024-06-03 04:40:37 [INFO]: Epoch 007 - training loss: 0.4946, validation loss: 0.5124
2024-06-03 04:40:41 [INFO]: Epoch 008 - training loss: 0.4804, validation loss: 0.5121
2024-06-03 04:40:45 [INFO]: Epoch 009 - training loss: 0.4746, validation loss: 0.5090
2024-06-03 04:40:49 [INFO]: Epoch 010 - training loss: 0.4687, validation loss: 0.5038
2024-06-03 04:40:52 [INFO]: Epoch 011 - training loss: 0.4582, validation loss: 0.4973
2024-06-03 04:40:56 [INFO]: Epoch 012 - training loss: 0.4519, validation loss: 0.4960
2024-06-03 04:41:00 [INFO]: Epoch 013 - training loss: 0.4513, validation loss: 0.5051
2024-06-03 04:41:04 [INFO]: Epoch 014 - training loss: 0.4462, validation loss: 0.4962
2024-06-03 04:41:07 [INFO]: Epoch 015 - training loss: 0.4401, validation loss: 0.4915
2024-06-03 04:41:11 [INFO]: Epoch 016 - training loss: 0.4360, validation loss: 0.4892
2024-06-03 04:41:15 [INFO]: Epoch 017 - training loss: 0.4318, validation loss: 0.4889
2024-06-03 04:41:19 [INFO]: Epoch 018 - training loss: 0.4306, validation loss: 0.4926
2024-06-03 04:41:22 [INFO]: Epoch 019 - training loss: 0.4211, validation loss: 0.4942
2024-06-03 04:41:26 [INFO]: Epoch 020 - training loss: 0.4252, validation loss: 0.4889
2024-06-03 04:41:30 [INFO]: Epoch 021 - training loss: 0.4160, validation loss: 0.4861
2024-06-03 04:41:34 [INFO]: Epoch 022 - training loss: 0.4175, validation loss: 0.4887
2024-06-03 04:41:37 [INFO]: Epoch 023 - training loss: 0.4081, validation loss: 0.4813
2024-06-03 04:41:41 [INFO]: Epoch 024 - training loss: 0.4046, validation loss: 0.4844
2024-06-03 04:41:44 [INFO]: Epoch 025 - training loss: 0.4012, validation loss: 0.4862
2024-06-03 04:41:47 [INFO]: Epoch 026 - training loss: 0.3987, validation loss: 0.4833
2024-06-03 04:41:51 [INFO]: Epoch 027 - training loss: 0.3927, validation loss: 0.4811
2024-06-03 04:41:54 [INFO]: Epoch 028 - training loss: 0.3851, validation loss: 0.4899
2024-06-03 04:41:57 [INFO]: Epoch 029 - training loss: 0.3902, validation loss: 0.4870
2024-06-03 04:42:01 [INFO]: Epoch 030 - training loss: 0.3882, validation loss: 0.4855
2024-06-03 04:42:04 [INFO]: Epoch 031 - training loss: 0.3847, validation loss: 0.4837
2024-06-03 04:42:08 [INFO]: Epoch 032 - training loss: 0.3786, validation loss: 0.4838
2024-06-03 04:42:11 [INFO]: Epoch 033 - training loss: 0.3734, validation loss: 0.4824
2024-06-03 04:42:15 [INFO]: Epoch 034 - training loss: 0.3683, validation loss: 0.4841
2024-06-03 04:42:18 [INFO]: Epoch 035 - training loss: 0.3709, validation loss: 0.4859
2024-06-03 04:42:21 [INFO]: Epoch 036 - training loss: 0.3630, validation loss: 0.4848
2024-06-03 04:42:25 [INFO]: Epoch 037 - training loss: 0.3573, validation loss: 0.4904
2024-06-03 04:42:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:42:25 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 04:42:25 [INFO]: Saved the model to results_point_rate09/PeMS/SAITS_PeMS/round_2/20240603_T044007/SAITS.pypots
2024-06-03 04:42:26 [INFO]: Successfully saved to results_point_rate09/PeMS/SAITS_PeMS/round_2/imputation.pkl
2024-06-03 04:42:26 [INFO]: Round2 - SAITS on PeMS: MAE=0.3530, MSE=0.6944, MRE=0.4380
2024-06-03 04:42:26 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:42:26 [INFO]: Using the given device: cuda:0
2024-06-03 04:42:26 [INFO]: Model files will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_3/20240603_T044226
2024-06-03 04:42:26 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_3/20240603_T044226/tensorboard
2024-06-03 04:42:26 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-03 04:42:26 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:42:28 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 78,229,072
2024-06-03 04:42:31 [INFO]: Epoch 001 - training loss: 1.1838, validation loss: 0.8127
2024-06-03 04:42:34 [INFO]: Epoch 002 - training loss: 0.7525, validation loss: 0.7203
2024-06-03 04:42:38 [INFO]: Epoch 003 - training loss: 0.6324, validation loss: 0.6128
2024-06-03 04:42:40 [INFO]: Epoch 004 - training loss: 0.5638, validation loss: 0.5764
2024-06-03 04:42:42 [INFO]: Epoch 005 - training loss: 0.5336, validation loss: 0.5361
2024-06-03 04:42:44 [INFO]: Epoch 006 - training loss: 0.5099, validation loss: 0.5341
2024-06-03 04:42:46 [INFO]: Epoch 007 - training loss: 0.4898, validation loss: 0.5215
2024-06-03 04:42:48 [INFO]: Epoch 008 - training loss: 0.4787, validation loss: 0.5155
2024-06-03 04:42:50 [INFO]: Epoch 009 - training loss: 0.4775, validation loss: 0.5095
2024-06-03 04:42:51 [INFO]: Epoch 010 - training loss: 0.4726, validation loss: 0.5010
2024-06-03 04:42:53 [INFO]: Epoch 011 - training loss: 0.4614, validation loss: 0.5095
2024-06-03 04:42:55 [INFO]: Epoch 012 - training loss: 0.4526, validation loss: 0.5067
2024-06-03 04:42:56 [INFO]: Epoch 013 - training loss: 0.4467, validation loss: 0.5021
2024-06-03 04:42:58 [INFO]: Epoch 014 - training loss: 0.4484, validation loss: 0.5004
2024-06-03 04:43:01 [INFO]: Epoch 015 - training loss: 0.4443, validation loss: 0.4989
2024-06-03 04:43:02 [INFO]: Epoch 016 - training loss: 0.4375, validation loss: 0.4923
2024-06-03 04:43:04 [INFO]: Epoch 017 - training loss: 0.4378, validation loss: 0.5002
2024-06-03 04:43:06 [INFO]: Epoch 018 - training loss: 0.4303, validation loss: 0.4934
2024-06-03 04:43:08 [INFO]: Epoch 019 - training loss: 0.4224, validation loss: 0.4949
2024-06-03 04:43:09 [INFO]: Epoch 020 - training loss: 0.4208, validation loss: 0.4945
2024-06-03 04:43:11 [INFO]: Epoch 021 - training loss: 0.4184, validation loss: 0.4875
2024-06-03 04:43:13 [INFO]: Epoch 022 - training loss: 0.4130, validation loss: 0.4957
2024-06-03 04:43:14 [INFO]: Epoch 023 - training loss: 0.4113, validation loss: 0.4909
2024-06-03 04:43:16 [INFO]: Epoch 024 - training loss: 0.4075, validation loss: 0.4971
2024-06-03 04:43:17 [INFO]: Epoch 025 - training loss: 0.4047, validation loss: 0.4933
2024-06-03 04:43:19 [INFO]: Epoch 026 - training loss: 0.3999, validation loss: 0.4970
2024-06-03 04:43:21 [INFO]: Epoch 027 - training loss: 0.3981, validation loss: 0.4890
2024-06-03 04:43:23 [INFO]: Epoch 028 - training loss: 0.3937, validation loss: 0.4925
2024-06-03 04:43:26 [INFO]: Epoch 029 - training loss: 0.3916, validation loss: 0.4975
2024-06-03 04:43:29 [INFO]: Epoch 030 - training loss: 0.3871, validation loss: 0.4906
2024-06-03 04:43:32 [INFO]: Epoch 031 - training loss: 0.3811, validation loss: 0.4903
2024-06-03 04:43:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:43:32 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 04:43:32 [INFO]: Saved the model to results_point_rate09/PeMS/SAITS_PeMS/round_3/20240603_T044226/SAITS.pypots
2024-06-03 04:43:33 [INFO]: Successfully saved to results_point_rate09/PeMS/SAITS_PeMS/round_3/imputation.pkl
2024-06-03 04:43:33 [INFO]: Round3 - SAITS on PeMS: MAE=0.3522, MSE=0.6903, MRE=0.4371
2024-06-03 04:43:33 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:43:33 [INFO]: Using the given device: cuda:0
2024-06-03 04:43:33 [INFO]: Model files will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_4/20240603_T044333
2024-06-03 04:43:33 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/SAITS_PeMS/round_4/20240603_T044333/tensorboard
2024-06-03 04:43:33 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-03 04:43:33 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:43:35 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 78,229,072
2024-06-03 04:43:38 [INFO]: Epoch 001 - training loss: 1.1889, validation loss: 0.8162
2024-06-03 04:43:41 [INFO]: Epoch 002 - training loss: 0.7561, validation loss: 0.6982
2024-06-03 04:43:44 [INFO]: Epoch 003 - training loss: 0.6273, validation loss: 0.6020
2024-06-03 04:43:47 [INFO]: Epoch 004 - training loss: 0.5667, validation loss: 0.5588
2024-06-03 04:43:50 [INFO]: Epoch 005 - training loss: 0.5275, validation loss: 0.5371
2024-06-03 04:43:53 [INFO]: Epoch 006 - training loss: 0.5066, validation loss: 0.5216
2024-06-03 04:43:56 [INFO]: Epoch 007 - training loss: 0.5031, validation loss: 0.5175
2024-06-03 04:43:59 [INFO]: Epoch 008 - training loss: 0.4808, validation loss: 0.5130
2024-06-03 04:44:02 [INFO]: Epoch 009 - training loss: 0.4713, validation loss: 0.5105
2024-06-03 04:44:05 [INFO]: Epoch 010 - training loss: 0.4701, validation loss: 0.5062
2024-06-03 04:44:08 [INFO]: Epoch 011 - training loss: 0.4634, validation loss: 0.5128
2024-06-03 04:44:11 [INFO]: Epoch 012 - training loss: 0.4624, validation loss: 0.4991
2024-06-03 04:44:13 [INFO]: Epoch 013 - training loss: 0.4550, validation loss: 0.5015
2024-06-03 04:44:16 [INFO]: Epoch 014 - training loss: 0.4447, validation loss: 0.4998
2024-06-03 04:44:19 [INFO]: Epoch 015 - training loss: 0.4477, validation loss: 0.4938
2024-06-03 04:44:21 [INFO]: Epoch 016 - training loss: 0.4387, validation loss: 0.4935
2024-06-03 04:44:24 [INFO]: Epoch 017 - training loss: 0.4356, validation loss: 0.4896
2024-06-03 04:44:27 [INFO]: Epoch 018 - training loss: 0.4340, validation loss: 0.4934
2024-06-03 04:44:29 [INFO]: Epoch 019 - training loss: 0.4292, validation loss: 0.4887
2024-06-03 04:44:32 [INFO]: Epoch 020 - training loss: 0.4249, validation loss: 0.4944
2024-06-03 04:44:35 [INFO]: Epoch 021 - training loss: 0.4175, validation loss: 0.4877
2024-06-03 04:44:38 [INFO]: Epoch 022 - training loss: 0.4153, validation loss: 0.4921
2024-06-03 04:44:41 [INFO]: Epoch 023 - training loss: 0.4169, validation loss: 0.4903
2024-06-03 04:44:44 [INFO]: Epoch 024 - training loss: 0.4095, validation loss: 0.4841
2024-06-03 04:44:47 [INFO]: Epoch 025 - training loss: 0.4043, validation loss: 0.4857
2024-06-03 04:44:50 [INFO]: Epoch 026 - training loss: 0.3993, validation loss: 0.4847
2024-06-03 04:44:53 [INFO]: Epoch 027 - training loss: 0.3962, validation loss: 0.4865
2024-06-03 04:44:56 [INFO]: Epoch 028 - training loss: 0.3920, validation loss: 0.4867
2024-06-03 04:44:58 [INFO]: Epoch 029 - training loss: 0.3907, validation loss: 0.4839
2024-06-03 04:45:01 [INFO]: Epoch 030 - training loss: 0.3846, validation loss: 0.4885
2024-06-03 04:45:04 [INFO]: Epoch 031 - training loss: 0.3825, validation loss: 0.4863
2024-06-03 04:45:07 [INFO]: Epoch 032 - training loss: 0.3763, validation loss: 0.4884
2024-06-03 04:45:10 [INFO]: Epoch 033 - training loss: 0.3721, validation loss: 0.4836
2024-06-03 04:45:13 [INFO]: Epoch 034 - training loss: 0.3717, validation loss: 0.4864
2024-06-03 04:45:16 [INFO]: Epoch 035 - training loss: 0.3690, validation loss: 0.4875
2024-06-03 04:45:19 [INFO]: Epoch 036 - training loss: 0.3657, validation loss: 0.4877
2024-06-03 04:45:21 [INFO]: Epoch 037 - training loss: 0.3646, validation loss: 0.4817
2024-06-03 04:45:24 [INFO]: Epoch 038 - training loss: 0.3623, validation loss: 0.4875
2024-06-03 04:45:27 [INFO]: Epoch 039 - training loss: 0.3634, validation loss: 0.4815
2024-06-03 04:45:30 [INFO]: Epoch 040 - training loss: 0.3560, validation loss: 0.4827
2024-06-03 04:45:33 [INFO]: Epoch 041 - training loss: 0.3556, validation loss: 0.4860
2024-06-03 04:45:36 [INFO]: Epoch 042 - training loss: 0.3503, validation loss: 0.4890
2024-06-03 04:45:39 [INFO]: Epoch 043 - training loss: 0.3468, validation loss: 0.4860
2024-06-03 04:45:41 [INFO]: Epoch 044 - training loss: 0.3450, validation loss: 0.4852
2024-06-03 04:45:44 [INFO]: Epoch 045 - training loss: 0.3408, validation loss: 0.4824
2024-06-03 04:45:47 [INFO]: Epoch 046 - training loss: 0.3393, validation loss: 0.4839
2024-06-03 04:45:50 [INFO]: Epoch 047 - training loss: 0.3352, validation loss: 0.4864
2024-06-03 04:45:52 [INFO]: Epoch 048 - training loss: 0.3345, validation loss: 0.4855
2024-06-03 04:45:55 [INFO]: Epoch 049 - training loss: 0.3304, validation loss: 0.4852
2024-06-03 04:45:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:45:55 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 04:45:56 [INFO]: Saved the model to results_point_rate09/PeMS/SAITS_PeMS/round_4/20240603_T044333/SAITS.pypots
2024-06-03 04:45:57 [INFO]: Successfully saved to results_point_rate09/PeMS/SAITS_PeMS/round_4/imputation.pkl
2024-06-03 04:45:57 [INFO]: Round4 - SAITS on PeMS: MAE=0.3545, MSE=0.6874, MRE=0.4399
2024-06-03 04:45:57 [INFO]: Done! Final results:
Averaged SAITS (78,229,072 params) on PeMS: MAE=0.3533 ± 0.0014610939782282036, MSE=0.6924 ± 0.0034401971198175243, MRE=0.4384 ± 0.0018129705544561961, average inference time=0.20
