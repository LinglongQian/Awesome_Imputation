2024-06-03 03:53:27 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:53:27 [INFO]: Using the given device: cuda:0
2024-06-03 03:53:27 [INFO]: Model files will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_0/20240603_T035327
2024-06-03 03:53:27 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_0/20240603_T035327/tensorboard
2024-06-03 03:53:28 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 03:53:54 [INFO]: Epoch 001 - training loss: 1.2956, validation loss: 0.9031
2024-06-03 03:54:04 [INFO]: Epoch 002 - training loss: 0.8848, validation loss: 0.9348
2024-06-03 03:54:15 [INFO]: Epoch 003 - training loss: 0.8267, validation loss: 0.9374
2024-06-03 03:54:26 [INFO]: Epoch 004 - training loss: 0.7751, validation loss: 0.9657
2024-06-03 03:54:35 [INFO]: Epoch 005 - training loss: 0.7224, validation loss: 0.8369
2024-06-03 03:54:44 [INFO]: Epoch 006 - training loss: 0.6576, validation loss: 0.8345
2024-06-03 03:54:56 [INFO]: Epoch 007 - training loss: 0.6206, validation loss: 0.7867
2024-06-03 03:55:10 [INFO]: Epoch 008 - training loss: 0.5821, validation loss: 0.7299
2024-06-03 03:55:21 [INFO]: Epoch 009 - training loss: 0.5634, validation loss: 0.7172
2024-06-03 03:55:30 [INFO]: Epoch 010 - training loss: 0.5344, validation loss: 0.6902
2024-06-03 03:55:41 [INFO]: Epoch 011 - training loss: 0.5038, validation loss: 0.6882
2024-06-03 03:55:53 [INFO]: Epoch 012 - training loss: 0.4775, validation loss: 0.7044
2024-06-03 03:56:05 [INFO]: Epoch 013 - training loss: 0.4595, validation loss: 0.6470
2024-06-03 03:56:16 [INFO]: Epoch 014 - training loss: 0.4477, validation loss: 0.6805
2024-06-03 03:56:25 [INFO]: Epoch 015 - training loss: 0.4352, validation loss: 0.6421
2024-06-03 03:56:35 [INFO]: Epoch 016 - training loss: 0.4285, validation loss: 0.6426
2024-06-03 03:56:49 [INFO]: Epoch 017 - training loss: 0.4185, validation loss: 0.6500
2024-06-03 03:57:01 [INFO]: Epoch 018 - training loss: 0.4108, validation loss: 0.6324
2024-06-03 03:57:12 [INFO]: Epoch 019 - training loss: 0.4056, validation loss: 0.6568
2024-06-03 03:57:23 [INFO]: Epoch 020 - training loss: 0.3990, validation loss: 0.6366
2024-06-03 03:57:33 [INFO]: Epoch 021 - training loss: 0.3940, validation loss: 0.6362
2024-06-03 03:57:45 [INFO]: Epoch 022 - training loss: 0.3912, validation loss: 0.6411
2024-06-03 03:57:57 [INFO]: Epoch 023 - training loss: 0.3932, validation loss: 0.6299
2024-06-03 03:58:06 [INFO]: Epoch 024 - training loss: 0.3838, validation loss: 0.6382
2024-06-03 03:58:17 [INFO]: Epoch 025 - training loss: 0.3827, validation loss: 0.6323
2024-06-03 03:58:28 [INFO]: Epoch 026 - training loss: 0.3806, validation loss: 0.6353
2024-06-03 03:58:38 [INFO]: Epoch 027 - training loss: 0.3702, validation loss: 0.6299
2024-06-03 03:58:48 [INFO]: Epoch 028 - training loss: 0.3768, validation loss: 0.6331
2024-06-03 03:58:59 [INFO]: Epoch 029 - training loss: 0.3685, validation loss: 0.6208
2024-06-03 03:59:10 [INFO]: Epoch 030 - training loss: 0.3678, validation loss: 0.6124
2024-06-03 03:59:20 [INFO]: Epoch 031 - training loss: 0.3667, validation loss: 0.6266
2024-06-03 03:59:30 [INFO]: Epoch 032 - training loss: 0.3624, validation loss: 0.6231
2024-06-03 03:59:41 [INFO]: Epoch 033 - training loss: 0.3556, validation loss: 0.6235
2024-06-03 03:59:51 [INFO]: Epoch 034 - training loss: 0.3549, validation loss: 0.6156
2024-06-03 04:00:02 [INFO]: Epoch 035 - training loss: 0.3508, validation loss: 0.6275
2024-06-03 04:00:13 [INFO]: Epoch 036 - training loss: 0.3468, validation loss: 0.6143
2024-06-03 04:00:24 [INFO]: Epoch 037 - training loss: 0.3446, validation loss: 0.6135
2024-06-03 04:00:34 [INFO]: Epoch 038 - training loss: 0.3434, validation loss: 0.6124
2024-06-03 04:00:46 [INFO]: Epoch 039 - training loss: 0.3420, validation loss: 0.6120
2024-06-03 04:00:57 [INFO]: Epoch 040 - training loss: 0.3450, validation loss: 0.6254
2024-06-03 04:01:06 [INFO]: Epoch 041 - training loss: 0.3408, validation loss: 0.6268
2024-06-03 04:01:17 [INFO]: Epoch 042 - training loss: 0.3374, validation loss: 0.6021
2024-06-03 04:01:26 [INFO]: Epoch 043 - training loss: 0.3365, validation loss: 0.6178
2024-06-03 04:01:35 [INFO]: Epoch 044 - training loss: 0.3375, validation loss: 0.6114
2024-06-03 04:01:45 [INFO]: Epoch 045 - training loss: 0.3310, validation loss: 0.6141
2024-06-03 04:01:55 [INFO]: Epoch 046 - training loss: 0.3295, validation loss: 0.6129
2024-06-03 04:02:06 [INFO]: Epoch 047 - training loss: 0.3292, validation loss: 0.6314
2024-06-03 04:02:18 [INFO]: Epoch 048 - training loss: 0.3280, validation loss: 0.6081
2024-06-03 04:02:29 [INFO]: Epoch 049 - training loss: 0.3304, validation loss: 0.6044
2024-06-03 04:02:41 [INFO]: Epoch 050 - training loss: 0.3249, validation loss: 0.6064
2024-06-03 04:02:51 [INFO]: Epoch 051 - training loss: 0.3240, validation loss: 0.6003
2024-06-03 04:03:01 [INFO]: Epoch 052 - training loss: 0.3261, validation loss: 0.5953
2024-06-03 04:03:12 [INFO]: Epoch 053 - training loss: 0.3249, validation loss: 0.6135
2024-06-03 04:03:20 [INFO]: Epoch 054 - training loss: 0.3226, validation loss: 0.6020
2024-06-03 04:03:30 [INFO]: Epoch 055 - training loss: 0.3186, validation loss: 0.6013
2024-06-03 04:03:41 [INFO]: Epoch 056 - training loss: 0.3193, validation loss: 0.6047
2024-06-03 04:03:50 [INFO]: Epoch 057 - training loss: 0.3188, validation loss: 0.6020
2024-06-03 04:04:00 [INFO]: Epoch 058 - training loss: 0.3154, validation loss: 0.6019
2024-06-03 04:04:09 [INFO]: Epoch 059 - training loss: 0.3142, validation loss: 0.6094
2024-06-03 04:04:18 [INFO]: Epoch 060 - training loss: 0.3150, validation loss: 0.6049
2024-06-03 04:04:29 [INFO]: Epoch 061 - training loss: 0.3145, validation loss: 0.6103
2024-06-03 04:04:39 [INFO]: Epoch 062 - training loss: 0.3205, validation loss: 0.5858
2024-06-03 04:04:48 [INFO]: Epoch 063 - training loss: 0.3143, validation loss: 0.6081
2024-06-03 04:04:58 [INFO]: Epoch 064 - training loss: 0.3153, validation loss: 0.5999
2024-06-03 04:05:09 [INFO]: Epoch 065 - training loss: 0.3111, validation loss: 0.5982
2024-06-03 04:05:20 [INFO]: Epoch 066 - training loss: 0.3075, validation loss: 0.6020
2024-06-03 04:05:32 [INFO]: Epoch 067 - training loss: 0.3067, validation loss: 0.5867
2024-06-03 04:05:43 [INFO]: Epoch 068 - training loss: 0.3051, validation loss: 0.6068
2024-06-03 04:05:53 [INFO]: Epoch 069 - training loss: 0.3068, validation loss: 0.5961
2024-06-03 04:06:03 [INFO]: Epoch 070 - training loss: 0.3089, validation loss: 0.5957
2024-06-03 04:06:15 [INFO]: Epoch 071 - training loss: 0.3120, validation loss: 0.6156
2024-06-03 04:06:25 [INFO]: Epoch 072 - training loss: 0.3107, validation loss: 0.5977
2024-06-03 04:06:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:06:25 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 04:06:25 [INFO]: Saved the model to results_point_rate09/PeMS/Koopa_PeMS/round_0/20240603_T035327/Koopa.pypots
2024-06-03 04:06:27 [INFO]: Successfully saved to results_point_rate09/PeMS/Koopa_PeMS/round_0/imputation.pkl
2024-06-03 04:06:27 [INFO]: Round0 - Koopa on PeMS: MAE=0.4710, MSE=0.8641, MRE=0.5844
2024-06-03 04:06:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:06:27 [INFO]: Using the given device: cuda:0
2024-06-03 04:06:27 [INFO]: Model files will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_1/20240603_T040627
2024-06-03 04:06:27 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_1/20240603_T040627/tensorboard
2024-06-03 04:06:27 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 04:06:39 [INFO]: Epoch 001 - training loss: 1.3018, validation loss: 0.9572
2024-06-03 04:06:49 [INFO]: Epoch 002 - training loss: 0.8971, validation loss: 0.9212
2024-06-03 04:06:59 [INFO]: Epoch 003 - training loss: 0.8533, validation loss: 0.9119
2024-06-03 04:07:07 [INFO]: Epoch 004 - training loss: 0.8203, validation loss: 0.9281
2024-06-03 04:07:18 [INFO]: Epoch 005 - training loss: 0.7844, validation loss: 0.9099
2024-06-03 04:07:28 [INFO]: Epoch 006 - training loss: 0.7488, validation loss: 0.8782
2024-06-03 04:07:41 [INFO]: Epoch 007 - training loss: 0.7125, validation loss: 0.8836
2024-06-03 04:07:53 [INFO]: Epoch 008 - training loss: 0.6837, validation loss: 0.8502
2024-06-03 04:08:03 [INFO]: Epoch 009 - training loss: 0.6445, validation loss: 0.8305
2024-06-03 04:08:13 [INFO]: Epoch 010 - training loss: 0.6012, validation loss: 0.7686
2024-06-03 04:08:24 [INFO]: Epoch 011 - training loss: 0.5816, validation loss: 0.8032
2024-06-03 04:08:35 [INFO]: Epoch 012 - training loss: 0.5454, validation loss: 0.7538
2024-06-03 04:08:45 [INFO]: Epoch 013 - training loss: 0.5305, validation loss: 0.7376
2024-06-03 04:08:54 [INFO]: Epoch 014 - training loss: 0.5060, validation loss: 0.7649
2024-06-03 04:09:04 [INFO]: Epoch 015 - training loss: 0.4954, validation loss: 0.7085
2024-06-03 04:09:14 [INFO]: Epoch 016 - training loss: 0.4772, validation loss: 0.7419
2024-06-03 04:09:26 [INFO]: Epoch 017 - training loss: 0.4639, validation loss: 0.7261
2024-06-03 04:09:34 [INFO]: Epoch 018 - training loss: 0.4514, validation loss: 0.7152
2024-06-03 04:09:45 [INFO]: Epoch 019 - training loss: 0.4476, validation loss: 0.7206
2024-06-03 04:09:57 [INFO]: Epoch 020 - training loss: 0.4361, validation loss: 0.7197
2024-06-03 04:10:08 [INFO]: Epoch 021 - training loss: 0.4309, validation loss: 0.7226
2024-06-03 04:10:17 [INFO]: Epoch 022 - training loss: 0.4206, validation loss: 0.6964
2024-06-03 04:10:27 [INFO]: Epoch 023 - training loss: 0.4230, validation loss: 0.6979
2024-06-03 04:10:38 [INFO]: Epoch 024 - training loss: 0.4194, validation loss: 0.7033
2024-06-03 04:10:49 [INFO]: Epoch 025 - training loss: 0.4066, validation loss: 0.6859
2024-06-03 04:10:59 [INFO]: Epoch 026 - training loss: 0.4044, validation loss: 0.6755
2024-06-03 04:11:09 [INFO]: Epoch 027 - training loss: 0.3980, validation loss: 0.6786
2024-06-03 04:11:19 [INFO]: Epoch 028 - training loss: 0.3934, validation loss: 0.6840
2024-06-03 04:11:29 [INFO]: Epoch 029 - training loss: 0.3846, validation loss: 0.6880
2024-06-03 04:11:40 [INFO]: Epoch 030 - training loss: 0.3871, validation loss: 0.6834
2024-06-03 04:11:50 [INFO]: Epoch 031 - training loss: 0.3833, validation loss: 0.6961
2024-06-03 04:12:02 [INFO]: Epoch 032 - training loss: 0.3818, validation loss: 0.7016
2024-06-03 04:12:12 [INFO]: Epoch 033 - training loss: 0.3788, validation loss: 0.6915
2024-06-03 04:12:21 [INFO]: Epoch 034 - training loss: 0.3749, validation loss: 0.6979
2024-06-03 04:12:32 [INFO]: Epoch 035 - training loss: 0.3732, validation loss: 0.7034
2024-06-03 04:12:41 [INFO]: Epoch 036 - training loss: 0.3712, validation loss: 0.6633
2024-06-03 04:12:51 [INFO]: Epoch 037 - training loss: 0.3738, validation loss: 0.6707
2024-06-03 04:13:01 [INFO]: Epoch 038 - training loss: 0.3659, validation loss: 0.6993
2024-06-03 04:13:12 [INFO]: Epoch 039 - training loss: 0.3788, validation loss: 0.6764
2024-06-03 04:13:23 [INFO]: Epoch 040 - training loss: 0.3699, validation loss: 0.6753
2024-06-03 04:13:34 [INFO]: Epoch 041 - training loss: 0.3597, validation loss: 0.6715
2024-06-03 04:13:45 [INFO]: Epoch 042 - training loss: 0.3565, validation loss: 0.6663
2024-06-03 04:13:56 [INFO]: Epoch 043 - training loss: 0.3594, validation loss: 0.6888
2024-06-03 04:14:06 [INFO]: Epoch 044 - training loss: 0.3592, validation loss: 0.6869
2024-06-03 04:14:17 [INFO]: Epoch 045 - training loss: 0.3571, validation loss: 0.6776
2024-06-03 04:14:28 [INFO]: Epoch 046 - training loss: 0.3545, validation loss: 0.6815
2024-06-03 04:14:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:14:28 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 04:14:28 [INFO]: Saved the model to results_point_rate09/PeMS/Koopa_PeMS/round_1/20240603_T040627/Koopa.pypots
2024-06-03 04:14:30 [INFO]: Successfully saved to results_point_rate09/PeMS/Koopa_PeMS/round_1/imputation.pkl
2024-06-03 04:14:30 [INFO]: Round1 - Koopa on PeMS: MAE=0.5312, MSE=1.0181, MRE=0.6591
2024-06-03 04:14:30 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:14:30 [INFO]: Using the given device: cuda:0
2024-06-03 04:14:30 [INFO]: Model files will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_2/20240603_T041430
2024-06-03 04:14:30 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_2/20240603_T041430/tensorboard
2024-06-03 04:14:30 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 04:14:42 [INFO]: Epoch 001 - training loss: 1.3191, validation loss: 0.9744
2024-06-03 04:14:52 [INFO]: Epoch 002 - training loss: 0.9006, validation loss: 0.9120
2024-06-03 04:15:03 [INFO]: Epoch 003 - training loss: 0.8223, validation loss: 0.9038
2024-06-03 04:15:14 [INFO]: Epoch 004 - training loss: 0.7759, validation loss: 0.9164
2024-06-03 04:15:24 [INFO]: Epoch 005 - training loss: 0.7385, validation loss: 0.8851
2024-06-03 04:15:34 [INFO]: Epoch 006 - training loss: 0.6865, validation loss: 0.8352
2024-06-03 04:15:43 [INFO]: Epoch 007 - training loss: 0.6528, validation loss: 0.8087
2024-06-03 04:15:53 [INFO]: Epoch 008 - training loss: 0.6247, validation loss: 0.7605
2024-06-03 04:16:02 [INFO]: Epoch 009 - training loss: 0.5973, validation loss: 0.7360
2024-06-03 04:16:11 [INFO]: Epoch 010 - training loss: 0.5597, validation loss: 0.7307
2024-06-03 04:16:20 [INFO]: Epoch 011 - training loss: 0.5316, validation loss: 0.6955
2024-06-03 04:16:31 [INFO]: Epoch 012 - training loss: 0.5122, validation loss: 0.6971
2024-06-03 04:16:43 [INFO]: Epoch 013 - training loss: 0.4825, validation loss: 0.6827
2024-06-03 04:16:54 [INFO]: Epoch 014 - training loss: 0.4672, validation loss: 0.6857
2024-06-03 04:17:05 [INFO]: Epoch 015 - training loss: 0.4485, validation loss: 0.6598
2024-06-03 04:17:15 [INFO]: Epoch 016 - training loss: 0.4396, validation loss: 0.6534
2024-06-03 04:17:26 [INFO]: Epoch 017 - training loss: 0.4285, validation loss: 0.6539
2024-06-03 04:17:36 [INFO]: Epoch 018 - training loss: 0.4236, validation loss: 0.6616
2024-06-03 04:17:47 [INFO]: Epoch 019 - training loss: 0.4166, validation loss: 0.6522
2024-06-03 04:17:58 [INFO]: Epoch 020 - training loss: 0.4104, validation loss: 0.6501
2024-06-03 04:18:07 [INFO]: Epoch 021 - training loss: 0.4040, validation loss: 0.6380
2024-06-03 04:18:18 [INFO]: Epoch 022 - training loss: 0.3988, validation loss: 0.6451
2024-06-03 04:18:30 [INFO]: Epoch 023 - training loss: 0.3908, validation loss: 0.6312
2024-06-03 04:18:40 [INFO]: Epoch 024 - training loss: 0.3870, validation loss: 0.6342
2024-06-03 04:18:48 [INFO]: Epoch 025 - training loss: 0.3865, validation loss: 0.6413
2024-06-03 04:19:00 [INFO]: Epoch 026 - training loss: 0.3824, validation loss: 0.6272
2024-06-03 04:19:11 [INFO]: Epoch 027 - training loss: 0.3796, validation loss: 0.6371
2024-06-03 04:19:22 [INFO]: Epoch 028 - training loss: 0.3747, validation loss: 0.6297
2024-06-03 04:19:34 [INFO]: Epoch 029 - training loss: 0.3688, validation loss: 0.6244
2024-06-03 04:19:45 [INFO]: Epoch 030 - training loss: 0.3637, validation loss: 0.6359
2024-06-03 04:19:55 [INFO]: Epoch 031 - training loss: 0.3590, validation loss: 0.6256
2024-06-03 04:20:06 [INFO]: Epoch 032 - training loss: 0.3591, validation loss: 0.6334
2024-06-03 04:20:11 [INFO]: Epoch 033 - training loss: 0.3594, validation loss: 0.6242
2024-06-03 04:20:17 [INFO]: Epoch 034 - training loss: 0.3527, validation loss: 0.6357
2024-06-03 04:20:24 [INFO]: Epoch 035 - training loss: 0.3517, validation loss: 0.6394
2024-06-03 04:20:29 [INFO]: Epoch 036 - training loss: 0.3482, validation loss: 0.6383
2024-06-03 04:20:36 [INFO]: Epoch 037 - training loss: 0.3435, validation loss: 0.6215
2024-06-03 04:20:41 [INFO]: Epoch 038 - training loss: 0.3472, validation loss: 0.6411
2024-06-03 04:20:47 [INFO]: Epoch 039 - training loss: 0.3485, validation loss: 0.6299
2024-06-03 04:20:54 [INFO]: Epoch 040 - training loss: 0.3434, validation loss: 0.6409
2024-06-03 04:20:59 [INFO]: Epoch 041 - training loss: 0.3416, validation loss: 0.6296
2024-06-03 04:21:04 [INFO]: Epoch 042 - training loss: 0.3399, validation loss: 0.6255
2024-06-03 04:21:09 [INFO]: Epoch 043 - training loss: 0.3369, validation loss: 0.6377
2024-06-03 04:21:15 [INFO]: Epoch 044 - training loss: 0.3340, validation loss: 0.6122
2024-06-03 04:21:20 [INFO]: Epoch 045 - training loss: 0.3350, validation loss: 0.6262
2024-06-03 04:21:26 [INFO]: Epoch 046 - training loss: 0.3322, validation loss: 0.6336
2024-06-03 04:21:32 [INFO]: Epoch 047 - training loss: 0.3281, validation loss: 0.6329
2024-06-03 04:21:38 [INFO]: Epoch 048 - training loss: 0.3258, validation loss: 0.6353
2024-06-03 04:21:43 [INFO]: Epoch 049 - training loss: 0.3242, validation loss: 0.6183
2024-06-03 04:21:48 [INFO]: Epoch 050 - training loss: 0.3246, validation loss: 0.6335
2024-06-03 04:21:53 [INFO]: Epoch 051 - training loss: 0.3217, validation loss: 0.6199
2024-06-03 04:21:58 [INFO]: Epoch 052 - training loss: 0.3224, validation loss: 0.6342
2024-06-03 04:22:03 [INFO]: Epoch 053 - training loss: 0.3264, validation loss: 0.6164
2024-06-03 04:22:08 [INFO]: Epoch 054 - training loss: 0.3247, validation loss: 0.6351
2024-06-03 04:22:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:22:08 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 04:22:09 [INFO]: Saved the model to results_point_rate09/PeMS/Koopa_PeMS/round_2/20240603_T041430/Koopa.pypots
2024-06-03 04:22:10 [INFO]: Successfully saved to results_point_rate09/PeMS/Koopa_PeMS/round_2/imputation.pkl
2024-06-03 04:22:10 [INFO]: Round2 - Koopa on PeMS: MAE=0.4850, MSE=0.9086, MRE=0.6019
2024-06-03 04:22:10 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:22:10 [INFO]: Using the given device: cuda:0
2024-06-03 04:22:10 [INFO]: Model files will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_3/20240603_T042210
2024-06-03 04:22:10 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_3/20240603_T042210/tensorboard
2024-06-03 04:22:10 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 04:22:16 [INFO]: Epoch 001 - training loss: 1.2772, validation loss: 0.9271
2024-06-03 04:22:22 [INFO]: Epoch 002 - training loss: 0.8884, validation loss: 0.9512
2024-06-03 04:22:28 [INFO]: Epoch 003 - training loss: 0.8211, validation loss: 0.9241
2024-06-03 04:22:34 [INFO]: Epoch 004 - training loss: 0.7804, validation loss: 0.8990
2024-06-03 04:22:40 [INFO]: Epoch 005 - training loss: 0.7183, validation loss: 0.8338
2024-06-03 04:22:46 [INFO]: Epoch 006 - training loss: 0.6588, validation loss: 0.7961
2024-06-03 04:22:52 [INFO]: Epoch 007 - training loss: 0.6058, validation loss: 0.8158
2024-06-03 04:22:58 [INFO]: Epoch 008 - training loss: 0.5732, validation loss: 0.7475
2024-06-03 04:23:04 [INFO]: Epoch 009 - training loss: 0.5407, validation loss: 0.7266
2024-06-03 04:23:10 [INFO]: Epoch 010 - training loss: 0.5178, validation loss: 0.7103
2024-06-03 04:23:15 [INFO]: Epoch 011 - training loss: 0.4946, validation loss: 0.6814
2024-06-03 04:23:22 [INFO]: Epoch 012 - training loss: 0.4838, validation loss: 0.6839
2024-06-03 04:23:28 [INFO]: Epoch 013 - training loss: 0.4616, validation loss: 0.6785
2024-06-03 04:23:33 [INFO]: Epoch 014 - training loss: 0.4456, validation loss: 0.6666
2024-06-03 04:23:39 [INFO]: Epoch 015 - training loss: 0.4350, validation loss: 0.6681
2024-06-03 04:23:45 [INFO]: Epoch 016 - training loss: 0.4244, validation loss: 0.6434
2024-06-03 04:23:51 [INFO]: Epoch 017 - training loss: 0.4176, validation loss: 0.6436
2024-06-03 04:23:58 [INFO]: Epoch 018 - training loss: 0.4082, validation loss: 0.6332
2024-06-03 04:24:03 [INFO]: Epoch 019 - training loss: 0.4046, validation loss: 0.6234
2024-06-03 04:24:10 [INFO]: Epoch 020 - training loss: 0.3969, validation loss: 0.6295
2024-06-03 04:24:16 [INFO]: Epoch 021 - training loss: 0.3995, validation loss: 0.6253
2024-06-03 04:24:21 [INFO]: Epoch 022 - training loss: 0.3924, validation loss: 0.6183
2024-06-03 04:24:28 [INFO]: Epoch 023 - training loss: 0.3840, validation loss: 0.6274
2024-06-03 04:24:34 [INFO]: Epoch 024 - training loss: 0.3813, validation loss: 0.6270
2024-06-03 04:24:40 [INFO]: Epoch 025 - training loss: 0.3751, validation loss: 0.6128
2024-06-03 04:24:47 [INFO]: Epoch 026 - training loss: 0.3696, validation loss: 0.6171
2024-06-03 04:24:53 [INFO]: Epoch 027 - training loss: 0.3673, validation loss: 0.6126
2024-06-03 04:24:59 [INFO]: Epoch 028 - training loss: 0.3676, validation loss: 0.6225
2024-06-03 04:25:05 [INFO]: Epoch 029 - training loss: 0.3632, validation loss: 0.6240
2024-06-03 04:25:11 [INFO]: Epoch 030 - training loss: 0.3641, validation loss: 0.6334
2024-06-03 04:25:16 [INFO]: Epoch 031 - training loss: 0.3625, validation loss: 0.6072
2024-06-03 04:25:22 [INFO]: Epoch 032 - training loss: 0.3547, validation loss: 0.5983
2024-06-03 04:25:28 [INFO]: Epoch 033 - training loss: 0.3522, validation loss: 0.5956
2024-06-03 04:25:35 [INFO]: Epoch 034 - training loss: 0.3527, validation loss: 0.6034
2024-06-03 04:25:40 [INFO]: Epoch 035 - training loss: 0.3492, validation loss: 0.6103
2024-06-03 04:25:46 [INFO]: Epoch 036 - training loss: 0.3480, validation loss: 0.6136
2024-06-03 04:25:52 [INFO]: Epoch 037 - training loss: 0.3442, validation loss: 0.6016
2024-06-03 04:25:58 [INFO]: Epoch 038 - training loss: 0.3395, validation loss: 0.6037
2024-06-03 04:26:04 [INFO]: Epoch 039 - training loss: 0.3403, validation loss: 0.5966
2024-06-03 04:26:10 [INFO]: Epoch 040 - training loss: 0.3410, validation loss: 0.6150
2024-06-03 04:26:16 [INFO]: Epoch 041 - training loss: 0.3383, validation loss: 0.6047
2024-06-03 04:26:22 [INFO]: Epoch 042 - training loss: 0.3364, validation loss: 0.5994
2024-06-03 04:26:28 [INFO]: Epoch 043 - training loss: 0.3379, validation loss: 0.6130
2024-06-03 04:26:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:26:28 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 04:26:28 [INFO]: Saved the model to results_point_rate09/PeMS/Koopa_PeMS/round_3/20240603_T042210/Koopa.pypots
2024-06-03 04:26:29 [INFO]: Successfully saved to results_point_rate09/PeMS/Koopa_PeMS/round_3/imputation.pkl
2024-06-03 04:26:29 [INFO]: Round3 - Koopa on PeMS: MAE=0.4857, MSE=0.8821, MRE=0.6026
2024-06-03 04:26:29 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:26:29 [INFO]: Using the given device: cuda:0
2024-06-03 04:26:29 [INFO]: Model files will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_4/20240603_T042629
2024-06-03 04:26:29 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Koopa_PeMS/round_4/20240603_T042629/tensorboard
2024-06-03 04:26:29 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 04:26:36 [INFO]: Epoch 001 - training loss: 1.2228, validation loss: 0.9165
2024-06-03 04:26:42 [INFO]: Epoch 002 - training loss: 0.8693, validation loss: 0.8976
2024-06-03 04:26:47 [INFO]: Epoch 003 - training loss: 0.7971, validation loss: 0.8810
2024-06-03 04:26:54 [INFO]: Epoch 004 - training loss: 0.7449, validation loss: 0.9067
2024-06-03 04:26:59 [INFO]: Epoch 005 - training loss: 0.6995, validation loss: 0.8069
2024-06-03 04:27:04 [INFO]: Epoch 006 - training loss: 0.6522, validation loss: 0.7778
2024-06-03 04:27:11 [INFO]: Epoch 007 - training loss: 0.6140, validation loss: 0.7287
2024-06-03 04:27:16 [INFO]: Epoch 008 - training loss: 0.5802, validation loss: 0.7038
2024-06-03 04:27:22 [INFO]: Epoch 009 - training loss: 0.5476, validation loss: 0.7123
2024-06-03 04:27:29 [INFO]: Epoch 010 - training loss: 0.5187, validation loss: 0.6940
2024-06-03 04:27:34 [INFO]: Epoch 011 - training loss: 0.4950, validation loss: 0.6793
2024-06-03 04:27:40 [INFO]: Epoch 012 - training loss: 0.4714, validation loss: 0.6697
2024-06-03 04:27:47 [INFO]: Epoch 013 - training loss: 0.4548, validation loss: 0.6662
2024-06-03 04:27:53 [INFO]: Epoch 014 - training loss: 0.4481, validation loss: 0.6659
2024-06-03 04:27:58 [INFO]: Epoch 015 - training loss: 0.4345, validation loss: 0.6670
2024-06-03 04:28:04 [INFO]: Epoch 016 - training loss: 0.4268, validation loss: 0.6445
2024-06-03 04:28:09 [INFO]: Epoch 017 - training loss: 0.4171, validation loss: 0.6504
2024-06-03 04:28:17 [INFO]: Epoch 018 - training loss: 0.4070, validation loss: 0.6382
2024-06-03 04:28:24 [INFO]: Epoch 019 - training loss: 0.4078, validation loss: 0.6465
2024-06-03 04:28:29 [INFO]: Epoch 020 - training loss: 0.3984, validation loss: 0.6485
2024-06-03 04:28:34 [INFO]: Epoch 021 - training loss: 0.3920, validation loss: 0.6338
2024-06-03 04:28:40 [INFO]: Epoch 022 - training loss: 0.3863, validation loss: 0.6295
2024-06-03 04:28:46 [INFO]: Epoch 023 - training loss: 0.3790, validation loss: 0.6397
2024-06-03 04:28:52 [INFO]: Epoch 024 - training loss: 0.3801, validation loss: 0.6325
2024-06-03 04:28:58 [INFO]: Epoch 025 - training loss: 0.3770, validation loss: 0.6209
2024-06-03 04:29:05 [INFO]: Epoch 026 - training loss: 0.5992, validation loss: 0.6442
2024-06-03 04:29:11 [INFO]: Epoch 027 - training loss: 4.1301, validation loss: 6.7682
2024-06-03 04:29:16 [INFO]: Epoch 028 - training loss: 1.8214, validation loss: 1.9179
2024-06-03 04:29:22 [INFO]: Epoch 029 - training loss: 0.9880, validation loss: 0.6717
2024-06-03 04:29:28 [INFO]: Epoch 030 - training loss: 0.5010, validation loss: 0.6308
2024-06-03 04:29:34 [INFO]: Epoch 031 - training loss: 0.4084, validation loss: 0.6144
2024-06-03 04:29:40 [INFO]: Epoch 032 - training loss: 0.3822, validation loss: 0.6139
2024-06-03 04:29:47 [INFO]: Epoch 033 - training loss: 0.3704, validation loss: 0.6115
2024-06-03 04:29:52 [INFO]: Epoch 034 - training loss: 0.3697, validation loss: 0.6217
2024-06-03 04:29:58 [INFO]: Epoch 035 - training loss: 0.3625, validation loss: 0.6104
2024-06-03 04:30:02 [INFO]: Epoch 036 - training loss: 0.3622, validation loss: 0.6047
2024-06-03 04:30:08 [INFO]: Epoch 037 - training loss: 0.3548, validation loss: 0.6005
2024-06-03 04:30:15 [INFO]: Epoch 038 - training loss: 0.3501, validation loss: 0.6001
2024-06-03 04:30:21 [INFO]: Epoch 039 - training loss: 0.3487, validation loss: 0.6020
2024-06-03 04:30:27 [INFO]: Epoch 040 - training loss: 0.3498, validation loss: 0.6119
2024-06-03 04:30:33 [INFO]: Epoch 041 - training loss: 0.3514, validation loss: 0.6092
2024-06-03 04:30:40 [INFO]: Epoch 042 - training loss: 0.3446, validation loss: 0.6009
2024-06-03 04:30:46 [INFO]: Epoch 043 - training loss: 0.3415, validation loss: 0.6008
2024-06-03 04:30:52 [INFO]: Epoch 044 - training loss: 0.3381, validation loss: 0.6055
2024-06-03 04:30:58 [INFO]: Epoch 045 - training loss: 0.3391, validation loss: 0.6094
2024-06-03 04:31:04 [INFO]: Epoch 046 - training loss: 0.3377, validation loss: 0.6114
2024-06-03 04:31:10 [INFO]: Epoch 047 - training loss: 0.3325, validation loss: 0.6049
2024-06-03 04:31:15 [INFO]: Epoch 048 - training loss: 0.3349, validation loss: 0.5949
2024-06-03 04:31:21 [INFO]: Epoch 049 - training loss: 0.3299, validation loss: 0.5873
2024-06-03 04:31:27 [INFO]: Epoch 050 - training loss: 0.3283, validation loss: 0.5909
2024-06-03 04:31:33 [INFO]: Epoch 051 - training loss: 0.3297, validation loss: 0.6018
2024-06-03 04:31:37 [INFO]: Epoch 052 - training loss: 0.3266, validation loss: 0.5934
2024-06-03 04:31:45 [INFO]: Epoch 053 - training loss: 0.3249, validation loss: 0.5877
2024-06-03 04:31:51 [INFO]: Epoch 054 - training loss: 0.3277, validation loss: 0.5970
2024-06-03 04:31:57 [INFO]: Epoch 055 - training loss: 0.3229, validation loss: 0.5936
2024-06-03 04:31:58 [INFO]: Epoch 056 - training loss: 0.3212, validation loss: 0.5958
2024-06-03 04:32:00 [INFO]: Epoch 057 - training loss: 0.3161, validation loss: 0.5865
2024-06-03 04:32:03 [INFO]: Epoch 058 - training loss: 0.3182, validation loss: 0.5876
2024-06-03 04:32:04 [INFO]: Epoch 059 - training loss: 0.3139, validation loss: 0.5907
2024-06-03 04:32:06 [INFO]: Epoch 060 - training loss: 0.3192, validation loss: 0.5831
2024-06-03 04:32:07 [INFO]: Epoch 061 - training loss: 0.3149, validation loss: 0.5988
2024-06-03 04:32:09 [INFO]: Epoch 062 - training loss: 0.3157, validation loss: 0.5935
2024-06-03 04:32:12 [INFO]: Epoch 063 - training loss: 0.3139, validation loss: 0.5900
2024-06-03 04:32:13 [INFO]: Epoch 064 - training loss: 0.3119, validation loss: 0.5876
2024-06-03 04:32:14 [INFO]: Epoch 065 - training loss: 0.3102, validation loss: 0.5903
2024-06-03 04:32:15 [INFO]: Epoch 066 - training loss: 0.3123, validation loss: 0.6043
2024-06-03 04:32:15 [INFO]: Epoch 067 - training loss: 0.3081, validation loss: 0.5910
2024-06-03 04:32:16 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.5886
2024-06-03 04:32:17 [INFO]: Epoch 069 - training loss: 0.3051, validation loss: 0.5878
2024-06-03 04:32:17 [INFO]: Epoch 070 - training loss: 0.3080, validation loss: 0.5811
2024-06-03 04:32:18 [INFO]: Epoch 071 - training loss: 0.3146, validation loss: 0.5858
2024-06-03 04:32:18 [INFO]: Epoch 072 - training loss: 0.3131, validation loss: 0.5942
2024-06-03 04:32:19 [INFO]: Epoch 073 - training loss: 0.3127, validation loss: 0.5764
2024-06-03 04:32:19 [INFO]: Epoch 074 - training loss: 0.3054, validation loss: 0.5840
2024-06-03 04:32:20 [INFO]: Epoch 075 - training loss: 0.3065, validation loss: 0.5870
2024-06-03 04:32:21 [INFO]: Epoch 076 - training loss: 0.3045, validation loss: 0.5739
2024-06-03 04:32:21 [INFO]: Epoch 077 - training loss: 0.3066, validation loss: 0.5762
2024-06-03 04:32:22 [INFO]: Epoch 078 - training loss: 0.3051, validation loss: 0.5808
2024-06-03 04:32:22 [INFO]: Epoch 079 - training loss: 0.3017, validation loss: 0.6027
2024-06-03 04:32:23 [INFO]: Epoch 080 - training loss: 0.3022, validation loss: 0.5865
2024-06-03 04:32:24 [INFO]: Epoch 081 - training loss: 0.2983, validation loss: 0.5845
2024-06-03 04:32:24 [INFO]: Epoch 082 - training loss: 0.3014, validation loss: 0.5799
2024-06-03 04:32:25 [INFO]: Epoch 083 - training loss: 0.2981, validation loss: 0.5843
2024-06-03 04:32:25 [INFO]: Epoch 084 - training loss: 0.3006, validation loss: 0.5836
2024-06-03 04:32:26 [INFO]: Epoch 085 - training loss: 0.2956, validation loss: 0.5836
2024-06-03 04:32:27 [INFO]: Epoch 086 - training loss: 0.2965, validation loss: 0.5814
2024-06-03 04:32:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:32:27 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 04:32:27 [INFO]: Saved the model to results_point_rate09/PeMS/Koopa_PeMS/round_4/20240603_T042629/Koopa.pypots
2024-06-03 04:32:27 [INFO]: Successfully saved to results_point_rate09/PeMS/Koopa_PeMS/round_4/imputation.pkl
2024-06-03 04:32:27 [INFO]: Round4 - Koopa on PeMS: MAE=0.4547, MSE=0.8320, MRE=0.5643
2024-06-03 04:32:27 [INFO]: Done! Final results:
Averaged Koopa (13,306,214 params) on PeMS: MAE=0.4855 ± 0.025474378899060682, MSE=0.9010 ± 0.06364442968556347, MRE=0.6024 ± 0.0316093964695296, average inference time=0.21
