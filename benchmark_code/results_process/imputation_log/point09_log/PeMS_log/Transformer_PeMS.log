2024-06-03 04:32:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:32:41 [INFO]: Using the given device: cuda:0
2024-06-03 04:32:42 [INFO]: Model files will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_0/20240603_T043242
2024-06-03 04:32:42 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_0/20240603_T043242/tensorboard
2024-06-03 04:32:42 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=256
2024-06-03 04:32:42 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:32:43 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 23,135,326
2024-06-03 04:32:47 [INFO]: Epoch 001 - training loss: 1.0940, validation loss: 0.7083
2024-06-03 04:32:49 [INFO]: Epoch 002 - training loss: 0.6751, validation loss: 0.5838
2024-06-03 04:32:50 [INFO]: Epoch 003 - training loss: 0.5775, validation loss: 0.5381
2024-06-03 04:32:52 [INFO]: Epoch 004 - training loss: 0.5322, validation loss: 0.5294
2024-06-03 04:32:54 [INFO]: Epoch 005 - training loss: 0.5152, validation loss: 0.5167
2024-06-03 04:32:56 [INFO]: Epoch 006 - training loss: 0.5051, validation loss: 0.5199
2024-06-03 04:32:58 [INFO]: Epoch 007 - training loss: 0.4875, validation loss: 0.5149
2024-06-03 04:33:01 [INFO]: Epoch 008 - training loss: 0.4750, validation loss: 0.5138
2024-06-03 04:33:03 [INFO]: Epoch 009 - training loss: 0.4668, validation loss: 0.5092
2024-06-03 04:33:05 [INFO]: Epoch 010 - training loss: 0.4552, validation loss: 0.5094
2024-06-03 04:33:07 [INFO]: Epoch 011 - training loss: 0.4499, validation loss: 0.5093
2024-06-03 04:33:10 [INFO]: Epoch 012 - training loss: 0.4327, validation loss: 0.5126
2024-06-03 04:33:12 [INFO]: Epoch 013 - training loss: 0.4223, validation loss: 0.5112
2024-06-03 04:33:14 [INFO]: Epoch 014 - training loss: 0.4151, validation loss: 0.5112
2024-06-03 04:33:16 [INFO]: Epoch 015 - training loss: 0.4111, validation loss: 0.5134
2024-06-03 04:33:18 [INFO]: Epoch 016 - training loss: 0.3984, validation loss: 0.5074
2024-06-03 04:33:20 [INFO]: Epoch 017 - training loss: 0.3916, validation loss: 0.5034
2024-06-03 04:33:23 [INFO]: Epoch 018 - training loss: 0.3844, validation loss: 0.5055
2024-06-03 04:33:25 [INFO]: Epoch 019 - training loss: 0.3768, validation loss: 0.5090
2024-06-03 04:33:27 [INFO]: Epoch 020 - training loss: 0.3732, validation loss: 0.5084
2024-06-03 04:33:30 [INFO]: Epoch 021 - training loss: 0.3645, validation loss: 0.5106
2024-06-03 04:33:33 [INFO]: Epoch 022 - training loss: 0.3643, validation loss: 0.5051
2024-06-03 04:33:37 [INFO]: Epoch 023 - training loss: 0.3582, validation loss: 0.5070
2024-06-03 04:33:40 [INFO]: Epoch 024 - training loss: 0.3562, validation loss: 0.5097
2024-06-03 04:33:43 [INFO]: Epoch 025 - training loss: 0.3497, validation loss: 0.5025
2024-06-03 04:33:46 [INFO]: Epoch 026 - training loss: 0.3444, validation loss: 0.5062
2024-06-03 04:33:49 [INFO]: Epoch 027 - training loss: 0.3425, validation loss: 0.5081
2024-06-03 04:33:52 [INFO]: Epoch 028 - training loss: 0.3407, validation loss: 0.5055
2024-06-03 04:33:55 [INFO]: Epoch 029 - training loss: 0.3314, validation loss: 0.5042
2024-06-03 04:33:58 [INFO]: Epoch 030 - training loss: 0.3284, validation loss: 0.5041
2024-06-03 04:34:01 [INFO]: Epoch 031 - training loss: 0.3271, validation loss: 0.5062
2024-06-03 04:34:04 [INFO]: Epoch 032 - training loss: 0.3241, validation loss: 0.5037
2024-06-03 04:34:07 [INFO]: Epoch 033 - training loss: 0.3184, validation loss: 0.5022
2024-06-03 04:34:10 [INFO]: Epoch 034 - training loss: 0.3150, validation loss: 0.5071
2024-06-03 04:34:13 [INFO]: Epoch 035 - training loss: 0.3113, validation loss: 0.4987
2024-06-03 04:34:16 [INFO]: Epoch 036 - training loss: 0.3100, validation loss: 0.5020
2024-06-03 04:34:19 [INFO]: Epoch 037 - training loss: 0.3142, validation loss: 0.5020
2024-06-03 04:34:22 [INFO]: Epoch 038 - training loss: 0.3077, validation loss: 0.5030
2024-06-03 04:34:25 [INFO]: Epoch 039 - training loss: 0.3040, validation loss: 0.5017
2024-06-03 04:34:28 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.4999
2024-06-03 04:34:32 [INFO]: Epoch 041 - training loss: 0.2993, validation loss: 0.4998
2024-06-03 04:34:34 [INFO]: Epoch 042 - training loss: 0.2979, validation loss: 0.5003
2024-06-03 04:34:38 [INFO]: Epoch 043 - training loss: 0.2921, validation loss: 0.5023
2024-06-03 04:34:41 [INFO]: Epoch 044 - training loss: 0.2933, validation loss: 0.5029
2024-06-03 04:34:44 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.4998
2024-06-03 04:34:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:34:44 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 04:34:44 [INFO]: Saved the model to results_point_rate09/PeMS/Transformer_PeMS/round_0/20240603_T043242/Transformer.pypots
2024-06-03 04:34:46 [INFO]: Successfully saved to results_point_rate09/PeMS/Transformer_PeMS/round_0/imputation.pkl
2024-06-03 04:34:46 [INFO]: Round0 - Transformer on PeMS: MAE=0.3789, MSE=0.6990, MRE=0.4702
2024-06-03 04:34:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:34:46 [INFO]: Using the given device: cuda:0
2024-06-03 04:34:46 [INFO]: Model files will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_1/20240603_T043446
2024-06-03 04:34:46 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_1/20240603_T043446/tensorboard
2024-06-03 04:34:46 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=256
2024-06-03 04:34:46 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:34:46 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 23,135,326
2024-06-03 04:34:50 [INFO]: Epoch 001 - training loss: 1.0948, validation loss: 0.7646
2024-06-03 04:34:53 [INFO]: Epoch 002 - training loss: 0.6950, validation loss: 0.6021
2024-06-03 04:34:56 [INFO]: Epoch 003 - training loss: 0.5861, validation loss: 0.5677
2024-06-03 04:34:59 [INFO]: Epoch 004 - training loss: 0.5404, validation loss: 0.5334
2024-06-03 04:35:02 [INFO]: Epoch 005 - training loss: 0.5073, validation loss: 0.5323
2024-06-03 04:35:05 [INFO]: Epoch 006 - training loss: 0.5033, validation loss: 0.5233
2024-06-03 04:35:08 [INFO]: Epoch 007 - training loss: 0.4909, validation loss: 0.5298
2024-06-03 04:35:11 [INFO]: Epoch 008 - training loss: 0.4708, validation loss: 0.5123
2024-06-03 04:35:14 [INFO]: Epoch 009 - training loss: 0.4598, validation loss: 0.5137
2024-06-03 04:35:17 [INFO]: Epoch 010 - training loss: 0.4507, validation loss: 0.5174
2024-06-03 04:35:20 [INFO]: Epoch 011 - training loss: 0.4436, validation loss: 0.5152
2024-06-03 04:35:22 [INFO]: Epoch 012 - training loss: 0.4314, validation loss: 0.5118
2024-06-03 04:35:25 [INFO]: Epoch 013 - training loss: 0.4189, validation loss: 0.5196
2024-06-03 04:35:28 [INFO]: Epoch 014 - training loss: 0.4151, validation loss: 0.5066
2024-06-03 04:35:32 [INFO]: Epoch 015 - training loss: 0.4076, validation loss: 0.5013
2024-06-03 04:35:35 [INFO]: Epoch 016 - training loss: 0.3966, validation loss: 0.5162
2024-06-03 04:35:38 [INFO]: Epoch 017 - training loss: 0.3952, validation loss: 0.5057
2024-06-03 04:35:41 [INFO]: Epoch 018 - training loss: 0.3804, validation loss: 0.5045
2024-06-03 04:35:44 [INFO]: Epoch 019 - training loss: 0.3762, validation loss: 0.5097
2024-06-03 04:35:47 [INFO]: Epoch 020 - training loss: 0.3738, validation loss: 0.5071
2024-06-03 04:35:50 [INFO]: Epoch 021 - training loss: 0.3664, validation loss: 0.5137
2024-06-03 04:35:53 [INFO]: Epoch 022 - training loss: 0.3622, validation loss: 0.5054
2024-06-03 04:35:56 [INFO]: Epoch 023 - training loss: 0.3579, validation loss: 0.5110
2024-06-03 04:35:59 [INFO]: Epoch 024 - training loss: 0.3495, validation loss: 0.5061
2024-06-03 04:36:02 [INFO]: Epoch 025 - training loss: 0.3471, validation loss: 0.5073
2024-06-03 04:36:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:36:02 [INFO]: Finished training. The best model is from epoch#15.
2024-06-03 04:36:02 [INFO]: Saved the model to results_point_rate09/PeMS/Transformer_PeMS/round_1/20240603_T043446/Transformer.pypots
2024-06-03 04:36:03 [INFO]: Successfully saved to results_point_rate09/PeMS/Transformer_PeMS/round_1/imputation.pkl
2024-06-03 04:36:03 [INFO]: Round1 - Transformer on PeMS: MAE=0.3755, MSE=0.7171, MRE=0.4659
2024-06-03 04:36:03 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:36:03 [INFO]: Using the given device: cuda:0
2024-06-03 04:36:04 [INFO]: Model files will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_2/20240603_T043603
2024-06-03 04:36:04 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_2/20240603_T043603/tensorboard
2024-06-03 04:36:04 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=256
2024-06-03 04:36:04 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:36:04 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 23,135,326
2024-06-03 04:36:07 [INFO]: Epoch 001 - training loss: 1.0962, validation loss: 0.6911
2024-06-03 04:36:10 [INFO]: Epoch 002 - training loss: 0.6795, validation loss: 0.6010
2024-06-03 04:36:13 [INFO]: Epoch 003 - training loss: 0.5911, validation loss: 0.5639
2024-06-03 04:36:16 [INFO]: Epoch 004 - training loss: 0.5350, validation loss: 0.5288
2024-06-03 04:36:20 [INFO]: Epoch 005 - training loss: 0.5206, validation loss: 0.5262
2024-06-03 04:36:23 [INFO]: Epoch 006 - training loss: 0.5059, validation loss: 0.5279
2024-06-03 04:36:26 [INFO]: Epoch 007 - training loss: 0.4838, validation loss: 0.5216
2024-06-03 04:36:29 [INFO]: Epoch 008 - training loss: 0.4726, validation loss: 0.5139
2024-06-03 04:36:32 [INFO]: Epoch 009 - training loss: 0.4646, validation loss: 0.5199
2024-06-03 04:36:35 [INFO]: Epoch 010 - training loss: 0.4498, validation loss: 0.5124
2024-06-03 04:36:38 [INFO]: Epoch 011 - training loss: 0.4436, validation loss: 0.5157
2024-06-03 04:36:41 [INFO]: Epoch 012 - training loss: 0.4417, validation loss: 0.5265
2024-06-03 04:36:44 [INFO]: Epoch 013 - training loss: 0.4328, validation loss: 0.5143
2024-06-03 04:36:46 [INFO]: Epoch 014 - training loss: 0.4176, validation loss: 0.5115
2024-06-03 04:36:49 [INFO]: Epoch 015 - training loss: 0.4066, validation loss: 0.5159
2024-06-03 04:36:52 [INFO]: Epoch 016 - training loss: 0.3990, validation loss: 0.5147
2024-06-03 04:36:55 [INFO]: Epoch 017 - training loss: 0.3963, validation loss: 0.5117
2024-06-03 04:36:58 [INFO]: Epoch 018 - training loss: 0.3845, validation loss: 0.5130
2024-06-03 04:37:01 [INFO]: Epoch 019 - training loss: 0.3787, validation loss: 0.5114
2024-06-03 04:37:04 [INFO]: Epoch 020 - training loss: 0.3736, validation loss: 0.5206
2024-06-03 04:37:07 [INFO]: Epoch 021 - training loss: 0.3667, validation loss: 0.5091
2024-06-03 04:37:10 [INFO]: Epoch 022 - training loss: 0.3585, validation loss: 0.5073
2024-06-03 04:37:13 [INFO]: Epoch 023 - training loss: 0.3544, validation loss: 0.5159
2024-06-03 04:37:16 [INFO]: Epoch 024 - training loss: 0.3478, validation loss: 0.5116
2024-06-03 04:37:19 [INFO]: Epoch 025 - training loss: 0.3412, validation loss: 0.5129
2024-06-03 04:37:22 [INFO]: Epoch 026 - training loss: 0.3454, validation loss: 0.5108
2024-06-03 04:37:25 [INFO]: Epoch 027 - training loss: 0.3413, validation loss: 0.5089
2024-06-03 04:37:28 [INFO]: Epoch 028 - training loss: 0.3387, validation loss: 0.5178
2024-06-03 04:37:31 [INFO]: Epoch 029 - training loss: 0.3358, validation loss: 0.5068
2024-06-03 04:37:35 [INFO]: Epoch 030 - training loss: 0.3276, validation loss: 0.5118
2024-06-03 04:37:38 [INFO]: Epoch 031 - training loss: 0.3275, validation loss: 0.5106
2024-06-03 04:37:41 [INFO]: Epoch 032 - training loss: 0.3262, validation loss: 0.5075
2024-06-03 04:37:44 [INFO]: Epoch 033 - training loss: 0.3199, validation loss: 0.5064
2024-06-03 04:37:46 [INFO]: Epoch 034 - training loss: 0.3161, validation loss: 0.5111
2024-06-03 04:37:49 [INFO]: Epoch 035 - training loss: 0.3169, validation loss: 0.5101
2024-06-03 04:37:53 [INFO]: Epoch 036 - training loss: 0.3117, validation loss: 0.5084
2024-06-03 04:37:56 [INFO]: Epoch 037 - training loss: 0.3104, validation loss: 0.5064
2024-06-03 04:37:59 [INFO]: Epoch 038 - training loss: 0.3062, validation loss: 0.5035
2024-06-03 04:38:02 [INFO]: Epoch 039 - training loss: 0.3059, validation loss: 0.5086
2024-06-03 04:38:05 [INFO]: Epoch 040 - training loss: 0.3057, validation loss: 0.5051
2024-06-03 04:38:08 [INFO]: Epoch 041 - training loss: 0.3015, validation loss: 0.5039
2024-06-03 04:38:11 [INFO]: Epoch 042 - training loss: 0.2968, validation loss: 0.5070
2024-06-03 04:38:14 [INFO]: Epoch 043 - training loss: 0.2969, validation loss: 0.5087
2024-06-03 04:38:17 [INFO]: Epoch 044 - training loss: 0.2937, validation loss: 0.5083
2024-06-03 04:38:20 [INFO]: Epoch 045 - training loss: 0.2939, validation loss: 0.5106
2024-06-03 04:38:23 [INFO]: Epoch 046 - training loss: 0.2909, validation loss: 0.5059
2024-06-03 04:38:26 [INFO]: Epoch 047 - training loss: 0.2898, validation loss: 0.5067
2024-06-03 04:38:29 [INFO]: Epoch 048 - training loss: 0.2866, validation loss: 0.5059
2024-06-03 04:38:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:38:29 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 04:38:30 [INFO]: Saved the model to results_point_rate09/PeMS/Transformer_PeMS/round_2/20240603_T043603/Transformer.pypots
2024-06-03 04:38:31 [INFO]: Successfully saved to results_point_rate09/PeMS/Transformer_PeMS/round_2/imputation.pkl
2024-06-03 04:38:31 [INFO]: Round2 - Transformer on PeMS: MAE=0.3768, MSE=0.7162, MRE=0.4676
2024-06-03 04:38:31 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:38:31 [INFO]: Using the given device: cuda:0
2024-06-03 04:38:31 [INFO]: Model files will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_3/20240603_T043831
2024-06-03 04:38:31 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_3/20240603_T043831/tensorboard
2024-06-03 04:38:31 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=256
2024-06-03 04:38:31 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:38:32 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 23,135,326
2024-06-03 04:38:35 [INFO]: Epoch 001 - training loss: 1.0858, validation loss: 0.6969
2024-06-03 04:38:38 [INFO]: Epoch 002 - training loss: 0.6709, validation loss: 0.5977
2024-06-03 04:38:41 [INFO]: Epoch 003 - training loss: 0.5794, validation loss: 0.5496
2024-06-03 04:38:44 [INFO]: Epoch 004 - training loss: 0.5368, validation loss: 0.5347
2024-06-03 04:38:47 [INFO]: Epoch 005 - training loss: 0.5095, validation loss: 0.5203
2024-06-03 04:38:50 [INFO]: Epoch 006 - training loss: 0.4955, validation loss: 0.5202
2024-06-03 04:38:53 [INFO]: Epoch 007 - training loss: 0.4886, validation loss: 0.5208
2024-06-03 04:38:57 [INFO]: Epoch 008 - training loss: 0.4776, validation loss: 0.5168
2024-06-03 04:39:00 [INFO]: Epoch 009 - training loss: 0.4682, validation loss: 0.5087
2024-06-03 04:39:03 [INFO]: Epoch 010 - training loss: 0.4554, validation loss: 0.5078
2024-06-03 04:39:06 [INFO]: Epoch 011 - training loss: 0.4424, validation loss: 0.5087
2024-06-03 04:39:09 [INFO]: Epoch 012 - training loss: 0.4318, validation loss: 0.5072
2024-06-03 04:39:12 [INFO]: Epoch 013 - training loss: 0.4222, validation loss: 0.5071
2024-06-03 04:39:15 [INFO]: Epoch 014 - training loss: 0.4103, validation loss: 0.5027
2024-06-03 04:39:18 [INFO]: Epoch 015 - training loss: 0.4069, validation loss: 0.5089
2024-06-03 04:39:21 [INFO]: Epoch 016 - training loss: 0.3945, validation loss: 0.4993
2024-06-03 04:39:24 [INFO]: Epoch 017 - training loss: 0.3961, validation loss: 0.5061
2024-06-03 04:39:27 [INFO]: Epoch 018 - training loss: 0.3917, validation loss: 0.5102
2024-06-03 04:39:30 [INFO]: Epoch 019 - training loss: 0.3864, validation loss: 0.5064
2024-06-03 04:39:33 [INFO]: Epoch 020 - training loss: 0.3735, validation loss: 0.5021
2024-06-03 04:39:36 [INFO]: Epoch 021 - training loss: 0.3658, validation loss: 0.5052
2024-06-03 04:39:39 [INFO]: Epoch 022 - training loss: 0.3608, validation loss: 0.5055
2024-06-03 04:39:41 [INFO]: Epoch 023 - training loss: 0.3557, validation loss: 0.5082
2024-06-03 04:39:44 [INFO]: Epoch 024 - training loss: 0.3500, validation loss: 0.5073
2024-06-03 04:39:47 [INFO]: Epoch 025 - training loss: 0.3474, validation loss: 0.5057
2024-06-03 04:39:49 [INFO]: Epoch 026 - training loss: 0.3440, validation loss: 0.5011
2024-06-03 04:39:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:39:49 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 04:39:50 [INFO]: Saved the model to results_point_rate09/PeMS/Transformer_PeMS/round_3/20240603_T043831/Transformer.pypots
2024-06-03 04:39:50 [INFO]: Successfully saved to results_point_rate09/PeMS/Transformer_PeMS/round_3/imputation.pkl
2024-06-03 04:39:50 [INFO]: Round3 - Transformer on PeMS: MAE=0.3716, MSE=0.7080, MRE=0.4612
2024-06-03 04:39:50 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:39:50 [INFO]: Using the given device: cuda:0
2024-06-03 04:39:51 [INFO]: Model files will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_4/20240603_T043950
2024-06-03 04:39:51 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Transformer_PeMS/round_4/20240603_T043950/tensorboard
2024-06-03 04:39:51 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=256
2024-06-03 04:39:51 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-03 04:39:51 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 23,135,326
2024-06-03 04:39:54 [INFO]: Epoch 001 - training loss: 1.1255, validation loss: 0.7293
2024-06-03 04:39:56 [INFO]: Epoch 002 - training loss: 0.6968, validation loss: 0.6113
2024-06-03 04:39:59 [INFO]: Epoch 003 - training loss: 0.5890, validation loss: 0.5486
2024-06-03 04:40:01 [INFO]: Epoch 004 - training loss: 0.5387, validation loss: 0.5334
2024-06-03 04:40:04 [INFO]: Epoch 005 - training loss: 0.5177, validation loss: 0.5261
2024-06-03 04:40:06 [INFO]: Epoch 006 - training loss: 0.4951, validation loss: 0.5278
2024-06-03 04:40:08 [INFO]: Epoch 007 - training loss: 0.4829, validation loss: 0.5319
2024-06-03 04:40:11 [INFO]: Epoch 008 - training loss: 0.4768, validation loss: 0.5147
2024-06-03 04:40:13 [INFO]: Epoch 009 - training loss: 0.4667, validation loss: 0.5178
2024-06-03 04:40:16 [INFO]: Epoch 010 - training loss: 0.4567, validation loss: 0.5075
2024-06-03 04:40:18 [INFO]: Epoch 011 - training loss: 0.4438, validation loss: 0.5074
2024-06-03 04:40:21 [INFO]: Epoch 012 - training loss: 0.4369, validation loss: 0.5098
2024-06-03 04:40:23 [INFO]: Epoch 013 - training loss: 0.4224, validation loss: 0.5124
2024-06-03 04:40:26 [INFO]: Epoch 014 - training loss: 0.4185, validation loss: 0.5174
2024-06-03 04:40:28 [INFO]: Epoch 015 - training loss: 0.4088, validation loss: 0.5175
2024-06-03 04:40:31 [INFO]: Epoch 016 - training loss: 0.4008, validation loss: 0.5119
2024-06-03 04:40:34 [INFO]: Epoch 017 - training loss: 0.3971, validation loss: 0.5073
2024-06-03 04:40:36 [INFO]: Epoch 018 - training loss: 0.3864, validation loss: 0.5053
2024-06-03 04:40:39 [INFO]: Epoch 019 - training loss: 0.3821, validation loss: 0.5063
2024-06-03 04:40:42 [INFO]: Epoch 020 - training loss: 0.3732, validation loss: 0.5064
2024-06-03 04:40:44 [INFO]: Epoch 021 - training loss: 0.3667, validation loss: 0.5060
2024-06-03 04:40:47 [INFO]: Epoch 022 - training loss: 0.3633, validation loss: 0.5076
2024-06-03 04:40:50 [INFO]: Epoch 023 - training loss: 0.3596, validation loss: 0.5056
2024-06-03 04:40:52 [INFO]: Epoch 024 - training loss: 0.3548, validation loss: 0.5030
2024-06-03 04:40:55 [INFO]: Epoch 025 - training loss: 0.3529, validation loss: 0.5039
2024-06-03 04:40:58 [INFO]: Epoch 026 - training loss: 0.3434, validation loss: 0.5095
2024-06-03 04:41:00 [INFO]: Epoch 027 - training loss: 0.3479, validation loss: 0.5014
2024-06-03 04:41:03 [INFO]: Epoch 028 - training loss: 0.3439, validation loss: 0.5079
2024-06-03 04:41:05 [INFO]: Epoch 029 - training loss: 0.3355, validation loss: 0.5055
2024-06-03 04:41:08 [INFO]: Epoch 030 - training loss: 0.3315, validation loss: 0.5013
2024-06-03 04:41:10 [INFO]: Epoch 031 - training loss: 0.3249, validation loss: 0.5050
2024-06-03 04:41:13 [INFO]: Epoch 032 - training loss: 0.3235, validation loss: 0.5038
2024-06-03 04:41:16 [INFO]: Epoch 033 - training loss: 0.3219, validation loss: 0.5004
2024-06-03 04:41:18 [INFO]: Epoch 034 - training loss: 0.3187, validation loss: 0.5036
2024-06-03 04:41:20 [INFO]: Epoch 035 - training loss: 0.3150, validation loss: 0.5024
2024-06-03 04:41:23 [INFO]: Epoch 036 - training loss: 0.3130, validation loss: 0.5021
2024-06-03 04:41:25 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.5052
2024-06-03 04:41:28 [INFO]: Epoch 038 - training loss: 0.3069, validation loss: 0.5079
2024-06-03 04:41:30 [INFO]: Epoch 039 - training loss: 0.3105, validation loss: 0.5114
2024-06-03 04:41:32 [INFO]: Epoch 040 - training loss: 0.3081, validation loss: 0.5032
2024-06-03 04:41:35 [INFO]: Epoch 041 - training loss: 0.3021, validation loss: 0.5074
2024-06-03 04:41:37 [INFO]: Epoch 042 - training loss: 0.3046, validation loss: 0.5027
2024-06-03 04:41:39 [INFO]: Epoch 043 - training loss: 0.3005, validation loss: 0.5047
2024-06-03 04:41:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:41:39 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 04:41:40 [INFO]: Saved the model to results_point_rate09/PeMS/Transformer_PeMS/round_4/20240603_T043950/Transformer.pypots
2024-06-03 04:41:40 [INFO]: Successfully saved to results_point_rate09/PeMS/Transformer_PeMS/round_4/imputation.pkl
2024-06-03 04:41:40 [INFO]: Round4 - Transformer on PeMS: MAE=0.3759, MSE=0.7137, MRE=0.4665
2024-06-03 04:41:40 [INFO]: Done! Final results:
Averaged Transformer (23,135,326 params) on PeMS: MAE=0.3758 ± 0.002377263158854185, MSE=0.7108 ± 0.006695150228001059, MRE=0.4663 ± 0.002949781582443159, average inference time=0.14
