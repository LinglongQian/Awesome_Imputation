2024-06-03 04:32:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:32:41 [INFO]: Using the given device: cuda:0
2024-06-03 04:32:42 [INFO]: Model files will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_0/20240603_T043242
2024-06-03 04:32:42 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_0/20240603_T043242/tensorboard
2024-06-03 04:32:43 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 04:32:48 [INFO]: Epoch 001 - training loss: 1.2303, validation loss: 1.0290
2024-06-03 04:32:51 [INFO]: Epoch 002 - training loss: 0.8924, validation loss: 0.9035
2024-06-03 04:32:53 [INFO]: Epoch 003 - training loss: 0.7842, validation loss: 0.8551
2024-06-03 04:32:56 [INFO]: Epoch 004 - training loss: 0.6895, validation loss: 0.7685
2024-06-03 04:32:59 [INFO]: Epoch 005 - training loss: 0.6249, validation loss: 0.7365
2024-06-03 04:33:02 [INFO]: Epoch 006 - training loss: 0.5945, validation loss: 0.7068
2024-06-03 04:33:04 [INFO]: Epoch 007 - training loss: 0.5777, validation loss: 0.7049
2024-06-03 04:33:07 [INFO]: Epoch 008 - training loss: 0.5619, validation loss: 0.6744
2024-06-03 04:33:10 [INFO]: Epoch 009 - training loss: 0.5518, validation loss: 0.6623
2024-06-03 04:33:13 [INFO]: Epoch 010 - training loss: 0.5427, validation loss: 0.6641
2024-06-03 04:33:16 [INFO]: Epoch 011 - training loss: 0.5327, validation loss: 0.6632
2024-06-03 04:33:20 [INFO]: Epoch 012 - training loss: 0.5219, validation loss: 0.6538
2024-06-03 04:33:23 [INFO]: Epoch 013 - training loss: 0.5152, validation loss: 0.6543
2024-06-03 04:33:26 [INFO]: Epoch 014 - training loss: 0.5155, validation loss: 0.6527
2024-06-03 04:33:29 [INFO]: Epoch 015 - training loss: 0.5095, validation loss: 0.6492
2024-06-03 04:33:33 [INFO]: Epoch 016 - training loss: 0.5063, validation loss: 0.6546
2024-06-03 04:33:37 [INFO]: Epoch 017 - training loss: 0.4963, validation loss: 0.6417
2024-06-03 04:33:41 [INFO]: Epoch 018 - training loss: 0.4875, validation loss: 0.6347
2024-06-03 04:33:45 [INFO]: Epoch 019 - training loss: 0.4779, validation loss: 0.6312
2024-06-03 04:33:49 [INFO]: Epoch 020 - training loss: 0.4716, validation loss: 0.6261
2024-06-03 04:33:53 [INFO]: Epoch 021 - training loss: 0.4690, validation loss: 0.6142
2024-06-03 04:33:56 [INFO]: Epoch 022 - training loss: 0.4664, validation loss: 0.6199
2024-06-03 04:34:00 [INFO]: Epoch 023 - training loss: 0.4607, validation loss: 0.5986
2024-06-03 04:34:04 [INFO]: Epoch 024 - training loss: 0.4577, validation loss: 0.6056
2024-06-03 04:34:08 [INFO]: Epoch 025 - training loss: 0.4541, validation loss: 0.6001
2024-06-03 04:34:12 [INFO]: Epoch 026 - training loss: 0.4447, validation loss: 0.5966
2024-06-03 04:34:16 [INFO]: Epoch 027 - training loss: 0.4431, validation loss: 0.6002
2024-06-03 04:34:20 [INFO]: Epoch 028 - training loss: 0.4351, validation loss: 0.5933
2024-06-03 04:34:23 [INFO]: Epoch 029 - training loss: 0.4308, validation loss: 0.5966
2024-06-03 04:34:27 [INFO]: Epoch 030 - training loss: 0.4237, validation loss: 0.6037
2024-06-03 04:34:31 [INFO]: Epoch 031 - training loss: 0.4191, validation loss: 0.5840
2024-06-03 04:34:35 [INFO]: Epoch 032 - training loss: 0.4211, validation loss: 0.5845
2024-06-03 04:34:39 [INFO]: Epoch 033 - training loss: 0.4135, validation loss: 0.5772
2024-06-03 04:34:43 [INFO]: Epoch 034 - training loss: 0.4089, validation loss: 0.5817
2024-06-03 04:34:47 [INFO]: Epoch 035 - training loss: 0.4045, validation loss: 0.5772
2024-06-03 04:34:51 [INFO]: Epoch 036 - training loss: 0.4009, validation loss: 0.5708
2024-06-03 04:34:55 [INFO]: Epoch 037 - training loss: 0.4010, validation loss: 0.5696
2024-06-03 04:34:59 [INFO]: Epoch 038 - training loss: 0.3954, validation loss: 0.5770
2024-06-03 04:35:03 [INFO]: Epoch 039 - training loss: 0.3916, validation loss: 0.5761
2024-06-03 04:35:07 [INFO]: Epoch 040 - training loss: 0.3876, validation loss: 0.5743
2024-06-03 04:35:11 [INFO]: Epoch 041 - training loss: 0.3869, validation loss: 0.5871
2024-06-03 04:35:15 [INFO]: Epoch 042 - training loss: 0.3825, validation loss: 0.5671
2024-06-03 04:35:19 [INFO]: Epoch 043 - training loss: 0.3814, validation loss: 0.5772
2024-06-03 04:35:22 [INFO]: Epoch 044 - training loss: 0.3808, validation loss: 0.5632
2024-06-03 04:35:26 [INFO]: Epoch 045 - training loss: 0.3787, validation loss: 0.5713
2024-06-03 04:35:31 [INFO]: Epoch 046 - training loss: 0.3806, validation loss: 0.5688
2024-06-03 04:35:35 [INFO]: Epoch 047 - training loss: 0.3744, validation loss: 0.5709
2024-06-03 04:35:39 [INFO]: Epoch 048 - training loss: 0.3690, validation loss: 0.5701
2024-06-03 04:35:43 [INFO]: Epoch 049 - training loss: 0.3670, validation loss: 0.5748
2024-06-03 04:35:47 [INFO]: Epoch 050 - training loss: 0.3660, validation loss: 0.5650
2024-06-03 04:35:50 [INFO]: Epoch 051 - training loss: 0.3629, validation loss: 0.5587
2024-06-03 04:35:54 [INFO]: Epoch 052 - training loss: 0.3618, validation loss: 0.5695
2024-06-03 04:35:58 [INFO]: Epoch 053 - training loss: 0.3595, validation loss: 0.5801
2024-06-03 04:36:02 [INFO]: Epoch 054 - training loss: 0.3562, validation loss: 0.5701
2024-06-03 04:36:06 [INFO]: Epoch 055 - training loss: 0.3523, validation loss: 0.5807
2024-06-03 04:36:10 [INFO]: Epoch 056 - training loss: 0.3540, validation loss: 0.5689
2024-06-03 04:36:14 [INFO]: Epoch 057 - training loss: 0.3502, validation loss: 0.5652
2024-06-03 04:36:18 [INFO]: Epoch 058 - training loss: 0.3474, validation loss: 0.5649
2024-06-03 04:36:23 [INFO]: Epoch 059 - training loss: 0.3468, validation loss: 0.5713
2024-06-03 04:36:27 [INFO]: Epoch 060 - training loss: 0.3456, validation loss: 0.5728
2024-06-03 04:36:31 [INFO]: Epoch 061 - training loss: 0.3430, validation loss: 0.5684
2024-06-03 04:36:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:36:31 [INFO]: Finished training. The best model is from epoch#51.
2024-06-03 04:36:31 [INFO]: Saved the model to results_point_rate09/PeMS/StemGNN_PeMS/round_0/20240603_T043242/StemGNN.pypots
2024-06-03 04:36:33 [INFO]: Successfully saved to results_point_rate09/PeMS/StemGNN_PeMS/round_0/imputation.pkl
2024-06-03 04:36:33 [INFO]: Round0 - StemGNN on PeMS: MAE=0.4373, MSE=0.8373, MRE=0.5426
2024-06-03 04:36:33 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:36:33 [INFO]: Using the given device: cuda:0
2024-06-03 04:36:33 [INFO]: Model files will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_1/20240603_T043633
2024-06-03 04:36:33 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_1/20240603_T043633/tensorboard
2024-06-03 04:36:33 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 04:36:37 [INFO]: Epoch 001 - training loss: 1.2501, validation loss: 0.9856
2024-06-03 04:36:41 [INFO]: Epoch 002 - training loss: 0.9054, validation loss: 0.9198
2024-06-03 04:36:44 [INFO]: Epoch 003 - training loss: 0.8146, validation loss: 0.8349
2024-06-03 04:36:48 [INFO]: Epoch 004 - training loss: 0.7199, validation loss: 0.7570
2024-06-03 04:36:52 [INFO]: Epoch 005 - training loss: 0.6390, validation loss: 0.7378
2024-06-03 04:36:56 [INFO]: Epoch 006 - training loss: 0.5944, validation loss: 0.7097
2024-06-03 04:37:00 [INFO]: Epoch 007 - training loss: 0.5757, validation loss: 0.6734
2024-06-03 04:37:04 [INFO]: Epoch 008 - training loss: 0.5593, validation loss: 0.6352
2024-06-03 04:37:08 [INFO]: Epoch 009 - training loss: 0.5373, validation loss: 0.6392
2024-06-03 04:37:12 [INFO]: Epoch 010 - training loss: 0.5213, validation loss: 0.6091
2024-06-03 04:37:17 [INFO]: Epoch 011 - training loss: 0.5149, validation loss: 0.6169
2024-06-03 04:37:20 [INFO]: Epoch 012 - training loss: 0.4993, validation loss: 0.6149
2024-06-03 04:37:24 [INFO]: Epoch 013 - training loss: 0.4859, validation loss: 0.6025
2024-06-03 04:37:28 [INFO]: Epoch 014 - training loss: 0.4815, validation loss: 0.6033
2024-06-03 04:37:32 [INFO]: Epoch 015 - training loss: 0.4669, validation loss: 0.6029
2024-06-03 04:37:36 [INFO]: Epoch 016 - training loss: 0.4645, validation loss: 0.5903
2024-06-03 04:37:40 [INFO]: Epoch 017 - training loss: 0.4498, validation loss: 0.5819
2024-06-03 04:37:44 [INFO]: Epoch 018 - training loss: 0.4446, validation loss: 0.5777
2024-06-03 04:37:48 [INFO]: Epoch 019 - training loss: 0.4340, validation loss: 0.5815
2024-06-03 04:37:52 [INFO]: Epoch 020 - training loss: 0.4351, validation loss: 0.5721
2024-06-03 04:37:56 [INFO]: Epoch 021 - training loss: 0.4317, validation loss: 0.5647
2024-06-03 04:38:00 [INFO]: Epoch 022 - training loss: 0.4262, validation loss: 0.5816
2024-06-03 04:38:05 [INFO]: Epoch 023 - training loss: 0.4189, validation loss: 0.5695
2024-06-03 04:38:08 [INFO]: Epoch 024 - training loss: 0.4102, validation loss: 0.5685
2024-06-03 04:38:12 [INFO]: Epoch 025 - training loss: 0.4079, validation loss: 0.5664
2024-06-03 04:38:16 [INFO]: Epoch 026 - training loss: 0.4061, validation loss: 0.5587
2024-06-03 04:38:20 [INFO]: Epoch 027 - training loss: 0.3937, validation loss: 0.5646
2024-06-03 04:38:24 [INFO]: Epoch 028 - training loss: 0.3935, validation loss: 0.5618
2024-06-03 04:38:28 [INFO]: Epoch 029 - training loss: 0.3848, validation loss: 0.5577
2024-06-03 04:38:32 [INFO]: Epoch 030 - training loss: 0.3825, validation loss: 0.5579
2024-06-03 04:38:36 [INFO]: Epoch 031 - training loss: 0.3817, validation loss: 0.5526
2024-06-03 04:38:40 [INFO]: Epoch 032 - training loss: 0.3791, validation loss: 0.5683
2024-06-03 04:38:44 [INFO]: Epoch 033 - training loss: 0.3745, validation loss: 0.5564
2024-06-03 04:38:48 [INFO]: Epoch 034 - training loss: 0.3706, validation loss: 0.5561
2024-06-03 04:38:53 [INFO]: Epoch 035 - training loss: 0.3705, validation loss: 0.5547
2024-06-03 04:38:57 [INFO]: Epoch 036 - training loss: 0.3678, validation loss: 0.5578
2024-06-03 04:39:01 [INFO]: Epoch 037 - training loss: 0.3622, validation loss: 0.5507
2024-06-03 04:39:05 [INFO]: Epoch 038 - training loss: 0.3577, validation loss: 0.5498
2024-06-03 04:39:09 [INFO]: Epoch 039 - training loss: 0.3569, validation loss: 0.5578
2024-06-03 04:39:13 [INFO]: Epoch 040 - training loss: 0.3527, validation loss: 0.5489
2024-06-03 04:39:17 [INFO]: Epoch 041 - training loss: 0.3508, validation loss: 0.5513
2024-06-03 04:39:21 [INFO]: Epoch 042 - training loss: 0.3441, validation loss: 0.5504
2024-06-03 04:39:25 [INFO]: Epoch 043 - training loss: 0.3474, validation loss: 0.5441
2024-06-03 04:39:29 [INFO]: Epoch 044 - training loss: 0.3454, validation loss: 0.5453
2024-06-03 04:39:33 [INFO]: Epoch 045 - training loss: 0.3410, validation loss: 0.5495
2024-06-03 04:39:37 [INFO]: Epoch 046 - training loss: 0.3405, validation loss: 0.5423
2024-06-03 04:39:40 [INFO]: Epoch 047 - training loss: 0.3377, validation loss: 0.5477
2024-06-03 04:39:44 [INFO]: Epoch 048 - training loss: 0.3427, validation loss: 0.5530
2024-06-03 04:39:47 [INFO]: Epoch 049 - training loss: 0.3385, validation loss: 0.5573
2024-06-03 04:39:51 [INFO]: Epoch 050 - training loss: 0.3355, validation loss: 0.5472
2024-06-03 04:39:54 [INFO]: Epoch 051 - training loss: 0.3301, validation loss: 0.5442
2024-06-03 04:39:57 [INFO]: Epoch 052 - training loss: 0.3303, validation loss: 0.5415
2024-06-03 04:40:01 [INFO]: Epoch 053 - training loss: 0.3270, validation loss: 0.5430
2024-06-03 04:40:04 [INFO]: Epoch 054 - training loss: 0.3282, validation loss: 0.5409
2024-06-03 04:40:08 [INFO]: Epoch 055 - training loss: 0.3260, validation loss: 0.5450
2024-06-03 04:40:11 [INFO]: Epoch 056 - training loss: 0.3205, validation loss: 0.5443
2024-06-03 04:40:14 [INFO]: Epoch 057 - training loss: 0.3183, validation loss: 0.5448
2024-06-03 04:40:18 [INFO]: Epoch 058 - training loss: 0.3223, validation loss: 0.5465
2024-06-03 04:40:21 [INFO]: Epoch 059 - training loss: 0.3209, validation loss: 0.5469
2024-06-03 04:40:24 [INFO]: Epoch 060 - training loss: 0.3193, validation loss: 0.5501
2024-06-03 04:40:28 [INFO]: Epoch 061 - training loss: 0.3199, validation loss: 0.5472
2024-06-03 04:40:31 [INFO]: Epoch 062 - training loss: 0.3174, validation loss: 0.5433
2024-06-03 04:40:35 [INFO]: Epoch 063 - training loss: 0.3158, validation loss: 0.5470
2024-06-03 04:40:38 [INFO]: Epoch 064 - training loss: 0.3095, validation loss: 0.5491
2024-06-03 04:40:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:40:38 [INFO]: Finished training. The best model is from epoch#54.
2024-06-03 04:40:38 [INFO]: Saved the model to results_point_rate09/PeMS/StemGNN_PeMS/round_1/20240603_T043633/StemGNN.pypots
2024-06-03 04:40:40 [INFO]: Successfully saved to results_point_rate09/PeMS/StemGNN_PeMS/round_1/imputation.pkl
2024-06-03 04:40:40 [INFO]: Round1 - StemGNN on PeMS: MAE=0.4249, MSE=0.8206, MRE=0.5272
2024-06-03 04:40:40 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:40:40 [INFO]: Using the given device: cuda:0
2024-06-03 04:40:40 [INFO]: Model files will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_2/20240603_T044040
2024-06-03 04:40:40 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_2/20240603_T044040/tensorboard
2024-06-03 04:40:40 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 04:40:43 [INFO]: Epoch 001 - training loss: 1.2800, validation loss: 0.9519
2024-06-03 04:40:47 [INFO]: Epoch 002 - training loss: 0.9273, validation loss: 0.9448
2024-06-03 04:40:50 [INFO]: Epoch 003 - training loss: 0.8453, validation loss: 0.8704
2024-06-03 04:40:54 [INFO]: Epoch 004 - training loss: 0.7481, validation loss: 0.8236
2024-06-03 04:40:57 [INFO]: Epoch 005 - training loss: 0.6663, validation loss: 0.7656
2024-06-03 04:41:01 [INFO]: Epoch 006 - training loss: 0.6336, validation loss: 0.7483
2024-06-03 04:41:04 [INFO]: Epoch 007 - training loss: 0.6063, validation loss: 0.7213
2024-06-03 04:41:07 [INFO]: Epoch 008 - training loss: 0.5854, validation loss: 0.6785
2024-06-03 04:41:11 [INFO]: Epoch 009 - training loss: 0.5647, validation loss: 0.6566
2024-06-03 04:41:14 [INFO]: Epoch 010 - training loss: 0.5436, validation loss: 0.6418
2024-06-03 04:41:17 [INFO]: Epoch 011 - training loss: 0.5358, validation loss: 0.6328
2024-06-03 04:41:20 [INFO]: Epoch 012 - training loss: 0.5189, validation loss: 0.6194
2024-06-03 04:41:24 [INFO]: Epoch 013 - training loss: 0.5106, validation loss: 0.6168
2024-06-03 04:41:27 [INFO]: Epoch 014 - training loss: 0.5009, validation loss: 0.6205
2024-06-03 04:41:30 [INFO]: Epoch 015 - training loss: 0.5019, validation loss: 0.6212
2024-06-03 04:41:33 [INFO]: Epoch 016 - training loss: 0.4926, validation loss: 0.6273
2024-06-03 04:41:36 [INFO]: Epoch 017 - training loss: 0.4851, validation loss: 0.6315
2024-06-03 04:41:39 [INFO]: Epoch 018 - training loss: 0.4779, validation loss: 0.6244
2024-06-03 04:41:42 [INFO]: Epoch 019 - training loss: 0.4788, validation loss: 0.6272
2024-06-03 04:41:46 [INFO]: Epoch 020 - training loss: 0.4734, validation loss: 0.6237
2024-06-03 04:41:48 [INFO]: Epoch 021 - training loss: 0.4682, validation loss: 0.6255
2024-06-03 04:41:51 [INFO]: Epoch 022 - training loss: 0.4665, validation loss: 0.6133
2024-06-03 04:41:54 [INFO]: Epoch 023 - training loss: 0.4578, validation loss: 0.6112
2024-06-03 04:41:56 [INFO]: Epoch 024 - training loss: 0.4517, validation loss: 0.6094
2024-06-03 04:41:59 [INFO]: Epoch 025 - training loss: 0.4492, validation loss: 0.6144
2024-06-03 04:42:02 [INFO]: Epoch 026 - training loss: 0.4413, validation loss: 0.6109
2024-06-03 04:42:05 [INFO]: Epoch 027 - training loss: 0.4437, validation loss: 0.6067
2024-06-03 04:42:07 [INFO]: Epoch 028 - training loss: 0.4370, validation loss: 0.6074
2024-06-03 04:42:10 [INFO]: Epoch 029 - training loss: 0.4336, validation loss: 0.6040
2024-06-03 04:42:13 [INFO]: Epoch 030 - training loss: 0.4267, validation loss: 0.6052
2024-06-03 04:42:15 [INFO]: Epoch 031 - training loss: 0.4233, validation loss: 0.5968
2024-06-03 04:42:18 [INFO]: Epoch 032 - training loss: 0.4202, validation loss: 0.5958
2024-06-03 04:42:21 [INFO]: Epoch 033 - training loss: 0.4160, validation loss: 0.5940
2024-06-03 04:42:23 [INFO]: Epoch 034 - training loss: 0.4114, validation loss: 0.5981
2024-06-03 04:42:26 [INFO]: Epoch 035 - training loss: 0.4109, validation loss: 0.5976
2024-06-03 04:42:28 [INFO]: Epoch 036 - training loss: 0.4072, validation loss: 0.5975
2024-06-03 04:42:31 [INFO]: Epoch 037 - training loss: 0.4047, validation loss: 0.6020
2024-06-03 04:42:34 [INFO]: Epoch 038 - training loss: 0.4009, validation loss: 0.6032
2024-06-03 04:42:37 [INFO]: Epoch 039 - training loss: 0.4007, validation loss: 0.6000
2024-06-03 04:42:39 [INFO]: Epoch 040 - training loss: 0.3964, validation loss: 0.5964
2024-06-03 04:42:42 [INFO]: Epoch 041 - training loss: 0.3873, validation loss: 0.5901
2024-06-03 04:42:43 [INFO]: Epoch 042 - training loss: 0.3873, validation loss: 0.5988
2024-06-03 04:42:45 [INFO]: Epoch 043 - training loss: 0.3794, validation loss: 0.5888
2024-06-03 04:42:47 [INFO]: Epoch 044 - training loss: 0.3773, validation loss: 0.5929
2024-06-03 04:42:48 [INFO]: Epoch 045 - training loss: 0.3809, validation loss: 0.5975
2024-06-03 04:42:50 [INFO]: Epoch 046 - training loss: 0.3786, validation loss: 0.5922
2024-06-03 04:42:51 [INFO]: Epoch 047 - training loss: 0.3722, validation loss: 0.5869
2024-06-03 04:42:53 [INFO]: Epoch 048 - training loss: 0.3687, validation loss: 0.5929
2024-06-03 04:42:54 [INFO]: Epoch 049 - training loss: 0.3661, validation loss: 0.5914
2024-06-03 04:42:56 [INFO]: Epoch 050 - training loss: 0.3671, validation loss: 0.5881
2024-06-03 04:42:57 [INFO]: Epoch 051 - training loss: 0.3636, validation loss: 0.5956
2024-06-03 04:42:59 [INFO]: Epoch 052 - training loss: 0.3620, validation loss: 0.6038
2024-06-03 04:43:01 [INFO]: Epoch 053 - training loss: 0.3611, validation loss: 0.6071
2024-06-03 04:43:03 [INFO]: Epoch 054 - training loss: 0.3564, validation loss: 0.5959
2024-06-03 04:43:05 [INFO]: Epoch 055 - training loss: 0.3545, validation loss: 0.5859
2024-06-03 04:43:06 [INFO]: Epoch 056 - training loss: 0.3538, validation loss: 0.5884
2024-06-03 04:43:08 [INFO]: Epoch 057 - training loss: 0.3474, validation loss: 0.5925
2024-06-03 04:43:09 [INFO]: Epoch 058 - training loss: 0.3461, validation loss: 0.5912
2024-06-03 04:43:11 [INFO]: Epoch 059 - training loss: 0.3500, validation loss: 0.5853
2024-06-03 04:43:12 [INFO]: Epoch 060 - training loss: 0.3477, validation loss: 0.5949
2024-06-03 04:43:14 [INFO]: Epoch 061 - training loss: 0.3423, validation loss: 0.5964
2024-06-03 04:43:15 [INFO]: Epoch 062 - training loss: 0.3442, validation loss: 0.5898
2024-06-03 04:43:17 [INFO]: Epoch 063 - training loss: 0.3384, validation loss: 0.5882
2024-06-03 04:43:19 [INFO]: Epoch 064 - training loss: 0.3381, validation loss: 0.5880
2024-06-03 04:43:20 [INFO]: Epoch 065 - training loss: 0.3334, validation loss: 0.5953
2024-06-03 04:43:22 [INFO]: Epoch 066 - training loss: 0.3360, validation loss: 0.5819
2024-06-03 04:43:24 [INFO]: Epoch 067 - training loss: 0.3372, validation loss: 0.5883
2024-06-03 04:43:26 [INFO]: Epoch 068 - training loss: 0.3315, validation loss: 0.5924
2024-06-03 04:43:29 [INFO]: Epoch 069 - training loss: 0.3302, validation loss: 0.5978
2024-06-03 04:43:31 [INFO]: Epoch 070 - training loss: 0.3267, validation loss: 0.5841
2024-06-03 04:43:33 [INFO]: Epoch 071 - training loss: 0.3236, validation loss: 0.5865
2024-06-03 04:43:35 [INFO]: Epoch 072 - training loss: 0.3291, validation loss: 0.5897
2024-06-03 04:43:38 [INFO]: Epoch 073 - training loss: 0.3208, validation loss: 0.5934
2024-06-03 04:43:40 [INFO]: Epoch 074 - training loss: 0.3222, validation loss: 0.5904
2024-06-03 04:43:43 [INFO]: Epoch 075 - training loss: 0.3165, validation loss: 0.5829
2024-06-03 04:43:45 [INFO]: Epoch 076 - training loss: 0.3155, validation loss: 0.5887
2024-06-03 04:43:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:43:45 [INFO]: Finished training. The best model is from epoch#66.
2024-06-03 04:43:45 [INFO]: Saved the model to results_point_rate09/PeMS/StemGNN_PeMS/round_2/20240603_T044040/StemGNN.pypots
2024-06-03 04:43:46 [INFO]: Successfully saved to results_point_rate09/PeMS/StemGNN_PeMS/round_2/imputation.pkl
2024-06-03 04:43:46 [INFO]: Round2 - StemGNN on PeMS: MAE=0.4367, MSE=0.8451, MRE=0.5419
2024-06-03 04:43:46 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:43:46 [INFO]: Using the given device: cuda:0
2024-06-03 04:43:46 [INFO]: Model files will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_3/20240603_T044346
2024-06-03 04:43:46 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_3/20240603_T044346/tensorboard
2024-06-03 04:43:46 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 04:43:49 [INFO]: Epoch 001 - training loss: 1.3072, validation loss: 0.9922
2024-06-03 04:43:51 [INFO]: Epoch 002 - training loss: 0.9544, validation loss: 0.9097
2024-06-03 04:43:54 [INFO]: Epoch 003 - training loss: 0.8290, validation loss: 0.8506
2024-06-03 04:43:56 [INFO]: Epoch 004 - training loss: 0.7532, validation loss: 0.8010
2024-06-03 04:43:58 [INFO]: Epoch 005 - training loss: 0.6842, validation loss: 0.7434
2024-06-03 04:44:01 [INFO]: Epoch 006 - training loss: 0.6162, validation loss: 0.7183
2024-06-03 04:44:03 [INFO]: Epoch 007 - training loss: 0.5752, validation loss: 0.6879
2024-06-03 04:44:05 [INFO]: Epoch 008 - training loss: 0.5485, validation loss: 0.6638
2024-06-03 04:44:08 [INFO]: Epoch 009 - training loss: 0.5347, validation loss: 0.6385
2024-06-03 04:44:10 [INFO]: Epoch 010 - training loss: 0.5170, validation loss: 0.6396
2024-06-03 04:44:12 [INFO]: Epoch 011 - training loss: 0.5098, validation loss: 0.6312
2024-06-03 04:44:15 [INFO]: Epoch 012 - training loss: 0.5051, validation loss: 0.6073
2024-06-03 04:44:17 [INFO]: Epoch 013 - training loss: 0.4921, validation loss: 0.6179
2024-06-03 04:44:19 [INFO]: Epoch 014 - training loss: 0.4854, validation loss: 0.6019
2024-06-03 04:44:22 [INFO]: Epoch 015 - training loss: 0.4734, validation loss: 0.6009
2024-06-03 04:44:24 [INFO]: Epoch 016 - training loss: 0.4736, validation loss: 0.6091
2024-06-03 04:44:27 [INFO]: Epoch 017 - training loss: 0.4624, validation loss: 0.5944
2024-06-03 04:44:29 [INFO]: Epoch 018 - training loss: 0.4509, validation loss: 0.5931
2024-06-03 04:44:31 [INFO]: Epoch 019 - training loss: 0.4451, validation loss: 0.5835
2024-06-03 04:44:34 [INFO]: Epoch 020 - training loss: 0.4410, validation loss: 0.5835
2024-06-03 04:44:36 [INFO]: Epoch 021 - training loss: 0.4396, validation loss: 0.5844
2024-06-03 04:44:39 [INFO]: Epoch 022 - training loss: 0.4317, validation loss: 0.5843
2024-06-03 04:44:41 [INFO]: Epoch 023 - training loss: 0.4239, validation loss: 0.5817
2024-06-03 04:44:43 [INFO]: Epoch 024 - training loss: 0.4200, validation loss: 0.5888
2024-06-03 04:44:45 [INFO]: Epoch 025 - training loss: 0.4142, validation loss: 0.5792
2024-06-03 04:44:48 [INFO]: Epoch 026 - training loss: 0.4059, validation loss: 0.5767
2024-06-03 04:44:50 [INFO]: Epoch 027 - training loss: 0.4031, validation loss: 0.5731
2024-06-03 04:44:52 [INFO]: Epoch 028 - training loss: 0.4048, validation loss: 0.5817
2024-06-03 04:44:55 [INFO]: Epoch 029 - training loss: 0.4067, validation loss: 0.5834
2024-06-03 04:44:57 [INFO]: Epoch 030 - training loss: 0.3950, validation loss: 0.5767
2024-06-03 04:45:00 [INFO]: Epoch 031 - training loss: 0.3880, validation loss: 0.5779
2024-06-03 04:45:02 [INFO]: Epoch 032 - training loss: 0.3842, validation loss: 0.5745
2024-06-03 04:45:04 [INFO]: Epoch 033 - training loss: 0.3793, validation loss: 0.5848
2024-06-03 04:45:07 [INFO]: Epoch 034 - training loss: 0.3772, validation loss: 0.5756
2024-06-03 04:45:09 [INFO]: Epoch 035 - training loss: 0.3754, validation loss: 0.5737
2024-06-03 04:45:12 [INFO]: Epoch 036 - training loss: 0.3731, validation loss: 0.5722
2024-06-03 04:45:14 [INFO]: Epoch 037 - training loss: 0.3680, validation loss: 0.5773
2024-06-03 04:45:16 [INFO]: Epoch 038 - training loss: 0.3641, validation loss: 0.5747
2024-06-03 04:45:18 [INFO]: Epoch 039 - training loss: 0.3608, validation loss: 0.5702
2024-06-03 04:45:21 [INFO]: Epoch 040 - training loss: 0.3663, validation loss: 0.5699
2024-06-03 04:45:23 [INFO]: Epoch 041 - training loss: 0.3605, validation loss: 0.5700
2024-06-03 04:45:25 [INFO]: Epoch 042 - training loss: 0.3552, validation loss: 0.5772
2024-06-03 04:45:28 [INFO]: Epoch 043 - training loss: 0.3494, validation loss: 0.5646
2024-06-03 04:45:30 [INFO]: Epoch 044 - training loss: 0.3511, validation loss: 0.5738
2024-06-03 04:45:33 [INFO]: Epoch 045 - training loss: 0.3452, validation loss: 0.5768
2024-06-03 04:45:35 [INFO]: Epoch 046 - training loss: 0.3481, validation loss: 0.5690
2024-06-03 04:45:37 [INFO]: Epoch 047 - training loss: 0.3437, validation loss: 0.5692
2024-06-03 04:45:40 [INFO]: Epoch 048 - training loss: 0.3436, validation loss: 0.5684
2024-06-03 04:45:42 [INFO]: Epoch 049 - training loss: 0.3372, validation loss: 0.5684
2024-06-03 04:45:45 [INFO]: Epoch 050 - training loss: 0.3338, validation loss: 0.5841
2024-06-03 04:45:47 [INFO]: Epoch 051 - training loss: 0.3370, validation loss: 0.5728
2024-06-03 04:45:49 [INFO]: Epoch 052 - training loss: 0.3343, validation loss: 0.5674
2024-06-03 04:45:52 [INFO]: Epoch 053 - training loss: 0.3274, validation loss: 0.5726
2024-06-03 04:45:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:45:52 [INFO]: Finished training. The best model is from epoch#43.
2024-06-03 04:45:52 [INFO]: Saved the model to results_point_rate09/PeMS/StemGNN_PeMS/round_3/20240603_T044346/StemGNN.pypots
2024-06-03 04:45:53 [INFO]: Successfully saved to results_point_rate09/PeMS/StemGNN_PeMS/round_3/imputation.pkl
2024-06-03 04:45:53 [INFO]: Round3 - StemGNN on PeMS: MAE=0.4319, MSE=0.8499, MRE=0.5359
2024-06-03 04:45:53 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:45:53 [INFO]: Using the given device: cuda:0
2024-06-03 04:45:53 [INFO]: Model files will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_4/20240603_T044553
2024-06-03 04:45:53 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/StemGNN_PeMS/round_4/20240603_T044553/tensorboard
2024-06-03 04:45:53 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 04:45:55 [INFO]: Epoch 001 - training loss: 1.1839, validation loss: 0.9780
2024-06-03 04:45:58 [INFO]: Epoch 002 - training loss: 0.9080, validation loss: 0.8744
2024-06-03 04:46:00 [INFO]: Epoch 003 - training loss: 0.7913, validation loss: 0.8472
2024-06-03 04:46:02 [INFO]: Epoch 004 - training loss: 0.7030, validation loss: 0.7799
2024-06-03 04:46:03 [INFO]: Epoch 005 - training loss: 0.6291, validation loss: 0.7223
2024-06-03 04:46:05 [INFO]: Epoch 006 - training loss: 0.5902, validation loss: 0.6923
2024-06-03 04:46:07 [INFO]: Epoch 007 - training loss: 0.5717, validation loss: 0.6738
2024-06-03 04:46:09 [INFO]: Epoch 008 - training loss: 0.5510, validation loss: 0.6677
2024-06-03 04:46:11 [INFO]: Epoch 009 - training loss: 0.5354, validation loss: 0.6142
2024-06-03 04:46:13 [INFO]: Epoch 010 - training loss: 0.5268, validation loss: 0.6108
2024-06-03 04:46:15 [INFO]: Epoch 011 - training loss: 0.5108, validation loss: 0.5954
2024-06-03 04:46:17 [INFO]: Epoch 012 - training loss: 0.4993, validation loss: 0.6044
2024-06-03 04:46:19 [INFO]: Epoch 013 - training loss: 0.4840, validation loss: 0.5804
2024-06-03 04:46:21 [INFO]: Epoch 014 - training loss: 0.4723, validation loss: 0.5852
2024-06-03 04:46:23 [INFO]: Epoch 015 - training loss: 0.4595, validation loss: 0.5731
2024-06-03 04:46:24 [INFO]: Epoch 016 - training loss: 0.4533, validation loss: 0.5649
2024-06-03 04:46:26 [INFO]: Epoch 017 - training loss: 0.4413, validation loss: 0.5633
2024-06-03 04:46:28 [INFO]: Epoch 018 - training loss: 0.4344, validation loss: 0.5577
2024-06-03 04:46:30 [INFO]: Epoch 019 - training loss: 0.4316, validation loss: 0.5642
2024-06-03 04:46:32 [INFO]: Epoch 020 - training loss: 0.4293, validation loss: 0.5501
2024-06-03 04:46:34 [INFO]: Epoch 021 - training loss: 0.4237, validation loss: 0.5498
2024-06-03 04:46:36 [INFO]: Epoch 022 - training loss: 0.4172, validation loss: 0.5552
2024-06-03 04:46:38 [INFO]: Epoch 023 - training loss: 0.4090, validation loss: 0.5574
2024-06-03 04:46:40 [INFO]: Epoch 024 - training loss: 0.4015, validation loss: 0.5458
2024-06-03 04:46:42 [INFO]: Epoch 025 - training loss: 0.3919, validation loss: 0.5467
2024-06-03 04:46:44 [INFO]: Epoch 026 - training loss: 0.3919, validation loss: 0.5484
2024-06-03 04:46:45 [INFO]: Epoch 027 - training loss: 0.3835, validation loss: 0.5380
2024-06-03 04:46:47 [INFO]: Epoch 028 - training loss: 0.3810, validation loss: 0.5428
2024-06-03 04:46:49 [INFO]: Epoch 029 - training loss: 0.3759, validation loss: 0.5529
2024-06-03 04:46:51 [INFO]: Epoch 030 - training loss: 0.3740, validation loss: 0.5397
2024-06-03 04:46:53 [INFO]: Epoch 031 - training loss: 0.3677, validation loss: 0.5316
2024-06-03 04:46:55 [INFO]: Epoch 032 - training loss: 0.3630, validation loss: 0.5325
2024-06-03 04:46:57 [INFO]: Epoch 033 - training loss: 0.3629, validation loss: 0.5337
2024-06-03 04:46:59 [INFO]: Epoch 034 - training loss: 0.3614, validation loss: 0.5337
2024-06-03 04:47:01 [INFO]: Epoch 035 - training loss: 0.3559, validation loss: 0.5394
2024-06-03 04:47:02 [INFO]: Epoch 036 - training loss: 0.3557, validation loss: 0.5386
2024-06-03 04:47:04 [INFO]: Epoch 037 - training loss: 0.3485, validation loss: 0.5475
2024-06-03 04:47:06 [INFO]: Epoch 038 - training loss: 0.3460, validation loss: 0.5429
2024-06-03 04:47:08 [INFO]: Epoch 039 - training loss: 0.3466, validation loss: 0.5397
2024-06-03 04:47:10 [INFO]: Epoch 040 - training loss: 0.3425, validation loss: 0.5298
2024-06-03 04:47:12 [INFO]: Epoch 041 - training loss: 0.3366, validation loss: 0.5365
2024-06-03 04:47:14 [INFO]: Epoch 042 - training loss: 0.3362, validation loss: 0.5383
2024-06-03 04:47:15 [INFO]: Epoch 043 - training loss: 0.3303, validation loss: 0.5352
2024-06-03 04:47:17 [INFO]: Epoch 044 - training loss: 0.3277, validation loss: 0.5308
2024-06-03 04:47:19 [INFO]: Epoch 045 - training loss: 0.3291, validation loss: 0.5233
2024-06-03 04:47:21 [INFO]: Epoch 046 - training loss: 0.3293, validation loss: 0.5523
2024-06-03 04:47:23 [INFO]: Epoch 047 - training loss: 0.3251, validation loss: 0.5323
2024-06-03 04:47:25 [INFO]: Epoch 048 - training loss: 0.3247, validation loss: 0.5378
2024-06-03 04:47:27 [INFO]: Epoch 049 - training loss: 0.3199, validation loss: 0.5329
2024-06-03 04:47:28 [INFO]: Epoch 050 - training loss: 0.3172, validation loss: 0.5371
2024-06-03 04:47:30 [INFO]: Epoch 051 - training loss: 0.3117, validation loss: 0.5323
2024-06-03 04:47:32 [INFO]: Epoch 052 - training loss: 0.3140, validation loss: 0.5365
2024-06-03 04:47:34 [INFO]: Epoch 053 - training loss: 0.3136, validation loss: 0.5456
2024-06-03 04:47:36 [INFO]: Epoch 054 - training loss: 0.3125, validation loss: 0.5402
2024-06-03 04:47:38 [INFO]: Epoch 055 - training loss: 0.3085, validation loss: 0.5360
2024-06-03 04:47:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:47:38 [INFO]: Finished training. The best model is from epoch#45.
2024-06-03 04:47:38 [INFO]: Saved the model to results_point_rate09/PeMS/StemGNN_PeMS/round_4/20240603_T044553/StemGNN.pypots
2024-06-03 04:47:39 [INFO]: Successfully saved to results_point_rate09/PeMS/StemGNN_PeMS/round_4/imputation.pkl
2024-06-03 04:47:39 [INFO]: Round4 - StemGNN on PeMS: MAE=0.4202, MSE=0.8104, MRE=0.5214
2024-06-03 04:47:39 [INFO]: Done! Final results:
Averaged StemGNN (2,386,294 params) on PeMS: MAE=0.4302 ± 0.006698218859597307, MSE=0.8327 ± 0.01493303354206495, MRE=0.5338 ± 0.008311356928921947, average inference time=0.23
