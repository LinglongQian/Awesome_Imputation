2024-06-03 00:06:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:06:45 [INFO]: Using the given device: cuda:0
2024-06-03 00:06:45 [INFO]: Model files will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_0/20240603_T000645
2024-06-03 00:06:45 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_0/20240603_T000645/tensorboard
2024-06-03 00:06:46 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 00:06:52 [INFO]: Epoch 001 - training loss: 1.1882, validation loss: 0.8936
2024-06-03 00:06:56 [INFO]: Epoch 002 - training loss: 0.7741, validation loss: 0.7562
2024-06-03 00:07:01 [INFO]: Epoch 003 - training loss: 0.6529, validation loss: 0.6701
2024-06-03 00:07:07 [INFO]: Epoch 004 - training loss: 0.5793, validation loss: 0.6047
2024-06-03 00:07:12 [INFO]: Epoch 005 - training loss: 0.5412, validation loss: 0.5887
2024-06-03 00:07:17 [INFO]: Epoch 006 - training loss: 0.5152, validation loss: 0.5842
2024-06-03 00:07:22 [INFO]: Epoch 007 - training loss: 0.5009, validation loss: 0.5663
2024-06-03 00:07:27 [INFO]: Epoch 008 - training loss: 0.4923, validation loss: 0.5458
2024-06-03 00:07:32 [INFO]: Epoch 009 - training loss: 0.4728, validation loss: 0.5432
2024-06-03 00:07:38 [INFO]: Epoch 010 - training loss: 0.4578, validation loss: 0.5340
2024-06-03 00:07:43 [INFO]: Epoch 011 - training loss: 0.4490, validation loss: 0.5310
2024-06-03 00:07:48 [INFO]: Epoch 012 - training loss: 0.4422, validation loss: 0.5305
2024-06-03 00:07:52 [INFO]: Epoch 013 - training loss: 0.4364, validation loss: 0.5314
2024-06-03 00:07:57 [INFO]: Epoch 014 - training loss: 0.4205, validation loss: 0.5174
2024-06-03 00:08:02 [INFO]: Epoch 015 - training loss: 0.4127, validation loss: 0.5181
2024-06-03 00:08:07 [INFO]: Epoch 016 - training loss: 0.4095, validation loss: 0.5212
2024-06-03 00:08:13 [INFO]: Epoch 017 - training loss: 0.4062, validation loss: 0.5197
2024-06-03 00:08:18 [INFO]: Epoch 018 - training loss: 0.4004, validation loss: 0.5165
2024-06-03 00:08:23 [INFO]: Epoch 019 - training loss: 0.3931, validation loss: 0.5247
2024-06-03 00:08:28 [INFO]: Epoch 020 - training loss: 0.3848, validation loss: 0.5183
2024-06-03 00:08:33 [INFO]: Epoch 021 - training loss: 0.3800, validation loss: 0.5137
2024-06-03 00:08:38 [INFO]: Epoch 022 - training loss: 0.3746, validation loss: 0.5199
2024-06-03 00:08:43 [INFO]: Epoch 023 - training loss: 0.3786, validation loss: 0.5114
2024-06-03 00:08:48 [INFO]: Epoch 024 - training loss: 0.3681, validation loss: 0.5097
2024-06-03 00:08:53 [INFO]: Epoch 025 - training loss: 0.3594, validation loss: 0.5166
2024-06-03 00:08:58 [INFO]: Epoch 026 - training loss: 0.3556, validation loss: 0.5099
2024-06-03 00:09:03 [INFO]: Epoch 027 - training loss: 0.3542, validation loss: 0.5181
2024-06-03 00:09:08 [INFO]: Epoch 028 - training loss: 0.3532, validation loss: 0.5126
2024-06-03 00:09:14 [INFO]: Epoch 029 - training loss: 0.3469, validation loss: 0.5162
2024-06-03 00:09:19 [INFO]: Epoch 030 - training loss: 0.3401, validation loss: 0.5110
2024-06-03 00:09:24 [INFO]: Epoch 031 - training loss: 0.3430, validation loss: 0.5261
2024-06-03 00:09:29 [INFO]: Epoch 032 - training loss: 0.3439, validation loss: 0.5166
2024-06-03 00:09:34 [INFO]: Epoch 033 - training loss: 0.3317, validation loss: 0.5103
2024-06-03 00:09:39 [INFO]: Epoch 034 - training loss: 0.3333, validation loss: 0.5179
2024-06-03 00:09:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:09:39 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 00:09:39 [INFO]: Saved the model to results_point_rate09/PeMS/Crossformer_PeMS/round_0/20240603_T000645/Crossformer.pypots
2024-06-03 00:09:41 [INFO]: Successfully saved to results_point_rate09/PeMS/Crossformer_PeMS/round_0/imputation.pkl
2024-06-03 00:09:41 [INFO]: Round0 - Crossformer on PeMS: MAE=0.3953, MSE=0.7394, MRE=0.4905
2024-06-03 00:09:41 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:09:41 [INFO]: Using the given device: cuda:0
2024-06-03 00:09:41 [INFO]: Model files will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_1/20240603_T000941
2024-06-03 00:09:41 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_1/20240603_T000941/tensorboard
2024-06-03 00:09:42 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 00:09:47 [INFO]: Epoch 001 - training loss: 1.2194, validation loss: 0.9320
2024-06-03 00:09:52 [INFO]: Epoch 002 - training loss: 0.8575, validation loss: 0.7909
2024-06-03 00:09:58 [INFO]: Epoch 003 - training loss: 0.6989, validation loss: 0.7538
2024-06-03 00:10:03 [INFO]: Epoch 004 - training loss: 0.6163, validation loss: 0.6520
2024-06-03 00:10:08 [INFO]: Epoch 005 - training loss: 0.5774, validation loss: 0.6339
2024-06-03 00:10:14 [INFO]: Epoch 006 - training loss: 0.5500, validation loss: 0.6055
2024-06-03 00:10:19 [INFO]: Epoch 007 - training loss: 0.5297, validation loss: 0.6099
2024-06-03 00:10:24 [INFO]: Epoch 008 - training loss: 0.5149, validation loss: 0.5837
2024-06-03 00:10:28 [INFO]: Epoch 009 - training loss: 0.4921, validation loss: 0.5701
2024-06-03 00:10:33 [INFO]: Epoch 010 - training loss: 0.4777, validation loss: 0.5450
2024-06-03 00:10:39 [INFO]: Epoch 011 - training loss: 0.4708, validation loss: 0.5453
2024-06-03 00:10:44 [INFO]: Epoch 012 - training loss: 0.4605, validation loss: 0.5440
2024-06-03 00:10:49 [INFO]: Epoch 013 - training loss: 0.4540, validation loss: 0.5415
2024-06-03 00:10:54 [INFO]: Epoch 014 - training loss: 0.4371, validation loss: 0.5368
2024-06-03 00:10:59 [INFO]: Epoch 015 - training loss: 0.4252, validation loss: 0.5359
2024-06-03 00:11:05 [INFO]: Epoch 016 - training loss: 0.4206, validation loss: 0.5338
2024-06-03 00:11:10 [INFO]: Epoch 017 - training loss: 0.4127, validation loss: 0.5300
2024-06-03 00:11:15 [INFO]: Epoch 018 - training loss: 0.4040, validation loss: 0.5221
2024-06-03 00:11:19 [INFO]: Epoch 019 - training loss: 0.4037, validation loss: 0.5238
2024-06-03 00:11:24 [INFO]: Epoch 020 - training loss: 0.3901, validation loss: 0.5207
2024-06-03 00:11:29 [INFO]: Epoch 021 - training loss: 0.3832, validation loss: 0.5173
2024-06-03 00:11:34 [INFO]: Epoch 022 - training loss: 0.3803, validation loss: 0.5250
2024-06-03 00:11:39 [INFO]: Epoch 023 - training loss: 0.3861, validation loss: 0.5236
2024-06-03 00:11:43 [INFO]: Epoch 024 - training loss: 0.3810, validation loss: 0.5221
2024-06-03 00:11:48 [INFO]: Epoch 025 - training loss: 0.3706, validation loss: 0.5136
2024-06-03 00:11:53 [INFO]: Epoch 026 - training loss: 0.3686, validation loss: 0.5252
2024-06-03 00:11:57 [INFO]: Epoch 027 - training loss: 0.3680, validation loss: 0.5172
2024-06-03 00:12:02 [INFO]: Epoch 028 - training loss: 0.3576, validation loss: 0.5162
2024-06-03 00:12:07 [INFO]: Epoch 029 - training loss: 0.3601, validation loss: 0.5126
2024-06-03 00:12:11 [INFO]: Epoch 030 - training loss: 0.3551, validation loss: 0.5122
2024-06-03 00:12:16 [INFO]: Epoch 031 - training loss: 0.3461, validation loss: 0.5198
2024-06-03 00:12:20 [INFO]: Epoch 032 - training loss: 0.3455, validation loss: 0.5171
2024-06-03 00:12:25 [INFO]: Epoch 033 - training loss: 0.3398, validation loss: 0.5116
2024-06-03 00:12:30 [INFO]: Epoch 034 - training loss: 0.3345, validation loss: 0.5100
2024-06-03 00:12:35 [INFO]: Epoch 035 - training loss: 0.3344, validation loss: 0.5118
2024-06-03 00:12:40 [INFO]: Epoch 036 - training loss: 0.3318, validation loss: 0.5123
2024-06-03 00:12:45 [INFO]: Epoch 037 - training loss: 0.3269, validation loss: 0.5069
2024-06-03 00:12:49 [INFO]: Epoch 038 - training loss: 0.3284, validation loss: 0.5175
2024-06-03 00:12:54 [INFO]: Epoch 039 - training loss: 0.3382, validation loss: 0.5157
2024-06-03 00:12:58 [INFO]: Epoch 040 - training loss: 0.3299, validation loss: 0.5195
2024-06-03 00:13:03 [INFO]: Epoch 041 - training loss: 0.3354, validation loss: 0.5114
2024-06-03 00:13:08 [INFO]: Epoch 042 - training loss: 0.3319, validation loss: 0.5127
2024-06-03 00:13:12 [INFO]: Epoch 043 - training loss: 0.3231, validation loss: 0.5128
2024-06-03 00:13:17 [INFO]: Epoch 044 - training loss: 0.3190, validation loss: 0.5121
2024-06-03 00:13:21 [INFO]: Epoch 045 - training loss: 0.3125, validation loss: 0.5111
2024-06-03 00:13:26 [INFO]: Epoch 046 - training loss: 0.3091, validation loss: 0.5148
2024-06-03 00:13:30 [INFO]: Epoch 047 - training loss: 0.3048, validation loss: 0.5118
2024-06-03 00:13:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:13:30 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 00:13:30 [INFO]: Saved the model to results_point_rate09/PeMS/Crossformer_PeMS/round_1/20240603_T000941/Crossformer.pypots
2024-06-03 00:13:32 [INFO]: Successfully saved to results_point_rate09/PeMS/Crossformer_PeMS/round_1/imputation.pkl
2024-06-03 00:13:32 [INFO]: Round1 - Crossformer on PeMS: MAE=0.4093, MSE=0.7368, MRE=0.5079
2024-06-03 00:13:32 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:13:32 [INFO]: Using the given device: cuda:0
2024-06-03 00:13:32 [INFO]: Model files will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_2/20240603_T001332
2024-06-03 00:13:32 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_2/20240603_T001332/tensorboard
2024-06-03 00:13:33 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 00:13:37 [INFO]: Epoch 001 - training loss: 1.1962, validation loss: 0.9739
2024-06-03 00:13:42 [INFO]: Epoch 002 - training loss: 0.8802, validation loss: 0.9578
2024-06-03 00:13:46 [INFO]: Epoch 003 - training loss: 0.7378, validation loss: 0.8073
2024-06-03 00:13:50 [INFO]: Epoch 004 - training loss: 0.6313, validation loss: 0.6521
2024-06-03 00:13:55 [INFO]: Epoch 005 - training loss: 0.5821, validation loss: 0.6272
2024-06-03 00:13:59 [INFO]: Epoch 006 - training loss: 0.5541, validation loss: 0.5776
2024-06-03 00:14:04 [INFO]: Epoch 007 - training loss: 0.5233, validation loss: 0.5838
2024-06-03 00:14:08 [INFO]: Epoch 008 - training loss: 0.5031, validation loss: 0.5676
2024-06-03 00:14:13 [INFO]: Epoch 009 - training loss: 0.4849, validation loss: 0.5435
2024-06-03 00:14:17 [INFO]: Epoch 010 - training loss: 0.4713, validation loss: 0.5581
2024-06-03 00:14:22 [INFO]: Epoch 011 - training loss: 0.4651, validation loss: 0.5335
2024-06-03 00:14:26 [INFO]: Epoch 012 - training loss: 0.4541, validation loss: 0.5301
2024-06-03 00:14:31 [INFO]: Epoch 013 - training loss: 0.4337, validation loss: 0.5317
2024-06-03 00:14:35 [INFO]: Epoch 014 - training loss: 0.4289, validation loss: 0.5242
2024-06-03 00:14:39 [INFO]: Epoch 015 - training loss: 0.4329, validation loss: 0.5206
2024-06-03 00:14:44 [INFO]: Epoch 016 - training loss: 0.4147, validation loss: 0.5150
2024-06-03 00:14:48 [INFO]: Epoch 017 - training loss: 0.4034, validation loss: 0.5098
2024-06-03 00:14:53 [INFO]: Epoch 018 - training loss: 0.4008, validation loss: 0.5108
2024-06-03 00:14:57 [INFO]: Epoch 019 - training loss: 0.3909, validation loss: 0.5084
2024-06-03 00:15:02 [INFO]: Epoch 020 - training loss: 0.3973, validation loss: 0.5129
2024-06-03 00:15:06 [INFO]: Epoch 021 - training loss: 0.3923, validation loss: 0.4991
2024-06-03 00:15:10 [INFO]: Epoch 022 - training loss: 0.3860, validation loss: 0.5126
2024-06-03 00:15:15 [INFO]: Epoch 023 - training loss: 0.3739, validation loss: 0.5171
2024-06-03 00:15:19 [INFO]: Epoch 024 - training loss: 0.3724, validation loss: 0.5129
2024-06-03 00:15:24 [INFO]: Epoch 025 - training loss: 0.3661, validation loss: 0.5035
2024-06-03 00:15:27 [INFO]: Epoch 026 - training loss: 0.3605, validation loss: 0.5111
2024-06-03 00:15:32 [INFO]: Epoch 027 - training loss: 0.3580, validation loss: 0.5029
2024-06-03 00:15:36 [INFO]: Epoch 028 - training loss: 0.3564, validation loss: 0.5103
2024-06-03 00:15:41 [INFO]: Epoch 029 - training loss: 0.3490, validation loss: 0.5011
2024-06-03 00:15:45 [INFO]: Epoch 030 - training loss: 0.3475, validation loss: 0.5009
2024-06-03 00:15:49 [INFO]: Epoch 031 - training loss: 0.3416, validation loss: 0.5041
2024-06-03 00:15:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:15:49 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 00:15:50 [INFO]: Saved the model to results_point_rate09/PeMS/Crossformer_PeMS/round_2/20240603_T001332/Crossformer.pypots
2024-06-03 00:15:51 [INFO]: Successfully saved to results_point_rate09/PeMS/Crossformer_PeMS/round_2/imputation.pkl
2024-06-03 00:15:51 [INFO]: Round2 - Crossformer on PeMS: MAE=0.3897, MSE=0.7315, MRE=0.4835
2024-06-03 00:15:51 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:15:51 [INFO]: Using the given device: cuda:0
2024-06-03 00:15:52 [INFO]: Model files will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_3/20240603_T001551
2024-06-03 00:15:52 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_3/20240603_T001551/tensorboard
2024-06-03 00:15:52 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 00:15:56 [INFO]: Epoch 001 - training loss: 1.2060, validation loss: 0.8896
2024-06-03 00:16:01 [INFO]: Epoch 002 - training loss: 0.8074, validation loss: 0.7538
2024-06-03 00:16:05 [INFO]: Epoch 003 - training loss: 0.6326, validation loss: 0.6576
2024-06-03 00:16:09 [INFO]: Epoch 004 - training loss: 0.5734, validation loss: 0.6042
2024-06-03 00:16:12 [INFO]: Epoch 005 - training loss: 0.5552, validation loss: 0.5883
2024-06-03 00:16:16 [INFO]: Epoch 006 - training loss: 0.5318, validation loss: 0.5635
2024-06-03 00:16:20 [INFO]: Epoch 007 - training loss: 0.5061, validation loss: 0.5613
2024-06-03 00:16:24 [INFO]: Epoch 008 - training loss: 0.5015, validation loss: 0.5521
2024-06-03 00:16:28 [INFO]: Epoch 009 - training loss: 0.4864, validation loss: 0.5471
2024-06-03 00:16:32 [INFO]: Epoch 010 - training loss: 0.4698, validation loss: 0.5419
2024-06-03 00:16:36 [INFO]: Epoch 011 - training loss: 0.4534, validation loss: 0.5313
2024-06-03 00:16:40 [INFO]: Epoch 012 - training loss: 0.4476, validation loss: 0.5231
2024-06-03 00:16:44 [INFO]: Epoch 013 - training loss: 0.4402, validation loss: 0.5187
2024-06-03 00:16:48 [INFO]: Epoch 014 - training loss: 0.4273, validation loss: 0.5326
2024-06-03 00:16:52 [INFO]: Epoch 015 - training loss: 0.4231, validation loss: 0.5228
2024-06-03 00:16:56 [INFO]: Epoch 016 - training loss: 0.4136, validation loss: 0.5259
2024-06-03 00:17:00 [INFO]: Epoch 017 - training loss: 0.4044, validation loss: 0.5380
2024-06-03 00:17:04 [INFO]: Epoch 018 - training loss: 0.3976, validation loss: 0.5212
2024-06-03 00:17:08 [INFO]: Epoch 019 - training loss: 0.3904, validation loss: 0.5140
2024-06-03 00:17:11 [INFO]: Epoch 020 - training loss: 0.3846, validation loss: 0.5134
2024-06-03 00:17:15 [INFO]: Epoch 021 - training loss: 0.3790, validation loss: 0.5098
2024-06-03 00:17:20 [INFO]: Epoch 022 - training loss: 0.3712, validation loss: 0.5119
2024-06-03 00:17:24 [INFO]: Epoch 023 - training loss: 0.3727, validation loss: 0.5138
2024-06-03 00:17:28 [INFO]: Epoch 024 - training loss: 0.3676, validation loss: 0.5068
2024-06-03 00:17:32 [INFO]: Epoch 025 - training loss: 0.3638, validation loss: 0.5144
2024-06-03 00:17:35 [INFO]: Epoch 026 - training loss: 0.3612, validation loss: 0.5154
2024-06-03 00:17:39 [INFO]: Epoch 027 - training loss: 0.3564, validation loss: 0.5085
2024-06-03 00:17:43 [INFO]: Epoch 028 - training loss: 0.3566, validation loss: 0.5061
2024-06-03 00:17:47 [INFO]: Epoch 029 - training loss: 0.3490, validation loss: 0.5084
2024-06-03 00:17:51 [INFO]: Epoch 030 - training loss: 0.3476, validation loss: 0.5068
2024-06-03 00:17:55 [INFO]: Epoch 031 - training loss: 0.3395, validation loss: 0.5045
2024-06-03 00:17:59 [INFO]: Epoch 032 - training loss: 0.3402, validation loss: 0.5075
2024-06-03 00:18:03 [INFO]: Epoch 033 - training loss: 0.3338, validation loss: 0.5140
2024-06-03 00:18:06 [INFO]: Epoch 034 - training loss: 0.3371, validation loss: 0.5032
2024-06-03 00:18:11 [INFO]: Epoch 035 - training loss: 0.3295, validation loss: 0.5100
2024-06-03 00:18:14 [INFO]: Epoch 036 - training loss: 0.3288, validation loss: 0.5077
2024-06-03 00:18:18 [INFO]: Epoch 037 - training loss: 0.3265, validation loss: 0.5076
2024-06-03 00:18:22 [INFO]: Epoch 038 - training loss: 0.3256, validation loss: 0.5076
2024-06-03 00:18:26 [INFO]: Epoch 039 - training loss: 0.3176, validation loss: 0.5069
2024-06-03 00:18:30 [INFO]: Epoch 040 - training loss: 0.3180, validation loss: 0.5066
2024-06-03 00:18:34 [INFO]: Epoch 041 - training loss: 0.3192, validation loss: 0.5120
2024-06-03 00:18:38 [INFO]: Epoch 042 - training loss: 0.3137, validation loss: 0.5046
2024-06-03 00:18:41 [INFO]: Epoch 043 - training loss: 0.3144, validation loss: 0.5116
2024-06-03 00:18:45 [INFO]: Epoch 044 - training loss: 0.3120, validation loss: 0.5062
2024-06-03 00:18:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:18:45 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 00:18:46 [INFO]: Saved the model to results_point_rate09/PeMS/Crossformer_PeMS/round_3/20240603_T001551/Crossformer.pypots
2024-06-03 00:18:47 [INFO]: Successfully saved to results_point_rate09/PeMS/Crossformer_PeMS/round_3/imputation.pkl
2024-06-03 00:18:47 [INFO]: Round3 - Crossformer on PeMS: MAE=0.4026, MSE=0.7309, MRE=0.4996
2024-06-03 00:18:47 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:18:47 [INFO]: Using the given device: cuda:0
2024-06-03 00:18:47 [INFO]: Model files will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_4/20240603_T001847
2024-06-03 00:18:47 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/Crossformer_PeMS/round_4/20240603_T001847/tensorboard
2024-06-03 00:18:48 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 00:18:52 [INFO]: Epoch 001 - training loss: 1.2051, validation loss: 0.9758
2024-06-03 00:18:56 [INFO]: Epoch 002 - training loss: 0.8122, validation loss: 0.8310
2024-06-03 00:19:00 [INFO]: Epoch 003 - training loss: 0.6677, validation loss: 0.6777
2024-06-03 00:19:04 [INFO]: Epoch 004 - training loss: 0.6017, validation loss: 0.6344
2024-06-03 00:19:08 [INFO]: Epoch 005 - training loss: 0.5832, validation loss: 0.5996
2024-06-03 00:19:12 [INFO]: Epoch 006 - training loss: 0.5282, validation loss: 0.5719
2024-06-03 00:19:16 [INFO]: Epoch 007 - training loss: 0.4998, validation loss: 0.5608
2024-06-03 00:19:19 [INFO]: Epoch 008 - training loss: 0.4835, validation loss: 0.5456
2024-06-03 00:19:23 [INFO]: Epoch 009 - training loss: 0.4777, validation loss: 0.5396
2024-06-03 00:19:26 [INFO]: Epoch 010 - training loss: 0.4745, validation loss: 0.5422
2024-06-03 00:19:29 [INFO]: Epoch 011 - training loss: 0.4548, validation loss: 0.5263
2024-06-03 00:19:33 [INFO]: Epoch 012 - training loss: 0.4406, validation loss: 0.5360
2024-06-03 00:19:36 [INFO]: Epoch 013 - training loss: 0.4293, validation loss: 0.5202
2024-06-03 00:19:40 [INFO]: Epoch 014 - training loss: 0.4221, validation loss: 0.5242
2024-06-03 00:19:44 [INFO]: Epoch 015 - training loss: 0.4124, validation loss: 0.5204
2024-06-03 00:19:47 [INFO]: Epoch 016 - training loss: 0.4122, validation loss: 0.5224
2024-06-03 00:19:51 [INFO]: Epoch 017 - training loss: 0.3964, validation loss: 0.5170
2024-06-03 00:19:54 [INFO]: Epoch 018 - training loss: 0.3927, validation loss: 0.5134
2024-06-03 00:19:58 [INFO]: Epoch 019 - training loss: 0.3866, validation loss: 0.5116
2024-06-03 00:20:02 [INFO]: Epoch 020 - training loss: 0.3822, validation loss: 0.5116
2024-06-03 00:20:05 [INFO]: Epoch 021 - training loss: 0.3753, validation loss: 0.5119
2024-06-03 00:20:09 [INFO]: Epoch 022 - training loss: 0.3692, validation loss: 0.5068
2024-06-03 00:20:12 [INFO]: Epoch 023 - training loss: 0.3668, validation loss: 0.5129
2024-06-03 00:20:16 [INFO]: Epoch 024 - training loss: 0.3624, validation loss: 0.5158
2024-06-03 00:20:19 [INFO]: Epoch 025 - training loss: 0.3627, validation loss: 0.5040
2024-06-03 00:20:23 [INFO]: Epoch 026 - training loss: 0.3559, validation loss: 0.5103
2024-06-03 00:20:26 [INFO]: Epoch 027 - training loss: 0.3524, validation loss: 0.5037
2024-06-03 00:20:30 [INFO]: Epoch 028 - training loss: 0.3433, validation loss: 0.5007
2024-06-03 00:20:34 [INFO]: Epoch 029 - training loss: 0.3464, validation loss: 0.5043
2024-06-03 00:20:37 [INFO]: Epoch 030 - training loss: 0.3437, validation loss: 0.5104
2024-06-03 00:20:41 [INFO]: Epoch 031 - training loss: 0.3389, validation loss: 0.5017
2024-06-03 00:20:45 [INFO]: Epoch 032 - training loss: 0.3376, validation loss: 0.5008
2024-06-03 00:20:48 [INFO]: Epoch 033 - training loss: 0.3351, validation loss: 0.5102
2024-06-03 00:20:52 [INFO]: Epoch 034 - training loss: 0.3349, validation loss: 0.5074
2024-06-03 00:20:55 [INFO]: Epoch 035 - training loss: 0.3265, validation loss: 0.5033
2024-06-03 00:20:59 [INFO]: Epoch 036 - training loss: 0.3246, validation loss: 0.5061
2024-06-03 00:21:03 [INFO]: Epoch 037 - training loss: 0.3230, validation loss: 0.5049
2024-06-03 00:21:06 [INFO]: Epoch 038 - training loss: 0.3198, validation loss: 0.5051
2024-06-03 00:21:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:21:06 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 00:21:06 [INFO]: Saved the model to results_point_rate09/PeMS/Crossformer_PeMS/round_4/20240603_T001847/Crossformer.pypots
2024-06-03 00:21:08 [INFO]: Successfully saved to results_point_rate09/PeMS/Crossformer_PeMS/round_4/imputation.pkl
2024-06-03 00:21:08 [INFO]: Round4 - Crossformer on PeMS: MAE=0.3996, MSE=0.7269, MRE=0.4959
2024-06-03 00:21:08 [INFO]: Done! Final results:
Averaged Crossformer (12,645,238 params) on PeMS: MAE=0.3993 ± 0.006630507724535422, MSE=0.7331 ± 0.004458712862402019, MRE=0.4955 ± 0.008227338860334171, average inference time=0.32
