2024-06-03 04:32:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:32:41 [INFO]: Using the given device: cuda:0
2024-06-03 04:32:42 [INFO]: Model files will be saved to results_point_rate09/PeMS/MICN_PeMS/round_0/20240603_T043242
2024-06-03 04:32:42 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/MICN_PeMS/round_0/20240603_T043242/tensorboard
2024-06-03 04:32:43 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 04:32:48 [INFO]: Epoch 001 - training loss: 1.0854, validation loss: 0.8132
2024-06-03 04:32:50 [INFO]: Epoch 002 - training loss: 0.7376, validation loss: 0.7911
2024-06-03 04:32:52 [INFO]: Epoch 003 - training loss: 0.6561, validation loss: 0.7458
2024-06-03 04:32:54 [INFO]: Epoch 004 - training loss: 0.6199, validation loss: 0.7666
2024-06-03 04:32:56 [INFO]: Epoch 005 - training loss: 0.5922, validation loss: 0.7634
2024-06-03 04:32:58 [INFO]: Epoch 006 - training loss: 0.5616, validation loss: 0.7492
2024-06-03 04:33:00 [INFO]: Epoch 007 - training loss: 0.5409, validation loss: 0.7588
2024-06-03 04:33:02 [INFO]: Epoch 008 - training loss: 0.5302, validation loss: 0.7268
2024-06-03 04:33:05 [INFO]: Epoch 009 - training loss: 0.5193, validation loss: 0.7032
2024-06-03 04:33:07 [INFO]: Epoch 010 - training loss: 0.5095, validation loss: 0.6690
2024-06-03 04:33:09 [INFO]: Epoch 011 - training loss: 0.5033, validation loss: 0.6926
2024-06-03 04:33:11 [INFO]: Epoch 012 - training loss: 0.4940, validation loss: 0.6929
2024-06-03 04:33:13 [INFO]: Epoch 013 - training loss: 0.4952, validation loss: 0.6822
2024-06-03 04:33:15 [INFO]: Epoch 014 - training loss: 0.4900, validation loss: 0.6538
2024-06-03 04:33:17 [INFO]: Epoch 015 - training loss: 0.4780, validation loss: 0.6682
2024-06-03 04:33:19 [INFO]: Epoch 016 - training loss: 0.4735, validation loss: 0.6529
2024-06-03 04:33:22 [INFO]: Epoch 017 - training loss: 0.4726, validation loss: 0.6585
2024-06-03 04:33:24 [INFO]: Epoch 018 - training loss: 0.4694, validation loss: 0.6431
2024-06-03 04:33:26 [INFO]: Epoch 019 - training loss: 0.4634, validation loss: 0.6627
2024-06-03 04:33:29 [INFO]: Epoch 020 - training loss: 0.4576, validation loss: 0.6674
2024-06-03 04:33:32 [INFO]: Epoch 021 - training loss: 0.4579, validation loss: 0.6632
2024-06-03 04:33:35 [INFO]: Epoch 022 - training loss: 0.4538, validation loss: 0.6393
2024-06-03 04:33:38 [INFO]: Epoch 023 - training loss: 0.4469, validation loss: 0.6560
2024-06-03 04:33:41 [INFO]: Epoch 024 - training loss: 0.4424, validation loss: 0.6532
2024-06-03 04:33:44 [INFO]: Epoch 025 - training loss: 0.4398, validation loss: 0.6308
2024-06-03 04:33:47 [INFO]: Epoch 026 - training loss: 0.4373, validation loss: 0.6389
2024-06-03 04:33:50 [INFO]: Epoch 027 - training loss: 0.4352, validation loss: 0.6402
2024-06-03 04:33:53 [INFO]: Epoch 028 - training loss: 0.4289, validation loss: 0.6560
2024-06-03 04:33:56 [INFO]: Epoch 029 - training loss: 0.4249, validation loss: 0.6344
2024-06-03 04:33:59 [INFO]: Epoch 030 - training loss: 0.4214, validation loss: 0.6455
2024-06-03 04:34:02 [INFO]: Epoch 031 - training loss: 0.4160, validation loss: 0.6501
2024-06-03 04:34:04 [INFO]: Epoch 032 - training loss: 0.4158, validation loss: 0.6371
2024-06-03 04:34:07 [INFO]: Epoch 033 - training loss: 0.4113, validation loss: 0.6363
2024-06-03 04:34:11 [INFO]: Epoch 034 - training loss: 0.4106, validation loss: 0.6296
2024-06-03 04:34:14 [INFO]: Epoch 035 - training loss: 0.4041, validation loss: 0.6199
2024-06-03 04:34:17 [INFO]: Epoch 036 - training loss: 0.4040, validation loss: 0.6459
2024-06-03 04:34:20 [INFO]: Epoch 037 - training loss: 0.3989, validation loss: 0.6381
2024-06-03 04:34:23 [INFO]: Epoch 038 - training loss: 0.3965, validation loss: 0.6348
2024-06-03 04:34:26 [INFO]: Epoch 039 - training loss: 0.3944, validation loss: 0.6276
2024-06-03 04:34:29 [INFO]: Epoch 040 - training loss: 0.3931, validation loss: 0.6417
2024-06-03 04:34:32 [INFO]: Epoch 041 - training loss: 0.3903, validation loss: 0.6290
2024-06-03 04:34:35 [INFO]: Epoch 042 - training loss: 0.3885, validation loss: 0.6459
2024-06-03 04:34:38 [INFO]: Epoch 043 - training loss: 0.3842, validation loss: 0.6357
2024-06-03 04:34:41 [INFO]: Epoch 044 - training loss: 0.3813, validation loss: 0.6387
2024-06-03 04:34:44 [INFO]: Epoch 045 - training loss: 0.3831, validation loss: 0.6352
2024-06-03 04:34:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:34:44 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 04:34:44 [INFO]: Saved the model to results_point_rate09/PeMS/MICN_PeMS/round_0/20240603_T043242/MICN.pypots
2024-06-03 04:34:46 [INFO]: Successfully saved to results_point_rate09/PeMS/MICN_PeMS/round_0/imputation.pkl
2024-06-03 04:34:46 [INFO]: Round0 - MICN on PeMS: MAE=0.5014, MSE=0.9424, MRE=0.6221
2024-06-03 04:34:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:34:46 [INFO]: Using the given device: cuda:0
2024-06-03 04:34:46 [INFO]: Model files will be saved to results_point_rate09/PeMS/MICN_PeMS/round_1/20240603_T043446
2024-06-03 04:34:46 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/MICN_PeMS/round_1/20240603_T043446/tensorboard
2024-06-03 04:34:46 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 04:34:49 [INFO]: Epoch 001 - training loss: 1.0875, validation loss: 0.8166
2024-06-03 04:34:52 [INFO]: Epoch 002 - training loss: 0.7284, validation loss: 0.7983
2024-06-03 04:34:55 [INFO]: Epoch 003 - training loss: 0.6484, validation loss: 0.7853
2024-06-03 04:34:58 [INFO]: Epoch 004 - training loss: 0.6023, validation loss: 0.7479
2024-06-03 04:35:01 [INFO]: Epoch 005 - training loss: 0.5747, validation loss: 0.7251
2024-06-03 04:35:04 [INFO]: Epoch 006 - training loss: 0.5470, validation loss: 0.7432
2024-06-03 04:35:07 [INFO]: Epoch 007 - training loss: 0.5280, validation loss: 0.7502
2024-06-03 04:35:10 [INFO]: Epoch 008 - training loss: 0.5183, validation loss: 0.6919
2024-06-03 04:35:13 [INFO]: Epoch 009 - training loss: 0.5104, validation loss: 0.6712
2024-06-03 04:35:16 [INFO]: Epoch 010 - training loss: 0.5014, validation loss: 0.6741
2024-06-03 04:35:18 [INFO]: Epoch 011 - training loss: 0.4941, validation loss: 0.6668
2024-06-03 04:35:21 [INFO]: Epoch 012 - training loss: 0.4841, validation loss: 0.6740
2024-06-03 04:35:24 [INFO]: Epoch 013 - training loss: 0.4818, validation loss: 0.6491
2024-06-03 04:35:27 [INFO]: Epoch 014 - training loss: 0.4777, validation loss: 0.6390
2024-06-03 04:35:30 [INFO]: Epoch 015 - training loss: 0.4737, validation loss: 0.6564
2024-06-03 04:35:33 [INFO]: Epoch 016 - training loss: 0.4692, validation loss: 0.6662
2024-06-03 04:35:36 [INFO]: Epoch 017 - training loss: 0.4648, validation loss: 0.6499
2024-06-03 04:35:39 [INFO]: Epoch 018 - training loss: 0.4600, validation loss: 0.6487
2024-06-03 04:35:42 [INFO]: Epoch 019 - training loss: 0.4625, validation loss: 0.6240
2024-06-03 04:35:45 [INFO]: Epoch 020 - training loss: 0.4541, validation loss: 0.6495
2024-06-03 04:35:48 [INFO]: Epoch 021 - training loss: 0.4456, validation loss: 0.6383
2024-06-03 04:35:51 [INFO]: Epoch 022 - training loss: 0.4487, validation loss: 0.6635
2024-06-03 04:35:54 [INFO]: Epoch 023 - training loss: 0.4421, validation loss: 0.6419
2024-06-03 04:35:57 [INFO]: Epoch 024 - training loss: 0.4362, validation loss: 0.6286
2024-06-03 04:36:00 [INFO]: Epoch 025 - training loss: 0.4349, validation loss: 0.6334
2024-06-03 04:36:03 [INFO]: Epoch 026 - training loss: 0.4340, validation loss: 0.6250
2024-06-03 04:36:06 [INFO]: Epoch 027 - training loss: 0.4263, validation loss: 0.6258
2024-06-03 04:36:09 [INFO]: Epoch 028 - training loss: 0.4249, validation loss: 0.6228
2024-06-03 04:36:12 [INFO]: Epoch 029 - training loss: 0.4191, validation loss: 0.6300
2024-06-03 04:36:15 [INFO]: Epoch 030 - training loss: 0.4155, validation loss: 0.6462
2024-06-03 04:36:18 [INFO]: Epoch 031 - training loss: 0.4175, validation loss: 0.6383
2024-06-03 04:36:21 [INFO]: Epoch 032 - training loss: 0.4115, validation loss: 0.6322
2024-06-03 04:36:24 [INFO]: Epoch 033 - training loss: 0.4079, validation loss: 0.6352
2024-06-03 04:36:27 [INFO]: Epoch 034 - training loss: 0.4028, validation loss: 0.6262
2024-06-03 04:36:30 [INFO]: Epoch 035 - training loss: 0.3999, validation loss: 0.6232
2024-06-03 04:36:33 [INFO]: Epoch 036 - training loss: 0.3973, validation loss: 0.6141
2024-06-03 04:36:36 [INFO]: Epoch 037 - training loss: 0.3955, validation loss: 0.6203
2024-06-03 04:36:38 [INFO]: Epoch 038 - training loss: 0.3930, validation loss: 0.6143
2024-06-03 04:36:41 [INFO]: Epoch 039 - training loss: 0.3916, validation loss: 0.6294
2024-06-03 04:36:44 [INFO]: Epoch 040 - training loss: 0.3905, validation loss: 0.6203
2024-06-03 04:36:47 [INFO]: Epoch 041 - training loss: 0.3869, validation loss: 0.6216
2024-06-03 04:36:49 [INFO]: Epoch 042 - training loss: 0.3801, validation loss: 0.6165
2024-06-03 04:36:52 [INFO]: Epoch 043 - training loss: 0.3786, validation loss: 0.6251
2024-06-03 04:36:55 [INFO]: Epoch 044 - training loss: 0.3803, validation loss: 0.6228
2024-06-03 04:36:58 [INFO]: Epoch 045 - training loss: 0.3761, validation loss: 0.6046
2024-06-03 04:37:01 [INFO]: Epoch 046 - training loss: 0.3721, validation loss: 0.6164
2024-06-03 04:37:04 [INFO]: Epoch 047 - training loss: 0.3702, validation loss: 0.6230
2024-06-03 04:37:07 [INFO]: Epoch 048 - training loss: 0.3706, validation loss: 0.6341
2024-06-03 04:37:10 [INFO]: Epoch 049 - training loss: 0.3707, validation loss: 0.6253
2024-06-03 04:37:13 [INFO]: Epoch 050 - training loss: 0.3657, validation loss: 0.6243
2024-06-03 04:37:16 [INFO]: Epoch 051 - training loss: 0.3693, validation loss: 0.6241
2024-06-03 04:37:19 [INFO]: Epoch 052 - training loss: 0.3658, validation loss: 0.6094
2024-06-03 04:37:22 [INFO]: Epoch 053 - training loss: 0.3649, validation loss: 0.6054
2024-06-03 04:37:25 [INFO]: Epoch 054 - training loss: 0.3610, validation loss: 0.6192
2024-06-03 04:37:28 [INFO]: Epoch 055 - training loss: 0.3614, validation loss: 0.6039
2024-06-03 04:37:31 [INFO]: Epoch 056 - training loss: 0.3574, validation loss: 0.6177
2024-06-03 04:37:34 [INFO]: Epoch 057 - training loss: 0.3545, validation loss: 0.6123
2024-06-03 04:37:38 [INFO]: Epoch 058 - training loss: 0.3531, validation loss: 0.6171
2024-06-03 04:37:40 [INFO]: Epoch 059 - training loss: 0.3506, validation loss: 0.6122
2024-06-03 04:37:43 [INFO]: Epoch 060 - training loss: 0.3478, validation loss: 0.6121
2024-06-03 04:37:46 [INFO]: Epoch 061 - training loss: 0.3492, validation loss: 0.6177
2024-06-03 04:37:49 [INFO]: Epoch 062 - training loss: 0.3452, validation loss: 0.6066
2024-06-03 04:37:52 [INFO]: Epoch 063 - training loss: 0.3455, validation loss: 0.6083
2024-06-03 04:37:55 [INFO]: Epoch 064 - training loss: 0.3445, validation loss: 0.6127
2024-06-03 04:37:58 [INFO]: Epoch 065 - training loss: 0.3432, validation loss: 0.6276
2024-06-03 04:37:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:37:58 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 04:37:59 [INFO]: Saved the model to results_point_rate09/PeMS/MICN_PeMS/round_1/20240603_T043446/MICN.pypots
2024-06-03 04:38:00 [INFO]: Successfully saved to results_point_rate09/PeMS/MICN_PeMS/round_1/imputation.pkl
2024-06-03 04:38:00 [INFO]: Round1 - MICN on PeMS: MAE=0.4887, MSE=0.9211, MRE=0.6064
2024-06-03 04:38:00 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:38:00 [INFO]: Using the given device: cuda:0
2024-06-03 04:38:00 [INFO]: Model files will be saved to results_point_rate09/PeMS/MICN_PeMS/round_2/20240603_T043800
2024-06-03 04:38:00 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/MICN_PeMS/round_2/20240603_T043800/tensorboard
2024-06-03 04:38:00 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 04:38:04 [INFO]: Epoch 001 - training loss: 1.1010, validation loss: 0.8085
2024-06-03 04:38:07 [INFO]: Epoch 002 - training loss: 0.7522, validation loss: 0.8036
2024-06-03 04:38:09 [INFO]: Epoch 003 - training loss: 0.6635, validation loss: 0.7597
2024-06-03 04:38:12 [INFO]: Epoch 004 - training loss: 0.6098, validation loss: 0.7585
2024-06-03 04:38:15 [INFO]: Epoch 005 - training loss: 0.5784, validation loss: 0.7412
2024-06-03 04:38:18 [INFO]: Epoch 006 - training loss: 0.5603, validation loss: 0.7396
2024-06-03 04:38:21 [INFO]: Epoch 007 - training loss: 0.5355, validation loss: 0.7241
2024-06-03 04:38:24 [INFO]: Epoch 008 - training loss: 0.5274, validation loss: 0.6656
2024-06-03 04:38:27 [INFO]: Epoch 009 - training loss: 0.5184, validation loss: 0.6285
2024-06-03 04:38:30 [INFO]: Epoch 010 - training loss: 0.5101, validation loss: 0.6339
2024-06-03 04:38:32 [INFO]: Epoch 011 - training loss: 0.5036, validation loss: 0.6427
2024-06-03 04:38:35 [INFO]: Epoch 012 - training loss: 0.4942, validation loss: 0.6420
2024-06-03 04:38:38 [INFO]: Epoch 013 - training loss: 0.4879, validation loss: 0.6377
2024-06-03 04:38:41 [INFO]: Epoch 014 - training loss: 0.4830, validation loss: 0.6210
2024-06-03 04:38:45 [INFO]: Epoch 015 - training loss: 0.4835, validation loss: 0.6354
2024-06-03 04:38:48 [INFO]: Epoch 016 - training loss: 0.4750, validation loss: 0.6371
2024-06-03 04:38:50 [INFO]: Epoch 017 - training loss: 0.4720, validation loss: 0.6334
2024-06-03 04:38:53 [INFO]: Epoch 018 - training loss: 0.4622, validation loss: 0.6248
2024-06-03 04:38:56 [INFO]: Epoch 019 - training loss: 0.4574, validation loss: 0.6290
2024-06-03 04:38:59 [INFO]: Epoch 020 - training loss: 0.4584, validation loss: 0.6223
2024-06-03 04:39:02 [INFO]: Epoch 021 - training loss: 0.4542, validation loss: 0.6245
2024-06-03 04:39:05 [INFO]: Epoch 022 - training loss: 0.4458, validation loss: 0.6240
2024-06-03 04:39:08 [INFO]: Epoch 023 - training loss: 0.4426, validation loss: 0.6316
2024-06-03 04:39:11 [INFO]: Epoch 024 - training loss: 0.4404, validation loss: 0.6215
2024-06-03 04:39:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:39:11 [INFO]: Finished training. The best model is from epoch#14.
2024-06-03 04:39:11 [INFO]: Saved the model to results_point_rate09/PeMS/MICN_PeMS/round_2/20240603_T043800/MICN.pypots
2024-06-03 04:39:12 [INFO]: Successfully saved to results_point_rate09/PeMS/MICN_PeMS/round_2/imputation.pkl
2024-06-03 04:39:12 [INFO]: Round2 - MICN on PeMS: MAE=0.5003, MSE=0.9249, MRE=0.6207
2024-06-03 04:39:12 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:39:12 [INFO]: Using the given device: cuda:0
2024-06-03 04:39:12 [INFO]: Model files will be saved to results_point_rate09/PeMS/MICN_PeMS/round_3/20240603_T043912
2024-06-03 04:39:12 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/MICN_PeMS/round_3/20240603_T043912/tensorboard
2024-06-03 04:39:13 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 04:39:16 [INFO]: Epoch 001 - training loss: 1.0862, validation loss: 0.8745
2024-06-03 04:39:19 [INFO]: Epoch 002 - training loss: 0.7400, validation loss: 0.8324
2024-06-03 04:39:22 [INFO]: Epoch 003 - training loss: 0.6621, validation loss: 0.7685
2024-06-03 04:39:25 [INFO]: Epoch 004 - training loss: 0.6273, validation loss: 0.7517
2024-06-03 04:39:28 [INFO]: Epoch 005 - training loss: 0.5943, validation loss: 0.7531
2024-06-03 04:39:31 [INFO]: Epoch 006 - training loss: 0.5660, validation loss: 0.7414
2024-06-03 04:39:34 [INFO]: Epoch 007 - training loss: 0.5426, validation loss: 0.7461
2024-06-03 04:39:37 [INFO]: Epoch 008 - training loss: 0.5275, validation loss: 0.7300
2024-06-03 04:39:39 [INFO]: Epoch 009 - training loss: 0.5142, validation loss: 0.7145
2024-06-03 04:39:42 [INFO]: Epoch 010 - training loss: 0.5081, validation loss: 0.7075
2024-06-03 04:39:44 [INFO]: Epoch 011 - training loss: 0.5025, validation loss: 0.6944
2024-06-03 04:39:47 [INFO]: Epoch 012 - training loss: 0.4985, validation loss: 0.6812
2024-06-03 04:39:49 [INFO]: Epoch 013 - training loss: 0.4944, validation loss: 0.6805
2024-06-03 04:39:52 [INFO]: Epoch 014 - training loss: 0.4879, validation loss: 0.6768
2024-06-03 04:39:55 [INFO]: Epoch 015 - training loss: 0.4806, validation loss: 0.6818
2024-06-03 04:39:57 [INFO]: Epoch 016 - training loss: 0.4761, validation loss: 0.6869
2024-06-03 04:40:00 [INFO]: Epoch 017 - training loss: 0.4741, validation loss: 0.6739
2024-06-03 04:40:02 [INFO]: Epoch 018 - training loss: 0.4723, validation loss: 0.6615
2024-06-03 04:40:05 [INFO]: Epoch 019 - training loss: 0.4613, validation loss: 0.6743
2024-06-03 04:40:07 [INFO]: Epoch 020 - training loss: 0.4612, validation loss: 0.7041
2024-06-03 04:40:10 [INFO]: Epoch 021 - training loss: 0.4569, validation loss: 0.6450
2024-06-03 04:40:12 [INFO]: Epoch 022 - training loss: 0.4517, validation loss: 0.6808
2024-06-03 04:40:15 [INFO]: Epoch 023 - training loss: 0.4479, validation loss: 0.6444
2024-06-03 04:40:17 [INFO]: Epoch 024 - training loss: 0.4448, validation loss: 0.6633
2024-06-03 04:40:20 [INFO]: Epoch 025 - training loss: 0.4400, validation loss: 0.6681
2024-06-03 04:40:22 [INFO]: Epoch 026 - training loss: 0.4376, validation loss: 0.6628
2024-06-03 04:40:25 [INFO]: Epoch 027 - training loss: 0.4350, validation loss: 0.6508
2024-06-03 04:40:27 [INFO]: Epoch 028 - training loss: 0.4299, validation loss: 0.6617
2024-06-03 04:40:30 [INFO]: Epoch 029 - training loss: 0.4271, validation loss: 0.6491
2024-06-03 04:40:32 [INFO]: Epoch 030 - training loss: 0.4239, validation loss: 0.6680
2024-06-03 04:40:34 [INFO]: Epoch 031 - training loss: 0.4228, validation loss: 0.6433
2024-06-03 04:40:37 [INFO]: Epoch 032 - training loss: 0.4184, validation loss: 0.6496
2024-06-03 04:40:40 [INFO]: Epoch 033 - training loss: 0.4136, validation loss: 0.6476
2024-06-03 04:40:42 [INFO]: Epoch 034 - training loss: 0.4091, validation loss: 0.6454
2024-06-03 04:40:45 [INFO]: Epoch 035 - training loss: 0.4067, validation loss: 0.6575
2024-06-03 04:40:47 [INFO]: Epoch 036 - training loss: 0.4041, validation loss: 0.6646
2024-06-03 04:40:50 [INFO]: Epoch 037 - training loss: 0.4040, validation loss: 0.6432
2024-06-03 04:40:52 [INFO]: Epoch 038 - training loss: 0.4005, validation loss: 0.6584
2024-06-03 04:40:55 [INFO]: Epoch 039 - training loss: 0.3997, validation loss: 0.6503
2024-06-03 04:40:57 [INFO]: Epoch 040 - training loss: 0.3973, validation loss: 0.6467
2024-06-03 04:41:00 [INFO]: Epoch 041 - training loss: 0.3931, validation loss: 0.6530
2024-06-03 04:41:02 [INFO]: Epoch 042 - training loss: 0.3902, validation loss: 0.6506
2024-06-03 04:41:04 [INFO]: Epoch 043 - training loss: 0.3885, validation loss: 0.6387
2024-06-03 04:41:07 [INFO]: Epoch 044 - training loss: 0.3867, validation loss: 0.6503
2024-06-03 04:41:09 [INFO]: Epoch 045 - training loss: 0.3820, validation loss: 0.6556
2024-06-03 04:41:12 [INFO]: Epoch 046 - training loss: 0.3818, validation loss: 0.6598
2024-06-03 04:41:14 [INFO]: Epoch 047 - training loss: 0.3802, validation loss: 0.6530
2024-06-03 04:41:16 [INFO]: Epoch 048 - training loss: 0.3766, validation loss: 0.6323
2024-06-03 04:41:18 [INFO]: Epoch 049 - training loss: 0.3763, validation loss: 0.6570
2024-06-03 04:41:21 [INFO]: Epoch 050 - training loss: 0.3758, validation loss: 0.6555
2024-06-03 04:41:23 [INFO]: Epoch 051 - training loss: 0.3710, validation loss: 0.6363
2024-06-03 04:41:25 [INFO]: Epoch 052 - training loss: 0.3694, validation loss: 0.6520
2024-06-03 04:41:28 [INFO]: Epoch 053 - training loss: 0.3668, validation loss: 0.6356
2024-06-03 04:41:30 [INFO]: Epoch 054 - training loss: 0.3653, validation loss: 0.6516
2024-06-03 04:41:32 [INFO]: Epoch 055 - training loss: 0.3635, validation loss: 0.6377
2024-06-03 04:41:35 [INFO]: Epoch 056 - training loss: 0.3629, validation loss: 0.6476
2024-06-03 04:41:37 [INFO]: Epoch 057 - training loss: 0.3600, validation loss: 0.6418
2024-06-03 04:41:39 [INFO]: Epoch 058 - training loss: 0.3589, validation loss: 0.6455
2024-06-03 04:41:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:41:39 [INFO]: Finished training. The best model is from epoch#48.
2024-06-03 04:41:39 [INFO]: Saved the model to results_point_rate09/PeMS/MICN_PeMS/round_3/20240603_T043912/MICN.pypots
2024-06-03 04:41:40 [INFO]: Successfully saved to results_point_rate09/PeMS/MICN_PeMS/round_3/imputation.pkl
2024-06-03 04:41:40 [INFO]: Round3 - MICN on PeMS: MAE=0.4994, MSE=0.9463, MRE=0.6197
2024-06-03 04:41:40 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:41:40 [INFO]: Using the given device: cuda:0
2024-06-03 04:41:40 [INFO]: Model files will be saved to results_point_rate09/PeMS/MICN_PeMS/round_4/20240603_T044140
2024-06-03 04:41:40 [INFO]: Tensorboard file will be saved to results_point_rate09/PeMS/MICN_PeMS/round_4/20240603_T044140/tensorboard
2024-06-03 04:41:40 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 04:41:42 [INFO]: Epoch 001 - training loss: 1.0790, validation loss: 0.8246
2024-06-03 04:41:44 [INFO]: Epoch 002 - training loss: 0.7325, validation loss: 0.7753
2024-06-03 04:41:46 [INFO]: Epoch 003 - training loss: 0.6481, validation loss: 0.7844
2024-06-03 04:41:48 [INFO]: Epoch 004 - training loss: 0.6128, validation loss: 0.7277
2024-06-03 04:41:50 [INFO]: Epoch 005 - training loss: 0.5936, validation loss: 0.7566
2024-06-03 04:41:52 [INFO]: Epoch 006 - training loss: 0.5542, validation loss: 0.7386
2024-06-03 04:41:54 [INFO]: Epoch 007 - training loss: 0.5366, validation loss: 0.7232
2024-06-03 04:41:56 [INFO]: Epoch 008 - training loss: 0.5251, validation loss: 0.7155
2024-06-03 04:41:58 [INFO]: Epoch 009 - training loss: 0.5130, validation loss: 0.6784
2024-06-03 04:42:00 [INFO]: Epoch 010 - training loss: 0.5089, validation loss: 0.6794
2024-06-03 04:42:02 [INFO]: Epoch 011 - training loss: 0.5020, validation loss: 0.6650
2024-06-03 04:42:04 [INFO]: Epoch 012 - training loss: 0.4927, validation loss: 0.6725
2024-06-03 04:42:06 [INFO]: Epoch 013 - training loss: 0.4916, validation loss: 0.6676
2024-06-03 04:42:07 [INFO]: Epoch 014 - training loss: 0.4850, validation loss: 0.6592
2024-06-03 04:42:09 [INFO]: Epoch 015 - training loss: 0.4766, validation loss: 0.6419
2024-06-03 04:42:11 [INFO]: Epoch 016 - training loss: 0.4719, validation loss: 0.6536
2024-06-03 04:42:13 [INFO]: Epoch 017 - training loss: 0.4689, validation loss: 0.6447
2024-06-03 04:42:15 [INFO]: Epoch 018 - training loss: 0.4657, validation loss: 0.6452
2024-06-03 04:42:17 [INFO]: Epoch 019 - training loss: 0.4643, validation loss: 0.6641
2024-06-03 04:42:19 [INFO]: Epoch 020 - training loss: 0.4568, validation loss: 0.6524
2024-06-03 04:42:21 [INFO]: Epoch 021 - training loss: 0.4530, validation loss: 0.6462
2024-06-03 04:42:22 [INFO]: Epoch 022 - training loss: 0.4514, validation loss: 0.6549
2024-06-03 04:42:24 [INFO]: Epoch 023 - training loss: 0.4467, validation loss: 0.6217
2024-06-03 04:42:26 [INFO]: Epoch 024 - training loss: 0.4444, validation loss: 0.6335
2024-06-03 04:42:28 [INFO]: Epoch 025 - training loss: 0.4380, validation loss: 0.6520
2024-06-03 04:42:30 [INFO]: Epoch 026 - training loss: 0.4339, validation loss: 0.6462
2024-06-03 04:42:32 [INFO]: Epoch 027 - training loss: 0.4293, validation loss: 0.6296
2024-06-03 04:42:34 [INFO]: Epoch 028 - training loss: 0.4263, validation loss: 0.6333
2024-06-03 04:42:36 [INFO]: Epoch 029 - training loss: 0.4253, validation loss: 0.6349
2024-06-03 04:42:38 [INFO]: Epoch 030 - training loss: 0.4239, validation loss: 0.6354
2024-06-03 04:42:40 [INFO]: Epoch 031 - training loss: 0.4210, validation loss: 0.6357
2024-06-03 04:42:41 [INFO]: Epoch 032 - training loss: 0.4103, validation loss: 0.6419
2024-06-03 04:42:43 [INFO]: Epoch 033 - training loss: 0.4091, validation loss: 0.6413
2024-06-03 04:42:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:42:43 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 04:42:43 [INFO]: Saved the model to results_point_rate09/PeMS/MICN_PeMS/round_4/20240603_T044140/MICN.pypots
2024-06-03 04:42:43 [INFO]: Successfully saved to results_point_rate09/PeMS/MICN_PeMS/round_4/imputation.pkl
2024-06-03 04:42:43 [INFO]: Round4 - MICN on PeMS: MAE=0.4991, MSE=0.9360, MRE=0.6193
2024-06-03 04:42:43 [INFO]: Done! Final results:
Averaged MICN (15,490,402 params) on PeMS: MAE=0.4978 ± 0.004590573066513501, MSE=0.9341 ± 0.009737498350260327, MRE=0.6177 ± 0.005696124904820318, average inference time=0.16
