2024-06-03 01:11:55 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:11:55 [INFO]: Using the given device: cuda:0
2024-06-03 01:11:55 [INFO]: Model files will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_0/20240603_T011155
2024-06-03 01:11:55 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_0/20240603_T011155/tensorboard
2024-06-03 01:11:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 01:16:04 [INFO]: Epoch 001 - training loss: 0.7104, validation loss: 0.6677
2024-06-03 01:20:05 [INFO]: Epoch 002 - training loss: 0.4301, validation loss: 0.7053
2024-06-03 01:24:08 [INFO]: Epoch 003 - training loss: 0.3876, validation loss: 0.5954
2024-06-03 01:28:10 [INFO]: Epoch 004 - training loss: 0.3894, validation loss: 0.4508
2024-06-03 01:32:13 [INFO]: Epoch 005 - training loss: 0.4169, validation loss: 0.4443
2024-06-03 01:36:17 [INFO]: Epoch 006 - training loss: 0.3773, validation loss: 0.4363
2024-06-03 01:40:20 [INFO]: Epoch 007 - training loss: 0.3720, validation loss: 0.4215
2024-06-03 01:44:21 [INFO]: Epoch 008 - training loss: 0.3547, validation loss: 0.4186
2024-06-03 01:48:19 [INFO]: Epoch 009 - training loss: 0.3613, validation loss: 0.4024
2024-06-03 01:52:15 [INFO]: Epoch 010 - training loss: 0.3597, validation loss: 0.3967
2024-06-03 01:56:13 [INFO]: Epoch 011 - training loss: 0.3415, validation loss: 0.3892
2024-06-03 02:00:12 [INFO]: Epoch 012 - training loss: 0.3406, validation loss: 0.3770
2024-06-03 02:04:09 [INFO]: Epoch 013 - training loss: 0.3191, validation loss: 0.3670
2024-06-03 02:08:08 [INFO]: Epoch 014 - training loss: 0.3256, validation loss: 0.3701
2024-06-03 02:12:05 [INFO]: Epoch 015 - training loss: 0.3054, validation loss: 0.3602
2024-06-03 02:15:34 [INFO]: Epoch 016 - training loss: 0.3284, validation loss: 0.3589
2024-06-03 02:18:03 [INFO]: Epoch 017 - training loss: 0.3293, validation loss: 0.3527
2024-06-03 02:20:31 [INFO]: Epoch 018 - training loss: 0.3087, validation loss: 0.3535
2024-06-03 02:23:01 [INFO]: Epoch 019 - training loss: 0.3365, validation loss: 0.3354
2024-06-03 02:25:29 [INFO]: Epoch 020 - training loss: 0.3152, validation loss: 0.3407
2024-06-03 02:27:57 [INFO]: Epoch 021 - training loss: 0.2913, validation loss: 0.3402
2024-06-03 02:30:05 [INFO]: Epoch 022 - training loss: 0.2850, validation loss: 0.3303
2024-06-03 02:32:11 [INFO]: Epoch 023 - training loss: 0.3093, validation loss: 0.3261
2024-06-03 02:34:17 [INFO]: Epoch 024 - training loss: 0.2959, validation loss: 0.3221
2024-06-03 02:36:23 [INFO]: Epoch 025 - training loss: 0.2952, validation loss: 0.3286
2024-06-03 02:38:28 [INFO]: Epoch 026 - training loss: 0.2944, validation loss: 0.3273
2024-06-03 02:40:34 [INFO]: Epoch 027 - training loss: 0.2885, validation loss: 0.3218
2024-06-03 02:42:39 [INFO]: Epoch 028 - training loss: 0.2491, validation loss: 0.3236
2024-06-03 02:44:45 [INFO]: Epoch 029 - training loss: 0.2894, validation loss: 0.3200
2024-06-03 02:46:51 [INFO]: Epoch 030 - training loss: 0.2720, validation loss: 0.3236
2024-06-03 02:48:56 [INFO]: Epoch 031 - training loss: 0.2781, validation loss: 0.3247
2024-06-03 02:51:02 [INFO]: Epoch 032 - training loss: 0.2881, validation loss: 0.3146
2024-06-03 02:53:07 [INFO]: Epoch 033 - training loss: 0.2601, validation loss: 0.3158
2024-06-03 02:55:13 [INFO]: Epoch 034 - training loss: 0.2703, validation loss: 0.3149
2024-06-03 02:57:18 [INFO]: Epoch 035 - training loss: 0.2767, validation loss: 0.3200
2024-06-03 02:59:24 [INFO]: Epoch 036 - training loss: 0.2885, validation loss: 0.3245
2024-06-03 03:01:30 [INFO]: Epoch 037 - training loss: 0.2908, validation loss: 0.3177
2024-06-03 03:03:36 [INFO]: Epoch 038 - training loss: 0.2790, validation loss: 0.3119
2024-06-03 03:05:42 [INFO]: Epoch 039 - training loss: 0.2635, validation loss: 0.3161
2024-06-03 03:07:47 [INFO]: Epoch 040 - training loss: 0.2913, validation loss: 0.3099
2024-06-03 03:09:53 [INFO]: Epoch 041 - training loss: 0.2710, validation loss: 0.3131
2024-06-03 03:11:58 [INFO]: Epoch 042 - training loss: 0.2676, validation loss: 0.3059
2024-06-03 03:14:04 [INFO]: Epoch 043 - training loss: 0.2777, validation loss: 0.3044
2024-06-03 03:16:09 [INFO]: Epoch 044 - training loss: 0.2862, validation loss: 0.3054
2024-06-03 03:18:15 [INFO]: Epoch 045 - training loss: 0.2737, validation loss: 0.3084
2024-06-03 03:20:21 [INFO]: Epoch 046 - training loss: 0.2752, validation loss: 0.3085
2024-06-03 03:22:27 [INFO]: Epoch 047 - training loss: 0.2745, validation loss: 0.3079
2024-06-03 03:24:32 [INFO]: Epoch 048 - training loss: 0.2735, validation loss: 0.3150
2024-06-03 03:26:38 [INFO]: Epoch 049 - training loss: 0.2757, validation loss: 0.3008
2024-06-03 03:28:43 [INFO]: Epoch 050 - training loss: 0.2501, validation loss: 0.3047
2024-06-03 03:30:49 [INFO]: Epoch 051 - training loss: 0.2613, validation loss: 0.3049
2024-06-03 03:32:55 [INFO]: Epoch 052 - training loss: 0.2546, validation loss: 0.3091
2024-06-03 03:35:00 [INFO]: Epoch 053 - training loss: 0.2853, validation loss: 0.3099
2024-06-03 03:37:04 [INFO]: Epoch 054 - training loss: 0.2635, validation loss: 0.3026
2024-06-03 03:39:10 [INFO]: Epoch 055 - training loss: 0.2550, validation loss: 0.3049
2024-06-03 03:41:15 [INFO]: Epoch 056 - training loss: 0.2514, validation loss: 0.3107
2024-06-03 03:43:21 [INFO]: Epoch 057 - training loss: 0.2620, validation loss: 0.3049
2024-06-03 03:45:27 [INFO]: Epoch 058 - training loss: 0.2558, validation loss: 0.3009
2024-06-03 03:47:33 [INFO]: Epoch 059 - training loss: 0.2687, validation loss: 0.3076
2024-06-03 03:47:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:47:33 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 03:47:33 [INFO]: Saved the model to results_point_rate09/Electricity/CSDI_Electricity/round_0/20240603_T011155/CSDI.pypots
2024-06-03 04:04:39 [INFO]: Successfully saved to results_point_rate09/Electricity/CSDI_Electricity/round_0/imputation.pkl
2024-06-03 04:04:39 [INFO]: Round0 - CSDI on Electricity: MAE=4.8165, MSE=85.5670, MRE=2.5784
2024-06-03 04:04:39 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:04:39 [INFO]: Using the given device: cuda:0
2024-06-03 04:04:39 [INFO]: Model files will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_1/20240603_T040439
2024-06-03 04:04:39 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_1/20240603_T040439/tensorboard
2024-06-03 04:04:39 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 04:06:45 [INFO]: Epoch 001 - training loss: 0.6922, validation loss: 0.7366
2024-06-03 04:08:51 [INFO]: Epoch 002 - training loss: 0.4008, validation loss: 0.7173
2024-06-03 04:10:57 [INFO]: Epoch 003 - training loss: 0.3959, validation loss: 0.6614
2024-06-03 04:13:02 [INFO]: Epoch 004 - training loss: 0.4081, validation loss: 0.5971
2024-06-03 04:15:08 [INFO]: Epoch 005 - training loss: 0.3837, validation loss: 0.6048
2024-06-03 04:17:13 [INFO]: Epoch 006 - training loss: 0.3674, validation loss: 0.5731
2024-06-03 04:19:18 [INFO]: Epoch 007 - training loss: 0.3800, validation loss: 0.5433
2024-06-03 04:21:24 [INFO]: Epoch 008 - training loss: 0.3690, validation loss: 0.5420
2024-06-03 04:23:29 [INFO]: Epoch 009 - training loss: 0.3352, validation loss: 0.5246
2024-06-03 04:25:35 [INFO]: Epoch 010 - training loss: 0.3223, validation loss: 0.5309
2024-06-03 04:27:41 [INFO]: Epoch 011 - training loss: 0.3656, validation loss: 0.5196
2024-06-03 04:29:46 [INFO]: Epoch 012 - training loss: 0.3303, validation loss: 0.4879
2024-06-03 04:31:51 [INFO]: Epoch 013 - training loss: 0.3117, validation loss: 0.5024
2024-06-03 04:33:57 [INFO]: Epoch 014 - training loss: 0.3262, validation loss: 0.4864
2024-06-03 04:36:02 [INFO]: Epoch 015 - training loss: 0.3124, validation loss: 0.4726
2024-06-03 04:38:07 [INFO]: Epoch 016 - training loss: 0.3153, validation loss: 0.4656
2024-06-03 04:40:13 [INFO]: Epoch 017 - training loss: 0.3173, validation loss: 0.4600
2024-06-03 04:42:19 [INFO]: Epoch 018 - training loss: 0.3034, validation loss: 0.4619
2024-06-03 04:44:24 [INFO]: Epoch 019 - training loss: 0.2883, validation loss: 0.4733
2024-06-03 04:46:30 [INFO]: Epoch 020 - training loss: 0.2997, validation loss: 0.4535
2024-06-03 04:48:35 [INFO]: Epoch 021 - training loss: 0.3156, validation loss: 0.4512
2024-06-03 04:50:41 [INFO]: Epoch 022 - training loss: 0.2998, validation loss: 0.4436
2024-06-03 04:52:46 [INFO]: Epoch 023 - training loss: 0.2929, validation loss: 0.4356
2024-06-03 04:54:52 [INFO]: Epoch 024 - training loss: 0.2866, validation loss: 0.4485
2024-06-03 04:56:58 [INFO]: Epoch 025 - training loss: 0.3033, validation loss: 0.4187
2024-06-03 04:59:03 [INFO]: Epoch 026 - training loss: 0.2953, validation loss: 0.4201
2024-06-03 05:01:08 [INFO]: Epoch 027 - training loss: 0.2815, validation loss: 0.4035
2024-06-03 05:03:14 [INFO]: Epoch 028 - training loss: 0.2963, validation loss: 0.4002
2024-06-03 05:05:19 [INFO]: Epoch 029 - training loss: 0.2959, validation loss: 0.4075
2024-06-03 05:07:24 [INFO]: Epoch 030 - training loss: 0.2753, validation loss: 0.4185
2024-06-03 05:09:30 [INFO]: Epoch 031 - training loss: 0.2778, validation loss: 0.4119
2024-06-03 05:11:36 [INFO]: Epoch 032 - training loss: 0.3112, validation loss: 0.3984
2024-06-03 05:13:41 [INFO]: Epoch 033 - training loss: 0.2811, validation loss: 0.4006
2024-06-03 05:15:47 [INFO]: Epoch 034 - training loss: 0.2675, validation loss: 0.4128
2024-06-03 05:17:52 [INFO]: Epoch 035 - training loss: 0.2487, validation loss: 0.3998
2024-06-03 05:19:57 [INFO]: Epoch 036 - training loss: 0.2917, validation loss: 0.4087
2024-06-03 05:22:03 [INFO]: Epoch 037 - training loss: 0.2921, validation loss: 0.4086
2024-06-03 05:24:08 [INFO]: Epoch 038 - training loss: 0.2565, validation loss: 0.4221
2024-06-03 05:26:14 [INFO]: Epoch 039 - training loss: 0.2548, validation loss: 0.4043
2024-06-03 05:28:18 [INFO]: Epoch 040 - training loss: 0.2699, validation loss: 0.3856
2024-06-03 05:30:23 [INFO]: Epoch 041 - training loss: 0.2867, validation loss: 0.3883
2024-06-03 05:32:28 [INFO]: Epoch 042 - training loss: 0.2628, validation loss: 0.3979
2024-06-03 05:34:34 [INFO]: Epoch 043 - training loss: 0.2755, validation loss: 0.3876
2024-06-03 05:36:40 [INFO]: Epoch 044 - training loss: 0.2793, validation loss: 0.3879
2024-06-03 05:38:45 [INFO]: Epoch 045 - training loss: 0.2505, validation loss: 0.3750
2024-06-03 05:40:51 [INFO]: Epoch 046 - training loss: 0.2452, validation loss: 0.3901
2024-06-03 05:42:56 [INFO]: Epoch 047 - training loss: 0.2679, validation loss: 0.4060
2024-06-03 05:45:01 [INFO]: Epoch 048 - training loss: 0.2591, validation loss: 0.3802
2024-06-03 05:47:07 [INFO]: Epoch 049 - training loss: 0.2782, validation loss: 0.3800
2024-06-03 05:49:12 [INFO]: Epoch 050 - training loss: 0.2587, validation loss: 0.3736
2024-06-03 05:51:18 [INFO]: Epoch 051 - training loss: 0.2696, validation loss: 0.3781
2024-06-03 05:53:24 [INFO]: Epoch 052 - training loss: 0.2558, validation loss: 0.3760
2024-06-03 05:55:29 [INFO]: Epoch 053 - training loss: 0.2591, validation loss: 0.3851
2024-06-03 05:57:35 [INFO]: Epoch 054 - training loss: 0.2752, validation loss: 0.3589
2024-06-03 05:59:40 [INFO]: Epoch 055 - training loss: 0.2595, validation loss: 0.3669
2024-06-03 06:01:45 [INFO]: Epoch 056 - training loss: 0.2413, validation loss: 0.3690
2024-06-03 06:03:50 [INFO]: Epoch 057 - training loss: 0.2596, validation loss: 0.3703
2024-06-03 06:05:56 [INFO]: Epoch 058 - training loss: 0.2627, validation loss: 0.3723
2024-06-03 06:08:02 [INFO]: Epoch 059 - training loss: 0.2591, validation loss: 0.3554
2024-06-03 06:10:08 [INFO]: Epoch 060 - training loss: 0.2666, validation loss: 0.3617
2024-06-03 06:12:13 [INFO]: Epoch 061 - training loss: 0.2605, validation loss: 0.3593
2024-06-03 06:14:18 [INFO]: Epoch 062 - training loss: 0.2709, validation loss: 0.3494
2024-06-03 06:16:24 [INFO]: Epoch 063 - training loss: 0.2583, validation loss: 0.3529
2024-06-03 06:18:29 [INFO]: Epoch 064 - training loss: 0.2528, validation loss: 0.3645
2024-06-03 06:20:35 [INFO]: Epoch 065 - training loss: 0.2625, validation loss: 0.3602
2024-06-03 06:22:40 [INFO]: Epoch 066 - training loss: 0.2467, validation loss: 0.3556
2024-06-03 06:24:46 [INFO]: Epoch 067 - training loss: 0.2599, validation loss: 0.3516
2024-06-03 06:26:51 [INFO]: Epoch 068 - training loss: 0.2618, validation loss: 0.3472
2024-06-03 06:28:57 [INFO]: Epoch 069 - training loss: 0.2320, validation loss: 0.3565
2024-06-03 06:31:02 [INFO]: Epoch 070 - training loss: 0.2513, validation loss: 0.3576
2024-06-03 06:33:07 [INFO]: Epoch 071 - training loss: 0.2395, validation loss: 0.3553
2024-06-03 06:35:13 [INFO]: Epoch 072 - training loss: 0.2570, validation loss: 0.3681
2024-06-03 06:37:19 [INFO]: Epoch 073 - training loss: 0.2601, validation loss: 0.3553
2024-06-03 06:39:24 [INFO]: Epoch 074 - training loss: 0.2480, validation loss: 0.3626
2024-06-03 06:41:30 [INFO]: Epoch 075 - training loss: 0.2561, validation loss: 0.3580
2024-06-03 06:43:35 [INFO]: Epoch 076 - training loss: 0.2580, validation loss: 0.3578
2024-06-03 06:45:41 [INFO]: Epoch 077 - training loss: 0.2405, validation loss: 0.3467
2024-06-03 06:47:46 [INFO]: Epoch 078 - training loss: 0.2554, validation loss: 0.3507
2024-06-03 06:49:51 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.3393
2024-06-03 06:51:57 [INFO]: Epoch 080 - training loss: 0.2465, validation loss: 0.3497
2024-06-03 06:54:03 [INFO]: Epoch 081 - training loss: 0.2656, validation loss: 0.3525
2024-06-03 06:56:08 [INFO]: Epoch 082 - training loss: 0.2485, validation loss: 0.3583
2024-06-03 06:58:14 [INFO]: Epoch 083 - training loss: 0.2416, validation loss: 0.3541
2024-06-03 07:00:19 [INFO]: Epoch 084 - training loss: 0.2709, validation loss: 0.3570
2024-06-03 07:02:24 [INFO]: Epoch 085 - training loss: 0.2481, validation loss: 0.3653
2024-06-03 07:04:30 [INFO]: Epoch 086 - training loss: 0.2385, validation loss: 0.3510
2024-06-03 07:06:35 [INFO]: Epoch 087 - training loss: 0.2471, validation loss: 0.3484
2024-06-03 07:08:41 [INFO]: Epoch 088 - training loss: 0.2616, validation loss: 0.3338
2024-06-03 07:10:47 [INFO]: Epoch 089 - training loss: 0.2699, validation loss: 0.3613
2024-06-03 07:12:52 [INFO]: Epoch 090 - training loss: 0.2404, validation loss: 0.3480
2024-06-03 07:14:57 [INFO]: Epoch 091 - training loss: 0.2518, validation loss: 0.3427
2024-06-03 07:17:03 [INFO]: Epoch 092 - training loss: 0.2434, validation loss: 0.3501
2024-06-03 07:19:08 [INFO]: Epoch 093 - training loss: 0.2520, validation loss: 0.3417
2024-06-03 07:21:13 [INFO]: Epoch 094 - training loss: 0.2400, validation loss: 0.3522
2024-06-03 07:23:19 [INFO]: Epoch 095 - training loss: 0.2371, validation loss: 0.3505
2024-06-03 07:25:25 [INFO]: Epoch 096 - training loss: 0.2545, validation loss: 0.3433
2024-06-03 07:27:30 [INFO]: Epoch 097 - training loss: 0.2597, validation loss: 0.3543
2024-06-03 07:29:36 [INFO]: Epoch 098 - training loss: 0.2294, validation loss: 0.3541
2024-06-03 07:29:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:29:36 [INFO]: Finished training. The best model is from epoch#88.
2024-06-03 07:29:36 [INFO]: Saved the model to results_point_rate09/Electricity/CSDI_Electricity/round_1/20240603_T040439/CSDI.pypots
2024-06-03 07:46:41 [INFO]: Successfully saved to results_point_rate09/Electricity/CSDI_Electricity/round_1/imputation.pkl
2024-06-03 07:46:41 [INFO]: Round1 - CSDI on Electricity: MAE=0.8861, MSE=7.7700, MRE=0.4743
2024-06-03 07:46:41 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 07:46:41 [INFO]: Using the given device: cuda:0
2024-06-03 07:46:41 [INFO]: Model files will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_2/20240603_T074641
2024-06-03 07:46:41 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_2/20240603_T074641/tensorboard
2024-06-03 07:46:41 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 07:48:47 [INFO]: Epoch 001 - training loss: 0.6938, validation loss: 0.6164
2024-06-03 07:50:52 [INFO]: Epoch 002 - training loss: 0.4142, validation loss: 0.5951
2024-06-03 07:52:57 [INFO]: Epoch 003 - training loss: 0.4055, validation loss: 0.4925
2024-06-03 07:55:03 [INFO]: Epoch 004 - training loss: 0.3973, validation loss: 0.4473
2024-06-03 07:57:09 [INFO]: Epoch 005 - training loss: 0.3519, validation loss: 0.4481
2024-06-03 07:59:14 [INFO]: Epoch 006 - training loss: 0.3487, validation loss: 0.4583
2024-06-03 08:01:20 [INFO]: Epoch 007 - training loss: 0.3515, validation loss: 0.4471
2024-06-03 08:03:25 [INFO]: Epoch 008 - training loss: 0.3379, validation loss: 0.4700
2024-06-03 08:05:31 [INFO]: Epoch 009 - training loss: 0.3725, validation loss: 0.4571
2024-06-03 08:07:37 [INFO]: Epoch 010 - training loss: 0.3131, validation loss: 0.4847
2024-06-03 08:09:42 [INFO]: Epoch 011 - training loss: 0.3197, validation loss: 0.4740
2024-06-03 08:11:48 [INFO]: Epoch 012 - training loss: 0.3317, validation loss: 0.4603
2024-06-03 08:13:54 [INFO]: Epoch 013 - training loss: 0.2922, validation loss: 0.4677
2024-06-03 08:15:59 [INFO]: Epoch 014 - training loss: 0.2749, validation loss: 0.4942
2024-06-03 08:18:05 [INFO]: Epoch 015 - training loss: 0.3177, validation loss: 0.4769
2024-06-03 08:20:10 [INFO]: Epoch 016 - training loss: 0.3220, validation loss: 0.4718
2024-06-03 08:22:16 [INFO]: Epoch 017 - training loss: 0.3071, validation loss: 0.4766
2024-06-03 08:22:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:22:16 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 08:22:16 [INFO]: Saved the model to results_point_rate09/Electricity/CSDI_Electricity/round_2/20240603_T074641/CSDI.pypots
2024-06-03 08:39:22 [INFO]: Successfully saved to results_point_rate09/Electricity/CSDI_Electricity/round_2/imputation.pkl
2024-06-03 08:39:22 [INFO]: Round2 - CSDI on Electricity: MAE=1.2151, MSE=7.1705, MRE=0.6505
2024-06-03 08:39:22 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:39:22 [INFO]: Using the given device: cuda:0
2024-06-03 08:39:22 [INFO]: Model files will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_3/20240603_T083922
2024-06-03 08:39:22 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_3/20240603_T083922/tensorboard
2024-06-03 08:39:22 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 08:41:28 [INFO]: Epoch 001 - training loss: 0.6848, validation loss: 0.5761
2024-06-03 08:43:33 [INFO]: Epoch 002 - training loss: 0.3762, validation loss: 0.5516
2024-06-03 08:45:39 [INFO]: Epoch 003 - training loss: 0.4247, validation loss: 0.5177
2024-06-03 08:47:44 [INFO]: Epoch 004 - training loss: 0.3664, validation loss: 0.5016
2024-06-03 08:49:50 [INFO]: Epoch 005 - training loss: 0.3781, validation loss: 0.4565
2024-06-03 08:51:55 [INFO]: Epoch 006 - training loss: 0.3399, validation loss: 0.4146
2024-06-03 08:54:01 [INFO]: Epoch 007 - training loss: 0.3483, validation loss: 0.4159
2024-06-03 08:56:07 [INFO]: Epoch 008 - training loss: 0.3663, validation loss: 0.3929
2024-06-03 08:58:12 [INFO]: Epoch 009 - training loss: 0.3474, validation loss: 0.3866
2024-06-03 09:00:17 [INFO]: Epoch 010 - training loss: 0.3312, validation loss: 0.3800
2024-06-03 09:02:23 [INFO]: Epoch 011 - training loss: 0.3140, validation loss: 0.3625
2024-06-03 09:04:29 [INFO]: Epoch 012 - training loss: 0.3363, validation loss: 0.3581
2024-06-03 09:06:34 [INFO]: Epoch 013 - training loss: 0.2809, validation loss: 0.3553
2024-06-03 09:08:40 [INFO]: Epoch 014 - training loss: 0.3249, validation loss: 0.3592
2024-06-03 09:10:46 [INFO]: Epoch 015 - training loss: 0.2945, validation loss: 0.3451
2024-06-03 09:12:51 [INFO]: Epoch 016 - training loss: 0.3121, validation loss: 0.3440
2024-06-03 09:14:56 [INFO]: Epoch 017 - training loss: 0.3111, validation loss: 0.3403
2024-06-03 09:17:02 [INFO]: Epoch 018 - training loss: 0.3256, validation loss: 0.3301
2024-06-03 09:19:07 [INFO]: Epoch 019 - training loss: 0.2965, validation loss: 0.3328
2024-06-03 09:21:13 [INFO]: Epoch 020 - training loss: 0.3003, validation loss: 0.3213
2024-06-03 09:23:19 [INFO]: Epoch 021 - training loss: 0.2915, validation loss: 0.3193
2024-06-03 09:25:25 [INFO]: Epoch 022 - training loss: 0.2912, validation loss: 0.3139
2024-06-03 09:27:31 [INFO]: Epoch 023 - training loss: 0.3077, validation loss: 0.3140
2024-06-03 09:29:36 [INFO]: Epoch 024 - training loss: 0.2979, validation loss: 0.3147
2024-06-03 09:31:41 [INFO]: Epoch 025 - training loss: 0.2733, validation loss: 0.3050
2024-06-03 09:33:47 [INFO]: Epoch 026 - training loss: 0.2666, validation loss: 0.3091
2024-06-03 09:35:52 [INFO]: Epoch 027 - training loss: 0.2924, validation loss: 0.3023
2024-06-03 09:37:58 [INFO]: Epoch 028 - training loss: 0.2564, validation loss: 0.3023
2024-06-03 09:40:04 [INFO]: Epoch 029 - training loss: 0.2886, validation loss: 0.3018
2024-06-03 09:42:09 [INFO]: Epoch 030 - training loss: 0.2711, validation loss: 0.2983
2024-06-03 09:44:15 [INFO]: Epoch 031 - training loss: 0.2594, validation loss: 0.3000
2024-06-03 09:46:20 [INFO]: Epoch 032 - training loss: 0.2713, validation loss: 0.2975
2024-06-03 09:48:26 [INFO]: Epoch 033 - training loss: 0.2708, validation loss: 0.2985
2024-06-03 09:50:31 [INFO]: Epoch 034 - training loss: 0.2511, validation loss: 0.2953
2024-06-03 09:52:37 [INFO]: Epoch 035 - training loss: 0.2668, validation loss: 0.2976
2024-06-03 09:54:43 [INFO]: Epoch 036 - training loss: 0.2824, validation loss: 0.2972
2024-06-03 09:56:48 [INFO]: Epoch 037 - training loss: 0.2569, validation loss: 0.2931
2024-06-03 09:58:54 [INFO]: Epoch 038 - training loss: 0.2554, validation loss: 0.2961
2024-06-03 10:00:59 [INFO]: Epoch 039 - training loss: 0.2918, validation loss: 0.2914
2024-06-03 10:03:04 [INFO]: Epoch 040 - training loss: 0.2519, validation loss: 0.2880
2024-06-03 10:05:09 [INFO]: Epoch 041 - training loss: 0.2491, validation loss: 0.2899
2024-06-03 10:07:14 [INFO]: Epoch 042 - training loss: 0.2770, validation loss: 0.2947
2024-06-03 10:09:20 [INFO]: Epoch 043 - training loss: 0.2400, validation loss: 0.2894
2024-06-03 10:11:25 [INFO]: Epoch 044 - training loss: 0.2597, validation loss: 0.2847
2024-06-03 10:13:30 [INFO]: Epoch 045 - training loss: 0.2529, validation loss: 0.2830
2024-06-03 10:15:36 [INFO]: Epoch 046 - training loss: 0.2747, validation loss: 0.2838
2024-06-03 10:17:41 [INFO]: Epoch 047 - training loss: 0.2540, validation loss: 0.2775
2024-06-03 10:19:47 [INFO]: Epoch 048 - training loss: 0.2628, validation loss: 0.2837
2024-06-03 10:21:53 [INFO]: Epoch 049 - training loss: 0.2678, validation loss: 0.2759
2024-06-03 10:23:58 [INFO]: Epoch 050 - training loss: 0.2587, validation loss: 0.2766
2024-06-03 10:26:04 [INFO]: Epoch 051 - training loss: 0.2489, validation loss: 0.2741
2024-06-03 10:28:09 [INFO]: Epoch 052 - training loss: 0.2617, validation loss: 0.2802
2024-06-03 10:30:15 [INFO]: Epoch 053 - training loss: 0.2707, validation loss: 0.2749
2024-06-03 10:32:20 [INFO]: Epoch 054 - training loss: 0.2533, validation loss: 0.2781
2024-06-03 10:34:26 [INFO]: Epoch 055 - training loss: 0.2330, validation loss: 0.2726
2024-06-03 10:36:31 [INFO]: Epoch 056 - training loss: 0.2504, validation loss: 0.2684
2024-06-03 10:38:37 [INFO]: Epoch 057 - training loss: 0.2572, validation loss: 0.2717
2024-06-03 10:40:43 [INFO]: Epoch 058 - training loss: 0.2615, validation loss: 0.2770
2024-06-03 10:42:48 [INFO]: Epoch 059 - training loss: 0.2654, validation loss: 0.2719
2024-06-03 10:44:54 [INFO]: Epoch 060 - training loss: 0.2499, validation loss: 0.2712
2024-06-03 10:46:59 [INFO]: Epoch 061 - training loss: 0.2865, validation loss: 0.2747
2024-06-03 10:49:05 [INFO]: Epoch 062 - training loss: 0.2426, validation loss: 0.2697
2024-06-03 10:51:10 [INFO]: Epoch 063 - training loss: 0.2528, validation loss: 0.2683
2024-06-03 10:53:16 [INFO]: Epoch 064 - training loss: 0.2580, validation loss: 0.2718
2024-06-03 10:55:22 [INFO]: Epoch 065 - training loss: 0.2619, validation loss: 0.2616
2024-06-03 10:57:27 [INFO]: Epoch 066 - training loss: 0.2527, validation loss: 0.2702
2024-06-03 10:59:33 [INFO]: Epoch 067 - training loss: 0.2506, validation loss: 0.2625
2024-06-03 11:01:38 [INFO]: Epoch 068 - training loss: 0.2589, validation loss: 0.2597
2024-06-03 11:03:43 [INFO]: Epoch 069 - training loss: 0.2374, validation loss: 0.2660
2024-06-03 11:05:49 [INFO]: Epoch 070 - training loss: 0.2697, validation loss: 0.2669
2024-06-03 11:07:55 [INFO]: Epoch 071 - training loss: 0.2424, validation loss: 0.2631
2024-06-03 11:10:00 [INFO]: Epoch 072 - training loss: 0.2424, validation loss: 0.2645
2024-06-03 11:12:06 [INFO]: Epoch 073 - training loss: 0.2637, validation loss: 0.2676
2024-06-03 11:14:06 [INFO]: Epoch 074 - training loss: 0.2384, validation loss: 0.2700
2024-06-03 11:15:47 [INFO]: Epoch 075 - training loss: 0.2881, validation loss: 0.2574
2024-06-03 11:17:29 [INFO]: Epoch 076 - training loss: 0.2598, validation loss: 0.2591
2024-06-03 11:19:10 [INFO]: Epoch 077 - training loss: 0.2599, validation loss: 0.2594
2024-06-03 11:20:51 [INFO]: Epoch 078 - training loss: 0.2500, validation loss: 0.2611
2024-06-03 11:22:32 [INFO]: Epoch 079 - training loss: 0.2340, validation loss: 0.2622
2024-06-03 11:24:14 [INFO]: Epoch 080 - training loss: 0.2415, validation loss: 0.2566
2024-06-03 11:25:55 [INFO]: Epoch 081 - training loss: 0.2593, validation loss: 0.2696
2024-06-03 11:27:36 [INFO]: Epoch 082 - training loss: 0.2405, validation loss: 0.2593
2024-06-03 11:29:17 [INFO]: Epoch 083 - training loss: 0.2386, validation loss: 0.2564
2024-06-03 11:30:58 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.2557
2024-06-03 11:32:40 [INFO]: Epoch 085 - training loss: 0.2408, validation loss: 0.2652
2024-06-03 11:34:21 [INFO]: Epoch 086 - training loss: 0.2371, validation loss: 0.2539
2024-06-03 11:36:03 [INFO]: Epoch 087 - training loss: 0.2529, validation loss: 0.2558
2024-06-03 11:37:44 [INFO]: Epoch 088 - training loss: 0.2657, validation loss: 0.2616
2024-06-03 11:39:25 [INFO]: Epoch 089 - training loss: 0.2446, validation loss: 0.2513
2024-06-03 11:41:06 [INFO]: Epoch 090 - training loss: 0.2422, validation loss: 0.2542
2024-06-03 11:42:47 [INFO]: Epoch 091 - training loss: 0.2241, validation loss: 0.2565
2024-06-03 11:44:29 [INFO]: Epoch 092 - training loss: 0.2653, validation loss: 0.2509
2024-06-03 11:46:10 [INFO]: Epoch 093 - training loss: 0.2387, validation loss: 0.2518
2024-06-03 11:47:51 [INFO]: Epoch 094 - training loss: 0.2530, validation loss: 0.2513
2024-06-03 11:49:32 [INFO]: Epoch 095 - training loss: 0.2481, validation loss: 0.2531
2024-06-03 11:51:14 [INFO]: Epoch 096 - training loss: 0.2445, validation loss: 0.2548
2024-06-03 11:52:55 [INFO]: Epoch 097 - training loss: 0.2440, validation loss: 0.2535
2024-06-03 11:54:36 [INFO]: Epoch 098 - training loss: 0.2520, validation loss: 0.2530
2024-06-03 11:56:17 [INFO]: Epoch 099 - training loss: 0.2502, validation loss: 0.2516
2024-06-03 11:57:59 [INFO]: Epoch 100 - training loss: 0.2413, validation loss: 0.2467
2024-06-03 11:57:59 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 11:57:59 [INFO]: Saved the model to results_point_rate09/Electricity/CSDI_Electricity/round_3/20240603_T083922/CSDI.pypots
2024-06-03 12:11:48 [INFO]: Successfully saved to results_point_rate09/Electricity/CSDI_Electricity/round_3/imputation.pkl
2024-06-03 12:11:48 [INFO]: Round3 - CSDI on Electricity: MAE=0.6095, MSE=4.0809, MRE=0.3263
2024-06-03 12:11:48 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:11:48 [INFO]: Using the given device: cuda:0
2024-06-03 12:11:48 [INFO]: Model files will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_4/20240603_T121148
2024-06-03 12:11:48 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/CSDI_Electricity/round_4/20240603_T121148/tensorboard
2024-06-03 12:11:48 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 12:13:29 [INFO]: Epoch 001 - training loss: 0.7047, validation loss: 0.6688
2024-06-03 12:15:10 [INFO]: Epoch 002 - training loss: 0.4214, validation loss: 0.6934
2024-06-03 12:16:51 [INFO]: Epoch 003 - training loss: 0.3945, validation loss: 0.6553
2024-06-03 12:18:33 [INFO]: Epoch 004 - training loss: 0.3680, validation loss: 0.6245
2024-06-03 12:20:14 [INFO]: Epoch 005 - training loss: 0.3828, validation loss: 0.5718
2024-06-03 12:21:55 [INFO]: Epoch 006 - training loss: 0.3770, validation loss: 0.5499
2024-06-03 12:23:37 [INFO]: Epoch 007 - training loss: 0.3762, validation loss: 0.5288
2024-06-03 12:25:18 [INFO]: Epoch 008 - training loss: 0.3626, validation loss: 0.4816
2024-06-03 12:26:59 [INFO]: Epoch 009 - training loss: 0.3387, validation loss: 0.4512
2024-06-03 12:28:40 [INFO]: Epoch 010 - training loss: 0.3220, validation loss: 0.4089
2024-06-03 12:30:22 [INFO]: Epoch 011 - training loss: 0.3640, validation loss: 0.3936
2024-06-03 12:32:03 [INFO]: Epoch 012 - training loss: 0.3417, validation loss: 0.3883
2024-06-03 12:33:44 [INFO]: Epoch 013 - training loss: 0.3075, validation loss: 0.3867
2024-06-03 12:35:26 [INFO]: Epoch 014 - training loss: 0.3038, validation loss: 0.3941
2024-06-03 12:37:07 [INFO]: Epoch 015 - training loss: 0.3140, validation loss: 0.3800
2024-06-03 12:38:48 [INFO]: Epoch 016 - training loss: 0.3127, validation loss: 0.3876
2024-06-03 12:40:30 [INFO]: Epoch 017 - training loss: 0.3106, validation loss: 0.3854
2024-06-03 12:42:11 [INFO]: Epoch 018 - training loss: 0.3268, validation loss: 0.3798
2024-06-03 12:43:52 [INFO]: Epoch 019 - training loss: 0.2991, validation loss: 0.3905
2024-06-03 12:45:33 [INFO]: Epoch 020 - training loss: 0.2746, validation loss: 0.3855
2024-06-03 12:47:15 [INFO]: Epoch 021 - training loss: 0.2873, validation loss: 0.3805
2024-06-03 12:48:56 [INFO]: Epoch 022 - training loss: 0.3080, validation loss: 0.3701
2024-06-03 12:50:37 [INFO]: Epoch 023 - training loss: 0.2775, validation loss: 0.3650
2024-06-03 12:52:19 [INFO]: Epoch 024 - training loss: 0.2765, validation loss: 0.3670
2024-06-03 12:54:00 [INFO]: Epoch 025 - training loss: 0.2985, validation loss: 0.3637
2024-06-03 12:55:41 [INFO]: Epoch 026 - training loss: 0.2975, validation loss: 0.3654
2024-06-03 12:57:23 [INFO]: Epoch 027 - training loss: 0.2822, validation loss: 0.3585
2024-06-03 12:59:04 [INFO]: Epoch 028 - training loss: 0.2787, validation loss: 0.3456
2024-06-03 13:00:45 [INFO]: Epoch 029 - training loss: 0.2574, validation loss: 0.3457
2024-06-03 13:02:27 [INFO]: Epoch 030 - training loss: 0.2717, validation loss: 0.3456
2024-06-03 13:04:08 [INFO]: Epoch 031 - training loss: 0.2723, validation loss: 0.3409
2024-06-03 13:05:49 [INFO]: Epoch 032 - training loss: 0.2807, validation loss: 0.3427
2024-06-03 13:07:30 [INFO]: Epoch 033 - training loss: 0.2846, validation loss: 0.3425
2024-06-03 13:09:12 [INFO]: Epoch 034 - training loss: 0.2922, validation loss: 0.3413
2024-06-03 13:10:53 [INFO]: Epoch 035 - training loss: 0.3221, validation loss: 0.3342
2024-06-03 13:12:34 [INFO]: Epoch 036 - training loss: 0.2860, validation loss: 0.3392
2024-06-03 13:14:16 [INFO]: Epoch 037 - training loss: 0.2738, validation loss: 0.3403
2024-06-03 13:15:57 [INFO]: Epoch 038 - training loss: 0.2577, validation loss: 0.3297
2024-06-03 13:17:38 [INFO]: Epoch 039 - training loss: 0.2729, validation loss: 0.3334
2024-06-03 13:19:20 [INFO]: Epoch 040 - training loss: 0.2376, validation loss: 0.3350
2024-06-03 13:21:01 [INFO]: Epoch 041 - training loss: 0.2467, validation loss: 0.3313
2024-06-03 13:22:42 [INFO]: Epoch 042 - training loss: 0.2260, validation loss: 0.3334
2024-06-03 13:24:23 [INFO]: Epoch 043 - training loss: 0.2773, validation loss: 0.3259
2024-06-03 13:26:05 [INFO]: Epoch 044 - training loss: 0.2570, validation loss: 0.3205
2024-06-03 13:27:46 [INFO]: Epoch 045 - training loss: 0.2691, validation loss: 0.3242
2024-06-03 13:29:27 [INFO]: Epoch 046 - training loss: 0.2671, validation loss: 0.3197
2024-06-03 13:31:09 [INFO]: Epoch 047 - training loss: 0.2652, validation loss: 0.3169
2024-06-03 13:32:50 [INFO]: Epoch 048 - training loss: 0.2579, validation loss: 0.3150
2024-06-03 13:34:31 [INFO]: Epoch 049 - training loss: 0.2773, validation loss: 0.3109
2024-06-03 13:36:13 [INFO]: Epoch 050 - training loss: 0.2840, validation loss: 0.3127
2024-06-03 13:37:54 [INFO]: Epoch 051 - training loss: 0.2731, validation loss: 0.3082
2024-06-03 13:39:35 [INFO]: Epoch 052 - training loss: 0.2715, validation loss: 0.3054
2024-06-03 13:41:16 [INFO]: Epoch 053 - training loss: 0.2608, validation loss: 0.3170
2024-06-03 13:42:58 [INFO]: Epoch 054 - training loss: 0.2813, validation loss: 0.3066
2024-06-03 13:44:39 [INFO]: Epoch 055 - training loss: 0.2571, validation loss: 0.3034
2024-06-03 13:46:20 [INFO]: Epoch 056 - training loss: 0.2741, validation loss: 0.2982
2024-06-03 13:48:02 [INFO]: Epoch 057 - training loss: 0.2675, validation loss: 0.3077
2024-06-03 13:49:43 [INFO]: Epoch 058 - training loss: 0.2630, validation loss: 0.2993
2024-06-03 13:51:24 [INFO]: Epoch 059 - training loss: 0.2838, validation loss: 0.2980
2024-06-03 13:53:06 [INFO]: Epoch 060 - training loss: 0.2497, validation loss: 0.2966
2024-06-03 13:54:47 [INFO]: Epoch 061 - training loss: 0.2343, validation loss: 0.3100
2024-06-03 13:56:28 [INFO]: Epoch 062 - training loss: 0.2528, validation loss: 0.2948
2024-06-03 13:58:10 [INFO]: Epoch 063 - training loss: 0.2619, validation loss: 0.2910
2024-06-03 13:59:51 [INFO]: Epoch 064 - training loss: 0.2500, validation loss: 0.2903
2024-06-03 14:01:32 [INFO]: Epoch 065 - training loss: 0.2619, validation loss: 0.2919
2024-06-03 14:03:14 [INFO]: Epoch 066 - training loss: 0.2480, validation loss: 0.2885
2024-06-03 14:04:55 [INFO]: Epoch 067 - training loss: 0.2586, validation loss: 0.2862
2024-06-03 14:06:36 [INFO]: Epoch 068 - training loss: 0.2595, validation loss: 0.2902
2024-06-03 14:08:18 [INFO]: Epoch 069 - training loss: 0.2410, validation loss: 0.2902
2024-06-03 14:09:59 [INFO]: Epoch 070 - training loss: 0.2546, validation loss: 0.2827
2024-06-03 14:11:40 [INFO]: Epoch 071 - training loss: 0.2474, validation loss: 0.2840
2024-06-03 14:13:22 [INFO]: Epoch 072 - training loss: 0.2595, validation loss: 0.2844
2024-06-03 14:15:03 [INFO]: Epoch 073 - training loss: 0.2424, validation loss: 0.2803
2024-06-03 14:16:44 [INFO]: Epoch 074 - training loss: 0.2505, validation loss: 0.2790
2024-06-03 14:18:26 [INFO]: Epoch 075 - training loss: 0.2343, validation loss: 0.2826
2024-06-03 14:20:07 [INFO]: Epoch 076 - training loss: 0.2352, validation loss: 0.2810
2024-06-03 14:21:48 [INFO]: Epoch 077 - training loss: 0.2360, validation loss: 0.2778
2024-06-03 14:23:30 [INFO]: Epoch 078 - training loss: 0.2384, validation loss: 0.2759
2024-06-03 14:25:11 [INFO]: Epoch 079 - training loss: 0.2504, validation loss: 0.2736
2024-06-03 14:26:52 [INFO]: Epoch 080 - training loss: 0.2439, validation loss: 0.2770
2024-06-03 14:28:34 [INFO]: Epoch 081 - training loss: 0.2527, validation loss: 0.2728
2024-06-03 14:30:15 [INFO]: Epoch 082 - training loss: 0.2470, validation loss: 0.2745
2024-06-03 14:31:56 [INFO]: Epoch 083 - training loss: 0.2626, validation loss: 0.2712
2024-06-03 14:33:38 [INFO]: Epoch 084 - training loss: 0.2484, validation loss: 0.2747
2024-06-03 14:35:19 [INFO]: Epoch 085 - training loss: 0.2286, validation loss: 0.2717
2024-06-03 14:37:00 [INFO]: Epoch 086 - training loss: 0.2283, validation loss: 0.2790
2024-06-03 14:38:41 [INFO]: Epoch 087 - training loss: 0.2439, validation loss: 0.2668
2024-06-03 14:40:23 [INFO]: Epoch 088 - training loss: 0.2369, validation loss: 0.2656
2024-06-03 14:42:04 [INFO]: Epoch 089 - training loss: 0.2271, validation loss: 0.2692
2024-06-03 14:43:45 [INFO]: Epoch 090 - training loss: 0.2365, validation loss: 0.2727
2024-06-03 14:45:27 [INFO]: Epoch 091 - training loss: 0.2340, validation loss: 0.2719
2024-06-03 14:47:08 [INFO]: Epoch 092 - training loss: 0.2437, validation loss: 0.2749
2024-06-03 14:48:49 [INFO]: Epoch 093 - training loss: 0.2215, validation loss: 0.2694
2024-06-03 14:50:31 [INFO]: Epoch 094 - training loss: 0.2338, validation loss: 0.2710
2024-06-03 14:52:12 [INFO]: Epoch 095 - training loss: 0.2501, validation loss: 0.2676
2024-06-03 14:53:53 [INFO]: Epoch 096 - training loss: 0.2629, validation loss: 0.2669
2024-06-03 14:55:35 [INFO]: Epoch 097 - training loss: 0.2373, validation loss: 0.2664
2024-06-03 14:57:16 [INFO]: Epoch 098 - training loss: 0.2416, validation loss: 0.2689
2024-06-03 14:57:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 14:57:16 [INFO]: Finished training. The best model is from epoch#88.
2024-06-03 14:57:16 [INFO]: Saved the model to results_point_rate09/Electricity/CSDI_Electricity/round_4/20240603_T121148/CSDI.pypots
2024-06-03 15:11:06 [INFO]: Successfully saved to results_point_rate09/Electricity/CSDI_Electricity/round_4/imputation.pkl
2024-06-03 15:11:06 [INFO]: Round4 - CSDI on Electricity: MAE=1.6332, MSE=66.9408, MRE=0.8743
2024-06-03 15:11:06 [INFO]: Done! Final results:
Averaged CSDI (43,185 params) on Electricity: MAE=1.8321 ± 1.5307920147097107, MSE=34.3058 ± 34.77577370601107, MRE=0.9808 ± 0.8194766456684106, average inference time=947.14
