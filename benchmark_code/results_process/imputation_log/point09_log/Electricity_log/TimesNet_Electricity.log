2024-06-03 01:15:38 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:15:38 [INFO]: Using the given device: cuda:0
2024-06-03 01:15:38 [INFO]: Model files will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_0/20240603_T011538
2024-06-03 01:15:38 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_0/20240603_T011538/tensorboard
2024-06-03 01:15:41 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-03 01:15:56 [INFO]: Epoch 001 - training loss: 0.7780, validation loss: 3.5487
2024-06-03 01:16:07 [INFO]: Epoch 002 - training loss: 0.4605, validation loss: 3.4137
2024-06-03 01:16:19 [INFO]: Epoch 003 - training loss: 0.4031, validation loss: 3.3505
2024-06-03 01:16:31 [INFO]: Epoch 004 - training loss: 0.3419, validation loss: 3.2222
2024-06-03 01:16:43 [INFO]: Epoch 005 - training loss: 0.2954, validation loss: 3.1756
2024-06-03 01:16:54 [INFO]: Epoch 006 - training loss: 0.2742, validation loss: 3.1503
2024-06-03 01:17:06 [INFO]: Epoch 007 - training loss: 0.2617, validation loss: 3.1200
2024-06-03 01:17:18 [INFO]: Epoch 008 - training loss: 0.2519, validation loss: 3.1153
2024-06-03 01:17:30 [INFO]: Epoch 009 - training loss: 0.2497, validation loss: 3.0881
2024-06-03 01:17:41 [INFO]: Epoch 010 - training loss: 0.2408, validation loss: 3.0879
2024-06-03 01:17:53 [INFO]: Epoch 011 - training loss: 0.2345, validation loss: 3.0711
2024-06-03 01:18:05 [INFO]: Epoch 012 - training loss: 0.2297, validation loss: 3.0512
2024-06-03 01:18:16 [INFO]: Epoch 013 - training loss: 0.2265, validation loss: 3.0439
2024-06-03 01:18:28 [INFO]: Epoch 014 - training loss: 0.2209, validation loss: 3.0246
2024-06-03 01:18:39 [INFO]: Epoch 015 - training loss: 0.2186, validation loss: 3.0158
2024-06-03 01:18:51 [INFO]: Epoch 016 - training loss: 0.2166, validation loss: 3.0232
2024-06-03 01:19:03 [INFO]: Epoch 017 - training loss: 0.2125, validation loss: 3.0257
2024-06-03 01:19:15 [INFO]: Epoch 018 - training loss: 0.2075, validation loss: 3.0166
2024-06-03 01:19:27 [INFO]: Epoch 019 - training loss: 0.2060, validation loss: 3.0041
2024-06-03 01:19:38 [INFO]: Epoch 020 - training loss: 0.2046, validation loss: 2.9974
2024-06-03 01:19:50 [INFO]: Epoch 021 - training loss: 0.2022, validation loss: 2.9873
2024-06-03 01:20:02 [INFO]: Epoch 022 - training loss: 0.2004, validation loss: 2.9920
2024-06-03 01:20:13 [INFO]: Epoch 023 - training loss: 0.1986, validation loss: 2.9723
2024-06-03 01:20:25 [INFO]: Epoch 024 - training loss: 0.1967, validation loss: 2.9633
2024-06-03 01:20:37 [INFO]: Epoch 025 - training loss: 0.1957, validation loss: 2.9551
2024-06-03 01:20:48 [INFO]: Epoch 026 - training loss: 0.1919, validation loss: 2.9549
2024-06-03 01:21:00 [INFO]: Epoch 027 - training loss: 0.1911, validation loss: 2.9482
2024-06-03 01:21:12 [INFO]: Epoch 028 - training loss: 0.1890, validation loss: 2.9518
2024-06-03 01:21:24 [INFO]: Epoch 029 - training loss: 0.1850, validation loss: 2.9431
2024-06-03 01:21:36 [INFO]: Epoch 030 - training loss: 0.1846, validation loss: 2.9367
2024-06-03 01:21:47 [INFO]: Epoch 031 - training loss: 0.1833, validation loss: 2.9269
2024-06-03 01:21:59 [INFO]: Epoch 032 - training loss: 0.1828, validation loss: 2.9182
2024-06-03 01:22:10 [INFO]: Epoch 033 - training loss: 0.1811, validation loss: 2.9095
2024-06-03 01:22:22 [INFO]: Epoch 034 - training loss: 0.1776, validation loss: 2.9009
2024-06-03 01:22:33 [INFO]: Epoch 035 - training loss: 0.1764, validation loss: 2.8915
2024-06-03 01:22:45 [INFO]: Epoch 036 - training loss: 0.1720, validation loss: 2.8881
2024-06-03 01:22:57 [INFO]: Epoch 037 - training loss: 0.1723, validation loss: 2.8906
2024-06-03 01:23:08 [INFO]: Epoch 038 - training loss: 0.1701, validation loss: 2.8759
2024-06-03 01:23:20 [INFO]: Epoch 039 - training loss: 0.1694, validation loss: 2.8790
2024-06-03 01:23:31 [INFO]: Epoch 040 - training loss: 0.1668, validation loss: 2.8650
2024-06-03 01:23:43 [INFO]: Epoch 041 - training loss: 0.1635, validation loss: 2.8671
2024-06-03 01:23:55 [INFO]: Epoch 042 - training loss: 0.1654, validation loss: 2.8854
2024-06-03 01:24:07 [INFO]: Epoch 043 - training loss: 0.1616, validation loss: 2.8693
2024-06-03 01:24:19 [INFO]: Epoch 044 - training loss: 0.1620, validation loss: 2.8657
2024-06-03 01:24:30 [INFO]: Epoch 045 - training loss: 0.1583, validation loss: 2.8635
2024-06-03 01:24:41 [INFO]: Epoch 046 - training loss: 0.1586, validation loss: 2.8624
2024-06-03 01:24:53 [INFO]: Epoch 047 - training loss: 0.1572, validation loss: 2.8558
2024-06-03 01:25:05 [INFO]: Epoch 048 - training loss: 0.1562, validation loss: 2.8535
2024-06-03 01:25:17 [INFO]: Epoch 049 - training loss: 0.1536, validation loss: 2.8593
2024-06-03 01:25:28 [INFO]: Epoch 050 - training loss: 0.1536, validation loss: 2.8581
2024-06-03 01:25:40 [INFO]: Epoch 051 - training loss: 0.1526, validation loss: 2.8588
2024-06-03 01:25:52 [INFO]: Epoch 052 - training loss: 0.1512, validation loss: 2.8551
2024-06-03 01:26:04 [INFO]: Epoch 053 - training loss: 0.1493, validation loss: 2.8430
2024-06-03 01:26:15 [INFO]: Epoch 054 - training loss: 0.1479, validation loss: 2.8536
2024-06-03 01:26:25 [INFO]: Epoch 055 - training loss: 0.1458, validation loss: 2.8680
2024-06-03 01:26:36 [INFO]: Epoch 056 - training loss: 0.1465, validation loss: 2.8587
2024-06-03 01:26:47 [INFO]: Epoch 057 - training loss: 0.1453, validation loss: 2.8502
2024-06-03 01:26:58 [INFO]: Epoch 058 - training loss: 0.1437, validation loss: 2.8652
2024-06-03 01:27:10 [INFO]: Epoch 059 - training loss: 0.1409, validation loss: 2.8636
2024-06-03 01:27:22 [INFO]: Epoch 060 - training loss: 0.1422, validation loss: 2.8671
2024-06-03 01:27:33 [INFO]: Epoch 061 - training loss: 0.1412, validation loss: 2.8572
2024-06-03 01:27:45 [INFO]: Epoch 062 - training loss: 0.1389, validation loss: 2.8690
2024-06-03 01:27:56 [INFO]: Epoch 063 - training loss: 0.1402, validation loss: 2.8635
2024-06-03 01:27:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:27:56 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 01:27:57 [INFO]: Saved the model to results_point_rate09/Electricity/TimesNet_Electricity/round_0/20240603_T011538/TimesNet.pypots
2024-06-03 01:28:00 [INFO]: Successfully saved to results_point_rate09/Electricity/TimesNet_Electricity/round_0/imputation.pkl
2024-06-03 01:28:00 [INFO]: Round0 - TimesNet on Electricity: MAE=1.3226, MSE=3.9785, MRE=0.7080
2024-06-03 01:28:00 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:28:00 [INFO]: Using the given device: cuda:0
2024-06-03 01:28:00 [INFO]: Model files will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_1/20240603_T012800
2024-06-03 01:28:00 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_1/20240603_T012800/tensorboard
2024-06-03 01:28:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-03 01:28:14 [INFO]: Epoch 001 - training loss: 0.7828, validation loss: 3.5737
2024-06-03 01:28:26 [INFO]: Epoch 002 - training loss: 0.4582, validation loss: 3.4422
2024-06-03 01:28:37 [INFO]: Epoch 003 - training loss: 0.3986, validation loss: 3.3291
2024-06-03 01:28:49 [INFO]: Epoch 004 - training loss: 0.3375, validation loss: 3.2262
2024-06-03 01:29:01 [INFO]: Epoch 005 - training loss: 0.2979, validation loss: 3.1695
2024-06-03 01:29:12 [INFO]: Epoch 006 - training loss: 0.2750, validation loss: 3.1558
2024-06-03 01:29:24 [INFO]: Epoch 007 - training loss: 0.2588, validation loss: 3.1365
2024-06-03 01:29:36 [INFO]: Epoch 008 - training loss: 0.2525, validation loss: 3.1206
2024-06-03 01:29:47 [INFO]: Epoch 009 - training loss: 0.2453, validation loss: 3.0886
2024-06-03 01:29:59 [INFO]: Epoch 010 - training loss: 0.2402, validation loss: 3.0741
2024-06-03 01:30:10 [INFO]: Epoch 011 - training loss: 0.2342, validation loss: 3.0668
2024-06-03 01:30:20 [INFO]: Epoch 012 - training loss: 0.2299, validation loss: 3.0476
2024-06-03 01:30:31 [INFO]: Epoch 013 - training loss: 0.2234, validation loss: 3.0133
2024-06-03 01:30:42 [INFO]: Epoch 014 - training loss: 0.2183, validation loss: 3.0152
2024-06-03 01:30:53 [INFO]: Epoch 015 - training loss: 0.2137, validation loss: 3.0148
2024-06-03 01:31:03 [INFO]: Epoch 016 - training loss: 0.2122, validation loss: 3.0026
2024-06-03 01:31:14 [INFO]: Epoch 017 - training loss: 0.2084, validation loss: 2.9947
2024-06-03 01:31:25 [INFO]: Epoch 018 - training loss: 0.2044, validation loss: 2.9904
2024-06-03 01:31:35 [INFO]: Epoch 019 - training loss: 0.2030, validation loss: 2.9754
2024-06-03 01:31:46 [INFO]: Epoch 020 - training loss: 0.1997, validation loss: 2.9785
2024-06-03 01:31:57 [INFO]: Epoch 021 - training loss: 0.1983, validation loss: 2.9684
2024-06-03 01:32:07 [INFO]: Epoch 022 - training loss: 0.1973, validation loss: 2.9527
2024-06-03 01:32:17 [INFO]: Epoch 023 - training loss: 0.1961, validation loss: 2.9552
2024-06-03 01:32:28 [INFO]: Epoch 024 - training loss: 0.1925, validation loss: 2.9449
2024-06-03 01:32:38 [INFO]: Epoch 025 - training loss: 0.1914, validation loss: 2.9482
2024-06-03 01:32:49 [INFO]: Epoch 026 - training loss: 0.1925, validation loss: 2.9341
2024-06-03 01:32:59 [INFO]: Epoch 027 - training loss: 0.1895, validation loss: 2.9339
2024-06-03 01:33:10 [INFO]: Epoch 028 - training loss: 0.1859, validation loss: 2.9296
2024-06-03 01:33:21 [INFO]: Epoch 029 - training loss: 0.1883, validation loss: 2.9318
2024-06-03 01:33:32 [INFO]: Epoch 030 - training loss: 0.1871, validation loss: 2.9105
2024-06-03 01:33:42 [INFO]: Epoch 031 - training loss: 0.1834, validation loss: 2.9094
2024-06-03 01:33:53 [INFO]: Epoch 032 - training loss: 0.1821, validation loss: 2.9169
2024-06-03 01:34:04 [INFO]: Epoch 033 - training loss: 0.1818, validation loss: 2.8957
2024-06-03 01:34:15 [INFO]: Epoch 034 - training loss: 0.1787, validation loss: 2.8972
2024-06-03 01:34:25 [INFO]: Epoch 035 - training loss: 0.1774, validation loss: 2.8981
2024-06-03 01:34:36 [INFO]: Epoch 036 - training loss: 0.1756, validation loss: 2.9002
2024-06-03 01:34:46 [INFO]: Epoch 037 - training loss: 0.1750, validation loss: 2.8921
2024-06-03 01:34:57 [INFO]: Epoch 038 - training loss: 0.1718, validation loss: 2.8908
2024-06-03 01:35:07 [INFO]: Epoch 039 - training loss: 0.1695, validation loss: 2.8810
2024-06-03 01:35:18 [INFO]: Epoch 040 - training loss: 0.1724, validation loss: 2.8696
2024-06-03 01:35:29 [INFO]: Epoch 041 - training loss: 0.1667, validation loss: 2.8744
2024-06-03 01:35:39 [INFO]: Epoch 042 - training loss: 0.1668, validation loss: 2.8612
2024-06-03 01:35:50 [INFO]: Epoch 043 - training loss: 0.1627, validation loss: 2.8699
2024-06-03 01:36:01 [INFO]: Epoch 044 - training loss: 0.1647, validation loss: 2.8634
2024-06-03 01:36:12 [INFO]: Epoch 045 - training loss: 0.1643, validation loss: 2.8700
2024-06-03 01:36:22 [INFO]: Epoch 046 - training loss: 0.1604, validation loss: 2.8593
2024-06-03 01:36:33 [INFO]: Epoch 047 - training loss: 0.1602, validation loss: 2.8676
2024-06-03 01:36:44 [INFO]: Epoch 048 - training loss: 0.1574, validation loss: 2.8575
2024-06-03 01:36:54 [INFO]: Epoch 049 - training loss: 0.1569, validation loss: 2.8540
2024-06-03 01:37:05 [INFO]: Epoch 050 - training loss: 0.1547, validation loss: 2.8599
2024-06-03 01:37:15 [INFO]: Epoch 051 - training loss: 0.1541, validation loss: 2.8640
2024-06-03 01:37:24 [INFO]: Epoch 052 - training loss: 0.1552, validation loss: 2.8654
2024-06-03 01:37:35 [INFO]: Epoch 053 - training loss: 0.1506, validation loss: 2.8574
2024-06-03 01:37:45 [INFO]: Epoch 054 - training loss: 0.1501, validation loss: 2.8703
2024-06-03 01:37:56 [INFO]: Epoch 055 - training loss: 0.1492, validation loss: 2.8715
2024-06-03 01:38:07 [INFO]: Epoch 056 - training loss: 0.1484, validation loss: 2.8787
2024-06-03 01:38:17 [INFO]: Epoch 057 - training loss: 0.1460, validation loss: 2.8698
2024-06-03 01:38:28 [INFO]: Epoch 058 - training loss: 0.1451, validation loss: 2.8719
2024-06-03 01:38:39 [INFO]: Epoch 059 - training loss: 0.1456, validation loss: 2.8754
2024-06-03 01:38:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:38:39 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 01:38:39 [INFO]: Saved the model to results_point_rate09/Electricity/TimesNet_Electricity/round_1/20240603_T012800/TimesNet.pypots
2024-06-03 01:38:41 [INFO]: Successfully saved to results_point_rate09/Electricity/TimesNet_Electricity/round_1/imputation.pkl
2024-06-03 01:38:41 [INFO]: Round1 - TimesNet on Electricity: MAE=1.3122, MSE=3.8729, MRE=0.7024
2024-06-03 01:38:41 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:38:41 [INFO]: Using the given device: cuda:0
2024-06-03 01:38:41 [INFO]: Model files will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_2/20240603_T013841
2024-06-03 01:38:41 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_2/20240603_T013841/tensorboard
2024-06-03 01:38:43 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-03 01:38:54 [INFO]: Epoch 001 - training loss: 0.7653, validation loss: 3.5739
2024-06-03 01:39:04 [INFO]: Epoch 002 - training loss: 0.4567, validation loss: 3.4100
2024-06-03 01:39:15 [INFO]: Epoch 003 - training loss: 0.3976, validation loss: 3.3638
2024-06-03 01:39:25 [INFO]: Epoch 004 - training loss: 0.3386, validation loss: 3.2393
2024-06-03 01:39:36 [INFO]: Epoch 005 - training loss: 0.2941, validation loss: 3.1959
2024-06-03 01:39:46 [INFO]: Epoch 006 - training loss: 0.2729, validation loss: 3.1466
2024-06-03 01:39:57 [INFO]: Epoch 007 - training loss: 0.2588, validation loss: 3.1319
2024-06-03 01:40:08 [INFO]: Epoch 008 - training loss: 0.2518, validation loss: 3.1090
2024-06-03 01:40:18 [INFO]: Epoch 009 - training loss: 0.2451, validation loss: 3.0960
2024-06-03 01:40:28 [INFO]: Epoch 010 - training loss: 0.2389, validation loss: 3.0818
2024-06-03 01:40:39 [INFO]: Epoch 011 - training loss: 0.2308, validation loss: 3.0540
2024-06-03 01:40:50 [INFO]: Epoch 012 - training loss: 0.2266, validation loss: 3.0473
2024-06-03 01:41:01 [INFO]: Epoch 013 - training loss: 0.2228, validation loss: 3.0353
2024-06-03 01:41:11 [INFO]: Epoch 014 - training loss: 0.2193, validation loss: 3.0234
2024-06-03 01:41:22 [INFO]: Epoch 015 - training loss: 0.2154, validation loss: 3.0188
2024-06-03 01:41:33 [INFO]: Epoch 016 - training loss: 0.2164, validation loss: 3.0095
2024-06-03 01:41:43 [INFO]: Epoch 017 - training loss: 0.2125, validation loss: 2.9991
2024-06-03 01:41:52 [INFO]: Epoch 018 - training loss: 0.2110, validation loss: 3.0114
2024-06-03 01:42:00 [INFO]: Epoch 019 - training loss: 0.2067, validation loss: 3.0069
2024-06-03 01:42:10 [INFO]: Epoch 020 - training loss: 0.2038, validation loss: 2.9944
2024-06-03 01:42:21 [INFO]: Epoch 021 - training loss: 0.2018, validation loss: 2.9865
2024-06-03 01:42:32 [INFO]: Epoch 022 - training loss: 0.1990, validation loss: 2.9777
2024-06-03 01:42:42 [INFO]: Epoch 023 - training loss: 0.1980, validation loss: 2.9706
2024-06-03 01:42:53 [INFO]: Epoch 024 - training loss: 0.1932, validation loss: 2.9635
2024-06-03 01:43:04 [INFO]: Epoch 025 - training loss: 0.1926, validation loss: 2.9613
2024-06-03 01:43:14 [INFO]: Epoch 026 - training loss: 0.1876, validation loss: 2.9528
2024-06-03 01:43:25 [INFO]: Epoch 027 - training loss: 0.1889, validation loss: 2.9526
2024-06-03 01:43:35 [INFO]: Epoch 028 - training loss: 0.1862, validation loss: 2.9515
2024-06-03 01:43:46 [INFO]: Epoch 029 - training loss: 0.1865, validation loss: 2.9465
2024-06-03 01:43:57 [INFO]: Epoch 030 - training loss: 0.1824, validation loss: 2.9291
2024-06-03 01:44:07 [INFO]: Epoch 031 - training loss: 0.1826, validation loss: 2.9226
2024-06-03 01:44:18 [INFO]: Epoch 032 - training loss: 0.1797, validation loss: 2.9161
2024-06-03 01:44:29 [INFO]: Epoch 033 - training loss: 0.1790, validation loss: 2.9092
2024-06-03 01:44:39 [INFO]: Epoch 034 - training loss: 0.1761, validation loss: 2.8971
2024-06-03 01:44:50 [INFO]: Epoch 035 - training loss: 0.1762, validation loss: 2.8942
2024-06-03 01:45:00 [INFO]: Epoch 036 - training loss: 0.1753, validation loss: 2.8932
2024-06-03 01:45:11 [INFO]: Epoch 037 - training loss: 0.1715, validation loss: 2.8835
2024-06-03 01:45:21 [INFO]: Epoch 038 - training loss: 0.1702, validation loss: 2.8799
2024-06-03 01:45:32 [INFO]: Epoch 039 - training loss: 0.1689, validation loss: 2.8788
2024-06-03 01:45:43 [INFO]: Epoch 040 - training loss: 0.1670, validation loss: 2.8795
2024-06-03 01:45:53 [INFO]: Epoch 041 - training loss: 0.1637, validation loss: 2.8748
2024-06-03 01:46:04 [INFO]: Epoch 042 - training loss: 0.1645, validation loss: 2.8659
2024-06-03 01:46:15 [INFO]: Epoch 043 - training loss: 0.1611, validation loss: 2.8556
2024-06-03 01:46:25 [INFO]: Epoch 044 - training loss: 0.1608, validation loss: 2.8600
2024-06-03 01:46:36 [INFO]: Epoch 045 - training loss: 0.1600, validation loss: 2.8516
2024-06-03 01:46:47 [INFO]: Epoch 046 - training loss: 0.1586, validation loss: 2.8554
2024-06-03 01:46:57 [INFO]: Epoch 047 - training loss: 0.1569, validation loss: 2.8550
2024-06-03 01:47:08 [INFO]: Epoch 048 - training loss: 0.1539, validation loss: 2.8560
2024-06-03 01:47:19 [INFO]: Epoch 049 - training loss: 0.1541, validation loss: 2.8545
2024-06-03 01:47:29 [INFO]: Epoch 050 - training loss: 0.1516, validation loss: 2.8553
2024-06-03 01:47:40 [INFO]: Epoch 051 - training loss: 0.1517, validation loss: 2.8576
2024-06-03 01:47:50 [INFO]: Epoch 052 - training loss: 0.1489, validation loss: 2.8528
2024-06-03 01:48:01 [INFO]: Epoch 053 - training loss: 0.1484, validation loss: 2.8569
2024-06-03 01:48:11 [INFO]: Epoch 054 - training loss: 0.1479, validation loss: 2.8625
2024-06-03 01:48:21 [INFO]: Epoch 055 - training loss: 0.1485, validation loss: 2.8557
2024-06-03 01:48:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:48:21 [INFO]: Finished training. The best model is from epoch#45.
2024-06-03 01:48:21 [INFO]: Saved the model to results_point_rate09/Electricity/TimesNet_Electricity/round_2/20240603_T013841/TimesNet.pypots
2024-06-03 01:48:23 [INFO]: Successfully saved to results_point_rate09/Electricity/TimesNet_Electricity/round_2/imputation.pkl
2024-06-03 01:48:23 [INFO]: Round2 - TimesNet on Electricity: MAE=1.3194, MSE=3.8310, MRE=0.7063
2024-06-03 01:48:23 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:48:23 [INFO]: Using the given device: cuda:0
2024-06-03 01:48:23 [INFO]: Model files will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_3/20240603_T014823
2024-06-03 01:48:23 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_3/20240603_T014823/tensorboard
2024-06-03 01:48:25 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-03 01:48:36 [INFO]: Epoch 001 - training loss: 0.7728, validation loss: 3.5536
2024-06-03 01:48:46 [INFO]: Epoch 002 - training loss: 0.4569, validation loss: 3.4610
2024-06-03 01:48:57 [INFO]: Epoch 003 - training loss: 0.3971, validation loss: 3.3216
2024-06-03 01:49:07 [INFO]: Epoch 004 - training loss: 0.3328, validation loss: 3.2424
2024-06-03 01:49:18 [INFO]: Epoch 005 - training loss: 0.2929, validation loss: 3.1869
2024-06-03 01:49:28 [INFO]: Epoch 006 - training loss: 0.2715, validation loss: 3.1466
2024-06-03 01:49:39 [INFO]: Epoch 007 - training loss: 0.2593, validation loss: 3.1367
2024-06-03 01:49:49 [INFO]: Epoch 008 - training loss: 0.2519, validation loss: 3.1318
2024-06-03 01:50:00 [INFO]: Epoch 009 - training loss: 0.2484, validation loss: 3.1224
2024-06-03 01:50:10 [INFO]: Epoch 010 - training loss: 0.2421, validation loss: 3.1023
2024-06-03 01:50:20 [INFO]: Epoch 011 - training loss: 0.2342, validation loss: 3.0861
2024-06-03 01:50:31 [INFO]: Epoch 012 - training loss: 0.2305, validation loss: 3.0699
2024-06-03 01:50:42 [INFO]: Epoch 013 - training loss: 0.2255, validation loss: 3.0592
2024-06-03 01:50:52 [INFO]: Epoch 014 - training loss: 0.2183, validation loss: 3.0458
2024-06-03 01:51:03 [INFO]: Epoch 015 - training loss: 0.2167, validation loss: 3.0464
2024-06-03 01:51:13 [INFO]: Epoch 016 - training loss: 0.2150, validation loss: 3.0378
2024-06-03 01:51:24 [INFO]: Epoch 017 - training loss: 0.2119, validation loss: 3.0250
2024-06-03 01:51:34 [INFO]: Epoch 018 - training loss: 0.2102, validation loss: 3.0256
2024-06-03 01:51:45 [INFO]: Epoch 019 - training loss: 0.2111, validation loss: 3.0044
2024-06-03 01:51:56 [INFO]: Epoch 020 - training loss: 0.2042, validation loss: 2.9951
2024-06-03 01:52:07 [INFO]: Epoch 021 - training loss: 0.2032, validation loss: 2.9878
2024-06-03 01:52:17 [INFO]: Epoch 022 - training loss: 0.2018, validation loss: 2.9754
2024-06-03 01:52:28 [INFO]: Epoch 023 - training loss: 0.1976, validation loss: 2.9689
2024-06-03 01:52:38 [INFO]: Epoch 024 - training loss: 0.1964, validation loss: 2.9656
2024-06-03 01:52:48 [INFO]: Epoch 025 - training loss: 0.1956, validation loss: 2.9521
2024-06-03 01:52:59 [INFO]: Epoch 026 - training loss: 0.1939, validation loss: 2.9465
2024-06-03 01:53:10 [INFO]: Epoch 027 - training loss: 0.1913, validation loss: 2.9312
2024-06-03 01:53:20 [INFO]: Epoch 028 - training loss: 0.1906, validation loss: 2.9274
2024-06-03 01:53:31 [INFO]: Epoch 029 - training loss: 0.1876, validation loss: 2.9136
2024-06-03 01:53:42 [INFO]: Epoch 030 - training loss: 0.1861, validation loss: 2.9138
2024-06-03 01:53:52 [INFO]: Epoch 031 - training loss: 0.1820, validation loss: 2.9035
2024-06-03 01:54:03 [INFO]: Epoch 032 - training loss: 0.1818, validation loss: 2.8999
2024-06-03 01:54:13 [INFO]: Epoch 033 - training loss: 0.1788, validation loss: 2.8944
2024-06-03 01:54:24 [INFO]: Epoch 034 - training loss: 0.1769, validation loss: 2.8866
2024-06-03 01:54:35 [INFO]: Epoch 035 - training loss: 0.1769, validation loss: 2.8788
2024-06-03 01:54:46 [INFO]: Epoch 036 - training loss: 0.1734, validation loss: 2.8803
2024-06-03 01:54:56 [INFO]: Epoch 037 - training loss: 0.1708, validation loss: 2.8743
2024-06-03 01:55:07 [INFO]: Epoch 038 - training loss: 0.1685, validation loss: 2.8745
2024-06-03 01:55:17 [INFO]: Epoch 039 - training loss: 0.1686, validation loss: 2.8748
2024-06-03 01:55:28 [INFO]: Epoch 040 - training loss: 0.1658, validation loss: 2.8655
2024-06-03 01:55:39 [INFO]: Epoch 041 - training loss: 0.1636, validation loss: 2.8670
2024-06-03 01:55:50 [INFO]: Epoch 042 - training loss: 0.1627, validation loss: 2.8772
2024-06-03 01:56:00 [INFO]: Epoch 043 - training loss: 0.1604, validation loss: 2.8600
2024-06-03 01:56:10 [INFO]: Epoch 044 - training loss: 0.1596, validation loss: 2.8596
2024-06-03 01:56:21 [INFO]: Epoch 045 - training loss: 0.1590, validation loss: 2.8581
2024-06-03 01:56:32 [INFO]: Epoch 046 - training loss: 0.1568, validation loss: 2.8564
2024-06-03 01:56:42 [INFO]: Epoch 047 - training loss: 0.1569, validation loss: 2.8626
2024-06-03 01:56:53 [INFO]: Epoch 048 - training loss: 0.1544, validation loss: 2.8626
2024-06-03 01:57:03 [INFO]: Epoch 049 - training loss: 0.1550, validation loss: 2.8524
2024-06-03 01:57:14 [INFO]: Epoch 050 - training loss: 0.1505, validation loss: 2.8578
2024-06-03 01:57:25 [INFO]: Epoch 051 - training loss: 0.1514, validation loss: 2.8586
2024-06-03 01:57:36 [INFO]: Epoch 052 - training loss: 0.1496, validation loss: 2.8574
2024-06-03 01:57:47 [INFO]: Epoch 053 - training loss: 0.1492, validation loss: 2.8495
2024-06-03 01:57:57 [INFO]: Epoch 054 - training loss: 0.1463, validation loss: 2.8606
2024-06-03 01:58:08 [INFO]: Epoch 055 - training loss: 0.1462, validation loss: 2.8576
2024-06-03 01:58:19 [INFO]: Epoch 056 - training loss: 0.1440, validation loss: 2.8564
2024-06-03 01:58:29 [INFO]: Epoch 057 - training loss: 0.1424, validation loss: 2.8620
2024-06-03 01:58:40 [INFO]: Epoch 058 - training loss: 0.1425, validation loss: 2.8558
2024-06-03 01:58:51 [INFO]: Epoch 059 - training loss: 0.1409, validation loss: 2.8600
2024-06-03 01:59:01 [INFO]: Epoch 060 - training loss: 0.1412, validation loss: 2.8621
2024-06-03 01:59:12 [INFO]: Epoch 061 - training loss: 0.1384, validation loss: 2.8713
2024-06-03 01:59:23 [INFO]: Epoch 062 - training loss: 0.1387, validation loss: 2.8694
2024-06-03 01:59:33 [INFO]: Epoch 063 - training loss: 0.1370, validation loss: 2.8643
2024-06-03 01:59:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:59:33 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 01:59:33 [INFO]: Saved the model to results_point_rate09/Electricity/TimesNet_Electricity/round_3/20240603_T014823/TimesNet.pypots
2024-06-03 01:59:35 [INFO]: Successfully saved to results_point_rate09/Electricity/TimesNet_Electricity/round_3/imputation.pkl
2024-06-03 01:59:35 [INFO]: Round3 - TimesNet on Electricity: MAE=1.3082, MSE=3.8419, MRE=0.7003
2024-06-03 01:59:35 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:59:35 [INFO]: Using the given device: cuda:0
2024-06-03 01:59:35 [INFO]: Model files will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_4/20240603_T015935
2024-06-03 01:59:35 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/TimesNet_Electricity/round_4/20240603_T015935/tensorboard
2024-06-03 01:59:37 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-03 01:59:48 [INFO]: Epoch 001 - training loss: 0.7768, validation loss: 3.6005
2024-06-03 01:59:59 [INFO]: Epoch 002 - training loss: 0.4653, validation loss: 3.4737
2024-06-03 02:00:10 [INFO]: Epoch 003 - training loss: 0.4052, validation loss: 3.3835
2024-06-03 02:00:20 [INFO]: Epoch 004 - training loss: 0.3510, validation loss: 3.2284
2024-06-03 02:00:31 [INFO]: Epoch 005 - training loss: 0.3002, validation loss: 3.1783
2024-06-03 02:00:41 [INFO]: Epoch 006 - training loss: 0.2756, validation loss: 3.1663
2024-06-03 02:00:52 [INFO]: Epoch 007 - training loss: 0.2582, validation loss: 3.1298
2024-06-03 02:01:03 [INFO]: Epoch 008 - training loss: 0.2530, validation loss: 3.1100
2024-06-03 02:01:13 [INFO]: Epoch 009 - training loss: 0.2479, validation loss: 3.1091
2024-06-03 02:01:24 [INFO]: Epoch 010 - training loss: 0.2415, validation loss: 3.0955
2024-06-03 02:01:34 [INFO]: Epoch 011 - training loss: 0.2391, validation loss: 3.0718
2024-06-03 02:01:45 [INFO]: Epoch 012 - training loss: 0.2281, validation loss: 3.0467
2024-06-03 02:01:56 [INFO]: Epoch 013 - training loss: 0.2233, validation loss: 3.0319
2024-06-03 02:02:07 [INFO]: Epoch 014 - training loss: 0.2198, validation loss: 3.0240
2024-06-03 02:02:17 [INFO]: Epoch 015 - training loss: 0.2179, validation loss: 3.0192
2024-06-03 02:02:28 [INFO]: Epoch 016 - training loss: 0.2120, validation loss: 3.0072
2024-06-03 02:02:39 [INFO]: Epoch 017 - training loss: 0.2097, validation loss: 3.0077
2024-06-03 02:02:49 [INFO]: Epoch 018 - training loss: 0.2072, validation loss: 3.0051
2024-06-03 02:03:00 [INFO]: Epoch 019 - training loss: 0.2074, validation loss: 3.0107
2024-06-03 02:03:10 [INFO]: Epoch 020 - training loss: 0.2021, validation loss: 3.0053
2024-06-03 02:03:20 [INFO]: Epoch 021 - training loss: 0.2011, validation loss: 3.0023
2024-06-03 02:03:30 [INFO]: Epoch 022 - training loss: 0.1987, validation loss: 2.9832
2024-06-03 02:03:40 [INFO]: Epoch 023 - training loss: 0.1972, validation loss: 2.9811
2024-06-03 02:03:51 [INFO]: Epoch 024 - training loss: 0.1956, validation loss: 2.9697
2024-06-03 02:04:02 [INFO]: Epoch 025 - training loss: 0.1932, validation loss: 2.9709
2024-06-03 02:04:12 [INFO]: Epoch 026 - training loss: 0.1924, validation loss: 2.9553
2024-06-03 02:04:23 [INFO]: Epoch 027 - training loss: 0.1894, validation loss: 2.9695
2024-06-03 02:04:33 [INFO]: Epoch 028 - training loss: 0.1903, validation loss: 2.9516
2024-06-03 02:04:42 [INFO]: Epoch 029 - training loss: 0.1870, validation loss: 2.9542
2024-06-03 02:04:51 [INFO]: Epoch 030 - training loss: 0.1859, validation loss: 2.9564
2024-06-03 02:05:01 [INFO]: Epoch 031 - training loss: 0.1861, validation loss: 2.9482
2024-06-03 02:05:12 [INFO]: Epoch 032 - training loss: 0.1809, validation loss: 2.9375
2024-06-03 02:05:23 [INFO]: Epoch 033 - training loss: 0.1827, validation loss: 2.9291
2024-06-03 02:05:33 [INFO]: Epoch 034 - training loss: 0.1794, validation loss: 2.9192
2024-06-03 02:05:44 [INFO]: Epoch 035 - training loss: 0.1792, validation loss: 2.9127
2024-06-03 02:05:55 [INFO]: Epoch 036 - training loss: 0.1761, validation loss: 2.9014
2024-06-03 02:06:05 [INFO]: Epoch 037 - training loss: 0.1733, validation loss: 2.9012
2024-06-03 02:06:16 [INFO]: Epoch 038 - training loss: 0.1744, validation loss: 2.8862
2024-06-03 02:06:27 [INFO]: Epoch 039 - training loss: 0.1713, validation loss: 2.8836
2024-06-03 02:06:37 [INFO]: Epoch 040 - training loss: 0.1713, validation loss: 2.8887
2024-06-03 02:06:48 [INFO]: Epoch 041 - training loss: 0.1701, validation loss: 2.8876
2024-06-03 02:06:59 [INFO]: Epoch 042 - training loss: 0.1671, validation loss: 2.8847
2024-06-03 02:07:09 [INFO]: Epoch 043 - training loss: 0.1659, validation loss: 2.8761
2024-06-03 02:07:20 [INFO]: Epoch 044 - training loss: 0.1645, validation loss: 2.8776
2024-06-03 02:07:30 [INFO]: Epoch 045 - training loss: 0.1621, validation loss: 2.8797
2024-06-03 02:07:41 [INFO]: Epoch 046 - training loss: 0.1613, validation loss: 2.8715
2024-06-03 02:07:51 [INFO]: Epoch 047 - training loss: 0.1593, validation loss: 2.8640
2024-06-03 02:08:02 [INFO]: Epoch 048 - training loss: 0.1564, validation loss: 2.8623
2024-06-03 02:08:12 [INFO]: Epoch 049 - training loss: 0.1582, validation loss: 2.8574
2024-06-03 02:08:23 [INFO]: Epoch 050 - training loss: 0.1564, validation loss: 2.8629
2024-06-03 02:08:33 [INFO]: Epoch 051 - training loss: 0.1550, validation loss: 2.8599
2024-06-03 02:08:44 [INFO]: Epoch 052 - training loss: 0.1535, validation loss: 2.8605
2024-06-03 02:08:55 [INFO]: Epoch 053 - training loss: 0.1524, validation loss: 2.8691
2024-06-03 02:09:06 [INFO]: Epoch 054 - training loss: 0.1513, validation loss: 2.8605
2024-06-03 02:09:16 [INFO]: Epoch 055 - training loss: 0.1471, validation loss: 2.8734
2024-06-03 02:09:27 [INFO]: Epoch 056 - training loss: 0.1482, validation loss: 2.8528
2024-06-03 02:09:38 [INFO]: Epoch 057 - training loss: 0.1455, validation loss: 2.8644
2024-06-03 02:09:48 [INFO]: Epoch 058 - training loss: 0.1444, validation loss: 2.8664
2024-06-03 02:09:59 [INFO]: Epoch 059 - training loss: 0.1433, validation loss: 2.8543
2024-06-03 02:10:10 [INFO]: Epoch 060 - training loss: 0.1434, validation loss: 2.8626
2024-06-03 02:10:21 [INFO]: Epoch 061 - training loss: 0.1422, validation loss: 2.8630
2024-06-03 02:10:31 [INFO]: Epoch 062 - training loss: 0.1407, validation loss: 2.8608
2024-06-03 02:10:42 [INFO]: Epoch 063 - training loss: 0.1393, validation loss: 2.8583
2024-06-03 02:10:53 [INFO]: Epoch 064 - training loss: 0.1392, validation loss: 2.8659
2024-06-03 02:11:03 [INFO]: Epoch 065 - training loss: 0.1384, validation loss: 2.8618
2024-06-03 02:11:14 [INFO]: Epoch 066 - training loss: 0.1376, validation loss: 2.8577
2024-06-03 02:11:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:11:14 [INFO]: Finished training. The best model is from epoch#56.
2024-06-03 02:11:15 [INFO]: Saved the model to results_point_rate09/Electricity/TimesNet_Electricity/round_4/20240603_T015935/TimesNet.pypots
2024-06-03 02:11:17 [INFO]: Successfully saved to results_point_rate09/Electricity/TimesNet_Electricity/round_4/imputation.pkl
2024-06-03 02:11:17 [INFO]: Round4 - TimesNet on Electricity: MAE=1.3147, MSE=3.8565, MRE=0.7038
2024-06-03 02:11:17 [INFO]: Done! Final results:
Averaged TimesNet (45,569,394 params) on Electricity: MAE=1.3154 ± 0.005085688858539837, MSE=3.8762 ± 0.05306404402963718, MRE=0.7042 ± 0.0027225143629324394, average inference time=1.61
