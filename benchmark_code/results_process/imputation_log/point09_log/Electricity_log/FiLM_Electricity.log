2024-06-03 01:13:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:13:04 [INFO]: Using the given device: cuda:0
2024-06-03 01:13:05 [INFO]: Model files will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_0/20240603_T011304
2024-06-03 01:13:05 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_0/20240603_T011304/tensorboard
2024-06-03 01:13:05 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 01:13:14 [INFO]: Epoch 001 - training loss: 1.5498, validation loss: 4.0872
2024-06-03 01:13:20 [INFO]: Epoch 002 - training loss: 1.3152, validation loss: 3.8594
2024-06-03 01:13:28 [INFO]: Epoch 003 - training loss: 1.2844, validation loss: 3.8198
2024-06-03 01:13:35 [INFO]: Epoch 004 - training loss: 1.2028, validation loss: 3.7726
2024-06-03 01:13:42 [INFO]: Epoch 005 - training loss: 1.1269, validation loss: 3.8662
2024-06-03 01:13:49 [INFO]: Epoch 006 - training loss: 1.1016, validation loss: 3.8063
2024-06-03 01:13:56 [INFO]: Epoch 007 - training loss: 1.0864, validation loss: 3.8417
2024-06-03 01:14:03 [INFO]: Epoch 008 - training loss: 1.0770, validation loss: 3.8294
2024-06-03 01:14:10 [INFO]: Epoch 009 - training loss: 1.0669, validation loss: 3.7443
2024-06-03 01:14:17 [INFO]: Epoch 010 - training loss: 1.0596, validation loss: 3.7139
2024-06-03 01:14:25 [INFO]: Epoch 011 - training loss: 1.0533, validation loss: 3.7336
2024-06-03 01:14:32 [INFO]: Epoch 012 - training loss: 1.0508, validation loss: 3.7673
2024-06-03 01:14:39 [INFO]: Epoch 013 - training loss: 1.0470, validation loss: 3.7156
2024-06-03 01:14:46 [INFO]: Epoch 014 - training loss: 1.0432, validation loss: 3.5899
2024-06-03 01:14:54 [INFO]: Epoch 015 - training loss: 1.0396, validation loss: 3.7305
2024-06-03 01:15:01 [INFO]: Epoch 016 - training loss: 1.0376, validation loss: 3.6803
2024-06-03 01:15:08 [INFO]: Epoch 017 - training loss: 1.0345, validation loss: 3.6358
2024-06-03 01:15:15 [INFO]: Epoch 018 - training loss: 1.0310, validation loss: 3.5205
2024-06-03 01:15:22 [INFO]: Epoch 019 - training loss: 1.0284, validation loss: 3.5032
2024-06-03 01:15:29 [INFO]: Epoch 020 - training loss: 1.0267, validation loss: 3.5556
2024-06-03 01:15:36 [INFO]: Epoch 021 - training loss: 1.0265, validation loss: 3.5282
2024-06-03 01:15:43 [INFO]: Epoch 022 - training loss: 1.0230, validation loss: 3.4685
2024-06-03 01:15:50 [INFO]: Epoch 023 - training loss: 1.0214, validation loss: 3.4793
2024-06-03 01:15:58 [INFO]: Epoch 024 - training loss: 1.0205, validation loss: 3.4117
2024-06-03 01:16:05 [INFO]: Epoch 025 - training loss: 1.0156, validation loss: 3.3827
2024-06-03 01:16:12 [INFO]: Epoch 026 - training loss: 1.0161, validation loss: 3.4498
2024-06-03 01:16:19 [INFO]: Epoch 027 - training loss: 1.0146, validation loss: 3.3894
2024-06-03 01:16:26 [INFO]: Epoch 028 - training loss: 1.0129, validation loss: 3.3597
2024-06-03 01:16:33 [INFO]: Epoch 029 - training loss: 1.0129, validation loss: 3.2300
2024-06-03 01:16:41 [INFO]: Epoch 030 - training loss: 1.0107, validation loss: 3.3026
2024-06-03 01:16:48 [INFO]: Epoch 031 - training loss: 1.0085, validation loss: 3.2775
2024-06-03 01:16:55 [INFO]: Epoch 032 - training loss: 1.0066, validation loss: 3.2758
2024-06-03 01:17:02 [INFO]: Epoch 033 - training loss: 1.0074, validation loss: 3.1994
2024-06-03 01:17:09 [INFO]: Epoch 034 - training loss: 1.0042, validation loss: 3.3910
2024-06-03 01:17:17 [INFO]: Epoch 035 - training loss: 1.0035, validation loss: 3.1889
2024-06-03 01:17:24 [INFO]: Epoch 036 - training loss: 1.0013, validation loss: 3.2196
2024-06-03 01:17:31 [INFO]: Epoch 037 - training loss: 1.0006, validation loss: 3.1347
2024-06-03 01:17:38 [INFO]: Epoch 038 - training loss: 0.9989, validation loss: 3.2167
2024-06-03 01:17:45 [INFO]: Epoch 039 - training loss: 0.9981, validation loss: 3.1188
2024-06-03 01:17:53 [INFO]: Epoch 040 - training loss: 0.9975, validation loss: 3.1980
2024-06-03 01:18:00 [INFO]: Epoch 041 - training loss: 0.9942, validation loss: 3.1774
2024-06-03 01:18:07 [INFO]: Epoch 042 - training loss: 0.9948, validation loss: 3.1097
2024-06-03 01:18:14 [INFO]: Epoch 043 - training loss: 0.9930, validation loss: 3.2059
2024-06-03 01:18:22 [INFO]: Epoch 044 - training loss: 0.9912, validation loss: 3.0958
2024-06-03 01:18:29 [INFO]: Epoch 045 - training loss: 0.9894, validation loss: 3.0316
2024-06-03 01:18:36 [INFO]: Epoch 046 - training loss: 0.9878, validation loss: 3.0942
2024-06-03 01:18:43 [INFO]: Epoch 047 - training loss: 0.9850, validation loss: 3.0750
2024-06-03 01:18:50 [INFO]: Epoch 048 - training loss: 0.9855, validation loss: 3.0724
2024-06-03 01:18:57 [INFO]: Epoch 049 - training loss: 0.9840, validation loss: 2.9777
2024-06-03 01:19:03 [INFO]: Epoch 050 - training loss: 0.9827, validation loss: 2.9970
2024-06-03 01:19:10 [INFO]: Epoch 051 - training loss: 0.9833, validation loss: 2.9822
2024-06-03 01:19:17 [INFO]: Epoch 052 - training loss: 0.9801, validation loss: 2.9481
2024-06-03 01:19:24 [INFO]: Epoch 053 - training loss: 0.9791, validation loss: 2.8932
2024-06-03 01:19:32 [INFO]: Epoch 054 - training loss: 0.9781, validation loss: 2.8891
2024-06-03 01:19:39 [INFO]: Epoch 055 - training loss: 0.9764, validation loss: 2.9276
2024-06-03 01:19:47 [INFO]: Epoch 056 - training loss: 0.9764, validation loss: 2.8133
2024-06-03 01:19:53 [INFO]: Epoch 057 - training loss: 0.9757, validation loss: 2.8452
2024-06-03 01:20:01 [INFO]: Epoch 058 - training loss: 0.9747, validation loss: 2.7728
2024-06-03 01:20:08 [INFO]: Epoch 059 - training loss: 0.9726, validation loss: 2.7866
2024-06-03 01:20:15 [INFO]: Epoch 060 - training loss: 0.9723, validation loss: 2.7889
2024-06-03 01:20:22 [INFO]: Epoch 061 - training loss: 0.9735, validation loss: 2.7786
2024-06-03 01:20:29 [INFO]: Epoch 062 - training loss: 0.9719, validation loss: 2.7203
2024-06-03 01:20:36 [INFO]: Epoch 063 - training loss: 0.9703, validation loss: 2.6916
2024-06-03 01:20:44 [INFO]: Epoch 064 - training loss: 0.9701, validation loss: 2.7125
2024-06-03 01:20:51 [INFO]: Epoch 065 - training loss: 0.9684, validation loss: 2.7424
2024-06-03 01:20:58 [INFO]: Epoch 066 - training loss: 0.9669, validation loss: 2.7079
2024-06-03 01:21:06 [INFO]: Epoch 067 - training loss: 0.9685, validation loss: 2.7290
2024-06-03 01:21:13 [INFO]: Epoch 068 - training loss: 0.9671, validation loss: 2.6695
2024-06-03 01:21:21 [INFO]: Epoch 069 - training loss: 0.9674, validation loss: 2.6528
2024-06-03 01:21:28 [INFO]: Epoch 070 - training loss: 0.9649, validation loss: 2.6430
2024-06-03 01:21:35 [INFO]: Epoch 071 - training loss: 0.9648, validation loss: 2.6337
2024-06-03 01:21:42 [INFO]: Epoch 072 - training loss: 0.9634, validation loss: 2.5747
2024-06-03 01:21:49 [INFO]: Epoch 073 - training loss: 0.9659, validation loss: 2.6242
2024-06-03 01:21:56 [INFO]: Epoch 074 - training loss: 0.9641, validation loss: 2.5673
2024-06-03 01:22:04 [INFO]: Epoch 075 - training loss: 0.9622, validation loss: 2.6533
2024-06-03 01:22:11 [INFO]: Epoch 076 - training loss: 0.9626, validation loss: 2.5562
2024-06-03 01:22:18 [INFO]: Epoch 077 - training loss: 0.9625, validation loss: 2.5896
2024-06-03 01:22:25 [INFO]: Epoch 078 - training loss: 0.9620, validation loss: 2.5633
2024-06-03 01:22:33 [INFO]: Epoch 079 - training loss: 0.9602, validation loss: 2.5693
2024-06-03 01:22:40 [INFO]: Epoch 080 - training loss: 0.9596, validation loss: 2.5955
2024-06-03 01:22:47 [INFO]: Epoch 081 - training loss: 0.9609, validation loss: 2.5205
2024-06-03 01:22:54 [INFO]: Epoch 082 - training loss: 0.9592, validation loss: 2.5043
2024-06-03 01:23:01 [INFO]: Epoch 083 - training loss: 0.9583, validation loss: 2.5361
2024-06-03 01:23:09 [INFO]: Epoch 084 - training loss: 0.9583, validation loss: 2.5198
2024-06-03 01:23:16 [INFO]: Epoch 085 - training loss: 0.9590, validation loss: 2.4951
2024-06-03 01:23:23 [INFO]: Epoch 086 - training loss: 0.9574, validation loss: 2.5241
2024-06-03 01:23:30 [INFO]: Epoch 087 - training loss: 0.9578, validation loss: 2.5064
2024-06-03 01:23:37 [INFO]: Epoch 088 - training loss: 0.9559, validation loss: 2.5147
2024-06-03 01:23:44 [INFO]: Epoch 089 - training loss: 0.9565, validation loss: 2.4734
2024-06-03 01:23:51 [INFO]: Epoch 090 - training loss: 0.9570, validation loss: 2.4712
2024-06-03 01:23:59 [INFO]: Epoch 091 - training loss: 0.9555, validation loss: 2.5017
2024-06-03 01:24:06 [INFO]: Epoch 092 - training loss: 0.9559, validation loss: 2.4780
2024-06-03 01:24:13 [INFO]: Epoch 093 - training loss: 0.9541, validation loss: 2.4681
2024-06-03 01:24:20 [INFO]: Epoch 094 - training loss: 0.9537, validation loss: 2.4627
2024-06-03 01:24:27 [INFO]: Epoch 095 - training loss: 0.9541, validation loss: 2.4400
2024-06-03 01:24:34 [INFO]: Epoch 096 - training loss: 0.9532, validation loss: 2.4667
2024-06-03 01:24:41 [INFO]: Epoch 097 - training loss: 0.9539, validation loss: 2.4785
2024-06-03 01:24:48 [INFO]: Epoch 098 - training loss: 0.9529, validation loss: 2.4348
2024-06-03 01:24:55 [INFO]: Epoch 099 - training loss: 0.9536, validation loss: 2.4439
2024-06-03 01:25:02 [INFO]: Epoch 100 - training loss: 0.9519, validation loss: 2.4456
2024-06-03 01:25:02 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 01:25:02 [INFO]: Saved the model to results_point_rate09/Electricity/FiLM_Electricity/round_0/20240603_T011304/FiLM.pypots
2024-06-03 01:25:03 [INFO]: Successfully saved to results_point_rate09/Electricity/FiLM_Electricity/round_0/imputation.pkl
2024-06-03 01:25:03 [INFO]: Round0 - FiLM on Electricity: MAE=1.0722, MSE=2.0458, MRE=0.5740
2024-06-03 01:25:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:25:03 [INFO]: Using the given device: cuda:0
2024-06-03 01:25:03 [INFO]: Model files will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_1/20240603_T012503
2024-06-03 01:25:03 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_1/20240603_T012503/tensorboard
2024-06-03 01:25:03 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 01:25:10 [INFO]: Epoch 001 - training loss: 1.4963, validation loss: 3.9809
2024-06-03 01:25:17 [INFO]: Epoch 002 - training loss: 1.2659, validation loss: 3.6972
2024-06-03 01:25:24 [INFO]: Epoch 003 - training loss: 1.1642, validation loss: 3.5833
2024-06-03 01:25:32 [INFO]: Epoch 004 - training loss: 1.1099, validation loss: 3.6552
2024-06-03 01:25:39 [INFO]: Epoch 005 - training loss: 1.0874, validation loss: 3.6617
2024-06-03 01:25:46 [INFO]: Epoch 006 - training loss: 1.0693, validation loss: 3.5674
2024-06-03 01:25:53 [INFO]: Epoch 007 - training loss: 1.0579, validation loss: 3.5330
2024-06-03 01:26:01 [INFO]: Epoch 008 - training loss: 1.0512, validation loss: 3.4417
2024-06-03 01:26:08 [INFO]: Epoch 009 - training loss: 1.0451, validation loss: 3.3582
2024-06-03 01:26:14 [INFO]: Epoch 010 - training loss: 1.0425, validation loss: 3.3623
2024-06-03 01:26:21 [INFO]: Epoch 011 - training loss: 1.0372, validation loss: 3.3127
2024-06-03 01:26:28 [INFO]: Epoch 012 - training loss: 1.0341, validation loss: 3.2706
2024-06-03 01:26:36 [INFO]: Epoch 013 - training loss: 1.0304, validation loss: 3.2151
2024-06-03 01:26:43 [INFO]: Epoch 014 - training loss: 1.0274, validation loss: 3.2243
2024-06-03 01:26:50 [INFO]: Epoch 015 - training loss: 1.0238, validation loss: 3.1673
2024-06-03 01:26:57 [INFO]: Epoch 016 - training loss: 1.0213, validation loss: 3.1751
2024-06-03 01:27:04 [INFO]: Epoch 017 - training loss: 1.0185, validation loss: 3.1390
2024-06-03 01:27:11 [INFO]: Epoch 018 - training loss: 1.0153, validation loss: 3.1395
2024-06-03 01:27:18 [INFO]: Epoch 019 - training loss: 1.0130, validation loss: 3.1352
2024-06-03 01:27:26 [INFO]: Epoch 020 - training loss: 1.0100, validation loss: 3.1085
2024-06-03 01:27:33 [INFO]: Epoch 021 - training loss: 1.0084, validation loss: 3.0941
2024-06-03 01:27:40 [INFO]: Epoch 022 - training loss: 1.0066, validation loss: 3.0550
2024-06-03 01:27:47 [INFO]: Epoch 023 - training loss: 1.0038, validation loss: 3.0491
2024-06-03 01:27:54 [INFO]: Epoch 024 - training loss: 1.0016, validation loss: 3.0276
2024-06-03 01:28:01 [INFO]: Epoch 025 - training loss: 1.0017, validation loss: 3.0496
2024-06-03 01:28:08 [INFO]: Epoch 026 - training loss: 0.9992, validation loss: 3.0232
2024-06-03 01:28:16 [INFO]: Epoch 027 - training loss: 0.9989, validation loss: 2.9876
2024-06-03 01:28:23 [INFO]: Epoch 028 - training loss: 0.9952, validation loss: 2.9432
2024-06-03 01:28:30 [INFO]: Epoch 029 - training loss: 0.9939, validation loss: 2.9823
2024-06-03 01:28:37 [INFO]: Epoch 030 - training loss: 0.9936, validation loss: 2.9540
2024-06-03 01:28:43 [INFO]: Epoch 031 - training loss: 0.9913, validation loss: 2.9389
2024-06-03 01:28:50 [INFO]: Epoch 032 - training loss: 0.9912, validation loss: 2.9092
2024-06-03 01:28:56 [INFO]: Epoch 033 - training loss: 0.9877, validation loss: 2.9129
2024-06-03 01:29:04 [INFO]: Epoch 034 - training loss: 0.9862, validation loss: 2.8817
2024-06-03 01:29:11 [INFO]: Epoch 035 - training loss: 0.9852, validation loss: 2.8612
2024-06-03 01:29:18 [INFO]: Epoch 036 - training loss: 0.9848, validation loss: 2.8802
2024-06-03 01:29:24 [INFO]: Epoch 037 - training loss: 0.9840, validation loss: 2.8635
2024-06-03 01:29:31 [INFO]: Epoch 038 - training loss: 0.9822, validation loss: 2.8480
2024-06-03 01:29:38 [INFO]: Epoch 039 - training loss: 0.9814, validation loss: 2.7916
2024-06-03 01:29:45 [INFO]: Epoch 040 - training loss: 0.9796, validation loss: 2.7994
2024-06-03 01:29:52 [INFO]: Epoch 041 - training loss: 0.9785, validation loss: 2.7777
2024-06-03 01:29:59 [INFO]: Epoch 042 - training loss: 0.9761, validation loss: 2.7413
2024-06-03 01:30:06 [INFO]: Epoch 043 - training loss: 0.9759, validation loss: 2.7465
2024-06-03 01:30:13 [INFO]: Epoch 044 - training loss: 0.9744, validation loss: 2.7711
2024-06-03 01:30:20 [INFO]: Epoch 045 - training loss: 0.9740, validation loss: 2.7397
2024-06-03 01:30:27 [INFO]: Epoch 046 - training loss: 0.9735, validation loss: 2.7487
2024-06-03 01:30:35 [INFO]: Epoch 047 - training loss: 0.9720, validation loss: 2.7105
2024-06-03 01:30:42 [INFO]: Epoch 048 - training loss: 0.9702, validation loss: 2.7358
2024-06-03 01:30:49 [INFO]: Epoch 049 - training loss: 0.9706, validation loss: 2.6735
2024-06-03 01:30:56 [INFO]: Epoch 050 - training loss: 0.9687, validation loss: 2.6628
2024-06-03 01:31:03 [INFO]: Epoch 051 - training loss: 0.9681, validation loss: 2.6871
2024-06-03 01:31:10 [INFO]: Epoch 052 - training loss: 0.9684, validation loss: 2.6374
2024-06-03 01:31:17 [INFO]: Epoch 053 - training loss: 0.9674, validation loss: 2.6580
2024-06-03 01:31:24 [INFO]: Epoch 054 - training loss: 0.9668, validation loss: 2.6408
2024-06-03 01:31:31 [INFO]: Epoch 055 - training loss: 0.9643, validation loss: 2.6371
2024-06-03 01:31:38 [INFO]: Epoch 056 - training loss: 0.9638, validation loss: 2.5940
2024-06-03 01:31:46 [INFO]: Epoch 057 - training loss: 0.9649, validation loss: 2.5926
2024-06-03 01:31:53 [INFO]: Epoch 058 - training loss: 0.9633, validation loss: 2.5974
2024-06-03 01:32:00 [INFO]: Epoch 059 - training loss: 0.9626, validation loss: 2.6023
2024-06-03 01:32:07 [INFO]: Epoch 060 - training loss: 0.9624, validation loss: 2.5812
2024-06-03 01:32:14 [INFO]: Epoch 061 - training loss: 0.9619, validation loss: 2.5628
2024-06-03 01:32:21 [INFO]: Epoch 062 - training loss: 0.9631, validation loss: 2.5846
2024-06-03 01:32:29 [INFO]: Epoch 063 - training loss: 0.9601, validation loss: 2.5806
2024-06-03 01:32:35 [INFO]: Epoch 064 - training loss: 0.9602, validation loss: 2.5579
2024-06-03 01:32:40 [INFO]: Epoch 065 - training loss: 0.9595, validation loss: 2.5590
2024-06-03 01:32:45 [INFO]: Epoch 066 - training loss: 0.9601, validation loss: 2.5410
2024-06-03 01:32:50 [INFO]: Epoch 067 - training loss: 0.9584, validation loss: 2.5437
2024-06-03 01:32:55 [INFO]: Epoch 068 - training loss: 0.9595, validation loss: 2.5477
2024-06-03 01:33:00 [INFO]: Epoch 069 - training loss: 0.9576, validation loss: 2.5062
2024-06-03 01:33:05 [INFO]: Epoch 070 - training loss: 0.9584, validation loss: 2.5029
2024-06-03 01:33:09 [INFO]: Epoch 071 - training loss: 0.9563, validation loss: 2.5030
2024-06-03 01:33:12 [INFO]: Epoch 072 - training loss: 0.9560, validation loss: 2.5262
2024-06-03 01:33:16 [INFO]: Epoch 073 - training loss: 0.9569, validation loss: 2.4704
2024-06-03 01:33:19 [INFO]: Epoch 074 - training loss: 0.9567, validation loss: 2.4874
2024-06-03 01:33:23 [INFO]: Epoch 075 - training loss: 0.9557, validation loss: 2.5031
2024-06-03 01:33:26 [INFO]: Epoch 076 - training loss: 0.9553, validation loss: 2.4801
2024-06-03 01:33:30 [INFO]: Epoch 077 - training loss: 0.9555, validation loss: 2.4673
2024-06-03 01:33:34 [INFO]: Epoch 078 - training loss: 0.9551, validation loss: 2.4437
2024-06-03 01:33:37 [INFO]: Epoch 079 - training loss: 0.9542, validation loss: 2.4698
2024-06-03 01:33:40 [INFO]: Epoch 080 - training loss: 0.9537, validation loss: 2.4475
2024-06-03 01:33:44 [INFO]: Epoch 081 - training loss: 0.9536, validation loss: 2.4390
2024-06-03 01:33:47 [INFO]: Epoch 082 - training loss: 0.9526, validation loss: 2.4326
2024-06-03 01:33:51 [INFO]: Epoch 083 - training loss: 0.9526, validation loss: 2.4197
2024-06-03 01:33:55 [INFO]: Epoch 084 - training loss: 0.9528, validation loss: 2.4263
2024-06-03 01:33:58 [INFO]: Epoch 085 - training loss: 0.9518, validation loss: 2.4213
2024-06-03 01:34:02 [INFO]: Epoch 086 - training loss: 0.9527, validation loss: 2.4126
2024-06-03 01:34:06 [INFO]: Epoch 087 - training loss: 0.9510, validation loss: 2.4086
2024-06-03 01:34:09 [INFO]: Epoch 088 - training loss: 0.9507, validation loss: 2.3901
2024-06-03 01:34:13 [INFO]: Epoch 089 - training loss: 0.9517, validation loss: 2.3952
2024-06-03 01:34:16 [INFO]: Epoch 090 - training loss: 0.9512, validation loss: 2.4010
2024-06-03 01:34:20 [INFO]: Epoch 091 - training loss: 0.9501, validation loss: 2.4061
2024-06-03 01:34:23 [INFO]: Epoch 092 - training loss: 0.9504, validation loss: 2.3976
2024-06-03 01:34:27 [INFO]: Epoch 093 - training loss: 0.9506, validation loss: 2.3841
2024-06-03 01:34:30 [INFO]: Epoch 094 - training loss: 0.9508, validation loss: 2.3637
2024-06-03 01:34:34 [INFO]: Epoch 095 - training loss: 0.9497, validation loss: 2.3776
2024-06-03 01:34:38 [INFO]: Epoch 096 - training loss: 0.9488, validation loss: 2.3915
2024-06-03 01:34:41 [INFO]: Epoch 097 - training loss: 0.9493, validation loss: 2.3874
2024-06-03 01:34:45 [INFO]: Epoch 098 - training loss: 0.9501, validation loss: 2.3512
2024-06-03 01:34:48 [INFO]: Epoch 099 - training loss: 0.9500, validation loss: 2.3767
2024-06-03 01:34:52 [INFO]: Epoch 100 - training loss: 0.9488, validation loss: 2.3578
2024-06-03 01:34:52 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 01:34:52 [INFO]: Saved the model to results_point_rate09/Electricity/FiLM_Electricity/round_1/20240603_T012503/FiLM.pypots
2024-06-03 01:34:52 [INFO]: Successfully saved to results_point_rate09/Electricity/FiLM_Electricity/round_1/imputation.pkl
2024-06-03 01:34:52 [INFO]: Round1 - FiLM on Electricity: MAE=1.0159, MSE=1.8655, MRE=0.5438
2024-06-03 01:34:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:34:52 [INFO]: Using the given device: cuda:0
2024-06-03 01:34:52 [INFO]: Model files will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_2/20240603_T013452
2024-06-03 01:34:52 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_2/20240603_T013452/tensorboard
2024-06-03 01:34:52 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 01:34:56 [INFO]: Epoch 001 - training loss: 1.6020, validation loss: 4.2462
2024-06-03 01:34:59 [INFO]: Epoch 002 - training loss: 1.2887, validation loss: 3.8342
2024-06-03 01:35:03 [INFO]: Epoch 003 - training loss: 1.1502, validation loss: 3.6606
2024-06-03 01:35:06 [INFO]: Epoch 004 - training loss: 1.0961, validation loss: 3.6534
2024-06-03 01:35:10 [INFO]: Epoch 005 - training loss: 1.0771, validation loss: 3.6567
2024-06-03 01:35:13 [INFO]: Epoch 006 - training loss: 1.0673, validation loss: 3.5657
2024-06-03 01:35:17 [INFO]: Epoch 007 - training loss: 1.0588, validation loss: 3.6049
2024-06-03 01:35:21 [INFO]: Epoch 008 - training loss: 1.0533, validation loss: 3.5549
2024-06-03 01:35:25 [INFO]: Epoch 009 - training loss: 1.0467, validation loss: 3.4986
2024-06-03 01:35:29 [INFO]: Epoch 010 - training loss: 1.0434, validation loss: 3.4469
2024-06-03 01:35:32 [INFO]: Epoch 011 - training loss: 1.0396, validation loss: 3.4542
2024-06-03 01:35:36 [INFO]: Epoch 012 - training loss: 1.0357, validation loss: 3.4068
2024-06-03 01:35:40 [INFO]: Epoch 013 - training loss: 1.0330, validation loss: 3.4136
2024-06-03 01:35:44 [INFO]: Epoch 014 - training loss: 1.0286, validation loss: 3.2966
2024-06-03 01:35:47 [INFO]: Epoch 015 - training loss: 1.0257, validation loss: 3.2838
2024-06-03 01:35:51 [INFO]: Epoch 016 - training loss: 1.0225, validation loss: 3.2452
2024-06-03 01:35:54 [INFO]: Epoch 017 - training loss: 1.0208, validation loss: 3.2628
2024-06-03 01:35:58 [INFO]: Epoch 018 - training loss: 1.0173, validation loss: 3.2510
2024-06-03 01:36:02 [INFO]: Epoch 019 - training loss: 1.0135, validation loss: 3.1543
2024-06-03 01:36:05 [INFO]: Epoch 020 - training loss: 1.0113, validation loss: 3.1555
2024-06-03 01:36:09 [INFO]: Epoch 021 - training loss: 1.0096, validation loss: 3.1804
2024-06-03 01:36:12 [INFO]: Epoch 022 - training loss: 1.0068, validation loss: 3.1438
2024-06-03 01:36:16 [INFO]: Epoch 023 - training loss: 1.0030, validation loss: 3.1341
2024-06-03 01:36:20 [INFO]: Epoch 024 - training loss: 1.0005, validation loss: 3.1422
2024-06-03 01:36:24 [INFO]: Epoch 025 - training loss: 0.9996, validation loss: 3.1080
2024-06-03 01:36:27 [INFO]: Epoch 026 - training loss: 0.9963, validation loss: 3.0568
2024-06-03 01:36:31 [INFO]: Epoch 027 - training loss: 0.9954, validation loss: 3.0443
2024-06-03 01:36:35 [INFO]: Epoch 028 - training loss: 0.9923, validation loss: 2.9964
2024-06-03 01:36:38 [INFO]: Epoch 029 - training loss: 0.9909, validation loss: 3.0471
2024-06-03 01:36:42 [INFO]: Epoch 030 - training loss: 0.9897, validation loss: 2.9763
2024-06-03 01:36:46 [INFO]: Epoch 031 - training loss: 0.9880, validation loss: 2.9296
2024-06-03 01:36:50 [INFO]: Epoch 032 - training loss: 0.9862, validation loss: 2.9102
2024-06-03 01:36:53 [INFO]: Epoch 033 - training loss: 0.9844, validation loss: 2.9310
2024-06-03 01:36:56 [INFO]: Epoch 034 - training loss: 0.9829, validation loss: 2.8835
2024-06-03 01:37:00 [INFO]: Epoch 035 - training loss: 0.9809, validation loss: 2.8928
2024-06-03 01:37:04 [INFO]: Epoch 036 - training loss: 0.9807, validation loss: 2.8414
2024-06-03 01:37:08 [INFO]: Epoch 037 - training loss: 0.9794, validation loss: 2.8084
2024-06-03 01:37:11 [INFO]: Epoch 038 - training loss: 0.9776, validation loss: 2.7765
2024-06-03 01:37:15 [INFO]: Epoch 039 - training loss: 0.9770, validation loss: 2.7740
2024-06-03 01:37:19 [INFO]: Epoch 040 - training loss: 0.9765, validation loss: 2.7379
2024-06-03 01:37:23 [INFO]: Epoch 041 - training loss: 0.9750, validation loss: 2.7636
2024-06-03 01:37:26 [INFO]: Epoch 042 - training loss: 0.9730, validation loss: 2.7666
2024-06-03 01:37:30 [INFO]: Epoch 043 - training loss: 0.9726, validation loss: 2.7093
2024-06-03 01:37:34 [INFO]: Epoch 044 - training loss: 0.9708, validation loss: 2.7429
2024-06-03 01:37:38 [INFO]: Epoch 045 - training loss: 0.9703, validation loss: 2.7335
2024-06-03 01:37:41 [INFO]: Epoch 046 - training loss: 0.9693, validation loss: 2.6969
2024-06-03 01:37:44 [INFO]: Epoch 047 - training loss: 0.9670, validation loss: 2.6586
2024-06-03 01:37:48 [INFO]: Epoch 048 - training loss: 0.9687, validation loss: 2.6698
2024-06-03 01:37:51 [INFO]: Epoch 049 - training loss: 0.9663, validation loss: 2.6535
2024-06-03 01:37:55 [INFO]: Epoch 050 - training loss: 0.9663, validation loss: 2.6732
2024-06-03 01:37:59 [INFO]: Epoch 051 - training loss: 0.9656, validation loss: 2.5963
2024-06-03 01:38:02 [INFO]: Epoch 052 - training loss: 0.9661, validation loss: 2.6464
2024-06-03 01:38:06 [INFO]: Epoch 053 - training loss: 0.9645, validation loss: 2.6072
2024-06-03 01:38:09 [INFO]: Epoch 054 - training loss: 0.9628, validation loss: 2.6016
2024-06-03 01:38:13 [INFO]: Epoch 055 - training loss: 0.9626, validation loss: 2.5953
2024-06-03 01:38:17 [INFO]: Epoch 056 - training loss: 0.9639, validation loss: 2.6153
2024-06-03 01:38:20 [INFO]: Epoch 057 - training loss: 0.9636, validation loss: 2.5914
2024-06-03 01:38:24 [INFO]: Epoch 058 - training loss: 0.9631, validation loss: 2.5827
2024-06-03 01:38:28 [INFO]: Epoch 059 - training loss: 0.9611, validation loss: 2.5548
2024-06-03 01:38:31 [INFO]: Epoch 060 - training loss: 0.9617, validation loss: 2.5459
2024-06-03 01:38:35 [INFO]: Epoch 061 - training loss: 0.9592, validation loss: 2.5394
2024-06-03 01:38:39 [INFO]: Epoch 062 - training loss: 0.9587, validation loss: 2.5443
2024-06-03 01:38:42 [INFO]: Epoch 063 - training loss: 0.9585, validation loss: 2.5334
2024-06-03 01:38:46 [INFO]: Epoch 064 - training loss: 0.9586, validation loss: 2.5172
2024-06-03 01:38:49 [INFO]: Epoch 065 - training loss: 0.9590, validation loss: 2.4853
2024-06-03 01:38:52 [INFO]: Epoch 066 - training loss: 0.9574, validation loss: 2.5107
2024-06-03 01:38:55 [INFO]: Epoch 067 - training loss: 0.9580, validation loss: 2.4803
2024-06-03 01:38:57 [INFO]: Epoch 068 - training loss: 0.9562, validation loss: 2.5018
2024-06-03 01:39:00 [INFO]: Epoch 069 - training loss: 0.9571, validation loss: 2.4707
2024-06-03 01:39:02 [INFO]: Epoch 070 - training loss: 0.9574, validation loss: 2.4558
2024-06-03 01:39:04 [INFO]: Epoch 071 - training loss: 0.9558, validation loss: 2.4354
2024-06-03 01:39:05 [INFO]: Epoch 072 - training loss: 0.9566, validation loss: 2.4550
2024-06-03 01:39:07 [INFO]: Epoch 073 - training loss: 0.9561, validation loss: 2.4550
2024-06-03 01:39:09 [INFO]: Epoch 074 - training loss: 0.9541, validation loss: 2.4749
2024-06-03 01:39:10 [INFO]: Epoch 075 - training loss: 0.9554, validation loss: 2.4219
2024-06-03 01:39:12 [INFO]: Epoch 076 - training loss: 0.9552, validation loss: 2.4142
2024-06-03 01:39:14 [INFO]: Epoch 077 - training loss: 0.9545, validation loss: 2.4310
2024-06-03 01:39:15 [INFO]: Epoch 078 - training loss: 0.9536, validation loss: 2.4332
2024-06-03 01:39:17 [INFO]: Epoch 079 - training loss: 0.9528, validation loss: 2.4208
2024-06-03 01:39:19 [INFO]: Epoch 080 - training loss: 0.9531, validation loss: 2.3779
2024-06-03 01:39:20 [INFO]: Epoch 081 - training loss: 0.9538, validation loss: 2.4042
2024-06-03 01:39:22 [INFO]: Epoch 082 - training loss: 0.9516, validation loss: 2.3940
2024-06-03 01:39:24 [INFO]: Epoch 083 - training loss: 0.9528, validation loss: 2.4052
2024-06-03 01:39:25 [INFO]: Epoch 084 - training loss: 0.9531, validation loss: 2.3887
2024-06-03 01:39:27 [INFO]: Epoch 085 - training loss: 0.9510, validation loss: 2.3921
2024-06-03 01:39:29 [INFO]: Epoch 086 - training loss: 0.9520, validation loss: 2.3971
2024-06-03 01:39:30 [INFO]: Epoch 087 - training loss: 0.9519, validation loss: 2.3623
2024-06-03 01:39:32 [INFO]: Epoch 088 - training loss: 0.9526, validation loss: 2.3721
2024-06-03 01:39:34 [INFO]: Epoch 089 - training loss: 0.9512, validation loss: 2.3748
2024-06-03 01:39:35 [INFO]: Epoch 090 - training loss: 0.9507, validation loss: 2.3818
2024-06-03 01:39:37 [INFO]: Epoch 091 - training loss: 0.9502, validation loss: 2.3724
2024-06-03 01:39:39 [INFO]: Epoch 092 - training loss: 0.9494, validation loss: 2.3720
2024-06-03 01:39:40 [INFO]: Epoch 093 - training loss: 0.9508, validation loss: 2.3509
2024-06-03 01:39:42 [INFO]: Epoch 094 - training loss: 0.9516, validation loss: 2.3608
2024-06-03 01:39:44 [INFO]: Epoch 095 - training loss: 0.9504, validation loss: 2.3672
2024-06-03 01:39:45 [INFO]: Epoch 096 - training loss: 0.9491, validation loss: 2.3835
2024-06-03 01:39:47 [INFO]: Epoch 097 - training loss: 0.9504, validation loss: 2.3555
2024-06-03 01:39:49 [INFO]: Epoch 098 - training loss: 0.9496, validation loss: 2.3620
2024-06-03 01:39:50 [INFO]: Epoch 099 - training loss: 0.9501, validation loss: 2.3507
2024-06-03 01:39:52 [INFO]: Epoch 100 - training loss: 0.9486, validation loss: 2.3693
2024-06-03 01:39:52 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 01:39:52 [INFO]: Saved the model to results_point_rate09/Electricity/FiLM_Electricity/round_2/20240603_T013452/FiLM.pypots
2024-06-03 01:39:52 [INFO]: Successfully saved to results_point_rate09/Electricity/FiLM_Electricity/round_2/imputation.pkl
2024-06-03 01:39:52 [INFO]: Round2 - FiLM on Electricity: MAE=1.0843, MSE=1.9920, MRE=0.5804
2024-06-03 01:39:52 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:39:52 [INFO]: Using the given device: cuda:0
2024-06-03 01:39:52 [INFO]: Model files will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_3/20240603_T013952
2024-06-03 01:39:52 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_3/20240603_T013952/tensorboard
2024-06-03 01:39:52 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 01:39:54 [INFO]: Epoch 001 - training loss: 1.5465, validation loss: 4.0830
2024-06-03 01:39:56 [INFO]: Epoch 002 - training loss: 1.2227, validation loss: 3.6680
2024-06-03 01:39:58 [INFO]: Epoch 003 - training loss: 1.1118, validation loss: 3.5161
2024-06-03 01:39:59 [INFO]: Epoch 004 - training loss: 1.0778, validation loss: 3.4351
2024-06-03 01:40:01 [INFO]: Epoch 005 - training loss: 1.0656, validation loss: 3.3810
2024-06-03 01:40:03 [INFO]: Epoch 006 - training loss: 1.0568, validation loss: 3.3995
2024-06-03 01:40:04 [INFO]: Epoch 007 - training loss: 1.0481, validation loss: 3.3767
2024-06-03 01:40:06 [INFO]: Epoch 008 - training loss: 1.0413, validation loss: 3.3311
2024-06-03 01:40:08 [INFO]: Epoch 009 - training loss: 1.0392, validation loss: 3.3118
2024-06-03 01:40:09 [INFO]: Epoch 010 - training loss: 1.0342, validation loss: 3.3130
2024-06-03 01:40:11 [INFO]: Epoch 011 - training loss: 1.0303, validation loss: 3.2337
2024-06-03 01:40:13 [INFO]: Epoch 012 - training loss: 1.0250, validation loss: 3.2354
2024-06-03 01:40:15 [INFO]: Epoch 013 - training loss: 1.0218, validation loss: 3.1736
2024-06-03 01:40:16 [INFO]: Epoch 014 - training loss: 1.0192, validation loss: 3.1642
2024-06-03 01:40:18 [INFO]: Epoch 015 - training loss: 1.0147, validation loss: 3.0828
2024-06-03 01:40:20 [INFO]: Epoch 016 - training loss: 1.0121, validation loss: 3.1107
2024-06-03 01:40:21 [INFO]: Epoch 017 - training loss: 1.0088, validation loss: 3.0599
2024-06-03 01:40:23 [INFO]: Epoch 018 - training loss: 1.0055, validation loss: 3.0489
2024-06-03 01:40:25 [INFO]: Epoch 019 - training loss: 1.0029, validation loss: 3.0705
2024-06-03 01:40:26 [INFO]: Epoch 020 - training loss: 1.0015, validation loss: 3.0077
2024-06-03 01:40:28 [INFO]: Epoch 021 - training loss: 0.9994, validation loss: 2.9748
2024-06-03 01:40:30 [INFO]: Epoch 022 - training loss: 0.9960, validation loss: 2.9876
2024-06-03 01:40:31 [INFO]: Epoch 023 - training loss: 0.9948, validation loss: 2.9611
2024-06-03 01:40:33 [INFO]: Epoch 024 - training loss: 0.9920, validation loss: 2.9269
2024-06-03 01:40:35 [INFO]: Epoch 025 - training loss: 0.9906, validation loss: 2.9428
2024-06-03 01:40:37 [INFO]: Epoch 026 - training loss: 0.9879, validation loss: 2.9257
2024-06-03 01:40:38 [INFO]: Epoch 027 - training loss: 0.9875, validation loss: 2.8882
2024-06-03 01:40:40 [INFO]: Epoch 028 - training loss: 0.9853, validation loss: 2.9159
2024-06-03 01:40:42 [INFO]: Epoch 029 - training loss: 0.9851, validation loss: 2.8383
2024-06-03 01:40:43 [INFO]: Epoch 030 - training loss: 0.9805, validation loss: 2.8177
2024-06-03 01:40:45 [INFO]: Epoch 031 - training loss: 0.9802, validation loss: 2.8198
2024-06-03 01:40:47 [INFO]: Epoch 032 - training loss: 0.9792, validation loss: 2.7864
2024-06-03 01:40:48 [INFO]: Epoch 033 - training loss: 0.9779, validation loss: 2.7770
2024-06-03 01:40:50 [INFO]: Epoch 034 - training loss: 0.9763, validation loss: 2.7850
2024-06-03 01:40:52 [INFO]: Epoch 035 - training loss: 0.9744, validation loss: 2.7783
2024-06-03 01:40:54 [INFO]: Epoch 036 - training loss: 0.9749, validation loss: 2.7303
2024-06-03 01:40:55 [INFO]: Epoch 037 - training loss: 0.9746, validation loss: 2.7177
2024-06-03 01:40:57 [INFO]: Epoch 038 - training loss: 0.9727, validation loss: 2.7087
2024-06-03 01:40:59 [INFO]: Epoch 039 - training loss: 0.9710, validation loss: 2.6935
2024-06-03 01:41:00 [INFO]: Epoch 040 - training loss: 0.9705, validation loss: 2.6966
2024-06-03 01:41:02 [INFO]: Epoch 041 - training loss: 0.9703, validation loss: 2.6718
2024-06-03 01:41:04 [INFO]: Epoch 042 - training loss: 0.9685, validation loss: 2.6675
2024-06-03 01:41:05 [INFO]: Epoch 043 - training loss: 0.9678, validation loss: 2.6687
2024-06-03 01:41:07 [INFO]: Epoch 044 - training loss: 0.9675, validation loss: 2.6356
2024-06-03 01:41:09 [INFO]: Epoch 045 - training loss: 0.9661, validation loss: 2.6497
2024-06-03 01:41:10 [INFO]: Epoch 046 - training loss: 0.9654, validation loss: 2.6257
2024-06-03 01:41:12 [INFO]: Epoch 047 - training loss: 0.9644, validation loss: 2.6341
2024-06-03 01:41:14 [INFO]: Epoch 048 - training loss: 0.9641, validation loss: 2.6367
2024-06-03 01:41:16 [INFO]: Epoch 049 - training loss: 0.9645, validation loss: 2.6092
2024-06-03 01:41:17 [INFO]: Epoch 050 - training loss: 0.9634, validation loss: 2.6000
2024-06-03 01:41:19 [INFO]: Epoch 051 - training loss: 0.9639, validation loss: 2.5970
2024-06-03 01:41:21 [INFO]: Epoch 052 - training loss: 0.9621, validation loss: 2.5698
2024-06-03 01:41:22 [INFO]: Epoch 053 - training loss: 0.9604, validation loss: 2.5536
2024-06-03 01:41:24 [INFO]: Epoch 054 - training loss: 0.9616, validation loss: 2.5756
2024-06-03 01:41:26 [INFO]: Epoch 055 - training loss: 0.9602, validation loss: 2.5515
2024-06-03 01:41:27 [INFO]: Epoch 056 - training loss: 0.9608, validation loss: 2.5308
2024-06-03 01:41:29 [INFO]: Epoch 057 - training loss: 0.9605, validation loss: 2.5167
2024-06-03 01:41:31 [INFO]: Epoch 058 - training loss: 0.9604, validation loss: 2.4996
2024-06-03 01:41:32 [INFO]: Epoch 059 - training loss: 0.9590, validation loss: 2.5177
2024-06-03 01:41:34 [INFO]: Epoch 060 - training loss: 0.9588, validation loss: 2.4787
2024-06-03 01:41:36 [INFO]: Epoch 061 - training loss: 0.9578, validation loss: 2.4838
2024-06-03 01:41:37 [INFO]: Epoch 062 - training loss: 0.9546, validation loss: 2.4797
2024-06-03 01:41:39 [INFO]: Epoch 063 - training loss: 0.9565, validation loss: 2.4929
2024-06-03 01:41:41 [INFO]: Epoch 064 - training loss: 0.9570, validation loss: 2.4549
2024-06-03 01:41:43 [INFO]: Epoch 065 - training loss: 0.9578, validation loss: 2.4718
2024-06-03 01:41:44 [INFO]: Epoch 066 - training loss: 0.9559, validation loss: 2.4817
2024-06-03 01:41:46 [INFO]: Epoch 067 - training loss: 0.9547, validation loss: 2.4440
2024-06-03 01:41:48 [INFO]: Epoch 068 - training loss: 0.9553, validation loss: 2.4297
2024-06-03 01:41:49 [INFO]: Epoch 069 - training loss: 0.9568, validation loss: 2.4484
2024-06-03 01:41:51 [INFO]: Epoch 070 - training loss: 0.9550, validation loss: 2.4403
2024-06-03 01:41:53 [INFO]: Epoch 071 - training loss: 0.9554, validation loss: 2.4163
2024-06-03 01:41:54 [INFO]: Epoch 072 - training loss: 0.9536, validation loss: 2.4310
2024-06-03 01:41:56 [INFO]: Epoch 073 - training loss: 0.9542, validation loss: 2.4272
2024-06-03 01:41:58 [INFO]: Epoch 074 - training loss: 0.9529, validation loss: 2.4216
2024-06-03 01:41:59 [INFO]: Epoch 075 - training loss: 0.9537, validation loss: 2.4109
2024-06-03 01:42:01 [INFO]: Epoch 076 - training loss: 0.9528, validation loss: 2.4272
2024-06-03 01:42:03 [INFO]: Epoch 077 - training loss: 0.9528, validation loss: 2.4256
2024-06-03 01:42:05 [INFO]: Epoch 078 - training loss: 0.9521, validation loss: 2.4288
2024-06-03 01:42:06 [INFO]: Epoch 079 - training loss: 0.9527, validation loss: 2.4210
2024-06-03 01:42:08 [INFO]: Epoch 080 - training loss: 0.9520, validation loss: 2.4119
2024-06-03 01:42:10 [INFO]: Epoch 081 - training loss: 0.9518, validation loss: 2.3799
2024-06-03 01:42:11 [INFO]: Epoch 082 - training loss: 0.9519, validation loss: 2.4105
2024-06-03 01:42:13 [INFO]: Epoch 083 - training loss: 0.9530, validation loss: 2.3882
2024-06-03 01:42:15 [INFO]: Epoch 084 - training loss: 0.9519, validation loss: 2.4072
2024-06-03 01:42:16 [INFO]: Epoch 085 - training loss: 0.9517, validation loss: 2.3892
2024-06-03 01:42:18 [INFO]: Epoch 086 - training loss: 0.9524, validation loss: 2.3892
2024-06-03 01:42:20 [INFO]: Epoch 087 - training loss: 0.9501, validation loss: 2.3587
2024-06-03 01:42:21 [INFO]: Epoch 088 - training loss: 0.9506, validation loss: 2.3694
2024-06-03 01:42:23 [INFO]: Epoch 089 - training loss: 0.9513, validation loss: 2.3507
2024-06-03 01:42:25 [INFO]: Epoch 090 - training loss: 0.9508, validation loss: 2.3708
2024-06-03 01:42:27 [INFO]: Epoch 091 - training loss: 0.9502, validation loss: 2.3621
2024-06-03 01:42:28 [INFO]: Epoch 092 - training loss: 0.9499, validation loss: 2.3886
2024-06-03 01:42:30 [INFO]: Epoch 093 - training loss: 0.9482, validation loss: 2.3491
2024-06-03 01:42:32 [INFO]: Epoch 094 - training loss: 0.9499, validation loss: 2.3500
2024-06-03 01:42:33 [INFO]: Epoch 095 - training loss: 0.9496, validation loss: 2.3575
2024-06-03 01:42:35 [INFO]: Epoch 096 - training loss: 0.9495, validation loss: 2.3612
2024-06-03 01:42:37 [INFO]: Epoch 097 - training loss: 0.9491, validation loss: 2.3653
2024-06-03 01:42:38 [INFO]: Epoch 098 - training loss: 0.9486, validation loss: 2.3441
2024-06-03 01:42:40 [INFO]: Epoch 099 - training loss: 0.9484, validation loss: 2.3669
2024-06-03 01:42:42 [INFO]: Epoch 100 - training loss: 0.9478, validation loss: 2.3441
2024-06-03 01:42:42 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 01:42:42 [INFO]: Saved the model to results_point_rate09/Electricity/FiLM_Electricity/round_3/20240603_T013952/FiLM.pypots
2024-06-03 01:42:42 [INFO]: Successfully saved to results_point_rate09/Electricity/FiLM_Electricity/round_3/imputation.pkl
2024-06-03 01:42:42 [INFO]: Round3 - FiLM on Electricity: MAE=1.0217, MSE=1.8355, MRE=0.5470
2024-06-03 01:42:42 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:42:42 [INFO]: Using the given device: cuda:0
2024-06-03 01:42:42 [INFO]: Model files will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_4/20240603_T014242
2024-06-03 01:42:42 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/FiLM_Electricity/round_4/20240603_T014242/tensorboard
2024-06-03 01:42:42 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 01:42:44 [INFO]: Epoch 001 - training loss: 1.5519, validation loss: 3.6155
2024-06-03 01:42:46 [INFO]: Epoch 002 - training loss: 1.1969, validation loss: 3.6161
2024-06-03 01:42:47 [INFO]: Epoch 003 - training loss: 1.1052, validation loss: 3.4663
2024-06-03 01:42:49 [INFO]: Epoch 004 - training loss: 1.0815, validation loss: 3.4631
2024-06-03 01:42:51 [INFO]: Epoch 005 - training loss: 1.0679, validation loss: 3.4256
2024-06-03 01:42:53 [INFO]: Epoch 006 - training loss: 1.0598, validation loss: 3.4104
2024-06-03 01:42:54 [INFO]: Epoch 007 - training loss: 1.0509, validation loss: 3.3296
2024-06-03 01:42:56 [INFO]: Epoch 008 - training loss: 1.0461, validation loss: 3.3505
2024-06-03 01:42:58 [INFO]: Epoch 009 - training loss: 1.0431, validation loss: 3.2858
2024-06-03 01:42:59 [INFO]: Epoch 010 - training loss: 1.0388, validation loss: 3.2954
2024-06-03 01:43:01 [INFO]: Epoch 011 - training loss: 1.0344, validation loss: 3.2505
2024-06-03 01:43:03 [INFO]: Epoch 012 - training loss: 1.0309, validation loss: 3.1690
2024-06-03 01:43:04 [INFO]: Epoch 013 - training loss: 1.0289, validation loss: 3.1808
2024-06-03 01:43:06 [INFO]: Epoch 014 - training loss: 1.0247, validation loss: 3.1822
2024-06-03 01:43:08 [INFO]: Epoch 015 - training loss: 1.0213, validation loss: 3.2148
2024-06-03 01:43:09 [INFO]: Epoch 016 - training loss: 1.0183, validation loss: 3.1090
2024-06-03 01:43:11 [INFO]: Epoch 017 - training loss: 1.0147, validation loss: 3.0873
2024-06-03 01:43:13 [INFO]: Epoch 018 - training loss: 1.0127, validation loss: 3.0849
2024-06-03 01:43:15 [INFO]: Epoch 019 - training loss: 1.0099, validation loss: 3.0350
2024-06-03 01:43:16 [INFO]: Epoch 020 - training loss: 1.0075, validation loss: 3.0524
2024-06-03 01:43:18 [INFO]: Epoch 021 - training loss: 1.0043, validation loss: 3.0147
2024-06-03 01:43:20 [INFO]: Epoch 022 - training loss: 1.0033, validation loss: 2.9730
2024-06-03 01:43:21 [INFO]: Epoch 023 - training loss: 1.0026, validation loss: 2.9842
2024-06-03 01:43:23 [INFO]: Epoch 024 - training loss: 0.9988, validation loss: 2.9377
2024-06-03 01:43:25 [INFO]: Epoch 025 - training loss: 0.9971, validation loss: 2.9722
2024-06-03 01:43:26 [INFO]: Epoch 026 - training loss: 0.9952, validation loss: 2.9128
2024-06-03 01:43:28 [INFO]: Epoch 027 - training loss: 0.9945, validation loss: 2.9181
2024-06-03 01:43:30 [INFO]: Epoch 028 - training loss: 0.9935, validation loss: 2.9078
2024-06-03 01:43:31 [INFO]: Epoch 029 - training loss: 0.9917, validation loss: 2.9114
2024-06-03 01:43:33 [INFO]: Epoch 030 - training loss: 0.9901, validation loss: 2.8466
2024-06-03 01:43:35 [INFO]: Epoch 031 - training loss: 0.9871, validation loss: 2.8612
2024-06-03 01:43:37 [INFO]: Epoch 032 - training loss: 0.9877, validation loss: 2.8845
2024-06-03 01:43:38 [INFO]: Epoch 033 - training loss: 0.9873, validation loss: 2.8360
2024-06-03 01:43:40 [INFO]: Epoch 034 - training loss: 0.9829, validation loss: 2.8088
2024-06-03 01:43:42 [INFO]: Epoch 035 - training loss: 0.9819, validation loss: 2.8377
2024-06-03 01:43:43 [INFO]: Epoch 036 - training loss: 0.9804, validation loss: 2.7788
2024-06-03 01:43:45 [INFO]: Epoch 037 - training loss: 0.9794, validation loss: 2.8220
2024-06-03 01:43:47 [INFO]: Epoch 038 - training loss: 0.9777, validation loss: 2.8004
2024-06-03 01:43:48 [INFO]: Epoch 039 - training loss: 0.9773, validation loss: 2.7611
2024-06-03 01:43:50 [INFO]: Epoch 040 - training loss: 0.9767, validation loss: 2.7753
2024-06-03 01:43:52 [INFO]: Epoch 041 - training loss: 0.9749, validation loss: 2.7411
2024-06-03 01:43:53 [INFO]: Epoch 042 - training loss: 0.9745, validation loss: 2.7515
2024-06-03 01:43:55 [INFO]: Epoch 043 - training loss: 0.9739, validation loss: 2.7321
2024-06-03 01:43:57 [INFO]: Epoch 044 - training loss: 0.9728, validation loss: 2.6895
2024-06-03 01:43:58 [INFO]: Epoch 045 - training loss: 0.9718, validation loss: 2.6922
2024-06-03 01:44:00 [INFO]: Epoch 046 - training loss: 0.9715, validation loss: 2.6778
2024-06-03 01:44:02 [INFO]: Epoch 047 - training loss: 0.9711, validation loss: 2.6613
2024-06-03 01:44:03 [INFO]: Epoch 048 - training loss: 0.9695, validation loss: 2.6424
2024-06-03 01:44:05 [INFO]: Epoch 049 - training loss: 0.9687, validation loss: 2.6826
2024-06-03 01:44:07 [INFO]: Epoch 050 - training loss: 0.9664, validation loss: 2.6255
2024-06-03 01:44:08 [INFO]: Epoch 051 - training loss: 0.9658, validation loss: 2.6431
2024-06-03 01:44:10 [INFO]: Epoch 052 - training loss: 0.9660, validation loss: 2.6246
2024-06-03 01:44:12 [INFO]: Epoch 053 - training loss: 0.9659, validation loss: 2.6336
2024-06-03 01:44:14 [INFO]: Epoch 054 - training loss: 0.9640, validation loss: 2.6180
2024-06-03 01:44:15 [INFO]: Epoch 055 - training loss: 0.9633, validation loss: 2.6018
2024-06-03 01:44:17 [INFO]: Epoch 056 - training loss: 0.9632, validation loss: 2.5975
2024-06-03 01:44:19 [INFO]: Epoch 057 - training loss: 0.9637, validation loss: 2.5617
2024-06-03 01:44:20 [INFO]: Epoch 058 - training loss: 0.9625, validation loss: 2.5828
2024-06-03 01:44:22 [INFO]: Epoch 059 - training loss: 0.9615, validation loss: 2.5545
2024-06-03 01:44:24 [INFO]: Epoch 060 - training loss: 0.9612, validation loss: 2.5649
2024-06-03 01:44:25 [INFO]: Epoch 061 - training loss: 0.9604, validation loss: 2.5490
2024-06-03 01:44:27 [INFO]: Epoch 062 - training loss: 0.9586, validation loss: 2.5411
2024-06-03 01:44:29 [INFO]: Epoch 063 - training loss: 0.9600, validation loss: 2.5504
2024-06-03 01:44:30 [INFO]: Epoch 064 - training loss: 0.9603, validation loss: 2.5311
2024-06-03 01:44:32 [INFO]: Epoch 065 - training loss: 0.9584, validation loss: 2.5502
2024-06-03 01:44:34 [INFO]: Epoch 066 - training loss: 0.9600, validation loss: 2.5000
2024-06-03 01:44:35 [INFO]: Epoch 067 - training loss: 0.9594, validation loss: 2.5339
2024-06-03 01:44:37 [INFO]: Epoch 068 - training loss: 0.9580, validation loss: 2.5120
2024-06-03 01:44:39 [INFO]: Epoch 069 - training loss: 0.9568, validation loss: 2.5086
2024-06-03 01:44:41 [INFO]: Epoch 070 - training loss: 0.9570, validation loss: 2.4860
2024-06-03 01:44:42 [INFO]: Epoch 071 - training loss: 0.9564, validation loss: 2.4834
2024-06-03 01:44:44 [INFO]: Epoch 072 - training loss: 0.9563, validation loss: 2.5059
2024-06-03 01:44:46 [INFO]: Epoch 073 - training loss: 0.9561, validation loss: 2.4739
2024-06-03 01:44:47 [INFO]: Epoch 074 - training loss: 0.9552, validation loss: 2.4673
2024-06-03 01:44:49 [INFO]: Epoch 075 - training loss: 0.9552, validation loss: 2.4794
2024-06-03 01:44:51 [INFO]: Epoch 076 - training loss: 0.9547, validation loss: 2.4709
2024-06-03 01:44:52 [INFO]: Epoch 077 - training loss: 0.9552, validation loss: 2.4370
2024-06-03 01:44:54 [INFO]: Epoch 078 - training loss: 0.9547, validation loss: 2.4700
2024-06-03 01:44:56 [INFO]: Epoch 079 - training loss: 0.9550, validation loss: 2.4293
2024-06-03 01:44:57 [INFO]: Epoch 080 - training loss: 0.9537, validation loss: 2.4500
2024-06-03 01:44:59 [INFO]: Epoch 081 - training loss: 0.9524, validation loss: 2.4281
2024-06-03 01:45:01 [INFO]: Epoch 082 - training loss: 0.9533, validation loss: 2.4102
2024-06-03 01:45:02 [INFO]: Epoch 083 - training loss: 0.9520, validation loss: 2.4473
2024-06-03 01:45:04 [INFO]: Epoch 084 - training loss: 0.9530, validation loss: 2.4193
2024-06-03 01:45:06 [INFO]: Epoch 085 - training loss: 0.9523, validation loss: 2.4314
2024-06-03 01:45:07 [INFO]: Epoch 086 - training loss: 0.9512, validation loss: 2.4152
2024-06-03 01:45:09 [INFO]: Epoch 087 - training loss: 0.9511, validation loss: 2.4084
2024-06-03 01:45:11 [INFO]: Epoch 088 - training loss: 0.9513, validation loss: 2.3929
2024-06-03 01:45:13 [INFO]: Epoch 089 - training loss: 0.9514, validation loss: 2.4247
2024-06-03 01:45:14 [INFO]: Epoch 090 - training loss: 0.9528, validation loss: 2.4087
2024-06-03 01:45:16 [INFO]: Epoch 091 - training loss: 0.9506, validation loss: 2.3956
2024-06-03 01:45:18 [INFO]: Epoch 092 - training loss: 0.9513, validation loss: 2.3791
2024-06-03 01:45:19 [INFO]: Epoch 093 - training loss: 0.9503, validation loss: 2.4098
2024-06-03 01:45:21 [INFO]: Epoch 094 - training loss: 0.9491, validation loss: 2.3786
2024-06-03 01:45:23 [INFO]: Epoch 095 - training loss: 0.9501, validation loss: 2.3848
2024-06-03 01:45:24 [INFO]: Epoch 096 - training loss: 0.9493, validation loss: 2.3654
2024-06-03 01:45:26 [INFO]: Epoch 097 - training loss: 0.9498, validation loss: 2.3725
2024-06-03 01:45:28 [INFO]: Epoch 098 - training loss: 0.9492, validation loss: 2.3640
2024-06-03 01:45:29 [INFO]: Epoch 099 - training loss: 0.9494, validation loss: 2.3785
2024-06-03 01:45:31 [INFO]: Epoch 100 - training loss: 0.9489, validation loss: 2.3745
2024-06-03 01:45:31 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 01:45:31 [INFO]: Saved the model to results_point_rate09/Electricity/FiLM_Electricity/round_4/20240603_T014242/FiLM.pypots
2024-06-03 01:45:31 [INFO]: Successfully saved to results_point_rate09/Electricity/FiLM_Electricity/round_4/imputation.pkl
2024-06-03 01:45:31 [INFO]: Round4 - FiLM on Electricity: MAE=1.0502, MSE=1.9212, MRE=0.5622
2024-06-03 01:45:31 [INFO]: Done! Final results:
Averaged FiLM (570,613 params) on Electricity: MAE=1.0489 ± 0.026919818752210688, MSE=1.9320 ± 0.07797954128382295, MRE=0.5615 ± 0.01441094711827755, average inference time=0.34
