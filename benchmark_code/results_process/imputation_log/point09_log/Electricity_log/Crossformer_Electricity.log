2024-06-03 01:11:55 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:11:55 [INFO]: Using the given device: cuda:0
2024-06-03 01:11:55 [INFO]: Model files will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_0/20240603_T011155
2024-06-03 01:11:55 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_0/20240603_T011155/tensorboard
2024-06-03 01:11:56 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-03 01:12:16 [INFO]: Epoch 001 - training loss: 1.2108, validation loss: 3.6559
2024-06-03 01:12:37 [INFO]: Epoch 002 - training loss: 0.9576, validation loss: 3.2338
2024-06-03 01:12:58 [INFO]: Epoch 003 - training loss: 0.7419, validation loss: 2.9938
2024-06-03 01:13:20 [INFO]: Epoch 004 - training loss: 0.6749, validation loss: 2.8866
2024-06-03 01:13:41 [INFO]: Epoch 005 - training loss: 0.6431, validation loss: 2.8120
2024-06-03 01:14:02 [INFO]: Epoch 006 - training loss: 0.6177, validation loss: 2.7384
2024-06-03 01:14:23 [INFO]: Epoch 007 - training loss: 0.5967, validation loss: 2.6915
2024-06-03 01:14:45 [INFO]: Epoch 008 - training loss: 0.5776, validation loss: 2.6519
2024-06-03 01:15:06 [INFO]: Epoch 009 - training loss: 0.5627, validation loss: 2.6140
2024-06-03 01:15:27 [INFO]: Epoch 010 - training loss: 0.5480, validation loss: 2.5907
2024-06-03 01:15:49 [INFO]: Epoch 011 - training loss: 0.5372, validation loss: 2.5536
2024-06-03 01:16:10 [INFO]: Epoch 012 - training loss: 0.5274, validation loss: 2.5338
2024-06-03 01:16:30 [INFO]: Epoch 013 - training loss: 0.5183, validation loss: 2.5131
2024-06-03 01:16:51 [INFO]: Epoch 014 - training loss: 0.5112, validation loss: 2.4985
2024-06-03 01:17:13 [INFO]: Epoch 015 - training loss: 0.5053, validation loss: 2.4854
2024-06-03 01:17:34 [INFO]: Epoch 016 - training loss: 0.4998, validation loss: 2.4729
2024-06-03 01:17:56 [INFO]: Epoch 017 - training loss: 0.4926, validation loss: 2.4741
2024-06-03 01:18:17 [INFO]: Epoch 018 - training loss: 0.4893, validation loss: 2.4500
2024-06-03 01:18:39 [INFO]: Epoch 019 - training loss: 0.4837, validation loss: 2.4515
2024-06-03 01:19:00 [INFO]: Epoch 020 - training loss: 0.4801, validation loss: 2.4446
2024-06-03 01:19:22 [INFO]: Epoch 021 - training loss: 0.4775, validation loss: 2.4416
2024-06-03 01:19:43 [INFO]: Epoch 022 - training loss: 0.4719, validation loss: 2.4359
2024-06-03 01:20:04 [INFO]: Epoch 023 - training loss: 0.4687, validation loss: 2.4241
2024-06-03 01:20:25 [INFO]: Epoch 024 - training loss: 0.4664, validation loss: 2.4433
2024-06-03 01:20:46 [INFO]: Epoch 025 - training loss: 0.4636, validation loss: 2.4382
2024-06-03 01:21:07 [INFO]: Epoch 026 - training loss: 0.4607, validation loss: 2.4266
2024-06-03 01:21:28 [INFO]: Epoch 027 - training loss: 0.4585, validation loss: 2.4313
2024-06-03 01:21:49 [INFO]: Epoch 028 - training loss: 0.4574, validation loss: 2.4254
2024-06-03 01:22:11 [INFO]: Epoch 029 - training loss: 0.4519, validation loss: 2.4193
2024-06-03 01:22:33 [INFO]: Epoch 030 - training loss: 0.4500, validation loss: 2.4248
2024-06-03 01:22:54 [INFO]: Epoch 031 - training loss: 0.4487, validation loss: 2.4176
2024-06-03 01:23:15 [INFO]: Epoch 032 - training loss: 0.4457, validation loss: 2.4323
2024-06-03 01:23:37 [INFO]: Epoch 033 - training loss: 0.4441, validation loss: 2.4509
2024-06-03 01:23:58 [INFO]: Epoch 034 - training loss: 0.4435, validation loss: 2.4458
2024-06-03 01:24:19 [INFO]: Epoch 035 - training loss: 0.4404, validation loss: 2.4460
2024-06-03 01:24:40 [INFO]: Epoch 036 - training loss: 0.4392, validation loss: 2.4363
2024-06-03 01:25:01 [INFO]: Epoch 037 - training loss: 0.4379, validation loss: 2.4442
2024-06-03 01:25:23 [INFO]: Epoch 038 - training loss: 0.4362, validation loss: 2.4294
2024-06-03 01:25:44 [INFO]: Epoch 039 - training loss: 0.4350, validation loss: 2.4708
2024-06-03 01:26:05 [INFO]: Epoch 040 - training loss: 0.4350, validation loss: 2.4538
2024-06-03 01:26:26 [INFO]: Epoch 041 - training loss: 0.4320, validation loss: 2.4365
2024-06-03 01:26:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:26:26 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 01:26:27 [INFO]: Saved the model to results_point_rate09/Electricity/Crossformer_Electricity/round_0/20240603_T011155/Crossformer.pypots
2024-06-03 01:26:29 [INFO]: Successfully saved to results_point_rate09/Electricity/Crossformer_Electricity/round_0/imputation.pkl
2024-06-03 01:26:29 [INFO]: Round0 - Crossformer on Electricity: MAE=1.0331, MSE=2.5454, MRE=0.5531
2024-06-03 01:26:29 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:26:29 [INFO]: Using the given device: cuda:0
2024-06-03 01:26:29 [INFO]: Model files will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_1/20240603_T012629
2024-06-03 01:26:29 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_1/20240603_T012629/tensorboard
2024-06-03 01:26:29 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-03 01:26:51 [INFO]: Epoch 001 - training loss: 1.2068, validation loss: 3.6797
2024-06-03 01:27:13 [INFO]: Epoch 002 - training loss: 0.9889, validation loss: 3.4876
2024-06-03 01:27:34 [INFO]: Epoch 003 - training loss: 0.7881, validation loss: 3.0016
2024-06-03 01:27:55 [INFO]: Epoch 004 - training loss: 0.6783, validation loss: 2.8967
2024-06-03 01:28:16 [INFO]: Epoch 005 - training loss: 0.6411, validation loss: 2.8067
2024-06-03 01:28:36 [INFO]: Epoch 006 - training loss: 0.6119, validation loss: 2.7381
2024-06-03 01:28:57 [INFO]: Epoch 007 - training loss: 0.5871, validation loss: 2.6561
2024-06-03 01:29:18 [INFO]: Epoch 008 - training loss: 0.5686, validation loss: 2.6148
2024-06-03 01:29:39 [INFO]: Epoch 009 - training loss: 0.5525, validation loss: 2.5828
2024-06-03 01:30:00 [INFO]: Epoch 010 - training loss: 0.5404, validation loss: 2.5395
2024-06-03 01:30:21 [INFO]: Epoch 011 - training loss: 0.5299, validation loss: 2.5168
2024-06-03 01:30:43 [INFO]: Epoch 012 - training loss: 0.5220, validation loss: 2.4971
2024-06-03 01:31:04 [INFO]: Epoch 013 - training loss: 0.5138, validation loss: 2.4769
2024-06-03 01:31:25 [INFO]: Epoch 014 - training loss: 0.5059, validation loss: 2.4601
2024-06-03 01:31:46 [INFO]: Epoch 015 - training loss: 0.5011, validation loss: 2.4454
2024-06-03 01:32:08 [INFO]: Epoch 016 - training loss: 0.4951, validation loss: 2.4325
2024-06-03 01:32:28 [INFO]: Epoch 017 - training loss: 0.4903, validation loss: 2.4241
2024-06-03 01:32:49 [INFO]: Epoch 018 - training loss: 0.4862, validation loss: 2.4282
2024-06-03 01:33:10 [INFO]: Epoch 019 - training loss: 0.4840, validation loss: 2.4168
2024-06-03 01:33:31 [INFO]: Epoch 020 - training loss: 0.4769, validation loss: 2.4128
2024-06-03 01:33:52 [INFO]: Epoch 021 - training loss: 0.4734, validation loss: 2.4012
2024-06-03 01:34:13 [INFO]: Epoch 022 - training loss: 0.4704, validation loss: 2.3915
2024-06-03 01:34:35 [INFO]: Epoch 023 - training loss: 0.4669, validation loss: 2.3907
2024-06-03 01:34:56 [INFO]: Epoch 024 - training loss: 0.4638, validation loss: 2.3812
2024-06-03 01:35:18 [INFO]: Epoch 025 - training loss: 0.4601, validation loss: 2.3801
2024-06-03 01:35:39 [INFO]: Epoch 026 - training loss: 0.4582, validation loss: 2.3853
2024-06-03 01:36:00 [INFO]: Epoch 027 - training loss: 0.4565, validation loss: 2.3805
2024-06-03 01:36:21 [INFO]: Epoch 028 - training loss: 0.4538, validation loss: 2.3976
2024-06-03 01:36:41 [INFO]: Epoch 029 - training loss: 0.4525, validation loss: 2.3821
2024-06-03 01:37:02 [INFO]: Epoch 030 - training loss: 0.4492, validation loss: 2.3861
2024-06-03 01:37:23 [INFO]: Epoch 031 - training loss: 0.4477, validation loss: 2.3855
2024-06-03 01:37:44 [INFO]: Epoch 032 - training loss: 0.4453, validation loss: 2.3926
2024-06-03 01:38:06 [INFO]: Epoch 033 - training loss: 0.4457, validation loss: 2.3938
2024-06-03 01:38:27 [INFO]: Epoch 034 - training loss: 0.4415, validation loss: 2.3926
2024-06-03 01:38:48 [INFO]: Epoch 035 - training loss: 0.4411, validation loss: 2.3919
2024-06-03 01:38:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:38:48 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 01:38:49 [INFO]: Saved the model to results_point_rate09/Electricity/Crossformer_Electricity/round_1/20240603_T012629/Crossformer.pypots
2024-06-03 01:38:51 [INFO]: Successfully saved to results_point_rate09/Electricity/Crossformer_Electricity/round_1/imputation.pkl
2024-06-03 01:38:51 [INFO]: Round1 - Crossformer on Electricity: MAE=1.0127, MSE=2.4279, MRE=0.5421
2024-06-03 01:38:51 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:38:51 [INFO]: Using the given device: cuda:0
2024-06-03 01:38:51 [INFO]: Model files will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_2/20240603_T013851
2024-06-03 01:38:51 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_2/20240603_T013851/tensorboard
2024-06-03 01:38:51 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-03 01:39:13 [INFO]: Epoch 001 - training loss: 1.2163, validation loss: 3.6916
2024-06-03 01:39:34 [INFO]: Epoch 002 - training loss: 0.9442, validation loss: 3.2178
2024-06-03 01:39:55 [INFO]: Epoch 003 - training loss: 0.7342, validation loss: 2.9841
2024-06-03 01:40:16 [INFO]: Epoch 004 - training loss: 0.6711, validation loss: 2.8716
2024-06-03 01:40:36 [INFO]: Epoch 005 - training loss: 0.6359, validation loss: 2.7913
2024-06-03 01:40:56 [INFO]: Epoch 006 - training loss: 0.6128, validation loss: 2.7210
2024-06-03 01:41:17 [INFO]: Epoch 007 - training loss: 0.5881, validation loss: 2.6540
2024-06-03 01:41:39 [INFO]: Epoch 008 - training loss: 0.5700, validation loss: 2.6224
2024-06-03 01:42:00 [INFO]: Epoch 009 - training loss: 0.5557, validation loss: 2.6012
2024-06-03 01:42:21 [INFO]: Epoch 010 - training loss: 0.5410, validation loss: 2.5728
2024-06-03 01:42:42 [INFO]: Epoch 011 - training loss: 0.5329, validation loss: 2.5476
2024-06-03 01:43:02 [INFO]: Epoch 012 - training loss: 0.5220, validation loss: 2.5422
2024-06-03 01:43:22 [INFO]: Epoch 013 - training loss: 0.5164, validation loss: 2.5099
2024-06-03 01:43:41 [INFO]: Epoch 014 - training loss: 0.5094, validation loss: 2.4996
2024-06-03 01:44:01 [INFO]: Epoch 015 - training loss: 0.5017, validation loss: 2.4893
2024-06-03 01:44:21 [INFO]: Epoch 016 - training loss: 0.4962, validation loss: 2.4831
2024-06-03 01:44:40 [INFO]: Epoch 017 - training loss: 0.4910, validation loss: 2.4807
2024-06-03 01:45:00 [INFO]: Epoch 018 - training loss: 0.4890, validation loss: 2.4671
2024-06-03 01:45:19 [INFO]: Epoch 019 - training loss: 0.4832, validation loss: 2.4682
2024-06-03 01:45:39 [INFO]: Epoch 020 - training loss: 0.4777, validation loss: 2.4498
2024-06-03 01:45:59 [INFO]: Epoch 021 - training loss: 0.4753, validation loss: 2.4481
2024-06-03 01:46:19 [INFO]: Epoch 022 - training loss: 0.4725, validation loss: 2.4482
2024-06-03 01:46:39 [INFO]: Epoch 023 - training loss: 0.4692, validation loss: 2.4390
2024-06-03 01:46:59 [INFO]: Epoch 024 - training loss: 0.4656, validation loss: 2.4529
2024-06-03 01:47:18 [INFO]: Epoch 025 - training loss: 0.4627, validation loss: 2.4376
2024-06-03 01:47:38 [INFO]: Epoch 026 - training loss: 0.4593, validation loss: 2.4393
2024-06-03 01:47:58 [INFO]: Epoch 027 - training loss: 0.4575, validation loss: 2.4480
2024-06-03 01:48:17 [INFO]: Epoch 028 - training loss: 0.4558, validation loss: 2.4538
2024-06-03 01:48:36 [INFO]: Epoch 029 - training loss: 0.4536, validation loss: 2.4544
2024-06-03 01:48:55 [INFO]: Epoch 030 - training loss: 0.4517, validation loss: 2.4407
2024-06-03 01:49:15 [INFO]: Epoch 031 - training loss: 0.4498, validation loss: 2.4598
2024-06-03 01:49:35 [INFO]: Epoch 032 - training loss: 0.4469, validation loss: 2.4383
2024-06-03 01:49:54 [INFO]: Epoch 033 - training loss: 0.4461, validation loss: 2.4618
2024-06-03 01:50:14 [INFO]: Epoch 034 - training loss: 0.4442, validation loss: 2.4471
2024-06-03 01:50:34 [INFO]: Epoch 035 - training loss: 0.4420, validation loss: 2.4517
2024-06-03 01:50:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:50:34 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 01:50:34 [INFO]: Saved the model to results_point_rate09/Electricity/Crossformer_Electricity/round_2/20240603_T013851/Crossformer.pypots
2024-06-03 01:50:36 [INFO]: Successfully saved to results_point_rate09/Electricity/Crossformer_Electricity/round_2/imputation.pkl
2024-06-03 01:50:36 [INFO]: Round2 - Crossformer on Electricity: MAE=1.0212, MSE=2.5211, MRE=0.5467
2024-06-03 01:50:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:50:36 [INFO]: Using the given device: cuda:0
2024-06-03 01:50:36 [INFO]: Model files will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_3/20240603_T015036
2024-06-03 01:50:36 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_3/20240603_T015036/tensorboard
2024-06-03 01:50:36 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-03 01:50:57 [INFO]: Epoch 001 - training loss: 1.2141, validation loss: 3.6687
2024-06-03 01:51:17 [INFO]: Epoch 002 - training loss: 0.9751, validation loss: 3.2944
2024-06-03 01:51:37 [INFO]: Epoch 003 - training loss: 0.7624, validation loss: 3.0050
2024-06-03 01:51:57 [INFO]: Epoch 004 - training loss: 0.6805, validation loss: 2.9288
2024-06-03 01:52:16 [INFO]: Epoch 005 - training loss: 0.6432, validation loss: 2.8392
2024-06-03 01:52:35 [INFO]: Epoch 006 - training loss: 0.6167, validation loss: 2.7710
2024-06-03 01:52:54 [INFO]: Epoch 007 - training loss: 0.5943, validation loss: 2.7189
2024-06-03 01:53:14 [INFO]: Epoch 008 - training loss: 0.5736, validation loss: 2.6823
2024-06-03 01:53:34 [INFO]: Epoch 009 - training loss: 0.5573, validation loss: 2.6320
2024-06-03 01:53:54 [INFO]: Epoch 010 - training loss: 0.5450, validation loss: 2.5830
2024-06-03 01:54:13 [INFO]: Epoch 011 - training loss: 0.5334, validation loss: 2.5438
2024-06-03 01:54:32 [INFO]: Epoch 012 - training loss: 0.5263, validation loss: 2.5485
2024-06-03 01:54:51 [INFO]: Epoch 013 - training loss: 0.5166, validation loss: 2.5183
2024-06-03 01:55:10 [INFO]: Epoch 014 - training loss: 0.5097, validation loss: 2.4994
2024-06-03 01:55:29 [INFO]: Epoch 015 - training loss: 0.5032, validation loss: 2.4955
2024-06-03 01:55:48 [INFO]: Epoch 016 - training loss: 0.4983, validation loss: 2.4835
2024-06-03 01:56:07 [INFO]: Epoch 017 - training loss: 0.4926, validation loss: 2.4825
2024-06-03 01:56:26 [INFO]: Epoch 018 - training loss: 0.4878, validation loss: 2.4771
2024-06-03 01:56:44 [INFO]: Epoch 019 - training loss: 0.4864, validation loss: 2.4552
2024-06-03 01:57:03 [INFO]: Epoch 020 - training loss: 0.4798, validation loss: 2.4543
2024-06-03 01:57:21 [INFO]: Epoch 021 - training loss: 0.4764, validation loss: 2.4437
2024-06-03 01:57:41 [INFO]: Epoch 022 - training loss: 0.4730, validation loss: 2.4624
2024-06-03 01:58:00 [INFO]: Epoch 023 - training loss: 0.4706, validation loss: 2.4557
2024-06-03 01:58:19 [INFO]: Epoch 024 - training loss: 0.4659, validation loss: 2.4440
2024-06-03 01:58:38 [INFO]: Epoch 025 - training loss: 0.4634, validation loss: 2.4685
2024-06-03 01:58:57 [INFO]: Epoch 026 - training loss: 0.4614, validation loss: 2.4351
2024-06-03 01:59:16 [INFO]: Epoch 027 - training loss: 0.4581, validation loss: 2.4491
2024-06-03 01:59:34 [INFO]: Epoch 028 - training loss: 0.4556, validation loss: 2.4501
2024-06-03 01:59:53 [INFO]: Epoch 029 - training loss: 0.4543, validation loss: 2.4456
2024-06-03 02:00:12 [INFO]: Epoch 030 - training loss: 0.4514, validation loss: 2.4520
2024-06-03 02:00:31 [INFO]: Epoch 031 - training loss: 0.4494, validation loss: 2.4842
2024-06-03 02:00:49 [INFO]: Epoch 032 - training loss: 0.4470, validation loss: 2.4508
2024-06-03 02:01:08 [INFO]: Epoch 033 - training loss: 0.4452, validation loss: 2.4652
2024-06-03 02:01:27 [INFO]: Epoch 034 - training loss: 0.4436, validation loss: 2.4769
2024-06-03 02:01:46 [INFO]: Epoch 035 - training loss: 0.4433, validation loss: 2.4601
2024-06-03 02:02:04 [INFO]: Epoch 036 - training loss: 0.4407, validation loss: 2.4687
2024-06-03 02:02:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:02:04 [INFO]: Finished training. The best model is from epoch#26.
2024-06-03 02:02:05 [INFO]: Saved the model to results_point_rate09/Electricity/Crossformer_Electricity/round_3/20240603_T015036/Crossformer.pypots
2024-06-03 02:02:07 [INFO]: Successfully saved to results_point_rate09/Electricity/Crossformer_Electricity/round_3/imputation.pkl
2024-06-03 02:02:07 [INFO]: Round3 - Crossformer on Electricity: MAE=1.0550, MSE=2.6366, MRE=0.5648
2024-06-03 02:02:07 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:02:07 [INFO]: Using the given device: cuda:0
2024-06-03 02:02:07 [INFO]: Model files will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_4/20240603_T020207
2024-06-03 02:02:07 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/Crossformer_Electricity/round_4/20240603_T020207/tensorboard
2024-06-03 02:02:07 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-03 02:02:26 [INFO]: Epoch 001 - training loss: 1.2117, validation loss: 3.6450
2024-06-03 02:02:45 [INFO]: Epoch 002 - training loss: 0.9555, validation loss: 3.2085
2024-06-03 02:03:04 [INFO]: Epoch 003 - training loss: 0.7386, validation loss: 2.9904
2024-06-03 02:03:23 [INFO]: Epoch 004 - training loss: 0.6730, validation loss: 2.9006
2024-06-03 02:03:42 [INFO]: Epoch 005 - training loss: 0.6417, validation loss: 2.8028
2024-06-03 02:04:01 [INFO]: Epoch 006 - training loss: 0.6166, validation loss: 2.7367
2024-06-03 02:04:20 [INFO]: Epoch 007 - training loss: 0.5949, validation loss: 2.6848
2024-06-03 02:04:38 [INFO]: Epoch 008 - training loss: 0.5786, validation loss: 2.6538
2024-06-03 02:04:57 [INFO]: Epoch 009 - training loss: 0.5638, validation loss: 2.6159
2024-06-03 02:05:16 [INFO]: Epoch 010 - training loss: 0.5474, validation loss: 2.5773
2024-06-03 02:05:35 [INFO]: Epoch 011 - training loss: 0.5358, validation loss: 2.5460
2024-06-03 02:05:54 [INFO]: Epoch 012 - training loss: 0.5256, validation loss: 2.5343
2024-06-03 02:06:13 [INFO]: Epoch 013 - training loss: 0.5189, validation loss: 2.5190
2024-06-03 02:06:31 [INFO]: Epoch 014 - training loss: 0.5110, validation loss: 2.4993
2024-06-03 02:06:51 [INFO]: Epoch 015 - training loss: 0.5031, validation loss: 2.4788
2024-06-03 02:07:10 [INFO]: Epoch 016 - training loss: 0.4985, validation loss: 2.4713
2024-06-03 02:07:29 [INFO]: Epoch 017 - training loss: 0.4935, validation loss: 2.4532
2024-06-03 02:07:48 [INFO]: Epoch 018 - training loss: 0.4882, validation loss: 2.4460
2024-06-03 02:08:07 [INFO]: Epoch 019 - training loss: 0.4835, validation loss: 2.4332
2024-06-03 02:08:25 [INFO]: Epoch 020 - training loss: 0.4794, validation loss: 2.4344
2024-06-03 02:08:44 [INFO]: Epoch 021 - training loss: 0.4752, validation loss: 2.4262
2024-06-03 02:09:03 [INFO]: Epoch 022 - training loss: 0.4717, validation loss: 2.4171
2024-06-03 02:09:22 [INFO]: Epoch 023 - training loss: 0.4685, validation loss: 2.4148
2024-06-03 02:09:41 [INFO]: Epoch 024 - training loss: 0.4668, validation loss: 2.4028
2024-06-03 02:10:00 [INFO]: Epoch 025 - training loss: 0.4648, validation loss: 2.4093
2024-06-03 02:10:19 [INFO]: Epoch 026 - training loss: 0.4613, validation loss: 2.4066
2024-06-03 02:10:38 [INFO]: Epoch 027 - training loss: 0.4587, validation loss: 2.4072
2024-06-03 02:10:57 [INFO]: Epoch 028 - training loss: 0.4585, validation loss: 2.4256
2024-06-03 02:11:16 [INFO]: Epoch 029 - training loss: 0.4559, validation loss: 2.4068
2024-06-03 02:11:35 [INFO]: Epoch 030 - training loss: 0.4513, validation loss: 2.3930
2024-06-03 02:11:54 [INFO]: Epoch 031 - training loss: 0.4494, validation loss: 2.4105
2024-06-03 02:12:12 [INFO]: Epoch 032 - training loss: 0.4474, validation loss: 2.4106
2024-06-03 02:12:31 [INFO]: Epoch 033 - training loss: 0.4452, validation loss: 2.4003
2024-06-03 02:12:49 [INFO]: Epoch 034 - training loss: 0.4439, validation loss: 2.4197
2024-06-03 02:13:08 [INFO]: Epoch 035 - training loss: 0.4428, validation loss: 2.4007
2024-06-03 02:13:27 [INFO]: Epoch 036 - training loss: 0.4413, validation loss: 2.4040
2024-06-03 02:13:46 [INFO]: Epoch 037 - training loss: 0.4408, validation loss: 2.4025
2024-06-03 02:14:05 [INFO]: Epoch 038 - training loss: 0.4384, validation loss: 2.4127
2024-06-03 02:14:24 [INFO]: Epoch 039 - training loss: 0.4379, validation loss: 2.4444
2024-06-03 02:14:43 [INFO]: Epoch 040 - training loss: 0.4346, validation loss: 2.4304
2024-06-03 02:14:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:14:43 [INFO]: Finished training. The best model is from epoch#30.
2024-06-03 02:14:44 [INFO]: Saved the model to results_point_rate09/Electricity/Crossformer_Electricity/round_4/20240603_T020207/Crossformer.pypots
2024-06-03 02:14:46 [INFO]: Successfully saved to results_point_rate09/Electricity/Crossformer_Electricity/round_4/imputation.pkl
2024-06-03 02:14:46 [INFO]: Round4 - Crossformer on Electricity: MAE=1.0034, MSE=2.4876, MRE=0.5372
2024-06-03 02:14:46 [INFO]: Done! Final results:
Averaged Crossformer (9,967,314 params) on Electricity: MAE=1.0251 ± 0.017855637774479485, MSE=2.5237 ± 0.06887302174636531, MRE=0.5488 ± 0.009558632400153552, average inference time=1.77
