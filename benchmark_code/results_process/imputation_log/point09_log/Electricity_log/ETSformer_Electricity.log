2024-06-03 01:11:55 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:11:55 [INFO]: Using the given device: cuda:0
2024-06-03 01:11:55 [INFO]: Model files will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_0/20240603_T011155
2024-06-03 01:11:55 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_0/20240603_T011155/tensorboard
2024-06-03 01:11:56 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-03 01:12:15 [INFO]: Epoch 001 - training loss: 1.1151, validation loss: 3.2942
2024-06-03 01:12:31 [INFO]: Epoch 002 - training loss: 0.8753, validation loss: 3.2587
2024-06-03 01:12:47 [INFO]: Epoch 003 - training loss: 0.8164, validation loss: 3.1822
2024-06-03 01:13:03 [INFO]: Epoch 004 - training loss: 0.7580, validation loss: 3.1603
2024-06-03 01:13:19 [INFO]: Epoch 005 - training loss: 0.7078, validation loss: 3.1630
2024-06-03 01:13:35 [INFO]: Epoch 006 - training loss: 0.6762, validation loss: 3.1059
2024-06-03 01:13:51 [INFO]: Epoch 007 - training loss: 0.6507, validation loss: 3.0684
2024-06-03 01:14:07 [INFO]: Epoch 008 - training loss: 0.6317, validation loss: 3.0686
2024-06-03 01:14:24 [INFO]: Epoch 009 - training loss: 0.6149, validation loss: 3.0316
2024-06-03 01:14:40 [INFO]: Epoch 010 - training loss: 0.6040, validation loss: 3.0067
2024-06-03 01:14:56 [INFO]: Epoch 011 - training loss: 0.5908, validation loss: 3.0183
2024-06-03 01:15:12 [INFO]: Epoch 012 - training loss: 0.5819, validation loss: 3.0254
2024-06-03 01:15:29 [INFO]: Epoch 013 - training loss: 0.5745, validation loss: 2.9963
2024-06-03 01:15:45 [INFO]: Epoch 014 - training loss: 0.5672, validation loss: 2.9814
2024-06-03 01:16:00 [INFO]: Epoch 015 - training loss: 0.5609, validation loss: 2.9808
2024-06-03 01:16:16 [INFO]: Epoch 016 - training loss: 0.5543, validation loss: 2.9781
2024-06-03 01:16:32 [INFO]: Epoch 017 - training loss: 0.5496, validation loss: 2.9747
2024-06-03 01:16:47 [INFO]: Epoch 018 - training loss: 0.5444, validation loss: 2.9675
2024-06-03 01:17:03 [INFO]: Epoch 019 - training loss: 0.5384, validation loss: 2.9631
2024-06-03 01:17:19 [INFO]: Epoch 020 - training loss: 0.5341, validation loss: 2.9527
2024-06-03 01:17:36 [INFO]: Epoch 021 - training loss: 0.5308, validation loss: 2.9439
2024-06-03 01:17:52 [INFO]: Epoch 022 - training loss: 0.5261, validation loss: 2.9521
2024-06-03 01:18:09 [INFO]: Epoch 023 - training loss: 0.5222, validation loss: 2.9478
2024-06-03 01:18:25 [INFO]: Epoch 024 - training loss: 0.5172, validation loss: 2.9427
2024-06-03 01:18:41 [INFO]: Epoch 025 - training loss: 0.5139, validation loss: 2.9548
2024-06-03 01:18:58 [INFO]: Epoch 026 - training loss: 0.5109, validation loss: 2.9291
2024-06-03 01:19:15 [INFO]: Epoch 027 - training loss: 0.5083, validation loss: 2.9222
2024-06-03 01:19:31 [INFO]: Epoch 028 - training loss: 0.5055, validation loss: 2.9297
2024-06-03 01:19:47 [INFO]: Epoch 029 - training loss: 0.5035, validation loss: 2.9248
2024-06-03 01:20:03 [INFO]: Epoch 030 - training loss: 0.4998, validation loss: 2.9239
2024-06-03 01:20:18 [INFO]: Epoch 031 - training loss: 0.4977, validation loss: 2.9132
2024-06-03 01:20:34 [INFO]: Epoch 032 - training loss: 0.4946, validation loss: 2.9159
2024-06-03 01:20:49 [INFO]: Epoch 033 - training loss: 0.4921, validation loss: 2.9207
2024-06-03 01:21:05 [INFO]: Epoch 034 - training loss: 0.4908, validation loss: 2.9169
2024-06-03 01:21:21 [INFO]: Epoch 035 - training loss: 0.4880, validation loss: 2.9163
2024-06-03 01:21:37 [INFO]: Epoch 036 - training loss: 0.4865, validation loss: 2.9130
2024-06-03 01:21:53 [INFO]: Epoch 037 - training loss: 0.4840, validation loss: 2.9108
2024-06-03 01:22:10 [INFO]: Epoch 038 - training loss: 0.4812, validation loss: 2.9116
2024-06-03 01:22:26 [INFO]: Epoch 039 - training loss: 0.4802, validation loss: 2.9150
2024-06-03 01:22:42 [INFO]: Epoch 040 - training loss: 0.4785, validation loss: 2.9143
2024-06-03 01:22:58 [INFO]: Epoch 041 - training loss: 0.4781, validation loss: 2.8933
2024-06-03 01:23:15 [INFO]: Epoch 042 - training loss: 0.4762, validation loss: 2.9017
2024-06-03 01:23:31 [INFO]: Epoch 043 - training loss: 0.4740, validation loss: 2.9065
2024-06-03 01:23:47 [INFO]: Epoch 044 - training loss: 0.4713, validation loss: 2.9057
2024-06-03 01:24:03 [INFO]: Epoch 045 - training loss: 0.4701, validation loss: 2.9067
2024-06-03 01:24:18 [INFO]: Epoch 046 - training loss: 0.4697, validation loss: 2.8990
2024-06-03 01:24:34 [INFO]: Epoch 047 - training loss: 0.4672, validation loss: 2.9006
2024-06-03 01:24:49 [INFO]: Epoch 048 - training loss: 0.4656, validation loss: 2.8954
2024-06-03 01:25:05 [INFO]: Epoch 049 - training loss: 0.4656, validation loss: 2.9066
2024-06-03 01:25:21 [INFO]: Epoch 050 - training loss: 0.4638, validation loss: 2.8989
2024-06-03 01:25:37 [INFO]: Epoch 051 - training loss: 0.4629, validation loss: 2.8953
2024-06-03 01:25:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:25:37 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 01:25:37 [INFO]: Saved the model to results_point_rate09/Electricity/ETSformer_Electricity/round_0/20240603_T011155/ETSformer.pypots
2024-06-03 01:25:40 [INFO]: Successfully saved to results_point_rate09/Electricity/ETSformer_Electricity/round_0/imputation.pkl
2024-06-03 01:25:40 [INFO]: Round0 - ETSformer on Electricity: MAE=1.3959, MSE=4.3191, MRE=0.7472
2024-06-03 01:25:40 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:25:40 [INFO]: Using the given device: cuda:0
2024-06-03 01:25:40 [INFO]: Model files will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_1/20240603_T012540
2024-06-03 01:25:40 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_1/20240603_T012540/tensorboard
2024-06-03 01:25:41 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-03 01:25:57 [INFO]: Epoch 001 - training loss: 1.1025, validation loss: 3.2736
2024-06-03 01:26:13 [INFO]: Epoch 002 - training loss: 0.8741, validation loss: 3.2859
2024-06-03 01:26:29 [INFO]: Epoch 003 - training loss: 0.8099, validation loss: 3.2458
2024-06-03 01:26:45 [INFO]: Epoch 004 - training loss: 0.7585, validation loss: 3.2577
2024-06-03 01:27:02 [INFO]: Epoch 005 - training loss: 0.7101, validation loss: 3.1762
2024-06-03 01:27:18 [INFO]: Epoch 006 - training loss: 0.6728, validation loss: 3.1287
2024-06-03 01:27:35 [INFO]: Epoch 007 - training loss: 0.6440, validation loss: 3.0885
2024-06-03 01:27:51 [INFO]: Epoch 008 - training loss: 0.6250, validation loss: 3.1120
2024-06-03 01:28:07 [INFO]: Epoch 009 - training loss: 0.6080, validation loss: 3.0815
2024-06-03 01:28:22 [INFO]: Epoch 010 - training loss: 0.5969, validation loss: 3.0774
2024-06-03 01:28:38 [INFO]: Epoch 011 - training loss: 0.5884, validation loss: 3.0720
2024-06-03 01:28:54 [INFO]: Epoch 012 - training loss: 0.5778, validation loss: 3.0357
2024-06-03 01:29:10 [INFO]: Epoch 013 - training loss: 0.5705, validation loss: 3.0467
2024-06-03 01:29:26 [INFO]: Epoch 014 - training loss: 0.5632, validation loss: 3.0383
2024-06-03 01:29:42 [INFO]: Epoch 015 - training loss: 0.5574, validation loss: 3.0296
2024-06-03 01:29:59 [INFO]: Epoch 016 - training loss: 0.5521, validation loss: 3.0131
2024-06-03 01:30:15 [INFO]: Epoch 017 - training loss: 0.5462, validation loss: 3.0168
2024-06-03 01:30:31 [INFO]: Epoch 018 - training loss: 0.5404, validation loss: 3.0171
2024-06-03 01:30:47 [INFO]: Epoch 019 - training loss: 0.5358, validation loss: 3.0045
2024-06-03 01:31:03 [INFO]: Epoch 020 - training loss: 0.5320, validation loss: 3.0084
2024-06-03 01:31:20 [INFO]: Epoch 021 - training loss: 0.5279, validation loss: 3.0204
2024-06-03 01:31:36 [INFO]: Epoch 022 - training loss: 0.5240, validation loss: 3.0064
2024-06-03 01:31:52 [INFO]: Epoch 023 - training loss: 0.5195, validation loss: 2.9989
2024-06-03 01:32:09 [INFO]: Epoch 024 - training loss: 0.5181, validation loss: 2.9989
2024-06-03 01:32:25 [INFO]: Epoch 025 - training loss: 0.5128, validation loss: 2.9957
2024-06-03 01:32:40 [INFO]: Epoch 026 - training loss: 0.5103, validation loss: 2.9919
2024-06-03 01:32:56 [INFO]: Epoch 027 - training loss: 0.5065, validation loss: 2.9814
2024-06-03 01:33:11 [INFO]: Epoch 028 - training loss: 0.5038, validation loss: 2.9830
2024-06-03 01:33:27 [INFO]: Epoch 029 - training loss: 0.5001, validation loss: 2.9799
2024-06-03 01:33:43 [INFO]: Epoch 030 - training loss: 0.4998, validation loss: 2.9768
2024-06-03 01:34:00 [INFO]: Epoch 031 - training loss: 0.4958, validation loss: 2.9710
2024-06-03 01:34:17 [INFO]: Epoch 032 - training loss: 0.4947, validation loss: 2.9762
2024-06-03 01:34:33 [INFO]: Epoch 033 - training loss: 0.4911, validation loss: 2.9833
2024-06-03 01:34:49 [INFO]: Epoch 034 - training loss: 0.4892, validation loss: 2.9688
2024-06-03 01:35:05 [INFO]: Epoch 035 - training loss: 0.4868, validation loss: 2.9638
2024-06-03 01:35:21 [INFO]: Epoch 036 - training loss: 0.4863, validation loss: 2.9564
2024-06-03 01:35:38 [INFO]: Epoch 037 - training loss: 0.4833, validation loss: 2.9585
2024-06-03 01:35:53 [INFO]: Epoch 038 - training loss: 0.4815, validation loss: 2.9623
2024-06-03 01:36:09 [INFO]: Epoch 039 - training loss: 0.4794, validation loss: 2.9539
2024-06-03 01:36:25 [INFO]: Epoch 040 - training loss: 0.4767, validation loss: 2.9482
2024-06-03 01:36:40 [INFO]: Epoch 041 - training loss: 0.4764, validation loss: 2.9501
2024-06-03 01:36:56 [INFO]: Epoch 042 - training loss: 0.4743, validation loss: 2.9628
2024-06-03 01:37:12 [INFO]: Epoch 043 - training loss: 0.4727, validation loss: 2.9575
2024-06-03 01:37:28 [INFO]: Epoch 044 - training loss: 0.4709, validation loss: 2.9582
2024-06-03 01:37:44 [INFO]: Epoch 045 - training loss: 0.4699, validation loss: 2.9434
2024-06-03 01:38:00 [INFO]: Epoch 046 - training loss: 0.4679, validation loss: 2.9436
2024-06-03 01:38:16 [INFO]: Epoch 047 - training loss: 0.4665, validation loss: 2.9544
2024-06-03 01:38:32 [INFO]: Epoch 048 - training loss: 0.4652, validation loss: 2.9422
2024-06-03 01:38:47 [INFO]: Epoch 049 - training loss: 0.4635, validation loss: 2.9429
2024-06-03 01:39:03 [INFO]: Epoch 050 - training loss: 0.4627, validation loss: 2.9496
2024-06-03 01:39:20 [INFO]: Epoch 051 - training loss: 0.4628, validation loss: 2.9389
2024-06-03 01:39:36 [INFO]: Epoch 052 - training loss: 0.4616, validation loss: 2.9403
2024-06-03 01:39:52 [INFO]: Epoch 053 - training loss: 0.4592, validation loss: 2.9336
2024-06-03 01:40:08 [INFO]: Epoch 054 - training loss: 0.4588, validation loss: 2.9464
2024-06-03 01:40:24 [INFO]: Epoch 055 - training loss: 0.4574, validation loss: 2.9371
2024-06-03 01:40:40 [INFO]: Epoch 056 - training loss: 0.4563, validation loss: 2.9392
2024-06-03 01:40:56 [INFO]: Epoch 057 - training loss: 0.4545, validation loss: 2.9380
2024-06-03 01:41:11 [INFO]: Epoch 058 - training loss: 0.4538, validation loss: 2.9351
2024-06-03 01:41:28 [INFO]: Epoch 059 - training loss: 0.4523, validation loss: 2.9309
2024-06-03 01:41:44 [INFO]: Epoch 060 - training loss: 0.4513, validation loss: 2.9356
2024-06-03 01:42:00 [INFO]: Epoch 061 - training loss: 0.4510, validation loss: 2.9405
2024-06-03 01:42:16 [INFO]: Epoch 062 - training loss: 0.4499, validation loss: 2.9259
2024-06-03 01:42:32 [INFO]: Epoch 063 - training loss: 0.4495, validation loss: 2.9370
2024-06-03 01:42:46 [INFO]: Epoch 064 - training loss: 0.4485, validation loss: 2.9320
2024-06-03 01:43:00 [INFO]: Epoch 065 - training loss: 0.4476, validation loss: 2.9226
2024-06-03 01:43:14 [INFO]: Epoch 066 - training loss: 0.4464, validation loss: 2.9241
2024-06-03 01:43:28 [INFO]: Epoch 067 - training loss: 0.4456, validation loss: 2.9284
2024-06-03 01:43:43 [INFO]: Epoch 068 - training loss: 0.4438, validation loss: 2.9238
2024-06-03 01:43:57 [INFO]: Epoch 069 - training loss: 0.4430, validation loss: 2.9231
2024-06-03 01:44:12 [INFO]: Epoch 070 - training loss: 0.4423, validation loss: 2.9236
2024-06-03 01:44:26 [INFO]: Epoch 071 - training loss: 0.4420, validation loss: 2.9246
2024-06-03 01:44:39 [INFO]: Epoch 072 - training loss: 0.4414, validation loss: 2.9227
2024-06-03 01:44:54 [INFO]: Epoch 073 - training loss: 0.4398, validation loss: 2.9316
2024-06-03 01:45:07 [INFO]: Epoch 074 - training loss: 0.4400, validation loss: 2.9347
2024-06-03 01:45:21 [INFO]: Epoch 075 - training loss: 0.4389, validation loss: 2.9217
2024-06-03 01:45:36 [INFO]: Epoch 076 - training loss: 0.4393, validation loss: 2.9207
2024-06-03 01:45:50 [INFO]: Epoch 077 - training loss: 0.4371, validation loss: 2.9216
2024-06-03 01:46:04 [INFO]: Epoch 078 - training loss: 0.4366, validation loss: 2.9287
2024-06-03 01:46:19 [INFO]: Epoch 079 - training loss: 0.4360, validation loss: 2.9240
2024-06-03 01:46:33 [INFO]: Epoch 080 - training loss: 0.4360, validation loss: 2.9224
2024-06-03 01:46:47 [INFO]: Epoch 081 - training loss: 0.4357, validation loss: 2.9231
2024-06-03 01:47:02 [INFO]: Epoch 082 - training loss: 0.4335, validation loss: 2.9305
2024-06-03 01:47:16 [INFO]: Epoch 083 - training loss: 0.4333, validation loss: 2.9201
2024-06-03 01:47:30 [INFO]: Epoch 084 - training loss: 0.4338, validation loss: 2.9195
2024-06-03 01:47:45 [INFO]: Epoch 085 - training loss: 0.4330, validation loss: 2.9204
2024-06-03 01:47:59 [INFO]: Epoch 086 - training loss: 0.4320, validation loss: 2.9209
2024-06-03 01:48:13 [INFO]: Epoch 087 - training loss: 0.4318, validation loss: 2.9239
2024-06-03 01:48:27 [INFO]: Epoch 088 - training loss: 0.4312, validation loss: 2.9128
2024-06-03 01:48:41 [INFO]: Epoch 089 - training loss: 0.4308, validation loss: 2.9151
2024-06-03 01:48:55 [INFO]: Epoch 090 - training loss: 0.4305, validation loss: 2.9144
2024-06-03 01:49:09 [INFO]: Epoch 091 - training loss: 0.4292, validation loss: 2.9133
2024-06-03 01:49:23 [INFO]: Epoch 092 - training loss: 0.4283, validation loss: 2.9087
2024-06-03 01:49:37 [INFO]: Epoch 093 - training loss: 0.4270, validation loss: 2.9112
2024-06-03 01:49:52 [INFO]: Epoch 094 - training loss: 0.4277, validation loss: 2.9178
2024-06-03 01:50:06 [INFO]: Epoch 095 - training loss: 0.4279, validation loss: 2.9168
2024-06-03 01:50:21 [INFO]: Epoch 096 - training loss: 0.4269, validation loss: 2.9153
2024-06-03 01:50:35 [INFO]: Epoch 097 - training loss: 0.4261, validation loss: 2.9039
2024-06-03 01:50:49 [INFO]: Epoch 098 - training loss: 0.4256, validation loss: 2.9080
2024-06-03 01:51:03 [INFO]: Epoch 099 - training loss: 0.4252, validation loss: 2.9122
2024-06-03 01:51:18 [INFO]: Epoch 100 - training loss: 0.4250, validation loss: 2.9047
2024-06-03 01:51:18 [INFO]: Finished training. The best model is from epoch#97.
2024-06-03 01:51:18 [INFO]: Saved the model to results_point_rate09/Electricity/ETSformer_Electricity/round_1/20240603_T012540/ETSformer.pypots
2024-06-03 01:51:20 [INFO]: Successfully saved to results_point_rate09/Electricity/ETSformer_Electricity/round_1/imputation.pkl
2024-06-03 01:51:20 [INFO]: Round1 - ETSformer on Electricity: MAE=1.4053, MSE=4.4363, MRE=0.7523
2024-06-03 01:51:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:51:20 [INFO]: Using the given device: cuda:0
2024-06-03 01:51:20 [INFO]: Model files will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_2/20240603_T015120
2024-06-03 01:51:20 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_2/20240603_T015120/tensorboard
2024-06-03 01:51:21 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-03 01:51:35 [INFO]: Epoch 001 - training loss: 1.1217, validation loss: 3.2870
2024-06-03 01:51:50 [INFO]: Epoch 002 - training loss: 0.8841, validation loss: 3.2848
2024-06-03 01:52:04 [INFO]: Epoch 003 - training loss: 0.8294, validation loss: 3.2559
2024-06-03 01:52:18 [INFO]: Epoch 004 - training loss: 0.7747, validation loss: 3.2494
2024-06-03 01:52:32 [INFO]: Epoch 005 - training loss: 0.7233, validation loss: 3.1994
2024-06-03 01:52:46 [INFO]: Epoch 006 - training loss: 0.6883, validation loss: 3.1742
2024-06-03 01:53:00 [INFO]: Epoch 007 - training loss: 0.6578, validation loss: 3.1051
2024-06-03 01:53:14 [INFO]: Epoch 008 - training loss: 0.6383, validation loss: 3.0694
2024-06-03 01:53:28 [INFO]: Epoch 009 - training loss: 0.6243, validation loss: 3.0847
2024-06-03 01:53:43 [INFO]: Epoch 010 - training loss: 0.6065, validation loss: 3.0742
2024-06-03 01:53:57 [INFO]: Epoch 011 - training loss: 0.5964, validation loss: 3.0592
2024-06-03 01:54:09 [INFO]: Epoch 012 - training loss: 0.5873, validation loss: 3.0556
2024-06-03 01:54:21 [INFO]: Epoch 013 - training loss: 0.5801, validation loss: 3.0277
2024-06-03 01:54:34 [INFO]: Epoch 014 - training loss: 0.5735, validation loss: 3.0129
2024-06-03 01:54:45 [INFO]: Epoch 015 - training loss: 0.5672, validation loss: 2.9943
2024-06-03 01:54:57 [INFO]: Epoch 016 - training loss: 0.5609, validation loss: 3.0062
2024-06-03 01:55:10 [INFO]: Epoch 017 - training loss: 0.5545, validation loss: 3.0064
2024-06-03 01:55:22 [INFO]: Epoch 018 - training loss: 0.5494, validation loss: 2.9873
2024-06-03 01:55:34 [INFO]: Epoch 019 - training loss: 0.5459, validation loss: 2.9979
2024-06-03 01:55:46 [INFO]: Epoch 020 - training loss: 0.5416, validation loss: 3.0029
2024-06-03 01:55:58 [INFO]: Epoch 021 - training loss: 0.5363, validation loss: 2.9793
2024-06-03 01:56:10 [INFO]: Epoch 022 - training loss: 0.5326, validation loss: 2.9899
2024-06-03 01:56:21 [INFO]: Epoch 023 - training loss: 0.5299, validation loss: 2.9889
2024-06-03 01:56:33 [INFO]: Epoch 024 - training loss: 0.5275, validation loss: 2.9791
2024-06-03 01:56:44 [INFO]: Epoch 025 - training loss: 0.5238, validation loss: 2.9768
2024-06-03 01:56:55 [INFO]: Epoch 026 - training loss: 0.5205, validation loss: 2.9574
2024-06-03 01:57:08 [INFO]: Epoch 027 - training loss: 0.5198, validation loss: 2.9747
2024-06-03 01:57:20 [INFO]: Epoch 028 - training loss: 0.5164, validation loss: 2.9711
2024-06-03 01:57:32 [INFO]: Epoch 029 - training loss: 0.5147, validation loss: 2.9521
2024-06-03 01:57:44 [INFO]: Epoch 030 - training loss: 0.5102, validation loss: 2.9591
2024-06-03 01:57:56 [INFO]: Epoch 031 - training loss: 0.5079, validation loss: 2.9487
2024-06-03 01:58:08 [INFO]: Epoch 032 - training loss: 0.5046, validation loss: 2.9611
2024-06-03 01:58:20 [INFO]: Epoch 033 - training loss: 0.5031, validation loss: 2.9547
2024-06-03 01:58:32 [INFO]: Epoch 034 - training loss: 0.5019, validation loss: 2.9560
2024-06-03 01:58:44 [INFO]: Epoch 035 - training loss: 0.5000, validation loss: 2.9394
2024-06-03 01:58:56 [INFO]: Epoch 036 - training loss: 0.4977, validation loss: 2.9494
2024-06-03 01:59:08 [INFO]: Epoch 037 - training loss: 0.4970, validation loss: 2.9485
2024-06-03 01:59:20 [INFO]: Epoch 038 - training loss: 0.4957, validation loss: 2.9582
2024-06-03 01:59:33 [INFO]: Epoch 039 - training loss: 0.4920, validation loss: 2.9514
2024-06-03 01:59:45 [INFO]: Epoch 040 - training loss: 0.4899, validation loss: 2.9649
2024-06-03 01:59:57 [INFO]: Epoch 041 - training loss: 0.4889, validation loss: 2.9504
2024-06-03 02:00:09 [INFO]: Epoch 042 - training loss: 0.4867, validation loss: 2.9464
2024-06-03 02:00:21 [INFO]: Epoch 043 - training loss: 0.4862, validation loss: 2.9512
2024-06-03 02:00:32 [INFO]: Epoch 044 - training loss: 0.4860, validation loss: 2.9645
2024-06-03 02:00:44 [INFO]: Epoch 045 - training loss: 0.4842, validation loss: 2.9515
2024-06-03 02:00:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:00:44 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 02:00:44 [INFO]: Saved the model to results_point_rate09/Electricity/ETSformer_Electricity/round_2/20240603_T015120/ETSformer.pypots
2024-06-03 02:00:46 [INFO]: Successfully saved to results_point_rate09/Electricity/ETSformer_Electricity/round_2/imputation.pkl
2024-06-03 02:00:46 [INFO]: Round2 - ETSformer on Electricity: MAE=1.4025, MSE=4.3661, MRE=0.7508
2024-06-03 02:00:46 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 02:00:46 [INFO]: Using the given device: cuda:0
2024-06-03 02:00:46 [INFO]: Model files will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_3/20240603_T020046
2024-06-03 02:00:46 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_3/20240603_T020046/tensorboard
2024-06-03 02:00:47 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-03 02:00:59 [INFO]: Epoch 001 - training loss: 1.1104, validation loss: 3.2719
2024-06-03 02:01:11 [INFO]: Epoch 002 - training loss: 0.8778, validation loss: 3.2603
2024-06-03 02:01:23 [INFO]: Epoch 003 - training loss: 0.8151, validation loss: 3.2337
2024-06-03 02:01:35 [INFO]: Epoch 004 - training loss: 0.7642, validation loss: 3.2110
2024-06-03 02:01:47 [INFO]: Epoch 005 - training loss: 0.7159, validation loss: 3.1905
2024-06-03 02:01:59 [INFO]: Epoch 006 - training loss: 0.6799, validation loss: 3.1442
2024-06-03 02:02:11 [INFO]: Epoch 007 - training loss: 0.6469, validation loss: 3.0866
2024-06-03 02:02:23 [INFO]: Epoch 008 - training loss: 0.6266, validation loss: 3.0472
2024-06-03 02:02:35 [INFO]: Epoch 009 - training loss: 0.6109, validation loss: 3.0278
2024-06-03 02:02:48 [INFO]: Epoch 010 - training loss: 0.6000, validation loss: 3.0199
2024-06-03 02:03:00 [INFO]: Epoch 011 - training loss: 0.5924, validation loss: 3.0117
2024-06-03 02:03:12 [INFO]: Epoch 012 - training loss: 0.5812, validation loss: 3.0090
2024-06-03 02:03:24 [INFO]: Epoch 013 - training loss: 0.5725, validation loss: 2.9982
2024-06-03 02:03:36 [INFO]: Epoch 014 - training loss: 0.5631, validation loss: 2.9810
2024-06-03 02:03:48 [INFO]: Epoch 015 - training loss: 0.5605, validation loss: 2.9881
2024-06-03 02:04:00 [INFO]: Epoch 016 - training loss: 0.5531, validation loss: 2.9595
2024-06-03 02:04:11 [INFO]: Epoch 017 - training loss: 0.5472, validation loss: 2.9590
2024-06-03 02:04:23 [INFO]: Epoch 018 - training loss: 0.5423, validation loss: 2.9519
2024-06-03 02:04:34 [INFO]: Epoch 019 - training loss: 0.5368, validation loss: 2.9481
2024-06-03 02:04:46 [INFO]: Epoch 020 - training loss: 0.5344, validation loss: 2.9587
2024-06-03 02:04:58 [INFO]: Epoch 021 - training loss: 0.5282, validation loss: 2.9462
2024-06-03 02:05:10 [INFO]: Epoch 022 - training loss: 0.5272, validation loss: 2.9602
2024-06-03 02:05:22 [INFO]: Epoch 023 - training loss: 0.5211, validation loss: 2.9600
2024-06-03 02:05:35 [INFO]: Epoch 024 - training loss: 0.5165, validation loss: 2.9425
2024-06-03 02:05:47 [INFO]: Epoch 025 - training loss: 0.5141, validation loss: 2.9386
2024-06-03 02:05:59 [INFO]: Epoch 026 - training loss: 0.5108, validation loss: 2.9473
2024-06-03 02:06:11 [INFO]: Epoch 027 - training loss: 0.5063, validation loss: 2.9338
2024-06-03 02:06:24 [INFO]: Epoch 028 - training loss: 0.5019, validation loss: 2.9309
2024-06-03 02:06:36 [INFO]: Epoch 029 - training loss: 0.5002, validation loss: 2.9246
2024-06-03 02:06:48 [INFO]: Epoch 030 - training loss: 0.4977, validation loss: 2.9202
2024-06-03 02:07:00 [INFO]: Epoch 031 - training loss: 0.4963, validation loss: 2.9243
2024-06-03 02:07:12 [INFO]: Epoch 032 - training loss: 0.4940, validation loss: 2.9117
2024-06-03 02:07:24 [INFO]: Epoch 033 - training loss: 0.4907, validation loss: 2.9189
2024-06-03 02:07:36 [INFO]: Epoch 034 - training loss: 0.4870, validation loss: 2.9139
2024-06-03 02:07:48 [INFO]: Epoch 035 - training loss: 0.4863, validation loss: 2.9021
2024-06-03 02:08:00 [INFO]: Epoch 036 - training loss: 0.4841, validation loss: 2.9065
2024-06-03 02:08:12 [INFO]: Epoch 037 - training loss: 0.4826, validation loss: 2.9050
2024-06-03 02:08:24 [INFO]: Epoch 038 - training loss: 0.4815, validation loss: 2.8983
2024-06-03 02:08:36 [INFO]: Epoch 039 - training loss: 0.4797, validation loss: 2.8947
2024-06-03 02:08:47 [INFO]: Epoch 040 - training loss: 0.4768, validation loss: 2.8941
2024-06-03 02:08:59 [INFO]: Epoch 041 - training loss: 0.4754, validation loss: 2.8945
2024-06-03 02:09:11 [INFO]: Epoch 042 - training loss: 0.4729, validation loss: 2.8899
2024-06-03 02:09:23 [INFO]: Epoch 043 - training loss: 0.4707, validation loss: 2.8889
2024-06-03 02:09:35 [INFO]: Epoch 044 - training loss: 0.4691, validation loss: 2.8827
2024-06-03 02:09:47 [INFO]: Epoch 045 - training loss: 0.4691, validation loss: 2.8779
2024-06-03 02:09:59 [INFO]: Epoch 046 - training loss: 0.4669, validation loss: 2.8939
2024-06-03 02:10:11 [INFO]: Epoch 047 - training loss: 0.4654, validation loss: 2.8967
2024-06-03 02:10:23 [INFO]: Epoch 048 - training loss: 0.4640, validation loss: 2.8889
2024-06-03 02:10:35 [INFO]: Epoch 049 - training loss: 0.4627, validation loss: 2.8845
2024-06-03 02:10:47 [INFO]: Epoch 050 - training loss: 0.4630, validation loss: 2.8854
2024-06-03 02:10:58 [INFO]: Epoch 051 - training loss: 0.4597, validation loss: 2.8788
2024-06-03 02:11:11 [INFO]: Epoch 052 - training loss: 0.4603, validation loss: 2.8827
2024-06-03 02:11:23 [INFO]: Epoch 053 - training loss: 0.4582, validation loss: 2.8803
2024-06-03 02:11:35 [INFO]: Epoch 054 - training loss: 0.4572, validation loss: 2.8739
2024-06-03 02:11:47 [INFO]: Epoch 055 - training loss: 0.4560, validation loss: 2.8865
2024-06-03 02:11:59 [INFO]: Epoch 056 - training loss: 0.4546, validation loss: 2.8838
2024-06-03 02:12:11 [INFO]: Epoch 057 - training loss: 0.4534, validation loss: 2.8824
2024-06-03 02:12:22 [INFO]: Epoch 058 - training loss: 0.4527, validation loss: 2.8829
2024-06-03 02:12:34 [INFO]: Epoch 059 - training loss: 0.4517, validation loss: 2.8777
2024-06-03 02:12:46 [INFO]: Epoch 060 - training loss: 0.4507, validation loss: 2.8773
2024-06-03 02:12:58 [INFO]: Epoch 061 - training loss: 0.4496, validation loss: 2.8712
2024-06-03 02:13:10 [INFO]: Epoch 062 - training loss: 0.4509, validation loss: 2.8815
2024-06-03 02:13:22 [INFO]: Epoch 063 - training loss: 0.4477, validation loss: 2.8791
2024-06-03 02:13:34 [INFO]: Epoch 064 - training loss: 0.4466, validation loss: 2.8685
2024-06-03 02:13:46 [INFO]: Epoch 065 - training loss: 0.4460, validation loss: 2.8808
2024-06-03 02:13:58 [INFO]: Epoch 066 - training loss: 0.4452, validation loss: 2.8731
2024-06-03 02:14:10 [INFO]: Epoch 067 - training loss: 0.4433, validation loss: 2.8723
2024-06-03 02:14:22 [INFO]: Epoch 068 - training loss: 0.4432, validation loss: 2.8709
2024-06-03 02:14:34 [INFO]: Epoch 069 - training loss: 0.4415, validation loss: 2.8670
2024-06-03 02:14:46 [INFO]: Epoch 070 - training loss: 0.4411, validation loss: 2.8681
2024-06-03 02:14:54 [INFO]: Epoch 071 - training loss: 0.4407, validation loss: 2.8610
2024-06-03 02:15:02 [INFO]: Epoch 072 - training loss: 0.4405, validation loss: 2.8656
2024-06-03 02:15:09 [INFO]: Epoch 073 - training loss: 0.4398, validation loss: 2.8647
2024-06-03 02:15:17 [INFO]: Epoch 074 - training loss: 0.4387, validation loss: 2.8730
2024-06-03 02:15:24 [INFO]: Epoch 075 - training loss: 0.4372, validation loss: 2.8654
2024-06-03 02:15:32 [INFO]: Epoch 076 - training loss: 0.4363, validation loss: 2.8618
2024-06-03 02:15:39 [INFO]: Epoch 077 - training loss: 0.4371, validation loss: 2.8693
2024-06-03 02:15:46 [INFO]: Epoch 078 - training loss: 0.4362, validation loss: 2.8599
2024-06-03 02:15:53 [INFO]: Epoch 079 - training loss: 0.4350, validation loss: 2.8618
2024-06-03 02:16:00 [INFO]: Epoch 080 - training loss: 0.4342, validation loss: 2.8629
2024-06-03 02:16:08 [INFO]: Epoch 081 - training loss: 0.4337, validation loss: 2.8647
2024-06-03 02:16:15 [INFO]: Epoch 082 - training loss: 0.4328, validation loss: 2.8633
2024-06-03 02:16:22 [INFO]: Epoch 083 - training loss: 0.4326, validation loss: 2.8623
2024-06-03 02:16:29 [INFO]: Epoch 084 - training loss: 0.4327, validation loss: 2.8730
2024-06-03 02:16:37 [INFO]: Epoch 085 - training loss: 0.4313, validation loss: 2.8577
2024-06-03 02:16:44 [INFO]: Epoch 086 - training loss: 0.4315, validation loss: 2.8580
2024-06-03 02:16:51 [INFO]: Epoch 087 - training loss: 0.4303, validation loss: 2.8646
2024-06-03 02:16:59 [INFO]: Epoch 088 - training loss: 0.4291, validation loss: 2.8675
2024-06-03 02:17:06 [INFO]: Epoch 089 - training loss: 0.4291, validation loss: 2.8560
2024-06-03 02:17:13 [INFO]: Epoch 090 - training loss: 0.4281, validation loss: 2.8684
2024-06-03 02:17:21 [INFO]: Epoch 091 - training loss: 0.4278, validation loss: 2.8654
2024-06-03 02:17:28 [INFO]: Epoch 092 - training loss: 0.4274, validation loss: 2.8678
2024-06-03 02:17:36 [INFO]: Epoch 093 - training loss: 0.4272, validation loss: 2.8630
2024-06-03 02:17:43 [INFO]: Epoch 094 - training loss: 0.4267, validation loss: 2.8627
2024-06-03 02:17:51 [INFO]: Epoch 095 - training loss: 0.4258, validation loss: 2.8660
2024-06-03 02:17:58 [INFO]: Epoch 096 - training loss: 0.4266, validation loss: 2.8609
2024-06-03 02:18:05 [INFO]: Epoch 097 - training loss: 0.4262, validation loss: 2.8687
2024-06-03 02:18:12 [INFO]: Epoch 098 - training loss: 0.4248, validation loss: 2.8611
2024-06-03 02:18:19 [INFO]: Epoch 099 - training loss: 0.4226, validation loss: 2.8676
2024-06-03 02:18:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:18:19 [INFO]: Finished training. The best model is from epoch#89.
2024-06-03 02:18:19 [INFO]: Saved the model to results_point_rate09/Electricity/ETSformer_Electricity/round_3/20240603_T020046/ETSformer.pypots
2024-06-03 02:18:20 [INFO]: Successfully saved to results_point_rate09/Electricity/ETSformer_Electricity/round_3/imputation.pkl
2024-06-03 02:18:20 [INFO]: Round3 - ETSformer on Electricity: MAE=1.4054, MSE=4.3371, MRE=0.7524
2024-06-03 02:18:20 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:18:20 [INFO]: Using the given device: cuda:0
2024-06-03 02:18:20 [INFO]: Model files will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_4/20240603_T021820
2024-06-03 02:18:20 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/ETSformer_Electricity/round_4/20240603_T021820/tensorboard
2024-06-03 02:18:20 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-03 02:18:27 [INFO]: Epoch 001 - training loss: 1.1813, validation loss: 3.2788
2024-06-03 02:18:35 [INFO]: Epoch 002 - training loss: 0.9024, validation loss: 3.2930
2024-06-03 02:18:42 [INFO]: Epoch 003 - training loss: 0.8419, validation loss: 3.2405
2024-06-03 02:18:50 [INFO]: Epoch 004 - training loss: 0.7913, validation loss: 3.2653
2024-06-03 02:18:57 [INFO]: Epoch 005 - training loss: 0.7461, validation loss: 3.2879
2024-06-03 02:19:05 [INFO]: Epoch 006 - training loss: 0.7108, validation loss: 3.2666
2024-06-03 02:19:13 [INFO]: Epoch 007 - training loss: 0.6783, validation loss: 3.1765
2024-06-03 02:19:20 [INFO]: Epoch 008 - training loss: 0.6530, validation loss: 3.1846
2024-06-03 02:19:28 [INFO]: Epoch 009 - training loss: 0.6364, validation loss: 3.1373
2024-06-03 02:19:34 [INFO]: Epoch 010 - training loss: 0.6217, validation loss: 3.0977
2024-06-03 02:19:42 [INFO]: Epoch 011 - training loss: 0.6088, validation loss: 3.1085
2024-06-03 02:19:50 [INFO]: Epoch 012 - training loss: 0.5975, validation loss: 3.0800
2024-06-03 02:19:57 [INFO]: Epoch 013 - training loss: 0.5921, validation loss: 3.0743
2024-06-03 02:20:04 [INFO]: Epoch 014 - training loss: 0.5864, validation loss: 3.0723
2024-06-03 02:20:12 [INFO]: Epoch 015 - training loss: 0.5758, validation loss: 3.0634
2024-06-03 02:20:19 [INFO]: Epoch 016 - training loss: 0.5725, validation loss: 3.0308
2024-06-03 02:20:27 [INFO]: Epoch 017 - training loss: 0.5657, validation loss: 3.0329
2024-06-03 02:20:34 [INFO]: Epoch 018 - training loss: 0.5575, validation loss: 3.0275
2024-06-03 02:20:40 [INFO]: Epoch 019 - training loss: 0.5535, validation loss: 3.0047
2024-06-03 02:20:47 [INFO]: Epoch 020 - training loss: 0.5498, validation loss: 2.9993
2024-06-03 02:20:53 [INFO]: Epoch 021 - training loss: 0.5453, validation loss: 2.9863
2024-06-03 02:21:01 [INFO]: Epoch 022 - training loss: 0.5401, validation loss: 3.0078
2024-06-03 02:21:08 [INFO]: Epoch 023 - training loss: 0.5378, validation loss: 2.9931
2024-06-03 02:21:16 [INFO]: Epoch 024 - training loss: 0.5329, validation loss: 2.9906
2024-06-03 02:21:23 [INFO]: Epoch 025 - training loss: 0.5304, validation loss: 2.9873
2024-06-03 02:21:31 [INFO]: Epoch 026 - training loss: 0.5250, validation loss: 2.9825
2024-06-03 02:21:38 [INFO]: Epoch 027 - training loss: 0.5212, validation loss: 2.9727
2024-06-03 02:21:46 [INFO]: Epoch 028 - training loss: 0.5196, validation loss: 2.9710
2024-06-03 02:21:53 [INFO]: Epoch 029 - training loss: 0.5158, validation loss: 2.9726
2024-06-03 02:22:01 [INFO]: Epoch 030 - training loss: 0.5154, validation loss: 2.9502
2024-06-03 02:22:08 [INFO]: Epoch 031 - training loss: 0.5115, validation loss: 2.9531
2024-06-03 02:22:16 [INFO]: Epoch 032 - training loss: 0.5086, validation loss: 2.9628
2024-06-03 02:22:24 [INFO]: Epoch 033 - training loss: 0.5070, validation loss: 2.9685
2024-06-03 02:22:31 [INFO]: Epoch 034 - training loss: 0.5038, validation loss: 2.9650
2024-06-03 02:22:39 [INFO]: Epoch 035 - training loss: 0.5025, validation loss: 2.9523
2024-06-03 02:22:46 [INFO]: Epoch 036 - training loss: 0.5001, validation loss: 2.9409
2024-06-03 02:22:54 [INFO]: Epoch 037 - training loss: 0.4969, validation loss: 2.9500
2024-06-03 02:23:02 [INFO]: Epoch 038 - training loss: 0.4942, validation loss: 2.9547
2024-06-03 02:23:09 [INFO]: Epoch 039 - training loss: 0.4930, validation loss: 2.9569
2024-06-03 02:23:16 [INFO]: Epoch 040 - training loss: 0.4909, validation loss: 2.9576
2024-06-03 02:23:23 [INFO]: Epoch 041 - training loss: 0.4890, validation loss: 2.9388
2024-06-03 02:23:30 [INFO]: Epoch 042 - training loss: 0.4866, validation loss: 2.9284
2024-06-03 02:23:38 [INFO]: Epoch 043 - training loss: 0.4847, validation loss: 2.9454
2024-06-03 02:23:45 [INFO]: Epoch 044 - training loss: 0.4828, validation loss: 2.9473
2024-06-03 02:23:53 [INFO]: Epoch 045 - training loss: 0.4821, validation loss: 2.9400
2024-06-03 02:24:00 [INFO]: Epoch 046 - training loss: 0.4817, validation loss: 2.9250
2024-06-03 02:24:07 [INFO]: Epoch 047 - training loss: 0.4797, validation loss: 2.9310
2024-06-03 02:24:14 [INFO]: Epoch 048 - training loss: 0.4779, validation loss: 2.9263
2024-06-03 02:24:22 [INFO]: Epoch 049 - training loss: 0.4749, validation loss: 2.9265
2024-06-03 02:24:29 [INFO]: Epoch 050 - training loss: 0.4737, validation loss: 2.9260
2024-06-03 02:24:37 [INFO]: Epoch 051 - training loss: 0.4722, validation loss: 2.9375
2024-06-03 02:24:44 [INFO]: Epoch 052 - training loss: 0.4717, validation loss: 2.9235
2024-06-03 02:24:52 [INFO]: Epoch 053 - training loss: 0.4698, validation loss: 2.9198
2024-06-03 02:25:00 [INFO]: Epoch 054 - training loss: 0.4680, validation loss: 2.9236
2024-06-03 02:25:07 [INFO]: Epoch 055 - training loss: 0.4676, validation loss: 2.9179
2024-06-03 02:25:15 [INFO]: Epoch 056 - training loss: 0.4667, validation loss: 2.9201
2024-06-03 02:25:23 [INFO]: Epoch 057 - training loss: 0.4643, validation loss: 2.9264
2024-06-03 02:25:30 [INFO]: Epoch 058 - training loss: 0.4640, validation loss: 2.9260
2024-06-03 02:25:38 [INFO]: Epoch 059 - training loss: 0.4624, validation loss: 2.9190
2024-06-03 02:25:44 [INFO]: Epoch 060 - training loss: 0.4612, validation loss: 2.9116
2024-06-03 02:25:51 [INFO]: Epoch 061 - training loss: 0.4602, validation loss: 2.9164
2024-06-03 02:25:58 [INFO]: Epoch 062 - training loss: 0.4581, validation loss: 2.9167
2024-06-03 02:26:06 [INFO]: Epoch 063 - training loss: 0.4574, validation loss: 2.9288
2024-06-03 02:26:14 [INFO]: Epoch 064 - training loss: 0.4573, validation loss: 2.8991
2024-06-03 02:26:22 [INFO]: Epoch 065 - training loss: 0.4543, validation loss: 2.9048
2024-06-03 02:26:29 [INFO]: Epoch 066 - training loss: 0.4556, validation loss: 2.9074
2024-06-03 02:26:36 [INFO]: Epoch 067 - training loss: 0.4530, validation loss: 2.9066
2024-06-03 02:26:44 [INFO]: Epoch 068 - training loss: 0.4524, validation loss: 2.9009
2024-06-03 02:26:51 [INFO]: Epoch 069 - training loss: 0.4518, validation loss: 2.8996
2024-06-03 02:26:59 [INFO]: Epoch 070 - training loss: 0.4503, validation loss: 2.8921
2024-06-03 02:27:06 [INFO]: Epoch 071 - training loss: 0.4500, validation loss: 2.9045
2024-06-03 02:27:14 [INFO]: Epoch 072 - training loss: 0.4494, validation loss: 2.9017
2024-06-03 02:27:21 [INFO]: Epoch 073 - training loss: 0.4480, validation loss: 2.9007
2024-06-03 02:27:29 [INFO]: Epoch 074 - training loss: 0.4484, validation loss: 2.9016
2024-06-03 02:27:36 [INFO]: Epoch 075 - training loss: 0.4471, validation loss: 2.8956
2024-06-03 02:27:44 [INFO]: Epoch 076 - training loss: 0.4464, validation loss: 2.9033
2024-06-03 02:27:52 [INFO]: Epoch 077 - training loss: 0.4453, validation loss: 2.8937
2024-06-03 02:27:59 [INFO]: Epoch 078 - training loss: 0.4443, validation loss: 2.8936
2024-06-03 02:28:06 [INFO]: Epoch 079 - training loss: 0.4427, validation loss: 2.8974
2024-06-03 02:28:13 [INFO]: Epoch 080 - training loss: 0.4429, validation loss: 2.8928
2024-06-03 02:28:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:28:13 [INFO]: Finished training. The best model is from epoch#70.
2024-06-03 02:28:13 [INFO]: Saved the model to results_point_rate09/Electricity/ETSformer_Electricity/round_4/20240603_T021820/ETSformer.pypots
2024-06-03 02:28:15 [INFO]: Successfully saved to results_point_rate09/Electricity/ETSformer_Electricity/round_4/imputation.pkl
2024-06-03 02:28:15 [INFO]: Round4 - ETSformer on Electricity: MAE=1.4114, MSE=4.4121, MRE=0.7555
2024-06-03 02:28:15 [INFO]: Done! Final results:
Averaged ETSformer (10,518,266 params) on Electricity: MAE=1.4041 ± 0.005022874145713289, MSE=4.3742 ± 0.04420278468301858, MRE=0.7516 ± 0.0026888878547777295, average inference time=1.70
