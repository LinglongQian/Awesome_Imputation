2024-06-03 01:15:38 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:15:38 [INFO]: Using the given device: cuda:0
2024-06-03 01:15:38 [INFO]: Model files will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_0/20240603_T011538
2024-06-03 01:15:38 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_0/20240603_T011538/tensorboard
2024-06-03 01:15:39 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 01:16:00 [INFO]: Epoch 001 - training loss: 1.5036, validation loss: 3.8382
2024-06-03 01:16:28 [INFO]: Epoch 002 - training loss: 1.2064, validation loss: 3.6903
2024-06-03 01:16:57 [INFO]: Epoch 003 - training loss: 1.0855, validation loss: 3.6539
2024-06-03 01:17:26 [INFO]: Epoch 004 - training loss: 1.0353, validation loss: 3.6313
2024-06-03 01:17:54 [INFO]: Epoch 005 - training loss: 0.9621, validation loss: 3.5741
2024-06-03 01:18:23 [INFO]: Epoch 006 - training loss: 0.8353, validation loss: 3.4584
2024-06-03 01:18:52 [INFO]: Epoch 007 - training loss: 0.7424, validation loss: 3.3617
2024-06-03 01:19:22 [INFO]: Epoch 008 - training loss: 0.7035, validation loss: 3.3003
2024-06-03 01:19:51 [INFO]: Epoch 009 - training loss: 0.6846, validation loss: 3.2724
2024-06-03 01:20:20 [INFO]: Epoch 010 - training loss: 0.6686, validation loss: 3.2060
2024-06-03 01:20:49 [INFO]: Epoch 011 - training loss: 0.6490, validation loss: 3.1664
2024-06-03 01:21:18 [INFO]: Epoch 012 - training loss: 0.6298, validation loss: 3.1343
2024-06-03 01:21:47 [INFO]: Epoch 013 - training loss: 0.6114, validation loss: 3.1075
2024-06-03 01:22:16 [INFO]: Epoch 014 - training loss: 0.5985, validation loss: 3.0988
2024-06-03 01:22:45 [INFO]: Epoch 015 - training loss: 0.5890, validation loss: 3.0781
2024-06-03 01:23:14 [INFO]: Epoch 016 - training loss: 0.5792, validation loss: 3.0633
2024-06-03 01:23:43 [INFO]: Epoch 017 - training loss: 0.5729, validation loss: 3.0598
2024-06-03 01:24:12 [INFO]: Epoch 018 - training loss: 0.5655, validation loss: 3.0354
2024-06-03 01:24:42 [INFO]: Epoch 019 - training loss: 0.5584, validation loss: 3.0264
2024-06-03 01:25:11 [INFO]: Epoch 020 - training loss: 0.5527, validation loss: 3.0220
2024-06-03 01:25:39 [INFO]: Epoch 021 - training loss: 0.5469, validation loss: 3.0064
2024-06-03 01:26:08 [INFO]: Epoch 022 - training loss: 0.5418, validation loss: 2.9992
2024-06-03 01:26:35 [INFO]: Epoch 023 - training loss: 0.5356, validation loss: 2.9759
2024-06-03 01:27:04 [INFO]: Epoch 024 - training loss: 0.5318, validation loss: 2.9828
2024-06-03 01:27:33 [INFO]: Epoch 025 - training loss: 0.5267, validation loss: 2.9711
2024-06-03 01:28:01 [INFO]: Epoch 026 - training loss: 0.5222, validation loss: 2.9721
2024-06-03 01:28:30 [INFO]: Epoch 027 - training loss: 0.5179, validation loss: 2.9711
2024-06-03 01:28:59 [INFO]: Epoch 028 - training loss: 0.5143, validation loss: 2.9644
2024-06-03 01:29:28 [INFO]: Epoch 029 - training loss: 0.5121, validation loss: 2.9588
2024-06-03 01:29:57 [INFO]: Epoch 030 - training loss: 0.5088, validation loss: 2.9567
2024-06-03 01:30:26 [INFO]: Epoch 031 - training loss: 0.5049, validation loss: 2.9518
2024-06-03 01:30:54 [INFO]: Epoch 032 - training loss: 0.5032, validation loss: 2.9551
2024-06-03 01:31:22 [INFO]: Epoch 033 - training loss: 0.5002, validation loss: 2.9492
2024-06-03 01:31:50 [INFO]: Epoch 034 - training loss: 0.4968, validation loss: 2.9389
2024-06-03 01:32:18 [INFO]: Epoch 035 - training loss: 0.4953, validation loss: 2.9402
2024-06-03 01:32:47 [INFO]: Epoch 036 - training loss: 0.4930, validation loss: 2.9280
2024-06-03 01:33:15 [INFO]: Epoch 037 - training loss: 0.4903, validation loss: 2.9409
2024-06-03 01:33:43 [INFO]: Epoch 038 - training loss: 0.4890, validation loss: 2.9218
2024-06-03 01:34:12 [INFO]: Epoch 039 - training loss: 0.4859, validation loss: 2.9169
2024-06-03 01:34:40 [INFO]: Epoch 040 - training loss: 0.4840, validation loss: 2.9157
2024-06-03 01:35:08 [INFO]: Epoch 041 - training loss: 0.4825, validation loss: 2.9133
2024-06-03 01:35:36 [INFO]: Epoch 042 - training loss: 0.4795, validation loss: 2.9160
2024-06-03 01:36:05 [INFO]: Epoch 043 - training loss: 0.4786, validation loss: 2.9072
2024-06-03 01:36:33 [INFO]: Epoch 044 - training loss: 0.4754, validation loss: 2.9071
2024-06-03 01:37:01 [INFO]: Epoch 045 - training loss: 0.4740, validation loss: 2.9031
2024-06-03 01:37:27 [INFO]: Epoch 046 - training loss: 0.4717, validation loss: 2.8974
2024-06-03 01:37:56 [INFO]: Epoch 047 - training loss: 0.4700, validation loss: 2.8930
2024-06-03 01:38:24 [INFO]: Epoch 048 - training loss: 0.4685, validation loss: 2.8900
2024-06-03 01:38:52 [INFO]: Epoch 049 - training loss: 0.4667, validation loss: 2.8890
2024-06-03 01:39:20 [INFO]: Epoch 050 - training loss: 0.4655, validation loss: 2.8908
2024-06-03 01:39:49 [INFO]: Epoch 051 - training loss: 0.4640, validation loss: 2.8827
2024-06-03 01:40:17 [INFO]: Epoch 052 - training loss: 0.4622, validation loss: 2.8772
2024-06-03 01:40:45 [INFO]: Epoch 053 - training loss: 0.4610, validation loss: 2.8728
2024-06-03 01:41:13 [INFO]: Epoch 054 - training loss: 0.4587, validation loss: 2.8775
2024-06-03 01:41:41 [INFO]: Epoch 055 - training loss: 0.4574, validation loss: 2.8842
2024-06-03 01:42:04 [INFO]: Epoch 056 - training loss: 0.4561, validation loss: 2.8714
2024-06-03 01:42:32 [INFO]: Epoch 057 - training loss: 0.4552, validation loss: 2.8741
2024-06-03 01:43:00 [INFO]: Epoch 058 - training loss: 0.4535, validation loss: 2.8697
2024-06-03 01:43:28 [INFO]: Epoch 059 - training loss: 0.4525, validation loss: 2.8724
2024-06-03 01:43:57 [INFO]: Epoch 060 - training loss: 0.4525, validation loss: 2.8757
2024-06-03 01:44:25 [INFO]: Epoch 061 - training loss: 0.4507, validation loss: 2.8675
2024-06-03 01:44:54 [INFO]: Epoch 062 - training loss: 0.4488, validation loss: 2.8656
2024-06-03 01:45:22 [INFO]: Epoch 063 - training loss: 0.4476, validation loss: 2.8665
2024-06-03 01:45:50 [INFO]: Epoch 064 - training loss: 0.4469, validation loss: 2.8608
2024-06-03 01:46:18 [INFO]: Epoch 065 - training loss: 0.4453, validation loss: 2.8667
2024-06-03 01:46:46 [INFO]: Epoch 066 - training loss: 0.4447, validation loss: 2.8687
2024-06-03 01:47:15 [INFO]: Epoch 067 - training loss: 0.4439, validation loss: 2.8551
2024-06-03 01:47:43 [INFO]: Epoch 068 - training loss: 0.4418, validation loss: 2.8528
2024-06-03 01:48:11 [INFO]: Epoch 069 - training loss: 0.4406, validation loss: 2.8604
2024-06-03 01:48:37 [INFO]: Epoch 070 - training loss: 0.4399, validation loss: 2.8564
2024-06-03 01:49:05 [INFO]: Epoch 071 - training loss: 0.4383, validation loss: 2.8497
2024-06-03 01:49:33 [INFO]: Epoch 072 - training loss: 0.4373, validation loss: 2.8526
2024-06-03 01:50:01 [INFO]: Epoch 073 - training loss: 0.4367, validation loss: 2.8638
2024-06-03 01:50:29 [INFO]: Epoch 074 - training loss: 0.4348, validation loss: 2.8507
2024-06-03 01:50:57 [INFO]: Epoch 075 - training loss: 0.4345, validation loss: 2.8578
2024-06-03 01:51:26 [INFO]: Epoch 076 - training loss: 0.4334, validation loss: 2.8592
2024-06-03 01:51:54 [INFO]: Epoch 077 - training loss: 0.4321, validation loss: 2.8518
2024-06-03 01:52:23 [INFO]: Epoch 078 - training loss: 0.4318, validation loss: 2.8564
2024-06-03 01:52:51 [INFO]: Epoch 079 - training loss: 0.4300, validation loss: 2.8589
2024-06-03 01:53:20 [INFO]: Epoch 080 - training loss: 0.4303, validation loss: 2.8579
2024-06-03 01:53:48 [INFO]: Epoch 081 - training loss: 0.4287, validation loss: 2.8600
2024-06-03 01:53:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:53:48 [INFO]: Finished training. The best model is from epoch#71.
2024-06-03 01:53:48 [INFO]: Saved the model to results_point_rate09/Electricity/StemGNN_Electricity/round_0/20240603_T011538/StemGNN.pypots
2024-06-03 01:53:51 [INFO]: Successfully saved to results_point_rate09/Electricity/StemGNN_Electricity/round_0/imputation.pkl
2024-06-03 01:53:51 [INFO]: Round0 - StemGNN on Electricity: MAE=1.3426, MSE=3.9146, MRE=0.7187
2024-06-03 01:53:51 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:53:51 [INFO]: Using the given device: cuda:0
2024-06-03 01:53:51 [INFO]: Model files will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_1/20240603_T015351
2024-06-03 01:53:51 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_1/20240603_T015351/tensorboard
2024-06-03 01:53:52 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 01:54:20 [INFO]: Epoch 001 - training loss: 1.5002, validation loss: 3.8220
2024-06-03 01:54:49 [INFO]: Epoch 002 - training loss: 1.2066, validation loss: 3.6794
2024-06-03 01:55:17 [INFO]: Epoch 003 - training loss: 1.0762, validation loss: 3.6135
2024-06-03 01:55:45 [INFO]: Epoch 004 - training loss: 0.9790, validation loss: 3.4988
2024-06-03 01:56:13 [INFO]: Epoch 005 - training loss: 0.8549, validation loss: 3.3362
2024-06-03 01:56:42 [INFO]: Epoch 006 - training loss: 0.7567, validation loss: 3.2441
2024-06-03 01:57:10 [INFO]: Epoch 007 - training loss: 0.7064, validation loss: 3.1987
2024-06-03 01:57:39 [INFO]: Epoch 008 - training loss: 0.6846, validation loss: 3.1781
2024-06-03 01:58:07 [INFO]: Epoch 009 - training loss: 0.6676, validation loss: 3.1638
2024-06-03 01:58:35 [INFO]: Epoch 010 - training loss: 0.6539, validation loss: 3.1502
2024-06-03 01:59:03 [INFO]: Epoch 011 - training loss: 0.6432, validation loss: 3.1110
2024-06-03 01:59:31 [INFO]: Epoch 012 - training loss: 0.6307, validation loss: 3.1013
2024-06-03 01:59:58 [INFO]: Epoch 013 - training loss: 0.6175, validation loss: 3.1014
2024-06-03 02:00:26 [INFO]: Epoch 014 - training loss: 0.6027, validation loss: 3.0639
2024-06-03 02:00:55 [INFO]: Epoch 015 - training loss: 0.5916, validation loss: 3.0574
2024-06-03 02:01:23 [INFO]: Epoch 016 - training loss: 0.5814, validation loss: 3.0406
2024-06-03 02:01:52 [INFO]: Epoch 017 - training loss: 0.5754, validation loss: 3.0416
2024-06-03 02:02:20 [INFO]: Epoch 018 - training loss: 0.5679, validation loss: 3.0551
2024-06-03 02:02:48 [INFO]: Epoch 019 - training loss: 0.5627, validation loss: 3.0197
2024-06-03 02:03:16 [INFO]: Epoch 020 - training loss: 0.5576, validation loss: 3.0255
2024-06-03 02:03:42 [INFO]: Epoch 021 - training loss: 0.5522, validation loss: 3.0143
2024-06-03 02:04:10 [INFO]: Epoch 022 - training loss: 0.5463, validation loss: 3.0033
2024-06-03 02:04:36 [INFO]: Epoch 023 - training loss: 0.5433, validation loss: 3.0197
2024-06-03 02:05:00 [INFO]: Epoch 024 - training loss: 0.5366, validation loss: 2.9986
2024-06-03 02:05:29 [INFO]: Epoch 025 - training loss: 0.5323, validation loss: 3.0011
2024-06-03 02:05:57 [INFO]: Epoch 026 - training loss: 0.5278, validation loss: 2.9850
2024-06-03 02:06:25 [INFO]: Epoch 027 - training loss: 0.5232, validation loss: 2.9947
2024-06-03 02:06:53 [INFO]: Epoch 028 - training loss: 0.5192, validation loss: 2.9948
2024-06-03 02:07:21 [INFO]: Epoch 029 - training loss: 0.5169, validation loss: 2.9937
2024-06-03 02:07:49 [INFO]: Epoch 030 - training loss: 0.5138, validation loss: 2.9881
2024-06-03 02:08:17 [INFO]: Epoch 031 - training loss: 0.5100, validation loss: 3.0000
2024-06-03 02:08:45 [INFO]: Epoch 032 - training loss: 0.5070, validation loss: 2.9849
2024-06-03 02:09:13 [INFO]: Epoch 033 - training loss: 0.5038, validation loss: 2.9962
2024-06-03 02:09:42 [INFO]: Epoch 034 - training loss: 0.5019, validation loss: 2.9920
2024-06-03 02:10:10 [INFO]: Epoch 035 - training loss: 0.4989, validation loss: 2.9701
2024-06-03 02:10:38 [INFO]: Epoch 036 - training loss: 0.4965, validation loss: 2.9997
2024-06-03 02:11:07 [INFO]: Epoch 037 - training loss: 0.4947, validation loss: 2.9819
2024-06-03 02:11:32 [INFO]: Epoch 038 - training loss: 0.4917, validation loss: 2.9839
2024-06-03 02:11:56 [INFO]: Epoch 039 - training loss: 0.4894, validation loss: 2.9795
2024-06-03 02:12:20 [INFO]: Epoch 040 - training loss: 0.4869, validation loss: 2.9803
2024-06-03 02:12:44 [INFO]: Epoch 041 - training loss: 0.4843, validation loss: 2.9814
2024-06-03 02:13:08 [INFO]: Epoch 042 - training loss: 0.4820, validation loss: 2.9757
2024-06-03 02:13:31 [INFO]: Epoch 043 - training loss: 0.4802, validation loss: 2.9725
2024-06-03 02:13:55 [INFO]: Epoch 044 - training loss: 0.4782, validation loss: 2.9849
2024-06-03 02:14:16 [INFO]: Epoch 045 - training loss: 0.4766, validation loss: 2.9758
2024-06-03 02:14:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:14:16 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 02:14:16 [INFO]: Saved the model to results_point_rate09/Electricity/StemGNN_Electricity/round_1/20240603_T015351/StemGNN.pypots
2024-06-03 02:14:18 [INFO]: Successfully saved to results_point_rate09/Electricity/StemGNN_Electricity/round_1/imputation.pkl
2024-06-03 02:14:18 [INFO]: Round1 - StemGNN on Electricity: MAE=1.4361, MSE=4.3357, MRE=0.7688
2024-06-03 02:14:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 02:14:18 [INFO]: Using the given device: cuda:0
2024-06-03 02:14:18 [INFO]: Model files will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_2/20240603_T021418
2024-06-03 02:14:18 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_2/20240603_T021418/tensorboard
2024-06-03 02:14:18 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 02:14:35 [INFO]: Epoch 001 - training loss: 1.4939, validation loss: 3.8445
2024-06-03 02:14:51 [INFO]: Epoch 002 - training loss: 1.2055, validation loss: 3.6866
2024-06-03 02:15:07 [INFO]: Epoch 003 - training loss: 1.0361, validation loss: 3.5211
2024-06-03 02:15:23 [INFO]: Epoch 004 - training loss: 0.8870, validation loss: 3.3368
2024-06-03 02:15:39 [INFO]: Epoch 005 - training loss: 0.8113, validation loss: 3.2267
2024-06-03 02:15:55 [INFO]: Epoch 006 - training loss: 0.7773, validation loss: 3.1442
2024-06-03 02:16:12 [INFO]: Epoch 007 - training loss: 0.7247, validation loss: 3.0554
2024-06-03 02:16:28 [INFO]: Epoch 008 - training loss: 0.6798, validation loss: 3.0058
2024-06-03 02:16:44 [INFO]: Epoch 009 - training loss: 0.6568, validation loss: 2.9756
2024-06-03 02:17:00 [INFO]: Epoch 010 - training loss: 0.6406, validation loss: 2.9540
2024-06-03 02:17:16 [INFO]: Epoch 011 - training loss: 0.6241, validation loss: 2.9286
2024-06-03 02:17:32 [INFO]: Epoch 012 - training loss: 0.6075, validation loss: 2.9078
2024-06-03 02:17:49 [INFO]: Epoch 013 - training loss: 0.5920, validation loss: 2.8868
2024-06-03 02:18:05 [INFO]: Epoch 014 - training loss: 0.5820, validation loss: 2.8798
2024-06-03 02:18:21 [INFO]: Epoch 015 - training loss: 0.5736, validation loss: 2.8575
2024-06-03 02:18:38 [INFO]: Epoch 016 - training loss: 0.5661, validation loss: 2.8432
2024-06-03 02:18:54 [INFO]: Epoch 017 - training loss: 0.5608, validation loss: 2.8373
2024-06-03 02:19:10 [INFO]: Epoch 018 - training loss: 0.5551, validation loss: 2.8269
2024-06-03 02:19:26 [INFO]: Epoch 019 - training loss: 0.5502, validation loss: 2.8298
2024-06-03 02:19:43 [INFO]: Epoch 020 - training loss: 0.5455, validation loss: 2.8191
2024-06-03 02:19:59 [INFO]: Epoch 021 - training loss: 0.5411, validation loss: 2.8135
2024-06-03 02:20:15 [INFO]: Epoch 022 - training loss: 0.5369, validation loss: 2.8026
2024-06-03 02:20:32 [INFO]: Epoch 023 - training loss: 0.5334, validation loss: 2.8051
2024-06-03 02:20:48 [INFO]: Epoch 024 - training loss: 0.5285, validation loss: 2.8015
2024-06-03 02:21:04 [INFO]: Epoch 025 - training loss: 0.5247, validation loss: 2.7903
2024-06-03 02:21:20 [INFO]: Epoch 026 - training loss: 0.5208, validation loss: 2.7901
2024-06-03 02:21:37 [INFO]: Epoch 027 - training loss: 0.5172, validation loss: 2.7862
2024-06-03 02:21:53 [INFO]: Epoch 028 - training loss: 0.5134, validation loss: 2.7803
2024-06-03 02:22:09 [INFO]: Epoch 029 - training loss: 0.5095, validation loss: 2.7768
2024-06-03 02:22:25 [INFO]: Epoch 030 - training loss: 0.5066, validation loss: 2.7665
2024-06-03 02:22:42 [INFO]: Epoch 031 - training loss: 0.5030, validation loss: 2.7694
2024-06-03 02:22:58 [INFO]: Epoch 032 - training loss: 0.5002, validation loss: 2.7678
2024-06-03 02:23:14 [INFO]: Epoch 033 - training loss: 0.4965, validation loss: 2.7702
2024-06-03 02:23:30 [INFO]: Epoch 034 - training loss: 0.4944, validation loss: 2.7592
2024-06-03 02:23:46 [INFO]: Epoch 035 - training loss: 0.4919, validation loss: 2.7558
2024-06-03 02:24:02 [INFO]: Epoch 036 - training loss: 0.4897, validation loss: 2.7565
2024-06-03 02:24:18 [INFO]: Epoch 037 - training loss: 0.4869, validation loss: 2.7529
2024-06-03 02:24:35 [INFO]: Epoch 038 - training loss: 0.4844, validation loss: 2.7577
2024-06-03 02:24:51 [INFO]: Epoch 039 - training loss: 0.4821, validation loss: 2.7524
2024-06-03 02:25:07 [INFO]: Epoch 040 - training loss: 0.4808, validation loss: 2.7534
2024-06-03 02:25:23 [INFO]: Epoch 041 - training loss: 0.4788, validation loss: 2.7488
2024-06-03 02:25:39 [INFO]: Epoch 042 - training loss: 0.4764, validation loss: 2.7411
2024-06-03 02:25:55 [INFO]: Epoch 043 - training loss: 0.4742, validation loss: 2.7459
2024-06-03 02:26:12 [INFO]: Epoch 044 - training loss: 0.4729, validation loss: 2.7475
2024-06-03 02:26:28 [INFO]: Epoch 045 - training loss: 0.4711, validation loss: 2.7494
2024-06-03 02:26:44 [INFO]: Epoch 046 - training loss: 0.4693, validation loss: 2.7404
2024-06-03 02:27:00 [INFO]: Epoch 047 - training loss: 0.4672, validation loss: 2.7384
2024-06-03 02:27:16 [INFO]: Epoch 048 - training loss: 0.4657, validation loss: 2.7399
2024-06-03 02:27:32 [INFO]: Epoch 049 - training loss: 0.4635, validation loss: 2.7327
2024-06-03 02:27:48 [INFO]: Epoch 050 - training loss: 0.4628, validation loss: 2.7323
2024-06-03 02:28:01 [INFO]: Epoch 051 - training loss: 0.4616, validation loss: 2.7387
2024-06-03 02:28:14 [INFO]: Epoch 052 - training loss: 0.4590, validation loss: 2.7332
2024-06-03 02:28:31 [INFO]: Epoch 053 - training loss: 0.4576, validation loss: 2.7309
2024-06-03 02:28:47 [INFO]: Epoch 054 - training loss: 0.4563, validation loss: 2.7300
2024-06-03 02:29:03 [INFO]: Epoch 055 - training loss: 0.4556, validation loss: 2.7298
2024-06-03 02:29:19 [INFO]: Epoch 056 - training loss: 0.4531, validation loss: 2.7357
2024-06-03 02:29:36 [INFO]: Epoch 057 - training loss: 0.4529, validation loss: 2.7298
2024-06-03 02:29:52 [INFO]: Epoch 058 - training loss: 0.4508, validation loss: 2.7264
2024-06-03 02:30:08 [INFO]: Epoch 059 - training loss: 0.4500, validation loss: 2.7255
2024-06-03 02:30:25 [INFO]: Epoch 060 - training loss: 0.4480, validation loss: 2.7234
2024-06-03 02:30:41 [INFO]: Epoch 061 - training loss: 0.4476, validation loss: 2.7220
2024-06-03 02:30:57 [INFO]: Epoch 062 - training loss: 0.4465, validation loss: 2.7230
2024-06-03 02:31:13 [INFO]: Epoch 063 - training loss: 0.4449, validation loss: 2.7184
2024-06-03 02:31:30 [INFO]: Epoch 064 - training loss: 0.4430, validation loss: 2.7284
2024-06-03 02:31:46 [INFO]: Epoch 065 - training loss: 0.4424, validation loss: 2.7214
2024-06-03 02:32:02 [INFO]: Epoch 066 - training loss: 0.4410, validation loss: 2.7259
2024-06-03 02:32:19 [INFO]: Epoch 067 - training loss: 0.4408, validation loss: 2.7181
2024-06-03 02:32:35 [INFO]: Epoch 068 - training loss: 0.4390, validation loss: 2.7222
2024-06-03 02:32:51 [INFO]: Epoch 069 - training loss: 0.4386, validation loss: 2.7245
2024-06-03 02:33:08 [INFO]: Epoch 070 - training loss: 0.4373, validation loss: 2.7191
2024-06-03 02:33:24 [INFO]: Epoch 071 - training loss: 0.4361, validation loss: 2.7238
2024-06-03 02:33:40 [INFO]: Epoch 072 - training loss: 0.4352, validation loss: 2.7210
2024-06-03 02:33:57 [INFO]: Epoch 073 - training loss: 0.4344, validation loss: 2.7280
2024-06-03 02:34:13 [INFO]: Epoch 074 - training loss: 0.4339, validation loss: 2.7229
2024-06-03 02:34:29 [INFO]: Epoch 075 - training loss: 0.4334, validation loss: 2.7206
2024-06-03 02:34:45 [INFO]: Epoch 076 - training loss: 0.4320, validation loss: 2.7255
2024-06-03 02:35:02 [INFO]: Epoch 077 - training loss: 0.4306, validation loss: 2.7205
2024-06-03 02:35:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:35:02 [INFO]: Finished training. The best model is from epoch#67.
2024-06-03 02:35:02 [INFO]: Saved the model to results_point_rate09/Electricity/StemGNN_Electricity/round_2/20240603_T021418/StemGNN.pypots
2024-06-03 02:35:04 [INFO]: Successfully saved to results_point_rate09/Electricity/StemGNN_Electricity/round_2/imputation.pkl
2024-06-03 02:35:04 [INFO]: Round2 - StemGNN on Electricity: MAE=1.1819, MSE=3.3952, MRE=0.6327
2024-06-03 02:35:04 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 02:35:04 [INFO]: Using the given device: cuda:0
2024-06-03 02:35:04 [INFO]: Model files will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_3/20240603_T023504
2024-06-03 02:35:04 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_3/20240603_T023504/tensorboard
2024-06-03 02:35:04 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 02:35:21 [INFO]: Epoch 001 - training loss: 1.5024, validation loss: 3.8571
2024-06-03 02:35:37 [INFO]: Epoch 002 - training loss: 1.2342, validation loss: 3.6991
2024-06-03 02:35:49 [INFO]: Epoch 003 - training loss: 1.0552, validation loss: 3.5360
2024-06-03 02:36:03 [INFO]: Epoch 004 - training loss: 0.9031, validation loss: 3.3504
2024-06-03 02:36:19 [INFO]: Epoch 005 - training loss: 0.8195, validation loss: 3.2275
2024-06-03 02:36:36 [INFO]: Epoch 006 - training loss: 0.7891, validation loss: 3.1769
2024-06-03 02:36:52 [INFO]: Epoch 007 - training loss: 0.7654, validation loss: 3.1105
2024-06-03 02:37:09 [INFO]: Epoch 008 - training loss: 0.7335, validation loss: 3.0451
2024-06-03 02:37:25 [INFO]: Epoch 009 - training loss: 0.6960, validation loss: 2.9877
2024-06-03 02:37:41 [INFO]: Epoch 010 - training loss: 0.6673, validation loss: 2.9486
2024-06-03 02:37:57 [INFO]: Epoch 011 - training loss: 0.6510, validation loss: 2.9267
2024-06-03 02:38:14 [INFO]: Epoch 012 - training loss: 0.6379, validation loss: 2.8974
2024-06-03 02:38:30 [INFO]: Epoch 013 - training loss: 0.6215, validation loss: 2.8678
2024-06-03 02:38:46 [INFO]: Epoch 014 - training loss: 0.6066, validation loss: 2.8531
2024-06-03 02:39:02 [INFO]: Epoch 015 - training loss: 0.5953, validation loss: 2.8293
2024-06-03 02:39:19 [INFO]: Epoch 016 - training loss: 0.5850, validation loss: 2.8200
2024-06-03 02:39:35 [INFO]: Epoch 017 - training loss: 0.5770, validation loss: 2.8053
2024-06-03 02:39:51 [INFO]: Epoch 018 - training loss: 0.5713, validation loss: 2.7981
2024-06-03 02:40:08 [INFO]: Epoch 019 - training loss: 0.5662, validation loss: 2.7936
2024-06-03 02:40:24 [INFO]: Epoch 020 - training loss: 0.5606, validation loss: 2.7902
2024-06-03 02:40:40 [INFO]: Epoch 021 - training loss: 0.5556, validation loss: 2.7788
2024-06-03 02:40:56 [INFO]: Epoch 022 - training loss: 0.5486, validation loss: 2.7669
2024-06-03 02:41:13 [INFO]: Epoch 023 - training loss: 0.5435, validation loss: 2.7698
2024-06-03 02:41:29 [INFO]: Epoch 024 - training loss: 0.5373, validation loss: 2.7626
2024-06-03 02:41:45 [INFO]: Epoch 025 - training loss: 0.5327, validation loss: 2.7513
2024-06-03 02:42:02 [INFO]: Epoch 026 - training loss: 0.5294, validation loss: 2.7492
2024-06-03 02:42:18 [INFO]: Epoch 027 - training loss: 0.5250, validation loss: 2.7495
2024-06-03 02:42:34 [INFO]: Epoch 028 - training loss: 0.5209, validation loss: 2.7439
2024-06-03 02:42:51 [INFO]: Epoch 029 - training loss: 0.5171, validation loss: 2.7369
2024-06-03 02:43:07 [INFO]: Epoch 030 - training loss: 0.5136, validation loss: 2.7390
2024-06-03 02:43:23 [INFO]: Epoch 031 - training loss: 0.5110, validation loss: 2.7328
2024-06-03 02:43:40 [INFO]: Epoch 032 - training loss: 0.5072, validation loss: 2.7260
2024-06-03 02:43:56 [INFO]: Epoch 033 - training loss: 0.5040, validation loss: 2.7281
2024-06-03 02:44:13 [INFO]: Epoch 034 - training loss: 0.5014, validation loss: 2.7269
2024-06-03 02:44:29 [INFO]: Epoch 035 - training loss: 0.4974, validation loss: 2.7211
2024-06-03 02:44:46 [INFO]: Epoch 036 - training loss: 0.4942, validation loss: 2.7162
2024-06-03 02:45:02 [INFO]: Epoch 037 - training loss: 0.4919, validation loss: 2.7174
2024-06-03 02:45:12 [INFO]: Epoch 038 - training loss: 0.4882, validation loss: 2.7188
2024-06-03 02:45:22 [INFO]: Epoch 039 - training loss: 0.4863, validation loss: 2.7164
2024-06-03 02:45:31 [INFO]: Epoch 040 - training loss: 0.4835, validation loss: 2.7143
2024-06-03 02:45:40 [INFO]: Epoch 041 - training loss: 0.4815, validation loss: 2.7159
2024-06-03 02:45:50 [INFO]: Epoch 042 - training loss: 0.4796, validation loss: 2.7092
2024-06-03 02:45:59 [INFO]: Epoch 043 - training loss: 0.4776, validation loss: 2.7056
2024-06-03 02:46:09 [INFO]: Epoch 044 - training loss: 0.4752, validation loss: 2.6996
2024-06-03 02:46:18 [INFO]: Epoch 045 - training loss: 0.4736, validation loss: 2.7011
2024-06-03 02:46:28 [INFO]: Epoch 046 - training loss: 0.4722, validation loss: 2.7067
2024-06-03 02:46:37 [INFO]: Epoch 047 - training loss: 0.4708, validation loss: 2.6958
2024-06-03 02:46:47 [INFO]: Epoch 048 - training loss: 0.4683, validation loss: 2.7019
2024-06-03 02:46:56 [INFO]: Epoch 049 - training loss: 0.4666, validation loss: 2.7024
2024-06-03 02:47:06 [INFO]: Epoch 050 - training loss: 0.4654, validation loss: 2.7012
2024-06-03 02:47:15 [INFO]: Epoch 051 - training loss: 0.4647, validation loss: 2.7012
2024-06-03 02:47:24 [INFO]: Epoch 052 - training loss: 0.4634, validation loss: 2.6989
2024-06-03 02:47:34 [INFO]: Epoch 053 - training loss: 0.4614, validation loss: 2.6976
2024-06-03 02:47:43 [INFO]: Epoch 054 - training loss: 0.4601, validation loss: 2.6950
2024-06-03 02:47:53 [INFO]: Epoch 055 - training loss: 0.4587, validation loss: 2.6880
2024-06-03 02:48:02 [INFO]: Epoch 056 - training loss: 0.4576, validation loss: 2.6939
2024-06-03 02:48:11 [INFO]: Epoch 057 - training loss: 0.4557, validation loss: 2.6897
2024-06-03 02:48:21 [INFO]: Epoch 058 - training loss: 0.4547, validation loss: 2.6920
2024-06-03 02:48:30 [INFO]: Epoch 059 - training loss: 0.4531, validation loss: 2.6959
2024-06-03 02:48:40 [INFO]: Epoch 060 - training loss: 0.4525, validation loss: 2.6963
2024-06-03 02:48:49 [INFO]: Epoch 061 - training loss: 0.4517, validation loss: 2.6946
2024-06-03 02:48:59 [INFO]: Epoch 062 - training loss: 0.4504, validation loss: 2.6919
2024-06-03 02:49:08 [INFO]: Epoch 063 - training loss: 0.4492, validation loss: 2.6886
2024-06-03 02:49:18 [INFO]: Epoch 064 - training loss: 0.4476, validation loss: 2.6905
2024-06-03 02:49:27 [INFO]: Epoch 065 - training loss: 0.4465, validation loss: 2.6957
2024-06-03 02:49:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:49:27 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 02:49:27 [INFO]: Saved the model to results_point_rate09/Electricity/StemGNN_Electricity/round_3/20240603_T023504/StemGNN.pypots
2024-06-03 02:49:28 [INFO]: Successfully saved to results_point_rate09/Electricity/StemGNN_Electricity/round_3/imputation.pkl
2024-06-03 02:49:28 [INFO]: Round3 - StemGNN on Electricity: MAE=1.2437, MSE=3.3726, MRE=0.6658
2024-06-03 02:49:28 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:49:28 [INFO]: Using the given device: cuda:0
2024-06-03 02:49:28 [INFO]: Model files will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_4/20240603_T024928
2024-06-03 02:49:28 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/StemGNN_Electricity/round_4/20240603_T024928/tensorboard
2024-06-03 02:49:28 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 02:49:38 [INFO]: Epoch 001 - training loss: 1.4811, validation loss: 3.8409
2024-06-03 02:49:47 [INFO]: Epoch 002 - training loss: 1.2278, validation loss: 3.7064
2024-06-03 02:49:57 [INFO]: Epoch 003 - training loss: 1.0877, validation loss: 3.5975
2024-06-03 02:50:06 [INFO]: Epoch 004 - training loss: 0.9438, validation loss: 3.4033
2024-06-03 02:50:16 [INFO]: Epoch 005 - training loss: 0.8237, validation loss: 3.2780
2024-06-03 02:50:25 [INFO]: Epoch 006 - training loss: 0.7588, validation loss: 3.1750
2024-06-03 02:50:34 [INFO]: Epoch 007 - training loss: 0.7059, validation loss: 3.1082
2024-06-03 02:50:44 [INFO]: Epoch 008 - training loss: 0.6759, validation loss: 3.0843
2024-06-03 02:50:53 [INFO]: Epoch 009 - training loss: 0.6561, validation loss: 3.0528
2024-06-03 02:51:03 [INFO]: Epoch 010 - training loss: 0.6368, validation loss: 3.0209
2024-06-03 02:51:12 [INFO]: Epoch 011 - training loss: 0.6201, validation loss: 3.0019
2024-06-03 02:51:22 [INFO]: Epoch 012 - training loss: 0.6067, validation loss: 2.9872
2024-06-03 02:51:31 [INFO]: Epoch 013 - training loss: 0.5954, validation loss: 2.9668
2024-06-03 02:51:40 [INFO]: Epoch 014 - training loss: 0.5884, validation loss: 2.9496
2024-06-03 02:51:50 [INFO]: Epoch 015 - training loss: 0.5813, validation loss: 2.9373
2024-06-03 02:51:59 [INFO]: Epoch 016 - training loss: 0.5747, validation loss: 2.9304
2024-06-03 02:52:09 [INFO]: Epoch 017 - training loss: 0.5676, validation loss: 2.9241
2024-06-03 02:52:18 [INFO]: Epoch 018 - training loss: 0.5609, validation loss: 2.9184
2024-06-03 02:52:27 [INFO]: Epoch 019 - training loss: 0.5545, validation loss: 2.9084
2024-06-03 02:52:37 [INFO]: Epoch 020 - training loss: 0.5488, validation loss: 2.9024
2024-06-03 02:52:46 [INFO]: Epoch 021 - training loss: 0.5420, validation loss: 2.8794
2024-06-03 02:52:56 [INFO]: Epoch 022 - training loss: 0.5350, validation loss: 2.8730
2024-06-03 02:53:05 [INFO]: Epoch 023 - training loss: 0.5295, validation loss: 2.8742
2024-06-03 02:53:15 [INFO]: Epoch 024 - training loss: 0.5258, validation loss: 2.8661
2024-06-03 02:53:24 [INFO]: Epoch 025 - training loss: 0.5219, validation loss: 2.8667
2024-06-03 02:53:33 [INFO]: Epoch 026 - training loss: 0.5171, validation loss: 2.8653
2024-06-03 02:53:43 [INFO]: Epoch 027 - training loss: 0.5130, validation loss: 2.8590
2024-06-03 02:53:52 [INFO]: Epoch 028 - training loss: 0.5100, validation loss: 2.8432
2024-06-03 02:54:02 [INFO]: Epoch 029 - training loss: 0.5058, validation loss: 2.8461
2024-06-03 02:54:11 [INFO]: Epoch 030 - training loss: 0.5026, validation loss: 2.8511
2024-06-03 02:54:20 [INFO]: Epoch 031 - training loss: 0.5001, validation loss: 2.8443
2024-06-03 02:54:30 [INFO]: Epoch 032 - training loss: 0.4972, validation loss: 2.8430
2024-06-03 02:54:39 [INFO]: Epoch 033 - training loss: 0.4947, validation loss: 2.8387
2024-06-03 02:54:49 [INFO]: Epoch 034 - training loss: 0.4932, validation loss: 2.8307
2024-06-03 02:54:58 [INFO]: Epoch 035 - training loss: 0.4901, validation loss: 2.8253
2024-06-03 02:55:08 [INFO]: Epoch 036 - training loss: 0.4884, validation loss: 2.8228
2024-06-03 02:55:17 [INFO]: Epoch 037 - training loss: 0.4865, validation loss: 2.8153
2024-06-03 02:55:26 [INFO]: Epoch 038 - training loss: 0.4830, validation loss: 2.8173
2024-06-03 02:55:36 [INFO]: Epoch 039 - training loss: 0.4817, validation loss: 2.8099
2024-06-03 02:55:45 [INFO]: Epoch 040 - training loss: 0.4796, validation loss: 2.8111
2024-06-03 02:55:54 [INFO]: Epoch 041 - training loss: 0.4781, validation loss: 2.8054
2024-06-03 02:56:04 [INFO]: Epoch 042 - training loss: 0.4767, validation loss: 2.7957
2024-06-03 02:56:13 [INFO]: Epoch 043 - training loss: 0.4759, validation loss: 2.8027
2024-06-03 02:56:23 [INFO]: Epoch 044 - training loss: 0.4738, validation loss: 2.7919
2024-06-03 02:56:32 [INFO]: Epoch 045 - training loss: 0.4716, validation loss: 2.7922
2024-06-03 02:56:42 [INFO]: Epoch 046 - training loss: 0.4706, validation loss: 2.7901
2024-06-03 02:56:51 [INFO]: Epoch 047 - training loss: 0.4689, validation loss: 2.7851
2024-06-03 02:57:01 [INFO]: Epoch 048 - training loss: 0.4676, validation loss: 2.7858
2024-06-03 02:57:10 [INFO]: Epoch 049 - training loss: 0.4662, validation loss: 2.7836
2024-06-03 02:57:19 [INFO]: Epoch 050 - training loss: 0.4647, validation loss: 2.7810
2024-06-03 02:57:29 [INFO]: Epoch 051 - training loss: 0.4639, validation loss: 2.7776
2024-06-03 02:57:38 [INFO]: Epoch 052 - training loss: 0.4621, validation loss: 2.7813
2024-06-03 02:57:48 [INFO]: Epoch 053 - training loss: 0.4595, validation loss: 2.7828
2024-06-03 02:57:57 [INFO]: Epoch 054 - training loss: 0.4589, validation loss: 2.7760
2024-06-03 02:58:06 [INFO]: Epoch 055 - training loss: 0.4580, validation loss: 2.7725
2024-06-03 02:58:16 [INFO]: Epoch 056 - training loss: 0.4568, validation loss: 2.7638
2024-06-03 02:58:25 [INFO]: Epoch 057 - training loss: 0.4556, validation loss: 2.7689
2024-06-03 02:58:35 [INFO]: Epoch 058 - training loss: 0.4535, validation loss: 2.7650
2024-06-03 02:58:44 [INFO]: Epoch 059 - training loss: 0.4516, validation loss: 2.7647
2024-06-03 02:58:54 [INFO]: Epoch 060 - training loss: 0.4510, validation loss: 2.7627
2024-06-03 02:59:03 [INFO]: Epoch 061 - training loss: 0.4498, validation loss: 2.7599
2024-06-03 02:59:12 [INFO]: Epoch 062 - training loss: 0.4486, validation loss: 2.7624
2024-06-03 02:59:22 [INFO]: Epoch 063 - training loss: 0.4480, validation loss: 2.7546
2024-06-03 02:59:31 [INFO]: Epoch 064 - training loss: 0.4462, validation loss: 2.7513
2024-06-03 02:59:41 [INFO]: Epoch 065 - training loss: 0.4444, validation loss: 2.7517
2024-06-03 02:59:50 [INFO]: Epoch 066 - training loss: 0.4433, validation loss: 2.7503
2024-06-03 02:59:59 [INFO]: Epoch 067 - training loss: 0.4426, validation loss: 2.7439
2024-06-03 03:00:09 [INFO]: Epoch 068 - training loss: 0.4419, validation loss: 2.7469
2024-06-03 03:00:18 [INFO]: Epoch 069 - training loss: 0.4406, validation loss: 2.7462
2024-06-03 03:00:28 [INFO]: Epoch 070 - training loss: 0.4385, validation loss: 2.7494
2024-06-03 03:00:37 [INFO]: Epoch 071 - training loss: 0.4377, validation loss: 2.7451
2024-06-03 03:00:47 [INFO]: Epoch 072 - training loss: 0.4370, validation loss: 2.7406
2024-06-03 03:00:56 [INFO]: Epoch 073 - training loss: 0.4361, validation loss: 2.7356
2024-06-03 03:01:05 [INFO]: Epoch 074 - training loss: 0.4348, validation loss: 2.7408
2024-06-03 03:01:15 [INFO]: Epoch 075 - training loss: 0.4334, validation loss: 2.7430
2024-06-03 03:01:24 [INFO]: Epoch 076 - training loss: 0.4331, validation loss: 2.7405
2024-06-03 03:01:34 [INFO]: Epoch 077 - training loss: 0.4317, validation loss: 2.7390
2024-06-03 03:01:43 [INFO]: Epoch 078 - training loss: 0.4312, validation loss: 2.7391
2024-06-03 03:01:53 [INFO]: Epoch 079 - training loss: 0.4300, validation loss: 2.7311
2024-06-03 03:02:02 [INFO]: Epoch 080 - training loss: 0.4284, validation loss: 2.7336
2024-06-03 03:02:11 [INFO]: Epoch 081 - training loss: 0.4284, validation loss: 2.7280
2024-06-03 03:02:21 [INFO]: Epoch 082 - training loss: 0.4273, validation loss: 2.7254
2024-06-03 03:02:30 [INFO]: Epoch 083 - training loss: 0.4260, validation loss: 2.7317
2024-06-03 03:02:40 [INFO]: Epoch 084 - training loss: 0.4255, validation loss: 2.7314
2024-06-03 03:02:49 [INFO]: Epoch 085 - training loss: 0.4251, validation loss: 2.7297
2024-06-03 03:02:58 [INFO]: Epoch 086 - training loss: 0.4237, validation loss: 2.7293
2024-06-03 03:03:08 [INFO]: Epoch 087 - training loss: 0.4231, validation loss: 2.7294
2024-06-03 03:03:17 [INFO]: Epoch 088 - training loss: 0.4216, validation loss: 2.7224
2024-06-03 03:03:27 [INFO]: Epoch 089 - training loss: 0.4215, validation loss: 2.7235
2024-06-03 03:03:36 [INFO]: Epoch 090 - training loss: 0.4201, validation loss: 2.7178
2024-06-03 03:03:46 [INFO]: Epoch 091 - training loss: 0.4200, validation loss: 2.7244
2024-06-03 03:03:55 [INFO]: Epoch 092 - training loss: 0.4195, validation loss: 2.7271
2024-06-03 03:04:04 [INFO]: Epoch 093 - training loss: 0.4183, validation loss: 2.7302
2024-06-03 03:04:14 [INFO]: Epoch 094 - training loss: 0.4177, validation loss: 2.7293
2024-06-03 03:04:23 [INFO]: Epoch 095 - training loss: 0.4165, validation loss: 2.7300
2024-06-03 03:04:32 [INFO]: Epoch 096 - training loss: 0.4160, validation loss: 2.7196
2024-06-03 03:04:42 [INFO]: Epoch 097 - training loss: 0.4151, validation loss: 2.7283
2024-06-03 03:04:51 [INFO]: Epoch 098 - training loss: 0.4152, validation loss: 2.7232
2024-06-03 03:05:01 [INFO]: Epoch 099 - training loss: 0.4134, validation loss: 2.7252
2024-06-03 03:05:10 [INFO]: Epoch 100 - training loss: 0.4132, validation loss: 2.7255
2024-06-03 03:05:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:05:10 [INFO]: Finished training. The best model is from epoch#90.
2024-06-03 03:05:10 [INFO]: Saved the model to results_point_rate09/Electricity/StemGNN_Electricity/round_4/20240603_T024928/StemGNN.pypots
2024-06-03 03:05:11 [INFO]: Successfully saved to results_point_rate09/Electricity/StemGNN_Electricity/round_4/imputation.pkl
2024-06-03 03:05:11 [INFO]: Round4 - StemGNN on Electricity: MAE=1.2661, MSE=3.5313, MRE=0.6778
2024-06-03 03:05:11 [INFO]: Done! Final results:
Averaged StemGNN (16,863,634 params) on Electricity: MAE=1.2941 ± 0.08766776493324256, MSE=3.7099 ± 0.36829927935727075, MRE=0.6928 ± 0.046931056113696724, average inference time=1.69
