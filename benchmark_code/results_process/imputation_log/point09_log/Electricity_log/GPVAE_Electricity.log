2024-06-03 01:13:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 01:13:04 [INFO]: Using the given device: cuda:0
2024-06-03 01:13:04 [INFO]: Model files will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_0/20240603_T011304
2024-06-03 01:13:04 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_0/20240603_T011304/tensorboard
2024-06-03 01:13:05 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 01:13:26 [INFO]: Epoch 001 - training loss: 202988.6244, validation loss: 3.6722
2024-06-03 01:13:43 [INFO]: Epoch 002 - training loss: 170078.3084, validation loss: 3.7201
2024-06-03 01:14:02 [INFO]: Epoch 003 - training loss: 168550.5949, validation loss: 3.8342
2024-06-03 01:14:21 [INFO]: Epoch 004 - training loss: 168127.2321, validation loss: 3.5171
2024-06-03 01:14:39 [INFO]: Epoch 005 - training loss: 167828.0231, validation loss: 3.5134
2024-06-03 01:14:56 [INFO]: Epoch 006 - training loss: 167927.5868, validation loss: 3.3621
2024-06-03 01:15:14 [INFO]: Epoch 007 - training loss: 167666.2037, validation loss: 3.3238
2024-06-03 01:15:32 [INFO]: Epoch 008 - training loss: 167746.9491, validation loss: 3.3232
2024-06-03 01:15:50 [INFO]: Epoch 009 - training loss: 167645.4363, validation loss: 3.1621
2024-06-03 01:16:08 [INFO]: Epoch 010 - training loss: 167525.9172, validation loss: 3.0801
2024-06-03 01:16:26 [INFO]: Epoch 011 - training loss: 167504.3530, validation loss: 3.1174
2024-06-03 01:16:44 [INFO]: Epoch 012 - training loss: 167514.3443, validation loss: 3.0610
2024-06-03 01:17:03 [INFO]: Epoch 013 - training loss: 167452.4115, validation loss: 3.0329
2024-06-03 01:17:21 [INFO]: Epoch 014 - training loss: 167455.3351, validation loss: 3.0314
2024-06-03 01:17:39 [INFO]: Epoch 015 - training loss: 167442.7228, validation loss: 3.0265
2024-06-03 01:17:57 [INFO]: Epoch 016 - training loss: 167440.7772, validation loss: 3.0378
2024-06-03 01:18:15 [INFO]: Epoch 017 - training loss: 167428.4213, validation loss: 3.0016
2024-06-03 01:18:33 [INFO]: Epoch 018 - training loss: 167413.3953, validation loss: 3.0242
2024-06-03 01:18:50 [INFO]: Epoch 019 - training loss: 167407.3848, validation loss: 3.0242
2024-06-03 01:19:08 [INFO]: Epoch 020 - training loss: 167437.1701, validation loss: 2.9689
2024-06-03 01:19:25 [INFO]: Epoch 021 - training loss: 167408.9294, validation loss: 3.0326
2024-06-03 01:19:43 [INFO]: Epoch 022 - training loss: 167401.0098, validation loss: 3.0030
2024-06-03 01:20:01 [INFO]: Epoch 023 - training loss: 167370.4398, validation loss: 2.9299
2024-06-03 01:20:19 [INFO]: Epoch 024 - training loss: 167368.5006, validation loss: 2.9107
2024-06-03 01:20:37 [INFO]: Epoch 025 - training loss: 167359.1973, validation loss: 2.8953
2024-06-03 01:20:55 [INFO]: Epoch 026 - training loss: 167327.9306, validation loss: 2.8892
2024-06-03 01:21:12 [INFO]: Epoch 027 - training loss: 167313.2326, validation loss: 2.8809
2024-06-03 01:21:31 [INFO]: Epoch 028 - training loss: 167301.7581, validation loss: 2.8721
2024-06-03 01:21:49 [INFO]: Epoch 029 - training loss: 167296.1782, validation loss: 2.8578
2024-06-03 01:22:06 [INFO]: Epoch 030 - training loss: 167294.0457, validation loss: 2.8615
2024-06-03 01:22:25 [INFO]: Epoch 031 - training loss: 167291.6655, validation loss: 2.8531
2024-06-03 01:22:43 [INFO]: Epoch 032 - training loss: 167273.7755, validation loss: 2.8843
2024-06-03 01:23:01 [INFO]: Epoch 033 - training loss: 167265.2309, validation loss: 2.8376
2024-06-03 01:23:20 [INFO]: Epoch 034 - training loss: 167271.0521, validation loss: 2.8951
2024-06-03 01:23:38 [INFO]: Epoch 035 - training loss: 167264.5758, validation loss: 2.8371
2024-06-03 01:23:56 [INFO]: Epoch 036 - training loss: 167255.6759, validation loss: 2.8317
2024-06-03 01:24:14 [INFO]: Epoch 037 - training loss: 167251.1464, validation loss: 2.8079
2024-06-03 01:24:32 [INFO]: Epoch 038 - training loss: 167253.8229, validation loss: 2.8293
2024-06-03 01:24:50 [INFO]: Epoch 039 - training loss: 167251.3883, validation loss: 2.8106
2024-06-03 01:25:07 [INFO]: Epoch 040 - training loss: 167245.9306, validation loss: 2.7908
2024-06-03 01:25:25 [INFO]: Epoch 041 - training loss: 167238.9392, validation loss: 2.8018
2024-06-03 01:25:42 [INFO]: Epoch 042 - training loss: 167238.5469, validation loss: 2.7893
2024-06-03 01:26:00 [INFO]: Epoch 043 - training loss: 167236.7714, validation loss: 2.7855
2024-06-03 01:26:18 [INFO]: Epoch 044 - training loss: 167232.3750, validation loss: 2.7970
2024-06-03 01:26:35 [INFO]: Epoch 045 - training loss: 167234.4670, validation loss: 2.7903
2024-06-03 01:26:53 [INFO]: Epoch 046 - training loss: 167228.4549, validation loss: 2.7844
2024-06-03 01:27:11 [INFO]: Epoch 047 - training loss: 167224.2691, validation loss: 2.7908
2024-06-03 01:27:29 [INFO]: Epoch 048 - training loss: 167225.1302, validation loss: 2.7984
2024-06-03 01:27:46 [INFO]: Epoch 049 - training loss: 167236.4352, validation loss: 2.7791
2024-06-03 01:28:05 [INFO]: Epoch 050 - training loss: 167222.3617, validation loss: 2.7876
2024-06-03 01:28:22 [INFO]: Epoch 051 - training loss: 167217.3953, validation loss: 2.7995
2024-06-03 01:28:41 [INFO]: Epoch 052 - training loss: 167212.8721, validation loss: 2.7751
2024-06-03 01:28:58 [INFO]: Epoch 053 - training loss: 167211.9948, validation loss: 2.8116
2024-06-03 01:29:17 [INFO]: Epoch 054 - training loss: 167210.1360, validation loss: 2.7721
2024-06-03 01:29:34 [INFO]: Epoch 055 - training loss: 167208.7870, validation loss: 2.7863
2024-06-03 01:29:52 [INFO]: Epoch 056 - training loss: 167210.1858, validation loss: 2.7909
2024-06-03 01:30:10 [INFO]: Epoch 057 - training loss: 167209.5561, validation loss: 2.7888
2024-06-03 01:30:28 [INFO]: Epoch 058 - training loss: 167205.6013, validation loss: 2.7829
2024-06-03 01:30:46 [INFO]: Epoch 059 - training loss: 167204.2951, validation loss: 2.7738
2024-06-03 01:31:05 [INFO]: Epoch 060 - training loss: 167202.1470, validation loss: 2.7802
2024-06-03 01:31:23 [INFO]: Epoch 061 - training loss: 167199.6400, validation loss: 2.7596
2024-06-03 01:31:41 [INFO]: Epoch 062 - training loss: 167198.8571, validation loss: 2.7715
2024-06-03 01:31:59 [INFO]: Epoch 063 - training loss: 167198.6308, validation loss: 2.7700
2024-06-03 01:32:16 [INFO]: Epoch 064 - training loss: 167195.2054, validation loss: 2.7765
2024-06-03 01:32:34 [INFO]: Epoch 065 - training loss: 167195.6985, validation loss: 2.7442
2024-06-03 01:32:50 [INFO]: Epoch 066 - training loss: 167195.8605, validation loss: 2.7587
2024-06-03 01:33:06 [INFO]: Epoch 067 - training loss: 167192.0741, validation loss: 2.7512
2024-06-03 01:33:18 [INFO]: Epoch 068 - training loss: 167190.7818, validation loss: 2.7579
2024-06-03 01:33:30 [INFO]: Epoch 069 - training loss: 167192.8466, validation loss: 2.7617
2024-06-03 01:33:44 [INFO]: Epoch 070 - training loss: 167190.8137, validation loss: 2.7678
2024-06-03 01:33:56 [INFO]: Epoch 071 - training loss: 167189.2263, validation loss: 2.7670
2024-06-03 01:34:08 [INFO]: Epoch 072 - training loss: 167193.3333, validation loss: 2.7591
2024-06-03 01:34:21 [INFO]: Epoch 073 - training loss: 167186.9172, validation loss: 2.7685
2024-06-03 01:34:32 [INFO]: Epoch 074 - training loss: 167186.7274, validation loss: 2.7461
2024-06-03 01:34:45 [INFO]: Epoch 075 - training loss: 167187.8837, validation loss: 2.7817
2024-06-03 01:34:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:34:45 [INFO]: Finished training. The best model is from epoch#65.
2024-06-03 01:34:45 [INFO]: Saved the model to results_point_rate09/Electricity/GPVAE_Electricity/round_0/20240603_T011304/GPVAE.pypots
2024-06-03 01:35:10 [INFO]: Successfully saved to results_point_rate09/Electricity/GPVAE_Electricity/round_0/imputation.pkl
2024-06-03 01:35:10 [INFO]: Round0 - GPVAE on Electricity: MAE=1.2380, MSE=3.5245, MRE=0.6628
2024-06-03 01:35:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:35:10 [INFO]: Using the given device: cuda:0
2024-06-03 01:35:10 [INFO]: Model files will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_1/20240603_T013510
2024-06-03 01:35:10 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_1/20240603_T013510/tensorboard
2024-06-03 01:35:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 01:35:22 [INFO]: Epoch 001 - training loss: 203299.7124, validation loss: 3.9973
2024-06-03 01:35:33 [INFO]: Epoch 002 - training loss: 169779.8744, validation loss: 3.4577
2024-06-03 01:35:45 [INFO]: Epoch 003 - training loss: 169878.2911, validation loss: 3.6663
2024-06-03 01:35:56 [INFO]: Epoch 004 - training loss: 168228.7685, validation loss: 3.4792
2024-06-03 01:36:07 [INFO]: Epoch 005 - training loss: 167833.0544, validation loss: 3.3955
2024-06-03 01:36:18 [INFO]: Epoch 006 - training loss: 167716.1285, validation loss: 3.3022
2024-06-03 01:36:29 [INFO]: Epoch 007 - training loss: 167681.7593, validation loss: 3.1914
2024-06-03 01:36:41 [INFO]: Epoch 008 - training loss: 167616.3328, validation loss: 3.2050
2024-06-03 01:36:52 [INFO]: Epoch 009 - training loss: 167593.0098, validation loss: 3.2001
2024-06-03 01:37:04 [INFO]: Epoch 010 - training loss: 167567.6806, validation loss: 3.2167
2024-06-03 01:37:15 [INFO]: Epoch 011 - training loss: 167572.1887, validation loss: 3.2256
2024-06-03 01:37:26 [INFO]: Epoch 012 - training loss: 167589.1319, validation loss: 3.2001
2024-06-03 01:37:38 [INFO]: Epoch 013 - training loss: 167544.5625, validation loss: 3.1865
2024-06-03 01:37:49 [INFO]: Epoch 014 - training loss: 167584.2963, validation loss: 3.2121
2024-06-03 01:38:00 [INFO]: Epoch 015 - training loss: 167515.8895, validation loss: 3.1625
2024-06-03 01:38:11 [INFO]: Epoch 016 - training loss: 167474.1163, validation loss: 3.1538
2024-06-03 01:38:22 [INFO]: Epoch 017 - training loss: 167434.8600, validation loss: 3.0573
2024-06-03 01:38:33 [INFO]: Epoch 018 - training loss: 167408.1956, validation loss: 3.0809
2024-06-03 01:38:44 [INFO]: Epoch 019 - training loss: 167389.4907, validation loss: 3.0059
2024-06-03 01:38:54 [INFO]: Epoch 020 - training loss: 167371.8455, validation loss: 2.9492
2024-06-03 01:39:01 [INFO]: Epoch 021 - training loss: 167348.7043, validation loss: 2.9528
2024-06-03 01:39:07 [INFO]: Epoch 022 - training loss: 167330.1383, validation loss: 2.9630
2024-06-03 01:39:12 [INFO]: Epoch 023 - training loss: 167321.0185, validation loss: 2.9637
2024-06-03 01:39:17 [INFO]: Epoch 024 - training loss: 167328.8669, validation loss: 2.9527
2024-06-03 01:39:22 [INFO]: Epoch 025 - training loss: 167315.1019, validation loss: 2.9652
2024-06-03 01:39:28 [INFO]: Epoch 026 - training loss: 167299.7072, validation loss: 2.9396
2024-06-03 01:39:33 [INFO]: Epoch 027 - training loss: 167307.2546, validation loss: 2.9192
2024-06-03 01:39:38 [INFO]: Epoch 028 - training loss: 167297.6869, validation loss: 2.9264
2024-06-03 01:39:43 [INFO]: Epoch 029 - training loss: 167279.6076, validation loss: 2.9084
2024-06-03 01:39:48 [INFO]: Epoch 030 - training loss: 167270.9236, validation loss: 2.8973
2024-06-03 01:39:54 [INFO]: Epoch 031 - training loss: 167266.6887, validation loss: 2.8763
2024-06-03 01:39:59 [INFO]: Epoch 032 - training loss: 167263.3733, validation loss: 2.8622
2024-06-03 01:40:04 [INFO]: Epoch 033 - training loss: 167257.7812, validation loss: 2.8605
2024-06-03 01:40:09 [INFO]: Epoch 034 - training loss: 167252.3119, validation loss: 2.8369
2024-06-03 01:40:14 [INFO]: Epoch 035 - training loss: 167248.5220, validation loss: 2.8452
2024-06-03 01:40:19 [INFO]: Epoch 036 - training loss: 167248.4311, validation loss: 2.8703
2024-06-03 01:40:24 [INFO]: Epoch 037 - training loss: 167261.4965, validation loss: 2.8530
2024-06-03 01:40:29 [INFO]: Epoch 038 - training loss: 167246.1962, validation loss: 2.8258
2024-06-03 01:40:34 [INFO]: Epoch 039 - training loss: 167240.2812, validation loss: 2.8135
2024-06-03 01:40:39 [INFO]: Epoch 040 - training loss: 167236.4786, validation loss: 2.8173
2024-06-03 01:40:44 [INFO]: Epoch 041 - training loss: 167233.5116, validation loss: 2.8271
2024-06-03 01:40:49 [INFO]: Epoch 042 - training loss: 167235.7436, validation loss: 2.8172
2024-06-03 01:40:54 [INFO]: Epoch 043 - training loss: 167232.8495, validation loss: 2.8109
2024-06-03 01:40:59 [INFO]: Epoch 044 - training loss: 167229.1152, validation loss: 2.8156
2024-06-03 01:41:05 [INFO]: Epoch 045 - training loss: 167226.1863, validation loss: 2.8378
2024-06-03 01:41:10 [INFO]: Epoch 046 - training loss: 167226.8194, validation loss: 2.8233
2024-06-03 01:41:15 [INFO]: Epoch 047 - training loss: 167223.9826, validation loss: 2.8262
2024-06-03 01:41:20 [INFO]: Epoch 048 - training loss: 167227.4884, validation loss: 2.8157
2024-06-03 01:41:25 [INFO]: Epoch 049 - training loss: 167230.0637, validation loss: 2.8178
2024-06-03 01:41:30 [INFO]: Epoch 050 - training loss: 167221.9416, validation loss: 2.8240
2024-06-03 01:41:35 [INFO]: Epoch 051 - training loss: 167218.5955, validation loss: 2.8156
2024-06-03 01:41:40 [INFO]: Epoch 052 - training loss: 167215.8200, validation loss: 2.8061
2024-06-03 01:41:45 [INFO]: Epoch 053 - training loss: 167213.9311, validation loss: 2.8145
2024-06-03 01:41:50 [INFO]: Epoch 054 - training loss: 167213.8547, validation loss: 2.7978
2024-06-03 01:41:55 [INFO]: Epoch 055 - training loss: 167208.8958, validation loss: 2.8104
2024-06-03 01:42:00 [INFO]: Epoch 056 - training loss: 167205.9439, validation loss: 2.8021
2024-06-03 01:42:05 [INFO]: Epoch 057 - training loss: 167206.2899, validation loss: 2.8047
2024-06-03 01:42:10 [INFO]: Epoch 058 - training loss: 167203.9832, validation loss: 2.8037
2024-06-03 01:42:15 [INFO]: Epoch 059 - training loss: 167203.6834, validation loss: 2.8023
2024-06-03 01:42:20 [INFO]: Epoch 060 - training loss: 167204.3056, validation loss: 2.8234
2024-06-03 01:42:25 [INFO]: Epoch 061 - training loss: 167201.4491, validation loss: 2.7929
2024-06-03 01:42:30 [INFO]: Epoch 062 - training loss: 167199.9057, validation loss: 2.8035
2024-06-03 01:42:36 [INFO]: Epoch 063 - training loss: 167203.6163, validation loss: 2.8151
2024-06-03 01:42:41 [INFO]: Epoch 064 - training loss: 167196.3403, validation loss: 2.7988
2024-06-03 01:42:46 [INFO]: Epoch 065 - training loss: 167197.2801, validation loss: 2.8005
2024-06-03 01:42:51 [INFO]: Epoch 066 - training loss: 167196.5145, validation loss: 2.8039
2024-06-03 01:42:56 [INFO]: Epoch 067 - training loss: 167195.0891, validation loss: 2.7854
2024-06-03 01:43:01 [INFO]: Epoch 068 - training loss: 167193.9676, validation loss: 2.8028
2024-06-03 01:43:06 [INFO]: Epoch 069 - training loss: 167194.9109, validation loss: 2.7926
2024-06-03 01:43:11 [INFO]: Epoch 070 - training loss: 167193.0602, validation loss: 2.7919
2024-06-03 01:43:16 [INFO]: Epoch 071 - training loss: 167194.2240, validation loss: 2.8007
2024-06-03 01:43:21 [INFO]: Epoch 072 - training loss: 167193.9439, validation loss: 2.7912
2024-06-03 01:43:26 [INFO]: Epoch 073 - training loss: 167190.3472, validation loss: 2.7859
2024-06-03 01:43:31 [INFO]: Epoch 074 - training loss: 167191.1105, validation loss: 2.8006
2024-06-03 01:43:36 [INFO]: Epoch 075 - training loss: 167187.8588, validation loss: 2.7973
2024-06-03 01:43:41 [INFO]: Epoch 076 - training loss: 167192.6030, validation loss: 2.8107
2024-06-03 01:43:46 [INFO]: Epoch 077 - training loss: 167190.3657, validation loss: 2.7901
2024-06-03 01:43:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:43:46 [INFO]: Finished training. The best model is from epoch#67.
2024-06-03 01:43:46 [INFO]: Saved the model to results_point_rate09/Electricity/GPVAE_Electricity/round_1/20240603_T013510/GPVAE.pypots
2024-06-03 01:43:58 [INFO]: Successfully saved to results_point_rate09/Electricity/GPVAE_Electricity/round_1/imputation.pkl
2024-06-03 01:43:58 [INFO]: Round1 - GPVAE on Electricity: MAE=1.2833, MSE=3.6697, MRE=0.6870
2024-06-03 01:43:58 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:43:58 [INFO]: Using the given device: cuda:0
2024-06-03 01:43:58 [INFO]: Model files will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_2/20240603_T014358
2024-06-03 01:43:58 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_2/20240603_T014358/tensorboard
2024-06-03 01:43:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 01:44:03 [INFO]: Epoch 001 - training loss: 203106.2899, validation loss: 3.9638
2024-06-03 01:44:08 [INFO]: Epoch 002 - training loss: 169778.4433, validation loss: 4.1963
2024-06-03 01:44:13 [INFO]: Epoch 003 - training loss: 168825.0700, validation loss: 3.8599
2024-06-03 01:44:18 [INFO]: Epoch 004 - training loss: 168280.7951, validation loss: 3.5217
2024-06-03 01:44:23 [INFO]: Epoch 005 - training loss: 167995.6672, validation loss: 3.3930
2024-06-03 01:44:28 [INFO]: Epoch 006 - training loss: 167828.7760, validation loss: 3.3977
2024-06-03 01:44:33 [INFO]: Epoch 007 - training loss: 167683.8883, validation loss: 3.3482
2024-06-03 01:44:38 [INFO]: Epoch 008 - training loss: 167696.0451, validation loss: 3.2834
2024-06-03 01:44:43 [INFO]: Epoch 009 - training loss: 167627.4942, validation loss: 3.1965
2024-06-03 01:44:48 [INFO]: Epoch 010 - training loss: 167580.3588, validation loss: 3.1396
2024-06-03 01:44:53 [INFO]: Epoch 011 - training loss: 167687.3791, validation loss: 3.2478
2024-06-03 01:44:58 [INFO]: Epoch 012 - training loss: 167583.6586, validation loss: 3.0915
2024-06-03 01:45:03 [INFO]: Epoch 013 - training loss: 167491.1921, validation loss: 3.1108
2024-06-03 01:45:08 [INFO]: Epoch 014 - training loss: 167478.0775, validation loss: 3.0818
2024-06-03 01:45:13 [INFO]: Epoch 015 - training loss: 167450.0012, validation loss: 3.0289
2024-06-03 01:45:18 [INFO]: Epoch 016 - training loss: 167446.4572, validation loss: 3.0366
2024-06-03 01:45:22 [INFO]: Epoch 017 - training loss: 167450.4300, validation loss: 3.0348
2024-06-03 01:45:27 [INFO]: Epoch 018 - training loss: 167430.9213, validation loss: 3.0135
2024-06-03 01:45:32 [INFO]: Epoch 019 - training loss: 167413.6811, validation loss: 3.0048
2024-06-03 01:45:36 [INFO]: Epoch 020 - training loss: 167404.5978, validation loss: 2.9959
2024-06-03 01:45:40 [INFO]: Epoch 021 - training loss: 167396.4792, validation loss: 3.0045
2024-06-03 01:45:44 [INFO]: Epoch 022 - training loss: 167411.7708, validation loss: 2.9519
2024-06-03 01:45:48 [INFO]: Epoch 023 - training loss: 167392.8958, validation loss: 2.9663
2024-06-03 01:45:52 [INFO]: Epoch 024 - training loss: 167403.7002, validation loss: 2.9155
2024-06-03 01:45:56 [INFO]: Epoch 025 - training loss: 167344.5457, validation loss: 2.9093
2024-06-03 01:46:00 [INFO]: Epoch 026 - training loss: 167330.2020, validation loss: 2.9009
2024-06-03 01:46:04 [INFO]: Epoch 027 - training loss: 167316.5365, validation loss: 2.8624
2024-06-03 01:46:08 [INFO]: Epoch 028 - training loss: 167307.2350, validation loss: 2.8596
2024-06-03 01:46:12 [INFO]: Epoch 029 - training loss: 167302.0307, validation loss: 2.8521
2024-06-03 01:46:16 [INFO]: Epoch 030 - training loss: 167299.3709, validation loss: 2.8432
2024-06-03 01:46:20 [INFO]: Epoch 031 - training loss: 167288.4068, validation loss: 2.8429
2024-06-03 01:46:24 [INFO]: Epoch 032 - training loss: 167287.7378, validation loss: 2.8259
2024-06-03 01:46:28 [INFO]: Epoch 033 - training loss: 167276.3958, validation loss: 2.8222
2024-06-03 01:46:32 [INFO]: Epoch 034 - training loss: 167270.0712, validation loss: 2.8188
2024-06-03 01:46:36 [INFO]: Epoch 035 - training loss: 167270.2350, validation loss: 2.8198
2024-06-03 01:46:40 [INFO]: Epoch 036 - training loss: 167266.7407, validation loss: 2.8093
2024-06-03 01:46:44 [INFO]: Epoch 037 - training loss: 167263.2917, validation loss: 2.8354
2024-06-03 01:46:48 [INFO]: Epoch 038 - training loss: 167266.1956, validation loss: 2.8054
2024-06-03 01:46:52 [INFO]: Epoch 039 - training loss: 167258.5093, validation loss: 2.7970
2024-06-03 01:46:56 [INFO]: Epoch 040 - training loss: 167254.0995, validation loss: 2.8033
2024-06-03 01:47:00 [INFO]: Epoch 041 - training loss: 167253.5191, validation loss: 2.8093
2024-06-03 01:47:04 [INFO]: Epoch 042 - training loss: 167251.4259, validation loss: 2.7935
2024-06-03 01:47:08 [INFO]: Epoch 043 - training loss: 167243.4705, validation loss: 2.8113
2024-06-03 01:47:12 [INFO]: Epoch 044 - training loss: 167244.4664, validation loss: 2.7858
2024-06-03 01:47:16 [INFO]: Epoch 045 - training loss: 167242.9416, validation loss: 2.7994
2024-06-03 01:47:20 [INFO]: Epoch 046 - training loss: 167239.3461, validation loss: 2.7915
2024-06-03 01:47:24 [INFO]: Epoch 047 - training loss: 167236.2928, validation loss: 2.8105
2024-06-03 01:47:28 [INFO]: Epoch 048 - training loss: 167234.4271, validation loss: 2.8003
2024-06-03 01:47:32 [INFO]: Epoch 049 - training loss: 167236.6395, validation loss: 2.8032
2024-06-03 01:47:36 [INFO]: Epoch 050 - training loss: 167232.5162, validation loss: 2.8006
2024-06-03 01:47:40 [INFO]: Epoch 051 - training loss: 167229.0243, validation loss: 2.7960
2024-06-03 01:47:44 [INFO]: Epoch 052 - training loss: 167224.1088, validation loss: 2.7901
2024-06-03 01:47:48 [INFO]: Epoch 053 - training loss: 167223.0069, validation loss: 2.7848
2024-06-03 01:47:52 [INFO]: Epoch 054 - training loss: 167220.5567, validation loss: 2.7921
2024-06-03 01:47:56 [INFO]: Epoch 055 - training loss: 167221.8015, validation loss: 2.7894
2024-06-03 01:48:00 [INFO]: Epoch 056 - training loss: 167215.0127, validation loss: 2.7907
2024-06-03 01:48:04 [INFO]: Epoch 057 - training loss: 167216.0579, validation loss: 2.7817
2024-06-03 01:48:08 [INFO]: Epoch 058 - training loss: 167211.9271, validation loss: 2.7732
2024-06-03 01:48:12 [INFO]: Epoch 059 - training loss: 167210.6649, validation loss: 2.7867
2024-06-03 01:48:16 [INFO]: Epoch 060 - training loss: 167211.6528, validation loss: 2.7874
2024-06-03 01:48:20 [INFO]: Epoch 061 - training loss: 167209.5197, validation loss: 2.7897
2024-06-03 01:48:24 [INFO]: Epoch 062 - training loss: 167207.4589, validation loss: 2.7784
2024-06-03 01:48:28 [INFO]: Epoch 063 - training loss: 167208.5885, validation loss: 2.7743
2024-06-03 01:48:32 [INFO]: Epoch 064 - training loss: 167205.5475, validation loss: 2.7921
2024-06-03 01:48:36 [INFO]: Epoch 065 - training loss: 167204.6030, validation loss: 2.7968
2024-06-03 01:48:40 [INFO]: Epoch 066 - training loss: 167203.8484, validation loss: 2.7850
2024-06-03 01:48:44 [INFO]: Epoch 067 - training loss: 167202.2859, validation loss: 2.7911
2024-06-03 01:48:48 [INFO]: Epoch 068 - training loss: 167200.3316, validation loss: 2.7765
2024-06-03 01:48:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:48:48 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 01:48:48 [INFO]: Saved the model to results_point_rate09/Electricity/GPVAE_Electricity/round_2/20240603_T014358/GPVAE.pypots
2024-06-03 01:48:56 [INFO]: Successfully saved to results_point_rate09/Electricity/GPVAE_Electricity/round_2/imputation.pkl
2024-06-03 01:48:56 [INFO]: Round2 - GPVAE on Electricity: MAE=1.2045, MSE=3.5168, MRE=0.6448
2024-06-03 01:48:56 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:48:56 [INFO]: Using the given device: cuda:0
2024-06-03 01:48:56 [INFO]: Model files will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_3/20240603_T014856
2024-06-03 01:48:56 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_3/20240603_T014856/tensorboard
2024-06-03 01:48:56 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 01:49:00 [INFO]: Epoch 001 - training loss: 202567.3594, validation loss: 4.4804
2024-06-03 01:49:04 [INFO]: Epoch 002 - training loss: 170177.6314, validation loss: 4.4733
2024-06-03 01:49:08 [INFO]: Epoch 003 - training loss: 170301.4641, validation loss: 3.4867
2024-06-03 01:49:11 [INFO]: Epoch 004 - training loss: 168991.4624, validation loss: 3.5379
2024-06-03 01:49:15 [INFO]: Epoch 005 - training loss: 167902.1748, validation loss: 3.4957
2024-06-03 01:49:19 [INFO]: Epoch 006 - training loss: 167818.2095, validation loss: 3.3975
2024-06-03 01:49:23 [INFO]: Epoch 007 - training loss: 167743.9190, validation loss: 3.2239
2024-06-03 01:49:26 [INFO]: Epoch 008 - training loss: 167652.5388, validation loss: 3.1986
2024-06-03 01:49:30 [INFO]: Epoch 009 - training loss: 167622.4502, validation loss: 3.2038
2024-06-03 01:49:34 [INFO]: Epoch 010 - training loss: 167594.7737, validation loss: 3.2024
2024-06-03 01:49:38 [INFO]: Epoch 011 - training loss: 167587.5046, validation loss: 3.1913
2024-06-03 01:49:41 [INFO]: Epoch 012 - training loss: 167582.2830, validation loss: 3.1967
2024-06-03 01:49:45 [INFO]: Epoch 013 - training loss: 167598.0880, validation loss: 3.1844
2024-06-03 01:49:49 [INFO]: Epoch 014 - training loss: 167578.1192, validation loss: 3.1863
2024-06-03 01:49:53 [INFO]: Epoch 015 - training loss: 167567.8409, validation loss: 3.1654
2024-06-03 01:49:56 [INFO]: Epoch 016 - training loss: 167554.5804, validation loss: 3.1790
2024-06-03 01:50:00 [INFO]: Epoch 017 - training loss: 167554.9543, validation loss: 3.1816
2024-06-03 01:50:04 [INFO]: Epoch 018 - training loss: 167541.4201, validation loss: 3.2574
2024-06-03 01:50:08 [INFO]: Epoch 019 - training loss: 167521.7419, validation loss: 3.1408
2024-06-03 01:50:11 [INFO]: Epoch 020 - training loss: 167508.4381, validation loss: 3.1960
2024-06-03 01:50:15 [INFO]: Epoch 021 - training loss: 167482.7222, validation loss: 3.1157
2024-06-03 01:50:19 [INFO]: Epoch 022 - training loss: 167504.4045, validation loss: 3.1155
2024-06-03 01:50:22 [INFO]: Epoch 023 - training loss: 167496.2934, validation loss: 3.0818
2024-06-03 01:50:26 [INFO]: Epoch 024 - training loss: 167439.4502, validation loss: 3.0431
2024-06-03 01:50:30 [INFO]: Epoch 025 - training loss: 167411.9850, validation loss: 3.0399
2024-06-03 01:50:34 [INFO]: Epoch 026 - training loss: 167388.5642, validation loss: 3.0303
2024-06-03 01:50:37 [INFO]: Epoch 027 - training loss: 167374.0434, validation loss: 3.0335
2024-06-03 01:50:41 [INFO]: Epoch 028 - training loss: 167357.3067, validation loss: 2.9866
2024-06-03 01:50:45 [INFO]: Epoch 029 - training loss: 167346.9491, validation loss: 2.9941
2024-06-03 01:50:49 [INFO]: Epoch 030 - training loss: 167334.8356, validation loss: 2.9690
2024-06-03 01:50:52 [INFO]: Epoch 031 - training loss: 167328.6395, validation loss: 2.9606
2024-06-03 01:50:56 [INFO]: Epoch 032 - training loss: 167311.2448, validation loss: 2.9295
2024-06-03 01:51:00 [INFO]: Epoch 033 - training loss: 167303.9919, validation loss: 2.8847
2024-06-03 01:51:04 [INFO]: Epoch 034 - training loss: 167298.2627, validation loss: 2.8778
2024-06-03 01:51:07 [INFO]: Epoch 035 - training loss: 167285.3640, validation loss: 2.8873
2024-06-03 01:51:11 [INFO]: Epoch 036 - training loss: 167283.2824, validation loss: 2.9269
2024-06-03 01:51:15 [INFO]: Epoch 037 - training loss: 167279.4884, validation loss: 2.8523
2024-06-03 01:51:18 [INFO]: Epoch 038 - training loss: 167271.2963, validation loss: 2.8799
2024-06-03 01:51:22 [INFO]: Epoch 039 - training loss: 167267.8032, validation loss: 2.8530
2024-06-03 01:51:26 [INFO]: Epoch 040 - training loss: 167264.3611, validation loss: 2.8521
2024-06-03 01:51:30 [INFO]: Epoch 041 - training loss: 167261.8877, validation loss: 2.8557
2024-06-03 01:51:33 [INFO]: Epoch 042 - training loss: 167258.4288, validation loss: 2.8478
2024-06-03 01:51:37 [INFO]: Epoch 043 - training loss: 167252.9120, validation loss: 2.8355
2024-06-03 01:51:41 [INFO]: Epoch 044 - training loss: 167264.1001, validation loss: 2.8227
2024-06-03 01:51:45 [INFO]: Epoch 045 - training loss: 167254.0932, validation loss: 2.8135
2024-06-03 01:51:48 [INFO]: Epoch 046 - training loss: 167249.1053, validation loss: 2.8068
2024-06-03 01:51:52 [INFO]: Epoch 047 - training loss: 167243.5793, validation loss: 2.8137
2024-06-03 01:51:56 [INFO]: Epoch 048 - training loss: 167242.4815, validation loss: 2.7896
2024-06-03 01:52:00 [INFO]: Epoch 049 - training loss: 167239.0289, validation loss: 2.8116
2024-06-03 01:52:03 [INFO]: Epoch 050 - training loss: 167236.4468, validation loss: 2.7945
2024-06-03 01:52:07 [INFO]: Epoch 051 - training loss: 167234.4016, validation loss: 2.8040
2024-06-03 01:52:11 [INFO]: Epoch 052 - training loss: 167234.8837, validation loss: 2.7966
2024-06-03 01:52:15 [INFO]: Epoch 053 - training loss: 167237.4716, validation loss: 2.7832
2024-06-03 01:52:18 [INFO]: Epoch 054 - training loss: 167231.1291, validation loss: 2.7811
2024-06-03 01:52:22 [INFO]: Epoch 055 - training loss: 167229.0677, validation loss: 2.7738
2024-06-03 01:52:26 [INFO]: Epoch 056 - training loss: 167230.2089, validation loss: 2.7966
2024-06-03 01:52:29 [INFO]: Epoch 057 - training loss: 167232.7899, validation loss: 2.7948
2024-06-03 01:52:33 [INFO]: Epoch 058 - training loss: 167224.7598, validation loss: 2.7744
2024-06-03 01:52:37 [INFO]: Epoch 059 - training loss: 167222.8600, validation loss: 2.7936
2024-06-03 01:52:41 [INFO]: Epoch 060 - training loss: 167224.8924, validation loss: 2.7689
2024-06-03 01:52:44 [INFO]: Epoch 061 - training loss: 167222.4896, validation loss: 2.7842
2024-06-03 01:52:48 [INFO]: Epoch 062 - training loss: 167222.8293, validation loss: 2.7577
2024-06-03 01:52:52 [INFO]: Epoch 063 - training loss: 167221.0584, validation loss: 2.7861
2024-06-03 01:52:56 [INFO]: Epoch 064 - training loss: 167219.1644, validation loss: 2.7667
2024-06-03 01:52:59 [INFO]: Epoch 065 - training loss: 167214.0932, validation loss: 2.7583
2024-06-03 01:53:03 [INFO]: Epoch 066 - training loss: 167210.8142, validation loss: 2.7761
2024-06-03 01:53:07 [INFO]: Epoch 067 - training loss: 167210.5301, validation loss: 2.7698
2024-06-03 01:53:11 [INFO]: Epoch 068 - training loss: 167211.8264, validation loss: 2.7499
2024-06-03 01:53:14 [INFO]: Epoch 069 - training loss: 167212.5035, validation loss: 2.7692
2024-06-03 01:53:18 [INFO]: Epoch 070 - training loss: 167210.2911, validation loss: 2.7482
2024-06-03 01:53:22 [INFO]: Epoch 071 - training loss: 167206.8420, validation loss: 2.7570
2024-06-03 01:53:26 [INFO]: Epoch 072 - training loss: 167205.6823, validation loss: 2.7454
2024-06-03 01:53:29 [INFO]: Epoch 073 - training loss: 167211.6991, validation loss: 2.7470
2024-06-03 01:53:33 [INFO]: Epoch 074 - training loss: 167205.6464, validation loss: 2.7455
2024-06-03 01:53:37 [INFO]: Epoch 075 - training loss: 167202.2998, validation loss: 2.7375
2024-06-03 01:53:41 [INFO]: Epoch 076 - training loss: 167200.0868, validation loss: 2.7496
2024-06-03 01:53:44 [INFO]: Epoch 077 - training loss: 167197.9346, validation loss: 2.7348
2024-06-03 01:53:48 [INFO]: Epoch 078 - training loss: 167199.2292, validation loss: 2.7467
2024-06-03 01:53:52 [INFO]: Epoch 079 - training loss: 167202.0764, validation loss: 2.7493
2024-06-03 01:53:56 [INFO]: Epoch 080 - training loss: 167197.7541, validation loss: 2.7239
2024-06-03 01:53:59 [INFO]: Epoch 081 - training loss: 167196.2396, validation loss: 2.7372
2024-06-03 01:54:03 [INFO]: Epoch 082 - training loss: 167197.6279, validation loss: 2.7328
2024-06-03 01:54:07 [INFO]: Epoch 083 - training loss: 167194.3756, validation loss: 2.7437
2024-06-03 01:54:11 [INFO]: Epoch 084 - training loss: 167195.2459, validation loss: 2.7329
2024-06-03 01:54:14 [INFO]: Epoch 085 - training loss: 167194.1968, validation loss: 2.7483
2024-06-03 01:54:18 [INFO]: Epoch 086 - training loss: 167191.7222, validation loss: 2.7381
2024-06-03 01:54:22 [INFO]: Epoch 087 - training loss: 167192.6887, validation loss: 2.7470
2024-06-03 01:54:26 [INFO]: Epoch 088 - training loss: 167192.2454, validation loss: 2.7381
2024-06-03 01:54:29 [INFO]: Epoch 089 - training loss: 167191.2581, validation loss: 2.7543
2024-06-03 01:54:33 [INFO]: Epoch 090 - training loss: 167194.7471, validation loss: 2.7342
2024-06-03 01:54:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:54:33 [INFO]: Finished training. The best model is from epoch#80.
2024-06-03 01:54:33 [INFO]: Saved the model to results_point_rate09/Electricity/GPVAE_Electricity/round_3/20240603_T014856/GPVAE.pypots
2024-06-03 01:54:42 [INFO]: Successfully saved to results_point_rate09/Electricity/GPVAE_Electricity/round_3/imputation.pkl
2024-06-03 01:54:42 [INFO]: Round3 - GPVAE on Electricity: MAE=1.2202, MSE=3.3699, MRE=0.6532
2024-06-03 01:54:42 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:54:42 [INFO]: Using the given device: cuda:0
2024-06-03 01:54:42 [INFO]: Model files will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_4/20240603_T015442
2024-06-03 01:54:42 [INFO]: Tensorboard file will be saved to results_point_rate09/Electricity/GPVAE_Electricity/round_4/20240603_T015442/tensorboard
2024-06-03 01:54:42 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 01:54:46 [INFO]: Epoch 001 - training loss: 202597.0278, validation loss: 3.5787
2024-06-03 01:54:49 [INFO]: Epoch 002 - training loss: 169945.3900, validation loss: 3.8351
2024-06-03 01:54:53 [INFO]: Epoch 003 - training loss: 170023.9919, validation loss: 3.7345
2024-06-03 01:54:57 [INFO]: Epoch 004 - training loss: 168351.6348, validation loss: 3.3734
2024-06-03 01:55:01 [INFO]: Epoch 005 - training loss: 167822.9427, validation loss: 3.2932
2024-06-03 01:55:04 [INFO]: Epoch 006 - training loss: 167666.0446, validation loss: 3.2569
2024-06-03 01:55:08 [INFO]: Epoch 007 - training loss: 167673.3605, validation loss: 3.1872
2024-06-03 01:55:12 [INFO]: Epoch 008 - training loss: 167624.4022, validation loss: 3.1593
2024-06-03 01:55:16 [INFO]: Epoch 009 - training loss: 167581.9664, validation loss: 3.1508
2024-06-03 01:55:20 [INFO]: Epoch 010 - training loss: 167574.6389, validation loss: 3.1686
2024-06-03 01:55:23 [INFO]: Epoch 011 - training loss: 167559.8154, validation loss: 3.1831
2024-06-03 01:55:27 [INFO]: Epoch 012 - training loss: 167595.5231, validation loss: 3.1231
2024-06-03 01:55:31 [INFO]: Epoch 013 - training loss: 167565.7025, validation loss: 3.1180
2024-06-03 01:55:35 [INFO]: Epoch 014 - training loss: 167543.4878, validation loss: 3.0569
2024-06-03 01:55:38 [INFO]: Epoch 015 - training loss: 167458.1817, validation loss: 3.0538
2024-06-03 01:55:42 [INFO]: Epoch 016 - training loss: 167437.2488, validation loss: 3.0666
2024-06-03 01:55:46 [INFO]: Epoch 017 - training loss: 167400.6557, validation loss: 3.0677
2024-06-03 01:55:50 [INFO]: Epoch 018 - training loss: 167382.4392, validation loss: 3.0184
2024-06-03 01:55:53 [INFO]: Epoch 019 - training loss: 167379.2726, validation loss: 3.0048
2024-06-03 01:55:57 [INFO]: Epoch 020 - training loss: 167357.2564, validation loss: 2.9664
2024-06-03 01:56:01 [INFO]: Epoch 021 - training loss: 167343.3970, validation loss: 2.9766
2024-06-03 01:56:05 [INFO]: Epoch 022 - training loss: 167330.7905, validation loss: 2.9656
2024-06-03 01:56:08 [INFO]: Epoch 023 - training loss: 167326.9010, validation loss: 2.9722
2024-06-03 01:56:12 [INFO]: Epoch 024 - training loss: 167319.6140, validation loss: 2.9576
2024-06-03 01:56:16 [INFO]: Epoch 025 - training loss: 167307.8860, validation loss: 2.9436
2024-06-03 01:56:20 [INFO]: Epoch 026 - training loss: 167302.1748, validation loss: 2.9280
2024-06-03 01:56:23 [INFO]: Epoch 027 - training loss: 167300.7998, validation loss: 2.9206
2024-06-03 01:56:27 [INFO]: Epoch 028 - training loss: 167287.9618, validation loss: 2.9233
2024-06-03 01:56:31 [INFO]: Epoch 029 - training loss: 167287.7870, validation loss: 2.9593
2024-06-03 01:56:35 [INFO]: Epoch 030 - training loss: 167277.1360, validation loss: 2.9727
2024-06-03 01:56:39 [INFO]: Epoch 031 - training loss: 167269.6829, validation loss: 2.9274
2024-06-03 01:56:42 [INFO]: Epoch 032 - training loss: 167269.3061, validation loss: 2.9396
2024-06-03 01:56:46 [INFO]: Epoch 033 - training loss: 167268.2014, validation loss: 2.9093
2024-06-03 01:56:50 [INFO]: Epoch 034 - training loss: 167261.9971, validation loss: 2.9437
2024-06-03 01:56:54 [INFO]: Epoch 035 - training loss: 167256.8941, validation loss: 2.8956
2024-06-03 01:56:57 [INFO]: Epoch 036 - training loss: 167249.8154, validation loss: 2.8913
2024-06-03 01:57:01 [INFO]: Epoch 037 - training loss: 167255.9022, validation loss: 2.8767
2024-06-03 01:57:05 [INFO]: Epoch 038 - training loss: 167251.1273, validation loss: 2.9063
2024-06-03 01:57:09 [INFO]: Epoch 039 - training loss: 167245.0914, validation loss: 2.9124
2024-06-03 01:57:12 [INFO]: Epoch 040 - training loss: 167241.1516, validation loss: 2.8697
2024-06-03 01:57:16 [INFO]: Epoch 041 - training loss: 167244.0793, validation loss: 2.8390
2024-06-03 01:57:20 [INFO]: Epoch 042 - training loss: 167239.0156, validation loss: 2.8514
2024-06-03 01:57:24 [INFO]: Epoch 043 - training loss: 167230.2708, validation loss: 2.8250
2024-06-03 01:57:27 [INFO]: Epoch 044 - training loss: 167227.8032, validation loss: 2.8289
2024-06-03 01:57:31 [INFO]: Epoch 045 - training loss: 167225.2292, validation loss: 2.8076
2024-06-03 01:57:35 [INFO]: Epoch 046 - training loss: 167227.5411, validation loss: 2.8000
2024-06-03 01:57:39 [INFO]: Epoch 047 - training loss: 167222.3466, validation loss: 2.8077
2024-06-03 01:57:43 [INFO]: Epoch 048 - training loss: 167221.3634, validation loss: 2.7924
2024-06-03 01:57:46 [INFO]: Epoch 049 - training loss: 167216.3420, validation loss: 2.7788
2024-06-03 01:57:50 [INFO]: Epoch 050 - training loss: 167216.0041, validation loss: 2.7873
2024-06-03 01:57:54 [INFO]: Epoch 051 - training loss: 167211.0787, validation loss: 2.7830
2024-06-03 01:57:58 [INFO]: Epoch 052 - training loss: 167212.1846, validation loss: 2.7643
2024-06-03 01:58:01 [INFO]: Epoch 053 - training loss: 167210.2118, validation loss: 2.7777
2024-06-03 01:58:05 [INFO]: Epoch 054 - training loss: 167210.0689, validation loss: 2.7911
2024-06-03 01:58:09 [INFO]: Epoch 055 - training loss: 167208.0237, validation loss: 2.7859
2024-06-03 01:58:13 [INFO]: Epoch 056 - training loss: 167209.9444, validation loss: 2.7846
2024-06-03 01:58:16 [INFO]: Epoch 057 - training loss: 167207.7598, validation loss: 2.7800
2024-06-03 01:58:20 [INFO]: Epoch 058 - training loss: 167207.4288, validation loss: 2.7713
2024-06-03 01:58:24 [INFO]: Epoch 059 - training loss: 167207.9936, validation loss: 2.7948
2024-06-03 01:58:28 [INFO]: Epoch 060 - training loss: 167207.8119, validation loss: 2.7730
2024-06-03 01:58:32 [INFO]: Epoch 061 - training loss: 167204.3131, validation loss: 2.7620
2024-06-03 01:58:35 [INFO]: Epoch 062 - training loss: 167201.0625, validation loss: 2.7631
2024-06-03 01:58:39 [INFO]: Epoch 063 - training loss: 167198.4062, validation loss: 2.7610
2024-06-03 01:58:43 [INFO]: Epoch 064 - training loss: 167203.6713, validation loss: 2.7995
2024-06-03 01:58:47 [INFO]: Epoch 065 - training loss: 167204.0220, validation loss: 2.7685
2024-06-03 01:58:50 [INFO]: Epoch 066 - training loss: 167198.9959, validation loss: 2.7735
2024-06-03 01:58:54 [INFO]: Epoch 067 - training loss: 167197.9699, validation loss: 2.7680
2024-06-03 01:58:58 [INFO]: Epoch 068 - training loss: 167196.1464, validation loss: 2.7565
2024-06-03 01:59:02 [INFO]: Epoch 069 - training loss: 167193.6603, validation loss: 2.7646
2024-06-03 01:59:05 [INFO]: Epoch 070 - training loss: 167192.2593, validation loss: 2.7719
2024-06-03 01:59:09 [INFO]: Epoch 071 - training loss: 167191.7002, validation loss: 2.7676
2024-06-03 01:59:13 [INFO]: Epoch 072 - training loss: 167191.9612, validation loss: 2.7677
2024-06-03 01:59:17 [INFO]: Epoch 073 - training loss: 167189.0098, validation loss: 2.7781
2024-06-03 01:59:20 [INFO]: Epoch 074 - training loss: 167189.4618, validation loss: 2.7574
2024-06-03 01:59:24 [INFO]: Epoch 075 - training loss: 167189.8600, validation loss: 2.7477
2024-06-03 01:59:28 [INFO]: Epoch 076 - training loss: 167186.2685, validation loss: 2.7670
2024-06-03 01:59:32 [INFO]: Epoch 077 - training loss: 167189.0938, validation loss: 2.7584
2024-06-03 01:59:36 [INFO]: Epoch 078 - training loss: 167191.1603, validation loss: 2.7537
2024-06-03 01:59:39 [INFO]: Epoch 079 - training loss: 167191.0203, validation loss: 2.7635
2024-06-03 01:59:43 [INFO]: Epoch 080 - training loss: 167187.9659, validation loss: 2.7580
2024-06-03 01:59:47 [INFO]: Epoch 081 - training loss: 167189.8356, validation loss: 2.7521
2024-06-03 01:59:51 [INFO]: Epoch 082 - training loss: 167184.2743, validation loss: 2.7538
2024-06-03 01:59:54 [INFO]: Epoch 083 - training loss: 167183.3588, validation loss: 2.7508
2024-06-03 01:59:58 [INFO]: Epoch 084 - training loss: 167180.5457, validation loss: 2.7641
2024-06-03 02:00:02 [INFO]: Epoch 085 - training loss: 167181.2593, validation loss: 2.7522
2024-06-03 02:00:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:00:02 [INFO]: Finished training. The best model is from epoch#75.
2024-06-03 02:00:02 [INFO]: Saved the model to results_point_rate09/Electricity/GPVAE_Electricity/round_4/20240603_T015442/GPVAE.pypots
2024-06-03 02:00:11 [INFO]: Successfully saved to results_point_rate09/Electricity/GPVAE_Electricity/round_4/imputation.pkl
2024-06-03 02:00:11 [INFO]: Round4 - GPVAE on Electricity: MAE=1.2442, MSE=3.5569, MRE=0.6661
2024-06-03 02:00:11 [INFO]: Done! Final results:
Averaged GPVAE (1,825,022 params) on Electricity: MAE=1.2380 ± 0.02656238507420466, MSE=3.5275 ± 0.09596405738305405, MRE=0.6628 ± 0.014219602671294091, average inference time=12.46
