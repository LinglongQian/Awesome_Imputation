2024-06-03 00:18:18 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:18:18 [INFO]: Using the given device: cuda:0
2024-06-03 00:18:19 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T001819
2024-06-03 00:18:19 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T001819/tensorboard
2024-06-03 00:18:20 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 00:18:24 [INFO]: Epoch 001 - training loss: 1.2834, validation loss: 2.1427
2024-06-03 00:18:26 [INFO]: Epoch 002 - training loss: 1.1843, validation loss: 2.1201
2024-06-03 00:18:28 [INFO]: Epoch 003 - training loss: 1.1792, validation loss: 2.1505
2024-06-03 00:18:30 [INFO]: Epoch 004 - training loss: 1.1279, validation loss: 2.1710
2024-06-03 00:18:32 [INFO]: Epoch 005 - training loss: 1.1469, validation loss: 2.1192
2024-06-03 00:18:33 [INFO]: Epoch 006 - training loss: 1.0957, validation loss: 2.1041
2024-06-03 00:18:35 [INFO]: Epoch 007 - training loss: 1.0577, validation loss: 1.9968
2024-06-03 00:18:37 [INFO]: Epoch 008 - training loss: 0.9488, validation loss: 1.5537
2024-06-03 00:18:39 [INFO]: Epoch 009 - training loss: 0.8500, validation loss: 1.4090
2024-06-03 00:18:41 [INFO]: Epoch 010 - training loss: 0.7801, validation loss: 1.3637
2024-06-03 00:18:43 [INFO]: Epoch 011 - training loss: 0.7667, validation loss: 1.2560
2024-06-03 00:18:45 [INFO]: Epoch 012 - training loss: 0.7140, validation loss: 1.0992
2024-06-03 00:18:47 [INFO]: Epoch 013 - training loss: 0.7288, validation loss: 1.1549
2024-06-03 00:18:49 [INFO]: Epoch 014 - training loss: 0.6937, validation loss: 0.9795
2024-06-03 00:18:51 [INFO]: Epoch 015 - training loss: 0.6432, validation loss: 0.9056
2024-06-03 00:18:53 [INFO]: Epoch 016 - training loss: 0.6495, validation loss: 0.9976
2024-06-03 00:18:55 [INFO]: Epoch 017 - training loss: 0.6235, validation loss: 0.9431
2024-06-03 00:18:57 [INFO]: Epoch 018 - training loss: 0.6225, validation loss: 0.9004
2024-06-03 00:18:58 [INFO]: Epoch 019 - training loss: 0.5784, validation loss: 0.8855
2024-06-03 00:19:00 [INFO]: Epoch 020 - training loss: 0.5995, validation loss: 0.9198
2024-06-03 00:19:02 [INFO]: Epoch 021 - training loss: 0.6020, validation loss: 0.8542
2024-06-03 00:19:04 [INFO]: Epoch 022 - training loss: 0.6203, validation loss: 0.8445
2024-06-03 00:19:06 [INFO]: Epoch 023 - training loss: 0.6019, validation loss: 0.9434
2024-06-03 00:19:08 [INFO]: Epoch 024 - training loss: 0.5674, validation loss: 0.8969
2024-06-03 00:19:10 [INFO]: Epoch 025 - training loss: 0.5730, validation loss: 0.8740
2024-06-03 00:19:11 [INFO]: Epoch 026 - training loss: 0.5546, validation loss: 0.8626
2024-06-03 00:19:13 [INFO]: Epoch 027 - training loss: 0.5940, validation loss: 0.7972
2024-06-03 00:19:15 [INFO]: Epoch 028 - training loss: 0.5554, validation loss: 0.8908
2024-06-03 00:19:17 [INFO]: Epoch 029 - training loss: 0.5481, validation loss: 0.8962
2024-06-03 00:19:19 [INFO]: Epoch 030 - training loss: 0.5456, validation loss: 0.7993
2024-06-03 00:19:21 [INFO]: Epoch 031 - training loss: 0.5544, validation loss: 0.8355
2024-06-03 00:19:22 [INFO]: Epoch 032 - training loss: 0.5275, validation loss: 0.7825
2024-06-03 00:19:24 [INFO]: Epoch 033 - training loss: 0.5329, validation loss: 0.8304
2024-06-03 00:19:26 [INFO]: Epoch 034 - training loss: 0.5106, validation loss: 0.8640
2024-06-03 00:19:28 [INFO]: Epoch 035 - training loss: 0.5150, validation loss: 0.7513
2024-06-03 00:19:30 [INFO]: Epoch 036 - training loss: 0.5234, validation loss: 0.8444
2024-06-03 00:19:32 [INFO]: Epoch 037 - training loss: 0.5310, validation loss: 0.8091
2024-06-03 00:19:33 [INFO]: Epoch 038 - training loss: 0.5265, validation loss: 0.8060
2024-06-03 00:19:35 [INFO]: Epoch 039 - training loss: 0.5056, validation loss: 0.8390
2024-06-03 00:19:37 [INFO]: Epoch 040 - training loss: 0.4929, validation loss: 0.7510
2024-06-03 00:19:39 [INFO]: Epoch 041 - training loss: 0.5103, validation loss: 0.7500
2024-06-03 00:19:41 [INFO]: Epoch 042 - training loss: 0.4866, validation loss: 0.7419
2024-06-03 00:19:43 [INFO]: Epoch 043 - training loss: 0.5215, validation loss: 0.7657
2024-06-03 00:19:44 [INFO]: Epoch 044 - training loss: 0.5015, validation loss: 0.8389
2024-06-03 00:19:46 [INFO]: Epoch 045 - training loss: 0.5058, validation loss: 0.7292
2024-06-03 00:19:48 [INFO]: Epoch 046 - training loss: 0.4833, validation loss: 0.7583
2024-06-03 00:19:50 [INFO]: Epoch 047 - training loss: 0.4775, validation loss: 0.7346
2024-06-03 00:19:52 [INFO]: Epoch 048 - training loss: 0.4812, validation loss: 0.7467
2024-06-03 00:19:54 [INFO]: Epoch 049 - training loss: 0.4660, validation loss: 0.7459
2024-06-03 00:19:56 [INFO]: Epoch 050 - training loss: 0.4967, validation loss: 0.6813
2024-06-03 00:19:58 [INFO]: Epoch 051 - training loss: 0.4871, validation loss: 0.7198
2024-06-03 00:20:00 [INFO]: Epoch 052 - training loss: 0.4837, validation loss: 0.7270
2024-06-03 00:20:02 [INFO]: Epoch 053 - training loss: 0.4755, validation loss: 0.6877
2024-06-03 00:20:04 [INFO]: Epoch 054 - training loss: 0.4682, validation loss: 0.7536
2024-06-03 00:20:06 [INFO]: Epoch 055 - training loss: 0.4633, validation loss: 0.7381
2024-06-03 00:20:08 [INFO]: Epoch 056 - training loss: 0.4517, validation loss: 0.7319
2024-06-03 00:20:10 [INFO]: Epoch 057 - training loss: 0.4519, validation loss: 0.7439
2024-06-03 00:20:12 [INFO]: Epoch 058 - training loss: 0.4701, validation loss: 0.7072
2024-06-03 00:20:14 [INFO]: Epoch 059 - training loss: 0.4608, validation loss: 0.7503
2024-06-03 00:20:16 [INFO]: Epoch 060 - training loss: 0.4555, validation loss: 0.6879
2024-06-03 00:20:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:20:16 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 00:20:16 [INFO]: Saved the model to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T001819/Crossformer.pypots
2024-06-03 00:20:17 [INFO]: Successfully saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_0/imputation.pkl
2024-06-03 00:20:17 [INFO]: Round0 - Crossformer on ItalyAir: MAE=0.4580, MSE=0.5273, MRE=0.6019
2024-06-03 00:20:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:20:17 [INFO]: Using the given device: cuda:0
2024-06-03 00:20:17 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T002017
2024-06-03 00:20:17 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T002017/tensorboard
2024-06-03 00:20:17 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 00:20:19 [INFO]: Epoch 001 - training loss: 1.2773, validation loss: 2.1428
2024-06-03 00:20:21 [INFO]: Epoch 002 - training loss: 1.1727, validation loss: 2.1459
2024-06-03 00:20:23 [INFO]: Epoch 003 - training loss: 1.1090, validation loss: 2.1441
2024-06-03 00:20:25 [INFO]: Epoch 004 - training loss: 1.1435, validation loss: 2.1466
2024-06-03 00:20:27 [INFO]: Epoch 005 - training loss: 1.0966, validation loss: 2.1940
2024-06-03 00:20:29 [INFO]: Epoch 006 - training loss: 1.1168, validation loss: 2.2032
2024-06-03 00:20:30 [INFO]: Epoch 007 - training loss: 1.0781, validation loss: 2.1618
2024-06-03 00:20:32 [INFO]: Epoch 008 - training loss: 1.0730, validation loss: 2.1876
2024-06-03 00:20:34 [INFO]: Epoch 009 - training loss: 1.0675, validation loss: 2.1572
2024-06-03 00:20:36 [INFO]: Epoch 010 - training loss: 1.0612, validation loss: 2.1307
2024-06-03 00:20:37 [INFO]: Epoch 011 - training loss: 0.9860, validation loss: 1.6961
2024-06-03 00:20:39 [INFO]: Epoch 012 - training loss: 0.8629, validation loss: 1.5393
2024-06-03 00:20:41 [INFO]: Epoch 013 - training loss: 0.7967, validation loss: 1.2843
2024-06-03 00:20:43 [INFO]: Epoch 014 - training loss: 0.7287, validation loss: 1.1211
2024-06-03 00:20:44 [INFO]: Epoch 015 - training loss: 0.6871, validation loss: 1.1474
2024-06-03 00:20:46 [INFO]: Epoch 016 - training loss: 0.6646, validation loss: 0.9750
2024-06-03 00:20:48 [INFO]: Epoch 017 - training loss: 0.6402, validation loss: 1.0092
2024-06-03 00:20:49 [INFO]: Epoch 018 - training loss: 0.6121, validation loss: 1.0174
2024-06-03 00:20:51 [INFO]: Epoch 019 - training loss: 0.6002, validation loss: 0.9469
2024-06-03 00:20:52 [INFO]: Epoch 020 - training loss: 0.5850, validation loss: 0.9765
2024-06-03 00:20:54 [INFO]: Epoch 021 - training loss: 0.6043, validation loss: 1.0550
2024-06-03 00:20:55 [INFO]: Epoch 022 - training loss: 0.5837, validation loss: 0.9786
2024-06-03 00:20:57 [INFO]: Epoch 023 - training loss: 0.5939, validation loss: 0.8958
2024-06-03 00:20:58 [INFO]: Epoch 024 - training loss: 0.5870, validation loss: 0.9062
2024-06-03 00:21:00 [INFO]: Epoch 025 - training loss: 0.5867, validation loss: 0.9614
2024-06-03 00:21:01 [INFO]: Epoch 026 - training loss: 0.5371, validation loss: 0.9760
2024-06-03 00:21:03 [INFO]: Epoch 027 - training loss: 0.5718, validation loss: 0.8824
2024-06-03 00:21:04 [INFO]: Epoch 028 - training loss: 0.5805, validation loss: 0.9157
2024-06-03 00:21:05 [INFO]: Epoch 029 - training loss: 0.5497, validation loss: 0.9513
2024-06-03 00:21:07 [INFO]: Epoch 030 - training loss: 0.5484, validation loss: 0.9405
2024-06-03 00:21:08 [INFO]: Epoch 031 - training loss: 0.5323, validation loss: 0.8538
2024-06-03 00:21:10 [INFO]: Epoch 032 - training loss: 0.5419, validation loss: 0.8310
2024-06-03 00:21:12 [INFO]: Epoch 033 - training loss: 0.5587, validation loss: 0.8496
2024-06-03 00:21:13 [INFO]: Epoch 034 - training loss: 0.5338, validation loss: 0.8490
2024-06-03 00:21:15 [INFO]: Epoch 035 - training loss: 0.5484, validation loss: 0.8659
2024-06-03 00:21:17 [INFO]: Epoch 036 - training loss: 0.5257, validation loss: 0.8472
2024-06-03 00:21:18 [INFO]: Epoch 037 - training loss: 0.5342, validation loss: 0.8625
2024-06-03 00:21:20 [INFO]: Epoch 038 - training loss: 0.5413, validation loss: 1.0304
2024-06-03 00:21:21 [INFO]: Epoch 039 - training loss: 0.5507, validation loss: 0.9294
2024-06-03 00:21:22 [INFO]: Epoch 040 - training loss: 0.5289, validation loss: 0.8414
2024-06-03 00:21:24 [INFO]: Epoch 041 - training loss: 0.5179, validation loss: 0.8546
2024-06-03 00:21:25 [INFO]: Epoch 042 - training loss: 0.4981, validation loss: 0.8005
2024-06-03 00:21:27 [INFO]: Epoch 043 - training loss: 0.5166, validation loss: 0.8410
2024-06-03 00:21:28 [INFO]: Epoch 044 - training loss: 0.5296, validation loss: 0.8381
2024-06-03 00:21:30 [INFO]: Epoch 045 - training loss: 0.5173, validation loss: 0.8128
2024-06-03 00:21:31 [INFO]: Epoch 046 - training loss: 0.5008, validation loss: 0.8631
2024-06-03 00:21:32 [INFO]: Epoch 047 - training loss: 0.5185, validation loss: 0.8235
2024-06-03 00:21:34 [INFO]: Epoch 048 - training loss: 0.4829, validation loss: 0.7792
2024-06-03 00:21:35 [INFO]: Epoch 049 - training loss: 0.4792, validation loss: 0.8333
2024-06-03 00:21:36 [INFO]: Epoch 050 - training loss: 0.4994, validation loss: 0.8088
2024-06-03 00:21:38 [INFO]: Epoch 051 - training loss: 0.5025, validation loss: 0.7864
2024-06-03 00:21:39 [INFO]: Epoch 052 - training loss: 0.4826, validation loss: 0.7646
2024-06-03 00:21:40 [INFO]: Epoch 053 - training loss: 0.4969, validation loss: 0.7834
2024-06-03 00:21:41 [INFO]: Epoch 054 - training loss: 0.4893, validation loss: 0.8231
2024-06-03 00:21:43 [INFO]: Epoch 055 - training loss: 0.4617, validation loss: 0.8032
2024-06-03 00:21:44 [INFO]: Epoch 056 - training loss: 0.4983, validation loss: 0.7907
2024-06-03 00:21:45 [INFO]: Epoch 057 - training loss: 0.4711, validation loss: 0.8283
2024-06-03 00:21:46 [INFO]: Epoch 058 - training loss: 0.4878, validation loss: 0.8036
2024-06-03 00:21:47 [INFO]: Epoch 059 - training loss: 0.4632, validation loss: 0.8330
2024-06-03 00:21:48 [INFO]: Epoch 060 - training loss: 0.4853, validation loss: 0.7514
2024-06-03 00:21:50 [INFO]: Epoch 061 - training loss: 0.4562, validation loss: 0.7917
2024-06-03 00:21:51 [INFO]: Epoch 062 - training loss: 0.4628, validation loss: 0.7648
2024-06-03 00:21:52 [INFO]: Epoch 063 - training loss: 0.4553, validation loss: 0.7655
2024-06-03 00:21:53 [INFO]: Epoch 064 - training loss: 0.4622, validation loss: 0.7812
2024-06-03 00:21:55 [INFO]: Epoch 065 - training loss: 0.4487, validation loss: 0.7752
2024-06-03 00:21:56 [INFO]: Epoch 066 - training loss: 0.4769, validation loss: 0.7445
2024-06-03 00:21:57 [INFO]: Epoch 067 - training loss: 0.5145, validation loss: 0.7618
2024-06-03 00:21:58 [INFO]: Epoch 068 - training loss: 0.4593, validation loss: 0.7725
2024-06-03 00:22:00 [INFO]: Epoch 069 - training loss: 0.4534, validation loss: 0.7897
2024-06-03 00:22:01 [INFO]: Epoch 070 - training loss: 0.4661, validation loss: 0.7269
2024-06-03 00:22:02 [INFO]: Epoch 071 - training loss: 0.4523, validation loss: 0.7591
2024-06-03 00:22:03 [INFO]: Epoch 072 - training loss: 0.4811, validation loss: 0.7335
2024-06-03 00:22:05 [INFO]: Epoch 073 - training loss: 0.4621, validation loss: 0.7823
2024-06-03 00:22:06 [INFO]: Epoch 074 - training loss: 0.4821, validation loss: 0.7353
2024-06-03 00:22:07 [INFO]: Epoch 075 - training loss: 0.4535, validation loss: 0.7716
2024-06-03 00:22:08 [INFO]: Epoch 076 - training loss: 0.4344, validation loss: 0.8434
2024-06-03 00:22:09 [INFO]: Epoch 077 - training loss: 0.4377, validation loss: 0.7397
2024-06-03 00:22:11 [INFO]: Epoch 078 - training loss: 0.4317, validation loss: 0.7266
2024-06-03 00:22:12 [INFO]: Epoch 079 - training loss: 0.4446, validation loss: 0.7028
2024-06-03 00:22:13 [INFO]: Epoch 080 - training loss: 0.4335, validation loss: 0.7654
2024-06-03 00:22:14 [INFO]: Epoch 081 - training loss: 0.4423, validation loss: 0.7308
2024-06-03 00:22:16 [INFO]: Epoch 082 - training loss: 0.4602, validation loss: 0.7137
2024-06-03 00:22:17 [INFO]: Epoch 083 - training loss: 0.4460, validation loss: 0.7716
2024-06-03 00:22:18 [INFO]: Epoch 084 - training loss: 0.4462, validation loss: 0.6985
2024-06-03 00:22:19 [INFO]: Epoch 085 - training loss: 0.4353, validation loss: 0.6947
2024-06-03 00:22:20 [INFO]: Epoch 086 - training loss: 0.4253, validation loss: 0.6743
2024-06-03 00:22:22 [INFO]: Epoch 087 - training loss: 0.4302, validation loss: 0.7354
2024-06-03 00:22:23 [INFO]: Epoch 088 - training loss: 0.4356, validation loss: 0.7318
2024-06-03 00:22:24 [INFO]: Epoch 089 - training loss: 0.4144, validation loss: 0.7126
2024-06-03 00:22:25 [INFO]: Epoch 090 - training loss: 0.4233, validation loss: 0.7261
2024-06-03 00:22:26 [INFO]: Epoch 091 - training loss: 0.4049, validation loss: 0.7199
2024-06-03 00:22:27 [INFO]: Epoch 092 - training loss: 0.4237, validation loss: 0.7023
2024-06-03 00:22:28 [INFO]: Epoch 093 - training loss: 0.4320, validation loss: 0.7206
2024-06-03 00:22:30 [INFO]: Epoch 094 - training loss: 0.4196, validation loss: 0.6838
2024-06-03 00:22:31 [INFO]: Epoch 095 - training loss: 0.4319, validation loss: 0.6938
2024-06-03 00:22:32 [INFO]: Epoch 096 - training loss: 0.4301, validation loss: 0.6941
2024-06-03 00:22:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:22:32 [INFO]: Finished training. The best model is from epoch#86.
2024-06-03 00:22:32 [INFO]: Saved the model to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T002017/Crossformer.pypots
2024-06-03 00:22:33 [INFO]: Successfully saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_1/imputation.pkl
2024-06-03 00:22:33 [INFO]: Round1 - Crossformer on ItalyAir: MAE=0.4572, MSE=0.5258, MRE=0.6008
2024-06-03 00:22:33 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:22:33 [INFO]: Using the given device: cuda:0
2024-06-03 00:22:33 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T002233
2024-06-03 00:22:33 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T002233/tensorboard
2024-06-03 00:22:33 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 00:22:34 [INFO]: Epoch 001 - training loss: 1.2799, validation loss: 2.1923
2024-06-03 00:22:35 [INFO]: Epoch 002 - training loss: 1.1595, validation loss: 2.1518
2024-06-03 00:22:36 [INFO]: Epoch 003 - training loss: 1.1376, validation loss: 2.1312
2024-06-03 00:22:38 [INFO]: Epoch 004 - training loss: 1.1405, validation loss: 2.1360
2024-06-03 00:22:39 [INFO]: Epoch 005 - training loss: 1.1108, validation loss: 2.1287
2024-06-03 00:22:40 [INFO]: Epoch 006 - training loss: 1.0753, validation loss: 2.0547
2024-06-03 00:22:42 [INFO]: Epoch 007 - training loss: 1.0138, validation loss: 1.6463
2024-06-03 00:22:43 [INFO]: Epoch 008 - training loss: 0.9156, validation loss: 1.4416
2024-06-03 00:22:44 [INFO]: Epoch 009 - training loss: 0.8238, validation loss: 1.2352
2024-06-03 00:22:45 [INFO]: Epoch 010 - training loss: 0.7731, validation loss: 1.1095
2024-06-03 00:22:47 [INFO]: Epoch 011 - training loss: 0.7198, validation loss: 1.1014
2024-06-03 00:22:48 [INFO]: Epoch 012 - training loss: 0.7174, validation loss: 1.0274
2024-06-03 00:22:49 [INFO]: Epoch 013 - training loss: 0.6576, validation loss: 0.9147
2024-06-03 00:22:50 [INFO]: Epoch 014 - training loss: 0.6732, validation loss: 0.9920
2024-06-03 00:22:51 [INFO]: Epoch 015 - training loss: 0.6452, validation loss: 0.8436
2024-06-03 00:22:52 [INFO]: Epoch 016 - training loss: 0.6355, validation loss: 0.8670
2024-06-03 00:22:54 [INFO]: Epoch 017 - training loss: 0.6230, validation loss: 0.8411
2024-06-03 00:22:55 [INFO]: Epoch 018 - training loss: 0.5941, validation loss: 0.9041
2024-06-03 00:22:56 [INFO]: Epoch 019 - training loss: 0.6224, validation loss: 0.8308
2024-06-03 00:22:57 [INFO]: Epoch 020 - training loss: 0.6119, validation loss: 0.8453
2024-06-03 00:22:58 [INFO]: Epoch 021 - training loss: 0.6508, validation loss: 0.8271
2024-06-03 00:22:59 [INFO]: Epoch 022 - training loss: 0.5867, validation loss: 0.8174
2024-06-03 00:23:00 [INFO]: Epoch 023 - training loss: 0.5863, validation loss: 0.9349
2024-06-03 00:23:01 [INFO]: Epoch 024 - training loss: 0.5556, validation loss: 0.8609
2024-06-03 00:23:02 [INFO]: Epoch 025 - training loss: 0.5605, validation loss: 0.8267
2024-06-03 00:23:03 [INFO]: Epoch 026 - training loss: 0.5512, validation loss: 0.7739
2024-06-03 00:23:04 [INFO]: Epoch 027 - training loss: 0.5536, validation loss: 0.7814
2024-06-03 00:23:05 [INFO]: Epoch 028 - training loss: 0.5608, validation loss: 0.7823
2024-06-03 00:23:06 [INFO]: Epoch 029 - training loss: 0.5409, validation loss: 0.7659
2024-06-03 00:23:07 [INFO]: Epoch 030 - training loss: 0.5490, validation loss: 0.7757
2024-06-03 00:23:08 [INFO]: Epoch 031 - training loss: 0.5348, validation loss: 0.7320
2024-06-03 00:23:09 [INFO]: Epoch 032 - training loss: 0.5499, validation loss: 0.7213
2024-06-03 00:23:10 [INFO]: Epoch 033 - training loss: 0.5393, validation loss: 0.7968
2024-06-03 00:23:11 [INFO]: Epoch 034 - training loss: 0.5443, validation loss: 0.7537
2024-06-03 00:23:12 [INFO]: Epoch 035 - training loss: 0.5206, validation loss: 0.7526
2024-06-03 00:23:13 [INFO]: Epoch 036 - training loss: 0.5186, validation loss: 0.7130
2024-06-03 00:23:14 [INFO]: Epoch 037 - training loss: 0.5241, validation loss: 0.7436
2024-06-03 00:23:15 [INFO]: Epoch 038 - training loss: 0.5238, validation loss: 0.7224
2024-06-03 00:23:16 [INFO]: Epoch 039 - training loss: 0.5090, validation loss: 0.7026
2024-06-03 00:23:17 [INFO]: Epoch 040 - training loss: 0.5137, validation loss: 0.7924
2024-06-03 00:23:18 [INFO]: Epoch 041 - training loss: 0.5290, validation loss: 0.7118
2024-06-03 00:23:19 [INFO]: Epoch 042 - training loss: 0.5236, validation loss: 0.7382
2024-06-03 00:23:20 [INFO]: Epoch 043 - training loss: 0.5291, validation loss: 0.7108
2024-06-03 00:23:21 [INFO]: Epoch 044 - training loss: 0.5026, validation loss: 0.7987
2024-06-03 00:23:22 [INFO]: Epoch 045 - training loss: 0.5240, validation loss: 0.7126
2024-06-03 00:23:23 [INFO]: Epoch 046 - training loss: 0.5080, validation loss: 0.8069
2024-06-03 00:23:25 [INFO]: Epoch 047 - training loss: 0.5152, validation loss: 0.7502
2024-06-03 00:23:26 [INFO]: Epoch 048 - training loss: 0.4973, validation loss: 0.7361
2024-06-03 00:23:27 [INFO]: Epoch 049 - training loss: 0.4851, validation loss: 0.6738
2024-06-03 00:23:28 [INFO]: Epoch 050 - training loss: 0.4817, validation loss: 0.7137
2024-06-03 00:23:29 [INFO]: Epoch 051 - training loss: 0.4899, validation loss: 0.6804
2024-06-03 00:23:30 [INFO]: Epoch 052 - training loss: 0.4916, validation loss: 0.6571
2024-06-03 00:23:32 [INFO]: Epoch 053 - training loss: 0.4681, validation loss: 0.6431
2024-06-03 00:23:33 [INFO]: Epoch 054 - training loss: 0.4616, validation loss: 0.7042
2024-06-03 00:23:34 [INFO]: Epoch 055 - training loss: 0.4813, validation loss: 0.7446
2024-06-03 00:23:35 [INFO]: Epoch 056 - training loss: 0.4916, validation loss: 0.7098
2024-06-03 00:23:36 [INFO]: Epoch 057 - training loss: 0.4654, validation loss: 0.6754
2024-06-03 00:23:37 [INFO]: Epoch 058 - training loss: 0.4720, validation loss: 0.7229
2024-06-03 00:23:38 [INFO]: Epoch 059 - training loss: 0.4705, validation loss: 0.6745
2024-06-03 00:23:40 [INFO]: Epoch 060 - training loss: 0.4425, validation loss: 0.6893
2024-06-03 00:23:41 [INFO]: Epoch 061 - training loss: 0.4708, validation loss: 0.6662
2024-06-03 00:23:42 [INFO]: Epoch 062 - training loss: 0.4537, validation loss: 0.7199
2024-06-03 00:23:43 [INFO]: Epoch 063 - training loss: 0.4718, validation loss: 0.6508
2024-06-03 00:23:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:23:43 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 00:23:43 [INFO]: Saved the model to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T002233/Crossformer.pypots
2024-06-03 00:23:43 [INFO]: Successfully saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_2/imputation.pkl
2024-06-03 00:23:43 [INFO]: Round2 - Crossformer on ItalyAir: MAE=0.4526, MSE=0.5122, MRE=0.5947
2024-06-03 00:23:43 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:23:43 [INFO]: Using the given device: cuda:0
2024-06-03 00:23:43 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T002343
2024-06-03 00:23:43 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T002343/tensorboard
2024-06-03 00:23:43 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 00:23:45 [INFO]: Epoch 001 - training loss: 1.2262, validation loss: 2.1097
2024-06-03 00:23:46 [INFO]: Epoch 002 - training loss: 1.1138, validation loss: 2.1455
2024-06-03 00:23:47 [INFO]: Epoch 003 - training loss: 1.1122, validation loss: 2.1544
2024-06-03 00:23:48 [INFO]: Epoch 004 - training loss: 1.1365, validation loss: 2.1739
2024-06-03 00:23:49 [INFO]: Epoch 005 - training loss: 1.0943, validation loss: 2.1585
2024-06-03 00:23:50 [INFO]: Epoch 006 - training loss: 1.0905, validation loss: 2.1152
2024-06-03 00:23:51 [INFO]: Epoch 007 - training loss: 1.0839, validation loss: 2.1255
2024-06-03 00:23:52 [INFO]: Epoch 008 - training loss: 1.0676, validation loss: 2.0813
2024-06-03 00:23:54 [INFO]: Epoch 009 - training loss: 1.0182, validation loss: 1.8441
2024-06-03 00:23:55 [INFO]: Epoch 010 - training loss: 0.9258, validation loss: 1.4282
2024-06-03 00:23:56 [INFO]: Epoch 011 - training loss: 0.8475, validation loss: 1.3010
2024-06-03 00:23:57 [INFO]: Epoch 012 - training loss: 0.7859, validation loss: 1.1695
2024-06-03 00:23:58 [INFO]: Epoch 013 - training loss: 0.7449, validation loss: 1.1848
2024-06-03 00:23:59 [INFO]: Epoch 014 - training loss: 0.7004, validation loss: 1.1156
2024-06-03 00:24:00 [INFO]: Epoch 015 - training loss: 0.6752, validation loss: 1.0238
2024-06-03 00:24:01 [INFO]: Epoch 016 - training loss: 0.6455, validation loss: 1.0521
2024-06-03 00:24:02 [INFO]: Epoch 017 - training loss: 0.6453, validation loss: 1.0210
2024-06-03 00:24:04 [INFO]: Epoch 018 - training loss: 0.6029, validation loss: 1.0909
2024-06-03 00:24:05 [INFO]: Epoch 019 - training loss: 0.6045, validation loss: 0.9919
2024-06-03 00:24:06 [INFO]: Epoch 020 - training loss: 0.5953, validation loss: 0.8974
2024-06-03 00:24:07 [INFO]: Epoch 021 - training loss: 0.6386, validation loss: 1.0380
2024-06-03 00:24:08 [INFO]: Epoch 022 - training loss: 0.6185, validation loss: 0.8304
2024-06-03 00:24:09 [INFO]: Epoch 023 - training loss: 0.5895, validation loss: 0.8954
2024-06-03 00:24:11 [INFO]: Epoch 024 - training loss: 0.5679, validation loss: 0.8738
2024-06-03 00:24:12 [INFO]: Epoch 025 - training loss: 0.5514, validation loss: 0.9064
2024-06-03 00:24:13 [INFO]: Epoch 026 - training loss: 0.5596, validation loss: 0.8348
2024-06-03 00:24:14 [INFO]: Epoch 027 - training loss: 0.5701, validation loss: 0.9230
2024-06-03 00:24:15 [INFO]: Epoch 028 - training loss: 0.5394, validation loss: 0.8240
2024-06-03 00:24:17 [INFO]: Epoch 029 - training loss: 0.5426, validation loss: 0.8990
2024-06-03 00:24:18 [INFO]: Epoch 030 - training loss: 0.5630, validation loss: 0.8650
2024-06-03 00:24:19 [INFO]: Epoch 031 - training loss: 0.5269, validation loss: 0.8971
2024-06-03 00:24:20 [INFO]: Epoch 032 - training loss: 0.5272, validation loss: 0.8466
2024-06-03 00:24:21 [INFO]: Epoch 033 - training loss: 0.5473, validation loss: 0.7907
2024-06-03 00:24:22 [INFO]: Epoch 034 - training loss: 0.5240, validation loss: 0.9016
2024-06-03 00:24:23 [INFO]: Epoch 035 - training loss: 0.5274, validation loss: 0.8404
2024-06-03 00:24:24 [INFO]: Epoch 036 - training loss: 0.5307, validation loss: 0.7780
2024-06-03 00:24:26 [INFO]: Epoch 037 - training loss: 0.5407, validation loss: 0.8020
2024-06-03 00:24:27 [INFO]: Epoch 038 - training loss: 0.5098, validation loss: 0.7969
2024-06-03 00:24:28 [INFO]: Epoch 039 - training loss: 0.5242, validation loss: 0.8114
2024-06-03 00:24:29 [INFO]: Epoch 040 - training loss: 0.5160, validation loss: 0.8691
2024-06-03 00:24:30 [INFO]: Epoch 041 - training loss: 0.5029, validation loss: 0.8195
2024-06-03 00:24:31 [INFO]: Epoch 042 - training loss: 0.5101, validation loss: 0.6997
2024-06-03 00:24:32 [INFO]: Epoch 043 - training loss: 0.5236, validation loss: 0.8316
2024-06-03 00:24:34 [INFO]: Epoch 044 - training loss: 0.5190, validation loss: 0.8280
2024-06-03 00:24:35 [INFO]: Epoch 045 - training loss: 0.4862, validation loss: 0.7690
2024-06-03 00:24:36 [INFO]: Epoch 046 - training loss: 0.5238, validation loss: 0.7616
2024-06-03 00:24:37 [INFO]: Epoch 047 - training loss: 0.5041, validation loss: 0.7295
2024-06-03 00:24:38 [INFO]: Epoch 048 - training loss: 0.4767, validation loss: 0.6917
2024-06-03 00:24:39 [INFO]: Epoch 049 - training loss: 0.4993, validation loss: 0.6736
2024-06-03 00:24:40 [INFO]: Epoch 050 - training loss: 0.4801, validation loss: 0.7306
2024-06-03 00:24:42 [INFO]: Epoch 051 - training loss: 0.4862, validation loss: 0.7402
2024-06-03 00:24:43 [INFO]: Epoch 052 - training loss: 0.4562, validation loss: 0.7795
2024-06-03 00:24:44 [INFO]: Epoch 053 - training loss: 0.4679, validation loss: 0.7080
2024-06-03 00:24:45 [INFO]: Epoch 054 - training loss: 0.4622, validation loss: 0.7637
2024-06-03 00:24:46 [INFO]: Epoch 055 - training loss: 0.4643, validation loss: 0.6977
2024-06-03 00:24:47 [INFO]: Epoch 056 - training loss: 0.4816, validation loss: 0.6740
2024-06-03 00:24:48 [INFO]: Epoch 057 - training loss: 0.4612, validation loss: 0.7003
2024-06-03 00:24:49 [INFO]: Epoch 058 - training loss: 0.4445, validation loss: 0.6715
2024-06-03 00:24:50 [INFO]: Epoch 059 - training loss: 0.4522, validation loss: 0.7261
2024-06-03 00:24:51 [INFO]: Epoch 060 - training loss: 0.4737, validation loss: 0.6911
2024-06-03 00:24:52 [INFO]: Epoch 061 - training loss: 0.4555, validation loss: 0.6689
2024-06-03 00:24:53 [INFO]: Epoch 062 - training loss: 0.4646, validation loss: 0.6716
2024-06-03 00:24:54 [INFO]: Epoch 063 - training loss: 0.4487, validation loss: 0.6697
2024-06-03 00:24:56 [INFO]: Epoch 064 - training loss: 0.4681, validation loss: 0.6731
2024-06-03 00:24:57 [INFO]: Epoch 065 - training loss: 0.4578, validation loss: 0.6787
2024-06-03 00:24:58 [INFO]: Epoch 066 - training loss: 0.4441, validation loss: 0.6566
2024-06-03 00:24:59 [INFO]: Epoch 067 - training loss: 0.4428, validation loss: 0.6629
2024-06-03 00:25:00 [INFO]: Epoch 068 - training loss: 0.4217, validation loss: 0.6877
2024-06-03 00:25:02 [INFO]: Epoch 069 - training loss: 0.4565, validation loss: 0.6766
2024-06-03 00:25:03 [INFO]: Epoch 070 - training loss: 0.4473, validation loss: 0.6626
2024-06-03 00:25:04 [INFO]: Epoch 071 - training loss: 0.4153, validation loss: 0.6369
2024-06-03 00:25:05 [INFO]: Epoch 072 - training loss: 0.4219, validation loss: 0.6873
2024-06-03 00:25:06 [INFO]: Epoch 073 - training loss: 0.4193, validation loss: 0.7000
2024-06-03 00:25:07 [INFO]: Epoch 074 - training loss: 0.4051, validation loss: 0.6710
2024-06-03 00:25:08 [INFO]: Epoch 075 - training loss: 0.4109, validation loss: 0.6627
2024-06-03 00:25:09 [INFO]: Epoch 076 - training loss: 0.4040, validation loss: 0.6782
2024-06-03 00:25:10 [INFO]: Epoch 077 - training loss: 0.4271, validation loss: 0.6559
2024-06-03 00:25:11 [INFO]: Epoch 078 - training loss: 0.4185, validation loss: 0.6238
2024-06-03 00:25:13 [INFO]: Epoch 079 - training loss: 0.4043, validation loss: 0.6284
2024-06-03 00:25:14 [INFO]: Epoch 080 - training loss: 0.4142, validation loss: 0.7054
2024-06-03 00:25:15 [INFO]: Epoch 081 - training loss: 0.3978, validation loss: 0.6295
2024-06-03 00:25:16 [INFO]: Epoch 082 - training loss: 0.3977, validation loss: 0.6658
2024-06-03 00:25:17 [INFO]: Epoch 083 - training loss: 0.4052, validation loss: 0.6711
2024-06-03 00:25:18 [INFO]: Epoch 084 - training loss: 0.3951, validation loss: 0.6479
2024-06-03 00:25:19 [INFO]: Epoch 085 - training loss: 0.4041, validation loss: 0.6135
2024-06-03 00:25:20 [INFO]: Epoch 086 - training loss: 0.3930, validation loss: 0.6517
2024-06-03 00:25:21 [INFO]: Epoch 087 - training loss: 0.4203, validation loss: 0.6535
2024-06-03 00:25:22 [INFO]: Epoch 088 - training loss: 0.4030, validation loss: 0.6660
2024-06-03 00:25:23 [INFO]: Epoch 089 - training loss: 0.4017, validation loss: 0.6411
2024-06-03 00:25:24 [INFO]: Epoch 090 - training loss: 0.3929, validation loss: 0.6261
2024-06-03 00:25:25 [INFO]: Epoch 091 - training loss: 0.3920, validation loss: 0.6941
2024-06-03 00:25:26 [INFO]: Epoch 092 - training loss: 0.4175, validation loss: 0.6381
2024-06-03 00:25:27 [INFO]: Epoch 093 - training loss: 0.3806, validation loss: 0.6569
2024-06-03 00:25:28 [INFO]: Epoch 094 - training loss: 0.4027, validation loss: 0.6102
2024-06-03 00:25:29 [INFO]: Epoch 095 - training loss: 0.3914, validation loss: 0.6037
2024-06-03 00:25:30 [INFO]: Epoch 096 - training loss: 0.4091, validation loss: 0.6395
2024-06-03 00:25:31 [INFO]: Epoch 097 - training loss: 0.4041, validation loss: 0.6235
2024-06-03 00:25:32 [INFO]: Epoch 098 - training loss: 0.4035, validation loss: 0.6474
2024-06-03 00:25:33 [INFO]: Epoch 099 - training loss: 0.3891, validation loss: 0.6156
2024-06-03 00:25:34 [INFO]: Epoch 100 - training loss: 0.3981, validation loss: 0.6325
2024-06-03 00:25:34 [INFO]: Finished training. The best model is from epoch#95.
2024-06-03 00:25:35 [INFO]: Saved the model to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T002343/Crossformer.pypots
2024-06-03 00:25:35 [INFO]: Successfully saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_3/imputation.pkl
2024-06-03 00:25:35 [INFO]: Round3 - Crossformer on ItalyAir: MAE=0.4678, MSE=0.5396, MRE=0.6147
2024-06-03 00:25:35 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:25:35 [INFO]: Using the given device: cuda:0
2024-06-03 00:25:35 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T002535
2024-06-03 00:25:35 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T002535/tensorboard
2024-06-03 00:25:35 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 00:25:36 [INFO]: Epoch 001 - training loss: 1.2469, validation loss: 2.1663
2024-06-03 00:25:37 [INFO]: Epoch 002 - training loss: 1.1694, validation loss: 2.1427
2024-06-03 00:25:38 [INFO]: Epoch 003 - training loss: 1.1227, validation loss: 2.1825
2024-06-03 00:25:39 [INFO]: Epoch 004 - training loss: 1.1164, validation loss: 2.1700
2024-06-03 00:25:40 [INFO]: Epoch 005 - training loss: 1.0661, validation loss: 2.1282
2024-06-03 00:25:41 [INFO]: Epoch 006 - training loss: 1.0395, validation loss: 2.0451
2024-06-03 00:25:42 [INFO]: Epoch 007 - training loss: 0.9922, validation loss: 1.6073
2024-06-03 00:25:43 [INFO]: Epoch 008 - training loss: 0.8874, validation loss: 1.2561
2024-06-03 00:25:44 [INFO]: Epoch 009 - training loss: 0.8259, validation loss: 1.1620
2024-06-03 00:25:45 [INFO]: Epoch 010 - training loss: 0.8012, validation loss: 1.0760
2024-06-03 00:25:46 [INFO]: Epoch 011 - training loss: 0.7562, validation loss: 1.0413
2024-06-03 00:25:47 [INFO]: Epoch 012 - training loss: 0.6983, validation loss: 1.0512
2024-06-03 00:25:48 [INFO]: Epoch 013 - training loss: 0.6863, validation loss: 1.0088
2024-06-03 00:25:49 [INFO]: Epoch 014 - training loss: 0.6703, validation loss: 0.9439
2024-06-03 00:25:50 [INFO]: Epoch 015 - training loss: 0.6669, validation loss: 0.9380
2024-06-03 00:25:51 [INFO]: Epoch 016 - training loss: 0.6700, validation loss: 0.8524
2024-06-03 00:25:52 [INFO]: Epoch 017 - training loss: 0.6643, validation loss: 0.8909
2024-06-03 00:25:53 [INFO]: Epoch 018 - training loss: 0.6050, validation loss: 0.8559
2024-06-03 00:25:54 [INFO]: Epoch 019 - training loss: 0.6131, validation loss: 0.9081
2024-06-03 00:25:55 [INFO]: Epoch 020 - training loss: 0.5801, validation loss: 0.9117
2024-06-03 00:25:56 [INFO]: Epoch 021 - training loss: 0.5882, validation loss: 0.8244
2024-06-03 00:25:58 [INFO]: Epoch 022 - training loss: 0.5736, validation loss: 0.8282
2024-06-03 00:25:59 [INFO]: Epoch 023 - training loss: 0.5512, validation loss: 0.8382
2024-06-03 00:26:00 [INFO]: Epoch 024 - training loss: 0.5285, validation loss: 0.7878
2024-06-03 00:26:01 [INFO]: Epoch 025 - training loss: 0.5384, validation loss: 0.8047
2024-06-03 00:26:02 [INFO]: Epoch 026 - training loss: 0.5470, validation loss: 0.8245
2024-06-03 00:26:03 [INFO]: Epoch 027 - training loss: 0.5532, validation loss: 0.8255
2024-06-03 00:26:04 [INFO]: Epoch 028 - training loss: 0.5445, validation loss: 0.7739
2024-06-03 00:26:05 [INFO]: Epoch 029 - training loss: 0.5182, validation loss: 0.7697
2024-06-03 00:26:06 [INFO]: Epoch 030 - training loss: 0.5186, validation loss: 0.7873
2024-06-03 00:26:07 [INFO]: Epoch 031 - training loss: 0.5410, validation loss: 0.8022
2024-06-03 00:26:08 [INFO]: Epoch 032 - training loss: 0.5077, validation loss: 0.7610
2024-06-03 00:26:09 [INFO]: Epoch 033 - training loss: 0.5198, validation loss: 0.7790
2024-06-03 00:26:10 [INFO]: Epoch 034 - training loss: 0.5179, validation loss: 0.7333
2024-06-03 00:26:11 [INFO]: Epoch 035 - training loss: 0.5061, validation loss: 0.7856
2024-06-03 00:26:12 [INFO]: Epoch 036 - training loss: 0.5118, validation loss: 0.7180
2024-06-03 00:26:13 [INFO]: Epoch 037 - training loss: 0.5143, validation loss: 0.8151
2024-06-03 00:26:14 [INFO]: Epoch 038 - training loss: 0.5260, validation loss: 0.7409
2024-06-03 00:26:15 [INFO]: Epoch 039 - training loss: 0.4949, validation loss: 0.7333
2024-06-03 00:26:16 [INFO]: Epoch 040 - training loss: 0.4868, validation loss: 0.7833
2024-06-03 00:26:17 [INFO]: Epoch 041 - training loss: 0.5320, validation loss: 0.7265
2024-06-03 00:26:18 [INFO]: Epoch 042 - training loss: 0.5091, validation loss: 0.7294
2024-06-03 00:26:19 [INFO]: Epoch 043 - training loss: 0.4812, validation loss: 0.6929
2024-06-03 00:26:20 [INFO]: Epoch 044 - training loss: 0.4881, validation loss: 0.7566
2024-06-03 00:26:21 [INFO]: Epoch 045 - training loss: 0.4695, validation loss: 0.7434
2024-06-03 00:26:22 [INFO]: Epoch 046 - training loss: 0.4912, validation loss: 0.7129
2024-06-03 00:26:23 [INFO]: Epoch 047 - training loss: 0.4759, validation loss: 0.6920
2024-06-03 00:26:24 [INFO]: Epoch 048 - training loss: 0.4700, validation loss: 0.6687
2024-06-03 00:26:25 [INFO]: Epoch 049 - training loss: 0.4655, validation loss: 0.6627
2024-06-03 00:26:26 [INFO]: Epoch 050 - training loss: 0.4601, validation loss: 0.6941
2024-06-03 00:26:27 [INFO]: Epoch 051 - training loss: 0.4689, validation loss: 0.6672
2024-06-03 00:26:28 [INFO]: Epoch 052 - training loss: 0.4588, validation loss: 0.6679
2024-06-03 00:26:29 [INFO]: Epoch 053 - training loss: 0.4753, validation loss: 0.6579
2024-06-03 00:26:30 [INFO]: Epoch 054 - training loss: 0.4454, validation loss: 0.6567
2024-06-03 00:26:31 [INFO]: Epoch 055 - training loss: 0.4541, validation loss: 0.6740
2024-06-03 00:26:32 [INFO]: Epoch 056 - training loss: 0.4735, validation loss: 0.6718
2024-06-03 00:26:34 [INFO]: Epoch 057 - training loss: 0.4709, validation loss: 0.6614
2024-06-03 00:26:35 [INFO]: Epoch 058 - training loss: 0.4516, validation loss: 0.6607
2024-06-03 00:26:36 [INFO]: Epoch 059 - training loss: 0.4501, validation loss: 0.6465
2024-06-03 00:26:37 [INFO]: Epoch 060 - training loss: 0.4342, validation loss: 0.6473
2024-06-03 00:26:38 [INFO]: Epoch 061 - training loss: 0.4496, validation loss: 0.6409
2024-06-03 00:26:39 [INFO]: Epoch 062 - training loss: 0.4292, validation loss: 0.6620
2024-06-03 00:26:40 [INFO]: Epoch 063 - training loss: 0.4185, validation loss: 0.6774
2024-06-03 00:26:41 [INFO]: Epoch 064 - training loss: 0.4225, validation loss: 0.7050
2024-06-03 00:26:42 [INFO]: Epoch 065 - training loss: 0.4380, validation loss: 0.6286
2024-06-03 00:26:43 [INFO]: Epoch 066 - training loss: 0.4561, validation loss: 0.7105
2024-06-03 00:26:44 [INFO]: Epoch 067 - training loss: 0.4536, validation loss: 0.6743
2024-06-03 00:26:45 [INFO]: Epoch 068 - training loss: 0.4189, validation loss: 0.6238
2024-06-03 00:26:46 [INFO]: Epoch 069 - training loss: 0.4282, validation loss: 0.7159
2024-06-03 00:26:47 [INFO]: Epoch 070 - training loss: 0.4211, validation loss: 0.7149
2024-06-03 00:26:48 [INFO]: Epoch 071 - training loss: 0.4341, validation loss: 0.6927
2024-06-03 00:26:49 [INFO]: Epoch 072 - training loss: 0.4266, validation loss: 0.6791
2024-06-03 00:26:51 [INFO]: Epoch 073 - training loss: 0.4295, validation loss: 0.6676
2024-06-03 00:26:52 [INFO]: Epoch 074 - training loss: 0.4133, validation loss: 0.6357
2024-06-03 00:26:52 [INFO]: Epoch 075 - training loss: 0.4031, validation loss: 0.6431
2024-06-03 00:26:53 [INFO]: Epoch 076 - training loss: 0.4097, validation loss: 0.6549
2024-06-03 00:26:54 [INFO]: Epoch 077 - training loss: 0.4063, validation loss: 0.6620
2024-06-03 00:26:56 [INFO]: Epoch 078 - training loss: 0.4390, validation loss: 0.6623
2024-06-03 00:26:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:26:56 [INFO]: Finished training. The best model is from epoch#68.
2024-06-03 00:26:56 [INFO]: Saved the model to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T002535/Crossformer.pypots
2024-06-03 00:26:56 [INFO]: Successfully saved to results_point_rate09/ItalyAir/Crossformer_ItalyAir/round_4/imputation.pkl
2024-06-03 00:26:56 [INFO]: Round4 - Crossformer on ItalyAir: MAE=0.4558, MSE=0.5119, MRE=0.5990
2024-06-03 00:26:56 [INFO]: Done! Final results:
Averaged Crossformer (2,908,185 params) on ItalyAir: MAE=0.4583 ± 0.005102869376145865, MSE=0.5234 ± 0.010412174451128776, MRE=0.6022 ± 0.006705723348786076, average inference time=0.10
