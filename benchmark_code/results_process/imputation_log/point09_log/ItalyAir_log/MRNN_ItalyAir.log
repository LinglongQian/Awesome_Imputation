2024-06-03 00:35:09 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:35:09 [INFO]: Using the given device: cuda:0
2024-06-03 00:35:09 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_0/20240603_T003509
2024-06-03 00:35:09 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_0/20240603_T003509/tensorboard
2024-06-03 00:35:10 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 402,111
2024-06-03 00:35:17 [INFO]: Epoch 001 - training loss: 1.2805, validation loss: 2.3896
2024-06-03 00:35:20 [INFO]: Epoch 002 - training loss: 0.5314, validation loss: 2.3254
2024-06-03 00:35:23 [INFO]: Epoch 003 - training loss: 0.4224, validation loss: 2.2828
2024-06-03 00:35:26 [INFO]: Epoch 004 - training loss: 0.3798, validation loss: 2.2561
2024-06-03 00:35:29 [INFO]: Epoch 005 - training loss: 0.3670, validation loss: 2.2406
2024-06-03 00:35:33 [INFO]: Epoch 006 - training loss: 0.3669, validation loss: 2.2268
2024-06-03 00:35:36 [INFO]: Epoch 007 - training loss: 0.3581, validation loss: 2.2162
2024-06-03 00:35:39 [INFO]: Epoch 008 - training loss: 0.3487, validation loss: 2.2081
2024-06-03 00:35:42 [INFO]: Epoch 009 - training loss: 0.3322, validation loss: 2.2010
2024-06-03 00:35:45 [INFO]: Epoch 010 - training loss: 0.3339, validation loss: 2.1950
2024-06-03 00:35:49 [INFO]: Epoch 011 - training loss: 0.3352, validation loss: 2.1923
2024-06-03 00:35:52 [INFO]: Epoch 012 - training loss: 0.3436, validation loss: 2.1890
2024-06-03 00:35:55 [INFO]: Epoch 013 - training loss: 0.3318, validation loss: 2.1863
2024-06-03 00:35:58 [INFO]: Epoch 014 - training loss: 0.3236, validation loss: 2.1835
2024-06-03 00:36:01 [INFO]: Epoch 015 - training loss: 0.3334, validation loss: 2.1811
2024-06-03 00:36:04 [INFO]: Epoch 016 - training loss: 0.3325, validation loss: 2.1804
2024-06-03 00:36:07 [INFO]: Epoch 017 - training loss: 0.3168, validation loss: 2.1782
2024-06-03 00:36:11 [INFO]: Epoch 018 - training loss: 0.3195, validation loss: 2.1777
2024-06-03 00:36:14 [INFO]: Epoch 019 - training loss: 0.3021, validation loss: 2.1766
2024-06-03 00:36:17 [INFO]: Epoch 020 - training loss: 0.3087, validation loss: 2.1738
2024-06-03 00:36:20 [INFO]: Epoch 021 - training loss: 0.3131, validation loss: 2.1747
2024-06-03 00:36:23 [INFO]: Epoch 022 - training loss: 0.3143, validation loss: 2.1735
2024-06-03 00:36:27 [INFO]: Epoch 023 - training loss: 0.3045, validation loss: 2.1744
2024-06-03 00:36:30 [INFO]: Epoch 024 - training loss: 0.3058, validation loss: 2.1710
2024-06-03 00:36:33 [INFO]: Epoch 025 - training loss: 0.3113, validation loss: 2.1698
2024-06-03 00:36:37 [INFO]: Epoch 026 - training loss: 0.3043, validation loss: 2.1708
2024-06-03 00:36:40 [INFO]: Epoch 027 - training loss: 0.3175, validation loss: 2.1690
2024-06-03 00:36:43 [INFO]: Epoch 028 - training loss: 0.2888, validation loss: 2.1674
2024-06-03 00:36:46 [INFO]: Epoch 029 - training loss: 0.2941, validation loss: 2.1677
2024-06-03 00:36:49 [INFO]: Epoch 030 - training loss: 0.2993, validation loss: 2.1678
2024-06-03 00:36:52 [INFO]: Epoch 031 - training loss: 0.3047, validation loss: 2.1670
2024-06-03 00:36:56 [INFO]: Epoch 032 - training loss: 0.3035, validation loss: 2.1650
2024-06-03 00:36:59 [INFO]: Epoch 033 - training loss: 0.2952, validation loss: 2.1656
2024-06-03 00:37:02 [INFO]: Epoch 034 - training loss: 0.2968, validation loss: 2.1643
2024-06-03 00:37:05 [INFO]: Epoch 035 - training loss: 0.2942, validation loss: 2.1623
2024-06-03 00:37:09 [INFO]: Epoch 036 - training loss: 0.3028, validation loss: 2.1625
2024-06-03 00:37:12 [INFO]: Epoch 037 - training loss: 0.2970, validation loss: 2.1616
2024-06-03 00:37:15 [INFO]: Epoch 038 - training loss: 0.2915, validation loss: 2.1611
2024-06-03 00:37:18 [INFO]: Epoch 039 - training loss: 0.2876, validation loss: 2.1607
2024-06-03 00:37:21 [INFO]: Epoch 040 - training loss: 0.2906, validation loss: 2.1620
2024-06-03 00:37:25 [INFO]: Epoch 041 - training loss: 0.2954, validation loss: 2.1591
2024-06-03 00:37:28 [INFO]: Epoch 042 - training loss: 0.2898, validation loss: 2.1600
2024-06-03 00:37:31 [INFO]: Epoch 043 - training loss: 0.2817, validation loss: 2.1596
2024-06-03 00:37:34 [INFO]: Epoch 044 - training loss: 0.2752, validation loss: 2.1607
2024-06-03 00:37:37 [INFO]: Epoch 045 - training loss: 0.2947, validation loss: 2.1591
2024-06-03 00:37:40 [INFO]: Epoch 046 - training loss: 0.2951, validation loss: 2.1587
2024-06-03 00:37:43 [INFO]: Epoch 047 - training loss: 0.2864, validation loss: 2.1589
2024-06-03 00:37:47 [INFO]: Epoch 048 - training loss: 0.2864, validation loss: 2.1583
2024-06-03 00:37:50 [INFO]: Epoch 049 - training loss: 0.2926, validation loss: 2.1586
2024-06-03 00:37:53 [INFO]: Epoch 050 - training loss: 0.2888, validation loss: 2.1574
2024-06-03 00:37:56 [INFO]: Epoch 051 - training loss: 0.2819, validation loss: 2.1575
2024-06-03 00:38:00 [INFO]: Epoch 052 - training loss: 0.2876, validation loss: 2.1568
2024-06-03 00:38:03 [INFO]: Epoch 053 - training loss: 0.3083, validation loss: 2.1585
2024-06-03 00:38:06 [INFO]: Epoch 054 - training loss: 0.2910, validation loss: 2.1575
2024-06-03 00:38:09 [INFO]: Epoch 055 - training loss: 0.2817, validation loss: 2.1591
2024-06-03 00:38:13 [INFO]: Epoch 056 - training loss: 0.2890, validation loss: 2.1566
2024-06-03 00:38:16 [INFO]: Epoch 057 - training loss: 0.2873, validation loss: 2.1591
2024-06-03 00:38:19 [INFO]: Epoch 058 - training loss: 0.2871, validation loss: 2.1572
2024-06-03 00:38:22 [INFO]: Epoch 059 - training loss: 0.2902, validation loss: 2.1581
2024-06-03 00:38:25 [INFO]: Epoch 060 - training loss: 0.2834, validation loss: 2.1570
2024-06-03 00:38:29 [INFO]: Epoch 061 - training loss: 0.2903, validation loss: 2.1579
2024-06-03 00:38:32 [INFO]: Epoch 062 - training loss: 0.2809, validation loss: 2.1566
2024-06-03 00:38:35 [INFO]: Epoch 063 - training loss: 0.2806, validation loss: 2.1559
2024-06-03 00:38:38 [INFO]: Epoch 064 - training loss: 0.2869, validation loss: 2.1581
2024-06-03 00:38:41 [INFO]: Epoch 065 - training loss: 0.2788, validation loss: 2.1579
2024-06-03 00:38:44 [INFO]: Epoch 066 - training loss: 0.2765, validation loss: 2.1568
2024-06-03 00:38:48 [INFO]: Epoch 067 - training loss: 0.2780, validation loss: 2.1573
2024-06-03 00:38:51 [INFO]: Epoch 068 - training loss: 0.2836, validation loss: 2.1570
2024-06-03 00:38:54 [INFO]: Epoch 069 - training loss: 0.2762, validation loss: 2.1556
2024-06-03 00:38:57 [INFO]: Epoch 070 - training loss: 0.2703, validation loss: 2.1559
2024-06-03 00:38:59 [INFO]: Epoch 071 - training loss: 0.2831, validation loss: 2.1564
2024-06-03 00:39:02 [INFO]: Epoch 072 - training loss: 0.2801, validation loss: 2.1577
2024-06-03 00:39:05 [INFO]: Epoch 073 - training loss: 0.2737, validation loss: 2.1562
2024-06-03 00:39:08 [INFO]: Epoch 074 - training loss: 0.2916, validation loss: 2.1567
2024-06-03 00:39:11 [INFO]: Epoch 075 - training loss: 0.2869, validation loss: 2.1553
2024-06-03 00:39:14 [INFO]: Epoch 076 - training loss: 0.2752, validation loss: 2.1565
2024-06-03 00:39:17 [INFO]: Epoch 077 - training loss: 0.2750, validation loss: 2.1564
2024-06-03 00:39:19 [INFO]: Epoch 078 - training loss: 0.2886, validation loss: 2.1549
2024-06-03 00:39:22 [INFO]: Epoch 079 - training loss: 0.2799, validation loss: 2.1554
2024-06-03 00:39:25 [INFO]: Epoch 080 - training loss: 0.2848, validation loss: 2.1550
2024-06-03 00:39:28 [INFO]: Epoch 081 - training loss: 0.2790, validation loss: 2.1560
2024-06-03 00:39:31 [INFO]: Epoch 082 - training loss: 0.2842, validation loss: 2.1547
2024-06-03 00:39:34 [INFO]: Epoch 083 - training loss: 0.2754, validation loss: 2.1560
2024-06-03 00:39:37 [INFO]: Epoch 084 - training loss: 0.2786, validation loss: 2.1561
2024-06-03 00:39:40 [INFO]: Epoch 085 - training loss: 0.2792, validation loss: 2.1556
2024-06-03 00:39:43 [INFO]: Epoch 086 - training loss: 0.2774, validation loss: 2.1552
2024-06-03 00:39:46 [INFO]: Epoch 087 - training loss: 0.2853, validation loss: 2.1563
2024-06-03 00:39:49 [INFO]: Epoch 088 - training loss: 0.2803, validation loss: 2.1559
2024-06-03 00:39:51 [INFO]: Epoch 089 - training loss: 0.2802, validation loss: 2.1549
2024-06-03 00:39:54 [INFO]: Epoch 090 - training loss: 0.2772, validation loss: 2.1545
2024-06-03 00:39:57 [INFO]: Epoch 091 - training loss: 0.2783, validation loss: 2.1549
2024-06-03 00:40:00 [INFO]: Epoch 092 - training loss: 0.2857, validation loss: 2.1549
2024-06-03 00:40:03 [INFO]: Epoch 093 - training loss: 0.2820, validation loss: 2.1545
2024-06-03 00:40:06 [INFO]: Epoch 094 - training loss: 0.2819, validation loss: 2.1540
2024-06-03 00:40:09 [INFO]: Epoch 095 - training loss: 0.2880, validation loss: 2.1538
2024-06-03 00:40:12 [INFO]: Epoch 096 - training loss: 0.2751, validation loss: 2.1550
2024-06-03 00:40:15 [INFO]: Epoch 097 - training loss: 0.2805, validation loss: 2.1543
2024-06-03 00:40:18 [INFO]: Epoch 098 - training loss: 0.2690, validation loss: 2.1545
2024-06-03 00:40:21 [INFO]: Epoch 099 - training loss: 0.2716, validation loss: 2.1544
2024-06-03 00:40:24 [INFO]: Epoch 100 - training loss: 0.2924, validation loss: 2.1541
2024-06-03 00:40:24 [INFO]: Finished training. The best model is from epoch#95.
2024-06-03 00:40:24 [INFO]: Saved the model to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_0/20240603_T003509/MRNN.pypots
2024-06-03 00:40:27 [INFO]: Successfully saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_0/imputation.pkl
2024-06-03 00:40:27 [INFO]: Round0 - MRNN on ItalyAir: MAE=0.7564, MSE=1.4924, MRE=0.9940
2024-06-03 00:40:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:40:27 [INFO]: Using the given device: cuda:0
2024-06-03 00:40:27 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_1/20240603_T004027
2024-06-03 00:40:27 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_1/20240603_T004027/tensorboard
2024-06-03 00:40:27 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 402,111
2024-06-03 00:40:31 [INFO]: Epoch 001 - training loss: 1.2625, validation loss: 2.3675
2024-06-03 00:40:33 [INFO]: Epoch 002 - training loss: 0.5644, validation loss: 2.3114
2024-06-03 00:40:36 [INFO]: Epoch 003 - training loss: 0.4577, validation loss: 2.2823
2024-06-03 00:40:39 [INFO]: Epoch 004 - training loss: 0.3848, validation loss: 2.2586
2024-06-03 00:40:42 [INFO]: Epoch 005 - training loss: 0.3549, validation loss: 2.2407
2024-06-03 00:40:44 [INFO]: Epoch 006 - training loss: 0.3510, validation loss: 2.2265
2024-06-03 00:40:47 [INFO]: Epoch 007 - training loss: 0.3507, validation loss: 2.2163
2024-06-03 00:40:50 [INFO]: Epoch 008 - training loss: 0.3433, validation loss: 2.2068
2024-06-03 00:40:53 [INFO]: Epoch 009 - training loss: 0.3459, validation loss: 2.1987
2024-06-03 00:40:56 [INFO]: Epoch 010 - training loss: 0.3406, validation loss: 2.1941
2024-06-03 00:40:58 [INFO]: Epoch 011 - training loss: 0.3342, validation loss: 2.1896
2024-06-03 00:41:01 [INFO]: Epoch 012 - training loss: 0.3312, validation loss: 2.1857
2024-06-03 00:41:04 [INFO]: Epoch 013 - training loss: 0.3248, validation loss: 2.1827
2024-06-03 00:41:07 [INFO]: Epoch 014 - training loss: 0.3224, validation loss: 2.1805
2024-06-03 00:41:10 [INFO]: Epoch 015 - training loss: 0.3153, validation loss: 2.1786
2024-06-03 00:41:13 [INFO]: Epoch 016 - training loss: 0.3282, validation loss: 2.1780
2024-06-03 00:41:16 [INFO]: Epoch 017 - training loss: 0.3223, validation loss: 2.1744
2024-06-03 00:41:19 [INFO]: Epoch 018 - training loss: 0.3116, validation loss: 2.1735
2024-06-03 00:41:21 [INFO]: Epoch 019 - training loss: 0.3202, validation loss: 2.1713
2024-06-03 00:41:24 [INFO]: Epoch 020 - training loss: 0.3293, validation loss: 2.1704
2024-06-03 00:41:27 [INFO]: Epoch 021 - training loss: 0.3332, validation loss: 2.1712
2024-06-03 00:41:30 [INFO]: Epoch 022 - training loss: 0.3255, validation loss: 2.1693
2024-06-03 00:41:33 [INFO]: Epoch 023 - training loss: 0.3072, validation loss: 2.1682
2024-06-03 00:41:36 [INFO]: Epoch 024 - training loss: 0.2994, validation loss: 2.1667
2024-06-03 00:41:39 [INFO]: Epoch 025 - training loss: 0.3016, validation loss: 2.1651
2024-06-03 00:41:42 [INFO]: Epoch 026 - training loss: 0.3063, validation loss: 2.1655
2024-06-03 00:41:45 [INFO]: Epoch 027 - training loss: 0.3007, validation loss: 2.1650
2024-06-03 00:41:48 [INFO]: Epoch 028 - training loss: 0.3117, validation loss: 2.1628
2024-06-03 00:41:51 [INFO]: Epoch 029 - training loss: 0.2960, validation loss: 2.1631
2024-06-03 00:41:54 [INFO]: Epoch 030 - training loss: 0.3016, validation loss: 2.1626
2024-06-03 00:41:57 [INFO]: Epoch 031 - training loss: 0.2887, validation loss: 2.1632
2024-06-03 00:42:00 [INFO]: Epoch 032 - training loss: 0.2914, validation loss: 2.1608
2024-06-03 00:42:03 [INFO]: Epoch 033 - training loss: 0.2970, validation loss: 2.1609
2024-06-03 00:42:06 [INFO]: Epoch 034 - training loss: 0.2921, validation loss: 2.1602
2024-06-03 00:42:09 [INFO]: Epoch 035 - training loss: 0.2887, validation loss: 2.1617
2024-06-03 00:42:12 [INFO]: Epoch 036 - training loss: 0.3007, validation loss: 2.1598
2024-06-03 00:42:15 [INFO]: Epoch 037 - training loss: 0.2911, validation loss: 2.1599
2024-06-03 00:42:18 [INFO]: Epoch 038 - training loss: 0.2962, validation loss: 2.1588
2024-06-03 00:42:20 [INFO]: Epoch 039 - training loss: 0.3185, validation loss: 2.1575
2024-06-03 00:42:23 [INFO]: Epoch 040 - training loss: 0.3129, validation loss: 2.1574
2024-06-03 00:42:26 [INFO]: Epoch 041 - training loss: 0.2923, validation loss: 2.1584
2024-06-03 00:42:29 [INFO]: Epoch 042 - training loss: 0.3034, validation loss: 2.1576
2024-06-03 00:42:32 [INFO]: Epoch 043 - training loss: 0.2985, validation loss: 2.1555
2024-06-03 00:42:34 [INFO]: Epoch 044 - training loss: 0.2959, validation loss: 2.1566
2024-06-03 00:42:37 [INFO]: Epoch 045 - training loss: 0.3112, validation loss: 2.1572
2024-06-03 00:42:40 [INFO]: Epoch 046 - training loss: 0.3189, validation loss: 2.1572
2024-06-03 00:42:43 [INFO]: Epoch 047 - training loss: 0.2907, validation loss: 2.1570
2024-06-03 00:42:46 [INFO]: Epoch 048 - training loss: 0.2824, validation loss: 2.1573
2024-06-03 00:42:49 [INFO]: Epoch 049 - training loss: 0.2862, validation loss: 2.1575
2024-06-03 00:42:52 [INFO]: Epoch 050 - training loss: 0.2925, validation loss: 2.1568
2024-06-03 00:42:55 [INFO]: Epoch 051 - training loss: 0.2897, validation loss: 2.1552
2024-06-03 00:42:58 [INFO]: Epoch 052 - training loss: 0.2854, validation loss: 2.1564
2024-06-03 00:43:01 [INFO]: Epoch 053 - training loss: 0.2837, validation loss: 2.1566
2024-06-03 00:43:04 [INFO]: Epoch 054 - training loss: 0.2829, validation loss: 2.1564
2024-06-03 00:43:07 [INFO]: Epoch 055 - training loss: 0.2791, validation loss: 2.1549
2024-06-03 00:43:09 [INFO]: Epoch 056 - training loss: 0.2939, validation loss: 2.1566
2024-06-03 00:43:12 [INFO]: Epoch 057 - training loss: 0.2883, validation loss: 2.1557
2024-06-03 00:43:15 [INFO]: Epoch 058 - training loss: 0.2836, validation loss: 2.1560
2024-06-03 00:43:18 [INFO]: Epoch 059 - training loss: 0.2921, validation loss: 2.1567
2024-06-03 00:43:21 [INFO]: Epoch 060 - training loss: 0.3050, validation loss: 2.1558
2024-06-03 00:43:24 [INFO]: Epoch 061 - training loss: 0.3048, validation loss: 2.1567
2024-06-03 00:43:27 [INFO]: Epoch 062 - training loss: 0.2857, validation loss: 2.1553
2024-06-03 00:43:30 [INFO]: Epoch 063 - training loss: 0.2868, validation loss: 2.1548
2024-06-03 00:43:32 [INFO]: Epoch 064 - training loss: 0.2925, validation loss: 2.1551
2024-06-03 00:43:35 [INFO]: Epoch 065 - training loss: 0.2930, validation loss: 2.1538
2024-06-03 00:43:38 [INFO]: Epoch 066 - training loss: 0.2689, validation loss: 2.1536
2024-06-03 00:43:41 [INFO]: Epoch 067 - training loss: 0.2883, validation loss: 2.1557
2024-06-03 00:43:43 [INFO]: Epoch 068 - training loss: 0.2834, validation loss: 2.1552
2024-06-03 00:43:47 [INFO]: Epoch 069 - training loss: 0.2884, validation loss: 2.1539
2024-06-03 00:43:49 [INFO]: Epoch 070 - training loss: 0.2845, validation loss: 2.1553
2024-06-03 00:43:52 [INFO]: Epoch 071 - training loss: 0.2859, validation loss: 2.1558
2024-06-03 00:43:56 [INFO]: Epoch 072 - training loss: 0.2749, validation loss: 2.1549
2024-06-03 00:43:58 [INFO]: Epoch 073 - training loss: 0.2902, validation loss: 2.1541
2024-06-03 00:44:02 [INFO]: Epoch 074 - training loss: 0.2949, validation loss: 2.1543
2024-06-03 00:44:05 [INFO]: Epoch 075 - training loss: 0.2922, validation loss: 2.1547
2024-06-03 00:44:07 [INFO]: Epoch 076 - training loss: 0.2695, validation loss: 2.1542
2024-06-03 00:44:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:44:07 [INFO]: Finished training. The best model is from epoch#66.
2024-06-03 00:44:07 [INFO]: Saved the model to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_1/20240603_T004027/MRNN.pypots
2024-06-03 00:44:11 [INFO]: Successfully saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_1/imputation.pkl
2024-06-03 00:44:11 [INFO]: Round1 - MRNN on ItalyAir: MAE=0.7577, MSE=1.4955, MRE=0.9957
2024-06-03 00:44:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:44:11 [INFO]: Using the given device: cuda:0
2024-06-03 00:44:11 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_2/20240603_T004411
2024-06-03 00:44:11 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_2/20240603_T004411/tensorboard
2024-06-03 00:44:11 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 402,111
2024-06-03 00:44:14 [INFO]: Epoch 001 - training loss: 1.2694, validation loss: 2.3941
2024-06-03 00:44:17 [INFO]: Epoch 002 - training loss: 0.5389, validation loss: 2.3415
2024-06-03 00:44:20 [INFO]: Epoch 003 - training loss: 0.4204, validation loss: 2.2994
2024-06-03 00:44:23 [INFO]: Epoch 004 - training loss: 0.3706, validation loss: 2.2675
2024-06-03 00:44:26 [INFO]: Epoch 005 - training loss: 0.3608, validation loss: 2.2491
2024-06-03 00:44:29 [INFO]: Epoch 006 - training loss: 0.3559, validation loss: 2.2346
2024-06-03 00:44:32 [INFO]: Epoch 007 - training loss: 0.3419, validation loss: 2.2250
2024-06-03 00:44:35 [INFO]: Epoch 008 - training loss: 0.3559, validation loss: 2.2148
2024-06-03 00:44:37 [INFO]: Epoch 009 - training loss: 0.3407, validation loss: 2.2059
2024-06-03 00:44:40 [INFO]: Epoch 010 - training loss: 0.3296, validation loss: 2.2011
2024-06-03 00:44:43 [INFO]: Epoch 011 - training loss: 0.3291, validation loss: 2.1955
2024-06-03 00:44:46 [INFO]: Epoch 012 - training loss: 0.3346, validation loss: 2.1921
2024-06-03 00:44:49 [INFO]: Epoch 013 - training loss: 0.3281, validation loss: 2.1899
2024-06-03 00:44:52 [INFO]: Epoch 014 - training loss: 0.3341, validation loss: 2.1859
2024-06-03 00:44:55 [INFO]: Epoch 015 - training loss: 0.3249, validation loss: 2.1826
2024-06-03 00:44:58 [INFO]: Epoch 016 - training loss: 0.3153, validation loss: 2.1823
2024-06-03 00:45:00 [INFO]: Epoch 017 - training loss: 0.3298, validation loss: 2.1801
2024-06-03 00:45:03 [INFO]: Epoch 018 - training loss: 0.3097, validation loss: 2.1788
2024-06-03 00:45:06 [INFO]: Epoch 019 - training loss: 0.3240, validation loss: 2.1773
2024-06-03 00:45:09 [INFO]: Epoch 020 - training loss: 0.3188, validation loss: 2.1759
2024-06-03 00:45:11 [INFO]: Epoch 021 - training loss: 0.3111, validation loss: 2.1745
2024-06-03 00:45:14 [INFO]: Epoch 022 - training loss: 0.3156, validation loss: 2.1743
2024-06-03 00:45:17 [INFO]: Epoch 023 - training loss: 0.3039, validation loss: 2.1734
2024-06-03 00:45:20 [INFO]: Epoch 024 - training loss: 0.3140, validation loss: 2.1725
2024-06-03 00:45:22 [INFO]: Epoch 025 - training loss: 0.3084, validation loss: 2.1718
2024-06-03 00:45:25 [INFO]: Epoch 026 - training loss: 0.3044, validation loss: 2.1716
2024-06-03 00:45:28 [INFO]: Epoch 027 - training loss: 0.3105, validation loss: 2.1708
2024-06-03 00:45:30 [INFO]: Epoch 028 - training loss: 0.3007, validation loss: 2.1705
2024-06-03 00:45:32 [INFO]: Epoch 029 - training loss: 0.2979, validation loss: 2.1711
2024-06-03 00:45:35 [INFO]: Epoch 030 - training loss: 0.3035, validation loss: 2.1698
2024-06-03 00:45:37 [INFO]: Epoch 031 - training loss: 0.2904, validation loss: 2.1697
2024-06-03 00:45:39 [INFO]: Epoch 032 - training loss: 0.2884, validation loss: 2.1691
2024-06-03 00:45:41 [INFO]: Epoch 033 - training loss: 0.2889, validation loss: 2.1684
2024-06-03 00:45:43 [INFO]: Epoch 034 - training loss: 0.2970, validation loss: 2.1683
2024-06-03 00:45:45 [INFO]: Epoch 035 - training loss: 0.2951, validation loss: 2.1668
2024-06-03 00:45:47 [INFO]: Epoch 036 - training loss: 0.2938, validation loss: 2.1666
2024-06-03 00:45:49 [INFO]: Epoch 037 - training loss: 0.3101, validation loss: 2.1659
2024-06-03 00:45:51 [INFO]: Epoch 038 - training loss: 0.3043, validation loss: 2.1658
2024-06-03 00:45:53 [INFO]: Epoch 039 - training loss: 0.3243, validation loss: 2.1653
2024-06-03 00:45:56 [INFO]: Epoch 040 - training loss: 0.3258, validation loss: 2.1662
2024-06-03 00:45:58 [INFO]: Epoch 041 - training loss: 0.3157, validation loss: 2.1640
2024-06-03 00:46:00 [INFO]: Epoch 042 - training loss: 0.2864, validation loss: 2.1645
2024-06-03 00:46:02 [INFO]: Epoch 043 - training loss: 0.2877, validation loss: 2.1648
2024-06-03 00:46:04 [INFO]: Epoch 044 - training loss: 0.2936, validation loss: 2.1644
2024-06-03 00:46:06 [INFO]: Epoch 045 - training loss: 0.2891, validation loss: 2.1624
2024-06-03 00:46:08 [INFO]: Epoch 046 - training loss: 0.2881, validation loss: 2.1617
2024-06-03 00:46:10 [INFO]: Epoch 047 - training loss: 0.2847, validation loss: 2.1623
2024-06-03 00:46:13 [INFO]: Epoch 048 - training loss: 0.2926, validation loss: 2.1628
2024-06-03 00:46:15 [INFO]: Epoch 049 - training loss: 0.2972, validation loss: 2.1616
2024-06-03 00:46:16 [INFO]: Epoch 050 - training loss: 0.2837, validation loss: 2.1606
2024-06-03 00:46:19 [INFO]: Epoch 051 - training loss: 0.2880, validation loss: 2.1604
2024-06-03 00:46:21 [INFO]: Epoch 052 - training loss: 0.2884, validation loss: 2.1608
2024-06-03 00:46:23 [INFO]: Epoch 053 - training loss: 0.2916, validation loss: 2.1602
2024-06-03 00:46:25 [INFO]: Epoch 054 - training loss: 0.2824, validation loss: 2.1593
2024-06-03 00:46:27 [INFO]: Epoch 055 - training loss: 0.2902, validation loss: 2.1605
2024-06-03 00:46:29 [INFO]: Epoch 056 - training loss: 0.2875, validation loss: 2.1590
2024-06-03 00:46:31 [INFO]: Epoch 057 - training loss: 0.2850, validation loss: 2.1592
2024-06-03 00:46:33 [INFO]: Epoch 058 - training loss: 0.2951, validation loss: 2.1592
2024-06-03 00:46:36 [INFO]: Epoch 059 - training loss: 0.2830, validation loss: 2.1584
2024-06-03 00:46:38 [INFO]: Epoch 060 - training loss: 0.2856, validation loss: 2.1579
2024-06-03 00:46:40 [INFO]: Epoch 061 - training loss: 0.2837, validation loss: 2.1584
2024-06-03 00:46:42 [INFO]: Epoch 062 - training loss: 0.2860, validation loss: 2.1580
2024-06-03 00:46:44 [INFO]: Epoch 063 - training loss: 0.2881, validation loss: 2.1578
2024-06-03 00:46:47 [INFO]: Epoch 064 - training loss: 0.2982, validation loss: 2.1576
2024-06-03 00:46:49 [INFO]: Epoch 065 - training loss: 0.3001, validation loss: 2.1574
2024-06-03 00:46:51 [INFO]: Epoch 066 - training loss: 0.2823, validation loss: 2.1580
2024-06-03 00:46:53 [INFO]: Epoch 067 - training loss: 0.2834, validation loss: 2.1593
2024-06-03 00:46:55 [INFO]: Epoch 068 - training loss: 0.2848, validation loss: 2.1575
2024-06-03 00:46:58 [INFO]: Epoch 069 - training loss: 0.2872, validation loss: 2.1577
2024-06-03 00:47:00 [INFO]: Epoch 070 - training loss: 0.2859, validation loss: 2.1584
2024-06-03 00:47:02 [INFO]: Epoch 071 - training loss: 0.2830, validation loss: 2.1577
2024-06-03 00:47:04 [INFO]: Epoch 072 - training loss: 0.2861, validation loss: 2.1582
2024-06-03 00:47:06 [INFO]: Epoch 073 - training loss: 0.2870, validation loss: 2.1571
2024-06-03 00:47:08 [INFO]: Epoch 074 - training loss: 0.2763, validation loss: 2.1569
2024-06-03 00:47:11 [INFO]: Epoch 075 - training loss: 0.2883, validation loss: 2.1572
2024-06-03 00:47:13 [INFO]: Epoch 076 - training loss: 0.2813, validation loss: 2.1580
2024-06-03 00:47:15 [INFO]: Epoch 077 - training loss: 0.2893, validation loss: 2.1575
2024-06-03 00:47:17 [INFO]: Epoch 078 - training loss: 0.2855, validation loss: 2.1580
2024-06-03 00:47:19 [INFO]: Epoch 079 - training loss: 0.2969, validation loss: 2.1578
2024-06-03 00:47:21 [INFO]: Epoch 080 - training loss: 0.2954, validation loss: 2.1571
2024-06-03 00:47:23 [INFO]: Epoch 081 - training loss: 0.2809, validation loss: 2.1563
2024-06-03 00:47:25 [INFO]: Epoch 082 - training loss: 0.2796, validation loss: 2.1570
2024-06-03 00:47:27 [INFO]: Epoch 083 - training loss: 0.2792, validation loss: 2.1572
2024-06-03 00:47:29 [INFO]: Epoch 084 - training loss: 0.2839, validation loss: 2.1572
2024-06-03 00:47:32 [INFO]: Epoch 085 - training loss: 0.2780, validation loss: 2.1571
2024-06-03 00:47:33 [INFO]: Epoch 086 - training loss: 0.2877, validation loss: 2.1568
2024-06-03 00:47:35 [INFO]: Epoch 087 - training loss: 0.2806, validation loss: 2.1567
2024-06-03 00:47:37 [INFO]: Epoch 088 - training loss: 0.2841, validation loss: 2.1569
2024-06-03 00:47:39 [INFO]: Epoch 089 - training loss: 0.2683, validation loss: 2.1577
2024-06-03 00:47:40 [INFO]: Epoch 090 - training loss: 0.2753, validation loss: 2.1570
2024-06-03 00:47:42 [INFO]: Epoch 091 - training loss: 0.2743, validation loss: 2.1567
2024-06-03 00:47:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:47:42 [INFO]: Finished training. The best model is from epoch#81.
2024-06-03 00:47:42 [INFO]: Saved the model to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_2/20240603_T004411/MRNN.pypots
2024-06-03 00:47:44 [INFO]: Successfully saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_2/imputation.pkl
2024-06-03 00:47:44 [INFO]: Round2 - MRNN on ItalyAir: MAE=0.7595, MSE=1.4963, MRE=0.9980
2024-06-03 00:47:44 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:47:44 [INFO]: Using the given device: cuda:0
2024-06-03 00:47:44 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_3/20240603_T004744
2024-06-03 00:47:44 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_3/20240603_T004744/tensorboard
2024-06-03 00:47:44 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 402,111
2024-06-03 00:47:46 [INFO]: Epoch 001 - training loss: 1.2438, validation loss: 2.3314
2024-06-03 00:47:48 [INFO]: Epoch 002 - training loss: 0.5596, validation loss: 2.3150
2024-06-03 00:47:50 [INFO]: Epoch 003 - training loss: 0.4061, validation loss: 2.2846
2024-06-03 00:47:52 [INFO]: Epoch 004 - training loss: 0.3723, validation loss: 2.2604
2024-06-03 00:47:53 [INFO]: Epoch 005 - training loss: 0.3571, validation loss: 2.2482
2024-06-03 00:47:55 [INFO]: Epoch 006 - training loss: 0.3509, validation loss: 2.2314
2024-06-03 00:47:57 [INFO]: Epoch 007 - training loss: 0.3420, validation loss: 2.2218
2024-06-03 00:47:59 [INFO]: Epoch 008 - training loss: 0.3509, validation loss: 2.2127
2024-06-03 00:48:00 [INFO]: Epoch 009 - training loss: 0.3352, validation loss: 2.2063
2024-06-03 00:48:02 [INFO]: Epoch 010 - training loss: 0.3374, validation loss: 2.2009
2024-06-03 00:48:04 [INFO]: Epoch 011 - training loss: 0.3280, validation loss: 2.1945
2024-06-03 00:48:05 [INFO]: Epoch 012 - training loss: 0.3361, validation loss: 2.1928
2024-06-03 00:48:07 [INFO]: Epoch 013 - training loss: 0.3280, validation loss: 2.1890
2024-06-03 00:48:09 [INFO]: Epoch 014 - training loss: 0.3117, validation loss: 2.1860
2024-06-03 00:48:11 [INFO]: Epoch 015 - training loss: 0.3167, validation loss: 2.1839
2024-06-03 00:48:12 [INFO]: Epoch 016 - training loss: 0.3140, validation loss: 2.1815
2024-06-03 00:48:14 [INFO]: Epoch 017 - training loss: 0.3246, validation loss: 2.1799
2024-06-03 00:48:16 [INFO]: Epoch 018 - training loss: 0.3188, validation loss: 2.1795
2024-06-03 00:48:18 [INFO]: Epoch 019 - training loss: 0.3204, validation loss: 2.1772
2024-06-03 00:48:19 [INFO]: Epoch 020 - training loss: 0.3066, validation loss: 2.1739
2024-06-03 00:48:21 [INFO]: Epoch 021 - training loss: 0.3021, validation loss: 2.1719
2024-06-03 00:48:23 [INFO]: Epoch 022 - training loss: 0.3116, validation loss: 2.1714
2024-06-03 00:48:25 [INFO]: Epoch 023 - training loss: 0.3021, validation loss: 2.1701
2024-06-03 00:48:26 [INFO]: Epoch 024 - training loss: 0.3076, validation loss: 2.1692
2024-06-03 00:48:28 [INFO]: Epoch 025 - training loss: 0.3082, validation loss: 2.1686
2024-06-03 00:48:30 [INFO]: Epoch 026 - training loss: 0.3114, validation loss: 2.1671
2024-06-03 00:48:32 [INFO]: Epoch 027 - training loss: 0.3080, validation loss: 2.1667
2024-06-03 00:48:33 [INFO]: Epoch 028 - training loss: 0.3040, validation loss: 2.1658
2024-06-03 00:48:35 [INFO]: Epoch 029 - training loss: 0.3088, validation loss: 2.1651
2024-06-03 00:48:37 [INFO]: Epoch 030 - training loss: 0.2996, validation loss: 2.1653
2024-06-03 00:48:39 [INFO]: Epoch 031 - training loss: 0.3033, validation loss: 2.1644
2024-06-03 00:48:40 [INFO]: Epoch 032 - training loss: 0.2965, validation loss: 2.1641
2024-06-03 00:48:42 [INFO]: Epoch 033 - training loss: 0.2986, validation loss: 2.1611
2024-06-03 00:48:44 [INFO]: Epoch 034 - training loss: 0.3032, validation loss: 2.1614
2024-06-03 00:48:46 [INFO]: Epoch 035 - training loss: 0.3039, validation loss: 2.1613
2024-06-03 00:48:47 [INFO]: Epoch 036 - training loss: 0.3063, validation loss: 2.1608
2024-06-03 00:48:49 [INFO]: Epoch 037 - training loss: 0.3014, validation loss: 2.1591
2024-06-03 00:48:51 [INFO]: Epoch 038 - training loss: 0.2989, validation loss: 2.1593
2024-06-03 00:48:52 [INFO]: Epoch 039 - training loss: 0.2990, validation loss: 2.1599
2024-06-03 00:48:54 [INFO]: Epoch 040 - training loss: 0.3002, validation loss: 2.1571
2024-06-03 00:48:56 [INFO]: Epoch 041 - training loss: 0.2921, validation loss: 2.1587
2024-06-03 00:48:57 [INFO]: Epoch 042 - training loss: 0.2959, validation loss: 2.1581
2024-06-03 00:48:59 [INFO]: Epoch 043 - training loss: 0.2969, validation loss: 2.1566
2024-06-03 00:49:01 [INFO]: Epoch 044 - training loss: 0.2968, validation loss: 2.1552
2024-06-03 00:49:02 [INFO]: Epoch 045 - training loss: 0.2913, validation loss: 2.1562
2024-06-03 00:49:04 [INFO]: Epoch 046 - training loss: 0.2885, validation loss: 2.1564
2024-06-03 00:49:06 [INFO]: Epoch 047 - training loss: 0.2834, validation loss: 2.1544
2024-06-03 00:49:07 [INFO]: Epoch 048 - training loss: 0.2931, validation loss: 2.1535
2024-06-03 00:49:09 [INFO]: Epoch 049 - training loss: 0.2816, validation loss: 2.1551
2024-06-03 00:49:11 [INFO]: Epoch 050 - training loss: 0.2865, validation loss: 2.1545
2024-06-03 00:49:13 [INFO]: Epoch 051 - training loss: 0.2901, validation loss: 2.1538
2024-06-03 00:49:15 [INFO]: Epoch 052 - training loss: 0.2878, validation loss: 2.1543
2024-06-03 00:49:16 [INFO]: Epoch 053 - training loss: 0.2819, validation loss: 2.1551
2024-06-03 00:49:18 [INFO]: Epoch 054 - training loss: 0.2936, validation loss: 2.1552
2024-06-03 00:49:20 [INFO]: Epoch 055 - training loss: 0.2984, validation loss: 2.1532
2024-06-03 00:49:21 [INFO]: Epoch 056 - training loss: 0.2906, validation loss: 2.1541
2024-06-03 00:49:23 [INFO]: Epoch 057 - training loss: 0.2942, validation loss: 2.1535
2024-06-03 00:49:25 [INFO]: Epoch 058 - training loss: 0.3018, validation loss: 2.1544
2024-06-03 00:49:27 [INFO]: Epoch 059 - training loss: 0.3045, validation loss: 2.1532
2024-06-03 00:49:28 [INFO]: Epoch 060 - training loss: 0.2911, validation loss: 2.1534
2024-06-03 00:49:30 [INFO]: Epoch 061 - training loss: 0.2866, validation loss: 2.1524
2024-06-03 00:49:32 [INFO]: Epoch 062 - training loss: 0.2846, validation loss: 2.1540
2024-06-03 00:49:34 [INFO]: Epoch 063 - training loss: 0.3019, validation loss: 2.1532
2024-06-03 00:49:35 [INFO]: Epoch 064 - training loss: 0.2904, validation loss: 2.1522
2024-06-03 00:49:37 [INFO]: Epoch 065 - training loss: 0.2837, validation loss: 2.1546
2024-06-03 00:49:39 [INFO]: Epoch 066 - training loss: 0.2781, validation loss: 2.1544
2024-06-03 00:49:41 [INFO]: Epoch 067 - training loss: 0.2846, validation loss: 2.1528
2024-06-03 00:49:42 [INFO]: Epoch 068 - training loss: 0.2765, validation loss: 2.1530
2024-06-03 00:49:44 [INFO]: Epoch 069 - training loss: 0.2919, validation loss: 2.1523
2024-06-03 00:49:46 [INFO]: Epoch 070 - training loss: 0.2860, validation loss: 2.1540
2024-06-03 00:49:48 [INFO]: Epoch 071 - training loss: 0.2867, validation loss: 2.1535
2024-06-03 00:49:50 [INFO]: Epoch 072 - training loss: 0.2780, validation loss: 2.1546
2024-06-03 00:49:51 [INFO]: Epoch 073 - training loss: 0.2833, validation loss: 2.1535
2024-06-03 00:49:53 [INFO]: Epoch 074 - training loss: 0.2881, validation loss: 2.1530
2024-06-03 00:49:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:49:53 [INFO]: Finished training. The best model is from epoch#64.
2024-06-03 00:49:53 [INFO]: Saved the model to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_3/20240603_T004744/MRNN.pypots
2024-06-03 00:49:55 [INFO]: Successfully saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_3/imputation.pkl
2024-06-03 00:49:55 [INFO]: Round3 - MRNN on ItalyAir: MAE=0.7559, MSE=1.4946, MRE=0.9934
2024-06-03 00:49:55 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:49:55 [INFO]: Using the given device: cuda:0
2024-06-03 00:49:55 [INFO]: Model files will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_4/20240603_T004955
2024-06-03 00:49:55 [INFO]: Tensorboard file will be saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_4/20240603_T004955/tensorboard
2024-06-03 00:49:55 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 402,111
2024-06-03 00:49:57 [INFO]: Epoch 001 - training loss: 1.2826, validation loss: 2.3509
2024-06-03 00:49:59 [INFO]: Epoch 002 - training loss: 0.5189, validation loss: 2.3066
2024-06-03 00:50:00 [INFO]: Epoch 003 - training loss: 0.4083, validation loss: 2.2759
2024-06-03 00:50:02 [INFO]: Epoch 004 - training loss: 0.3703, validation loss: 2.2550
2024-06-03 00:50:03 [INFO]: Epoch 005 - training loss: 0.3740, validation loss: 2.2389
2024-06-03 00:50:05 [INFO]: Epoch 006 - training loss: 0.3583, validation loss: 2.2253
2024-06-03 00:50:07 [INFO]: Epoch 007 - training loss: 0.3409, validation loss: 2.2159
2024-06-03 00:50:09 [INFO]: Epoch 008 - training loss: 0.3419, validation loss: 2.2082
2024-06-03 00:50:11 [INFO]: Epoch 009 - training loss: 0.3442, validation loss: 2.2047
2024-06-03 00:50:12 [INFO]: Epoch 010 - training loss: 0.3491, validation loss: 2.1981
2024-06-03 00:50:14 [INFO]: Epoch 011 - training loss: 0.3298, validation loss: 2.1941
2024-06-03 00:50:16 [INFO]: Epoch 012 - training loss: 0.3252, validation loss: 2.1911
2024-06-03 00:50:18 [INFO]: Epoch 013 - training loss: 0.3347, validation loss: 2.1898
2024-06-03 00:50:19 [INFO]: Epoch 014 - training loss: 0.3212, validation loss: 2.1870
2024-06-03 00:50:21 [INFO]: Epoch 015 - training loss: 0.3285, validation loss: 2.1855
2024-06-03 00:50:23 [INFO]: Epoch 016 - training loss: 0.3289, validation loss: 2.1852
2024-06-03 00:50:24 [INFO]: Epoch 017 - training loss: 0.3122, validation loss: 2.1845
2024-06-03 00:50:26 [INFO]: Epoch 018 - training loss: 0.3223, validation loss: 2.1842
2024-06-03 00:50:28 [INFO]: Epoch 019 - training loss: 0.3130, validation loss: 2.1843
2024-06-03 00:50:28 [INFO]: Epoch 020 - training loss: 0.3106, validation loss: 2.1825
2024-06-03 00:50:29 [INFO]: Epoch 021 - training loss: 0.3112, validation loss: 2.1808
2024-06-03 00:50:30 [INFO]: Epoch 022 - training loss: 0.3018, validation loss: 2.1818
2024-06-03 00:50:31 [INFO]: Epoch 023 - training loss: 0.2985, validation loss: 2.1784
2024-06-03 00:50:31 [INFO]: Epoch 024 - training loss: 0.3180, validation loss: 2.1790
2024-06-03 00:50:32 [INFO]: Epoch 025 - training loss: 0.3137, validation loss: 2.1781
2024-06-03 00:50:33 [INFO]: Epoch 026 - training loss: 0.3006, validation loss: 2.1775
2024-06-03 00:50:33 [INFO]: Epoch 027 - training loss: 0.2955, validation loss: 2.1775
2024-06-03 00:50:34 [INFO]: Epoch 028 - training loss: 0.3113, validation loss: 2.1767
2024-06-03 00:50:34 [INFO]: Epoch 029 - training loss: 0.2945, validation loss: 2.1758
2024-06-03 00:50:35 [INFO]: Epoch 030 - training loss: 0.2955, validation loss: 2.1760
2024-06-03 00:50:36 [INFO]: Epoch 031 - training loss: 0.2956, validation loss: 2.1763
2024-06-03 00:50:36 [INFO]: Epoch 032 - training loss: 0.2911, validation loss: 2.1751
2024-06-03 00:50:37 [INFO]: Epoch 033 - training loss: 0.2893, validation loss: 2.1742
2024-06-03 00:50:38 [INFO]: Epoch 034 - training loss: 0.2944, validation loss: 2.1730
2024-06-03 00:50:38 [INFO]: Epoch 035 - training loss: 0.2902, validation loss: 2.1726
2024-06-03 00:50:39 [INFO]: Epoch 036 - training loss: 0.2931, validation loss: 2.1733
2024-06-03 00:50:39 [INFO]: Epoch 037 - training loss: 0.2972, validation loss: 2.1728
2024-06-03 00:50:40 [INFO]: Epoch 038 - training loss: 0.2948, validation loss: 2.1710
2024-06-03 00:50:41 [INFO]: Epoch 039 - training loss: 0.3008, validation loss: 2.1704
2024-06-03 00:50:41 [INFO]: Epoch 040 - training loss: 0.3005, validation loss: 2.1705
2024-06-03 00:50:42 [INFO]: Epoch 041 - training loss: 0.2942, validation loss: 2.1696
2024-06-03 00:50:43 [INFO]: Epoch 042 - training loss: 0.3069, validation loss: 2.1703
2024-06-03 00:50:43 [INFO]: Epoch 043 - training loss: 0.2968, validation loss: 2.1692
2024-06-03 00:50:44 [INFO]: Epoch 044 - training loss: 0.2909, validation loss: 2.1694
2024-06-03 00:50:45 [INFO]: Epoch 045 - training loss: 0.2920, validation loss: 2.1668
2024-06-03 00:50:45 [INFO]: Epoch 046 - training loss: 0.3000, validation loss: 2.1687
2024-06-03 00:50:46 [INFO]: Epoch 047 - training loss: 0.2924, validation loss: 2.1676
2024-06-03 00:50:47 [INFO]: Epoch 048 - training loss: 0.2862, validation loss: 2.1674
2024-06-03 00:50:47 [INFO]: Epoch 049 - training loss: 0.2833, validation loss: 2.1654
2024-06-03 00:50:48 [INFO]: Epoch 050 - training loss: 0.2861, validation loss: 2.1662
2024-06-03 00:50:49 [INFO]: Epoch 051 - training loss: 0.2868, validation loss: 2.1643
2024-06-03 00:50:50 [INFO]: Epoch 052 - training loss: 0.2850, validation loss: 2.1644
2024-06-03 00:50:50 [INFO]: Epoch 053 - training loss: 0.2814, validation loss: 2.1655
2024-06-03 00:50:51 [INFO]: Epoch 054 - training loss: 0.2805, validation loss: 2.1633
2024-06-03 00:50:52 [INFO]: Epoch 055 - training loss: 0.2914, validation loss: 2.1638
2024-06-03 00:50:52 [INFO]: Epoch 056 - training loss: 0.2939, validation loss: 2.1629
2024-06-03 00:50:53 [INFO]: Epoch 057 - training loss: 0.2839, validation loss: 2.1632
2024-06-03 00:50:53 [INFO]: Epoch 058 - training loss: 0.2851, validation loss: 2.1619
2024-06-03 00:50:54 [INFO]: Epoch 059 - training loss: 0.2808, validation loss: 2.1628
2024-06-03 00:50:54 [INFO]: Epoch 060 - training loss: 0.2848, validation loss: 2.1626
2024-06-03 00:50:55 [INFO]: Epoch 061 - training loss: 0.3020, validation loss: 2.1620
2024-06-03 00:50:55 [INFO]: Epoch 062 - training loss: 0.2821, validation loss: 2.1620
2024-06-03 00:50:56 [INFO]: Epoch 063 - training loss: 0.2883, validation loss: 2.1627
2024-06-03 00:50:56 [INFO]: Epoch 064 - training loss: 0.2871, validation loss: 2.1631
2024-06-03 00:50:57 [INFO]: Epoch 065 - training loss: 0.2853, validation loss: 2.1615
2024-06-03 00:50:57 [INFO]: Epoch 066 - training loss: 0.2784, validation loss: 2.1617
2024-06-03 00:50:58 [INFO]: Epoch 067 - training loss: 0.2800, validation loss: 2.1626
2024-06-03 00:50:58 [INFO]: Epoch 068 - training loss: 0.2814, validation loss: 2.1608
2024-06-03 00:50:59 [INFO]: Epoch 069 - training loss: 0.2746, validation loss: 2.1612
2024-06-03 00:50:59 [INFO]: Epoch 070 - training loss: 0.2899, validation loss: 2.1617
2024-06-03 00:51:00 [INFO]: Epoch 071 - training loss: 0.2804, validation loss: 2.1624
2024-06-03 00:51:00 [INFO]: Epoch 072 - training loss: 0.2853, validation loss: 2.1609
2024-06-03 00:51:01 [INFO]: Epoch 073 - training loss: 0.2909, validation loss: 2.1603
2024-06-03 00:51:01 [INFO]: Epoch 074 - training loss: 0.2981, validation loss: 2.1602
2024-06-03 00:51:01 [INFO]: Epoch 075 - training loss: 0.3021, validation loss: 2.1624
2024-06-03 00:51:02 [INFO]: Epoch 076 - training loss: 0.2930, validation loss: 2.1591
2024-06-03 00:51:02 [INFO]: Epoch 077 - training loss: 0.2762, validation loss: 2.1588
2024-06-03 00:51:03 [INFO]: Epoch 078 - training loss: 0.2774, validation loss: 2.1595
2024-06-03 00:51:03 [INFO]: Epoch 079 - training loss: 0.2813, validation loss: 2.1588
2024-06-03 00:51:04 [INFO]: Epoch 080 - training loss: 0.2864, validation loss: 2.1604
2024-06-03 00:51:04 [INFO]: Epoch 081 - training loss: 0.2865, validation loss: 2.1592
2024-06-03 00:51:05 [INFO]: Epoch 082 - training loss: 0.2886, validation loss: 2.1581
2024-06-03 00:51:05 [INFO]: Epoch 083 - training loss: 0.2736, validation loss: 2.1593
2024-06-03 00:51:06 [INFO]: Epoch 084 - training loss: 0.2690, validation loss: 2.1589
2024-06-03 00:51:06 [INFO]: Epoch 085 - training loss: 0.2971, validation loss: 2.1593
2024-06-03 00:51:07 [INFO]: Epoch 086 - training loss: 0.2758, validation loss: 2.1594
2024-06-03 00:51:07 [INFO]: Epoch 087 - training loss: 0.2875, validation loss: 2.1597
2024-06-03 00:51:08 [INFO]: Epoch 088 - training loss: 0.2812, validation loss: 2.1586
2024-06-03 00:51:08 [INFO]: Epoch 089 - training loss: 0.2813, validation loss: 2.1594
2024-06-03 00:51:09 [INFO]: Epoch 090 - training loss: 0.2821, validation loss: 2.1591
2024-06-03 00:51:09 [INFO]: Epoch 091 - training loss: 0.2805, validation loss: 2.1596
2024-06-03 00:51:10 [INFO]: Epoch 092 - training loss: 0.2766, validation loss: 2.1585
2024-06-03 00:51:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:51:10 [INFO]: Finished training. The best model is from epoch#82.
2024-06-03 00:51:10 [INFO]: Saved the model to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_4/20240603_T004955/MRNN.pypots
2024-06-03 00:51:10 [INFO]: Successfully saved to results_point_rate09/ItalyAir/MRNN_ItalyAir/round_4/imputation.pkl
2024-06-03 00:51:10 [INFO]: Round4 - MRNN on ItalyAir: MAE=0.7589, MSE=1.4981, MRE=0.9973
2024-06-03 00:51:10 [INFO]: Done! Final results:
Averaged MRNN (402,111 params) on ItalyAir: MAE=0.7577 ± 0.0013737326494928596, MSE=1.4954 ± 0.0018722833133140344, MRE=0.9957 ± 0.0018052335703038357, average inference time=0.37
