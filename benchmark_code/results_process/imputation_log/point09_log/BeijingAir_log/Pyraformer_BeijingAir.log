2024-06-03 10:25:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:25:47 [INFO]: Using the given device: cuda:0
2024-06-03 10:25:47 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T102547
2024-06-03 10:25:47 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T102547/tensorboard
2024-06-03 10:25:49 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 10:26:03 [INFO]: Epoch 001 - training loss: 1.3119, validation loss: 0.6446
2024-06-03 10:26:07 [INFO]: Epoch 002 - training loss: 0.9613, validation loss: 0.5191
2024-06-03 10:26:12 [INFO]: Epoch 003 - training loss: 0.8640, validation loss: 0.4917
2024-06-03 10:26:16 [INFO]: Epoch 004 - training loss: 0.7989, validation loss: 0.4622
2024-06-03 10:26:20 [INFO]: Epoch 005 - training loss: 0.7551, validation loss: 0.4358
2024-06-03 10:26:25 [INFO]: Epoch 006 - training loss: 0.7188, validation loss: 0.4129
2024-06-03 10:26:29 [INFO]: Epoch 007 - training loss: 0.6790, validation loss: 0.4204
2024-06-03 10:26:33 [INFO]: Epoch 008 - training loss: 0.6663, validation loss: 0.4224
2024-06-03 10:26:38 [INFO]: Epoch 009 - training loss: 0.6422, validation loss: 0.3929
2024-06-03 10:26:42 [INFO]: Epoch 010 - training loss: 0.6321, validation loss: 0.3970
2024-06-03 10:26:46 [INFO]: Epoch 011 - training loss: 0.6042, validation loss: 0.3792
2024-06-03 10:26:50 [INFO]: Epoch 012 - training loss: 0.5970, validation loss: 0.3876
2024-06-03 10:26:55 [INFO]: Epoch 013 - training loss: 0.5811, validation loss: 0.3806
2024-06-03 10:26:59 [INFO]: Epoch 014 - training loss: 0.5560, validation loss: 0.3738
2024-06-03 10:27:04 [INFO]: Epoch 015 - training loss: 0.5560, validation loss: 0.3700
2024-06-03 10:27:08 [INFO]: Epoch 016 - training loss: 0.5438, validation loss: 0.3791
2024-06-03 10:27:12 [INFO]: Epoch 017 - training loss: 0.5435, validation loss: 0.3810
2024-06-03 10:27:17 [INFO]: Epoch 018 - training loss: 0.5375, validation loss: 0.3672
2024-06-03 10:27:20 [INFO]: Epoch 019 - training loss: 0.5290, validation loss: 0.3658
2024-06-03 10:27:25 [INFO]: Epoch 020 - training loss: 0.5190, validation loss: 0.3636
2024-06-03 10:27:29 [INFO]: Epoch 021 - training loss: 0.5099, validation loss: 0.3640
2024-06-03 10:27:34 [INFO]: Epoch 022 - training loss: 0.5164, validation loss: 0.3744
2024-06-03 10:27:38 [INFO]: Epoch 023 - training loss: 0.5188, validation loss: 0.3696
2024-06-03 10:27:42 [INFO]: Epoch 024 - training loss: 0.5046, validation loss: 0.3607
2024-06-03 10:27:46 [INFO]: Epoch 025 - training loss: 0.5090, validation loss: 0.3755
2024-06-03 10:27:51 [INFO]: Epoch 026 - training loss: 0.4977, validation loss: 0.3687
2024-06-03 10:27:55 [INFO]: Epoch 027 - training loss: 0.4929, validation loss: 0.3732
2024-06-03 10:28:00 [INFO]: Epoch 028 - training loss: 0.4895, validation loss: 0.3523
2024-06-03 10:28:05 [INFO]: Epoch 029 - training loss: 0.4968, validation loss: 0.3675
2024-06-03 10:28:09 [INFO]: Epoch 030 - training loss: 0.4822, validation loss: 0.3659
2024-06-03 10:28:13 [INFO]: Epoch 031 - training loss: 0.4941, validation loss: 0.3518
2024-06-03 10:28:17 [INFO]: Epoch 032 - training loss: 0.4750, validation loss: 0.3496
2024-06-03 10:28:21 [INFO]: Epoch 033 - training loss: 0.4706, validation loss: 0.3457
2024-06-03 10:28:25 [INFO]: Epoch 034 - training loss: 0.4674, validation loss: 0.3429
2024-06-03 10:28:29 [INFO]: Epoch 035 - training loss: 0.4600, validation loss: 0.3481
2024-06-03 10:28:33 [INFO]: Epoch 036 - training loss: 0.4654, validation loss: 0.3628
2024-06-03 10:28:38 [INFO]: Epoch 037 - training loss: 0.4585, validation loss: 0.3481
2024-06-03 10:28:42 [INFO]: Epoch 038 - training loss: 0.4699, validation loss: 0.3677
2024-06-03 10:28:46 [INFO]: Epoch 039 - training loss: 0.4597, validation loss: 0.3439
2024-06-03 10:28:51 [INFO]: Epoch 040 - training loss: 0.4618, validation loss: 0.3826
2024-06-03 10:28:55 [INFO]: Epoch 041 - training loss: 0.4636, validation loss: 0.3445
2024-06-03 10:28:59 [INFO]: Epoch 042 - training loss: 0.4519, validation loss: 0.3457
2024-06-03 10:29:03 [INFO]: Epoch 043 - training loss: 0.4540, validation loss: 0.3469
2024-06-03 10:29:08 [INFO]: Epoch 044 - training loss: 0.4425, validation loss: 0.3430
2024-06-03 10:29:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:29:08 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 10:29:08 [INFO]: Saved the model to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T102547/Pyraformer.pypots
2024-06-03 10:29:10 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_0/imputation.pkl
2024-06-03 10:29:10 [INFO]: Round0 - Pyraformer on BeijingAir: MAE=0.2828, MSE=0.3730, MRE=0.3809
2024-06-03 10:29:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:29:10 [INFO]: Using the given device: cuda:0
2024-06-03 10:29:10 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T102910
2024-06-03 10:29:10 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T102910/tensorboard
2024-06-03 10:29:10 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 10:29:14 [INFO]: Epoch 001 - training loss: 1.3195, validation loss: 0.6417
2024-06-03 10:29:19 [INFO]: Epoch 002 - training loss: 0.9549, validation loss: 0.5806
2024-06-03 10:29:22 [INFO]: Epoch 003 - training loss: 0.8655, validation loss: 0.4981
2024-06-03 10:29:27 [INFO]: Epoch 004 - training loss: 0.7937, validation loss: 0.4629
2024-06-03 10:29:31 [INFO]: Epoch 005 - training loss: 0.7684, validation loss: 0.4377
2024-06-03 10:29:36 [INFO]: Epoch 006 - training loss: 0.7227, validation loss: 0.4365
2024-06-03 10:29:40 [INFO]: Epoch 007 - training loss: 0.6928, validation loss: 0.4044
2024-06-03 10:29:44 [INFO]: Epoch 008 - training loss: 0.6753, validation loss: 0.4242
2024-06-03 10:29:49 [INFO]: Epoch 009 - training loss: 0.6592, validation loss: 0.3965
2024-06-03 10:29:53 [INFO]: Epoch 010 - training loss: 0.6170, validation loss: 0.3975
2024-06-03 10:29:57 [INFO]: Epoch 011 - training loss: 0.5980, validation loss: 0.3841
2024-06-03 10:30:01 [INFO]: Epoch 012 - training loss: 0.5893, validation loss: 0.3705
2024-06-03 10:30:06 [INFO]: Epoch 013 - training loss: 0.5822, validation loss: 0.3809
2024-06-03 10:30:10 [INFO]: Epoch 014 - training loss: 0.5765, validation loss: 0.3781
2024-06-03 10:30:14 [INFO]: Epoch 015 - training loss: 0.5700, validation loss: 0.3767
2024-06-03 10:30:18 [INFO]: Epoch 016 - training loss: 0.5621, validation loss: 0.3734
2024-06-03 10:30:22 [INFO]: Epoch 017 - training loss: 0.5528, validation loss: 0.3747
2024-06-03 10:30:27 [INFO]: Epoch 018 - training loss: 0.5493, validation loss: 0.3657
2024-06-03 10:30:31 [INFO]: Epoch 019 - training loss: 0.5308, validation loss: 0.3968
2024-06-03 10:30:35 [INFO]: Epoch 020 - training loss: 0.5372, validation loss: 0.3652
2024-06-03 10:30:39 [INFO]: Epoch 021 - training loss: 0.5261, validation loss: 0.3623
2024-06-03 10:30:43 [INFO]: Epoch 022 - training loss: 0.5110, validation loss: 0.3798
2024-06-03 10:30:48 [INFO]: Epoch 023 - training loss: 0.5053, validation loss: 0.3807
2024-06-03 10:30:52 [INFO]: Epoch 024 - training loss: 0.5212, validation loss: 0.3701
2024-06-03 10:30:56 [INFO]: Epoch 025 - training loss: 0.5097, validation loss: 0.3558
2024-06-03 10:31:00 [INFO]: Epoch 026 - training loss: 0.5047, validation loss: 0.3627
2024-06-03 10:31:04 [INFO]: Epoch 027 - training loss: 0.4927, validation loss: 0.3833
2024-06-03 10:31:09 [INFO]: Epoch 028 - training loss: 0.5062, validation loss: 0.3588
2024-06-03 10:31:13 [INFO]: Epoch 029 - training loss: 0.4901, validation loss: 0.3544
2024-06-03 10:31:17 [INFO]: Epoch 030 - training loss: 0.4846, validation loss: 0.3651
2024-06-03 10:31:22 [INFO]: Epoch 031 - training loss: 0.4904, validation loss: 0.3551
2024-06-03 10:31:26 [INFO]: Epoch 032 - training loss: 0.4818, validation loss: 0.3661
2024-06-03 10:31:30 [INFO]: Epoch 033 - training loss: 0.4739, validation loss: 0.3553
2024-06-03 10:31:35 [INFO]: Epoch 034 - training loss: 0.4759, validation loss: 0.3537
2024-06-03 10:31:39 [INFO]: Epoch 035 - training loss: 0.4668, validation loss: 0.3602
2024-06-03 10:31:44 [INFO]: Epoch 036 - training loss: 0.4722, validation loss: 0.3508
2024-06-03 10:31:48 [INFO]: Epoch 037 - training loss: 0.4608, validation loss: 0.3540
2024-06-03 10:31:53 [INFO]: Epoch 038 - training loss: 0.4571, validation loss: 0.3578
2024-06-03 10:31:57 [INFO]: Epoch 039 - training loss: 0.4576, validation loss: 0.3588
2024-06-03 10:32:01 [INFO]: Epoch 040 - training loss: 0.4734, validation loss: 0.3638
2024-06-03 10:32:06 [INFO]: Epoch 041 - training loss: 0.4629, validation loss: 0.3559
2024-06-03 10:32:10 [INFO]: Epoch 042 - training loss: 0.4557, validation loss: 0.3547
2024-06-03 10:32:15 [INFO]: Epoch 043 - training loss: 0.4534, validation loss: 0.3501
2024-06-03 10:32:19 [INFO]: Epoch 044 - training loss: 0.4503, validation loss: 0.3552
2024-06-03 10:32:23 [INFO]: Epoch 045 - training loss: 0.4466, validation loss: 0.3528
2024-06-03 10:32:28 [INFO]: Epoch 046 - training loss: 0.4389, validation loss: 0.3533
2024-06-03 10:32:32 [INFO]: Epoch 047 - training loss: 0.4435, validation loss: 0.3441
2024-06-03 10:32:36 [INFO]: Epoch 048 - training loss: 0.4403, validation loss: 0.3477
2024-06-03 10:32:41 [INFO]: Epoch 049 - training loss: 0.4411, validation loss: 0.3420
2024-06-03 10:32:45 [INFO]: Epoch 050 - training loss: 0.4317, validation loss: 0.3446
2024-06-03 10:32:49 [INFO]: Epoch 051 - training loss: 0.4299, validation loss: 0.3427
2024-06-03 10:32:53 [INFO]: Epoch 052 - training loss: 0.4330, validation loss: 0.3652
2024-06-03 10:32:57 [INFO]: Epoch 053 - training loss: 0.4319, validation loss: 0.3462
2024-06-03 10:33:01 [INFO]: Epoch 054 - training loss: 0.4358, validation loss: 0.3421
2024-06-03 10:33:05 [INFO]: Epoch 055 - training loss: 0.4325, validation loss: 0.3416
2024-06-03 10:33:09 [INFO]: Epoch 056 - training loss: 0.4300, validation loss: 0.3412
2024-06-03 10:33:14 [INFO]: Epoch 057 - training loss: 0.4233, validation loss: 0.3392
2024-06-03 10:33:18 [INFO]: Epoch 058 - training loss: 0.4343, validation loss: 0.3549
2024-06-03 10:33:23 [INFO]: Epoch 059 - training loss: 0.4277, validation loss: 0.3415
2024-06-03 10:33:27 [INFO]: Epoch 060 - training loss: 0.4212, validation loss: 0.3340
2024-06-03 10:33:31 [INFO]: Epoch 061 - training loss: 0.4180, validation loss: 0.3302
2024-06-03 10:33:35 [INFO]: Epoch 062 - training loss: 0.4194, validation loss: 0.3293
2024-06-03 10:33:37 [INFO]: Epoch 063 - training loss: 0.4187, validation loss: 0.3438
2024-06-03 10:33:41 [INFO]: Epoch 064 - training loss: 0.4187, validation loss: 0.3469
2024-06-03 10:33:44 [INFO]: Epoch 065 - training loss: 0.4141, validation loss: 0.3496
2024-06-03 10:33:47 [INFO]: Epoch 066 - training loss: 0.4117, validation loss: 0.3449
2024-06-03 10:33:51 [INFO]: Epoch 067 - training loss: 0.4085, validation loss: 0.3325
2024-06-03 10:33:55 [INFO]: Epoch 068 - training loss: 0.4120, validation loss: 0.3419
2024-06-03 10:33:59 [INFO]: Epoch 069 - training loss: 0.4141, validation loss: 0.3434
2024-06-03 10:34:03 [INFO]: Epoch 070 - training loss: 0.4119, validation loss: 0.3552
2024-06-03 10:34:08 [INFO]: Epoch 071 - training loss: 0.4195, validation loss: 0.3426
2024-06-03 10:34:12 [INFO]: Epoch 072 - training loss: 0.4127, validation loss: 0.3376
2024-06-03 10:34:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:34:12 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 10:34:12 [INFO]: Saved the model to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T102910/Pyraformer.pypots
2024-06-03 10:34:14 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_1/imputation.pkl
2024-06-03 10:34:14 [INFO]: Round1 - Pyraformer on BeijingAir: MAE=0.2718, MSE=0.3699, MRE=0.3661
2024-06-03 10:34:14 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:34:14 [INFO]: Using the given device: cuda:0
2024-06-03 10:34:14 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T103414
2024-06-03 10:34:14 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T103414/tensorboard
2024-06-03 10:34:14 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 10:34:19 [INFO]: Epoch 001 - training loss: 1.3261, validation loss: 0.6642
2024-06-03 10:34:23 [INFO]: Epoch 002 - training loss: 1.0240, validation loss: 0.5706
2024-06-03 10:34:27 [INFO]: Epoch 003 - training loss: 0.8864, validation loss: 0.4776
2024-06-03 10:34:31 [INFO]: Epoch 004 - training loss: 0.8136, validation loss: 0.4571
2024-06-03 10:34:36 [INFO]: Epoch 005 - training loss: 0.7490, validation loss: 0.4385
2024-06-03 10:34:40 [INFO]: Epoch 006 - training loss: 0.7240, validation loss: 0.4601
2024-06-03 10:34:44 [INFO]: Epoch 007 - training loss: 0.7123, validation loss: 0.4061
2024-06-03 10:34:48 [INFO]: Epoch 008 - training loss: 0.6675, validation loss: 0.4156
2024-06-03 10:34:52 [INFO]: Epoch 009 - training loss: 0.6765, validation loss: 0.3969
2024-06-03 10:34:56 [INFO]: Epoch 010 - training loss: 0.6316, validation loss: 0.3955
2024-06-03 10:35:01 [INFO]: Epoch 011 - training loss: 0.6153, validation loss: 0.3780
2024-06-03 10:35:05 [INFO]: Epoch 012 - training loss: 0.5970, validation loss: 0.3858
2024-06-03 10:35:09 [INFO]: Epoch 013 - training loss: 0.5883, validation loss: 0.3910
2024-06-03 10:35:13 [INFO]: Epoch 014 - training loss: 0.5842, validation loss: 0.3744
2024-06-03 10:35:18 [INFO]: Epoch 015 - training loss: 0.5748, validation loss: 0.3740
2024-06-03 10:35:22 [INFO]: Epoch 016 - training loss: 0.5633, validation loss: 0.3768
2024-06-03 10:35:27 [INFO]: Epoch 017 - training loss: 0.5612, validation loss: 0.3672
2024-06-03 10:35:31 [INFO]: Epoch 018 - training loss: 0.5575, validation loss: 0.3726
2024-06-03 10:35:35 [INFO]: Epoch 019 - training loss: 0.5408, validation loss: 0.3684
2024-06-03 10:35:39 [INFO]: Epoch 020 - training loss: 0.5380, validation loss: 0.3676
2024-06-03 10:35:44 [INFO]: Epoch 021 - training loss: 0.5344, validation loss: 0.3666
2024-06-03 10:35:48 [INFO]: Epoch 022 - training loss: 0.5270, validation loss: 0.3630
2024-06-03 10:35:52 [INFO]: Epoch 023 - training loss: 0.5245, validation loss: 0.4001
2024-06-03 10:35:56 [INFO]: Epoch 024 - training loss: 0.5173, validation loss: 0.3712
2024-06-03 10:36:01 [INFO]: Epoch 025 - training loss: 0.5091, validation loss: 0.3633
2024-06-03 10:36:05 [INFO]: Epoch 026 - training loss: 0.5126, validation loss: 0.3546
2024-06-03 10:36:09 [INFO]: Epoch 027 - training loss: 0.5069, validation loss: 0.3564
2024-06-03 10:36:13 [INFO]: Epoch 028 - training loss: 0.5001, validation loss: 0.3726
2024-06-03 10:36:18 [INFO]: Epoch 029 - training loss: 0.4949, validation loss: 0.3521
2024-06-03 10:36:22 [INFO]: Epoch 030 - training loss: 0.4875, validation loss: 0.3685
2024-06-03 10:36:26 [INFO]: Epoch 031 - training loss: 0.4839, validation loss: 0.3633
2024-06-03 10:36:30 [INFO]: Epoch 032 - training loss: 0.4965, validation loss: 0.3702
2024-06-03 10:36:35 [INFO]: Epoch 033 - training loss: 0.4797, validation loss: 0.3652
2024-06-03 10:36:39 [INFO]: Epoch 034 - training loss: 0.4824, validation loss: 0.3579
2024-06-03 10:36:43 [INFO]: Epoch 035 - training loss: 0.4672, validation loss: 0.3570
2024-06-03 10:36:48 [INFO]: Epoch 036 - training loss: 0.4740, validation loss: 0.3679
2024-06-03 10:36:52 [INFO]: Epoch 037 - training loss: 0.4834, validation loss: 0.3470
2024-06-03 10:36:56 [INFO]: Epoch 038 - training loss: 0.4637, validation loss: 0.3543
2024-06-03 10:37:01 [INFO]: Epoch 039 - training loss: 0.4635, validation loss: 0.3465
2024-06-03 10:37:05 [INFO]: Epoch 040 - training loss: 0.4636, validation loss: 0.3442
2024-06-03 10:37:09 [INFO]: Epoch 041 - training loss: 0.4570, validation loss: 0.3687
2024-06-03 10:37:13 [INFO]: Epoch 042 - training loss: 0.4634, validation loss: 0.3520
2024-06-03 10:37:18 [INFO]: Epoch 043 - training loss: 0.4529, validation loss: 0.3526
2024-06-03 10:37:22 [INFO]: Epoch 044 - training loss: 0.4434, validation loss: 0.3516
2024-06-03 10:37:26 [INFO]: Epoch 045 - training loss: 0.4526, validation loss: 0.3412
2024-06-03 10:37:31 [INFO]: Epoch 046 - training loss: 0.4492, validation loss: 0.3425
2024-06-03 10:37:35 [INFO]: Epoch 047 - training loss: 0.4540, validation loss: 0.3639
2024-06-03 10:37:39 [INFO]: Epoch 048 - training loss: 0.4534, validation loss: 0.3447
2024-06-03 10:37:43 [INFO]: Epoch 049 - training loss: 0.4462, validation loss: 0.3501
2024-06-03 10:37:47 [INFO]: Epoch 050 - training loss: 0.4461, validation loss: 0.3539
2024-06-03 10:37:51 [INFO]: Epoch 051 - training loss: 0.4416, validation loss: 0.3520
2024-06-03 10:37:55 [INFO]: Epoch 052 - training loss: 0.4362, validation loss: 0.3400
2024-06-03 10:37:59 [INFO]: Epoch 053 - training loss: 0.4433, validation loss: 0.3517
2024-06-03 10:38:03 [INFO]: Epoch 054 - training loss: 0.4438, validation loss: 0.3469
2024-06-03 10:38:08 [INFO]: Epoch 055 - training loss: 0.4356, validation loss: 0.3377
2024-06-03 10:38:11 [INFO]: Epoch 056 - training loss: 0.4356, validation loss: 0.3373
2024-06-03 10:38:15 [INFO]: Epoch 057 - training loss: 0.4289, validation loss: 0.3436
2024-06-03 10:38:19 [INFO]: Epoch 058 - training loss: 0.4374, validation loss: 0.3529
2024-06-03 10:38:23 [INFO]: Epoch 059 - training loss: 0.4332, validation loss: 0.3411
2024-06-03 10:38:27 [INFO]: Epoch 060 - training loss: 0.4261, validation loss: 0.3379
2024-06-03 10:38:31 [INFO]: Epoch 061 - training loss: 0.4241, validation loss: 0.3376
2024-06-03 10:38:35 [INFO]: Epoch 062 - training loss: 0.4204, validation loss: 0.3413
2024-06-03 10:38:39 [INFO]: Epoch 063 - training loss: 0.4212, validation loss: 0.3411
2024-06-03 10:38:43 [INFO]: Epoch 064 - training loss: 0.4207, validation loss: 0.3348
2024-06-03 10:38:47 [INFO]: Epoch 065 - training loss: 0.4143, validation loss: 0.3359
2024-06-03 10:38:51 [INFO]: Epoch 066 - training loss: 0.4173, validation loss: 0.3370
2024-06-03 10:38:55 [INFO]: Epoch 067 - training loss: 0.4243, validation loss: 0.3420
2024-06-03 10:38:59 [INFO]: Epoch 068 - training loss: 0.4138, validation loss: 0.3429
2024-06-03 10:39:03 [INFO]: Epoch 069 - training loss: 0.4157, validation loss: 0.3397
2024-06-03 10:39:07 [INFO]: Epoch 070 - training loss: 0.4116, validation loss: 0.3391
2024-06-03 10:39:11 [INFO]: Epoch 071 - training loss: 0.4072, validation loss: 0.3353
2024-06-03 10:39:14 [INFO]: Epoch 072 - training loss: 0.4168, validation loss: 0.3449
2024-06-03 10:39:18 [INFO]: Epoch 073 - training loss: 0.4076, validation loss: 0.3356
2024-06-03 10:39:22 [INFO]: Epoch 074 - training loss: 0.4070, validation loss: 0.3361
2024-06-03 10:39:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:39:22 [INFO]: Finished training. The best model is from epoch#64.
2024-06-03 10:39:22 [INFO]: Saved the model to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T103414/Pyraformer.pypots
2024-06-03 10:39:24 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_2/imputation.pkl
2024-06-03 10:39:24 [INFO]: Round2 - Pyraformer on BeijingAir: MAE=0.2754, MSE=0.3709, MRE=0.3708
2024-06-03 10:39:24 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:39:24 [INFO]: Using the given device: cuda:0
2024-06-03 10:39:24 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T103924
2024-06-03 10:39:24 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T103924/tensorboard
2024-06-03 10:39:24 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 10:39:28 [INFO]: Epoch 001 - training loss: 1.2795, validation loss: 0.5960
2024-06-03 10:39:32 [INFO]: Epoch 002 - training loss: 0.9797, validation loss: 0.5346
2024-06-03 10:39:35 [INFO]: Epoch 003 - training loss: 0.8550, validation loss: 0.4726
2024-06-03 10:39:39 [INFO]: Epoch 004 - training loss: 0.7859, validation loss: 0.4851
2024-06-03 10:39:43 [INFO]: Epoch 005 - training loss: 0.7447, validation loss: 0.4250
2024-06-03 10:39:47 [INFO]: Epoch 006 - training loss: 0.7348, validation loss: 0.4375
2024-06-03 10:39:50 [INFO]: Epoch 007 - training loss: 0.6894, validation loss: 0.4173
2024-06-03 10:39:54 [INFO]: Epoch 008 - training loss: 0.6921, validation loss: 0.4030
2024-06-03 10:39:58 [INFO]: Epoch 009 - training loss: 0.6559, validation loss: 0.3975
2024-06-03 10:40:02 [INFO]: Epoch 010 - training loss: 0.6231, validation loss: 0.3983
2024-06-03 10:40:06 [INFO]: Epoch 011 - training loss: 0.6099, validation loss: 0.3854
2024-06-03 10:40:10 [INFO]: Epoch 012 - training loss: 0.5937, validation loss: 0.3896
2024-06-03 10:40:14 [INFO]: Epoch 013 - training loss: 0.5853, validation loss: 0.3836
2024-06-03 10:40:18 [INFO]: Epoch 014 - training loss: 0.5804, validation loss: 0.3695
2024-06-03 10:40:21 [INFO]: Epoch 015 - training loss: 0.5608, validation loss: 0.3734
2024-06-03 10:40:25 [INFO]: Epoch 016 - training loss: 0.5546, validation loss: 0.3830
2024-06-03 10:40:29 [INFO]: Epoch 017 - training loss: 0.5588, validation loss: 0.3760
2024-06-03 10:40:33 [INFO]: Epoch 018 - training loss: 0.5456, validation loss: 0.3654
2024-06-03 10:40:37 [INFO]: Epoch 019 - training loss: 0.5287, validation loss: 0.3635
2024-06-03 10:40:41 [INFO]: Epoch 020 - training loss: 0.5342, validation loss: 0.3841
2024-06-03 10:40:45 [INFO]: Epoch 021 - training loss: 0.5292, validation loss: 0.3693
2024-06-03 10:40:49 [INFO]: Epoch 022 - training loss: 0.5193, validation loss: 0.3607
2024-06-03 10:40:53 [INFO]: Epoch 023 - training loss: 0.5123, validation loss: 0.3646
2024-06-03 10:40:57 [INFO]: Epoch 024 - training loss: 0.5116, validation loss: 0.3639
2024-06-03 10:41:01 [INFO]: Epoch 025 - training loss: 0.5092, validation loss: 0.3652
2024-06-03 10:41:05 [INFO]: Epoch 026 - training loss: 0.4996, validation loss: 0.3826
2024-06-03 10:41:09 [INFO]: Epoch 027 - training loss: 0.4916, validation loss: 0.3599
2024-06-03 10:41:13 [INFO]: Epoch 028 - training loss: 0.4945, validation loss: 0.3675
2024-06-03 10:41:17 [INFO]: Epoch 029 - training loss: 0.4872, validation loss: 0.3644
2024-06-03 10:41:21 [INFO]: Epoch 030 - training loss: 0.4821, validation loss: 0.3624
2024-06-03 10:41:24 [INFO]: Epoch 031 - training loss: 0.4845, validation loss: 0.3662
2024-06-03 10:41:28 [INFO]: Epoch 032 - training loss: 0.4824, validation loss: 0.3564
2024-06-03 10:41:32 [INFO]: Epoch 033 - training loss: 0.4826, validation loss: 0.3630
2024-06-03 10:41:36 [INFO]: Epoch 034 - training loss: 0.4766, validation loss: 0.3523
2024-06-03 10:41:40 [INFO]: Epoch 035 - training loss: 0.4672, validation loss: 0.3453
2024-06-03 10:41:43 [INFO]: Epoch 036 - training loss: 0.4707, validation loss: 0.3614
2024-06-03 10:41:47 [INFO]: Epoch 037 - training loss: 0.4534, validation loss: 0.3468
2024-06-03 10:41:51 [INFO]: Epoch 038 - training loss: 0.4539, validation loss: 0.3365
2024-06-03 10:41:54 [INFO]: Epoch 039 - training loss: 0.4559, validation loss: 0.3487
2024-06-03 10:41:58 [INFO]: Epoch 040 - training loss: 0.4566, validation loss: 0.3453
2024-06-03 10:42:02 [INFO]: Epoch 041 - training loss: 0.4554, validation loss: 0.3406
2024-06-03 10:42:06 [INFO]: Epoch 042 - training loss: 0.4493, validation loss: 0.3600
2024-06-03 10:42:10 [INFO]: Epoch 043 - training loss: 0.4559, validation loss: 0.3627
2024-06-03 10:42:14 [INFO]: Epoch 044 - training loss: 0.4586, validation loss: 0.3724
2024-06-03 10:42:18 [INFO]: Epoch 045 - training loss: 0.4552, validation loss: 0.3589
2024-06-03 10:42:21 [INFO]: Epoch 046 - training loss: 0.4469, validation loss: 0.3427
2024-06-03 10:42:25 [INFO]: Epoch 047 - training loss: 0.4480, validation loss: 0.3467
2024-06-03 10:42:29 [INFO]: Epoch 048 - training loss: 0.4456, validation loss: 0.3607
2024-06-03 10:42:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:42:29 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 10:42:29 [INFO]: Saved the model to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T103924/Pyraformer.pypots
2024-06-03 10:42:31 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_3/imputation.pkl
2024-06-03 10:42:31 [INFO]: Round3 - Pyraformer on BeijingAir: MAE=0.2843, MSE=0.3896, MRE=0.3829
2024-06-03 10:42:31 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:42:31 [INFO]: Using the given device: cuda:0
2024-06-03 10:42:31 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T104231
2024-06-03 10:42:31 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T104231/tensorboard
2024-06-03 10:42:31 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 10:42:35 [INFO]: Epoch 001 - training loss: 1.3034, validation loss: 0.6615
2024-06-03 10:42:38 [INFO]: Epoch 002 - training loss: 1.0021, validation loss: 0.5494
2024-06-03 10:42:41 [INFO]: Epoch 003 - training loss: 0.9301, validation loss: 0.5199
2024-06-03 10:42:45 [INFO]: Epoch 004 - training loss: 0.8180, validation loss: 0.4616
2024-06-03 10:42:47 [INFO]: Epoch 005 - training loss: 0.7926, validation loss: 0.4706
2024-06-03 10:42:49 [INFO]: Epoch 006 - training loss: 0.7516, validation loss: 0.4279
2024-06-03 10:42:52 [INFO]: Epoch 007 - training loss: 0.6980, validation loss: 0.4233
2024-06-03 10:42:54 [INFO]: Epoch 008 - training loss: 0.6859, validation loss: 0.4052
2024-06-03 10:42:56 [INFO]: Epoch 009 - training loss: 0.6429, validation loss: 0.4411
2024-06-03 10:42:59 [INFO]: Epoch 010 - training loss: 0.6621, validation loss: 0.4002
2024-06-03 10:43:02 [INFO]: Epoch 011 - training loss: 0.6235, validation loss: 0.3867
2024-06-03 10:43:05 [INFO]: Epoch 012 - training loss: 0.6028, validation loss: 0.3860
2024-06-03 10:43:09 [INFO]: Epoch 013 - training loss: 0.5827, validation loss: 0.3715
2024-06-03 10:43:12 [INFO]: Epoch 014 - training loss: 0.5762, validation loss: 0.3728
2024-06-03 10:43:15 [INFO]: Epoch 015 - training loss: 0.5714, validation loss: 0.3786
2024-06-03 10:43:18 [INFO]: Epoch 016 - training loss: 0.5597, validation loss: 0.3707
2024-06-03 10:43:21 [INFO]: Epoch 017 - training loss: 0.5575, validation loss: 0.3676
2024-06-03 10:43:25 [INFO]: Epoch 018 - training loss: 0.5395, validation loss: 0.3622
2024-06-03 10:43:28 [INFO]: Epoch 019 - training loss: 0.5395, validation loss: 0.3647
2024-06-03 10:43:32 [INFO]: Epoch 020 - training loss: 0.5331, validation loss: 0.3725
2024-06-03 10:43:35 [INFO]: Epoch 021 - training loss: 0.5252, validation loss: 0.3843
2024-06-03 10:43:38 [INFO]: Epoch 022 - training loss: 0.5171, validation loss: 0.3621
2024-06-03 10:43:41 [INFO]: Epoch 023 - training loss: 0.5224, validation loss: 0.3733
2024-06-03 10:43:44 [INFO]: Epoch 024 - training loss: 0.5138, validation loss: 0.3617
2024-06-03 10:43:48 [INFO]: Epoch 025 - training loss: 0.4994, validation loss: 0.3589
2024-06-03 10:43:51 [INFO]: Epoch 026 - training loss: 0.5095, validation loss: 0.3674
2024-06-03 10:43:54 [INFO]: Epoch 027 - training loss: 0.5139, validation loss: 0.3801
2024-06-03 10:43:58 [INFO]: Epoch 028 - training loss: 0.5070, validation loss: 0.3865
2024-06-03 10:44:01 [INFO]: Epoch 029 - training loss: 0.4997, validation loss: 0.3684
2024-06-03 10:44:04 [INFO]: Epoch 030 - training loss: 0.4866, validation loss: 0.3658
2024-06-03 10:44:07 [INFO]: Epoch 031 - training loss: 0.4887, validation loss: 0.3566
2024-06-03 10:44:10 [INFO]: Epoch 032 - training loss: 0.4769, validation loss: 0.3624
2024-06-03 10:44:14 [INFO]: Epoch 033 - training loss: 0.4757, validation loss: 0.3498
2024-06-03 10:44:17 [INFO]: Epoch 034 - training loss: 0.4819, validation loss: 0.3540
2024-06-03 10:44:20 [INFO]: Epoch 035 - training loss: 0.4744, validation loss: 0.3477
2024-06-03 10:44:24 [INFO]: Epoch 036 - training loss: 0.4724, validation loss: 0.3580
2024-06-03 10:44:27 [INFO]: Epoch 037 - training loss: 0.4685, validation loss: 0.3596
2024-06-03 10:44:30 [INFO]: Epoch 038 - training loss: 0.4724, validation loss: 0.3438
2024-06-03 10:44:33 [INFO]: Epoch 039 - training loss: 0.4610, validation loss: 0.3528
2024-06-03 10:44:36 [INFO]: Epoch 040 - training loss: 0.4632, validation loss: 0.3504
2024-06-03 10:44:40 [INFO]: Epoch 041 - training loss: 0.4623, validation loss: 0.3456
2024-06-03 10:44:43 [INFO]: Epoch 042 - training loss: 0.4620, validation loss: 0.3560
2024-06-03 10:44:46 [INFO]: Epoch 043 - training loss: 0.4540, validation loss: 0.3411
2024-06-03 10:44:49 [INFO]: Epoch 044 - training loss: 0.4500, validation loss: 0.3496
2024-06-03 10:44:53 [INFO]: Epoch 045 - training loss: 0.4478, validation loss: 0.3435
2024-06-03 10:44:56 [INFO]: Epoch 046 - training loss: 0.4442, validation loss: 0.3361
2024-06-03 10:44:59 [INFO]: Epoch 047 - training loss: 0.4429, validation loss: 0.3457
2024-06-03 10:45:02 [INFO]: Epoch 048 - training loss: 0.4411, validation loss: 0.3470
2024-06-03 10:45:05 [INFO]: Epoch 049 - training loss: 0.4334, validation loss: 0.3512
2024-06-03 10:45:09 [INFO]: Epoch 050 - training loss: 0.4351, validation loss: 0.3405
2024-06-03 10:45:12 [INFO]: Epoch 051 - training loss: 0.4353, validation loss: 0.3540
2024-06-03 10:45:15 [INFO]: Epoch 052 - training loss: 0.4335, validation loss: 0.3370
2024-06-03 10:45:18 [INFO]: Epoch 053 - training loss: 0.4316, validation loss: 0.3495
2024-06-03 10:45:22 [INFO]: Epoch 054 - training loss: 0.4375, validation loss: 0.3387
2024-06-03 10:45:25 [INFO]: Epoch 055 - training loss: 0.4468, validation loss: 0.3649
2024-06-03 10:45:28 [INFO]: Epoch 056 - training loss: 0.4358, validation loss: 0.3443
2024-06-03 10:45:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:45:28 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 10:45:28 [INFO]: Saved the model to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T104231/Pyraformer.pypots
2024-06-03 10:45:30 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Pyraformer_BeijingAir/round_4/imputation.pkl
2024-06-03 10:45:30 [INFO]: Round4 - Pyraformer on BeijingAir: MAE=0.2802, MSE=0.3715, MRE=0.3774
2024-06-03 10:45:30 [INFO]: Done! Final results:
Averaged Pyraformer (3,230,212 params) on BeijingAir: MAE=0.2742 ± 0.0050313906895400285, MSE=0.3716 ± 0.008076772509020268, MRE=0.3638 ± 0.006674801147750147, average inference time=0.32