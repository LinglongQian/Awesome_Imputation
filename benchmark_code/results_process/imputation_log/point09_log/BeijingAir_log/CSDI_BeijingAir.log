2024-06-03 00:37:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:37:47 [INFO]: Using the given device: cuda:0
2024-06-03 00:37:47 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_0/20240603_T003747
2024-06-03 00:37:47 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_0/20240603_T003747/tensorboard
2024-06-03 00:37:47 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 00:39:13 [INFO]: Epoch 001 - training loss: 0.5934, validation loss: 0.4276
2024-06-03 00:40:33 [INFO]: Epoch 002 - training loss: 0.4407, validation loss: 0.3628
2024-06-03 00:41:53 [INFO]: Epoch 003 - training loss: 0.3763, validation loss: 0.3512
2024-06-03 00:43:12 [INFO]: Epoch 004 - training loss: 0.4394, validation loss: 0.3366
2024-06-03 00:44:31 [INFO]: Epoch 005 - training loss: 0.3766, validation loss: 0.3294
2024-06-03 00:45:50 [INFO]: Epoch 006 - training loss: 0.3794, validation loss: 0.3232
2024-06-03 00:47:10 [INFO]: Epoch 007 - training loss: 0.3610, validation loss: 0.3434
2024-06-03 00:48:29 [INFO]: Epoch 008 - training loss: 0.3569, validation loss: 0.3141
2024-06-03 00:49:48 [INFO]: Epoch 009 - training loss: 0.3439, validation loss: 0.3112
2024-06-03 00:51:05 [INFO]: Epoch 010 - training loss: 0.3730, validation loss: 0.3155
2024-06-03 00:52:20 [INFO]: Epoch 011 - training loss: 0.3591, validation loss: 0.3054
2024-06-03 00:53:34 [INFO]: Epoch 012 - training loss: 0.3339, validation loss: 0.3213
2024-06-03 00:54:49 [INFO]: Epoch 013 - training loss: 0.3400, validation loss: 0.2958
2024-06-03 00:56:04 [INFO]: Epoch 014 - training loss: 0.3377, validation loss: 0.3331
2024-06-03 00:57:19 [INFO]: Epoch 015 - training loss: 0.3251, validation loss: 0.3492
2024-06-03 00:58:34 [INFO]: Epoch 016 - training loss: 0.3153, validation loss: 0.3487
2024-06-03 00:59:49 [INFO]: Epoch 017 - training loss: 0.3211, validation loss: 0.3015
2024-06-03 01:01:04 [INFO]: Epoch 018 - training loss: 0.3347, validation loss: 0.3175
2024-06-03 01:02:18 [INFO]: Epoch 019 - training loss: 0.3433, validation loss: 0.3279
2024-06-03 01:03:32 [INFO]: Epoch 020 - training loss: 0.3020, validation loss: 0.3416
2024-06-03 01:04:44 [INFO]: Epoch 021 - training loss: 0.3206, validation loss: 0.3309
2024-06-03 01:05:56 [INFO]: Epoch 022 - training loss: 0.2900, validation loss: 0.3372
2024-06-03 01:07:07 [INFO]: Epoch 023 - training loss: 0.3031, validation loss: 0.3277
2024-06-03 01:07:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:07:07 [INFO]: Finished training. The best model is from epoch#13.
2024-06-03 01:07:07 [INFO]: Saved the model to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_0/20240603_T003747/CSDI.pypots
2024-06-03 01:52:20 [INFO]: Successfully saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_0/imputation.pkl
2024-06-03 01:52:20 [INFO]: Round0 - CSDI on BeijingAir: MAE=0.6390, MSE=1.7708, MRE=0.8605
2024-06-03 01:52:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:52:20 [INFO]: Using the given device: cuda:0
2024-06-03 01:52:20 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_1/20240603_T015220
2024-06-03 01:52:20 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_1/20240603_T015220/tensorboard
2024-06-03 01:52:20 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 01:53:28 [INFO]: Epoch 001 - training loss: 0.5520, validation loss: 0.4121
2024-06-03 01:54:36 [INFO]: Epoch 002 - training loss: 0.4087, validation loss: 0.3554
2024-06-03 01:55:45 [INFO]: Epoch 003 - training loss: 0.4110, validation loss: 0.3594
2024-06-03 01:56:54 [INFO]: Epoch 004 - training loss: 0.3972, validation loss: 0.3441
2024-06-03 01:58:02 [INFO]: Epoch 005 - training loss: 0.3760, validation loss: 0.3251
2024-06-03 01:59:11 [INFO]: Epoch 006 - training loss: 0.3633, validation loss: 0.3854
2024-06-03 02:00:20 [INFO]: Epoch 007 - training loss: 0.3677, validation loss: 0.3177
2024-06-03 02:01:28 [INFO]: Epoch 008 - training loss: 0.3348, validation loss: 0.3132
2024-06-03 02:02:37 [INFO]: Epoch 009 - training loss: 0.3342, validation loss: 0.3145
2024-06-03 02:03:45 [INFO]: Epoch 010 - training loss: 0.3337, validation loss: 0.3111
2024-06-03 02:04:54 [INFO]: Epoch 011 - training loss: 0.3478, validation loss: 0.3027
2024-06-03 02:06:02 [INFO]: Epoch 012 - training loss: 0.3221, validation loss: 0.3143
2024-06-03 02:07:10 [INFO]: Epoch 013 - training loss: 0.3077, validation loss: 0.3001
2024-06-03 02:08:19 [INFO]: Epoch 014 - training loss: 0.3343, validation loss: 0.3010
2024-06-03 02:09:27 [INFO]: Epoch 015 - training loss: 0.3133, validation loss: 0.3069
2024-06-03 02:10:36 [INFO]: Epoch 016 - training loss: 0.3012, validation loss: 0.3109
2024-06-03 02:11:44 [INFO]: Epoch 017 - training loss: 0.3129, validation loss: 0.2985
2024-06-03 02:12:53 [INFO]: Epoch 018 - training loss: 0.3036, validation loss: 0.2934
2024-06-03 02:14:01 [INFO]: Epoch 019 - training loss: 0.3105, validation loss: 0.2913
2024-06-03 02:15:06 [INFO]: Epoch 020 - training loss: 0.3077, validation loss: 0.3226
2024-06-03 02:16:10 [INFO]: Epoch 021 - training loss: 0.3193, validation loss: 0.2870
2024-06-03 02:17:14 [INFO]: Epoch 022 - training loss: 0.3211, validation loss: 0.2994
2024-06-03 02:18:17 [INFO]: Epoch 023 - training loss: 0.3088, validation loss: 0.3084
2024-06-03 02:19:21 [INFO]: Epoch 024 - training loss: 0.2894, validation loss: 0.2963
2024-06-03 02:20:24 [INFO]: Epoch 025 - training loss: 0.2979, validation loss: 0.2910
2024-06-03 02:21:28 [INFO]: Epoch 026 - training loss: 0.3075, validation loss: 0.2812
2024-06-03 02:22:32 [INFO]: Epoch 027 - training loss: 0.2905, validation loss: 0.2896
2024-06-03 02:23:36 [INFO]: Epoch 028 - training loss: 0.2784, validation loss: 0.2924
2024-06-03 02:24:40 [INFO]: Epoch 029 - training loss: 0.3043, validation loss: 0.2914
2024-06-03 02:25:43 [INFO]: Epoch 030 - training loss: 0.3228, validation loss: 0.2862
2024-06-03 02:26:47 [INFO]: Epoch 031 - training loss: 0.3258, validation loss: 0.2896
2024-06-03 02:27:51 [INFO]: Epoch 032 - training loss: 0.2903, validation loss: 0.2870
2024-06-03 02:28:55 [INFO]: Epoch 033 - training loss: 0.3051, validation loss: 0.2874
2024-06-03 02:29:59 [INFO]: Epoch 034 - training loss: 0.2814, validation loss: 0.2814
2024-06-03 02:31:03 [INFO]: Epoch 035 - training loss: 0.2813, validation loss: 0.2798
2024-06-03 02:32:06 [INFO]: Epoch 036 - training loss: 0.3156, validation loss: 0.2833
2024-06-03 02:33:10 [INFO]: Epoch 037 - training loss: 0.2917, validation loss: 0.2877
2024-06-03 02:34:14 [INFO]: Epoch 038 - training loss: 0.2703, validation loss: 0.2865
2024-06-03 02:35:18 [INFO]: Epoch 039 - training loss: 0.2864, validation loss: 0.2826
2024-06-03 02:36:22 [INFO]: Epoch 040 - training loss: 0.2729, validation loss: 0.2850
2024-06-03 02:37:26 [INFO]: Epoch 041 - training loss: 0.2872, validation loss: 0.2822
2024-06-03 02:38:30 [INFO]: Epoch 042 - training loss: 0.2835, validation loss: 0.2885
2024-06-03 02:39:34 [INFO]: Epoch 043 - training loss: 0.2668, validation loss: 0.2855
2024-06-03 02:40:37 [INFO]: Epoch 044 - training loss: 0.2824, validation loss: 0.2706
2024-06-03 02:41:41 [INFO]: Epoch 045 - training loss: 0.2561, validation loss: 0.2744
2024-06-03 02:42:45 [INFO]: Epoch 046 - training loss: 0.2528, validation loss: 0.2674
2024-06-03 02:43:49 [INFO]: Epoch 047 - training loss: 0.2595, validation loss: 0.2654
2024-06-03 02:44:53 [INFO]: Epoch 048 - training loss: 0.2700, validation loss: 0.2725
2024-06-03 02:45:57 [INFO]: Epoch 049 - training loss: 0.2637, validation loss: 0.2707
2024-06-03 02:47:01 [INFO]: Epoch 050 - training loss: 0.2569, validation loss: 0.2696
2024-06-03 02:48:05 [INFO]: Epoch 051 - training loss: 0.2507, validation loss: 0.2705
2024-06-03 02:49:09 [INFO]: Epoch 052 - training loss: 0.2540, validation loss: 0.2683
2024-06-03 02:50:13 [INFO]: Epoch 053 - training loss: 0.2406, validation loss: 0.2671
2024-06-03 02:51:17 [INFO]: Epoch 054 - training loss: 0.2486, validation loss: 0.2675
2024-06-03 02:52:21 [INFO]: Epoch 055 - training loss: 0.2671, validation loss: 0.2718
2024-06-03 02:53:25 [INFO]: Epoch 056 - training loss: 0.2423, validation loss: 0.2584
2024-06-03 02:54:29 [INFO]: Epoch 057 - training loss: 0.2720, validation loss: 0.2694
2024-06-03 02:55:33 [INFO]: Epoch 058 - training loss: 0.2632, validation loss: 0.2587
2024-06-03 02:56:37 [INFO]: Epoch 059 - training loss: 0.2776, validation loss: 0.2577
2024-06-03 02:57:41 [INFO]: Epoch 060 - training loss: 0.2499, validation loss: 0.2769
2024-06-03 02:58:45 [INFO]: Epoch 061 - training loss: 0.2706, validation loss: 0.2608
2024-06-03 02:59:48 [INFO]: Epoch 062 - training loss: 0.2519, validation loss: 0.2560
2024-06-03 03:00:52 [INFO]: Epoch 063 - training loss: 0.2633, validation loss: 0.2620
2024-06-03 03:01:56 [INFO]: Epoch 064 - training loss: 0.2656, validation loss: 0.2553
2024-06-03 03:03:00 [INFO]: Epoch 065 - training loss: 0.2717, validation loss: 0.2542
2024-06-03 03:04:04 [INFO]: Epoch 066 - training loss: 0.2670, validation loss: 0.2605
2024-06-03 03:05:08 [INFO]: Epoch 067 - training loss: 0.2649, validation loss: 0.2509
2024-06-03 03:06:12 [INFO]: Epoch 068 - training loss: 0.2512, validation loss: 0.2528
2024-06-03 03:07:16 [INFO]: Epoch 069 - training loss: 0.2685, validation loss: 0.2579
2024-06-03 03:08:20 [INFO]: Epoch 070 - training loss: 0.2486, validation loss: 0.2513
2024-06-03 03:09:25 [INFO]: Epoch 071 - training loss: 0.2657, validation loss: 0.2517
2024-06-03 03:10:29 [INFO]: Epoch 072 - training loss: 0.2411, validation loss: 0.2389
2024-06-03 03:11:33 [INFO]: Epoch 073 - training loss: 0.2574, validation loss: 0.2397
2024-06-03 03:12:37 [INFO]: Epoch 074 - training loss: 0.2557, validation loss: 0.2378
2024-06-03 03:13:42 [INFO]: Epoch 075 - training loss: 0.2570, validation loss: 0.2452
2024-06-03 03:14:46 [INFO]: Epoch 076 - training loss: 0.2477, validation loss: 0.2517
2024-06-03 03:15:50 [INFO]: Epoch 077 - training loss: 0.2440, validation loss: 0.2395
2024-06-03 03:16:54 [INFO]: Epoch 078 - training loss: 0.2742, validation loss: 0.2475
2024-06-03 03:17:58 [INFO]: Epoch 079 - training loss: 0.2657, validation loss: 0.2304
2024-06-03 03:19:02 [INFO]: Epoch 080 - training loss: 0.2631, validation loss: 0.2380
2024-06-03 03:20:06 [INFO]: Epoch 081 - training loss: 0.2534, validation loss: 0.2453
2024-06-03 03:21:10 [INFO]: Epoch 082 - training loss: 0.2445, validation loss: 0.2343
2024-06-03 03:22:14 [INFO]: Epoch 083 - training loss: 0.2416, validation loss: 0.2464
2024-06-03 03:23:18 [INFO]: Epoch 084 - training loss: 0.2453, validation loss: 0.2479
2024-06-03 03:24:23 [INFO]: Epoch 085 - training loss: 0.2560, validation loss: 0.2352
2024-06-03 03:25:27 [INFO]: Epoch 086 - training loss: 0.2294, validation loss: 0.2344
2024-06-03 03:26:31 [INFO]: Epoch 087 - training loss: 0.2399, validation loss: 0.2316
2024-06-03 03:27:34 [INFO]: Epoch 088 - training loss: 0.2560, validation loss: 0.2402
2024-06-03 03:28:38 [INFO]: Epoch 089 - training loss: 0.2582, validation loss: 0.2314
2024-06-03 03:28:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:28:38 [INFO]: Finished training. The best model is from epoch#79.
2024-06-03 03:28:38 [INFO]: Saved the model to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_1/20240603_T015220/CSDI.pypots
2024-06-03 04:10:11 [INFO]: Successfully saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_1/imputation.pkl
2024-06-03 04:10:11 [INFO]: Round1 - CSDI on BeijingAir: MAE=0.4169, MSE=1.9205, MRE=0.5614
2024-06-03 04:10:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:10:11 [INFO]: Using the given device: cuda:0
2024-06-03 04:10:11 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_2/20240603_T041011
2024-06-03 04:10:11 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_2/20240603_T041011/tensorboard
2024-06-03 04:10:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 04:11:15 [INFO]: Epoch 001 - training loss: 0.5502, validation loss: 0.4474
2024-06-03 04:12:19 [INFO]: Epoch 002 - training loss: 0.4105, validation loss: 0.3729
2024-06-03 04:13:23 [INFO]: Epoch 003 - training loss: 0.4046, validation loss: 0.3448
2024-06-03 04:14:27 [INFO]: Epoch 004 - training loss: 0.3624, validation loss: 0.3281
2024-06-03 04:15:30 [INFO]: Epoch 005 - training loss: 0.3794, validation loss: 0.3314
2024-06-03 04:16:34 [INFO]: Epoch 006 - training loss: 0.3879, validation loss: 0.3168
2024-06-03 04:17:39 [INFO]: Epoch 007 - training loss: 0.3280, validation loss: 0.3160
2024-06-03 04:18:42 [INFO]: Epoch 008 - training loss: 0.3398, validation loss: 0.3055
2024-06-03 04:19:46 [INFO]: Epoch 009 - training loss: 0.3335, validation loss: 0.3232
2024-06-03 04:20:50 [INFO]: Epoch 010 - training loss: 0.3398, validation loss: 0.2991
2024-06-03 04:21:54 [INFO]: Epoch 011 - training loss: 0.3321, validation loss: 0.3114
2024-06-03 04:22:58 [INFO]: Epoch 012 - training loss: 0.3142, validation loss: 0.3297
2024-06-03 04:24:02 [INFO]: Epoch 013 - training loss: 0.3220, validation loss: 0.3170
2024-06-03 04:25:06 [INFO]: Epoch 014 - training loss: 0.3242, validation loss: 0.2921
2024-06-03 04:26:10 [INFO]: Epoch 015 - training loss: 0.3167, validation loss: 0.2860
2024-06-03 04:27:14 [INFO]: Epoch 016 - training loss: 0.3322, validation loss: 0.3003
2024-06-03 04:28:18 [INFO]: Epoch 017 - training loss: 0.3160, validation loss: 0.3255
2024-06-03 04:29:22 [INFO]: Epoch 018 - training loss: 0.3284, validation loss: 0.3199
2024-06-03 04:30:25 [INFO]: Epoch 019 - training loss: 0.3038, validation loss: 0.2892
2024-06-03 04:31:30 [INFO]: Epoch 020 - training loss: 0.2976, validation loss: 0.3093
2024-06-03 04:32:33 [INFO]: Epoch 021 - training loss: 0.3152, validation loss: 0.2848
2024-06-03 04:33:37 [INFO]: Epoch 022 - training loss: 0.2957, validation loss: 0.2870
2024-06-03 04:34:41 [INFO]: Epoch 023 - training loss: 0.3062, validation loss: 0.2842
2024-06-03 04:35:45 [INFO]: Epoch 024 - training loss: 0.3029, validation loss: 0.2951
2024-06-03 04:36:49 [INFO]: Epoch 025 - training loss: 0.3183, validation loss: 0.2854
2024-06-03 04:37:53 [INFO]: Epoch 026 - training loss: 0.2929, validation loss: 0.2782
2024-06-03 04:38:57 [INFO]: Epoch 027 - training loss: 0.2840, validation loss: 0.2784
2024-06-03 04:40:01 [INFO]: Epoch 028 - training loss: 0.2749, validation loss: 0.2774
2024-06-03 04:41:05 [INFO]: Epoch 029 - training loss: 0.3032, validation loss: 0.2893
2024-06-03 04:42:09 [INFO]: Epoch 030 - training loss: 0.2943, validation loss: 0.2716
2024-06-03 04:43:12 [INFO]: Epoch 031 - training loss: 0.3167, validation loss: 0.2806
2024-06-03 04:44:16 [INFO]: Epoch 032 - training loss: 0.2889, validation loss: 0.2704
2024-06-03 04:45:20 [INFO]: Epoch 033 - training loss: 0.2913, validation loss: 0.3237
2024-06-03 04:46:24 [INFO]: Epoch 034 - training loss: 0.2866, validation loss: 0.2674
2024-06-03 04:47:27 [INFO]: Epoch 035 - training loss: 0.2739, validation loss: 0.2945
2024-06-03 04:48:31 [INFO]: Epoch 036 - training loss: 0.2553, validation loss: 0.2753
2024-06-03 04:49:35 [INFO]: Epoch 037 - training loss: 0.2648, validation loss: 0.3068
2024-06-03 04:50:39 [INFO]: Epoch 038 - training loss: 0.2395, validation loss: 0.2688
2024-06-03 04:51:43 [INFO]: Epoch 039 - training loss: 0.2787, validation loss: 0.2963
2024-06-03 04:52:47 [INFO]: Epoch 040 - training loss: 0.2471, validation loss: 0.2539
2024-06-03 04:53:51 [INFO]: Epoch 041 - training loss: 0.2754, validation loss: 0.2753
2024-06-03 04:54:55 [INFO]: Epoch 042 - training loss: 0.2717, validation loss: 0.2655
2024-06-03 04:55:58 [INFO]: Epoch 043 - training loss: 0.2578, validation loss: 0.3169
2024-06-03 04:57:02 [INFO]: Epoch 044 - training loss: 0.2510, validation loss: 0.2573
2024-06-03 04:58:06 [INFO]: Epoch 045 - training loss: 0.2759, validation loss: 0.2521
2024-06-03 04:59:10 [INFO]: Epoch 046 - training loss: 0.2726, validation loss: 0.2651
2024-06-03 05:00:14 [INFO]: Epoch 047 - training loss: 0.2558, validation loss: 0.2647
2024-06-03 05:01:18 [INFO]: Epoch 048 - training loss: 0.2356, validation loss: 0.2549
2024-06-03 05:02:22 [INFO]: Epoch 049 - training loss: 0.2539, validation loss: 0.2461
2024-06-03 05:03:26 [INFO]: Epoch 050 - training loss: 0.3004, validation loss: 0.2609
2024-06-03 05:04:30 [INFO]: Epoch 051 - training loss: 0.2432, validation loss: 0.2551
2024-06-03 05:05:34 [INFO]: Epoch 052 - training loss: 0.2599, validation loss: 0.2742
2024-06-03 05:06:38 [INFO]: Epoch 053 - training loss: 0.2506, validation loss: 0.2784
2024-06-03 05:07:41 [INFO]: Epoch 054 - training loss: 0.2597, validation loss: 0.2460
2024-06-03 05:08:45 [INFO]: Epoch 055 - training loss: 0.2715, validation loss: 0.2759
2024-06-03 05:09:49 [INFO]: Epoch 056 - training loss: 0.2733, validation loss: 0.2462
2024-06-03 05:10:53 [INFO]: Epoch 057 - training loss: 0.2400, validation loss: 0.2592
2024-06-03 05:11:57 [INFO]: Epoch 058 - training loss: 0.2691, validation loss: 0.2410
2024-06-03 05:13:01 [INFO]: Epoch 059 - training loss: 0.2492, validation loss: 0.2520
2024-06-03 05:14:05 [INFO]: Epoch 060 - training loss: 0.2525, validation loss: 0.2549
2024-06-03 05:15:09 [INFO]: Epoch 061 - training loss: 0.2276, validation loss: 0.2486
2024-06-03 05:16:13 [INFO]: Epoch 062 - training loss: 0.2256, validation loss: 0.2367
2024-06-03 05:17:17 [INFO]: Epoch 063 - training loss: 0.2369, validation loss: 0.2375
2024-06-03 05:18:21 [INFO]: Epoch 064 - training loss: 0.2292, validation loss: 0.2361
2024-06-03 05:19:25 [INFO]: Epoch 065 - training loss: 0.2272, validation loss: 0.2267
2024-06-03 05:20:29 [INFO]: Epoch 066 - training loss: 0.2557, validation loss: 0.2388
2024-06-03 05:21:32 [INFO]: Epoch 067 - training loss: 0.2339, validation loss: 0.2294
2024-06-03 05:22:36 [INFO]: Epoch 068 - training loss: 0.2399, validation loss: 0.2310
2024-06-03 05:23:40 [INFO]: Epoch 069 - training loss: 0.2698, validation loss: 0.2333
2024-06-03 05:24:44 [INFO]: Epoch 070 - training loss: 0.2225, validation loss: 0.2315
2024-06-03 05:25:48 [INFO]: Epoch 071 - training loss: 0.2439, validation loss: 0.2271
2024-06-03 05:26:52 [INFO]: Epoch 072 - training loss: 0.2131, validation loss: 0.2243
2024-06-03 05:27:56 [INFO]: Epoch 073 - training loss: 0.2460, validation loss: 0.2272
2024-06-03 05:28:59 [INFO]: Epoch 074 - training loss: 0.2291, validation loss: 0.2397
2024-06-03 05:30:03 [INFO]: Epoch 075 - training loss: 0.2447, validation loss: 0.2296
2024-06-03 05:31:07 [INFO]: Epoch 076 - training loss: 0.2335, validation loss: 0.2234
2024-06-03 05:32:11 [INFO]: Epoch 077 - training loss: 0.2490, validation loss: 0.2275
2024-06-03 05:33:15 [INFO]: Epoch 078 - training loss: 0.2434, validation loss: 0.2217
2024-06-03 05:34:19 [INFO]: Epoch 079 - training loss: 0.2379, validation loss: 0.2235
2024-06-03 05:35:24 [INFO]: Epoch 080 - training loss: 0.2230, validation loss: 0.2260
2024-06-03 05:36:27 [INFO]: Epoch 081 - training loss: 0.2684, validation loss: 0.2174
2024-06-03 05:37:32 [INFO]: Epoch 082 - training loss: 0.2497, validation loss: 0.2144
2024-06-03 05:38:36 [INFO]: Epoch 083 - training loss: 0.2236, validation loss: 0.2252
2024-06-03 05:39:39 [INFO]: Epoch 084 - training loss: 0.2484, validation loss: 0.2178
2024-06-03 05:40:43 [INFO]: Epoch 085 - training loss: 0.2334, validation loss: 0.2137
2024-06-03 05:41:48 [INFO]: Epoch 086 - training loss: 0.2513, validation loss: 0.2147
2024-06-03 05:42:51 [INFO]: Epoch 087 - training loss: 0.2229, validation loss: 0.2241
2024-06-03 05:43:56 [INFO]: Epoch 088 - training loss: 0.2264, validation loss: 0.2174
2024-06-03 05:45:00 [INFO]: Epoch 089 - training loss: 0.2465, validation loss: 0.2297
2024-06-03 05:46:04 [INFO]: Epoch 090 - training loss: 0.2474, validation loss: 0.2310
2024-06-03 05:47:08 [INFO]: Epoch 091 - training loss: 0.2297, validation loss: 0.2283
2024-06-03 05:48:12 [INFO]: Epoch 092 - training loss: 0.2248, validation loss: 0.2108
2024-06-03 05:49:16 [INFO]: Epoch 093 - training loss: 0.2316, validation loss: 0.2100
2024-06-03 05:50:20 [INFO]: Epoch 094 - training loss: 0.2250, validation loss: 0.2257
2024-06-03 05:51:24 [INFO]: Epoch 095 - training loss: 0.2237, validation loss: 0.2106
2024-06-03 05:52:28 [INFO]: Epoch 096 - training loss: 0.2501, validation loss: 0.2054
2024-06-03 05:53:32 [INFO]: Epoch 097 - training loss: 0.2229, validation loss: 0.2108
2024-06-03 05:54:36 [INFO]: Epoch 098 - training loss: 0.2253, validation loss: 0.2059
2024-06-03 05:55:40 [INFO]: Epoch 099 - training loss: 0.2095, validation loss: 0.2108
2024-06-03 05:56:44 [INFO]: Epoch 100 - training loss: 0.2326, validation loss: 0.2118
2024-06-03 05:56:44 [INFO]: Finished training. The best model is from epoch#96.
2024-06-03 05:56:44 [INFO]: Saved the model to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_2/20240603_T041011/CSDI.pypots
2024-06-03 06:23:23 [INFO]: Successfully saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_2/imputation.pkl
2024-06-03 06:23:23 [INFO]: Round2 - CSDI on BeijingAir: MAE=0.3107, MSE=0.4902, MRE=0.4184
2024-06-03 06:23:23 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 06:23:23 [INFO]: Using the given device: cuda:0
2024-06-03 06:23:23 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_3/20240603_T062323
2024-06-03 06:23:23 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_3/20240603_T062323/tensorboard
2024-06-03 06:23:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 06:23:49 [INFO]: Epoch 001 - training loss: 0.5927, validation loss: 0.4513
2024-06-03 06:24:15 [INFO]: Epoch 002 - training loss: 0.4223, validation loss: 0.3816
2024-06-03 06:24:41 [INFO]: Epoch 003 - training loss: 0.3941, validation loss: 0.3482
2024-06-03 06:25:07 [INFO]: Epoch 004 - training loss: 0.3948, validation loss: 0.3454
2024-06-03 06:25:33 [INFO]: Epoch 005 - training loss: 0.3719, validation loss: 0.3349
2024-06-03 06:25:59 [INFO]: Epoch 006 - training loss: 0.3731, validation loss: 0.3330
2024-06-03 06:26:25 [INFO]: Epoch 007 - training loss: 0.3695, validation loss: 0.3155
2024-06-03 06:26:51 [INFO]: Epoch 008 - training loss: 0.3473, validation loss: 0.3187
2024-06-03 06:27:17 [INFO]: Epoch 009 - training loss: 0.3281, validation loss: 0.3190
2024-06-03 06:27:43 [INFO]: Epoch 010 - training loss: 0.3359, validation loss: 0.3311
2024-06-03 06:28:09 [INFO]: Epoch 011 - training loss: 0.3294, validation loss: 0.3133
2024-06-03 06:28:35 [INFO]: Epoch 012 - training loss: 0.3176, validation loss: 0.3108
2024-06-03 06:29:01 [INFO]: Epoch 013 - training loss: 0.3355, validation loss: 0.3052
2024-06-03 06:29:27 [INFO]: Epoch 014 - training loss: 0.3391, validation loss: 0.3058
2024-06-03 06:29:53 [INFO]: Epoch 015 - training loss: 0.3289, validation loss: 0.2973
2024-06-03 06:30:19 [INFO]: Epoch 016 - training loss: 0.3200, validation loss: 0.3005
2024-06-03 06:30:45 [INFO]: Epoch 017 - training loss: 0.3069, validation loss: 0.3115
2024-06-03 06:31:11 [INFO]: Epoch 018 - training loss: 0.2860, validation loss: 0.2963
2024-06-03 06:31:37 [INFO]: Epoch 019 - training loss: 0.3051, validation loss: 0.3011
2024-06-03 06:32:03 [INFO]: Epoch 020 - training loss: 0.3262, validation loss: 0.2964
2024-06-03 06:32:29 [INFO]: Epoch 021 - training loss: 0.3124, validation loss: 0.2971
2024-06-03 06:32:55 [INFO]: Epoch 022 - training loss: 0.2908, validation loss: 0.2932
2024-06-03 06:33:21 [INFO]: Epoch 023 - training loss: 0.3182, validation loss: 0.2902
2024-06-03 06:33:47 [INFO]: Epoch 024 - training loss: 0.3066, validation loss: 0.3003
2024-06-03 06:34:13 [INFO]: Epoch 025 - training loss: 0.2793, validation loss: 0.3055
2024-06-03 06:34:39 [INFO]: Epoch 026 - training loss: 0.2877, validation loss: 0.2797
2024-06-03 06:35:05 [INFO]: Epoch 027 - training loss: 0.3014, validation loss: 0.2984
2024-06-03 06:35:31 [INFO]: Epoch 028 - training loss: 0.3001, validation loss: 0.2855
2024-06-03 06:35:57 [INFO]: Epoch 029 - training loss: 0.2968, validation loss: 0.2738
2024-06-03 06:36:24 [INFO]: Epoch 030 - training loss: 0.2926, validation loss: 0.2917
2024-06-03 06:36:50 [INFO]: Epoch 031 - training loss: 0.3019, validation loss: 0.2964
2024-06-03 06:37:16 [INFO]: Epoch 032 - training loss: 0.3119, validation loss: 0.2857
2024-06-03 06:37:42 [INFO]: Epoch 033 - training loss: 0.2936, validation loss: 0.2927
2024-06-03 06:38:08 [INFO]: Epoch 034 - training loss: 0.2857, validation loss: 0.2731
2024-06-03 06:38:34 [INFO]: Epoch 035 - training loss: 0.3004, validation loss: 0.2764
2024-06-03 06:39:00 [INFO]: Epoch 036 - training loss: 0.2995, validation loss: 0.3278
2024-06-03 06:39:26 [INFO]: Epoch 037 - training loss: 0.2858, validation loss: 0.2914
2024-06-03 06:39:52 [INFO]: Epoch 038 - training loss: 0.2764, validation loss: 0.3105
2024-06-03 06:40:18 [INFO]: Epoch 039 - training loss: 0.2710, validation loss: 0.2822
2024-06-03 06:40:44 [INFO]: Epoch 040 - training loss: 0.2854, validation loss: 0.2615
2024-06-03 06:41:10 [INFO]: Epoch 041 - training loss: 0.2811, validation loss: 0.2560
2024-06-03 06:41:36 [INFO]: Epoch 042 - training loss: 0.2436, validation loss: 0.2835
2024-06-03 06:42:02 [INFO]: Epoch 043 - training loss: 0.2858, validation loss: 0.2761
2024-06-03 06:42:28 [INFO]: Epoch 044 - training loss: 0.2713, validation loss: 0.2829
2024-06-03 06:42:54 [INFO]: Epoch 045 - training loss: 0.2759, validation loss: 0.2649
2024-06-03 06:43:20 [INFO]: Epoch 046 - training loss: 0.2656, validation loss: 0.2645
2024-06-03 06:43:46 [INFO]: Epoch 047 - training loss: 0.2889, validation loss: 0.2697
2024-06-03 06:44:12 [INFO]: Epoch 048 - training loss: 0.2528, validation loss: 0.2927
2024-06-03 06:44:38 [INFO]: Epoch 049 - training loss: 0.2802, validation loss: 0.2753
2024-06-03 06:45:04 [INFO]: Epoch 050 - training loss: 0.2687, validation loss: 0.2746
2024-06-03 06:45:30 [INFO]: Epoch 051 - training loss: 0.2405, validation loss: 0.2650
2024-06-03 06:45:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:45:30 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 06:45:30 [INFO]: Saved the model to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_3/20240603_T062323/CSDI.pypots
2024-06-03 07:02:51 [INFO]: Successfully saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_3/imputation.pkl
2024-06-03 07:02:51 [INFO]: Round3 - CSDI on BeijingAir: MAE=0.5101, MSE=1.3421, MRE=0.6869
2024-06-03 07:02:51 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 07:02:51 [INFO]: Using the given device: cuda:0
2024-06-03 07:02:51 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_4/20240603_T070251
2024-06-03 07:02:51 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_4/20240603_T070251/tensorboard
2024-06-03 07:02:51 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 07:03:17 [INFO]: Epoch 001 - training loss: 0.5464, validation loss: 0.4413
2024-06-03 07:03:43 [INFO]: Epoch 002 - training loss: 0.4114, validation loss: 0.3800
2024-06-03 07:04:09 [INFO]: Epoch 003 - training loss: 0.3931, validation loss: 0.3509
2024-06-03 07:04:35 [INFO]: Epoch 004 - training loss: 0.3747, validation loss: 0.3393
2024-06-03 07:05:01 [INFO]: Epoch 005 - training loss: 0.3662, validation loss: 0.3223
2024-06-03 07:05:27 [INFO]: Epoch 006 - training loss: 0.3595, validation loss: 0.3255
2024-06-03 07:05:53 [INFO]: Epoch 007 - training loss: 0.3499, validation loss: 0.3173
2024-06-03 07:06:19 [INFO]: Epoch 008 - training loss: 0.3663, validation loss: 0.3128
2024-06-03 07:06:45 [INFO]: Epoch 009 - training loss: 0.3229, validation loss: 0.3073
2024-06-03 07:07:11 [INFO]: Epoch 010 - training loss: 0.3269, validation loss: 0.3092
2024-06-03 07:07:37 [INFO]: Epoch 011 - training loss: 0.3270, validation loss: 0.3034
2024-06-03 07:08:03 [INFO]: Epoch 012 - training loss: 0.3235, validation loss: 0.2983
2024-06-03 07:08:29 [INFO]: Epoch 013 - training loss: 0.3190, validation loss: 0.3003
2024-06-03 07:08:55 [INFO]: Epoch 014 - training loss: 0.3319, validation loss: 0.2897
2024-06-03 07:09:21 [INFO]: Epoch 015 - training loss: 0.3269, validation loss: 0.2983
2024-06-03 07:09:47 [INFO]: Epoch 016 - training loss: 0.3147, validation loss: 0.2978
2024-06-03 07:10:13 [INFO]: Epoch 017 - training loss: 0.3321, validation loss: 0.2831
2024-06-03 07:10:39 [INFO]: Epoch 018 - training loss: 0.3190, validation loss: 0.2853
2024-06-03 07:11:05 [INFO]: Epoch 019 - training loss: 0.3183, validation loss: 0.2822
2024-06-03 07:11:31 [INFO]: Epoch 020 - training loss: 0.3124, validation loss: 0.2759
2024-06-03 07:11:57 [INFO]: Epoch 021 - training loss: 0.3064, validation loss: 0.2801
2024-06-03 07:12:23 [INFO]: Epoch 022 - training loss: 0.3051, validation loss: 0.2851
2024-06-03 07:12:49 [INFO]: Epoch 023 - training loss: 0.3082, validation loss: 0.2789
2024-06-03 07:13:15 [INFO]: Epoch 024 - training loss: 0.3171, validation loss: 0.2727
2024-06-03 07:13:41 [INFO]: Epoch 025 - training loss: 0.2945, validation loss: 0.2752
2024-06-03 07:14:07 [INFO]: Epoch 026 - training loss: 0.3045, validation loss: 0.2809
2024-06-03 07:14:33 [INFO]: Epoch 027 - training loss: 0.2953, validation loss: 0.2705
2024-06-03 07:14:59 [INFO]: Epoch 028 - training loss: 0.2882, validation loss: 0.2670
2024-06-03 07:15:25 [INFO]: Epoch 029 - training loss: 0.2753, validation loss: 0.2739
2024-06-03 07:15:51 [INFO]: Epoch 030 - training loss: 0.3058, validation loss: 0.2725
2024-06-03 07:16:17 [INFO]: Epoch 031 - training loss: 0.2877, validation loss: 0.2636
2024-06-03 07:16:43 [INFO]: Epoch 032 - training loss: 0.2770, validation loss: 0.2644
2024-06-03 07:17:10 [INFO]: Epoch 033 - training loss: 0.2452, validation loss: 0.2617
2024-06-03 07:17:36 [INFO]: Epoch 034 - training loss: 0.2627, validation loss: 0.2778
2024-06-03 07:18:02 [INFO]: Epoch 035 - training loss: 0.2687, validation loss: 0.2681
2024-06-03 07:18:28 [INFO]: Epoch 036 - training loss: 0.2709, validation loss: 0.2748
2024-06-03 07:18:54 [INFO]: Epoch 037 - training loss: 0.2720, validation loss: 0.2509
2024-06-03 07:19:20 [INFO]: Epoch 038 - training loss: 0.2669, validation loss: 0.2607
2024-06-03 07:19:46 [INFO]: Epoch 039 - training loss: 0.2687, validation loss: 0.2752
2024-06-03 07:20:12 [INFO]: Epoch 040 - training loss: 0.2760, validation loss: 0.2556
2024-06-03 07:20:38 [INFO]: Epoch 041 - training loss: 0.2677, validation loss: 0.2491
2024-06-03 07:21:04 [INFO]: Epoch 042 - training loss: 0.2758, validation loss: 0.2497
2024-06-03 07:21:30 [INFO]: Epoch 043 - training loss: 0.2785, validation loss: 0.2531
2024-06-03 07:21:56 [INFO]: Epoch 044 - training loss: 0.2378, validation loss: 0.2479
2024-06-03 07:22:22 [INFO]: Epoch 045 - training loss: 0.2633, validation loss: 0.2473
2024-06-03 07:22:48 [INFO]: Epoch 046 - training loss: 0.2421, validation loss: 0.2501
2024-06-03 07:23:14 [INFO]: Epoch 047 - training loss: 0.2417, validation loss: 0.2569
2024-06-03 07:23:40 [INFO]: Epoch 048 - training loss: 0.2508, validation loss: 0.2404
2024-06-03 07:24:06 [INFO]: Epoch 049 - training loss: 0.2576, validation loss: 0.2391
2024-06-03 07:24:32 [INFO]: Epoch 050 - training loss: 0.2691, validation loss: 0.2758
2024-06-03 07:24:58 [INFO]: Epoch 051 - training loss: 0.2412, validation loss: 0.2435
2024-06-03 07:25:24 [INFO]: Epoch 052 - training loss: 0.2646, validation loss: 0.2566
2024-06-03 07:25:50 [INFO]: Epoch 053 - training loss: 0.2433, validation loss: 0.2339
2024-06-03 07:26:16 [INFO]: Epoch 054 - training loss: 0.2629, validation loss: 0.2599
2024-06-03 07:26:42 [INFO]: Epoch 055 - training loss: 0.2715, validation loss: 0.2382
2024-06-03 07:27:08 [INFO]: Epoch 056 - training loss: 0.2511, validation loss: 0.2362
2024-06-03 07:27:34 [INFO]: Epoch 057 - training loss: 0.2407, validation loss: 0.2380
2024-06-03 07:28:00 [INFO]: Epoch 058 - training loss: 0.2403, validation loss: 0.2304
2024-06-03 07:28:26 [INFO]: Epoch 059 - training loss: 0.2535, validation loss: 0.2358
2024-06-03 07:28:52 [INFO]: Epoch 060 - training loss: 0.2315, validation loss: 0.2365
2024-06-03 07:29:18 [INFO]: Epoch 061 - training loss: 0.2456, validation loss: 0.2440
2024-06-03 07:29:44 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.2277
2024-06-03 07:30:10 [INFO]: Epoch 063 - training loss: 0.2318, validation loss: 0.2303
2024-06-03 07:30:36 [INFO]: Epoch 064 - training loss: 0.2319, validation loss: 0.2301
2024-06-03 07:31:02 [INFO]: Epoch 065 - training loss: 0.2210, validation loss: 0.2297
2024-06-03 07:31:28 [INFO]: Epoch 066 - training loss: 0.2215, validation loss: 0.2354
2024-06-03 07:31:54 [INFO]: Epoch 067 - training loss: 0.2392, validation loss: 0.2228
2024-06-03 07:32:21 [INFO]: Epoch 068 - training loss: 0.2597, validation loss: 0.2284
2024-06-03 07:32:47 [INFO]: Epoch 069 - training loss: 0.2390, validation loss: 0.2363
2024-06-03 07:33:13 [INFO]: Epoch 070 - training loss: 0.2332, validation loss: 0.2325
2024-06-03 07:33:39 [INFO]: Epoch 071 - training loss: 0.2431, validation loss: 0.2348
2024-06-03 07:34:05 [INFO]: Epoch 072 - training loss: 0.2327, validation loss: 0.2166
2024-06-03 07:34:31 [INFO]: Epoch 073 - training loss: 0.2326, validation loss: 0.2150
2024-06-03 07:34:57 [INFO]: Epoch 074 - training loss: 0.2512, validation loss: 0.2220
2024-06-03 07:35:23 [INFO]: Epoch 075 - training loss: 0.2525, validation loss: 0.2159
2024-06-03 07:35:49 [INFO]: Epoch 076 - training loss: 0.2534, validation loss: 0.2406
2024-06-03 07:36:15 [INFO]: Epoch 077 - training loss: 0.2393, validation loss: 0.2269
2024-06-03 07:36:41 [INFO]: Epoch 078 - training loss: 0.2400, validation loss: 0.2194
2024-06-03 07:37:07 [INFO]: Epoch 079 - training loss: 0.2205, validation loss: 0.2085
2024-06-03 07:37:33 [INFO]: Epoch 080 - training loss: 0.2291, validation loss: 0.2312
2024-06-03 07:37:59 [INFO]: Epoch 081 - training loss: 0.2338, validation loss: 0.2237
2024-06-03 07:38:25 [INFO]: Epoch 082 - training loss: 0.2070, validation loss: 0.2129
2024-06-03 07:38:51 [INFO]: Epoch 083 - training loss: 0.2470, validation loss: 0.2168
2024-06-03 07:39:17 [INFO]: Epoch 084 - training loss: 0.2257, validation loss: 0.2212
2024-06-03 07:39:43 [INFO]: Epoch 085 - training loss: 0.2333, validation loss: 0.2199
2024-06-03 07:40:09 [INFO]: Epoch 086 - training loss: 0.2164, validation loss: 0.2229
2024-06-03 07:40:35 [INFO]: Epoch 087 - training loss: 0.2346, validation loss: 0.2156
2024-06-03 07:41:01 [INFO]: Epoch 088 - training loss: 0.2046, validation loss: 0.2111
2024-06-03 07:41:27 [INFO]: Epoch 089 - training loss: 0.2215, validation loss: 0.2142
2024-06-03 07:41:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:41:27 [INFO]: Finished training. The best model is from epoch#79.
2024-06-03 07:41:27 [INFO]: Saved the model to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_4/20240603_T070251/CSDI.pypots
2024-06-03 07:58:48 [INFO]: Successfully saved to results_point_rate09/BeijingAir/CSDI_BeijingAir/round_4/imputation.pkl
2024-06-03 07:58:48 [INFO]: Round4 - CSDI on BeijingAir: MAE=0.2712, MSE=0.3897, MRE=0.3652
2024-06-03 07:58:48 [INFO]: Done! Final results:
Averaged CSDI (244,833 params) on BeijingAir: MAE=0.4229 ± 0.13528143589786754, MSE=1.1704 ± 0.6344516727337459, MRE=0.5610 ± 0.1794686080485877, average inference time=409.70