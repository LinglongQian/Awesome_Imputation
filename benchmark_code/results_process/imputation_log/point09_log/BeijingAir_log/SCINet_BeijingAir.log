2024-06-03 10:25:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:25:47 [INFO]: Using the given device: cuda:0
2024-06-03 10:25:48 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_0/20240603_T102547
2024-06-03 10:25:48 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_0/20240603_T102547/tensorboard
2024-06-03 10:25:49 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-03 10:26:02 [INFO]: Epoch 001 - training loss: 1.4528, validation loss: 1.0910
2024-06-03 10:26:07 [INFO]: Epoch 002 - training loss: 1.2270, validation loss: 0.7461
2024-06-03 10:26:11 [INFO]: Epoch 003 - training loss: 0.9342, validation loss: 0.5546
2024-06-03 10:26:16 [INFO]: Epoch 004 - training loss: 0.7957, validation loss: 0.4849
2024-06-03 10:26:21 [INFO]: Epoch 005 - training loss: 0.7062, validation loss: 0.4520
2024-06-03 10:26:26 [INFO]: Epoch 006 - training loss: 0.6550, validation loss: 0.4263
2024-06-03 10:26:31 [INFO]: Epoch 007 - training loss: 0.6189, validation loss: 0.4096
2024-06-03 10:26:35 [INFO]: Epoch 008 - training loss: 0.5949, validation loss: 0.3971
2024-06-03 10:26:40 [INFO]: Epoch 009 - training loss: 0.5752, validation loss: 0.3910
2024-06-03 10:26:45 [INFO]: Epoch 010 - training loss: 0.5575, validation loss: 0.3904
2024-06-03 10:26:50 [INFO]: Epoch 011 - training loss: 0.5418, validation loss: 0.3764
2024-06-03 10:26:54 [INFO]: Epoch 012 - training loss: 0.5250, validation loss: 0.3722
2024-06-03 10:26:59 [INFO]: Epoch 013 - training loss: 0.5127, validation loss: 0.3676
2024-06-03 10:27:04 [INFO]: Epoch 014 - training loss: 0.5032, validation loss: 0.3710
2024-06-03 10:27:09 [INFO]: Epoch 015 - training loss: 0.4985, validation loss: 0.3646
2024-06-03 10:27:14 [INFO]: Epoch 016 - training loss: 0.4814, validation loss: 0.3595
2024-06-03 10:27:19 [INFO]: Epoch 017 - training loss: 0.4746, validation loss: 0.3589
2024-06-03 10:27:23 [INFO]: Epoch 018 - training loss: 0.4642, validation loss: 0.3571
2024-06-03 10:27:28 [INFO]: Epoch 019 - training loss: 0.4587, validation loss: 0.3571
2024-06-03 10:27:33 [INFO]: Epoch 020 - training loss: 0.4563, validation loss: 0.3590
2024-06-03 10:27:38 [INFO]: Epoch 021 - training loss: 0.4474, validation loss: 0.3554
2024-06-03 10:27:43 [INFO]: Epoch 022 - training loss: 0.4423, validation loss: 0.3562
2024-06-03 10:27:48 [INFO]: Epoch 023 - training loss: 0.4396, validation loss: 0.3551
2024-06-03 10:27:52 [INFO]: Epoch 024 - training loss: 0.4291, validation loss: 0.3530
2024-06-03 10:27:57 [INFO]: Epoch 025 - training loss: 0.4229, validation loss: 0.3539
2024-06-03 10:28:02 [INFO]: Epoch 026 - training loss: 0.4181, validation loss: 0.3529
2024-06-03 10:28:07 [INFO]: Epoch 027 - training loss: 0.4187, validation loss: 0.3547
2024-06-03 10:28:12 [INFO]: Epoch 028 - training loss: 0.4153, validation loss: 0.3562
2024-06-03 10:28:16 [INFO]: Epoch 029 - training loss: 0.4100, validation loss: 0.3511
2024-06-03 10:28:21 [INFO]: Epoch 030 - training loss: 0.4053, validation loss: 0.3500
2024-06-03 10:28:26 [INFO]: Epoch 031 - training loss: 0.3973, validation loss: 0.3502
2024-06-03 10:28:31 [INFO]: Epoch 032 - training loss: 0.3914, validation loss: 0.3518
2024-06-03 10:28:36 [INFO]: Epoch 033 - training loss: 0.3941, validation loss: 0.3516
2024-06-03 10:28:41 [INFO]: Epoch 034 - training loss: 0.3891, validation loss: 0.3480
2024-06-03 10:28:46 [INFO]: Epoch 035 - training loss: 0.3817, validation loss: 0.3482
2024-06-03 10:28:50 [INFO]: Epoch 036 - training loss: 0.3779, validation loss: 0.3485
2024-06-03 10:28:55 [INFO]: Epoch 037 - training loss: 0.3795, validation loss: 0.3467
2024-06-03 10:29:00 [INFO]: Epoch 038 - training loss: 0.3752, validation loss: 0.3466
2024-06-03 10:29:05 [INFO]: Epoch 039 - training loss: 0.3683, validation loss: 0.3491
2024-06-03 10:29:10 [INFO]: Epoch 040 - training loss: 0.3700, validation loss: 0.3472
2024-06-03 10:29:15 [INFO]: Epoch 041 - training loss: 0.3696, validation loss: 0.3489
2024-06-03 10:29:19 [INFO]: Epoch 042 - training loss: 0.3646, validation loss: 0.3489
2024-06-03 10:29:24 [INFO]: Epoch 043 - training loss: 0.3596, validation loss: 0.3483
2024-06-03 10:29:29 [INFO]: Epoch 044 - training loss: 0.3542, validation loss: 0.3474
2024-06-03 10:29:33 [INFO]: Epoch 045 - training loss: 0.3535, validation loss: 0.3475
2024-06-03 10:29:38 [INFO]: Epoch 046 - training loss: 0.3553, validation loss: 0.3447
2024-06-03 10:29:43 [INFO]: Epoch 047 - training loss: 0.3510, validation loss: 0.3479
2024-06-03 10:29:48 [INFO]: Epoch 048 - training loss: 0.3483, validation loss: 0.3472
2024-06-03 10:29:52 [INFO]: Epoch 049 - training loss: 0.3448, validation loss: 0.3464
2024-06-03 10:29:57 [INFO]: Epoch 050 - training loss: 0.3505, validation loss: 0.3446
2024-06-03 10:30:02 [INFO]: Epoch 051 - training loss: 0.3427, validation loss: 0.3501
2024-06-03 10:30:07 [INFO]: Epoch 052 - training loss: 0.3404, validation loss: 0.3424
2024-06-03 10:30:12 [INFO]: Epoch 053 - training loss: 0.3395, validation loss: 0.3456
2024-06-03 10:30:16 [INFO]: Epoch 054 - training loss: 0.3391, validation loss: 0.3465
2024-06-03 10:30:21 [INFO]: Epoch 055 - training loss: 0.3398, validation loss: 0.3470
2024-06-03 10:30:26 [INFO]: Epoch 056 - training loss: 0.3392, validation loss: 0.3452
2024-06-03 10:30:31 [INFO]: Epoch 057 - training loss: 0.3350, validation loss: 0.3437
2024-06-03 10:30:36 [INFO]: Epoch 058 - training loss: 0.3333, validation loss: 0.3427
2024-06-03 10:30:41 [INFO]: Epoch 059 - training loss: 0.3322, validation loss: 0.3437
2024-06-03 10:30:45 [INFO]: Epoch 060 - training loss: 0.3297, validation loss: 0.3439
2024-06-03 10:30:50 [INFO]: Epoch 061 - training loss: 0.3315, validation loss: 0.3428
2024-06-03 10:30:55 [INFO]: Epoch 062 - training loss: 0.3295, validation loss: 0.3453
2024-06-03 10:30:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:30:55 [INFO]: Finished training. The best model is from epoch#52.
2024-06-03 10:30:56 [INFO]: Saved the model to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_0/20240603_T102547/SCINet.pypots
2024-06-03 10:30:57 [INFO]: Successfully saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_0/imputation.pkl
2024-06-03 10:30:57 [INFO]: Round0 - SCINet on BeijingAir: MAE=0.3003, MSE=0.3613, MRE=0.4044
2024-06-03 10:30:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:30:57 [INFO]: Using the given device: cuda:0
2024-06-03 10:30:57 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_1/20240603_T103057
2024-06-03 10:30:57 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_1/20240603_T103057/tensorboard
2024-06-03 10:30:58 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-03 10:31:03 [INFO]: Epoch 001 - training loss: 1.4466, validation loss: 1.0427
2024-06-03 10:31:08 [INFO]: Epoch 002 - training loss: 1.1356, validation loss: 0.6927
2024-06-03 10:31:13 [INFO]: Epoch 003 - training loss: 0.9062, validation loss: 0.5679
2024-06-03 10:31:18 [INFO]: Epoch 004 - training loss: 0.8032, validation loss: 0.5024
2024-06-03 10:31:23 [INFO]: Epoch 005 - training loss: 0.7319, validation loss: 0.4671
2024-06-03 10:31:27 [INFO]: Epoch 006 - training loss: 0.6817, validation loss: 0.4467
2024-06-03 10:31:32 [INFO]: Epoch 007 - training loss: 0.6450, validation loss: 0.4288
2024-06-03 10:31:37 [INFO]: Epoch 008 - training loss: 0.6163, validation loss: 0.4116
2024-06-03 10:31:42 [INFO]: Epoch 009 - training loss: 0.5985, validation loss: 0.4006
2024-06-03 10:31:46 [INFO]: Epoch 010 - training loss: 0.5748, validation loss: 0.3923
2024-06-03 10:31:51 [INFO]: Epoch 011 - training loss: 0.5599, validation loss: 0.3854
2024-06-03 10:31:56 [INFO]: Epoch 012 - training loss: 0.5441, validation loss: 0.3844
2024-06-03 10:32:01 [INFO]: Epoch 013 - training loss: 0.5286, validation loss: 0.3817
2024-06-03 10:32:06 [INFO]: Epoch 014 - training loss: 0.5191, validation loss: 0.3765
2024-06-03 10:32:11 [INFO]: Epoch 015 - training loss: 0.5108, validation loss: 0.3746
2024-06-03 10:32:15 [INFO]: Epoch 016 - training loss: 0.5011, validation loss: 0.3679
2024-06-03 10:32:20 [INFO]: Epoch 017 - training loss: 0.4915, validation loss: 0.3680
2024-06-03 10:32:25 [INFO]: Epoch 018 - training loss: 0.4824, validation loss: 0.3682
2024-06-03 10:32:30 [INFO]: Epoch 019 - training loss: 0.4694, validation loss: 0.3670
2024-06-03 10:32:35 [INFO]: Epoch 020 - training loss: 0.4677, validation loss: 0.3618
2024-06-03 10:32:40 [INFO]: Epoch 021 - training loss: 0.4545, validation loss: 0.3608
2024-06-03 10:32:44 [INFO]: Epoch 022 - training loss: 0.4520, validation loss: 0.3620
2024-06-03 10:32:49 [INFO]: Epoch 023 - training loss: 0.4476, validation loss: 0.3612
2024-06-03 10:32:54 [INFO]: Epoch 024 - training loss: 0.4417, validation loss: 0.3601
2024-06-03 10:32:59 [INFO]: Epoch 025 - training loss: 0.4342, validation loss: 0.3590
2024-06-03 10:33:03 [INFO]: Epoch 026 - training loss: 0.4312, validation loss: 0.3563
2024-06-03 10:33:08 [INFO]: Epoch 027 - training loss: 0.4217, validation loss: 0.3590
2024-06-03 10:33:13 [INFO]: Epoch 028 - training loss: 0.4160, validation loss: 0.3547
2024-06-03 10:33:18 [INFO]: Epoch 029 - training loss: 0.4174, validation loss: 0.3554
2024-06-03 10:33:23 [INFO]: Epoch 030 - training loss: 0.4110, validation loss: 0.3547
2024-06-03 10:33:28 [INFO]: Epoch 031 - training loss: 0.4053, validation loss: 0.3530
2024-06-03 10:33:33 [INFO]: Epoch 032 - training loss: 0.4048, validation loss: 0.3542
2024-06-03 10:33:37 [INFO]: Epoch 033 - training loss: 0.3991, validation loss: 0.3537
2024-06-03 10:33:40 [INFO]: Epoch 034 - training loss: 0.3950, validation loss: 0.3548
2024-06-03 10:33:44 [INFO]: Epoch 035 - training loss: 0.3904, validation loss: 0.3546
2024-06-03 10:33:48 [INFO]: Epoch 036 - training loss: 0.3934, validation loss: 0.3530
2024-06-03 10:33:52 [INFO]: Epoch 037 - training loss: 0.3801, validation loss: 0.3508
2024-06-03 10:33:57 [INFO]: Epoch 038 - training loss: 0.3815, validation loss: 0.3539
2024-06-03 10:34:02 [INFO]: Epoch 039 - training loss: 0.3789, validation loss: 0.3494
2024-06-03 10:34:07 [INFO]: Epoch 040 - training loss: 0.3732, validation loss: 0.3528
2024-06-03 10:34:12 [INFO]: Epoch 041 - training loss: 0.3727, validation loss: 0.3505
2024-06-03 10:34:16 [INFO]: Epoch 042 - training loss: 0.3672, validation loss: 0.3512
2024-06-03 10:34:21 [INFO]: Epoch 043 - training loss: 0.3681, validation loss: 0.3509
2024-06-03 10:34:26 [INFO]: Epoch 044 - training loss: 0.3621, validation loss: 0.3500
2024-06-03 10:34:31 [INFO]: Epoch 045 - training loss: 0.3600, validation loss: 0.3516
2024-06-03 10:34:36 [INFO]: Epoch 046 - training loss: 0.3617, validation loss: 0.3497
2024-06-03 10:34:41 [INFO]: Epoch 047 - training loss: 0.3567, validation loss: 0.3521
2024-06-03 10:34:46 [INFO]: Epoch 048 - training loss: 0.3517, validation loss: 0.3507
2024-06-03 10:34:51 [INFO]: Epoch 049 - training loss: 0.3529, validation loss: 0.3513
2024-06-03 10:34:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:34:51 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 10:34:52 [INFO]: Saved the model to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_1/20240603_T103057/SCINet.pypots
2024-06-03 10:34:53 [INFO]: Successfully saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_1/imputation.pkl
2024-06-03 10:34:53 [INFO]: Round1 - SCINet on BeijingAir: MAE=0.3007, MSE=0.3660, MRE=0.4050
2024-06-03 10:34:53 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:34:53 [INFO]: Using the given device: cuda:0
2024-06-03 10:34:53 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_2/20240603_T103453
2024-06-03 10:34:53 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_2/20240603_T103453/tensorboard
2024-06-03 10:34:54 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-03 10:34:59 [INFO]: Epoch 001 - training loss: 1.4214, validation loss: 0.9285
2024-06-03 10:35:04 [INFO]: Epoch 002 - training loss: 1.0356, validation loss: 0.6438
2024-06-03 10:35:09 [INFO]: Epoch 003 - training loss: 0.8630, validation loss: 0.5473
2024-06-03 10:35:14 [INFO]: Epoch 004 - training loss: 0.7837, validation loss: 0.5122
2024-06-03 10:35:19 [INFO]: Epoch 005 - training loss: 0.7263, validation loss: 0.4896
2024-06-03 10:35:23 [INFO]: Epoch 006 - training loss: 0.6842, validation loss: 0.4670
2024-06-03 10:35:28 [INFO]: Epoch 007 - training loss: 0.6558, validation loss: 0.4598
2024-06-03 10:35:33 [INFO]: Epoch 008 - training loss: 0.6323, validation loss: 0.4463
2024-06-03 10:35:38 [INFO]: Epoch 009 - training loss: 0.6070, validation loss: 0.4426
2024-06-03 10:35:42 [INFO]: Epoch 010 - training loss: 0.5910, validation loss: 0.4333
2024-06-03 10:35:47 [INFO]: Epoch 011 - training loss: 0.5739, validation loss: 0.4330
2024-06-03 10:35:52 [INFO]: Epoch 012 - training loss: 0.5642, validation loss: 0.4274
2024-06-03 10:35:56 [INFO]: Epoch 013 - training loss: 0.5540, validation loss: 0.4251
2024-06-03 10:36:01 [INFO]: Epoch 014 - training loss: 0.5418, validation loss: 0.4255
2024-06-03 10:36:06 [INFO]: Epoch 015 - training loss: 0.5304, validation loss: 0.4149
2024-06-03 10:36:10 [INFO]: Epoch 016 - training loss: 0.5104, validation loss: 0.4115
2024-06-03 10:36:15 [INFO]: Epoch 017 - training loss: 0.5018, validation loss: 0.4156
2024-06-03 10:36:20 [INFO]: Epoch 018 - training loss: 0.4959, validation loss: 0.4102
2024-06-03 10:36:24 [INFO]: Epoch 019 - training loss: 0.4867, validation loss: 0.4057
2024-06-03 10:36:29 [INFO]: Epoch 020 - training loss: 0.4766, validation loss: 0.4059
2024-06-03 10:36:34 [INFO]: Epoch 021 - training loss: 0.4681, validation loss: 0.4090
2024-06-03 10:36:39 [INFO]: Epoch 022 - training loss: 0.4657, validation loss: 0.4030
2024-06-03 10:36:43 [INFO]: Epoch 023 - training loss: 0.4614, validation loss: 0.4013
2024-06-03 10:36:48 [INFO]: Epoch 024 - training loss: 0.4530, validation loss: 0.4036
2024-06-03 10:36:53 [INFO]: Epoch 025 - training loss: 0.4439, validation loss: 0.3976
2024-06-03 10:36:58 [INFO]: Epoch 026 - training loss: 0.4397, validation loss: 0.3987
2024-06-03 10:37:02 [INFO]: Epoch 027 - training loss: 0.4396, validation loss: 0.3956
2024-06-03 10:37:07 [INFO]: Epoch 028 - training loss: 0.4298, validation loss: 0.3987
2024-06-03 10:37:12 [INFO]: Epoch 029 - training loss: 0.4285, validation loss: 0.3978
2024-06-03 10:37:17 [INFO]: Epoch 030 - training loss: 0.4204, validation loss: 0.3951
2024-06-03 10:37:22 [INFO]: Epoch 031 - training loss: 0.4135, validation loss: 0.3951
2024-06-03 10:37:27 [INFO]: Epoch 032 - training loss: 0.4132, validation loss: 0.3968
2024-06-03 10:37:31 [INFO]: Epoch 033 - training loss: 0.4110, validation loss: 0.3948
2024-06-03 10:37:36 [INFO]: Epoch 034 - training loss: 0.4059, validation loss: 0.3942
2024-06-03 10:37:41 [INFO]: Epoch 035 - training loss: 0.4003, validation loss: 0.3973
2024-06-03 10:37:46 [INFO]: Epoch 036 - training loss: 0.3963, validation loss: 0.3910
2024-06-03 10:37:50 [INFO]: Epoch 037 - training loss: 0.3985, validation loss: 0.3939
2024-06-03 10:37:55 [INFO]: Epoch 038 - training loss: 0.3876, validation loss: 0.3944
2024-06-03 10:38:00 [INFO]: Epoch 039 - training loss: 0.3881, validation loss: 0.3932
2024-06-03 10:38:05 [INFO]: Epoch 040 - training loss: 0.3814, validation loss: 0.3915
2024-06-03 10:38:10 [INFO]: Epoch 041 - training loss: 0.3791, validation loss: 0.3902
2024-06-03 10:38:14 [INFO]: Epoch 042 - training loss: 0.3800, validation loss: 0.3923
2024-06-03 10:38:19 [INFO]: Epoch 043 - training loss: 0.3726, validation loss: 0.3915
2024-06-03 10:38:24 [INFO]: Epoch 044 - training loss: 0.3710, validation loss: 0.3911
2024-06-03 10:38:28 [INFO]: Epoch 045 - training loss: 0.3693, validation loss: 0.3913
2024-06-03 10:38:32 [INFO]: Epoch 046 - training loss: 0.3679, validation loss: 0.3914
2024-06-03 10:38:37 [INFO]: Epoch 047 - training loss: 0.3652, validation loss: 0.3905
2024-06-03 10:38:42 [INFO]: Epoch 048 - training loss: 0.3658, validation loss: 0.3908
2024-06-03 10:38:46 [INFO]: Epoch 049 - training loss: 0.3609, validation loss: 0.3925
2024-06-03 10:38:51 [INFO]: Epoch 050 - training loss: 0.3597, validation loss: 0.3881
2024-06-03 10:38:56 [INFO]: Epoch 051 - training loss: 0.3573, validation loss: 0.3901
2024-06-03 10:39:01 [INFO]: Epoch 052 - training loss: 0.3559, validation loss: 0.3906
2024-06-03 10:39:05 [INFO]: Epoch 053 - training loss: 0.3543, validation loss: 0.3871
2024-06-03 10:39:10 [INFO]: Epoch 054 - training loss: 0.3486, validation loss: 0.3917
2024-06-03 10:39:14 [INFO]: Epoch 055 - training loss: 0.3467, validation loss: 0.3898
2024-06-03 10:39:19 [INFO]: Epoch 056 - training loss: 0.3501, validation loss: 0.3885
2024-06-03 10:39:23 [INFO]: Epoch 057 - training loss: 0.3431, validation loss: 0.3897
2024-06-03 10:39:28 [INFO]: Epoch 058 - training loss: 0.3427, validation loss: 0.3880
2024-06-03 10:39:32 [INFO]: Epoch 059 - training loss: 0.3408, validation loss: 0.3892
2024-06-03 10:39:36 [INFO]: Epoch 060 - training loss: 0.3401, validation loss: 0.3895
2024-06-03 10:39:41 [INFO]: Epoch 061 - training loss: 0.3391, validation loss: 0.3890
2024-06-03 10:39:45 [INFO]: Epoch 062 - training loss: 0.3345, validation loss: 0.3896
2024-06-03 10:39:49 [INFO]: Epoch 063 - training loss: 0.3348, validation loss: 0.3881
2024-06-03 10:39:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:39:49 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 10:39:50 [INFO]: Saved the model to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_2/20240603_T103453/SCINet.pypots
2024-06-03 10:39:51 [INFO]: Successfully saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_2/imputation.pkl
2024-06-03 10:39:51 [INFO]: Round2 - SCINet on BeijingAir: MAE=0.3186, MSE=0.4124, MRE=0.4290
2024-06-03 10:39:51 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:39:51 [INFO]: Using the given device: cuda:0
2024-06-03 10:39:51 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_3/20240603_T103951
2024-06-03 10:39:51 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_3/20240603_T103951/tensorboard
2024-06-03 10:39:52 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-03 10:39:57 [INFO]: Epoch 001 - training loss: 1.4113, validation loss: 0.9621
2024-06-03 10:40:01 [INFO]: Epoch 002 - training loss: 1.0575, validation loss: 0.6332
2024-06-03 10:40:06 [INFO]: Epoch 003 - training loss: 0.8754, validation loss: 0.5241
2024-06-03 10:40:10 [INFO]: Epoch 004 - training loss: 0.7614, validation loss: 0.4765
2024-06-03 10:40:15 [INFO]: Epoch 005 - training loss: 0.6968, validation loss: 0.4467
2024-06-03 10:40:19 [INFO]: Epoch 006 - training loss: 0.6549, validation loss: 0.4233
2024-06-03 10:40:24 [INFO]: Epoch 007 - training loss: 0.6205, validation loss: 0.4099
2024-06-03 10:40:29 [INFO]: Epoch 008 - training loss: 0.5869, validation loss: 0.3897
2024-06-03 10:40:33 [INFO]: Epoch 009 - training loss: 0.5720, validation loss: 0.3883
2024-06-03 10:40:37 [INFO]: Epoch 010 - training loss: 0.5491, validation loss: 0.3826
2024-06-03 10:40:42 [INFO]: Epoch 011 - training loss: 0.5391, validation loss: 0.3773
2024-06-03 10:40:46 [INFO]: Epoch 012 - training loss: 0.5300, validation loss: 0.3772
2024-06-03 10:40:51 [INFO]: Epoch 013 - training loss: 0.5198, validation loss: 0.3719
2024-06-03 10:40:55 [INFO]: Epoch 014 - training loss: 0.5025, validation loss: 0.3699
2024-06-03 10:41:00 [INFO]: Epoch 015 - training loss: 0.4912, validation loss: 0.3674
2024-06-03 10:41:04 [INFO]: Epoch 016 - training loss: 0.4869, validation loss: 0.3669
2024-06-03 10:41:09 [INFO]: Epoch 017 - training loss: 0.4761, validation loss: 0.3660
2024-06-03 10:41:13 [INFO]: Epoch 018 - training loss: 0.4712, validation loss: 0.3630
2024-06-03 10:41:18 [INFO]: Epoch 019 - training loss: 0.4654, validation loss: 0.3593
2024-06-03 10:41:22 [INFO]: Epoch 020 - training loss: 0.4553, validation loss: 0.3613
2024-06-03 10:41:26 [INFO]: Epoch 021 - training loss: 0.4498, validation loss: 0.3603
2024-06-03 10:41:30 [INFO]: Epoch 022 - training loss: 0.4425, validation loss: 0.3595
2024-06-03 10:41:35 [INFO]: Epoch 023 - training loss: 0.4341, validation loss: 0.3574
2024-06-03 10:41:39 [INFO]: Epoch 024 - training loss: 0.4352, validation loss: 0.3570
2024-06-03 10:41:44 [INFO]: Epoch 025 - training loss: 0.4250, validation loss: 0.3536
2024-06-03 10:41:49 [INFO]: Epoch 026 - training loss: 0.4233, validation loss: 0.3551
2024-06-03 10:41:53 [INFO]: Epoch 027 - training loss: 0.4200, validation loss: 0.3535
2024-06-03 10:41:58 [INFO]: Epoch 028 - training loss: 0.4139, validation loss: 0.3535
2024-06-03 10:42:02 [INFO]: Epoch 029 - training loss: 0.4098, validation loss: 0.3534
2024-06-03 10:42:07 [INFO]: Epoch 030 - training loss: 0.4022, validation loss: 0.3521
2024-06-03 10:42:11 [INFO]: Epoch 031 - training loss: 0.4016, validation loss: 0.3526
2024-06-03 10:42:16 [INFO]: Epoch 032 - training loss: 0.3981, validation loss: 0.3516
2024-06-03 10:42:21 [INFO]: Epoch 033 - training loss: 0.3891, validation loss: 0.3481
2024-06-03 10:42:25 [INFO]: Epoch 034 - training loss: 0.3898, validation loss: 0.3469
2024-06-03 10:42:30 [INFO]: Epoch 035 - training loss: 0.3840, validation loss: 0.3525
2024-06-03 10:42:35 [INFO]: Epoch 036 - training loss: 0.3827, validation loss: 0.3490
2024-06-03 10:42:39 [INFO]: Epoch 037 - training loss: 0.3829, validation loss: 0.3507
2024-06-03 10:42:44 [INFO]: Epoch 038 - training loss: 0.3799, validation loss: 0.3526
2024-06-03 10:42:47 [INFO]: Epoch 039 - training loss: 0.3778, validation loss: 0.3491
2024-06-03 10:42:50 [INFO]: Epoch 040 - training loss: 0.3726, validation loss: 0.3501
2024-06-03 10:42:53 [INFO]: Epoch 041 - training loss: 0.3715, validation loss: 0.3476
2024-06-03 10:42:56 [INFO]: Epoch 042 - training loss: 0.3670, validation loss: 0.3505
2024-06-03 10:43:00 [INFO]: Epoch 043 - training loss: 0.3640, validation loss: 0.3495
2024-06-03 10:43:04 [INFO]: Epoch 044 - training loss: 0.3561, validation loss: 0.3483
2024-06-03 10:43:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:43:04 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 10:43:04 [INFO]: Saved the model to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_3/20240603_T103951/SCINet.pypots
2024-06-03 10:43:06 [INFO]: Successfully saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_3/imputation.pkl
2024-06-03 10:43:06 [INFO]: Round3 - SCINet on BeijingAir: MAE=0.2991, MSE=0.3663, MRE=0.4028
2024-06-03 10:43:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:43:06 [INFO]: Using the given device: cuda:0
2024-06-03 10:43:06 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_4/20240603_T104306
2024-06-03 10:43:06 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_4/20240603_T104306/tensorboard
2024-06-03 10:43:07 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 26,833,140
2024-06-03 10:43:10 [INFO]: Epoch 001 - training loss: 1.4200, validation loss: 0.8965
2024-06-03 10:43:14 [INFO]: Epoch 002 - training loss: 1.0212, validation loss: 0.6036
2024-06-03 10:43:18 [INFO]: Epoch 003 - training loss: 0.8460, validation loss: 0.5162
2024-06-03 10:43:22 [INFO]: Epoch 004 - training loss: 0.7457, validation loss: 0.4627
2024-06-03 10:43:26 [INFO]: Epoch 005 - training loss: 0.6868, validation loss: 0.4334
2024-06-03 10:43:30 [INFO]: Epoch 006 - training loss: 0.6442, validation loss: 0.4129
2024-06-03 10:43:35 [INFO]: Epoch 007 - training loss: 0.6150, validation loss: 0.4000
2024-06-03 10:43:39 [INFO]: Epoch 008 - training loss: 0.5860, validation loss: 0.3993
2024-06-03 10:43:43 [INFO]: Epoch 009 - training loss: 0.5693, validation loss: 0.3853
2024-06-03 10:43:47 [INFO]: Epoch 010 - training loss: 0.5523, validation loss: 0.3806
2024-06-03 10:43:51 [INFO]: Epoch 011 - training loss: 0.5370, validation loss: 0.3737
2024-06-03 10:43:55 [INFO]: Epoch 012 - training loss: 0.5195, validation loss: 0.3687
2024-06-03 10:43:59 [INFO]: Epoch 013 - training loss: 0.5152, validation loss: 0.3685
2024-06-03 10:44:04 [INFO]: Epoch 014 - training loss: 0.5013, validation loss: 0.3621
2024-06-03 10:44:08 [INFO]: Epoch 015 - training loss: 0.4927, validation loss: 0.3611
2024-06-03 10:44:12 [INFO]: Epoch 016 - training loss: 0.4854, validation loss: 0.3597
2024-06-03 10:44:16 [INFO]: Epoch 017 - training loss: 0.4799, validation loss: 0.3577
2024-06-03 10:44:20 [INFO]: Epoch 018 - training loss: 0.4693, validation loss: 0.3592
2024-06-03 10:44:24 [INFO]: Epoch 019 - training loss: 0.4588, validation loss: 0.3556
2024-06-03 10:44:28 [INFO]: Epoch 020 - training loss: 0.4561, validation loss: 0.3557
2024-06-03 10:44:32 [INFO]: Epoch 021 - training loss: 0.4477, validation loss: 0.3539
2024-06-03 10:44:36 [INFO]: Epoch 022 - training loss: 0.4468, validation loss: 0.3579
2024-06-03 10:44:40 [INFO]: Epoch 023 - training loss: 0.4378, validation loss: 0.3540
2024-06-03 10:44:44 [INFO]: Epoch 024 - training loss: 0.4343, validation loss: 0.3539
2024-06-03 10:44:48 [INFO]: Epoch 025 - training loss: 0.4265, validation loss: 0.3547
2024-06-03 10:44:52 [INFO]: Epoch 026 - training loss: 0.4233, validation loss: 0.3502
2024-06-03 10:44:56 [INFO]: Epoch 027 - training loss: 0.4161, validation loss: 0.3504
2024-06-03 10:45:00 [INFO]: Epoch 028 - training loss: 0.4147, validation loss: 0.3525
2024-06-03 10:45:05 [INFO]: Epoch 029 - training loss: 0.4124, validation loss: 0.3536
2024-06-03 10:45:09 [INFO]: Epoch 030 - training loss: 0.4069, validation loss: 0.3511
2024-06-03 10:45:12 [INFO]: Epoch 031 - training loss: 0.4003, validation loss: 0.3517
2024-06-03 10:45:16 [INFO]: Epoch 032 - training loss: 0.3929, validation loss: 0.3465
2024-06-03 10:45:21 [INFO]: Epoch 033 - training loss: 0.3906, validation loss: 0.3479
2024-06-03 10:45:24 [INFO]: Epoch 034 - training loss: 0.3925, validation loss: 0.3455
2024-06-03 10:45:29 [INFO]: Epoch 035 - training loss: 0.3834, validation loss: 0.3494
2024-06-03 10:45:33 [INFO]: Epoch 036 - training loss: 0.3832, validation loss: 0.3439
2024-06-03 10:45:36 [INFO]: Epoch 037 - training loss: 0.3796, validation loss: 0.3495
2024-06-03 10:45:40 [INFO]: Epoch 038 - training loss: 0.3723, validation loss: 0.3464
2024-06-03 10:45:44 [INFO]: Epoch 039 - training loss: 0.3719, validation loss: 0.3450
2024-06-03 10:45:48 [INFO]: Epoch 040 - training loss: 0.3685, validation loss: 0.3449
2024-06-03 10:45:51 [INFO]: Epoch 041 - training loss: 0.3697, validation loss: 0.3479
2024-06-03 10:45:55 [INFO]: Epoch 042 - training loss: 0.3635, validation loss: 0.3484
2024-06-03 10:45:59 [INFO]: Epoch 043 - training loss: 0.3609, validation loss: 0.3519
2024-06-03 10:46:02 [INFO]: Epoch 044 - training loss: 0.3609, validation loss: 0.3472
2024-06-03 10:46:06 [INFO]: Epoch 045 - training loss: 0.3553, validation loss: 0.3480
2024-06-03 10:46:09 [INFO]: Epoch 046 - training loss: 0.3599, validation loss: 0.3453
2024-06-03 10:46:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:46:09 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 10:46:10 [INFO]: Saved the model to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_4/20240603_T104306/SCINet.pypots
2024-06-03 10:46:11 [INFO]: Successfully saved to results_point_rate09/BeijingAir/SCINet_BeijingAir/round_4/imputation.pkl
2024-06-03 10:46:11 [INFO]: Round4 - SCINet on BeijingAir: MAE=0.2998, MSE=0.3635, MRE=0.4037
2024-06-03 10:46:11 [INFO]: Done! Final results:
Averaged SCINet (26,833,140 params) on BeijingAir: MAE=0.2997 ± 0.007704169159757691, MSE=0.3713 ± 0.020047401556072764, MRE=0.3976 ± 0.010220593136787996, average inference time=0.31