2024-06-03 00:37:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:37:46 [INFO]: Using the given device: cuda:0
2024-06-03 00:37:47 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T003747
2024-06-03 00:37:47 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T003747/tensorboard
2024-06-03 00:37:48 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 00:37:58 [INFO]: Epoch 001 - training loss: 1.6728, validation loss: 1.4410
2024-06-03 00:38:06 [INFO]: Epoch 002 - training loss: 1.5674, validation loss: 1.4409
2024-06-03 00:38:15 [INFO]: Epoch 003 - training loss: 1.4668, validation loss: 1.4436
2024-06-03 00:38:24 [INFO]: Epoch 004 - training loss: 1.3998, validation loss: 1.4455
2024-06-03 00:38:32 [INFO]: Epoch 005 - training loss: 1.3426, validation loss: 1.4461
2024-06-03 00:38:41 [INFO]: Epoch 006 - training loss: 1.3000, validation loss: 1.4441
2024-06-03 00:38:49 [INFO]: Epoch 007 - training loss: 1.2710, validation loss: 1.4401
2024-06-03 00:38:58 [INFO]: Epoch 008 - training loss: 1.2466, validation loss: 1.4344
2024-06-03 00:39:07 [INFO]: Epoch 009 - training loss: 1.2245, validation loss: 1.4281
2024-06-03 00:39:15 [INFO]: Epoch 010 - training loss: 1.2053, validation loss: 1.4214
2024-06-03 00:39:24 [INFO]: Epoch 011 - training loss: 1.1900, validation loss: 1.4153
2024-06-03 00:39:32 [INFO]: Epoch 012 - training loss: 1.1821, validation loss: 1.4100
2024-06-03 00:39:41 [INFO]: Epoch 013 - training loss: 1.1701, validation loss: 1.4044
2024-06-03 00:39:49 [INFO]: Epoch 014 - training loss: 1.1655, validation loss: 1.3993
2024-06-03 00:39:58 [INFO]: Epoch 015 - training loss: 1.1480, validation loss: 1.3953
2024-06-03 00:40:06 [INFO]: Epoch 016 - training loss: 1.1433, validation loss: 1.3910
2024-06-03 00:40:14 [INFO]: Epoch 017 - training loss: 1.1382, validation loss: 1.3878
2024-06-03 00:40:23 [INFO]: Epoch 018 - training loss: 1.1299, validation loss: 1.3847
2024-06-03 00:40:31 [INFO]: Epoch 019 - training loss: 1.1239, validation loss: 1.3820
2024-06-03 00:40:39 [INFO]: Epoch 020 - training loss: 1.1155, validation loss: 1.3794
2024-06-03 00:40:48 [INFO]: Epoch 021 - training loss: 1.1104, validation loss: 1.3766
2024-06-03 00:40:56 [INFO]: Epoch 022 - training loss: 1.1027, validation loss: 1.3747
2024-06-03 00:41:04 [INFO]: Epoch 023 - training loss: 1.1034, validation loss: 1.3725
2024-06-03 00:41:13 [INFO]: Epoch 024 - training loss: 1.1002, validation loss: 1.3706
2024-06-03 00:41:22 [INFO]: Epoch 025 - training loss: 1.0926, validation loss: 1.3695
2024-06-03 00:41:30 [INFO]: Epoch 026 - training loss: 1.0860, validation loss: 1.3685
2024-06-03 00:41:39 [INFO]: Epoch 027 - training loss: 1.0895, validation loss: 1.3671
2024-06-03 00:41:47 [INFO]: Epoch 028 - training loss: 1.0809, validation loss: 1.3661
2024-06-03 00:41:55 [INFO]: Epoch 029 - training loss: 1.0771, validation loss: 1.3648
2024-06-03 00:42:04 [INFO]: Epoch 030 - training loss: 1.0747, validation loss: 1.3642
2024-06-03 00:42:13 [INFO]: Epoch 031 - training loss: 1.0742, validation loss: 1.3636
2024-06-03 00:42:21 [INFO]: Epoch 032 - training loss: 1.0672, validation loss: 1.3623
2024-06-03 00:42:30 [INFO]: Epoch 033 - training loss: 1.0630, validation loss: 1.3620
2024-06-03 00:42:38 [INFO]: Epoch 034 - training loss: 1.0638, validation loss: 1.3615
2024-06-03 00:42:46 [INFO]: Epoch 035 - training loss: 1.0625, validation loss: 1.3605
2024-06-03 00:42:55 [INFO]: Epoch 036 - training loss: 1.0555, validation loss: 1.3601
2024-06-03 00:43:04 [INFO]: Epoch 037 - training loss: 1.0550, validation loss: 1.3594
2024-06-03 00:43:12 [INFO]: Epoch 038 - training loss: 1.0548, validation loss: 1.3586
2024-06-03 00:43:20 [INFO]: Epoch 039 - training loss: 1.0460, validation loss: 1.3582
2024-06-03 00:43:29 [INFO]: Epoch 040 - training loss: 1.0416, validation loss: 1.3586
2024-06-03 00:43:38 [INFO]: Epoch 041 - training loss: 1.0403, validation loss: 1.3578
2024-06-03 00:43:46 [INFO]: Epoch 042 - training loss: 1.0395, validation loss: 1.3570
2024-06-03 00:43:54 [INFO]: Epoch 043 - training loss: 1.0378, validation loss: 1.3568
2024-06-03 00:44:03 [INFO]: Epoch 044 - training loss: 1.0389, validation loss: 1.3563
2024-06-03 00:44:12 [INFO]: Epoch 045 - training loss: 1.0359, validation loss: 1.3557
2024-06-03 00:44:20 [INFO]: Epoch 046 - training loss: 1.0296, validation loss: 1.3555
2024-06-03 00:44:28 [INFO]: Epoch 047 - training loss: 1.0308, validation loss: 1.3550
2024-06-03 00:44:35 [INFO]: Epoch 048 - training loss: 1.0202, validation loss: 1.3552
2024-06-03 00:44:44 [INFO]: Epoch 049 - training loss: 1.0268, validation loss: 1.3549
2024-06-03 00:44:52 [INFO]: Epoch 050 - training loss: 1.0226, validation loss: 1.3548
2024-06-03 00:45:00 [INFO]: Epoch 051 - training loss: 1.0211, validation loss: 1.3546
2024-06-03 00:45:08 [INFO]: Epoch 052 - training loss: 1.0194, validation loss: 1.3542
2024-06-03 00:45:16 [INFO]: Epoch 053 - training loss: 1.0171, validation loss: 1.3539
2024-06-03 00:45:24 [INFO]: Epoch 054 - training loss: 1.0135, validation loss: 1.3533
2024-06-03 00:45:33 [INFO]: Epoch 055 - training loss: 1.0121, validation loss: 1.3534
2024-06-03 00:45:42 [INFO]: Epoch 056 - training loss: 1.0064, validation loss: 1.3530
2024-06-03 00:45:50 [INFO]: Epoch 057 - training loss: 1.0044, validation loss: 1.3530
2024-06-03 00:45:58 [INFO]: Epoch 058 - training loss: 1.0026, validation loss: 1.3530
2024-06-03 00:46:06 [INFO]: Epoch 059 - training loss: 1.0050, validation loss: 1.3523
2024-06-03 00:46:15 [INFO]: Epoch 060 - training loss: 1.0027, validation loss: 1.3517
2024-06-03 00:46:24 [INFO]: Epoch 061 - training loss: 1.0030, validation loss: 1.3514
2024-06-03 00:46:33 [INFO]: Epoch 062 - training loss: 0.9912, validation loss: 1.3513
2024-06-03 00:46:41 [INFO]: Epoch 063 - training loss: 0.9934, validation loss: 1.3511
2024-06-03 00:46:49 [INFO]: Epoch 064 - training loss: 0.9925, validation loss: 1.3508
2024-06-03 00:46:57 [INFO]: Epoch 065 - training loss: 0.9892, validation loss: 1.3508
2024-06-03 00:47:05 [INFO]: Epoch 066 - training loss: 0.9930, validation loss: 1.3505
2024-06-03 00:47:13 [INFO]: Epoch 067 - training loss: 0.9884, validation loss: 1.3504
2024-06-03 00:47:21 [INFO]: Epoch 068 - training loss: 0.9850, validation loss: 1.3503
2024-06-03 00:47:29 [INFO]: Epoch 069 - training loss: 0.9881, validation loss: 1.3501
2024-06-03 00:47:37 [INFO]: Epoch 070 - training loss: 0.9829, validation loss: 1.3496
2024-06-03 00:47:44 [INFO]: Epoch 071 - training loss: 0.9825, validation loss: 1.3492
2024-06-03 00:47:52 [INFO]: Epoch 072 - training loss: 0.9812, validation loss: 1.3495
2024-06-03 00:48:00 [INFO]: Epoch 073 - training loss: 0.9790, validation loss: 1.3494
2024-06-03 00:48:08 [INFO]: Epoch 074 - training loss: 0.9742, validation loss: 1.3490
2024-06-03 00:48:16 [INFO]: Epoch 075 - training loss: 0.9734, validation loss: 1.3491
2024-06-03 00:48:24 [INFO]: Epoch 076 - training loss: 0.9707, validation loss: 1.3490
2024-06-03 00:48:31 [INFO]: Epoch 077 - training loss: 0.9683, validation loss: 1.3488
2024-06-03 00:48:39 [INFO]: Epoch 078 - training loss: 0.9721, validation loss: 1.3489
2024-06-03 00:48:47 [INFO]: Epoch 079 - training loss: 0.9652, validation loss: 1.3488
2024-06-03 00:48:55 [INFO]: Epoch 080 - training loss: 0.9611, validation loss: 1.3487
2024-06-03 00:49:02 [INFO]: Epoch 081 - training loss: 0.9680, validation loss: 1.3487
2024-06-03 00:49:10 [INFO]: Epoch 082 - training loss: 0.9617, validation loss: 1.3483
2024-06-03 00:49:18 [INFO]: Epoch 083 - training loss: 0.9611, validation loss: 1.3485
2024-06-03 00:49:26 [INFO]: Epoch 084 - training loss: 0.9568, validation loss: 1.3487
2024-06-03 00:49:33 [INFO]: Epoch 085 - training loss: 0.9580, validation loss: 1.3486
2024-06-03 00:49:42 [INFO]: Epoch 086 - training loss: 0.9520, validation loss: 1.3490
2024-06-03 00:49:50 [INFO]: Epoch 087 - training loss: 0.9488, validation loss: 1.3490
2024-06-03 00:49:57 [INFO]: Epoch 088 - training loss: 0.9521, validation loss: 1.3493
2024-06-03 00:50:05 [INFO]: Epoch 089 - training loss: 0.9471, validation loss: 1.3489
2024-06-03 00:50:13 [INFO]: Epoch 090 - training loss: 0.9493, validation loss: 1.3490
2024-06-03 00:50:21 [INFO]: Epoch 091 - training loss: 0.9423, validation loss: 1.3496
2024-06-03 00:50:30 [INFO]: Epoch 092 - training loss: 0.9439, validation loss: 1.3497
2024-06-03 00:50:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:50:30 [INFO]: Finished training. The best model is from epoch#82.
2024-06-03 00:50:30 [INFO]: Saved the model to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T003747/Autoformer.pypots
2024-06-03 00:50:31 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_0/imputation.pkl
2024-06-03 00:50:31 [INFO]: Round0 - Autoformer on BeijingAir: MAE=0.7973, MSE=1.3567, MRE=1.0737
2024-06-03 00:50:31 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:50:31 [INFO]: Using the given device: cuda:0
2024-06-03 00:50:31 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T005031
2024-06-03 00:50:31 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T005031/tensorboard
2024-06-03 00:50:32 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 00:50:39 [INFO]: Epoch 001 - training loss: 1.6768, validation loss: 1.4506
2024-06-03 00:50:46 [INFO]: Epoch 002 - training loss: 1.5603, validation loss: 1.4495
2024-06-03 00:50:53 [INFO]: Epoch 003 - training loss: 1.4710, validation loss: 1.4498
2024-06-03 00:51:00 [INFO]: Epoch 004 - training loss: 1.3959, validation loss: 1.4504
2024-06-03 00:51:07 [INFO]: Epoch 005 - training loss: 1.3453, validation loss: 1.4494
2024-06-03 00:51:14 [INFO]: Epoch 006 - training loss: 1.3003, validation loss: 1.4465
2024-06-03 00:51:21 [INFO]: Epoch 007 - training loss: 1.2711, validation loss: 1.4416
2024-06-03 00:51:28 [INFO]: Epoch 008 - training loss: 1.2499, validation loss: 1.4350
2024-06-03 00:51:35 [INFO]: Epoch 009 - training loss: 1.2241, validation loss: 1.4285
2024-06-03 00:51:42 [INFO]: Epoch 010 - training loss: 1.2066, validation loss: 1.4220
2024-06-03 00:51:49 [INFO]: Epoch 011 - training loss: 1.1869, validation loss: 1.4153
2024-06-03 00:51:56 [INFO]: Epoch 012 - training loss: 1.1799, validation loss: 1.4096
2024-06-03 00:52:03 [INFO]: Epoch 013 - training loss: 1.1723, validation loss: 1.4037
2024-06-03 00:52:10 [INFO]: Epoch 014 - training loss: 1.1586, validation loss: 1.3988
2024-06-03 00:52:17 [INFO]: Epoch 015 - training loss: 1.1446, validation loss: 1.3945
2024-06-03 00:52:23 [INFO]: Epoch 016 - training loss: 1.1393, validation loss: 1.3902
2024-06-03 00:52:30 [INFO]: Epoch 017 - training loss: 1.1360, validation loss: 1.3869
2024-06-03 00:52:37 [INFO]: Epoch 018 - training loss: 1.1268, validation loss: 1.3837
2024-06-03 00:52:44 [INFO]: Epoch 019 - training loss: 1.1253, validation loss: 1.3808
2024-06-03 00:52:51 [INFO]: Epoch 020 - training loss: 1.1148, validation loss: 1.3781
2024-06-03 00:52:58 [INFO]: Epoch 021 - training loss: 1.1095, validation loss: 1.3761
2024-06-03 00:53:05 [INFO]: Epoch 022 - training loss: 1.1047, validation loss: 1.3742
2024-06-03 00:53:12 [INFO]: Epoch 023 - training loss: 1.1047, validation loss: 1.3727
2024-06-03 00:53:19 [INFO]: Epoch 024 - training loss: 1.0975, validation loss: 1.3713
2024-06-03 00:53:26 [INFO]: Epoch 025 - training loss: 1.0950, validation loss: 1.3698
2024-06-03 00:53:32 [INFO]: Epoch 026 - training loss: 1.0871, validation loss: 1.3680
2024-06-03 00:53:39 [INFO]: Epoch 027 - training loss: 1.0843, validation loss: 1.3668
2024-06-03 00:53:46 [INFO]: Epoch 028 - training loss: 1.0839, validation loss: 1.3655
2024-06-03 00:53:53 [INFO]: Epoch 029 - training loss: 1.0838, validation loss: 1.3650
2024-06-03 00:54:00 [INFO]: Epoch 030 - training loss: 1.0791, validation loss: 1.3638
2024-06-03 00:54:07 [INFO]: Epoch 031 - training loss: 1.0723, validation loss: 1.3633
2024-06-03 00:54:14 [INFO]: Epoch 032 - training loss: 1.0639, validation loss: 1.3626
2024-06-03 00:54:21 [INFO]: Epoch 033 - training loss: 1.0677, validation loss: 1.3615
2024-06-03 00:54:28 [INFO]: Epoch 034 - training loss: 1.0616, validation loss: 1.3610
2024-06-03 00:54:35 [INFO]: Epoch 035 - training loss: 1.0622, validation loss: 1.3604
2024-06-03 00:54:42 [INFO]: Epoch 036 - training loss: 1.0660, validation loss: 1.3597
2024-06-03 00:54:49 [INFO]: Epoch 037 - training loss: 1.0593, validation loss: 1.3592
2024-06-03 00:54:56 [INFO]: Epoch 038 - training loss: 1.0595, validation loss: 1.3589
2024-06-03 00:55:03 [INFO]: Epoch 039 - training loss: 1.0504, validation loss: 1.3578
2024-06-03 00:55:11 [INFO]: Epoch 040 - training loss: 1.0511, validation loss: 1.3576
2024-06-03 00:55:18 [INFO]: Epoch 041 - training loss: 1.0454, validation loss: 1.3575
2024-06-03 00:55:25 [INFO]: Epoch 042 - training loss: 1.0444, validation loss: 1.3568
2024-06-03 00:55:32 [INFO]: Epoch 043 - training loss: 1.0433, validation loss: 1.3565
2024-06-03 00:55:38 [INFO]: Epoch 044 - training loss: 1.0456, validation loss: 1.3560
2024-06-03 00:55:45 [INFO]: Epoch 045 - training loss: 1.0399, validation loss: 1.3557
2024-06-03 00:55:52 [INFO]: Epoch 046 - training loss: 1.0306, validation loss: 1.3554
2024-06-03 00:55:59 [INFO]: Epoch 047 - training loss: 1.0335, validation loss: 1.3553
2024-06-03 00:56:05 [INFO]: Epoch 048 - training loss: 1.0360, validation loss: 1.3553
2024-06-03 00:56:13 [INFO]: Epoch 049 - training loss: 1.0325, validation loss: 1.3549
2024-06-03 00:56:19 [INFO]: Epoch 050 - training loss: 1.0337, validation loss: 1.3545
2024-06-03 00:56:26 [INFO]: Epoch 051 - training loss: 1.0286, validation loss: 1.3542
2024-06-03 00:56:33 [INFO]: Epoch 052 - training loss: 1.0260, validation loss: 1.3538
2024-06-03 00:56:40 [INFO]: Epoch 053 - training loss: 1.0269, validation loss: 1.3531
2024-06-03 00:56:47 [INFO]: Epoch 054 - training loss: 1.0238, validation loss: 1.3530
2024-06-03 00:56:54 [INFO]: Epoch 055 - training loss: 1.0217, validation loss: 1.3530
2024-06-03 00:57:01 [INFO]: Epoch 056 - training loss: 1.0221, validation loss: 1.3529
2024-06-03 00:57:08 [INFO]: Epoch 057 - training loss: 1.0171, validation loss: 1.3525
2024-06-03 00:57:15 [INFO]: Epoch 058 - training loss: 1.0150, validation loss: 1.3524
2024-06-03 00:57:22 [INFO]: Epoch 059 - training loss: 1.0133, validation loss: 1.3521
2024-06-03 00:57:29 [INFO]: Epoch 060 - training loss: 1.0099, validation loss: 1.3518
2024-06-03 00:57:36 [INFO]: Epoch 061 - training loss: 1.0108, validation loss: 1.3521
2024-06-03 00:57:43 [INFO]: Epoch 062 - training loss: 1.0083, validation loss: 1.3516
2024-06-03 00:57:50 [INFO]: Epoch 063 - training loss: 1.0016, validation loss: 1.3516
2024-06-03 00:57:57 [INFO]: Epoch 064 - training loss: 1.0090, validation loss: 1.3516
2024-06-03 00:58:04 [INFO]: Epoch 065 - training loss: 1.0075, validation loss: 1.3512
2024-06-03 00:58:10 [INFO]: Epoch 066 - training loss: 1.0070, validation loss: 1.3508
2024-06-03 00:58:17 [INFO]: Epoch 067 - training loss: 1.0049, validation loss: 1.3506
2024-06-03 00:58:24 [INFO]: Epoch 068 - training loss: 0.9974, validation loss: 1.3506
2024-06-03 00:58:31 [INFO]: Epoch 069 - training loss: 0.9964, validation loss: 1.3503
2024-06-03 00:58:38 [INFO]: Epoch 070 - training loss: 0.9927, validation loss: 1.3500
2024-06-03 00:58:45 [INFO]: Epoch 071 - training loss: 0.9976, validation loss: 1.3499
2024-06-03 00:58:51 [INFO]: Epoch 072 - training loss: 0.9926, validation loss: 1.3500
2024-06-03 00:58:59 [INFO]: Epoch 073 - training loss: 0.9914, validation loss: 1.3497
2024-06-03 00:59:06 [INFO]: Epoch 074 - training loss: 0.9895, validation loss: 1.3500
2024-06-03 00:59:13 [INFO]: Epoch 075 - training loss: 0.9879, validation loss: 1.3497
2024-06-03 00:59:20 [INFO]: Epoch 076 - training loss: 0.9902, validation loss: 1.3490
2024-06-03 00:59:27 [INFO]: Epoch 077 - training loss: 0.9885, validation loss: 1.3494
2024-06-03 00:59:33 [INFO]: Epoch 078 - training loss: 0.9911, validation loss: 1.3494
2024-06-03 00:59:40 [INFO]: Epoch 079 - training loss: 0.9834, validation loss: 1.3491
2024-06-03 00:59:47 [INFO]: Epoch 080 - training loss: 0.9861, validation loss: 1.3490
2024-06-03 00:59:54 [INFO]: Epoch 081 - training loss: 0.9828, validation loss: 1.3491
2024-06-03 01:00:01 [INFO]: Epoch 082 - training loss: 0.9878, validation loss: 1.3484
2024-06-03 01:00:08 [INFO]: Epoch 083 - training loss: 0.9803, validation loss: 1.3483
2024-06-03 01:00:15 [INFO]: Epoch 084 - training loss: 0.9846, validation loss: 1.3481
2024-06-03 01:00:22 [INFO]: Epoch 085 - training loss: 0.9800, validation loss: 1.3485
2024-06-03 01:00:29 [INFO]: Epoch 086 - training loss: 0.9722, validation loss: 1.3486
2024-06-03 01:00:36 [INFO]: Epoch 087 - training loss: 0.9765, validation loss: 1.3485
2024-06-03 01:00:43 [INFO]: Epoch 088 - training loss: 0.9804, validation loss: 1.3481
2024-06-03 01:00:50 [INFO]: Epoch 089 - training loss: 0.9709, validation loss: 1.3483
2024-06-03 01:00:57 [INFO]: Epoch 090 - training loss: 0.9761, validation loss: 1.3480
2024-06-03 01:01:04 [INFO]: Epoch 091 - training loss: 0.9769, validation loss: 1.3478
2024-06-03 01:01:11 [INFO]: Epoch 092 - training loss: 0.9662, validation loss: 1.3479
2024-06-03 01:01:17 [INFO]: Epoch 093 - training loss: 0.9699, validation loss: 1.3479
2024-06-03 01:01:25 [INFO]: Epoch 094 - training loss: 0.9688, validation loss: 1.3478
2024-06-03 01:01:32 [INFO]: Epoch 095 - training loss: 0.9663, validation loss: 1.3476
2024-06-03 01:01:39 [INFO]: Epoch 096 - training loss: 0.9666, validation loss: 1.3477
2024-06-03 01:01:47 [INFO]: Epoch 097 - training loss: 0.9661, validation loss: 1.3475
2024-06-03 01:01:54 [INFO]: Epoch 098 - training loss: 0.9668, validation loss: 1.3474
2024-06-03 01:02:02 [INFO]: Epoch 099 - training loss: 0.9590, validation loss: 1.3476
2024-06-03 01:02:09 [INFO]: Epoch 100 - training loss: 0.9671, validation loss: 1.3476
2024-06-03 01:02:09 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 01:02:09 [INFO]: Saved the model to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T005031/Autoformer.pypots
2024-06-03 01:02:10 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_1/imputation.pkl
2024-06-03 01:02:10 [INFO]: Round1 - Autoformer on BeijingAir: MAE=0.7948, MSE=1.3551, MRE=1.0703
2024-06-03 01:02:10 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:02:10 [INFO]: Using the given device: cuda:0
2024-06-03 01:02:10 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T010210
2024-06-03 01:02:10 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T010210/tensorboard
2024-06-03 01:02:11 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 01:02:17 [INFO]: Epoch 001 - training loss: 1.6779, validation loss: 1.4434
2024-06-03 01:02:24 [INFO]: Epoch 002 - training loss: 1.5688, validation loss: 1.4431
2024-06-03 01:02:31 [INFO]: Epoch 003 - training loss: 1.4785, validation loss: 1.4450
2024-06-03 01:02:38 [INFO]: Epoch 004 - training loss: 1.4072, validation loss: 1.4470
2024-06-03 01:02:45 [INFO]: Epoch 005 - training loss: 1.3502, validation loss: 1.4464
2024-06-03 01:02:52 [INFO]: Epoch 006 - training loss: 1.3048, validation loss: 1.4440
2024-06-03 01:02:58 [INFO]: Epoch 007 - training loss: 1.2696, validation loss: 1.4399
2024-06-03 01:03:05 [INFO]: Epoch 008 - training loss: 1.2471, validation loss: 1.4347
2024-06-03 01:03:12 [INFO]: Epoch 009 - training loss: 1.2320, validation loss: 1.4281
2024-06-03 01:03:19 [INFO]: Epoch 010 - training loss: 1.2085, validation loss: 1.4216
2024-06-03 01:03:26 [INFO]: Epoch 011 - training loss: 1.1939, validation loss: 1.4152
2024-06-03 01:03:32 [INFO]: Epoch 012 - training loss: 1.1828, validation loss: 1.4093
2024-06-03 01:03:39 [INFO]: Epoch 013 - training loss: 1.1667, validation loss: 1.4036
2024-06-03 01:03:44 [INFO]: Epoch 014 - training loss: 1.1582, validation loss: 1.3990
2024-06-03 01:03:50 [INFO]: Epoch 015 - training loss: 1.1474, validation loss: 1.3949
2024-06-03 01:03:56 [INFO]: Epoch 016 - training loss: 1.1381, validation loss: 1.3906
2024-06-03 01:04:02 [INFO]: Epoch 017 - training loss: 1.1345, validation loss: 1.3873
2024-06-03 01:04:08 [INFO]: Epoch 018 - training loss: 1.1282, validation loss: 1.3842
2024-06-03 01:04:14 [INFO]: Epoch 019 - training loss: 1.1234, validation loss: 1.3815
2024-06-03 01:04:20 [INFO]: Epoch 020 - training loss: 1.1194, validation loss: 1.3788
2024-06-03 01:04:26 [INFO]: Epoch 021 - training loss: 1.1197, validation loss: 1.3766
2024-06-03 01:04:32 [INFO]: Epoch 022 - training loss: 1.1045, validation loss: 1.3743
2024-06-03 01:04:38 [INFO]: Epoch 023 - training loss: 1.1006, validation loss: 1.3728
2024-06-03 01:04:44 [INFO]: Epoch 024 - training loss: 1.1053, validation loss: 1.3710
2024-06-03 01:04:50 [INFO]: Epoch 025 - training loss: 1.0961, validation loss: 1.3698
2024-06-03 01:04:56 [INFO]: Epoch 026 - training loss: 1.0950, validation loss: 1.3689
2024-06-03 01:05:02 [INFO]: Epoch 027 - training loss: 1.0846, validation loss: 1.3676
2024-06-03 01:05:08 [INFO]: Epoch 028 - training loss: 1.0812, validation loss: 1.3667
2024-06-03 01:05:14 [INFO]: Epoch 029 - training loss: 1.0820, validation loss: 1.3654
2024-06-03 01:05:20 [INFO]: Epoch 030 - training loss: 1.0797, validation loss: 1.3642
2024-06-03 01:05:26 [INFO]: Epoch 031 - training loss: 1.0729, validation loss: 1.3634
2024-06-03 01:05:32 [INFO]: Epoch 032 - training loss: 1.0693, validation loss: 1.3630
2024-06-03 01:05:38 [INFO]: Epoch 033 - training loss: 1.0714, validation loss: 1.3625
2024-06-03 01:05:43 [INFO]: Epoch 034 - training loss: 1.0680, validation loss: 1.3613
2024-06-03 01:05:49 [INFO]: Epoch 035 - training loss: 1.0595, validation loss: 1.3604
2024-06-03 01:05:55 [INFO]: Epoch 036 - training loss: 1.0594, validation loss: 1.3603
2024-06-03 01:06:01 [INFO]: Epoch 037 - training loss: 1.0601, validation loss: 1.3594
2024-06-03 01:06:07 [INFO]: Epoch 038 - training loss: 1.0541, validation loss: 1.3586
2024-06-03 01:06:13 [INFO]: Epoch 039 - training loss: 1.0518, validation loss: 1.3579
2024-06-03 01:06:19 [INFO]: Epoch 040 - training loss: 1.0483, validation loss: 1.3577
2024-06-03 01:06:25 [INFO]: Epoch 041 - training loss: 1.0535, validation loss: 1.3567
2024-06-03 01:06:31 [INFO]: Epoch 042 - training loss: 1.0408, validation loss: 1.3568
2024-06-03 01:06:37 [INFO]: Epoch 043 - training loss: 1.0428, validation loss: 1.3565
2024-06-03 01:06:43 [INFO]: Epoch 044 - training loss: 1.0496, validation loss: 1.3563
2024-06-03 01:06:49 [INFO]: Epoch 045 - training loss: 1.0402, validation loss: 1.3562
2024-06-03 01:06:54 [INFO]: Epoch 046 - training loss: 1.0348, validation loss: 1.3557
2024-06-03 01:07:01 [INFO]: Epoch 047 - training loss: 1.0356, validation loss: 1.3552
2024-06-03 01:07:07 [INFO]: Epoch 048 - training loss: 1.0273, validation loss: 1.3549
2024-06-03 01:07:13 [INFO]: Epoch 049 - training loss: 1.0272, validation loss: 1.3549
2024-06-03 01:07:19 [INFO]: Epoch 050 - training loss: 1.0334, validation loss: 1.3544
2024-06-03 01:07:25 [INFO]: Epoch 051 - training loss: 1.0227, validation loss: 1.3543
2024-06-03 01:07:31 [INFO]: Epoch 052 - training loss: 1.0241, validation loss: 1.3539
2024-06-03 01:07:37 [INFO]: Epoch 053 - training loss: 1.0205, validation loss: 1.3538
2024-06-03 01:07:43 [INFO]: Epoch 054 - training loss: 1.0203, validation loss: 1.3535
2024-06-03 01:07:49 [INFO]: Epoch 055 - training loss: 1.0165, validation loss: 1.3531
2024-06-03 01:07:56 [INFO]: Epoch 056 - training loss: 1.0213, validation loss: 1.3525
2024-06-03 01:08:02 [INFO]: Epoch 057 - training loss: 1.0165, validation loss: 1.3524
2024-06-03 01:08:08 [INFO]: Epoch 058 - training loss: 1.0150, validation loss: 1.3523
2024-06-03 01:08:14 [INFO]: Epoch 059 - training loss: 1.0070, validation loss: 1.3522
2024-06-03 01:08:20 [INFO]: Epoch 060 - training loss: 1.0096, validation loss: 1.3519
2024-06-03 01:08:26 [INFO]: Epoch 061 - training loss: 1.0061, validation loss: 1.3517
2024-06-03 01:08:32 [INFO]: Epoch 062 - training loss: 1.0113, validation loss: 1.3512
2024-06-03 01:08:38 [INFO]: Epoch 063 - training loss: 0.9993, validation loss: 1.3512
2024-06-03 01:08:44 [INFO]: Epoch 064 - training loss: 1.0011, validation loss: 1.3509
2024-06-03 01:08:50 [INFO]: Epoch 065 - training loss: 1.0019, validation loss: 1.3505
2024-06-03 01:08:56 [INFO]: Epoch 066 - training loss: 0.9985, validation loss: 1.3503
2024-06-03 01:09:02 [INFO]: Epoch 067 - training loss: 0.9952, validation loss: 1.3504
2024-06-03 01:09:08 [INFO]: Epoch 068 - training loss: 0.9957, validation loss: 1.3506
2024-06-03 01:09:14 [INFO]: Epoch 069 - training loss: 0.9931, validation loss: 1.3506
2024-06-03 01:09:20 [INFO]: Epoch 070 - training loss: 0.9934, validation loss: 1.3505
2024-06-03 01:09:27 [INFO]: Epoch 071 - training loss: 0.9936, validation loss: 1.3500
2024-06-03 01:09:33 [INFO]: Epoch 072 - training loss: 0.9902, validation loss: 1.3500
2024-06-03 01:09:39 [INFO]: Epoch 073 - training loss: 0.9857, validation loss: 1.3501
2024-06-03 01:09:45 [INFO]: Epoch 074 - training loss: 0.9868, validation loss: 1.3497
2024-06-03 01:09:51 [INFO]: Epoch 075 - training loss: 0.9820, validation loss: 1.3496
2024-06-03 01:09:57 [INFO]: Epoch 076 - training loss: 0.9884, validation loss: 1.3493
2024-06-03 01:10:03 [INFO]: Epoch 077 - training loss: 0.9817, validation loss: 1.3492
2024-06-03 01:10:09 [INFO]: Epoch 078 - training loss: 0.9836, validation loss: 1.3491
2024-06-03 01:10:15 [INFO]: Epoch 079 - training loss: 0.9780, validation loss: 1.3488
2024-06-03 01:10:21 [INFO]: Epoch 080 - training loss: 0.9826, validation loss: 1.3489
2024-06-03 01:10:27 [INFO]: Epoch 081 - training loss: 0.9726, validation loss: 1.3486
2024-06-03 01:10:34 [INFO]: Epoch 082 - training loss: 0.9847, validation loss: 1.3482
2024-06-03 01:10:40 [INFO]: Epoch 083 - training loss: 0.9702, validation loss: 1.3481
2024-06-03 01:10:46 [INFO]: Epoch 084 - training loss: 0.9693, validation loss: 1.3482
2024-06-03 01:10:52 [INFO]: Epoch 085 - training loss: 0.9679, validation loss: 1.3482
2024-06-03 01:10:58 [INFO]: Epoch 086 - training loss: 0.9697, validation loss: 1.3482
2024-06-03 01:11:04 [INFO]: Epoch 087 - training loss: 0.9692, validation loss: 1.3484
2024-06-03 01:11:11 [INFO]: Epoch 088 - training loss: 0.9648, validation loss: 1.3483
2024-06-03 01:11:17 [INFO]: Epoch 089 - training loss: 0.9635, validation loss: 1.3483
2024-06-03 01:11:23 [INFO]: Epoch 090 - training loss: 0.9630, validation loss: 1.3483
2024-06-03 01:11:29 [INFO]: Epoch 091 - training loss: 0.9650, validation loss: 1.3482
2024-06-03 01:11:35 [INFO]: Epoch 092 - training loss: 0.9598, validation loss: 1.3481
2024-06-03 01:11:41 [INFO]: Epoch 093 - training loss: 0.9553, validation loss: 1.3480
2024-06-03 01:11:47 [INFO]: Epoch 094 - training loss: 0.9550, validation loss: 1.3483
2024-06-03 01:11:53 [INFO]: Epoch 095 - training loss: 0.9571, validation loss: 1.3480
2024-06-03 01:12:00 [INFO]: Epoch 096 - training loss: 0.9561, validation loss: 1.3481
2024-06-03 01:12:05 [INFO]: Epoch 097 - training loss: 0.9563, validation loss: 1.3477
2024-06-03 01:12:11 [INFO]: Epoch 098 - training loss: 0.9554, validation loss: 1.3476
2024-06-03 01:12:18 [INFO]: Epoch 099 - training loss: 0.9509, validation loss: 1.3474
2024-06-03 01:12:24 [INFO]: Epoch 100 - training loss: 0.9500, validation loss: 1.3478
2024-06-03 01:12:24 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 01:12:24 [INFO]: Saved the model to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T010210/Autoformer.pypots
2024-06-03 01:12:25 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_2/imputation.pkl
2024-06-03 01:12:25 [INFO]: Round2 - Autoformer on BeijingAir: MAE=0.7951, MSE=1.3551, MRE=1.0706
2024-06-03 01:12:25 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:12:25 [INFO]: Using the given device: cuda:0
2024-06-03 01:12:25 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T011225
2024-06-03 01:12:25 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T011225/tensorboard
2024-06-03 01:12:25 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 01:12:31 [INFO]: Epoch 001 - training loss: 1.6806, validation loss: 1.4482
2024-06-03 01:12:37 [INFO]: Epoch 002 - training loss: 1.5687, validation loss: 1.4469
2024-06-03 01:12:43 [INFO]: Epoch 003 - training loss: 1.4751, validation loss: 1.4480
2024-06-03 01:12:49 [INFO]: Epoch 004 - training loss: 1.4052, validation loss: 1.4490
2024-06-03 01:12:56 [INFO]: Epoch 005 - training loss: 1.3484, validation loss: 1.4485
2024-06-03 01:13:02 [INFO]: Epoch 006 - training loss: 1.3062, validation loss: 1.4457
2024-06-03 01:13:08 [INFO]: Epoch 007 - training loss: 1.2742, validation loss: 1.4413
2024-06-03 01:13:14 [INFO]: Epoch 008 - training loss: 1.2461, validation loss: 1.4358
2024-06-03 01:13:20 [INFO]: Epoch 009 - training loss: 1.2192, validation loss: 1.4292
2024-06-03 01:13:26 [INFO]: Epoch 010 - training loss: 1.2083, validation loss: 1.4232
2024-06-03 01:13:32 [INFO]: Epoch 011 - training loss: 1.1937, validation loss: 1.4165
2024-06-03 01:13:38 [INFO]: Epoch 012 - training loss: 1.1822, validation loss: 1.4106
2024-06-03 01:13:44 [INFO]: Epoch 013 - training loss: 1.1693, validation loss: 1.4048
2024-06-03 01:13:50 [INFO]: Epoch 014 - training loss: 1.1580, validation loss: 1.3995
2024-06-03 01:13:56 [INFO]: Epoch 015 - training loss: 1.1515, validation loss: 1.3955
2024-06-03 01:14:02 [INFO]: Epoch 016 - training loss: 1.1477, validation loss: 1.3916
2024-06-03 01:14:09 [INFO]: Epoch 017 - training loss: 1.1357, validation loss: 1.3882
2024-06-03 01:14:14 [INFO]: Epoch 018 - training loss: 1.1326, validation loss: 1.3852
2024-06-03 01:14:21 [INFO]: Epoch 019 - training loss: 1.1205, validation loss: 1.3822
2024-06-03 01:14:27 [INFO]: Epoch 020 - training loss: 1.1172, validation loss: 1.3798
2024-06-03 01:14:33 [INFO]: Epoch 021 - training loss: 1.1092, validation loss: 1.3773
2024-06-03 01:14:39 [INFO]: Epoch 022 - training loss: 1.1142, validation loss: 1.3750
2024-06-03 01:14:45 [INFO]: Epoch 023 - training loss: 1.1011, validation loss: 1.3736
2024-06-03 01:14:51 [INFO]: Epoch 024 - training loss: 1.0996, validation loss: 1.3722
2024-06-03 01:14:57 [INFO]: Epoch 025 - training loss: 1.0969, validation loss: 1.3706
2024-06-03 01:15:03 [INFO]: Epoch 026 - training loss: 1.0911, validation loss: 1.3690
2024-06-03 01:15:09 [INFO]: Epoch 027 - training loss: 1.0895, validation loss: 1.3677
2024-06-03 01:15:16 [INFO]: Epoch 028 - training loss: 1.0863, validation loss: 1.3671
2024-06-03 01:15:22 [INFO]: Epoch 029 - training loss: 1.0823, validation loss: 1.3666
2024-06-03 01:15:28 [INFO]: Epoch 030 - training loss: 1.0781, validation loss: 1.3655
2024-06-03 01:15:34 [INFO]: Epoch 031 - training loss: 1.0708, validation loss: 1.3644
2024-06-03 01:15:40 [INFO]: Epoch 032 - training loss: 1.0710, validation loss: 1.3635
2024-06-03 01:15:45 [INFO]: Epoch 033 - training loss: 1.0685, validation loss: 1.3623
2024-06-03 01:15:52 [INFO]: Epoch 034 - training loss: 1.0627, validation loss: 1.3620
2024-06-03 01:15:58 [INFO]: Epoch 035 - training loss: 1.0664, validation loss: 1.3615
2024-06-03 01:16:04 [INFO]: Epoch 036 - training loss: 1.0609, validation loss: 1.3607
2024-06-03 01:16:09 [INFO]: Epoch 037 - training loss: 1.0615, validation loss: 1.3600
2024-06-03 01:16:15 [INFO]: Epoch 038 - training loss: 1.0567, validation loss: 1.3595
2024-06-03 01:16:21 [INFO]: Epoch 039 - training loss: 1.0563, validation loss: 1.3592
2024-06-03 01:16:27 [INFO]: Epoch 040 - training loss: 1.0482, validation loss: 1.3586
2024-06-03 01:16:33 [INFO]: Epoch 041 - training loss: 1.0434, validation loss: 1.3582
2024-06-03 01:16:39 [INFO]: Epoch 042 - training loss: 1.0446, validation loss: 1.3577
2024-06-03 01:16:45 [INFO]: Epoch 043 - training loss: 1.0437, validation loss: 1.3571
2024-06-03 01:16:51 [INFO]: Epoch 044 - training loss: 1.0419, validation loss: 1.3573
2024-06-03 01:16:57 [INFO]: Epoch 045 - training loss: 1.0403, validation loss: 1.3567
2024-06-03 01:17:03 [INFO]: Epoch 046 - training loss: 1.0332, validation loss: 1.3564
2024-06-03 01:17:09 [INFO]: Epoch 047 - training loss: 1.0333, validation loss: 1.3561
2024-06-03 01:17:15 [INFO]: Epoch 048 - training loss: 1.0329, validation loss: 1.3552
2024-06-03 01:17:21 [INFO]: Epoch 049 - training loss: 1.0265, validation loss: 1.3556
2024-06-03 01:17:27 [INFO]: Epoch 050 - training loss: 1.0286, validation loss: 1.3553
2024-06-03 01:17:33 [INFO]: Epoch 051 - training loss: 1.0262, validation loss: 1.3548
2024-06-03 01:17:39 [INFO]: Epoch 052 - training loss: 1.0291, validation loss: 1.3543
2024-06-03 01:17:45 [INFO]: Epoch 053 - training loss: 1.0246, validation loss: 1.3542
2024-06-03 01:17:51 [INFO]: Epoch 054 - training loss: 1.0200, validation loss: 1.3540
2024-06-03 01:17:57 [INFO]: Epoch 055 - training loss: 1.0198, validation loss: 1.3540
2024-06-03 01:18:03 [INFO]: Epoch 056 - training loss: 1.0131, validation loss: 1.3538
2024-06-03 01:18:09 [INFO]: Epoch 057 - training loss: 1.0142, validation loss: 1.3536
2024-06-03 01:18:15 [INFO]: Epoch 058 - training loss: 1.0135, validation loss: 1.3532
2024-06-03 01:18:21 [INFO]: Epoch 059 - training loss: 1.0141, validation loss: 1.3529
2024-06-03 01:18:27 [INFO]: Epoch 060 - training loss: 1.0094, validation loss: 1.3527
2024-06-03 01:18:33 [INFO]: Epoch 061 - training loss: 1.0085, validation loss: 1.3526
2024-06-03 01:18:39 [INFO]: Epoch 062 - training loss: 1.0083, validation loss: 1.3520
2024-06-03 01:18:45 [INFO]: Epoch 063 - training loss: 1.0040, validation loss: 1.3518
2024-06-03 01:18:51 [INFO]: Epoch 064 - training loss: 1.0029, validation loss: 1.3516
2024-06-03 01:18:57 [INFO]: Epoch 065 - training loss: 0.9963, validation loss: 1.3518
2024-06-03 01:19:03 [INFO]: Epoch 066 - training loss: 0.9948, validation loss: 1.3519
2024-06-03 01:19:09 [INFO]: Epoch 067 - training loss: 1.0009, validation loss: 1.3515
2024-06-03 01:19:15 [INFO]: Epoch 068 - training loss: 0.9986, validation loss: 1.3513
2024-06-03 01:19:21 [INFO]: Epoch 069 - training loss: 0.9958, validation loss: 1.3513
2024-06-03 01:19:28 [INFO]: Epoch 070 - training loss: 0.9975, validation loss: 1.3510
2024-06-03 01:19:34 [INFO]: Epoch 071 - training loss: 0.9938, validation loss: 1.3510
2024-06-03 01:19:40 [INFO]: Epoch 072 - training loss: 0.9904, validation loss: 1.3506
2024-06-03 01:19:46 [INFO]: Epoch 073 - training loss: 0.9878, validation loss: 1.3505
2024-06-03 01:19:52 [INFO]: Epoch 074 - training loss: 0.9826, validation loss: 1.3505
2024-06-03 01:19:58 [INFO]: Epoch 075 - training loss: 0.9854, validation loss: 1.3505
2024-06-03 01:20:04 [INFO]: Epoch 076 - training loss: 0.9827, validation loss: 1.3504
2024-06-03 01:20:10 [INFO]: Epoch 077 - training loss: 0.9802, validation loss: 1.3504
2024-06-03 01:20:16 [INFO]: Epoch 078 - training loss: 0.9845, validation loss: 1.3503
2024-06-03 01:20:22 [INFO]: Epoch 079 - training loss: 0.9863, validation loss: 1.3499
2024-06-03 01:20:29 [INFO]: Epoch 080 - training loss: 0.9810, validation loss: 1.3498
2024-06-03 01:20:35 [INFO]: Epoch 081 - training loss: 0.9808, validation loss: 1.3497
2024-06-03 01:20:40 [INFO]: Epoch 082 - training loss: 0.9720, validation loss: 1.3498
2024-06-03 01:20:47 [INFO]: Epoch 083 - training loss: 0.9731, validation loss: 1.3496
2024-06-03 01:20:53 [INFO]: Epoch 084 - training loss: 0.9731, validation loss: 1.3491
2024-06-03 01:20:59 [INFO]: Epoch 085 - training loss: 0.9659, validation loss: 1.3492
2024-06-03 01:21:05 [INFO]: Epoch 086 - training loss: 0.9694, validation loss: 1.3491
2024-06-03 01:21:12 [INFO]: Epoch 087 - training loss: 0.9733, validation loss: 1.3488
2024-06-03 01:21:18 [INFO]: Epoch 088 - training loss: 0.9683, validation loss: 1.3488
2024-06-03 01:21:24 [INFO]: Epoch 089 - training loss: 0.9682, validation loss: 1.3486
2024-06-03 01:21:30 [INFO]: Epoch 090 - training loss: 0.9674, validation loss: 1.3485
2024-06-03 01:21:36 [INFO]: Epoch 091 - training loss: 0.9664, validation loss: 1.3483
2024-06-03 01:21:42 [INFO]: Epoch 092 - training loss: 0.9679, validation loss: 1.3485
2024-06-03 01:21:48 [INFO]: Epoch 093 - training loss: 0.9700, validation loss: 1.3487
2024-06-03 01:21:54 [INFO]: Epoch 094 - training loss: 0.9627, validation loss: 1.3483
2024-06-03 01:22:00 [INFO]: Epoch 095 - training loss: 0.9581, validation loss: 1.3484
2024-06-03 01:22:06 [INFO]: Epoch 096 - training loss: 0.9589, validation loss: 1.3482
2024-06-03 01:22:12 [INFO]: Epoch 097 - training loss: 0.9546, validation loss: 1.3483
2024-06-03 01:22:18 [INFO]: Epoch 098 - training loss: 0.9602, validation loss: 1.3484
2024-06-03 01:22:25 [INFO]: Epoch 099 - training loss: 0.9588, validation loss: 1.3484
2024-06-03 01:22:31 [INFO]: Epoch 100 - training loss: 0.9488, validation loss: 1.3482
2024-06-03 01:22:31 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 01:22:31 [INFO]: Saved the model to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T011225/Autoformer.pypots
2024-06-03 01:22:32 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_3/imputation.pkl
2024-06-03 01:22:32 [INFO]: Round3 - Autoformer on BeijingAir: MAE=0.7951, MSE=1.3546, MRE=1.0707
2024-06-03 01:22:32 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:22:32 [INFO]: Using the given device: cuda:0
2024-06-03 01:22:32 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T012232
2024-06-03 01:22:32 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T012232/tensorboard
2024-06-03 01:22:32 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 01:22:38 [INFO]: Epoch 001 - training loss: 1.6765, validation loss: 1.4473
2024-06-03 01:22:44 [INFO]: Epoch 002 - training loss: 1.5695, validation loss: 1.4465
2024-06-03 01:22:51 [INFO]: Epoch 003 - training loss: 1.4758, validation loss: 1.4485
2024-06-03 01:22:57 [INFO]: Epoch 004 - training loss: 1.4007, validation loss: 1.4506
2024-06-03 01:23:03 [INFO]: Epoch 005 - training loss: 1.3471, validation loss: 1.4508
2024-06-03 01:23:09 [INFO]: Epoch 006 - training loss: 1.3063, validation loss: 1.4485
2024-06-03 01:23:14 [INFO]: Epoch 007 - training loss: 1.2745, validation loss: 1.4431
2024-06-03 01:23:20 [INFO]: Epoch 008 - training loss: 1.2435, validation loss: 1.4374
2024-06-03 01:23:27 [INFO]: Epoch 009 - training loss: 1.2272, validation loss: 1.4314
2024-06-03 01:23:33 [INFO]: Epoch 010 - training loss: 1.2102, validation loss: 1.4245
2024-06-03 01:23:39 [INFO]: Epoch 011 - training loss: 1.1962, validation loss: 1.4177
2024-06-03 01:23:45 [INFO]: Epoch 012 - training loss: 1.1798, validation loss: 1.4114
2024-06-03 01:23:51 [INFO]: Epoch 013 - training loss: 1.1689, validation loss: 1.4055
2024-06-03 01:23:57 [INFO]: Epoch 014 - training loss: 1.1619, validation loss: 1.4003
2024-06-03 01:24:03 [INFO]: Epoch 015 - training loss: 1.1517, validation loss: 1.3958
2024-06-03 01:24:09 [INFO]: Epoch 016 - training loss: 1.1439, validation loss: 1.3917
2024-06-03 01:24:15 [INFO]: Epoch 017 - training loss: 1.1342, validation loss: 1.3882
2024-06-03 01:24:21 [INFO]: Epoch 018 - training loss: 1.1275, validation loss: 1.3850
2024-06-03 01:24:27 [INFO]: Epoch 019 - training loss: 1.1255, validation loss: 1.3818
2024-06-03 01:24:33 [INFO]: Epoch 020 - training loss: 1.1147, validation loss: 1.3791
2024-06-03 01:24:39 [INFO]: Epoch 021 - training loss: 1.1104, validation loss: 1.3771
2024-06-03 01:24:45 [INFO]: Epoch 022 - training loss: 1.1093, validation loss: 1.3749
2024-06-03 01:24:51 [INFO]: Epoch 023 - training loss: 1.1007, validation loss: 1.3734
2024-06-03 01:24:57 [INFO]: Epoch 024 - training loss: 1.0940, validation loss: 1.3720
2024-06-03 01:25:03 [INFO]: Epoch 025 - training loss: 1.0906, validation loss: 1.3705
2024-06-03 01:25:09 [INFO]: Epoch 026 - training loss: 1.0912, validation loss: 1.3694
2024-06-03 01:25:15 [INFO]: Epoch 027 - training loss: 1.0788, validation loss: 1.3684
2024-06-03 01:25:21 [INFO]: Epoch 028 - training loss: 1.0845, validation loss: 1.3673
2024-06-03 01:25:27 [INFO]: Epoch 029 - training loss: 1.0780, validation loss: 1.3663
2024-06-03 01:25:33 [INFO]: Epoch 030 - training loss: 1.0762, validation loss: 1.3649
2024-06-03 01:25:39 [INFO]: Epoch 031 - training loss: 1.0777, validation loss: 1.3639
2024-06-03 01:25:45 [INFO]: Epoch 032 - training loss: 1.0682, validation loss: 1.3631
2024-06-03 01:25:51 [INFO]: Epoch 033 - training loss: 1.0644, validation loss: 1.3621
2024-06-03 01:25:57 [INFO]: Epoch 034 - training loss: 1.0612, validation loss: 1.3615
2024-06-03 01:26:03 [INFO]: Epoch 035 - training loss: 1.0573, validation loss: 1.3611
2024-06-03 01:26:09 [INFO]: Epoch 036 - training loss: 1.0616, validation loss: 1.3601
2024-06-03 01:26:15 [INFO]: Epoch 037 - training loss: 1.0523, validation loss: 1.3596
2024-06-03 01:26:21 [INFO]: Epoch 038 - training loss: 1.0574, validation loss: 1.3588
2024-06-03 01:26:27 [INFO]: Epoch 039 - training loss: 1.0511, validation loss: 1.3585
2024-06-03 01:26:34 [INFO]: Epoch 040 - training loss: 1.0478, validation loss: 1.3578
2024-06-03 01:26:40 [INFO]: Epoch 041 - training loss: 1.0458, validation loss: 1.3574
2024-06-03 01:26:45 [INFO]: Epoch 042 - training loss: 1.0449, validation loss: 1.3567
2024-06-03 01:26:51 [INFO]: Epoch 043 - training loss: 1.0375, validation loss: 1.3564
2024-06-03 01:26:57 [INFO]: Epoch 044 - training loss: 1.0399, validation loss: 1.3559
2024-06-03 01:27:04 [INFO]: Epoch 045 - training loss: 1.0342, validation loss: 1.3558
2024-06-03 01:27:10 [INFO]: Epoch 046 - training loss: 1.0309, validation loss: 1.3556
2024-06-03 01:27:16 [INFO]: Epoch 047 - training loss: 1.0297, validation loss: 1.3556
2024-06-03 01:27:22 [INFO]: Epoch 048 - training loss: 1.0235, validation loss: 1.3549
2024-06-03 01:27:29 [INFO]: Epoch 049 - training loss: 1.0241, validation loss: 1.3545
2024-06-03 01:27:35 [INFO]: Epoch 050 - training loss: 1.0235, validation loss: 1.3542
2024-06-03 01:27:40 [INFO]: Epoch 051 - training loss: 1.0236, validation loss: 1.3539
2024-06-03 01:27:47 [INFO]: Epoch 052 - training loss: 1.0170, validation loss: 1.3536
2024-06-03 01:27:53 [INFO]: Epoch 053 - training loss: 1.0158, validation loss: 1.3532
2024-06-03 01:27:59 [INFO]: Epoch 054 - training loss: 1.0107, validation loss: 1.3529
2024-06-03 01:28:05 [INFO]: Epoch 055 - training loss: 1.0108, validation loss: 1.3531
2024-06-03 01:28:11 [INFO]: Epoch 056 - training loss: 1.0112, validation loss: 1.3525
2024-06-03 01:28:17 [INFO]: Epoch 057 - training loss: 1.0025, validation loss: 1.3521
2024-06-03 01:28:23 [INFO]: Epoch 058 - training loss: 1.0038, validation loss: 1.3519
2024-06-03 01:28:29 [INFO]: Epoch 059 - training loss: 1.0015, validation loss: 1.3518
2024-06-03 01:28:35 [INFO]: Epoch 060 - training loss: 1.0035, validation loss: 1.3518
2024-06-03 01:28:41 [INFO]: Epoch 061 - training loss: 0.9995, validation loss: 1.3515
2024-06-03 01:28:47 [INFO]: Epoch 062 - training loss: 0.9946, validation loss: 1.3513
2024-06-03 01:28:53 [INFO]: Epoch 063 - training loss: 0.9980, validation loss: 1.3511
2024-06-03 01:28:59 [INFO]: Epoch 064 - training loss: 0.9936, validation loss: 1.3507
2024-06-03 01:29:05 [INFO]: Epoch 065 - training loss: 0.9906, validation loss: 1.3507
2024-06-03 01:29:12 [INFO]: Epoch 066 - training loss: 0.9898, validation loss: 1.3504
2024-06-03 01:29:18 [INFO]: Epoch 067 - training loss: 0.9863, validation loss: 1.3504
2024-06-03 01:29:24 [INFO]: Epoch 068 - training loss: 0.9871, validation loss: 1.3505
2024-06-03 01:29:30 [INFO]: Epoch 069 - training loss: 0.9811, validation loss: 1.3504
2024-06-03 01:29:36 [INFO]: Epoch 070 - training loss: 0.9854, validation loss: 1.3501
2024-06-03 01:29:42 [INFO]: Epoch 071 - training loss: 0.9823, validation loss: 1.3494
2024-06-03 01:29:48 [INFO]: Epoch 072 - training loss: 0.9729, validation loss: 1.3496
2024-06-03 01:29:54 [INFO]: Epoch 073 - training loss: 0.9748, validation loss: 1.3495
2024-06-03 01:30:00 [INFO]: Epoch 074 - training loss: 0.9734, validation loss: 1.3493
2024-06-03 01:30:07 [INFO]: Epoch 075 - training loss: 0.9675, validation loss: 1.3495
2024-06-03 01:30:13 [INFO]: Epoch 076 - training loss: 0.9705, validation loss: 1.3496
2024-06-03 01:30:18 [INFO]: Epoch 077 - training loss: 0.9681, validation loss: 1.3492
2024-06-03 01:30:24 [INFO]: Epoch 078 - training loss: 0.9674, validation loss: 1.3495
2024-06-03 01:30:30 [INFO]: Epoch 079 - training loss: 0.9674, validation loss: 1.3495
2024-06-03 01:30:36 [INFO]: Epoch 080 - training loss: 0.9630, validation loss: 1.3494
2024-06-03 01:30:42 [INFO]: Epoch 081 - training loss: 0.9639, validation loss: 1.3493
2024-06-03 01:30:48 [INFO]: Epoch 082 - training loss: 0.9614, validation loss: 1.3493
2024-06-03 01:30:55 [INFO]: Epoch 083 - training loss: 0.9590, validation loss: 1.3493
2024-06-03 01:31:01 [INFO]: Epoch 084 - training loss: 0.9566, validation loss: 1.3497
2024-06-03 01:31:07 [INFO]: Epoch 085 - training loss: 0.9516, validation loss: 1.3499
2024-06-03 01:31:13 [INFO]: Epoch 086 - training loss: 0.9567, validation loss: 1.3502
2024-06-03 01:31:19 [INFO]: Epoch 087 - training loss: 0.9472, validation loss: 1.3501
2024-06-03 01:31:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:31:19 [INFO]: Finished training. The best model is from epoch#77.
2024-06-03 01:31:19 [INFO]: Saved the model to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T012232/Autoformer.pypots
2024-06-03 01:31:21 [INFO]: Successfully saved to results_point_rate09/BeijingAir/Autoformer_BeijingAir/round_4/imputation.pkl
2024-06-03 01:31:21 [INFO]: Round4 - Autoformer on BeijingAir: MAE=0.7994, MSE=1.3581, MRE=1.0766
2024-06-03 01:31:21 [INFO]: Done! Final results:
Averaged Autoformer (6,700,164 params) on BeijingAir: MAE=0.8058 ± 0.0017106983202540475, MSE=1.3755 ± 0.0012710761094677254, MRE=1.0690 ± 0.002269466200512791, average inference time=0.26