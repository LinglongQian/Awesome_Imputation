2024-06-03 08:00:49 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 08:00:49 [INFO]: Using the given device: cuda:0
2024-06-03 08:00:49 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T080049
2024-06-03 08:00:49 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T080049/tensorboard
2024-06-03 08:00:50 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 08:01:07 [INFO]: Epoch 001 - training loss: 1.0544, validation loss: 0.6646
2024-06-03 08:01:14 [INFO]: Epoch 002 - training loss: 0.6957, validation loss: 0.6023
2024-06-03 08:01:20 [INFO]: Epoch 003 - training loss: 0.6517, validation loss: 0.6089
2024-06-03 08:01:27 [INFO]: Epoch 004 - training loss: 0.6365, validation loss: 0.5803
2024-06-03 08:01:34 [INFO]: Epoch 005 - training loss: 0.6290, validation loss: 0.5829
2024-06-03 08:01:42 [INFO]: Epoch 006 - training loss: 0.6156, validation loss: 0.5678
2024-06-03 08:01:48 [INFO]: Epoch 007 - training loss: 0.6105, validation loss: 0.5464
2024-06-03 08:01:55 [INFO]: Epoch 008 - training loss: 0.6024, validation loss: 0.5427
2024-06-03 08:02:02 [INFO]: Epoch 009 - training loss: 0.5953, validation loss: 0.5411
2024-06-03 08:02:10 [INFO]: Epoch 010 - training loss: 0.5964, validation loss: 0.5437
2024-06-03 08:02:17 [INFO]: Epoch 011 - training loss: 0.5851, validation loss: 0.5375
2024-06-03 08:02:24 [INFO]: Epoch 012 - training loss: 0.5854, validation loss: 0.5284
2024-06-03 08:02:31 [INFO]: Epoch 013 - training loss: 0.5791, validation loss: 0.5438
2024-06-03 08:02:38 [INFO]: Epoch 014 - training loss: 0.5711, validation loss: 0.5327
2024-06-03 08:02:45 [INFO]: Epoch 015 - training loss: 0.5802, validation loss: 0.5229
2024-06-03 08:02:52 [INFO]: Epoch 016 - training loss: 0.5769, validation loss: 0.5260
2024-06-03 08:02:58 [INFO]: Epoch 017 - training loss: 0.5710, validation loss: 0.5248
2024-06-03 08:03:05 [INFO]: Epoch 018 - training loss: 0.5681, validation loss: 0.5248
2024-06-03 08:03:12 [INFO]: Epoch 019 - training loss: 0.5581, validation loss: 0.5174
2024-06-03 08:03:20 [INFO]: Epoch 020 - training loss: 0.5614, validation loss: 0.5122
2024-06-03 08:03:27 [INFO]: Epoch 021 - training loss: 0.5532, validation loss: 0.5145
2024-06-03 08:03:33 [INFO]: Epoch 022 - training loss: 0.5461, validation loss: 0.5063
2024-06-03 08:03:41 [INFO]: Epoch 023 - training loss: 0.5447, validation loss: 0.5108
2024-06-03 08:03:48 [INFO]: Epoch 024 - training loss: 0.5437, validation loss: 0.5216
2024-06-03 08:03:55 [INFO]: Epoch 025 - training loss: 0.5459, validation loss: 0.5332
2024-06-03 08:04:02 [INFO]: Epoch 026 - training loss: 0.5388, validation loss: 0.5088
2024-06-03 08:04:09 [INFO]: Epoch 027 - training loss: 0.5356, validation loss: 0.5094
2024-06-03 08:04:16 [INFO]: Epoch 028 - training loss: 0.5344, validation loss: 0.5108
2024-06-03 08:04:23 [INFO]: Epoch 029 - training loss: 0.5264, validation loss: 0.5049
2024-06-03 08:04:30 [INFO]: Epoch 030 - training loss: 0.5243, validation loss: 0.5025
2024-06-03 08:04:37 [INFO]: Epoch 031 - training loss: 0.5293, validation loss: 0.5044
2024-06-03 08:04:44 [INFO]: Epoch 032 - training loss: 0.5229, validation loss: 0.5098
2024-06-03 08:04:51 [INFO]: Epoch 033 - training loss: 0.5191, validation loss: 0.5081
2024-06-03 08:04:58 [INFO]: Epoch 034 - training loss: 0.5134, validation loss: 0.5109
2024-06-03 08:05:05 [INFO]: Epoch 035 - training loss: 0.5119, validation loss: 0.5157
2024-06-03 08:05:11 [INFO]: Epoch 036 - training loss: 0.5208, validation loss: 0.5013
2024-06-03 08:05:18 [INFO]: Epoch 037 - training loss: 0.5106, validation loss: 0.5048
2024-06-03 08:05:25 [INFO]: Epoch 038 - training loss: 0.5046, validation loss: 0.5005
2024-06-03 08:05:32 [INFO]: Epoch 039 - training loss: 0.5052, validation loss: 0.4984
2024-06-03 08:05:39 [INFO]: Epoch 040 - training loss: 0.5012, validation loss: 0.4984
2024-06-03 08:05:46 [INFO]: Epoch 041 - training loss: 0.5017, validation loss: 0.4914
2024-06-03 08:05:53 [INFO]: Epoch 042 - training loss: 0.4997, validation loss: 0.4880
2024-06-03 08:05:59 [INFO]: Epoch 043 - training loss: 0.4950, validation loss: 0.4934
2024-06-03 08:06:06 [INFO]: Epoch 044 - training loss: 0.4924, validation loss: 0.4928
2024-06-03 08:06:13 [INFO]: Epoch 045 - training loss: 0.4980, validation loss: 0.4988
2024-06-03 08:06:20 [INFO]: Epoch 046 - training loss: 0.4990, validation loss: 0.4956
2024-06-03 08:06:27 [INFO]: Epoch 047 - training loss: 0.4942, validation loss: 0.4965
2024-06-03 08:06:34 [INFO]: Epoch 048 - training loss: 0.4896, validation loss: 0.4905
2024-06-03 08:06:41 [INFO]: Epoch 049 - training loss: 0.4833, validation loss: 0.4926
2024-06-03 08:06:48 [INFO]: Epoch 050 - training loss: 0.4825, validation loss: 0.4843
2024-06-03 08:06:55 [INFO]: Epoch 051 - training loss: 0.4787, validation loss: 0.4846
2024-06-03 08:07:02 [INFO]: Epoch 052 - training loss: 0.4786, validation loss: 0.4918
2024-06-03 08:07:09 [INFO]: Epoch 053 - training loss: 0.4762, validation loss: 0.4952
2024-06-03 08:07:16 [INFO]: Epoch 054 - training loss: 0.4825, validation loss: 0.4918
2024-06-03 08:07:23 [INFO]: Epoch 055 - training loss: 0.4794, validation loss: 0.4830
2024-06-03 08:07:30 [INFO]: Epoch 056 - training loss: 0.4727, validation loss: 0.4882
2024-06-03 08:07:37 [INFO]: Epoch 057 - training loss: 0.4756, validation loss: 0.5027
2024-06-03 08:07:44 [INFO]: Epoch 058 - training loss: 0.4740, validation loss: 0.4885
2024-06-03 08:07:51 [INFO]: Epoch 059 - training loss: 0.4728, validation loss: 0.4838
2024-06-03 08:07:58 [INFO]: Epoch 060 - training loss: 0.4691, validation loss: 0.4872
2024-06-03 08:08:05 [INFO]: Epoch 061 - training loss: 0.4681, validation loss: 0.4915
2024-06-03 08:08:12 [INFO]: Epoch 062 - training loss: 0.4684, validation loss: 0.4788
2024-06-03 08:08:19 [INFO]: Epoch 063 - training loss: 0.4743, validation loss: 0.4887
2024-06-03 08:08:25 [INFO]: Epoch 064 - training loss: 0.4620, validation loss: 0.4788
2024-06-03 08:08:33 [INFO]: Epoch 065 - training loss: 0.4634, validation loss: 0.4859
2024-06-03 08:08:40 [INFO]: Epoch 066 - training loss: 0.4626, validation loss: 0.4768
2024-06-03 08:08:47 [INFO]: Epoch 067 - training loss: 0.4582, validation loss: 0.4779
2024-06-03 08:08:53 [INFO]: Epoch 068 - training loss: 0.4641, validation loss: 0.4938
2024-06-03 08:09:01 [INFO]: Epoch 069 - training loss: 0.4594, validation loss: 0.4808
2024-06-03 08:09:08 [INFO]: Epoch 070 - training loss: 0.4621, validation loss: 0.4827
2024-06-03 08:09:15 [INFO]: Epoch 071 - training loss: 0.4548, validation loss: 0.4810
2024-06-03 08:09:22 [INFO]: Epoch 072 - training loss: 0.4583, validation loss: 0.4820
2024-06-03 08:09:29 [INFO]: Epoch 073 - training loss: 0.4549, validation loss: 0.4854
2024-06-03 08:09:36 [INFO]: Epoch 074 - training loss: 0.4572, validation loss: 0.4806
2024-06-03 08:09:43 [INFO]: Epoch 075 - training loss: 0.4569, validation loss: 0.4828
2024-06-03 08:09:50 [INFO]: Epoch 076 - training loss: 0.4502, validation loss: 0.4789
2024-06-03 08:09:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:09:50 [INFO]: Finished training. The best model is from epoch#66.
2024-06-03 08:09:50 [INFO]: Saved the model to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T080049/iTransformer.pypots
2024-06-03 08:09:52 [INFO]: Successfully saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_0/imputation.pkl
2024-06-03 08:09:52 [INFO]: Round0 - iTransformer on BeijingAir: MAE=0.3528, MSE=0.5110, MRE=0.4751
2024-06-03 08:09:52 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 08:09:52 [INFO]: Using the given device: cuda:0
2024-06-03 08:09:52 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T080952
2024-06-03 08:09:52 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T080952/tensorboard
2024-06-03 08:09:53 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 08:09:59 [INFO]: Epoch 001 - training loss: 1.0863, validation loss: 0.6589
2024-06-03 08:10:07 [INFO]: Epoch 002 - training loss: 0.7040, validation loss: 0.6358
2024-06-03 08:10:14 [INFO]: Epoch 003 - training loss: 0.6543, validation loss: 0.6083
2024-06-03 08:10:20 [INFO]: Epoch 004 - training loss: 0.6364, validation loss: 0.5831
2024-06-03 08:10:27 [INFO]: Epoch 005 - training loss: 0.6354, validation loss: 0.5900
2024-06-03 08:10:34 [INFO]: Epoch 006 - training loss: 0.6148, validation loss: 0.5640
2024-06-03 08:10:42 [INFO]: Epoch 007 - training loss: 0.6112, validation loss: 0.5818
2024-06-03 08:10:49 [INFO]: Epoch 008 - training loss: 0.6073, validation loss: 0.5658
2024-06-03 08:10:56 [INFO]: Epoch 009 - training loss: 0.6014, validation loss: 0.5562
2024-06-03 08:11:03 [INFO]: Epoch 010 - training loss: 0.5965, validation loss: 0.5582
2024-06-03 08:11:10 [INFO]: Epoch 011 - training loss: 0.5835, validation loss: 0.5435
2024-06-03 08:11:16 [INFO]: Epoch 012 - training loss: 0.5799, validation loss: 0.5428
2024-06-03 08:11:24 [INFO]: Epoch 013 - training loss: 0.5833, validation loss: 0.5351
2024-06-03 08:11:31 [INFO]: Epoch 014 - training loss: 0.5843, validation loss: 0.5384
2024-06-03 08:11:38 [INFO]: Epoch 015 - training loss: 0.5780, validation loss: 0.5313
2024-06-03 08:11:45 [INFO]: Epoch 016 - training loss: 0.5694, validation loss: 0.5366
2024-06-03 08:11:52 [INFO]: Epoch 017 - training loss: 0.5694, validation loss: 0.5402
2024-06-03 08:11:59 [INFO]: Epoch 018 - training loss: 0.5745, validation loss: 0.5249
2024-06-03 08:12:06 [INFO]: Epoch 019 - training loss: 0.5675, validation loss: 0.5448
2024-06-03 08:12:13 [INFO]: Epoch 020 - training loss: 0.5594, validation loss: 0.5255
2024-06-03 08:12:20 [INFO]: Epoch 021 - training loss: 0.5544, validation loss: 0.5154
2024-06-03 08:12:27 [INFO]: Epoch 022 - training loss: 0.5529, validation loss: 0.5265
2024-06-03 08:12:34 [INFO]: Epoch 023 - training loss: 0.5612, validation loss: 0.5128
2024-06-03 08:12:41 [INFO]: Epoch 024 - training loss: 0.5461, validation loss: 0.5188
2024-06-03 08:12:48 [INFO]: Epoch 025 - training loss: 0.5487, validation loss: 0.5162
2024-06-03 08:12:55 [INFO]: Epoch 026 - training loss: 0.5457, validation loss: 0.5146
2024-06-03 08:13:03 [INFO]: Epoch 027 - training loss: 0.5417, validation loss: 0.5107
2024-06-03 08:13:09 [INFO]: Epoch 028 - training loss: 0.5396, validation loss: 0.5167
2024-06-03 08:13:16 [INFO]: Epoch 029 - training loss: 0.5396, validation loss: 0.5147
2024-06-03 08:13:22 [INFO]: Epoch 030 - training loss: 0.5313, validation loss: 0.5131
2024-06-03 08:13:28 [INFO]: Epoch 031 - training loss: 0.5260, validation loss: 0.5314
2024-06-03 08:13:34 [INFO]: Epoch 032 - training loss: 0.5294, validation loss: 0.5112
2024-06-03 08:13:40 [INFO]: Epoch 033 - training loss: 0.5273, validation loss: 0.5054
2024-06-03 08:13:47 [INFO]: Epoch 034 - training loss: 0.5270, validation loss: 0.5082
2024-06-03 08:13:53 [INFO]: Epoch 035 - training loss: 0.5167, validation loss: 0.5039
2024-06-03 08:13:59 [INFO]: Epoch 036 - training loss: 0.5136, validation loss: 0.5072
2024-06-03 08:14:05 [INFO]: Epoch 037 - training loss: 0.5130, validation loss: 0.5020
2024-06-03 08:14:12 [INFO]: Epoch 038 - training loss: 0.5148, validation loss: 0.4933
2024-06-03 08:14:18 [INFO]: Epoch 039 - training loss: 0.5124, validation loss: 0.5055
2024-06-03 08:14:24 [INFO]: Epoch 040 - training loss: 0.5056, validation loss: 0.4966
2024-06-03 08:14:30 [INFO]: Epoch 041 - training loss: 0.5018, validation loss: 0.4986
2024-06-03 08:14:37 [INFO]: Epoch 042 - training loss: 0.5015, validation loss: 0.5033
2024-06-03 08:14:43 [INFO]: Epoch 043 - training loss: 0.5056, validation loss: 0.5044
2024-06-03 08:14:49 [INFO]: Epoch 044 - training loss: 0.5002, validation loss: 0.4963
2024-06-03 08:14:56 [INFO]: Epoch 045 - training loss: 0.4916, validation loss: 0.4911
2024-06-03 08:15:02 [INFO]: Epoch 046 - training loss: 0.4909, validation loss: 0.4891
2024-06-03 08:15:08 [INFO]: Epoch 047 - training loss: 0.4946, validation loss: 0.4928
2024-06-03 08:15:14 [INFO]: Epoch 048 - training loss: 0.4940, validation loss: 0.4983
2024-06-03 08:15:20 [INFO]: Epoch 049 - training loss: 0.4935, validation loss: 0.4924
2024-06-03 08:15:27 [INFO]: Epoch 050 - training loss: 0.4924, validation loss: 0.4936
2024-06-03 08:15:33 [INFO]: Epoch 051 - training loss: 0.4858, validation loss: 0.4932
2024-06-03 08:15:39 [INFO]: Epoch 052 - training loss: 0.4871, validation loss: 0.4973
2024-06-03 08:15:45 [INFO]: Epoch 053 - training loss: 0.4871, validation loss: 0.4919
2024-06-03 08:15:51 [INFO]: Epoch 054 - training loss: 0.4831, validation loss: 0.4853
2024-06-03 08:15:57 [INFO]: Epoch 055 - training loss: 0.4747, validation loss: 0.4881
2024-06-03 08:16:04 [INFO]: Epoch 056 - training loss: 0.4746, validation loss: 0.4958
2024-06-03 08:16:10 [INFO]: Epoch 057 - training loss: 0.4789, validation loss: 0.4868
2024-06-03 08:16:16 [INFO]: Epoch 058 - training loss: 0.4752, validation loss: 0.4877
2024-06-03 08:16:22 [INFO]: Epoch 059 - training loss: 0.4837, validation loss: 0.4844
2024-06-03 08:16:28 [INFO]: Epoch 060 - training loss: 0.4754, validation loss: 0.4908
2024-06-03 08:16:35 [INFO]: Epoch 061 - training loss: 0.4728, validation loss: 0.4912
2024-06-03 08:16:41 [INFO]: Epoch 062 - training loss: 0.4670, validation loss: 0.4924
2024-06-03 08:16:47 [INFO]: Epoch 063 - training loss: 0.4692, validation loss: 0.4926
2024-06-03 08:16:53 [INFO]: Epoch 064 - training loss: 0.4626, validation loss: 0.4849
2024-06-03 08:16:59 [INFO]: Epoch 065 - training loss: 0.4627, validation loss: 0.4881
2024-06-03 08:17:05 [INFO]: Epoch 066 - training loss: 0.4700, validation loss: 0.4814
2024-06-03 08:17:11 [INFO]: Epoch 067 - training loss: 0.4651, validation loss: 0.4837
2024-06-03 08:17:18 [INFO]: Epoch 068 - training loss: 0.4626, validation loss: 0.4838
2024-06-03 08:17:24 [INFO]: Epoch 069 - training loss: 0.4615, validation loss: 0.4801
2024-06-03 08:17:30 [INFO]: Epoch 070 - training loss: 0.4580, validation loss: 0.4852
2024-06-03 08:17:36 [INFO]: Epoch 071 - training loss: 0.4602, validation loss: 0.4823
2024-06-03 08:17:42 [INFO]: Epoch 072 - training loss: 0.4652, validation loss: 0.4827
2024-06-03 08:17:48 [INFO]: Epoch 073 - training loss: 0.4586, validation loss: 0.4822
2024-06-03 08:17:54 [INFO]: Epoch 074 - training loss: 0.4585, validation loss: 0.4762
2024-06-03 08:18:01 [INFO]: Epoch 075 - training loss: 0.4600, validation loss: 0.4796
2024-06-03 08:18:07 [INFO]: Epoch 076 - training loss: 0.4605, validation loss: 0.4783
2024-06-03 08:18:13 [INFO]: Epoch 077 - training loss: 0.4496, validation loss: 0.4784
2024-06-03 08:18:19 [INFO]: Epoch 078 - training loss: 0.4538, validation loss: 0.4905
2024-06-03 08:18:26 [INFO]: Epoch 079 - training loss: 0.4558, validation loss: 0.4770
2024-06-03 08:18:32 [INFO]: Epoch 080 - training loss: 0.4544, validation loss: 0.4781
2024-06-03 08:18:38 [INFO]: Epoch 081 - training loss: 0.4546, validation loss: 0.4818
2024-06-03 08:18:43 [INFO]: Epoch 082 - training loss: 0.4513, validation loss: 0.4789
2024-06-03 08:18:49 [INFO]: Epoch 083 - training loss: 0.4514, validation loss: 0.4859
2024-06-03 08:18:55 [INFO]: Epoch 084 - training loss: 0.4485, validation loss: 0.4809
2024-06-03 08:18:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:18:55 [INFO]: Finished training. The best model is from epoch#74.
2024-06-03 08:18:55 [INFO]: Saved the model to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T080952/iTransformer.pypots
2024-06-03 08:18:57 [INFO]: Successfully saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_1/imputation.pkl
2024-06-03 08:18:57 [INFO]: Round1 - iTransformer on BeijingAir: MAE=0.3503, MSE=0.5082, MRE=0.4718
2024-06-03 08:18:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:18:57 [INFO]: Using the given device: cuda:0
2024-06-03 08:18:57 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T081857
2024-06-03 08:18:57 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T081857/tensorboard
2024-06-03 08:18:57 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 08:19:03 [INFO]: Epoch 001 - training loss: 1.0361, validation loss: 0.6614
2024-06-03 08:19:09 [INFO]: Epoch 002 - training loss: 0.6917, validation loss: 0.6290
2024-06-03 08:19:14 [INFO]: Epoch 003 - training loss: 0.6568, validation loss: 0.6036
2024-06-03 08:19:20 [INFO]: Epoch 004 - training loss: 0.6437, validation loss: 0.5767
2024-06-03 08:19:26 [INFO]: Epoch 005 - training loss: 0.6315, validation loss: 0.5770
2024-06-03 08:19:32 [INFO]: Epoch 006 - training loss: 0.6141, validation loss: 0.5793
2024-06-03 08:19:38 [INFO]: Epoch 007 - training loss: 0.6169, validation loss: 0.5608
2024-06-03 08:19:43 [INFO]: Epoch 008 - training loss: 0.5987, validation loss: 0.5522
2024-06-03 08:19:49 [INFO]: Epoch 009 - training loss: 0.5994, validation loss: 0.5376
2024-06-03 08:19:55 [INFO]: Epoch 010 - training loss: 0.5838, validation loss: 0.5427
2024-06-03 08:20:01 [INFO]: Epoch 011 - training loss: 0.5946, validation loss: 0.5374
2024-06-03 08:20:06 [INFO]: Epoch 012 - training loss: 0.5834, validation loss: 0.5316
2024-06-03 08:20:12 [INFO]: Epoch 013 - training loss: 0.5768, validation loss: 0.5365
2024-06-03 08:20:18 [INFO]: Epoch 014 - training loss: 0.5724, validation loss: 0.5274
2024-06-03 08:20:23 [INFO]: Epoch 015 - training loss: 0.5695, validation loss: 0.5323
2024-06-03 08:20:29 [INFO]: Epoch 016 - training loss: 0.5731, validation loss: 0.5237
2024-06-03 08:20:35 [INFO]: Epoch 017 - training loss: 0.5682, validation loss: 0.5229
2024-06-03 08:20:41 [INFO]: Epoch 018 - training loss: 0.5639, validation loss: 0.5161
2024-06-03 08:20:47 [INFO]: Epoch 019 - training loss: 0.5608, validation loss: 0.5227
2024-06-03 08:20:52 [INFO]: Epoch 020 - training loss: 0.5518, validation loss: 0.5192
2024-06-03 08:20:58 [INFO]: Epoch 021 - training loss: 0.5579, validation loss: 0.5333
2024-06-03 08:21:03 [INFO]: Epoch 022 - training loss: 0.5573, validation loss: 0.5225
2024-06-03 08:21:09 [INFO]: Epoch 023 - training loss: 0.5499, validation loss: 0.5149
2024-06-03 08:21:14 [INFO]: Epoch 024 - training loss: 0.5413, validation loss: 0.5185
2024-06-03 08:21:20 [INFO]: Epoch 025 - training loss: 0.5393, validation loss: 0.5086
2024-06-03 08:21:25 [INFO]: Epoch 026 - training loss: 0.5434, validation loss: 0.5171
2024-06-03 08:21:31 [INFO]: Epoch 027 - training loss: 0.5463, validation loss: 0.5125
2024-06-03 08:21:36 [INFO]: Epoch 028 - training loss: 0.5280, validation loss: 0.5109
2024-06-03 08:21:42 [INFO]: Epoch 029 - training loss: 0.5324, validation loss: 0.5082
2024-06-03 08:21:48 [INFO]: Epoch 030 - training loss: 0.5306, validation loss: 0.5036
2024-06-03 08:21:53 [INFO]: Epoch 031 - training loss: 0.5266, validation loss: 0.5054
2024-06-03 08:21:58 [INFO]: Epoch 032 - training loss: 0.5208, validation loss: 0.5041
2024-06-03 08:22:04 [INFO]: Epoch 033 - training loss: 0.5230, validation loss: 0.5078
2024-06-03 08:22:09 [INFO]: Epoch 034 - training loss: 0.5129, validation loss: 0.5052
2024-06-03 08:22:15 [INFO]: Epoch 035 - training loss: 0.5102, validation loss: 0.5035
2024-06-03 08:22:20 [INFO]: Epoch 036 - training loss: 0.5124, validation loss: 0.5052
2024-06-03 08:22:26 [INFO]: Epoch 037 - training loss: 0.5087, validation loss: 0.5036
2024-06-03 08:22:31 [INFO]: Epoch 038 - training loss: 0.5045, validation loss: 0.5071
2024-06-03 08:22:37 [INFO]: Epoch 039 - training loss: 0.5074, validation loss: 0.4971
2024-06-03 08:22:43 [INFO]: Epoch 040 - training loss: 0.5094, validation loss: 0.4941
2024-06-03 08:22:48 [INFO]: Epoch 041 - training loss: 0.4999, validation loss: 0.5000
2024-06-03 08:22:53 [INFO]: Epoch 042 - training loss: 0.4979, validation loss: 0.4956
2024-06-03 08:22:58 [INFO]: Epoch 043 - training loss: 0.5023, validation loss: 0.4967
2024-06-03 08:23:03 [INFO]: Epoch 044 - training loss: 0.4978, validation loss: 0.4977
2024-06-03 08:23:07 [INFO]: Epoch 045 - training loss: 0.4932, validation loss: 0.4981
2024-06-03 08:23:12 [INFO]: Epoch 046 - training loss: 0.4895, validation loss: 0.4993
2024-06-03 08:23:17 [INFO]: Epoch 047 - training loss: 0.4923, validation loss: 0.4962
2024-06-03 08:23:21 [INFO]: Epoch 048 - training loss: 0.4902, validation loss: 0.5068
2024-06-03 08:23:25 [INFO]: Epoch 049 - training loss: 0.4896, validation loss: 0.4978
2024-06-03 08:23:30 [INFO]: Epoch 050 - training loss: 0.4908, validation loss: 0.4983
2024-06-03 08:23:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:23:30 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 08:23:30 [INFO]: Saved the model to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T081857/iTransformer.pypots
2024-06-03 08:23:31 [INFO]: Successfully saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_2/imputation.pkl
2024-06-03 08:23:31 [INFO]: Round2 - iTransformer on BeijingAir: MAE=0.3647, MSE=0.5271, MRE=0.4911
2024-06-03 08:23:31 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:23:31 [INFO]: Using the given device: cuda:0
2024-06-03 08:23:31 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T082331
2024-06-03 08:23:31 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T082331/tensorboard
2024-06-03 08:23:32 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 08:23:36 [INFO]: Epoch 001 - training loss: 1.0266, validation loss: 0.6452
2024-06-03 08:23:41 [INFO]: Epoch 002 - training loss: 0.6878, validation loss: 0.6230
2024-06-03 08:23:45 [INFO]: Epoch 003 - training loss: 0.6507, validation loss: 0.5789
2024-06-03 08:23:50 [INFO]: Epoch 004 - training loss: 0.6364, validation loss: 0.5761
2024-06-03 08:23:55 [INFO]: Epoch 005 - training loss: 0.6239, validation loss: 0.5772
2024-06-03 08:23:59 [INFO]: Epoch 006 - training loss: 0.6132, validation loss: 0.5726
2024-06-03 08:24:04 [INFO]: Epoch 007 - training loss: 0.6087, validation loss: 0.5600
2024-06-03 08:24:08 [INFO]: Epoch 008 - training loss: 0.6000, validation loss: 0.5469
2024-06-03 08:24:13 [INFO]: Epoch 009 - training loss: 0.6020, validation loss: 0.5459
2024-06-03 08:24:17 [INFO]: Epoch 010 - training loss: 0.5934, validation loss: 0.5328
2024-06-03 08:24:22 [INFO]: Epoch 011 - training loss: 0.5846, validation loss: 0.5384
2024-06-03 08:24:26 [INFO]: Epoch 012 - training loss: 0.5854, validation loss: 0.5348
2024-06-03 08:24:31 [INFO]: Epoch 013 - training loss: 0.5818, validation loss: 0.5272
2024-06-03 08:24:35 [INFO]: Epoch 014 - training loss: 0.5765, validation loss: 0.5307
2024-06-03 08:24:40 [INFO]: Epoch 015 - training loss: 0.5750, validation loss: 0.5268
2024-06-03 08:24:44 [INFO]: Epoch 016 - training loss: 0.5662, validation loss: 0.5198
2024-06-03 08:24:49 [INFO]: Epoch 017 - training loss: 0.5675, validation loss: 0.5190
2024-06-03 08:24:54 [INFO]: Epoch 018 - training loss: 0.5730, validation loss: 0.5195
2024-06-03 08:24:58 [INFO]: Epoch 019 - training loss: 0.5671, validation loss: 0.5297
2024-06-03 08:25:02 [INFO]: Epoch 020 - training loss: 0.5640, validation loss: 0.5166
2024-06-03 08:25:07 [INFO]: Epoch 021 - training loss: 0.5531, validation loss: 0.5137
2024-06-03 08:25:11 [INFO]: Epoch 022 - training loss: 0.5558, validation loss: 0.5164
2024-06-03 08:25:16 [INFO]: Epoch 023 - training loss: 0.5549, validation loss: 0.5260
2024-06-03 08:25:20 [INFO]: Epoch 024 - training loss: 0.5525, validation loss: 0.5114
2024-06-03 08:25:25 [INFO]: Epoch 025 - training loss: 0.5319, validation loss: 0.5146
2024-06-03 08:25:30 [INFO]: Epoch 026 - training loss: 0.5334, validation loss: 0.5115
2024-06-03 08:25:34 [INFO]: Epoch 027 - training loss: 0.5337, validation loss: 0.5022
2024-06-03 08:25:39 [INFO]: Epoch 028 - training loss: 0.5365, validation loss: 0.5110
2024-06-03 08:25:43 [INFO]: Epoch 029 - training loss: 0.5263, validation loss: 0.5104
2024-06-03 08:25:48 [INFO]: Epoch 030 - training loss: 0.5293, validation loss: 0.5002
2024-06-03 08:25:52 [INFO]: Epoch 031 - training loss: 0.5226, validation loss: 0.5012
2024-06-03 08:25:56 [INFO]: Epoch 032 - training loss: 0.5117, validation loss: 0.5020
2024-06-03 08:26:01 [INFO]: Epoch 033 - training loss: 0.5099, validation loss: 0.5080
2024-06-03 08:26:05 [INFO]: Epoch 034 - training loss: 0.5143, validation loss: 0.5151
2024-06-03 08:26:10 [INFO]: Epoch 035 - training loss: 0.5150, validation loss: 0.5027
2024-06-03 08:26:14 [INFO]: Epoch 036 - training loss: 0.5076, validation loss: 0.4944
2024-06-03 08:26:19 [INFO]: Epoch 037 - training loss: 0.5085, validation loss: 0.4953
2024-06-03 08:26:23 [INFO]: Epoch 038 - training loss: 0.5116, validation loss: 0.4980
2024-06-03 08:26:28 [INFO]: Epoch 039 - training loss: 0.5044, validation loss: 0.4920
2024-06-03 08:26:32 [INFO]: Epoch 040 - training loss: 0.4972, validation loss: 0.4955
2024-06-03 08:26:37 [INFO]: Epoch 041 - training loss: 0.4967, validation loss: 0.5028
2024-06-03 08:26:41 [INFO]: Epoch 042 - training loss: 0.4988, validation loss: 0.4941
2024-06-03 08:26:46 [INFO]: Epoch 043 - training loss: 0.4977, validation loss: 0.4989
2024-06-03 08:26:50 [INFO]: Epoch 044 - training loss: 0.4934, validation loss: 0.4927
2024-06-03 08:26:55 [INFO]: Epoch 045 - training loss: 0.4960, validation loss: 0.4898
2024-06-03 08:26:59 [INFO]: Epoch 046 - training loss: 0.4907, validation loss: 0.5028
2024-06-03 08:27:04 [INFO]: Epoch 047 - training loss: 0.4958, validation loss: 0.4940
2024-06-03 08:27:08 [INFO]: Epoch 048 - training loss: 0.4906, validation loss: 0.4897
2024-06-03 08:27:13 [INFO]: Epoch 049 - training loss: 0.4874, validation loss: 0.4897
2024-06-03 08:27:17 [INFO]: Epoch 050 - training loss: 0.4856, validation loss: 0.4875
2024-06-03 08:27:22 [INFO]: Epoch 051 - training loss: 0.4773, validation loss: 0.4841
2024-06-03 08:27:26 [INFO]: Epoch 052 - training loss: 0.4842, validation loss: 0.4836
2024-06-03 08:27:30 [INFO]: Epoch 053 - training loss: 0.4794, validation loss: 0.4895
2024-06-03 08:27:35 [INFO]: Epoch 054 - training loss: 0.4769, validation loss: 0.4902
2024-06-03 08:27:39 [INFO]: Epoch 055 - training loss: 0.4780, validation loss: 0.4867
2024-06-03 08:27:44 [INFO]: Epoch 056 - training loss: 0.4735, validation loss: 0.4840
2024-06-03 08:27:48 [INFO]: Epoch 057 - training loss: 0.4785, validation loss: 0.4922
2024-06-03 08:27:52 [INFO]: Epoch 058 - training loss: 0.4774, validation loss: 0.4813
2024-06-03 08:27:57 [INFO]: Epoch 059 - training loss: 0.4738, validation loss: 0.4889
2024-06-03 08:28:01 [INFO]: Epoch 060 - training loss: 0.4703, validation loss: 0.4854
2024-06-03 08:28:06 [INFO]: Epoch 061 - training loss: 0.4757, validation loss: 0.4822
2024-06-03 08:28:10 [INFO]: Epoch 062 - training loss: 0.4695, validation loss: 0.4856
2024-06-03 08:28:15 [INFO]: Epoch 063 - training loss: 0.4660, validation loss: 0.4900
2024-06-03 08:28:19 [INFO]: Epoch 064 - training loss: 0.4635, validation loss: 0.4872
2024-06-03 08:28:24 [INFO]: Epoch 065 - training loss: 0.4659, validation loss: 0.4914
2024-06-03 08:28:28 [INFO]: Epoch 066 - training loss: 0.4659, validation loss: 0.4816
2024-06-03 08:28:33 [INFO]: Epoch 067 - training loss: 0.4600, validation loss: 0.4803
2024-06-03 08:28:37 [INFO]: Epoch 068 - training loss: 0.4600, validation loss: 0.4894
2024-06-03 08:28:42 [INFO]: Epoch 069 - training loss: 0.4643, validation loss: 0.4908
2024-06-03 08:28:46 [INFO]: Epoch 070 - training loss: 0.4546, validation loss: 0.4836
2024-06-03 08:28:51 [INFO]: Epoch 071 - training loss: 0.4613, validation loss: 0.4816
2024-06-03 08:28:56 [INFO]: Epoch 072 - training loss: 0.4668, validation loss: 0.4765
2024-06-03 08:29:00 [INFO]: Epoch 073 - training loss: 0.4606, validation loss: 0.5013
2024-06-03 08:29:05 [INFO]: Epoch 074 - training loss: 0.4640, validation loss: 0.4857
2024-06-03 08:29:09 [INFO]: Epoch 075 - training loss: 0.4568, validation loss: 0.4797
2024-06-03 08:29:14 [INFO]: Epoch 076 - training loss: 0.4500, validation loss: 0.4914
2024-06-03 08:29:18 [INFO]: Epoch 077 - training loss: 0.4527, validation loss: 0.4832
2024-06-03 08:29:22 [INFO]: Epoch 078 - training loss: 0.4535, validation loss: 0.4768
2024-06-03 08:29:27 [INFO]: Epoch 079 - training loss: 0.4539, validation loss: 0.4876
2024-06-03 08:29:31 [INFO]: Epoch 080 - training loss: 0.4494, validation loss: 0.4765
2024-06-03 08:29:36 [INFO]: Epoch 081 - training loss: 0.4583, validation loss: 0.4795
2024-06-03 08:29:40 [INFO]: Epoch 082 - training loss: 0.4529, validation loss: 0.4821
2024-06-03 08:29:45 [INFO]: Epoch 083 - training loss: 0.4498, validation loss: 0.4798
2024-06-03 08:29:49 [INFO]: Epoch 084 - training loss: 0.4473, validation loss: 0.4743
2024-06-03 08:29:54 [INFO]: Epoch 085 - training loss: 0.4470, validation loss: 0.4753
2024-06-03 08:29:58 [INFO]: Epoch 086 - training loss: 0.4520, validation loss: 0.4774
2024-06-03 08:30:02 [INFO]: Epoch 087 - training loss: 0.4571, validation loss: 0.4789
2024-06-03 08:30:07 [INFO]: Epoch 088 - training loss: 0.4488, validation loss: 0.4863
2024-06-03 08:30:12 [INFO]: Epoch 089 - training loss: 0.4488, validation loss: 0.4767
2024-06-03 08:30:16 [INFO]: Epoch 090 - training loss: 0.4499, validation loss: 0.4787
2024-06-03 08:30:20 [INFO]: Epoch 091 - training loss: 0.4421, validation loss: 0.4738
2024-06-03 08:30:25 [INFO]: Epoch 092 - training loss: 0.4363, validation loss: 0.4764
2024-06-03 08:30:29 [INFO]: Epoch 093 - training loss: 0.4465, validation loss: 0.4790
2024-06-03 08:30:34 [INFO]: Epoch 094 - training loss: 0.4430, validation loss: 0.4775
2024-06-03 08:30:38 [INFO]: Epoch 095 - training loss: 0.4387, validation loss: 0.4764
2024-06-03 08:30:42 [INFO]: Epoch 096 - training loss: 0.4454, validation loss: 0.4787
2024-06-03 08:30:47 [INFO]: Epoch 097 - training loss: 0.4405, validation loss: 0.4725
2024-06-03 08:30:52 [INFO]: Epoch 098 - training loss: 0.4368, validation loss: 0.4729
2024-06-03 08:30:56 [INFO]: Epoch 099 - training loss: 0.4407, validation loss: 0.4768
2024-06-03 08:31:01 [INFO]: Epoch 100 - training loss: 0.4393, validation loss: 0.4798
2024-06-03 08:31:01 [INFO]: Finished training. The best model is from epoch#97.
2024-06-03 08:31:01 [INFO]: Saved the model to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T082331/iTransformer.pypots
2024-06-03 08:31:02 [INFO]: Successfully saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_3/imputation.pkl
2024-06-03 08:31:02 [INFO]: Round3 - iTransformer on BeijingAir: MAE=0.3543, MSE=0.5144, MRE=0.4771
2024-06-03 08:31:02 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:31:02 [INFO]: Using the given device: cuda:0
2024-06-03 08:31:02 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T083102
2024-06-03 08:31:02 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T083102/tensorboard
2024-06-03 08:31:03 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 08:31:07 [INFO]: Epoch 001 - training loss: 1.0530, validation loss: 0.6553
2024-06-03 08:31:12 [INFO]: Epoch 002 - training loss: 0.6913, validation loss: 0.6250
2024-06-03 08:31:17 [INFO]: Epoch 003 - training loss: 0.6545, validation loss: 0.6038
2024-06-03 08:31:21 [INFO]: Epoch 004 - training loss: 0.6407, validation loss: 0.5882
2024-06-03 08:31:26 [INFO]: Epoch 005 - training loss: 0.6313, validation loss: 0.6004
2024-06-03 08:31:30 [INFO]: Epoch 006 - training loss: 0.6153, validation loss: 0.5746
2024-06-03 08:31:34 [INFO]: Epoch 007 - training loss: 0.6058, validation loss: 0.5662
2024-06-03 08:31:39 [INFO]: Epoch 008 - training loss: 0.6080, validation loss: 0.5533
2024-06-03 08:31:43 [INFO]: Epoch 009 - training loss: 0.6020, validation loss: 0.5446
2024-06-03 08:31:48 [INFO]: Epoch 010 - training loss: 0.5892, validation loss: 0.5595
2024-06-03 08:31:52 [INFO]: Epoch 011 - training loss: 0.5851, validation loss: 0.5608
2024-06-03 08:31:57 [INFO]: Epoch 012 - training loss: 0.5882, validation loss: 0.5462
2024-06-03 08:32:01 [INFO]: Epoch 013 - training loss: 0.5787, validation loss: 0.5638
2024-06-03 08:32:06 [INFO]: Epoch 014 - training loss: 0.5789, validation loss: 0.5333
2024-06-03 08:32:10 [INFO]: Epoch 015 - training loss: 0.5717, validation loss: 0.5290
2024-06-03 08:32:15 [INFO]: Epoch 016 - training loss: 0.5753, validation loss: 0.5282
2024-06-03 08:32:19 [INFO]: Epoch 017 - training loss: 0.5666, validation loss: 0.5272
2024-06-03 08:32:24 [INFO]: Epoch 018 - training loss: 0.5594, validation loss: 0.5253
2024-06-03 08:32:28 [INFO]: Epoch 019 - training loss: 0.5616, validation loss: 0.5305
2024-06-03 08:32:33 [INFO]: Epoch 020 - training loss: 0.5669, validation loss: 0.5330
2024-06-03 08:32:37 [INFO]: Epoch 021 - training loss: 0.5583, validation loss: 0.5253
2024-06-03 08:32:42 [INFO]: Epoch 022 - training loss: 0.5515, validation loss: 0.5160
2024-06-03 08:32:46 [INFO]: Epoch 023 - training loss: 0.5533, validation loss: 0.5100
2024-06-03 08:32:51 [INFO]: Epoch 024 - training loss: 0.5495, validation loss: 0.5188
2024-06-03 08:32:55 [INFO]: Epoch 025 - training loss: 0.5426, validation loss: 0.5190
2024-06-03 08:33:00 [INFO]: Epoch 026 - training loss: 0.5382, validation loss: 0.5220
2024-06-03 08:33:04 [INFO]: Epoch 027 - training loss: 0.5419, validation loss: 0.5114
2024-06-03 08:33:09 [INFO]: Epoch 028 - training loss: 0.5356, validation loss: 0.5116
2024-06-03 08:33:13 [INFO]: Epoch 029 - training loss: 0.5292, validation loss: 0.5104
2024-06-03 08:33:17 [INFO]: Epoch 030 - training loss: 0.5245, validation loss: 0.5119
2024-06-03 08:33:22 [INFO]: Epoch 031 - training loss: 0.5216, validation loss: 0.5117
2024-06-03 08:33:26 [INFO]: Epoch 032 - training loss: 0.5187, validation loss: 0.5100
2024-06-03 08:33:31 [INFO]: Epoch 033 - training loss: 0.5206, validation loss: 0.5061
2024-06-03 08:33:35 [INFO]: Epoch 034 - training loss: 0.5167, validation loss: 0.4999
2024-06-03 08:33:40 [INFO]: Epoch 035 - training loss: 0.5211, validation loss: 0.5070
2024-06-03 08:33:44 [INFO]: Epoch 036 - training loss: 0.5055, validation loss: 0.4989
2024-06-03 08:33:49 [INFO]: Epoch 037 - training loss: 0.5024, validation loss: 0.5023
2024-06-03 08:33:53 [INFO]: Epoch 038 - training loss: 0.5013, validation loss: 0.4937
2024-06-03 08:33:57 [INFO]: Epoch 039 - training loss: 0.5108, validation loss: 0.4988
2024-06-03 08:34:02 [INFO]: Epoch 040 - training loss: 0.5006, validation loss: 0.4954
2024-06-03 08:34:06 [INFO]: Epoch 041 - training loss: 0.5034, validation loss: 0.5009
2024-06-03 08:34:11 [INFO]: Epoch 042 - training loss: 0.5009, validation loss: 0.4914
2024-06-03 08:34:15 [INFO]: Epoch 043 - training loss: 0.5000, validation loss: 0.5000
2024-06-03 08:34:20 [INFO]: Epoch 044 - training loss: 0.4947, validation loss: 0.4950
2024-06-03 08:34:25 [INFO]: Epoch 045 - training loss: 0.4914, validation loss: 0.4922
2024-06-03 08:34:29 [INFO]: Epoch 046 - training loss: 0.4899, validation loss: 0.5004
2024-06-03 08:34:34 [INFO]: Epoch 047 - training loss: 0.4914, validation loss: 0.4916
2024-06-03 08:34:38 [INFO]: Epoch 048 - training loss: 0.4878, validation loss: 0.4993
2024-06-03 08:34:42 [INFO]: Epoch 049 - training loss: 0.4962, validation loss: 0.4901
2024-06-03 08:34:47 [INFO]: Epoch 050 - training loss: 0.4929, validation loss: 0.5003
2024-06-03 08:34:51 [INFO]: Epoch 051 - training loss: 0.4879, validation loss: 0.5007
2024-06-03 08:34:56 [INFO]: Epoch 052 - training loss: 0.4897, validation loss: 0.4888
2024-06-03 08:35:00 [INFO]: Epoch 053 - training loss: 0.4838, validation loss: 0.4917
2024-06-03 08:35:05 [INFO]: Epoch 054 - training loss: 0.4770, validation loss: 0.5031
2024-06-03 08:35:09 [INFO]: Epoch 055 - training loss: 0.4771, validation loss: 0.4855
2024-06-03 08:35:14 [INFO]: Epoch 056 - training loss: 0.4800, validation loss: 0.4875
2024-06-03 08:35:18 [INFO]: Epoch 057 - training loss: 0.4712, validation loss: 0.4949
2024-06-03 08:35:23 [INFO]: Epoch 058 - training loss: 0.4723, validation loss: 0.4894
2024-06-03 08:35:27 [INFO]: Epoch 059 - training loss: 0.4721, validation loss: 0.4904
2024-06-03 08:35:32 [INFO]: Epoch 060 - training loss: 0.4765, validation loss: 0.4932
2024-06-03 08:35:36 [INFO]: Epoch 061 - training loss: 0.4794, validation loss: 0.5020
2024-06-03 08:35:40 [INFO]: Epoch 062 - training loss: 0.4684, validation loss: 0.4948
2024-06-03 08:35:45 [INFO]: Epoch 063 - training loss: 0.4669, validation loss: 0.4999
2024-06-03 08:35:49 [INFO]: Epoch 064 - training loss: 0.4689, validation loss: 0.4906
2024-06-03 08:35:54 [INFO]: Epoch 065 - training loss: 0.4673, validation loss: 0.4793
2024-06-03 08:35:58 [INFO]: Epoch 066 - training loss: 0.4575, validation loss: 0.4856
2024-06-03 08:36:03 [INFO]: Epoch 067 - training loss: 0.4650, validation loss: 0.4851
2024-06-03 08:36:07 [INFO]: Epoch 068 - training loss: 0.4615, validation loss: 0.4780
2024-06-03 08:36:12 [INFO]: Epoch 069 - training loss: 0.4686, validation loss: 0.4826
2024-06-03 08:36:16 [INFO]: Epoch 070 - training loss: 0.4598, validation loss: 0.4854
2024-06-03 08:36:21 [INFO]: Epoch 071 - training loss: 0.4639, validation loss: 0.4843
2024-06-03 08:36:25 [INFO]: Epoch 072 - training loss: 0.4629, validation loss: 0.4765
2024-06-03 08:36:30 [INFO]: Epoch 073 - training loss: 0.4550, validation loss: 0.4886
2024-06-03 08:36:34 [INFO]: Epoch 074 - training loss: 0.4620, validation loss: 0.4853
2024-06-03 08:36:39 [INFO]: Epoch 075 - training loss: 0.4567, validation loss: 0.4807
2024-06-03 08:36:43 [INFO]: Epoch 076 - training loss: 0.4605, validation loss: 0.4756
2024-06-03 08:36:47 [INFO]: Epoch 077 - training loss: 0.4588, validation loss: 0.4806
2024-06-03 08:36:52 [INFO]: Epoch 078 - training loss: 0.4538, validation loss: 0.4829
2024-06-03 08:36:56 [INFO]: Epoch 079 - training loss: 0.4520, validation loss: 0.4796
2024-06-03 08:37:01 [INFO]: Epoch 080 - training loss: 0.4516, validation loss: 0.4747
2024-06-03 08:37:06 [INFO]: Epoch 081 - training loss: 0.4496, validation loss: 0.4875
2024-06-03 08:37:10 [INFO]: Epoch 082 - training loss: 0.4465, validation loss: 0.4774
2024-06-03 08:37:14 [INFO]: Epoch 083 - training loss: 0.4575, validation loss: 0.4883
2024-06-03 08:37:19 [INFO]: Epoch 084 - training loss: 0.4511, validation loss: 0.4757
2024-06-03 08:37:24 [INFO]: Epoch 085 - training loss: 0.4540, validation loss: 0.4779
2024-06-03 08:37:28 [INFO]: Epoch 086 - training loss: 0.4408, validation loss: 0.4782
2024-06-03 08:37:33 [INFO]: Epoch 087 - training loss: 0.4417, validation loss: 0.4821
2024-06-03 08:37:37 [INFO]: Epoch 088 - training loss: 0.4419, validation loss: 0.4760
2024-06-03 08:37:42 [INFO]: Epoch 089 - training loss: 0.4440, validation loss: 0.4717
2024-06-03 08:37:46 [INFO]: Epoch 090 - training loss: 0.4459, validation loss: 0.4841
2024-06-03 08:37:51 [INFO]: Epoch 091 - training loss: 0.4408, validation loss: 0.4789
2024-06-03 08:37:55 [INFO]: Epoch 092 - training loss: 0.4382, validation loss: 0.4805
2024-06-03 08:38:00 [INFO]: Epoch 093 - training loss: 0.4420, validation loss: 0.4718
2024-06-03 08:38:05 [INFO]: Epoch 094 - training loss: 0.4469, validation loss: 0.4752
2024-06-03 08:38:09 [INFO]: Epoch 095 - training loss: 0.4399, validation loss: 0.4784
2024-06-03 08:38:13 [INFO]: Epoch 096 - training loss: 0.4433, validation loss: 0.4766
2024-06-03 08:38:18 [INFO]: Epoch 097 - training loss: 0.4395, validation loss: 0.4748
2024-06-03 08:38:22 [INFO]: Epoch 098 - training loss: 0.4382, validation loss: 0.4745
2024-06-03 08:38:27 [INFO]: Epoch 099 - training loss: 0.4385, validation loss: 0.4766
2024-06-03 08:38:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:38:27 [INFO]: Finished training. The best model is from epoch#89.
2024-06-03 08:38:27 [INFO]: Saved the model to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T083102/iTransformer.pypots
2024-06-03 08:38:28 [INFO]: Successfully saved to results_point_rate09/BeijingAir/iTransformer_BeijingAir/round_4/imputation.pkl
2024-06-03 08:38:28 [INFO]: Round4 - iTransformer on BeijingAir: MAE=0.3493, MSE=0.5033, MRE=0.4704
2024-06-03 08:38:28 [INFO]: Done! Final results:
Averaged iTransformer (8,286,232 params) on BeijingAir: MAE=0.3525 ± 0.005329401922838356, MSE=0.5145 ± 0.008017650417136158, MRE=0.4676 ± 0.007070152223586379, average inference time=0.34