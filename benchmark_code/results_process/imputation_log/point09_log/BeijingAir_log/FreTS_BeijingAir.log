2024-06-03 00:37:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:37:45 [INFO]: Using the given device: cuda:0
2024-06-03 00:37:47 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_0/20240603_T003747
2024-06-03 00:37:47 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_0/20240603_T003747/tensorboard
2024-06-03 00:37:48 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 00:37:54 [INFO]: Epoch 001 - training loss: 1.2672, validation loss: 0.6020
2024-06-03 00:37:59 [INFO]: Epoch 002 - training loss: 0.7939, validation loss: 0.4751
2024-06-03 00:38:04 [INFO]: Epoch 003 - training loss: 0.6832, validation loss: 0.4088
2024-06-03 00:38:09 [INFO]: Epoch 004 - training loss: 0.6242, validation loss: 0.3926
2024-06-03 00:38:14 [INFO]: Epoch 005 - training loss: 0.5911, validation loss: 0.3772
2024-06-03 00:38:19 [INFO]: Epoch 006 - training loss: 0.5696, validation loss: 0.3721
2024-06-03 00:38:25 [INFO]: Epoch 007 - training loss: 0.5573, validation loss: 0.3698
2024-06-03 00:38:30 [INFO]: Epoch 008 - training loss: 0.5474, validation loss: 0.3549
2024-06-03 00:38:35 [INFO]: Epoch 009 - training loss: 0.5465, validation loss: 0.3570
2024-06-03 00:38:41 [INFO]: Epoch 010 - training loss: 0.5357, validation loss: 0.3624
2024-06-03 00:38:46 [INFO]: Epoch 011 - training loss: 0.5307, validation loss: 0.3575
2024-06-03 00:38:51 [INFO]: Epoch 012 - training loss: 0.5245, validation loss: 0.3559
2024-06-03 00:38:56 [INFO]: Epoch 013 - training loss: 0.5268, validation loss: 0.3639
2024-06-03 00:39:02 [INFO]: Epoch 014 - training loss: 0.5201, validation loss: 0.3558
2024-06-03 00:39:07 [INFO]: Epoch 015 - training loss: 0.5190, validation loss: 0.3549
2024-06-03 00:39:12 [INFO]: Epoch 016 - training loss: 0.5127, validation loss: 0.3554
2024-06-03 00:39:17 [INFO]: Epoch 017 - training loss: 0.5122, validation loss: 0.3604
2024-06-03 00:39:22 [INFO]: Epoch 018 - training loss: 0.5048, validation loss: 0.3545
2024-06-03 00:39:28 [INFO]: Epoch 019 - training loss: 0.5113, validation loss: 0.3556
2024-06-03 00:39:33 [INFO]: Epoch 020 - training loss: 0.5026, validation loss: 0.3593
2024-06-03 00:39:38 [INFO]: Epoch 021 - training loss: 0.5039, validation loss: 0.3541
2024-06-03 00:39:43 [INFO]: Epoch 022 - training loss: 0.5027, validation loss: 0.3537
2024-06-03 00:39:49 [INFO]: Epoch 023 - training loss: 0.4980, validation loss: 0.3532
2024-06-03 00:39:54 [INFO]: Epoch 024 - training loss: 0.4922, validation loss: 0.3534
2024-06-03 00:39:59 [INFO]: Epoch 025 - training loss: 0.4889, validation loss: 0.3521
2024-06-03 00:40:04 [INFO]: Epoch 026 - training loss: 0.4897, validation loss: 0.3505
2024-06-03 00:40:09 [INFO]: Epoch 027 - training loss: 0.4892, validation loss: 0.3566
2024-06-03 00:40:14 [INFO]: Epoch 028 - training loss: 0.4820, validation loss: 0.3528
2024-06-03 00:40:19 [INFO]: Epoch 029 - training loss: 0.4767, validation loss: 0.3524
2024-06-03 00:40:25 [INFO]: Epoch 030 - training loss: 0.4753, validation loss: 0.3514
2024-06-03 00:40:30 [INFO]: Epoch 031 - training loss: 0.4757, validation loss: 0.3529
2024-06-03 00:40:35 [INFO]: Epoch 032 - training loss: 0.4691, validation loss: 0.3477
2024-06-03 00:40:40 [INFO]: Epoch 033 - training loss: 0.4677, validation loss: 0.3514
2024-06-03 00:40:45 [INFO]: Epoch 034 - training loss: 0.4640, validation loss: 0.3474
2024-06-03 00:40:51 [INFO]: Epoch 035 - training loss: 0.4633, validation loss: 0.3492
2024-06-03 00:40:56 [INFO]: Epoch 036 - training loss: 0.4545, validation loss: 0.3463
2024-06-03 00:41:01 [INFO]: Epoch 037 - training loss: 0.4588, validation loss: 0.3478
2024-06-03 00:41:06 [INFO]: Epoch 038 - training loss: 0.4490, validation loss: 0.3434
2024-06-03 00:41:11 [INFO]: Epoch 039 - training loss: 0.4440, validation loss: 0.3474
2024-06-03 00:41:17 [INFO]: Epoch 040 - training loss: 0.4455, validation loss: 0.3447
2024-06-03 00:41:22 [INFO]: Epoch 041 - training loss: 0.4447, validation loss: 0.3447
2024-06-03 00:41:27 [INFO]: Epoch 042 - training loss: 0.4351, validation loss: 0.3451
2024-06-03 00:41:32 [INFO]: Epoch 043 - training loss: 0.4342, validation loss: 0.3484
2024-06-03 00:41:38 [INFO]: Epoch 044 - training loss: 0.4308, validation loss: 0.3409
2024-06-03 00:41:43 [INFO]: Epoch 045 - training loss: 0.4281, validation loss: 0.3407
2024-06-03 00:41:48 [INFO]: Epoch 046 - training loss: 0.4278, validation loss: 0.3361
2024-06-03 00:41:53 [INFO]: Epoch 047 - training loss: 0.4280, validation loss: 0.3428
2024-06-03 00:41:58 [INFO]: Epoch 048 - training loss: 0.4228, validation loss: 0.3357
2024-06-03 00:42:04 [INFO]: Epoch 049 - training loss: 0.4198, validation loss: 0.3387
2024-06-03 00:42:09 [INFO]: Epoch 050 - training loss: 0.4233, validation loss: 0.3353
2024-06-03 00:42:14 [INFO]: Epoch 051 - training loss: 0.4173, validation loss: 0.3333
2024-06-03 00:42:19 [INFO]: Epoch 052 - training loss: 0.4150, validation loss: 0.3284
2024-06-03 00:42:25 [INFO]: Epoch 053 - training loss: 0.4147, validation loss: 0.3342
2024-06-03 00:42:30 [INFO]: Epoch 054 - training loss: 0.4113, validation loss: 0.3341
2024-06-03 00:42:35 [INFO]: Epoch 055 - training loss: 0.4118, validation loss: 0.3308
2024-06-03 00:42:40 [INFO]: Epoch 056 - training loss: 0.4068, validation loss: 0.3307
2024-06-03 00:42:45 [INFO]: Epoch 057 - training loss: 0.4101, validation loss: 0.3329
2024-06-03 00:42:51 [INFO]: Epoch 058 - training loss: 0.4081, validation loss: 0.3297
2024-06-03 00:42:56 [INFO]: Epoch 059 - training loss: 0.4085, validation loss: 0.3312
2024-06-03 00:43:01 [INFO]: Epoch 060 - training loss: 0.4058, validation loss: 0.3295
2024-06-03 00:43:06 [INFO]: Epoch 061 - training loss: 0.4037, validation loss: 0.3282
2024-06-03 00:43:11 [INFO]: Epoch 062 - training loss: 0.4019, validation loss: 0.3284
2024-06-03 00:43:16 [INFO]: Epoch 063 - training loss: 0.4002, validation loss: 0.3289
2024-06-03 00:43:22 [INFO]: Epoch 064 - training loss: 0.3975, validation loss: 0.3305
2024-06-03 00:43:27 [INFO]: Epoch 065 - training loss: 0.4042, validation loss: 0.3248
2024-06-03 00:43:32 [INFO]: Epoch 066 - training loss: 0.4007, validation loss: 0.3260
2024-06-03 00:43:38 [INFO]: Epoch 067 - training loss: 0.3952, validation loss: 0.3231
2024-06-03 00:43:43 [INFO]: Epoch 068 - training loss: 0.3961, validation loss: 0.3242
2024-06-03 00:43:48 [INFO]: Epoch 069 - training loss: 0.3936, validation loss: 0.3291
2024-06-03 00:43:54 [INFO]: Epoch 070 - training loss: 0.3965, validation loss: 0.3256
2024-06-03 00:43:59 [INFO]: Epoch 071 - training loss: 0.3971, validation loss: 0.3233
2024-06-03 00:44:04 [INFO]: Epoch 072 - training loss: 0.3938, validation loss: 0.3285
2024-06-03 00:44:09 [INFO]: Epoch 073 - training loss: 0.3939, validation loss: 0.3231
2024-06-03 00:44:14 [INFO]: Epoch 074 - training loss: 0.3943, validation loss: 0.3231
2024-06-03 00:44:20 [INFO]: Epoch 075 - training loss: 0.3895, validation loss: 0.3215
2024-06-03 00:44:25 [INFO]: Epoch 076 - training loss: 0.3912, validation loss: 0.3202
2024-06-03 00:44:29 [INFO]: Epoch 077 - training loss: 0.3877, validation loss: 0.3216
2024-06-03 00:44:35 [INFO]: Epoch 078 - training loss: 0.3881, validation loss: 0.3262
2024-06-03 00:44:40 [INFO]: Epoch 079 - training loss: 0.3879, validation loss: 0.3256
2024-06-03 00:44:45 [INFO]: Epoch 080 - training loss: 0.3882, validation loss: 0.3230
2024-06-03 00:44:50 [INFO]: Epoch 081 - training loss: 0.3912, validation loss: 0.3255
2024-06-03 00:44:55 [INFO]: Epoch 082 - training loss: 0.3886, validation loss: 0.3268
2024-06-03 00:45:00 [INFO]: Epoch 083 - training loss: 0.3860, validation loss: 0.3222
2024-06-03 00:45:05 [INFO]: Epoch 084 - training loss: 0.3876, validation loss: 0.3229
2024-06-03 00:45:10 [INFO]: Epoch 085 - training loss: 0.3833, validation loss: 0.3208
2024-06-03 00:45:15 [INFO]: Epoch 086 - training loss: 0.3879, validation loss: 0.3235
2024-06-03 00:45:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:45:15 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 00:45:15 [INFO]: Saved the model to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_0/20240603_T003747/FreTS.pypots
2024-06-03 00:45:16 [INFO]: Successfully saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_0/imputation.pkl
2024-06-03 00:45:16 [INFO]: Round0 - FreTS on BeijingAir: MAE=0.2599, MSE=0.3591, MRE=0.3501
2024-06-03 00:45:16 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:45:16 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:16 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_1/20240603_T004516
2024-06-03 00:45:16 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_1/20240603_T004516/tensorboard
2024-06-03 00:45:16 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 00:45:21 [INFO]: Epoch 001 - training loss: 1.1876, validation loss: 0.5514
2024-06-03 00:45:26 [INFO]: Epoch 002 - training loss: 0.7697, validation loss: 0.4798
2024-06-03 00:45:32 [INFO]: Epoch 003 - training loss: 0.6740, validation loss: 0.4107
2024-06-03 00:45:37 [INFO]: Epoch 004 - training loss: 0.6142, validation loss: 0.3886
2024-06-03 00:45:42 [INFO]: Epoch 005 - training loss: 0.5881, validation loss: 0.3672
2024-06-03 00:45:48 [INFO]: Epoch 006 - training loss: 0.5688, validation loss: 0.3654
2024-06-03 00:45:53 [INFO]: Epoch 007 - training loss: 0.5565, validation loss: 0.3695
2024-06-03 00:45:58 [INFO]: Epoch 008 - training loss: 0.5455, validation loss: 0.3661
2024-06-03 00:46:03 [INFO]: Epoch 009 - training loss: 0.5395, validation loss: 0.3578
2024-06-03 00:46:08 [INFO]: Epoch 010 - training loss: 0.5362, validation loss: 0.3570
2024-06-03 00:46:14 [INFO]: Epoch 011 - training loss: 0.5334, validation loss: 0.3645
2024-06-03 00:46:19 [INFO]: Epoch 012 - training loss: 0.5265, validation loss: 0.3581
2024-06-03 00:46:25 [INFO]: Epoch 013 - training loss: 0.5225, validation loss: 0.3552
2024-06-03 00:46:30 [INFO]: Epoch 014 - training loss: 0.5211, validation loss: 0.3543
2024-06-03 00:46:35 [INFO]: Epoch 015 - training loss: 0.5175, validation loss: 0.3600
2024-06-03 00:46:40 [INFO]: Epoch 016 - training loss: 0.5176, validation loss: 0.3539
2024-06-03 00:46:46 [INFO]: Epoch 017 - training loss: 0.5155, validation loss: 0.3572
2024-06-03 00:46:50 [INFO]: Epoch 018 - training loss: 0.5142, validation loss: 0.3616
2024-06-03 00:46:55 [INFO]: Epoch 019 - training loss: 0.5084, validation loss: 0.3599
2024-06-03 00:47:00 [INFO]: Epoch 020 - training loss: 0.5014, validation loss: 0.3554
2024-06-03 00:47:04 [INFO]: Epoch 021 - training loss: 0.5012, validation loss: 0.3553
2024-06-03 00:47:09 [INFO]: Epoch 022 - training loss: 0.5028, validation loss: 0.3557
2024-06-03 00:47:14 [INFO]: Epoch 023 - training loss: 0.5005, validation loss: 0.3569
2024-06-03 00:47:19 [INFO]: Epoch 024 - training loss: 0.4987, validation loss: 0.3571
2024-06-03 00:47:23 [INFO]: Epoch 025 - training loss: 0.4948, validation loss: 0.3555
2024-06-03 00:47:28 [INFO]: Epoch 026 - training loss: 0.5004, validation loss: 0.3576
2024-06-03 00:47:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:47:28 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 00:47:28 [INFO]: Saved the model to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_1/20240603_T004516/FreTS.pypots
2024-06-03 00:47:29 [INFO]: Successfully saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_1/imputation.pkl
2024-06-03 00:47:29 [INFO]: Round1 - FreTS on BeijingAir: MAE=0.3034, MSE=0.3874, MRE=0.4086
2024-06-03 00:47:29 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:47:29 [INFO]: Using the given device: cuda:0
2024-06-03 00:47:29 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_2/20240603_T004729
2024-06-03 00:47:29 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_2/20240603_T004729/tensorboard
2024-06-03 00:47:29 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 00:47:34 [INFO]: Epoch 001 - training loss: 1.1647, validation loss: 0.5716
2024-06-03 00:47:39 [INFO]: Epoch 002 - training loss: 0.7702, validation loss: 0.4999
2024-06-03 00:47:43 [INFO]: Epoch 003 - training loss: 0.6747, validation loss: 0.4279
2024-06-03 00:47:48 [INFO]: Epoch 004 - training loss: 0.6212, validation loss: 0.4051
2024-06-03 00:47:53 [INFO]: Epoch 005 - training loss: 0.5855, validation loss: 0.3731
2024-06-03 00:47:58 [INFO]: Epoch 006 - training loss: 0.5728, validation loss: 0.3697
2024-06-03 00:48:03 [INFO]: Epoch 007 - training loss: 0.5568, validation loss: 0.3705
2024-06-03 00:48:08 [INFO]: Epoch 008 - training loss: 0.5491, validation loss: 0.3616
2024-06-03 00:48:12 [INFO]: Epoch 009 - training loss: 0.5429, validation loss: 0.3655
2024-06-03 00:48:17 [INFO]: Epoch 010 - training loss: 0.5347, validation loss: 0.3623
2024-06-03 00:48:22 [INFO]: Epoch 011 - training loss: 0.5345, validation loss: 0.3571
2024-06-03 00:48:27 [INFO]: Epoch 012 - training loss: 0.5309, validation loss: 0.3573
2024-06-03 00:48:31 [INFO]: Epoch 013 - training loss: 0.5239, validation loss: 0.3622
2024-06-03 00:48:36 [INFO]: Epoch 014 - training loss: 0.5238, validation loss: 0.3560
2024-06-03 00:48:41 [INFO]: Epoch 015 - training loss: 0.5210, validation loss: 0.3592
2024-06-03 00:48:46 [INFO]: Epoch 016 - training loss: 0.5129, validation loss: 0.3610
2024-06-03 00:48:51 [INFO]: Epoch 017 - training loss: 0.5099, validation loss: 0.3564
2024-06-03 00:48:56 [INFO]: Epoch 018 - training loss: 0.5088, validation loss: 0.3529
2024-06-03 00:49:01 [INFO]: Epoch 019 - training loss: 0.5091, validation loss: 0.3621
2024-06-03 00:49:05 [INFO]: Epoch 020 - training loss: 0.5130, validation loss: 0.3587
2024-06-03 00:49:10 [INFO]: Epoch 021 - training loss: 0.5078, validation loss: 0.3535
2024-06-03 00:49:15 [INFO]: Epoch 022 - training loss: 0.5019, validation loss: 0.3594
2024-06-03 00:49:20 [INFO]: Epoch 023 - training loss: 0.5039, validation loss: 0.3571
2024-06-03 00:49:24 [INFO]: Epoch 024 - training loss: 0.5029, validation loss: 0.3567
2024-06-03 00:49:29 [INFO]: Epoch 025 - training loss: 0.5018, validation loss: 0.3580
2024-06-03 00:49:34 [INFO]: Epoch 026 - training loss: 0.4968, validation loss: 0.3579
2024-06-03 00:49:39 [INFO]: Epoch 027 - training loss: 0.4932, validation loss: 0.3568
2024-06-03 00:49:44 [INFO]: Epoch 028 - training loss: 0.4923, validation loss: 0.3604
2024-06-03 00:49:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:49:44 [INFO]: Finished training. The best model is from epoch#18.
2024-06-03 00:49:44 [INFO]: Saved the model to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_2/20240603_T004729/FreTS.pypots
2024-06-03 00:49:44 [INFO]: Successfully saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_2/imputation.pkl
2024-06-03 00:49:45 [INFO]: Round2 - FreTS on BeijingAir: MAE=0.3015, MSE=0.3864, MRE=0.4061
2024-06-03 00:49:45 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:49:45 [INFO]: Using the given device: cuda:0
2024-06-03 00:49:45 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_3/20240603_T004945
2024-06-03 00:49:45 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_3/20240603_T004945/tensorboard
2024-06-03 00:49:45 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 00:49:49 [INFO]: Epoch 001 - training loss: 1.3128, validation loss: 0.6217
2024-06-03 00:49:54 [INFO]: Epoch 002 - training loss: 0.8055, validation loss: 0.4836
2024-06-03 00:49:59 [INFO]: Epoch 003 - training loss: 0.6895, validation loss: 0.4230
2024-06-03 00:50:04 [INFO]: Epoch 004 - training loss: 0.6234, validation loss: 0.3866
2024-06-03 00:50:08 [INFO]: Epoch 005 - training loss: 0.5875, validation loss: 0.3766
2024-06-03 00:50:13 [INFO]: Epoch 006 - training loss: 0.5738, validation loss: 0.3788
2024-06-03 00:50:18 [INFO]: Epoch 007 - training loss: 0.5587, validation loss: 0.3731
2024-06-03 00:50:22 [INFO]: Epoch 008 - training loss: 0.5517, validation loss: 0.3690
2024-06-03 00:50:27 [INFO]: Epoch 009 - training loss: 0.5413, validation loss: 0.3570
2024-06-03 00:50:32 [INFO]: Epoch 010 - training loss: 0.5338, validation loss: 0.3605
2024-06-03 00:50:36 [INFO]: Epoch 011 - training loss: 0.5301, validation loss: 0.3647
2024-06-03 00:50:40 [INFO]: Epoch 012 - training loss: 0.5298, validation loss: 0.3608
2024-06-03 00:50:45 [INFO]: Epoch 013 - training loss: 0.5221, validation loss: 0.3572
2024-06-03 00:50:49 [INFO]: Epoch 014 - training loss: 0.5180, validation loss: 0.3557
2024-06-03 00:50:53 [INFO]: Epoch 015 - training loss: 0.5225, validation loss: 0.3566
2024-06-03 00:50:58 [INFO]: Epoch 016 - training loss: 0.5177, validation loss: 0.3594
2024-06-03 00:51:01 [INFO]: Epoch 017 - training loss: 0.5103, validation loss: 0.3567
2024-06-03 00:51:05 [INFO]: Epoch 018 - training loss: 0.5081, validation loss: 0.3614
2024-06-03 00:51:09 [INFO]: Epoch 019 - training loss: 0.5102, validation loss: 0.3569
2024-06-03 00:51:13 [INFO]: Epoch 020 - training loss: 0.5086, validation loss: 0.3550
2024-06-03 00:51:18 [INFO]: Epoch 021 - training loss: 0.5066, validation loss: 0.3624
2024-06-03 00:51:22 [INFO]: Epoch 022 - training loss: 0.5050, validation loss: 0.3602
2024-06-03 00:51:26 [INFO]: Epoch 023 - training loss: 0.5003, validation loss: 0.3586
2024-06-03 00:51:31 [INFO]: Epoch 024 - training loss: 0.4965, validation loss: 0.3551
2024-06-03 00:51:35 [INFO]: Epoch 025 - training loss: 0.4908, validation loss: 0.3533
2024-06-03 00:51:39 [INFO]: Epoch 026 - training loss: 0.4940, validation loss: 0.3555
2024-06-03 00:51:43 [INFO]: Epoch 027 - training loss: 0.4950, validation loss: 0.3582
2024-06-03 00:51:48 [INFO]: Epoch 028 - training loss: 0.4884, validation loss: 0.3522
2024-06-03 00:51:52 [INFO]: Epoch 029 - training loss: 0.4888, validation loss: 0.3545
2024-06-03 00:51:56 [INFO]: Epoch 030 - training loss: 0.4862, validation loss: 0.3550
2024-06-03 00:52:00 [INFO]: Epoch 031 - training loss: 0.4794, validation loss: 0.3517
2024-06-03 00:52:05 [INFO]: Epoch 032 - training loss: 0.4764, validation loss: 0.3538
2024-06-03 00:52:09 [INFO]: Epoch 033 - training loss: 0.4755, validation loss: 0.3536
2024-06-03 00:52:13 [INFO]: Epoch 034 - training loss: 0.4715, validation loss: 0.3514
2024-06-03 00:52:17 [INFO]: Epoch 035 - training loss: 0.4688, validation loss: 0.3496
2024-06-03 00:52:21 [INFO]: Epoch 036 - training loss: 0.4651, validation loss: 0.3484
2024-06-03 00:52:25 [INFO]: Epoch 037 - training loss: 0.4615, validation loss: 0.3475
2024-06-03 00:52:29 [INFO]: Epoch 038 - training loss: 0.4545, validation loss: 0.3498
2024-06-03 00:52:34 [INFO]: Epoch 039 - training loss: 0.4606, validation loss: 0.3493
2024-06-03 00:52:38 [INFO]: Epoch 040 - training loss: 0.4512, validation loss: 0.3393
2024-06-03 00:52:43 [INFO]: Epoch 041 - training loss: 0.4535, validation loss: 0.3412
2024-06-03 00:52:47 [INFO]: Epoch 042 - training loss: 0.4486, validation loss: 0.3418
2024-06-03 00:52:51 [INFO]: Epoch 043 - training loss: 0.4459, validation loss: 0.3410
2024-06-03 00:52:56 [INFO]: Epoch 044 - training loss: 0.4424, validation loss: 0.3405
2024-06-03 00:53:00 [INFO]: Epoch 045 - training loss: 0.4401, validation loss: 0.3352
2024-06-03 00:53:04 [INFO]: Epoch 046 - training loss: 0.4395, validation loss: 0.3411
2024-06-03 00:53:09 [INFO]: Epoch 047 - training loss: 0.4336, validation loss: 0.3365
2024-06-03 00:53:13 [INFO]: Epoch 048 - training loss: 0.4313, validation loss: 0.3375
2024-06-03 00:53:17 [INFO]: Epoch 049 - training loss: 0.4309, validation loss: 0.3381
2024-06-03 00:53:21 [INFO]: Epoch 050 - training loss: 0.4318, validation loss: 0.3348
2024-06-03 00:53:25 [INFO]: Epoch 051 - training loss: 0.4265, validation loss: 0.3372
2024-06-03 00:53:30 [INFO]: Epoch 052 - training loss: 0.4265, validation loss: 0.3417
2024-06-03 00:53:34 [INFO]: Epoch 053 - training loss: 0.4276, validation loss: 0.3325
2024-06-03 00:53:38 [INFO]: Epoch 054 - training loss: 0.4240, validation loss: 0.3322
2024-06-03 00:53:42 [INFO]: Epoch 055 - training loss: 0.4215, validation loss: 0.3276
2024-06-03 00:53:46 [INFO]: Epoch 056 - training loss: 0.4199, validation loss: 0.3334
2024-06-03 00:53:50 [INFO]: Epoch 057 - training loss: 0.4180, validation loss: 0.3293
2024-06-03 00:53:54 [INFO]: Epoch 058 - training loss: 0.4141, validation loss: 0.3305
2024-06-03 00:53:59 [INFO]: Epoch 059 - training loss: 0.4148, validation loss: 0.3318
2024-06-03 00:54:03 [INFO]: Epoch 060 - training loss: 0.4142, validation loss: 0.3287
2024-06-03 00:54:07 [INFO]: Epoch 061 - training loss: 0.4126, validation loss: 0.3279
2024-06-03 00:54:11 [INFO]: Epoch 062 - training loss: 0.4093, validation loss: 0.3259
2024-06-03 00:54:16 [INFO]: Epoch 063 - training loss: 0.4101, validation loss: 0.3265
2024-06-03 00:54:20 [INFO]: Epoch 064 - training loss: 0.4060, validation loss: 0.3274
2024-06-03 00:54:25 [INFO]: Epoch 065 - training loss: 0.4063, validation loss: 0.3269
2024-06-03 00:54:29 [INFO]: Epoch 066 - training loss: 0.4068, validation loss: 0.3238
2024-06-03 00:54:33 [INFO]: Epoch 067 - training loss: 0.4036, validation loss: 0.3255
2024-06-03 00:54:38 [INFO]: Epoch 068 - training loss: 0.3990, validation loss: 0.3283
2024-06-03 00:54:42 [INFO]: Epoch 069 - training loss: 0.3996, validation loss: 0.3253
2024-06-03 00:54:46 [INFO]: Epoch 070 - training loss: 0.3960, validation loss: 0.3203
2024-06-03 00:54:51 [INFO]: Epoch 071 - training loss: 0.4016, validation loss: 0.3255
2024-06-03 00:54:55 [INFO]: Epoch 072 - training loss: 0.3971, validation loss: 0.3249
2024-06-03 00:54:59 [INFO]: Epoch 073 - training loss: 0.3980, validation loss: 0.3249
2024-06-03 00:55:03 [INFO]: Epoch 074 - training loss: 0.3961, validation loss: 0.3252
2024-06-03 00:55:07 [INFO]: Epoch 075 - training loss: 0.3928, validation loss: 0.3233
2024-06-03 00:55:12 [INFO]: Epoch 076 - training loss: 0.3911, validation loss: 0.3197
2024-06-03 00:55:16 [INFO]: Epoch 077 - training loss: 0.3893, validation loss: 0.3204
2024-06-03 00:55:21 [INFO]: Epoch 078 - training loss: 0.3920, validation loss: 0.3173
2024-06-03 00:55:25 [INFO]: Epoch 079 - training loss: 0.3862, validation loss: 0.3227
2024-06-03 00:55:29 [INFO]: Epoch 080 - training loss: 0.3896, validation loss: 0.3202
2024-06-03 00:55:33 [INFO]: Epoch 081 - training loss: 0.3859, validation loss: 0.3207
2024-06-03 00:55:38 [INFO]: Epoch 082 - training loss: 0.3870, validation loss: 0.3168
2024-06-03 00:55:42 [INFO]: Epoch 083 - training loss: 0.3866, validation loss: 0.3222
2024-06-03 00:55:46 [INFO]: Epoch 084 - training loss: 0.3852, validation loss: 0.3187
2024-06-03 00:55:50 [INFO]: Epoch 085 - training loss: 0.3897, validation loss: 0.3240
2024-06-03 00:55:54 [INFO]: Epoch 086 - training loss: 0.3861, validation loss: 0.3207
2024-06-03 00:55:59 [INFO]: Epoch 087 - training loss: 0.3866, validation loss: 0.3184
2024-06-03 00:56:03 [INFO]: Epoch 088 - training loss: 0.3819, validation loss: 0.3238
2024-06-03 00:56:07 [INFO]: Epoch 089 - training loss: 0.3835, validation loss: 0.3227
2024-06-03 00:56:11 [INFO]: Epoch 090 - training loss: 0.3824, validation loss: 0.3172
2024-06-03 00:56:15 [INFO]: Epoch 091 - training loss: 0.3860, validation loss: 0.3207
2024-06-03 00:56:19 [INFO]: Epoch 092 - training loss: 0.3815, validation loss: 0.3168
2024-06-03 00:56:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:56:19 [INFO]: Finished training. The best model is from epoch#82.
2024-06-03 00:56:20 [INFO]: Saved the model to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_3/20240603_T004945/FreTS.pypots
2024-06-03 00:56:20 [INFO]: Successfully saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_3/imputation.pkl
2024-06-03 00:56:20 [INFO]: Round3 - FreTS on BeijingAir: MAE=0.2551, MSE=0.3547, MRE=0.3436
2024-06-03 00:56:20 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:56:20 [INFO]: Using the given device: cuda:0
2024-06-03 00:56:20 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_4/20240603_T005620
2024-06-03 00:56:20 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_4/20240603_T005620/tensorboard
2024-06-03 00:56:20 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 00:56:25 [INFO]: Epoch 001 - training loss: 1.2114, validation loss: 0.5718
2024-06-03 00:56:29 [INFO]: Epoch 002 - training loss: 0.7796, validation loss: 0.5149
2024-06-03 00:56:33 [INFO]: Epoch 003 - training loss: 0.6834, validation loss: 0.4171
2024-06-03 00:56:37 [INFO]: Epoch 004 - training loss: 0.6281, validation loss: 0.3869
2024-06-03 00:56:42 [INFO]: Epoch 005 - training loss: 0.5904, validation loss: 0.3851
2024-06-03 00:56:46 [INFO]: Epoch 006 - training loss: 0.5721, validation loss: 0.3744
2024-06-03 00:56:50 [INFO]: Epoch 007 - training loss: 0.5587, validation loss: 0.3683
2024-06-03 00:56:55 [INFO]: Epoch 008 - training loss: 0.5497, validation loss: 0.3638
2024-06-03 00:56:59 [INFO]: Epoch 009 - training loss: 0.5392, validation loss: 0.3574
2024-06-03 00:57:03 [INFO]: Epoch 010 - training loss: 0.5317, validation loss: 0.3554
2024-06-03 00:57:07 [INFO]: Epoch 011 - training loss: 0.5317, validation loss: 0.3606
2024-06-03 00:57:11 [INFO]: Epoch 012 - training loss: 0.5255, validation loss: 0.3591
2024-06-03 00:57:16 [INFO]: Epoch 013 - training loss: 0.5243, validation loss: 0.3707
2024-06-03 00:57:20 [INFO]: Epoch 014 - training loss: 0.5239, validation loss: 0.3583
2024-06-03 00:57:24 [INFO]: Epoch 015 - training loss: 0.5177, validation loss: 0.3602
2024-06-03 00:57:28 [INFO]: Epoch 016 - training loss: 0.5161, validation loss: 0.3554
2024-06-03 00:57:32 [INFO]: Epoch 017 - training loss: 0.5153, validation loss: 0.3577
2024-06-03 00:57:37 [INFO]: Epoch 018 - training loss: 0.5097, validation loss: 0.3545
2024-06-03 00:57:41 [INFO]: Epoch 019 - training loss: 0.5072, validation loss: 0.3592
2024-06-03 00:57:45 [INFO]: Epoch 020 - training loss: 0.5037, validation loss: 0.3544
2024-06-03 00:57:50 [INFO]: Epoch 021 - training loss: 0.5022, validation loss: 0.3556
2024-06-03 00:57:54 [INFO]: Epoch 022 - training loss: 0.5051, validation loss: 0.3597
2024-06-03 00:57:58 [INFO]: Epoch 023 - training loss: 0.4997, validation loss: 0.3538
2024-06-03 00:58:03 [INFO]: Epoch 024 - training loss: 0.4976, validation loss: 0.3554
2024-06-03 00:58:07 [INFO]: Epoch 025 - training loss: 0.4941, validation loss: 0.3582
2024-06-03 00:58:11 [INFO]: Epoch 026 - training loss: 0.4915, validation loss: 0.3518
2024-06-03 00:58:15 [INFO]: Epoch 027 - training loss: 0.4885, validation loss: 0.3546
2024-06-03 00:58:20 [INFO]: Epoch 028 - training loss: 0.4894, validation loss: 0.3543
2024-06-03 00:58:24 [INFO]: Epoch 029 - training loss: 0.4893, validation loss: 0.3630
2024-06-03 00:58:28 [INFO]: Epoch 030 - training loss: 0.4848, validation loss: 0.3517
2024-06-03 00:58:32 [INFO]: Epoch 031 - training loss: 0.4796, validation loss: 0.3532
2024-06-03 00:58:36 [INFO]: Epoch 032 - training loss: 0.4773, validation loss: 0.3526
2024-06-03 00:58:40 [INFO]: Epoch 033 - training loss: 0.4755, validation loss: 0.3554
2024-06-03 00:58:45 [INFO]: Epoch 034 - training loss: 0.4747, validation loss: 0.3556
2024-06-03 00:58:49 [INFO]: Epoch 035 - training loss: 0.4757, validation loss: 0.3532
2024-06-03 00:58:53 [INFO]: Epoch 036 - training loss: 0.4676, validation loss: 0.3489
2024-06-03 00:58:57 [INFO]: Epoch 037 - training loss: 0.4633, validation loss: 0.3495
2024-06-03 00:59:01 [INFO]: Epoch 038 - training loss: 0.4672, validation loss: 0.3512
2024-06-03 00:59:06 [INFO]: Epoch 039 - training loss: 0.4548, validation loss: 0.3494
2024-06-03 00:59:10 [INFO]: Epoch 040 - training loss: 0.4546, validation loss: 0.3444
2024-06-03 00:59:15 [INFO]: Epoch 041 - training loss: 0.4539, validation loss: 0.3466
2024-06-03 00:59:19 [INFO]: Epoch 042 - training loss: 0.4489, validation loss: 0.3426
2024-06-03 00:59:23 [INFO]: Epoch 043 - training loss: 0.4441, validation loss: 0.3440
2024-06-03 00:59:27 [INFO]: Epoch 044 - training loss: 0.4413, validation loss: 0.3475
2024-06-03 00:59:31 [INFO]: Epoch 045 - training loss: 0.4401, validation loss: 0.3426
2024-06-03 00:59:36 [INFO]: Epoch 046 - training loss: 0.4395, validation loss: 0.3469
2024-06-03 00:59:40 [INFO]: Epoch 047 - training loss: 0.4346, validation loss: 0.3476
2024-06-03 00:59:44 [INFO]: Epoch 048 - training loss: 0.4327, validation loss: 0.3448
2024-06-03 00:59:48 [INFO]: Epoch 049 - training loss: 0.4322, validation loss: 0.3460
2024-06-03 00:59:52 [INFO]: Epoch 050 - training loss: 0.4309, validation loss: 0.3441
2024-06-03 00:59:57 [INFO]: Epoch 051 - training loss: 0.4231, validation loss: 0.3361
2024-06-03 01:00:01 [INFO]: Epoch 052 - training loss: 0.4243, validation loss: 0.3393
2024-06-03 01:00:05 [INFO]: Epoch 053 - training loss: 0.4244, validation loss: 0.3376
2024-06-03 01:00:09 [INFO]: Epoch 054 - training loss: 0.4217, validation loss: 0.3369
2024-06-03 01:00:14 [INFO]: Epoch 055 - training loss: 0.4195, validation loss: 0.3347
2024-06-03 01:00:18 [INFO]: Epoch 056 - training loss: 0.4168, validation loss: 0.3366
2024-06-03 01:00:22 [INFO]: Epoch 057 - training loss: 0.4163, validation loss: 0.3380
2024-06-03 01:00:26 [INFO]: Epoch 058 - training loss: 0.4138, validation loss: 0.3373
2024-06-03 01:00:30 [INFO]: Epoch 059 - training loss: 0.4159, validation loss: 0.3321
2024-06-03 01:00:34 [INFO]: Epoch 060 - training loss: 0.4142, validation loss: 0.3321
2024-06-03 01:00:39 [INFO]: Epoch 061 - training loss: 0.4077, validation loss: 0.3360
2024-06-03 01:00:43 [INFO]: Epoch 062 - training loss: 0.4058, validation loss: 0.3316
2024-06-03 01:00:47 [INFO]: Epoch 063 - training loss: 0.4065, validation loss: 0.3329
2024-06-03 01:00:52 [INFO]: Epoch 064 - training loss: 0.4060, validation loss: 0.3326
2024-06-03 01:00:56 [INFO]: Epoch 065 - training loss: 0.4071, validation loss: 0.3274
2024-06-03 01:01:01 [INFO]: Epoch 066 - training loss: 0.4017, validation loss: 0.3290
2024-06-03 01:01:05 [INFO]: Epoch 067 - training loss: 0.4010, validation loss: 0.3289
2024-06-03 01:01:09 [INFO]: Epoch 068 - training loss: 0.4043, validation loss: 0.3260
2024-06-03 01:01:13 [INFO]: Epoch 069 - training loss: 0.4008, validation loss: 0.3276
2024-06-03 01:01:17 [INFO]: Epoch 070 - training loss: 0.4020, validation loss: 0.3278
2024-06-03 01:01:22 [INFO]: Epoch 071 - training loss: 0.3941, validation loss: 0.3268
2024-06-03 01:01:26 [INFO]: Epoch 072 - training loss: 0.3989, validation loss: 0.3261
2024-06-03 01:01:30 [INFO]: Epoch 073 - training loss: 0.3963, validation loss: 0.3286
2024-06-03 01:01:34 [INFO]: Epoch 074 - training loss: 0.3933, validation loss: 0.3302
2024-06-03 01:01:38 [INFO]: Epoch 075 - training loss: 0.3934, validation loss: 0.3240
2024-06-03 01:01:42 [INFO]: Epoch 076 - training loss: 0.3947, validation loss: 0.3271
2024-06-03 01:01:47 [INFO]: Epoch 077 - training loss: 0.3921, validation loss: 0.3250
2024-06-03 01:01:51 [INFO]: Epoch 078 - training loss: 0.3901, validation loss: 0.3243
2024-06-03 01:01:55 [INFO]: Epoch 079 - training loss: 0.3880, validation loss: 0.3261
2024-06-03 01:01:59 [INFO]: Epoch 080 - training loss: 0.3920, validation loss: 0.3239
2024-06-03 01:02:03 [INFO]: Epoch 081 - training loss: 0.3906, validation loss: 0.3282
2024-06-03 01:02:07 [INFO]: Epoch 082 - training loss: 0.3905, validation loss: 0.3296
2024-06-03 01:02:12 [INFO]: Epoch 083 - training loss: 0.3891, validation loss: 0.3255
2024-06-03 01:02:16 [INFO]: Epoch 084 - training loss: 0.3893, validation loss: 0.3306
2024-06-03 01:02:20 [INFO]: Epoch 085 - training loss: 0.3881, validation loss: 0.3225
2024-06-03 01:02:24 [INFO]: Epoch 086 - training loss: 0.3848, validation loss: 0.3256
2024-06-03 01:02:28 [INFO]: Epoch 087 - training loss: 0.3872, validation loss: 0.3217
2024-06-03 01:02:32 [INFO]: Epoch 088 - training loss: 0.3862, validation loss: 0.3252
2024-06-03 01:02:37 [INFO]: Epoch 089 - training loss: 0.3854, validation loss: 0.3245
2024-06-03 01:02:41 [INFO]: Epoch 090 - training loss: 0.3885, validation loss: 0.3235
2024-06-03 01:02:45 [INFO]: Epoch 091 - training loss: 0.3837, validation loss: 0.3215
2024-06-03 01:02:50 [INFO]: Epoch 092 - training loss: 0.3808, validation loss: 0.3276
2024-06-03 01:02:54 [INFO]: Epoch 093 - training loss: 0.3817, validation loss: 0.3244
2024-06-03 01:02:58 [INFO]: Epoch 094 - training loss: 0.3850, validation loss: 0.3265
2024-06-03 01:03:02 [INFO]: Epoch 095 - training loss: 0.3803, validation loss: 0.3208
2024-06-03 01:03:06 [INFO]: Epoch 096 - training loss: 0.3805, validation loss: 0.3281
2024-06-03 01:03:11 [INFO]: Epoch 097 - training loss: 0.3801, validation loss: 0.3238
2024-06-03 01:03:15 [INFO]: Epoch 098 - training loss: 0.3823, validation loss: 0.3253
2024-06-03 01:03:19 [INFO]: Epoch 099 - training loss: 0.3789, validation loss: 0.3194
2024-06-03 01:03:23 [INFO]: Epoch 100 - training loss: 0.3800, validation loss: 0.3204
2024-06-03 01:03:23 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 01:03:23 [INFO]: Saved the model to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_4/20240603_T005620/FreTS.pypots
2024-06-03 01:03:24 [INFO]: Successfully saved to results_point_rate09/BeijingAir/FreTS_BeijingAir/round_4/imputation.pkl
2024-06-03 01:03:24 [INFO]: Round4 - FreTS on BeijingAir: MAE=0.2567, MSE=0.3654, MRE=0.3457
2024-06-03 01:03:24 [INFO]: Done! Final results:
Averaged FreTS (909,852 params) on BeijingAir: MAE=0.2708 ± 0.022604838981853784, MSE=0.3668 ± 0.014498056401470536, MRE=0.3593 ± 0.02998829041331679, average inference time=0.17