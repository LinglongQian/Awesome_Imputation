2024-06-03 08:00:49 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 08:00:49 [INFO]: Using the given device: cuda:0
2024-06-03 08:00:49 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T080049
2024-06-03 08:00:49 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T080049/tensorboard
2024-06-03 08:00:50 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 08:01:09 [INFO]: Epoch 001 - training loss: 0.7050, validation loss: 0.6227
2024-06-03 08:01:14 [INFO]: Epoch 002 - training loss: 0.6618, validation loss: 0.6025
2024-06-03 08:01:20 [INFO]: Epoch 003 - training loss: 0.6499, validation loss: 0.5806
2024-06-03 08:01:26 [INFO]: Epoch 004 - training loss: 0.6431, validation loss: 0.6051
2024-06-03 08:01:31 [INFO]: Epoch 005 - training loss: 0.6345, validation loss: 0.5903
2024-06-03 08:01:37 [INFO]: Epoch 006 - training loss: 0.6291, validation loss: 0.5846
2024-06-03 08:01:43 [INFO]: Epoch 007 - training loss: 0.6239, validation loss: 0.5891
2024-06-03 08:01:49 [INFO]: Epoch 008 - training loss: 0.6197, validation loss: 0.5633
2024-06-03 08:01:54 [INFO]: Epoch 009 - training loss: 0.6112, validation loss: 0.5612
2024-06-03 08:02:00 [INFO]: Epoch 010 - training loss: 0.6148, validation loss: 0.5917
2024-06-03 08:02:06 [INFO]: Epoch 011 - training loss: 0.6085, validation loss: 0.5603
2024-06-03 08:02:12 [INFO]: Epoch 012 - training loss: 0.6034, validation loss: 0.5594
2024-06-03 08:02:18 [INFO]: Epoch 013 - training loss: 0.6017, validation loss: 0.5561
2024-06-03 08:02:24 [INFO]: Epoch 014 - training loss: 0.6027, validation loss: 0.5531
2024-06-03 08:02:29 [INFO]: Epoch 015 - training loss: 0.6052, validation loss: 0.5489
2024-06-03 08:02:35 [INFO]: Epoch 016 - training loss: 0.5999, validation loss: 0.5581
2024-06-03 08:02:41 [INFO]: Epoch 017 - training loss: 0.5989, validation loss: 0.5662
2024-06-03 08:02:47 [INFO]: Epoch 018 - training loss: 0.6001, validation loss: 0.5406
2024-06-03 08:02:52 [INFO]: Epoch 019 - training loss: 0.5997, validation loss: 0.5543
2024-06-03 08:02:58 [INFO]: Epoch 020 - training loss: 0.5925, validation loss: 0.5546
2024-06-03 08:03:03 [INFO]: Epoch 021 - training loss: 0.5895, validation loss: 0.5335
2024-06-03 08:03:09 [INFO]: Epoch 022 - training loss: 0.5899, validation loss: 0.5383
2024-06-03 08:03:15 [INFO]: Epoch 023 - training loss: 0.5945, validation loss: 0.5502
2024-06-03 08:03:20 [INFO]: Epoch 024 - training loss: 0.5927, validation loss: 0.5498
2024-06-03 08:03:26 [INFO]: Epoch 025 - training loss: 0.5874, validation loss: 0.5480
2024-06-03 08:03:32 [INFO]: Epoch 026 - training loss: 0.5872, validation loss: 0.5364
2024-06-03 08:03:37 [INFO]: Epoch 027 - training loss: 0.5894, validation loss: 0.5642
2024-06-03 08:03:43 [INFO]: Epoch 028 - training loss: 0.5844, validation loss: 0.5486
2024-06-03 08:03:49 [INFO]: Epoch 029 - training loss: 0.5839, validation loss: 0.5412
2024-06-03 08:03:55 [INFO]: Epoch 030 - training loss: 0.5889, validation loss: 0.5391
2024-06-03 08:04:00 [INFO]: Epoch 031 - training loss: 0.5837, validation loss: 0.5565
2024-06-03 08:04:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:04:00 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 08:04:01 [INFO]: Saved the model to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T080049/NonstationaryTransformer.pypots
2024-06-03 08:04:03 [INFO]: Successfully saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/imputation.pkl
2024-06-03 08:04:03 [INFO]: Round0 - NonstationaryTransformer on BeijingAir: MAE=0.3633, MSE=0.5356, MRE=0.4892
2024-06-03 08:04:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 08:04:03 [INFO]: Using the given device: cuda:0
2024-06-03 08:04:03 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T080403
2024-06-03 08:04:03 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T080403/tensorboard
2024-06-03 08:04:03 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 08:04:09 [INFO]: Epoch 001 - training loss: 0.6986, validation loss: 0.6086
2024-06-03 08:04:15 [INFO]: Epoch 002 - training loss: 0.6627, validation loss: 0.5972
2024-06-03 08:04:21 [INFO]: Epoch 003 - training loss: 0.6515, validation loss: 0.6211
2024-06-03 08:04:26 [INFO]: Epoch 004 - training loss: 0.6364, validation loss: 0.5834
2024-06-03 08:04:32 [INFO]: Epoch 005 - training loss: 0.6311, validation loss: 0.5872
2024-06-03 08:04:38 [INFO]: Epoch 006 - training loss: 0.6286, validation loss: 0.5815
2024-06-03 08:04:44 [INFO]: Epoch 007 - training loss: 0.6184, validation loss: 0.5810
2024-06-03 08:04:50 [INFO]: Epoch 008 - training loss: 0.6176, validation loss: 0.5628
2024-06-03 08:04:56 [INFO]: Epoch 009 - training loss: 0.6159, validation loss: 0.5667
2024-06-03 08:05:01 [INFO]: Epoch 010 - training loss: 0.6113, validation loss: 0.5614
2024-06-03 08:05:07 [INFO]: Epoch 011 - training loss: 0.6087, validation loss: 0.5624
2024-06-03 08:05:12 [INFO]: Epoch 012 - training loss: 0.6053, validation loss: 0.5646
2024-06-03 08:05:18 [INFO]: Epoch 013 - training loss: 0.6045, validation loss: 0.5643
2024-06-03 08:05:24 [INFO]: Epoch 014 - training loss: 0.5980, validation loss: 0.5533
2024-06-03 08:05:30 [INFO]: Epoch 015 - training loss: 0.5983, validation loss: 0.5542
2024-06-03 08:05:36 [INFO]: Epoch 016 - training loss: 0.6041, validation loss: 0.5423
2024-06-03 08:05:41 [INFO]: Epoch 017 - training loss: 0.5989, validation loss: 0.5583
2024-06-03 08:05:47 [INFO]: Epoch 018 - training loss: 0.5968, validation loss: 0.5381
2024-06-03 08:05:52 [INFO]: Epoch 019 - training loss: 0.5984, validation loss: 0.5510
2024-06-03 08:05:58 [INFO]: Epoch 020 - training loss: 0.5982, validation loss: 0.5537
2024-06-03 08:06:03 [INFO]: Epoch 021 - training loss: 0.5961, validation loss: 0.5353
2024-06-03 08:06:09 [INFO]: Epoch 022 - training loss: 0.5926, validation loss: 0.5438
2024-06-03 08:06:15 [INFO]: Epoch 023 - training loss: 0.5955, validation loss: 0.5488
2024-06-03 08:06:20 [INFO]: Epoch 024 - training loss: 0.5891, validation loss: 0.5396
2024-06-03 08:06:26 [INFO]: Epoch 025 - training loss: 0.5879, validation loss: 0.5436
2024-06-03 08:06:32 [INFO]: Epoch 026 - training loss: 0.5849, validation loss: 0.5500
2024-06-03 08:06:38 [INFO]: Epoch 027 - training loss: 0.5861, validation loss: 0.5561
2024-06-03 08:06:43 [INFO]: Epoch 028 - training loss: 0.5847, validation loss: 0.5408
2024-06-03 08:06:49 [INFO]: Epoch 029 - training loss: 0.5856, validation loss: 0.5490
2024-06-03 08:06:55 [INFO]: Epoch 030 - training loss: 0.5851, validation loss: 0.5328
2024-06-03 08:07:00 [INFO]: Epoch 031 - training loss: 0.5846, validation loss: 0.5316
2024-06-03 08:07:06 [INFO]: Epoch 032 - training loss: 0.5829, validation loss: 0.5397
2024-06-03 08:07:12 [INFO]: Epoch 033 - training loss: 0.5827, validation loss: 0.5375
2024-06-03 08:07:18 [INFO]: Epoch 034 - training loss: 0.5866, validation loss: 0.5411
2024-06-03 08:07:23 [INFO]: Epoch 035 - training loss: 0.5799, validation loss: 0.5477
2024-06-03 08:07:29 [INFO]: Epoch 036 - training loss: 0.5832, validation loss: 0.5414
2024-06-03 08:07:35 [INFO]: Epoch 037 - training loss: 0.5768, validation loss: 0.5320
2024-06-03 08:07:41 [INFO]: Epoch 038 - training loss: 0.5786, validation loss: 0.5369
2024-06-03 08:07:47 [INFO]: Epoch 039 - training loss: 0.5768, validation loss: 0.5315
2024-06-03 08:07:53 [INFO]: Epoch 040 - training loss: 0.5738, validation loss: 0.5440
2024-06-03 08:07:58 [INFO]: Epoch 041 - training loss: 0.5745, validation loss: 0.5365
2024-06-03 08:08:04 [INFO]: Epoch 042 - training loss: 0.5737, validation loss: 0.5322
2024-06-03 08:08:10 [INFO]: Epoch 043 - training loss: 0.5774, validation loss: 0.5353
2024-06-03 08:08:15 [INFO]: Epoch 044 - training loss: 0.5762, validation loss: 0.5458
2024-06-03 08:08:21 [INFO]: Epoch 045 - training loss: 0.5753, validation loss: 0.5349
2024-06-03 08:08:27 [INFO]: Epoch 046 - training loss: 0.5741, validation loss: 0.5410
2024-06-03 08:08:33 [INFO]: Epoch 047 - training loss: 0.5696, validation loss: 0.5395
2024-06-03 08:08:38 [INFO]: Epoch 048 - training loss: 0.5757, validation loss: 0.5373
2024-06-03 08:08:44 [INFO]: Epoch 049 - training loss: 0.5723, validation loss: 0.5389
2024-06-03 08:08:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:08:44 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 08:08:44 [INFO]: Saved the model to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T080403/NonstationaryTransformer.pypots
2024-06-03 08:08:47 [INFO]: Successfully saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/imputation.pkl
2024-06-03 08:08:47 [INFO]: Round1 - NonstationaryTransformer on BeijingAir: MAE=0.3601, MSE=0.5268, MRE=0.4849
2024-06-03 08:08:47 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:08:47 [INFO]: Using the given device: cuda:0
2024-06-03 08:08:47 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T080847
2024-06-03 08:08:47 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T080847/tensorboard
2024-06-03 08:08:47 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 08:08:53 [INFO]: Epoch 001 - training loss: 0.7066, validation loss: 0.6266
2024-06-03 08:08:58 [INFO]: Epoch 002 - training loss: 0.6559, validation loss: 0.6020
2024-06-03 08:09:04 [INFO]: Epoch 003 - training loss: 0.6469, validation loss: 0.5965
2024-06-03 08:09:10 [INFO]: Epoch 004 - training loss: 0.6355, validation loss: 0.5817
2024-06-03 08:09:15 [INFO]: Epoch 005 - training loss: 0.6276, validation loss: 0.6150
2024-06-03 08:09:21 [INFO]: Epoch 006 - training loss: 0.6329, validation loss: 0.5851
2024-06-03 08:09:27 [INFO]: Epoch 007 - training loss: 0.6238, validation loss: 0.5802
2024-06-03 08:09:32 [INFO]: Epoch 008 - training loss: 0.6169, validation loss: 0.5614
2024-06-03 08:09:38 [INFO]: Epoch 009 - training loss: 0.6132, validation loss: 0.5529
2024-06-03 08:09:43 [INFO]: Epoch 010 - training loss: 0.6099, validation loss: 0.5683
2024-06-03 08:09:49 [INFO]: Epoch 011 - training loss: 0.6076, validation loss: 0.5731
2024-06-03 08:09:55 [INFO]: Epoch 012 - training loss: 0.6085, validation loss: 0.5611
2024-06-03 08:10:01 [INFO]: Epoch 013 - training loss: 0.6073, validation loss: 0.5681
2024-06-03 08:10:07 [INFO]: Epoch 014 - training loss: 0.6001, validation loss: 0.5438
2024-06-03 08:10:13 [INFO]: Epoch 015 - training loss: 0.5976, validation loss: 0.5943
2024-06-03 08:10:18 [INFO]: Epoch 016 - training loss: 0.6013, validation loss: 0.5481
2024-06-03 08:10:23 [INFO]: Epoch 017 - training loss: 0.6019, validation loss: 0.5597
2024-06-03 08:10:29 [INFO]: Epoch 018 - training loss: 0.5962, validation loss: 0.5386
2024-06-03 08:10:35 [INFO]: Epoch 019 - training loss: 0.5994, validation loss: 0.5474
2024-06-03 08:10:41 [INFO]: Epoch 020 - training loss: 0.5937, validation loss: 0.5547
2024-06-03 08:10:47 [INFO]: Epoch 021 - training loss: 0.5908, validation loss: 0.5474
2024-06-03 08:10:52 [INFO]: Epoch 022 - training loss: 0.5871, validation loss: 0.5516
2024-06-03 08:10:58 [INFO]: Epoch 023 - training loss: 0.5876, validation loss: 0.5413
2024-06-03 08:11:03 [INFO]: Epoch 024 - training loss: 0.5961, validation loss: 0.5478
2024-06-03 08:11:09 [INFO]: Epoch 025 - training loss: 0.5859, validation loss: 0.5427
2024-06-03 08:11:14 [INFO]: Epoch 026 - training loss: 0.5864, validation loss: 0.5530
2024-06-03 08:11:20 [INFO]: Epoch 027 - training loss: 0.5880, validation loss: 0.5433
2024-06-03 08:11:26 [INFO]: Epoch 028 - training loss: 0.5863, validation loss: 0.5572
2024-06-03 08:11:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:11:26 [INFO]: Finished training. The best model is from epoch#18.
2024-06-03 08:11:26 [INFO]: Saved the model to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T080847/NonstationaryTransformer.pypots
2024-06-03 08:11:28 [INFO]: Successfully saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/imputation.pkl
2024-06-03 08:11:28 [INFO]: Round2 - NonstationaryTransformer on BeijingAir: MAE=0.3633, MSE=0.5532, MRE=0.4893
2024-06-03 08:11:28 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:11:28 [INFO]: Using the given device: cuda:0
2024-06-03 08:11:28 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T081128
2024-06-03 08:11:28 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T081128/tensorboard
2024-06-03 08:11:28 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 08:11:34 [INFO]: Epoch 001 - training loss: 0.6988, validation loss: 0.5927
2024-06-03 08:11:40 [INFO]: Epoch 002 - training loss: 0.6565, validation loss: 0.5970
2024-06-03 08:11:45 [INFO]: Epoch 003 - training loss: 0.6444, validation loss: 0.5896
2024-06-03 08:11:51 [INFO]: Epoch 004 - training loss: 0.6458, validation loss: 0.5759
2024-06-03 08:11:57 [INFO]: Epoch 005 - training loss: 0.6371, validation loss: 0.5891
2024-06-03 08:12:03 [INFO]: Epoch 006 - training loss: 0.6250, validation loss: 0.5675
2024-06-03 08:12:09 [INFO]: Epoch 007 - training loss: 0.6235, validation loss: 0.5673
2024-06-03 08:12:15 [INFO]: Epoch 008 - training loss: 0.6226, validation loss: 0.5677
2024-06-03 08:12:20 [INFO]: Epoch 009 - training loss: 0.6135, validation loss: 0.5568
2024-06-03 08:12:26 [INFO]: Epoch 010 - training loss: 0.6137, validation loss: 0.5529
2024-06-03 08:12:32 [INFO]: Epoch 011 - training loss: 0.6090, validation loss: 0.5530
2024-06-03 08:12:37 [INFO]: Epoch 012 - training loss: 0.6063, validation loss: 0.5525
2024-06-03 08:12:43 [INFO]: Epoch 013 - training loss: 0.6106, validation loss: 0.5676
2024-06-03 08:12:49 [INFO]: Epoch 014 - training loss: 0.6024, validation loss: 0.5443
2024-06-03 08:12:55 [INFO]: Epoch 015 - training loss: 0.6024, validation loss: 0.5531
2024-06-03 08:13:01 [INFO]: Epoch 016 - training loss: 0.6030, validation loss: 0.5461
2024-06-03 08:13:06 [INFO]: Epoch 017 - training loss: 0.5995, validation loss: 0.5460
2024-06-03 08:13:12 [INFO]: Epoch 018 - training loss: 0.6016, validation loss: 0.5551
2024-06-03 08:13:17 [INFO]: Epoch 019 - training loss: 0.6005, validation loss: 0.5538
2024-06-03 08:13:22 [INFO]: Epoch 020 - training loss: 0.5992, validation loss: 0.5389
2024-06-03 08:13:27 [INFO]: Epoch 021 - training loss: 0.5964, validation loss: 0.5433
2024-06-03 08:13:32 [INFO]: Epoch 022 - training loss: 0.5942, validation loss: 0.5460
2024-06-03 08:13:37 [INFO]: Epoch 023 - training loss: 0.5924, validation loss: 0.5272
2024-06-03 08:13:42 [INFO]: Epoch 024 - training loss: 0.5906, validation loss: 0.5445
2024-06-03 08:13:47 [INFO]: Epoch 025 - training loss: 0.5880, validation loss: 0.5405
2024-06-03 08:13:52 [INFO]: Epoch 026 - training loss: 0.5879, validation loss: 0.5386
2024-06-03 08:13:57 [INFO]: Epoch 027 - training loss: 0.5894, validation loss: 0.5264
2024-06-03 08:14:02 [INFO]: Epoch 028 - training loss: 0.5880, validation loss: 0.5377
2024-06-03 08:14:07 [INFO]: Epoch 029 - training loss: 0.5891, validation loss: 0.5340
2024-06-03 08:14:12 [INFO]: Epoch 030 - training loss: 0.5850, validation loss: 0.5322
2024-06-03 08:14:17 [INFO]: Epoch 031 - training loss: 0.5814, validation loss: 0.5368
2024-06-03 08:14:22 [INFO]: Epoch 032 - training loss: 0.5797, validation loss: 0.5357
2024-06-03 08:14:27 [INFO]: Epoch 033 - training loss: 0.5791, validation loss: 0.5257
2024-06-03 08:14:32 [INFO]: Epoch 034 - training loss: 0.5817, validation loss: 0.5334
2024-06-03 08:14:37 [INFO]: Epoch 035 - training loss: 0.5794, validation loss: 0.5304
2024-06-03 08:14:42 [INFO]: Epoch 036 - training loss: 0.5805, validation loss: 0.5472
2024-06-03 08:14:47 [INFO]: Epoch 037 - training loss: 0.5812, validation loss: 0.5369
2024-06-03 08:14:52 [INFO]: Epoch 038 - training loss: 0.5787, validation loss: 0.5331
2024-06-03 08:14:57 [INFO]: Epoch 039 - training loss: 0.5800, validation loss: 0.5370
2024-06-03 08:15:01 [INFO]: Epoch 040 - training loss: 0.5761, validation loss: 0.5254
2024-06-03 08:15:06 [INFO]: Epoch 041 - training loss: 0.5812, validation loss: 0.5322
2024-06-03 08:15:11 [INFO]: Epoch 042 - training loss: 0.5796, validation loss: 0.5435
2024-06-03 08:15:16 [INFO]: Epoch 043 - training loss: 0.5764, validation loss: 0.5287
2024-06-03 08:15:21 [INFO]: Epoch 044 - training loss: 0.5745, validation loss: 0.5298
2024-06-03 08:15:26 [INFO]: Epoch 045 - training loss: 0.5718, validation loss: 0.5362
2024-06-03 08:15:31 [INFO]: Epoch 046 - training loss: 0.5729, validation loss: 0.5353
2024-06-03 08:15:36 [INFO]: Epoch 047 - training loss: 0.5741, validation loss: 0.5299
2024-06-03 08:15:41 [INFO]: Epoch 048 - training loss: 0.5726, validation loss: 0.5336
2024-06-03 08:15:45 [INFO]: Epoch 049 - training loss: 0.5767, validation loss: 0.5364
2024-06-03 08:15:50 [INFO]: Epoch 050 - training loss: 0.5732, validation loss: 0.5278
2024-06-03 08:15:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:15:50 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 08:15:50 [INFO]: Saved the model to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T081128/NonstationaryTransformer.pypots
2024-06-03 08:15:52 [INFO]: Successfully saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/imputation.pkl
2024-06-03 08:15:52 [INFO]: Round3 - NonstationaryTransformer on BeijingAir: MAE=0.3603, MSE=0.5245, MRE=0.4851
2024-06-03 08:15:52 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:15:52 [INFO]: Using the given device: cuda:0
2024-06-03 08:15:52 [INFO]: Model files will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T081552
2024-06-03 08:15:52 [INFO]: Tensorboard file will be saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T081552/tensorboard
2024-06-03 08:15:52 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 08:15:57 [INFO]: Epoch 001 - training loss: 0.7002, validation loss: 0.6192
2024-06-03 08:16:02 [INFO]: Epoch 002 - training loss: 0.6614, validation loss: 0.5980
2024-06-03 08:16:07 [INFO]: Epoch 003 - training loss: 0.6439, validation loss: 0.6042
2024-06-03 08:16:12 [INFO]: Epoch 004 - training loss: 0.6420, validation loss: 0.5869
2024-06-03 08:16:17 [INFO]: Epoch 005 - training loss: 0.6356, validation loss: 0.5853
2024-06-03 08:16:22 [INFO]: Epoch 006 - training loss: 0.6282, validation loss: 0.5868
2024-06-03 08:16:27 [INFO]: Epoch 007 - training loss: 0.6223, validation loss: 0.5787
2024-06-03 08:16:32 [INFO]: Epoch 008 - training loss: 0.6207, validation loss: 0.5613
2024-06-03 08:16:37 [INFO]: Epoch 009 - training loss: 0.6169, validation loss: 0.5680
2024-06-03 08:16:42 [INFO]: Epoch 010 - training loss: 0.6127, validation loss: 0.5675
2024-06-03 08:16:47 [INFO]: Epoch 011 - training loss: 0.6095, validation loss: 0.5746
2024-06-03 08:16:52 [INFO]: Epoch 012 - training loss: 0.6084, validation loss: 0.5705
2024-06-03 08:16:57 [INFO]: Epoch 013 - training loss: 0.6093, validation loss: 0.5571
2024-06-03 08:17:02 [INFO]: Epoch 014 - training loss: 0.6043, validation loss: 0.5595
2024-06-03 08:17:07 [INFO]: Epoch 015 - training loss: 0.6024, validation loss: 0.5612
2024-06-03 08:17:12 [INFO]: Epoch 016 - training loss: 0.5980, validation loss: 0.5478
2024-06-03 08:17:17 [INFO]: Epoch 017 - training loss: 0.5981, validation loss: 0.5661
2024-06-03 08:17:22 [INFO]: Epoch 018 - training loss: 0.5972, validation loss: 0.5688
2024-06-03 08:17:27 [INFO]: Epoch 019 - training loss: 0.5960, validation loss: 0.5493
2024-06-03 08:17:32 [INFO]: Epoch 020 - training loss: 0.5940, validation loss: 0.5569
2024-06-03 08:17:37 [INFO]: Epoch 021 - training loss: 0.5943, validation loss: 0.5560
2024-06-03 08:17:42 [INFO]: Epoch 022 - training loss: 0.5880, validation loss: 0.5391
2024-06-03 08:17:47 [INFO]: Epoch 023 - training loss: 0.5898, validation loss: 0.5794
2024-06-03 08:17:52 [INFO]: Epoch 024 - training loss: 0.5869, validation loss: 0.5485
2024-06-03 08:17:57 [INFO]: Epoch 025 - training loss: 0.5876, validation loss: 0.5492
2024-06-03 08:18:02 [INFO]: Epoch 026 - training loss: 0.5901, validation loss: 0.5512
2024-06-03 08:18:07 [INFO]: Epoch 027 - training loss: 0.5868, validation loss: 0.5491
2024-06-03 08:18:13 [INFO]: Epoch 028 - training loss: 0.5853, validation loss: 0.5613
2024-06-03 08:18:18 [INFO]: Epoch 029 - training loss: 0.5844, validation loss: 0.5508
2024-06-03 08:18:23 [INFO]: Epoch 030 - training loss: 0.5867, validation loss: 0.5498
2024-06-03 08:18:28 [INFO]: Epoch 031 - training loss: 0.5832, validation loss: 0.5594
2024-06-03 08:18:33 [INFO]: Epoch 032 - training loss: 0.5875, validation loss: 0.5522
2024-06-03 08:18:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:18:33 [INFO]: Finished training. The best model is from epoch#22.
2024-06-03 08:18:33 [INFO]: Saved the model to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T081552/NonstationaryTransformer.pypots
2024-06-03 08:18:35 [INFO]: Successfully saved to results_point_rate09/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/imputation.pkl
2024-06-03 08:18:35 [INFO]: Round4 - NonstationaryTransformer on BeijingAir: MAE=0.3631, MSE=0.5450, MRE=0.4890
2024-06-03 08:18:35 [INFO]: Done! Final results:
Averaged NonstationaryTransformer (6,978,068 params) on BeijingAir: MAE=0.3569 ± 0.0015776232990171992, MSE=0.5312 ± 0.010981065226169642, MRE=0.4735 ± 0.0020929246915548055, average inference time=0.47