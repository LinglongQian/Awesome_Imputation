2024-06-03 00:46:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:46:04 [INFO]: Using the given device: cuda:0
2024-06-03 00:46:05 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T004605
2024-06-03 00:46:05 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T004605/tensorboard
2024-06-03 00:46:06 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 00:46:13 [INFO]: Epoch 001 - training loss: 1.1162, validation loss: 1.0328
2024-06-03 00:46:13 [INFO]: Epoch 002 - training loss: 0.9259, validation loss: 0.9027
2024-06-03 00:46:15 [INFO]: Epoch 003 - training loss: 0.8098, validation loss: 0.9888
2024-06-03 00:46:16 [INFO]: Epoch 004 - training loss: 0.7377, validation loss: 0.8036
2024-06-03 00:46:17 [INFO]: Epoch 005 - training loss: 0.6606, validation loss: 0.9084
2024-06-03 00:46:18 [INFO]: Epoch 006 - training loss: 0.6191, validation loss: 0.8441
2024-06-03 00:46:18 [INFO]: Epoch 007 - training loss: 0.5991, validation loss: 0.8037
2024-06-03 00:46:19 [INFO]: Epoch 008 - training loss: 0.5748, validation loss: 0.8938
2024-06-03 00:46:19 [INFO]: Epoch 009 - training loss: 0.5230, validation loss: 0.7968
2024-06-03 00:46:20 [INFO]: Epoch 010 - training loss: 0.5551, validation loss: 0.8144
2024-06-03 00:46:20 [INFO]: Epoch 011 - training loss: 0.5899, validation loss: 0.8110
2024-06-03 00:46:21 [INFO]: Epoch 012 - training loss: 0.5713, validation loss: 0.8180
2024-06-03 00:46:22 [INFO]: Epoch 013 - training loss: 0.5199, validation loss: 0.7173
2024-06-03 00:46:22 [INFO]: Epoch 014 - training loss: 0.5168, validation loss: 0.7477
2024-06-03 00:46:23 [INFO]: Epoch 015 - training loss: 0.5124, validation loss: 0.7507
2024-06-03 00:46:23 [INFO]: Epoch 016 - training loss: 0.5042, validation loss: 0.7636
2024-06-03 00:46:24 [INFO]: Epoch 017 - training loss: 0.4959, validation loss: 0.7818
2024-06-03 00:46:25 [INFO]: Epoch 018 - training loss: 0.5112, validation loss: 0.6865
2024-06-03 00:46:25 [INFO]: Epoch 019 - training loss: 0.4682, validation loss: 0.7781
2024-06-03 00:46:26 [INFO]: Epoch 020 - training loss: 0.5005, validation loss: 0.7105
2024-06-03 00:46:26 [INFO]: Epoch 021 - training loss: 0.5175, validation loss: 0.7086
2024-06-03 00:46:27 [INFO]: Epoch 022 - training loss: 0.5382, validation loss: 0.7670
2024-06-03 00:46:27 [INFO]: Epoch 023 - training loss: 0.5531, validation loss: 0.7214
2024-06-03 00:46:28 [INFO]: Epoch 024 - training loss: 0.4275, validation loss: 0.6580
2024-06-03 00:46:29 [INFO]: Epoch 025 - training loss: 0.4615, validation loss: 0.7065
2024-06-03 00:46:29 [INFO]: Epoch 026 - training loss: 0.4188, validation loss: 0.6974
2024-06-03 00:46:30 [INFO]: Epoch 027 - training loss: 0.4008, validation loss: 0.6644
2024-06-03 00:46:30 [INFO]: Epoch 028 - training loss: 0.5281, validation loss: 0.7072
2024-06-03 00:46:31 [INFO]: Epoch 029 - training loss: 0.4477, validation loss: 0.6291
2024-06-03 00:46:32 [INFO]: Epoch 030 - training loss: 0.4279, validation loss: 0.6982
2024-06-03 00:46:32 [INFO]: Epoch 031 - training loss: 0.4136, validation loss: 0.7239
2024-06-03 00:46:33 [INFO]: Epoch 032 - training loss: 0.5142, validation loss: 0.6580
2024-06-03 00:46:34 [INFO]: Epoch 033 - training loss: 0.4216, validation loss: 0.7308
2024-06-03 00:46:34 [INFO]: Epoch 034 - training loss: 0.4642, validation loss: 0.6912
2024-06-03 00:46:35 [INFO]: Epoch 035 - training loss: 0.4535, validation loss: 0.6894
2024-06-03 00:46:35 [INFO]: Epoch 036 - training loss: 0.4408, validation loss: 0.7049
2024-06-03 00:46:36 [INFO]: Epoch 037 - training loss: 0.4366, validation loss: 0.7702
2024-06-03 00:46:36 [INFO]: Epoch 038 - training loss: 0.4402, validation loss: 0.6900
2024-06-03 00:46:37 [INFO]: Epoch 039 - training loss: 0.4026, validation loss: 0.7270
2024-06-03 00:46:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:46:37 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 00:46:37 [INFO]: Saved the model to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T004605/TimesNet.pypots
2024-06-03 00:46:38 [INFO]: Successfully saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_0/imputation.pkl
2024-06-03 00:46:38 [INFO]: Round0 - TimesNet on ETT_h1: MAE=0.6413, MSE=0.7468, MRE=0.7547
2024-06-03 00:46:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:46:38 [INFO]: Using the given device: cuda:0
2024-06-03 00:46:38 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T004638
2024-06-03 00:46:38 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T004638/tensorboard
2024-06-03 00:46:38 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 00:46:39 [INFO]: Epoch 001 - training loss: 1.0813, validation loss: 1.0460
2024-06-03 00:46:39 [INFO]: Epoch 002 - training loss: 0.9211, validation loss: 1.0022
2024-06-03 00:46:40 [INFO]: Epoch 003 - training loss: 0.8194, validation loss: 0.6910
2024-06-03 00:46:40 [INFO]: Epoch 004 - training loss: 0.7154, validation loss: 0.9624
2024-06-03 00:46:41 [INFO]: Epoch 005 - training loss: 0.6831, validation loss: 0.7920
2024-06-03 00:46:42 [INFO]: Epoch 006 - training loss: 0.6301, validation loss: 0.8472
2024-06-03 00:46:42 [INFO]: Epoch 007 - training loss: 0.5873, validation loss: 0.8038
2024-06-03 00:46:43 [INFO]: Epoch 008 - training loss: 0.6013, validation loss: 0.8269
2024-06-03 00:46:44 [INFO]: Epoch 009 - training loss: 0.5498, validation loss: 0.7620
2024-06-03 00:46:44 [INFO]: Epoch 010 - training loss: 0.4921, validation loss: 0.7967
2024-06-03 00:46:45 [INFO]: Epoch 011 - training loss: 0.5490, validation loss: 0.7481
2024-06-03 00:46:45 [INFO]: Epoch 012 - training loss: 0.4700, validation loss: 0.7926
2024-06-03 00:46:46 [INFO]: Epoch 013 - training loss: 0.5401, validation loss: 0.7235
2024-06-03 00:46:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:46:46 [INFO]: Finished training. The best model is from epoch#3.
2024-06-03 00:46:46 [INFO]: Saved the model to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T004638/TimesNet.pypots
2024-06-03 00:46:46 [INFO]: Successfully saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_1/imputation.pkl
2024-06-03 00:46:46 [INFO]: Round1 - TimesNet on ETT_h1: MAE=0.6492, MSE=0.7508, MRE=0.7640
2024-06-03 00:46:46 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:46:46 [INFO]: Using the given device: cuda:0
2024-06-03 00:46:46 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T004646
2024-06-03 00:46:46 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T004646/tensorboard
2024-06-03 00:46:47 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 00:46:47 [INFO]: Epoch 001 - training loss: 1.0825, validation loss: 1.0256
2024-06-03 00:46:48 [INFO]: Epoch 002 - training loss: 1.0248, validation loss: 1.0580
2024-06-03 00:46:48 [INFO]: Epoch 003 - training loss: 0.8779, validation loss: 0.8967
2024-06-03 00:46:49 [INFO]: Epoch 004 - training loss: 0.7028, validation loss: 0.7368
2024-06-03 00:46:50 [INFO]: Epoch 005 - training loss: 0.6942, validation loss: 0.8739
2024-06-03 00:46:50 [INFO]: Epoch 006 - training loss: 0.6552, validation loss: 0.8696
2024-06-03 00:46:51 [INFO]: Epoch 007 - training loss: 0.5986, validation loss: 0.7685
2024-06-03 00:46:51 [INFO]: Epoch 008 - training loss: 0.5742, validation loss: 0.8414
2024-06-03 00:46:52 [INFO]: Epoch 009 - training loss: 0.5699, validation loss: 0.7510
2024-06-03 00:46:52 [INFO]: Epoch 010 - training loss: 0.5933, validation loss: 0.7237
2024-06-03 00:46:53 [INFO]: Epoch 011 - training loss: 0.6169, validation loss: 0.9061
2024-06-03 00:46:53 [INFO]: Epoch 012 - training loss: 0.6051, validation loss: 0.7440
2024-06-03 00:46:54 [INFO]: Epoch 013 - training loss: 0.4816, validation loss: 0.7556
2024-06-03 00:46:55 [INFO]: Epoch 014 - training loss: 0.5676, validation loss: 0.7415
2024-06-03 00:46:55 [INFO]: Epoch 015 - training loss: 0.5083, validation loss: 0.7250
2024-06-03 00:46:56 [INFO]: Epoch 016 - training loss: 0.5770, validation loss: 0.6725
2024-06-03 00:46:57 [INFO]: Epoch 017 - training loss: 0.5052, validation loss: 0.7706
2024-06-03 00:46:57 [INFO]: Epoch 018 - training loss: 0.4818, validation loss: 0.6933
2024-06-03 00:46:58 [INFO]: Epoch 019 - training loss: 0.5334, validation loss: 0.7484
2024-06-03 00:46:58 [INFO]: Epoch 020 - training loss: 0.4866, validation loss: 0.6624
2024-06-03 00:46:59 [INFO]: Epoch 021 - training loss: 0.4813, validation loss: 0.7298
2024-06-03 00:46:59 [INFO]: Epoch 022 - training loss: 0.4687, validation loss: 0.6589
2024-06-03 00:47:00 [INFO]: Epoch 023 - training loss: 0.4913, validation loss: 0.6944
2024-06-03 00:47:01 [INFO]: Epoch 024 - training loss: 0.4889, validation loss: 0.7636
2024-06-03 00:47:01 [INFO]: Epoch 025 - training loss: 0.4883, validation loss: 0.6995
2024-06-03 00:47:02 [INFO]: Epoch 026 - training loss: 0.4254, validation loss: 0.6950
2024-06-03 00:47:02 [INFO]: Epoch 027 - training loss: 0.4171, validation loss: 0.6308
2024-06-03 00:47:03 [INFO]: Epoch 028 - training loss: 0.4862, validation loss: 0.7776
2024-06-03 00:47:03 [INFO]: Epoch 029 - training loss: 0.4499, validation loss: 0.6614
2024-06-03 00:47:04 [INFO]: Epoch 030 - training loss: 0.4569, validation loss: 0.6624
2024-06-03 00:47:05 [INFO]: Epoch 031 - training loss: 0.4433, validation loss: 0.7097
2024-06-03 00:47:05 [INFO]: Epoch 032 - training loss: 0.4259, validation loss: 0.6665
2024-06-03 00:47:06 [INFO]: Epoch 033 - training loss: 0.4445, validation loss: 0.6902
2024-06-03 00:47:06 [INFO]: Epoch 034 - training loss: 0.4454, validation loss: 0.6998
2024-06-03 00:47:07 [INFO]: Epoch 035 - training loss: 0.4441, validation loss: 0.6591
2024-06-03 00:47:07 [INFO]: Epoch 036 - training loss: 0.4369, validation loss: 0.6550
2024-06-03 00:47:08 [INFO]: Epoch 037 - training loss: 0.4226, validation loss: 0.6852
2024-06-03 00:47:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:47:08 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 00:47:08 [INFO]: Saved the model to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T004646/TimesNet.pypots
2024-06-03 00:47:08 [INFO]: Successfully saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_2/imputation.pkl
2024-06-03 00:47:08 [INFO]: Round2 - TimesNet on ETT_h1: MAE=0.6161, MSE=0.6859, MRE=0.7250
2024-06-03 00:47:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:47:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:47:08 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T004708
2024-06-03 00:47:08 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T004708/tensorboard
2024-06-03 00:47:09 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 00:47:09 [INFO]: Epoch 001 - training loss: 1.2687, validation loss: 1.0700
2024-06-03 00:47:09 [INFO]: Epoch 002 - training loss: 0.9874, validation loss: 0.9444
2024-06-03 00:47:10 [INFO]: Epoch 003 - training loss: 0.8473, validation loss: 0.9859
2024-06-03 00:47:10 [INFO]: Epoch 004 - training loss: 0.8743, validation loss: 0.9025
2024-06-03 00:47:10 [INFO]: Epoch 005 - training loss: 0.7319, validation loss: 0.8053
2024-06-03 00:47:11 [INFO]: Epoch 006 - training loss: 0.6571, validation loss: 0.8862
2024-06-03 00:47:11 [INFO]: Epoch 007 - training loss: 0.6298, validation loss: 0.8461
2024-06-03 00:47:12 [INFO]: Epoch 008 - training loss: 0.6069, validation loss: 0.8397
2024-06-03 00:47:12 [INFO]: Epoch 009 - training loss: 0.5841, validation loss: 0.7564
2024-06-03 00:47:12 [INFO]: Epoch 010 - training loss: 0.5333, validation loss: 0.7642
2024-06-03 00:47:13 [INFO]: Epoch 011 - training loss: 0.5572, validation loss: 0.6756
2024-06-03 00:47:13 [INFO]: Epoch 012 - training loss: 0.5205, validation loss: 0.7249
2024-06-03 00:47:13 [INFO]: Epoch 013 - training loss: 0.5163, validation loss: 0.8211
2024-06-03 00:47:14 [INFO]: Epoch 014 - training loss: 0.5468, validation loss: 0.7060
2024-06-03 00:47:15 [INFO]: Epoch 015 - training loss: 0.5628, validation loss: 0.7237
2024-06-03 00:47:15 [INFO]: Epoch 016 - training loss: 0.5161, validation loss: 0.7152
2024-06-03 00:47:16 [INFO]: Epoch 017 - training loss: 0.4805, validation loss: 0.6863
2024-06-03 00:47:17 [INFO]: Epoch 018 - training loss: 0.4720, validation loss: 0.6957
2024-06-03 00:47:17 [INFO]: Epoch 019 - training loss: 0.4864, validation loss: 0.7380
2024-06-03 00:47:18 [INFO]: Epoch 020 - training loss: 0.4615, validation loss: 0.7169
2024-06-03 00:47:18 [INFO]: Epoch 021 - training loss: 0.4858, validation loss: 0.6590
2024-06-03 00:47:19 [INFO]: Epoch 022 - training loss: 0.4670, validation loss: 0.7031
2024-06-03 00:47:20 [INFO]: Epoch 023 - training loss: 0.4873, validation loss: 0.6778
2024-06-03 00:47:20 [INFO]: Epoch 024 - training loss: 0.4527, validation loss: 0.7255
2024-06-03 00:47:21 [INFO]: Epoch 025 - training loss: 0.4675, validation loss: 0.7300
2024-06-03 00:47:21 [INFO]: Epoch 026 - training loss: 0.4246, validation loss: 0.6346
2024-06-03 00:47:22 [INFO]: Epoch 027 - training loss: 0.4527, validation loss: 0.7296
2024-06-03 00:47:22 [INFO]: Epoch 028 - training loss: 0.4996, validation loss: 0.7075
2024-06-03 00:47:23 [INFO]: Epoch 029 - training loss: 0.4591, validation loss: 0.6752
2024-06-03 00:47:24 [INFO]: Epoch 030 - training loss: 0.4655, validation loss: 0.6884
2024-06-03 00:47:24 [INFO]: Epoch 031 - training loss: 0.4658, validation loss: 0.6307
2024-06-03 00:47:25 [INFO]: Epoch 032 - training loss: 0.4259, validation loss: 0.6439
2024-06-03 00:47:25 [INFO]: Epoch 033 - training loss: 0.4184, validation loss: 0.6241
2024-06-03 00:47:26 [INFO]: Epoch 034 - training loss: 0.4917, validation loss: 0.7115
2024-06-03 00:47:27 [INFO]: Epoch 035 - training loss: 0.4515, validation loss: 0.6808
2024-06-03 00:47:27 [INFO]: Epoch 036 - training loss: 0.4439, validation loss: 0.6912
2024-06-03 00:47:28 [INFO]: Epoch 037 - training loss: 0.4502, validation loss: 0.6547
2024-06-03 00:47:28 [INFO]: Epoch 038 - training loss: 0.4445, validation loss: 0.6717
2024-06-03 00:47:29 [INFO]: Epoch 039 - training loss: 0.4415, validation loss: 0.7059
2024-06-03 00:47:29 [INFO]: Epoch 040 - training loss: 0.3971, validation loss: 0.6972
2024-06-03 00:47:30 [INFO]: Epoch 041 - training loss: 0.4499, validation loss: 0.7122
2024-06-03 00:47:30 [INFO]: Epoch 042 - training loss: 0.3987, validation loss: 0.6672
2024-06-03 00:47:31 [INFO]: Epoch 043 - training loss: 0.4163, validation loss: 0.6398
2024-06-03 00:47:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:47:31 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 00:47:31 [INFO]: Saved the model to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T004708/TimesNet.pypots
2024-06-03 00:47:31 [INFO]: Successfully saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_3/imputation.pkl
2024-06-03 00:47:31 [INFO]: Round3 - TimesNet on ETT_h1: MAE=0.6076, MSE=0.6627, MRE=0.7151
2024-06-03 00:47:31 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:47:31 [INFO]: Using the given device: cuda:0
2024-06-03 00:47:31 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T004731
2024-06-03 00:47:31 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T004731/tensorboard
2024-06-03 00:47:32 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 00:47:32 [INFO]: Epoch 001 - training loss: 1.1614, validation loss: 0.9658
2024-06-03 00:47:33 [INFO]: Epoch 002 - training loss: 0.9350, validation loss: 1.0011
2024-06-03 00:47:33 [INFO]: Epoch 003 - training loss: 0.8823, validation loss: 0.9350
2024-06-03 00:47:34 [INFO]: Epoch 004 - training loss: 0.7288, validation loss: 0.8061
2024-06-03 00:47:34 [INFO]: Epoch 005 - training loss: 0.6031, validation loss: 0.7831
2024-06-03 00:47:34 [INFO]: Epoch 006 - training loss: 0.5740, validation loss: 0.9484
2024-06-03 00:47:35 [INFO]: Epoch 007 - training loss: 0.6670, validation loss: 0.7888
2024-06-03 00:47:35 [INFO]: Epoch 008 - training loss: 0.5718, validation loss: 0.7931
2024-06-03 00:47:36 [INFO]: Epoch 009 - training loss: 0.5843, validation loss: 0.7762
2024-06-03 00:47:36 [INFO]: Epoch 010 - training loss: 0.5470, validation loss: 0.8001
2024-06-03 00:47:37 [INFO]: Epoch 011 - training loss: 0.5698, validation loss: 0.8005
2024-06-03 00:47:38 [INFO]: Epoch 012 - training loss: 0.5240, validation loss: 0.7525
2024-06-03 00:47:38 [INFO]: Epoch 013 - training loss: 0.5179, validation loss: 0.8170
2024-06-03 00:47:39 [INFO]: Epoch 014 - training loss: 0.5186, validation loss: 0.6865
2024-06-03 00:47:39 [INFO]: Epoch 015 - training loss: 0.5014, validation loss: 0.7351
2024-06-03 00:47:40 [INFO]: Epoch 016 - training loss: 0.5023, validation loss: 0.7480
2024-06-03 00:47:40 [INFO]: Epoch 017 - training loss: 0.4941, validation loss: 0.7141
2024-06-03 00:47:41 [INFO]: Epoch 018 - training loss: 0.4989, validation loss: 0.7310
2024-06-03 00:47:41 [INFO]: Epoch 019 - training loss: 0.5360, validation loss: 0.6693
2024-06-03 00:47:42 [INFO]: Epoch 020 - training loss: 0.4429, validation loss: 0.6884
2024-06-03 00:47:42 [INFO]: Epoch 021 - training loss: 0.4825, validation loss: 0.6986
2024-06-03 00:47:42 [INFO]: Epoch 022 - training loss: 0.4975, validation loss: 0.7119
2024-06-03 00:47:43 [INFO]: Epoch 023 - training loss: 0.4482, validation loss: 0.6343
2024-06-03 00:47:43 [INFO]: Epoch 024 - training loss: 0.4803, validation loss: 0.7593
2024-06-03 00:47:44 [INFO]: Epoch 025 - training loss: 0.5105, validation loss: 0.6736
2024-06-03 00:47:44 [INFO]: Epoch 026 - training loss: 0.4880, validation loss: 0.6443
2024-06-03 00:47:45 [INFO]: Epoch 027 - training loss: 0.4966, validation loss: 0.7555
2024-06-03 00:47:46 [INFO]: Epoch 028 - training loss: 0.4569, validation loss: 0.6847
2024-06-03 00:47:46 [INFO]: Epoch 029 - training loss: 0.4884, validation loss: 0.6696
2024-06-03 00:47:47 [INFO]: Epoch 030 - training loss: 0.5171, validation loss: 0.6947
2024-06-03 00:47:47 [INFO]: Epoch 031 - training loss: 0.4263, validation loss: 0.7252
2024-06-03 00:47:47 [INFO]: Epoch 032 - training loss: 0.4633, validation loss: 0.6312
2024-06-03 00:47:48 [INFO]: Epoch 033 - training loss: 0.4550, validation loss: 0.6652
2024-06-03 00:47:49 [INFO]: Epoch 034 - training loss: 0.4742, validation loss: 0.6874
2024-06-03 00:47:49 [INFO]: Epoch 035 - training loss: 0.4273, validation loss: 0.6428
2024-06-03 00:47:50 [INFO]: Epoch 036 - training loss: 0.4694, validation loss: 0.6178
2024-06-03 00:47:50 [INFO]: Epoch 037 - training loss: 0.3912, validation loss: 0.6558
2024-06-03 00:47:50 [INFO]: Epoch 038 - training loss: 0.4171, validation loss: 0.6547
2024-06-03 00:47:51 [INFO]: Epoch 039 - training loss: 0.4120, validation loss: 0.7031
2024-06-03 00:47:52 [INFO]: Epoch 040 - training loss: 0.4252, validation loss: 0.6806
2024-06-03 00:47:52 [INFO]: Epoch 041 - training loss: 0.4176, validation loss: 0.6861
2024-06-03 00:47:53 [INFO]: Epoch 042 - training loss: 0.4232, validation loss: 0.6581
2024-06-03 00:47:53 [INFO]: Epoch 043 - training loss: 0.3680, validation loss: 0.6682
2024-06-03 00:47:54 [INFO]: Epoch 044 - training loss: 0.3941, validation loss: 0.6609
2024-06-03 00:47:54 [INFO]: Epoch 045 - training loss: 0.4273, validation loss: 0.7201
2024-06-03 00:47:55 [INFO]: Epoch 046 - training loss: 0.4195, validation loss: 0.6102
2024-06-03 00:47:55 [INFO]: Epoch 047 - training loss: 0.3769, validation loss: 0.6662
2024-06-03 00:47:56 [INFO]: Epoch 048 - training loss: 0.4226, validation loss: 0.6369
2024-06-03 00:47:56 [INFO]: Epoch 049 - training loss: 0.4357, validation loss: 0.6795
2024-06-03 00:47:57 [INFO]: Epoch 050 - training loss: 0.4259, validation loss: 0.6569
2024-06-03 00:47:57 [INFO]: Epoch 051 - training loss: 0.3763, validation loss: 0.6302
2024-06-03 00:47:57 [INFO]: Epoch 052 - training loss: 0.3871, validation loss: 0.6620
2024-06-03 00:47:58 [INFO]: Epoch 053 - training loss: 0.3911, validation loss: 0.6404
2024-06-03 00:47:58 [INFO]: Epoch 054 - training loss: 0.3674, validation loss: 0.6708
2024-06-03 00:47:59 [INFO]: Epoch 055 - training loss: 0.3862, validation loss: 0.6379
2024-06-03 00:47:59 [INFO]: Epoch 056 - training loss: 0.3926, validation loss: 0.6118
2024-06-03 00:47:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:47:59 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 00:47:59 [INFO]: Saved the model to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T004731/TimesNet.pypots
2024-06-03 00:47:59 [INFO]: Successfully saved to results_point_rate09/ETT_h1/TimesNet_ETT_h1/round_4/imputation.pkl
2024-06-03 00:47:59 [INFO]: Round4 - TimesNet on ETT_h1: MAE=0.5946, MSE=0.6254, MRE=0.6998
2024-06-03 00:47:59 [INFO]: Done! Final results:
Averaged TimesNet (5,510,663 params) on ETT_h1: MAE=0.6218 ± 0.0204852583857916, MSE=0.6943 ± 0.04850679386361805, MRE=0.7317 ± 0.024108866889615842, average inference time=0.16
