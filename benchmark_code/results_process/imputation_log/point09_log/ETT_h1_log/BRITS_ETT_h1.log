2024-06-03 00:25:10 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:25:10 [INFO]: Using the given device: cuda:0
2024-06-03 00:25:10 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_0/20240603_T002510
2024-06-03 00:25:10 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_0/20240603_T002510/tensorboard
2024-06-03 00:25:12 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,178,496
2024-06-03 00:25:35 [INFO]: Epoch 001 - training loss: 1.6014, validation loss: 0.9686
2024-06-03 00:25:55 [INFO]: Epoch 002 - training loss: 1.5114, validation loss: 0.9691
2024-06-03 00:26:14 [INFO]: Epoch 003 - training loss: 1.4663, validation loss: 0.9710
2024-06-03 00:26:33 [INFO]: Epoch 004 - training loss: 1.4497, validation loss: 0.9531
2024-06-03 00:26:53 [INFO]: Epoch 005 - training loss: 1.3961, validation loss: 0.9358
2024-06-03 00:27:08 [INFO]: Epoch 006 - training loss: 1.3706, validation loss: 0.9778
2024-06-03 00:27:24 [INFO]: Epoch 007 - training loss: 1.3181, validation loss: 1.0220
2024-06-03 00:27:35 [INFO]: Epoch 008 - training loss: 1.3027, validation loss: 0.9421
2024-06-03 00:27:45 [INFO]: Epoch 009 - training loss: 1.2463, validation loss: 0.9137
2024-06-03 00:27:56 [INFO]: Epoch 010 - training loss: 1.2309, validation loss: 0.9070
2024-06-03 00:28:06 [INFO]: Epoch 011 - training loss: 1.2099, validation loss: 0.9057
2024-06-03 00:28:13 [INFO]: Epoch 012 - training loss: 1.2043, validation loss: 0.9339
2024-06-03 00:28:23 [INFO]: Epoch 013 - training loss: 1.1936, validation loss: 0.8936
2024-06-03 00:28:30 [INFO]: Epoch 014 - training loss: 1.1884, validation loss: 0.8790
2024-06-03 00:28:40 [INFO]: Epoch 015 - training loss: 1.1515, validation loss: 0.8552
2024-06-03 00:28:51 [INFO]: Epoch 016 - training loss: 1.1241, validation loss: 0.8343
2024-06-03 00:29:12 [INFO]: Epoch 017 - training loss: 1.1112, validation loss: 0.7960
2024-06-03 00:29:25 [INFO]: Epoch 018 - training loss: 1.0985, validation loss: 0.7866
2024-06-03 00:29:35 [INFO]: Epoch 019 - training loss: 1.0745, validation loss: 0.7667
2024-06-03 00:29:44 [INFO]: Epoch 020 - training loss: 1.0766, validation loss: 0.7933
2024-06-03 00:29:53 [INFO]: Epoch 021 - training loss: 1.0611, validation loss: 0.7651
2024-06-03 00:30:02 [INFO]: Epoch 022 - training loss: 1.0449, validation loss: 0.7466
2024-06-03 00:30:12 [INFO]: Epoch 023 - training loss: 1.0291, validation loss: 0.7340
2024-06-03 00:30:22 [INFO]: Epoch 024 - training loss: 1.0160, validation loss: 0.7490
2024-06-03 00:30:35 [INFO]: Epoch 025 - training loss: 1.0171, validation loss: 0.6917
2024-06-03 00:30:55 [INFO]: Epoch 026 - training loss: 0.9866, validation loss: 0.7105
2024-06-03 00:31:07 [INFO]: Epoch 027 - training loss: 0.9873, validation loss: 0.6961
2024-06-03 00:31:16 [INFO]: Epoch 028 - training loss: 0.9712, validation loss: 0.6833
2024-06-03 00:31:25 [INFO]: Epoch 029 - training loss: 0.9510, validation loss: 0.7068
2024-06-03 00:31:35 [INFO]: Epoch 030 - training loss: 0.9835, validation loss: 0.7177
2024-06-03 00:31:45 [INFO]: Epoch 031 - training loss: 0.9826, validation loss: 0.7006
2024-06-03 00:31:52 [INFO]: Epoch 032 - training loss: 0.9677, validation loss: 0.7052
2024-06-03 00:32:01 [INFO]: Epoch 033 - training loss: 0.9444, validation loss: 0.6437
2024-06-03 00:32:11 [INFO]: Epoch 034 - training loss: 0.9306, validation loss: 0.6934
2024-06-03 00:32:20 [INFO]: Epoch 035 - training loss: 0.9305, validation loss: 0.7017
2024-06-03 00:32:31 [INFO]: Epoch 036 - training loss: 0.9126, validation loss: 0.6693
2024-06-03 00:32:46 [INFO]: Epoch 037 - training loss: 0.9087, validation loss: 0.6702
2024-06-03 00:33:06 [INFO]: Epoch 038 - training loss: 0.8843, validation loss: 0.6656
2024-06-03 00:33:16 [INFO]: Epoch 039 - training loss: 0.8926, validation loss: 0.6517
2024-06-03 00:33:24 [INFO]: Epoch 040 - training loss: 0.8727, validation loss: 0.6588
2024-06-03 00:33:34 [INFO]: Epoch 041 - training loss: 0.8765, validation loss: 0.6608
2024-06-03 00:33:43 [INFO]: Epoch 042 - training loss: 0.8590, validation loss: 0.6717
2024-06-03 00:33:53 [INFO]: Epoch 043 - training loss: 0.8258, validation loss: 0.6546
2024-06-03 00:33:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:33:53 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 00:33:53 [INFO]: Saved the model to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_0/20240603_T002510/BRITS.pypots
2024-06-03 00:34:03 [INFO]: Successfully saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_0/imputation.pkl
2024-06-03 00:34:03 [INFO]: Round0 - BRITS on ETT_h1: MAE=0.6130, MSE=0.6859, MRE=0.7214
2024-06-03 00:34:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:34:03 [INFO]: Using the given device: cuda:0
2024-06-03 00:34:03 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_1/20240603_T003403
2024-06-03 00:34:03 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_1/20240603_T003403/tensorboard
2024-06-03 00:34:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,178,496
2024-06-03 00:34:13 [INFO]: Epoch 001 - training loss: 1.6118, validation loss: 1.0195
2024-06-03 00:34:27 [INFO]: Epoch 002 - training loss: 1.4994, validation loss: 1.0072
2024-06-03 00:34:47 [INFO]: Epoch 003 - training loss: 1.4935, validation loss: 1.0123
2024-06-03 00:34:59 [INFO]: Epoch 004 - training loss: 1.4743, validation loss: 0.9995
2024-06-03 00:35:09 [INFO]: Epoch 005 - training loss: 1.4186, validation loss: 0.9578
2024-06-03 00:35:18 [INFO]: Epoch 006 - training loss: 1.3678, validation loss: 0.9647
2024-06-03 00:35:28 [INFO]: Epoch 007 - training loss: 1.3351, validation loss: 0.9519
2024-06-03 00:35:37 [INFO]: Epoch 008 - training loss: 1.2881, validation loss: 0.9589
2024-06-03 00:35:46 [INFO]: Epoch 009 - training loss: 1.2595, validation loss: 0.9421
2024-06-03 00:35:56 [INFO]: Epoch 010 - training loss: 1.2548, validation loss: 0.9612
2024-06-03 00:36:08 [INFO]: Epoch 011 - training loss: 1.2248, validation loss: 0.9356
2024-06-03 00:36:27 [INFO]: Epoch 012 - training loss: 1.2222, validation loss: 0.9464
2024-06-03 00:36:42 [INFO]: Epoch 013 - training loss: 1.1768, validation loss: 0.9329
2024-06-03 00:36:43 [INFO]: Epoch 014 - training loss: 1.1653, validation loss: 0.9050
2024-06-03 00:36:44 [INFO]: Epoch 015 - training loss: 1.1534, validation loss: 0.8845
2024-06-03 00:36:46 [INFO]: Epoch 016 - training loss: 1.1403, validation loss: 0.8888
2024-06-03 00:36:47 [INFO]: Epoch 017 - training loss: 1.1248, validation loss: 0.8600
2024-06-03 00:36:48 [INFO]: Epoch 018 - training loss: 1.0916, validation loss: 0.8255
2024-06-03 00:36:49 [INFO]: Epoch 019 - training loss: 1.0719, validation loss: 0.8127
2024-06-03 00:36:50 [INFO]: Epoch 020 - training loss: 1.0597, validation loss: 0.7996
2024-06-03 00:36:51 [INFO]: Epoch 021 - training loss: 1.0520, validation loss: 0.8045
2024-06-03 00:36:52 [INFO]: Epoch 022 - training loss: 1.0513, validation loss: 0.7867
2024-06-03 00:36:53 [INFO]: Epoch 023 - training loss: 1.0288, validation loss: 0.7542
2024-06-03 00:36:55 [INFO]: Epoch 024 - training loss: 1.0194, validation loss: 0.7489
2024-06-03 00:36:56 [INFO]: Epoch 025 - training loss: 0.9851, validation loss: 0.7305
2024-06-03 00:36:57 [INFO]: Epoch 026 - training loss: 0.9789, validation loss: 0.7250
2024-06-03 00:36:58 [INFO]: Epoch 027 - training loss: 0.9660, validation loss: 0.7621
2024-06-03 00:36:59 [INFO]: Epoch 028 - training loss: 0.9666, validation loss: 0.6976
2024-06-03 00:37:00 [INFO]: Epoch 029 - training loss: 0.9560, validation loss: 0.7150
2024-06-03 00:37:01 [INFO]: Epoch 030 - training loss: 0.9249, validation loss: 0.7120
2024-06-03 00:37:02 [INFO]: Epoch 031 - training loss: 0.9241, validation loss: 0.6977
2024-06-03 00:37:03 [INFO]: Epoch 032 - training loss: 0.9296, validation loss: 0.7039
2024-06-03 00:37:05 [INFO]: Epoch 033 - training loss: 0.9096, validation loss: 0.7001
2024-06-03 00:37:06 [INFO]: Epoch 034 - training loss: 0.9245, validation loss: 0.6441
2024-06-03 00:37:07 [INFO]: Epoch 035 - training loss: 0.9011, validation loss: 0.6568
2024-06-03 00:37:08 [INFO]: Epoch 036 - training loss: 0.8822, validation loss: 0.6618
2024-06-03 00:37:09 [INFO]: Epoch 037 - training loss: 0.8622, validation loss: 0.6614
2024-06-03 00:37:10 [INFO]: Epoch 038 - training loss: 0.8463, validation loss: 0.6609
2024-06-03 00:37:11 [INFO]: Epoch 039 - training loss: 0.8516, validation loss: 0.6603
2024-06-03 00:37:12 [INFO]: Epoch 040 - training loss: 0.8350, validation loss: 0.6462
2024-06-03 00:37:13 [INFO]: Epoch 041 - training loss: 0.8222, validation loss: 0.6360
2024-06-03 00:37:15 [INFO]: Epoch 042 - training loss: 0.8113, validation loss: 0.6437
2024-06-03 00:37:16 [INFO]: Epoch 043 - training loss: 0.8075, validation loss: 0.6537
2024-06-03 00:37:17 [INFO]: Epoch 044 - training loss: 0.8081, validation loss: 0.6219
2024-06-03 00:37:18 [INFO]: Epoch 045 - training loss: 0.7916, validation loss: 0.6282
2024-06-03 00:37:19 [INFO]: Epoch 046 - training loss: 0.7798, validation loss: 0.6351
2024-06-03 00:37:20 [INFO]: Epoch 047 - training loss: 0.7677, validation loss: 0.6350
2024-06-03 00:37:21 [INFO]: Epoch 048 - training loss: 0.7625, validation loss: 0.6501
2024-06-03 00:37:22 [INFO]: Epoch 049 - training loss: 0.7635, validation loss: 0.6444
2024-06-03 00:37:24 [INFO]: Epoch 050 - training loss: 0.7568, validation loss: 0.6195
2024-06-03 00:37:25 [INFO]: Epoch 051 - training loss: 0.7460, validation loss: 0.6443
2024-06-03 00:37:26 [INFO]: Epoch 052 - training loss: 0.7356, validation loss: 0.6474
2024-06-03 00:37:27 [INFO]: Epoch 053 - training loss: 0.7212, validation loss: 0.6166
2024-06-03 00:37:28 [INFO]: Epoch 054 - training loss: 0.7138, validation loss: 0.6285
2024-06-03 00:37:29 [INFO]: Epoch 055 - training loss: 0.6809, validation loss: 0.6134
2024-06-03 00:37:30 [INFO]: Epoch 056 - training loss: 0.6768, validation loss: 0.6046
2024-06-03 00:37:31 [INFO]: Epoch 057 - training loss: 0.6746, validation loss: 0.5991
2024-06-03 00:37:33 [INFO]: Epoch 058 - training loss: 0.6638, validation loss: 0.6109
2024-06-03 00:37:34 [INFO]: Epoch 059 - training loss: 0.6683, validation loss: 0.6196
2024-06-03 00:37:35 [INFO]: Epoch 060 - training loss: 0.6519, validation loss: 0.6252
2024-06-03 00:37:36 [INFO]: Epoch 061 - training loss: 0.6360, validation loss: 0.6059
2024-06-03 00:37:37 [INFO]: Epoch 062 - training loss: 0.6216, validation loss: 0.6181
2024-06-03 00:37:38 [INFO]: Epoch 063 - training loss: 0.6032, validation loss: 0.6120
2024-06-03 00:37:39 [INFO]: Epoch 064 - training loss: 0.5908, validation loss: 0.6126
2024-06-03 00:37:41 [INFO]: Epoch 065 - training loss: 0.5858, validation loss: 0.6232
2024-06-03 00:37:42 [INFO]: Epoch 066 - training loss: 0.5700, validation loss: 0.6067
2024-06-03 00:37:43 [INFO]: Epoch 067 - training loss: 0.5908, validation loss: 0.6169
2024-06-03 00:37:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:37:43 [INFO]: Finished training. The best model is from epoch#57.
2024-06-03 00:37:43 [INFO]: Saved the model to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_1/20240603_T003403/BRITS.pypots
2024-06-03 00:37:44 [INFO]: Successfully saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_1/imputation.pkl
2024-06-03 00:37:44 [INFO]: Round1 - BRITS on ETT_h1: MAE=0.6100, MSE=0.6594, MRE=0.7179
2024-06-03 00:37:44 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:37:44 [INFO]: Using the given device: cuda:0
2024-06-03 00:37:44 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_2/20240603_T003744
2024-06-03 00:37:44 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_2/20240603_T003744/tensorboard
2024-06-03 00:37:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,178,496
2024-06-03 00:37:45 [INFO]: Epoch 001 - training loss: 1.6925, validation loss: 1.0669
2024-06-03 00:37:47 [INFO]: Epoch 002 - training loss: 1.5214, validation loss: 1.0019
2024-06-03 00:37:48 [INFO]: Epoch 003 - training loss: 1.4861, validation loss: 1.0028
2024-06-03 00:37:49 [INFO]: Epoch 004 - training loss: 1.4945, validation loss: 0.9829
2024-06-03 00:37:50 [INFO]: Epoch 005 - training loss: 1.4598, validation loss: 0.9992
2024-06-03 00:37:51 [INFO]: Epoch 006 - training loss: 1.4183, validation loss: 0.9983
2024-06-03 00:37:52 [INFO]: Epoch 007 - training loss: 1.3844, validation loss: 0.9665
2024-06-03 00:37:53 [INFO]: Epoch 008 - training loss: 1.3217, validation loss: 0.9473
2024-06-03 00:37:54 [INFO]: Epoch 009 - training loss: 1.2912, validation loss: 0.9300
2024-06-03 00:37:56 [INFO]: Epoch 010 - training loss: 1.2518, validation loss: 0.9386
2024-06-03 00:37:57 [INFO]: Epoch 011 - training loss: 1.2236, validation loss: 0.9386
2024-06-03 00:37:58 [INFO]: Epoch 012 - training loss: 1.1874, validation loss: 0.8931
2024-06-03 00:37:59 [INFO]: Epoch 013 - training loss: 1.1607, validation loss: 0.8775
2024-06-03 00:38:00 [INFO]: Epoch 014 - training loss: 1.1597, validation loss: 0.8703
2024-06-03 00:38:01 [INFO]: Epoch 015 - training loss: 1.1367, validation loss: 0.8608
2024-06-03 00:38:02 [INFO]: Epoch 016 - training loss: 1.1211, validation loss: 0.8036
2024-06-03 00:38:03 [INFO]: Epoch 017 - training loss: 1.1073, validation loss: 0.7979
2024-06-03 00:38:05 [INFO]: Epoch 018 - training loss: 1.0831, validation loss: 0.7975
2024-06-03 00:38:06 [INFO]: Epoch 019 - training loss: 1.0807, validation loss: 0.7955
2024-06-03 00:38:07 [INFO]: Epoch 020 - training loss: 1.0561, validation loss: 0.7477
2024-06-03 00:38:08 [INFO]: Epoch 021 - training loss: 1.0381, validation loss: 0.7524
2024-06-03 00:38:09 [INFO]: Epoch 022 - training loss: 1.0187, validation loss: 0.7131
2024-06-03 00:38:10 [INFO]: Epoch 023 - training loss: 1.0119, validation loss: 0.7251
2024-06-03 00:38:11 [INFO]: Epoch 024 - training loss: 0.9907, validation loss: 0.7204
2024-06-03 00:38:13 [INFO]: Epoch 025 - training loss: 0.9853, validation loss: 0.7281
2024-06-03 00:38:14 [INFO]: Epoch 026 - training loss: 0.9968, validation loss: 0.7504
2024-06-03 00:38:15 [INFO]: Epoch 027 - training loss: 0.9883, validation loss: 0.6997
2024-06-03 00:38:16 [INFO]: Epoch 028 - training loss: 0.9744, validation loss: 0.6910
2024-06-03 00:38:17 [INFO]: Epoch 029 - training loss: 0.9456, validation loss: 0.6798
2024-06-03 00:38:18 [INFO]: Epoch 030 - training loss: 0.9347, validation loss: 0.6607
2024-06-03 00:38:19 [INFO]: Epoch 031 - training loss: 0.9195, validation loss: 0.6570
2024-06-03 00:38:20 [INFO]: Epoch 032 - training loss: 0.9029, validation loss: 0.6469
2024-06-03 00:38:21 [INFO]: Epoch 033 - training loss: 0.8978, validation loss: 0.6767
2024-06-03 00:38:23 [INFO]: Epoch 034 - training loss: 0.9121, validation loss: 0.6576
2024-06-03 00:38:24 [INFO]: Epoch 035 - training loss: 0.9044, validation loss: 0.6767
2024-06-03 00:38:25 [INFO]: Epoch 036 - training loss: 0.8892, validation loss: 0.6251
2024-06-03 00:38:26 [INFO]: Epoch 037 - training loss: 0.8676, validation loss: 0.6305
2024-06-03 00:38:27 [INFO]: Epoch 038 - training loss: 0.8522, validation loss: 0.6285
2024-06-03 00:38:28 [INFO]: Epoch 039 - training loss: 0.8460, validation loss: 0.6538
2024-06-03 00:38:29 [INFO]: Epoch 040 - training loss: 0.8450, validation loss: 0.6295
2024-06-03 00:38:31 [INFO]: Epoch 041 - training loss: 0.8205, validation loss: 0.6070
2024-06-03 00:38:32 [INFO]: Epoch 042 - training loss: 0.8101, validation loss: 0.6078
2024-06-03 00:38:33 [INFO]: Epoch 043 - training loss: 0.7998, validation loss: 0.6264
2024-06-03 00:38:34 [INFO]: Epoch 044 - training loss: 0.7749, validation loss: 0.6324
2024-06-03 00:38:35 [INFO]: Epoch 045 - training loss: 0.7750, validation loss: 0.6465
2024-06-03 00:38:36 [INFO]: Epoch 046 - training loss: 0.7937, validation loss: 0.6162
2024-06-03 00:38:37 [INFO]: Epoch 047 - training loss: 0.7707, validation loss: 0.5941
2024-06-03 00:38:39 [INFO]: Epoch 048 - training loss: 0.7535, validation loss: 0.6061
2024-06-03 00:38:40 [INFO]: Epoch 049 - training loss: 0.7510, validation loss: 0.6107
2024-06-03 00:38:41 [INFO]: Epoch 050 - training loss: 0.7368, validation loss: 0.6016
2024-06-03 00:38:42 [INFO]: Epoch 051 - training loss: 0.7165, validation loss: 0.5850
2024-06-03 00:38:43 [INFO]: Epoch 052 - training loss: 0.7017, validation loss: 0.6077
2024-06-03 00:38:44 [INFO]: Epoch 053 - training loss: 0.7017, validation loss: 0.5922
2024-06-03 00:38:45 [INFO]: Epoch 054 - training loss: 0.6985, validation loss: 0.5885
2024-06-03 00:38:46 [INFO]: Epoch 055 - training loss: 0.6926, validation loss: 0.6032
2024-06-03 00:38:48 [INFO]: Epoch 056 - training loss: 0.6679, validation loss: 0.5847
2024-06-03 00:38:49 [INFO]: Epoch 057 - training loss: 0.6571, validation loss: 0.5966
2024-06-03 00:38:50 [INFO]: Epoch 058 - training loss: 0.6744, validation loss: 0.5883
2024-06-03 00:38:51 [INFO]: Epoch 059 - training loss: 0.6810, validation loss: 0.5799
2024-06-03 00:38:52 [INFO]: Epoch 060 - training loss: 0.6615, validation loss: 0.5948
2024-06-03 00:38:53 [INFO]: Epoch 061 - training loss: 0.6528, validation loss: 0.5944
2024-06-03 00:38:54 [INFO]: Epoch 062 - training loss: 0.6491, validation loss: 0.6161
2024-06-03 00:38:55 [INFO]: Epoch 063 - training loss: 0.6360, validation loss: 0.5951
2024-06-03 00:38:57 [INFO]: Epoch 064 - training loss: 0.6265, validation loss: 0.6067
2024-06-03 00:38:58 [INFO]: Epoch 065 - training loss: 0.6149, validation loss: 0.5904
2024-06-03 00:38:59 [INFO]: Epoch 066 - training loss: 0.5966, validation loss: 0.6156
2024-06-03 00:39:00 [INFO]: Epoch 067 - training loss: 0.5965, validation loss: 0.6075
2024-06-03 00:39:01 [INFO]: Epoch 068 - training loss: 0.5824, validation loss: 0.6000
2024-06-03 00:39:02 [INFO]: Epoch 069 - training loss: 0.5688, validation loss: 0.6064
2024-06-03 00:39:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:39:02 [INFO]: Finished training. The best model is from epoch#59.
2024-06-03 00:39:02 [INFO]: Saved the model to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_2/20240603_T003744/BRITS.pypots
2024-06-03 00:39:03 [INFO]: Successfully saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_2/imputation.pkl
2024-06-03 00:39:03 [INFO]: Round2 - BRITS on ETT_h1: MAE=0.5996, MSE=0.6548, MRE=0.7056
2024-06-03 00:39:03 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:39:03 [INFO]: Using the given device: cuda:0
2024-06-03 00:39:03 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_3/20240603_T003903
2024-06-03 00:39:03 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_3/20240603_T003903/tensorboard
2024-06-03 00:39:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,178,496
2024-06-03 00:39:05 [INFO]: Epoch 001 - training loss: 1.5597, validation loss: 1.0125
2024-06-03 00:39:06 [INFO]: Epoch 002 - training loss: 1.5030, validation loss: 1.0354
2024-06-03 00:39:07 [INFO]: Epoch 003 - training loss: 1.4905, validation loss: 1.0382
2024-06-03 00:39:08 [INFO]: Epoch 004 - training loss: 1.4754, validation loss: 1.0495
2024-06-03 00:39:09 [INFO]: Epoch 005 - training loss: 1.4323, validation loss: 0.9778
2024-06-03 00:39:10 [INFO]: Epoch 006 - training loss: 1.4158, validation loss: 0.9643
2024-06-03 00:39:12 [INFO]: Epoch 007 - training loss: 1.3750, validation loss: 0.9541
2024-06-03 00:39:13 [INFO]: Epoch 008 - training loss: 1.3418, validation loss: 0.9515
2024-06-03 00:39:14 [INFO]: Epoch 009 - training loss: 1.2881, validation loss: 0.9495
2024-06-03 00:39:15 [INFO]: Epoch 010 - training loss: 1.2484, validation loss: 0.9488
2024-06-03 00:39:16 [INFO]: Epoch 011 - training loss: 1.2144, validation loss: 0.9369
2024-06-03 00:39:17 [INFO]: Epoch 012 - training loss: 1.1983, validation loss: 0.9150
2024-06-03 00:39:18 [INFO]: Epoch 013 - training loss: 1.1850, validation loss: 0.9062
2024-06-03 00:39:19 [INFO]: Epoch 014 - training loss: 1.1608, validation loss: 0.8976
2024-06-03 00:39:21 [INFO]: Epoch 015 - training loss: 1.1493, validation loss: 0.8874
2024-06-03 00:39:22 [INFO]: Epoch 016 - training loss: 1.1260, validation loss: 0.8472
2024-06-03 00:39:23 [INFO]: Epoch 017 - training loss: 1.0861, validation loss: 0.8162
2024-06-03 00:39:24 [INFO]: Epoch 018 - training loss: 1.0813, validation loss: 0.8208
2024-06-03 00:39:25 [INFO]: Epoch 019 - training loss: 1.0745, validation loss: 0.8111
2024-06-03 00:39:26 [INFO]: Epoch 020 - training loss: 1.0419, validation loss: 0.7707
2024-06-03 00:39:27 [INFO]: Epoch 021 - training loss: 1.0372, validation loss: 0.7644
2024-06-03 00:39:29 [INFO]: Epoch 022 - training loss: 1.0223, validation loss: 0.7657
2024-06-03 00:39:30 [INFO]: Epoch 023 - training loss: 1.0054, validation loss: 0.7519
2024-06-03 00:39:31 [INFO]: Epoch 024 - training loss: 0.9975, validation loss: 0.7456
2024-06-03 00:39:32 [INFO]: Epoch 025 - training loss: 0.9913, validation loss: 0.7330
2024-06-03 00:39:33 [INFO]: Epoch 026 - training loss: 0.9778, validation loss: 0.7602
2024-06-03 00:39:34 [INFO]: Epoch 027 - training loss: 0.9683, validation loss: 0.7496
2024-06-03 00:39:35 [INFO]: Epoch 028 - training loss: 0.9602, validation loss: 0.7029
2024-06-03 00:39:36 [INFO]: Epoch 029 - training loss: 0.9491, validation loss: 0.7298
2024-06-03 00:39:38 [INFO]: Epoch 030 - training loss: 0.9581, validation loss: 0.7280
2024-06-03 00:39:39 [INFO]: Epoch 031 - training loss: 0.9409, validation loss: 0.6982
2024-06-03 00:39:40 [INFO]: Epoch 032 - training loss: 0.9207, validation loss: 0.6903
2024-06-03 00:39:41 [INFO]: Epoch 033 - training loss: 0.9117, validation loss: 0.7050
2024-06-03 00:39:42 [INFO]: Epoch 034 - training loss: 0.9016, validation loss: 0.6680
2024-06-03 00:39:43 [INFO]: Epoch 035 - training loss: 0.8942, validation loss: 0.6764
2024-06-03 00:39:44 [INFO]: Epoch 036 - training loss: 0.8851, validation loss: 0.6960
2024-06-03 00:39:46 [INFO]: Epoch 037 - training loss: 0.8805, validation loss: 0.6569
2024-06-03 00:39:47 [INFO]: Epoch 038 - training loss: 0.8623, validation loss: 0.6810
2024-06-03 00:39:48 [INFO]: Epoch 039 - training loss: 0.8673, validation loss: 0.6759
2024-06-03 00:39:49 [INFO]: Epoch 040 - training loss: 0.8481, validation loss: 0.6792
2024-06-03 00:39:50 [INFO]: Epoch 041 - training loss: 0.8244, validation loss: 0.6529
2024-06-03 00:39:51 [INFO]: Epoch 042 - training loss: 0.8122, validation loss: 0.6468
2024-06-03 00:39:52 [INFO]: Epoch 043 - training loss: 0.7970, validation loss: 0.6625
2024-06-03 00:39:53 [INFO]: Epoch 044 - training loss: 0.7933, validation loss: 0.6518
2024-06-03 00:39:55 [INFO]: Epoch 045 - training loss: 0.7932, validation loss: 0.6729
2024-06-03 00:39:56 [INFO]: Epoch 046 - training loss: 0.7893, validation loss: 0.6617
2024-06-03 00:39:57 [INFO]: Epoch 047 - training loss: 0.7880, validation loss: 0.6617
2024-06-03 00:39:58 [INFO]: Epoch 048 - training loss: 0.7696, validation loss: 0.6603
2024-06-03 00:39:59 [INFO]: Epoch 049 - training loss: 0.7622, validation loss: 0.6439
2024-06-03 00:40:00 [INFO]: Epoch 050 - training loss: 0.7696, validation loss: 0.6518
2024-06-03 00:40:01 [INFO]: Epoch 051 - training loss: 0.7788, validation loss: 0.6473
2024-06-03 00:40:02 [INFO]: Epoch 052 - training loss: 0.7673, validation loss: 0.6675
2024-06-03 00:40:04 [INFO]: Epoch 053 - training loss: 0.7620, validation loss: 0.6487
2024-06-03 00:40:05 [INFO]: Epoch 054 - training loss: 0.7527, validation loss: 0.6567
2024-06-03 00:40:06 [INFO]: Epoch 055 - training loss: 0.7326, validation loss: 0.6457
2024-06-03 00:40:07 [INFO]: Epoch 056 - training loss: 0.7028, validation loss: 0.6379
2024-06-03 00:40:08 [INFO]: Epoch 057 - training loss: 0.6874, validation loss: 0.6544
2024-06-03 00:40:09 [INFO]: Epoch 058 - training loss: 0.6790, validation loss: 0.6484
2024-06-03 00:40:10 [INFO]: Epoch 059 - training loss: 0.6826, validation loss: 0.6497
2024-06-03 00:40:11 [INFO]: Epoch 060 - training loss: 0.6636, validation loss: 0.6492
2024-06-03 00:40:13 [INFO]: Epoch 061 - training loss: 0.6488, validation loss: 0.6523
2024-06-03 00:40:14 [INFO]: Epoch 062 - training loss: 0.6442, validation loss: 0.6360
2024-06-03 00:40:15 [INFO]: Epoch 063 - training loss: 0.6312, validation loss: 0.6448
2024-06-03 00:40:16 [INFO]: Epoch 064 - training loss: 0.6247, validation loss: 0.6723
2024-06-03 00:40:17 [INFO]: Epoch 065 - training loss: 0.6312, validation loss: 0.6638
2024-06-03 00:40:18 [INFO]: Epoch 066 - training loss: 0.6166, validation loss: 0.6468
2024-06-03 00:40:19 [INFO]: Epoch 067 - training loss: 0.6096, validation loss: 0.6364
2024-06-03 00:40:21 [INFO]: Epoch 068 - training loss: 0.6001, validation loss: 0.6569
2024-06-03 00:40:22 [INFO]: Epoch 069 - training loss: 0.5949, validation loss: 0.6622
2024-06-03 00:40:23 [INFO]: Epoch 070 - training loss: 0.5744, validation loss: 0.6488
2024-06-03 00:40:24 [INFO]: Epoch 071 - training loss: 0.5626, validation loss: 0.6459
2024-06-03 00:40:25 [INFO]: Epoch 072 - training loss: 0.5504, validation loss: 0.6411
2024-06-03 00:40:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:40:25 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 00:40:25 [INFO]: Saved the model to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_3/20240603_T003903/BRITS.pypots
2024-06-03 00:40:26 [INFO]: Successfully saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_3/imputation.pkl
2024-06-03 00:40:26 [INFO]: Round3 - BRITS on ETT_h1: MAE=0.6247, MSE=0.7030, MRE=0.7352
2024-06-03 00:40:26 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:40:26 [INFO]: Using the given device: cuda:0
2024-06-03 00:40:26 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_4/20240603_T004026
2024-06-03 00:40:26 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_4/20240603_T004026/tensorboard
2024-06-03 00:40:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 2,178,496
2024-06-03 00:40:28 [INFO]: Epoch 001 - training loss: 1.7930, validation loss: 0.9987
2024-06-03 00:40:29 [INFO]: Epoch 002 - training loss: 1.5100, validation loss: 0.9923
2024-06-03 00:40:30 [INFO]: Epoch 003 - training loss: 1.4739, validation loss: 0.9919
2024-06-03 00:40:31 [INFO]: Epoch 004 - training loss: 1.4224, validation loss: 0.9544
2024-06-03 00:40:32 [INFO]: Epoch 005 - training loss: 1.3789, validation loss: 0.9613
2024-06-03 00:40:33 [INFO]: Epoch 006 - training loss: 1.3414, validation loss: 0.9390
2024-06-03 00:40:34 [INFO]: Epoch 007 - training loss: 1.3193, validation loss: 0.9533
2024-06-03 00:40:35 [INFO]: Epoch 008 - training loss: 1.2743, validation loss: 0.9438
2024-06-03 00:40:37 [INFO]: Epoch 009 - training loss: 1.2475, validation loss: 0.9346
2024-06-03 00:40:38 [INFO]: Epoch 010 - training loss: 1.2260, validation loss: 0.9358
2024-06-03 00:40:39 [INFO]: Epoch 011 - training loss: 1.2142, validation loss: 0.9280
2024-06-03 00:40:40 [INFO]: Epoch 012 - training loss: 1.1867, validation loss: 0.9112
2024-06-03 00:40:41 [INFO]: Epoch 013 - training loss: 1.1876, validation loss: 0.9101
2024-06-03 00:40:42 [INFO]: Epoch 014 - training loss: 1.1546, validation loss: 0.9035
2024-06-03 00:40:43 [INFO]: Epoch 015 - training loss: 1.1503, validation loss: 0.8710
2024-06-03 00:40:45 [INFO]: Epoch 016 - training loss: 1.1309, validation loss: 0.8514
2024-06-03 00:40:46 [INFO]: Epoch 017 - training loss: 1.1106, validation loss: 0.8465
2024-06-03 00:40:47 [INFO]: Epoch 018 - training loss: 1.1145, validation loss: 0.8347
2024-06-03 00:40:48 [INFO]: Epoch 019 - training loss: 1.0865, validation loss: 0.7973
2024-06-03 00:40:49 [INFO]: Epoch 020 - training loss: 1.0627, validation loss: 0.8010
2024-06-03 00:40:50 [INFO]: Epoch 021 - training loss: 1.0529, validation loss: 0.7887
2024-06-03 00:40:51 [INFO]: Epoch 022 - training loss: 1.0438, validation loss: 0.7842
2024-06-03 00:40:52 [INFO]: Epoch 023 - training loss: 1.0360, validation loss: 0.7364
2024-06-03 00:40:54 [INFO]: Epoch 024 - training loss: 1.0378, validation loss: 0.7299
2024-06-03 00:40:55 [INFO]: Epoch 025 - training loss: 1.0082, validation loss: 0.7343
2024-06-03 00:40:56 [INFO]: Epoch 026 - training loss: 0.9889, validation loss: 0.7045
2024-06-03 00:40:57 [INFO]: Epoch 027 - training loss: 0.9852, validation loss: 0.7134
2024-06-03 00:40:58 [INFO]: Epoch 028 - training loss: 0.9914, validation loss: 0.7128
2024-06-03 00:40:59 [INFO]: Epoch 029 - training loss: 0.9909, validation loss: 0.6712
2024-06-03 00:41:00 [INFO]: Epoch 030 - training loss: 0.9714, validation loss: 0.7212
2024-06-03 00:41:01 [INFO]: Epoch 031 - training loss: 0.9648, validation loss: 0.6831
2024-06-03 00:41:03 [INFO]: Epoch 032 - training loss: 0.9504, validation loss: 0.6739
2024-06-03 00:41:04 [INFO]: Epoch 033 - training loss: 0.9408, validation loss: 0.7128
2024-06-03 00:41:05 [INFO]: Epoch 034 - training loss: 0.9440, validation loss: 0.6615
2024-06-03 00:41:06 [INFO]: Epoch 035 - training loss: 0.9337, validation loss: 0.6799
2024-06-03 00:41:07 [INFO]: Epoch 036 - training loss: 0.9124, validation loss: 0.6684
2024-06-03 00:41:08 [INFO]: Epoch 037 - training loss: 0.9026, validation loss: 0.6398
2024-06-03 00:41:09 [INFO]: Epoch 038 - training loss: 0.8937, validation loss: 0.6558
2024-06-03 00:41:11 [INFO]: Epoch 039 - training loss: 0.8706, validation loss: 0.6516
2024-06-03 00:41:12 [INFO]: Epoch 040 - training loss: 0.8594, validation loss: 0.6420
2024-06-03 00:41:13 [INFO]: Epoch 041 - training loss: 0.8627, validation loss: 0.6460
2024-06-03 00:41:14 [INFO]: Epoch 042 - training loss: 0.8451, validation loss: 0.6190
2024-06-03 00:41:15 [INFO]: Epoch 043 - training loss: 0.8297, validation loss: 0.6140
2024-06-03 00:41:16 [INFO]: Epoch 044 - training loss: 0.8211, validation loss: 0.6092
2024-06-03 00:41:17 [INFO]: Epoch 045 - training loss: 0.8060, validation loss: 0.6266
2024-06-03 00:41:19 [INFO]: Epoch 046 - training loss: 0.8066, validation loss: 0.5958
2024-06-03 00:41:20 [INFO]: Epoch 047 - training loss: 0.8330, validation loss: 0.6149
2024-06-03 00:41:21 [INFO]: Epoch 048 - training loss: 0.7928, validation loss: 0.6247
2024-06-03 00:41:22 [INFO]: Epoch 049 - training loss: 0.7776, validation loss: 0.6023
2024-06-03 00:41:23 [INFO]: Epoch 050 - training loss: 0.7492, validation loss: 0.6039
2024-06-03 00:41:24 [INFO]: Epoch 051 - training loss: 0.7371, validation loss: 0.5955
2024-06-03 00:41:25 [INFO]: Epoch 052 - training loss: 0.7241, validation loss: 0.5838
2024-06-03 00:41:26 [INFO]: Epoch 053 - training loss: 0.7152, validation loss: 0.5868
2024-06-03 00:41:28 [INFO]: Epoch 054 - training loss: 0.7102, validation loss: 0.5972
2024-06-03 00:41:29 [INFO]: Epoch 055 - training loss: 0.6907, validation loss: 0.5978
2024-06-03 00:41:30 [INFO]: Epoch 056 - training loss: 0.6884, validation loss: 0.5969
2024-06-03 00:41:31 [INFO]: Epoch 057 - training loss: 0.6867, validation loss: 0.5860
2024-06-03 00:41:32 [INFO]: Epoch 058 - training loss: 0.6591, validation loss: 0.5980
2024-06-03 00:41:33 [INFO]: Epoch 059 - training loss: 0.6638, validation loss: 0.5841
2024-06-03 00:41:34 [INFO]: Epoch 060 - training loss: 0.6628, validation loss: 0.5978
2024-06-03 00:41:35 [INFO]: Epoch 061 - training loss: 0.6685, validation loss: 0.5864
2024-06-03 00:41:37 [INFO]: Epoch 062 - training loss: 0.6617, validation loss: 0.5957
2024-06-03 00:41:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:41:37 [INFO]: Finished training. The best model is from epoch#52.
2024-06-03 00:41:37 [INFO]: Saved the model to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_4/20240603_T004026/BRITS.pypots
2024-06-03 00:41:38 [INFO]: Successfully saved to results_point_rate09/ETT_h1/BRITS_ETT_h1/round_4/imputation.pkl
2024-06-03 00:41:38 [INFO]: Round4 - BRITS on ETT_h1: MAE=0.5960, MSE=0.6323, MRE=0.7014
2024-06-03 00:41:38 [INFO]: Done! Final results:
Averaged BRITS (2,178,496 params) on ETT_h1: MAE=0.6087 ± 0.01019618492876506, MSE=0.6671 ± 0.024725523322611822, MRE=0.7163 ± 0.011999773720208516, average inference time=0.73
