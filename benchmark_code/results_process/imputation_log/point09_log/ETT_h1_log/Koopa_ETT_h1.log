2024-06-03 00:41:52 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:41:52 [INFO]: Using the given device: cuda:0
2024-06-03 00:41:53 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_0/20240603_T004153
2024-06-03 00:41:53 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_0/20240603_T004153/tensorboard
2024-06-03 00:41:54 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 00:41:59 [INFO]: Epoch 001 - training loss: 3.8352, validation loss: 1.8843
2024-06-03 00:42:05 [INFO]: Epoch 002 - training loss: 1.8024, validation loss: 1.0792
2024-06-03 00:42:11 [INFO]: Epoch 003 - training loss: 1.6162, validation loss: 1.2271
2024-06-03 00:42:17 [INFO]: Epoch 004 - training loss: 1.5442, validation loss: 1.1156
2024-06-03 00:42:22 [INFO]: Epoch 005 - training loss: 1.5412, validation loss: 1.0790
2024-06-03 00:42:28 [INFO]: Epoch 006 - training loss: 1.5068, validation loss: 1.0081
2024-06-03 00:42:34 [INFO]: Epoch 007 - training loss: 1.4653, validation loss: 0.9511
2024-06-03 00:42:39 [INFO]: Epoch 008 - training loss: 1.3931, validation loss: 0.9571
2024-06-03 00:42:44 [INFO]: Epoch 009 - training loss: 1.3805, validation loss: 1.0089
2024-06-03 00:42:49 [INFO]: Epoch 010 - training loss: 1.3832, validation loss: 0.9364
2024-06-03 00:42:55 [INFO]: Epoch 011 - training loss: 1.3490, validation loss: 0.8654
2024-06-03 00:43:01 [INFO]: Epoch 012 - training loss: 1.3046, validation loss: 0.8670
2024-06-03 00:43:07 [INFO]: Epoch 013 - training loss: 1.2837, validation loss: 0.8413
2024-06-03 00:43:13 [INFO]: Epoch 014 - training loss: 1.2435, validation loss: 0.7885
2024-06-03 00:43:18 [INFO]: Epoch 015 - training loss: 1.1949, validation loss: 0.9424
2024-06-03 00:43:22 [INFO]: Epoch 016 - training loss: 1.1196, validation loss: 0.9044
2024-06-03 00:43:27 [INFO]: Epoch 017 - training loss: 1.0126, validation loss: 0.7263
2024-06-03 00:43:32 [INFO]: Epoch 018 - training loss: 1.0124, validation loss: 0.7485
2024-06-03 00:43:36 [INFO]: Epoch 019 - training loss: 0.9370, validation loss: 0.6414
2024-06-03 00:43:40 [INFO]: Epoch 020 - training loss: 0.9510, validation loss: 0.6106
2024-06-03 00:43:43 [INFO]: Epoch 021 - training loss: 0.9003, validation loss: 0.5924
2024-06-03 00:43:48 [INFO]: Epoch 022 - training loss: 0.8770, validation loss: 0.5471
2024-06-03 00:43:53 [INFO]: Epoch 023 - training loss: 0.8584, validation loss: 0.5114
2024-06-03 00:43:58 [INFO]: Epoch 024 - training loss: 0.8891, validation loss: 0.5929
2024-06-03 00:44:01 [INFO]: Epoch 025 - training loss: 0.8856, validation loss: 0.4747
2024-06-03 00:44:03 [INFO]: Epoch 026 - training loss: 0.8371, validation loss: 0.6077
2024-06-03 00:44:08 [INFO]: Epoch 027 - training loss: 0.9493, validation loss: 0.5083
2024-06-03 00:44:12 [INFO]: Epoch 028 - training loss: 0.8480, validation loss: 0.4601
2024-06-03 00:44:16 [INFO]: Epoch 029 - training loss: 0.8296, validation loss: 0.4751
2024-06-03 00:44:19 [INFO]: Epoch 030 - training loss: 0.8522, validation loss: 0.5041
2024-06-03 00:44:21 [INFO]: Epoch 031 - training loss: 0.8450, validation loss: 0.4970
2024-06-03 00:44:24 [INFO]: Epoch 032 - training loss: 0.8431, validation loss: 0.4815
2024-06-03 00:44:27 [INFO]: Epoch 033 - training loss: 0.8364, validation loss: 0.4528
2024-06-03 00:44:29 [INFO]: Epoch 034 - training loss: 0.8179, validation loss: 0.4788
2024-06-03 00:44:32 [INFO]: Epoch 035 - training loss: 0.8141, validation loss: 0.4496
2024-06-03 00:44:33 [INFO]: Epoch 036 - training loss: 0.7942, validation loss: 0.4624
2024-06-03 00:44:36 [INFO]: Epoch 037 - training loss: 0.8144, validation loss: 0.4887
2024-06-03 00:44:38 [INFO]: Epoch 038 - training loss: 0.8086, validation loss: 0.4678
2024-06-03 00:44:41 [INFO]: Epoch 039 - training loss: 0.8072, validation loss: 0.5190
2024-06-03 00:44:43 [INFO]: Epoch 040 - training loss: 0.7963, validation loss: 0.5128
2024-06-03 00:44:44 [INFO]: Epoch 041 - training loss: 0.8076, validation loss: 0.4727
2024-06-03 00:44:45 [INFO]: Epoch 042 - training loss: 0.7977, validation loss: 0.4798
2024-06-03 00:44:47 [INFO]: Epoch 043 - training loss: 0.8061, validation loss: 0.4795
2024-06-03 00:44:48 [INFO]: Epoch 044 - training loss: 0.7871, validation loss: 0.4841
2024-06-03 00:44:50 [INFO]: Epoch 045 - training loss: 0.7855, validation loss: 0.4855
2024-06-03 00:44:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:44:50 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 00:44:50 [INFO]: Saved the model to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_0/20240603_T004153/Koopa.pypots
2024-06-03 00:44:50 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_0/imputation.pkl
2024-06-03 00:44:50 [INFO]: Round0 - Koopa on ETT_h1: MAE=0.5605, MSE=0.5909, MRE=0.6597
2024-06-03 00:44:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:44:50 [INFO]: Using the given device: cuda:0
2024-06-03 00:44:50 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_1/20240603_T004450
2024-06-03 00:44:50 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_1/20240603_T004450/tensorboard
2024-06-03 00:44:50 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 00:44:51 [INFO]: Epoch 001 - training loss: 4.7065, validation loss: 2.4077
2024-06-03 00:44:51 [INFO]: Epoch 002 - training loss: 2.0785, validation loss: 1.4313
2024-06-03 00:44:52 [INFO]: Epoch 003 - training loss: 1.6175, validation loss: 1.1227
2024-06-03 00:44:52 [INFO]: Epoch 004 - training loss: 1.5054, validation loss: 1.0657
2024-06-03 00:44:53 [INFO]: Epoch 005 - training loss: 1.4976, validation loss: 1.0765
2024-06-03 00:44:53 [INFO]: Epoch 006 - training loss: 1.4739, validation loss: 0.9823
2024-06-03 00:44:53 [INFO]: Epoch 007 - training loss: 1.4103, validation loss: 0.9748
2024-06-03 00:44:54 [INFO]: Epoch 008 - training loss: 1.3530, validation loss: 1.0451
2024-06-03 00:44:54 [INFO]: Epoch 009 - training loss: 1.2531, validation loss: 0.9475
2024-06-03 00:44:54 [INFO]: Epoch 010 - training loss: 1.1846, validation loss: 0.8433
2024-06-03 00:44:55 [INFO]: Epoch 011 - training loss: 1.1333, validation loss: 0.9058
2024-06-03 00:44:55 [INFO]: Epoch 012 - training loss: 1.0785, validation loss: 0.8461
2024-06-03 00:44:56 [INFO]: Epoch 013 - training loss: 1.0814, validation loss: 0.8766
2024-06-03 00:44:56 [INFO]: Epoch 014 - training loss: 0.9863, validation loss: 0.8375
2024-06-03 00:44:56 [INFO]: Epoch 015 - training loss: 1.0125, validation loss: 0.8733
2024-06-03 00:44:57 [INFO]: Epoch 016 - training loss: 1.0091, validation loss: 0.8080
2024-06-03 00:44:57 [INFO]: Epoch 017 - training loss: 0.9814, validation loss: 0.8600
2024-06-03 00:44:58 [INFO]: Epoch 018 - training loss: 0.9653, validation loss: 0.8506
2024-06-03 00:44:58 [INFO]: Epoch 019 - training loss: 0.9625, validation loss: 0.7917
2024-06-03 00:44:58 [INFO]: Epoch 020 - training loss: 0.9566, validation loss: 0.7271
2024-06-03 00:44:59 [INFO]: Epoch 021 - training loss: 0.9289, validation loss: 0.8165
2024-06-03 00:44:59 [INFO]: Epoch 022 - training loss: 0.9218, validation loss: 0.8071
2024-06-03 00:44:59 [INFO]: Epoch 023 - training loss: 0.8988, validation loss: 0.7951
2024-06-03 00:45:00 [INFO]: Epoch 024 - training loss: 0.9110, validation loss: 0.7890
2024-06-03 00:45:00 [INFO]: Epoch 025 - training loss: 0.9364, validation loss: 0.8850
2024-06-03 00:45:00 [INFO]: Epoch 026 - training loss: 0.9149, validation loss: 0.8763
2024-06-03 00:45:01 [INFO]: Epoch 027 - training loss: 0.9077, validation loss: 0.8447
2024-06-03 00:45:01 [INFO]: Epoch 028 - training loss: 0.9299, validation loss: 0.8351
2024-06-03 00:45:02 [INFO]: Epoch 029 - training loss: 0.9510, validation loss: 0.8007
2024-06-03 00:45:02 [INFO]: Epoch 030 - training loss: 0.9159, validation loss: 0.8604
2024-06-03 00:45:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:45:02 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 00:45:02 [INFO]: Saved the model to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_1/20240603_T004450/Koopa.pypots
2024-06-03 00:45:02 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_1/imputation.pkl
2024-06-03 00:45:02 [INFO]: Round1 - Koopa on ETT_h1: MAE=0.7283, MSE=1.0773, MRE=0.8571
2024-06-03 00:45:02 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:45:02 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:02 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_2/20240603_T004502
2024-06-03 00:45:02 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_2/20240603_T004502/tensorboard
2024-06-03 00:45:02 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 00:45:02 [INFO]: Epoch 001 - training loss: 3.5006, validation loss: 1.2403
2024-06-03 00:45:03 [INFO]: Epoch 002 - training loss: 1.6733, validation loss: 1.1584
2024-06-03 00:45:03 [INFO]: Epoch 003 - training loss: 1.5751, validation loss: 1.0078
2024-06-03 00:45:04 [INFO]: Epoch 004 - training loss: 1.4986, validation loss: 0.9777
2024-06-03 00:45:04 [INFO]: Epoch 005 - training loss: 1.4487, validation loss: 1.0063
2024-06-03 00:45:04 [INFO]: Epoch 006 - training loss: 1.4109, validation loss: 1.0487
2024-06-03 00:45:05 [INFO]: Epoch 007 - training loss: 1.2933, validation loss: 1.0519
2024-06-03 00:45:05 [INFO]: Epoch 008 - training loss: 1.2207, validation loss: 1.0322
2024-06-03 00:45:05 [INFO]: Epoch 009 - training loss: 1.1429, validation loss: 1.0856
2024-06-03 00:45:06 [INFO]: Epoch 010 - training loss: 1.1046, validation loss: 0.9023
2024-06-03 00:45:06 [INFO]: Epoch 011 - training loss: 1.0886, validation loss: 0.7895
2024-06-03 00:45:06 [INFO]: Epoch 012 - training loss: 1.0300, validation loss: 0.8815
2024-06-03 00:45:07 [INFO]: Epoch 013 - training loss: 1.0110, validation loss: 0.8620
2024-06-03 00:45:07 [INFO]: Epoch 014 - training loss: 1.0233, validation loss: 0.7718
2024-06-03 00:45:08 [INFO]: Epoch 015 - training loss: 0.9660, validation loss: 0.7915
2024-06-03 00:45:08 [INFO]: Epoch 016 - training loss: 0.9819, validation loss: 0.7842
2024-06-03 00:45:08 [INFO]: Epoch 017 - training loss: 0.9801, validation loss: 0.8088
2024-06-03 00:45:09 [INFO]: Epoch 018 - training loss: 0.9720, validation loss: 0.7773
2024-06-03 00:45:09 [INFO]: Epoch 019 - training loss: 0.9294, validation loss: 0.8191
2024-06-03 00:45:09 [INFO]: Epoch 020 - training loss: 0.9191, validation loss: 0.7972
2024-06-03 00:45:10 [INFO]: Epoch 021 - training loss: 0.9328, validation loss: 0.8052
2024-06-03 00:45:10 [INFO]: Epoch 022 - training loss: 0.9274, validation loss: 0.6626
2024-06-03 00:45:10 [INFO]: Epoch 023 - training loss: 0.9276, validation loss: 0.7466
2024-06-03 00:45:11 [INFO]: Epoch 024 - training loss: 0.8978, validation loss: 0.7292
2024-06-03 00:45:11 [INFO]: Epoch 025 - training loss: 0.8936, validation loss: 0.7681
2024-06-03 00:45:12 [INFO]: Epoch 026 - training loss: 0.8993, validation loss: 0.7194
2024-06-03 00:45:12 [INFO]: Epoch 027 - training loss: 0.8729, validation loss: 0.7191
2024-06-03 00:45:12 [INFO]: Epoch 028 - training loss: 0.8778, validation loss: 0.6645
2024-06-03 00:45:13 [INFO]: Epoch 029 - training loss: 0.8694, validation loss: 0.7317
2024-06-03 00:45:13 [INFO]: Epoch 030 - training loss: 0.8676, validation loss: 0.7499
2024-06-03 00:45:13 [INFO]: Epoch 031 - training loss: 0.8340, validation loss: 0.6323
2024-06-03 00:45:14 [INFO]: Epoch 032 - training loss: 0.8475, validation loss: 0.6909
2024-06-03 00:45:14 [INFO]: Epoch 033 - training loss: 0.8570, validation loss: 0.7879
2024-06-03 00:45:15 [INFO]: Epoch 034 - training loss: 0.8651, validation loss: 0.7404
2024-06-03 00:45:15 [INFO]: Epoch 035 - training loss: 0.8499, validation loss: 0.7158
2024-06-03 00:45:15 [INFO]: Epoch 036 - training loss: 0.8284, validation loss: 0.6864
2024-06-03 00:45:16 [INFO]: Epoch 037 - training loss: 0.8382, validation loss: 0.6539
2024-06-03 00:45:16 [INFO]: Epoch 038 - training loss: 0.8373, validation loss: 0.6774
2024-06-03 00:45:16 [INFO]: Epoch 039 - training loss: 0.8638, validation loss: 0.7820
2024-06-03 00:45:17 [INFO]: Epoch 040 - training loss: 0.8393, validation loss: 0.8464
2024-06-03 00:45:17 [INFO]: Epoch 041 - training loss: 0.8539, validation loss: 0.6723
2024-06-03 00:45:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:45:17 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 00:45:17 [INFO]: Saved the model to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_2/20240603_T004502/Koopa.pypots
2024-06-03 00:45:17 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_2/imputation.pkl
2024-06-03 00:45:17 [INFO]: Round2 - Koopa on ETT_h1: MAE=0.6421, MSE=0.7522, MRE=0.7557
2024-06-03 00:45:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:45:17 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:17 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_3/20240603_T004517
2024-06-03 00:45:17 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_3/20240603_T004517/tensorboard
2024-06-03 00:45:17 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 00:45:18 [INFO]: Epoch 001 - training loss: 4.4385, validation loss: 1.9706
2024-06-03 00:45:18 [INFO]: Epoch 002 - training loss: 1.8578, validation loss: 1.1020
2024-06-03 00:45:18 [INFO]: Epoch 003 - training loss: 1.5836, validation loss: 1.0503
2024-06-03 00:45:19 [INFO]: Epoch 004 - training loss: 1.5175, validation loss: 1.0204
2024-06-03 00:45:19 [INFO]: Epoch 005 - training loss: 1.4503, validation loss: 0.9921
2024-06-03 00:45:19 [INFO]: Epoch 006 - training loss: 1.4531, validation loss: 0.9559
2024-06-03 00:45:20 [INFO]: Epoch 007 - training loss: 1.4388, validation loss: 0.9570
2024-06-03 00:45:20 [INFO]: Epoch 008 - training loss: 1.4502, validation loss: 1.0042
2024-06-03 00:45:20 [INFO]: Epoch 009 - training loss: 1.3802, validation loss: 1.0155
2024-06-03 00:45:21 [INFO]: Epoch 010 - training loss: 1.3620, validation loss: 1.4083
2024-06-03 00:45:21 [INFO]: Epoch 011 - training loss: 1.4154, validation loss: 0.9476
2024-06-03 00:45:22 [INFO]: Epoch 012 - training loss: 1.2547, validation loss: 0.8970
2024-06-03 00:45:22 [INFO]: Epoch 013 - training loss: 1.1891, validation loss: 0.8844
2024-06-03 00:45:22 [INFO]: Epoch 014 - training loss: 1.1316, validation loss: 0.8142
2024-06-03 00:45:23 [INFO]: Epoch 015 - training loss: 1.0841, validation loss: 0.7726
2024-06-03 00:45:23 [INFO]: Epoch 016 - training loss: 1.0361, validation loss: 0.6784
2024-06-03 00:45:23 [INFO]: Epoch 017 - training loss: 0.9810, validation loss: 0.6822
2024-06-03 00:45:24 [INFO]: Epoch 018 - training loss: 0.9382, validation loss: 0.6391
2024-06-03 00:45:24 [INFO]: Epoch 019 - training loss: 0.9319, validation loss: 0.5461
2024-06-03 00:45:25 [INFO]: Epoch 020 - training loss: 0.8675, validation loss: 0.6713
2024-06-03 00:45:25 [INFO]: Epoch 021 - training loss: 0.9042, validation loss: 0.4774
2024-06-03 00:45:25 [INFO]: Epoch 022 - training loss: 0.8812, validation loss: 0.4587
2024-06-03 00:45:26 [INFO]: Epoch 023 - training loss: 0.8551, validation loss: 0.4773
2024-06-03 00:45:26 [INFO]: Epoch 024 - training loss: 0.8456, validation loss: 0.4906
2024-06-03 00:45:26 [INFO]: Epoch 025 - training loss: 0.8727, validation loss: 0.4727
2024-06-03 00:45:27 [INFO]: Epoch 026 - training loss: 0.8254, validation loss: 0.4387
2024-06-03 00:45:27 [INFO]: Epoch 027 - training loss: 0.8251, validation loss: 0.4506
2024-06-03 00:45:27 [INFO]: Epoch 028 - training loss: 0.8304, validation loss: 0.4803
2024-06-03 00:45:28 [INFO]: Epoch 029 - training loss: 0.8373, validation loss: 0.4329
2024-06-03 00:45:28 [INFO]: Epoch 030 - training loss: 0.8275, validation loss: 0.4528
2024-06-03 00:45:29 [INFO]: Epoch 031 - training loss: 0.7860, validation loss: 0.4461
2024-06-03 00:45:29 [INFO]: Epoch 032 - training loss: 0.7836, validation loss: 0.5021
2024-06-03 00:45:29 [INFO]: Epoch 033 - training loss: 0.7988, validation loss: 0.4614
2024-06-03 00:45:30 [INFO]: Epoch 034 - training loss: 0.7646, validation loss: 0.4641
2024-06-03 00:45:30 [INFO]: Epoch 035 - training loss: 0.7679, validation loss: 0.4695
2024-06-03 00:45:30 [INFO]: Epoch 036 - training loss: 0.7687, validation loss: 0.4507
2024-06-03 00:45:31 [INFO]: Epoch 037 - training loss: 0.7429, validation loss: 0.4237
2024-06-03 00:45:31 [INFO]: Epoch 038 - training loss: 0.7526, validation loss: 0.4138
2024-06-03 00:45:31 [INFO]: Epoch 039 - training loss: 0.7814, validation loss: 0.4893
2024-06-03 00:45:32 [INFO]: Epoch 040 - training loss: 0.7791, validation loss: 0.4363
2024-06-03 00:45:32 [INFO]: Epoch 041 - training loss: 0.7712, validation loss: 0.4468
2024-06-03 00:45:33 [INFO]: Epoch 042 - training loss: 0.7463, validation loss: 0.4176
2024-06-03 00:45:33 [INFO]: Epoch 043 - training loss: 0.7420, validation loss: 0.4268
2024-06-03 00:45:33 [INFO]: Epoch 044 - training loss: 0.7442, validation loss: 0.4590
2024-06-03 00:45:34 [INFO]: Epoch 045 - training loss: 0.7629, validation loss: 0.4715
2024-06-03 00:45:34 [INFO]: Epoch 046 - training loss: 0.7430, validation loss: 0.4410
2024-06-03 00:45:34 [INFO]: Epoch 047 - training loss: 0.7433, validation loss: 0.4341
2024-06-03 00:45:35 [INFO]: Epoch 048 - training loss: 0.7686, validation loss: 0.4142
2024-06-03 00:45:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:45:35 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 00:45:35 [INFO]: Saved the model to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_3/20240603_T004517/Koopa.pypots
2024-06-03 00:45:35 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_3/imputation.pkl
2024-06-03 00:45:35 [INFO]: Round3 - Koopa on ETT_h1: MAE=0.5207, MSE=0.5313, MRE=0.6128
2024-06-03 00:45:35 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:45:35 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:35 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_4/20240603_T004535
2024-06-03 00:45:35 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_4/20240603_T004535/tensorboard
2024-06-03 00:45:35 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 00:45:35 [INFO]: Epoch 001 - training loss: 4.2910, validation loss: 1.8315
2024-06-03 00:45:36 [INFO]: Epoch 002 - training loss: 1.8175, validation loss: 1.3231
2024-06-03 00:45:36 [INFO]: Epoch 003 - training loss: 1.5904, validation loss: 1.0045
2024-06-03 00:45:36 [INFO]: Epoch 004 - training loss: 1.5547, validation loss: 1.1076
2024-06-03 00:45:37 [INFO]: Epoch 005 - training loss: 1.4960, validation loss: 1.0319
2024-06-03 00:45:37 [INFO]: Epoch 006 - training loss: 1.4787, validation loss: 0.9717
2024-06-03 00:45:37 [INFO]: Epoch 007 - training loss: 1.4569, validation loss: 0.9474
2024-06-03 00:45:38 [INFO]: Epoch 008 - training loss: 1.4175, validation loss: 0.9365
2024-06-03 00:45:38 [INFO]: Epoch 009 - training loss: 1.3915, validation loss: 0.9268
2024-06-03 00:45:39 [INFO]: Epoch 010 - training loss: 1.3335, validation loss: 0.9720
2024-06-03 00:45:39 [INFO]: Epoch 011 - training loss: 1.2865, validation loss: 0.9419
2024-06-03 00:45:39 [INFO]: Epoch 012 - training loss: 1.2336, validation loss: 0.9257
2024-06-03 00:45:40 [INFO]: Epoch 013 - training loss: 1.1630, validation loss: 0.8790
2024-06-03 00:45:40 [INFO]: Epoch 014 - training loss: 1.1300, validation loss: 0.8021
2024-06-03 00:45:40 [INFO]: Epoch 015 - training loss: 1.0965, validation loss: 0.8040
2024-06-03 00:45:41 [INFO]: Epoch 016 - training loss: 1.0738, validation loss: 0.7714
2024-06-03 00:45:41 [INFO]: Epoch 017 - training loss: 1.0455, validation loss: 0.7402
2024-06-03 00:45:41 [INFO]: Epoch 018 - training loss: 1.0383, validation loss: 0.7419
2024-06-03 00:45:42 [INFO]: Epoch 019 - training loss: 1.0812, validation loss: 0.7716
2024-06-03 00:45:42 [INFO]: Epoch 020 - training loss: 1.0436, validation loss: 0.7709
2024-06-03 00:45:43 [INFO]: Epoch 021 - training loss: 0.9817, validation loss: 0.6709
2024-06-03 00:45:43 [INFO]: Epoch 022 - training loss: 0.9651, validation loss: 0.7047
2024-06-03 00:45:43 [INFO]: Epoch 023 - training loss: 0.9619, validation loss: 0.5874
2024-06-03 00:45:44 [INFO]: Epoch 024 - training loss: 0.9170, validation loss: 0.6455
2024-06-03 00:45:44 [INFO]: Epoch 025 - training loss: 0.9175, validation loss: 0.6394
2024-06-03 00:45:44 [INFO]: Epoch 026 - training loss: 0.9147, validation loss: 0.6253
2024-06-03 00:45:45 [INFO]: Epoch 027 - training loss: 0.9483, validation loss: 0.6454
2024-06-03 00:45:45 [INFO]: Epoch 028 - training loss: 0.8811, validation loss: 0.5904
2024-06-03 00:45:45 [INFO]: Epoch 029 - training loss: 0.8907, validation loss: 0.6213
2024-06-03 00:45:46 [INFO]: Epoch 030 - training loss: 0.8814, validation loss: 0.5722
2024-06-03 00:45:46 [INFO]: Epoch 031 - training loss: 0.8700, validation loss: 0.6262
2024-06-03 00:45:47 [INFO]: Epoch 032 - training loss: 0.8586, validation loss: 0.6214
2024-06-03 00:45:47 [INFO]: Epoch 033 - training loss: 0.8476, validation loss: 0.6265
2024-06-03 00:45:47 [INFO]: Epoch 034 - training loss: 0.8282, validation loss: 0.6485
2024-06-03 00:45:48 [INFO]: Epoch 035 - training loss: 0.8289, validation loss: 0.6010
2024-06-03 00:45:48 [INFO]: Epoch 036 - training loss: 0.8304, validation loss: 0.6006
2024-06-03 00:45:48 [INFO]: Epoch 037 - training loss: 0.8159, validation loss: 0.5921
2024-06-03 00:45:49 [INFO]: Epoch 038 - training loss: 0.8290, validation loss: 0.5771
2024-06-03 00:45:49 [INFO]: Epoch 039 - training loss: 0.8197, validation loss: 0.5854
2024-06-03 00:45:49 [INFO]: Epoch 040 - training loss: 0.8166, validation loss: 0.5914
2024-06-03 00:45:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:45:49 [INFO]: Finished training. The best model is from epoch#30.
2024-06-03 00:45:49 [INFO]: Saved the model to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_4/20240603_T004535/Koopa.pypots
2024-06-03 00:45:50 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Koopa_ETT_h1/round_4/imputation.pkl
2024-06-03 00:45:50 [INFO]: Round4 - Koopa on ETT_h1: MAE=0.5957, MSE=0.6468, MRE=0.7011
2024-06-03 00:45:50 [INFO]: Done! Final results:
Averaged Koopa (465,389 params) on ETT_h1: MAE=0.6095 ± 0.07163891393144811, MSE=0.7197 ± 0.19303046573076324, MRE=0.7173 ± 0.08431102051843571, average inference time=0.02
