2024-06-03 00:25:10 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:25:10 [INFO]: Using the given device: cuda:0
2024-06-03 00:25:10 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_0/20240603_T002510
2024-06-03 00:25:10 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_0/20240603_T002510/tensorboard
2024-06-03 00:25:10 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-03 00:25:24 [INFO]: Epoch 001 - training loss: 0.7477, validation loss: 0.5448
2024-06-03 00:25:30 [INFO]: Epoch 002 - training loss: 0.5283, validation loss: 0.5002
2024-06-03 00:25:36 [INFO]: Epoch 003 - training loss: 0.5402, validation loss: 0.4769
2024-06-03 00:25:42 [INFO]: Epoch 004 - training loss: 0.4386, validation loss: 0.4219
2024-06-03 00:25:48 [INFO]: Epoch 005 - training loss: 0.3717, validation loss: 0.4633
2024-06-03 00:25:54 [INFO]: Epoch 006 - training loss: 0.3982, validation loss: 0.4019
2024-06-03 00:26:00 [INFO]: Epoch 007 - training loss: 0.3778, validation loss: 0.4090
2024-06-03 00:26:06 [INFO]: Epoch 008 - training loss: 0.3712, validation loss: 0.4157
2024-06-03 00:26:12 [INFO]: Epoch 009 - training loss: 0.4218, validation loss: 0.4108
2024-06-03 00:26:19 [INFO]: Epoch 010 - training loss: 0.4197, validation loss: 0.4040
2024-06-03 00:26:25 [INFO]: Epoch 011 - training loss: 0.3978, validation loss: 0.4420
2024-06-03 00:26:31 [INFO]: Epoch 012 - training loss: 0.4302, validation loss: 0.3908
2024-06-03 00:26:38 [INFO]: Epoch 013 - training loss: 0.3401, validation loss: 0.3977
2024-06-03 00:26:44 [INFO]: Epoch 014 - training loss: 0.3981, validation loss: 0.3953
2024-06-03 00:26:50 [INFO]: Epoch 015 - training loss: 0.4494, validation loss: 0.3931
2024-06-03 00:26:56 [INFO]: Epoch 016 - training loss: 0.4336, validation loss: 0.3920
2024-06-03 00:27:01 [INFO]: Epoch 017 - training loss: 0.4229, validation loss: 0.3975
2024-06-03 00:27:05 [INFO]: Epoch 018 - training loss: 0.4375, validation loss: 0.3929
2024-06-03 00:27:10 [INFO]: Epoch 019 - training loss: 0.3807, validation loss: 0.4022
2024-06-03 00:27:15 [INFO]: Epoch 020 - training loss: 0.4301, validation loss: 0.3806
2024-06-03 00:27:20 [INFO]: Epoch 021 - training loss: 0.4014, validation loss: 0.3954
2024-06-03 00:27:24 [INFO]: Epoch 022 - training loss: 0.4244, validation loss: 0.3938
2024-06-03 00:27:29 [INFO]: Epoch 023 - training loss: 0.3882, validation loss: 0.4189
2024-06-03 00:27:32 [INFO]: Epoch 024 - training loss: 0.4455, validation loss: 0.3863
2024-06-03 00:27:35 [INFO]: Epoch 025 - training loss: 0.3939, validation loss: 0.3969
2024-06-03 00:27:37 [INFO]: Epoch 026 - training loss: 0.3201, validation loss: 0.3748
2024-06-03 00:27:40 [INFO]: Epoch 027 - training loss: 0.4515, validation loss: 0.3975
2024-06-03 00:27:43 [INFO]: Epoch 028 - training loss: 0.2946, validation loss: 0.3631
2024-06-03 00:27:46 [INFO]: Epoch 029 - training loss: 0.3753, validation loss: 0.3651
2024-06-03 00:27:49 [INFO]: Epoch 030 - training loss: 0.3169, validation loss: 0.3613
2024-06-03 00:27:51 [INFO]: Epoch 031 - training loss: 0.3246, validation loss: 0.3518
2024-06-03 00:27:55 [INFO]: Epoch 032 - training loss: 0.3337, validation loss: 0.3755
2024-06-03 00:27:57 [INFO]: Epoch 033 - training loss: 0.2813, validation loss: 0.3517
2024-06-03 00:28:00 [INFO]: Epoch 034 - training loss: 0.3480, validation loss: 0.3686
2024-06-03 00:28:03 [INFO]: Epoch 035 - training loss: 0.3912, validation loss: 0.3548
2024-06-03 00:28:06 [INFO]: Epoch 036 - training loss: 0.3664, validation loss: 0.3448
2024-06-03 00:28:09 [INFO]: Epoch 037 - training loss: 0.3226, validation loss: 0.3541
2024-06-03 00:28:11 [INFO]: Epoch 038 - training loss: 0.3039, validation loss: 0.3462
2024-06-03 00:28:14 [INFO]: Epoch 039 - training loss: 0.3350, validation loss: 0.3307
2024-06-03 00:28:15 [INFO]: Epoch 040 - training loss: 0.3215, validation loss: 0.3342
2024-06-03 00:28:17 [INFO]: Epoch 041 - training loss: 0.4027, validation loss: 0.3712
2024-06-03 00:28:19 [INFO]: Epoch 042 - training loss: 0.3867, validation loss: 0.3424
2024-06-03 00:28:21 [INFO]: Epoch 043 - training loss: 0.3376, validation loss: 0.3370
2024-06-03 00:28:23 [INFO]: Epoch 044 - training loss: 0.3849, validation loss: 0.3416
2024-06-03 00:28:24 [INFO]: Epoch 045 - training loss: 0.3371, validation loss: 0.3299
2024-06-03 00:28:26 [INFO]: Epoch 046 - training loss: 0.3564, validation loss: 0.3344
2024-06-03 00:28:27 [INFO]: Epoch 047 - training loss: 0.3772, validation loss: 0.3420
2024-06-03 00:28:28 [INFO]: Epoch 048 - training loss: 0.3829, validation loss: 0.3240
2024-06-03 00:28:30 [INFO]: Epoch 049 - training loss: 0.3774, validation loss: 0.3333
2024-06-03 00:28:31 [INFO]: Epoch 050 - training loss: 0.3883, validation loss: 0.3622
2024-06-03 00:28:32 [INFO]: Epoch 051 - training loss: 0.3462, validation loss: 0.3285
2024-06-03 00:28:34 [INFO]: Epoch 052 - training loss: 0.4228, validation loss: 0.3287
2024-06-03 00:28:35 [INFO]: Epoch 053 - training loss: 0.3221, validation loss: 0.3350
2024-06-03 00:28:36 [INFO]: Epoch 054 - training loss: 0.3774, validation loss: 0.3409
2024-06-03 00:28:37 [INFO]: Epoch 055 - training loss: 0.2669, validation loss: 0.3371
2024-06-03 00:28:39 [INFO]: Epoch 056 - training loss: 0.3756, validation loss: 0.3275
2024-06-03 00:28:40 [INFO]: Epoch 057 - training loss: 0.3427, validation loss: 0.3477
2024-06-03 00:28:41 [INFO]: Epoch 058 - training loss: 0.3348, validation loss: 0.3340
2024-06-03 00:28:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:28:41 [INFO]: Finished training. The best model is from epoch#48.
2024-06-03 00:28:41 [INFO]: Saved the model to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_0/20240603_T002510/CSDI.pypots
2024-06-03 00:29:25 [INFO]: Successfully saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_0/imputation.pkl
2024-06-03 00:29:25 [INFO]: Round0 - CSDI on ETT_h1: MAE=0.6566, MSE=1.0610, MRE=0.7727
2024-06-03 00:29:25 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:29:25 [INFO]: Using the given device: cuda:0
2024-06-03 00:29:25 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_1/20240603_T002925
2024-06-03 00:29:25 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_1/20240603_T002925/tensorboard
2024-06-03 00:29:25 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-03 00:29:26 [INFO]: Epoch 001 - training loss: 0.7753, validation loss: 0.5206
2024-06-03 00:29:27 [INFO]: Epoch 002 - training loss: 0.5076, validation loss: 0.5217
2024-06-03 00:29:29 [INFO]: Epoch 003 - training loss: 0.4924, validation loss: 0.5011
2024-06-03 00:29:30 [INFO]: Epoch 004 - training loss: 0.4617, validation loss: 0.4716
2024-06-03 00:29:31 [INFO]: Epoch 005 - training loss: 0.4377, validation loss: 0.4556
2024-06-03 00:29:33 [INFO]: Epoch 006 - training loss: 0.3847, validation loss: 0.4111
2024-06-03 00:29:34 [INFO]: Epoch 007 - training loss: 0.4410, validation loss: 0.4018
2024-06-03 00:29:35 [INFO]: Epoch 008 - training loss: 0.4259, validation loss: 0.3961
2024-06-03 00:29:36 [INFO]: Epoch 009 - training loss: 0.3792, validation loss: 0.3988
2024-06-03 00:29:38 [INFO]: Epoch 010 - training loss: 0.3684, validation loss: 0.4102
2024-06-03 00:29:39 [INFO]: Epoch 011 - training loss: 0.4087, validation loss: 0.4417
2024-06-03 00:29:40 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.4014
2024-06-03 00:29:42 [INFO]: Epoch 013 - training loss: 0.4162, validation loss: 0.3870
2024-06-03 00:29:43 [INFO]: Epoch 014 - training loss: 0.3669, validation loss: 0.4011
2024-06-03 00:29:44 [INFO]: Epoch 015 - training loss: 0.3453, validation loss: 0.3746
2024-06-03 00:29:45 [INFO]: Epoch 016 - training loss: 0.3796, validation loss: 0.3778
2024-06-03 00:29:47 [INFO]: Epoch 017 - training loss: 0.4201, validation loss: 0.3756
2024-06-03 00:29:48 [INFO]: Epoch 018 - training loss: 0.3342, validation loss: 0.3775
2024-06-03 00:29:49 [INFO]: Epoch 019 - training loss: 0.3593, validation loss: 0.3787
2024-06-03 00:29:51 [INFO]: Epoch 020 - training loss: 0.3444, validation loss: 0.3915
2024-06-03 00:29:52 [INFO]: Epoch 021 - training loss: 0.4328, validation loss: 0.3651
2024-06-03 00:29:53 [INFO]: Epoch 022 - training loss: 0.3576, validation loss: 0.3682
2024-06-03 00:29:55 [INFO]: Epoch 023 - training loss: 0.3893, validation loss: 0.3719
2024-06-03 00:29:56 [INFO]: Epoch 024 - training loss: 0.3935, validation loss: 0.3704
2024-06-03 00:29:57 [INFO]: Epoch 025 - training loss: 0.3592, validation loss: 0.3605
2024-06-03 00:29:58 [INFO]: Epoch 026 - training loss: 0.3841, validation loss: 0.3529
2024-06-03 00:30:00 [INFO]: Epoch 027 - training loss: 0.3336, validation loss: 0.3506
2024-06-03 00:30:01 [INFO]: Epoch 028 - training loss: 0.3455, validation loss: 0.3554
2024-06-03 00:30:02 [INFO]: Epoch 029 - training loss: 0.3767, validation loss: 0.3587
2024-06-03 00:30:04 [INFO]: Epoch 030 - training loss: 0.3127, validation loss: 0.3494
2024-06-03 00:30:05 [INFO]: Epoch 031 - training loss: 0.3208, validation loss: 0.3573
2024-06-03 00:30:06 [INFO]: Epoch 032 - training loss: 0.3710, validation loss: 0.3576
2024-06-03 00:30:07 [INFO]: Epoch 033 - training loss: 0.3374, validation loss: 0.3417
2024-06-03 00:30:09 [INFO]: Epoch 034 - training loss: 0.3345, validation loss: 0.3308
2024-06-03 00:30:10 [INFO]: Epoch 035 - training loss: 0.3438, validation loss: 0.3457
2024-06-03 00:30:11 [INFO]: Epoch 036 - training loss: 0.3623, validation loss: 0.3580
2024-06-03 00:30:13 [INFO]: Epoch 037 - training loss: 0.3053, validation loss: 0.3328
2024-06-03 00:30:14 [INFO]: Epoch 038 - training loss: 0.3838, validation loss: 0.3583
2024-06-03 00:30:15 [INFO]: Epoch 039 - training loss: 0.3560, validation loss: 0.3513
2024-06-03 00:30:16 [INFO]: Epoch 040 - training loss: 0.3861, validation loss: 0.3375
2024-06-03 00:30:18 [INFO]: Epoch 041 - training loss: 0.3710, validation loss: 0.3553
2024-06-03 00:30:19 [INFO]: Epoch 042 - training loss: 0.3281, validation loss: 0.3328
2024-06-03 00:30:20 [INFO]: Epoch 043 - training loss: 0.3521, validation loss: 0.3349
2024-06-03 00:30:22 [INFO]: Epoch 044 - training loss: 0.4056, validation loss: 0.3433
2024-06-03 00:30:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:30:22 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 00:30:22 [INFO]: Saved the model to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_1/20240603_T002925/CSDI.pypots
2024-06-03 00:31:05 [INFO]: Successfully saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_1/imputation.pkl
2024-06-03 00:31:05 [INFO]: Round1 - CSDI on ETT_h1: MAE=0.6263, MSE=0.8208, MRE=0.7371
2024-06-03 00:31:05 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:31:05 [INFO]: Using the given device: cuda:0
2024-06-03 00:31:05 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_2/20240603_T003105
2024-06-03 00:31:05 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_2/20240603_T003105/tensorboard
2024-06-03 00:31:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-03 00:31:06 [INFO]: Epoch 001 - training loss: 0.7471, validation loss: 0.5450
2024-06-03 00:31:07 [INFO]: Epoch 002 - training loss: 0.5693, validation loss: 0.5025
2024-06-03 00:31:09 [INFO]: Epoch 003 - training loss: 0.4927, validation loss: 0.5559
2024-06-03 00:31:10 [INFO]: Epoch 004 - training loss: 0.4427, validation loss: 0.4721
2024-06-03 00:31:11 [INFO]: Epoch 005 - training loss: 0.4099, validation loss: 0.4393
2024-06-03 00:31:12 [INFO]: Epoch 006 - training loss: 0.4357, validation loss: 0.4297
2024-06-03 00:31:14 [INFO]: Epoch 007 - training loss: 0.4092, validation loss: 0.4009
2024-06-03 00:31:15 [INFO]: Epoch 008 - training loss: 0.4168, validation loss: 0.3895
2024-06-03 00:31:16 [INFO]: Epoch 009 - training loss: 0.3945, validation loss: 0.3972
2024-06-03 00:31:18 [INFO]: Epoch 010 - training loss: 0.3447, validation loss: 0.3833
2024-06-03 00:31:19 [INFO]: Epoch 011 - training loss: 0.4333, validation loss: 0.3978
2024-06-03 00:31:20 [INFO]: Epoch 012 - training loss: 0.3831, validation loss: 0.3938
2024-06-03 00:31:21 [INFO]: Epoch 013 - training loss: 0.4278, validation loss: 0.3930
2024-06-03 00:31:23 [INFO]: Epoch 014 - training loss: 0.3188, validation loss: 0.3905
2024-06-03 00:31:24 [INFO]: Epoch 015 - training loss: 0.3909, validation loss: 0.3982
2024-06-03 00:31:25 [INFO]: Epoch 016 - training loss: 0.3769, validation loss: 0.3874
2024-06-03 00:31:27 [INFO]: Epoch 017 - training loss: 0.3307, validation loss: 0.3983
2024-06-03 00:31:28 [INFO]: Epoch 018 - training loss: 0.4361, validation loss: 0.3716
2024-06-03 00:31:29 [INFO]: Epoch 019 - training loss: 0.4163, validation loss: 0.3745
2024-06-03 00:31:30 [INFO]: Epoch 020 - training loss: 0.3690, validation loss: 0.3712
2024-06-03 00:31:32 [INFO]: Epoch 021 - training loss: 0.3669, validation loss: 0.3680
2024-06-03 00:31:33 [INFO]: Epoch 022 - training loss: 0.3451, validation loss: 0.3626
2024-06-03 00:31:34 [INFO]: Epoch 023 - training loss: 0.4078, validation loss: 0.3536
2024-06-03 00:31:36 [INFO]: Epoch 024 - training loss: 0.2840, validation loss: 0.3611
2024-06-03 00:31:37 [INFO]: Epoch 025 - training loss: 0.3189, validation loss: 0.3810
2024-06-03 00:31:38 [INFO]: Epoch 026 - training loss: 0.3598, validation loss: 0.4343
2024-06-03 00:31:39 [INFO]: Epoch 027 - training loss: 0.2956, validation loss: 0.3889
2024-06-03 00:31:41 [INFO]: Epoch 028 - training loss: 0.3436, validation loss: 0.3661
2024-06-03 00:31:42 [INFO]: Epoch 029 - training loss: 0.4013, validation loss: 0.3475
2024-06-03 00:31:43 [INFO]: Epoch 030 - training loss: 0.3002, validation loss: 0.3390
2024-06-03 00:31:44 [INFO]: Epoch 031 - training loss: 0.3697, validation loss: 0.3614
2024-06-03 00:31:46 [INFO]: Epoch 032 - training loss: 0.3962, validation loss: 0.3461
2024-06-03 00:31:47 [INFO]: Epoch 033 - training loss: 0.4253, validation loss: 0.3560
2024-06-03 00:31:48 [INFO]: Epoch 034 - training loss: 0.3555, validation loss: 0.3497
2024-06-03 00:31:50 [INFO]: Epoch 035 - training loss: 0.3297, validation loss: 0.3695
2024-06-03 00:31:51 [INFO]: Epoch 036 - training loss: 0.4028, validation loss: 0.3439
2024-06-03 00:31:52 [INFO]: Epoch 037 - training loss: 0.3439, validation loss: 0.3493
2024-06-03 00:31:54 [INFO]: Epoch 038 - training loss: 0.3836, validation loss: 0.3550
2024-06-03 00:31:55 [INFO]: Epoch 039 - training loss: 0.3741, validation loss: 0.3358
2024-06-03 00:31:56 [INFO]: Epoch 040 - training loss: 0.3528, validation loss: 0.3476
2024-06-03 00:31:57 [INFO]: Epoch 041 - training loss: 0.2916, validation loss: 0.3400
2024-06-03 00:31:59 [INFO]: Epoch 042 - training loss: 0.2849, validation loss: 0.3405
2024-06-03 00:32:00 [INFO]: Epoch 043 - training loss: 0.3731, validation loss: 0.3344
2024-06-03 00:32:01 [INFO]: Epoch 044 - training loss: 0.3282, validation loss: 0.3372
2024-06-03 00:32:03 [INFO]: Epoch 045 - training loss: 0.3651, validation loss: 0.3350
2024-06-03 00:32:04 [INFO]: Epoch 046 - training loss: 0.4214, validation loss: 0.3481
2024-06-03 00:32:05 [INFO]: Epoch 047 - training loss: 0.3100, validation loss: 0.3498
2024-06-03 00:32:06 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.3249
2024-06-03 00:32:08 [INFO]: Epoch 049 - training loss: 0.3314, validation loss: 0.3322
2024-06-03 00:32:09 [INFO]: Epoch 050 - training loss: 0.3340, validation loss: 0.3438
2024-06-03 00:32:10 [INFO]: Epoch 051 - training loss: 0.3232, validation loss: 0.3453
2024-06-03 00:32:12 [INFO]: Epoch 052 - training loss: 0.3943, validation loss: 0.3595
2024-06-03 00:32:13 [INFO]: Epoch 053 - training loss: 0.3687, validation loss: 0.3339
2024-06-03 00:32:14 [INFO]: Epoch 054 - training loss: 0.4039, validation loss: 0.3376
2024-06-03 00:32:15 [INFO]: Epoch 055 - training loss: 0.3008, validation loss: 0.3203
2024-06-03 00:32:17 [INFO]: Epoch 056 - training loss: 0.3334, validation loss: 0.3383
2024-06-03 00:32:18 [INFO]: Epoch 057 - training loss: 0.3224, validation loss: 0.3215
2024-06-03 00:32:19 [INFO]: Epoch 058 - training loss: 0.3395, validation loss: 0.3297
2024-06-03 00:32:20 [INFO]: Epoch 059 - training loss: 0.3233, validation loss: 0.3294
2024-06-03 00:32:22 [INFO]: Epoch 060 - training loss: 0.3586, validation loss: 0.3312
2024-06-03 00:32:23 [INFO]: Epoch 061 - training loss: 0.3103, validation loss: 0.3229
2024-06-03 00:32:24 [INFO]: Epoch 062 - training loss: 0.3762, validation loss: 0.3365
2024-06-03 00:32:26 [INFO]: Epoch 063 - training loss: 0.3560, validation loss: 0.3446
2024-06-03 00:32:27 [INFO]: Epoch 064 - training loss: 0.2886, validation loss: 0.3313
2024-06-03 00:32:28 [INFO]: Epoch 065 - training loss: 0.3027, validation loss: 0.3368
2024-06-03 00:32:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:32:28 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 00:32:28 [INFO]: Saved the model to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_2/20240603_T003105/CSDI.pypots
2024-06-03 00:33:12 [INFO]: Successfully saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_2/imputation.pkl
2024-06-03 00:33:12 [INFO]: Round2 - CSDI on ETT_h1: MAE=0.5873, MSE=0.7227, MRE=0.6912
2024-06-03 00:33:12 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:33:12 [INFO]: Using the given device: cuda:0
2024-06-03 00:33:12 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_3/20240603_T003312
2024-06-03 00:33:12 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_3/20240603_T003312/tensorboard
2024-06-03 00:33:12 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-03 00:33:13 [INFO]: Epoch 001 - training loss: 0.7789, validation loss: 0.5785
2024-06-03 00:33:14 [INFO]: Epoch 002 - training loss: 0.6348, validation loss: 0.5310
2024-06-03 00:33:16 [INFO]: Epoch 003 - training loss: 0.5074, validation loss: 0.4911
2024-06-03 00:33:17 [INFO]: Epoch 004 - training loss: 0.4101, validation loss: 0.4463
2024-06-03 00:33:18 [INFO]: Epoch 005 - training loss: 0.4107, validation loss: 0.4208
2024-06-03 00:33:20 [INFO]: Epoch 006 - training loss: 0.4068, validation loss: 0.4044
2024-06-03 00:33:21 [INFO]: Epoch 007 - training loss: 0.3973, validation loss: 0.3991
2024-06-03 00:33:22 [INFO]: Epoch 008 - training loss: 0.4856, validation loss: 0.4320
2024-06-03 00:33:24 [INFO]: Epoch 009 - training loss: 0.3830, validation loss: 0.4046
2024-06-03 00:33:25 [INFO]: Epoch 010 - training loss: 0.3895, validation loss: 0.3931
2024-06-03 00:33:26 [INFO]: Epoch 011 - training loss: 0.4582, validation loss: 0.4104
2024-06-03 00:33:27 [INFO]: Epoch 012 - training loss: 0.3770, validation loss: 0.3915
2024-06-03 00:33:29 [INFO]: Epoch 013 - training loss: 0.4142, validation loss: 0.3932
2024-06-03 00:33:30 [INFO]: Epoch 014 - training loss: 0.4057, validation loss: 0.3980
2024-06-03 00:33:31 [INFO]: Epoch 015 - training loss: 0.4108, validation loss: 0.3945
2024-06-03 00:33:33 [INFO]: Epoch 016 - training loss: 0.4011, validation loss: 0.4095
2024-06-03 00:33:34 [INFO]: Epoch 017 - training loss: 0.3842, validation loss: 0.3933
2024-06-03 00:33:35 [INFO]: Epoch 018 - training loss: 0.3974, validation loss: 0.3932
2024-06-03 00:33:36 [INFO]: Epoch 019 - training loss: 0.4101, validation loss: 0.3896
2024-06-03 00:33:38 [INFO]: Epoch 020 - training loss: 0.4229, validation loss: 0.3788
2024-06-03 00:33:39 [INFO]: Epoch 021 - training loss: 0.3549, validation loss: 0.3820
2024-06-03 00:33:40 [INFO]: Epoch 022 - training loss: 0.4023, validation loss: 0.3696
2024-06-03 00:33:42 [INFO]: Epoch 023 - training loss: 0.3540, validation loss: 0.3844
2024-06-03 00:33:43 [INFO]: Epoch 024 - training loss: 0.3613, validation loss: 0.3827
2024-06-03 00:33:44 [INFO]: Epoch 025 - training loss: 0.3423, validation loss: 0.3752
2024-06-03 00:33:45 [INFO]: Epoch 026 - training loss: 0.3268, validation loss: 0.3549
2024-06-03 00:33:47 [INFO]: Epoch 027 - training loss: 0.3987, validation loss: 0.3888
2024-06-03 00:33:48 [INFO]: Epoch 028 - training loss: 0.4410, validation loss: 0.3642
2024-06-03 00:33:49 [INFO]: Epoch 029 - training loss: 0.3329, validation loss: 0.3616
2024-06-03 00:33:51 [INFO]: Epoch 030 - training loss: 0.3645, validation loss: 0.3801
2024-06-03 00:33:52 [INFO]: Epoch 031 - training loss: 0.3505, validation loss: 0.3424
2024-06-03 00:33:53 [INFO]: Epoch 032 - training loss: 0.3961, validation loss: 0.3435
2024-06-03 00:33:54 [INFO]: Epoch 033 - training loss: 0.3439, validation loss: 0.3669
2024-06-03 00:33:56 [INFO]: Epoch 034 - training loss: 0.3522, validation loss: 0.3566
2024-06-03 00:33:57 [INFO]: Epoch 035 - training loss: 0.3405, validation loss: 0.3695
2024-06-03 00:33:58 [INFO]: Epoch 036 - training loss: 0.4320, validation loss: 0.3650
2024-06-03 00:33:59 [INFO]: Epoch 037 - training loss: 0.3991, validation loss: 0.3874
2024-06-03 00:34:01 [INFO]: Epoch 038 - training loss: 0.3045, validation loss: 0.3332
2024-06-03 00:34:02 [INFO]: Epoch 039 - training loss: 0.2914, validation loss: 0.3867
2024-06-03 00:34:03 [INFO]: Epoch 040 - training loss: 0.3734, validation loss: 0.3549
2024-06-03 00:34:04 [INFO]: Epoch 041 - training loss: 0.3100, validation loss: 0.3424
2024-06-03 00:34:06 [INFO]: Epoch 042 - training loss: 0.3259, validation loss: 0.3682
2024-06-03 00:34:07 [INFO]: Epoch 043 - training loss: 0.2652, validation loss: 0.3651
2024-06-03 00:34:08 [INFO]: Epoch 044 - training loss: 0.3352, validation loss: 0.3523
2024-06-03 00:34:10 [INFO]: Epoch 045 - training loss: 0.3377, validation loss: 0.3518
2024-06-03 00:34:11 [INFO]: Epoch 046 - training loss: 0.3334, validation loss: 0.3584
2024-06-03 00:34:12 [INFO]: Epoch 047 - training loss: 0.3701, validation loss: 0.3560
2024-06-03 00:34:14 [INFO]: Epoch 048 - training loss: 0.3419, validation loss: 0.3617
2024-06-03 00:34:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:34:14 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 00:34:14 [INFO]: Saved the model to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_3/20240603_T003312/CSDI.pypots
2024-06-03 00:34:57 [INFO]: Successfully saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_3/imputation.pkl
2024-06-03 00:34:57 [INFO]: Round3 - CSDI on ETT_h1: MAE=0.7335, MSE=1.1117, MRE=0.8632
2024-06-03 00:34:57 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:34:57 [INFO]: Using the given device: cuda:0
2024-06-03 00:34:57 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_4/20240603_T003457
2024-06-03 00:34:57 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_4/20240603_T003457/tensorboard
2024-06-03 00:34:57 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,194,993
2024-06-03 00:34:58 [INFO]: Epoch 001 - training loss: 0.7766, validation loss: 0.6038
2024-06-03 00:35:00 [INFO]: Epoch 002 - training loss: 0.5177, validation loss: 0.4999
2024-06-03 00:35:01 [INFO]: Epoch 003 - training loss: 0.4764, validation loss: 0.4808
2024-06-03 00:35:02 [INFO]: Epoch 004 - training loss: 0.4211, validation loss: 0.4990
2024-06-03 00:35:03 [INFO]: Epoch 005 - training loss: 0.4920, validation loss: 0.4280
2024-06-03 00:35:05 [INFO]: Epoch 006 - training loss: 0.4027, validation loss: 0.4359
2024-06-03 00:35:06 [INFO]: Epoch 007 - training loss: 0.3729, validation loss: 0.4231
2024-06-03 00:35:07 [INFO]: Epoch 008 - training loss: 0.4153, validation loss: 0.4049
2024-06-03 00:35:09 [INFO]: Epoch 009 - training loss: 0.4055, validation loss: 0.3827
2024-06-03 00:35:10 [INFO]: Epoch 010 - training loss: 0.4003, validation loss: 0.3864
2024-06-03 00:35:11 [INFO]: Epoch 011 - training loss: 0.4397, validation loss: 0.4011
2024-06-03 00:35:12 [INFO]: Epoch 012 - training loss: 0.3593, validation loss: 0.3979
2024-06-03 00:35:14 [INFO]: Epoch 013 - training loss: 0.4766, validation loss: 0.3969
2024-06-03 00:35:15 [INFO]: Epoch 014 - training loss: 0.3753, validation loss: 0.4087
2024-06-03 00:35:16 [INFO]: Epoch 015 - training loss: 0.3931, validation loss: 0.3965
2024-06-03 00:35:18 [INFO]: Epoch 016 - training loss: 0.4543, validation loss: 0.3917
2024-06-03 00:35:19 [INFO]: Epoch 017 - training loss: 0.4123, validation loss: 0.3978
2024-06-03 00:35:20 [INFO]: Epoch 018 - training loss: 0.4285, validation loss: 0.4091
2024-06-03 00:35:21 [INFO]: Epoch 019 - training loss: 0.3540, validation loss: 0.3742
2024-06-03 00:35:23 [INFO]: Epoch 020 - training loss: 0.4094, validation loss: 0.3853
2024-06-03 00:35:24 [INFO]: Epoch 021 - training loss: 0.3652, validation loss: 0.3623
2024-06-03 00:35:25 [INFO]: Epoch 022 - training loss: 0.4116, validation loss: 0.3781
2024-06-03 00:35:27 [INFO]: Epoch 023 - training loss: 0.3791, validation loss: 0.3661
2024-06-03 00:35:28 [INFO]: Epoch 024 - training loss: 0.3780, validation loss: 0.3653
2024-06-03 00:35:29 [INFO]: Epoch 025 - training loss: 0.3680, validation loss: 0.3596
2024-06-03 00:35:30 [INFO]: Epoch 026 - training loss: 0.3188, validation loss: 0.3596
2024-06-03 00:35:32 [INFO]: Epoch 027 - training loss: 0.4266, validation loss: 0.3601
2024-06-03 00:35:33 [INFO]: Epoch 028 - training loss: 0.3471, validation loss: 0.3717
2024-06-03 00:35:34 [INFO]: Epoch 029 - training loss: 0.3988, validation loss: 0.3797
2024-06-03 00:35:36 [INFO]: Epoch 030 - training loss: 0.3426, validation loss: 0.3614
2024-06-03 00:35:37 [INFO]: Epoch 031 - training loss: 0.3962, validation loss: 0.3693
2024-06-03 00:35:38 [INFO]: Epoch 032 - training loss: 0.3219, validation loss: 0.3403
2024-06-03 00:35:39 [INFO]: Epoch 033 - training loss: 0.3222, validation loss: 0.3425
2024-06-03 00:35:41 [INFO]: Epoch 034 - training loss: 0.3575, validation loss: 0.3518
2024-06-03 00:35:42 [INFO]: Epoch 035 - training loss: 0.3616, validation loss: 0.3621
2024-06-03 00:35:43 [INFO]: Epoch 036 - training loss: 0.3295, validation loss: 0.3424
2024-06-03 00:35:45 [INFO]: Epoch 037 - training loss: 0.3513, validation loss: 0.3709
2024-06-03 00:35:46 [INFO]: Epoch 038 - training loss: 0.3856, validation loss: 0.3268
2024-06-03 00:35:47 [INFO]: Epoch 039 - training loss: 0.3701, validation loss: 0.3342
2024-06-03 00:35:48 [INFO]: Epoch 040 - training loss: 0.3825, validation loss: 0.3396
2024-06-03 00:35:50 [INFO]: Epoch 041 - training loss: 0.3422, validation loss: 0.3440
2024-06-03 00:35:51 [INFO]: Epoch 042 - training loss: 0.4531, validation loss: 0.3555
2024-06-03 00:35:52 [INFO]: Epoch 043 - training loss: 0.3238, validation loss: 0.3476
2024-06-03 00:35:54 [INFO]: Epoch 044 - training loss: 0.3433, validation loss: 0.3740
2024-06-03 00:35:55 [INFO]: Epoch 045 - training loss: 0.3806, validation loss: 0.3513
2024-06-03 00:35:56 [INFO]: Epoch 046 - training loss: 0.3604, validation loss: 0.3383
2024-06-03 00:35:57 [INFO]: Epoch 047 - training loss: 0.3484, validation loss: 0.3534
2024-06-03 00:35:59 [INFO]: Epoch 048 - training loss: 0.4054, validation loss: 0.3285
2024-06-03 00:35:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:35:59 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 00:35:59 [INFO]: Saved the model to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_4/20240603_T003457/CSDI.pypots
2024-06-03 00:36:42 [INFO]: Successfully saved to results_point_rate09/ETT_h1/CSDI_ETT_h1/round_4/imputation.pkl
2024-06-03 00:36:42 [INFO]: Round4 - CSDI on ETT_h1: MAE=0.5972, MSE=0.7124, MRE=0.7028
2024-06-03 00:36:42 [INFO]: Done! Final results:
Averaged CSDI (1,194,993 params) on ETT_h1: MAE=0.6402 ± 0.0525526748469054, MSE=0.8857 ± 0.16891111275376672, MRE=0.7534 ± 0.061848643483846825, average inference time=9.86
