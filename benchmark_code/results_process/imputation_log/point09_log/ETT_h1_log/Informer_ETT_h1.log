2024-06-03 00:41:51 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:41:51 [INFO]: Using the given device: cuda:0
2024-06-03 00:41:53 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_0/20240603_T004153
2024-06-03 00:41:53 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_0/20240603_T004153/tensorboard
2024-06-03 00:41:54 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 00:42:00 [INFO]: Epoch 001 - training loss: 1.6446, validation loss: 1.3046
2024-06-03 00:42:01 [INFO]: Epoch 002 - training loss: 1.1281, validation loss: 0.8974
2024-06-03 00:42:02 [INFO]: Epoch 003 - training loss: 0.9553, validation loss: 1.0081
2024-06-03 00:42:02 [INFO]: Epoch 004 - training loss: 0.8961, validation loss: 0.9480
2024-06-03 00:42:03 [INFO]: Epoch 005 - training loss: 0.8440, validation loss: 0.8466
2024-06-03 00:42:04 [INFO]: Epoch 006 - training loss: 0.7927, validation loss: 0.9112
2024-06-03 00:42:05 [INFO]: Epoch 007 - training loss: 0.7630, validation loss: 0.7721
2024-06-03 00:42:06 [INFO]: Epoch 008 - training loss: 0.7330, validation loss: 0.7954
2024-06-03 00:42:07 [INFO]: Epoch 009 - training loss: 0.7482, validation loss: 0.8210
2024-06-03 00:42:07 [INFO]: Epoch 010 - training loss: 0.7283, validation loss: 0.8917
2024-06-03 00:42:08 [INFO]: Epoch 011 - training loss: 0.7303, validation loss: 0.8270
2024-06-03 00:42:09 [INFO]: Epoch 012 - training loss: 0.6953, validation loss: 0.7927
2024-06-03 00:42:10 [INFO]: Epoch 013 - training loss: 0.6455, validation loss: 0.7340
2024-06-03 00:42:11 [INFO]: Epoch 014 - training loss: 0.6532, validation loss: 0.7678
2024-06-03 00:42:12 [INFO]: Epoch 015 - training loss: 0.6485, validation loss: 0.7345
2024-06-03 00:42:12 [INFO]: Epoch 016 - training loss: 0.6503, validation loss: 0.7251
2024-06-03 00:42:13 [INFO]: Epoch 017 - training loss: 0.6488, validation loss: 0.7035
2024-06-03 00:42:14 [INFO]: Epoch 018 - training loss: 0.6528, validation loss: 0.6921
2024-06-03 00:42:15 [INFO]: Epoch 019 - training loss: 0.6377, validation loss: 0.7005
2024-06-03 00:42:16 [INFO]: Epoch 020 - training loss: 0.6051, validation loss: 0.6794
2024-06-03 00:42:17 [INFO]: Epoch 021 - training loss: 0.6434, validation loss: 0.6708
2024-06-03 00:42:18 [INFO]: Epoch 022 - training loss: 0.6029, validation loss: 0.6579
2024-06-03 00:42:18 [INFO]: Epoch 023 - training loss: 0.5904, validation loss: 0.6517
2024-06-03 00:42:19 [INFO]: Epoch 024 - training loss: 0.5820, validation loss: 0.6371
2024-06-03 00:42:20 [INFO]: Epoch 025 - training loss: 0.5890, validation loss: 0.6520
2024-06-03 00:42:20 [INFO]: Epoch 026 - training loss: 0.5677, validation loss: 0.6590
2024-06-03 00:42:21 [INFO]: Epoch 027 - training loss: 0.5756, validation loss: 0.6393
2024-06-03 00:42:22 [INFO]: Epoch 028 - training loss: 0.5685, validation loss: 0.6222
2024-06-03 00:42:23 [INFO]: Epoch 029 - training loss: 0.5787, validation loss: 0.6442
2024-06-03 00:42:24 [INFO]: Epoch 030 - training loss: 0.6055, validation loss: 0.6048
2024-06-03 00:42:24 [INFO]: Epoch 031 - training loss: 0.5603, validation loss: 0.6210
2024-06-03 00:42:25 [INFO]: Epoch 032 - training loss: 0.5698, validation loss: 0.6135
2024-06-03 00:42:26 [INFO]: Epoch 033 - training loss: 0.5283, validation loss: 0.6200
2024-06-03 00:42:27 [INFO]: Epoch 034 - training loss: 0.5590, validation loss: 0.6237
2024-06-03 00:42:27 [INFO]: Epoch 035 - training loss: 0.5371, validation loss: 0.6056
2024-06-03 00:42:28 [INFO]: Epoch 036 - training loss: 0.5262, validation loss: 0.5584
2024-06-03 00:42:29 [INFO]: Epoch 037 - training loss: 0.5447, validation loss: 0.6329
2024-06-03 00:42:30 [INFO]: Epoch 038 - training loss: 0.5322, validation loss: 0.5915
2024-06-03 00:42:31 [INFO]: Epoch 039 - training loss: 0.5382, validation loss: 0.6294
2024-06-03 00:42:32 [INFO]: Epoch 040 - training loss: 0.5281, validation loss: 0.5930
2024-06-03 00:42:32 [INFO]: Epoch 041 - training loss: 0.5083, validation loss: 0.5679
2024-06-03 00:42:33 [INFO]: Epoch 042 - training loss: 0.4990, validation loss: 0.5790
2024-06-03 00:42:34 [INFO]: Epoch 043 - training loss: 0.5218, validation loss: 0.5985
2024-06-03 00:42:35 [INFO]: Epoch 044 - training loss: 0.5282, validation loss: 0.6302
2024-06-03 00:42:36 [INFO]: Epoch 045 - training loss: 0.5164, validation loss: 0.5906
2024-06-03 00:42:37 [INFO]: Epoch 046 - training loss: 0.5302, validation loss: 0.5868
2024-06-03 00:42:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:42:37 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 00:42:37 [INFO]: Saved the model to results_point_rate09/ETT_h1/Informer_ETT_h1/round_0/20240603_T004153/Informer.pypots
2024-06-03 00:42:38 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_0/imputation.pkl
2024-06-03 00:42:38 [INFO]: Round0 - Informer on ETT_h1: MAE=0.6113, MSE=0.7284, MRE=0.7194
2024-06-03 00:42:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:42:38 [INFO]: Using the given device: cuda:0
2024-06-03 00:42:38 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_1/20240603_T004238
2024-06-03 00:42:38 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_1/20240603_T004238/tensorboard
2024-06-03 00:42:38 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 00:42:38 [INFO]: Epoch 001 - training loss: 1.8062, validation loss: 1.2450
2024-06-03 00:42:39 [INFO]: Epoch 002 - training loss: 1.2816, validation loss: 1.0182
2024-06-03 00:42:40 [INFO]: Epoch 003 - training loss: 1.0443, validation loss: 0.9171
2024-06-03 00:42:40 [INFO]: Epoch 004 - training loss: 0.9256, validation loss: 0.8711
2024-06-03 00:42:41 [INFO]: Epoch 005 - training loss: 0.8279, validation loss: 0.8149
2024-06-03 00:42:42 [INFO]: Epoch 006 - training loss: 0.8317, validation loss: 0.8377
2024-06-03 00:42:43 [INFO]: Epoch 007 - training loss: 0.7794, validation loss: 0.8390
2024-06-03 00:42:43 [INFO]: Epoch 008 - training loss: 0.7385, validation loss: 0.8756
2024-06-03 00:42:44 [INFO]: Epoch 009 - training loss: 0.7781, validation loss: 0.8311
2024-06-03 00:42:45 [INFO]: Epoch 010 - training loss: 0.7641, validation loss: 0.8331
2024-06-03 00:42:46 [INFO]: Epoch 011 - training loss: 0.7551, validation loss: 0.7518
2024-06-03 00:42:46 [INFO]: Epoch 012 - training loss: 0.6983, validation loss: 0.7361
2024-06-03 00:42:47 [INFO]: Epoch 013 - training loss: 0.7100, validation loss: 0.7326
2024-06-03 00:42:48 [INFO]: Epoch 014 - training loss: 0.6850, validation loss: 0.6848
2024-06-03 00:42:49 [INFO]: Epoch 015 - training loss: 0.6861, validation loss: 0.6413
2024-06-03 00:42:50 [INFO]: Epoch 016 - training loss: 0.6714, validation loss: 0.6409
2024-06-03 00:42:51 [INFO]: Epoch 017 - training loss: 0.6507, validation loss: 0.6639
2024-06-03 00:42:52 [INFO]: Epoch 018 - training loss: 0.6692, validation loss: 0.6397
2024-06-03 00:42:52 [INFO]: Epoch 019 - training loss: 0.6598, validation loss: 0.6173
2024-06-03 00:42:53 [INFO]: Epoch 020 - training loss: 0.6607, validation loss: 0.7082
2024-06-03 00:42:54 [INFO]: Epoch 021 - training loss: 0.6102, validation loss: 0.6916
2024-06-03 00:42:54 [INFO]: Epoch 022 - training loss: 0.5955, validation loss: 0.7009
2024-06-03 00:42:55 [INFO]: Epoch 023 - training loss: 0.6062, validation loss: 0.6610
2024-06-03 00:42:56 [INFO]: Epoch 024 - training loss: 0.5863, validation loss: 0.7139
2024-06-03 00:42:57 [INFO]: Epoch 025 - training loss: 0.5860, validation loss: 0.7614
2024-06-03 00:42:58 [INFO]: Epoch 026 - training loss: 0.5810, validation loss: 0.7853
2024-06-03 00:42:58 [INFO]: Epoch 027 - training loss: 0.5960, validation loss: 0.7080
2024-06-03 00:42:59 [INFO]: Epoch 028 - training loss: 0.5648, validation loss: 0.6445
2024-06-03 00:43:00 [INFO]: Epoch 029 - training loss: 0.5576, validation loss: 0.6182
2024-06-03 00:43:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:43:00 [INFO]: Finished training. The best model is from epoch#19.
2024-06-03 00:43:00 [INFO]: Saved the model to results_point_rate09/ETT_h1/Informer_ETT_h1/round_1/20240603_T004238/Informer.pypots
2024-06-03 00:43:01 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_1/imputation.pkl
2024-06-03 00:43:01 [INFO]: Round1 - Informer on ETT_h1: MAE=0.6235, MSE=0.8015, MRE=0.7338
2024-06-03 00:43:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:43:01 [INFO]: Using the given device: cuda:0
2024-06-03 00:43:01 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_2/20240603_T004301
2024-06-03 00:43:01 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_2/20240603_T004301/tensorboard
2024-06-03 00:43:01 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 00:43:02 [INFO]: Epoch 001 - training loss: 1.7698, validation loss: 1.1268
2024-06-03 00:43:03 [INFO]: Epoch 002 - training loss: 1.3334, validation loss: 1.1314
2024-06-03 00:43:03 [INFO]: Epoch 003 - training loss: 1.0013, validation loss: 0.9453
2024-06-03 00:43:04 [INFO]: Epoch 004 - training loss: 0.9089, validation loss: 0.9833
2024-06-03 00:43:05 [INFO]: Epoch 005 - training loss: 0.8648, validation loss: 0.8354
2024-06-03 00:43:06 [INFO]: Epoch 006 - training loss: 0.7911, validation loss: 0.8196
2024-06-03 00:43:07 [INFO]: Epoch 007 - training loss: 0.7350, validation loss: 0.8352
2024-06-03 00:43:08 [INFO]: Epoch 008 - training loss: 0.7246, validation loss: 0.8484
2024-06-03 00:43:08 [INFO]: Epoch 009 - training loss: 0.7110, validation loss: 0.8320
2024-06-03 00:43:09 [INFO]: Epoch 010 - training loss: 0.7358, validation loss: 0.8087
2024-06-03 00:43:10 [INFO]: Epoch 011 - training loss: 0.7017, validation loss: 0.7294
2024-06-03 00:43:11 [INFO]: Epoch 012 - training loss: 0.6903, validation loss: 0.7414
2024-06-03 00:43:12 [INFO]: Epoch 013 - training loss: 0.6913, validation loss: 0.7610
2024-06-03 00:43:13 [INFO]: Epoch 014 - training loss: 0.6527, validation loss: 0.7802
2024-06-03 00:43:13 [INFO]: Epoch 015 - training loss: 0.6813, validation loss: 0.7348
2024-06-03 00:43:14 [INFO]: Epoch 016 - training loss: 0.6617, validation loss: 0.7275
2024-06-03 00:43:15 [INFO]: Epoch 017 - training loss: 0.6263, validation loss: 0.7086
2024-06-03 00:43:16 [INFO]: Epoch 018 - training loss: 0.6438, validation loss: 0.7617
2024-06-03 00:43:17 [INFO]: Epoch 019 - training loss: 0.6194, validation loss: 0.7192
2024-06-03 00:43:17 [INFO]: Epoch 020 - training loss: 0.5985, validation loss: 0.6781
2024-06-03 00:43:18 [INFO]: Epoch 021 - training loss: 0.5983, validation loss: 0.6813
2024-06-03 00:43:19 [INFO]: Epoch 022 - training loss: 0.6471, validation loss: 0.6889
2024-06-03 00:43:19 [INFO]: Epoch 023 - training loss: 0.6196, validation loss: 0.6703
2024-06-03 00:43:20 [INFO]: Epoch 024 - training loss: 0.6031, validation loss: 0.6943
2024-06-03 00:43:21 [INFO]: Epoch 025 - training loss: 0.6026, validation loss: 0.6782
2024-06-03 00:43:21 [INFO]: Epoch 026 - training loss: 0.5630, validation loss: 0.7194
2024-06-03 00:43:22 [INFO]: Epoch 027 - training loss: 0.5854, validation loss: 0.6714
2024-06-03 00:43:22 [INFO]: Epoch 028 - training loss: 0.6077, validation loss: 0.6531
2024-06-03 00:43:23 [INFO]: Epoch 029 - training loss: 0.5444, validation loss: 0.6410
2024-06-03 00:43:24 [INFO]: Epoch 030 - training loss: 0.5412, validation loss: 0.6409
2024-06-03 00:43:25 [INFO]: Epoch 031 - training loss: 0.5469, validation loss: 0.6757
2024-06-03 00:43:26 [INFO]: Epoch 032 - training loss: 0.5672, validation loss: 0.7115
2024-06-03 00:43:26 [INFO]: Epoch 033 - training loss: 0.5463, validation loss: 0.6831
2024-06-03 00:43:27 [INFO]: Epoch 034 - training loss: 0.5651, validation loss: 0.7014
2024-06-03 00:43:28 [INFO]: Epoch 035 - training loss: 0.5311, validation loss: 0.6901
2024-06-03 00:43:29 [INFO]: Epoch 036 - training loss: 0.5751, validation loss: 0.6492
2024-06-03 00:43:29 [INFO]: Epoch 037 - training loss: 0.5219, validation loss: 0.6441
2024-06-03 00:43:30 [INFO]: Epoch 038 - training loss: 0.5279, validation loss: 0.6737
2024-06-03 00:43:31 [INFO]: Epoch 039 - training loss: 0.5475, validation loss: 0.6712
2024-06-03 00:43:32 [INFO]: Epoch 040 - training loss: 0.5344, validation loss: 0.6943
2024-06-03 00:43:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:43:32 [INFO]: Finished training. The best model is from epoch#30.
2024-06-03 00:43:32 [INFO]: Saved the model to results_point_rate09/ETT_h1/Informer_ETT_h1/round_2/20240603_T004301/Informer.pypots
2024-06-03 00:43:32 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_2/imputation.pkl
2024-06-03 00:43:32 [INFO]: Round2 - Informer on ETT_h1: MAE=0.6625, MSE=0.8622, MRE=0.7797
2024-06-03 00:43:32 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:43:32 [INFO]: Using the given device: cuda:0
2024-06-03 00:43:32 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_3/20240603_T004332
2024-06-03 00:43:32 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_3/20240603_T004332/tensorboard
2024-06-03 00:43:32 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 00:43:33 [INFO]: Epoch 001 - training loss: 1.7002, validation loss: 1.1580
2024-06-03 00:43:33 [INFO]: Epoch 002 - training loss: 1.2521, validation loss: 1.0236
2024-06-03 00:43:34 [INFO]: Epoch 003 - training loss: 0.9968, validation loss: 0.8481
2024-06-03 00:43:35 [INFO]: Epoch 004 - training loss: 0.8693, validation loss: 0.8636
2024-06-03 00:43:35 [INFO]: Epoch 005 - training loss: 0.8244, validation loss: 0.8993
2024-06-03 00:43:36 [INFO]: Epoch 006 - training loss: 0.8094, validation loss: 0.8154
2024-06-03 00:43:37 [INFO]: Epoch 007 - training loss: 0.7825, validation loss: 0.8093
2024-06-03 00:43:37 [INFO]: Epoch 008 - training loss: 0.7676, validation loss: 0.8666
2024-06-03 00:43:38 [INFO]: Epoch 009 - training loss: 0.7560, validation loss: 0.7991
2024-06-03 00:43:38 [INFO]: Epoch 010 - training loss: 0.7305, validation loss: 0.7738
2024-06-03 00:43:39 [INFO]: Epoch 011 - training loss: 0.7270, validation loss: 0.8293
2024-06-03 00:43:39 [INFO]: Epoch 012 - training loss: 0.6881, validation loss: 0.7440
2024-06-03 00:43:40 [INFO]: Epoch 013 - training loss: 0.6913, validation loss: 0.7292
2024-06-03 00:43:40 [INFO]: Epoch 014 - training loss: 0.6938, validation loss: 0.7435
2024-06-03 00:43:41 [INFO]: Epoch 015 - training loss: 0.6679, validation loss: 0.7203
2024-06-03 00:43:41 [INFO]: Epoch 016 - training loss: 0.6431, validation loss: 0.7308
2024-06-03 00:43:42 [INFO]: Epoch 017 - training loss: 0.6279, validation loss: 0.6908
2024-06-03 00:43:42 [INFO]: Epoch 018 - training loss: 0.6212, validation loss: 0.6481
2024-06-03 00:43:43 [INFO]: Epoch 019 - training loss: 0.6514, validation loss: 0.7056
2024-06-03 00:43:44 [INFO]: Epoch 020 - training loss: 0.6738, validation loss: 0.8149
2024-06-03 00:43:44 [INFO]: Epoch 021 - training loss: 0.6629, validation loss: 0.7172
2024-06-03 00:43:45 [INFO]: Epoch 022 - training loss: 0.5988, validation loss: 0.6466
2024-06-03 00:43:46 [INFO]: Epoch 023 - training loss: 0.6064, validation loss: 0.6490
2024-06-03 00:43:46 [INFO]: Epoch 024 - training loss: 0.5797, validation loss: 0.6434
2024-06-03 00:43:47 [INFO]: Epoch 025 - training loss: 0.5704, validation loss: 0.6867
2024-06-03 00:43:47 [INFO]: Epoch 026 - training loss: 0.5902, validation loss: 0.6829
2024-06-03 00:43:48 [INFO]: Epoch 027 - training loss: 0.6004, validation loss: 0.6826
2024-06-03 00:43:49 [INFO]: Epoch 028 - training loss: 0.5877, validation loss: 0.6167
2024-06-03 00:43:49 [INFO]: Epoch 029 - training loss: 0.5981, validation loss: 0.6429
2024-06-03 00:43:50 [INFO]: Epoch 030 - training loss: 0.5668, validation loss: 0.5989
2024-06-03 00:43:50 [INFO]: Epoch 031 - training loss: 0.5716, validation loss: 0.5735
2024-06-03 00:43:51 [INFO]: Epoch 032 - training loss: 0.5649, validation loss: 0.6302
2024-06-03 00:43:52 [INFO]: Epoch 033 - training loss: 0.5504, validation loss: 0.5990
2024-06-03 00:43:53 [INFO]: Epoch 034 - training loss: 0.5670, validation loss: 0.6144
2024-06-03 00:43:53 [INFO]: Epoch 035 - training loss: 0.5340, validation loss: 0.6195
2024-06-03 00:43:54 [INFO]: Epoch 036 - training loss: 0.4953, validation loss: 0.5922
2024-06-03 00:43:54 [INFO]: Epoch 037 - training loss: 0.4959, validation loss: 0.5618
2024-06-03 00:43:55 [INFO]: Epoch 038 - training loss: 0.5420, validation loss: 0.5628
2024-06-03 00:43:55 [INFO]: Epoch 039 - training loss: 0.5389, validation loss: 0.5409
2024-06-03 00:43:56 [INFO]: Epoch 040 - training loss: 0.5243, validation loss: 0.5791
2024-06-03 00:43:57 [INFO]: Epoch 041 - training loss: 0.5013, validation loss: 0.5841
2024-06-03 00:43:57 [INFO]: Epoch 042 - training loss: 0.4878, validation loss: 0.5684
2024-06-03 00:43:58 [INFO]: Epoch 043 - training loss: 0.5083, validation loss: 0.5496
2024-06-03 00:43:58 [INFO]: Epoch 044 - training loss: 0.5007, validation loss: 0.5976
2024-06-03 00:43:59 [INFO]: Epoch 045 - training loss: 0.5015, validation loss: 0.6087
2024-06-03 00:43:59 [INFO]: Epoch 046 - training loss: 0.5085, validation loss: 0.5855
2024-06-03 00:44:00 [INFO]: Epoch 047 - training loss: 0.4899, validation loss: 0.5694
2024-06-03 00:44:00 [INFO]: Epoch 048 - training loss: 0.4913, validation loss: 0.5703
2024-06-03 00:44:01 [INFO]: Epoch 049 - training loss: 0.4930, validation loss: 0.5681
2024-06-03 00:44:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:44:01 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 00:44:01 [INFO]: Saved the model to results_point_rate09/ETT_h1/Informer_ETT_h1/round_3/20240603_T004332/Informer.pypots
2024-06-03 00:44:01 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_3/imputation.pkl
2024-06-03 00:44:01 [INFO]: Round3 - Informer on ETT_h1: MAE=0.6075, MSE=0.7217, MRE=0.7149
2024-06-03 00:44:01 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:44:01 [INFO]: Using the given device: cuda:0
2024-06-03 00:44:01 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_4/20240603_T004401
2024-06-03 00:44:01 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_4/20240603_T004401/tensorboard
2024-06-03 00:44:01 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 00:44:02 [INFO]: Epoch 001 - training loss: 1.7068, validation loss: 1.1891
2024-06-03 00:44:02 [INFO]: Epoch 002 - training loss: 1.2375, validation loss: 0.9446
2024-06-03 00:44:03 [INFO]: Epoch 003 - training loss: 0.9668, validation loss: 0.9334
2024-06-03 00:44:03 [INFO]: Epoch 004 - training loss: 0.8933, validation loss: 0.9008
2024-06-03 00:44:03 [INFO]: Epoch 005 - training loss: 0.8266, validation loss: 0.9158
2024-06-03 00:44:04 [INFO]: Epoch 006 - training loss: 0.7496, validation loss: 0.9079
2024-06-03 00:44:04 [INFO]: Epoch 007 - training loss: 0.7448, validation loss: 0.8124
2024-06-03 00:44:05 [INFO]: Epoch 008 - training loss: 0.7842, validation loss: 0.8857
2024-06-03 00:44:05 [INFO]: Epoch 009 - training loss: 0.8063, validation loss: 0.8235
2024-06-03 00:44:06 [INFO]: Epoch 010 - training loss: 0.7506, validation loss: 0.7906
2024-06-03 00:44:06 [INFO]: Epoch 011 - training loss: 0.7493, validation loss: 0.7392
2024-06-03 00:44:07 [INFO]: Epoch 012 - training loss: 0.7091, validation loss: 0.7691
2024-06-03 00:44:07 [INFO]: Epoch 013 - training loss: 0.7135, validation loss: 0.6929
2024-06-03 00:44:08 [INFO]: Epoch 014 - training loss: 0.6795, validation loss: 0.6797
2024-06-03 00:44:08 [INFO]: Epoch 015 - training loss: 0.6573, validation loss: 0.6576
2024-06-03 00:44:09 [INFO]: Epoch 016 - training loss: 0.6497, validation loss: 0.6576
2024-06-03 00:44:09 [INFO]: Epoch 017 - training loss: 0.6707, validation loss: 0.7020
2024-06-03 00:44:10 [INFO]: Epoch 018 - training loss: 0.6368, validation loss: 0.6409
2024-06-03 00:44:10 [INFO]: Epoch 019 - training loss: 0.6508, validation loss: 0.6441
2024-06-03 00:44:11 [INFO]: Epoch 020 - training loss: 0.6455, validation loss: 0.6292
2024-06-03 00:44:11 [INFO]: Epoch 021 - training loss: 0.6438, validation loss: 0.6358
2024-06-03 00:44:12 [INFO]: Epoch 022 - training loss: 0.6041, validation loss: 0.6528
2024-06-03 00:44:12 [INFO]: Epoch 023 - training loss: 0.5923, validation loss: 0.6058
2024-06-03 00:44:13 [INFO]: Epoch 024 - training loss: 0.6052, validation loss: 0.6359
2024-06-03 00:44:14 [INFO]: Epoch 025 - training loss: 0.5987, validation loss: 0.6447
2024-06-03 00:44:14 [INFO]: Epoch 026 - training loss: 0.6024, validation loss: 0.6295
2024-06-03 00:44:15 [INFO]: Epoch 027 - training loss: 0.5980, validation loss: 0.6189
2024-06-03 00:44:15 [INFO]: Epoch 028 - training loss: 0.5752, validation loss: 0.6041
2024-06-03 00:44:16 [INFO]: Epoch 029 - training loss: 0.5885, validation loss: 0.5964
2024-06-03 00:44:16 [INFO]: Epoch 030 - training loss: 0.5433, validation loss: 0.6278
2024-06-03 00:44:16 [INFO]: Epoch 031 - training loss: 0.5422, validation loss: 0.5817
2024-06-03 00:44:17 [INFO]: Epoch 032 - training loss: 0.5221, validation loss: 0.5601
2024-06-03 00:44:17 [INFO]: Epoch 033 - training loss: 0.5625, validation loss: 0.5592
2024-06-03 00:44:18 [INFO]: Epoch 034 - training loss: 0.5480, validation loss: 0.5913
2024-06-03 00:44:18 [INFO]: Epoch 035 - training loss: 0.5192, validation loss: 0.5585
2024-06-03 00:44:18 [INFO]: Epoch 036 - training loss: 0.5176, validation loss: 0.5645
2024-06-03 00:44:19 [INFO]: Epoch 037 - training loss: 0.5271, validation loss: 0.5328
2024-06-03 00:44:19 [INFO]: Epoch 038 - training loss: 0.5270, validation loss: 0.5858
2024-06-03 00:44:20 [INFO]: Epoch 039 - training loss: 0.5261, validation loss: 0.5537
2024-06-03 00:44:20 [INFO]: Epoch 040 - training loss: 0.5004, validation loss: 0.5454
2024-06-03 00:44:20 [INFO]: Epoch 041 - training loss: 0.5015, validation loss: 0.5734
2024-06-03 00:44:21 [INFO]: Epoch 042 - training loss: 0.5018, validation loss: 0.5701
2024-06-03 00:44:21 [INFO]: Epoch 043 - training loss: 0.5370, validation loss: 0.6057
2024-06-03 00:44:21 [INFO]: Epoch 044 - training loss: 0.5313, validation loss: 0.5522
2024-06-03 00:44:22 [INFO]: Epoch 045 - training loss: 0.5028, validation loss: 0.5877
2024-06-03 00:44:22 [INFO]: Epoch 046 - training loss: 0.5179, validation loss: 0.5983
2024-06-03 00:44:23 [INFO]: Epoch 047 - training loss: 0.4756, validation loss: 0.5705
2024-06-03 00:44:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:44:23 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 00:44:23 [INFO]: Saved the model to results_point_rate09/ETT_h1/Informer_ETT_h1/round_4/20240603_T004401/Informer.pypots
2024-06-03 00:44:23 [INFO]: Successfully saved to results_point_rate09/ETT_h1/Informer_ETT_h1/round_4/imputation.pkl
2024-06-03 00:44:23 [INFO]: Round4 - Informer on ETT_h1: MAE=0.6011, MSE=0.6696, MRE=0.7075
2024-06-03 00:44:23 [INFO]: Done! Final results:
Averaged Informer (1,058,311 params) on ETT_h1: MAE=0.6212 ± 0.021907357440966432, MSE=0.7567 ± 0.06744192929215911, MRE=0.7311 ± 0.0257825190437346, average inference time=0.12
