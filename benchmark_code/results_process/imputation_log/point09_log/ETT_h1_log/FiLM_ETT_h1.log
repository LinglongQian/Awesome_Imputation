2024-06-03 00:25:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:25:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:25:08 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_0/20240603_T002508
2024-06-03 00:25:08 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_0/20240603_T002508/tensorboard
2024-06-03 00:25:10 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 00:25:13 [INFO]: Epoch 001 - training loss: 1.7128, validation loss: 1.1270
2024-06-03 00:25:13 [INFO]: Epoch 002 - training loss: 1.5447, validation loss: 1.0320
2024-06-03 00:25:14 [INFO]: Epoch 003 - training loss: 1.4715, validation loss: 1.0103
2024-06-03 00:25:15 [INFO]: Epoch 004 - training loss: 1.4115, validation loss: 0.9610
2024-06-03 00:25:16 [INFO]: Epoch 005 - training loss: 1.2101, validation loss: 0.9161
2024-06-03 00:25:16 [INFO]: Epoch 006 - training loss: 1.0908, validation loss: 0.9036
2024-06-03 00:25:17 [INFO]: Epoch 007 - training loss: 1.0342, validation loss: 0.8011
2024-06-03 00:25:18 [INFO]: Epoch 008 - training loss: 1.0466, validation loss: 0.7571
2024-06-03 00:25:19 [INFO]: Epoch 009 - training loss: 0.9649, validation loss: 0.7163
2024-06-03 00:25:20 [INFO]: Epoch 010 - training loss: 0.9472, validation loss: 0.6914
2024-06-03 00:25:21 [INFO]: Epoch 011 - training loss: 0.9393, validation loss: 0.6434
2024-06-03 00:25:22 [INFO]: Epoch 012 - training loss: 0.9117, validation loss: 0.6770
2024-06-03 00:25:23 [INFO]: Epoch 013 - training loss: 0.9312, validation loss: 0.6350
2024-06-03 00:25:24 [INFO]: Epoch 014 - training loss: 0.9374, validation loss: 0.6865
2024-06-03 00:25:25 [INFO]: Epoch 015 - training loss: 0.9248, validation loss: 0.6394
2024-06-03 00:25:26 [INFO]: Epoch 016 - training loss: 0.9250, validation loss: 0.6838
2024-06-03 00:25:26 [INFO]: Epoch 017 - training loss: 0.9011, validation loss: 0.6542
2024-06-03 00:25:27 [INFO]: Epoch 018 - training loss: 0.8976, validation loss: 0.6646
2024-06-03 00:25:28 [INFO]: Epoch 019 - training loss: 0.9120, validation loss: 0.6746
2024-06-03 00:25:29 [INFO]: Epoch 020 - training loss: 0.9264, validation loss: 0.6557
2024-06-03 00:25:30 [INFO]: Epoch 021 - training loss: 0.9133, validation loss: 0.6787
2024-06-03 00:25:31 [INFO]: Epoch 022 - training loss: 0.9089, validation loss: 0.6666
2024-06-03 00:25:32 [INFO]: Epoch 023 - training loss: 0.9304, validation loss: 0.6823
2024-06-03 00:25:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:25:32 [INFO]: Finished training. The best model is from epoch#13.
2024-06-03 00:25:32 [INFO]: Saved the model to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_0/20240603_T002508/FiLM.pypots
2024-06-03 00:25:33 [INFO]: Successfully saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_0/imputation.pkl
2024-06-03 00:25:33 [INFO]: Round0 - FiLM on ETT_h1: MAE=0.6974, MSE=0.9643, MRE=0.8208
2024-06-03 00:25:33 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:25:33 [INFO]: Using the given device: cuda:0
2024-06-03 00:25:33 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_1/20240603_T002533
2024-06-03 00:25:33 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_1/20240603_T002533/tensorboard
2024-06-03 00:25:33 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 00:25:34 [INFO]: Epoch 001 - training loss: 2.3377, validation loss: 1.1451
2024-06-03 00:25:35 [INFO]: Epoch 002 - training loss: 1.7554, validation loss: 0.9867
2024-06-03 00:25:36 [INFO]: Epoch 003 - training loss: 1.5647, validation loss: 1.2107
2024-06-03 00:25:36 [INFO]: Epoch 004 - training loss: 1.5480, validation loss: 0.9479
2024-06-03 00:25:37 [INFO]: Epoch 005 - training loss: 1.4801, validation loss: 1.1368
2024-06-03 00:25:38 [INFO]: Epoch 006 - training loss: 1.4804, validation loss: 0.8865
2024-06-03 00:25:39 [INFO]: Epoch 007 - training loss: 1.3964, validation loss: 1.0255
2024-06-03 00:25:40 [INFO]: Epoch 008 - training loss: 1.2217, validation loss: 0.8943
2024-06-03 00:25:41 [INFO]: Epoch 009 - training loss: 1.0870, validation loss: 0.8745
2024-06-03 00:25:42 [INFO]: Epoch 010 - training loss: 1.0332, validation loss: 0.8784
2024-06-03 00:25:43 [INFO]: Epoch 011 - training loss: 0.9831, validation loss: 0.7617
2024-06-03 00:25:44 [INFO]: Epoch 012 - training loss: 0.9283, validation loss: 0.7765
2024-06-03 00:25:45 [INFO]: Epoch 013 - training loss: 0.9804, validation loss: 0.7237
2024-06-03 00:25:45 [INFO]: Epoch 014 - training loss: 0.9497, validation loss: 0.6789
2024-06-03 00:25:46 [INFO]: Epoch 015 - training loss: 0.9333, validation loss: 0.6937
2024-06-03 00:25:47 [INFO]: Epoch 016 - training loss: 0.9270, validation loss: 0.6720
2024-06-03 00:25:48 [INFO]: Epoch 017 - training loss: 0.9027, validation loss: 0.6614
2024-06-03 00:25:49 [INFO]: Epoch 018 - training loss: 0.9315, validation loss: 0.6718
2024-06-03 00:25:50 [INFO]: Epoch 019 - training loss: 0.9206, validation loss: 0.6650
2024-06-03 00:25:50 [INFO]: Epoch 020 - training loss: 0.8993, validation loss: 0.6522
2024-06-03 00:25:51 [INFO]: Epoch 021 - training loss: 0.9349, validation loss: 0.6647
2024-06-03 00:25:52 [INFO]: Epoch 022 - training loss: 0.9322, validation loss: 0.6593
2024-06-03 00:25:53 [INFO]: Epoch 023 - training loss: 0.8946, validation loss: 0.6669
2024-06-03 00:25:54 [INFO]: Epoch 024 - training loss: 0.9116, validation loss: 0.6504
2024-06-03 00:25:54 [INFO]: Epoch 025 - training loss: 0.9219, validation loss: 0.6842
2024-06-03 00:25:55 [INFO]: Epoch 026 - training loss: 0.8972, validation loss: 0.6573
2024-06-03 00:25:56 [INFO]: Epoch 027 - training loss: 0.8962, validation loss: 0.6743
2024-06-03 00:25:57 [INFO]: Epoch 028 - training loss: 0.8985, validation loss: 0.6276
2024-06-03 00:25:58 [INFO]: Epoch 029 - training loss: 0.9304, validation loss: 0.6775
2024-06-03 00:25:58 [INFO]: Epoch 030 - training loss: 0.9021, validation loss: 0.6650
2024-06-03 00:25:59 [INFO]: Epoch 031 - training loss: 0.9057, validation loss: 0.6665
2024-06-03 00:26:00 [INFO]: Epoch 032 - training loss: 0.9232, validation loss: 0.6814
2024-06-03 00:26:01 [INFO]: Epoch 033 - training loss: 0.8950, validation loss: 0.6677
2024-06-03 00:26:02 [INFO]: Epoch 034 - training loss: 0.9160, validation loss: 0.6626
2024-06-03 00:26:03 [INFO]: Epoch 035 - training loss: 0.9155, validation loss: 0.6639
2024-06-03 00:26:04 [INFO]: Epoch 036 - training loss: 0.9269, validation loss: 0.6794
2024-06-03 00:26:05 [INFO]: Epoch 037 - training loss: 0.9068, validation loss: 0.6623
2024-06-03 00:26:06 [INFO]: Epoch 038 - training loss: 0.9179, validation loss: 0.6761
2024-06-03 00:26:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:26:06 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 00:26:06 [INFO]: Saved the model to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_1/20240603_T002533/FiLM.pypots
2024-06-03 00:26:06 [INFO]: Successfully saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_1/imputation.pkl
2024-06-03 00:26:06 [INFO]: Round1 - FiLM on ETT_h1: MAE=0.6990, MSE=0.9645, MRE=0.8226
2024-06-03 00:26:06 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:26:06 [INFO]: Using the given device: cuda:0
2024-06-03 00:26:06 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_2/20240603_T002606
2024-06-03 00:26:06 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_2/20240603_T002606/tensorboard
2024-06-03 00:26:06 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 00:26:07 [INFO]: Epoch 001 - training loss: 1.8325, validation loss: 1.1847
2024-06-03 00:26:08 [INFO]: Epoch 002 - training loss: 1.6150, validation loss: 1.0499
2024-06-03 00:26:09 [INFO]: Epoch 003 - training loss: 1.4950, validation loss: 1.0390
2024-06-03 00:26:10 [INFO]: Epoch 004 - training loss: 1.4992, validation loss: 1.0647
2024-06-03 00:26:11 [INFO]: Epoch 005 - training loss: 1.4812, validation loss: 0.9931
2024-06-03 00:26:12 [INFO]: Epoch 006 - training loss: 1.4584, validation loss: 0.9273
2024-06-03 00:26:12 [INFO]: Epoch 007 - training loss: 1.3186, validation loss: 0.8936
2024-06-03 00:26:13 [INFO]: Epoch 008 - training loss: 1.1177, validation loss: 0.9066
2024-06-03 00:26:14 [INFO]: Epoch 009 - training loss: 1.0289, validation loss: 0.7754
2024-06-03 00:26:15 [INFO]: Epoch 010 - training loss: 0.9958, validation loss: 0.7767
2024-06-03 00:26:16 [INFO]: Epoch 011 - training loss: 0.9757, validation loss: 0.7226
2024-06-03 00:26:17 [INFO]: Epoch 012 - training loss: 0.9612, validation loss: 0.6859
2024-06-03 00:26:18 [INFO]: Epoch 013 - training loss: 0.9308, validation loss: 0.6831
2024-06-03 00:26:19 [INFO]: Epoch 014 - training loss: 0.9303, validation loss: 0.6630
2024-06-03 00:26:19 [INFO]: Epoch 015 - training loss: 0.9270, validation loss: 0.6621
2024-06-03 00:26:20 [INFO]: Epoch 016 - training loss: 0.9151, validation loss: 0.6639
2024-06-03 00:26:21 [INFO]: Epoch 017 - training loss: 0.9175, validation loss: 0.6490
2024-06-03 00:26:22 [INFO]: Epoch 018 - training loss: 0.8975, validation loss: 0.6661
2024-06-03 00:26:23 [INFO]: Epoch 019 - training loss: 0.9228, validation loss: 0.6650
2024-06-03 00:26:24 [INFO]: Epoch 020 - training loss: 0.9337, validation loss: 0.6424
2024-06-03 00:26:25 [INFO]: Epoch 021 - training loss: 0.9135, validation loss: 0.6527
2024-06-03 00:26:25 [INFO]: Epoch 022 - training loss: 0.8978, validation loss: 0.6665
2024-06-03 00:26:26 [INFO]: Epoch 023 - training loss: 0.8969, validation loss: 0.6395
2024-06-03 00:26:27 [INFO]: Epoch 024 - training loss: 0.9122, validation loss: 0.6636
2024-06-03 00:26:28 [INFO]: Epoch 025 - training loss: 0.8997, validation loss: 0.6612
2024-06-03 00:26:29 [INFO]: Epoch 026 - training loss: 0.9021, validation loss: 0.6584
2024-06-03 00:26:30 [INFO]: Epoch 027 - training loss: 0.9071, validation loss: 0.6635
2024-06-03 00:26:30 [INFO]: Epoch 028 - training loss: 0.9059, validation loss: 0.6700
2024-06-03 00:26:31 [INFO]: Epoch 029 - training loss: 0.9207, validation loss: 0.6561
2024-06-03 00:26:32 [INFO]: Epoch 030 - training loss: 0.9124, validation loss: 0.6542
2024-06-03 00:26:33 [INFO]: Epoch 031 - training loss: 0.9168, validation loss: 0.6645
2024-06-03 00:26:34 [INFO]: Epoch 032 - training loss: 0.8993, validation loss: 0.6514
2024-06-03 00:26:35 [INFO]: Epoch 033 - training loss: 0.9066, validation loss: 0.6922
2024-06-03 00:26:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:26:35 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 00:26:35 [INFO]: Saved the model to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_2/20240603_T002606/FiLM.pypots
2024-06-03 00:26:35 [INFO]: Successfully saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_2/imputation.pkl
2024-06-03 00:26:35 [INFO]: Round2 - FiLM on ETT_h1: MAE=0.7092, MSE=0.9873, MRE=0.8347
2024-06-03 00:26:35 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:26:35 [INFO]: Using the given device: cuda:0
2024-06-03 00:26:35 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_3/20240603_T002635
2024-06-03 00:26:35 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_3/20240603_T002635/tensorboard
2024-06-03 00:26:35 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 00:26:36 [INFO]: Epoch 001 - training loss: 1.5539, validation loss: 1.0515
2024-06-03 00:26:37 [INFO]: Epoch 002 - training loss: 1.5205, validation loss: 0.9748
2024-06-03 00:26:38 [INFO]: Epoch 003 - training loss: 1.4614, validation loss: 1.0575
2024-06-03 00:26:39 [INFO]: Epoch 004 - training loss: 1.4847, validation loss: 1.0168
2024-06-03 00:26:40 [INFO]: Epoch 005 - training loss: 1.4247, validation loss: 0.9110
2024-06-03 00:26:41 [INFO]: Epoch 006 - training loss: 1.2910, validation loss: 0.9350
2024-06-03 00:26:41 [INFO]: Epoch 007 - training loss: 1.1449, validation loss: 0.8806
2024-06-03 00:26:42 [INFO]: Epoch 008 - training loss: 1.0618, validation loss: 0.8688
2024-06-03 00:26:43 [INFO]: Epoch 009 - training loss: 1.0506, validation loss: 0.7129
2024-06-03 00:26:44 [INFO]: Epoch 010 - training loss: 0.9933, validation loss: 0.7724
2024-06-03 00:26:45 [INFO]: Epoch 011 - training loss: 0.9702, validation loss: 0.6754
2024-06-03 00:26:46 [INFO]: Epoch 012 - training loss: 0.9393, validation loss: 0.7138
2024-06-03 00:26:47 [INFO]: Epoch 013 - training loss: 0.9279, validation loss: 0.6602
2024-06-03 00:26:47 [INFO]: Epoch 014 - training loss: 0.9320, validation loss: 0.6750
2024-06-03 00:26:48 [INFO]: Epoch 015 - training loss: 0.9079, validation loss: 0.6499
2024-06-03 00:26:49 [INFO]: Epoch 016 - training loss: 0.9171, validation loss: 0.6600
2024-06-03 00:26:50 [INFO]: Epoch 017 - training loss: 0.9044, validation loss: 0.6636
2024-06-03 00:26:51 [INFO]: Epoch 018 - training loss: 0.9146, validation loss: 0.6350
2024-06-03 00:26:51 [INFO]: Epoch 019 - training loss: 0.8988, validation loss: 0.6689
2024-06-03 00:26:52 [INFO]: Epoch 020 - training loss: 0.9015, validation loss: 0.6431
2024-06-03 00:26:53 [INFO]: Epoch 021 - training loss: 0.9166, validation loss: 0.6533
2024-06-03 00:26:54 [INFO]: Epoch 022 - training loss: 0.9182, validation loss: 0.6485
2024-06-03 00:26:55 [INFO]: Epoch 023 - training loss: 0.9292, validation loss: 0.6568
2024-06-03 00:26:55 [INFO]: Epoch 024 - training loss: 0.9091, validation loss: 0.6824
2024-06-03 00:26:56 [INFO]: Epoch 025 - training loss: 0.9103, validation loss: 0.6546
2024-06-03 00:26:57 [INFO]: Epoch 026 - training loss: 0.8989, validation loss: 0.6698
2024-06-03 00:26:57 [INFO]: Epoch 027 - training loss: 0.9055, validation loss: 0.6674
2024-06-03 00:26:58 [INFO]: Epoch 028 - training loss: 0.8996, validation loss: 0.6524
2024-06-03 00:26:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:26:58 [INFO]: Finished training. The best model is from epoch#18.
2024-06-03 00:26:58 [INFO]: Saved the model to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_3/20240603_T002635/FiLM.pypots
2024-06-03 00:26:59 [INFO]: Successfully saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_3/imputation.pkl
2024-06-03 00:26:59 [INFO]: Round3 - FiLM on ETT_h1: MAE=0.6821, MSE=0.9466, MRE=0.8027
2024-06-03 00:26:59 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:26:59 [INFO]: Using the given device: cuda:0
2024-06-03 00:26:59 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_4/20240603_T002659
2024-06-03 00:26:59 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_4/20240603_T002659/tensorboard
2024-06-03 00:26:59 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 00:26:59 [INFO]: Epoch 001 - training loss: 1.7235, validation loss: 1.1765
2024-06-03 00:27:00 [INFO]: Epoch 002 - training loss: 1.5544, validation loss: 0.9875
2024-06-03 00:27:01 [INFO]: Epoch 003 - training loss: 1.5289, validation loss: 1.0418
2024-06-03 00:27:02 [INFO]: Epoch 004 - training loss: 1.4903, validation loss: 1.0168
2024-06-03 00:27:02 [INFO]: Epoch 005 - training loss: 1.4650, validation loss: 0.9731
2024-06-03 00:27:03 [INFO]: Epoch 006 - training loss: 1.4608, validation loss: 1.0254
2024-06-03 00:27:04 [INFO]: Epoch 007 - training loss: 1.4346, validation loss: 0.9265
2024-06-03 00:27:04 [INFO]: Epoch 008 - training loss: 1.3482, validation loss: 0.9204
2024-06-03 00:27:05 [INFO]: Epoch 009 - training loss: 1.1498, validation loss: 0.9143
2024-06-03 00:27:06 [INFO]: Epoch 010 - training loss: 1.0995, validation loss: 0.8526
2024-06-03 00:27:06 [INFO]: Epoch 011 - training loss: 1.0426, validation loss: 0.8159
2024-06-03 00:27:07 [INFO]: Epoch 012 - training loss: 0.9893, validation loss: 0.7001
2024-06-03 00:27:08 [INFO]: Epoch 013 - training loss: 1.0055, validation loss: 0.7335
2024-06-03 00:27:08 [INFO]: Epoch 014 - training loss: 0.9663, validation loss: 0.7090
2024-06-03 00:27:09 [INFO]: Epoch 015 - training loss: 0.9623, validation loss: 0.6996
2024-06-03 00:27:10 [INFO]: Epoch 016 - training loss: 0.9160, validation loss: 0.6859
2024-06-03 00:27:10 [INFO]: Epoch 017 - training loss: 0.9317, validation loss: 0.6614
2024-06-03 00:27:11 [INFO]: Epoch 018 - training loss: 0.9168, validation loss: 0.6552
2024-06-03 00:27:12 [INFO]: Epoch 019 - training loss: 0.9171, validation loss: 0.6633
2024-06-03 00:27:12 [INFO]: Epoch 020 - training loss: 0.9025, validation loss: 0.6546
2024-06-03 00:27:13 [INFO]: Epoch 021 - training loss: 0.9211, validation loss: 0.6696
2024-06-03 00:27:13 [INFO]: Epoch 022 - training loss: 0.9011, validation loss: 0.6582
2024-06-03 00:27:14 [INFO]: Epoch 023 - training loss: 0.9070, validation loss: 0.6657
2024-06-03 00:27:15 [INFO]: Epoch 024 - training loss: 0.9024, validation loss: 0.6611
2024-06-03 00:27:15 [INFO]: Epoch 025 - training loss: 0.8843, validation loss: 0.6604
2024-06-03 00:27:16 [INFO]: Epoch 026 - training loss: 0.9024, validation loss: 0.6481
2024-06-03 00:27:17 [INFO]: Epoch 027 - training loss: 0.9282, validation loss: 0.6668
2024-06-03 00:27:17 [INFO]: Epoch 028 - training loss: 0.9180, validation loss: 0.6477
2024-06-03 00:27:18 [INFO]: Epoch 029 - training loss: 0.9083, validation loss: 0.6544
2024-06-03 00:27:19 [INFO]: Epoch 030 - training loss: 0.9190, validation loss: 0.6717
2024-06-03 00:27:19 [INFO]: Epoch 031 - training loss: 0.8981, validation loss: 0.6588
2024-06-03 00:27:20 [INFO]: Epoch 032 - training loss: 0.9140, validation loss: 0.6767
2024-06-03 00:27:21 [INFO]: Epoch 033 - training loss: 0.9021, validation loss: 0.6732
2024-06-03 00:27:21 [INFO]: Epoch 034 - training loss: 0.9053, validation loss: 0.6570
2024-06-03 00:27:22 [INFO]: Epoch 035 - training loss: 0.9144, validation loss: 0.6645
2024-06-03 00:27:23 [INFO]: Epoch 036 - training loss: 0.8983, validation loss: 0.6596
2024-06-03 00:27:23 [INFO]: Epoch 037 - training loss: 0.9033, validation loss: 0.6825
2024-06-03 00:27:24 [INFO]: Epoch 038 - training loss: 0.8922, validation loss: 0.6817
2024-06-03 00:27:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:27:24 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 00:27:24 [INFO]: Saved the model to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_4/20240603_T002659/FiLM.pypots
2024-06-03 00:27:24 [INFO]: Successfully saved to results_point_rate09/ETT_h1/FiLM_ETT_h1/round_4/imputation.pkl
2024-06-03 00:27:24 [INFO]: Round4 - FiLM on ETT_h1: MAE=0.6984, MSE=0.9720, MRE=0.8220
2024-06-03 00:27:24 [INFO]: Done! Final results:
Averaged FiLM (12,490 params) on ETT_h1: MAE=0.6972 ± 0.008690201137546125, MSE=0.9669 ± 0.013152016732300426, MRE=0.8205 ± 0.010227398577232667, average inference time=0.12
