2024-06-03 19:07:24 [INFO]: Have set the random seed as 1024 for numpy and pytorch.
2024-06-03 19:07:24 [INFO]: Using the given device: cuda:0
2024-06-03 19:07:24 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T190724
2024-06-03 19:07:24 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T190724/tensorboard
2024-06-03 19:07:24 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 19:07:26 [INFO]: Epoch 001 - training loss: 1.5090, validation loss: 1.0336
2024-06-03 19:07:27 [INFO]: Epoch 002 - training loss: 1.4980, validation loss: 0.9609
2024-06-03 19:07:28 [INFO]: Epoch 003 - training loss: 1.4333, validation loss: 0.9315
2024-06-03 19:07:29 [INFO]: Epoch 004 - training loss: 1.3835, validation loss: 0.9600
2024-06-03 19:07:30 [INFO]: Epoch 005 - training loss: 1.2096, validation loss: 0.8852
2024-06-03 19:07:31 [INFO]: Epoch 006 - training loss: 1.0578, validation loss: 0.8392
2024-06-03 19:07:32 [INFO]: Epoch 007 - training loss: 0.9817, validation loss: 0.8103
2024-06-03 19:07:33 [INFO]: Epoch 008 - training loss: 0.9477, validation loss: 0.6742
2024-06-03 19:07:34 [INFO]: Epoch 009 - training loss: 0.9158, validation loss: 0.6484
2024-06-03 19:07:34 [INFO]: Epoch 010 - training loss: 0.9213, validation loss: 0.6668
2024-06-03 19:07:35 [INFO]: Epoch 011 - training loss: 0.9197, validation loss: 0.6277
2024-06-03 19:07:36 [INFO]: Epoch 012 - training loss: 0.8919, validation loss: 0.6457
2024-06-03 19:07:37 [INFO]: Epoch 013 - training loss: 0.8820, validation loss: 0.6624
2024-06-03 19:07:38 [INFO]: Epoch 014 - training loss: 0.8729, validation loss: 0.6133
2024-06-03 19:07:39 [INFO]: Epoch 015 - training loss: 0.8676, validation loss: 0.5794
2024-06-03 19:07:40 [INFO]: Epoch 016 - training loss: 0.8694, validation loss: 0.5445
2024-06-03 19:07:41 [INFO]: Epoch 017 - training loss: 0.8470, validation loss: 0.5999
2024-06-03 19:07:42 [INFO]: Epoch 018 - training loss: 0.8329, validation loss: 0.5914
2024-06-03 19:07:43 [INFO]: Epoch 019 - training loss: 0.8131, validation loss: 0.5065
2024-06-03 19:07:44 [INFO]: Epoch 020 - training loss: 0.7838, validation loss: 0.5520
2024-06-03 19:07:45 [INFO]: Epoch 021 - training loss: 0.8276, validation loss: 0.4993
2024-06-03 19:07:46 [INFO]: Epoch 022 - training loss: 0.8274, validation loss: 0.4787
2024-06-03 19:07:47 [INFO]: Epoch 023 - training loss: 0.8470, validation loss: 0.5615
2024-06-03 19:07:47 [INFO]: Epoch 024 - training loss: 0.8038, validation loss: 0.4884
2024-06-03 19:07:48 [INFO]: Epoch 025 - training loss: 0.8113, validation loss: 0.4770
2024-06-03 19:07:49 [INFO]: Epoch 026 - training loss: 0.7955, validation loss: 0.4958
2024-06-03 19:07:50 [INFO]: Epoch 027 - training loss: 0.8126, validation loss: 0.4673
2024-06-03 19:07:51 [INFO]: Epoch 028 - training loss: 0.7738, validation loss: 0.4681
2024-06-03 19:07:52 [INFO]: Epoch 029 - training loss: 0.7977, validation loss: 0.4607
2024-06-03 19:07:53 [INFO]: Epoch 030 - training loss: 0.8051, validation loss: 0.4996
2024-06-03 19:07:54 [INFO]: Epoch 031 - training loss: 0.8136, validation loss: 0.4697
2024-06-03 19:07:55 [INFO]: Epoch 032 - training loss: 0.7758, validation loss: 0.4732
2024-06-03 19:07:56 [INFO]: Epoch 033 - training loss: 0.7824, validation loss: 0.4971
2024-06-03 19:07:57 [INFO]: Epoch 034 - training loss: 0.7686, validation loss: 0.4507
2024-06-03 19:07:58 [INFO]: Epoch 035 - training loss: 0.7924, validation loss: 0.5072
2024-06-03 19:07:59 [INFO]: Epoch 036 - training loss: 0.8045, validation loss: 0.5581
2024-06-03 19:07:59 [INFO]: Epoch 037 - training loss: 0.7901, validation loss: 0.4823
2024-06-03 19:08:00 [INFO]: Epoch 038 - training loss: 0.7920, validation loss: 0.4579
2024-06-03 19:08:01 [INFO]: Epoch 039 - training loss: 0.7772, validation loss: 0.5192
2024-06-03 19:08:02 [INFO]: Epoch 040 - training loss: 0.7772, validation loss: 0.5251
2024-06-03 19:08:03 [INFO]: Epoch 041 - training loss: 0.7749, validation loss: 0.4958
2024-06-03 19:08:04 [INFO]: Epoch 042 - training loss: 0.7795, validation loss: 0.4664
2024-06-03 19:08:05 [INFO]: Epoch 043 - training loss: 0.7695, validation loss: 0.5280
2024-06-03 19:08:06 [INFO]: Epoch 044 - training loss: 0.7490, validation loss: 0.4851
2024-06-03 19:08:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:08:06 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 19:08:06 [INFO]: Saved the model to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T190724/StemGNN.pypots
2024-06-03 19:08:07 [INFO]: Successfully saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_0/imputation.pkl
2024-06-03 19:08:07 [INFO]: Round0 - StemGNN on ETT_h1: MAE=0.5659, MSE=0.5845, MRE=0.6659
2024-06-03 19:08:07 [INFO]: Have set the random seed as 1025 for numpy and pytorch.
2024-06-03 19:08:07 [INFO]: Using the given device: cuda:0
2024-06-03 19:08:07 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T190807
2024-06-03 19:08:07 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T190807/tensorboard
2024-06-03 19:08:07 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 19:08:08 [INFO]: Epoch 001 - training loss: 1.4990, validation loss: 1.0058
2024-06-03 19:08:09 [INFO]: Epoch 002 - training loss: 1.4831, validation loss: 0.9687
2024-06-03 19:08:10 [INFO]: Epoch 003 - training loss: 1.4227, validation loss: 0.9475
2024-06-03 19:08:11 [INFO]: Epoch 004 - training loss: 1.4551, validation loss: 0.9543
2024-06-03 19:08:12 [INFO]: Epoch 005 - training loss: 1.4375, validation loss: 0.9060
2024-06-03 19:08:12 [INFO]: Epoch 006 - training loss: 1.4255, validation loss: 0.9744
2024-06-03 19:08:13 [INFO]: Epoch 007 - training loss: 1.4185, validation loss: 0.9090
2024-06-03 19:08:14 [INFO]: Epoch 008 - training loss: 1.3661, validation loss: 0.9118
2024-06-03 19:08:15 [INFO]: Epoch 009 - training loss: 1.3720, validation loss: 0.9097
2024-06-03 19:08:16 [INFO]: Epoch 010 - training loss: 1.3528, validation loss: 0.9285
2024-06-03 19:08:17 [INFO]: Epoch 011 - training loss: 1.3114, validation loss: 0.9209
2024-06-03 19:08:18 [INFO]: Epoch 012 - training loss: 1.2985, validation loss: 0.8850
2024-06-03 19:08:19 [INFO]: Epoch 013 - training loss: 1.1764, validation loss: 0.7627
2024-06-03 19:08:20 [INFO]: Epoch 014 - training loss: 1.0249, validation loss: 0.7255
2024-06-03 19:08:21 [INFO]: Epoch 015 - training loss: 0.9784, validation loss: 0.6663
2024-06-03 19:08:22 [INFO]: Epoch 016 - training loss: 0.8990, validation loss: 0.6840
2024-06-03 19:08:23 [INFO]: Epoch 017 - training loss: 0.8791, validation loss: 0.5557
2024-06-03 19:08:24 [INFO]: Epoch 018 - training loss: 0.8484, validation loss: 0.5239
2024-06-03 19:08:25 [INFO]: Epoch 019 - training loss: 0.8552, validation loss: 0.5635
2024-06-03 19:08:26 [INFO]: Epoch 020 - training loss: 0.8435, validation loss: 0.5879
2024-06-03 19:08:26 [INFO]: Epoch 021 - training loss: 0.8541, validation loss: 0.5262
2024-06-03 19:08:27 [INFO]: Epoch 022 - training loss: 0.8011, validation loss: 0.4982
2024-06-03 19:08:28 [INFO]: Epoch 023 - training loss: 0.8073, validation loss: 0.5487
2024-06-03 19:08:29 [INFO]: Epoch 024 - training loss: 0.7758, validation loss: 0.5197
2024-06-03 19:08:30 [INFO]: Epoch 025 - training loss: 0.7793, validation loss: 0.4660
2024-06-03 19:08:31 [INFO]: Epoch 026 - training loss: 0.7984, validation loss: 0.4898
2024-06-03 19:08:32 [INFO]: Epoch 027 - training loss: 0.7843, validation loss: 0.4833
2024-06-03 19:08:33 [INFO]: Epoch 028 - training loss: 0.7573, validation loss: 0.5148
2024-06-03 19:08:34 [INFO]: Epoch 029 - training loss: 0.7725, validation loss: 0.4605
2024-06-03 19:08:35 [INFO]: Epoch 030 - training loss: 0.7694, validation loss: 0.4921
2024-06-03 19:08:36 [INFO]: Epoch 031 - training loss: 0.7793, validation loss: 0.4807
2024-06-03 19:08:37 [INFO]: Epoch 032 - training loss: 0.7480, validation loss: 0.5063
2024-06-03 19:08:38 [INFO]: Epoch 033 - training loss: 0.7264, validation loss: 0.5014
2024-06-03 19:08:39 [INFO]: Epoch 034 - training loss: 0.7378, validation loss: 0.4834
2024-06-03 19:08:39 [INFO]: Epoch 035 - training loss: 0.7375, validation loss: 0.4638
2024-06-03 19:08:40 [INFO]: Epoch 036 - training loss: 0.7089, validation loss: 0.4671
2024-06-03 19:08:41 [INFO]: Epoch 037 - training loss: 0.7227, validation loss: 0.4472
2024-06-03 19:08:42 [INFO]: Epoch 038 - training loss: 0.7297, validation loss: 0.4394
2024-06-03 19:08:43 [INFO]: Epoch 039 - training loss: 0.7296, validation loss: 0.4178
2024-06-03 19:08:44 [INFO]: Epoch 040 - training loss: 0.7212, validation loss: 0.4228
2024-06-03 19:08:45 [INFO]: Epoch 041 - training loss: 0.6969, validation loss: 0.4486
2024-06-03 19:08:46 [INFO]: Epoch 042 - training loss: 0.7017, validation loss: 0.4371
2024-06-03 19:08:47 [INFO]: Epoch 043 - training loss: 0.6873, validation loss: 0.4137
2024-06-03 19:08:48 [INFO]: Epoch 044 - training loss: 0.6877, validation loss: 0.4294
2024-06-03 19:08:49 [INFO]: Epoch 045 - training loss: 0.7063, validation loss: 0.4562
2024-06-03 19:08:50 [INFO]: Epoch 046 - training loss: 0.7082, validation loss: 0.4617
2024-06-03 19:08:51 [INFO]: Epoch 047 - training loss: 0.6894, validation loss: 0.4098
2024-06-03 19:08:52 [INFO]: Epoch 048 - training loss: 0.6736, validation loss: 0.4208
2024-06-03 19:08:52 [INFO]: Epoch 049 - training loss: 0.6901, validation loss: 0.4411
2024-06-03 19:08:53 [INFO]: Epoch 050 - training loss: 0.6922, validation loss: 0.4221
2024-06-03 19:08:54 [INFO]: Epoch 051 - training loss: 0.6757, validation loss: 0.4450
2024-06-03 19:08:55 [INFO]: Epoch 052 - training loss: 0.6740, validation loss: 0.4344
2024-06-03 19:08:56 [INFO]: Epoch 053 - training loss: 0.6788, validation loss: 0.4312
2024-06-03 19:08:57 [INFO]: Epoch 054 - training loss: 0.6907, validation loss: 0.4103
2024-06-03 19:08:58 [INFO]: Epoch 055 - training loss: 0.6888, validation loss: 0.4721
2024-06-03 19:08:59 [INFO]: Epoch 056 - training loss: 0.6855, validation loss: 0.4027
2024-06-03 19:09:00 [INFO]: Epoch 057 - training loss: 0.6894, validation loss: 0.3912
2024-06-03 19:09:01 [INFO]: Epoch 058 - training loss: 0.6546, validation loss: 0.4068
2024-06-03 19:09:02 [INFO]: Epoch 059 - training loss: 0.6722, validation loss: 0.4251
2024-06-03 19:09:03 [INFO]: Epoch 060 - training loss: 0.6519, validation loss: 0.4378
2024-06-03 19:09:04 [INFO]: Epoch 061 - training loss: 0.6585, validation loss: 0.4344
2024-06-03 19:09:05 [INFO]: Epoch 062 - training loss: 0.6444, validation loss: 0.4468
2024-06-03 19:09:05 [INFO]: Epoch 063 - training loss: 0.6487, validation loss: 0.4369
2024-06-03 19:09:06 [INFO]: Epoch 064 - training loss: 0.6693, validation loss: 0.4016
2024-06-03 19:09:07 [INFO]: Epoch 065 - training loss: 0.6721, validation loss: 0.4174
2024-06-03 19:09:08 [INFO]: Epoch 066 - training loss: 0.6486, validation loss: 0.4251
2024-06-03 19:09:09 [INFO]: Epoch 067 - training loss: 0.6549, validation loss: 0.4378
2024-06-03 19:09:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:09:09 [INFO]: Finished training. The best model is from epoch#57.
2024-06-03 19:09:09 [INFO]: Saved the model to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T190807/StemGNN.pypots
2024-06-03 19:09:10 [INFO]: Successfully saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_1/imputation.pkl
2024-06-03 19:09:10 [INFO]: Round1 - StemGNN on ETT_h1: MAE=0.5351, MSE=0.5238, MRE=0.6297
2024-06-03 19:09:10 [INFO]: Have set the random seed as 1026 for numpy and pytorch.
2024-06-03 19:09:10 [INFO]: Using the given device: cuda:0
2024-06-03 19:09:10 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T190910
2024-06-03 19:09:10 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T190910/tensorboard
2024-06-03 19:09:10 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 19:09:11 [INFO]: Epoch 001 - training loss: 1.5025, validation loss: 1.0273
2024-06-03 19:09:12 [INFO]: Epoch 002 - training loss: 1.5199, validation loss: 1.0078
2024-06-03 19:09:13 [INFO]: Epoch 003 - training loss: 1.4478, validation loss: 0.9538
2024-06-03 19:09:14 [INFO]: Epoch 004 - training loss: 1.3747, validation loss: 0.9744
2024-06-03 19:09:14 [INFO]: Epoch 005 - training loss: 1.2292, validation loss: 0.8262
2024-06-03 19:09:15 [INFO]: Epoch 006 - training loss: 1.0967, validation loss: 0.7942
2024-06-03 19:09:16 [INFO]: Epoch 007 - training loss: 0.9795, validation loss: 0.7323
2024-06-03 19:09:17 [INFO]: Epoch 008 - training loss: 0.9315, validation loss: 0.6374
2024-06-03 19:09:18 [INFO]: Epoch 009 - training loss: 0.9199, validation loss: 0.6172
2024-06-03 19:09:19 [INFO]: Epoch 010 - training loss: 0.9171, validation loss: 0.6053
2024-06-03 19:09:20 [INFO]: Epoch 011 - training loss: 0.8747, validation loss: 0.6270
2024-06-03 19:09:21 [INFO]: Epoch 012 - training loss: 0.8704, validation loss: 0.5993
2024-06-03 19:09:22 [INFO]: Epoch 013 - training loss: 0.8344, validation loss: 0.5863
2024-06-03 19:09:23 [INFO]: Epoch 014 - training loss: 0.8253, validation loss: 0.5692
2024-06-03 19:09:24 [INFO]: Epoch 015 - training loss: 0.8254, validation loss: 0.5687
2024-06-03 19:09:25 [INFO]: Epoch 016 - training loss: 0.8166, validation loss: 0.5737
2024-06-03 19:09:26 [INFO]: Epoch 017 - training loss: 0.8157, validation loss: 0.5779
2024-06-03 19:09:27 [INFO]: Epoch 018 - training loss: 0.8014, validation loss: 0.5064
2024-06-03 19:09:28 [INFO]: Epoch 019 - training loss: 0.8026, validation loss: 0.5173
2024-06-03 19:09:28 [INFO]: Epoch 020 - training loss: 0.7662, validation loss: 0.5049
2024-06-03 19:09:29 [INFO]: Epoch 021 - training loss: 0.7474, validation loss: 0.5008
2024-06-03 19:09:30 [INFO]: Epoch 022 - training loss: 0.7548, validation loss: 0.4719
2024-06-03 19:09:31 [INFO]: Epoch 023 - training loss: 0.7482, validation loss: 0.4647
2024-06-03 19:09:32 [INFO]: Epoch 024 - training loss: 0.7442, validation loss: 0.4374
2024-06-03 19:09:33 [INFO]: Epoch 025 - training loss: 0.7319, validation loss: 0.4504
2024-06-03 19:09:34 [INFO]: Epoch 026 - training loss: 0.6928, validation loss: 0.4595
2024-06-03 19:09:35 [INFO]: Epoch 027 - training loss: 0.7300, validation loss: 0.4251
2024-06-03 19:09:36 [INFO]: Epoch 028 - training loss: 0.7074, validation loss: 0.4273
2024-06-03 19:09:37 [INFO]: Epoch 029 - training loss: 0.7073, validation loss: 0.4313
2024-06-03 19:09:38 [INFO]: Epoch 030 - training loss: 0.7037, validation loss: 0.4280
2024-06-03 19:09:39 [INFO]: Epoch 031 - training loss: 0.7255, validation loss: 0.4325
2024-06-03 19:09:40 [INFO]: Epoch 032 - training loss: 0.6996, validation loss: 0.4310
2024-06-03 19:09:41 [INFO]: Epoch 033 - training loss: 0.6943, validation loss: 0.4235
2024-06-03 19:09:41 [INFO]: Epoch 034 - training loss: 0.6917, validation loss: 0.4449
2024-06-03 19:09:42 [INFO]: Epoch 035 - training loss: 0.6563, validation loss: 0.4718
2024-06-03 19:09:43 [INFO]: Epoch 036 - training loss: 0.6779, validation loss: 0.4150
2024-06-03 19:09:44 [INFO]: Epoch 037 - training loss: 0.6511, validation loss: 0.4189
2024-06-03 19:09:45 [INFO]: Epoch 038 - training loss: 0.6484, validation loss: 0.4213
2024-06-03 19:09:46 [INFO]: Epoch 039 - training loss: 0.6622, validation loss: 0.4147
2024-06-03 19:09:47 [INFO]: Epoch 040 - training loss: 0.6663, validation loss: 0.4153
2024-06-03 19:09:48 [INFO]: Epoch 041 - training loss: 0.6577, validation loss: 0.3996
2024-06-03 19:09:49 [INFO]: Epoch 042 - training loss: 0.6406, validation loss: 0.4141
2024-06-03 19:09:50 [INFO]: Epoch 043 - training loss: 0.6531, validation loss: 0.4191
2024-06-03 19:09:51 [INFO]: Epoch 044 - training loss: 0.6426, validation loss: 0.4058
2024-06-03 19:09:52 [INFO]: Epoch 045 - training loss: 0.6519, validation loss: 0.4004
2024-06-03 19:09:53 [INFO]: Epoch 046 - training loss: 0.6620, validation loss: 0.3945
2024-06-03 19:09:53 [INFO]: Epoch 047 - training loss: 0.6462, validation loss: 0.3930
2024-06-03 19:09:54 [INFO]: Epoch 048 - training loss: 0.6528, validation loss: 0.3846
2024-06-03 19:09:55 [INFO]: Epoch 049 - training loss: 0.6414, validation loss: 0.3965
2024-06-03 19:09:56 [INFO]: Epoch 050 - training loss: 0.6416, validation loss: 0.3857
2024-06-03 19:09:57 [INFO]: Epoch 051 - training loss: 0.6494, validation loss: 0.3812
2024-06-03 19:09:58 [INFO]: Epoch 052 - training loss: 0.6532, validation loss: 0.4060
2024-06-03 19:09:59 [INFO]: Epoch 053 - training loss: 0.6634, validation loss: 0.4112
2024-06-03 19:10:00 [INFO]: Epoch 054 - training loss: 0.6507, validation loss: 0.4122
2024-06-03 19:10:01 [INFO]: Epoch 055 - training loss: 0.6447, validation loss: 0.4126
2024-06-03 19:10:02 [INFO]: Epoch 056 - training loss: 0.6398, validation loss: 0.3994
2024-06-03 19:10:03 [INFO]: Epoch 057 - training loss: 0.6140, validation loss: 0.3838
2024-06-03 19:10:04 [INFO]: Epoch 058 - training loss: 0.6047, validation loss: 0.3936
2024-06-03 19:10:05 [INFO]: Epoch 059 - training loss: 0.6418, validation loss: 0.3972
2024-06-03 19:10:06 [INFO]: Epoch 060 - training loss: 0.6397, validation loss: 0.3912
2024-06-03 19:10:06 [INFO]: Epoch 061 - training loss: 0.6425, validation loss: 0.3976
2024-06-03 19:10:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:10:06 [INFO]: Finished training. The best model is from epoch#51.
2024-06-03 19:10:07 [INFO]: Saved the model to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T190910/StemGNN.pypots
2024-06-03 19:10:07 [INFO]: Successfully saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_2/imputation.pkl
2024-06-03 19:10:07 [INFO]: Round2 - StemGNN on ETT_h1: MAE=0.5279, MSE=0.5140, MRE=0.6212
2024-06-03 19:10:07 [INFO]: Have set the random seed as 1027 for numpy and pytorch.
2024-06-03 19:10:07 [INFO]: Using the given device: cuda:0
2024-06-03 19:10:07 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T191007
2024-06-03 19:10:07 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T191007/tensorboard
2024-06-03 19:10:07 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 19:10:08 [INFO]: Epoch 001 - training loss: 1.5622, validation loss: 1.0411
2024-06-03 19:10:09 [INFO]: Epoch 002 - training loss: 1.5147, validation loss: 0.9974
2024-06-03 19:10:10 [INFO]: Epoch 003 - training loss: 1.4466, validation loss: 0.9729
2024-06-03 19:10:11 [INFO]: Epoch 004 - training loss: 1.3702, validation loss: 0.9185
2024-06-03 19:10:12 [INFO]: Epoch 005 - training loss: 1.2312, validation loss: 0.9327
2024-06-03 19:10:13 [INFO]: Epoch 006 - training loss: 1.1394, validation loss: 0.8530
2024-06-03 19:10:14 [INFO]: Epoch 007 - training loss: 1.0032, validation loss: 0.7087
2024-06-03 19:10:15 [INFO]: Epoch 008 - training loss: 0.9614, validation loss: 0.6543
2024-06-03 19:10:16 [INFO]: Epoch 009 - training loss: 0.9549, validation loss: 0.7568
2024-06-03 19:10:16 [INFO]: Epoch 010 - training loss: 0.9313, validation loss: 0.6950
2024-06-03 19:10:17 [INFO]: Epoch 011 - training loss: 0.9115, validation loss: 0.6438
2024-06-03 19:10:18 [INFO]: Epoch 012 - training loss: 0.8954, validation loss: 0.6268
2024-06-03 19:10:19 [INFO]: Epoch 013 - training loss: 0.8636, validation loss: 0.6415
2024-06-03 19:10:20 [INFO]: Epoch 014 - training loss: 0.8453, validation loss: 0.6438
2024-06-03 19:10:21 [INFO]: Epoch 015 - training loss: 0.8412, validation loss: 0.6395
2024-06-03 19:10:22 [INFO]: Epoch 016 - training loss: 0.8581, validation loss: 0.6174
2024-06-03 19:10:23 [INFO]: Epoch 017 - training loss: 0.8372, validation loss: 0.6089
2024-06-03 19:10:24 [INFO]: Epoch 018 - training loss: 0.8447, validation loss: 0.5971
2024-06-03 19:10:25 [INFO]: Epoch 019 - training loss: 0.8461, validation loss: 0.5664
2024-06-03 19:10:26 [INFO]: Epoch 020 - training loss: 0.8512, validation loss: 0.5273
2024-06-03 19:10:27 [INFO]: Epoch 021 - training loss: 0.8168, validation loss: 0.5379
2024-06-03 19:10:28 [INFO]: Epoch 022 - training loss: 0.7960, validation loss: 0.5152
2024-06-03 19:10:29 [INFO]: Epoch 023 - training loss: 0.8137, validation loss: 0.5010
2024-06-03 19:10:30 [INFO]: Epoch 024 - training loss: 0.8016, validation loss: 0.5094
2024-06-03 19:10:31 [INFO]: Epoch 025 - training loss: 0.7943, validation loss: 0.5740
2024-06-03 19:10:32 [INFO]: Epoch 026 - training loss: 0.7852, validation loss: 0.5182
2024-06-03 19:10:33 [INFO]: Epoch 027 - training loss: 0.7893, validation loss: 0.5247
2024-06-03 19:10:34 [INFO]: Epoch 028 - training loss: 0.7644, validation loss: 0.4927
2024-06-03 19:10:34 [INFO]: Epoch 029 - training loss: 0.7514, validation loss: 0.5014
2024-06-03 19:10:35 [INFO]: Epoch 030 - training loss: 0.7265, validation loss: 0.5132
2024-06-03 19:10:36 [INFO]: Epoch 031 - training loss: 0.7391, validation loss: 0.4907
2024-06-03 19:10:37 [INFO]: Epoch 032 - training loss: 0.7373, validation loss: 0.4818
2024-06-03 19:10:38 [INFO]: Epoch 033 - training loss: 0.7569, validation loss: 0.4729
2024-06-03 19:10:39 [INFO]: Epoch 034 - training loss: 0.7505, validation loss: 0.4741
2024-06-03 19:10:40 [INFO]: Epoch 035 - training loss: 0.7376, validation loss: 0.4831
2024-06-03 19:10:41 [INFO]: Epoch 036 - training loss: 0.7116, validation loss: 0.4622
2024-06-03 19:10:42 [INFO]: Epoch 037 - training loss: 0.7178, validation loss: 0.4299
2024-06-03 19:10:43 [INFO]: Epoch 038 - training loss: 0.7057, validation loss: 0.4258
2024-06-03 19:10:44 [INFO]: Epoch 039 - training loss: 0.7464, validation loss: 0.4639
2024-06-03 19:10:45 [INFO]: Epoch 040 - training loss: 0.7090, validation loss: 0.4668
2024-06-03 19:10:46 [INFO]: Epoch 041 - training loss: 0.7123, validation loss: 0.4612
2024-06-03 19:10:47 [INFO]: Epoch 042 - training loss: 0.7148, validation loss: 0.4838
2024-06-03 19:10:48 [INFO]: Epoch 043 - training loss: 0.7035, validation loss: 0.4835
2024-06-03 19:10:49 [INFO]: Epoch 044 - training loss: 0.7220, validation loss: 0.4435
2024-06-03 19:10:50 [INFO]: Epoch 045 - training loss: 0.6957, validation loss: 0.4358
2024-06-03 19:10:50 [INFO]: Epoch 046 - training loss: 0.7207, validation loss: 0.4512
2024-06-03 19:10:51 [INFO]: Epoch 047 - training loss: 0.6786, validation loss: 0.4535
2024-06-03 19:10:52 [INFO]: Epoch 048 - training loss: 0.6744, validation loss: 0.4512
2024-06-03 19:10:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:10:52 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 19:10:52 [INFO]: Saved the model to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T191007/StemGNN.pypots
2024-06-03 19:10:53 [INFO]: Successfully saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_3/imputation.pkl
2024-06-03 19:10:53 [INFO]: Round3 - StemGNN on ETT_h1: MAE=0.5571, MSE=0.5790, MRE=0.6556
2024-06-03 19:10:53 [INFO]: Have set the random seed as 1028 for numpy and pytorch.
2024-06-03 19:10:53 [INFO]: Using the given device: cuda:0
2024-06-03 19:10:53 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T191053
2024-06-03 19:10:53 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T191053/tensorboard
2024-06-03 19:10:53 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 19:10:54 [INFO]: Epoch 001 - training loss: 1.5067, validation loss: 1.0289
2024-06-03 19:10:55 [INFO]: Epoch 002 - training loss: 1.5176, validation loss: 0.9945
2024-06-03 19:10:56 [INFO]: Epoch 003 - training loss: 1.4672, validation loss: 0.9994
2024-06-03 19:10:57 [INFO]: Epoch 004 - training loss: 1.4627, validation loss: 0.9556
2024-06-03 19:10:58 [INFO]: Epoch 005 - training loss: 1.4471, validation loss: 0.9493
2024-06-03 19:10:59 [INFO]: Epoch 006 - training loss: 1.4131, validation loss: 0.9287
2024-06-03 19:11:00 [INFO]: Epoch 007 - training loss: 1.4288, validation loss: 0.9310
2024-06-03 19:11:00 [INFO]: Epoch 008 - training loss: 1.3827, validation loss: 0.9451
2024-06-03 19:11:01 [INFO]: Epoch 009 - training loss: 1.3493, validation loss: 0.9102
2024-06-03 19:11:02 [INFO]: Epoch 010 - training loss: 1.2498, validation loss: 0.9153
2024-06-03 19:11:03 [INFO]: Epoch 011 - training loss: 1.1239, validation loss: 0.8070
2024-06-03 19:11:04 [INFO]: Epoch 012 - training loss: 0.9734, validation loss: 0.7319
2024-06-03 19:11:05 [INFO]: Epoch 013 - training loss: 0.9396, validation loss: 0.6351
2024-06-03 19:11:06 [INFO]: Epoch 014 - training loss: 0.9071, validation loss: 0.6269
2024-06-03 19:11:07 [INFO]: Epoch 015 - training loss: 0.8309, validation loss: 0.5648
2024-06-03 19:11:08 [INFO]: Epoch 016 - training loss: 0.8177, validation loss: 0.5484
2024-06-03 19:11:09 [INFO]: Epoch 017 - training loss: 0.8080, validation loss: 0.5930
2024-06-03 19:11:10 [INFO]: Epoch 018 - training loss: 0.8285, validation loss: 0.5193
2024-06-03 19:11:11 [INFO]: Epoch 019 - training loss: 0.7813, validation loss: 0.5343
2024-06-03 19:11:12 [INFO]: Epoch 020 - training loss: 0.7764, validation loss: 0.5061
2024-06-03 19:11:13 [INFO]: Epoch 021 - training loss: 0.7609, validation loss: 0.4843
2024-06-03 19:11:14 [INFO]: Epoch 022 - training loss: 0.7575, validation loss: 0.5000
2024-06-03 19:11:15 [INFO]: Epoch 023 - training loss: 0.7600, validation loss: 0.5548
2024-06-03 19:11:15 [INFO]: Epoch 024 - training loss: 0.7788, validation loss: 0.4845
2024-06-03 19:11:16 [INFO]: Epoch 025 - training loss: 0.7605, validation loss: 0.4748
2024-06-03 19:11:17 [INFO]: Epoch 026 - training loss: 0.7416, validation loss: 0.5051
2024-06-03 19:11:18 [INFO]: Epoch 027 - training loss: 0.7641, validation loss: 0.5062
2024-06-03 19:11:19 [INFO]: Epoch 028 - training loss: 0.7812, validation loss: 0.4897
2024-06-03 19:11:20 [INFO]: Epoch 029 - training loss: 0.7917, validation loss: 0.4456
2024-06-03 19:11:21 [INFO]: Epoch 030 - training loss: 0.7791, validation loss: 0.5572
2024-06-03 19:11:22 [INFO]: Epoch 031 - training loss: 0.7477, validation loss: 0.5352
2024-06-03 19:11:23 [INFO]: Epoch 032 - training loss: 0.7474, validation loss: 0.4709
2024-06-03 19:11:24 [INFO]: Epoch 033 - training loss: 0.7169, validation loss: 0.4409
2024-06-03 19:11:25 [INFO]: Epoch 034 - training loss: 0.7063, validation loss: 0.4807
2024-06-03 19:11:26 [INFO]: Epoch 035 - training loss: 0.6901, validation loss: 0.4801
2024-06-03 19:11:27 [INFO]: Epoch 036 - training loss: 0.6861, validation loss: 0.4292
2024-06-03 19:11:28 [INFO]: Epoch 037 - training loss: 0.6938, validation loss: 0.4509
2024-06-03 19:11:29 [INFO]: Epoch 038 - training loss: 0.7130, validation loss: 0.4464
2024-06-03 19:11:30 [INFO]: Epoch 039 - training loss: 0.7013, validation loss: 0.4432
2024-06-03 19:11:31 [INFO]: Epoch 040 - training loss: 0.6919, validation loss: 0.4276
2024-06-03 19:11:31 [INFO]: Epoch 041 - training loss: 0.6770, validation loss: 0.4013
2024-06-03 19:11:32 [INFO]: Epoch 042 - training loss: 0.6857, validation loss: 0.4498
2024-06-03 19:11:33 [INFO]: Epoch 043 - training loss: 0.6708, validation loss: 0.4688
2024-06-03 19:11:34 [INFO]: Epoch 044 - training loss: 0.6751, validation loss: 0.4419
2024-06-03 19:11:35 [INFO]: Epoch 045 - training loss: 0.7185, validation loss: 0.4464
2024-06-03 19:11:36 [INFO]: Epoch 046 - training loss: 0.6752, validation loss: 0.4292
2024-06-03 19:11:37 [INFO]: Epoch 047 - training loss: 0.6686, validation loss: 0.4483
2024-06-03 19:11:38 [INFO]: Epoch 048 - training loss: 0.6703, validation loss: 0.4263
2024-06-03 19:11:39 [INFO]: Epoch 049 - training loss: 0.6681, validation loss: 0.4283
2024-06-03 19:11:40 [INFO]: Epoch 050 - training loss: 0.6553, validation loss: 0.4241
2024-06-03 19:11:41 [INFO]: Epoch 051 - training loss: 0.6586, validation loss: 0.4289
2024-06-03 19:11:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:11:41 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 19:11:41 [INFO]: Saved the model to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T191053/StemGNN.pypots
2024-06-03 19:11:41 [INFO]: Successfully saved to results_point_rate09/ETT_h1/StemGNN_ETT_h1/round_4/imputation.pkl
2024-06-03 19:11:41 [INFO]: Round4 - StemGNN on ETT_h1: MAE=0.5414, MSE=0.5658, MRE=0.6372
2024-06-03 19:11:41 [INFO]: Done! Final results:
Averaged StemGNN (6,397,975 params) on ETT_h1: MAE=0.5455 ± 0.014036958045771021, MSE=0.5534 ± 0.028993967912091384, MRE=0.6419 ± 0.01651993578442427, average inference time=0.18
