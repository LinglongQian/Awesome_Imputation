2024-06-03 00:41:51 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:41:51 [INFO]: Using the given device: cuda:0
2024-06-03 00:41:53 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_0/20240603_T004153
2024-06-03 00:41:53 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_0/20240603_T004153/tensorboard
2024-06-03 00:41:54 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 2,259
2024-06-03 00:41:59 [INFO]: Epoch 001 - training loss: 1.5461, validation loss: 1.3675
2024-06-03 00:42:00 [INFO]: Epoch 002 - training loss: 1.3961, validation loss: 1.3399
2024-06-03 00:42:01 [INFO]: Epoch 003 - training loss: 1.3217, validation loss: 1.3060
2024-06-03 00:42:01 [INFO]: Epoch 004 - training loss: 1.2312, validation loss: 1.2761
2024-06-03 00:42:02 [INFO]: Epoch 005 - training loss: 1.1248, validation loss: 1.2483
2024-06-03 00:42:02 [INFO]: Epoch 006 - training loss: 0.9714, validation loss: 1.2227
2024-06-03 00:42:03 [INFO]: Epoch 007 - training loss: 0.7780, validation loss: 1.2037
2024-06-03 00:42:03 [INFO]: Epoch 008 - training loss: 0.5785, validation loss: 1.1896
2024-06-03 00:42:04 [INFO]: Epoch 009 - training loss: 0.4833, validation loss: 1.1871
2024-06-03 00:42:05 [INFO]: Epoch 010 - training loss: 0.4618, validation loss: 1.1857
2024-06-03 00:42:05 [INFO]: Epoch 011 - training loss: 0.4388, validation loss: 1.1794
2024-06-03 00:42:06 [INFO]: Epoch 012 - training loss: 0.4202, validation loss: 1.1720
2024-06-03 00:42:06 [INFO]: Epoch 013 - training loss: 0.4119, validation loss: 1.1665
2024-06-03 00:42:07 [INFO]: Epoch 014 - training loss: 0.4029, validation loss: 1.1628
2024-06-03 00:42:08 [INFO]: Epoch 015 - training loss: 0.3940, validation loss: 1.1593
2024-06-03 00:42:08 [INFO]: Epoch 016 - training loss: 0.3883, validation loss: 1.1558
2024-06-03 00:42:09 [INFO]: Epoch 017 - training loss: 0.3834, validation loss: 1.1523
2024-06-03 00:42:09 [INFO]: Epoch 018 - training loss: 0.3726, validation loss: 1.1488
2024-06-03 00:42:10 [INFO]: Epoch 019 - training loss: 0.3695, validation loss: 1.1450
2024-06-03 00:42:10 [INFO]: Epoch 020 - training loss: 0.3651, validation loss: 1.1422
2024-06-03 00:42:11 [INFO]: Epoch 021 - training loss: 0.3593, validation loss: 1.1428
2024-06-03 00:42:11 [INFO]: Epoch 022 - training loss: 0.3562, validation loss: 1.1406
2024-06-03 00:42:12 [INFO]: Epoch 023 - training loss: 0.3463, validation loss: 1.1380
2024-06-03 00:42:13 [INFO]: Epoch 024 - training loss: 0.3443, validation loss: 1.1355
2024-06-03 00:42:13 [INFO]: Epoch 025 - training loss: 0.3458, validation loss: 1.1365
2024-06-03 00:42:14 [INFO]: Epoch 026 - training loss: 0.3387, validation loss: 1.1359
2024-06-03 00:42:14 [INFO]: Epoch 027 - training loss: 0.3385, validation loss: 1.1318
2024-06-03 00:42:15 [INFO]: Epoch 028 - training loss: 0.3384, validation loss: 1.1288
2024-06-03 00:42:15 [INFO]: Epoch 029 - training loss: 0.3398, validation loss: 1.1322
2024-06-03 00:42:16 [INFO]: Epoch 030 - training loss: 0.3354, validation loss: 1.1283
2024-06-03 00:42:17 [INFO]: Epoch 031 - training loss: 0.3252, validation loss: 1.1262
2024-06-03 00:42:17 [INFO]: Epoch 032 - training loss: 0.3257, validation loss: 1.1255
2024-06-03 00:42:18 [INFO]: Epoch 033 - training loss: 0.3240, validation loss: 1.1241
2024-06-03 00:42:18 [INFO]: Epoch 034 - training loss: 0.3205, validation loss: 1.1236
2024-06-03 00:42:19 [INFO]: Epoch 035 - training loss: 0.3174, validation loss: 1.1229
2024-06-03 00:42:19 [INFO]: Epoch 036 - training loss: 0.3141, validation loss: 1.1234
2024-06-03 00:42:20 [INFO]: Epoch 037 - training loss: 0.3167, validation loss: 1.1208
2024-06-03 00:42:21 [INFO]: Epoch 038 - training loss: 0.3126, validation loss: 1.1212
2024-06-03 00:42:21 [INFO]: Epoch 039 - training loss: 0.3128, validation loss: 1.1196
2024-06-03 00:42:22 [INFO]: Epoch 040 - training loss: 0.3109, validation loss: 1.1191
2024-06-03 00:42:22 [INFO]: Epoch 041 - training loss: 0.3126, validation loss: 1.1200
2024-06-03 00:42:23 [INFO]: Epoch 042 - training loss: 0.3118, validation loss: 1.1159
2024-06-03 00:42:23 [INFO]: Epoch 043 - training loss: 0.3232, validation loss: 1.1233
2024-06-03 00:42:24 [INFO]: Epoch 044 - training loss: 0.3158, validation loss: 1.1227
2024-06-03 00:42:24 [INFO]: Epoch 045 - training loss: 0.3211, validation loss: 1.1159
2024-06-03 00:42:25 [INFO]: Epoch 046 - training loss: 0.3179, validation loss: 1.1135
2024-06-03 00:42:26 [INFO]: Epoch 047 - training loss: 0.3167, validation loss: 1.1180
2024-06-03 00:42:26 [INFO]: Epoch 048 - training loss: 0.3145, validation loss: 1.1190
2024-06-03 00:42:27 [INFO]: Epoch 049 - training loss: 0.3148, validation loss: 1.1118
2024-06-03 00:42:27 [INFO]: Epoch 050 - training loss: 0.3109, validation loss: 1.1113
2024-06-03 00:42:28 [INFO]: Epoch 051 - training loss: 0.3153, validation loss: 1.1174
2024-06-03 00:42:28 [INFO]: Epoch 052 - training loss: 0.3035, validation loss: 1.1156
2024-06-03 00:42:29 [INFO]: Epoch 053 - training loss: 0.3096, validation loss: 1.1150
2024-06-03 00:42:29 [INFO]: Epoch 054 - training loss: 0.3042, validation loss: 1.1130
2024-06-03 00:42:30 [INFO]: Epoch 055 - training loss: 0.3009, validation loss: 1.1112
2024-06-03 00:42:30 [INFO]: Epoch 056 - training loss: 0.2993, validation loss: 1.1113
2024-06-03 00:42:31 [INFO]: Epoch 057 - training loss: 0.2939, validation loss: 1.1156
2024-06-03 00:42:31 [INFO]: Epoch 058 - training loss: 0.2985, validation loss: 1.1122
2024-06-03 00:42:32 [INFO]: Epoch 059 - training loss: 0.2985, validation loss: 1.1132
2024-06-03 00:42:33 [INFO]: Epoch 060 - training loss: 0.3053, validation loss: 1.1152
2024-06-03 00:42:33 [INFO]: Epoch 061 - training loss: 0.3061, validation loss: 1.1081
2024-06-03 00:42:34 [INFO]: Epoch 062 - training loss: 0.3038, validation loss: 1.1096
2024-06-03 00:42:34 [INFO]: Epoch 063 - training loss: 0.3014, validation loss: 1.1153
2024-06-03 00:42:35 [INFO]: Epoch 064 - training loss: 0.2983, validation loss: 1.1138
2024-06-03 00:42:35 [INFO]: Epoch 065 - training loss: 0.2934, validation loss: 1.1097
2024-06-03 00:42:36 [INFO]: Epoch 066 - training loss: 0.2877, validation loss: 1.1111
2024-06-03 00:42:36 [INFO]: Epoch 067 - training loss: 0.2909, validation loss: 1.1117
2024-06-03 00:42:37 [INFO]: Epoch 068 - training loss: 0.2923, validation loss: 1.1104
2024-06-03 00:42:37 [INFO]: Epoch 069 - training loss: 0.3005, validation loss: 1.1108
2024-06-03 00:42:38 [INFO]: Epoch 070 - training loss: 0.2906, validation loss: 1.1091
2024-06-03 00:42:38 [INFO]: Epoch 071 - training loss: 0.2870, validation loss: 1.1088
2024-06-03 00:42:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:42:38 [INFO]: Finished training. The best model is from epoch#61.
2024-06-03 00:42:38 [INFO]: Saved the model to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_0/20240603_T004153/MRNN.pypots
2024-06-03 00:42:42 [INFO]: Successfully saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_0/imputation.pkl
2024-06-03 00:42:42 [INFO]: Round0 - MRNN on ETT_h1: MAE=0.8616, MSE=1.3318, MRE=1.0140
2024-06-03 00:42:42 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:42:42 [INFO]: Using the given device: cuda:0
2024-06-03 00:42:42 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_1/20240603_T004242
2024-06-03 00:42:42 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_1/20240603_T004242/tensorboard
2024-06-03 00:42:42 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 2,259
2024-06-03 00:42:45 [INFO]: Epoch 001 - training loss: 1.5274, validation loss: 1.4106
2024-06-03 00:42:46 [INFO]: Epoch 002 - training loss: 1.3730, validation loss: 1.3820
2024-06-03 00:42:46 [INFO]: Epoch 003 - training loss: 1.2708, validation loss: 1.3495
2024-06-03 00:42:47 [INFO]: Epoch 004 - training loss: 1.1686, validation loss: 1.3148
2024-06-03 00:42:48 [INFO]: Epoch 005 - training loss: 1.0346, validation loss: 1.2875
2024-06-03 00:42:48 [INFO]: Epoch 006 - training loss: 0.8606, validation loss: 1.2607
2024-06-03 00:42:49 [INFO]: Epoch 007 - training loss: 0.6650, validation loss: 1.2419
2024-06-03 00:42:49 [INFO]: Epoch 008 - training loss: 0.5137, validation loss: 1.2347
2024-06-03 00:42:50 [INFO]: Epoch 009 - training loss: 0.4925, validation loss: 1.2346
2024-06-03 00:42:51 [INFO]: Epoch 010 - training loss: 0.4600, validation loss: 1.2325
2024-06-03 00:42:51 [INFO]: Epoch 011 - training loss: 0.4443, validation loss: 1.2241
2024-06-03 00:42:52 [INFO]: Epoch 012 - training loss: 0.4354, validation loss: 1.2138
2024-06-03 00:42:52 [INFO]: Epoch 013 - training loss: 0.4322, validation loss: 1.2057
2024-06-03 00:42:53 [INFO]: Epoch 014 - training loss: 0.4206, validation loss: 1.2006
2024-06-03 00:42:53 [INFO]: Epoch 015 - training loss: 0.4132, validation loss: 1.1961
2024-06-03 00:42:54 [INFO]: Epoch 016 - training loss: 0.4106, validation loss: 1.1912
2024-06-03 00:42:54 [INFO]: Epoch 017 - training loss: 0.4026, validation loss: 1.1854
2024-06-03 00:42:55 [INFO]: Epoch 018 - training loss: 0.3966, validation loss: 1.1800
2024-06-03 00:42:55 [INFO]: Epoch 019 - training loss: 0.3987, validation loss: 1.1756
2024-06-03 00:42:56 [INFO]: Epoch 020 - training loss: 0.3883, validation loss: 1.1731
2024-06-03 00:42:56 [INFO]: Epoch 021 - training loss: 0.3804, validation loss: 1.1685
2024-06-03 00:42:57 [INFO]: Epoch 022 - training loss: 0.3701, validation loss: 1.1646
2024-06-03 00:42:58 [INFO]: Epoch 023 - training loss: 0.3722, validation loss: 1.1634
2024-06-03 00:42:58 [INFO]: Epoch 024 - training loss: 0.3659, validation loss: 1.1587
2024-06-03 00:42:59 [INFO]: Epoch 025 - training loss: 0.3574, validation loss: 1.1562
2024-06-03 00:42:59 [INFO]: Epoch 026 - training loss: 0.3525, validation loss: 1.1529
2024-06-03 00:43:00 [INFO]: Epoch 027 - training loss: 0.3477, validation loss: 1.1507
2024-06-03 00:43:00 [INFO]: Epoch 028 - training loss: 0.3423, validation loss: 1.1493
2024-06-03 00:43:01 [INFO]: Epoch 029 - training loss: 0.3395, validation loss: 1.1469
2024-06-03 00:43:01 [INFO]: Epoch 030 - training loss: 0.3360, validation loss: 1.1440
2024-06-03 00:43:02 [INFO]: Epoch 031 - training loss: 0.3281, validation loss: 1.1437
2024-06-03 00:43:02 [INFO]: Epoch 032 - training loss: 0.3278, validation loss: 1.1391
2024-06-03 00:43:03 [INFO]: Epoch 033 - training loss: 0.3398, validation loss: 1.1439
2024-06-03 00:43:03 [INFO]: Epoch 034 - training loss: 0.3394, validation loss: 1.1405
2024-06-03 00:43:04 [INFO]: Epoch 035 - training loss: 0.3207, validation loss: 1.1379
2024-06-03 00:43:05 [INFO]: Epoch 036 - training loss: 0.3277, validation loss: 1.1329
2024-06-03 00:43:05 [INFO]: Epoch 037 - training loss: 0.3360, validation loss: 1.1379
2024-06-03 00:43:06 [INFO]: Epoch 038 - training loss: 0.3350, validation loss: 1.1295
2024-06-03 00:43:06 [INFO]: Epoch 039 - training loss: 0.3298, validation loss: 1.1372
2024-06-03 00:43:07 [INFO]: Epoch 040 - training loss: 0.3297, validation loss: 1.1285
2024-06-03 00:43:07 [INFO]: Epoch 041 - training loss: 0.3241, validation loss: 1.1344
2024-06-03 00:43:08 [INFO]: Epoch 042 - training loss: 0.3196, validation loss: 1.1281
2024-06-03 00:43:08 [INFO]: Epoch 043 - training loss: 0.3155, validation loss: 1.1279
2024-06-03 00:43:09 [INFO]: Epoch 044 - training loss: 0.3086, validation loss: 1.1262
2024-06-03 00:43:09 [INFO]: Epoch 045 - training loss: 0.3109, validation loss: 1.1256
2024-06-03 00:43:10 [INFO]: Epoch 046 - training loss: 0.3085, validation loss: 1.1228
2024-06-03 00:43:10 [INFO]: Epoch 047 - training loss: 0.3100, validation loss: 1.1240
2024-06-03 00:43:11 [INFO]: Epoch 048 - training loss: 0.3022, validation loss: 1.1253
2024-06-03 00:43:12 [INFO]: Epoch 049 - training loss: 0.3011, validation loss: 1.1209
2024-06-03 00:43:12 [INFO]: Epoch 050 - training loss: 0.3125, validation loss: 1.1261
2024-06-03 00:43:13 [INFO]: Epoch 051 - training loss: 0.3093, validation loss: 1.1258
2024-06-03 00:43:13 [INFO]: Epoch 052 - training loss: 0.3110, validation loss: 1.1204
2024-06-03 00:43:14 [INFO]: Epoch 053 - training loss: 0.3082, validation loss: 1.1190
2024-06-03 00:43:14 [INFO]: Epoch 054 - training loss: 0.3059, validation loss: 1.1229
2024-06-03 00:43:15 [INFO]: Epoch 055 - training loss: 0.3087, validation loss: 1.1214
2024-06-03 00:43:15 [INFO]: Epoch 056 - training loss: 0.3021, validation loss: 1.1178
2024-06-03 00:43:16 [INFO]: Epoch 057 - training loss: 0.3044, validation loss: 1.1159
2024-06-03 00:43:16 [INFO]: Epoch 058 - training loss: 0.3035, validation loss: 1.1201
2024-06-03 00:43:17 [INFO]: Epoch 059 - training loss: 0.3030, validation loss: 1.1188
2024-06-03 00:43:17 [INFO]: Epoch 060 - training loss: 0.2963, validation loss: 1.1174
2024-06-03 00:43:18 [INFO]: Epoch 061 - training loss: 0.2908, validation loss: 1.1167
2024-06-03 00:43:18 [INFO]: Epoch 062 - training loss: 0.2923, validation loss: 1.1137
2024-06-03 00:43:19 [INFO]: Epoch 063 - training loss: 0.2935, validation loss: 1.1146
2024-06-03 00:43:19 [INFO]: Epoch 064 - training loss: 0.2913, validation loss: 1.1149
2024-06-03 00:43:20 [INFO]: Epoch 065 - training loss: 0.2900, validation loss: 1.1104
2024-06-03 00:43:20 [INFO]: Epoch 066 - training loss: 0.3027, validation loss: 1.1192
2024-06-03 00:43:21 [INFO]: Epoch 067 - training loss: 0.2993, validation loss: 1.1124
2024-06-03 00:43:21 [INFO]: Epoch 068 - training loss: 0.2920, validation loss: 1.1071
2024-06-03 00:43:22 [INFO]: Epoch 069 - training loss: 0.2982, validation loss: 1.1125
2024-06-03 00:43:22 [INFO]: Epoch 070 - training loss: 0.2919, validation loss: 1.1142
2024-06-03 00:43:23 [INFO]: Epoch 071 - training loss: 0.2961, validation loss: 1.1089
2024-06-03 00:43:23 [INFO]: Epoch 072 - training loss: 0.2968, validation loss: 1.1078
2024-06-03 00:43:24 [INFO]: Epoch 073 - training loss: 0.2881, validation loss: 1.1079
2024-06-03 00:43:24 [INFO]: Epoch 074 - training loss: 0.2854, validation loss: 1.1091
2024-06-03 00:43:25 [INFO]: Epoch 075 - training loss: 0.2850, validation loss: 1.1074
2024-06-03 00:43:25 [INFO]: Epoch 076 - training loss: 0.2859, validation loss: 1.1047
2024-06-03 00:43:26 [INFO]: Epoch 077 - training loss: 0.2852, validation loss: 1.1065
2024-06-03 00:43:26 [INFO]: Epoch 078 - training loss: 0.2807, validation loss: 1.1046
2024-06-03 00:43:27 [INFO]: Epoch 079 - training loss: 0.2844, validation loss: 1.1044
2024-06-03 00:43:27 [INFO]: Epoch 080 - training loss: 0.2939, validation loss: 1.1036
2024-06-03 00:43:27 [INFO]: Epoch 081 - training loss: 0.2814, validation loss: 1.1033
2024-06-03 00:43:28 [INFO]: Epoch 082 - training loss: 0.2760, validation loss: 1.1020
2024-06-03 00:43:28 [INFO]: Epoch 083 - training loss: 0.2806, validation loss: 1.1024
2024-06-03 00:43:29 [INFO]: Epoch 084 - training loss: 0.2775, validation loss: 1.1009
2024-06-03 00:43:30 [INFO]: Epoch 085 - training loss: 0.2783, validation loss: 1.1028
2024-06-03 00:43:30 [INFO]: Epoch 086 - training loss: 0.2788, validation loss: 1.0999
2024-06-03 00:43:30 [INFO]: Epoch 087 - training loss: 0.2796, validation loss: 1.0994
2024-06-03 00:43:31 [INFO]: Epoch 088 - training loss: 0.2774, validation loss: 1.0978
2024-06-03 00:43:31 [INFO]: Epoch 089 - training loss: 0.2783, validation loss: 1.0974
2024-06-03 00:43:32 [INFO]: Epoch 090 - training loss: 0.2781, validation loss: 1.0999
2024-06-03 00:43:32 [INFO]: Epoch 091 - training loss: 0.2787, validation loss: 1.0980
2024-06-03 00:43:33 [INFO]: Epoch 092 - training loss: 0.2780, validation loss: 1.0974
2024-06-03 00:43:33 [INFO]: Epoch 093 - training loss: 0.2773, validation loss: 1.0993
2024-06-03 00:43:34 [INFO]: Epoch 094 - training loss: 0.2792, validation loss: 1.0964
2024-06-03 00:43:34 [INFO]: Epoch 095 - training loss: 0.2762, validation loss: 1.0963
2024-06-03 00:43:35 [INFO]: Epoch 096 - training loss: 0.2780, validation loss: 1.0940
2024-06-03 00:43:35 [INFO]: Epoch 097 - training loss: 0.2870, validation loss: 1.0926
2024-06-03 00:43:36 [INFO]: Epoch 098 - training loss: 0.2867, validation loss: 1.0978
2024-06-03 00:43:36 [INFO]: Epoch 099 - training loss: 0.2871, validation loss: 1.0971
2024-06-03 00:43:36 [INFO]: Epoch 100 - training loss: 0.2873, validation loss: 1.0921
2024-06-03 00:43:36 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 00:43:37 [INFO]: Saved the model to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_1/20240603_T004242/MRNN.pypots
2024-06-03 00:43:39 [INFO]: Successfully saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_1/imputation.pkl
2024-06-03 00:43:39 [INFO]: Round1 - MRNN on ETT_h1: MAE=0.8557, MSE=1.3139, MRE=1.0070
2024-06-03 00:43:39 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:43:39 [INFO]: Using the given device: cuda:0
2024-06-03 00:43:39 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_2/20240603_T004339
2024-06-03 00:43:39 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_2/20240603_T004339/tensorboard
2024-06-03 00:43:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 2,259
2024-06-03 00:43:42 [INFO]: Epoch 001 - training loss: 1.6075, validation loss: 1.3006
2024-06-03 00:43:42 [INFO]: Epoch 002 - training loss: 1.4584, validation loss: 1.2843
2024-06-03 00:43:42 [INFO]: Epoch 003 - training loss: 1.3716, validation loss: 1.2619
2024-06-03 00:43:43 [INFO]: Epoch 004 - training loss: 1.2981, validation loss: 1.2369
2024-06-03 00:43:43 [INFO]: Epoch 005 - training loss: 1.2127, validation loss: 1.2157
2024-06-03 00:43:44 [INFO]: Epoch 006 - training loss: 1.1007, validation loss: 1.1961
2024-06-03 00:43:44 [INFO]: Epoch 007 - training loss: 0.9484, validation loss: 1.1793
2024-06-03 00:43:44 [INFO]: Epoch 008 - training loss: 0.7851, validation loss: 1.1678
2024-06-03 00:43:45 [INFO]: Epoch 009 - training loss: 0.6033, validation loss: 1.1635
2024-06-03 00:43:45 [INFO]: Epoch 010 - training loss: 0.5096, validation loss: 1.1652
2024-06-03 00:43:46 [INFO]: Epoch 011 - training loss: 0.4838, validation loss: 1.1673
2024-06-03 00:43:46 [INFO]: Epoch 012 - training loss: 0.4642, validation loss: 1.1625
2024-06-03 00:43:47 [INFO]: Epoch 013 - training loss: 0.4520, validation loss: 1.1561
2024-06-03 00:43:47 [INFO]: Epoch 014 - training loss: 0.4421, validation loss: 1.1514
2024-06-03 00:43:48 [INFO]: Epoch 015 - training loss: 0.4302, validation loss: 1.1464
2024-06-03 00:43:48 [INFO]: Epoch 016 - training loss: 0.4210, validation loss: 1.1447
2024-06-03 00:43:48 [INFO]: Epoch 017 - training loss: 0.4120, validation loss: 1.1424
2024-06-03 00:43:49 [INFO]: Epoch 018 - training loss: 0.4068, validation loss: 1.1393
2024-06-03 00:43:49 [INFO]: Epoch 019 - training loss: 0.4018, validation loss: 1.1375
2024-06-03 00:43:50 [INFO]: Epoch 020 - training loss: 0.3895, validation loss: 1.1353
2024-06-03 00:43:50 [INFO]: Epoch 021 - training loss: 0.3811, validation loss: 1.1334
2024-06-03 00:43:51 [INFO]: Epoch 022 - training loss: 0.3770, validation loss: 1.1308
2024-06-03 00:43:51 [INFO]: Epoch 023 - training loss: 0.3737, validation loss: 1.1287
2024-06-03 00:43:52 [INFO]: Epoch 024 - training loss: 0.3666, validation loss: 1.1283
2024-06-03 00:43:52 [INFO]: Epoch 025 - training loss: 0.3571, validation loss: 1.1257
2024-06-03 00:43:53 [INFO]: Epoch 026 - training loss: 0.3499, validation loss: 1.1240
2024-06-03 00:43:53 [INFO]: Epoch 027 - training loss: 0.3428, validation loss: 1.1224
2024-06-03 00:43:54 [INFO]: Epoch 028 - training loss: 0.3434, validation loss: 1.1210
2024-06-03 00:43:54 [INFO]: Epoch 029 - training loss: 0.3444, validation loss: 1.1228
2024-06-03 00:43:54 [INFO]: Epoch 030 - training loss: 0.3444, validation loss: 1.1197
2024-06-03 00:43:55 [INFO]: Epoch 031 - training loss: 0.3525, validation loss: 1.1112
2024-06-03 00:43:55 [INFO]: Epoch 032 - training loss: 0.3515, validation loss: 1.1186
2024-06-03 00:43:56 [INFO]: Epoch 033 - training loss: 0.3305, validation loss: 1.1184
2024-06-03 00:43:56 [INFO]: Epoch 034 - training loss: 0.3314, validation loss: 1.1126
2024-06-03 00:43:57 [INFO]: Epoch 035 - training loss: 0.3350, validation loss: 1.1124
2024-06-03 00:43:57 [INFO]: Epoch 036 - training loss: 0.3245, validation loss: 1.1140
2024-06-03 00:43:57 [INFO]: Epoch 037 - training loss: 0.3219, validation loss: 1.1148
2024-06-03 00:43:58 [INFO]: Epoch 038 - training loss: 0.3215, validation loss: 1.1145
2024-06-03 00:43:58 [INFO]: Epoch 039 - training loss: 0.3160, validation loss: 1.1141
2024-06-03 00:43:58 [INFO]: Epoch 040 - training loss: 0.3144, validation loss: 1.1119
2024-06-03 00:43:59 [INFO]: Epoch 041 - training loss: 0.3112, validation loss: 1.1138
2024-06-03 00:43:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:43:59 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 00:43:59 [INFO]: Saved the model to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_2/20240603_T004339/MRNN.pypots
2024-06-03 00:44:02 [INFO]: Successfully saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_2/imputation.pkl
2024-06-03 00:44:02 [INFO]: Round2 - MRNN on ETT_h1: MAE=0.8624, MSE=1.3356, MRE=1.0149
2024-06-03 00:44:02 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 00:44:02 [INFO]: Using the given device: cuda:0
2024-06-03 00:44:02 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_3/20240603_T004402
2024-06-03 00:44:02 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_3/20240603_T004402/tensorboard
2024-06-03 00:44:02 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 2,259
2024-06-03 00:44:04 [INFO]: Epoch 001 - training loss: 1.6589, validation loss: 1.4690
2024-06-03 00:44:04 [INFO]: Epoch 002 - training loss: 1.4854, validation loss: 1.4372
2024-06-03 00:44:05 [INFO]: Epoch 003 - training loss: 1.3849, validation loss: 1.4066
2024-06-03 00:44:05 [INFO]: Epoch 004 - training loss: 1.3283, validation loss: 1.3697
2024-06-03 00:44:05 [INFO]: Epoch 005 - training loss: 1.2408, validation loss: 1.3343
2024-06-03 00:44:06 [INFO]: Epoch 006 - training loss: 1.1346, validation loss: 1.3051
2024-06-03 00:44:06 [INFO]: Epoch 007 - training loss: 1.0062, validation loss: 1.2767
2024-06-03 00:44:06 [INFO]: Epoch 008 - training loss: 0.8460, validation loss: 1.2554
2024-06-03 00:44:07 [INFO]: Epoch 009 - training loss: 0.6518, validation loss: 1.2397
2024-06-03 00:44:07 [INFO]: Epoch 010 - training loss: 0.5213, validation loss: 1.2329
2024-06-03 00:44:07 [INFO]: Epoch 011 - training loss: 0.5110, validation loss: 1.2317
2024-06-03 00:44:08 [INFO]: Epoch 012 - training loss: 0.4730, validation loss: 1.2258
2024-06-03 00:44:08 [INFO]: Epoch 013 - training loss: 0.4639, validation loss: 1.2153
2024-06-03 00:44:09 [INFO]: Epoch 014 - training loss: 0.4476, validation loss: 1.2055
2024-06-03 00:44:09 [INFO]: Epoch 015 - training loss: 0.4353, validation loss: 1.1996
2024-06-03 00:44:09 [INFO]: Epoch 016 - training loss: 0.4213, validation loss: 1.1942
2024-06-03 00:44:10 [INFO]: Epoch 017 - training loss: 0.4052, validation loss: 1.1883
2024-06-03 00:44:10 [INFO]: Epoch 018 - training loss: 0.3960, validation loss: 1.1823
2024-06-03 00:44:10 [INFO]: Epoch 019 - training loss: 0.3893, validation loss: 1.1771
2024-06-03 00:44:11 [INFO]: Epoch 020 - training loss: 0.3784, validation loss: 1.1729
2024-06-03 00:44:11 [INFO]: Epoch 021 - training loss: 0.3724, validation loss: 1.1688
2024-06-03 00:44:11 [INFO]: Epoch 022 - training loss: 0.3625, validation loss: 1.1653
2024-06-03 00:44:12 [INFO]: Epoch 023 - training loss: 0.3554, validation loss: 1.1618
2024-06-03 00:44:12 [INFO]: Epoch 024 - training loss: 0.3517, validation loss: 1.1582
2024-06-03 00:44:12 [INFO]: Epoch 025 - training loss: 0.3466, validation loss: 1.1574
2024-06-03 00:44:13 [INFO]: Epoch 026 - training loss: 0.3631, validation loss: 1.1515
2024-06-03 00:44:13 [INFO]: Epoch 027 - training loss: 0.3523, validation loss: 1.1497
2024-06-03 00:44:13 [INFO]: Epoch 028 - training loss: 0.3488, validation loss: 1.1480
2024-06-03 00:44:14 [INFO]: Epoch 029 - training loss: 0.3450, validation loss: 1.1461
2024-06-03 00:44:14 [INFO]: Epoch 030 - training loss: 0.3388, validation loss: 1.1429
2024-06-03 00:44:14 [INFO]: Epoch 031 - training loss: 0.3314, validation loss: 1.1410
2024-06-03 00:44:15 [INFO]: Epoch 032 - training loss: 0.3263, validation loss: 1.1400
2024-06-03 00:44:15 [INFO]: Epoch 033 - training loss: 0.3213, validation loss: 1.1379
2024-06-03 00:44:16 [INFO]: Epoch 034 - training loss: 0.3169, validation loss: 1.1360
2024-06-03 00:44:16 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 1.1360
2024-06-03 00:44:16 [INFO]: Epoch 036 - training loss: 0.3156, validation loss: 1.1334
2024-06-03 00:44:16 [INFO]: Epoch 037 - training loss: 0.3142, validation loss: 1.1333
2024-06-03 00:44:17 [INFO]: Epoch 038 - training loss: 0.3111, validation loss: 1.1297
2024-06-03 00:44:17 [INFO]: Epoch 039 - training loss: 0.3122, validation loss: 1.1280
2024-06-03 00:44:17 [INFO]: Epoch 040 - training loss: 0.3150, validation loss: 1.1261
2024-06-03 00:44:18 [INFO]: Epoch 041 - training loss: 0.3245, validation loss: 1.1311
2024-06-03 00:44:18 [INFO]: Epoch 042 - training loss: 0.3101, validation loss: 1.1260
2024-06-03 00:44:18 [INFO]: Epoch 043 - training loss: 0.3070, validation loss: 1.1272
2024-06-03 00:44:19 [INFO]: Epoch 044 - training loss: 0.3091, validation loss: 1.1256
2024-06-03 00:44:19 [INFO]: Epoch 045 - training loss: 0.3058, validation loss: 1.1245
2024-06-03 00:44:19 [INFO]: Epoch 046 - training loss: 0.3034, validation loss: 1.1221
2024-06-03 00:44:19 [INFO]: Epoch 047 - training loss: 0.3075, validation loss: 1.1201
2024-06-03 00:44:20 [INFO]: Epoch 048 - training loss: 0.3141, validation loss: 1.1243
2024-06-03 00:44:20 [INFO]: Epoch 049 - training loss: 0.3097, validation loss: 1.1256
2024-06-03 00:44:20 [INFO]: Epoch 050 - training loss: 0.3094, validation loss: 1.1198
2024-06-03 00:44:21 [INFO]: Epoch 051 - training loss: 0.3094, validation loss: 1.1203
2024-06-03 00:44:21 [INFO]: Epoch 052 - training loss: 0.2973, validation loss: 1.1219
2024-06-03 00:44:21 [INFO]: Epoch 053 - training loss: 0.2948, validation loss: 1.1237
2024-06-03 00:44:21 [INFO]: Epoch 054 - training loss: 0.3069, validation loss: 1.1175
2024-06-03 00:44:22 [INFO]: Epoch 055 - training loss: 0.2965, validation loss: 1.1155
2024-06-03 00:44:22 [INFO]: Epoch 056 - training loss: 0.3040, validation loss: 1.1209
2024-06-03 00:44:22 [INFO]: Epoch 057 - training loss: 0.3005, validation loss: 1.1218
2024-06-03 00:44:22 [INFO]: Epoch 058 - training loss: 0.3026, validation loss: 1.1139
2024-06-03 00:44:23 [INFO]: Epoch 059 - training loss: 0.3028, validation loss: 1.1200
2024-06-03 00:44:23 [INFO]: Epoch 060 - training loss: 0.2943, validation loss: 1.1218
2024-06-03 00:44:23 [INFO]: Epoch 061 - training loss: 0.2993, validation loss: 1.1155
2024-06-03 00:44:23 [INFO]: Epoch 062 - training loss: 0.2897, validation loss: 1.1175
2024-06-03 00:44:24 [INFO]: Epoch 063 - training loss: 0.2881, validation loss: 1.1194
2024-06-03 00:44:24 [INFO]: Epoch 064 - training loss: 0.2972, validation loss: 1.1148
2024-06-03 00:44:24 [INFO]: Epoch 065 - training loss: 0.2901, validation loss: 1.1168
2024-06-03 00:44:24 [INFO]: Epoch 066 - training loss: 0.2880, validation loss: 1.1181
2024-06-03 00:44:25 [INFO]: Epoch 067 - training loss: 0.2914, validation loss: 1.1186
2024-06-03 00:44:25 [INFO]: Epoch 068 - training loss: 0.2970, validation loss: 1.1118
2024-06-03 00:44:25 [INFO]: Epoch 069 - training loss: 0.2894, validation loss: 1.1132
2024-06-03 00:44:25 [INFO]: Epoch 070 - training loss: 0.2933, validation loss: 1.1126
2024-06-03 00:44:26 [INFO]: Epoch 071 - training loss: 0.2898, validation loss: 1.1173
2024-06-03 00:44:26 [INFO]: Epoch 072 - training loss: 0.2906, validation loss: 1.1170
2024-06-03 00:44:26 [INFO]: Epoch 073 - training loss: 0.2924, validation loss: 1.1126
2024-06-03 00:44:26 [INFO]: Epoch 074 - training loss: 0.2911, validation loss: 1.1115
2024-06-03 00:44:26 [INFO]: Epoch 075 - training loss: 0.2831, validation loss: 1.1099
2024-06-03 00:44:27 [INFO]: Epoch 076 - training loss: 0.2830, validation loss: 1.1103
2024-06-03 00:44:27 [INFO]: Epoch 077 - training loss: 0.2909, validation loss: 1.1092
2024-06-03 00:44:27 [INFO]: Epoch 078 - training loss: 0.2855, validation loss: 1.1129
2024-06-03 00:44:27 [INFO]: Epoch 079 - training loss: 0.2891, validation loss: 1.1124
2024-06-03 00:44:27 [INFO]: Epoch 080 - training loss: 0.2866, validation loss: 1.1081
2024-06-03 00:44:28 [INFO]: Epoch 081 - training loss: 0.2880, validation loss: 1.1078
2024-06-03 00:44:28 [INFO]: Epoch 082 - training loss: 0.2877, validation loss: 1.1135
2024-06-03 00:44:28 [INFO]: Epoch 083 - training loss: 0.2909, validation loss: 1.1059
2024-06-03 00:44:28 [INFO]: Epoch 084 - training loss: 0.2849, validation loss: 1.1121
2024-06-03 00:44:29 [INFO]: Epoch 085 - training loss: 0.2824, validation loss: 1.1115
2024-06-03 00:44:29 [INFO]: Epoch 086 - training loss: 0.2860, validation loss: 1.1053
2024-06-03 00:44:29 [INFO]: Epoch 087 - training loss: 0.2848, validation loss: 1.1053
2024-06-03 00:44:29 [INFO]: Epoch 088 - training loss: 0.2850, validation loss: 1.1077
2024-06-03 00:44:29 [INFO]: Epoch 089 - training loss: 0.2835, validation loss: 1.1080
2024-06-03 00:44:30 [INFO]: Epoch 090 - training loss: 0.2813, validation loss: 1.1043
2024-06-03 00:44:30 [INFO]: Epoch 091 - training loss: 0.2817, validation loss: 1.1040
2024-06-03 00:44:30 [INFO]: Epoch 092 - training loss: 0.2828, validation loss: 1.1074
2024-06-03 00:44:30 [INFO]: Epoch 093 - training loss: 0.2790, validation loss: 1.1077
2024-06-03 00:44:31 [INFO]: Epoch 094 - training loss: 0.2825, validation loss: 1.1025
2024-06-03 00:44:31 [INFO]: Epoch 095 - training loss: 0.2812, validation loss: 1.1021
2024-06-03 00:44:31 [INFO]: Epoch 096 - training loss: 0.2818, validation loss: 1.1064
2024-06-03 00:44:31 [INFO]: Epoch 097 - training loss: 0.2812, validation loss: 1.1010
2024-06-03 00:44:32 [INFO]: Epoch 098 - training loss: 0.2773, validation loss: 1.1006
2024-06-03 00:44:32 [INFO]: Epoch 099 - training loss: 0.2813, validation loss: 1.1035
2024-06-03 00:44:32 [INFO]: Epoch 100 - training loss: 0.2753, validation loss: 1.1031
2024-06-03 00:44:32 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 00:44:32 [INFO]: Saved the model to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_3/20240603_T004402/MRNN.pypots
2024-06-03 00:44:33 [INFO]: Successfully saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_3/imputation.pkl
2024-06-03 00:44:33 [INFO]: Round3 - MRNN on ETT_h1: MAE=0.8600, MSE=1.3257, MRE=1.0121
2024-06-03 00:44:33 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 00:44:33 [INFO]: Using the given device: cuda:0
2024-06-03 00:44:33 [INFO]: Model files will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_4/20240603_T004433
2024-06-03 00:44:33 [INFO]: Tensorboard file will be saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_4/20240603_T004433/tensorboard
2024-06-03 00:44:33 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 2,259
2024-06-03 00:44:34 [INFO]: Epoch 001 - training loss: 1.4366, validation loss: 1.3397
2024-06-03 00:44:35 [INFO]: Epoch 002 - training loss: 1.3562, validation loss: 1.3096
2024-06-03 00:44:35 [INFO]: Epoch 003 - training loss: 1.2863, validation loss: 1.2784
2024-06-03 00:44:35 [INFO]: Epoch 004 - training loss: 1.2001, validation loss: 1.2505
2024-06-03 00:44:35 [INFO]: Epoch 005 - training loss: 1.0856, validation loss: 1.2248
2024-06-03 00:44:35 [INFO]: Epoch 006 - training loss: 0.9266, validation loss: 1.2040
2024-06-03 00:44:35 [INFO]: Epoch 007 - training loss: 0.7355, validation loss: 1.1883
2024-06-03 00:44:36 [INFO]: Epoch 008 - training loss: 0.5490, validation loss: 1.1792
2024-06-03 00:44:36 [INFO]: Epoch 009 - training loss: 0.4907, validation loss: 1.1767
2024-06-03 00:44:36 [INFO]: Epoch 010 - training loss: 0.4599, validation loss: 1.1721
2024-06-03 00:44:36 [INFO]: Epoch 011 - training loss: 0.4364, validation loss: 1.1642
2024-06-03 00:44:37 [INFO]: Epoch 012 - training loss: 0.4202, validation loss: 1.1573
2024-06-03 00:44:37 [INFO]: Epoch 013 - training loss: 0.4132, validation loss: 1.1518
2024-06-03 00:44:37 [INFO]: Epoch 014 - training loss: 0.4012, validation loss: 1.1478
2024-06-03 00:44:37 [INFO]: Epoch 015 - training loss: 0.3951, validation loss: 1.1453
2024-06-03 00:44:37 [INFO]: Epoch 016 - training loss: 0.3863, validation loss: 1.1432
2024-06-03 00:44:38 [INFO]: Epoch 017 - training loss: 0.3861, validation loss: 1.1387
2024-06-03 00:44:38 [INFO]: Epoch 018 - training loss: 0.3745, validation loss: 1.1354
2024-06-03 00:44:38 [INFO]: Epoch 019 - training loss: 0.3612, validation loss: 1.1321
2024-06-03 00:44:38 [INFO]: Epoch 020 - training loss: 0.3633, validation loss: 1.1310
2024-06-03 00:44:38 [INFO]: Epoch 021 - training loss: 0.3571, validation loss: 1.1303
2024-06-03 00:44:39 [INFO]: Epoch 022 - training loss: 0.3523, validation loss: 1.1306
2024-06-03 00:44:39 [INFO]: Epoch 023 - training loss: 0.3491, validation loss: 1.1333
2024-06-03 00:44:39 [INFO]: Epoch 024 - training loss: 0.3619, validation loss: 1.1255
2024-06-03 00:44:39 [INFO]: Epoch 025 - training loss: 0.3443, validation loss: 1.1250
2024-06-03 00:44:39 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 1.1255
2024-06-03 00:44:39 [INFO]: Epoch 027 - training loss: 0.3327, validation loss: 1.1248
2024-06-03 00:44:40 [INFO]: Epoch 028 - training loss: 0.3287, validation loss: 1.1228
2024-06-03 00:44:40 [INFO]: Epoch 029 - training loss: 0.3304, validation loss: 1.1258
2024-06-03 00:44:40 [INFO]: Epoch 030 - training loss: 0.3443, validation loss: 1.1255
2024-06-03 00:44:40 [INFO]: Epoch 031 - training loss: 0.3350, validation loss: 1.1200
2024-06-03 00:44:40 [INFO]: Epoch 032 - training loss: 0.3359, validation loss: 1.1187
2024-06-03 00:44:41 [INFO]: Epoch 033 - training loss: 0.3289, validation loss: 1.1226
2024-06-03 00:44:41 [INFO]: Epoch 034 - training loss: 0.3298, validation loss: 1.1220
2024-06-03 00:44:41 [INFO]: Epoch 035 - training loss: 0.3260, validation loss: 1.1154
2024-06-03 00:44:41 [INFO]: Epoch 036 - training loss: 0.3314, validation loss: 1.1190
2024-06-03 00:44:41 [INFO]: Epoch 037 - training loss: 0.3304, validation loss: 1.1164
2024-06-03 00:44:42 [INFO]: Epoch 038 - training loss: 0.3279, validation loss: 1.1200
2024-06-03 00:44:42 [INFO]: Epoch 039 - training loss: 0.3231, validation loss: 1.1188
2024-06-03 00:44:42 [INFO]: Epoch 040 - training loss: 0.3122, validation loss: 1.1161
2024-06-03 00:44:42 [INFO]: Epoch 041 - training loss: 0.3084, validation loss: 1.1150
2024-06-03 00:44:43 [INFO]: Epoch 042 - training loss: 0.3071, validation loss: 1.1136
2024-06-03 00:44:43 [INFO]: Epoch 043 - training loss: 0.3049, validation loss: 1.1146
2024-06-03 00:44:43 [INFO]: Epoch 044 - training loss: 0.3064, validation loss: 1.1177
2024-06-03 00:44:43 [INFO]: Epoch 045 - training loss: 0.3098, validation loss: 1.1166
2024-06-03 00:44:43 [INFO]: Epoch 046 - training loss: 0.3171, validation loss: 1.1082
2024-06-03 00:44:43 [INFO]: Epoch 047 - training loss: 0.3073, validation loss: 1.1123
2024-06-03 00:44:44 [INFO]: Epoch 048 - training loss: 0.3050, validation loss: 1.1116
2024-06-03 00:44:44 [INFO]: Epoch 049 - training loss: 0.3135, validation loss: 1.1086
2024-06-03 00:44:44 [INFO]: Epoch 050 - training loss: 0.3105, validation loss: 1.1127
2024-06-03 00:44:44 [INFO]: Epoch 051 - training loss: 0.3109, validation loss: 1.1132
2024-06-03 00:44:44 [INFO]: Epoch 052 - training loss: 0.3074, validation loss: 1.1079
2024-06-03 00:44:44 [INFO]: Epoch 053 - training loss: 0.3106, validation loss: 1.1071
2024-06-03 00:44:44 [INFO]: Epoch 054 - training loss: 0.3031, validation loss: 1.1109
2024-06-03 00:44:45 [INFO]: Epoch 055 - training loss: 0.3092, validation loss: 1.1106
2024-06-03 00:44:45 [INFO]: Epoch 056 - training loss: 0.3025, validation loss: 1.1031
2024-06-03 00:44:45 [INFO]: Epoch 057 - training loss: 0.3056, validation loss: 1.1046
2024-06-03 00:44:45 [INFO]: Epoch 058 - training loss: 0.2992, validation loss: 1.1072
2024-06-03 00:44:45 [INFO]: Epoch 059 - training loss: 0.3000, validation loss: 1.1102
2024-06-03 00:44:45 [INFO]: Epoch 060 - training loss: 0.3013, validation loss: 1.1029
2024-06-03 00:44:45 [INFO]: Epoch 061 - training loss: 0.3053, validation loss: 1.1075
2024-06-03 00:44:46 [INFO]: Epoch 062 - training loss: 0.3019, validation loss: 1.1090
2024-06-03 00:44:46 [INFO]: Epoch 063 - training loss: 0.2988, validation loss: 1.1033
2024-06-03 00:44:46 [INFO]: Epoch 064 - training loss: 0.2965, validation loss: 1.0994
2024-06-03 00:44:46 [INFO]: Epoch 065 - training loss: 0.2975, validation loss: 1.1053
2024-06-03 00:44:46 [INFO]: Epoch 066 - training loss: 0.2968, validation loss: 1.1074
2024-06-03 00:44:46 [INFO]: Epoch 067 - training loss: 0.2987, validation loss: 1.0993
2024-06-03 00:44:46 [INFO]: Epoch 068 - training loss: 0.2973, validation loss: 1.0988
2024-06-03 00:44:46 [INFO]: Epoch 069 - training loss: 0.2960, validation loss: 1.1036
2024-06-03 00:44:47 [INFO]: Epoch 070 - training loss: 0.2970, validation loss: 1.1029
2024-06-03 00:44:47 [INFO]: Epoch 071 - training loss: 0.2904, validation loss: 1.1002
2024-06-03 00:44:47 [INFO]: Epoch 072 - training loss: 0.2866, validation loss: 1.0993
2024-06-03 00:44:47 [INFO]: Epoch 073 - training loss: 0.2860, validation loss: 1.1016
2024-06-03 00:44:47 [INFO]: Epoch 074 - training loss: 0.2850, validation loss: 1.0986
2024-06-03 00:44:47 [INFO]: Epoch 075 - training loss: 0.2823, validation loss: 1.1000
2024-06-03 00:44:47 [INFO]: Epoch 076 - training loss: 0.2810, validation loss: 1.0985
2024-06-03 00:44:48 [INFO]: Epoch 077 - training loss: 0.2841, validation loss: 1.0981
2024-06-03 00:44:48 [INFO]: Epoch 078 - training loss: 0.2835, validation loss: 1.0971
2024-06-03 00:44:48 [INFO]: Epoch 079 - training loss: 0.2809, validation loss: 1.0959
2024-06-03 00:44:48 [INFO]: Epoch 080 - training loss: 0.2813, validation loss: 1.0948
2024-06-03 00:44:48 [INFO]: Epoch 081 - training loss: 0.2854, validation loss: 1.0947
2024-06-03 00:44:48 [INFO]: Epoch 082 - training loss: 0.2818, validation loss: 1.0953
2024-06-03 00:44:48 [INFO]: Epoch 083 - training loss: 0.2816, validation loss: 1.0925
2024-06-03 00:44:48 [INFO]: Epoch 084 - training loss: 0.2810, validation loss: 1.0973
2024-06-03 00:44:49 [INFO]: Epoch 085 - training loss: 0.2833, validation loss: 1.0931
2024-06-03 00:44:49 [INFO]: Epoch 086 - training loss: 0.2868, validation loss: 1.0976
2024-06-03 00:44:49 [INFO]: Epoch 087 - training loss: 0.2870, validation loss: 1.0998
2024-06-03 00:44:49 [INFO]: Epoch 088 - training loss: 0.2941, validation loss: 1.0893
2024-06-03 00:44:49 [INFO]: Epoch 089 - training loss: 0.2894, validation loss: 1.0865
2024-06-03 00:44:49 [INFO]: Epoch 090 - training loss: 0.2910, validation loss: 1.0950
2024-06-03 00:44:49 [INFO]: Epoch 091 - training loss: 0.2887, validation loss: 1.0942
2024-06-03 00:44:50 [INFO]: Epoch 092 - training loss: 0.2907, validation loss: 1.0875
2024-06-03 00:44:50 [INFO]: Epoch 093 - training loss: 0.2903, validation loss: 1.0873
2024-06-03 00:44:50 [INFO]: Epoch 094 - training loss: 0.2854, validation loss: 1.0930
2024-06-03 00:44:50 [INFO]: Epoch 095 - training loss: 0.2865, validation loss: 1.0942
2024-06-03 00:44:50 [INFO]: Epoch 096 - training loss: 0.2890, validation loss: 1.0876
2024-06-03 00:44:50 [INFO]: Epoch 097 - training loss: 0.2857, validation loss: 1.0849
2024-06-03 00:44:50 [INFO]: Epoch 098 - training loss: 0.2865, validation loss: 1.0912
2024-06-03 00:44:50 [INFO]: Epoch 099 - training loss: 0.2840, validation loss: 1.0913
2024-06-03 00:44:51 [INFO]: Epoch 100 - training loss: 0.2868, validation loss: 1.0828
2024-06-03 00:44:51 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 00:44:51 [INFO]: Saved the model to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_4/20240603_T004433/MRNN.pypots
2024-06-03 00:44:51 [INFO]: Successfully saved to results_point_rate09/ETT_h1/MRNN_ETT_h1/round_4/imputation.pkl
2024-06-03 00:44:51 [INFO]: Round4 - MRNN on ETT_h1: MAE=0.8535, MSE=1.2995, MRE=1.0044
2024-06-03 00:44:51 [INFO]: Done! Final results:
Averaged MRNN (2,259 params) on ETT_h1: MAE=0.8586 ± 0.003458405220342567, MSE=1.3213 ± 0.013162674585676814, MRE=1.0105 ± 0.004070157648849681, average inference time=0.42
