2024-06-03 15:13:43 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 15:13:43 [INFO]: Using the given device: cuda:0
2024-06-03 15:13:43 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T151343
2024-06-03 15:13:43 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T151343/tensorboard
2024-06-03 15:13:44 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 15:13:59 [INFO]: Epoch 001 - training loss: 0.8642, validation loss: 0.6151
2024-06-03 15:14:06 [INFO]: Epoch 002 - training loss: 0.5114, validation loss: 0.6652
2024-06-03 15:14:13 [INFO]: Epoch 003 - training loss: 0.4650, validation loss: 0.6586
2024-06-03 15:14:19 [INFO]: Epoch 004 - training loss: 0.4512, validation loss: 0.6306
2024-06-03 15:14:26 [INFO]: Epoch 005 - training loss: 0.4442, validation loss: 0.6083
2024-06-03 15:14:33 [INFO]: Epoch 006 - training loss: 0.4289, validation loss: 0.6402
2024-06-03 15:14:39 [INFO]: Epoch 007 - training loss: 0.4241, validation loss: 0.5918
2024-06-03 15:14:46 [INFO]: Epoch 008 - training loss: 0.4120, validation loss: 0.5977
2024-06-03 15:14:54 [INFO]: Epoch 009 - training loss: 0.4041, validation loss: 0.5765
2024-06-03 15:15:01 [INFO]: Epoch 010 - training loss: 0.3985, validation loss: 0.6013
2024-06-03 15:15:07 [INFO]: Epoch 011 - training loss: 0.3859, validation loss: 0.5858
2024-06-03 15:15:15 [INFO]: Epoch 012 - training loss: 0.3707, validation loss: 0.5885
2024-06-03 15:15:21 [INFO]: Epoch 013 - training loss: 0.3713, validation loss: 0.5935
2024-06-03 15:15:28 [INFO]: Epoch 014 - training loss: 0.3601, validation loss: 0.5894
2024-06-03 15:15:35 [INFO]: Epoch 015 - training loss: 0.3502, validation loss: 0.5980
2024-06-03 15:15:42 [INFO]: Epoch 016 - training loss: 0.3441, validation loss: 0.5944
2024-06-03 15:15:49 [INFO]: Epoch 017 - training loss: 0.3401, validation loss: 0.5914
2024-06-03 15:15:56 [INFO]: Epoch 018 - training loss: 0.3337, validation loss: 0.5887
2024-06-03 15:16:03 [INFO]: Epoch 019 - training loss: 0.3280, validation loss: 0.5886
2024-06-03 15:16:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 15:16:03 [INFO]: Finished training. The best model is from epoch#9.
2024-06-03 15:16:03 [INFO]: Saved the model to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_0/20240603_T151343/iTransformer.pypots
2024-06-03 15:16:05 [INFO]: Successfully saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_0/imputation.pkl
2024-06-03 15:16:05 [INFO]: Round0 - iTransformer on BeijingAir: MAE=0.4788, MSE=0.6480, MRE=0.6472
2024-06-03 15:16:05 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 15:16:05 [INFO]: Using the given device: cuda:0
2024-06-03 15:16:05 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T151605
2024-06-03 15:16:05 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T151605/tensorboard
2024-06-03 15:16:05 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 15:16:12 [INFO]: Epoch 001 - training loss: 0.8538, validation loss: 0.6610
2024-06-03 15:16:19 [INFO]: Epoch 002 - training loss: 0.5070, validation loss: 0.6974
2024-06-03 15:16:26 [INFO]: Epoch 003 - training loss: 0.4679, validation loss: 0.6453
2024-06-03 15:16:33 [INFO]: Epoch 004 - training loss: 0.4471, validation loss: 0.6314
2024-06-03 15:16:40 [INFO]: Epoch 005 - training loss: 0.4375, validation loss: 0.5990
2024-06-03 15:16:47 [INFO]: Epoch 006 - training loss: 0.4361, validation loss: 0.6433
2024-06-03 15:16:54 [INFO]: Epoch 007 - training loss: 0.4232, validation loss: 0.5985
2024-06-03 15:17:01 [INFO]: Epoch 008 - training loss: 0.4107, validation loss: 0.6193
2024-06-03 15:17:08 [INFO]: Epoch 009 - training loss: 0.3995, validation loss: 0.6115
2024-06-03 15:17:15 [INFO]: Epoch 010 - training loss: 0.3946, validation loss: 0.6007
2024-06-03 15:17:21 [INFO]: Epoch 011 - training loss: 0.3883, validation loss: 0.6512
2024-06-03 15:17:28 [INFO]: Epoch 012 - training loss: 0.3807, validation loss: 0.6061
2024-06-03 15:17:34 [INFO]: Epoch 013 - training loss: 0.3629, validation loss: 0.5936
2024-06-03 15:17:41 [INFO]: Epoch 014 - training loss: 0.3567, validation loss: 0.6261
2024-06-03 15:17:48 [INFO]: Epoch 015 - training loss: 0.3557, validation loss: 0.5935
2024-06-03 15:17:55 [INFO]: Epoch 016 - training loss: 0.3396, validation loss: 0.5867
2024-06-03 15:18:02 [INFO]: Epoch 017 - training loss: 0.3353, validation loss: 0.5987
2024-06-03 15:18:09 [INFO]: Epoch 018 - training loss: 0.3334, validation loss: 0.6040
2024-06-03 15:18:16 [INFO]: Epoch 019 - training loss: 0.3305, validation loss: 0.5677
2024-06-03 15:18:23 [INFO]: Epoch 020 - training loss: 0.3204, validation loss: 0.5972
2024-06-03 15:18:30 [INFO]: Epoch 021 - training loss: 0.3117, validation loss: 0.5817
2024-06-03 15:18:37 [INFO]: Epoch 022 - training loss: 0.3125, validation loss: 0.5798
2024-06-03 15:18:43 [INFO]: Epoch 023 - training loss: 0.3107, validation loss: 0.5747
2024-06-03 15:18:50 [INFO]: Epoch 024 - training loss: 0.3119, validation loss: 0.5661
2024-06-03 15:18:57 [INFO]: Epoch 025 - training loss: 0.3085, validation loss: 0.5819
2024-06-03 15:19:04 [INFO]: Epoch 026 - training loss: 0.2989, validation loss: 0.5597
2024-06-03 15:19:11 [INFO]: Epoch 027 - training loss: 0.2968, validation loss: 0.5547
2024-06-03 15:19:18 [INFO]: Epoch 028 - training loss: 0.2949, validation loss: 0.5684
2024-06-03 15:19:24 [INFO]: Epoch 029 - training loss: 0.2888, validation loss: 0.5601
2024-06-03 15:19:31 [INFO]: Epoch 030 - training loss: 0.2922, validation loss: 0.5810
2024-06-03 15:19:38 [INFO]: Epoch 031 - training loss: 0.2900, validation loss: 0.5568
2024-06-03 15:19:45 [INFO]: Epoch 032 - training loss: 0.2846, validation loss: 0.5322
2024-06-03 15:19:52 [INFO]: Epoch 033 - training loss: 0.2837, validation loss: 0.5574
2024-06-03 15:19:59 [INFO]: Epoch 034 - training loss: 0.2909, validation loss: 0.5512
2024-06-03 15:20:06 [INFO]: Epoch 035 - training loss: 0.2918, validation loss: 0.5311
2024-06-03 15:20:13 [INFO]: Epoch 036 - training loss: 0.2808, validation loss: 0.5446
2024-06-03 15:20:20 [INFO]: Epoch 037 - training loss: 0.2752, validation loss: 0.5262
2024-06-03 15:20:27 [INFO]: Epoch 038 - training loss: 0.2792, validation loss: 0.5140
2024-06-03 15:20:34 [INFO]: Epoch 039 - training loss: 0.2720, validation loss: 0.5183
2024-06-03 15:20:41 [INFO]: Epoch 040 - training loss: 0.2663, validation loss: 0.5105
2024-06-03 15:20:48 [INFO]: Epoch 041 - training loss: 0.2653, validation loss: 0.5166
2024-06-03 15:20:54 [INFO]: Epoch 042 - training loss: 0.2640, validation loss: 0.4864
2024-06-03 15:21:01 [INFO]: Epoch 043 - training loss: 0.2664, validation loss: 0.5118
2024-06-03 15:21:08 [INFO]: Epoch 044 - training loss: 0.2627, validation loss: 0.5060
2024-06-03 15:21:15 [INFO]: Epoch 045 - training loss: 0.2609, validation loss: 0.4894
2024-06-03 15:21:22 [INFO]: Epoch 046 - training loss: 0.2604, validation loss: 0.4925
2024-06-03 15:21:29 [INFO]: Epoch 047 - training loss: 0.2622, validation loss: 0.4829
2024-06-03 15:21:36 [INFO]: Epoch 048 - training loss: 0.2565, validation loss: 0.4952
2024-06-03 15:21:42 [INFO]: Epoch 049 - training loss: 0.2541, validation loss: 0.4870
2024-06-03 15:21:49 [INFO]: Epoch 050 - training loss: 0.2576, validation loss: 0.4759
2024-06-03 15:21:56 [INFO]: Epoch 051 - training loss: 0.2600, validation loss: 0.4869
2024-06-03 15:22:03 [INFO]: Epoch 052 - training loss: 0.2642, validation loss: 0.4698
2024-06-03 15:22:10 [INFO]: Epoch 053 - training loss: 0.2548, validation loss: 0.4628
2024-06-03 15:22:17 [INFO]: Epoch 054 - training loss: 0.2465, validation loss: 0.4661
2024-06-03 15:22:24 [INFO]: Epoch 055 - training loss: 0.2471, validation loss: 0.4470
2024-06-03 15:22:31 [INFO]: Epoch 056 - training loss: 0.2494, validation loss: 0.4476
2024-06-03 15:22:38 [INFO]: Epoch 057 - training loss: 0.2501, validation loss: 0.4738
2024-06-03 15:22:44 [INFO]: Epoch 058 - training loss: 0.2475, validation loss: 0.4586
2024-06-03 15:22:50 [INFO]: Epoch 059 - training loss: 0.2447, validation loss: 0.4752
2024-06-03 15:22:56 [INFO]: Epoch 060 - training loss: 0.2450, validation loss: 0.4359
2024-06-03 15:23:01 [INFO]: Epoch 061 - training loss: 0.2417, validation loss: 0.4409
2024-06-03 15:23:07 [INFO]: Epoch 062 - training loss: 0.2383, validation loss: 0.4428
2024-06-03 15:23:13 [INFO]: Epoch 063 - training loss: 0.2457, validation loss: 0.4313
2024-06-03 15:23:20 [INFO]: Epoch 064 - training loss: 0.2469, validation loss: 0.4426
2024-06-03 15:23:26 [INFO]: Epoch 065 - training loss: 0.2436, validation loss: 0.4462
2024-06-03 15:23:32 [INFO]: Epoch 066 - training loss: 0.2386, validation loss: 0.4336
2024-06-03 15:23:38 [INFO]: Epoch 067 - training loss: 0.2365, validation loss: 0.4346
2024-06-03 15:23:44 [INFO]: Epoch 068 - training loss: 0.2380, validation loss: 0.4319
2024-06-03 15:23:51 [INFO]: Epoch 069 - training loss: 0.2325, validation loss: 0.4348
2024-06-03 15:23:57 [INFO]: Epoch 070 - training loss: 0.2315, validation loss: 0.4240
2024-06-03 15:24:03 [INFO]: Epoch 071 - training loss: 0.2380, validation loss: 0.4367
2024-06-03 15:24:09 [INFO]: Epoch 072 - training loss: 0.2334, validation loss: 0.4291
2024-06-03 15:24:15 [INFO]: Epoch 073 - training loss: 0.2372, validation loss: 0.4215
2024-06-03 15:24:21 [INFO]: Epoch 074 - training loss: 0.2344, validation loss: 0.4138
2024-06-03 15:24:27 [INFO]: Epoch 075 - training loss: 0.2302, validation loss: 0.4111
2024-06-03 15:24:33 [INFO]: Epoch 076 - training loss: 0.2290, validation loss: 0.4138
2024-06-03 15:24:40 [INFO]: Epoch 077 - training loss: 0.2281, validation loss: 0.4197
2024-06-03 15:24:46 [INFO]: Epoch 078 - training loss: 0.2280, validation loss: 0.4163
2024-06-03 15:24:52 [INFO]: Epoch 079 - training loss: 0.2255, validation loss: 0.4165
2024-06-03 15:24:58 [INFO]: Epoch 080 - training loss: 0.2278, validation loss: 0.4172
2024-06-03 15:25:04 [INFO]: Epoch 081 - training loss: 0.2253, validation loss: 0.4137
2024-06-03 15:25:10 [INFO]: Epoch 082 - training loss: 0.2266, validation loss: 0.4255
2024-06-03 15:25:17 [INFO]: Epoch 083 - training loss: 0.2299, validation loss: 0.4125
2024-06-03 15:25:23 [INFO]: Epoch 084 - training loss: 0.2244, validation loss: 0.3979
2024-06-03 15:25:29 [INFO]: Epoch 085 - training loss: 0.2233, validation loss: 0.4062
2024-06-03 15:25:36 [INFO]: Epoch 086 - training loss: 0.2307, validation loss: 0.4061
2024-06-03 15:25:42 [INFO]: Epoch 087 - training loss: 0.2312, validation loss: 0.4074
2024-06-03 15:25:48 [INFO]: Epoch 088 - training loss: 0.2210, validation loss: 0.4024
2024-06-03 15:25:54 [INFO]: Epoch 089 - training loss: 0.2222, validation loss: 0.4026
2024-06-03 15:26:00 [INFO]: Epoch 090 - training loss: 0.2177, validation loss: 0.3925
2024-06-03 15:26:07 [INFO]: Epoch 091 - training loss: 0.2209, validation loss: 0.3868
2024-06-03 15:26:13 [INFO]: Epoch 092 - training loss: 0.2187, validation loss: 0.3814
2024-06-03 15:26:19 [INFO]: Epoch 093 - training loss: 0.2167, validation loss: 0.4049
2024-06-03 15:26:25 [INFO]: Epoch 094 - training loss: 0.2201, validation loss: 0.3937
2024-06-03 15:26:31 [INFO]: Epoch 095 - training loss: 0.2267, validation loss: 0.3898
2024-06-03 15:26:37 [INFO]: Epoch 096 - training loss: 0.2214, validation loss: 0.4000
2024-06-03 15:26:43 [INFO]: Epoch 097 - training loss: 0.2179, validation loss: 0.3852
2024-06-03 15:26:50 [INFO]: Epoch 098 - training loss: 0.2164, validation loss: 0.3916
2024-06-03 15:26:55 [INFO]: Epoch 099 - training loss: 0.2141, validation loss: 0.3747
2024-06-03 15:27:01 [INFO]: Epoch 100 - training loss: 0.2178, validation loss: 0.3824
2024-06-03 15:27:01 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 15:27:01 [INFO]: Saved the model to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_1/20240603_T151605/iTransformer.pypots
2024-06-03 15:27:03 [INFO]: Successfully saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_1/imputation.pkl
2024-06-03 15:27:03 [INFO]: Round1 - iTransformer on BeijingAir: MAE=0.3245, MSE=0.4385, MRE=0.4387
2024-06-03 15:27:03 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 15:27:03 [INFO]: Using the given device: cuda:0
2024-06-03 15:27:03 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T152703
2024-06-03 15:27:03 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T152703/tensorboard
2024-06-03 15:27:04 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 15:27:10 [INFO]: Epoch 001 - training loss: 0.8698, validation loss: 0.6341
2024-06-03 15:27:16 [INFO]: Epoch 002 - training loss: 0.5117, validation loss: 0.6491
2024-06-03 15:27:22 [INFO]: Epoch 003 - training loss: 0.4659, validation loss: 0.6429
2024-06-03 15:27:28 [INFO]: Epoch 004 - training loss: 0.4534, validation loss: 0.6120
2024-06-03 15:27:34 [INFO]: Epoch 005 - training loss: 0.4456, validation loss: 0.6224
2024-06-03 15:27:40 [INFO]: Epoch 006 - training loss: 0.4315, validation loss: 0.6296
2024-06-03 15:27:46 [INFO]: Epoch 007 - training loss: 0.4199, validation loss: 0.5830
2024-06-03 15:27:53 [INFO]: Epoch 008 - training loss: 0.4162, validation loss: 0.5998
2024-06-03 15:27:59 [INFO]: Epoch 009 - training loss: 0.4005, validation loss: 0.6237
2024-06-03 15:28:05 [INFO]: Epoch 010 - training loss: 0.4048, validation loss: 0.6082
2024-06-03 15:28:11 [INFO]: Epoch 011 - training loss: 0.3805, validation loss: 0.6068
2024-06-03 15:28:17 [INFO]: Epoch 012 - training loss: 0.3727, validation loss: 0.5907
2024-06-03 15:28:23 [INFO]: Epoch 013 - training loss: 0.3664, validation loss: 0.5887
2024-06-03 15:28:30 [INFO]: Epoch 014 - training loss: 0.3531, validation loss: 0.5762
2024-06-03 15:28:36 [INFO]: Epoch 015 - training loss: 0.3549, validation loss: 0.5869
2024-06-03 15:28:42 [INFO]: Epoch 016 - training loss: 0.3479, validation loss: 0.5868
2024-06-03 15:28:48 [INFO]: Epoch 017 - training loss: 0.3450, validation loss: 0.5776
2024-06-03 15:28:55 [INFO]: Epoch 018 - training loss: 0.3346, validation loss: 0.5615
2024-06-03 15:29:01 [INFO]: Epoch 019 - training loss: 0.3284, validation loss: 0.5856
2024-06-03 15:29:07 [INFO]: Epoch 020 - training loss: 0.3241, validation loss: 0.5615
2024-06-03 15:29:13 [INFO]: Epoch 021 - training loss: 0.3223, validation loss: 0.5698
2024-06-03 15:29:19 [INFO]: Epoch 022 - training loss: 0.3107, validation loss: 0.5731
2024-06-03 15:29:25 [INFO]: Epoch 023 - training loss: 0.3085, validation loss: 0.5513
2024-06-03 15:29:31 [INFO]: Epoch 024 - training loss: 0.3106, validation loss: 0.5676
2024-06-03 15:29:38 [INFO]: Epoch 025 - training loss: 0.3077, validation loss: 0.5436
2024-06-03 15:29:44 [INFO]: Epoch 026 - training loss: 0.3081, validation loss: 0.5624
2024-06-03 15:29:50 [INFO]: Epoch 027 - training loss: 0.3099, validation loss: 0.5669
2024-06-03 15:29:56 [INFO]: Epoch 028 - training loss: 0.3135, validation loss: 0.5784
2024-06-03 15:30:02 [INFO]: Epoch 029 - training loss: 0.2928, validation loss: 0.5585
2024-06-03 15:30:08 [INFO]: Epoch 030 - training loss: 0.2848, validation loss: 0.5399
2024-06-03 15:30:14 [INFO]: Epoch 031 - training loss: 0.2847, validation loss: 0.5446
2024-06-03 15:30:20 [INFO]: Epoch 032 - training loss: 0.2830, validation loss: 0.5201
2024-06-03 15:30:26 [INFO]: Epoch 033 - training loss: 0.2818, validation loss: 0.5192
2024-06-03 15:30:32 [INFO]: Epoch 034 - training loss: 0.2837, validation loss: 0.5504
2024-06-03 15:30:39 [INFO]: Epoch 035 - training loss: 0.2898, validation loss: 0.5191
2024-06-03 15:30:45 [INFO]: Epoch 036 - training loss: 0.2825, validation loss: 0.5268
2024-06-03 15:30:50 [INFO]: Epoch 037 - training loss: 0.2809, validation loss: 0.5398
2024-06-03 15:30:56 [INFO]: Epoch 038 - training loss: 0.2736, validation loss: 0.5192
2024-06-03 15:31:01 [INFO]: Epoch 039 - training loss: 0.2717, validation loss: 0.5290
2024-06-03 15:31:07 [INFO]: Epoch 040 - training loss: 0.2693, validation loss: 0.5169
2024-06-03 15:31:14 [INFO]: Epoch 041 - training loss: 0.2658, validation loss: 0.5105
2024-06-03 15:31:20 [INFO]: Epoch 042 - training loss: 0.2684, validation loss: 0.5092
2024-06-03 15:31:27 [INFO]: Epoch 043 - training loss: 0.2742, validation loss: 0.4943
2024-06-03 15:31:33 [INFO]: Epoch 044 - training loss: 0.2633, validation loss: 0.5066
2024-06-03 15:31:39 [INFO]: Epoch 045 - training loss: 0.2607, validation loss: 0.4921
2024-06-03 15:31:45 [INFO]: Epoch 046 - training loss: 0.2713, validation loss: 0.4968
2024-06-03 15:31:51 [INFO]: Epoch 047 - training loss: 0.2646, validation loss: 0.4893
2024-06-03 15:31:57 [INFO]: Epoch 048 - training loss: 0.2543, validation loss: 0.4912
2024-06-03 15:32:03 [INFO]: Epoch 049 - training loss: 0.2612, validation loss: 0.4844
2024-06-03 15:32:09 [INFO]: Epoch 050 - training loss: 0.2600, validation loss: 0.4673
2024-06-03 15:32:15 [INFO]: Epoch 051 - training loss: 0.2508, validation loss: 0.4714
2024-06-03 15:32:22 [INFO]: Epoch 052 - training loss: 0.2503, validation loss: 0.4659
2024-06-03 15:32:28 [INFO]: Epoch 053 - training loss: 0.2503, validation loss: 0.4677
2024-06-03 15:32:34 [INFO]: Epoch 054 - training loss: 0.2542, validation loss: 0.4671
2024-06-03 15:32:40 [INFO]: Epoch 055 - training loss: 0.2502, validation loss: 0.4842
2024-06-03 15:32:46 [INFO]: Epoch 056 - training loss: 0.2506, validation loss: 0.4555
2024-06-03 15:32:52 [INFO]: Epoch 057 - training loss: 0.2457, validation loss: 0.4481
2024-06-03 15:32:58 [INFO]: Epoch 058 - training loss: 0.2440, validation loss: 0.4481
2024-06-03 15:33:04 [INFO]: Epoch 059 - training loss: 0.2454, validation loss: 0.4408
2024-06-03 15:33:09 [INFO]: Epoch 060 - training loss: 0.2427, validation loss: 0.4532
2024-06-03 15:33:15 [INFO]: Epoch 061 - training loss: 0.2470, validation loss: 0.4363
2024-06-03 15:33:21 [INFO]: Epoch 062 - training loss: 0.2425, validation loss: 0.4228
2024-06-03 15:33:27 [INFO]: Epoch 063 - training loss: 0.2406, validation loss: 0.4409
2024-06-03 15:33:33 [INFO]: Epoch 064 - training loss: 0.2391, validation loss: 0.4287
2024-06-03 15:33:38 [INFO]: Epoch 065 - training loss: 0.2424, validation loss: 0.4355
2024-06-03 15:33:44 [INFO]: Epoch 066 - training loss: 0.2386, validation loss: 0.4302
2024-06-03 15:33:50 [INFO]: Epoch 067 - training loss: 0.2350, validation loss: 0.4241
2024-06-03 15:33:56 [INFO]: Epoch 068 - training loss: 0.2339, validation loss: 0.4302
2024-06-03 15:34:01 [INFO]: Epoch 069 - training loss: 0.2401, validation loss: 0.4280
2024-06-03 15:34:07 [INFO]: Epoch 070 - training loss: 0.2347, validation loss: 0.4133
2024-06-03 15:34:13 [INFO]: Epoch 071 - training loss: 0.2386, validation loss: 0.4102
2024-06-03 15:34:19 [INFO]: Epoch 072 - training loss: 0.2346, validation loss: 0.4286
2024-06-03 15:34:25 [INFO]: Epoch 073 - training loss: 0.2329, validation loss: 0.4173
2024-06-03 15:34:30 [INFO]: Epoch 074 - training loss: 0.2290, validation loss: 0.4097
2024-06-03 15:34:36 [INFO]: Epoch 075 - training loss: 0.2314, validation loss: 0.4317
2024-06-03 15:34:41 [INFO]: Epoch 076 - training loss: 0.2354, validation loss: 0.4347
2024-06-03 15:34:46 [INFO]: Epoch 077 - training loss: 0.2293, validation loss: 0.4037
2024-06-03 15:34:51 [INFO]: Epoch 078 - training loss: 0.2316, validation loss: 0.4111
2024-06-03 15:34:56 [INFO]: Epoch 079 - training loss: 0.2260, validation loss: 0.3985
2024-06-03 15:35:01 [INFO]: Epoch 080 - training loss: 0.2231, validation loss: 0.4162
2024-06-03 15:35:06 [INFO]: Epoch 081 - training loss: 0.2264, validation loss: 0.4170
2024-06-03 15:35:11 [INFO]: Epoch 082 - training loss: 0.2341, validation loss: 0.3956
2024-06-03 15:35:16 [INFO]: Epoch 083 - training loss: 0.2237, validation loss: 0.3877
2024-06-03 15:35:21 [INFO]: Epoch 084 - training loss: 0.2239, validation loss: 0.4081
2024-06-03 15:35:26 [INFO]: Epoch 085 - training loss: 0.2244, validation loss: 0.3859
2024-06-03 15:35:31 [INFO]: Epoch 086 - training loss: 0.2242, validation loss: 0.3794
2024-06-03 15:35:36 [INFO]: Epoch 087 - training loss: 0.2232, validation loss: 0.3928
2024-06-03 15:35:41 [INFO]: Epoch 088 - training loss: 0.2264, validation loss: 0.3839
2024-06-03 15:35:46 [INFO]: Epoch 089 - training loss: 0.2215, validation loss: 0.3771
2024-06-03 15:35:51 [INFO]: Epoch 090 - training loss: 0.2224, validation loss: 0.3938
2024-06-03 15:35:56 [INFO]: Epoch 091 - training loss: 0.2218, validation loss: 0.3771
2024-06-03 15:36:01 [INFO]: Epoch 092 - training loss: 0.2236, validation loss: 0.4085
2024-06-03 15:36:05 [INFO]: Epoch 093 - training loss: 0.2226, validation loss: 0.3734
2024-06-03 15:36:10 [INFO]: Epoch 094 - training loss: 0.2180, validation loss: 0.3704
2024-06-03 15:36:15 [INFO]: Epoch 095 - training loss: 0.2200, validation loss: 0.3997
2024-06-03 15:36:20 [INFO]: Epoch 096 - training loss: 0.2178, validation loss: 0.3741
2024-06-03 15:36:25 [INFO]: Epoch 097 - training loss: 0.2169, validation loss: 0.3782
2024-06-03 15:36:30 [INFO]: Epoch 098 - training loss: 0.2210, validation loss: 0.3886
2024-06-03 15:36:35 [INFO]: Epoch 099 - training loss: 0.2289, validation loss: 0.3752
2024-06-03 15:36:40 [INFO]: Epoch 100 - training loss: 0.2264, validation loss: 0.3839
2024-06-03 15:36:40 [INFO]: Finished training. The best model is from epoch#94.
2024-06-03 15:36:40 [INFO]: Saved the model to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_2/20240603_T152703/iTransformer.pypots
2024-06-03 15:36:41 [INFO]: Successfully saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_2/imputation.pkl
2024-06-03 15:36:41 [INFO]: Round2 - iTransformer on BeijingAir: MAE=0.3184, MSE=0.4399, MRE=0.4304
2024-06-03 15:36:41 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 15:36:41 [INFO]: Using the given device: cuda:0
2024-06-03 15:36:41 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T153641
2024-06-03 15:36:41 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T153641/tensorboard
2024-06-03 15:36:42 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 15:36:46 [INFO]: Epoch 001 - training loss: 0.8589, validation loss: 0.6473
2024-06-03 15:36:50 [INFO]: Epoch 002 - training loss: 0.5058, validation loss: 0.6455
2024-06-03 15:36:55 [INFO]: Epoch 003 - training loss: 0.4654, validation loss: 0.6517
2024-06-03 15:37:00 [INFO]: Epoch 004 - training loss: 0.4538, validation loss: 0.6289
2024-06-03 15:37:04 [INFO]: Epoch 005 - training loss: 0.4428, validation loss: 0.6381
2024-06-03 15:37:09 [INFO]: Epoch 006 - training loss: 0.4277, validation loss: 0.6343
2024-06-03 15:37:13 [INFO]: Epoch 007 - training loss: 0.4303, validation loss: 0.5869
2024-06-03 15:37:17 [INFO]: Epoch 008 - training loss: 0.4127, validation loss: 0.5921
2024-06-03 15:37:22 [INFO]: Epoch 009 - training loss: 0.3993, validation loss: 0.6089
2024-06-03 15:37:26 [INFO]: Epoch 010 - training loss: 0.3962, validation loss: 0.5973
2024-06-03 15:37:31 [INFO]: Epoch 011 - training loss: 0.3787, validation loss: 0.6068
2024-06-03 15:37:35 [INFO]: Epoch 012 - training loss: 0.3736, validation loss: 0.6335
2024-06-03 15:37:40 [INFO]: Epoch 013 - training loss: 0.3590, validation loss: 0.5915
2024-06-03 15:37:44 [INFO]: Epoch 014 - training loss: 0.3606, validation loss: 0.6299
2024-06-03 15:37:49 [INFO]: Epoch 015 - training loss: 0.3481, validation loss: 0.5935
2024-06-03 15:37:53 [INFO]: Epoch 016 - training loss: 0.3466, validation loss: 0.5901
2024-06-03 15:37:57 [INFO]: Epoch 017 - training loss: 0.3257, validation loss: 0.5929
2024-06-03 15:37:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 15:37:57 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 15:37:57 [INFO]: Saved the model to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_3/20240603_T153641/iTransformer.pypots
2024-06-03 15:37:59 [INFO]: Successfully saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_3/imputation.pkl
2024-06-03 15:37:59 [INFO]: Round3 - iTransformer on BeijingAir: MAE=0.4798, MSE=0.6551, MRE=0.6486
2024-06-03 15:37:59 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 15:37:59 [INFO]: Using the given device: cuda:0
2024-06-03 15:37:59 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T153759
2024-06-03 15:37:59 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T153759/tensorboard
2024-06-03 15:37:59 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 8,286,232
2024-06-03 15:38:03 [INFO]: Epoch 001 - training loss: 0.8496, validation loss: 0.5963
2024-06-03 15:38:08 [INFO]: Epoch 002 - training loss: 0.5052, validation loss: 0.6750
2024-06-03 15:38:13 [INFO]: Epoch 003 - training loss: 0.4639, validation loss: 0.6362
2024-06-03 15:38:17 [INFO]: Epoch 004 - training loss: 0.4474, validation loss: 0.6042
2024-06-03 15:38:22 [INFO]: Epoch 005 - training loss: 0.4522, validation loss: 0.6424
2024-06-03 15:38:26 [INFO]: Epoch 006 - training loss: 0.4354, validation loss: 0.6261
2024-06-03 15:38:31 [INFO]: Epoch 007 - training loss: 0.4198, validation loss: 0.5986
2024-06-03 15:38:35 [INFO]: Epoch 008 - training loss: 0.4127, validation loss: 0.6254
2024-06-03 15:38:40 [INFO]: Epoch 009 - training loss: 0.4116, validation loss: 0.5982
2024-06-03 15:38:44 [INFO]: Epoch 010 - training loss: 0.3938, validation loss: 0.6101
2024-06-03 15:38:49 [INFO]: Epoch 011 - training loss: 0.3897, validation loss: 0.6008
2024-06-03 15:38:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 15:38:49 [INFO]: Finished training. The best model is from epoch#1.
2024-06-03 15:38:49 [INFO]: Saved the model to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_4/20240603_T153759/iTransformer.pypots
2024-06-03 15:38:50 [INFO]: Successfully saved to results_block_rate05/BeijingAir/iTransformer_BeijingAir/round_4/imputation.pkl
2024-06-03 15:38:50 [INFO]: Round4 - iTransformer on BeijingAir: MAE=0.4773, MSE=0.6629, MRE=0.6452
2024-06-03 15:38:50 [INFO]: Done! Final results:
Averaged iTransformer (8,286,232 params) on BeijingAir: MAE=0.4184 ± 0.08088015839377187, MSE=0.5763 ± 0.11162296853479499, MRE=0.5507 ± 0.10646032302822848, average inference time=0.35