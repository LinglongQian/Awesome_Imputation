2024-06-03 13:05:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 13:05:13 [INFO]: Using the given device: cuda:0
2024-06-03 13:05:13 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_0/20240603_T130513
2024-06-03 13:05:13 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_0/20240603_T130513/tensorboard
2024-06-03 13:05:14 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 13:05:25 [INFO]: Epoch 001 - training loss: 1.0672, validation loss: 0.5359
2024-06-03 13:05:30 [INFO]: Epoch 002 - training loss: 0.6894, validation loss: 0.3850
2024-06-03 13:05:35 [INFO]: Epoch 003 - training loss: 0.5931, validation loss: 0.3403
2024-06-03 13:05:41 [INFO]: Epoch 004 - training loss: 0.5493, validation loss: 0.3688
2024-06-03 13:05:46 [INFO]: Epoch 005 - training loss: 0.5194, validation loss: 0.3174
2024-06-03 13:05:51 [INFO]: Epoch 006 - training loss: 0.4969, validation loss: 0.3079
2024-06-03 13:05:56 [INFO]: Epoch 007 - training loss: 0.4876, validation loss: 0.3058
2024-06-03 13:06:01 [INFO]: Epoch 008 - training loss: 0.4741, validation loss: 0.2991
2024-06-03 13:06:07 [INFO]: Epoch 009 - training loss: 0.4654, validation loss: 0.3008
2024-06-03 13:06:12 [INFO]: Epoch 010 - training loss: 0.4604, validation loss: 0.3024
2024-06-03 13:06:17 [INFO]: Epoch 011 - training loss: 0.4540, validation loss: 0.2991
2024-06-03 13:06:22 [INFO]: Epoch 012 - training loss: 0.4477, validation loss: 0.3109
2024-06-03 13:06:27 [INFO]: Epoch 013 - training loss: 0.4415, validation loss: 0.3096
2024-06-03 13:06:33 [INFO]: Epoch 014 - training loss: 0.4381, validation loss: 0.3105
2024-06-03 13:06:38 [INFO]: Epoch 015 - training loss: 0.4360, validation loss: 0.3069
2024-06-03 13:06:43 [INFO]: Epoch 016 - training loss: 0.4344, validation loss: 0.3032
2024-06-03 13:06:48 [INFO]: Epoch 017 - training loss: 0.4297, validation loss: 0.2986
2024-06-03 13:06:53 [INFO]: Epoch 018 - training loss: 0.4288, validation loss: 0.3089
2024-06-03 13:06:58 [INFO]: Epoch 019 - training loss: 0.4285, validation loss: 0.3138
2024-06-03 13:07:03 [INFO]: Epoch 020 - training loss: 0.4165, validation loss: 0.3118
2024-06-03 13:07:09 [INFO]: Epoch 021 - training loss: 0.4164, validation loss: 0.2982
2024-06-03 13:07:14 [INFO]: Epoch 022 - training loss: 0.4147, validation loss: 0.3042
2024-06-03 13:07:19 [INFO]: Epoch 023 - training loss: 0.4137, validation loss: 0.3001
2024-06-03 13:07:24 [INFO]: Epoch 024 - training loss: 0.4089, validation loss: 0.3002
2024-06-03 13:07:30 [INFO]: Epoch 025 - training loss: 0.4063, validation loss: 0.2947
2024-06-03 13:07:35 [INFO]: Epoch 026 - training loss: 0.4034, validation loss: 0.3023
2024-06-03 13:07:40 [INFO]: Epoch 027 - training loss: 0.4069, validation loss: 0.2999
2024-06-03 13:07:46 [INFO]: Epoch 028 - training loss: 0.4049, validation loss: 0.3089
2024-06-03 13:07:51 [INFO]: Epoch 029 - training loss: 0.4011, validation loss: 0.3045
2024-06-03 13:07:56 [INFO]: Epoch 030 - training loss: 0.3992, validation loss: 0.2953
2024-06-03 13:08:01 [INFO]: Epoch 031 - training loss: 0.3965, validation loss: 0.3104
2024-06-03 13:08:06 [INFO]: Epoch 032 - training loss: 0.3990, validation loss: 0.2921
2024-06-03 13:08:11 [INFO]: Epoch 033 - training loss: 0.3933, validation loss: 0.3020
2024-06-03 13:08:17 [INFO]: Epoch 034 - training loss: 0.3918, validation loss: 0.2971
2024-06-03 13:08:22 [INFO]: Epoch 035 - training loss: 0.3916, validation loss: 0.2995
2024-06-03 13:08:27 [INFO]: Epoch 036 - training loss: 0.3905, validation loss: 0.3008
2024-06-03 13:08:32 [INFO]: Epoch 037 - training loss: 0.3887, validation loss: 0.2993
2024-06-03 13:08:37 [INFO]: Epoch 038 - training loss: 0.3859, validation loss: 0.2980
2024-06-03 13:08:42 [INFO]: Epoch 039 - training loss: 0.3837, validation loss: 0.3003
2024-06-03 13:08:47 [INFO]: Epoch 040 - training loss: 0.3863, validation loss: 0.2909
2024-06-03 13:08:52 [INFO]: Epoch 041 - training loss: 0.3830, validation loss: 0.2923
2024-06-03 13:08:57 [INFO]: Epoch 042 - training loss: 0.3809, validation loss: 0.2974
2024-06-03 13:09:03 [INFO]: Epoch 043 - training loss: 0.3797, validation loss: 0.2838
2024-06-03 13:09:08 [INFO]: Epoch 044 - training loss: 0.3769, validation loss: 0.2837
2024-06-03 13:09:13 [INFO]: Epoch 045 - training loss: 0.3790, validation loss: 0.2821
2024-06-03 13:09:18 [INFO]: Epoch 046 - training loss: 0.3768, validation loss: 0.2820
2024-06-03 13:09:23 [INFO]: Epoch 047 - training loss: 0.3771, validation loss: 0.2893
2024-06-03 13:09:28 [INFO]: Epoch 048 - training loss: 0.3736, validation loss: 0.2862
2024-06-03 13:09:33 [INFO]: Epoch 049 - training loss: 0.3735, validation loss: 0.2905
2024-06-03 13:09:38 [INFO]: Epoch 050 - training loss: 0.3725, validation loss: 0.2877
2024-06-03 13:09:43 [INFO]: Epoch 051 - training loss: 0.3687, validation loss: 0.2837
2024-06-03 13:09:49 [INFO]: Epoch 052 - training loss: 0.3739, validation loss: 0.2947
2024-06-03 13:09:54 [INFO]: Epoch 053 - training loss: 0.3710, validation loss: 0.2793
2024-06-03 13:09:59 [INFO]: Epoch 054 - training loss: 0.3668, validation loss: 0.2858
2024-06-03 13:10:04 [INFO]: Epoch 055 - training loss: 0.3670, validation loss: 0.2816
2024-06-03 13:10:09 [INFO]: Epoch 056 - training loss: 0.3662, validation loss: 0.2833
2024-06-03 13:10:15 [INFO]: Epoch 057 - training loss: 0.3632, validation loss: 0.2833
2024-06-03 13:10:20 [INFO]: Epoch 058 - training loss: 0.3633, validation loss: 0.2854
2024-06-03 13:10:25 [INFO]: Epoch 059 - training loss: 0.3612, validation loss: 0.2779
2024-06-03 13:10:30 [INFO]: Epoch 060 - training loss: 0.3638, validation loss: 0.2685
2024-06-03 13:10:36 [INFO]: Epoch 061 - training loss: 0.3618, validation loss: 0.2834
2024-06-03 13:10:41 [INFO]: Epoch 062 - training loss: 0.3594, validation loss: 0.2803
2024-06-03 13:10:46 [INFO]: Epoch 063 - training loss: 0.3595, validation loss: 0.2725
2024-06-03 13:10:51 [INFO]: Epoch 064 - training loss: 0.3576, validation loss: 0.2741
2024-06-03 13:10:56 [INFO]: Epoch 065 - training loss: 0.3581, validation loss: 0.2773
2024-06-03 13:11:02 [INFO]: Epoch 066 - training loss: 0.3568, validation loss: 0.2759
2024-06-03 13:11:07 [INFO]: Epoch 067 - training loss: 0.3548, validation loss: 0.2758
2024-06-03 13:11:12 [INFO]: Epoch 068 - training loss: 0.3541, validation loss: 0.2734
2024-06-03 13:11:17 [INFO]: Epoch 069 - training loss: 0.3525, validation loss: 0.2753
2024-06-03 13:11:22 [INFO]: Epoch 070 - training loss: 0.3538, validation loss: 0.2691
2024-06-03 13:11:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:11:22 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 13:11:22 [INFO]: Saved the model to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_0/20240603_T130513/FreTS.pypots
2024-06-03 13:11:23 [INFO]: Successfully saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_0/imputation.pkl
2024-06-03 13:11:23 [INFO]: Round0 - FreTS on BeijingAir: MAE=0.2462, MSE=0.3050, MRE=0.3328
2024-06-03 13:11:23 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 13:11:23 [INFO]: Using the given device: cuda:0
2024-06-03 13:11:23 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_1/20240603_T131123
2024-06-03 13:11:23 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_1/20240603_T131123/tensorboard
2024-06-03 13:11:24 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 13:11:29 [INFO]: Epoch 001 - training loss: 1.0712, validation loss: 0.5420
2024-06-03 13:11:34 [INFO]: Epoch 002 - training loss: 0.6898, validation loss: 0.3886
2024-06-03 13:11:39 [INFO]: Epoch 003 - training loss: 0.5908, validation loss: 0.3642
2024-06-03 13:11:44 [INFO]: Epoch 004 - training loss: 0.5441, validation loss: 0.3390
2024-06-03 13:11:49 [INFO]: Epoch 005 - training loss: 0.5204, validation loss: 0.3205
2024-06-03 13:11:54 [INFO]: Epoch 006 - training loss: 0.5028, validation loss: 0.3141
2024-06-03 13:11:59 [INFO]: Epoch 007 - training loss: 0.4845, validation loss: 0.3111
2024-06-03 13:12:03 [INFO]: Epoch 008 - training loss: 0.4735, validation loss: 0.3113
2024-06-03 13:12:08 [INFO]: Epoch 009 - training loss: 0.4642, validation loss: 0.3046
2024-06-03 13:12:13 [INFO]: Epoch 010 - training loss: 0.4569, validation loss: 0.2983
2024-06-03 13:12:18 [INFO]: Epoch 011 - training loss: 0.4534, validation loss: 0.3039
2024-06-03 13:12:22 [INFO]: Epoch 012 - training loss: 0.4551, validation loss: 0.2986
2024-06-03 13:12:27 [INFO]: Epoch 013 - training loss: 0.4502, validation loss: 0.3047
2024-06-03 13:12:32 [INFO]: Epoch 014 - training loss: 0.4443, validation loss: 0.3002
2024-06-03 13:12:37 [INFO]: Epoch 015 - training loss: 0.4386, validation loss: 0.2962
2024-06-03 13:12:42 [INFO]: Epoch 016 - training loss: 0.4346, validation loss: 0.3060
2024-06-03 13:12:47 [INFO]: Epoch 017 - training loss: 0.4325, validation loss: 0.2995
2024-06-03 13:12:51 [INFO]: Epoch 018 - training loss: 0.4286, validation loss: 0.3043
2024-06-03 13:12:56 [INFO]: Epoch 019 - training loss: 0.4248, validation loss: 0.2999
2024-06-03 13:13:01 [INFO]: Epoch 020 - training loss: 0.4223, validation loss: 0.3003
2024-06-03 13:13:06 [INFO]: Epoch 021 - training loss: 0.4225, validation loss: 0.3061
2024-06-03 13:13:10 [INFO]: Epoch 022 - training loss: 0.4257, validation loss: 0.2978
2024-06-03 13:13:15 [INFO]: Epoch 023 - training loss: 0.4174, validation loss: 0.3100
2024-06-03 13:13:20 [INFO]: Epoch 024 - training loss: 0.4156, validation loss: 0.3150
2024-06-03 13:13:24 [INFO]: Epoch 025 - training loss: 0.4172, validation loss: 0.3102
2024-06-03 13:13:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:13:24 [INFO]: Finished training. The best model is from epoch#15.
2024-06-03 13:13:24 [INFO]: Saved the model to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_1/20240603_T131123/FreTS.pypots
2024-06-03 13:13:25 [INFO]: Successfully saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_1/imputation.pkl
2024-06-03 13:13:25 [INFO]: Round1 - FreTS on BeijingAir: MAE=0.2873, MSE=0.3491, MRE=0.3884
2024-06-03 13:13:25 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 13:13:25 [INFO]: Using the given device: cuda:0
2024-06-03 13:13:26 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_2/20240603_T131325
2024-06-03 13:13:26 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_2/20240603_T131325/tensorboard
2024-06-03 13:13:26 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 13:13:30 [INFO]: Epoch 001 - training loss: 1.0225, validation loss: 0.4701
2024-06-03 13:13:35 [INFO]: Epoch 002 - training loss: 0.6827, validation loss: 0.3807
2024-06-03 13:13:40 [INFO]: Epoch 003 - training loss: 0.5831, validation loss: 0.3338
2024-06-03 13:13:44 [INFO]: Epoch 004 - training loss: 0.5395, validation loss: 0.3234
2024-06-03 13:13:49 [INFO]: Epoch 005 - training loss: 0.5167, validation loss: 0.3169
2024-06-03 13:13:54 [INFO]: Epoch 006 - training loss: 0.4999, validation loss: 0.3122
2024-06-03 13:13:59 [INFO]: Epoch 007 - training loss: 0.4854, validation loss: 0.3033
2024-06-03 13:14:04 [INFO]: Epoch 008 - training loss: 0.4754, validation loss: 0.2990
2024-06-03 13:14:09 [INFO]: Epoch 009 - training loss: 0.4659, validation loss: 0.3008
2024-06-03 13:14:14 [INFO]: Epoch 010 - training loss: 0.4593, validation loss: 0.3018
2024-06-03 13:14:18 [INFO]: Epoch 011 - training loss: 0.4543, validation loss: 0.3049
2024-06-03 13:14:23 [INFO]: Epoch 012 - training loss: 0.4513, validation loss: 0.2979
2024-06-03 13:14:28 [INFO]: Epoch 013 - training loss: 0.4474, validation loss: 0.3006
2024-06-03 13:14:33 [INFO]: Epoch 014 - training loss: 0.4405, validation loss: 0.2988
2024-06-03 13:14:37 [INFO]: Epoch 015 - training loss: 0.4363, validation loss: 0.3045
2024-06-03 13:14:42 [INFO]: Epoch 016 - training loss: 0.4360, validation loss: 0.3046
2024-06-03 13:14:47 [INFO]: Epoch 017 - training loss: 0.4332, validation loss: 0.3208
2024-06-03 13:14:52 [INFO]: Epoch 018 - training loss: 0.4352, validation loss: 0.3050
2024-06-03 13:14:56 [INFO]: Epoch 019 - training loss: 0.4282, validation loss: 0.2922
2024-06-03 13:15:01 [INFO]: Epoch 020 - training loss: 0.4255, validation loss: 0.3133
2024-06-03 13:15:06 [INFO]: Epoch 021 - training loss: 0.4233, validation loss: 0.3014
2024-06-03 13:15:10 [INFO]: Epoch 022 - training loss: 0.4216, validation loss: 0.3055
2024-06-03 13:15:15 [INFO]: Epoch 023 - training loss: 0.4246, validation loss: 0.3025
2024-06-03 13:15:20 [INFO]: Epoch 024 - training loss: 0.4179, validation loss: 0.3167
2024-06-03 13:15:25 [INFO]: Epoch 025 - training loss: 0.4177, validation loss: 0.2982
2024-06-03 13:15:30 [INFO]: Epoch 026 - training loss: 0.4161, validation loss: 0.3051
2024-06-03 13:15:35 [INFO]: Epoch 027 - training loss: 0.4102, validation loss: 0.3023
2024-06-03 13:15:40 [INFO]: Epoch 028 - training loss: 0.4074, validation loss: 0.3041
2024-06-03 13:15:44 [INFO]: Epoch 029 - training loss: 0.4107, validation loss: 0.2959
2024-06-03 13:15:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:15:44 [INFO]: Finished training. The best model is from epoch#19.
2024-06-03 13:15:44 [INFO]: Saved the model to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_2/20240603_T131325/FreTS.pypots
2024-06-03 13:15:45 [INFO]: Successfully saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_2/imputation.pkl
2024-06-03 13:15:45 [INFO]: Round2 - FreTS on BeijingAir: MAE=0.2762, MSE=0.3295, MRE=0.3734
2024-06-03 13:15:45 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 13:15:45 [INFO]: Using the given device: cuda:0
2024-06-03 13:15:45 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_3/20240603_T131545
2024-06-03 13:15:45 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_3/20240603_T131545/tensorboard
2024-06-03 13:15:45 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 13:15:50 [INFO]: Epoch 001 - training loss: 1.0763, validation loss: 0.5067
2024-06-03 13:15:55 [INFO]: Epoch 002 - training loss: 0.6943, validation loss: 0.3808
2024-06-03 13:16:00 [INFO]: Epoch 003 - training loss: 0.5875, validation loss: 0.3345
2024-06-03 13:16:04 [INFO]: Epoch 004 - training loss: 0.5453, validation loss: 0.3348
2024-06-03 13:16:09 [INFO]: Epoch 005 - training loss: 0.5151, validation loss: 0.3195
2024-06-03 13:16:13 [INFO]: Epoch 006 - training loss: 0.5020, validation loss: 0.3104
2024-06-03 13:16:18 [INFO]: Epoch 007 - training loss: 0.4863, validation loss: 0.3007
2024-06-03 13:16:23 [INFO]: Epoch 008 - training loss: 0.4740, validation loss: 0.2973
2024-06-03 13:16:28 [INFO]: Epoch 009 - training loss: 0.4668, validation loss: 0.3016
2024-06-03 13:16:32 [INFO]: Epoch 010 - training loss: 0.4549, validation loss: 0.3012
2024-06-03 13:16:37 [INFO]: Epoch 011 - training loss: 0.4510, validation loss: 0.2977
2024-06-03 13:16:42 [INFO]: Epoch 012 - training loss: 0.4479, validation loss: 0.3135
2024-06-03 13:16:47 [INFO]: Epoch 013 - training loss: 0.4460, validation loss: 0.3013
2024-06-03 13:16:51 [INFO]: Epoch 014 - training loss: 0.4380, validation loss: 0.3034
2024-06-03 13:16:56 [INFO]: Epoch 015 - training loss: 0.4347, validation loss: 0.3072
2024-06-03 13:17:01 [INFO]: Epoch 016 - training loss: 0.4393, validation loss: 0.3012
2024-06-03 13:17:06 [INFO]: Epoch 017 - training loss: 0.4299, validation loss: 0.2972
2024-06-03 13:17:10 [INFO]: Epoch 018 - training loss: 0.4267, validation loss: 0.2967
2024-06-03 13:17:15 [INFO]: Epoch 019 - training loss: 0.4237, validation loss: 0.2966
2024-06-03 13:17:20 [INFO]: Epoch 020 - training loss: 0.4191, validation loss: 0.2993
2024-06-03 13:17:24 [INFO]: Epoch 021 - training loss: 0.4196, validation loss: 0.3073
2024-06-03 13:17:29 [INFO]: Epoch 022 - training loss: 0.4182, validation loss: 0.2939
2024-06-03 13:17:34 [INFO]: Epoch 023 - training loss: 0.4150, validation loss: 0.2978
2024-06-03 13:17:38 [INFO]: Epoch 024 - training loss: 0.4129, validation loss: 0.2960
2024-06-03 13:17:43 [INFO]: Epoch 025 - training loss: 0.4145, validation loss: 0.3080
2024-06-03 13:17:48 [INFO]: Epoch 026 - training loss: 0.4112, validation loss: 0.2995
2024-06-03 13:17:53 [INFO]: Epoch 027 - training loss: 0.4109, validation loss: 0.2987
2024-06-03 13:17:57 [INFO]: Epoch 028 - training loss: 0.4080, validation loss: 0.3017
2024-06-03 13:18:02 [INFO]: Epoch 029 - training loss: 0.4035, validation loss: 0.3177
2024-06-03 13:18:07 [INFO]: Epoch 030 - training loss: 0.4043, validation loss: 0.3143
2024-06-03 13:18:12 [INFO]: Epoch 031 - training loss: 0.4021, validation loss: 0.2890
2024-06-03 13:18:16 [INFO]: Epoch 032 - training loss: 0.4024, validation loss: 0.3071
2024-06-03 13:18:21 [INFO]: Epoch 033 - training loss: 0.3986, validation loss: 0.3001
2024-06-03 13:18:26 [INFO]: Epoch 034 - training loss: 0.3987, validation loss: 0.2948
2024-06-03 13:18:31 [INFO]: Epoch 035 - training loss: 0.3952, validation loss: 0.2943
2024-06-03 13:18:36 [INFO]: Epoch 036 - training loss: 0.3952, validation loss: 0.2982
2024-06-03 13:18:40 [INFO]: Epoch 037 - training loss: 0.3948, validation loss: 0.2941
2024-06-03 13:18:45 [INFO]: Epoch 038 - training loss: 0.3910, validation loss: 0.3035
2024-06-03 13:18:49 [INFO]: Epoch 039 - training loss: 0.3935, validation loss: 0.2991
2024-06-03 13:18:54 [INFO]: Epoch 040 - training loss: 0.3898, validation loss: 0.2878
2024-06-03 13:18:59 [INFO]: Epoch 041 - training loss: 0.3945, validation loss: 0.2934
2024-06-03 13:19:03 [INFO]: Epoch 042 - training loss: 0.3922, validation loss: 0.3144
2024-06-03 13:19:08 [INFO]: Epoch 043 - training loss: 0.3950, validation loss: 0.3173
2024-06-03 13:19:13 [INFO]: Epoch 044 - training loss: 0.3940, validation loss: 0.2986
2024-06-03 13:19:18 [INFO]: Epoch 045 - training loss: 0.3855, validation loss: 0.2890
2024-06-03 13:19:22 [INFO]: Epoch 046 - training loss: 0.3828, validation loss: 0.2923
2024-06-03 13:19:27 [INFO]: Epoch 047 - training loss: 0.3836, validation loss: 0.2902
2024-06-03 13:19:32 [INFO]: Epoch 048 - training loss: 0.3836, validation loss: 0.2912
2024-06-03 13:19:36 [INFO]: Epoch 049 - training loss: 0.3789, validation loss: 0.2959
2024-06-03 13:19:40 [INFO]: Epoch 050 - training loss: 0.3819, validation loss: 0.2897
2024-06-03 13:19:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:19:40 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 13:19:40 [INFO]: Saved the model to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_3/20240603_T131545/FreTS.pypots
2024-06-03 13:19:41 [INFO]: Successfully saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_3/imputation.pkl
2024-06-03 13:19:41 [INFO]: Round3 - FreTS on BeijingAir: MAE=0.2687, MSE=0.3250, MRE=0.3633
2024-06-03 13:19:41 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 13:19:41 [INFO]: Using the given device: cuda:0
2024-06-03 13:19:41 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_4/20240603_T131941
2024-06-03 13:19:41 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_4/20240603_T131941/tensorboard
2024-06-03 13:19:41 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 909,852
2024-06-03 13:19:45 [INFO]: Epoch 001 - training loss: 1.0814, validation loss: 0.5166
2024-06-03 13:19:49 [INFO]: Epoch 002 - training loss: 0.7091, validation loss: 0.3867
2024-06-03 13:19:54 [INFO]: Epoch 003 - training loss: 0.5957, validation loss: 0.3462
2024-06-03 13:19:58 [INFO]: Epoch 004 - training loss: 0.5455, validation loss: 0.3377
2024-06-03 13:20:02 [INFO]: Epoch 005 - training loss: 0.5193, validation loss: 0.3413
2024-06-03 13:20:06 [INFO]: Epoch 006 - training loss: 0.5045, validation loss: 0.3089
2024-06-03 13:20:10 [INFO]: Epoch 007 - training loss: 0.4851, validation loss: 0.3028
2024-06-03 13:20:14 [INFO]: Epoch 008 - training loss: 0.4731, validation loss: 0.3014
2024-06-03 13:20:18 [INFO]: Epoch 009 - training loss: 0.4657, validation loss: 0.3026
2024-06-03 13:20:22 [INFO]: Epoch 010 - training loss: 0.4573, validation loss: 0.3035
2024-06-03 13:20:26 [INFO]: Epoch 011 - training loss: 0.4572, validation loss: 0.3020
2024-06-03 13:20:30 [INFO]: Epoch 012 - training loss: 0.4512, validation loss: 0.3014
2024-06-03 13:20:35 [INFO]: Epoch 013 - training loss: 0.4460, validation loss: 0.2956
2024-06-03 13:20:39 [INFO]: Epoch 014 - training loss: 0.4383, validation loss: 0.2995
2024-06-03 13:20:43 [INFO]: Epoch 015 - training loss: 0.4370, validation loss: 0.2982
2024-06-03 13:20:47 [INFO]: Epoch 016 - training loss: 0.4378, validation loss: 0.2985
2024-06-03 13:20:51 [INFO]: Epoch 017 - training loss: 0.4347, validation loss: 0.2981
2024-06-03 13:20:56 [INFO]: Epoch 018 - training loss: 0.4297, validation loss: 0.3008
2024-06-03 13:21:00 [INFO]: Epoch 019 - training loss: 0.4265, validation loss: 0.3042
2024-06-03 13:21:04 [INFO]: Epoch 020 - training loss: 0.4207, validation loss: 0.2891
2024-06-03 13:21:08 [INFO]: Epoch 021 - training loss: 0.4217, validation loss: 0.2968
2024-06-03 13:21:12 [INFO]: Epoch 022 - training loss: 0.4223, validation loss: 0.3076
2024-06-03 13:21:16 [INFO]: Epoch 023 - training loss: 0.4183, validation loss: 0.3004
2024-06-03 13:21:20 [INFO]: Epoch 024 - training loss: 0.4152, validation loss: 0.2899
2024-06-03 13:21:24 [INFO]: Epoch 025 - training loss: 0.4127, validation loss: 0.2916
2024-06-03 13:21:29 [INFO]: Epoch 026 - training loss: 0.4103, validation loss: 0.2958
2024-06-03 13:21:33 [INFO]: Epoch 027 - training loss: 0.4053, validation loss: 0.3006
2024-06-03 13:21:37 [INFO]: Epoch 028 - training loss: 0.4062, validation loss: 0.2925
2024-06-03 13:21:41 [INFO]: Epoch 029 - training loss: 0.4062, validation loss: 0.2989
2024-06-03 13:21:45 [INFO]: Epoch 030 - training loss: 0.4064, validation loss: 0.2949
2024-06-03 13:21:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:21:45 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 13:21:45 [INFO]: Saved the model to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_4/20240603_T131941/FreTS.pypots
2024-06-03 13:21:46 [INFO]: Successfully saved to results_block_rate05/BeijingAir/FreTS_BeijingAir/round_4/imputation.pkl
2024-06-03 13:21:46 [INFO]: Round4 - FreTS on BeijingAir: MAE=0.2738, MSE=0.3332, MRE=0.3701
2024-06-03 13:21:46 [INFO]: Done! Final results:
Averaged FreTS (909,852 params) on BeijingAir: MAE=0.2640 ± 0.01419054402947953, MSE=0.3231 ± 0.015098110822106062, MRE=0.3475 ± 0.018678621942968678, average inference time=0.18