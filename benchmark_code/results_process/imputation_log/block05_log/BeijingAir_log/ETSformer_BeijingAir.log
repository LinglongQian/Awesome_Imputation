2024-06-03 13:05:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 13:05:13 [INFO]: Using the given device: cuda:0
2024-06-03 13:05:13 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T130513
2024-06-03 13:05:13 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T130513/tensorboard
2024-06-03 13:05:15 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 13:05:40 [INFO]: Epoch 001 - training loss: 1.0249, validation loss: 0.6584
2024-06-03 13:05:57 [INFO]: Epoch 002 - training loss: 0.8334, validation loss: 0.5427
2024-06-03 13:06:13 [INFO]: Epoch 003 - training loss: 0.7552, validation loss: 0.5106
2024-06-03 13:06:30 [INFO]: Epoch 004 - training loss: 0.7074, validation loss: 0.4867
2024-06-03 13:06:46 [INFO]: Epoch 005 - training loss: 0.6728, validation loss: 0.4753
2024-06-03 13:07:02 [INFO]: Epoch 006 - training loss: 0.6477, validation loss: 0.4620
2024-06-03 13:07:17 [INFO]: Epoch 007 - training loss: 0.6269, validation loss: 0.4526
2024-06-03 13:07:33 [INFO]: Epoch 008 - training loss: 0.6055, validation loss: 0.4425
2024-06-03 13:07:50 [INFO]: Epoch 009 - training loss: 0.5925, validation loss: 0.4369
2024-06-03 13:08:06 [INFO]: Epoch 010 - training loss: 0.5796, validation loss: 0.4310
2024-06-03 13:08:22 [INFO]: Epoch 011 - training loss: 0.5678, validation loss: 0.4250
2024-06-03 13:08:38 [INFO]: Epoch 012 - training loss: 0.5567, validation loss: 0.4347
2024-06-03 13:08:55 [INFO]: Epoch 013 - training loss: 0.5457, validation loss: 0.4199
2024-06-03 13:09:11 [INFO]: Epoch 014 - training loss: 0.5367, validation loss: 0.4216
2024-06-03 13:09:27 [INFO]: Epoch 015 - training loss: 0.5304, validation loss: 0.4197
2024-06-03 13:09:44 [INFO]: Epoch 016 - training loss: 0.5253, validation loss: 0.4127
2024-06-03 13:10:00 [INFO]: Epoch 017 - training loss: 0.5194, validation loss: 0.4156
2024-06-03 13:10:17 [INFO]: Epoch 018 - training loss: 0.5134, validation loss: 0.4152
2024-06-03 13:10:33 [INFO]: Epoch 019 - training loss: 0.5087, validation loss: 0.4131
2024-06-03 13:10:49 [INFO]: Epoch 020 - training loss: 0.5033, validation loss: 0.4109
2024-06-03 13:11:05 [INFO]: Epoch 021 - training loss: 0.4995, validation loss: 0.4027
2024-06-03 13:11:22 [INFO]: Epoch 022 - training loss: 0.4966, validation loss: 0.4085
2024-06-03 13:11:39 [INFO]: Epoch 023 - training loss: 0.4914, validation loss: 0.4028
2024-06-03 13:11:55 [INFO]: Epoch 024 - training loss: 0.4894, validation loss: 0.3982
2024-06-03 13:12:10 [INFO]: Epoch 025 - training loss: 0.4842, validation loss: 0.4005
2024-06-03 13:12:25 [INFO]: Epoch 026 - training loss: 0.4847, validation loss: 0.3957
2024-06-03 13:12:41 [INFO]: Epoch 027 - training loss: 0.4789, validation loss: 0.3932
2024-06-03 13:12:56 [INFO]: Epoch 028 - training loss: 0.4786, validation loss: 0.3963
2024-06-03 13:13:12 [INFO]: Epoch 029 - training loss: 0.4751, validation loss: 0.3938
2024-06-03 13:13:27 [INFO]: Epoch 030 - training loss: 0.4725, validation loss: 0.3955
2024-06-03 13:13:42 [INFO]: Epoch 031 - training loss: 0.4719, validation loss: 0.3915
2024-06-03 13:13:57 [INFO]: Epoch 032 - training loss: 0.4696, validation loss: 0.3911
2024-06-03 13:14:12 [INFO]: Epoch 033 - training loss: 0.4684, validation loss: 0.3858
2024-06-03 13:14:27 [INFO]: Epoch 034 - training loss: 0.4643, validation loss: 0.3834
2024-06-03 13:14:42 [INFO]: Epoch 035 - training loss: 0.4639, validation loss: 0.3849
2024-06-03 13:14:57 [INFO]: Epoch 036 - training loss: 0.4636, validation loss: 0.3829
2024-06-03 13:15:12 [INFO]: Epoch 037 - training loss: 0.4604, validation loss: 0.3878
2024-06-03 13:15:27 [INFO]: Epoch 038 - training loss: 0.4604, validation loss: 0.3856
2024-06-03 13:15:42 [INFO]: Epoch 039 - training loss: 0.4572, validation loss: 0.3819
2024-06-03 13:15:58 [INFO]: Epoch 040 - training loss: 0.4578, validation loss: 0.3828
2024-06-03 13:16:12 [INFO]: Epoch 041 - training loss: 0.4564, validation loss: 0.3745
2024-06-03 13:16:28 [INFO]: Epoch 042 - training loss: 0.4548, validation loss: 0.3779
2024-06-03 13:16:43 [INFO]: Epoch 043 - training loss: 0.4534, validation loss: 0.3750
2024-06-03 13:16:58 [INFO]: Epoch 044 - training loss: 0.4539, validation loss: 0.3789
2024-06-03 13:17:13 [INFO]: Epoch 045 - training loss: 0.4527, validation loss: 0.3812
2024-06-03 13:17:28 [INFO]: Epoch 046 - training loss: 0.4487, validation loss: 0.3732
2024-06-03 13:17:43 [INFO]: Epoch 047 - training loss: 0.4486, validation loss: 0.3761
2024-06-03 13:17:59 [INFO]: Epoch 048 - training loss: 0.4482, validation loss: 0.3754
2024-06-03 13:18:14 [INFO]: Epoch 049 - training loss: 0.4457, validation loss: 0.3760
2024-06-03 13:18:30 [INFO]: Epoch 050 - training loss: 0.4448, validation loss: 0.3746
2024-06-03 13:18:44 [INFO]: Epoch 051 - training loss: 0.4439, validation loss: 0.3661
2024-06-03 13:18:59 [INFO]: Epoch 052 - training loss: 0.4454, validation loss: 0.3728
2024-06-03 13:19:15 [INFO]: Epoch 053 - training loss: 0.4447, validation loss: 0.3617
2024-06-03 13:19:30 [INFO]: Epoch 054 - training loss: 0.4408, validation loss: 0.3712
2024-06-03 13:19:44 [INFO]: Epoch 055 - training loss: 0.4405, validation loss: 0.3678
2024-06-03 13:19:57 [INFO]: Epoch 056 - training loss: 0.4386, validation loss: 0.3697
2024-06-03 13:20:11 [INFO]: Epoch 057 - training loss: 0.4389, validation loss: 0.3627
2024-06-03 13:20:24 [INFO]: Epoch 058 - training loss: 0.4395, validation loss: 0.3630
2024-06-03 13:20:38 [INFO]: Epoch 059 - training loss: 0.4384, validation loss: 0.3670
2024-06-03 13:20:52 [INFO]: Epoch 060 - training loss: 0.4355, validation loss: 0.3644
2024-06-03 13:21:06 [INFO]: Epoch 061 - training loss: 0.4362, validation loss: 0.3621
2024-06-03 13:21:19 [INFO]: Epoch 062 - training loss: 0.4360, validation loss: 0.3635
2024-06-03 13:21:32 [INFO]: Epoch 063 - training loss: 0.4354, validation loss: 0.3661
2024-06-03 13:21:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:21:32 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 13:21:33 [INFO]: Saved the model to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T130513/ETSformer.pypots
2024-06-03 13:21:43 [INFO]: Successfully saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_0/imputation.pkl
2024-06-03 13:21:43 [INFO]: Round0 - ETSformer on BeijingAir: MAE=0.3311, MSE=0.3992, MRE=0.4476
2024-06-03 13:21:43 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 13:21:43 [INFO]: Using the given device: cuda:0
2024-06-03 13:21:43 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T132143
2024-06-03 13:21:43 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T132143/tensorboard
2024-06-03 13:21:44 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 13:21:56 [INFO]: Epoch 001 - training loss: 1.0115, validation loss: 0.6617
2024-06-03 13:22:09 [INFO]: Epoch 002 - training loss: 0.8436, validation loss: 0.5809
2024-06-03 13:22:21 [INFO]: Epoch 003 - training loss: 0.7271, validation loss: 0.4834
2024-06-03 13:22:32 [INFO]: Epoch 004 - training loss: 0.6706, validation loss: 0.4634
2024-06-03 13:22:44 [INFO]: Epoch 005 - training loss: 0.6388, validation loss: 0.4624
2024-06-03 13:22:56 [INFO]: Epoch 006 - training loss: 0.6183, validation loss: 0.4474
2024-06-03 13:23:08 [INFO]: Epoch 007 - training loss: 0.6018, validation loss: 0.4438
2024-06-03 13:23:19 [INFO]: Epoch 008 - training loss: 0.5837, validation loss: 0.4421
2024-06-03 13:23:31 [INFO]: Epoch 009 - training loss: 0.5722, validation loss: 0.4396
2024-06-03 13:23:42 [INFO]: Epoch 010 - training loss: 0.5603, validation loss: 0.4359
2024-06-03 13:23:54 [INFO]: Epoch 011 - training loss: 0.5485, validation loss: 0.4298
2024-06-03 13:24:06 [INFO]: Epoch 012 - training loss: 0.5420, validation loss: 0.4327
2024-06-03 13:24:18 [INFO]: Epoch 013 - training loss: 0.5366, validation loss: 0.4220
2024-06-03 13:24:30 [INFO]: Epoch 014 - training loss: 0.5263, validation loss: 0.4246
2024-06-03 13:24:42 [INFO]: Epoch 015 - training loss: 0.5181, validation loss: 0.4272
2024-06-03 13:24:54 [INFO]: Epoch 016 - training loss: 0.5148, validation loss: 0.4187
2024-06-03 13:25:05 [INFO]: Epoch 017 - training loss: 0.5110, validation loss: 0.4223
2024-06-03 13:25:18 [INFO]: Epoch 018 - training loss: 0.5053, validation loss: 0.4229
2024-06-03 13:25:29 [INFO]: Epoch 019 - training loss: 0.5030, validation loss: 0.4257
2024-06-03 13:25:41 [INFO]: Epoch 020 - training loss: 0.4961, validation loss: 0.4187
2024-06-03 13:25:53 [INFO]: Epoch 021 - training loss: 0.4928, validation loss: 0.4129
2024-06-03 13:26:05 [INFO]: Epoch 022 - training loss: 0.4914, validation loss: 0.4137
2024-06-03 13:26:17 [INFO]: Epoch 023 - training loss: 0.4883, validation loss: 0.4132
2024-06-03 13:26:29 [INFO]: Epoch 024 - training loss: 0.4858, validation loss: 0.4072
2024-06-03 13:26:41 [INFO]: Epoch 025 - training loss: 0.4814, validation loss: 0.4094
2024-06-03 13:26:53 [INFO]: Epoch 026 - training loss: 0.4802, validation loss: 0.4138
2024-06-03 13:27:05 [INFO]: Epoch 027 - training loss: 0.4777, validation loss: 0.4133
2024-06-03 13:27:17 [INFO]: Epoch 028 - training loss: 0.4759, validation loss: 0.4049
2024-06-03 13:27:29 [INFO]: Epoch 029 - training loss: 0.4745, validation loss: 0.4050
2024-06-03 13:27:41 [INFO]: Epoch 030 - training loss: 0.4730, validation loss: 0.4056
2024-06-03 13:27:52 [INFO]: Epoch 031 - training loss: 0.4699, validation loss: 0.4023
2024-06-03 13:28:05 [INFO]: Epoch 032 - training loss: 0.4678, validation loss: 0.4022
2024-06-03 13:28:16 [INFO]: Epoch 033 - training loss: 0.4687, validation loss: 0.3999
2024-06-03 13:28:28 [INFO]: Epoch 034 - training loss: 0.4647, validation loss: 0.4043
2024-06-03 13:28:40 [INFO]: Epoch 035 - training loss: 0.4624, validation loss: 0.4033
2024-06-03 13:28:52 [INFO]: Epoch 036 - training loss: 0.4649, validation loss: 0.4040
2024-06-03 13:29:04 [INFO]: Epoch 037 - training loss: 0.4601, validation loss: 0.4018
2024-06-03 13:29:15 [INFO]: Epoch 038 - training loss: 0.4591, validation loss: 0.3970
2024-06-03 13:29:28 [INFO]: Epoch 039 - training loss: 0.4615, validation loss: 0.3956
2024-06-03 13:29:40 [INFO]: Epoch 040 - training loss: 0.4576, validation loss: 0.3893
2024-06-03 13:29:51 [INFO]: Epoch 041 - training loss: 0.4561, validation loss: 0.3929
2024-06-03 13:30:03 [INFO]: Epoch 042 - training loss: 0.4549, validation loss: 0.3970
2024-06-03 13:30:15 [INFO]: Epoch 043 - training loss: 0.4570, validation loss: 0.3983
2024-06-03 13:30:27 [INFO]: Epoch 044 - training loss: 0.4529, validation loss: 0.3922
2024-06-03 13:30:39 [INFO]: Epoch 045 - training loss: 0.4519, validation loss: 0.3922
2024-06-03 13:30:51 [INFO]: Epoch 046 - training loss: 0.4518, validation loss: 0.3953
2024-06-03 13:31:02 [INFO]: Epoch 047 - training loss: 0.4521, validation loss: 0.3904
2024-06-03 13:31:14 [INFO]: Epoch 048 - training loss: 0.4512, validation loss: 0.3896
2024-06-03 13:31:26 [INFO]: Epoch 049 - training loss: 0.4501, validation loss: 0.3891
2024-06-03 13:31:38 [INFO]: Epoch 050 - training loss: 0.4477, validation loss: 0.3866
2024-06-03 13:31:50 [INFO]: Epoch 051 - training loss: 0.4472, validation loss: 0.3934
2024-06-03 13:32:02 [INFO]: Epoch 052 - training loss: 0.4484, validation loss: 0.3912
2024-06-03 13:32:13 [INFO]: Epoch 053 - training loss: 0.4468, validation loss: 0.3852
2024-06-03 13:32:25 [INFO]: Epoch 054 - training loss: 0.4463, validation loss: 0.3850
2024-06-03 13:32:37 [INFO]: Epoch 055 - training loss: 0.4455, validation loss: 0.3914
2024-06-03 13:32:49 [INFO]: Epoch 056 - training loss: 0.4452, validation loss: 0.3882
2024-06-03 13:33:01 [INFO]: Epoch 057 - training loss: 0.4432, validation loss: 0.3797
2024-06-03 13:33:13 [INFO]: Epoch 058 - training loss: 0.4444, validation loss: 0.3875
2024-06-03 13:33:25 [INFO]: Epoch 059 - training loss: 0.4419, validation loss: 0.3875
2024-06-03 13:33:37 [INFO]: Epoch 060 - training loss: 0.4423, validation loss: 0.3894
2024-06-03 13:33:49 [INFO]: Epoch 061 - training loss: 0.4416, validation loss: 0.3883
2024-06-03 13:34:01 [INFO]: Epoch 062 - training loss: 0.4404, validation loss: 0.3812
2024-06-03 13:34:12 [INFO]: Epoch 063 - training loss: 0.4401, validation loss: 0.3856
2024-06-03 13:34:24 [INFO]: Epoch 064 - training loss: 0.4405, validation loss: 0.3836
2024-06-03 13:34:36 [INFO]: Epoch 065 - training loss: 0.4399, validation loss: 0.3864
2024-06-03 13:34:48 [INFO]: Epoch 066 - training loss: 0.4402, validation loss: 0.3815
2024-06-03 13:35:00 [INFO]: Epoch 067 - training loss: 0.4388, validation loss: 0.3849
2024-06-03 13:35:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:35:00 [INFO]: Finished training. The best model is from epoch#57.
2024-06-03 13:35:00 [INFO]: Saved the model to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T132143/ETSformer.pypots
2024-06-03 13:35:09 [INFO]: Successfully saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_1/imputation.pkl
2024-06-03 13:35:09 [INFO]: Round1 - ETSformer on BeijingAir: MAE=0.3464, MSE=0.4223, MRE=0.4682
2024-06-03 13:35:09 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 13:35:09 [INFO]: Using the given device: cuda:0
2024-06-03 13:35:09 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T133509
2024-06-03 13:35:09 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T133509/tensorboard
2024-06-03 13:35:10 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 13:35:22 [INFO]: Epoch 001 - training loss: 1.0004, validation loss: 0.6629
2024-06-03 13:35:33 [INFO]: Epoch 002 - training loss: 0.8194, validation loss: 0.5623
2024-06-03 13:35:45 [INFO]: Epoch 003 - training loss: 0.7217, validation loss: 0.5019
2024-06-03 13:35:57 [INFO]: Epoch 004 - training loss: 0.6719, validation loss: 0.4776
2024-06-03 13:36:09 [INFO]: Epoch 005 - training loss: 0.6405, validation loss: 0.4706
2024-06-03 13:36:22 [INFO]: Epoch 006 - training loss: 0.6159, validation loss: 0.4661
2024-06-03 13:36:33 [INFO]: Epoch 007 - training loss: 0.5981, validation loss: 0.4567
2024-06-03 13:36:45 [INFO]: Epoch 008 - training loss: 0.5793, validation loss: 0.4571
2024-06-03 13:36:57 [INFO]: Epoch 009 - training loss: 0.5671, validation loss: 0.4450
2024-06-03 13:37:09 [INFO]: Epoch 010 - training loss: 0.5557, validation loss: 0.4463
2024-06-03 13:37:21 [INFO]: Epoch 011 - training loss: 0.5449, validation loss: 0.4450
2024-06-03 13:37:33 [INFO]: Epoch 012 - training loss: 0.5362, validation loss: 0.4414
2024-06-03 13:37:45 [INFO]: Epoch 013 - training loss: 0.5280, validation loss: 0.4379
2024-06-03 13:37:57 [INFO]: Epoch 014 - training loss: 0.5190, validation loss: 0.4409
2024-06-03 13:38:08 [INFO]: Epoch 015 - training loss: 0.5150, validation loss: 0.4384
2024-06-03 13:38:21 [INFO]: Epoch 016 - training loss: 0.5092, validation loss: 0.4325
2024-06-03 13:38:32 [INFO]: Epoch 017 - training loss: 0.5032, validation loss: 0.4338
2024-06-03 13:38:44 [INFO]: Epoch 018 - training loss: 0.4979, validation loss: 0.4366
2024-06-03 13:38:56 [INFO]: Epoch 019 - training loss: 0.4938, validation loss: 0.4376
2024-06-03 13:39:08 [INFO]: Epoch 020 - training loss: 0.4906, validation loss: 0.4299
2024-06-03 13:39:21 [INFO]: Epoch 021 - training loss: 0.4862, validation loss: 0.4329
2024-06-03 13:39:32 [INFO]: Epoch 022 - training loss: 0.4857, validation loss: 0.4345
2024-06-03 13:39:44 [INFO]: Epoch 023 - training loss: 0.4830, validation loss: 0.4348
2024-06-03 13:39:56 [INFO]: Epoch 024 - training loss: 0.4794, validation loss: 0.4284
2024-06-03 13:40:08 [INFO]: Epoch 025 - training loss: 0.4755, validation loss: 0.4295
2024-06-03 13:40:20 [INFO]: Epoch 026 - training loss: 0.4728, validation loss: 0.4245
2024-06-03 13:40:32 [INFO]: Epoch 027 - training loss: 0.4721, validation loss: 0.4292
2024-06-03 13:40:44 [INFO]: Epoch 028 - training loss: 0.4697, validation loss: 0.4264
2024-06-03 13:40:56 [INFO]: Epoch 029 - training loss: 0.4667, validation loss: 0.4223
2024-06-03 13:41:07 [INFO]: Epoch 030 - training loss: 0.4656, validation loss: 0.4240
2024-06-03 13:41:19 [INFO]: Epoch 031 - training loss: 0.4640, validation loss: 0.4250
2024-06-03 13:41:31 [INFO]: Epoch 032 - training loss: 0.4621, validation loss: 0.4303
2024-06-03 13:41:43 [INFO]: Epoch 033 - training loss: 0.4599, validation loss: 0.4210
2024-06-03 13:41:55 [INFO]: Epoch 034 - training loss: 0.4596, validation loss: 0.4259
2024-06-03 13:42:07 [INFO]: Epoch 035 - training loss: 0.4591, validation loss: 0.4253
2024-06-03 13:42:19 [INFO]: Epoch 036 - training loss: 0.4567, validation loss: 0.4263
2024-06-03 13:42:31 [INFO]: Epoch 037 - training loss: 0.4566, validation loss: 0.4177
2024-06-03 13:42:43 [INFO]: Epoch 038 - training loss: 0.4565, validation loss: 0.4160
2024-06-03 13:42:55 [INFO]: Epoch 039 - training loss: 0.4553, validation loss: 0.4251
2024-06-03 13:43:07 [INFO]: Epoch 040 - training loss: 0.4533, validation loss: 0.4191
2024-06-03 13:43:19 [INFO]: Epoch 041 - training loss: 0.4509, validation loss: 0.4212
2024-06-03 13:43:30 [INFO]: Epoch 042 - training loss: 0.4522, validation loss: 0.4132
2024-06-03 13:43:42 [INFO]: Epoch 043 - training loss: 0.4510, validation loss: 0.4190
2024-06-03 13:43:54 [INFO]: Epoch 044 - training loss: 0.4493, validation loss: 0.4172
2024-06-03 13:44:05 [INFO]: Epoch 045 - training loss: 0.4490, validation loss: 0.4206
2024-06-03 13:44:17 [INFO]: Epoch 046 - training loss: 0.4483, validation loss: 0.4154
2024-06-03 13:44:29 [INFO]: Epoch 047 - training loss: 0.4464, validation loss: 0.4141
2024-06-03 13:44:41 [INFO]: Epoch 048 - training loss: 0.4481, validation loss: 0.4150
2024-06-03 13:44:53 [INFO]: Epoch 049 - training loss: 0.4457, validation loss: 0.4160
2024-06-03 13:45:05 [INFO]: Epoch 050 - training loss: 0.4471, validation loss: 0.4151
2024-06-03 13:45:16 [INFO]: Epoch 051 - training loss: 0.4444, validation loss: 0.4165
2024-06-03 13:45:28 [INFO]: Epoch 052 - training loss: 0.4454, validation loss: 0.4115
2024-06-03 13:45:40 [INFO]: Epoch 053 - training loss: 0.4433, validation loss: 0.4144
2024-06-03 13:45:51 [INFO]: Epoch 054 - training loss: 0.4450, validation loss: 0.4138
2024-06-03 13:46:03 [INFO]: Epoch 055 - training loss: 0.4418, validation loss: 0.4158
2024-06-03 13:46:15 [INFO]: Epoch 056 - training loss: 0.4408, validation loss: 0.4121
2024-06-03 13:46:27 [INFO]: Epoch 057 - training loss: 0.4432, validation loss: 0.4151
2024-06-03 13:46:39 [INFO]: Epoch 058 - training loss: 0.4383, validation loss: 0.4090
2024-06-03 13:46:50 [INFO]: Epoch 059 - training loss: 0.4392, validation loss: 0.4123
2024-06-03 13:47:02 [INFO]: Epoch 060 - training loss: 0.4384, validation loss: 0.4109
2024-06-03 13:47:14 [INFO]: Epoch 061 - training loss: 0.4376, validation loss: 0.4071
2024-06-03 13:47:25 [INFO]: Epoch 062 - training loss: 0.4393, validation loss: 0.4076
2024-06-03 13:47:37 [INFO]: Epoch 063 - training loss: 0.4368, validation loss: 0.4067
2024-06-03 13:47:49 [INFO]: Epoch 064 - training loss: 0.4370, validation loss: 0.4100
2024-06-03 13:48:01 [INFO]: Epoch 065 - training loss: 0.4381, validation loss: 0.4052
2024-06-03 13:48:13 [INFO]: Epoch 066 - training loss: 0.4370, validation loss: 0.4085
2024-06-03 13:48:23 [INFO]: Epoch 067 - training loss: 0.4367, validation loss: 0.4031
2024-06-03 13:48:33 [INFO]: Epoch 068 - training loss: 0.4341, validation loss: 0.4022
2024-06-03 13:48:42 [INFO]: Epoch 069 - training loss: 0.4351, validation loss: 0.4058
2024-06-03 13:48:52 [INFO]: Epoch 070 - training loss: 0.4342, validation loss: 0.4063
2024-06-03 13:49:02 [INFO]: Epoch 071 - training loss: 0.4356, validation loss: 0.4083
2024-06-03 13:49:11 [INFO]: Epoch 072 - training loss: 0.4325, validation loss: 0.4024
2024-06-03 13:49:21 [INFO]: Epoch 073 - training loss: 0.4328, validation loss: 0.4035
2024-06-03 13:49:31 [INFO]: Epoch 074 - training loss: 0.4331, validation loss: 0.4009
2024-06-03 13:49:41 [INFO]: Epoch 075 - training loss: 0.4330, validation loss: 0.4042
2024-06-03 13:49:51 [INFO]: Epoch 076 - training loss: 0.4317, validation loss: 0.4007
2024-06-03 13:50:00 [INFO]: Epoch 077 - training loss: 0.4317, validation loss: 0.4054
2024-06-03 13:50:10 [INFO]: Epoch 078 - training loss: 0.4330, validation loss: 0.4039
2024-06-03 13:50:20 [INFO]: Epoch 079 - training loss: 0.4311, validation loss: 0.4041
2024-06-03 13:50:30 [INFO]: Epoch 080 - training loss: 0.4311, validation loss: 0.4031
2024-06-03 13:50:41 [INFO]: Epoch 081 - training loss: 0.4317, validation loss: 0.4033
2024-06-03 13:50:50 [INFO]: Epoch 082 - training loss: 0.4324, validation loss: 0.4049
2024-06-03 13:51:00 [INFO]: Epoch 083 - training loss: 0.4303, validation loss: 0.4048
2024-06-03 13:51:10 [INFO]: Epoch 084 - training loss: 0.4313, validation loss: 0.4031
2024-06-03 13:51:20 [INFO]: Epoch 085 - training loss: 0.4281, validation loss: 0.4027
2024-06-03 13:51:30 [INFO]: Epoch 086 - training loss: 0.4289, validation loss: 0.4017
2024-06-03 13:51:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:51:30 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 13:51:30 [INFO]: Saved the model to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T133509/ETSformer.pypots
2024-06-03 13:51:37 [INFO]: Successfully saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_2/imputation.pkl
2024-06-03 13:51:37 [INFO]: Round2 - ETSformer on BeijingAir: MAE=0.3589, MSE=0.4356, MRE=0.4851
2024-06-03 13:51:37 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 13:51:37 [INFO]: Using the given device: cuda:0
2024-06-03 13:51:37 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T135137
2024-06-03 13:51:37 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T135137/tensorboard
2024-06-03 13:51:37 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 13:51:47 [INFO]: Epoch 001 - training loss: 1.0271, validation loss: 0.6736
2024-06-03 13:51:57 [INFO]: Epoch 002 - training loss: 0.8501, validation loss: 0.6019
2024-06-03 13:52:07 [INFO]: Epoch 003 - training loss: 0.7465, validation loss: 0.5178
2024-06-03 13:52:17 [INFO]: Epoch 004 - training loss: 0.6867, validation loss: 0.4885
2024-06-03 13:52:26 [INFO]: Epoch 005 - training loss: 0.6544, validation loss: 0.4787
2024-06-03 13:52:36 [INFO]: Epoch 006 - training loss: 0.6290, validation loss: 0.4678
2024-06-03 13:52:46 [INFO]: Epoch 007 - training loss: 0.6112, validation loss: 0.4652
2024-06-03 13:52:56 [INFO]: Epoch 008 - training loss: 0.5956, validation loss: 0.4557
2024-06-03 13:53:05 [INFO]: Epoch 009 - training loss: 0.5784, validation loss: 0.4544
2024-06-03 13:53:15 [INFO]: Epoch 010 - training loss: 0.5676, validation loss: 0.4441
2024-06-03 13:53:24 [INFO]: Epoch 011 - training loss: 0.5547, validation loss: 0.4425
2024-06-03 13:53:35 [INFO]: Epoch 012 - training loss: 0.5461, validation loss: 0.4414
2024-06-03 13:53:44 [INFO]: Epoch 013 - training loss: 0.5368, validation loss: 0.4368
2024-06-03 13:53:54 [INFO]: Epoch 014 - training loss: 0.5292, validation loss: 0.4299
2024-06-03 13:54:04 [INFO]: Epoch 015 - training loss: 0.5226, validation loss: 0.4291
2024-06-03 13:54:14 [INFO]: Epoch 016 - training loss: 0.5139, validation loss: 0.4265
2024-06-03 13:54:24 [INFO]: Epoch 017 - training loss: 0.5111, validation loss: 0.4287
2024-06-03 13:54:33 [INFO]: Epoch 018 - training loss: 0.5045, validation loss: 0.4276
2024-06-03 13:54:43 [INFO]: Epoch 019 - training loss: 0.5006, validation loss: 0.4213
2024-06-03 13:54:53 [INFO]: Epoch 020 - training loss: 0.4973, validation loss: 0.4231
2024-06-03 13:55:03 [INFO]: Epoch 021 - training loss: 0.4935, validation loss: 0.4248
2024-06-03 13:55:13 [INFO]: Epoch 022 - training loss: 0.4902, validation loss: 0.4281
2024-06-03 13:55:22 [INFO]: Epoch 023 - training loss: 0.4852, validation loss: 0.4261
2024-06-03 13:55:32 [INFO]: Epoch 024 - training loss: 0.4826, validation loss: 0.4257
2024-06-03 13:55:42 [INFO]: Epoch 025 - training loss: 0.4804, validation loss: 0.4194
2024-06-03 13:55:51 [INFO]: Epoch 026 - training loss: 0.4792, validation loss: 0.4201
2024-06-03 13:56:01 [INFO]: Epoch 027 - training loss: 0.4768, validation loss: 0.4209
2024-06-03 13:56:11 [INFO]: Epoch 028 - training loss: 0.4722, validation loss: 0.4237
2024-06-03 13:56:21 [INFO]: Epoch 029 - training loss: 0.4701, validation loss: 0.4171
2024-06-03 13:56:30 [INFO]: Epoch 030 - training loss: 0.4693, validation loss: 0.4233
2024-06-03 13:56:40 [INFO]: Epoch 031 - training loss: 0.4689, validation loss: 0.4250
2024-06-03 13:56:50 [INFO]: Epoch 032 - training loss: 0.4688, validation loss: 0.4196
2024-06-03 13:57:00 [INFO]: Epoch 033 - training loss: 0.4654, validation loss: 0.4162
2024-06-03 13:57:10 [INFO]: Epoch 034 - training loss: 0.4638, validation loss: 0.4170
2024-06-03 13:57:20 [INFO]: Epoch 035 - training loss: 0.4619, validation loss: 0.4160
2024-06-03 13:57:29 [INFO]: Epoch 036 - training loss: 0.4612, validation loss: 0.4152
2024-06-03 13:57:39 [INFO]: Epoch 037 - training loss: 0.4581, validation loss: 0.4163
2024-06-03 13:57:49 [INFO]: Epoch 038 - training loss: 0.4580, validation loss: 0.4124
2024-06-03 13:57:59 [INFO]: Epoch 039 - training loss: 0.4594, validation loss: 0.4134
2024-06-03 13:58:09 [INFO]: Epoch 040 - training loss: 0.4570, validation loss: 0.4151
2024-06-03 13:58:19 [INFO]: Epoch 041 - training loss: 0.4539, validation loss: 0.4164
2024-06-03 13:58:29 [INFO]: Epoch 042 - training loss: 0.4554, validation loss: 0.4175
2024-06-03 13:58:39 [INFO]: Epoch 043 - training loss: 0.4524, validation loss: 0.4141
2024-06-03 13:58:49 [INFO]: Epoch 044 - training loss: 0.4517, validation loss: 0.4150
2024-06-03 13:58:59 [INFO]: Epoch 045 - training loss: 0.4517, validation loss: 0.4128
2024-06-03 13:59:08 [INFO]: Epoch 046 - training loss: 0.4501, validation loss: 0.4075
2024-06-03 13:59:18 [INFO]: Epoch 047 - training loss: 0.4484, validation loss: 0.4114
2024-06-03 13:59:28 [INFO]: Epoch 048 - training loss: 0.4491, validation loss: 0.4096
2024-06-03 13:59:37 [INFO]: Epoch 049 - training loss: 0.4482, validation loss: 0.4103
2024-06-03 13:59:47 [INFO]: Epoch 050 - training loss: 0.4463, validation loss: 0.4103
2024-06-03 13:59:57 [INFO]: Epoch 051 - training loss: 0.4465, validation loss: 0.4042
2024-06-03 14:00:07 [INFO]: Epoch 052 - training loss: 0.4446, validation loss: 0.4058
2024-06-03 14:00:17 [INFO]: Epoch 053 - training loss: 0.4448, validation loss: 0.4099
2024-06-03 14:00:26 [INFO]: Epoch 054 - training loss: 0.4453, validation loss: 0.4070
2024-06-03 14:00:36 [INFO]: Epoch 055 - training loss: 0.4413, validation loss: 0.4092
2024-06-03 14:00:46 [INFO]: Epoch 056 - training loss: 0.4455, validation loss: 0.4005
2024-06-03 14:00:56 [INFO]: Epoch 057 - training loss: 0.4446, validation loss: 0.4028
2024-06-03 14:01:06 [INFO]: Epoch 058 - training loss: 0.4427, validation loss: 0.4079
2024-06-03 14:01:16 [INFO]: Epoch 059 - training loss: 0.4411, validation loss: 0.4048
2024-06-03 14:01:25 [INFO]: Epoch 060 - training loss: 0.4420, validation loss: 0.4043
2024-06-03 14:01:35 [INFO]: Epoch 061 - training loss: 0.4399, validation loss: 0.4075
2024-06-03 14:01:45 [INFO]: Epoch 062 - training loss: 0.4400, validation loss: 0.4030
2024-06-03 14:01:55 [INFO]: Epoch 063 - training loss: 0.4395, validation loss: 0.4067
2024-06-03 14:02:05 [INFO]: Epoch 064 - training loss: 0.4390, validation loss: 0.4028
2024-06-03 14:02:15 [INFO]: Epoch 065 - training loss: 0.4367, validation loss: 0.4002
2024-06-03 14:02:25 [INFO]: Epoch 066 - training loss: 0.4380, validation loss: 0.4061
2024-06-03 14:02:34 [INFO]: Epoch 067 - training loss: 0.4369, validation loss: 0.4046
2024-06-03 14:02:43 [INFO]: Epoch 068 - training loss: 0.4376, validation loss: 0.4061
2024-06-03 14:02:53 [INFO]: Epoch 069 - training loss: 0.4365, validation loss: 0.3985
2024-06-03 14:03:03 [INFO]: Epoch 070 - training loss: 0.4358, validation loss: 0.3996
2024-06-03 14:03:13 [INFO]: Epoch 071 - training loss: 0.4343, validation loss: 0.3978
2024-06-03 14:03:23 [INFO]: Epoch 072 - training loss: 0.4354, validation loss: 0.3970
2024-06-03 14:03:33 [INFO]: Epoch 073 - training loss: 0.4338, validation loss: 0.3992
2024-06-03 14:03:43 [INFO]: Epoch 074 - training loss: 0.4343, validation loss: 0.4013
2024-06-03 14:03:53 [INFO]: Epoch 075 - training loss: 0.4337, validation loss: 0.3973
2024-06-03 14:04:03 [INFO]: Epoch 076 - training loss: 0.4336, validation loss: 0.3948
2024-06-03 14:04:12 [INFO]: Epoch 077 - training loss: 0.4330, validation loss: 0.3919
2024-06-03 14:04:23 [INFO]: Epoch 078 - training loss: 0.4330, validation loss: 0.3928
2024-06-03 14:04:32 [INFO]: Epoch 079 - training loss: 0.4341, validation loss: 0.3936
2024-06-03 14:04:42 [INFO]: Epoch 080 - training loss: 0.4329, validation loss: 0.3969
2024-06-03 14:04:52 [INFO]: Epoch 081 - training loss: 0.4307, validation loss: 0.3951
2024-06-03 14:05:01 [INFO]: Epoch 082 - training loss: 0.4315, validation loss: 0.3964
2024-06-03 14:05:11 [INFO]: Epoch 083 - training loss: 0.4305, validation loss: 0.3957
2024-06-03 14:05:21 [INFO]: Epoch 084 - training loss: 0.4316, validation loss: 0.3929
2024-06-03 14:05:31 [INFO]: Epoch 085 - training loss: 0.4301, validation loss: 0.3939
2024-06-03 14:05:41 [INFO]: Epoch 086 - training loss: 0.4304, validation loss: 0.3981
2024-06-03 14:05:51 [INFO]: Epoch 087 - training loss: 0.4292, validation loss: 0.3948
2024-06-03 14:05:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 14:05:51 [INFO]: Finished training. The best model is from epoch#77.
2024-06-03 14:05:51 [INFO]: Saved the model to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T135137/ETSformer.pypots
2024-06-03 14:05:58 [INFO]: Successfully saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_3/imputation.pkl
2024-06-03 14:05:58 [INFO]: Round3 - ETSformer on BeijingAir: MAE=0.3540, MSE=0.4276, MRE=0.4786
2024-06-03 14:05:58 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 14:05:58 [INFO]: Using the given device: cuda:0
2024-06-03 14:05:58 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T140558
2024-06-03 14:05:58 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T140558/tensorboard
2024-06-03 14:05:59 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 14:06:08 [INFO]: Epoch 001 - training loss: 1.0147, validation loss: 0.6726
2024-06-03 14:06:18 [INFO]: Epoch 002 - training loss: 0.8313, validation loss: 0.5579
2024-06-03 14:06:28 [INFO]: Epoch 003 - training loss: 0.7244, validation loss: 0.5094
2024-06-03 14:06:38 [INFO]: Epoch 004 - training loss: 0.6774, validation loss: 0.4876
2024-06-03 14:06:48 [INFO]: Epoch 005 - training loss: 0.6438, validation loss: 0.4803
2024-06-03 14:06:58 [INFO]: Epoch 006 - training loss: 0.6215, validation loss: 0.4713
2024-06-03 14:07:07 [INFO]: Epoch 007 - training loss: 0.6028, validation loss: 0.4677
2024-06-03 14:07:16 [INFO]: Epoch 008 - training loss: 0.5849, validation loss: 0.4611
2024-06-03 14:07:26 [INFO]: Epoch 009 - training loss: 0.5688, validation loss: 0.4566
2024-06-03 14:07:36 [INFO]: Epoch 010 - training loss: 0.5588, validation loss: 0.4528
2024-06-03 14:07:46 [INFO]: Epoch 011 - training loss: 0.5476, validation loss: 0.4490
2024-06-03 14:07:56 [INFO]: Epoch 012 - training loss: 0.5378, validation loss: 0.4464
2024-06-03 14:08:06 [INFO]: Epoch 013 - training loss: 0.5300, validation loss: 0.4455
2024-06-03 14:08:16 [INFO]: Epoch 014 - training loss: 0.5214, validation loss: 0.4424
2024-06-03 14:08:25 [INFO]: Epoch 015 - training loss: 0.5153, validation loss: 0.4400
2024-06-03 14:08:35 [INFO]: Epoch 016 - training loss: 0.5082, validation loss: 0.4349
2024-06-03 14:08:45 [INFO]: Epoch 017 - training loss: 0.5054, validation loss: 0.4371
2024-06-03 14:08:54 [INFO]: Epoch 018 - training loss: 0.5022, validation loss: 0.4356
2024-06-03 14:09:04 [INFO]: Epoch 019 - training loss: 0.4980, validation loss: 0.4295
2024-06-03 14:09:14 [INFO]: Epoch 020 - training loss: 0.4934, validation loss: 0.4287
2024-06-03 14:09:24 [INFO]: Epoch 021 - training loss: 0.4866, validation loss: 0.4262
2024-06-03 14:09:33 [INFO]: Epoch 022 - training loss: 0.4850, validation loss: 0.4232
2024-06-03 14:09:43 [INFO]: Epoch 023 - training loss: 0.4823, validation loss: 0.4234
2024-06-03 14:09:53 [INFO]: Epoch 024 - training loss: 0.4807, validation loss: 0.4213
2024-06-03 14:10:03 [INFO]: Epoch 025 - training loss: 0.4762, validation loss: 0.4209
2024-06-03 14:10:14 [INFO]: Epoch 026 - training loss: 0.4732, validation loss: 0.4164
2024-06-03 14:10:23 [INFO]: Epoch 027 - training loss: 0.4713, validation loss: 0.4175
2024-06-03 14:10:32 [INFO]: Epoch 028 - training loss: 0.4727, validation loss: 0.4144
2024-06-03 14:10:42 [INFO]: Epoch 029 - training loss: 0.4706, validation loss: 0.4159
2024-06-03 14:10:52 [INFO]: Epoch 030 - training loss: 0.4656, validation loss: 0.4146
2024-06-03 14:11:02 [INFO]: Epoch 031 - training loss: 0.4645, validation loss: 0.4150
2024-06-03 14:11:12 [INFO]: Epoch 032 - training loss: 0.4638, validation loss: 0.4117
2024-06-03 14:11:21 [INFO]: Epoch 033 - training loss: 0.4605, validation loss: 0.4108
2024-06-03 14:11:31 [INFO]: Epoch 034 - training loss: 0.4612, validation loss: 0.4119
2024-06-03 14:11:41 [INFO]: Epoch 035 - training loss: 0.4595, validation loss: 0.4098
2024-06-03 14:11:50 [INFO]: Epoch 036 - training loss: 0.4590, validation loss: 0.4055
2024-06-03 14:12:00 [INFO]: Epoch 037 - training loss: 0.4575, validation loss: 0.4048
2024-06-03 14:12:10 [INFO]: Epoch 038 - training loss: 0.4560, validation loss: 0.4065
2024-06-03 14:12:20 [INFO]: Epoch 039 - training loss: 0.4528, validation loss: 0.4073
2024-06-03 14:12:30 [INFO]: Epoch 040 - training loss: 0.4528, validation loss: 0.4076
2024-06-03 14:12:40 [INFO]: Epoch 041 - training loss: 0.4528, validation loss: 0.4019
2024-06-03 14:12:49 [INFO]: Epoch 042 - training loss: 0.4515, validation loss: 0.3980
2024-06-03 14:12:59 [INFO]: Epoch 043 - training loss: 0.4535, validation loss: 0.4003
2024-06-03 14:13:09 [INFO]: Epoch 044 - training loss: 0.4503, validation loss: 0.3981
2024-06-03 14:13:19 [INFO]: Epoch 045 - training loss: 0.4495, validation loss: 0.4044
2024-06-03 14:13:28 [INFO]: Epoch 046 - training loss: 0.4490, validation loss: 0.4028
2024-06-03 14:13:38 [INFO]: Epoch 047 - training loss: 0.4460, validation loss: 0.3959
2024-06-03 14:13:48 [INFO]: Epoch 048 - training loss: 0.4467, validation loss: 0.4001
2024-06-03 14:13:58 [INFO]: Epoch 049 - training loss: 0.4464, validation loss: 0.3993
2024-06-03 14:14:08 [INFO]: Epoch 050 - training loss: 0.4458, validation loss: 0.3936
2024-06-03 14:14:18 [INFO]: Epoch 051 - training loss: 0.4451, validation loss: 0.3990
2024-06-03 14:14:28 [INFO]: Epoch 052 - training loss: 0.4436, validation loss: 0.3914
2024-06-03 14:14:38 [INFO]: Epoch 053 - training loss: 0.4424, validation loss: 0.3938
2024-06-03 14:14:47 [INFO]: Epoch 054 - training loss: 0.4423, validation loss: 0.3913
2024-06-03 14:14:57 [INFO]: Epoch 055 - training loss: 0.4416, validation loss: 0.3899
2024-06-03 14:15:07 [INFO]: Epoch 056 - training loss: 0.4419, validation loss: 0.3895
2024-06-03 14:15:16 [INFO]: Epoch 057 - training loss: 0.4405, validation loss: 0.3915
2024-06-03 14:15:26 [INFO]: Epoch 058 - training loss: 0.4395, validation loss: 0.3955
2024-06-03 14:15:36 [INFO]: Epoch 059 - training loss: 0.4388, validation loss: 0.3941
2024-06-03 14:15:46 [INFO]: Epoch 060 - training loss: 0.4400, validation loss: 0.3922
2024-06-03 14:15:56 [INFO]: Epoch 061 - training loss: 0.4389, validation loss: 0.3929
2024-06-03 14:16:06 [INFO]: Epoch 062 - training loss: 0.4398, validation loss: 0.3854
2024-06-03 14:16:15 [INFO]: Epoch 063 - training loss: 0.4370, validation loss: 0.3939
2024-06-03 14:16:25 [INFO]: Epoch 064 - training loss: 0.4376, validation loss: 0.3812
2024-06-03 14:16:35 [INFO]: Epoch 065 - training loss: 0.4358, validation loss: 0.3880
2024-06-03 14:16:45 [INFO]: Epoch 066 - training loss: 0.4366, validation loss: 0.3855
2024-06-03 14:16:55 [INFO]: Epoch 067 - training loss: 0.4356, validation loss: 0.3875
2024-06-03 14:17:04 [INFO]: Epoch 068 - training loss: 0.4320, validation loss: 0.3880
2024-06-03 14:17:14 [INFO]: Epoch 069 - training loss: 0.4338, validation loss: 0.3858
2024-06-03 14:17:24 [INFO]: Epoch 070 - training loss: 0.4336, validation loss: 0.3828
2024-06-03 14:17:33 [INFO]: Epoch 071 - training loss: 0.4319, validation loss: 0.3773
2024-06-03 14:17:43 [INFO]: Epoch 072 - training loss: 0.4319, validation loss: 0.3820
2024-06-03 14:17:53 [INFO]: Epoch 073 - training loss: 0.4345, validation loss: 0.3820
2024-06-03 14:18:02 [INFO]: Epoch 074 - training loss: 0.4337, validation loss: 0.3842
2024-06-03 14:18:12 [INFO]: Epoch 075 - training loss: 0.4314, validation loss: 0.3832
2024-06-03 14:18:22 [INFO]: Epoch 076 - training loss: 0.4323, validation loss: 0.3866
2024-06-03 14:18:32 [INFO]: Epoch 077 - training loss: 0.4320, validation loss: 0.3766
2024-06-03 14:18:42 [INFO]: Epoch 078 - training loss: 0.4316, validation loss: 0.3785
2024-06-03 14:18:51 [INFO]: Epoch 079 - training loss: 0.4290, validation loss: 0.3774
2024-06-03 14:19:01 [INFO]: Epoch 080 - training loss: 0.4298, validation loss: 0.3805
2024-06-03 14:19:11 [INFO]: Epoch 081 - training loss: 0.4302, validation loss: 0.3810
2024-06-03 14:19:21 [INFO]: Epoch 082 - training loss: 0.4278, validation loss: 0.3804
2024-06-03 14:19:31 [INFO]: Epoch 083 - training loss: 0.4282, validation loss: 0.3722
2024-06-03 14:19:40 [INFO]: Epoch 084 - training loss: 0.4280, validation loss: 0.3781
2024-06-03 14:19:50 [INFO]: Epoch 085 - training loss: 0.4277, validation loss: 0.3798
2024-06-03 14:20:00 [INFO]: Epoch 086 - training loss: 0.4272, validation loss: 0.3731
2024-06-03 14:20:10 [INFO]: Epoch 087 - training loss: 0.4263, validation loss: 0.3797
2024-06-03 14:20:20 [INFO]: Epoch 088 - training loss: 0.4248, validation loss: 0.3735
2024-06-03 14:20:29 [INFO]: Epoch 089 - training loss: 0.4260, validation loss: 0.3749
2024-06-03 14:20:39 [INFO]: Epoch 090 - training loss: 0.4268, validation loss: 0.3748
2024-06-03 14:20:49 [INFO]: Epoch 091 - training loss: 0.4274, validation loss: 0.3741
2024-06-03 14:20:58 [INFO]: Epoch 092 - training loss: 0.4251, validation loss: 0.3731
2024-06-03 14:21:08 [INFO]: Epoch 093 - training loss: 0.4263, validation loss: 0.3698
2024-06-03 14:21:18 [INFO]: Epoch 094 - training loss: 0.4245, validation loss: 0.3684
2024-06-03 14:21:28 [INFO]: Epoch 095 - training loss: 0.4256, validation loss: 0.3689
2024-06-03 14:21:38 [INFO]: Epoch 096 - training loss: 0.4242, validation loss: 0.3752
2024-06-03 14:21:48 [INFO]: Epoch 097 - training loss: 0.4244, validation loss: 0.3721
2024-06-03 14:21:57 [INFO]: Epoch 098 - training loss: 0.4242, validation loss: 0.3732
2024-06-03 14:22:07 [INFO]: Epoch 099 - training loss: 0.4241, validation loss: 0.3695
2024-06-03 14:22:17 [INFO]: Epoch 100 - training loss: 0.4241, validation loss: 0.3714
2024-06-03 14:22:17 [INFO]: Finished training. The best model is from epoch#94.
2024-06-03 14:22:17 [INFO]: Saved the model to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T140558/ETSformer.pypots
2024-06-03 14:22:24 [INFO]: Successfully saved to results_block_rate05/BeijingAir/ETSformer_BeijingAir/round_4/imputation.pkl
2024-06-03 14:22:24 [INFO]: Round4 - ETSformer on BeijingAir: MAE=0.3421, MSE=0.4094, MRE=0.4624
2024-06-03 14:22:24 [INFO]: Done! Final results:
Averaged ETSformer (7,928,510 params) on BeijingAir: MAE=0.3446 ± 0.010121576347437666, MSE=0.4209 ± 0.01374255669317034, MRE=0.4536 ± 0.013322751944388722, average inference time=1.76