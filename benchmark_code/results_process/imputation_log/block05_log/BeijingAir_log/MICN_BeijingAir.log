2024-06-03 15:47:18 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 15:47:18 [INFO]: Using the given device: cuda:0
2024-06-03 15:47:19 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T154719
2024-06-03 15:47:19 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T154719/tensorboard
2024-06-03 15:47:20 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 15:47:35 [INFO]: Epoch 001 - training loss: 0.8429, validation loss: 0.8854
2024-06-03 15:47:40 [INFO]: Epoch 002 - training loss: 0.6706, validation loss: 0.8494
2024-06-03 15:47:45 [INFO]: Epoch 003 - training loss: 0.6517, validation loss: 0.8233
2024-06-03 15:47:50 [INFO]: Epoch 004 - training loss: 0.6309, validation loss: 0.8187
2024-06-03 15:47:55 [INFO]: Epoch 005 - training loss: 0.6140, validation loss: 0.7549
2024-06-03 15:48:00 [INFO]: Epoch 006 - training loss: 0.6012, validation loss: 0.7695
2024-06-03 15:48:05 [INFO]: Epoch 007 - training loss: 0.5917, validation loss: 0.7698
2024-06-03 15:48:10 [INFO]: Epoch 008 - training loss: 0.5828, validation loss: 0.7481
2024-06-03 15:48:14 [INFO]: Epoch 009 - training loss: 0.5709, validation loss: 0.7487
2024-06-03 15:48:19 [INFO]: Epoch 010 - training loss: 0.5609, validation loss: 0.7287
2024-06-03 15:48:30 [INFO]: Epoch 011 - training loss: 0.5580, validation loss: 0.7234
2024-06-03 15:48:35 [INFO]: Epoch 012 - training loss: 0.5483, validation loss: 0.7051
2024-06-03 15:48:39 [INFO]: Epoch 013 - training loss: 0.5441, validation loss: 0.7176
2024-06-03 15:48:44 [INFO]: Epoch 014 - training loss: 0.5369, validation loss: 0.7151
2024-06-03 15:48:48 [INFO]: Epoch 015 - training loss: 0.5353, validation loss: 0.6997
2024-06-03 15:48:53 [INFO]: Epoch 016 - training loss: 0.5286, validation loss: 0.6853
2024-06-03 15:48:58 [INFO]: Epoch 017 - training loss: 0.5243, validation loss: 0.6701
2024-06-03 15:49:02 [INFO]: Epoch 018 - training loss: 0.5196, validation loss: 0.6787
2024-06-03 15:49:07 [INFO]: Epoch 019 - training loss: 0.5165, validation loss: 0.6771
2024-06-03 15:49:12 [INFO]: Epoch 020 - training loss: 0.5107, validation loss: 0.6839
2024-06-03 15:49:16 [INFO]: Epoch 021 - training loss: 0.5059, validation loss: 0.6617
2024-06-03 15:49:21 [INFO]: Epoch 022 - training loss: 0.5048, validation loss: 0.6741
2024-06-03 15:49:26 [INFO]: Epoch 023 - training loss: 0.5022, validation loss: 0.6691
2024-06-03 15:49:30 [INFO]: Epoch 024 - training loss: 0.4982, validation loss: 0.6497
2024-06-03 15:49:35 [INFO]: Epoch 025 - training loss: 0.4953, validation loss: 0.6534
2024-06-03 15:49:40 [INFO]: Epoch 026 - training loss: 0.4889, validation loss: 0.6538
2024-06-03 15:49:44 [INFO]: Epoch 027 - training loss: 0.4904, validation loss: 0.6656
2024-06-03 15:49:49 [INFO]: Epoch 028 - training loss: 0.4857, validation loss: 0.6734
2024-06-03 15:49:54 [INFO]: Epoch 029 - training loss: 0.4866, validation loss: 0.6504
2024-06-03 15:49:58 [INFO]: Epoch 030 - training loss: 0.4799, validation loss: 0.6468
2024-06-03 15:50:02 [INFO]: Epoch 031 - training loss: 0.4790, validation loss: 0.6532
2024-06-03 15:50:07 [INFO]: Epoch 032 - training loss: 0.4768, validation loss: 0.6552
2024-06-03 15:50:12 [INFO]: Epoch 033 - training loss: 0.4743, validation loss: 0.6459
2024-06-03 15:50:16 [INFO]: Epoch 034 - training loss: 0.4719, validation loss: 0.6614
2024-06-03 15:50:21 [INFO]: Epoch 035 - training loss: 0.4725, validation loss: 0.6535
2024-06-03 15:50:25 [INFO]: Epoch 036 - training loss: 0.4693, validation loss: 0.6309
2024-06-03 15:50:30 [INFO]: Epoch 037 - training loss: 0.4668, validation loss: 0.6390
2024-06-03 15:50:35 [INFO]: Epoch 038 - training loss: 0.4647, validation loss: 0.6233
2024-06-03 15:50:39 [INFO]: Epoch 039 - training loss: 0.4618, validation loss: 0.6372
2024-06-03 15:50:44 [INFO]: Epoch 040 - training loss: 0.4612, validation loss: 0.6413
2024-06-03 15:50:48 [INFO]: Epoch 041 - training loss: 0.4592, validation loss: 0.6329
2024-06-03 15:50:53 [INFO]: Epoch 042 - training loss: 0.4583, validation loss: 0.6213
2024-06-03 15:50:57 [INFO]: Epoch 043 - training loss: 0.4601, validation loss: 0.6387
2024-06-03 15:51:02 [INFO]: Epoch 044 - training loss: 0.4565, validation loss: 0.6290
2024-06-03 15:51:07 [INFO]: Epoch 045 - training loss: 0.4565, validation loss: 0.6352
2024-06-03 15:51:12 [INFO]: Epoch 046 - training loss: 0.4520, validation loss: 0.6179
2024-06-03 15:51:16 [INFO]: Epoch 047 - training loss: 0.4523, validation loss: 0.6254
2024-06-03 15:51:21 [INFO]: Epoch 048 - training loss: 0.4515, validation loss: 0.6274
2024-06-03 15:51:26 [INFO]: Epoch 049 - training loss: 0.4489, validation loss: 0.6250
2024-06-03 15:51:31 [INFO]: Epoch 050 - training loss: 0.4474, validation loss: 0.6223
2024-06-03 15:51:35 [INFO]: Epoch 051 - training loss: 0.4433, validation loss: 0.6244
2024-06-03 15:51:40 [INFO]: Epoch 052 - training loss: 0.4452, validation loss: 0.6166
2024-06-03 15:51:44 [INFO]: Epoch 053 - training loss: 0.4423, validation loss: 0.6076
2024-06-03 15:51:49 [INFO]: Epoch 054 - training loss: 0.4426, validation loss: 0.6206
2024-06-03 15:51:54 [INFO]: Epoch 055 - training loss: 0.4409, validation loss: 0.6206
2024-06-03 15:51:58 [INFO]: Epoch 056 - training loss: 0.4381, validation loss: 0.6154
2024-06-03 15:52:03 [INFO]: Epoch 057 - training loss: 0.4372, validation loss: 0.6192
2024-06-03 15:52:07 [INFO]: Epoch 058 - training loss: 0.4372, validation loss: 0.6152
2024-06-03 15:52:12 [INFO]: Epoch 059 - training loss: 0.4364, validation loss: 0.6088
2024-06-03 15:52:17 [INFO]: Epoch 060 - training loss: 0.4353, validation loss: 0.6104
2024-06-03 15:52:21 [INFO]: Epoch 061 - training loss: 0.4351, validation loss: 0.5949
2024-06-03 15:52:26 [INFO]: Epoch 062 - training loss: 0.4313, validation loss: 0.5952
2024-06-03 15:52:31 [INFO]: Epoch 063 - training loss: 0.4315, validation loss: 0.6024
2024-06-03 15:52:36 [INFO]: Epoch 064 - training loss: 0.4319, validation loss: 0.5975
2024-06-03 15:52:41 [INFO]: Epoch 065 - training loss: 0.4286, validation loss: 0.6032
2024-06-03 15:52:45 [INFO]: Epoch 066 - training loss: 0.4266, validation loss: 0.5965
2024-06-03 15:52:50 [INFO]: Epoch 067 - training loss: 0.4284, validation loss: 0.5925
2024-06-03 15:52:55 [INFO]: Epoch 068 - training loss: 0.4256, validation loss: 0.6058
2024-06-03 15:53:00 [INFO]: Epoch 069 - training loss: 0.4265, validation loss: 0.5964
2024-06-03 15:53:05 [INFO]: Epoch 070 - training loss: 0.4240, validation loss: 0.6026
2024-06-03 15:53:09 [INFO]: Epoch 071 - training loss: 0.4217, validation loss: 0.5878
2024-06-03 15:53:14 [INFO]: Epoch 072 - training loss: 0.4197, validation loss: 0.5924
2024-06-03 15:53:19 [INFO]: Epoch 073 - training loss: 0.4223, validation loss: 0.5957
2024-06-03 15:53:24 [INFO]: Epoch 074 - training loss: 0.4197, validation loss: 0.5884
2024-06-03 15:53:29 [INFO]: Epoch 075 - training loss: 0.4198, validation loss: 0.5928
2024-06-03 15:53:33 [INFO]: Epoch 076 - training loss: 0.4182, validation loss: 0.5976
2024-06-03 15:53:38 [INFO]: Epoch 077 - training loss: 0.4190, validation loss: 0.5916
2024-06-03 15:53:43 [INFO]: Epoch 078 - training loss: 0.4184, validation loss: 0.5828
2024-06-03 15:53:48 [INFO]: Epoch 079 - training loss: 0.4155, validation loss: 0.5799
2024-06-03 15:53:52 [INFO]: Epoch 080 - training loss: 0.4151, validation loss: 0.5866
2024-06-03 15:53:57 [INFO]: Epoch 081 - training loss: 0.4133, validation loss: 0.5800
2024-06-03 15:54:02 [INFO]: Epoch 082 - training loss: 0.4147, validation loss: 0.5778
2024-06-03 15:54:06 [INFO]: Epoch 083 - training loss: 0.4119, validation loss: 0.5816
2024-06-03 15:54:11 [INFO]: Epoch 084 - training loss: 0.4118, validation loss: 0.5766
2024-06-03 15:54:15 [INFO]: Epoch 085 - training loss: 0.4119, validation loss: 0.5801
2024-06-03 15:54:20 [INFO]: Epoch 086 - training loss: 0.4104, validation loss: 0.5802
2024-06-03 15:54:25 [INFO]: Epoch 087 - training loss: 0.4090, validation loss: 0.5769
2024-06-03 15:54:30 [INFO]: Epoch 088 - training loss: 0.4078, validation loss: 0.5799
2024-06-03 15:54:34 [INFO]: Epoch 089 - training loss: 0.4067, validation loss: 0.5815
2024-06-03 15:54:39 [INFO]: Epoch 090 - training loss: 0.4063, validation loss: 0.5749
2024-06-03 15:54:44 [INFO]: Epoch 091 - training loss: 0.4052, validation loss: 0.5768
2024-06-03 15:54:48 [INFO]: Epoch 092 - training loss: 0.4054, validation loss: 0.5797
2024-06-03 15:54:53 [INFO]: Epoch 093 - training loss: 0.4051, validation loss: 0.5705
2024-06-03 15:54:57 [INFO]: Epoch 094 - training loss: 0.4032, validation loss: 0.5678
2024-06-03 15:55:02 [INFO]: Epoch 095 - training loss: 0.4033, validation loss: 0.5699
2024-06-03 15:55:06 [INFO]: Epoch 096 - training loss: 0.4024, validation loss: 0.5707
2024-06-03 15:55:11 [INFO]: Epoch 097 - training loss: 0.4012, validation loss: 0.5673
2024-06-03 15:55:15 [INFO]: Epoch 098 - training loss: 0.3998, validation loss: 0.5710
2024-06-03 15:55:20 [INFO]: Epoch 099 - training loss: 0.3982, validation loss: 0.5763
2024-06-03 15:55:24 [INFO]: Epoch 100 - training loss: 0.3986, validation loss: 0.5750
2024-06-03 15:55:24 [INFO]: Finished training. The best model is from epoch#97.
2024-06-03 15:55:26 [INFO]: Saved the model to results_block_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T154719/MICN.pypots
2024-06-03 15:55:27 [INFO]: Successfully saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_0/imputation.pkl
2024-06-03 15:55:27 [INFO]: Round0 - MICN on BeijingAir: MAE=0.4850, MSE=0.6134, MRE=0.6557
2024-06-03 15:55:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 15:55:27 [INFO]: Using the given device: cuda:0
2024-06-03 15:55:27 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T155527
2024-06-03 15:55:27 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T155527/tensorboard
2024-06-03 15:55:29 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 15:55:34 [INFO]: Epoch 001 - training loss: 0.8611, validation loss: 0.8284
2024-06-03 15:55:39 [INFO]: Epoch 002 - training loss: 0.6895, validation loss: 0.8145
2024-06-03 15:55:44 [INFO]: Epoch 003 - training loss: 0.6758, validation loss: 0.8077
2024-06-03 15:55:49 [INFO]: Epoch 004 - training loss: 0.6578, validation loss: 0.7236
2024-06-03 15:55:54 [INFO]: Epoch 005 - training loss: 0.6270, validation loss: 0.7185
2024-06-03 15:55:59 [INFO]: Epoch 006 - training loss: 0.6152, validation loss: 0.7017
2024-06-03 15:56:04 [INFO]: Epoch 007 - training loss: 0.5948, validation loss: 0.6902
2024-06-03 15:56:09 [INFO]: Epoch 008 - training loss: 0.5780, validation loss: 0.6599
2024-06-03 15:56:13 [INFO]: Epoch 009 - training loss: 0.5694, validation loss: 0.6694
2024-06-03 15:56:18 [INFO]: Epoch 010 - training loss: 0.5641, validation loss: 0.6623
2024-06-03 15:56:23 [INFO]: Epoch 011 - training loss: 0.5541, validation loss: 0.6390
2024-06-03 15:56:28 [INFO]: Epoch 012 - training loss: 0.5422, validation loss: 0.6437
2024-06-03 15:56:33 [INFO]: Epoch 013 - training loss: 0.5403, validation loss: 0.6309
2024-06-03 15:56:37 [INFO]: Epoch 014 - training loss: 0.5316, validation loss: 0.6397
2024-06-03 15:56:42 [INFO]: Epoch 015 - training loss: 0.5265, validation loss: 0.6095
2024-06-03 15:56:46 [INFO]: Epoch 016 - training loss: 0.5171, validation loss: 0.6281
2024-06-03 15:56:51 [INFO]: Epoch 017 - training loss: 0.5137, validation loss: 0.6333
2024-06-03 15:56:55 [INFO]: Epoch 018 - training loss: 0.5083, validation loss: 0.6111
2024-06-03 15:57:00 [INFO]: Epoch 019 - training loss: 0.4991, validation loss: 0.5977
2024-06-03 15:57:05 [INFO]: Epoch 020 - training loss: 0.4976, validation loss: 0.6062
2024-06-03 15:57:10 [INFO]: Epoch 021 - training loss: 0.4933, validation loss: 0.6232
2024-06-03 15:57:15 [INFO]: Epoch 022 - training loss: 0.4915, validation loss: 0.6161
2024-06-03 15:57:19 [INFO]: Epoch 023 - training loss: 0.4899, validation loss: 0.6067
2024-06-03 15:57:24 [INFO]: Epoch 024 - training loss: 0.4837, validation loss: 0.6017
2024-06-03 15:57:29 [INFO]: Epoch 025 - training loss: 0.4823, validation loss: 0.6081
2024-06-03 15:57:34 [INFO]: Epoch 026 - training loss: 0.4795, validation loss: 0.6094
2024-06-03 15:57:38 [INFO]: Epoch 027 - training loss: 0.4778, validation loss: 0.5865
2024-06-03 15:57:43 [INFO]: Epoch 028 - training loss: 0.4735, validation loss: 0.6060
2024-06-03 15:57:48 [INFO]: Epoch 029 - training loss: 0.4706, validation loss: 0.6068
2024-06-03 15:57:53 [INFO]: Epoch 030 - training loss: 0.4693, validation loss: 0.5946
2024-06-03 15:57:58 [INFO]: Epoch 031 - training loss: 0.4667, validation loss: 0.5980
2024-06-03 15:58:03 [INFO]: Epoch 032 - training loss: 0.4659, validation loss: 0.6006
2024-06-03 15:58:07 [INFO]: Epoch 033 - training loss: 0.4631, validation loss: 0.5919
2024-06-03 15:58:12 [INFO]: Epoch 034 - training loss: 0.4625, validation loss: 0.5936
2024-06-03 15:58:17 [INFO]: Epoch 035 - training loss: 0.4599, validation loss: 0.5954
2024-06-03 15:58:22 [INFO]: Epoch 036 - training loss: 0.4585, validation loss: 0.5875
2024-06-03 15:58:27 [INFO]: Epoch 037 - training loss: 0.4548, validation loss: 0.5917
2024-06-03 15:58:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 15:58:27 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 15:58:29 [INFO]: Saved the model to results_block_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T155527/MICN.pypots
2024-06-03 15:58:30 [INFO]: Successfully saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_1/imputation.pkl
2024-06-03 15:58:30 [INFO]: Round1 - MICN on BeijingAir: MAE=0.4913, MSE=0.6258, MRE=0.6641
2024-06-03 15:58:30 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 15:58:30 [INFO]: Using the given device: cuda:0
2024-06-03 15:58:30 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T155830
2024-06-03 15:58:30 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T155830/tensorboard
2024-06-03 15:58:32 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 15:58:37 [INFO]: Epoch 001 - training loss: 0.8516, validation loss: 0.8513
2024-06-03 15:58:42 [INFO]: Epoch 002 - training loss: 0.6739, validation loss: 0.8394
2024-06-03 15:58:47 [INFO]: Epoch 003 - training loss: 0.6550, validation loss: 0.8040
2024-06-03 15:58:52 [INFO]: Epoch 004 - training loss: 0.6398, validation loss: 0.7603
2024-06-03 15:58:56 [INFO]: Epoch 005 - training loss: 0.6163, validation loss: 0.7603
2024-06-03 15:58:59 [INFO]: Epoch 006 - training loss: 0.5998, validation loss: 0.7294
2024-06-03 15:59:03 [INFO]: Epoch 007 - training loss: 0.5832, validation loss: 0.7075
2024-06-03 15:59:07 [INFO]: Epoch 008 - training loss: 0.5673, validation loss: 0.7035
2024-06-03 15:59:11 [INFO]: Epoch 009 - training loss: 0.5621, validation loss: 0.6791
2024-06-03 15:59:15 [INFO]: Epoch 010 - training loss: 0.5559, validation loss: 0.6751
2024-06-03 15:59:20 [INFO]: Epoch 011 - training loss: 0.5479, validation loss: 0.6853
2024-06-03 15:59:25 [INFO]: Epoch 012 - training loss: 0.5399, validation loss: 0.6643
2024-06-03 15:59:30 [INFO]: Epoch 013 - training loss: 0.5333, validation loss: 0.6549
2024-06-03 15:59:35 [INFO]: Epoch 014 - training loss: 0.5278, validation loss: 0.6407
2024-06-03 15:59:39 [INFO]: Epoch 015 - training loss: 0.5243, validation loss: 0.6430
2024-06-03 15:59:44 [INFO]: Epoch 016 - training loss: 0.5180, validation loss: 0.6538
2024-06-03 15:59:50 [INFO]: Epoch 017 - training loss: 0.5139, validation loss: 0.6534
2024-06-03 15:59:55 [INFO]: Epoch 018 - training loss: 0.5098, validation loss: 0.6431
2024-06-03 16:00:00 [INFO]: Epoch 019 - training loss: 0.5083, validation loss: 0.6491
2024-06-03 16:00:05 [INFO]: Epoch 020 - training loss: 0.5040, validation loss: 0.6363
2024-06-03 16:00:10 [INFO]: Epoch 021 - training loss: 0.4980, validation loss: 0.6255
2024-06-03 16:00:14 [INFO]: Epoch 022 - training loss: 0.4951, validation loss: 0.6226
2024-06-03 16:00:19 [INFO]: Epoch 023 - training loss: 0.4934, validation loss: 0.6348
2024-06-03 16:00:24 [INFO]: Epoch 024 - training loss: 0.4909, validation loss: 0.6237
2024-06-03 16:00:29 [INFO]: Epoch 025 - training loss: 0.4880, validation loss: 0.6230
2024-06-03 16:00:33 [INFO]: Epoch 026 - training loss: 0.4847, validation loss: 0.6375
2024-06-03 16:00:38 [INFO]: Epoch 027 - training loss: 0.4804, validation loss: 0.6132
2024-06-03 16:00:43 [INFO]: Epoch 028 - training loss: 0.4799, validation loss: 0.6396
2024-06-03 16:00:47 [INFO]: Epoch 029 - training loss: 0.4794, validation loss: 0.6123
2024-06-03 16:00:52 [INFO]: Epoch 030 - training loss: 0.4741, validation loss: 0.6192
2024-06-03 16:00:57 [INFO]: Epoch 031 - training loss: 0.4739, validation loss: 0.6216
2024-06-03 16:01:01 [INFO]: Epoch 032 - training loss: 0.4712, validation loss: 0.6211
2024-06-03 16:01:05 [INFO]: Epoch 033 - training loss: 0.4683, validation loss: 0.6186
2024-06-03 16:01:10 [INFO]: Epoch 034 - training loss: 0.4648, validation loss: 0.6206
2024-06-03 16:01:14 [INFO]: Epoch 035 - training loss: 0.4650, validation loss: 0.6177
2024-06-03 16:01:19 [INFO]: Epoch 036 - training loss: 0.4625, validation loss: 0.6113
2024-06-03 16:01:23 [INFO]: Epoch 037 - training loss: 0.4633, validation loss: 0.6245
2024-06-03 16:01:28 [INFO]: Epoch 038 - training loss: 0.4605, validation loss: 0.6179
2024-06-03 16:01:32 [INFO]: Epoch 039 - training loss: 0.4589, validation loss: 0.6044
2024-06-03 16:01:35 [INFO]: Epoch 040 - training loss: 0.4544, validation loss: 0.6084
2024-06-03 16:01:39 [INFO]: Epoch 041 - training loss: 0.4533, validation loss: 0.6230
2024-06-03 16:01:43 [INFO]: Epoch 042 - training loss: 0.4548, validation loss: 0.6028
2024-06-03 16:01:47 [INFO]: Epoch 043 - training loss: 0.4500, validation loss: 0.6045
2024-06-03 16:01:50 [INFO]: Epoch 044 - training loss: 0.4528, validation loss: 0.6143
2024-06-03 16:01:54 [INFO]: Epoch 045 - training loss: 0.4490, validation loss: 0.6046
2024-06-03 16:01:58 [INFO]: Epoch 046 - training loss: 0.4470, validation loss: 0.5984
2024-06-03 16:02:02 [INFO]: Epoch 047 - training loss: 0.4466, validation loss: 0.6063
2024-06-03 16:02:05 [INFO]: Epoch 048 - training loss: 0.4446, validation loss: 0.5847
2024-06-03 16:02:08 [INFO]: Epoch 049 - training loss: 0.4425, validation loss: 0.6011
2024-06-03 16:02:11 [INFO]: Epoch 050 - training loss: 0.4443, validation loss: 0.6056
2024-06-03 16:02:14 [INFO]: Epoch 051 - training loss: 0.4406, validation loss: 0.5944
2024-06-03 16:02:17 [INFO]: Epoch 052 - training loss: 0.4401, validation loss: 0.5959
2024-06-03 16:02:20 [INFO]: Epoch 053 - training loss: 0.4398, validation loss: 0.5969
2024-06-03 16:02:23 [INFO]: Epoch 054 - training loss: 0.4389, validation loss: 0.5922
2024-06-03 16:02:26 [INFO]: Epoch 055 - training loss: 0.4375, validation loss: 0.6038
2024-06-03 16:02:29 [INFO]: Epoch 056 - training loss: 0.4372, validation loss: 0.5916
2024-06-03 16:02:32 [INFO]: Epoch 057 - training loss: 0.4332, validation loss: 0.5964
2024-06-03 16:02:35 [INFO]: Epoch 058 - training loss: 0.4335, validation loss: 0.6090
2024-06-03 16:02:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 16:02:35 [INFO]: Finished training. The best model is from epoch#48.
2024-06-03 16:02:36 [INFO]: Saved the model to results_block_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T155830/MICN.pypots
2024-06-03 16:02:37 [INFO]: Successfully saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_2/imputation.pkl
2024-06-03 16:02:37 [INFO]: Round2 - MICN on BeijingAir: MAE=0.4971, MSE=0.6434, MRE=0.6720
2024-06-03 16:02:37 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 16:02:37 [INFO]: Using the given device: cuda:0
2024-06-03 16:02:37 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T160237
2024-06-03 16:02:37 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T160237/tensorboard
2024-06-03 16:02:39 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 16:02:42 [INFO]: Epoch 001 - training loss: 0.8463, validation loss: 0.8680
2024-06-03 16:02:45 [INFO]: Epoch 002 - training loss: 0.6808, validation loss: 0.8403
2024-06-03 16:02:48 [INFO]: Epoch 003 - training loss: 0.6624, validation loss: 0.8069
2024-06-03 16:02:51 [INFO]: Epoch 004 - training loss: 0.6421, validation loss: 0.7778
2024-06-03 16:02:54 [INFO]: Epoch 005 - training loss: 0.6185, validation loss: 0.7581
2024-06-03 16:02:57 [INFO]: Epoch 006 - training loss: 0.6031, validation loss: 0.7419
2024-06-03 16:03:00 [INFO]: Epoch 007 - training loss: 0.5914, validation loss: 0.7174
2024-06-03 16:03:03 [INFO]: Epoch 008 - training loss: 0.5758, validation loss: 0.7033
2024-06-03 16:03:05 [INFO]: Epoch 009 - training loss: 0.5699, validation loss: 0.6976
2024-06-03 16:03:09 [INFO]: Epoch 010 - training loss: 0.5606, validation loss: 0.6822
2024-06-03 16:03:12 [INFO]: Epoch 011 - training loss: 0.5477, validation loss: 0.6700
2024-06-03 16:03:15 [INFO]: Epoch 012 - training loss: 0.5452, validation loss: 0.6733
2024-06-03 16:03:18 [INFO]: Epoch 013 - training loss: 0.5378, validation loss: 0.6709
2024-06-03 16:03:21 [INFO]: Epoch 014 - training loss: 0.5295, validation loss: 0.6562
2024-06-03 16:03:24 [INFO]: Epoch 015 - training loss: 0.5277, validation loss: 0.6599
2024-06-03 16:03:27 [INFO]: Epoch 016 - training loss: 0.5178, validation loss: 0.6574
2024-06-03 16:03:30 [INFO]: Epoch 017 - training loss: 0.5149, validation loss: 0.6559
2024-06-03 16:03:33 [INFO]: Epoch 018 - training loss: 0.5091, validation loss: 0.6606
2024-06-03 16:03:36 [INFO]: Epoch 019 - training loss: 0.5059, validation loss: 0.6568
2024-06-03 16:03:39 [INFO]: Epoch 020 - training loss: 0.5075, validation loss: 0.6229
2024-06-03 16:03:42 [INFO]: Epoch 021 - training loss: 0.5009, validation loss: 0.6441
2024-06-03 16:03:45 [INFO]: Epoch 022 - training loss: 0.4967, validation loss: 0.6328
2024-06-03 16:03:48 [INFO]: Epoch 023 - training loss: 0.4908, validation loss: 0.6335
2024-06-03 16:03:51 [INFO]: Epoch 024 - training loss: 0.4858, validation loss: 0.6352
2024-06-03 16:03:54 [INFO]: Epoch 025 - training loss: 0.4837, validation loss: 0.6318
2024-06-03 16:03:57 [INFO]: Epoch 026 - training loss: 0.4804, validation loss: 0.6265
2024-06-03 16:04:00 [INFO]: Epoch 027 - training loss: 0.4822, validation loss: 0.6504
2024-06-03 16:04:02 [INFO]: Epoch 028 - training loss: 0.4773, validation loss: 0.6305
2024-06-03 16:04:04 [INFO]: Epoch 029 - training loss: 0.4745, validation loss: 0.6118
2024-06-03 16:04:07 [INFO]: Epoch 030 - training loss: 0.4684, validation loss: 0.6204
2024-06-03 16:04:09 [INFO]: Epoch 031 - training loss: 0.4721, validation loss: 0.6104
2024-06-03 16:04:12 [INFO]: Epoch 032 - training loss: 0.4691, validation loss: 0.6040
2024-06-03 16:04:14 [INFO]: Epoch 033 - training loss: 0.4681, validation loss: 0.6167
2024-06-03 16:04:16 [INFO]: Epoch 034 - training loss: 0.4640, validation loss: 0.6148
2024-06-03 16:04:19 [INFO]: Epoch 035 - training loss: 0.4631, validation loss: 0.6222
2024-06-03 16:04:22 [INFO]: Epoch 036 - training loss: 0.4576, validation loss: 0.6135
2024-06-03 16:04:24 [INFO]: Epoch 037 - training loss: 0.4577, validation loss: 0.6179
2024-06-03 16:04:26 [INFO]: Epoch 038 - training loss: 0.4581, validation loss: 0.6029
2024-06-03 16:04:29 [INFO]: Epoch 039 - training loss: 0.4544, validation loss: 0.6192
2024-06-03 16:04:31 [INFO]: Epoch 040 - training loss: 0.4525, validation loss: 0.6015
2024-06-03 16:04:34 [INFO]: Epoch 041 - training loss: 0.4537, validation loss: 0.6054
2024-06-03 16:04:36 [INFO]: Epoch 042 - training loss: 0.4505, validation loss: 0.6086
2024-06-03 16:04:39 [INFO]: Epoch 043 - training loss: 0.4478, validation loss: 0.6026
2024-06-03 16:04:41 [INFO]: Epoch 044 - training loss: 0.4470, validation loss: 0.6085
2024-06-03 16:04:44 [INFO]: Epoch 045 - training loss: 0.4480, validation loss: 0.6000
2024-06-03 16:04:46 [INFO]: Epoch 046 - training loss: 0.4442, validation loss: 0.6135
2024-06-03 16:04:48 [INFO]: Epoch 047 - training loss: 0.4447, validation loss: 0.6058
2024-06-03 16:04:51 [INFO]: Epoch 048 - training loss: 0.4415, validation loss: 0.6087
2024-06-03 16:04:53 [INFO]: Epoch 049 - training loss: 0.4426, validation loss: 0.6007
2024-06-03 16:04:56 [INFO]: Epoch 050 - training loss: 0.4402, validation loss: 0.6078
2024-06-03 16:04:58 [INFO]: Epoch 051 - training loss: 0.4379, validation loss: 0.5967
2024-06-03 16:05:01 [INFO]: Epoch 052 - training loss: 0.4388, validation loss: 0.5918
2024-06-03 16:05:03 [INFO]: Epoch 053 - training loss: 0.4359, validation loss: 0.5975
2024-06-03 16:05:06 [INFO]: Epoch 054 - training loss: 0.4344, validation loss: 0.5907
2024-06-03 16:05:08 [INFO]: Epoch 055 - training loss: 0.4345, validation loss: 0.5888
2024-06-03 16:05:11 [INFO]: Epoch 056 - training loss: 0.4344, validation loss: 0.5887
2024-06-03 16:05:13 [INFO]: Epoch 057 - training loss: 0.4339, validation loss: 0.5932
2024-06-03 16:05:15 [INFO]: Epoch 058 - training loss: 0.4336, validation loss: 0.5937
2024-06-03 16:05:18 [INFO]: Epoch 059 - training loss: 0.4308, validation loss: 0.5885
2024-06-03 16:05:20 [INFO]: Epoch 060 - training loss: 0.4294, validation loss: 0.5874
2024-06-03 16:05:23 [INFO]: Epoch 061 - training loss: 0.4282, validation loss: 0.5924
2024-06-03 16:05:26 [INFO]: Epoch 062 - training loss: 0.4279, validation loss: 0.5828
2024-06-03 16:05:28 [INFO]: Epoch 063 - training loss: 0.4277, validation loss: 0.5924
2024-06-03 16:05:31 [INFO]: Epoch 064 - training loss: 0.4251, validation loss: 0.5804
2024-06-03 16:05:33 [INFO]: Epoch 065 - training loss: 0.4246, validation loss: 0.5928
2024-06-03 16:05:35 [INFO]: Epoch 066 - training loss: 0.4242, validation loss: 0.5877
2024-06-03 16:05:38 [INFO]: Epoch 067 - training loss: 0.4215, validation loss: 0.5825
2024-06-03 16:05:40 [INFO]: Epoch 068 - training loss: 0.4229, validation loss: 0.5833
2024-06-03 16:05:43 [INFO]: Epoch 069 - training loss: 0.4204, validation loss: 0.5792
2024-06-03 16:05:45 [INFO]: Epoch 070 - training loss: 0.4213, validation loss: 0.5780
2024-06-03 16:05:48 [INFO]: Epoch 071 - training loss: 0.4193, validation loss: 0.5778
2024-06-03 16:05:50 [INFO]: Epoch 072 - training loss: 0.4195, validation loss: 0.5761
2024-06-03 16:05:53 [INFO]: Epoch 073 - training loss: 0.4171, validation loss: 0.5830
2024-06-03 16:05:55 [INFO]: Epoch 074 - training loss: 0.4157, validation loss: 0.5805
2024-06-03 16:05:57 [INFO]: Epoch 075 - training loss: 0.4161, validation loss: 0.5766
2024-06-03 16:06:00 [INFO]: Epoch 076 - training loss: 0.4139, validation loss: 0.5739
2024-06-03 16:06:02 [INFO]: Epoch 077 - training loss: 0.4132, validation loss: 0.5813
2024-06-03 16:06:05 [INFO]: Epoch 078 - training loss: 0.4110, validation loss: 0.5723
2024-06-03 16:06:08 [INFO]: Epoch 079 - training loss: 0.4115, validation loss: 0.5751
2024-06-03 16:06:10 [INFO]: Epoch 080 - training loss: 0.4109, validation loss: 0.5807
2024-06-03 16:06:12 [INFO]: Epoch 081 - training loss: 0.4090, validation loss: 0.5761
2024-06-03 16:06:13 [INFO]: Epoch 082 - training loss: 0.4080, validation loss: 0.5798
2024-06-03 16:06:15 [INFO]: Epoch 083 - training loss: 0.4073, validation loss: 0.5815
2024-06-03 16:06:17 [INFO]: Epoch 084 - training loss: 0.4068, validation loss: 0.5740
2024-06-03 16:06:19 [INFO]: Epoch 085 - training loss: 0.4070, validation loss: 0.5651
2024-06-03 16:06:20 [INFO]: Epoch 086 - training loss: 0.4068, validation loss: 0.5778
2024-06-03 16:06:22 [INFO]: Epoch 087 - training loss: 0.4035, validation loss: 0.5805
2024-06-03 16:06:25 [INFO]: Epoch 088 - training loss: 0.4040, validation loss: 0.5806
2024-06-03 16:06:27 [INFO]: Epoch 089 - training loss: 0.4035, validation loss: 0.5770
2024-06-03 16:06:29 [INFO]: Epoch 090 - training loss: 0.4025, validation loss: 0.5716
2024-06-03 16:06:31 [INFO]: Epoch 091 - training loss: 0.3999, validation loss: 0.5689
2024-06-03 16:06:33 [INFO]: Epoch 092 - training loss: 0.4018, validation loss: 0.5737
2024-06-03 16:06:35 [INFO]: Epoch 093 - training loss: 0.4010, validation loss: 0.5777
2024-06-03 16:06:38 [INFO]: Epoch 094 - training loss: 0.3985, validation loss: 0.5853
2024-06-03 16:06:40 [INFO]: Epoch 095 - training loss: 0.4004, validation loss: 0.5682
2024-06-03 16:06:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 16:06:40 [INFO]: Finished training. The best model is from epoch#85.
2024-06-03 16:06:40 [INFO]: Saved the model to results_block_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T160237/MICN.pypots
2024-06-03 16:06:41 [INFO]: Successfully saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_3/imputation.pkl
2024-06-03 16:06:41 [INFO]: Round3 - MICN on BeijingAir: MAE=0.4788, MSE=0.6045, MRE=0.6473
2024-06-03 16:06:41 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 16:06:41 [INFO]: Using the given device: cuda:0
2024-06-03 16:06:41 [INFO]: Model files will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T160641
2024-06-03 16:06:41 [INFO]: Tensorboard file will be saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T160641/tensorboard
2024-06-03 16:06:42 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 16:06:44 [INFO]: Epoch 001 - training loss: 0.8710, validation loss: 0.8291
2024-06-03 16:06:45 [INFO]: Epoch 002 - training loss: 0.6957, validation loss: 0.7996
2024-06-03 16:06:47 [INFO]: Epoch 003 - training loss: 0.6757, validation loss: 0.7738
2024-06-03 16:06:49 [INFO]: Epoch 004 - training loss: 0.6476, validation loss: 0.7401
2024-06-03 16:06:50 [INFO]: Epoch 005 - training loss: 0.6177, validation loss: 0.7065
2024-06-03 16:06:52 [INFO]: Epoch 006 - training loss: 0.6059, validation loss: 0.6847
2024-06-03 16:06:53 [INFO]: Epoch 007 - training loss: 0.5928, validation loss: 0.6843
2024-06-03 16:06:55 [INFO]: Epoch 008 - training loss: 0.5804, validation loss: 0.6533
2024-06-03 16:06:57 [INFO]: Epoch 009 - training loss: 0.5707, validation loss: 0.6308
2024-06-03 16:06:58 [INFO]: Epoch 010 - training loss: 0.5603, validation loss: 0.6373
2024-06-03 16:07:00 [INFO]: Epoch 011 - training loss: 0.5506, validation loss: 0.6381
2024-06-03 16:07:02 [INFO]: Epoch 012 - training loss: 0.5449, validation loss: 0.6472
2024-06-03 16:07:04 [INFO]: Epoch 013 - training loss: 0.5370, validation loss: 0.6315
2024-06-03 16:07:05 [INFO]: Epoch 014 - training loss: 0.5350, validation loss: 0.6231
2024-06-03 16:07:07 [INFO]: Epoch 015 - training loss: 0.5231, validation loss: 0.6066
2024-06-03 16:07:08 [INFO]: Epoch 016 - training loss: 0.5195, validation loss: 0.6183
2024-06-03 16:07:10 [INFO]: Epoch 017 - training loss: 0.5144, validation loss: 0.6113
2024-06-03 16:07:11 [INFO]: Epoch 018 - training loss: 0.5113, validation loss: 0.6005
2024-06-03 16:07:13 [INFO]: Epoch 019 - training loss: 0.5073, validation loss: 0.6028
2024-06-03 16:07:15 [INFO]: Epoch 020 - training loss: 0.5025, validation loss: 0.5990
2024-06-03 16:07:17 [INFO]: Epoch 021 - training loss: 0.4993, validation loss: 0.6083
2024-06-03 16:07:18 [INFO]: Epoch 022 - training loss: 0.4935, validation loss: 0.6006
2024-06-03 16:07:20 [INFO]: Epoch 023 - training loss: 0.4918, validation loss: 0.6111
2024-06-03 16:07:21 [INFO]: Epoch 024 - training loss: 0.4901, validation loss: 0.6009
2024-06-03 16:07:23 [INFO]: Epoch 025 - training loss: 0.4851, validation loss: 0.5895
2024-06-03 16:07:25 [INFO]: Epoch 026 - training loss: 0.4818, validation loss: 0.6027
2024-06-03 16:07:26 [INFO]: Epoch 027 - training loss: 0.4816, validation loss: 0.5893
2024-06-03 16:07:28 [INFO]: Epoch 028 - training loss: 0.4796, validation loss: 0.5986
2024-06-03 16:07:30 [INFO]: Epoch 029 - training loss: 0.4758, validation loss: 0.6167
2024-06-03 16:07:31 [INFO]: Epoch 030 - training loss: 0.4715, validation loss: 0.5983
2024-06-03 16:07:33 [INFO]: Epoch 031 - training loss: 0.4697, validation loss: 0.5990
2024-06-03 16:07:35 [INFO]: Epoch 032 - training loss: 0.4657, validation loss: 0.5861
2024-06-03 16:07:36 [INFO]: Epoch 033 - training loss: 0.4666, validation loss: 0.5993
2024-06-03 16:07:38 [INFO]: Epoch 034 - training loss: 0.4664, validation loss: 0.5839
2024-06-03 16:07:39 [INFO]: Epoch 035 - training loss: 0.4632, validation loss: 0.5988
2024-06-03 16:07:41 [INFO]: Epoch 036 - training loss: 0.4596, validation loss: 0.5951
2024-06-03 16:07:42 [INFO]: Epoch 037 - training loss: 0.4582, validation loss: 0.5958
2024-06-03 16:07:44 [INFO]: Epoch 038 - training loss: 0.4581, validation loss: 0.5903
2024-06-03 16:07:46 [INFO]: Epoch 039 - training loss: 0.4577, validation loss: 0.5899
2024-06-03 16:07:47 [INFO]: Epoch 040 - training loss: 0.4539, validation loss: 0.5976
2024-06-03 16:07:49 [INFO]: Epoch 041 - training loss: 0.4514, validation loss: 0.5874
2024-06-03 16:07:50 [INFO]: Epoch 042 - training loss: 0.4470, validation loss: 0.6032
2024-06-03 16:07:52 [INFO]: Epoch 043 - training loss: 0.4498, validation loss: 0.5932
2024-06-03 16:07:54 [INFO]: Epoch 044 - training loss: 0.4467, validation loss: 0.5882
2024-06-03 16:07:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 16:07:54 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 16:07:54 [INFO]: Saved the model to results_block_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T160641/MICN.pypots
2024-06-03 16:07:55 [INFO]: Successfully saved to results_block_rate05/BeijingAir/MICN_BeijingAir/round_4/imputation.pkl
2024-06-03 16:07:55 [INFO]: Round4 - MICN on BeijingAir: MAE=0.4826, MSE=0.6172, MRE=0.6523
2024-06-03 16:07:55 [INFO]: Done! Final results:
Averaged MICN (57,048,200 params) on BeijingAir: MAE=0.4917 ± 0.0070026687470611144, MSE=0.6318 ± 0.013910192273748678, MRE=0.6472 ± 0.00921741984285252, average inference time=0.18