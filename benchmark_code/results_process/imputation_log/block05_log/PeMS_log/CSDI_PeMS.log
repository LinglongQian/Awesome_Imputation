2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:55 [INFO]: Model files will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_0/20240603_T100955
2024-06-03 10:09:55 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_0/20240603_T100955/tensorboard
2024-06-03 10:09:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-03 10:11:57 [INFO]: Epoch 001 - training loss: 0.7291, validation loss: 0.4395
2024-06-03 10:13:36 [INFO]: Epoch 002 - training loss: 0.4030, validation loss: 0.4196
2024-06-03 10:15:15 [INFO]: Epoch 003 - training loss: 0.3521, validation loss: 0.3726
2024-06-03 10:16:51 [INFO]: Epoch 004 - training loss: 0.3053, validation loss: 0.3620
2024-06-03 10:18:31 [INFO]: Epoch 005 - training loss: 0.3020, validation loss: 0.3512
2024-06-03 10:20:10 [INFO]: Epoch 006 - training loss: 0.3281, validation loss: 0.3380
2024-06-03 10:21:48 [INFO]: Epoch 007 - training loss: 0.2471, validation loss: 0.3262
2024-06-03 10:23:28 [INFO]: Epoch 008 - training loss: 0.2746, validation loss: 0.3319
2024-06-03 10:25:05 [INFO]: Epoch 009 - training loss: 0.2673, validation loss: 0.3216
2024-06-03 10:26:44 [INFO]: Epoch 010 - training loss: 0.2429, validation loss: 0.3182
2024-06-03 10:28:22 [INFO]: Epoch 011 - training loss: 0.2442, validation loss: 0.3179
2024-06-03 10:29:59 [INFO]: Epoch 012 - training loss: 0.2278, validation loss: 0.3025
2024-06-03 10:31:36 [INFO]: Epoch 013 - training loss: 0.2249, validation loss: 0.2971
2024-06-03 10:33:12 [INFO]: Epoch 014 - training loss: 0.2080, validation loss: 0.2996
2024-06-03 10:34:49 [INFO]: Epoch 015 - training loss: 0.2311, validation loss: 0.2894
2024-06-03 10:36:28 [INFO]: Epoch 016 - training loss: 0.1996, validation loss: 0.3190
2024-06-03 10:38:08 [INFO]: Epoch 017 - training loss: 0.1712, validation loss: 0.3020
2024-06-03 10:39:47 [INFO]: Epoch 018 - training loss: 0.1699, validation loss: 0.2916
2024-06-03 10:41:26 [INFO]: Epoch 019 - training loss: 0.1882, validation loss: 0.2891
2024-06-03 10:43:07 [INFO]: Epoch 020 - training loss: 0.1756, validation loss: 0.2670
2024-06-03 10:44:48 [INFO]: Epoch 021 - training loss: 0.1769, validation loss: 0.2471
2024-06-03 10:46:24 [INFO]: Epoch 022 - training loss: 0.2045, validation loss: 0.2578
2024-06-03 10:48:00 [INFO]: Epoch 023 - training loss: 0.2061, validation loss: 0.2689
2024-06-03 10:49:38 [INFO]: Epoch 024 - training loss: 0.1664, validation loss: 0.2705
2024-06-03 10:51:15 [INFO]: Epoch 025 - training loss: 0.1833, validation loss: 0.2911
2024-06-03 10:52:53 [INFO]: Epoch 026 - training loss: 0.1673, validation loss: 0.2447
2024-06-03 10:54:30 [INFO]: Epoch 027 - training loss: 0.1646, validation loss: 0.2469
2024-06-03 10:56:02 [INFO]: Epoch 028 - training loss: 0.1619, validation loss: 0.2562
2024-06-03 10:57:36 [INFO]: Epoch 029 - training loss: 0.1677, validation loss: 0.2499
2024-06-03 10:59:10 [INFO]: Epoch 030 - training loss: 0.1598, validation loss: 0.2422
2024-06-03 11:00:34 [INFO]: Epoch 031 - training loss: 0.1800, validation loss: 0.2661
2024-06-03 11:01:53 [INFO]: Epoch 032 - training loss: 0.1527, validation loss: 0.2559
2024-06-03 11:03:10 [INFO]: Epoch 033 - training loss: 0.1816, validation loss: 0.2391
2024-06-03 11:04:29 [INFO]: Epoch 034 - training loss: 0.1916, validation loss: 0.2177
2024-06-03 11:05:46 [INFO]: Epoch 035 - training loss: 0.1812, validation loss: 0.2197
2024-06-03 11:07:03 [INFO]: Epoch 036 - training loss: 0.1423, validation loss: 0.2235
2024-06-03 11:08:20 [INFO]: Epoch 037 - training loss: 0.1720, validation loss: 0.2355
2024-06-03 11:09:38 [INFO]: Epoch 038 - training loss: 0.1540, validation loss: 0.2217
2024-06-03 11:10:57 [INFO]: Epoch 039 - training loss: 0.1677, validation loss: 0.2309
2024-06-03 11:12:15 [INFO]: Epoch 040 - training loss: 0.1798, validation loss: 0.2413
2024-06-03 11:13:33 [INFO]: Epoch 041 - training loss: 0.1829, validation loss: 0.2115
2024-06-03 11:14:51 [INFO]: Epoch 042 - training loss: 0.1636, validation loss: 0.2300
2024-06-03 11:16:09 [INFO]: Epoch 043 - training loss: 0.1794, validation loss: 0.2418
2024-06-03 11:17:27 [INFO]: Epoch 044 - training loss: 0.1629, validation loss: 0.2622
2024-06-03 11:18:45 [INFO]: Epoch 045 - training loss: 0.1518, validation loss: 0.2225
2024-06-03 11:20:02 [INFO]: Epoch 046 - training loss: 0.1967, validation loss: 0.2110
2024-06-03 11:21:20 [INFO]: Epoch 047 - training loss: 0.1388, validation loss: 0.2223
2024-06-03 11:22:38 [INFO]: Epoch 048 - training loss: 0.1585, validation loss: 0.2119
2024-06-03 11:23:42 [INFO]: Epoch 049 - training loss: 0.1948, validation loss: 0.2331
2024-06-03 11:24:47 [INFO]: Epoch 050 - training loss: 0.1292, validation loss: 0.2462
2024-06-03 11:25:52 [INFO]: Epoch 051 - training loss: 0.1666, validation loss: 0.2190
2024-06-03 11:26:57 [INFO]: Epoch 052 - training loss: 0.1704, validation loss: 0.2118
2024-06-03 11:28:02 [INFO]: Epoch 053 - training loss: 0.1609, validation loss: 0.2123
2024-06-03 11:29:07 [INFO]: Epoch 054 - training loss: 0.1331, validation loss: 0.2083
2024-06-03 11:30:12 [INFO]: Epoch 055 - training loss: 0.1651, validation loss: 0.2018
2024-06-03 11:31:19 [INFO]: Epoch 056 - training loss: 0.1535, validation loss: 0.2121
2024-06-03 11:32:26 [INFO]: Epoch 057 - training loss: 0.1506, validation loss: 0.1993
2024-06-03 11:33:33 [INFO]: Epoch 058 - training loss: 0.1492, validation loss: 0.2123
2024-06-03 11:34:37 [INFO]: Epoch 059 - training loss: 0.1603, validation loss: 0.2234
2024-06-03 11:35:39 [INFO]: Epoch 060 - training loss: 0.1439, validation loss: 0.1997
2024-06-03 11:36:41 [INFO]: Epoch 061 - training loss: 0.1525, validation loss: 0.1952
2024-06-03 11:37:42 [INFO]: Epoch 062 - training loss: 0.1377, validation loss: 0.1925
2024-06-03 11:38:45 [INFO]: Epoch 063 - training loss: 0.1329, validation loss: 0.1917
2024-06-03 11:39:47 [INFO]: Epoch 064 - training loss: 0.1671, validation loss: 0.1984
2024-06-03 11:40:50 [INFO]: Epoch 065 - training loss: 0.1534, validation loss: 0.2014
2024-06-03 11:41:53 [INFO]: Epoch 066 - training loss: 0.1339, validation loss: 0.2056
2024-06-03 11:42:56 [INFO]: Epoch 067 - training loss: 0.1429, validation loss: 0.1999
2024-06-03 11:43:59 [INFO]: Epoch 068 - training loss: 0.1504, validation loss: 0.1976
2024-06-03 11:45:02 [INFO]: Epoch 069 - training loss: 0.1466, validation loss: 0.1999
2024-06-03 11:46:05 [INFO]: Epoch 070 - training loss: 0.1463, validation loss: 0.1992
2024-06-03 11:47:08 [INFO]: Epoch 071 - training loss: 0.1259, validation loss: 0.1977
2024-06-03 11:48:04 [INFO]: Epoch 072 - training loss: 0.1455, validation loss: 0.1949
2024-06-03 11:48:47 [INFO]: Epoch 073 - training loss: 0.1339, validation loss: 0.1975
2024-06-03 11:48:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:48:47 [INFO]: Finished training. The best model is from epoch#63.
2024-06-03 11:48:47 [INFO]: Saved the model to results_block_rate05/PeMS/CSDI_PeMS/round_0/20240603_T100955/CSDI.pypots
2024-06-03 12:22:55 [INFO]: Successfully saved to results_block_rate05/PeMS/CSDI_PeMS/round_0/imputation.pkl
2024-06-03 12:22:55 [INFO]: Round0 - CSDI on PeMS: MAE=0.3479, MSE=0.9764, MRE=0.4165
2024-06-03 12:22:55 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:22:55 [INFO]: Using the given device: cuda:0
2024-06-03 12:22:55 [INFO]: Model files will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_1/20240603_T122255
2024-06-03 12:22:55 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_1/20240603_T122255/tensorboard
2024-06-03 12:22:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-03 12:23:38 [INFO]: Epoch 001 - training loss: 0.6889, validation loss: 0.5321
2024-06-03 12:24:22 [INFO]: Epoch 002 - training loss: 0.3903, validation loss: 0.3910
2024-06-03 12:25:04 [INFO]: Epoch 003 - training loss: 0.3170, validation loss: 0.3481
2024-06-03 12:25:47 [INFO]: Epoch 004 - training loss: 0.3016, validation loss: 0.3428
2024-06-03 12:26:30 [INFO]: Epoch 005 - training loss: 0.2960, validation loss: 0.3767
2024-06-03 12:27:12 [INFO]: Epoch 006 - training loss: 0.2734, validation loss: 0.3713
2024-06-03 12:27:55 [INFO]: Epoch 007 - training loss: 0.2852, validation loss: 0.3548
2024-06-03 12:28:37 [INFO]: Epoch 008 - training loss: 0.2647, validation loss: 0.3125
2024-06-03 12:29:20 [INFO]: Epoch 009 - training loss: 0.2735, validation loss: 0.3531
2024-06-03 12:30:03 [INFO]: Epoch 010 - training loss: 0.2425, validation loss: 0.3207
2024-06-03 12:30:45 [INFO]: Epoch 011 - training loss: 0.2015, validation loss: 0.3349
2024-06-03 12:31:27 [INFO]: Epoch 012 - training loss: 0.2328, validation loss: 0.3127
2024-06-03 12:32:11 [INFO]: Epoch 013 - training loss: 0.2124, validation loss: 0.3297
2024-06-03 12:32:53 [INFO]: Epoch 014 - training loss: 0.2323, validation loss: 0.3047
2024-06-03 12:33:36 [INFO]: Epoch 015 - training loss: 0.1965, validation loss: 0.2752
2024-06-03 12:34:19 [INFO]: Epoch 016 - training loss: 0.1922, validation loss: 0.2708
2024-06-03 12:35:02 [INFO]: Epoch 017 - training loss: 0.1714, validation loss: 0.2586
2024-06-03 12:35:45 [INFO]: Epoch 018 - training loss: 0.1853, validation loss: 0.2566
2024-06-03 12:36:29 [INFO]: Epoch 019 - training loss: 0.1924, validation loss: 0.2488
2024-06-03 12:37:12 [INFO]: Epoch 020 - training loss: 0.1764, validation loss: 0.2504
2024-06-03 12:37:55 [INFO]: Epoch 021 - training loss: 0.2141, validation loss: 0.2974
2024-06-03 12:38:38 [INFO]: Epoch 022 - training loss: 0.1637, validation loss: 0.2960
2024-06-03 12:39:21 [INFO]: Epoch 023 - training loss: 0.2157, validation loss: 0.2552
2024-06-03 12:40:04 [INFO]: Epoch 024 - training loss: 0.1929, validation loss: 0.3064
2024-06-03 12:40:47 [INFO]: Epoch 025 - training loss: 0.2393, validation loss: 0.2697
2024-06-03 12:41:30 [INFO]: Epoch 026 - training loss: 0.2217, validation loss: 0.2668
2024-06-03 12:42:13 [INFO]: Epoch 027 - training loss: 0.1668, validation loss: 0.2556
2024-06-03 12:42:56 [INFO]: Epoch 028 - training loss: 0.1756, validation loss: 0.2534
2024-06-03 12:43:34 [INFO]: Epoch 029 - training loss: 0.1676, validation loss: 0.2835
2024-06-03 12:43:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:43:34 [INFO]: Finished training. The best model is from epoch#19.
2024-06-03 12:43:34 [INFO]: Saved the model to results_block_rate05/PeMS/CSDI_PeMS/round_1/20240603_T122255/CSDI.pypots
2024-06-03 13:09:51 [INFO]: Successfully saved to results_block_rate05/PeMS/CSDI_PeMS/round_1/imputation.pkl
2024-06-03 13:09:51 [INFO]: Round1 - CSDI on PeMS: MAE=3.7335, MSE=69.6730, MRE=4.4703
2024-06-03 13:09:51 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 13:09:51 [INFO]: Using the given device: cuda:0
2024-06-03 13:09:51 [INFO]: Model files will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_2/20240603_T130951
2024-06-03 13:09:51 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_2/20240603_T130951/tensorboard
2024-06-03 13:09:51 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-03 13:10:23 [INFO]: Epoch 001 - training loss: 0.8268, validation loss: 0.5283
2024-06-03 13:10:56 [INFO]: Epoch 002 - training loss: 0.4363, validation loss: 0.4237
2024-06-03 13:11:29 [INFO]: Epoch 003 - training loss: 0.3731, validation loss: 0.4025
2024-06-03 13:12:02 [INFO]: Epoch 004 - training loss: 0.3019, validation loss: 0.3543
2024-06-03 13:12:34 [INFO]: Epoch 005 - training loss: 0.3160, validation loss: 0.3439
2024-06-03 13:13:07 [INFO]: Epoch 006 - training loss: 0.2751, validation loss: 0.3185
2024-06-03 13:13:40 [INFO]: Epoch 007 - training loss: 0.2756, validation loss: 0.3358
2024-06-03 13:14:13 [INFO]: Epoch 008 - training loss: 0.2689, validation loss: 0.3252
2024-06-03 13:14:45 [INFO]: Epoch 009 - training loss: 0.2625, validation loss: 0.3061
2024-06-03 13:15:18 [INFO]: Epoch 010 - training loss: 0.2409, validation loss: 0.3004
2024-06-03 13:15:51 [INFO]: Epoch 011 - training loss: 0.2555, validation loss: 0.3183
2024-06-03 13:16:23 [INFO]: Epoch 012 - training loss: 0.2649, validation loss: 0.3042
2024-06-03 13:16:56 [INFO]: Epoch 013 - training loss: 0.2014, validation loss: 0.2850
2024-06-03 13:17:29 [INFO]: Epoch 014 - training loss: 0.2355, validation loss: 0.2743
2024-06-03 13:18:01 [INFO]: Epoch 015 - training loss: 0.2081, validation loss: 0.2910
2024-06-03 13:18:34 [INFO]: Epoch 016 - training loss: 0.2188, validation loss: 0.2939
2024-06-03 13:19:06 [INFO]: Epoch 017 - training loss: 0.1911, validation loss: 0.2706
2024-06-03 13:19:38 [INFO]: Epoch 018 - training loss: 0.1836, validation loss: 0.2721
2024-06-03 13:20:11 [INFO]: Epoch 019 - training loss: 0.1643, validation loss: 0.2580
2024-06-03 13:20:44 [INFO]: Epoch 020 - training loss: 0.1718, validation loss: 0.2683
2024-06-03 13:21:17 [INFO]: Epoch 021 - training loss: 0.1818, validation loss: 0.2733
2024-06-03 13:21:49 [INFO]: Epoch 022 - training loss: 0.1717, validation loss: 0.2519
2024-06-03 13:22:22 [INFO]: Epoch 023 - training loss: 0.1812, validation loss: 0.2447
2024-06-03 13:22:55 [INFO]: Epoch 024 - training loss: 0.2202, validation loss: 0.2469
2024-06-03 13:23:27 [INFO]: Epoch 025 - training loss: 0.1564, validation loss: 0.2415
2024-06-03 13:24:00 [INFO]: Epoch 026 - training loss: 0.1732, validation loss: 0.2564
2024-06-03 13:24:32 [INFO]: Epoch 027 - training loss: 0.1621, validation loss: 0.2513
2024-06-03 13:25:05 [INFO]: Epoch 028 - training loss: 0.1933, validation loss: 0.2561
2024-06-03 13:25:38 [INFO]: Epoch 029 - training loss: 0.2133, validation loss: 0.2613
2024-06-03 13:26:10 [INFO]: Epoch 030 - training loss: 0.2105, validation loss: 0.2322
2024-06-03 13:26:43 [INFO]: Epoch 031 - training loss: 0.1633, validation loss: 0.2550
2024-06-03 13:27:16 [INFO]: Epoch 032 - training loss: 0.1690, validation loss: 0.2572
2024-06-03 13:27:48 [INFO]: Epoch 033 - training loss: 0.1646, validation loss: 0.2563
2024-06-03 13:28:21 [INFO]: Epoch 034 - training loss: 0.1849, validation loss: 0.2539
2024-06-03 13:28:54 [INFO]: Epoch 035 - training loss: 0.1534, validation loss: 0.2382
2024-06-03 13:29:26 [INFO]: Epoch 036 - training loss: 0.1695, validation loss: 0.2420
2024-06-03 13:29:59 [INFO]: Epoch 037 - training loss: 0.1553, validation loss: 0.2497
2024-06-03 13:30:32 [INFO]: Epoch 038 - training loss: 0.1813, validation loss: 0.2201
2024-06-03 13:31:05 [INFO]: Epoch 039 - training loss: 0.1480, validation loss: 0.2189
2024-06-03 13:31:38 [INFO]: Epoch 040 - training loss: 0.1585, validation loss: 0.2355
2024-06-03 13:32:10 [INFO]: Epoch 041 - training loss: 0.1684, validation loss: 0.2226
2024-06-03 13:32:43 [INFO]: Epoch 042 - training loss: 0.1590, validation loss: 0.2093
2024-06-03 13:33:15 [INFO]: Epoch 043 - training loss: 0.1307, validation loss: 0.2288
2024-06-03 13:33:48 [INFO]: Epoch 044 - training loss: 0.1712, validation loss: 0.2123
2024-06-03 13:34:21 [INFO]: Epoch 045 - training loss: 0.1851, validation loss: 0.2140
2024-06-03 13:34:53 [INFO]: Epoch 046 - training loss: 0.1310, validation loss: 0.2113
2024-06-03 13:35:26 [INFO]: Epoch 047 - training loss: 0.1692, validation loss: 0.2036
2024-06-03 13:35:59 [INFO]: Epoch 048 - training loss: 0.1350, validation loss: 0.2026
2024-06-03 13:36:31 [INFO]: Epoch 049 - training loss: 0.1616, validation loss: 0.2207
2024-06-03 13:37:03 [INFO]: Epoch 050 - training loss: 0.1560, validation loss: 0.2045
2024-06-03 13:37:34 [INFO]: Epoch 051 - training loss: 0.1660, validation loss: 0.1965
2024-06-03 13:38:04 [INFO]: Epoch 052 - training loss: 0.1525, validation loss: 0.2021
2024-06-03 13:38:35 [INFO]: Epoch 053 - training loss: 0.1234, validation loss: 0.1977
2024-06-03 13:39:05 [INFO]: Epoch 054 - training loss: 0.1650, validation loss: 0.2120
2024-06-03 13:39:36 [INFO]: Epoch 055 - training loss: 0.1666, validation loss: 0.2039
2024-06-03 13:40:06 [INFO]: Epoch 056 - training loss: 0.1502, validation loss: 0.1943
2024-06-03 13:40:37 [INFO]: Epoch 057 - training loss: 0.1396, validation loss: 0.1940
2024-06-03 13:41:07 [INFO]: Epoch 058 - training loss: 0.1468, validation loss: 0.2033
2024-06-03 13:41:38 [INFO]: Epoch 059 - training loss: 0.1656, validation loss: 0.2061
2024-06-03 13:42:08 [INFO]: Epoch 060 - training loss: 0.1844, validation loss: 0.2015
2024-06-03 13:42:39 [INFO]: Epoch 061 - training loss: 0.1596, validation loss: 0.2020
2024-06-03 13:43:10 [INFO]: Epoch 062 - training loss: 0.1524, validation loss: 0.1977
2024-06-03 13:43:40 [INFO]: Epoch 063 - training loss: 0.1411, validation loss: 0.1949
2024-06-03 13:44:11 [INFO]: Epoch 064 - training loss: 0.1634, validation loss: 0.2065
2024-06-03 13:44:41 [INFO]: Epoch 065 - training loss: 0.1513, validation loss: 0.2142
2024-06-03 13:45:12 [INFO]: Epoch 066 - training loss: 0.1538, validation loss: 0.2097
2024-06-03 13:45:42 [INFO]: Epoch 067 - training loss: 0.1568, validation loss: 0.2354
2024-06-03 13:45:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:45:42 [INFO]: Finished training. The best model is from epoch#57.
2024-06-03 13:45:42 [INFO]: Saved the model to results_block_rate05/PeMS/CSDI_PeMS/round_2/20240603_T130951/CSDI.pypots
2024-06-03 14:10:25 [INFO]: Successfully saved to results_block_rate05/PeMS/CSDI_PeMS/round_2/imputation.pkl
2024-06-03 14:10:25 [INFO]: Round2 - CSDI on PeMS: MAE=0.8977, MSE=2.3152, MRE=1.0749
2024-06-03 14:10:25 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 14:10:25 [INFO]: Using the given device: cuda:0
2024-06-03 14:10:25 [INFO]: Model files will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_3/20240603_T141025
2024-06-03 14:10:25 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_3/20240603_T141025/tensorboard
2024-06-03 14:10:25 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-03 14:10:55 [INFO]: Epoch 001 - training loss: 0.6635, validation loss: 0.4354
2024-06-03 14:11:26 [INFO]: Epoch 002 - training loss: 0.3928, validation loss: 0.3906
2024-06-03 14:11:56 [INFO]: Epoch 003 - training loss: 0.3142, validation loss: 0.3488
2024-06-03 14:12:27 [INFO]: Epoch 004 - training loss: 0.3123, validation loss: 0.3376
2024-06-03 14:12:58 [INFO]: Epoch 005 - training loss: 0.2543, validation loss: 0.3393
2024-06-03 14:13:28 [INFO]: Epoch 006 - training loss: 0.2761, validation loss: 0.3221
2024-06-03 14:13:59 [INFO]: Epoch 007 - training loss: 0.2586, validation loss: 0.3168
2024-06-03 14:14:29 [INFO]: Epoch 008 - training loss: 0.2594, validation loss: 0.3214
2024-06-03 14:15:00 [INFO]: Epoch 009 - training loss: 0.2457, validation loss: 0.3217
2024-06-03 14:15:30 [INFO]: Epoch 010 - training loss: 0.2197, validation loss: 0.2998
2024-06-03 14:16:01 [INFO]: Epoch 011 - training loss: 0.2187, validation loss: 0.2967
2024-06-03 14:16:32 [INFO]: Epoch 012 - training loss: 0.2033, validation loss: 0.3033
2024-06-03 14:17:02 [INFO]: Epoch 013 - training loss: 0.1922, validation loss: 0.2759
2024-06-03 14:17:33 [INFO]: Epoch 014 - training loss: 0.1821, validation loss: 0.2924
2024-06-03 14:18:03 [INFO]: Epoch 015 - training loss: 0.1948, validation loss: 0.2714
2024-06-03 14:18:34 [INFO]: Epoch 016 - training loss: 0.1884, validation loss: 0.2770
2024-06-03 14:19:04 [INFO]: Epoch 017 - training loss: 0.2130, validation loss: 0.2780
2024-06-03 14:19:35 [INFO]: Epoch 018 - training loss: 0.2182, validation loss: 0.2895
2024-06-03 14:20:06 [INFO]: Epoch 019 - training loss: 0.1864, validation loss: 0.2554
2024-06-03 14:20:36 [INFO]: Epoch 020 - training loss: 0.1821, validation loss: 0.2500
2024-06-03 14:21:07 [INFO]: Epoch 021 - training loss: 0.1626, validation loss: 0.2619
2024-06-03 14:21:37 [INFO]: Epoch 022 - training loss: 0.1504, validation loss: 0.2529
2024-06-03 14:22:08 [INFO]: Epoch 023 - training loss: 0.1808, validation loss: 0.2429
2024-06-03 14:22:38 [INFO]: Epoch 024 - training loss: 0.1737, validation loss: 0.2680
2024-06-03 14:23:09 [INFO]: Epoch 025 - training loss: 0.1563, validation loss: 0.2672
2024-06-03 14:23:39 [INFO]: Epoch 026 - training loss: 0.1785, validation loss: 0.2355
2024-06-03 14:24:10 [INFO]: Epoch 027 - training loss: 0.1708, validation loss: 0.2420
2024-06-03 14:24:40 [INFO]: Epoch 028 - training loss: 0.1515, validation loss: 0.2436
2024-06-03 14:25:11 [INFO]: Epoch 029 - training loss: 0.1673, validation loss: 0.2315
2024-06-03 14:25:42 [INFO]: Epoch 030 - training loss: 0.1709, validation loss: 0.2253
2024-06-03 14:26:12 [INFO]: Epoch 031 - training loss: 0.1757, validation loss: 0.2192
2024-06-03 14:26:43 [INFO]: Epoch 032 - training loss: 0.1644, validation loss: 0.2167
2024-06-03 14:27:13 [INFO]: Epoch 033 - training loss: 0.1769, validation loss: 0.2164
2024-06-03 14:27:43 [INFO]: Epoch 034 - training loss: 0.1403, validation loss: 0.2225
2024-06-03 14:28:14 [INFO]: Epoch 035 - training loss: 0.1557, validation loss: 0.2254
2024-06-03 14:28:44 [INFO]: Epoch 036 - training loss: 0.2089, validation loss: 0.2254
2024-06-03 14:29:15 [INFO]: Epoch 037 - training loss: 0.1729, validation loss: 0.2238
2024-06-03 14:29:45 [INFO]: Epoch 038 - training loss: 0.1587, validation loss: 0.2077
2024-06-03 14:30:16 [INFO]: Epoch 039 - training loss: 0.1696, validation loss: 0.2097
2024-06-03 14:30:47 [INFO]: Epoch 040 - training loss: 0.1476, validation loss: 0.2183
2024-06-03 14:31:17 [INFO]: Epoch 041 - training loss: 0.1773, validation loss: 0.2105
2024-06-03 14:31:48 [INFO]: Epoch 042 - training loss: 0.1677, validation loss: 0.2111
2024-06-03 14:32:18 [INFO]: Epoch 043 - training loss: 0.1394, validation loss: 0.2075
2024-06-03 14:32:49 [INFO]: Epoch 044 - training loss: 0.1544, validation loss: 0.2064
2024-06-03 14:33:19 [INFO]: Epoch 045 - training loss: 0.1626, validation loss: 0.2084
2024-06-03 14:33:50 [INFO]: Epoch 046 - training loss: 0.1561, validation loss: 0.2050
2024-06-03 14:34:20 [INFO]: Epoch 047 - training loss: 0.1462, validation loss: 0.2051
2024-06-03 14:34:51 [INFO]: Epoch 048 - training loss: 0.1397, validation loss: 0.2037
2024-06-03 14:35:22 [INFO]: Epoch 049 - training loss: 0.1763, validation loss: 0.2048
2024-06-03 14:35:52 [INFO]: Epoch 050 - training loss: 0.1405, validation loss: 0.2082
2024-06-03 14:36:23 [INFO]: Epoch 051 - training loss: 0.1460, validation loss: 0.2019
2024-06-03 14:36:53 [INFO]: Epoch 052 - training loss: 0.1318, validation loss: 0.2010
2024-06-03 14:37:24 [INFO]: Epoch 053 - training loss: 0.1500, validation loss: 0.1977
2024-06-03 14:37:54 [INFO]: Epoch 054 - training loss: 0.1272, validation loss: 0.2050
2024-06-03 14:38:25 [INFO]: Epoch 055 - training loss: 0.1530, validation loss: 0.2076
2024-06-03 14:38:56 [INFO]: Epoch 056 - training loss: 0.1608, validation loss: 0.1983
2024-06-03 14:39:26 [INFO]: Epoch 057 - training loss: 0.1540, validation loss: 0.1990
2024-06-03 14:39:57 [INFO]: Epoch 058 - training loss: 0.1577, validation loss: 0.2086
2024-06-03 14:40:28 [INFO]: Epoch 059 - training loss: 0.1726, validation loss: 0.2217
2024-06-03 14:40:58 [INFO]: Epoch 060 - training loss: 0.1580, validation loss: 0.1990
2024-06-03 14:41:29 [INFO]: Epoch 061 - training loss: 0.1531, validation loss: 0.1961
2024-06-03 14:42:00 [INFO]: Epoch 062 - training loss: 0.1842, validation loss: 0.1994
2024-06-03 14:42:30 [INFO]: Epoch 063 - training loss: 0.1334, validation loss: 0.1956
2024-06-03 14:43:01 [INFO]: Epoch 064 - training loss: 0.1845, validation loss: 0.2276
2024-06-03 14:43:31 [INFO]: Epoch 065 - training loss: 0.1704, validation loss: 0.2188
2024-06-03 14:44:02 [INFO]: Epoch 066 - training loss: 0.1748, validation loss: 0.2246
2024-06-03 14:44:32 [INFO]: Epoch 067 - training loss: 0.1698, validation loss: 0.2040
2024-06-03 14:45:03 [INFO]: Epoch 068 - training loss: 0.1565, validation loss: 0.1968
2024-06-03 14:45:33 [INFO]: Epoch 069 - training loss: 0.1497, validation loss: 0.1939
2024-06-03 14:46:04 [INFO]: Epoch 070 - training loss: 0.1571, validation loss: 0.2127
2024-06-03 14:46:34 [INFO]: Epoch 071 - training loss: 0.1537, validation loss: 0.2041
2024-06-03 14:47:05 [INFO]: Epoch 072 - training loss: 0.1406, validation loss: 0.1951
2024-06-03 14:47:36 [INFO]: Epoch 073 - training loss: 0.1453, validation loss: 0.1923
2024-06-03 14:48:06 [INFO]: Epoch 074 - training loss: 0.1267, validation loss: 0.1979
2024-06-03 14:48:37 [INFO]: Epoch 075 - training loss: 0.1388, validation loss: 0.1919
2024-06-03 14:49:07 [INFO]: Epoch 076 - training loss: 0.1422, validation loss: 0.1922
2024-06-03 14:49:38 [INFO]: Epoch 077 - training loss: 0.1528, validation loss: 0.1910
2024-06-03 14:50:08 [INFO]: Epoch 078 - training loss: 0.1365, validation loss: 0.1901
2024-06-03 14:50:39 [INFO]: Epoch 079 - training loss: 0.1591, validation loss: 0.1907
2024-06-03 14:51:09 [INFO]: Epoch 080 - training loss: 0.1507, validation loss: 0.2047
2024-06-03 14:51:40 [INFO]: Epoch 081 - training loss: 0.1347, validation loss: 0.1913
2024-06-03 14:52:11 [INFO]: Epoch 082 - training loss: 0.1202, validation loss: 0.1910
2024-06-03 14:52:41 [INFO]: Epoch 083 - training loss: 0.1346, validation loss: 0.1895
2024-06-03 14:53:12 [INFO]: Epoch 084 - training loss: 0.1236, validation loss: 0.1886
2024-06-03 14:53:42 [INFO]: Epoch 085 - training loss: 0.1420, validation loss: 0.1872
2024-06-03 14:54:13 [INFO]: Epoch 086 - training loss: 0.1247, validation loss: 0.1904
2024-06-03 14:54:43 [INFO]: Epoch 087 - training loss: 0.1446, validation loss: 0.1915
2024-06-03 14:55:14 [INFO]: Epoch 088 - training loss: 0.1377, validation loss: 0.2015
2024-06-03 14:55:44 [INFO]: Epoch 089 - training loss: 0.1406, validation loss: 0.1959
2024-06-03 14:56:15 [INFO]: Epoch 090 - training loss: 0.1756, validation loss: 0.1944
2024-06-03 14:56:46 [INFO]: Epoch 091 - training loss: 0.1183, validation loss: 0.1872
2024-06-03 14:57:16 [INFO]: Epoch 092 - training loss: 0.1277, validation loss: 0.1880
2024-06-03 14:57:46 [INFO]: Epoch 093 - training loss: 0.1255, validation loss: 0.1858
2024-06-03 14:58:11 [INFO]: Epoch 094 - training loss: 0.1268, validation loss: 0.1886
2024-06-03 14:58:36 [INFO]: Epoch 095 - training loss: 0.1237, validation loss: 0.1874
2024-06-03 14:59:00 [INFO]: Epoch 096 - training loss: 0.1192, validation loss: 0.1879
2024-06-03 14:59:25 [INFO]: Epoch 097 - training loss: 0.1465, validation loss: 0.1863
2024-06-03 14:59:49 [INFO]: Epoch 098 - training loss: 0.1511, validation loss: 0.1860
2024-06-03 15:00:14 [INFO]: Epoch 099 - training loss: 0.1354, validation loss: 0.1842
2024-06-03 15:00:38 [INFO]: Epoch 100 - training loss: 0.1208, validation loss: 0.1844
2024-06-03 15:00:38 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 15:00:38 [INFO]: Saved the model to results_block_rate05/PeMS/CSDI_PeMS/round_3/20240603_T141025/CSDI.pypots
2024-06-03 15:20:35 [INFO]: Successfully saved to results_block_rate05/PeMS/CSDI_PeMS/round_3/imputation.pkl
2024-06-03 15:20:35 [INFO]: Round3 - CSDI on PeMS: MAE=0.3343, MSE=0.7298, MRE=0.4003
2024-06-03 15:20:35 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 15:20:35 [INFO]: Using the given device: cuda:0
2024-06-03 15:20:35 [INFO]: Model files will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_4/20240603_T152035
2024-06-03 15:20:35 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/CSDI_PeMS/round_4/20240603_T152035/tensorboard
2024-06-03 15:20:35 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 207,873
2024-06-03 15:20:59 [INFO]: Epoch 001 - training loss: 0.7902, validation loss: 0.5569
2024-06-03 15:21:24 [INFO]: Epoch 002 - training loss: 0.4520, validation loss: 0.4203
2024-06-03 15:21:48 [INFO]: Epoch 003 - training loss: 0.3435, validation loss: 0.3781
2024-06-03 15:22:13 [INFO]: Epoch 004 - training loss: 0.3094, validation loss: 0.3648
2024-06-03 15:22:37 [INFO]: Epoch 005 - training loss: 0.3260, validation loss: 0.3325
2024-06-03 15:23:02 [INFO]: Epoch 006 - training loss: 0.3085, validation loss: 0.3342
2024-06-03 15:23:26 [INFO]: Epoch 007 - training loss: 0.2651, validation loss: 0.3306
2024-06-03 15:23:51 [INFO]: Epoch 008 - training loss: 0.2632, validation loss: 0.3400
2024-06-03 15:24:15 [INFO]: Epoch 009 - training loss: 0.2743, validation loss: 0.3266
2024-06-03 15:24:40 [INFO]: Epoch 010 - training loss: 0.2428, validation loss: 0.3581
2024-06-03 15:25:04 [INFO]: Epoch 011 - training loss: 0.2488, validation loss: 0.2974
2024-06-03 15:25:29 [INFO]: Epoch 012 - training loss: 0.2437, validation loss: 0.3315
2024-06-03 15:25:53 [INFO]: Epoch 013 - training loss: 0.2557, validation loss: 0.2952
2024-06-03 15:26:18 [INFO]: Epoch 014 - training loss: 0.1960, validation loss: 0.2840
2024-06-03 15:26:42 [INFO]: Epoch 015 - training loss: 0.1994, validation loss: 0.2802
2024-06-03 15:27:07 [INFO]: Epoch 016 - training loss: 0.1924, validation loss: 0.3028
2024-06-03 15:27:31 [INFO]: Epoch 017 - training loss: 0.2411, validation loss: 0.2999
2024-06-03 15:27:56 [INFO]: Epoch 018 - training loss: 0.2096, validation loss: 0.3094
2024-06-03 15:28:20 [INFO]: Epoch 019 - training loss: 0.2055, validation loss: 0.2578
2024-06-03 15:28:45 [INFO]: Epoch 020 - training loss: 0.2202, validation loss: 0.2711
2024-06-03 15:29:09 [INFO]: Epoch 021 - training loss: 0.1729, validation loss: 0.2554
2024-06-03 15:29:34 [INFO]: Epoch 022 - training loss: 0.1842, validation loss: 0.2617
2024-06-03 15:29:58 [INFO]: Epoch 023 - training loss: 0.1993, validation loss: 0.2609
2024-06-03 15:30:23 [INFO]: Epoch 024 - training loss: 0.1823, validation loss: 0.2487
2024-06-03 15:30:47 [INFO]: Epoch 025 - training loss: 0.1990, validation loss: 0.2616
2024-06-03 15:31:12 [INFO]: Epoch 026 - training loss: 0.1783, validation loss: 0.2597
2024-06-03 15:31:36 [INFO]: Epoch 027 - training loss: 0.1708, validation loss: 0.2430
2024-06-03 15:32:01 [INFO]: Epoch 028 - training loss: 0.1606, validation loss: 0.2363
2024-06-03 15:32:26 [INFO]: Epoch 029 - training loss: 0.1847, validation loss: 0.2337
2024-06-03 15:32:50 [INFO]: Epoch 030 - training loss: 0.1734, validation loss: 0.2685
2024-06-03 15:33:15 [INFO]: Epoch 031 - training loss: 0.1715, validation loss: 0.2619
2024-06-03 15:33:39 [INFO]: Epoch 032 - training loss: 0.2170, validation loss: 0.2295
2024-06-03 15:34:04 [INFO]: Epoch 033 - training loss: 0.1966, validation loss: 0.2278
2024-06-03 15:34:28 [INFO]: Epoch 034 - training loss: 0.1744, validation loss: 0.2449
2024-06-03 15:34:53 [INFO]: Epoch 035 - training loss: 0.1652, validation loss: 0.2289
2024-06-03 15:35:17 [INFO]: Epoch 036 - training loss: 0.1827, validation loss: 0.2388
2024-06-03 15:35:42 [INFO]: Epoch 037 - training loss: 0.1585, validation loss: 0.2280
2024-06-03 15:36:06 [INFO]: Epoch 038 - training loss: 0.1697, validation loss: 0.2367
2024-06-03 15:36:31 [INFO]: Epoch 039 - training loss: 0.1662, validation loss: 0.2304
2024-06-03 15:36:55 [INFO]: Epoch 040 - training loss: 0.1829, validation loss: 0.2190
2024-06-03 15:37:20 [INFO]: Epoch 041 - training loss: 0.1509, validation loss: 0.2120
2024-06-03 15:37:44 [INFO]: Epoch 042 - training loss: 0.1701, validation loss: 0.2221
2024-06-03 15:38:09 [INFO]: Epoch 043 - training loss: 0.1720, validation loss: 0.2383
2024-06-03 15:38:33 [INFO]: Epoch 044 - training loss: 0.1787, validation loss: 0.2109
2024-06-03 15:38:58 [INFO]: Epoch 045 - training loss: 0.1727, validation loss: 0.2247
2024-06-03 15:39:22 [INFO]: Epoch 046 - training loss: 0.1614, validation loss: 0.2226
2024-06-03 15:39:47 [INFO]: Epoch 047 - training loss: 0.1408, validation loss: 0.2156
2024-06-03 15:40:11 [INFO]: Epoch 048 - training loss: 0.1717, validation loss: 0.2159
2024-06-03 15:40:36 [INFO]: Epoch 049 - training loss: 0.1633, validation loss: 0.2048
2024-06-03 15:41:00 [INFO]: Epoch 050 - training loss: 0.1405, validation loss: 0.1989
2024-06-03 15:41:25 [INFO]: Epoch 051 - training loss: 0.1634, validation loss: 0.1993
2024-06-03 15:41:49 [INFO]: Epoch 052 - training loss: 0.1658, validation loss: 0.2012
2024-06-03 15:42:14 [INFO]: Epoch 053 - training loss: 0.1710, validation loss: 0.1994
2024-06-03 15:42:38 [INFO]: Epoch 054 - training loss: 0.1496, validation loss: 0.2010
2024-06-03 15:43:03 [INFO]: Epoch 055 - training loss: 0.1681, validation loss: 0.2056
2024-06-03 15:43:27 [INFO]: Epoch 056 - training loss: 0.1767, validation loss: 0.2002
2024-06-03 15:43:52 [INFO]: Epoch 057 - training loss: 0.1551, validation loss: 0.2145
2024-06-03 15:44:16 [INFO]: Epoch 058 - training loss: 0.1732, validation loss: 0.2068
2024-06-03 15:44:41 [INFO]: Epoch 059 - training loss: 0.1783, validation loss: 0.2159
2024-06-03 15:45:05 [INFO]: Epoch 060 - training loss: 0.1401, validation loss: 0.2071
2024-06-03 15:45:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 15:45:05 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 15:45:05 [INFO]: Saved the model to results_block_rate05/PeMS/CSDI_PeMS/round_4/20240603_T152035/CSDI.pypots
2024-06-03 16:05:01 [INFO]: Successfully saved to results_block_rate05/PeMS/CSDI_PeMS/round_4/imputation.pkl
2024-06-03 16:05:01 [INFO]: Round4 - CSDI on PeMS: MAE=0.3487, MSE=0.8382, MRE=0.4175
2024-06-03 16:05:01 [INFO]: Done! Final results:
Averaged CSDI (207,873 params) on PeMS: MAE=1.1324 ± 1.318119792778264, MSE=14.9065 ± 27.389237970031587, MRE=1.3559 ± 1.578266639504673, average inference time=309.66
