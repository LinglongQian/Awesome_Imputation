2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:54 [INFO]: Model files will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T100954
2024-06-03 10:09:54 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T100954/tensorboard
2024-06-03 10:09:59 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 10:10:18 [INFO]: Epoch 001 - training loss: 1.1709, validation loss: 1.0029
2024-06-03 10:10:29 [INFO]: Epoch 002 - training loss: 0.6844, validation loss: 0.8218
2024-06-03 10:10:41 [INFO]: Epoch 003 - training loss: 0.5649, validation loss: 0.7561
2024-06-03 10:10:55 [INFO]: Epoch 004 - training loss: 0.5259, validation loss: 0.6980
2024-06-03 10:11:08 [INFO]: Epoch 005 - training loss: 0.4830, validation loss: 0.6542
2024-06-03 10:11:22 [INFO]: Epoch 006 - training loss: 0.4635, validation loss: 0.6324
2024-06-03 10:11:35 [INFO]: Epoch 007 - training loss: 0.4499, validation loss: 0.6355
2024-06-03 10:11:48 [INFO]: Epoch 008 - training loss: 0.4453, validation loss: 0.6130
2024-06-03 10:12:01 [INFO]: Epoch 009 - training loss: 0.4344, validation loss: 0.6083
2024-06-03 10:12:13 [INFO]: Epoch 010 - training loss: 0.4245, validation loss: 0.6200
2024-06-03 10:12:25 [INFO]: Epoch 011 - training loss: 0.4238, validation loss: 0.6033
2024-06-03 10:12:39 [INFO]: Epoch 012 - training loss: 0.4015, validation loss: 0.5894
2024-06-03 10:12:51 [INFO]: Epoch 013 - training loss: 0.4028, validation loss: 0.5908
2024-06-03 10:13:04 [INFO]: Epoch 014 - training loss: 0.3907, validation loss: 0.5886
2024-06-03 10:13:18 [INFO]: Epoch 015 - training loss: 0.3867, validation loss: 0.5855
2024-06-03 10:13:31 [INFO]: Epoch 016 - training loss: 0.3824, validation loss: 0.5891
2024-06-03 10:13:43 [INFO]: Epoch 017 - training loss: 0.3786, validation loss: 0.5869
2024-06-03 10:13:55 [INFO]: Epoch 018 - training loss: 0.3735, validation loss: 0.6191
2024-06-03 10:14:08 [INFO]: Epoch 019 - training loss: 0.3717, validation loss: 0.5796
2024-06-03 10:14:21 [INFO]: Epoch 020 - training loss: 0.3562, validation loss: 0.5700
2024-06-03 10:14:34 [INFO]: Epoch 021 - training loss: 0.3528, validation loss: 0.5634
2024-06-03 10:14:47 [INFO]: Epoch 022 - training loss: 0.3478, validation loss: 0.5682
2024-06-03 10:15:00 [INFO]: Epoch 023 - training loss: 0.3487, validation loss: 0.5674
2024-06-03 10:15:14 [INFO]: Epoch 024 - training loss: 0.3435, validation loss: 0.5647
2024-06-03 10:15:26 [INFO]: Epoch 025 - training loss: 0.3326, validation loss: 0.5571
2024-06-03 10:15:37 [INFO]: Epoch 026 - training loss: 0.3308, validation loss: 0.5692
2024-06-03 10:15:49 [INFO]: Epoch 027 - training loss: 0.3339, validation loss: 0.5626
2024-06-03 10:16:02 [INFO]: Epoch 028 - training loss: 0.3265, validation loss: 0.5534
2024-06-03 10:16:15 [INFO]: Epoch 029 - training loss: 0.3230, validation loss: 0.5646
2024-06-03 10:16:28 [INFO]: Epoch 030 - training loss: 0.3165, validation loss: 0.5591
2024-06-03 10:16:41 [INFO]: Epoch 031 - training loss: 0.3218, validation loss: 0.5579
2024-06-03 10:16:54 [INFO]: Epoch 032 - training loss: 0.3244, validation loss: 0.5702
2024-06-03 10:17:06 [INFO]: Epoch 033 - training loss: 0.3196, validation loss: 0.5518
2024-06-03 10:17:19 [INFO]: Epoch 034 - training loss: 0.3179, validation loss: 0.5572
2024-06-03 10:17:32 [INFO]: Epoch 035 - training loss: 0.3094, validation loss: 0.5568
2024-06-03 10:17:44 [INFO]: Epoch 036 - training loss: 0.3086, validation loss: 0.5529
2024-06-03 10:17:57 [INFO]: Epoch 037 - training loss: 0.3055, validation loss: 0.5550
2024-06-03 10:18:09 [INFO]: Epoch 038 - training loss: 0.3021, validation loss: 0.5540
2024-06-03 10:18:22 [INFO]: Epoch 039 - training loss: 0.3035, validation loss: 0.5533
2024-06-03 10:18:35 [INFO]: Epoch 040 - training loss: 0.2992, validation loss: 0.5580
2024-06-03 10:18:46 [INFO]: Epoch 041 - training loss: 0.2978, validation loss: 0.5558
2024-06-03 10:18:59 [INFO]: Epoch 042 - training loss: 0.2944, validation loss: 0.5590
2024-06-03 10:19:12 [INFO]: Epoch 043 - training loss: 0.2939, validation loss: 0.5522
2024-06-03 10:19:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:19:12 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 10:19:13 [INFO]: Saved the model to results_block_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T100954/Crossformer.pypots
2024-06-03 10:19:17 [INFO]: Successfully saved to results_block_rate05/PeMS/Crossformer_PeMS/round_0/imputation.pkl
2024-06-03 10:19:17 [INFO]: Round0 - Crossformer on PeMS: MAE=0.4065, MSE=0.8156, MRE=0.4867
2024-06-03 10:19:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:19:17 [INFO]: Using the given device: cuda:0
2024-06-03 10:19:17 [INFO]: Model files will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T101917
2024-06-03 10:19:17 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T101917/tensorboard
2024-06-03 10:19:20 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 10:19:33 [INFO]: Epoch 001 - training loss: 1.1697, validation loss: 1.0759
2024-06-03 10:19:46 [INFO]: Epoch 002 - training loss: 0.7353, validation loss: 0.8698
2024-06-03 10:19:59 [INFO]: Epoch 003 - training loss: 0.5892, validation loss: 0.7831
2024-06-03 10:20:11 [INFO]: Epoch 004 - training loss: 0.5351, validation loss: 0.7059
2024-06-03 10:20:23 [INFO]: Epoch 005 - training loss: 0.5066, validation loss: 0.6986
2024-06-03 10:20:35 [INFO]: Epoch 006 - training loss: 0.4865, validation loss: 0.6772
2024-06-03 10:20:49 [INFO]: Epoch 007 - training loss: 0.4658, validation loss: 0.6390
2024-06-03 10:21:01 [INFO]: Epoch 008 - training loss: 0.4627, validation loss: 0.6605
2024-06-03 10:21:15 [INFO]: Epoch 009 - training loss: 0.4534, validation loss: 0.6354
2024-06-03 10:21:28 [INFO]: Epoch 010 - training loss: 0.4371, validation loss: 0.6344
2024-06-03 10:21:41 [INFO]: Epoch 011 - training loss: 0.4264, validation loss: 0.6173
2024-06-03 10:21:53 [INFO]: Epoch 012 - training loss: 0.4205, validation loss: 0.5994
2024-06-03 10:22:05 [INFO]: Epoch 013 - training loss: 0.4097, validation loss: 0.5924
2024-06-03 10:22:19 [INFO]: Epoch 014 - training loss: 0.4063, validation loss: 0.5862
2024-06-03 10:22:32 [INFO]: Epoch 015 - training loss: 0.3976, validation loss: 0.6002
2024-06-03 10:22:44 [INFO]: Epoch 016 - training loss: 0.3913, validation loss: 0.5882
2024-06-03 10:22:58 [INFO]: Epoch 017 - training loss: 0.3793, validation loss: 0.5887
2024-06-03 10:23:10 [INFO]: Epoch 018 - training loss: 0.3771, validation loss: 0.5837
2024-06-03 10:23:22 [INFO]: Epoch 019 - training loss: 0.3712, validation loss: 0.5767
2024-06-03 10:23:34 [INFO]: Epoch 020 - training loss: 0.3671, validation loss: 0.5771
2024-06-03 10:23:45 [INFO]: Epoch 021 - training loss: 0.3554, validation loss: 0.5711
2024-06-03 10:23:58 [INFO]: Epoch 022 - training loss: 0.3524, validation loss: 0.5665
2024-06-03 10:24:11 [INFO]: Epoch 023 - training loss: 0.3479, validation loss: 0.5614
2024-06-03 10:24:24 [INFO]: Epoch 024 - training loss: 0.3426, validation loss: 0.5639
2024-06-03 10:24:37 [INFO]: Epoch 025 - training loss: 0.3415, validation loss: 0.5624
2024-06-03 10:24:50 [INFO]: Epoch 026 - training loss: 0.3416, validation loss: 0.5562
2024-06-03 10:25:03 [INFO]: Epoch 027 - training loss: 0.3408, validation loss: 0.5682
2024-06-03 10:25:14 [INFO]: Epoch 028 - training loss: 0.3315, validation loss: 0.5579
2024-06-03 10:25:25 [INFO]: Epoch 029 - training loss: 0.3273, validation loss: 0.5564
2024-06-03 10:25:37 [INFO]: Epoch 030 - training loss: 0.3251, validation loss: 0.5517
2024-06-03 10:25:50 [INFO]: Epoch 031 - training loss: 0.3217, validation loss: 0.5540
2024-06-03 10:26:02 [INFO]: Epoch 032 - training loss: 0.3337, validation loss: 0.5566
2024-06-03 10:26:14 [INFO]: Epoch 033 - training loss: 0.3210, validation loss: 0.5545
2024-06-03 10:26:26 [INFO]: Epoch 034 - training loss: 0.3176, validation loss: 0.5529
2024-06-03 10:26:39 [INFO]: Epoch 035 - training loss: 0.3124, validation loss: 0.5606
2024-06-03 10:26:51 [INFO]: Epoch 036 - training loss: 0.3118, validation loss: 0.5488
2024-06-03 10:27:02 [INFO]: Epoch 037 - training loss: 0.3103, validation loss: 0.5582
2024-06-03 10:27:15 [INFO]: Epoch 038 - training loss: 0.3127, validation loss: 0.5531
2024-06-03 10:27:26 [INFO]: Epoch 039 - training loss: 0.3170, validation loss: 0.5524
2024-06-03 10:27:39 [INFO]: Epoch 040 - training loss: 0.3034, validation loss: 0.5669
2024-06-03 10:27:51 [INFO]: Epoch 041 - training loss: 0.3077, validation loss: 0.5561
2024-06-03 10:28:04 [INFO]: Epoch 042 - training loss: 0.3037, validation loss: 0.5532
2024-06-03 10:28:16 [INFO]: Epoch 043 - training loss: 0.2965, validation loss: 0.5605
2024-06-03 10:28:28 [INFO]: Epoch 044 - training loss: 0.2974, validation loss: 0.5542
2024-06-03 10:28:39 [INFO]: Epoch 045 - training loss: 0.2945, validation loss: 0.5509
2024-06-03 10:28:51 [INFO]: Epoch 046 - training loss: 0.2938, validation loss: 0.5491
2024-06-03 10:28:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:28:51 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 10:28:52 [INFO]: Saved the model to results_block_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T101917/Crossformer.pypots
2024-06-03 10:28:56 [INFO]: Successfully saved to results_block_rate05/PeMS/Crossformer_PeMS/round_1/imputation.pkl
2024-06-03 10:28:56 [INFO]: Round1 - Crossformer on PeMS: MAE=0.4063, MSE=0.8113, MRE=0.4865
2024-06-03 10:28:56 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:28:56 [INFO]: Using the given device: cuda:0
2024-06-03 10:28:57 [INFO]: Model files will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T102856
2024-06-03 10:28:57 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T102856/tensorboard
2024-06-03 10:28:59 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 10:29:12 [INFO]: Epoch 001 - training loss: 1.1218, validation loss: 1.0293
2024-06-03 10:29:25 [INFO]: Epoch 002 - training loss: 0.7334, validation loss: 0.8619
2024-06-03 10:29:37 [INFO]: Epoch 003 - training loss: 0.5983, validation loss: 0.7922
2024-06-03 10:29:49 [INFO]: Epoch 004 - training loss: 0.5351, validation loss: 0.7141
2024-06-03 10:30:02 [INFO]: Epoch 005 - training loss: 0.5022, validation loss: 0.6904
2024-06-03 10:30:13 [INFO]: Epoch 006 - training loss: 0.4859, validation loss: 0.6379
2024-06-03 10:30:24 [INFO]: Epoch 007 - training loss: 0.4628, validation loss: 0.6324
2024-06-03 10:30:37 [INFO]: Epoch 008 - training loss: 0.4410, validation loss: 0.6130
2024-06-03 10:30:49 [INFO]: Epoch 009 - training loss: 0.4332, validation loss: 0.6016
2024-06-03 10:31:02 [INFO]: Epoch 010 - training loss: 0.4254, validation loss: 0.6052
2024-06-03 10:31:15 [INFO]: Epoch 011 - training loss: 0.4214, validation loss: 0.5924
2024-06-03 10:31:27 [INFO]: Epoch 012 - training loss: 0.4059, validation loss: 0.5828
2024-06-03 10:31:39 [INFO]: Epoch 013 - training loss: 0.3935, validation loss: 0.5841
2024-06-03 10:31:51 [INFO]: Epoch 014 - training loss: 0.3853, validation loss: 0.5798
2024-06-03 10:32:02 [INFO]: Epoch 015 - training loss: 0.3836, validation loss: 0.5706
2024-06-03 10:32:15 [INFO]: Epoch 016 - training loss: 0.3759, validation loss: 0.5724
2024-06-03 10:32:27 [INFO]: Epoch 017 - training loss: 0.3702, validation loss: 0.5662
2024-06-03 10:32:39 [INFO]: Epoch 018 - training loss: 0.3659, validation loss: 0.5697
2024-06-03 10:32:51 [INFO]: Epoch 019 - training loss: 0.3611, validation loss: 0.5654
2024-06-03 10:33:03 [INFO]: Epoch 020 - training loss: 0.3596, validation loss: 0.5639
2024-06-03 10:33:15 [INFO]: Epoch 021 - training loss: 0.3561, validation loss: 0.5541
2024-06-03 10:33:27 [INFO]: Epoch 022 - training loss: 0.3514, validation loss: 0.5699
2024-06-03 10:33:38 [INFO]: Epoch 023 - training loss: 0.3472, validation loss: 0.5583
2024-06-03 10:33:51 [INFO]: Epoch 024 - training loss: 0.3447, validation loss: 0.5592
2024-06-03 10:34:03 [INFO]: Epoch 025 - training loss: 0.3392, validation loss: 0.5531
2024-06-03 10:34:14 [INFO]: Epoch 026 - training loss: 0.3354, validation loss: 0.5534
2024-06-03 10:34:26 [INFO]: Epoch 027 - training loss: 0.3336, validation loss: 0.5468
2024-06-03 10:34:39 [INFO]: Epoch 028 - training loss: 0.3309, validation loss: 0.5529
2024-06-03 10:34:50 [INFO]: Epoch 029 - training loss: 0.3244, validation loss: 0.5557
2024-06-03 10:35:02 [INFO]: Epoch 030 - training loss: 0.3237, validation loss: 0.5493
2024-06-03 10:35:13 [INFO]: Epoch 031 - training loss: 0.3270, validation loss: 0.5459
2024-06-03 10:35:25 [INFO]: Epoch 032 - training loss: 0.3354, validation loss: 0.5504
2024-06-03 10:35:37 [INFO]: Epoch 033 - training loss: 0.3193, validation loss: 0.5499
2024-06-03 10:35:49 [INFO]: Epoch 034 - training loss: 0.3192, validation loss: 0.5464
2024-06-03 10:36:00 [INFO]: Epoch 035 - training loss: 0.3093, validation loss: 0.5545
2024-06-03 10:36:12 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.5551
2024-06-03 10:36:24 [INFO]: Epoch 037 - training loss: 0.3150, validation loss: 0.5509
2024-06-03 10:36:35 [INFO]: Epoch 038 - training loss: 0.3137, validation loss: 0.5543
2024-06-03 10:36:45 [INFO]: Epoch 039 - training loss: 0.3043, validation loss: 0.5489
2024-06-03 10:36:57 [INFO]: Epoch 040 - training loss: 0.3059, validation loss: 0.5501
2024-06-03 10:37:09 [INFO]: Epoch 041 - training loss: 0.3071, validation loss: 0.5593
2024-06-03 10:37:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:37:09 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 10:37:10 [INFO]: Saved the model to results_block_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T102856/Crossformer.pypots
2024-06-03 10:37:14 [INFO]: Successfully saved to results_block_rate05/PeMS/Crossformer_PeMS/round_2/imputation.pkl
2024-06-03 10:37:14 [INFO]: Round2 - Crossformer on PeMS: MAE=0.4194, MSE=0.8196, MRE=0.5021
2024-06-03 10:37:14 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:37:14 [INFO]: Using the given device: cuda:0
2024-06-03 10:37:14 [INFO]: Model files will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T103714
2024-06-03 10:37:14 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T103714/tensorboard
2024-06-03 10:37:16 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 10:37:29 [INFO]: Epoch 001 - training loss: 1.1330, validation loss: 0.9924
2024-06-03 10:37:41 [INFO]: Epoch 002 - training loss: 0.6976, validation loss: 0.8623
2024-06-03 10:37:52 [INFO]: Epoch 003 - training loss: 0.5666, validation loss: 0.7459
2024-06-03 10:38:04 [INFO]: Epoch 004 - training loss: 0.5224, validation loss: 0.7095
2024-06-03 10:38:15 [INFO]: Epoch 005 - training loss: 0.5035, validation loss: 0.6657
2024-06-03 10:38:25 [INFO]: Epoch 006 - training loss: 0.4950, validation loss: 0.6683
2024-06-03 10:38:37 [INFO]: Epoch 007 - training loss: 0.4817, validation loss: 0.6560
2024-06-03 10:38:49 [INFO]: Epoch 008 - training loss: 0.4572, validation loss: 0.6222
2024-06-03 10:39:01 [INFO]: Epoch 009 - training loss: 0.4367, validation loss: 0.6289
2024-06-03 10:39:13 [INFO]: Epoch 010 - training loss: 0.4272, validation loss: 0.6017
2024-06-03 10:39:24 [INFO]: Epoch 011 - training loss: 0.4155, validation loss: 0.6009
2024-06-03 10:39:36 [INFO]: Epoch 012 - training loss: 0.4184, validation loss: 0.5989
2024-06-03 10:39:47 [INFO]: Epoch 013 - training loss: 0.4151, validation loss: 0.5951
2024-06-03 10:39:58 [INFO]: Epoch 014 - training loss: 0.4012, validation loss: 0.5866
2024-06-03 10:40:08 [INFO]: Epoch 015 - training loss: 0.3935, validation loss: 0.5820
2024-06-03 10:40:20 [INFO]: Epoch 016 - training loss: 0.3869, validation loss: 0.5795
2024-06-03 10:40:32 [INFO]: Epoch 017 - training loss: 0.3802, validation loss: 0.5789
2024-06-03 10:40:43 [INFO]: Epoch 018 - training loss: 0.3711, validation loss: 0.5820
2024-06-03 10:40:55 [INFO]: Epoch 019 - training loss: 0.3689, validation loss: 0.5742
2024-06-03 10:41:06 [INFO]: Epoch 020 - training loss: 0.3652, validation loss: 0.5737
2024-06-03 10:41:18 [INFO]: Epoch 021 - training loss: 0.3623, validation loss: 0.5656
2024-06-03 10:41:29 [INFO]: Epoch 022 - training loss: 0.3495, validation loss: 0.5635
2024-06-03 10:41:40 [INFO]: Epoch 023 - training loss: 0.3491, validation loss: 0.5615
2024-06-03 10:41:51 [INFO]: Epoch 024 - training loss: 0.3423, validation loss: 0.5585
2024-06-03 10:42:03 [INFO]: Epoch 025 - training loss: 0.3474, validation loss: 0.5559
2024-06-03 10:42:14 [INFO]: Epoch 026 - training loss: 0.3364, validation loss: 0.5578
2024-06-03 10:42:26 [INFO]: Epoch 027 - training loss: 0.3331, validation loss: 0.5564
2024-06-03 10:42:37 [INFO]: Epoch 028 - training loss: 0.3333, validation loss: 0.5454
2024-06-03 10:42:50 [INFO]: Epoch 029 - training loss: 0.3237, validation loss: 0.5466
2024-06-03 10:43:02 [INFO]: Epoch 030 - training loss: 0.3281, validation loss: 0.5461
2024-06-03 10:43:13 [INFO]: Epoch 031 - training loss: 0.3195, validation loss: 0.5528
2024-06-03 10:43:25 [INFO]: Epoch 032 - training loss: 0.3217, validation loss: 0.5452
2024-06-03 10:43:36 [INFO]: Epoch 033 - training loss: 0.3129, validation loss: 0.5588
2024-06-03 10:43:47 [INFO]: Epoch 034 - training loss: 0.3151, validation loss: 0.5432
2024-06-03 10:43:59 [INFO]: Epoch 035 - training loss: 0.3124, validation loss: 0.5399
2024-06-03 10:44:11 [INFO]: Epoch 036 - training loss: 0.3124, validation loss: 0.5408
2024-06-03 10:44:23 [INFO]: Epoch 037 - training loss: 0.3093, validation loss: 0.5383
2024-06-03 10:44:35 [INFO]: Epoch 038 - training loss: 0.3110, validation loss: 0.5426
2024-06-03 10:44:46 [INFO]: Epoch 039 - training loss: 0.3045, validation loss: 0.5362
2024-06-03 10:44:57 [INFO]: Epoch 040 - training loss: 0.3066, validation loss: 0.5458
2024-06-03 10:45:07 [INFO]: Epoch 041 - training loss: 0.3048, validation loss: 0.5422
2024-06-03 10:45:18 [INFO]: Epoch 042 - training loss: 0.2962, validation loss: 0.5398
2024-06-03 10:45:29 [INFO]: Epoch 043 - training loss: 0.2962, validation loss: 0.5419
2024-06-03 10:45:40 [INFO]: Epoch 044 - training loss: 0.2953, validation loss: 0.5361
2024-06-03 10:45:51 [INFO]: Epoch 045 - training loss: 0.2927, validation loss: 0.5410
2024-06-03 10:46:03 [INFO]: Epoch 046 - training loss: 0.2929, validation loss: 0.5395
2024-06-03 10:46:14 [INFO]: Epoch 047 - training loss: 0.2934, validation loss: 0.5392
2024-06-03 10:46:24 [INFO]: Epoch 048 - training loss: 0.2878, validation loss: 0.5414
2024-06-03 10:46:35 [INFO]: Epoch 049 - training loss: 0.2901, validation loss: 0.5351
2024-06-03 10:46:45 [INFO]: Epoch 050 - training loss: 0.2861, validation loss: 0.5345
2024-06-03 10:46:55 [INFO]: Epoch 051 - training loss: 0.2851, validation loss: 0.5371
2024-06-03 10:47:06 [INFO]: Epoch 052 - training loss: 0.2823, validation loss: 0.5468
2024-06-03 10:47:17 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.5381
2024-06-03 10:47:27 [INFO]: Epoch 054 - training loss: 0.2797, validation loss: 0.5429
2024-06-03 10:47:38 [INFO]: Epoch 055 - training loss: 0.2803, validation loss: 0.5406
2024-06-03 10:47:49 [INFO]: Epoch 056 - training loss: 0.2843, validation loss: 0.5341
2024-06-03 10:47:59 [INFO]: Epoch 057 - training loss: 0.2814, validation loss: 0.5390
2024-06-03 10:48:09 [INFO]: Epoch 058 - training loss: 0.2765, validation loss: 0.5462
2024-06-03 10:48:20 [INFO]: Epoch 059 - training loss: 0.2817, validation loss: 0.5417
2024-06-03 10:48:31 [INFO]: Epoch 060 - training loss: 0.2772, validation loss: 0.5356
2024-06-03 10:48:41 [INFO]: Epoch 061 - training loss: 0.2762, validation loss: 0.5326
2024-06-03 10:48:52 [INFO]: Epoch 062 - training loss: 0.2796, validation loss: 0.5486
2024-06-03 10:49:02 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.5387
2024-06-03 10:49:13 [INFO]: Epoch 064 - training loss: 0.2689, validation loss: 0.5352
2024-06-03 10:49:24 [INFO]: Epoch 065 - training loss: 0.2682, validation loss: 0.5395
2024-06-03 10:49:34 [INFO]: Epoch 066 - training loss: 0.2693, validation loss: 0.5387
2024-06-03 10:49:45 [INFO]: Epoch 067 - training loss: 0.2648, validation loss: 0.5315
2024-06-03 10:49:55 [INFO]: Epoch 068 - training loss: 0.2657, validation loss: 0.5389
2024-06-03 10:50:06 [INFO]: Epoch 069 - training loss: 0.2668, validation loss: 0.5341
2024-06-03 10:50:17 [INFO]: Epoch 070 - training loss: 0.2667, validation loss: 0.5357
2024-06-03 10:50:28 [INFO]: Epoch 071 - training loss: 0.2634, validation loss: 0.5396
2024-06-03 10:50:39 [INFO]: Epoch 072 - training loss: 0.2597, validation loss: 0.5449
2024-06-03 10:50:49 [INFO]: Epoch 073 - training loss: 0.2631, validation loss: 0.5409
2024-06-03 10:51:00 [INFO]: Epoch 074 - training loss: 0.2600, validation loss: 0.5385
2024-06-03 10:51:10 [INFO]: Epoch 075 - training loss: 0.2603, validation loss: 0.5360
2024-06-03 10:51:20 [INFO]: Epoch 076 - training loss: 0.2574, validation loss: 0.5371
2024-06-03 10:51:30 [INFO]: Epoch 077 - training loss: 0.2585, validation loss: 0.5405
2024-06-03 10:51:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:51:30 [INFO]: Finished training. The best model is from epoch#67.
2024-06-03 10:51:31 [INFO]: Saved the model to results_block_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T103714/Crossformer.pypots
2024-06-03 10:51:34 [INFO]: Successfully saved to results_block_rate05/PeMS/Crossformer_PeMS/round_3/imputation.pkl
2024-06-03 10:51:34 [INFO]: Round3 - Crossformer on PeMS: MAE=0.3958, MSE=0.8010, MRE=0.4739
2024-06-03 10:51:34 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:51:34 [INFO]: Using the given device: cuda:0
2024-06-03 10:51:34 [INFO]: Model files will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T105134
2024-06-03 10:51:34 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T105134/tensorboard
2024-06-03 10:51:36 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 10:51:47 [INFO]: Epoch 001 - training loss: 1.1296, validation loss: 0.9585
2024-06-03 10:51:58 [INFO]: Epoch 002 - training loss: 0.6812, validation loss: 0.8356
2024-06-03 10:52:08 [INFO]: Epoch 003 - training loss: 0.5760, validation loss: 0.7398
2024-06-03 10:52:19 [INFO]: Epoch 004 - training loss: 0.5200, validation loss: 0.7137
2024-06-03 10:52:29 [INFO]: Epoch 005 - training loss: 0.4919, validation loss: 0.6863
2024-06-03 10:52:40 [INFO]: Epoch 006 - training loss: 0.4693, validation loss: 0.6697
2024-06-03 10:52:51 [INFO]: Epoch 007 - training loss: 0.4505, validation loss: 0.6330
2024-06-03 10:53:01 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.6157
2024-06-03 10:53:11 [INFO]: Epoch 009 - training loss: 0.4364, validation loss: 0.6154
2024-06-03 10:53:21 [INFO]: Epoch 010 - training loss: 0.4587, validation loss: 0.6191
2024-06-03 10:53:32 [INFO]: Epoch 011 - training loss: 0.4443, validation loss: 0.5991
2024-06-03 10:53:42 [INFO]: Epoch 012 - training loss: 0.4167, validation loss: 0.6041
2024-06-03 10:53:54 [INFO]: Epoch 013 - training loss: 0.4018, validation loss: 0.5930
2024-06-03 10:54:04 [INFO]: Epoch 014 - training loss: 0.3929, validation loss: 0.5854
2024-06-03 10:54:15 [INFO]: Epoch 015 - training loss: 0.3819, validation loss: 0.5780
2024-06-03 10:54:25 [INFO]: Epoch 016 - training loss: 0.3795, validation loss: 0.5790
2024-06-03 10:54:35 [INFO]: Epoch 017 - training loss: 0.3691, validation loss: 0.5814
2024-06-03 10:54:44 [INFO]: Epoch 018 - training loss: 0.3683, validation loss: 0.5696
2024-06-03 10:54:54 [INFO]: Epoch 019 - training loss: 0.3613, validation loss: 0.5709
2024-06-03 10:55:04 [INFO]: Epoch 020 - training loss: 0.3567, validation loss: 0.5694
2024-06-03 10:55:13 [INFO]: Epoch 021 - training loss: 0.3524, validation loss: 0.5730
2024-06-03 10:55:23 [INFO]: Epoch 022 - training loss: 0.3523, validation loss: 0.5638
2024-06-03 10:55:33 [INFO]: Epoch 023 - training loss: 0.3441, validation loss: 0.5645
2024-06-03 10:55:44 [INFO]: Epoch 024 - training loss: 0.3426, validation loss: 0.5742
2024-06-03 10:55:54 [INFO]: Epoch 025 - training loss: 0.3387, validation loss: 0.5613
2024-06-03 10:56:04 [INFO]: Epoch 026 - training loss: 0.3306, validation loss: 0.5609
2024-06-03 10:56:13 [INFO]: Epoch 027 - training loss: 0.3320, validation loss: 0.5623
2024-06-03 10:56:23 [INFO]: Epoch 028 - training loss: 0.3243, validation loss: 0.5541
2024-06-03 10:56:33 [INFO]: Epoch 029 - training loss: 0.3242, validation loss: 0.5591
2024-06-03 10:56:43 [INFO]: Epoch 030 - training loss: 0.3293, validation loss: 0.5478
2024-06-03 10:56:53 [INFO]: Epoch 031 - training loss: 0.3182, validation loss: 0.5497
2024-06-03 10:57:02 [INFO]: Epoch 032 - training loss: 0.3166, validation loss: 0.5582
2024-06-03 10:57:13 [INFO]: Epoch 033 - training loss: 0.3185, validation loss: 0.5554
2024-06-03 10:57:23 [INFO]: Epoch 034 - training loss: 0.3177, validation loss: 0.5512
2024-06-03 10:57:33 [INFO]: Epoch 035 - training loss: 0.3096, validation loss: 0.5478
2024-06-03 10:57:43 [INFO]: Epoch 036 - training loss: 0.3054, validation loss: 0.5528
2024-06-03 10:57:52 [INFO]: Epoch 037 - training loss: 0.3042, validation loss: 0.5475
2024-06-03 10:58:02 [INFO]: Epoch 038 - training loss: 0.3018, validation loss: 0.5434
2024-06-03 10:58:12 [INFO]: Epoch 039 - training loss: 0.3024, validation loss: 0.5491
2024-06-03 10:58:22 [INFO]: Epoch 040 - training loss: 0.3022, validation loss: 0.5456
2024-06-03 10:58:32 [INFO]: Epoch 041 - training loss: 0.3023, validation loss: 0.5513
2024-06-03 10:58:42 [INFO]: Epoch 042 - training loss: 0.2964, validation loss: 0.5529
2024-06-03 10:58:52 [INFO]: Epoch 043 - training loss: 0.2956, validation loss: 0.5476
2024-06-03 10:59:02 [INFO]: Epoch 044 - training loss: 0.2926, validation loss: 0.5447
2024-06-03 10:59:12 [INFO]: Epoch 045 - training loss: 0.2895, validation loss: 0.5440
2024-06-03 10:59:21 [INFO]: Epoch 046 - training loss: 0.2891, validation loss: 0.5440
2024-06-03 10:59:30 [INFO]: Epoch 047 - training loss: 0.2905, validation loss: 0.5485
2024-06-03 10:59:40 [INFO]: Epoch 048 - training loss: 0.2870, validation loss: 0.5479
2024-06-03 10:59:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:59:40 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 10:59:41 [INFO]: Saved the model to results_block_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T105134/Crossformer.pypots
2024-06-03 10:59:45 [INFO]: Successfully saved to results_block_rate05/PeMS/Crossformer_PeMS/round_4/imputation.pkl
2024-06-03 10:59:45 [INFO]: Round4 - Crossformer on PeMS: MAE=0.4025, MSE=0.8071, MRE=0.4819
2024-06-03 10:59:45 [INFO]: Done! Final results:
Averaged Crossformer (12,645,238 params) on PeMS: MAE=0.4061 ± 0.0076829693235527675, MSE=0.8109 ± 0.006491266461143894, MRE=0.4862 ± 0.009199296029189468, average inference time=0.71
