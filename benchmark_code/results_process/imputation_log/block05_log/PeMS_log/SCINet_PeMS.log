2024-06-03 17:36:39 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 17:36:39 [INFO]: Using the given device: cuda:0
2024-06-03 17:36:39 [INFO]: Model files will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_0/20240603_T173639
2024-06-03 17:36:39 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_0/20240603_T173639/tensorboard
2024-06-03 17:36:46 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 17:36:57 [INFO]: Epoch 001 - training loss: 1.6248, validation loss: 1.3754
2024-06-03 17:37:00 [INFO]: Epoch 002 - training loss: 1.1032, validation loss: 1.1415
2024-06-03 17:37:04 [INFO]: Epoch 003 - training loss: 0.9502, validation loss: 1.0662
2024-06-03 17:37:07 [INFO]: Epoch 004 - training loss: 0.8784, validation loss: 1.0305
2024-06-03 17:37:10 [INFO]: Epoch 005 - training loss: 0.8188, validation loss: 1.0130
2024-06-03 17:37:13 [INFO]: Epoch 006 - training loss: 0.7720, validation loss: 0.9866
2024-06-03 17:37:16 [INFO]: Epoch 007 - training loss: 0.7283, validation loss: 0.9807
2024-06-03 17:37:20 [INFO]: Epoch 008 - training loss: 0.6828, validation loss: 0.9435
2024-06-03 17:37:23 [INFO]: Epoch 009 - training loss: 0.6523, validation loss: 0.9280
2024-06-03 17:37:26 [INFO]: Epoch 010 - training loss: 0.6232, validation loss: 0.9186
2024-06-03 17:37:29 [INFO]: Epoch 011 - training loss: 0.6081, validation loss: 0.9034
2024-06-03 17:37:33 [INFO]: Epoch 012 - training loss: 0.6001, validation loss: 0.9210
2024-06-03 17:37:36 [INFO]: Epoch 013 - training loss: 0.5947, validation loss: 0.8845
2024-06-03 17:37:39 [INFO]: Epoch 014 - training loss: 0.5879, validation loss: 0.8874
2024-06-03 17:37:42 [INFO]: Epoch 015 - training loss: 0.5799, validation loss: 0.8816
2024-06-03 17:37:45 [INFO]: Epoch 016 - training loss: 0.5724, validation loss: 0.8543
2024-06-03 17:37:49 [INFO]: Epoch 017 - training loss: 0.5731, validation loss: 0.8555
2024-06-03 17:37:52 [INFO]: Epoch 018 - training loss: 0.5702, validation loss: 0.8583
2024-06-03 17:37:55 [INFO]: Epoch 019 - training loss: 0.5623, validation loss: 0.8415
2024-06-03 17:37:58 [INFO]: Epoch 020 - training loss: 0.5603, validation loss: 0.8307
2024-06-03 17:38:01 [INFO]: Epoch 021 - training loss: 0.5590, validation loss: 0.8269
2024-06-03 17:38:05 [INFO]: Epoch 022 - training loss: 0.5546, validation loss: 0.8264
2024-06-03 17:38:08 [INFO]: Epoch 023 - training loss: 0.5539, validation loss: 0.8210
2024-06-03 17:38:11 [INFO]: Epoch 024 - training loss: 0.5526, validation loss: 0.8274
2024-06-03 17:38:14 [INFO]: Epoch 025 - training loss: 0.5463, validation loss: 0.8177
2024-06-03 17:38:17 [INFO]: Epoch 026 - training loss: 0.5475, validation loss: 0.8156
2024-06-03 17:38:21 [INFO]: Epoch 027 - training loss: 0.5438, validation loss: 0.8198
2024-06-03 17:38:24 [INFO]: Epoch 028 - training loss: 0.5451, validation loss: 0.8179
2024-06-03 17:38:27 [INFO]: Epoch 029 - training loss: 0.5484, validation loss: 0.8057
2024-06-03 17:38:30 [INFO]: Epoch 030 - training loss: 0.5411, validation loss: 0.8303
2024-06-03 17:38:33 [INFO]: Epoch 031 - training loss: 0.5442, validation loss: 0.7998
2024-06-03 17:38:37 [INFO]: Epoch 032 - training loss: 0.5439, validation loss: 0.7905
2024-06-03 17:38:40 [INFO]: Epoch 033 - training loss: 0.5401, validation loss: 0.7862
2024-06-03 17:38:43 [INFO]: Epoch 034 - training loss: 0.5420, validation loss: 0.7978
2024-06-03 17:38:46 [INFO]: Epoch 035 - training loss: 0.5377, validation loss: 0.7926
2024-06-03 17:38:50 [INFO]: Epoch 036 - training loss: 0.5391, validation loss: 0.7820
2024-06-03 17:38:53 [INFO]: Epoch 037 - training loss: 0.5375, validation loss: 0.7953
2024-06-03 17:38:56 [INFO]: Epoch 038 - training loss: 0.5322, validation loss: 0.7915
2024-06-03 17:38:59 [INFO]: Epoch 039 - training loss: 0.5418, validation loss: 0.7981
2024-06-03 17:39:02 [INFO]: Epoch 040 - training loss: 0.5329, validation loss: 0.7929
2024-06-03 17:39:06 [INFO]: Epoch 041 - training loss: 0.5330, validation loss: 0.7735
2024-06-03 17:39:09 [INFO]: Epoch 042 - training loss: 0.5316, validation loss: 0.7857
2024-06-03 17:39:12 [INFO]: Epoch 043 - training loss: 0.5328, validation loss: 0.7819
2024-06-03 17:39:15 [INFO]: Epoch 044 - training loss: 0.5335, validation loss: 0.7765
2024-06-03 17:39:19 [INFO]: Epoch 045 - training loss: 0.5297, validation loss: 0.7933
2024-06-03 17:39:22 [INFO]: Epoch 046 - training loss: 0.5371, validation loss: 0.7918
2024-06-03 17:39:25 [INFO]: Epoch 047 - training loss: 0.5317, validation loss: 0.7817
2024-06-03 17:39:28 [INFO]: Epoch 048 - training loss: 0.5311, validation loss: 0.7685
2024-06-03 17:39:31 [INFO]: Epoch 049 - training loss: 0.5311, validation loss: 0.7707
2024-06-03 17:39:35 [INFO]: Epoch 050 - training loss: 0.5312, validation loss: 0.7855
2024-06-03 17:39:38 [INFO]: Epoch 051 - training loss: 0.5330, validation loss: 0.7779
2024-06-03 17:39:41 [INFO]: Epoch 052 - training loss: 0.5288, validation loss: 0.7734
2024-06-03 17:39:44 [INFO]: Epoch 053 - training loss: 0.5280, validation loss: 0.7709
2024-06-03 17:39:48 [INFO]: Epoch 054 - training loss: 0.5324, validation loss: 0.7770
2024-06-03 17:39:51 [INFO]: Epoch 055 - training loss: 0.5309, validation loss: 0.7785
2024-06-03 17:39:54 [INFO]: Epoch 056 - training loss: 0.5296, validation loss: 0.7616
2024-06-03 17:39:57 [INFO]: Epoch 057 - training loss: 0.5283, validation loss: 0.7644
2024-06-03 17:40:01 [INFO]: Epoch 058 - training loss: 0.5310, validation loss: 0.7709
2024-06-03 17:40:04 [INFO]: Epoch 059 - training loss: 0.5274, validation loss: 0.7619
2024-06-03 17:40:07 [INFO]: Epoch 060 - training loss: 0.5314, validation loss: 0.7686
2024-06-03 17:40:10 [INFO]: Epoch 061 - training loss: 0.5282, validation loss: 0.7873
2024-06-03 17:40:13 [INFO]: Epoch 062 - training loss: 0.5287, validation loss: 0.7797
2024-06-03 17:40:17 [INFO]: Epoch 063 - training loss: 0.5305, validation loss: 0.7802
2024-06-03 17:40:20 [INFO]: Epoch 064 - training loss: 0.5270, validation loss: 0.7763
2024-06-03 17:40:23 [INFO]: Epoch 065 - training loss: 0.5236, validation loss: 0.7574
2024-06-03 17:40:26 [INFO]: Epoch 066 - training loss: 0.5234, validation loss: 0.7608
2024-06-03 17:40:30 [INFO]: Epoch 067 - training loss: 0.5262, validation loss: 0.7821
2024-06-03 17:40:33 [INFO]: Epoch 068 - training loss: 0.5231, validation loss: 0.7581
2024-06-03 17:40:36 [INFO]: Epoch 069 - training loss: 0.5247, validation loss: 0.7698
2024-06-03 17:40:39 [INFO]: Epoch 070 - training loss: 0.5241, validation loss: 0.7799
2024-06-03 17:40:43 [INFO]: Epoch 071 - training loss: 0.5238, validation loss: 0.7916
2024-06-03 17:40:46 [INFO]: Epoch 072 - training loss: 0.5270, validation loss: 0.7728
2024-06-03 17:40:49 [INFO]: Epoch 073 - training loss: 0.5251, validation loss: 0.7743
2024-06-03 17:40:52 [INFO]: Epoch 074 - training loss: 0.5214, validation loss: 0.7759
2024-06-03 17:40:56 [INFO]: Epoch 075 - training loss: 0.5222, validation loss: 0.7536
2024-06-03 17:40:59 [INFO]: Epoch 076 - training loss: 0.5261, validation loss: 0.7701
2024-06-03 17:41:02 [INFO]: Epoch 077 - training loss: 0.5272, validation loss: 0.7686
2024-06-03 17:41:05 [INFO]: Epoch 078 - training loss: 0.5233, validation loss: 0.7640
2024-06-03 17:41:08 [INFO]: Epoch 079 - training loss: 0.5259, validation loss: 0.7608
2024-06-03 17:41:12 [INFO]: Epoch 080 - training loss: 0.5249, validation loss: 0.7551
2024-06-03 17:41:15 [INFO]: Epoch 081 - training loss: 0.5214, validation loss: 0.7687
2024-06-03 17:41:18 [INFO]: Epoch 082 - training loss: 0.5244, validation loss: 0.7713
2024-06-03 17:41:21 [INFO]: Epoch 083 - training loss: 0.5268, validation loss: 0.7703
2024-06-03 17:41:25 [INFO]: Epoch 084 - training loss: 0.5237, validation loss: 0.7590
2024-06-03 17:41:28 [INFO]: Epoch 085 - training loss: 0.5269, validation loss: 0.7629
2024-06-03 17:41:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 17:41:28 [INFO]: Finished training. The best model is from epoch#75.
2024-06-03 17:41:34 [INFO]: Saved the model to results_block_rate05/PeMS/SCINet_PeMS/round_0/20240603_T173639/SCINet.pypots
2024-06-03 17:41:35 [INFO]: Successfully saved to results_block_rate05/PeMS/SCINet_PeMS/round_0/imputation.pkl
2024-06-03 17:41:35 [INFO]: Round0 - SCINet on PeMS: MAE=0.5849, MSE=1.1508, MRE=0.7003
2024-06-03 17:41:35 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 17:41:35 [INFO]: Using the given device: cuda:0
2024-06-03 17:41:35 [INFO]: Model files will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_1/20240603_T174135
2024-06-03 17:41:35 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_1/20240603_T174135/tensorboard
2024-06-03 17:41:41 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 17:41:45 [INFO]: Epoch 001 - training loss: 1.6018, validation loss: 1.2473
2024-06-03 17:41:48 [INFO]: Epoch 002 - training loss: 1.0450, validation loss: 1.1118
2024-06-03 17:41:51 [INFO]: Epoch 003 - training loss: 0.9068, validation loss: 1.0680
2024-06-03 17:41:54 [INFO]: Epoch 004 - training loss: 0.8412, validation loss: 1.0589
2024-06-03 17:41:57 [INFO]: Epoch 005 - training loss: 0.7907, validation loss: 1.0433
2024-06-03 17:42:01 [INFO]: Epoch 006 - training loss: 0.7461, validation loss: 1.0249
2024-06-03 17:42:04 [INFO]: Epoch 007 - training loss: 0.7143, validation loss: 1.0171
2024-06-03 17:42:07 [INFO]: Epoch 008 - training loss: 0.6845, validation loss: 1.0066
2024-06-03 17:42:10 [INFO]: Epoch 009 - training loss: 0.6628, validation loss: 1.0198
2024-06-03 17:42:13 [INFO]: Epoch 010 - training loss: 0.6505, validation loss: 0.9974
2024-06-03 17:42:17 [INFO]: Epoch 011 - training loss: 0.6353, validation loss: 1.0093
2024-06-03 17:42:20 [INFO]: Epoch 012 - training loss: 0.6234, validation loss: 0.9946
2024-06-03 17:42:23 [INFO]: Epoch 013 - training loss: 0.6078, validation loss: 0.9800
2024-06-03 17:42:26 [INFO]: Epoch 014 - training loss: 0.6057, validation loss: 0.9889
2024-06-03 17:42:30 [INFO]: Epoch 015 - training loss: 0.5946, validation loss: 0.9829
2024-06-03 17:42:33 [INFO]: Epoch 016 - training loss: 0.5901, validation loss: 0.9935
2024-06-03 17:42:36 [INFO]: Epoch 017 - training loss: 0.5825, validation loss: 0.9641
2024-06-03 17:42:39 [INFO]: Epoch 018 - training loss: 0.5835, validation loss: 0.9417
2024-06-03 17:42:42 [INFO]: Epoch 019 - training loss: 0.5771, validation loss: 0.9684
2024-06-03 17:42:46 [INFO]: Epoch 020 - training loss: 0.5746, validation loss: 0.9687
2024-06-03 17:42:49 [INFO]: Epoch 021 - training loss: 0.5756, validation loss: 0.9632
2024-06-03 17:42:52 [INFO]: Epoch 022 - training loss: 0.5699, validation loss: 0.9604
2024-06-03 17:42:55 [INFO]: Epoch 023 - training loss: 0.5667, validation loss: 0.9741
2024-06-03 17:42:59 [INFO]: Epoch 024 - training loss: 0.5685, validation loss: 0.9566
2024-06-03 17:43:02 [INFO]: Epoch 025 - training loss: 0.5634, validation loss: 0.9577
2024-06-03 17:43:05 [INFO]: Epoch 026 - training loss: 0.5678, validation loss: 0.9464
2024-06-03 17:43:08 [INFO]: Epoch 027 - training loss: 0.5630, validation loss: 0.9440
2024-06-03 17:43:11 [INFO]: Epoch 028 - training loss: 0.5575, validation loss: 0.9447
2024-06-03 17:43:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 17:43:11 [INFO]: Finished training. The best model is from epoch#18.
2024-06-03 17:43:17 [INFO]: Saved the model to results_block_rate05/PeMS/SCINet_PeMS/round_1/20240603_T174135/SCINet.pypots
2024-06-03 17:43:19 [INFO]: Successfully saved to results_block_rate05/PeMS/SCINet_PeMS/round_1/imputation.pkl
2024-06-03 17:43:19 [INFO]: Round1 - SCINet on PeMS: MAE=0.6762, MSE=1.3661, MRE=0.8096
2024-06-03 17:43:19 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 17:43:19 [INFO]: Using the given device: cuda:0
2024-06-03 17:43:19 [INFO]: Model files will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_2/20240603_T174319
2024-06-03 17:43:19 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_2/20240603_T174319/tensorboard
2024-06-03 17:43:25 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 17:43:28 [INFO]: Epoch 001 - training loss: 1.7258, validation loss: 1.3326
2024-06-03 17:43:31 [INFO]: Epoch 002 - training loss: 1.1058, validation loss: 1.1203
2024-06-03 17:43:34 [INFO]: Epoch 003 - training loss: 0.9427, validation loss: 1.0877
2024-06-03 17:43:38 [INFO]: Epoch 004 - training loss: 0.8695, validation loss: 1.0672
2024-06-03 17:43:41 [INFO]: Epoch 005 - training loss: 0.8286, validation loss: 1.0386
2024-06-03 17:43:44 [INFO]: Epoch 006 - training loss: 0.7862, validation loss: 1.0192
2024-06-03 17:43:47 [INFO]: Epoch 007 - training loss: 0.7521, validation loss: 1.0091
2024-06-03 17:43:51 [INFO]: Epoch 008 - training loss: 0.7212, validation loss: 0.9911
2024-06-03 17:43:54 [INFO]: Epoch 009 - training loss: 0.6925, validation loss: 0.9643
2024-06-03 17:43:57 [INFO]: Epoch 010 - training loss: 0.6670, validation loss: 0.9570
2024-06-03 17:44:00 [INFO]: Epoch 011 - training loss: 0.6502, validation loss: 0.9294
2024-06-03 17:44:04 [INFO]: Epoch 012 - training loss: 0.6316, validation loss: 0.9093
2024-06-03 17:44:07 [INFO]: Epoch 013 - training loss: 0.6120, validation loss: 0.8948
2024-06-03 17:44:10 [INFO]: Epoch 014 - training loss: 0.5922, validation loss: 0.8787
2024-06-03 17:44:13 [INFO]: Epoch 015 - training loss: 0.5898, validation loss: 0.8506
2024-06-03 17:44:16 [INFO]: Epoch 016 - training loss: 0.5820, validation loss: 0.8520
2024-06-03 17:44:20 [INFO]: Epoch 017 - training loss: 0.5690, validation loss: 0.8351
2024-06-03 17:44:23 [INFO]: Epoch 018 - training loss: 0.5651, validation loss: 0.8188
2024-06-03 17:44:26 [INFO]: Epoch 019 - training loss: 0.5572, validation loss: 0.8157
2024-06-03 17:44:29 [INFO]: Epoch 020 - training loss: 0.5507, validation loss: 0.8149
2024-06-03 17:44:33 [INFO]: Epoch 021 - training loss: 0.5465, validation loss: 0.8123
2024-06-03 17:44:36 [INFO]: Epoch 022 - training loss: 0.5484, validation loss: 0.8004
2024-06-03 17:44:39 [INFO]: Epoch 023 - training loss: 0.5452, validation loss: 0.7918
2024-06-03 17:44:42 [INFO]: Epoch 024 - training loss: 0.5374, validation loss: 0.7992
2024-06-03 17:44:46 [INFO]: Epoch 025 - training loss: 0.5409, validation loss: 0.7881
2024-06-03 17:44:49 [INFO]: Epoch 026 - training loss: 0.5379, validation loss: 0.7978
2024-06-03 17:44:52 [INFO]: Epoch 027 - training loss: 0.5319, validation loss: 0.7965
2024-06-03 17:44:55 [INFO]: Epoch 028 - training loss: 0.5322, validation loss: 0.7889
2024-06-03 17:44:59 [INFO]: Epoch 029 - training loss: 0.5301, validation loss: 0.7970
2024-06-03 17:45:02 [INFO]: Epoch 030 - training loss: 0.5307, validation loss: 0.7890
2024-06-03 17:45:05 [INFO]: Epoch 031 - training loss: 0.5296, validation loss: 0.7844
2024-06-03 17:45:08 [INFO]: Epoch 032 - training loss: 0.5317, validation loss: 0.7863
2024-06-03 17:45:11 [INFO]: Epoch 033 - training loss: 0.5282, validation loss: 0.7930
2024-06-03 17:45:15 [INFO]: Epoch 034 - training loss: 0.5304, validation loss: 0.7866
2024-06-03 17:45:18 [INFO]: Epoch 035 - training loss: 0.5278, validation loss: 0.7841
2024-06-03 17:45:21 [INFO]: Epoch 036 - training loss: 0.5254, validation loss: 0.7907
2024-06-03 17:45:24 [INFO]: Epoch 037 - training loss: 0.5278, validation loss: 0.7872
2024-06-03 17:45:28 [INFO]: Epoch 038 - training loss: 0.5256, validation loss: 0.7912
2024-06-03 17:45:31 [INFO]: Epoch 039 - training loss: 0.5228, validation loss: 0.7760
2024-06-03 17:45:34 [INFO]: Epoch 040 - training loss: 0.5250, validation loss: 0.7801
2024-06-03 17:45:37 [INFO]: Epoch 041 - training loss: 0.5216, validation loss: 0.7761
2024-06-03 17:45:41 [INFO]: Epoch 042 - training loss: 0.5226, validation loss: 0.7800
2024-06-03 17:45:44 [INFO]: Epoch 043 - training loss: 0.5206, validation loss: 0.7630
2024-06-03 17:45:47 [INFO]: Epoch 044 - training loss: 0.5215, validation loss: 0.7766
2024-06-03 17:45:50 [INFO]: Epoch 045 - training loss: 0.5190, validation loss: 0.7844
2024-06-03 17:45:53 [INFO]: Epoch 046 - training loss: 0.5200, validation loss: 0.7760
2024-06-03 17:45:57 [INFO]: Epoch 047 - training loss: 0.5221, validation loss: 0.7807
2024-06-03 17:46:00 [INFO]: Epoch 048 - training loss: 0.5250, validation loss: 0.7856
2024-06-03 17:46:03 [INFO]: Epoch 049 - training loss: 0.5181, validation loss: 0.7820
2024-06-03 17:46:06 [INFO]: Epoch 050 - training loss: 0.5200, validation loss: 0.7866
2024-06-03 17:46:10 [INFO]: Epoch 051 - training loss: 0.5188, validation loss: 0.7933
2024-06-03 17:46:13 [INFO]: Epoch 052 - training loss: 0.5162, validation loss: 0.8000
2024-06-03 17:46:16 [INFO]: Epoch 053 - training loss: 0.5215, validation loss: 0.7750
2024-06-03 17:46:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 17:46:16 [INFO]: Finished training. The best model is from epoch#43.
2024-06-03 17:46:22 [INFO]: Saved the model to results_block_rate05/PeMS/SCINet_PeMS/round_2/20240603_T174319/SCINet.pypots
2024-06-03 17:46:23 [INFO]: Successfully saved to results_block_rate05/PeMS/SCINet_PeMS/round_2/imputation.pkl
2024-06-03 17:46:23 [INFO]: Round2 - SCINet on PeMS: MAE=0.5863, MSE=1.1754, MRE=0.7020
2024-06-03 17:46:23 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 17:46:23 [INFO]: Using the given device: cuda:0
2024-06-03 17:46:23 [INFO]: Model files will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_3/20240603_T174623
2024-06-03 17:46:23 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_3/20240603_T174623/tensorboard
2024-06-03 17:46:29 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 17:46:32 [INFO]: Epoch 001 - training loss: 1.5581, validation loss: 1.1691
2024-06-03 17:46:36 [INFO]: Epoch 002 - training loss: 1.0134, validation loss: 1.0861
2024-06-03 17:46:39 [INFO]: Epoch 003 - training loss: 0.8716, validation loss: 1.0428
2024-06-03 17:46:42 [INFO]: Epoch 004 - training loss: 0.8094, validation loss: 0.9872
2024-06-03 17:46:45 [INFO]: Epoch 005 - training loss: 0.7722, validation loss: 0.9703
2024-06-03 17:46:48 [INFO]: Epoch 006 - training loss: 0.7396, validation loss: 0.9497
2024-06-03 17:46:52 [INFO]: Epoch 007 - training loss: 0.7089, validation loss: 0.9369
2024-06-03 17:46:55 [INFO]: Epoch 008 - training loss: 0.6910, validation loss: 0.9262
2024-06-03 17:46:58 [INFO]: Epoch 009 - training loss: 0.6699, validation loss: 0.9123
2024-06-03 17:47:01 [INFO]: Epoch 010 - training loss: 0.6523, validation loss: 0.9104
2024-06-03 17:47:05 [INFO]: Epoch 011 - training loss: 0.6324, validation loss: 0.9245
2024-06-03 17:47:08 [INFO]: Epoch 012 - training loss: 0.6221, validation loss: 0.9012
2024-06-03 17:47:11 [INFO]: Epoch 013 - training loss: 0.6105, validation loss: 0.8930
2024-06-03 17:47:14 [INFO]: Epoch 014 - training loss: 0.5994, validation loss: 0.9013
2024-06-03 17:47:17 [INFO]: Epoch 015 - training loss: 0.5910, validation loss: 0.9042
2024-06-03 17:47:21 [INFO]: Epoch 016 - training loss: 0.5852, validation loss: 0.8890
2024-06-03 17:47:24 [INFO]: Epoch 017 - training loss: 0.5790, validation loss: 0.8772
2024-06-03 17:47:27 [INFO]: Epoch 018 - training loss: 0.5745, validation loss: 0.8851
2024-06-03 17:47:30 [INFO]: Epoch 019 - training loss: 0.5680, validation loss: 0.8879
2024-06-03 17:47:34 [INFO]: Epoch 020 - training loss: 0.5710, validation loss: 0.8755
2024-06-03 17:47:37 [INFO]: Epoch 021 - training loss: 0.5658, validation loss: 0.8894
2024-06-03 17:47:40 [INFO]: Epoch 022 - training loss: 0.5611, validation loss: 0.8831
2024-06-03 17:47:43 [INFO]: Epoch 023 - training loss: 0.5606, validation loss: 0.8960
2024-06-03 17:47:46 [INFO]: Epoch 024 - training loss: 0.5622, validation loss: 0.8656
2024-06-03 17:47:50 [INFO]: Epoch 025 - training loss: 0.5595, validation loss: 0.8907
2024-06-03 17:47:53 [INFO]: Epoch 026 - training loss: 0.5589, validation loss: 0.8855
2024-06-03 17:47:56 [INFO]: Epoch 027 - training loss: 0.5609, validation loss: 0.8872
2024-06-03 17:47:59 [INFO]: Epoch 028 - training loss: 0.5564, validation loss: 0.8621
2024-06-03 17:48:03 [INFO]: Epoch 029 - training loss: 0.5508, validation loss: 0.8676
2024-06-03 17:48:06 [INFO]: Epoch 030 - training loss: 0.5534, validation loss: 0.8734
2024-06-03 17:48:09 [INFO]: Epoch 031 - training loss: 0.5506, validation loss: 0.8762
2024-06-03 17:48:12 [INFO]: Epoch 032 - training loss: 0.5480, validation loss: 0.8715
2024-06-03 17:48:15 [INFO]: Epoch 033 - training loss: 0.5452, validation loss: 0.8768
2024-06-03 17:48:19 [INFO]: Epoch 034 - training loss: 0.5466, validation loss: 0.8717
2024-06-03 17:48:22 [INFO]: Epoch 035 - training loss: 0.5519, validation loss: 0.8525
2024-06-03 17:48:25 [INFO]: Epoch 036 - training loss: 0.5480, validation loss: 0.8681
2024-06-03 17:48:28 [INFO]: Epoch 037 - training loss: 0.5500, validation loss: 0.8659
2024-06-03 17:48:32 [INFO]: Epoch 038 - training loss: 0.5480, validation loss: 0.8640
2024-06-03 17:48:35 [INFO]: Epoch 039 - training loss: 0.5456, validation loss: 0.8790
2024-06-03 17:48:38 [INFO]: Epoch 040 - training loss: 0.5422, validation loss: 0.8787
2024-06-03 17:48:41 [INFO]: Epoch 041 - training loss: 0.5436, validation loss: 0.8777
2024-06-03 17:48:44 [INFO]: Epoch 042 - training loss: 0.5464, validation loss: 0.8527
2024-06-03 17:48:48 [INFO]: Epoch 043 - training loss: 0.5484, validation loss: 0.8411
2024-06-03 17:48:51 [INFO]: Epoch 044 - training loss: 0.5432, validation loss: 0.8684
2024-06-03 17:48:54 [INFO]: Epoch 045 - training loss: 0.5422, validation loss: 0.8700
2024-06-03 17:48:57 [INFO]: Epoch 046 - training loss: 0.5421, validation loss: 0.8679
2024-06-03 17:49:01 [INFO]: Epoch 047 - training loss: 0.5422, validation loss: 0.8688
2024-06-03 17:49:04 [INFO]: Epoch 048 - training loss: 0.5413, validation loss: 0.8656
2024-06-03 17:49:07 [INFO]: Epoch 049 - training loss: 0.5404, validation loss: 0.8527
2024-06-03 17:49:10 [INFO]: Epoch 050 - training loss: 0.5430, validation loss: 0.8683
2024-06-03 17:49:14 [INFO]: Epoch 051 - training loss: 0.5435, validation loss: 0.8551
2024-06-03 17:49:17 [INFO]: Epoch 052 - training loss: 0.5446, validation loss: 0.8510
2024-06-03 17:49:20 [INFO]: Epoch 053 - training loss: 0.5442, validation loss: 0.8580
2024-06-03 17:49:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 17:49:20 [INFO]: Finished training. The best model is from epoch#43.
2024-06-03 17:49:26 [INFO]: Saved the model to results_block_rate05/PeMS/SCINet_PeMS/round_3/20240603_T174623/SCINet.pypots
2024-06-03 17:49:27 [INFO]: Successfully saved to results_block_rate05/PeMS/SCINet_PeMS/round_3/imputation.pkl
2024-06-03 17:49:27 [INFO]: Round3 - SCINet on PeMS: MAE=0.6319, MSE=1.2216, MRE=0.7566
2024-06-03 17:49:27 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 17:49:27 [INFO]: Using the given device: cuda:0
2024-06-03 17:49:27 [INFO]: Model files will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_4/20240603_T174927
2024-06-03 17:49:27 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/SCINet_PeMS/round_4/20240603_T174927/tensorboard
2024-06-03 17:49:33 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 17:49:36 [INFO]: Epoch 001 - training loss: 1.5995, validation loss: 1.2449
2024-06-03 17:49:40 [INFO]: Epoch 002 - training loss: 1.0506, validation loss: 1.1170
2024-06-03 17:49:43 [INFO]: Epoch 003 - training loss: 0.8838, validation loss: 1.0236
2024-06-03 17:49:46 [INFO]: Epoch 004 - training loss: 0.8138, validation loss: 0.9940
2024-06-03 17:49:49 [INFO]: Epoch 005 - training loss: 0.7638, validation loss: 0.9657
2024-06-03 17:49:52 [INFO]: Epoch 006 - training loss: 0.7178, validation loss: 0.9621
2024-06-03 17:49:56 [INFO]: Epoch 007 - training loss: 0.6926, validation loss: 0.9246
2024-06-03 17:49:59 [INFO]: Epoch 008 - training loss: 0.6629, validation loss: 0.8876
2024-06-03 17:50:02 [INFO]: Epoch 009 - training loss: 0.6458, validation loss: 0.8807
2024-06-03 17:50:05 [INFO]: Epoch 010 - training loss: 0.6240, validation loss: 0.8357
2024-06-03 17:50:09 [INFO]: Epoch 011 - training loss: 0.6049, validation loss: 0.8267
2024-06-03 17:50:12 [INFO]: Epoch 012 - training loss: 0.5908, validation loss: 0.8283
2024-06-03 17:50:15 [INFO]: Epoch 013 - training loss: 0.5812, validation loss: 0.7887
2024-06-03 17:50:18 [INFO]: Epoch 014 - training loss: 0.5747, validation loss: 0.7691
2024-06-03 17:50:21 [INFO]: Epoch 015 - training loss: 0.5707, validation loss: 0.7750
2024-06-03 17:50:25 [INFO]: Epoch 016 - training loss: 0.5610, validation loss: 0.7722
2024-06-03 17:50:28 [INFO]: Epoch 017 - training loss: 0.5563, validation loss: 0.7546
2024-06-03 17:50:31 [INFO]: Epoch 018 - training loss: 0.5566, validation loss: 0.7872
2024-06-03 17:50:34 [INFO]: Epoch 019 - training loss: 0.5566, validation loss: 0.7498
2024-06-03 17:50:38 [INFO]: Epoch 020 - training loss: 0.5563, validation loss: 0.7564
2024-06-03 17:50:41 [INFO]: Epoch 021 - training loss: 0.5506, validation loss: 0.7705
2024-06-03 17:50:44 [INFO]: Epoch 022 - training loss: 0.5514, validation loss: 0.7854
2024-06-03 17:50:47 [INFO]: Epoch 023 - training loss: 0.5465, validation loss: 0.7579
2024-06-03 17:50:51 [INFO]: Epoch 024 - training loss: 0.5486, validation loss: 0.7637
2024-06-03 17:50:54 [INFO]: Epoch 025 - training loss: 0.5460, validation loss: 0.7707
2024-06-03 17:50:57 [INFO]: Epoch 026 - training loss: 0.5453, validation loss: 0.7655
2024-06-03 17:51:00 [INFO]: Epoch 027 - training loss: 0.5421, validation loss: 0.7632
2024-06-03 17:51:03 [INFO]: Epoch 028 - training loss: 0.5439, validation loss: 0.7699
2024-06-03 17:51:07 [INFO]: Epoch 029 - training loss: 0.5425, validation loss: 0.7409
2024-06-03 17:51:10 [INFO]: Epoch 030 - training loss: 0.5453, validation loss: 0.7640
2024-06-03 17:51:13 [INFO]: Epoch 031 - training loss: 0.5395, validation loss: 0.7572
2024-06-03 17:51:16 [INFO]: Epoch 032 - training loss: 0.5398, validation loss: 0.7716
2024-06-03 17:51:20 [INFO]: Epoch 033 - training loss: 0.5397, validation loss: 0.7444
2024-06-03 17:51:23 [INFO]: Epoch 034 - training loss: 0.5390, validation loss: 0.7539
2024-06-03 17:51:26 [INFO]: Epoch 035 - training loss: 0.5428, validation loss: 0.7833
2024-06-03 17:51:29 [INFO]: Epoch 036 - training loss: 0.5414, validation loss: 0.7707
2024-06-03 17:51:32 [INFO]: Epoch 037 - training loss: 0.5380, validation loss: 0.7720
2024-06-03 17:51:36 [INFO]: Epoch 038 - training loss: 0.5365, validation loss: 0.7741
2024-06-03 17:51:39 [INFO]: Epoch 039 - training loss: 0.5406, validation loss: 0.7694
2024-06-03 17:51:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 17:51:39 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 17:51:45 [INFO]: Saved the model to results_block_rate05/PeMS/SCINet_PeMS/round_4/20240603_T174927/SCINet.pypots
2024-06-03 17:51:46 [INFO]: Successfully saved to results_block_rate05/PeMS/SCINet_PeMS/round_4/imputation.pkl
2024-06-03 17:51:46 [INFO]: Round4 - SCINet on PeMS: MAE=0.6145, MSE=1.1754, MRE=0.7358
2024-06-03 17:51:46 [INFO]: Done! Final results:
Averaged SCINet (1,143,027,230 params) on PeMS: MAE=0.6188 ± 0.0337313216396234, MSE=1.2178 ± 0.07758147376315905, MRE=0.7409 ± 0.040388604997736596, average inference time=0.27
