2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:55 [INFO]: Model files will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_0/20240603_T100955
2024-06-03 10:09:55 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_0/20240603_T100955/tensorboard
2024-06-03 10:09:59 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 346,318
2024-06-03 10:10:26 [INFO]: Epoch 001 - training loss: 0.9398, validation loss: 1.2752
2024-06-03 10:10:36 [INFO]: Epoch 002 - training loss: 0.7387, validation loss: 1.1778
2024-06-03 10:10:46 [INFO]: Epoch 003 - training loss: 0.6824, validation loss: 1.1470
2024-06-03 10:10:57 [INFO]: Epoch 004 - training loss: 0.6696, validation loss: 1.0994
2024-06-03 10:11:08 [INFO]: Epoch 005 - training loss: 0.6564, validation loss: 1.0883
2024-06-03 10:11:20 [INFO]: Epoch 006 - training loss: 0.6444, validation loss: 1.1099
2024-06-03 10:11:31 [INFO]: Epoch 007 - training loss: 0.6312, validation loss: 1.1201
2024-06-03 10:11:43 [INFO]: Epoch 008 - training loss: 0.6265, validation loss: 1.0780
2024-06-03 10:11:54 [INFO]: Epoch 009 - training loss: 0.6188, validation loss: 1.0796
2024-06-03 10:12:04 [INFO]: Epoch 010 - training loss: 0.6101, validation loss: 1.0803
2024-06-03 10:12:14 [INFO]: Epoch 011 - training loss: 0.6128, validation loss: 1.0716
2024-06-03 10:12:24 [INFO]: Epoch 012 - training loss: 0.6061, validation loss: 1.0759
2024-06-03 10:12:35 [INFO]: Epoch 013 - training loss: 0.5987, validation loss: 1.0622
2024-06-03 10:12:46 [INFO]: Epoch 014 - training loss: 0.5972, validation loss: 1.0777
2024-06-03 10:12:57 [INFO]: Epoch 015 - training loss: 0.5965, validation loss: 1.0712
2024-06-03 10:13:06 [INFO]: Epoch 016 - training loss: 0.5929, validation loss: 1.0867
2024-06-03 10:13:16 [INFO]: Epoch 017 - training loss: 0.5965, validation loss: 1.0485
2024-06-03 10:13:27 [INFO]: Epoch 018 - training loss: 0.5904, validation loss: 1.0490
2024-06-03 10:13:37 [INFO]: Epoch 019 - training loss: 0.5909, validation loss: 1.0645
2024-06-03 10:13:48 [INFO]: Epoch 020 - training loss: 0.5878, validation loss: 1.0686
2024-06-03 10:13:58 [INFO]: Epoch 021 - training loss: 0.5931, validation loss: 1.0485
2024-06-03 10:14:08 [INFO]: Epoch 022 - training loss: 0.5890, validation loss: 1.0558
2024-06-03 10:14:19 [INFO]: Epoch 023 - training loss: 0.5853, validation loss: 1.0653
2024-06-03 10:14:30 [INFO]: Epoch 024 - training loss: 0.5870, validation loss: 1.0476
2024-06-03 10:14:41 [INFO]: Epoch 025 - training loss: 0.5823, validation loss: 1.0575
2024-06-03 10:14:52 [INFO]: Epoch 026 - training loss: 0.5828, validation loss: 1.0719
2024-06-03 10:15:03 [INFO]: Epoch 027 - training loss: 0.5852, validation loss: 1.0581
2024-06-03 10:15:13 [INFO]: Epoch 028 - training loss: 0.5818, validation loss: 1.0668
2024-06-03 10:15:24 [INFO]: Epoch 029 - training loss: 0.5839, validation loss: 1.0494
2024-06-03 10:15:33 [INFO]: Epoch 030 - training loss: 0.5810, validation loss: 1.0514
2024-06-03 10:15:44 [INFO]: Epoch 031 - training loss: 0.5824, validation loss: 1.0501
2024-06-03 10:15:54 [INFO]: Epoch 032 - training loss: 0.5816, validation loss: 1.0620
2024-06-03 10:16:04 [INFO]: Epoch 033 - training loss: 0.5789, validation loss: 1.0608
2024-06-03 10:16:15 [INFO]: Epoch 034 - training loss: 0.5748, validation loss: 1.0708
2024-06-03 10:16:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:16:15 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 10:16:15 [INFO]: Saved the model to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_0/20240603_T100955/NonstationaryTransformer.pypots
2024-06-03 10:16:20 [INFO]: Successfully saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_0/imputation.pkl
2024-06-03 10:16:20 [INFO]: Round0 - NonstationaryTransformer on PeMS: MAE=0.6839, MSE=1.3727, MRE=0.8189
2024-06-03 10:16:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:16:20 [INFO]: Using the given device: cuda:0
2024-06-03 10:16:20 [INFO]: Model files will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_1/20240603_T101620
2024-06-03 10:16:20 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_1/20240603_T101620/tensorboard
2024-06-03 10:16:21 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 346,318
2024-06-03 10:16:33 [INFO]: Epoch 001 - training loss: 0.9360, validation loss: 1.2705
2024-06-03 10:16:43 [INFO]: Epoch 002 - training loss: 0.7325, validation loss: 1.1418
2024-06-03 10:16:54 [INFO]: Epoch 003 - training loss: 0.6829, validation loss: 1.0858
2024-06-03 10:17:05 [INFO]: Epoch 004 - training loss: 0.6678, validation loss: 1.1115
2024-06-03 10:17:15 [INFO]: Epoch 005 - training loss: 0.6482, validation loss: 1.1102
2024-06-03 10:17:26 [INFO]: Epoch 006 - training loss: 0.6416, validation loss: 1.0915
2024-06-03 10:17:37 [INFO]: Epoch 007 - training loss: 0.6250, validation loss: 1.1067
2024-06-03 10:17:47 [INFO]: Epoch 008 - training loss: 0.6241, validation loss: 1.0870
2024-06-03 10:17:58 [INFO]: Epoch 009 - training loss: 0.6205, validation loss: 1.0775
2024-06-03 10:18:08 [INFO]: Epoch 010 - training loss: 0.6104, validation loss: 1.0981
2024-06-03 10:18:19 [INFO]: Epoch 011 - training loss: 0.6061, validation loss: 1.0936
2024-06-03 10:18:29 [INFO]: Epoch 012 - training loss: 0.6008, validation loss: 1.0859
2024-06-03 10:18:39 [INFO]: Epoch 013 - training loss: 0.5987, validation loss: 1.0860
2024-06-03 10:18:48 [INFO]: Epoch 014 - training loss: 0.5947, validation loss: 1.0861
2024-06-03 10:18:59 [INFO]: Epoch 015 - training loss: 0.5963, validation loss: 1.0813
2024-06-03 10:19:10 [INFO]: Epoch 016 - training loss: 0.5969, validation loss: 1.0958
2024-06-03 10:19:20 [INFO]: Epoch 017 - training loss: 0.5962, validation loss: 1.0860
2024-06-03 10:19:30 [INFO]: Epoch 018 - training loss: 0.5966, validation loss: 1.0746
2024-06-03 10:19:41 [INFO]: Epoch 019 - training loss: 0.5922, validation loss: 1.0644
2024-06-03 10:19:52 [INFO]: Epoch 020 - training loss: 0.5890, validation loss: 1.0832
2024-06-03 10:20:03 [INFO]: Epoch 021 - training loss: 0.5879, validation loss: 1.0730
2024-06-03 10:20:13 [INFO]: Epoch 022 - training loss: 0.5862, validation loss: 1.0902
2024-06-03 10:20:23 [INFO]: Epoch 023 - training loss: 0.5889, validation loss: 1.0711
2024-06-03 10:20:33 [INFO]: Epoch 024 - training loss: 0.5879, validation loss: 1.0825
2024-06-03 10:20:44 [INFO]: Epoch 025 - training loss: 0.5810, validation loss: 1.0935
2024-06-03 10:20:55 [INFO]: Epoch 026 - training loss: 0.5857, validation loss: 1.0874
2024-06-03 10:21:05 [INFO]: Epoch 027 - training loss: 0.5813, validation loss: 1.0980
2024-06-03 10:21:16 [INFO]: Epoch 028 - training loss: 0.5819, validation loss: 1.0766
2024-06-03 10:21:26 [INFO]: Epoch 029 - training loss: 0.5833, validation loss: 1.0842
2024-06-03 10:21:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:26 [INFO]: Finished training. The best model is from epoch#19.
2024-06-03 10:21:26 [INFO]: Saved the model to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_1/20240603_T101620/NonstationaryTransformer.pypots
2024-06-03 10:21:31 [INFO]: Successfully saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_1/imputation.pkl
2024-06-03 10:21:31 [INFO]: Round1 - NonstationaryTransformer on PeMS: MAE=0.6876, MSE=1.4186, MRE=0.8233
2024-06-03 10:21:31 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:21:31 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:31 [INFO]: Model files will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_2/20240603_T102131
2024-06-03 10:21:31 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_2/20240603_T102131/tensorboard
2024-06-03 10:21:32 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 346,318
2024-06-03 10:21:43 [INFO]: Epoch 001 - training loss: 0.9370, validation loss: 1.3383
2024-06-03 10:21:53 [INFO]: Epoch 002 - training loss: 0.7493, validation loss: 1.1867
2024-06-03 10:22:03 [INFO]: Epoch 003 - training loss: 0.6948, validation loss: 1.1157
2024-06-03 10:22:13 [INFO]: Epoch 004 - training loss: 0.6733, validation loss: 1.1328
2024-06-03 10:22:24 [INFO]: Epoch 005 - training loss: 0.6620, validation loss: 1.1109
2024-06-03 10:22:35 [INFO]: Epoch 006 - training loss: 0.6446, validation loss: 1.1609
2024-06-03 10:22:46 [INFO]: Epoch 007 - training loss: 0.6434, validation loss: 1.0795
2024-06-03 10:22:56 [INFO]: Epoch 008 - training loss: 0.6294, validation loss: 1.1079
2024-06-03 10:23:07 [INFO]: Epoch 009 - training loss: 0.6171, validation loss: 1.0928
2024-06-03 10:23:18 [INFO]: Epoch 010 - training loss: 0.6158, validation loss: 1.0783
2024-06-03 10:23:28 [INFO]: Epoch 011 - training loss: 0.6104, validation loss: 1.0561
2024-06-03 10:23:37 [INFO]: Epoch 012 - training loss: 0.6084, validation loss: 1.0676
2024-06-03 10:23:47 [INFO]: Epoch 013 - training loss: 0.6004, validation loss: 1.0636
2024-06-03 10:23:58 [INFO]: Epoch 014 - training loss: 0.6062, validation loss: 1.0652
2024-06-03 10:24:09 [INFO]: Epoch 015 - training loss: 0.5953, validation loss: 1.0648
2024-06-03 10:24:19 [INFO]: Epoch 016 - training loss: 0.5987, validation loss: 1.0527
2024-06-03 10:24:29 [INFO]: Epoch 017 - training loss: 0.6002, validation loss: 1.0666
2024-06-03 10:24:40 [INFO]: Epoch 018 - training loss: 0.5954, validation loss: 1.0586
2024-06-03 10:24:51 [INFO]: Epoch 019 - training loss: 0.5908, validation loss: 1.0708
2024-06-03 10:25:01 [INFO]: Epoch 020 - training loss: 0.5914, validation loss: 1.0568
2024-06-03 10:25:11 [INFO]: Epoch 021 - training loss: 0.5850, validation loss: 1.0573
2024-06-03 10:25:20 [INFO]: Epoch 022 - training loss: 0.5888, validation loss: 1.0614
2024-06-03 10:25:29 [INFO]: Epoch 023 - training loss: 0.5855, validation loss: 1.0489
2024-06-03 10:25:40 [INFO]: Epoch 024 - training loss: 0.5861, validation loss: 1.0471
2024-06-03 10:25:50 [INFO]: Epoch 025 - training loss: 0.5888, validation loss: 1.0750
2024-06-03 10:26:00 [INFO]: Epoch 026 - training loss: 0.5833, validation loss: 1.0573
2024-06-03 10:26:10 [INFO]: Epoch 027 - training loss: 0.5836, validation loss: 1.0780
2024-06-03 10:26:20 [INFO]: Epoch 028 - training loss: 0.5828, validation loss: 1.0461
2024-06-03 10:26:31 [INFO]: Epoch 029 - training loss: 0.5811, validation loss: 1.0693
2024-06-03 10:26:41 [INFO]: Epoch 030 - training loss: 0.5802, validation loss: 1.0523
2024-06-03 10:26:51 [INFO]: Epoch 031 - training loss: 0.5850, validation loss: 1.0824
2024-06-03 10:27:00 [INFO]: Epoch 032 - training loss: 0.5820, validation loss: 1.0590
2024-06-03 10:27:10 [INFO]: Epoch 033 - training loss: 0.5832, validation loss: 1.0603
2024-06-03 10:27:21 [INFO]: Epoch 034 - training loss: 0.5848, validation loss: 1.0561
2024-06-03 10:27:31 [INFO]: Epoch 035 - training loss: 0.5781, validation loss: 1.0736
2024-06-03 10:27:41 [INFO]: Epoch 036 - training loss: 0.5794, validation loss: 1.0521
2024-06-03 10:27:51 [INFO]: Epoch 037 - training loss: 0.5795, validation loss: 1.0583
2024-06-03 10:28:02 [INFO]: Epoch 038 - training loss: 0.5777, validation loss: 1.0700
2024-06-03 10:28:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:28:02 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 10:28:02 [INFO]: Saved the model to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_2/20240603_T102131/NonstationaryTransformer.pypots
2024-06-03 10:28:07 [INFO]: Successfully saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_2/imputation.pkl
2024-06-03 10:28:07 [INFO]: Round2 - NonstationaryTransformer on PeMS: MAE=0.6957, MSE=1.3786, MRE=0.8330
2024-06-03 10:28:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:28:07 [INFO]: Using the given device: cuda:0
2024-06-03 10:28:07 [INFO]: Model files will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_3/20240603_T102807
2024-06-03 10:28:07 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_3/20240603_T102807/tensorboard
2024-06-03 10:28:08 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 346,318
2024-06-03 10:28:18 [INFO]: Epoch 001 - training loss: 0.9420, validation loss: 1.2604
2024-06-03 10:28:28 [INFO]: Epoch 002 - training loss: 0.7372, validation loss: 1.1365
2024-06-03 10:28:37 [INFO]: Epoch 003 - training loss: 0.6839, validation loss: 1.1048
2024-06-03 10:28:47 [INFO]: Epoch 004 - training loss: 0.6647, validation loss: 1.0864
2024-06-03 10:28:58 [INFO]: Epoch 005 - training loss: 0.6534, validation loss: 1.0881
2024-06-03 10:29:08 [INFO]: Epoch 006 - training loss: 0.6366, validation loss: 1.1038
2024-06-03 10:29:18 [INFO]: Epoch 007 - training loss: 0.6337, validation loss: 1.0775
2024-06-03 10:29:28 [INFO]: Epoch 008 - training loss: 0.6217, validation loss: 1.0760
2024-06-03 10:29:39 [INFO]: Epoch 009 - training loss: 0.6169, validation loss: 1.0790
2024-06-03 10:29:49 [INFO]: Epoch 010 - training loss: 0.6120, validation loss: 1.0875
2024-06-03 10:29:59 [INFO]: Epoch 011 - training loss: 0.6072, validation loss: 1.0661
2024-06-03 10:30:08 [INFO]: Epoch 012 - training loss: 0.6005, validation loss: 1.0618
2024-06-03 10:30:17 [INFO]: Epoch 013 - training loss: 0.5988, validation loss: 1.0491
2024-06-03 10:30:27 [INFO]: Epoch 014 - training loss: 0.5997, validation loss: 1.0742
2024-06-03 10:30:37 [INFO]: Epoch 015 - training loss: 0.5935, validation loss: 1.0789
2024-06-03 10:30:47 [INFO]: Epoch 016 - training loss: 0.5943, validation loss: 1.0531
2024-06-03 10:30:57 [INFO]: Epoch 017 - training loss: 0.5959, validation loss: 1.0907
2024-06-03 10:31:08 [INFO]: Epoch 018 - training loss: 0.5949, validation loss: 1.0622
2024-06-03 10:31:18 [INFO]: Epoch 019 - training loss: 0.5868, validation loss: 1.0735
2024-06-03 10:31:28 [INFO]: Epoch 020 - training loss: 0.5947, validation loss: 1.0709
2024-06-03 10:31:38 [INFO]: Epoch 021 - training loss: 0.5874, validation loss: 1.0729
2024-06-03 10:31:48 [INFO]: Epoch 022 - training loss: 0.5869, validation loss: 1.0589
2024-06-03 10:31:57 [INFO]: Epoch 023 - training loss: 0.5900, validation loss: 1.0754
2024-06-03 10:31:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:31:57 [INFO]: Finished training. The best model is from epoch#13.
2024-06-03 10:31:57 [INFO]: Saved the model to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_3/20240603_T102807/NonstationaryTransformer.pypots
2024-06-03 10:32:02 [INFO]: Successfully saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_3/imputation.pkl
2024-06-03 10:32:02 [INFO]: Round3 - NonstationaryTransformer on PeMS: MAE=0.6916, MSE=1.3710, MRE=0.8281
2024-06-03 10:32:02 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:32:02 [INFO]: Using the given device: cuda:0
2024-06-03 10:32:02 [INFO]: Model files will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_4/20240603_T103202
2024-06-03 10:32:02 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_4/20240603_T103202/tensorboard
2024-06-03 10:32:03 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 346,318
2024-06-03 10:32:13 [INFO]: Epoch 001 - training loss: 0.9360, validation loss: 1.2992
2024-06-03 10:32:23 [INFO]: Epoch 002 - training loss: 0.7357, validation loss: 1.1842
2024-06-03 10:32:33 [INFO]: Epoch 003 - training loss: 0.6877, validation loss: 1.1307
2024-06-03 10:32:42 [INFO]: Epoch 004 - training loss: 0.6735, validation loss: 1.1114
2024-06-03 10:32:52 [INFO]: Epoch 005 - training loss: 0.6583, validation loss: 1.1089
2024-06-03 10:33:01 [INFO]: Epoch 006 - training loss: 0.6385, validation loss: 1.1056
2024-06-03 10:33:11 [INFO]: Epoch 007 - training loss: 0.6341, validation loss: 1.0861
2024-06-03 10:33:20 [INFO]: Epoch 008 - training loss: 0.6228, validation loss: 1.1106
2024-06-03 10:33:29 [INFO]: Epoch 009 - training loss: 0.6200, validation loss: 1.0857
2024-06-03 10:33:39 [INFO]: Epoch 010 - training loss: 0.6165, validation loss: 1.0604
2024-06-03 10:33:49 [INFO]: Epoch 011 - training loss: 0.6097, validation loss: 1.0849
2024-06-03 10:33:59 [INFO]: Epoch 012 - training loss: 0.6093, validation loss: 1.0730
2024-06-03 10:34:09 [INFO]: Epoch 013 - training loss: 0.6016, validation loss: 1.1077
2024-06-03 10:34:19 [INFO]: Epoch 014 - training loss: 0.5954, validation loss: 1.0647
2024-06-03 10:34:29 [INFO]: Epoch 015 - training loss: 0.5946, validation loss: 1.0761
2024-06-03 10:34:39 [INFO]: Epoch 016 - training loss: 0.5915, validation loss: 1.0702
2024-06-03 10:34:48 [INFO]: Epoch 017 - training loss: 0.5917, validation loss: 1.0698
2024-06-03 10:34:57 [INFO]: Epoch 018 - training loss: 0.5905, validation loss: 1.0711
2024-06-03 10:35:05 [INFO]: Epoch 019 - training loss: 0.5882, validation loss: 1.0854
2024-06-03 10:35:14 [INFO]: Epoch 020 - training loss: 0.5872, validation loss: 1.0726
2024-06-03 10:35:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:35:14 [INFO]: Finished training. The best model is from epoch#10.
2024-06-03 10:35:14 [INFO]: Saved the model to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_4/20240603_T103202/NonstationaryTransformer.pypots
2024-06-03 10:35:19 [INFO]: Successfully saved to results_block_rate05/PeMS/NonstationaryTransformer_PeMS/round_4/imputation.pkl
2024-06-03 10:35:19 [INFO]: Round4 - NonstationaryTransformer on PeMS: MAE=0.6910, MSE=1.3833, MRE=0.8273
2024-06-03 10:35:19 [INFO]: Done! Final results:
Averaged NonstationaryTransformer (346,318 params) on PeMS: MAE=0.6900 ± 0.0039631934057696785, MSE=1.3848 ± 0.017424605315659085, MRE=0.8261 ± 0.0047453774478624835, average inference time=0.75
