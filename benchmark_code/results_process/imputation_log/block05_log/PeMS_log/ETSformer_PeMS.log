2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:54 [INFO]: Model files will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T100954
2024-06-03 10:09:54 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T100954/tensorboard
2024-06-03 10:09:59 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 10:10:38 [INFO]: Epoch 001 - training loss: 1.6569, validation loss: 1.0252
2024-06-03 10:11:03 [INFO]: Epoch 002 - training loss: 0.8093, validation loss: 0.7454
2024-06-03 10:11:31 [INFO]: Epoch 003 - training loss: 0.6649, validation loss: 0.6855
2024-06-03 10:11:57 [INFO]: Epoch 004 - training loss: 0.6012, validation loss: 0.6448
2024-06-03 10:12:20 [INFO]: Epoch 005 - training loss: 0.5497, validation loss: 0.6192
2024-06-03 10:12:45 [INFO]: Epoch 006 - training loss: 0.5236, validation loss: 0.6122
2024-06-03 10:13:09 [INFO]: Epoch 007 - training loss: 0.5122, validation loss: 0.6028
2024-06-03 10:13:34 [INFO]: Epoch 008 - training loss: 0.4962, validation loss: 0.6023
2024-06-03 10:13:57 [INFO]: Epoch 009 - training loss: 0.4866, validation loss: 0.5882
2024-06-03 10:14:20 [INFO]: Epoch 010 - training loss: 0.4782, validation loss: 0.5883
2024-06-03 10:14:46 [INFO]: Epoch 011 - training loss: 0.4728, validation loss: 0.5834
2024-06-03 10:15:11 [INFO]: Epoch 012 - training loss: 0.4672, validation loss: 0.5804
2024-06-03 10:15:34 [INFO]: Epoch 013 - training loss: 0.4576, validation loss: 0.5765
2024-06-03 10:15:58 [INFO]: Epoch 014 - training loss: 0.4491, validation loss: 0.5699
2024-06-03 10:16:23 [INFO]: Epoch 015 - training loss: 0.4470, validation loss: 0.5720
2024-06-03 10:16:48 [INFO]: Epoch 016 - training loss: 0.4405, validation loss: 0.5778
2024-06-03 10:17:10 [INFO]: Epoch 017 - training loss: 0.4388, validation loss: 0.5755
2024-06-03 10:17:35 [INFO]: Epoch 018 - training loss: 0.4329, validation loss: 0.5694
2024-06-03 10:18:00 [INFO]: Epoch 019 - training loss: 0.4259, validation loss: 0.5672
2024-06-03 10:18:25 [INFO]: Epoch 020 - training loss: 0.4255, validation loss: 0.5678
2024-06-03 10:18:48 [INFO]: Epoch 021 - training loss: 0.4183, validation loss: 0.5640
2024-06-03 10:19:11 [INFO]: Epoch 022 - training loss: 0.4198, validation loss: 0.5613
2024-06-03 10:19:36 [INFO]: Epoch 023 - training loss: 0.4151, validation loss: 0.5656
2024-06-03 10:20:01 [INFO]: Epoch 024 - training loss: 0.4110, validation loss: 0.5546
2024-06-03 10:20:24 [INFO]: Epoch 025 - training loss: 0.4060, validation loss: 0.5567
2024-06-03 10:20:48 [INFO]: Epoch 026 - training loss: 0.4026, validation loss: 0.5598
2024-06-03 10:21:14 [INFO]: Epoch 027 - training loss: 0.4064, validation loss: 0.5624
2024-06-03 10:21:40 [INFO]: Epoch 028 - training loss: 0.4067, validation loss: 0.5600
2024-06-03 10:22:02 [INFO]: Epoch 029 - training loss: 0.4096, validation loss: 0.5593
2024-06-03 10:22:25 [INFO]: Epoch 030 - training loss: 0.4034, validation loss: 0.5555
2024-06-03 10:22:51 [INFO]: Epoch 031 - training loss: 0.3997, validation loss: 0.5544
2024-06-03 10:23:17 [INFO]: Epoch 032 - training loss: 0.3987, validation loss: 0.5600
2024-06-03 10:23:38 [INFO]: Epoch 033 - training loss: 0.3975, validation loss: 0.5544
2024-06-03 10:24:03 [INFO]: Epoch 034 - training loss: 0.3927, validation loss: 0.5531
2024-06-03 10:24:30 [INFO]: Epoch 035 - training loss: 0.3988, validation loss: 0.5561
2024-06-03 10:24:53 [INFO]: Epoch 036 - training loss: 0.4014, validation loss: 0.5496
2024-06-03 10:25:15 [INFO]: Epoch 037 - training loss: 0.3946, validation loss: 0.5485
2024-06-03 10:25:38 [INFO]: Epoch 038 - training loss: 0.3924, validation loss: 0.5553
2024-06-03 10:26:01 [INFO]: Epoch 039 - training loss: 0.3971, validation loss: 0.5485
2024-06-03 10:26:24 [INFO]: Epoch 040 - training loss: 0.3938, validation loss: 0.5484
2024-06-03 10:26:47 [INFO]: Epoch 041 - training loss: 0.3960, validation loss: 0.5453
2024-06-03 10:27:09 [INFO]: Epoch 042 - training loss: 0.3916, validation loss: 0.5516
2024-06-03 10:27:34 [INFO]: Epoch 043 - training loss: 0.3891, validation loss: 0.5493
2024-06-03 10:27:58 [INFO]: Epoch 044 - training loss: 0.3898, validation loss: 0.5486
2024-06-03 10:28:22 [INFO]: Epoch 045 - training loss: 0.3891, validation loss: 0.5465
2024-06-03 10:28:42 [INFO]: Epoch 046 - training loss: 0.3864, validation loss: 0.5526
2024-06-03 10:29:05 [INFO]: Epoch 047 - training loss: 0.3895, validation loss: 0.5476
2024-06-03 10:29:29 [INFO]: Epoch 048 - training loss: 0.3874, validation loss: 0.5440
2024-06-03 10:29:53 [INFO]: Epoch 049 - training loss: 0.3835, validation loss: 0.5477
2024-06-03 10:30:15 [INFO]: Epoch 050 - training loss: 0.3916, validation loss: 0.5510
2024-06-03 10:30:38 [INFO]: Epoch 051 - training loss: 0.3895, validation loss: 0.5467
2024-06-03 10:31:03 [INFO]: Epoch 052 - training loss: 0.3893, validation loss: 0.5452
2024-06-03 10:31:27 [INFO]: Epoch 053 - training loss: 0.3894, validation loss: 0.5477
2024-06-03 10:31:50 [INFO]: Epoch 054 - training loss: 0.3868, validation loss: 0.5421
2024-06-03 10:32:13 [INFO]: Epoch 055 - training loss: 0.3860, validation loss: 0.5440
2024-06-03 10:32:35 [INFO]: Epoch 056 - training loss: 0.3835, validation loss: 0.5487
2024-06-03 10:32:59 [INFO]: Epoch 057 - training loss: 0.3840, validation loss: 0.5404
2024-06-03 10:33:20 [INFO]: Epoch 058 - training loss: 0.3853, validation loss: 0.5434
2024-06-03 10:33:41 [INFO]: Epoch 059 - training loss: 0.3856, validation loss: 0.5445
2024-06-03 10:34:03 [INFO]: Epoch 060 - training loss: 0.3838, validation loss: 0.5392
2024-06-03 10:34:26 [INFO]: Epoch 061 - training loss: 0.3816, validation loss: 0.5445
2024-06-03 10:34:49 [INFO]: Epoch 062 - training loss: 0.3825, validation loss: 0.5408
2024-06-03 10:35:09 [INFO]: Epoch 063 - training loss: 0.3844, validation loss: 0.5402
2024-06-03 10:35:33 [INFO]: Epoch 064 - training loss: 0.3813, validation loss: 0.5420
2024-06-03 10:35:56 [INFO]: Epoch 065 - training loss: 0.3845, validation loss: 0.5444
2024-06-03 10:36:18 [INFO]: Epoch 066 - training loss: 0.3840, validation loss: 0.5422
2024-06-03 10:36:39 [INFO]: Epoch 067 - training loss: 0.3846, validation loss: 0.5389
2024-06-03 10:37:00 [INFO]: Epoch 068 - training loss: 0.3875, validation loss: 0.5369
2024-06-03 10:37:21 [INFO]: Epoch 069 - training loss: 0.3809, validation loss: 0.5364
2024-06-03 10:37:44 [INFO]: Epoch 070 - training loss: 0.3794, validation loss: 0.5458
2024-06-03 10:38:06 [INFO]: Epoch 071 - training loss: 0.3854, validation loss: 0.5375
2024-06-03 10:38:26 [INFO]: Epoch 072 - training loss: 0.3850, validation loss: 0.5370
2024-06-03 10:38:49 [INFO]: Epoch 073 - training loss: 0.3823, validation loss: 0.5376
2024-06-03 10:39:12 [INFO]: Epoch 074 - training loss: 0.3782, validation loss: 0.5399
2024-06-03 10:39:34 [INFO]: Epoch 075 - training loss: 0.3846, validation loss: 0.5363
2024-06-03 10:39:55 [INFO]: Epoch 076 - training loss: 0.3861, validation loss: 0.5459
2024-06-03 10:40:15 [INFO]: Epoch 077 - training loss: 0.3896, validation loss: 0.5420
2024-06-03 10:40:38 [INFO]: Epoch 078 - training loss: 0.3901, validation loss: 0.5380
2024-06-03 10:41:00 [INFO]: Epoch 079 - training loss: 0.3890, validation loss: 0.5375
2024-06-03 10:41:22 [INFO]: Epoch 080 - training loss: 0.3905, validation loss: 0.5415
2024-06-03 10:41:42 [INFO]: Epoch 081 - training loss: 0.4035, validation loss: 0.5385
2024-06-03 10:42:05 [INFO]: Epoch 082 - training loss: 0.4884, validation loss: 0.5707
2024-06-03 10:42:27 [INFO]: Epoch 083 - training loss: 1.4237, validation loss: 2.5317
2024-06-03 10:42:48 [INFO]: Epoch 084 - training loss: 4.4175, validation loss: 21.4316
2024-06-03 10:43:08 [INFO]: Epoch 085 - training loss: 3.5148, validation loss: 6.2259
2024-06-03 10:43:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:43:08 [INFO]: Finished training. The best model is from epoch#75.
2024-06-03 10:43:09 [INFO]: Saved the model to results_block_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T100954/ETSformer.pypots
2024-06-03 10:43:25 [INFO]: Successfully saved to results_block_rate05/PeMS/ETSformer_PeMS/round_0/imputation.pkl
2024-06-03 10:43:25 [INFO]: Round0 - ETSformer on PeMS: MAE=2.0151, MSE=7.2486, MRE=2.4129
2024-06-03 10:43:25 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:43:25 [INFO]: Using the given device: cuda:0
2024-06-03 10:43:25 [INFO]: Model files will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T104325
2024-06-03 10:43:25 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T104325/tensorboard
2024-06-03 10:43:26 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 10:43:48 [INFO]: Epoch 001 - training loss: 1.8831, validation loss: 1.0390
2024-06-03 10:44:09 [INFO]: Epoch 002 - training loss: 0.9119, validation loss: 0.7565
2024-06-03 10:44:30 [INFO]: Epoch 003 - training loss: 0.7228, validation loss: 0.6810
2024-06-03 10:44:51 [INFO]: Epoch 004 - training loss: 0.6370, validation loss: 0.6486
2024-06-03 10:45:09 [INFO]: Epoch 005 - training loss: 0.5782, validation loss: 0.6204
2024-06-03 10:45:28 [INFO]: Epoch 006 - training loss: 0.5468, validation loss: 0.6096
2024-06-03 10:45:48 [INFO]: Epoch 007 - training loss: 0.5314, validation loss: 0.5983
2024-06-03 10:46:07 [INFO]: Epoch 008 - training loss: 0.5253, validation loss: 0.5953
2024-06-03 10:46:26 [INFO]: Epoch 009 - training loss: 0.5058, validation loss: 0.5946
2024-06-03 10:46:44 [INFO]: Epoch 010 - training loss: 0.4878, validation loss: 0.5819
2024-06-03 10:47:04 [INFO]: Epoch 011 - training loss: 0.4815, validation loss: 0.5817
2024-06-03 10:47:24 [INFO]: Epoch 012 - training loss: 0.4727, validation loss: 0.5740
2024-06-03 10:47:44 [INFO]: Epoch 013 - training loss: 0.4662, validation loss: 0.5738
2024-06-03 10:48:02 [INFO]: Epoch 014 - training loss: 0.4488, validation loss: 0.5708
2024-06-03 10:48:19 [INFO]: Epoch 015 - training loss: 0.4504, validation loss: 0.5709
2024-06-03 10:48:37 [INFO]: Epoch 016 - training loss: 0.4488, validation loss: 0.5703
2024-06-03 10:48:57 [INFO]: Epoch 017 - training loss: 0.4450, validation loss: 0.5656
2024-06-03 10:49:16 [INFO]: Epoch 018 - training loss: 0.4416, validation loss: 0.5643
2024-06-03 10:49:34 [INFO]: Epoch 019 - training loss: 0.4337, validation loss: 0.5603
2024-06-03 10:49:51 [INFO]: Epoch 020 - training loss: 0.4242, validation loss: 0.5620
2024-06-03 10:50:09 [INFO]: Epoch 021 - training loss: 0.4217, validation loss: 0.5606
2024-06-03 10:50:28 [INFO]: Epoch 022 - training loss: 0.4281, validation loss: 0.5612
2024-06-03 10:50:47 [INFO]: Epoch 023 - training loss: 0.4232, validation loss: 0.5630
2024-06-03 10:51:06 [INFO]: Epoch 024 - training loss: 0.4171, validation loss: 0.5568
2024-06-03 10:51:25 [INFO]: Epoch 025 - training loss: 0.4117, validation loss: 0.5591
2024-06-03 10:51:44 [INFO]: Epoch 026 - training loss: 0.4104, validation loss: 0.5553
2024-06-03 10:52:03 [INFO]: Epoch 027 - training loss: 0.4079, validation loss: 0.5571
2024-06-03 10:52:22 [INFO]: Epoch 028 - training loss: 0.4094, validation loss: 0.5549
2024-06-03 10:52:41 [INFO]: Epoch 029 - training loss: 0.4129, validation loss: 0.5551
2024-06-03 10:52:59 [INFO]: Epoch 030 - training loss: 0.4131, validation loss: 0.5583
2024-06-03 10:53:17 [INFO]: Epoch 031 - training loss: 0.4054, validation loss: 0.5546
2024-06-03 10:53:36 [INFO]: Epoch 032 - training loss: 0.4042, validation loss: 0.5493
2024-06-03 10:53:55 [INFO]: Epoch 033 - training loss: 0.4028, validation loss: 0.5555
2024-06-03 10:54:14 [INFO]: Epoch 034 - training loss: 0.4093, validation loss: 0.5521
2024-06-03 10:54:32 [INFO]: Epoch 035 - training loss: 0.4041, validation loss: 0.5514
2024-06-03 10:54:49 [INFO]: Epoch 036 - training loss: 0.4008, validation loss: 0.5511
2024-06-03 10:55:07 [INFO]: Epoch 037 - training loss: 0.3955, validation loss: 0.5518
2024-06-03 10:55:25 [INFO]: Epoch 038 - training loss: 0.3945, validation loss: 0.5486
2024-06-03 10:55:43 [INFO]: Epoch 039 - training loss: 0.3948, validation loss: 0.5502
2024-06-03 10:56:00 [INFO]: Epoch 040 - training loss: 0.3945, validation loss: 0.5516
2024-06-03 10:56:16 [INFO]: Epoch 041 - training loss: 0.3991, validation loss: 0.5535
2024-06-03 10:56:33 [INFO]: Epoch 042 - training loss: 0.3956, validation loss: 0.5472
2024-06-03 10:56:51 [INFO]: Epoch 043 - training loss: 0.3930, validation loss: 0.5521
2024-06-03 10:57:08 [INFO]: Epoch 044 - training loss: 0.3956, validation loss: 0.5488
2024-06-03 10:57:25 [INFO]: Epoch 045 - training loss: 0.3925, validation loss: 0.5427
2024-06-03 10:57:42 [INFO]: Epoch 046 - training loss: 0.3890, validation loss: 0.5468
2024-06-03 10:57:58 [INFO]: Epoch 047 - training loss: 0.3964, validation loss: 0.5443
2024-06-03 10:58:15 [INFO]: Epoch 048 - training loss: 0.3916, validation loss: 0.5467
2024-06-03 10:58:33 [INFO]: Epoch 049 - training loss: 0.3923, validation loss: 0.5489
2024-06-03 10:58:51 [INFO]: Epoch 050 - training loss: 0.3922, validation loss: 0.5482
2024-06-03 10:59:09 [INFO]: Epoch 051 - training loss: 0.3921, validation loss: 0.5470
2024-06-03 10:59:25 [INFO]: Epoch 052 - training loss: 0.3885, validation loss: 0.5435
2024-06-03 10:59:43 [INFO]: Epoch 053 - training loss: 0.3882, validation loss: 0.5449
2024-06-03 10:59:59 [INFO]: Epoch 054 - training loss: 0.3847, validation loss: 0.5453
2024-06-03 11:00:14 [INFO]: Epoch 055 - training loss: 0.3855, validation loss: 0.5460
2024-06-03 11:00:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:00:14 [INFO]: Finished training. The best model is from epoch#45.
2024-06-03 11:00:14 [INFO]: Saved the model to results_block_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T104325/ETSformer.pypots
2024-06-03 11:00:26 [INFO]: Successfully saved to results_block_rate05/PeMS/ETSformer_PeMS/round_1/imputation.pkl
2024-06-03 11:00:26 [INFO]: Round1 - ETSformer on PeMS: MAE=0.4372, MSE=0.7878, MRE=0.5235
2024-06-03 11:00:26 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 11:00:26 [INFO]: Using the given device: cuda:0
2024-06-03 11:00:26 [INFO]: Model files will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T110026
2024-06-03 11:00:26 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T110026/tensorboard
2024-06-03 11:00:28 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 11:00:41 [INFO]: Epoch 001 - training loss: 1.5219, validation loss: 0.8764
2024-06-03 11:00:54 [INFO]: Epoch 002 - training loss: 0.8056, validation loss: 0.7794
2024-06-03 11:01:09 [INFO]: Epoch 003 - training loss: 0.6969, validation loss: 0.6952
2024-06-03 11:01:23 [INFO]: Epoch 004 - training loss: 0.6070, validation loss: 0.6575
2024-06-03 11:01:38 [INFO]: Epoch 005 - training loss: 0.5628, validation loss: 0.6395
2024-06-03 11:01:52 [INFO]: Epoch 006 - training loss: 0.5428, validation loss: 0.6170
2024-06-03 11:02:05 [INFO]: Epoch 007 - training loss: 0.5147, validation loss: 0.6141
2024-06-03 11:02:19 [INFO]: Epoch 008 - training loss: 0.5033, validation loss: 0.6139
2024-06-03 11:02:33 [INFO]: Epoch 009 - training loss: 0.5004, validation loss: 0.6046
2024-06-03 11:02:47 [INFO]: Epoch 010 - training loss: 0.4906, validation loss: 0.5997
2024-06-03 11:03:02 [INFO]: Epoch 011 - training loss: 0.4727, validation loss: 0.5969
2024-06-03 11:03:15 [INFO]: Epoch 012 - training loss: 0.4632, validation loss: 0.5890
2024-06-03 11:03:28 [INFO]: Epoch 013 - training loss: 0.4572, validation loss: 0.5874
2024-06-03 11:03:42 [INFO]: Epoch 014 - training loss: 0.4512, validation loss: 0.5885
2024-06-03 11:03:56 [INFO]: Epoch 015 - training loss: 0.4478, validation loss: 0.5787
2024-06-03 11:04:10 [INFO]: Epoch 016 - training loss: 0.4349, validation loss: 0.5799
2024-06-03 11:04:24 [INFO]: Epoch 017 - training loss: 0.4320, validation loss: 0.5752
2024-06-03 11:04:37 [INFO]: Epoch 018 - training loss: 0.4292, validation loss: 0.5768
2024-06-03 11:04:51 [INFO]: Epoch 019 - training loss: 0.4312, validation loss: 0.5704
2024-06-03 11:05:05 [INFO]: Epoch 020 - training loss: 0.4266, validation loss: 0.5762
2024-06-03 11:05:20 [INFO]: Epoch 021 - training loss: 0.4215, validation loss: 0.5734
2024-06-03 11:05:34 [INFO]: Epoch 022 - training loss: 0.4232, validation loss: 0.5696
2024-06-03 11:05:47 [INFO]: Epoch 023 - training loss: 0.4224, validation loss: 0.5706
2024-06-03 11:06:00 [INFO]: Epoch 024 - training loss: 0.4157, validation loss: 0.5649
2024-06-03 11:06:14 [INFO]: Epoch 025 - training loss: 0.4088, validation loss: 0.5676
2024-06-03 11:06:28 [INFO]: Epoch 026 - training loss: 0.4096, validation loss: 0.5604
2024-06-03 11:06:42 [INFO]: Epoch 027 - training loss: 0.4110, validation loss: 0.5666
2024-06-03 11:06:56 [INFO]: Epoch 028 - training loss: 0.4055, validation loss: 0.5621
2024-06-03 11:07:09 [INFO]: Epoch 029 - training loss: 0.4040, validation loss: 0.5623
2024-06-03 11:07:22 [INFO]: Epoch 030 - training loss: 0.4086, validation loss: 0.5656
2024-06-03 11:07:36 [INFO]: Epoch 031 - training loss: 0.4029, validation loss: 0.5615
2024-06-03 11:07:51 [INFO]: Epoch 032 - training loss: 0.4064, validation loss: 0.5575
2024-06-03 11:08:05 [INFO]: Epoch 033 - training loss: 0.3976, validation loss: 0.5584
2024-06-03 11:08:19 [INFO]: Epoch 034 - training loss: 0.4030, validation loss: 0.5605
2024-06-03 11:08:31 [INFO]: Epoch 035 - training loss: 0.3992, validation loss: 0.5622
2024-06-03 11:08:44 [INFO]: Epoch 036 - training loss: 0.4017, validation loss: 0.5581
2024-06-03 11:08:58 [INFO]: Epoch 037 - training loss: 0.3955, validation loss: 0.5543
2024-06-03 11:09:12 [INFO]: Epoch 038 - training loss: 0.3972, validation loss: 0.5566
2024-06-03 11:09:25 [INFO]: Epoch 039 - training loss: 0.3983, validation loss: 0.5569
2024-06-03 11:09:39 [INFO]: Epoch 040 - training loss: 0.3966, validation loss: 0.5567
2024-06-03 11:09:51 [INFO]: Epoch 041 - training loss: 0.3941, validation loss: 0.5558
2024-06-03 11:10:04 [INFO]: Epoch 042 - training loss: 0.3913, validation loss: 0.5545
2024-06-03 11:10:18 [INFO]: Epoch 043 - training loss: 0.3914, validation loss: 0.5545
2024-06-03 11:10:32 [INFO]: Epoch 044 - training loss: 0.3946, validation loss: 0.5527
2024-06-03 11:10:46 [INFO]: Epoch 045 - training loss: 0.3949, validation loss: 0.5550
2024-06-03 11:10:59 [INFO]: Epoch 046 - training loss: 0.3994, validation loss: 0.5515
2024-06-03 11:11:11 [INFO]: Epoch 047 - training loss: 0.4001, validation loss: 0.5504
2024-06-03 11:11:25 [INFO]: Epoch 048 - training loss: 0.3977, validation loss: 0.5522
2024-06-03 11:11:39 [INFO]: Epoch 049 - training loss: 0.3975, validation loss: 0.5491
2024-06-03 11:11:53 [INFO]: Epoch 050 - training loss: 0.3961, validation loss: 0.5477
2024-06-03 11:12:06 [INFO]: Epoch 051 - training loss: 0.3955, validation loss: 0.5490
2024-06-03 11:12:20 [INFO]: Epoch 052 - training loss: 0.3927, validation loss: 0.5498
2024-06-03 11:12:33 [INFO]: Epoch 053 - training loss: 0.3978, validation loss: 0.5488
2024-06-03 11:12:47 [INFO]: Epoch 054 - training loss: 0.3929, validation loss: 0.5503
2024-06-03 11:13:00 [INFO]: Epoch 055 - training loss: 0.3937, validation loss: 0.5473
2024-06-03 11:13:14 [INFO]: Epoch 056 - training loss: 0.3994, validation loss: 0.5484
2024-06-03 11:13:27 [INFO]: Epoch 057 - training loss: 0.3929, validation loss: 0.5456
2024-06-03 11:13:40 [INFO]: Epoch 058 - training loss: 0.3982, validation loss: 0.5439
2024-06-03 11:13:52 [INFO]: Epoch 059 - training loss: 0.3957, validation loss: 0.5460
2024-06-03 11:14:06 [INFO]: Epoch 060 - training loss: 0.3916, validation loss: 0.5503
2024-06-03 11:14:20 [INFO]: Epoch 061 - training loss: 0.3938, validation loss: 0.5499
2024-06-03 11:14:33 [INFO]: Epoch 062 - training loss: 0.3925, validation loss: 0.5478
2024-06-03 11:14:47 [INFO]: Epoch 063 - training loss: 0.3891, validation loss: 0.5451
2024-06-03 11:15:00 [INFO]: Epoch 064 - training loss: 0.3932, validation loss: 0.5495
2024-06-03 11:15:13 [INFO]: Epoch 065 - training loss: 0.4074, validation loss: 0.5473
2024-06-03 11:15:27 [INFO]: Epoch 066 - training loss: 0.3997, validation loss: 0.5468
2024-06-03 11:15:41 [INFO]: Epoch 067 - training loss: 0.4052, validation loss: 0.5437
2024-06-03 11:15:55 [INFO]: Epoch 068 - training loss: 0.3982, validation loss: 0.5454
2024-06-03 11:16:08 [INFO]: Epoch 069 - training loss: 0.3950, validation loss: 0.5446
2024-06-03 11:16:20 [INFO]: Epoch 070 - training loss: 0.3923, validation loss: 0.5439
2024-06-03 11:16:34 [INFO]: Epoch 071 - training loss: 0.3962, validation loss: 0.5393
2024-06-03 11:16:48 [INFO]: Epoch 072 - training loss: 0.3908, validation loss: 0.5447
2024-06-03 11:17:02 [INFO]: Epoch 073 - training loss: 0.3937, validation loss: 0.5403
2024-06-03 11:17:16 [INFO]: Epoch 074 - training loss: 0.4324, validation loss: 0.5962
2024-06-03 11:17:29 [INFO]: Epoch 075 - training loss: 0.6332, validation loss: 0.6441
2024-06-03 11:17:41 [INFO]: Epoch 076 - training loss: 1.8779, validation loss: 6.4697
2024-06-03 11:17:55 [INFO]: Epoch 077 - training loss: 10.1373, validation loss: 67.3894
2024-06-03 11:18:08 [INFO]: Epoch 078 - training loss: 6.5425, validation loss: 9.5880
2024-06-03 11:18:22 [INFO]: Epoch 079 - training loss: 2.6898, validation loss: 2.6266
2024-06-03 11:18:36 [INFO]: Epoch 080 - training loss: 1.5863, validation loss: 1.3572
2024-06-03 11:18:48 [INFO]: Epoch 081 - training loss: 1.1099, validation loss: 0.9876
2024-06-03 11:18:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:18:48 [INFO]: Finished training. The best model is from epoch#71.
2024-06-03 11:18:49 [INFO]: Saved the model to results_block_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T110026/ETSformer.pypots
2024-06-03 11:18:59 [INFO]: Successfully saved to results_block_rate05/PeMS/ETSformer_PeMS/round_2/imputation.pkl
2024-06-03 11:18:59 [INFO]: Round2 - ETSformer on PeMS: MAE=0.7219, MSE=1.2552, MRE=0.8644
2024-06-03 11:18:59 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 11:18:59 [INFO]: Using the given device: cuda:0
2024-06-03 11:18:59 [INFO]: Model files will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T111859
2024-06-03 11:18:59 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T111859/tensorboard
2024-06-03 11:19:00 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 11:19:14 [INFO]: Epoch 001 - training loss: 1.6864, validation loss: 0.9285
2024-06-03 11:19:28 [INFO]: Epoch 002 - training loss: 0.8179, validation loss: 0.7488
2024-06-03 11:19:42 [INFO]: Epoch 003 - training loss: 0.6770, validation loss: 0.6842
2024-06-03 11:19:55 [INFO]: Epoch 004 - training loss: 0.6113, validation loss: 0.6650
2024-06-03 11:20:08 [INFO]: Epoch 005 - training loss: 0.5677, validation loss: 0.6285
2024-06-03 11:20:21 [INFO]: Epoch 006 - training loss: 0.5313, validation loss: 0.6166
2024-06-03 11:20:34 [INFO]: Epoch 007 - training loss: 0.5110, validation loss: 0.6076
2024-06-03 11:20:48 [INFO]: Epoch 008 - training loss: 0.4969, validation loss: 0.6000
2024-06-03 11:21:02 [INFO]: Epoch 009 - training loss: 0.4834, validation loss: 0.5980
2024-06-03 11:21:16 [INFO]: Epoch 010 - training loss: 0.4755, validation loss: 0.5948
2024-06-03 11:21:29 [INFO]: Epoch 011 - training loss: 0.4698, validation loss: 0.5860
2024-06-03 11:21:41 [INFO]: Epoch 012 - training loss: 0.4633, validation loss: 0.5875
2024-06-03 11:21:55 [INFO]: Epoch 013 - training loss: 0.4539, validation loss: 0.5820
2024-06-03 11:22:08 [INFO]: Epoch 014 - training loss: 0.4461, validation loss: 0.5776
2024-06-03 11:22:22 [INFO]: Epoch 015 - training loss: 0.4433, validation loss: 0.5751
2024-06-03 11:22:35 [INFO]: Epoch 016 - training loss: 0.4426, validation loss: 0.5777
2024-06-03 11:22:47 [INFO]: Epoch 017 - training loss: 0.4369, validation loss: 0.5749
2024-06-03 11:22:57 [INFO]: Epoch 018 - training loss: 0.4355, validation loss: 0.5714
2024-06-03 11:23:09 [INFO]: Epoch 019 - training loss: 0.4253, validation loss: 0.5665
2024-06-03 11:23:20 [INFO]: Epoch 020 - training loss: 0.4220, validation loss: 0.5676
2024-06-03 11:23:31 [INFO]: Epoch 021 - training loss: 0.4225, validation loss: 0.5655
2024-06-03 11:23:42 [INFO]: Epoch 022 - training loss: 0.4160, validation loss: 0.5644
2024-06-03 11:23:52 [INFO]: Epoch 023 - training loss: 0.4178, validation loss: 0.5701
2024-06-03 11:24:02 [INFO]: Epoch 024 - training loss: 0.4137, validation loss: 0.5660
2024-06-03 11:24:14 [INFO]: Epoch 025 - training loss: 0.4072, validation loss: 0.5624
2024-06-03 11:24:25 [INFO]: Epoch 026 - training loss: 0.4114, validation loss: 0.5624
2024-06-03 11:24:36 [INFO]: Epoch 027 - training loss: 0.4122, validation loss: 0.5677
2024-06-03 11:24:47 [INFO]: Epoch 028 - training loss: 0.4010, validation loss: 0.5580
2024-06-03 11:24:57 [INFO]: Epoch 029 - training loss: 0.4010, validation loss: 0.5610
2024-06-03 11:25:08 [INFO]: Epoch 030 - training loss: 0.3999, validation loss: 0.5580
2024-06-03 11:25:19 [INFO]: Epoch 031 - training loss: 0.3994, validation loss: 0.5562
2024-06-03 11:25:30 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.5582
2024-06-03 11:25:41 [INFO]: Epoch 033 - training loss: 0.4022, validation loss: 0.5638
2024-06-03 11:25:52 [INFO]: Epoch 034 - training loss: 0.4024, validation loss: 0.5573
2024-06-03 11:26:02 [INFO]: Epoch 035 - training loss: 0.4048, validation loss: 0.5574
2024-06-03 11:26:12 [INFO]: Epoch 036 - training loss: 0.4026, validation loss: 0.5640
2024-06-03 11:26:23 [INFO]: Epoch 037 - training loss: 0.3929, validation loss: 0.5598
2024-06-03 11:26:35 [INFO]: Epoch 038 - training loss: 0.3924, validation loss: 0.5591
2024-06-03 11:26:47 [INFO]: Epoch 039 - training loss: 0.4027, validation loss: 0.5554
2024-06-03 11:26:58 [INFO]: Epoch 040 - training loss: 0.3958, validation loss: 0.5539
2024-06-03 11:27:07 [INFO]: Epoch 041 - training loss: 0.3892, validation loss: 0.5523
2024-06-03 11:27:19 [INFO]: Epoch 042 - training loss: 0.3917, validation loss: 0.5581
2024-06-03 11:27:30 [INFO]: Epoch 043 - training loss: 0.3965, validation loss: 0.5526
2024-06-03 11:27:42 [INFO]: Epoch 044 - training loss: 0.3895, validation loss: 0.5559
2024-06-03 11:27:53 [INFO]: Epoch 045 - training loss: 0.3912, validation loss: 0.5574
2024-06-03 11:28:03 [INFO]: Epoch 046 - training loss: 0.3977, validation loss: 0.5521
2024-06-03 11:28:13 [INFO]: Epoch 047 - training loss: 0.3915, validation loss: 0.5524
2024-06-03 11:28:24 [INFO]: Epoch 048 - training loss: 0.3895, validation loss: 0.5502
2024-06-03 11:28:35 [INFO]: Epoch 049 - training loss: 0.3881, validation loss: 0.5491
2024-06-03 11:28:46 [INFO]: Epoch 050 - training loss: 0.3860, validation loss: 0.5533
2024-06-03 11:28:58 [INFO]: Epoch 051 - training loss: 0.3856, validation loss: 0.5507
2024-06-03 11:29:09 [INFO]: Epoch 052 - training loss: 0.3860, validation loss: 0.5531
2024-06-03 11:29:19 [INFO]: Epoch 053 - training loss: 0.3851, validation loss: 0.5510
2024-06-03 11:29:29 [INFO]: Epoch 054 - training loss: 0.3823, validation loss: 0.5479
2024-06-03 11:29:40 [INFO]: Epoch 055 - training loss: 0.3827, validation loss: 0.5492
2024-06-03 11:29:50 [INFO]: Epoch 056 - training loss: 0.3863, validation loss: 0.5488
2024-06-03 11:30:01 [INFO]: Epoch 057 - training loss: 0.3868, validation loss: 0.5484
2024-06-03 11:30:11 [INFO]: Epoch 058 - training loss: 0.3869, validation loss: 0.5463
2024-06-03 11:30:21 [INFO]: Epoch 059 - training loss: 0.3880, validation loss: 0.5458
2024-06-03 11:30:31 [INFO]: Epoch 060 - training loss: 0.3924, validation loss: 0.5512
2024-06-03 11:30:40 [INFO]: Epoch 061 - training loss: 0.3942, validation loss: 0.5556
2024-06-03 11:30:50 [INFO]: Epoch 062 - training loss: 0.3921, validation loss: 0.5442
2024-06-03 11:31:00 [INFO]: Epoch 063 - training loss: 0.3927, validation loss: 0.5506
2024-06-03 11:31:11 [INFO]: Epoch 064 - training loss: 0.3859, validation loss: 0.5479
2024-06-03 11:31:20 [INFO]: Epoch 065 - training loss: 0.3838, validation loss: 0.5462
2024-06-03 11:31:30 [INFO]: Epoch 066 - training loss: 0.3829, validation loss: 0.5471
2024-06-03 11:31:40 [INFO]: Epoch 067 - training loss: 0.3865, validation loss: 0.5465
2024-06-03 11:31:49 [INFO]: Epoch 068 - training loss: 0.3839, validation loss: 0.5463
2024-06-03 11:32:00 [INFO]: Epoch 069 - training loss: 0.3834, validation loss: 0.5474
2024-06-03 11:32:10 [INFO]: Epoch 070 - training loss: 0.3862, validation loss: 0.5483
2024-06-03 11:32:20 [INFO]: Epoch 071 - training loss: 0.3840, validation loss: 0.5467
2024-06-03 11:32:29 [INFO]: Epoch 072 - training loss: 0.3862, validation loss: 0.5444
2024-06-03 11:32:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:32:29 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 11:32:29 [INFO]: Saved the model to results_block_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T111859/ETSformer.pypots
2024-06-03 11:32:37 [INFO]: Successfully saved to results_block_rate05/PeMS/ETSformer_PeMS/round_3/imputation.pkl
2024-06-03 11:32:37 [INFO]: Round3 - ETSformer on PeMS: MAE=0.4283, MSE=0.7767, MRE=0.5128
2024-06-03 11:32:37 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 11:32:37 [INFO]: Using the given device: cuda:0
2024-06-03 11:32:37 [INFO]: Model files will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T113237
2024-06-03 11:32:37 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T113237/tensorboard
2024-06-03 11:32:37 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 11:32:47 [INFO]: Epoch 001 - training loss: 1.4559, validation loss: 0.8765
2024-06-03 11:32:57 [INFO]: Epoch 002 - training loss: 0.8059, validation loss: 0.7576
2024-06-03 11:33:07 [INFO]: Epoch 003 - training loss: 0.6805, validation loss: 0.6907
2024-06-03 11:33:17 [INFO]: Epoch 004 - training loss: 0.6000, validation loss: 0.6681
2024-06-03 11:33:27 [INFO]: Epoch 005 - training loss: 0.5576, validation loss: 0.6435
2024-06-03 11:33:37 [INFO]: Epoch 006 - training loss: 0.5278, validation loss: 0.6278
2024-06-03 11:33:45 [INFO]: Epoch 007 - training loss: 0.5262, validation loss: 0.6210
2024-06-03 11:33:56 [INFO]: Epoch 008 - training loss: 0.5100, validation loss: 0.6088
2024-06-03 11:34:06 [INFO]: Epoch 009 - training loss: 0.4948, validation loss: 0.6143
2024-06-03 11:34:15 [INFO]: Epoch 010 - training loss: 0.4848, validation loss: 0.5994
2024-06-03 11:34:24 [INFO]: Epoch 011 - training loss: 0.4781, validation loss: 0.6088
2024-06-03 11:34:32 [INFO]: Epoch 012 - training loss: 0.4778, validation loss: 0.6007
2024-06-03 11:34:40 [INFO]: Epoch 013 - training loss: 0.4664, validation loss: 0.5922
2024-06-03 11:34:47 [INFO]: Epoch 014 - training loss: 0.4568, validation loss: 0.5936
2024-06-03 11:34:55 [INFO]: Epoch 015 - training loss: 0.4500, validation loss: 0.5931
2024-06-03 11:35:04 [INFO]: Epoch 016 - training loss: 0.4537, validation loss: 0.5829
2024-06-03 11:35:13 [INFO]: Epoch 017 - training loss: 0.4383, validation loss: 0.5785
2024-06-03 11:35:21 [INFO]: Epoch 018 - training loss: 0.4318, validation loss: 0.5795
2024-06-03 11:35:30 [INFO]: Epoch 019 - training loss: 0.4315, validation loss: 0.5749
2024-06-03 11:35:38 [INFO]: Epoch 020 - training loss: 0.4317, validation loss: 0.5771
2024-06-03 11:35:46 [INFO]: Epoch 021 - training loss: 0.4242, validation loss: 0.5752
2024-06-03 11:35:54 [INFO]: Epoch 022 - training loss: 0.4224, validation loss: 0.5752
2024-06-03 11:36:03 [INFO]: Epoch 023 - training loss: 0.4178, validation loss: 0.5730
2024-06-03 11:36:12 [INFO]: Epoch 024 - training loss: 0.4150, validation loss: 0.5667
2024-06-03 11:36:20 [INFO]: Epoch 025 - training loss: 0.4178, validation loss: 0.5676
2024-06-03 11:36:29 [INFO]: Epoch 026 - training loss: 0.4169, validation loss: 0.5723
2024-06-03 11:36:37 [INFO]: Epoch 027 - training loss: 0.4129, validation loss: 0.5668
2024-06-03 11:36:45 [INFO]: Epoch 028 - training loss: 0.4144, validation loss: 0.5675
2024-06-03 11:36:53 [INFO]: Epoch 029 - training loss: 0.4147, validation loss: 0.5658
2024-06-03 11:37:01 [INFO]: Epoch 030 - training loss: 0.4103, validation loss: 0.5671
2024-06-03 11:37:10 [INFO]: Epoch 031 - training loss: 0.4109, validation loss: 0.5666
2024-06-03 11:37:18 [INFO]: Epoch 032 - training loss: 0.4068, validation loss: 0.5637
2024-06-03 11:37:27 [INFO]: Epoch 033 - training loss: 0.4030, validation loss: 0.5597
2024-06-03 11:37:35 [INFO]: Epoch 034 - training loss: 0.4040, validation loss: 0.5658
2024-06-03 11:37:42 [INFO]: Epoch 035 - training loss: 0.4000, validation loss: 0.5592
2024-06-03 11:37:50 [INFO]: Epoch 036 - training loss: 0.4001, validation loss: 0.5615
2024-06-03 11:37:57 [INFO]: Epoch 037 - training loss: 0.4000, validation loss: 0.5600
2024-06-03 11:38:05 [INFO]: Epoch 038 - training loss: 0.4022, validation loss: 0.5636
2024-06-03 11:38:13 [INFO]: Epoch 039 - training loss: 0.4029, validation loss: 0.5663
2024-06-03 11:38:21 [INFO]: Epoch 040 - training loss: 0.4015, validation loss: 0.5528
2024-06-03 11:38:29 [INFO]: Epoch 041 - training loss: 0.3941, validation loss: 0.5577
2024-06-03 11:38:37 [INFO]: Epoch 042 - training loss: 0.3981, validation loss: 0.5528
2024-06-03 11:38:45 [INFO]: Epoch 043 - training loss: 0.3932, validation loss: 0.5581
2024-06-03 11:38:52 [INFO]: Epoch 044 - training loss: 0.3941, validation loss: 0.5566
2024-06-03 11:39:00 [INFO]: Epoch 045 - training loss: 0.3940, validation loss: 0.5560
2024-06-03 11:39:07 [INFO]: Epoch 046 - training loss: 0.3960, validation loss: 0.5580
2024-06-03 11:39:15 [INFO]: Epoch 047 - training loss: 0.3980, validation loss: 0.5570
2024-06-03 11:39:23 [INFO]: Epoch 048 - training loss: 0.3942, validation loss: 0.5486
2024-06-03 11:39:31 [INFO]: Epoch 049 - training loss: 0.3901, validation loss: 0.5519
2024-06-03 11:39:39 [INFO]: Epoch 050 - training loss: 0.3971, validation loss: 0.5519
2024-06-03 11:39:47 [INFO]: Epoch 051 - training loss: 0.3996, validation loss: 0.5583
2024-06-03 11:39:54 [INFO]: Epoch 052 - training loss: 0.4083, validation loss: 0.5520
2024-06-03 11:40:01 [INFO]: Epoch 053 - training loss: 0.4011, validation loss: 0.5552
2024-06-03 11:40:09 [INFO]: Epoch 054 - training loss: 0.3975, validation loss: 0.5509
2024-06-03 11:40:17 [INFO]: Epoch 055 - training loss: 0.4055, validation loss: 0.5552
2024-06-03 11:40:25 [INFO]: Epoch 056 - training loss: 0.4310, validation loss: 0.6446
2024-06-03 11:40:33 [INFO]: Epoch 057 - training loss: 0.6601, validation loss: 0.6795
2024-06-03 11:40:41 [INFO]: Epoch 058 - training loss: 0.8441, validation loss: 1.1244
2024-06-03 11:40:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:40:41 [INFO]: Finished training. The best model is from epoch#48.
2024-06-03 11:40:41 [INFO]: Saved the model to results_block_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T113237/ETSformer.pypots
2024-06-03 11:40:47 [INFO]: Successfully saved to results_block_rate05/PeMS/ETSformer_PeMS/round_4/imputation.pkl
2024-06-03 11:40:47 [INFO]: Round4 - ETSformer on PeMS: MAE=0.7516, MSE=1.3797, MRE=0.8999
2024-06-03 11:40:47 [INFO]: Done! Final results:
Averaged ETSformer (5,962,188 params) on PeMS: MAE=0.8708 ± 0.5881728023278819, MSE=2.2896 ± 2.491323741937193, MRE=1.0427 ± 0.7042558022905216, average inference time=2.07
