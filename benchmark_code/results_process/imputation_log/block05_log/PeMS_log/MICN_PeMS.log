2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:55 [INFO]: Model files will be saved to results_block_rate05/PeMS/MICN_PeMS/round_0/20240603_T100955
2024-06-03 10:09:55 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/MICN_PeMS/round_0/20240603_T100955/tensorboard
2024-06-03 10:10:01 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 10:10:20 [INFO]: Epoch 001 - training loss: 0.7827, validation loss: 0.9658
2024-06-03 10:10:30 [INFO]: Epoch 002 - training loss: 0.5471, validation loss: 0.9389
2024-06-03 10:10:39 [INFO]: Epoch 003 - training loss: 0.5244, validation loss: 0.9317
2024-06-03 10:10:48 [INFO]: Epoch 004 - training loss: 0.5044, validation loss: 0.9189
2024-06-03 10:10:59 [INFO]: Epoch 005 - training loss: 0.4910, validation loss: 0.9261
2024-06-03 10:11:08 [INFO]: Epoch 006 - training loss: 0.4820, validation loss: 0.8968
2024-06-03 10:11:18 [INFO]: Epoch 007 - training loss: 0.4743, validation loss: 0.8866
2024-06-03 10:11:28 [INFO]: Epoch 008 - training loss: 0.4717, validation loss: 0.8577
2024-06-03 10:11:38 [INFO]: Epoch 009 - training loss: 0.4704, validation loss: 0.8721
2024-06-03 10:11:49 [INFO]: Epoch 010 - training loss: 0.4678, validation loss: 0.8528
2024-06-03 10:11:59 [INFO]: Epoch 011 - training loss: 0.4637, validation loss: 0.8461
2024-06-03 10:12:08 [INFO]: Epoch 012 - training loss: 0.4626, validation loss: 0.8294
2024-06-03 10:12:18 [INFO]: Epoch 013 - training loss: 0.4626, validation loss: 0.8502
2024-06-03 10:12:27 [INFO]: Epoch 014 - training loss: 0.4616, validation loss: 0.8476
2024-06-03 10:12:37 [INFO]: Epoch 015 - training loss: 0.4553, validation loss: 0.8312
2024-06-03 10:12:46 [INFO]: Epoch 016 - training loss: 0.4561, validation loss: 0.8313
2024-06-03 10:12:56 [INFO]: Epoch 017 - training loss: 0.4572, validation loss: 0.8189
2024-06-03 10:13:05 [INFO]: Epoch 018 - training loss: 0.4590, validation loss: 0.8149
2024-06-03 10:13:15 [INFO]: Epoch 019 - training loss: 0.4559, validation loss: 0.8063
2024-06-03 10:13:24 [INFO]: Epoch 020 - training loss: 0.4528, validation loss: 0.8142
2024-06-03 10:13:34 [INFO]: Epoch 021 - training loss: 0.4551, validation loss: 0.8078
2024-06-03 10:13:43 [INFO]: Epoch 022 - training loss: 0.4525, validation loss: 0.7988
2024-06-03 10:13:52 [INFO]: Epoch 023 - training loss: 0.4503, validation loss: 0.7943
2024-06-03 10:14:01 [INFO]: Epoch 024 - training loss: 0.4525, validation loss: 0.7887
2024-06-03 10:14:11 [INFO]: Epoch 025 - training loss: 0.4521, validation loss: 0.8015
2024-06-03 10:14:21 [INFO]: Epoch 026 - training loss: 0.4504, validation loss: 0.7843
2024-06-03 10:14:30 [INFO]: Epoch 027 - training loss: 0.4507, validation loss: 0.7857
2024-06-03 10:14:40 [INFO]: Epoch 028 - training loss: 0.4495, validation loss: 0.7882
2024-06-03 10:14:50 [INFO]: Epoch 029 - training loss: 0.4480, validation loss: 0.7890
2024-06-03 10:15:00 [INFO]: Epoch 030 - training loss: 0.4478, validation loss: 0.8049
2024-06-03 10:15:10 [INFO]: Epoch 031 - training loss: 0.4436, validation loss: 0.7812
2024-06-03 10:15:20 [INFO]: Epoch 032 - training loss: 0.4455, validation loss: 0.7815
2024-06-03 10:15:29 [INFO]: Epoch 033 - training loss: 0.4438, validation loss: 0.7843
2024-06-03 10:15:37 [INFO]: Epoch 034 - training loss: 0.4450, validation loss: 0.7826
2024-06-03 10:15:47 [INFO]: Epoch 035 - training loss: 0.4407, validation loss: 0.8047
2024-06-03 10:15:56 [INFO]: Epoch 036 - training loss: 0.4431, validation loss: 0.7855
2024-06-03 10:16:06 [INFO]: Epoch 037 - training loss: 0.4398, validation loss: 0.7954
2024-06-03 10:16:15 [INFO]: Epoch 038 - training loss: 0.4401, validation loss: 0.7824
2024-06-03 10:16:25 [INFO]: Epoch 039 - training loss: 0.4404, validation loss: 0.7918
2024-06-03 10:16:35 [INFO]: Epoch 040 - training loss: 0.4391, validation loss: 0.7877
2024-06-03 10:16:44 [INFO]: Epoch 041 - training loss: 0.4397, validation loss: 0.7919
2024-06-03 10:16:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:16:44 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 10:16:45 [INFO]: Saved the model to results_block_rate05/PeMS/MICN_PeMS/round_0/20240603_T100955/MICN.pypots
2024-06-03 10:16:49 [INFO]: Successfully saved to results_block_rate05/PeMS/MICN_PeMS/round_0/imputation.pkl
2024-06-03 10:16:49 [INFO]: Round0 - MICN on PeMS: MAE=0.5979, MSE=1.1164, MRE=0.7159
2024-06-03 10:16:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:16:49 [INFO]: Using the given device: cuda:0
2024-06-03 10:16:49 [INFO]: Model files will be saved to results_block_rate05/PeMS/MICN_PeMS/round_1/20240603_T101649
2024-06-03 10:16:49 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/MICN_PeMS/round_1/20240603_T101649/tensorboard
2024-06-03 10:16:50 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 10:17:00 [INFO]: Epoch 001 - training loss: 0.7850, validation loss: 0.9120
2024-06-03 10:17:09 [INFO]: Epoch 002 - training loss: 0.5483, validation loss: 0.9202
2024-06-03 10:17:19 [INFO]: Epoch 003 - training loss: 0.5216, validation loss: 0.9153
2024-06-03 10:17:30 [INFO]: Epoch 004 - training loss: 0.4969, validation loss: 0.9030
2024-06-03 10:17:40 [INFO]: Epoch 005 - training loss: 0.4901, validation loss: 0.8525
2024-06-03 10:17:49 [INFO]: Epoch 006 - training loss: 0.4816, validation loss: 0.8780
2024-06-03 10:18:00 [INFO]: Epoch 007 - training loss: 0.4768, validation loss: 0.8660
2024-06-03 10:18:10 [INFO]: Epoch 008 - training loss: 0.4741, validation loss: 0.8552
2024-06-03 10:18:20 [INFO]: Epoch 009 - training loss: 0.4720, validation loss: 0.8628
2024-06-03 10:18:30 [INFO]: Epoch 010 - training loss: 0.4677, validation loss: 0.8286
2024-06-03 10:18:38 [INFO]: Epoch 011 - training loss: 0.4668, validation loss: 0.8347
2024-06-03 10:18:48 [INFO]: Epoch 012 - training loss: 0.4612, validation loss: 0.8553
2024-06-03 10:18:57 [INFO]: Epoch 013 - training loss: 0.4633, validation loss: 0.8344
2024-06-03 10:19:08 [INFO]: Epoch 014 - training loss: 0.4626, validation loss: 0.8359
2024-06-03 10:19:17 [INFO]: Epoch 015 - training loss: 0.4607, validation loss: 0.8101
2024-06-03 10:19:27 [INFO]: Epoch 016 - training loss: 0.4592, validation loss: 0.8277
2024-06-03 10:19:37 [INFO]: Epoch 017 - training loss: 0.4570, validation loss: 0.8094
2024-06-03 10:19:47 [INFO]: Epoch 018 - training loss: 0.4553, validation loss: 0.8137
2024-06-03 10:19:57 [INFO]: Epoch 019 - training loss: 0.4570, validation loss: 0.8287
2024-06-03 10:20:07 [INFO]: Epoch 020 - training loss: 0.4549, validation loss: 0.8030
2024-06-03 10:20:16 [INFO]: Epoch 021 - training loss: 0.4513, validation loss: 0.8024
2024-06-03 10:20:25 [INFO]: Epoch 022 - training loss: 0.4570, validation loss: 0.8019
2024-06-03 10:20:35 [INFO]: Epoch 023 - training loss: 0.4521, validation loss: 0.7907
2024-06-03 10:20:45 [INFO]: Epoch 024 - training loss: 0.4514, validation loss: 0.7870
2024-06-03 10:20:55 [INFO]: Epoch 025 - training loss: 0.4521, validation loss: 0.8209
2024-06-03 10:21:05 [INFO]: Epoch 026 - training loss: 0.4546, validation loss: 0.8014
2024-06-03 10:21:15 [INFO]: Epoch 027 - training loss: 0.4503, validation loss: 0.8118
2024-06-03 10:21:25 [INFO]: Epoch 028 - training loss: 0.4502, validation loss: 0.7972
2024-06-03 10:21:34 [INFO]: Epoch 029 - training loss: 0.4482, validation loss: 0.7914
2024-06-03 10:21:45 [INFO]: Epoch 030 - training loss: 0.4475, validation loss: 0.7836
2024-06-03 10:21:53 [INFO]: Epoch 031 - training loss: 0.4481, validation loss: 0.7855
2024-06-03 10:22:03 [INFO]: Epoch 032 - training loss: 0.4450, validation loss: 0.8011
2024-06-03 10:22:11 [INFO]: Epoch 033 - training loss: 0.4455, validation loss: 0.7840
2024-06-03 10:22:21 [INFO]: Epoch 034 - training loss: 0.4438, validation loss: 0.7864
2024-06-03 10:22:30 [INFO]: Epoch 035 - training loss: 0.4429, validation loss: 0.7661
2024-06-03 10:22:40 [INFO]: Epoch 036 - training loss: 0.4438, validation loss: 0.8061
2024-06-03 10:22:51 [INFO]: Epoch 037 - training loss: 0.4408, validation loss: 0.7484
2024-06-03 10:23:00 [INFO]: Epoch 038 - training loss: 0.4435, validation loss: 0.7814
2024-06-03 10:23:10 [INFO]: Epoch 039 - training loss: 0.4417, validation loss: 0.7925
2024-06-03 10:23:20 [INFO]: Epoch 040 - training loss: 0.4430, validation loss: 0.7852
2024-06-03 10:23:29 [INFO]: Epoch 041 - training loss: 0.4426, validation loss: 0.7646
2024-06-03 10:23:38 [INFO]: Epoch 042 - training loss: 0.4364, validation loss: 0.7909
2024-06-03 10:23:47 [INFO]: Epoch 043 - training loss: 0.4383, validation loss: 0.7830
2024-06-03 10:23:57 [INFO]: Epoch 044 - training loss: 0.4400, validation loss: 0.8035
2024-06-03 10:24:06 [INFO]: Epoch 045 - training loss: 0.4371, validation loss: 0.7643
2024-06-03 10:24:15 [INFO]: Epoch 046 - training loss: 0.4352, validation loss: 0.7836
2024-06-03 10:24:25 [INFO]: Epoch 047 - training loss: 0.4362, validation loss: 0.7811
2024-06-03 10:24:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:25 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 10:24:26 [INFO]: Saved the model to results_block_rate05/PeMS/MICN_PeMS/round_1/20240603_T101649/MICN.pypots
2024-06-03 10:24:30 [INFO]: Successfully saved to results_block_rate05/PeMS/MICN_PeMS/round_1/imputation.pkl
2024-06-03 10:24:30 [INFO]: Round1 - MICN on PeMS: MAE=0.5885, MSE=1.1017, MRE=0.7047
2024-06-03 10:24:30 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:24:30 [INFO]: Using the given device: cuda:0
2024-06-03 10:24:30 [INFO]: Model files will be saved to results_block_rate05/PeMS/MICN_PeMS/round_2/20240603_T102430
2024-06-03 10:24:30 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/MICN_PeMS/round_2/20240603_T102430/tensorboard
2024-06-03 10:24:31 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 10:24:41 [INFO]: Epoch 001 - training loss: 0.8011, validation loss: 0.9350
2024-06-03 10:24:51 [INFO]: Epoch 002 - training loss: 0.5605, validation loss: 0.9113
2024-06-03 10:25:01 [INFO]: Epoch 003 - training loss: 0.5325, validation loss: 0.8852
2024-06-03 10:25:10 [INFO]: Epoch 004 - training loss: 0.5070, validation loss: 0.8754
2024-06-03 10:25:18 [INFO]: Epoch 005 - training loss: 0.4936, validation loss: 0.8443
2024-06-03 10:25:27 [INFO]: Epoch 006 - training loss: 0.4889, validation loss: 0.8251
2024-06-03 10:25:36 [INFO]: Epoch 007 - training loss: 0.4801, validation loss: 0.8148
2024-06-03 10:25:45 [INFO]: Epoch 008 - training loss: 0.4769, validation loss: 0.8108
2024-06-03 10:25:54 [INFO]: Epoch 009 - training loss: 0.4752, validation loss: 0.7938
2024-06-03 10:26:03 [INFO]: Epoch 010 - training loss: 0.4702, validation loss: 0.7953
2024-06-03 10:26:12 [INFO]: Epoch 011 - training loss: 0.4662, validation loss: 0.8007
2024-06-03 10:26:21 [INFO]: Epoch 012 - training loss: 0.4667, validation loss: 0.7630
2024-06-03 10:26:31 [INFO]: Epoch 013 - training loss: 0.4637, validation loss: 0.7732
2024-06-03 10:26:40 [INFO]: Epoch 014 - training loss: 0.4604, validation loss: 0.7614
2024-06-03 10:26:49 [INFO]: Epoch 015 - training loss: 0.4629, validation loss: 0.7810
2024-06-03 10:26:57 [INFO]: Epoch 016 - training loss: 0.4586, validation loss: 0.7483
2024-06-03 10:27:07 [INFO]: Epoch 017 - training loss: 0.4612, validation loss: 0.7543
2024-06-03 10:27:16 [INFO]: Epoch 018 - training loss: 0.4552, validation loss: 0.7646
2024-06-03 10:27:26 [INFO]: Epoch 019 - training loss: 0.4560, validation loss: 0.7699
2024-06-03 10:27:35 [INFO]: Epoch 020 - training loss: 0.4584, validation loss: 0.7854
2024-06-03 10:27:44 [INFO]: Epoch 021 - training loss: 0.4574, validation loss: 0.7889
2024-06-03 10:27:53 [INFO]: Epoch 022 - training loss: 0.4539, validation loss: 0.7530
2024-06-03 10:28:02 [INFO]: Epoch 023 - training loss: 0.4530, validation loss: 0.7643
2024-06-03 10:28:11 [INFO]: Epoch 024 - training loss: 0.4523, validation loss: 0.7799
2024-06-03 10:28:20 [INFO]: Epoch 025 - training loss: 0.4534, validation loss: 0.7587
2024-06-03 10:28:28 [INFO]: Epoch 026 - training loss: 0.4498, validation loss: 0.7689
2024-06-03 10:28:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:28:28 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 10:28:29 [INFO]: Saved the model to results_block_rate05/PeMS/MICN_PeMS/round_2/20240603_T102430/MICN.pypots
2024-06-03 10:28:33 [INFO]: Successfully saved to results_block_rate05/PeMS/MICN_PeMS/round_2/imputation.pkl
2024-06-03 10:28:33 [INFO]: Round2 - MICN on PeMS: MAE=0.5895, MSE=1.0949, MRE=0.7059
2024-06-03 10:28:33 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:28:33 [INFO]: Using the given device: cuda:0
2024-06-03 10:28:33 [INFO]: Model files will be saved to results_block_rate05/PeMS/MICN_PeMS/round_3/20240603_T102833
2024-06-03 10:28:33 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/MICN_PeMS/round_3/20240603_T102833/tensorboard
2024-06-03 10:28:34 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 10:28:43 [INFO]: Epoch 001 - training loss: 0.7689, validation loss: 0.9947
2024-06-03 10:28:52 [INFO]: Epoch 002 - training loss: 0.5360, validation loss: 0.9689
2024-06-03 10:29:01 [INFO]: Epoch 003 - training loss: 0.5108, validation loss: 0.9457
2024-06-03 10:29:11 [INFO]: Epoch 004 - training loss: 0.4978, validation loss: 0.9361
2024-06-03 10:29:20 [INFO]: Epoch 005 - training loss: 0.4856, validation loss: 0.9265
2024-06-03 10:29:29 [INFO]: Epoch 006 - training loss: 0.4791, validation loss: 0.9237
2024-06-03 10:29:39 [INFO]: Epoch 007 - training loss: 0.4709, validation loss: 0.9064
2024-06-03 10:29:48 [INFO]: Epoch 008 - training loss: 0.4681, validation loss: 0.9138
2024-06-03 10:29:58 [INFO]: Epoch 009 - training loss: 0.4628, validation loss: 0.8950
2024-06-03 10:30:06 [INFO]: Epoch 010 - training loss: 0.4636, validation loss: 0.8932
2024-06-03 10:30:15 [INFO]: Epoch 011 - training loss: 0.4610, validation loss: 0.9106
2024-06-03 10:30:24 [INFO]: Epoch 012 - training loss: 0.4580, validation loss: 0.8959
2024-06-03 10:30:33 [INFO]: Epoch 013 - training loss: 0.4573, validation loss: 0.9219
2024-06-03 10:30:43 [INFO]: Epoch 014 - training loss: 0.4556, validation loss: 0.9117
2024-06-03 10:30:53 [INFO]: Epoch 015 - training loss: 0.4520, validation loss: 0.8846
2024-06-03 10:31:02 [INFO]: Epoch 016 - training loss: 0.4521, validation loss: 0.8618
2024-06-03 10:31:12 [INFO]: Epoch 017 - training loss: 0.4531, validation loss: 0.8842
2024-06-03 10:31:21 [INFO]: Epoch 018 - training loss: 0.4522, validation loss: 0.8576
2024-06-03 10:31:30 [INFO]: Epoch 019 - training loss: 0.4478, validation loss: 0.8835
2024-06-03 10:31:39 [INFO]: Epoch 020 - training loss: 0.4498, validation loss: 0.8616
2024-06-03 10:31:48 [INFO]: Epoch 021 - training loss: 0.4493, validation loss: 0.8700
2024-06-03 10:31:56 [INFO]: Epoch 022 - training loss: 0.4472, validation loss: 0.8708
2024-06-03 10:32:05 [INFO]: Epoch 023 - training loss: 0.4493, validation loss: 0.8407
2024-06-03 10:32:14 [INFO]: Epoch 024 - training loss: 0.4469, validation loss: 0.8499
2024-06-03 10:32:23 [INFO]: Epoch 025 - training loss: 0.4435, validation loss: 0.8527
2024-06-03 10:32:33 [INFO]: Epoch 026 - training loss: 0.4451, validation loss: 0.8673
2024-06-03 10:32:42 [INFO]: Epoch 027 - training loss: 0.4460, validation loss: 0.8412
2024-06-03 10:32:51 [INFO]: Epoch 028 - training loss: 0.4431, validation loss: 0.8626
2024-06-03 10:33:00 [INFO]: Epoch 029 - training loss: 0.4454, validation loss: 0.8293
2024-06-03 10:33:09 [INFO]: Epoch 030 - training loss: 0.4423, validation loss: 0.8450
2024-06-03 10:33:18 [INFO]: Epoch 031 - training loss: 0.4433, validation loss: 0.8415
2024-06-03 10:33:26 [INFO]: Epoch 032 - training loss: 0.4424, validation loss: 0.8301
2024-06-03 10:33:34 [INFO]: Epoch 033 - training loss: 0.4395, validation loss: 0.8538
2024-06-03 10:33:43 [INFO]: Epoch 034 - training loss: 0.4391, validation loss: 0.8209
2024-06-03 10:33:52 [INFO]: Epoch 035 - training loss: 0.4417, validation loss: 0.8216
2024-06-03 10:34:00 [INFO]: Epoch 036 - training loss: 0.4382, validation loss: 0.8342
2024-06-03 10:34:09 [INFO]: Epoch 037 - training loss: 0.4406, validation loss: 0.8507
2024-06-03 10:34:18 [INFO]: Epoch 038 - training loss: 0.4396, validation loss: 0.8388
2024-06-03 10:34:27 [INFO]: Epoch 039 - training loss: 0.4399, validation loss: 0.8494
2024-06-03 10:34:36 [INFO]: Epoch 040 - training loss: 0.4396, validation loss: 0.8359
2024-06-03 10:34:45 [INFO]: Epoch 041 - training loss: 0.4357, validation loss: 0.8488
2024-06-03 10:34:53 [INFO]: Epoch 042 - training loss: 0.4339, validation loss: 0.8140
2024-06-03 10:35:01 [INFO]: Epoch 043 - training loss: 0.4338, validation loss: 0.8485
2024-06-03 10:35:09 [INFO]: Epoch 044 - training loss: 0.4349, validation loss: 0.8377
2024-06-03 10:35:19 [INFO]: Epoch 045 - training loss: 0.4345, validation loss: 0.8487
2024-06-03 10:35:27 [INFO]: Epoch 046 - training loss: 0.4353, validation loss: 0.8356
2024-06-03 10:35:36 [INFO]: Epoch 047 - training loss: 0.4333, validation loss: 0.8337
2024-06-03 10:35:45 [INFO]: Epoch 048 - training loss: 0.4331, validation loss: 0.8256
2024-06-03 10:35:53 [INFO]: Epoch 049 - training loss: 0.4331, validation loss: 0.8255
2024-06-03 10:36:02 [INFO]: Epoch 050 - training loss: 0.4318, validation loss: 0.8288
2024-06-03 10:36:11 [INFO]: Epoch 051 - training loss: 0.4308, validation loss: 0.8152
2024-06-03 10:36:20 [INFO]: Epoch 052 - training loss: 0.4307, validation loss: 0.8486
2024-06-03 10:36:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:36:20 [INFO]: Finished training. The best model is from epoch#42.
2024-06-03 10:36:21 [INFO]: Saved the model to results_block_rate05/PeMS/MICN_PeMS/round_3/20240603_T102833/MICN.pypots
2024-06-03 10:36:24 [INFO]: Successfully saved to results_block_rate05/PeMS/MICN_PeMS/round_3/imputation.pkl
2024-06-03 10:36:24 [INFO]: Round3 - MICN on PeMS: MAE=0.6196, MSE=1.1761, MRE=0.7419
2024-06-03 10:36:24 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:36:24 [INFO]: Using the given device: cuda:0
2024-06-03 10:36:24 [INFO]: Model files will be saved to results_block_rate05/PeMS/MICN_PeMS/round_4/20240603_T103624
2024-06-03 10:36:24 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/MICN_PeMS/round_4/20240603_T103624/tensorboard
2024-06-03 10:36:26 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 10:36:34 [INFO]: Epoch 001 - training loss: 0.7785, validation loss: 0.9480
2024-06-03 10:36:42 [INFO]: Epoch 002 - training loss: 0.5453, validation loss: 0.9122
2024-06-03 10:36:50 [INFO]: Epoch 003 - training loss: 0.5141, validation loss: 0.9561
2024-06-03 10:36:59 [INFO]: Epoch 004 - training loss: 0.5007, validation loss: 0.8695
2024-06-03 10:37:07 [INFO]: Epoch 005 - training loss: 0.4899, validation loss: 0.8553
2024-06-03 10:37:16 [INFO]: Epoch 006 - training loss: 0.4797, validation loss: 0.8902
2024-06-03 10:37:24 [INFO]: Epoch 007 - training loss: 0.4756, validation loss: 0.8552
2024-06-03 10:37:32 [INFO]: Epoch 008 - training loss: 0.4701, validation loss: 0.8586
2024-06-03 10:37:41 [INFO]: Epoch 009 - training loss: 0.4668, validation loss: 0.8560
2024-06-03 10:37:50 [INFO]: Epoch 010 - training loss: 0.4658, validation loss: 0.8433
2024-06-03 10:37:58 [INFO]: Epoch 011 - training loss: 0.4644, validation loss: 0.8300
2024-06-03 10:38:07 [INFO]: Epoch 012 - training loss: 0.4594, validation loss: 0.8201
2024-06-03 10:38:15 [INFO]: Epoch 013 - training loss: 0.4593, validation loss: 0.8504
2024-06-03 10:38:23 [INFO]: Epoch 014 - training loss: 0.4571, validation loss: 0.8365
2024-06-03 10:38:32 [INFO]: Epoch 015 - training loss: 0.4539, validation loss: 0.8132
2024-06-03 10:38:40 [INFO]: Epoch 016 - training loss: 0.4527, validation loss: 0.8473
2024-06-03 10:38:49 [INFO]: Epoch 017 - training loss: 0.4506, validation loss: 0.8172
2024-06-03 10:38:57 [INFO]: Epoch 018 - training loss: 0.4532, validation loss: 0.8212
2024-06-03 10:39:06 [INFO]: Epoch 019 - training loss: 0.4536, validation loss: 0.8190
2024-06-03 10:39:14 [INFO]: Epoch 020 - training loss: 0.4497, validation loss: 0.8238
2024-06-03 10:39:23 [INFO]: Epoch 021 - training loss: 0.4510, validation loss: 0.8185
2024-06-03 10:39:31 [INFO]: Epoch 022 - training loss: 0.4500, validation loss: 0.8065
2024-06-03 10:39:40 [INFO]: Epoch 023 - training loss: 0.4472, validation loss: 0.7958
2024-06-03 10:39:48 [INFO]: Epoch 024 - training loss: 0.4482, validation loss: 0.8040
2024-06-03 10:39:56 [INFO]: Epoch 025 - training loss: 0.4469, validation loss: 0.7885
2024-06-03 10:40:04 [INFO]: Epoch 026 - training loss: 0.4446, validation loss: 0.8061
2024-06-03 10:40:12 [INFO]: Epoch 027 - training loss: 0.4451, validation loss: 0.7840
2024-06-03 10:40:21 [INFO]: Epoch 028 - training loss: 0.4457, validation loss: 0.8017
2024-06-03 10:40:30 [INFO]: Epoch 029 - training loss: 0.4466, validation loss: 0.7732
2024-06-03 10:40:38 [INFO]: Epoch 030 - training loss: 0.4449, validation loss: 0.8074
2024-06-03 10:40:46 [INFO]: Epoch 031 - training loss: 0.4460, validation loss: 0.7862
2024-06-03 10:40:55 [INFO]: Epoch 032 - training loss: 0.4396, validation loss: 0.7921
2024-06-03 10:41:03 [INFO]: Epoch 033 - training loss: 0.4397, validation loss: 0.8030
2024-06-03 10:41:12 [INFO]: Epoch 034 - training loss: 0.4413, validation loss: 0.8025
2024-06-03 10:41:20 [INFO]: Epoch 035 - training loss: 0.4394, validation loss: 0.7798
2024-06-03 10:41:29 [INFO]: Epoch 036 - training loss: 0.4359, validation loss: 0.7998
2024-06-03 10:41:37 [INFO]: Epoch 037 - training loss: 0.4396, validation loss: 0.7840
2024-06-03 10:41:45 [INFO]: Epoch 038 - training loss: 0.4402, validation loss: 0.7894
2024-06-03 10:41:54 [INFO]: Epoch 039 - training loss: 0.4396, validation loss: 0.7847
2024-06-03 10:41:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:41:54 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 10:41:54 [INFO]: Saved the model to results_block_rate05/PeMS/MICN_PeMS/round_4/20240603_T103624/MICN.pypots
2024-06-03 10:41:57 [INFO]: Successfully saved to results_block_rate05/PeMS/MICN_PeMS/round_4/imputation.pkl
2024-06-03 10:41:57 [INFO]: Round4 - MICN on PeMS: MAE=0.5949, MSE=1.1111, MRE=0.7123
2024-06-03 10:41:57 [INFO]: Done! Final results:
Averaged MICN (15,490,402 params) on PeMS: MAE=0.5981 ± 0.011280871594422918, MSE=1.1201 ± 0.02898829090510899, MRE=0.7161 ± 0.01350728772874788, average inference time=0.50
