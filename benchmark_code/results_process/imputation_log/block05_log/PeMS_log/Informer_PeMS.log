2024-06-03 10:09:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:09:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:54 [INFO]: Model files will be saved to results_block_rate05/PeMS/Informer_PeMS/round_0/20240603_T100954
2024-06-03 10:09:54 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Informer_PeMS/round_0/20240603_T100954/tensorboard
2024-06-03 10:10:00 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 10:10:34 [INFO]: Epoch 001 - training loss: 0.9037, validation loss: 0.7115
2024-06-03 10:10:56 [INFO]: Epoch 002 - training loss: 0.5921, validation loss: 0.6285
2024-06-03 10:11:20 [INFO]: Epoch 003 - training loss: 0.5307, validation loss: 0.5851
2024-06-03 10:11:44 [INFO]: Epoch 004 - training loss: 0.4992, validation loss: 0.5752
2024-06-03 10:12:06 [INFO]: Epoch 005 - training loss: 0.4858, validation loss: 0.5609
2024-06-03 10:12:27 [INFO]: Epoch 006 - training loss: 0.4730, validation loss: 0.5605
2024-06-03 10:12:50 [INFO]: Epoch 007 - training loss: 0.4635, validation loss: 0.5527
2024-06-03 10:13:11 [INFO]: Epoch 008 - training loss: 0.4582, validation loss: 0.5472
2024-06-03 10:13:35 [INFO]: Epoch 009 - training loss: 0.4457, validation loss: 0.5501
2024-06-03 10:13:53 [INFO]: Epoch 010 - training loss: 0.4404, validation loss: 0.5489
2024-06-03 10:14:15 [INFO]: Epoch 011 - training loss: 0.4300, validation loss: 0.5421
2024-06-03 10:14:40 [INFO]: Epoch 012 - training loss: 0.4201, validation loss: 0.5405
2024-06-03 10:15:04 [INFO]: Epoch 013 - training loss: 0.4140, validation loss: 0.5347
2024-06-03 10:15:25 [INFO]: Epoch 014 - training loss: 0.4074, validation loss: 0.5373
2024-06-03 10:15:45 [INFO]: Epoch 015 - training loss: 0.4031, validation loss: 0.5385
2024-06-03 10:16:08 [INFO]: Epoch 016 - training loss: 0.3979, validation loss: 0.5320
2024-06-03 10:16:32 [INFO]: Epoch 017 - training loss: 0.3927, validation loss: 0.5308
2024-06-03 10:16:53 [INFO]: Epoch 018 - training loss: 0.3860, validation loss: 0.5308
2024-06-03 10:17:13 [INFO]: Epoch 019 - training loss: 0.3828, validation loss: 0.5325
2024-06-03 10:17:36 [INFO]: Epoch 020 - training loss: 0.3781, validation loss: 0.5290
2024-06-03 10:17:59 [INFO]: Epoch 021 - training loss: 0.3726, validation loss: 0.5278
2024-06-03 10:18:21 [INFO]: Epoch 022 - training loss: 0.3721, validation loss: 0.5309
2024-06-03 10:18:43 [INFO]: Epoch 023 - training loss: 0.3681, validation loss: 0.5303
2024-06-03 10:19:05 [INFO]: Epoch 024 - training loss: 0.3625, validation loss: 0.5280
2024-06-03 10:19:28 [INFO]: Epoch 025 - training loss: 0.3597, validation loss: 0.5264
2024-06-03 10:19:51 [INFO]: Epoch 026 - training loss: 0.3549, validation loss: 0.5180
2024-06-03 10:20:13 [INFO]: Epoch 027 - training loss: 0.3473, validation loss: 0.5228
2024-06-03 10:20:32 [INFO]: Epoch 028 - training loss: 0.3471, validation loss: 0.5221
2024-06-03 10:20:56 [INFO]: Epoch 029 - training loss: 0.3432, validation loss: 0.5178
2024-06-03 10:21:21 [INFO]: Epoch 030 - training loss: 0.3422, validation loss: 0.5215
2024-06-03 10:21:44 [INFO]: Epoch 031 - training loss: 0.3339, validation loss: 0.5172
2024-06-03 10:22:02 [INFO]: Epoch 032 - training loss: 0.3331, validation loss: 0.5186
2024-06-03 10:22:25 [INFO]: Epoch 033 - training loss: 0.3296, validation loss: 0.5126
2024-06-03 10:22:48 [INFO]: Epoch 034 - training loss: 0.3292, validation loss: 0.5154
2024-06-03 10:23:12 [INFO]: Epoch 035 - training loss: 0.3222, validation loss: 0.5160
2024-06-03 10:23:34 [INFO]: Epoch 036 - training loss: 0.3210, validation loss: 0.5197
2024-06-03 10:23:54 [INFO]: Epoch 037 - training loss: 0.3208, validation loss: 0.5133
2024-06-03 10:24:17 [INFO]: Epoch 038 - training loss: 0.3193, validation loss: 0.5137
2024-06-03 10:24:39 [INFO]: Epoch 039 - training loss: 0.3119, validation loss: 0.5163
2024-06-03 10:25:00 [INFO]: Epoch 040 - training loss: 0.3076, validation loss: 0.5120
2024-06-03 10:25:19 [INFO]: Epoch 041 - training loss: 0.3078, validation loss: 0.5139
2024-06-03 10:25:38 [INFO]: Epoch 042 - training loss: 0.3073, validation loss: 0.5124
2024-06-03 10:26:01 [INFO]: Epoch 043 - training loss: 0.3075, validation loss: 0.5170
2024-06-03 10:26:23 [INFO]: Epoch 044 - training loss: 0.3068, validation loss: 0.5138
2024-06-03 10:26:45 [INFO]: Epoch 045 - training loss: 0.3056, validation loss: 0.5123
2024-06-03 10:27:04 [INFO]: Epoch 046 - training loss: 0.3012, validation loss: 0.5124
2024-06-03 10:27:26 [INFO]: Epoch 047 - training loss: 0.3017, validation loss: 0.5149
2024-06-03 10:27:48 [INFO]: Epoch 048 - training loss: 0.2941, validation loss: 0.5128
2024-06-03 10:28:11 [INFO]: Epoch 049 - training loss: 0.3014, validation loss: 0.5161
2024-06-03 10:28:31 [INFO]: Epoch 050 - training loss: 0.2979, validation loss: 0.5152
2024-06-03 10:28:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:28:31 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 10:28:31 [INFO]: Saved the model to results_block_rate05/PeMS/Informer_PeMS/round_0/20240603_T100954/Informer.pypots
2024-06-03 10:28:45 [INFO]: Successfully saved to results_block_rate05/PeMS/Informer_PeMS/round_0/imputation.pkl
2024-06-03 10:28:45 [INFO]: Round0 - Informer on PeMS: MAE=0.3522, MSE=0.7507, MRE=0.4217
2024-06-03 10:28:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:28:45 [INFO]: Using the given device: cuda:0
2024-06-03 10:28:45 [INFO]: Model files will be saved to results_block_rate05/PeMS/Informer_PeMS/round_1/20240603_T102845
2024-06-03 10:28:45 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Informer_PeMS/round_1/20240603_T102845/tensorboard
2024-06-03 10:28:47 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 10:29:09 [INFO]: Epoch 001 - training loss: 0.8939, validation loss: 0.7038
2024-06-03 10:29:32 [INFO]: Epoch 002 - training loss: 0.5919, validation loss: 0.6596
2024-06-03 10:29:55 [INFO]: Epoch 003 - training loss: 0.5343, validation loss: 0.5924
2024-06-03 10:30:13 [INFO]: Epoch 004 - training loss: 0.5030, validation loss: 0.5743
2024-06-03 10:30:34 [INFO]: Epoch 005 - training loss: 0.4826, validation loss: 0.5682
2024-06-03 10:30:57 [INFO]: Epoch 006 - training loss: 0.4738, validation loss: 0.5567
2024-06-03 10:31:19 [INFO]: Epoch 007 - training loss: 0.4616, validation loss: 0.5621
2024-06-03 10:31:40 [INFO]: Epoch 008 - training loss: 0.4547, validation loss: 0.5515
2024-06-03 10:31:59 [INFO]: Epoch 009 - training loss: 0.4439, validation loss: 0.5497
2024-06-03 10:32:22 [INFO]: Epoch 010 - training loss: 0.4334, validation loss: 0.5470
2024-06-03 10:32:43 [INFO]: Epoch 011 - training loss: 0.4248, validation loss: 0.5406
2024-06-03 10:33:06 [INFO]: Epoch 012 - training loss: 0.4177, validation loss: 0.5436
2024-06-03 10:33:25 [INFO]: Epoch 013 - training loss: 0.4120, validation loss: 0.5419
2024-06-03 10:33:42 [INFO]: Epoch 014 - training loss: 0.4097, validation loss: 0.5406
2024-06-03 10:34:03 [INFO]: Epoch 015 - training loss: 0.3996, validation loss: 0.5372
2024-06-03 10:34:25 [INFO]: Epoch 016 - training loss: 0.3957, validation loss: 0.5346
2024-06-03 10:34:45 [INFO]: Epoch 017 - training loss: 0.3917, validation loss: 0.5322
2024-06-03 10:35:02 [INFO]: Epoch 018 - training loss: 0.3866, validation loss: 0.5352
2024-06-03 10:35:22 [INFO]: Epoch 019 - training loss: 0.3791, validation loss: 0.5310
2024-06-03 10:35:43 [INFO]: Epoch 020 - training loss: 0.3828, validation loss: 0.5309
2024-06-03 10:36:05 [INFO]: Epoch 021 - training loss: 0.3756, validation loss: 0.5262
2024-06-03 10:36:27 [INFO]: Epoch 022 - training loss: 0.3740, validation loss: 0.5319
2024-06-03 10:36:46 [INFO]: Epoch 023 - training loss: 0.3767, validation loss: 0.5294
2024-06-03 10:37:08 [INFO]: Epoch 024 - training loss: 0.3628, validation loss: 0.5269
2024-06-03 10:37:28 [INFO]: Epoch 025 - training loss: 0.3562, validation loss: 0.5234
2024-06-03 10:37:50 [INFO]: Epoch 026 - training loss: 0.3501, validation loss: 0.5201
2024-06-03 10:38:10 [INFO]: Epoch 027 - training loss: 0.3419, validation loss: 0.5209
2024-06-03 10:38:30 [INFO]: Epoch 028 - training loss: 0.3411, validation loss: 0.5193
2024-06-03 10:38:50 [INFO]: Epoch 029 - training loss: 0.3390, validation loss: 0.5191
2024-06-03 10:39:12 [INFO]: Epoch 030 - training loss: 0.3391, validation loss: 0.5216
2024-06-03 10:39:32 [INFO]: Epoch 031 - training loss: 0.3340, validation loss: 0.5198
2024-06-03 10:39:52 [INFO]: Epoch 032 - training loss: 0.3292, validation loss: 0.5207
2024-06-03 10:40:09 [INFO]: Epoch 033 - training loss: 0.3297, validation loss: 0.5123
2024-06-03 10:40:30 [INFO]: Epoch 034 - training loss: 0.3260, validation loss: 0.5122
2024-06-03 10:40:53 [INFO]: Epoch 035 - training loss: 0.3233, validation loss: 0.5119
2024-06-03 10:41:13 [INFO]: Epoch 036 - training loss: 0.3221, validation loss: 0.5168
2024-06-03 10:41:31 [INFO]: Epoch 037 - training loss: 0.3172, validation loss: 0.5115
2024-06-03 10:41:49 [INFO]: Epoch 038 - training loss: 0.3158, validation loss: 0.5060
2024-06-03 10:42:09 [INFO]: Epoch 039 - training loss: 0.3159, validation loss: 0.5091
2024-06-03 10:42:29 [INFO]: Epoch 040 - training loss: 0.3107, validation loss: 0.5094
2024-06-03 10:42:49 [INFO]: Epoch 041 - training loss: 0.3105, validation loss: 0.5119
2024-06-03 10:43:09 [INFO]: Epoch 042 - training loss: 0.3119, validation loss: 0.5115
2024-06-03 10:43:26 [INFO]: Epoch 043 - training loss: 0.3047, validation loss: 0.5145
2024-06-03 10:43:46 [INFO]: Epoch 044 - training loss: 0.3013, validation loss: 0.5107
2024-06-03 10:44:06 [INFO]: Epoch 045 - training loss: 0.3021, validation loss: 0.5069
2024-06-03 10:44:27 [INFO]: Epoch 046 - training loss: 0.3007, validation loss: 0.5057
2024-06-03 10:44:47 [INFO]: Epoch 047 - training loss: 0.2983, validation loss: 0.5086
2024-06-03 10:45:04 [INFO]: Epoch 048 - training loss: 0.2956, validation loss: 0.5089
2024-06-03 10:45:22 [INFO]: Epoch 049 - training loss: 0.2967, validation loss: 0.5006
2024-06-03 10:45:42 [INFO]: Epoch 050 - training loss: 0.2947, validation loss: 0.5033
2024-06-03 10:46:00 [INFO]: Epoch 051 - training loss: 0.2934, validation loss: 0.5022
2024-06-03 10:46:19 [INFO]: Epoch 052 - training loss: 0.2972, validation loss: 0.5046
2024-06-03 10:46:35 [INFO]: Epoch 053 - training loss: 0.2896, validation loss: 0.5057
2024-06-03 10:46:52 [INFO]: Epoch 054 - training loss: 0.2862, validation loss: 0.5022
2024-06-03 10:47:12 [INFO]: Epoch 055 - training loss: 0.2838, validation loss: 0.5022
2024-06-03 10:47:31 [INFO]: Epoch 056 - training loss: 0.2821, validation loss: 0.5032
2024-06-03 10:47:49 [INFO]: Epoch 057 - training loss: 0.2855, validation loss: 0.5087
2024-06-03 10:48:07 [INFO]: Epoch 058 - training loss: 0.2843, validation loss: 0.5038
2024-06-03 10:48:23 [INFO]: Epoch 059 - training loss: 0.2797, validation loss: 0.5015
2024-06-03 10:48:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:48:23 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 10:48:23 [INFO]: Saved the model to results_block_rate05/PeMS/Informer_PeMS/round_1/20240603_T102845/Informer.pypots
2024-06-03 10:48:36 [INFO]: Successfully saved to results_block_rate05/PeMS/Informer_PeMS/round_1/imputation.pkl
2024-06-03 10:48:36 [INFO]: Round1 - Informer on PeMS: MAE=0.3488, MSE=0.7382, MRE=0.4177
2024-06-03 10:48:36 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:48:36 [INFO]: Using the given device: cuda:0
2024-06-03 10:48:36 [INFO]: Model files will be saved to results_block_rate05/PeMS/Informer_PeMS/round_2/20240603_T104836
2024-06-03 10:48:36 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Informer_PeMS/round_2/20240603_T104836/tensorboard
2024-06-03 10:48:37 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 10:48:56 [INFO]: Epoch 001 - training loss: 0.8965, validation loss: 0.7028
2024-06-03 10:49:14 [INFO]: Epoch 002 - training loss: 0.5860, validation loss: 0.6372
2024-06-03 10:49:31 [INFO]: Epoch 003 - training loss: 0.5314, validation loss: 0.5886
2024-06-03 10:49:47 [INFO]: Epoch 004 - training loss: 0.5013, validation loss: 0.5723
2024-06-03 10:50:03 [INFO]: Epoch 005 - training loss: 0.4807, validation loss: 0.5645
2024-06-03 10:50:21 [INFO]: Epoch 006 - training loss: 0.4779, validation loss: 0.5622
2024-06-03 10:50:38 [INFO]: Epoch 007 - training loss: 0.4592, validation loss: 0.5560
2024-06-03 10:50:57 [INFO]: Epoch 008 - training loss: 0.4516, validation loss: 0.5511
2024-06-03 10:51:15 [INFO]: Epoch 009 - training loss: 0.4421, validation loss: 0.5547
2024-06-03 10:51:30 [INFO]: Epoch 010 - training loss: 0.4367, validation loss: 0.5501
2024-06-03 10:51:48 [INFO]: Epoch 011 - training loss: 0.4271, validation loss: 0.5419
2024-06-03 10:52:07 [INFO]: Epoch 012 - training loss: 0.4228, validation loss: 0.5366
2024-06-03 10:52:25 [INFO]: Epoch 013 - training loss: 0.4170, validation loss: 0.5400
2024-06-03 10:52:45 [INFO]: Epoch 014 - training loss: 0.4095, validation loss: 0.5376
2024-06-03 10:53:01 [INFO]: Epoch 015 - training loss: 0.4007, validation loss: 0.5385
2024-06-03 10:53:19 [INFO]: Epoch 016 - training loss: 0.3994, validation loss: 0.5270
2024-06-03 10:53:36 [INFO]: Epoch 017 - training loss: 0.3917, validation loss: 0.5318
2024-06-03 10:53:54 [INFO]: Epoch 018 - training loss: 0.3907, validation loss: 0.5273
2024-06-03 10:54:12 [INFO]: Epoch 019 - training loss: 0.3845, validation loss: 0.5279
2024-06-03 10:54:28 [INFO]: Epoch 020 - training loss: 0.3756, validation loss: 0.5249
2024-06-03 10:54:43 [INFO]: Epoch 021 - training loss: 0.3729, validation loss: 0.5276
2024-06-03 10:54:59 [INFO]: Epoch 022 - training loss: 0.3667, validation loss: 0.5247
2024-06-03 10:55:17 [INFO]: Epoch 023 - training loss: 0.3640, validation loss: 0.5225
2024-06-03 10:55:34 [INFO]: Epoch 024 - training loss: 0.3591, validation loss: 0.5200
2024-06-03 10:55:51 [INFO]: Epoch 025 - training loss: 0.3525, validation loss: 0.5205
2024-06-03 10:56:07 [INFO]: Epoch 026 - training loss: 0.3520, validation loss: 0.5197
2024-06-03 10:56:22 [INFO]: Epoch 027 - training loss: 0.3475, validation loss: 0.5174
2024-06-03 10:56:37 [INFO]: Epoch 028 - training loss: 0.3404, validation loss: 0.5149
2024-06-03 10:56:55 [INFO]: Epoch 029 - training loss: 0.3398, validation loss: 0.5140
2024-06-03 10:57:12 [INFO]: Epoch 030 - training loss: 0.3315, validation loss: 0.5143
2024-06-03 10:57:29 [INFO]: Epoch 031 - training loss: 0.3338, validation loss: 0.5145
2024-06-03 10:57:43 [INFO]: Epoch 032 - training loss: 0.3342, validation loss: 0.5163
2024-06-03 10:57:59 [INFO]: Epoch 033 - training loss: 0.3287, validation loss: 0.5138
2024-06-03 10:58:16 [INFO]: Epoch 034 - training loss: 0.3265, validation loss: 0.5090
2024-06-03 10:58:32 [INFO]: Epoch 035 - training loss: 0.3224, validation loss: 0.5108
2024-06-03 10:58:50 [INFO]: Epoch 036 - training loss: 0.3173, validation loss: 0.5143
2024-06-03 10:59:07 [INFO]: Epoch 037 - training loss: 0.3147, validation loss: 0.5052
2024-06-03 10:59:21 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.5080
2024-06-03 10:59:37 [INFO]: Epoch 039 - training loss: 0.3124, validation loss: 0.5085
2024-06-03 10:59:53 [INFO]: Epoch 040 - training loss: 0.3112, validation loss: 0.5078
2024-06-03 11:00:07 [INFO]: Epoch 041 - training loss: 0.3086, validation loss: 0.5019
2024-06-03 11:00:22 [INFO]: Epoch 042 - training loss: 0.3072, validation loss: 0.5076
2024-06-03 11:00:35 [INFO]: Epoch 043 - training loss: 0.3060, validation loss: 0.5064
2024-06-03 11:00:47 [INFO]: Epoch 044 - training loss: 0.3058, validation loss: 0.5054
2024-06-03 11:01:01 [INFO]: Epoch 045 - training loss: 0.2987, validation loss: 0.5053
2024-06-03 11:01:15 [INFO]: Epoch 046 - training loss: 0.2990, validation loss: 0.5014
2024-06-03 11:01:28 [INFO]: Epoch 047 - training loss: 0.2957, validation loss: 0.5043
2024-06-03 11:01:42 [INFO]: Epoch 048 - training loss: 0.2937, validation loss: 0.5021
2024-06-03 11:01:54 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.5039
2024-06-03 11:02:07 [INFO]: Epoch 050 - training loss: 0.2896, validation loss: 0.5022
2024-06-03 11:02:19 [INFO]: Epoch 051 - training loss: 0.2914, validation loss: 0.5048
2024-06-03 11:02:33 [INFO]: Epoch 052 - training loss: 0.2911, validation loss: 0.5019
2024-06-03 11:02:46 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.5019
2024-06-03 11:03:00 [INFO]: Epoch 054 - training loss: 0.2858, validation loss: 0.5030
2024-06-03 11:03:14 [INFO]: Epoch 055 - training loss: 0.2839, validation loss: 0.4990
2024-06-03 11:03:25 [INFO]: Epoch 056 - training loss: 0.2833, validation loss: 0.4987
2024-06-03 11:03:39 [INFO]: Epoch 057 - training loss: 0.2860, validation loss: 0.4998
2024-06-03 11:03:52 [INFO]: Epoch 058 - training loss: 0.2821, validation loss: 0.4983
2024-06-03 11:04:05 [INFO]: Epoch 059 - training loss: 0.2848, validation loss: 0.5000
2024-06-03 11:04:18 [INFO]: Epoch 060 - training loss: 0.2791, validation loss: 0.4994
2024-06-03 11:04:31 [INFO]: Epoch 061 - training loss: 0.2792, validation loss: 0.4970
2024-06-03 11:04:42 [INFO]: Epoch 062 - training loss: 0.2773, validation loss: 0.4985
2024-06-03 11:04:55 [INFO]: Epoch 063 - training loss: 0.2760, validation loss: 0.4997
2024-06-03 11:05:08 [INFO]: Epoch 064 - training loss: 0.2788, validation loss: 0.4986
2024-06-03 11:05:21 [INFO]: Epoch 065 - training loss: 0.2744, validation loss: 0.5005
2024-06-03 11:05:34 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.5001
2024-06-03 11:05:47 [INFO]: Epoch 067 - training loss: 0.2696, validation loss: 0.5007
2024-06-03 11:05:58 [INFO]: Epoch 068 - training loss: 0.2688, validation loss: 0.5016
2024-06-03 11:06:12 [INFO]: Epoch 069 - training loss: 0.2683, validation loss: 0.4979
2024-06-03 11:06:25 [INFO]: Epoch 070 - training loss: 0.2697, validation loss: 0.4976
2024-06-03 11:06:38 [INFO]: Epoch 071 - training loss: 0.2701, validation loss: 0.4972
2024-06-03 11:06:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:06:38 [INFO]: Finished training. The best model is from epoch#61.
2024-06-03 11:06:39 [INFO]: Saved the model to results_block_rate05/PeMS/Informer_PeMS/round_2/20240603_T104836/Informer.pypots
2024-06-03 11:06:48 [INFO]: Successfully saved to results_block_rate05/PeMS/Informer_PeMS/round_2/imputation.pkl
2024-06-03 11:06:48 [INFO]: Round2 - Informer on PeMS: MAE=0.3482, MSE=0.7315, MRE=0.4169
2024-06-03 11:06:48 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 11:06:48 [INFO]: Using the given device: cuda:0
2024-06-03 11:06:48 [INFO]: Model files will be saved to results_block_rate05/PeMS/Informer_PeMS/round_3/20240603_T110648
2024-06-03 11:06:48 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Informer_PeMS/round_3/20240603_T110648/tensorboard
2024-06-03 11:06:49 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 11:07:02 [INFO]: Epoch 001 - training loss: 0.8926, validation loss: 0.7000
2024-06-03 11:07:13 [INFO]: Epoch 002 - training loss: 0.5860, validation loss: 0.6294
2024-06-03 11:07:25 [INFO]: Epoch 003 - training loss: 0.5337, validation loss: 0.5863
2024-06-03 11:07:38 [INFO]: Epoch 004 - training loss: 0.4997, validation loss: 0.5727
2024-06-03 11:07:51 [INFO]: Epoch 005 - training loss: 0.4833, validation loss: 0.5617
2024-06-03 11:08:05 [INFO]: Epoch 006 - training loss: 0.4722, validation loss: 0.5640
2024-06-03 11:08:19 [INFO]: Epoch 007 - training loss: 0.4593, validation loss: 0.5557
2024-06-03 11:08:30 [INFO]: Epoch 008 - training loss: 0.4535, validation loss: 0.5486
2024-06-03 11:08:42 [INFO]: Epoch 009 - training loss: 0.4422, validation loss: 0.5468
2024-06-03 11:08:56 [INFO]: Epoch 010 - training loss: 0.4330, validation loss: 0.5493
2024-06-03 11:09:07 [INFO]: Epoch 011 - training loss: 0.4260, validation loss: 0.5480
2024-06-03 11:09:20 [INFO]: Epoch 012 - training loss: 0.4163, validation loss: 0.5400
2024-06-03 11:09:33 [INFO]: Epoch 013 - training loss: 0.4104, validation loss: 0.5345
2024-06-03 11:09:45 [INFO]: Epoch 014 - training loss: 0.4143, validation loss: 0.5350
2024-06-03 11:09:56 [INFO]: Epoch 015 - training loss: 0.4019, validation loss: 0.5355
2024-06-03 11:10:09 [INFO]: Epoch 016 - training loss: 0.3972, validation loss: 0.5332
2024-06-03 11:10:22 [INFO]: Epoch 017 - training loss: 0.3964, validation loss: 0.5282
2024-06-03 11:10:35 [INFO]: Epoch 018 - training loss: 0.3893, validation loss: 0.5318
2024-06-03 11:10:48 [INFO]: Epoch 019 - training loss: 0.3844, validation loss: 0.5270
2024-06-03 11:10:59 [INFO]: Epoch 020 - training loss: 0.3792, validation loss: 0.5261
2024-06-03 11:11:11 [INFO]: Epoch 021 - training loss: 0.3717, validation loss: 0.5252
2024-06-03 11:11:23 [INFO]: Epoch 022 - training loss: 0.3693, validation loss: 0.5236
2024-06-03 11:11:37 [INFO]: Epoch 023 - training loss: 0.3625, validation loss: 0.5234
2024-06-03 11:11:50 [INFO]: Epoch 024 - training loss: 0.3596, validation loss: 0.5218
2024-06-03 11:12:03 [INFO]: Epoch 025 - training loss: 0.3539, validation loss: 0.5231
2024-06-03 11:12:16 [INFO]: Epoch 026 - training loss: 0.3580, validation loss: 0.5153
2024-06-03 11:12:27 [INFO]: Epoch 027 - training loss: 0.3492, validation loss: 0.5180
2024-06-03 11:12:39 [INFO]: Epoch 028 - training loss: 0.3415, validation loss: 0.5179
2024-06-03 11:12:53 [INFO]: Epoch 029 - training loss: 0.3375, validation loss: 0.5135
2024-06-03 11:13:06 [INFO]: Epoch 030 - training loss: 0.3363, validation loss: 0.5126
2024-06-03 11:13:19 [INFO]: Epoch 031 - training loss: 0.3329, validation loss: 0.5142
2024-06-03 11:13:31 [INFO]: Epoch 032 - training loss: 0.3347, validation loss: 0.5152
2024-06-03 11:13:42 [INFO]: Epoch 033 - training loss: 0.3339, validation loss: 0.5112
2024-06-03 11:13:54 [INFO]: Epoch 034 - training loss: 0.3267, validation loss: 0.5184
2024-06-03 11:14:07 [INFO]: Epoch 035 - training loss: 0.3257, validation loss: 0.5135
2024-06-03 11:14:20 [INFO]: Epoch 036 - training loss: 0.3218, validation loss: 0.5038
2024-06-03 11:14:33 [INFO]: Epoch 037 - training loss: 0.3185, validation loss: 0.5077
2024-06-03 11:14:47 [INFO]: Epoch 038 - training loss: 0.3131, validation loss: 0.5082
2024-06-03 11:14:58 [INFO]: Epoch 039 - training loss: 0.3143, validation loss: 0.5103
2024-06-03 11:15:10 [INFO]: Epoch 040 - training loss: 0.3082, validation loss: 0.5101
2024-06-03 11:15:24 [INFO]: Epoch 041 - training loss: 0.3056, validation loss: 0.5139
2024-06-03 11:15:37 [INFO]: Epoch 042 - training loss: 0.3056, validation loss: 0.5129
2024-06-03 11:15:51 [INFO]: Epoch 043 - training loss: 0.3012, validation loss: 0.5066
2024-06-03 11:16:04 [INFO]: Epoch 044 - training loss: 0.3003, validation loss: 0.5063
2024-06-03 11:16:15 [INFO]: Epoch 045 - training loss: 0.2995, validation loss: 0.5103
2024-06-03 11:16:27 [INFO]: Epoch 046 - training loss: 0.2989, validation loss: 0.5054
2024-06-03 11:16:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:16:27 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 11:16:27 [INFO]: Saved the model to results_block_rate05/PeMS/Informer_PeMS/round_3/20240603_T110648/Informer.pypots
2024-06-03 11:16:37 [INFO]: Successfully saved to results_block_rate05/PeMS/Informer_PeMS/round_3/imputation.pkl
2024-06-03 11:16:37 [INFO]: Round3 - Informer on PeMS: MAE=0.3496, MSE=0.7358, MRE=0.4186
2024-06-03 11:16:37 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 11:16:37 [INFO]: Using the given device: cuda:0
2024-06-03 11:16:37 [INFO]: Model files will be saved to results_block_rate05/PeMS/Informer_PeMS/round_4/20240603_T111637
2024-06-03 11:16:37 [INFO]: Tensorboard file will be saved to results_block_rate05/PeMS/Informer_PeMS/round_4/20240603_T111637/tensorboard
2024-06-03 11:16:38 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 11:16:52 [INFO]: Epoch 001 - training loss: 0.8979, validation loss: 0.7025
2024-06-03 11:17:05 [INFO]: Epoch 002 - training loss: 0.6000, validation loss: 0.6202
2024-06-03 11:17:18 [INFO]: Epoch 003 - training loss: 0.5349, validation loss: 0.5833
2024-06-03 11:17:30 [INFO]: Epoch 004 - training loss: 0.4991, validation loss: 0.5722
2024-06-03 11:17:41 [INFO]: Epoch 005 - training loss: 0.4838, validation loss: 0.5582
2024-06-03 11:17:54 [INFO]: Epoch 006 - training loss: 0.4724, validation loss: 0.5612
2024-06-03 11:18:08 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.5556
2024-06-03 11:18:21 [INFO]: Epoch 008 - training loss: 0.4509, validation loss: 0.5680
2024-06-03 11:18:34 [INFO]: Epoch 009 - training loss: 0.4460, validation loss: 0.5451
2024-06-03 11:18:46 [INFO]: Epoch 010 - training loss: 0.4317, validation loss: 0.5451
2024-06-03 11:18:57 [INFO]: Epoch 011 - training loss: 0.4260, validation loss: 0.5477
2024-06-03 11:19:10 [INFO]: Epoch 012 - training loss: 0.4161, validation loss: 0.5440
2024-06-03 11:19:24 [INFO]: Epoch 013 - training loss: 0.4152, validation loss: 0.5417
2024-06-03 11:19:37 [INFO]: Epoch 014 - training loss: 0.4039, validation loss: 0.5352
2024-06-03 11:19:49 [INFO]: Epoch 015 - training loss: 0.4015, validation loss: 0.5339
2024-06-03 11:20:02 [INFO]: Epoch 016 - training loss: 0.3976, validation loss: 0.5324
2024-06-03 11:20:13 [INFO]: Epoch 017 - training loss: 0.3936, validation loss: 0.5380
2024-06-03 11:20:25 [INFO]: Epoch 018 - training loss: 0.3917, validation loss: 0.5303
2024-06-03 11:20:38 [INFO]: Epoch 019 - training loss: 0.3814, validation loss: 0.5270
2024-06-03 11:20:51 [INFO]: Epoch 020 - training loss: 0.3766, validation loss: 0.5221
2024-06-03 11:21:05 [INFO]: Epoch 021 - training loss: 0.3737, validation loss: 0.5197
2024-06-03 11:21:18 [INFO]: Epoch 022 - training loss: 0.3674, validation loss: 0.5240
2024-06-03 11:21:30 [INFO]: Epoch 023 - training loss: 0.3680, validation loss: 0.5186
2024-06-03 11:21:42 [INFO]: Epoch 024 - training loss: 0.3633, validation loss: 0.5191
2024-06-03 11:21:56 [INFO]: Epoch 025 - training loss: 0.3591, validation loss: 0.5152
2024-06-03 11:22:09 [INFO]: Epoch 026 - training loss: 0.3536, validation loss: 0.5151
2024-06-03 11:22:22 [INFO]: Epoch 027 - training loss: 0.3437, validation loss: 0.5146
2024-06-03 11:22:34 [INFO]: Epoch 028 - training loss: 0.3420, validation loss: 0.5171
2024-06-03 11:22:45 [INFO]: Epoch 029 - training loss: 0.3401, validation loss: 0.5153
2024-06-03 11:22:54 [INFO]: Epoch 030 - training loss: 0.3356, validation loss: 0.5123
2024-06-03 11:23:05 [INFO]: Epoch 031 - training loss: 0.3330, validation loss: 0.5102
2024-06-03 11:23:15 [INFO]: Epoch 032 - training loss: 0.3334, validation loss: 0.5102
2024-06-03 11:23:26 [INFO]: Epoch 033 - training loss: 0.3349, validation loss: 0.5121
2024-06-03 11:23:35 [INFO]: Epoch 034 - training loss: 0.3263, validation loss: 0.5101
2024-06-03 11:23:45 [INFO]: Epoch 035 - training loss: 0.3207, validation loss: 0.5097
2024-06-03 11:23:53 [INFO]: Epoch 036 - training loss: 0.3152, validation loss: 0.5110
2024-06-03 11:24:04 [INFO]: Epoch 037 - training loss: 0.3150, validation loss: 0.5109
2024-06-03 11:24:15 [INFO]: Epoch 038 - training loss: 0.3134, validation loss: 0.5038
2024-06-03 11:24:26 [INFO]: Epoch 039 - training loss: 0.3122, validation loss: 0.5076
2024-06-03 11:24:37 [INFO]: Epoch 040 - training loss: 0.3134, validation loss: 0.5052
2024-06-03 11:24:47 [INFO]: Epoch 041 - training loss: 0.3083, validation loss: 0.5065
2024-06-03 11:24:55 [INFO]: Epoch 042 - training loss: 0.3067, validation loss: 0.5001
2024-06-03 11:25:05 [INFO]: Epoch 043 - training loss: 0.3061, validation loss: 0.5019
2024-06-03 11:25:15 [INFO]: Epoch 044 - training loss: 0.3062, validation loss: 0.5014
2024-06-03 11:25:26 [INFO]: Epoch 045 - training loss: 0.3016, validation loss: 0.5074
2024-06-03 11:25:37 [INFO]: Epoch 046 - training loss: 0.3012, validation loss: 0.5034
2024-06-03 11:25:47 [INFO]: Epoch 047 - training loss: 0.2962, validation loss: 0.4987
2024-06-03 11:25:57 [INFO]: Epoch 048 - training loss: 0.2945, validation loss: 0.4981
2024-06-03 11:26:05 [INFO]: Epoch 049 - training loss: 0.2966, validation loss: 0.5064
2024-06-03 11:26:16 [INFO]: Epoch 050 - training loss: 0.2985, validation loss: 0.5009
2024-06-03 11:26:26 [INFO]: Epoch 051 - training loss: 0.2930, validation loss: 0.5026
2024-06-03 11:26:37 [INFO]: Epoch 052 - training loss: 0.2919, validation loss: 0.4980
2024-06-03 11:26:48 [INFO]: Epoch 053 - training loss: 0.2904, validation loss: 0.5008
2024-06-03 11:26:58 [INFO]: Epoch 054 - training loss: 0.2865, validation loss: 0.5038
2024-06-03 11:27:07 [INFO]: Epoch 055 - training loss: 0.2843, validation loss: 0.4972
2024-06-03 11:27:17 [INFO]: Epoch 056 - training loss: 0.2818, validation loss: 0.4981
2024-06-03 11:27:27 [INFO]: Epoch 057 - training loss: 0.2803, validation loss: 0.4963
2024-06-03 11:27:38 [INFO]: Epoch 058 - training loss: 0.2790, validation loss: 0.5013
2024-06-03 11:27:48 [INFO]: Epoch 059 - training loss: 0.2834, validation loss: 0.4958
2024-06-03 11:27:58 [INFO]: Epoch 060 - training loss: 0.2834, validation loss: 0.4983
2024-06-03 11:28:08 [INFO]: Epoch 061 - training loss: 0.2751, validation loss: 0.5020
2024-06-03 11:28:17 [INFO]: Epoch 062 - training loss: 0.2743, validation loss: 0.4987
2024-06-03 11:28:28 [INFO]: Epoch 063 - training loss: 0.2748, validation loss: 0.4944
2024-06-03 11:28:38 [INFO]: Epoch 064 - training loss: 0.2759, validation loss: 0.4993
2024-06-03 11:28:48 [INFO]: Epoch 065 - training loss: 0.2734, validation loss: 0.4989
2024-06-03 11:28:59 [INFO]: Epoch 066 - training loss: 0.2731, validation loss: 0.4964
2024-06-03 11:29:09 [INFO]: Epoch 067 - training loss: 0.2691, validation loss: 0.4988
2024-06-03 11:29:18 [INFO]: Epoch 068 - training loss: 0.2675, validation loss: 0.4976
2024-06-03 11:29:27 [INFO]: Epoch 069 - training loss: 0.2687, validation loss: 0.4962
2024-06-03 11:29:38 [INFO]: Epoch 070 - training loss: 0.2677, validation loss: 0.4973
2024-06-03 11:29:47 [INFO]: Epoch 071 - training loss: 0.2682, validation loss: 0.4999
2024-06-03 11:29:58 [INFO]: Epoch 072 - training loss: 0.2654, validation loss: 0.4971
2024-06-03 11:30:08 [INFO]: Epoch 073 - training loss: 0.2633, validation loss: 0.5021
2024-06-03 11:30:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:30:08 [INFO]: Finished training. The best model is from epoch#63.
2024-06-03 11:30:08 [INFO]: Saved the model to results_block_rate05/PeMS/Informer_PeMS/round_4/20240603_T111637/Informer.pypots
2024-06-03 11:30:16 [INFO]: Successfully saved to results_block_rate05/PeMS/Informer_PeMS/round_4/imputation.pkl
2024-06-03 11:30:16 [INFO]: Round4 - Informer on PeMS: MAE=0.3541, MSE=0.7360, MRE=0.4240
2024-06-03 11:30:16 [INFO]: Done! Final results:
Averaged Informer (13,149,022 params) on PeMS: MAE=0.3506 ± 0.0022365400549346297, MSE=0.7384 ± 0.006493239269046584, MRE=0.4198 ± 0.0026779482228843797, average inference time=2.05
