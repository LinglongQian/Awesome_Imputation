2024-06-03 10:17:21 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:17:21 [INFO]: Using the given device: cuda:0
2024-06-03 10:17:25 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_0/20240603_T101725
2024-06-03 10:17:25 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_0/20240603_T101725/tensorboard
2024-06-03 10:17:29 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 384,796
2024-06-03 10:17:42 [INFO]: Epoch 001 - training loss: 7119.4164, validation loss: 1.0812
2024-06-03 10:17:43 [INFO]: Epoch 002 - training loss: 4515.4505, validation loss: 0.9436
2024-06-03 10:17:45 [INFO]: Epoch 003 - training loss: 4499.1101, validation loss: 0.9507
2024-06-03 10:17:47 [INFO]: Epoch 004 - training loss: 4525.7760, validation loss: 0.9423
2024-06-03 10:17:49 [INFO]: Epoch 005 - training loss: 4493.8211, validation loss: 0.9920
2024-06-03 10:17:51 [INFO]: Epoch 006 - training loss: 4485.4220, validation loss: 0.8951
2024-06-03 10:17:53 [INFO]: Epoch 007 - training loss: 4490.1229, validation loss: 0.9228
2024-06-03 10:17:55 [INFO]: Epoch 008 - training loss: 4497.3432, validation loss: 0.9108
2024-06-03 10:17:57 [INFO]: Epoch 009 - training loss: 4472.3712, validation loss: 1.0457
2024-06-03 10:17:59 [INFO]: Epoch 010 - training loss: 4472.6905, validation loss: 0.9863
2024-06-03 10:18:01 [INFO]: Epoch 011 - training loss: 4469.3693, validation loss: 0.8457
2024-06-03 10:18:04 [INFO]: Epoch 012 - training loss: 4450.2728, validation loss: 0.9450
2024-06-03 10:18:06 [INFO]: Epoch 013 - training loss: 4442.8451, validation loss: 0.8717
2024-06-03 10:18:08 [INFO]: Epoch 014 - training loss: 4437.6022, validation loss: 0.8129
2024-06-03 10:18:10 [INFO]: Epoch 015 - training loss: 4438.2343, validation loss: 0.9645
2024-06-03 10:18:13 [INFO]: Epoch 016 - training loss: 4450.7488, validation loss: 0.8915
2024-06-03 10:18:15 [INFO]: Epoch 017 - training loss: 4437.2426, validation loss: 0.8243
2024-06-03 10:18:17 [INFO]: Epoch 018 - training loss: 4432.3163, validation loss: 0.7782
2024-06-03 10:18:20 [INFO]: Epoch 019 - training loss: 4427.3891, validation loss: 0.6640
2024-06-03 10:18:22 [INFO]: Epoch 020 - training loss: 4425.3086, validation loss: 0.6972
2024-06-03 10:18:24 [INFO]: Epoch 021 - training loss: 4424.3599, validation loss: 0.6978
2024-06-03 10:18:27 [INFO]: Epoch 022 - training loss: 4422.8581, validation loss: 0.6490
2024-06-03 10:18:29 [INFO]: Epoch 023 - training loss: 4421.6664, validation loss: 0.6458
2024-06-03 10:18:31 [INFO]: Epoch 024 - training loss: 4420.2803, validation loss: 0.6741
2024-06-03 10:18:33 [INFO]: Epoch 025 - training loss: 4420.7199, validation loss: 0.6994
2024-06-03 10:18:35 [INFO]: Epoch 026 - training loss: 4419.2983, validation loss: 0.6492
2024-06-03 10:18:37 [INFO]: Epoch 027 - training loss: 4419.3338, validation loss: 0.6238
2024-06-03 10:18:39 [INFO]: Epoch 028 - training loss: 4417.3431, validation loss: 0.6039
2024-06-03 10:18:41 [INFO]: Epoch 029 - training loss: 4417.8218, validation loss: 0.6528
2024-06-03 10:18:43 [INFO]: Epoch 030 - training loss: 4416.1235, validation loss: 0.6194
2024-06-03 10:18:46 [INFO]: Epoch 031 - training loss: 4414.4709, validation loss: 0.6240
2024-06-03 10:18:48 [INFO]: Epoch 032 - training loss: 4415.0313, validation loss: 0.6245
2024-06-03 10:18:50 [INFO]: Epoch 033 - training loss: 4414.7879, validation loss: 0.5913
2024-06-03 10:18:52 [INFO]: Epoch 034 - training loss: 4414.7351, validation loss: 0.5958
2024-06-03 10:18:55 [INFO]: Epoch 035 - training loss: 4414.8627, validation loss: 0.6155
2024-06-03 10:18:57 [INFO]: Epoch 036 - training loss: 4415.7047, validation loss: 0.5996
2024-06-03 10:18:59 [INFO]: Epoch 037 - training loss: 4415.4316, validation loss: 0.6246
2024-06-03 10:19:01 [INFO]: Epoch 038 - training loss: 4414.0357, validation loss: 0.6461
2024-06-03 10:19:03 [INFO]: Epoch 039 - training loss: 4413.3891, validation loss: 0.6493
2024-06-03 10:19:05 [INFO]: Epoch 040 - training loss: 4415.7100, validation loss: 0.6405
2024-06-03 10:19:07 [INFO]: Epoch 041 - training loss: 4414.2780, validation loss: 0.6043
2024-06-03 10:19:09 [INFO]: Epoch 042 - training loss: 4415.0519, validation loss: 0.6535
2024-06-03 10:19:11 [INFO]: Epoch 043 - training loss: 4415.4650, validation loss: 0.6271
2024-06-03 10:19:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:19:11 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 10:19:11 [INFO]: Saved the model to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_0/20240603_T101725/GPVAE.pypots
2024-06-03 10:19:14 [INFO]: Successfully saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_0/imputation.pkl
2024-06-03 10:19:14 [INFO]: Round0 - GPVAE on ETT_h1: MAE=0.6346, MSE=0.7617, MRE=0.7880
2024-06-03 10:19:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:19:14 [INFO]: Using the given device: cuda:0
2024-06-03 10:19:14 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_1/20240603_T101914
2024-06-03 10:19:14 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_1/20240603_T101914/tensorboard
2024-06-03 10:19:14 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 384,796
2024-06-03 10:19:16 [INFO]: Epoch 001 - training loss: 7076.4736, validation loss: 0.8869
2024-06-03 10:19:18 [INFO]: Epoch 002 - training loss: 4516.1744, validation loss: 1.0264
2024-06-03 10:19:20 [INFO]: Epoch 003 - training loss: 4515.4438, validation loss: 0.9565
2024-06-03 10:19:21 [INFO]: Epoch 004 - training loss: 4502.5005, validation loss: 0.9386
2024-06-03 10:19:23 [INFO]: Epoch 005 - training loss: 4477.4714, validation loss: 0.8809
2024-06-03 10:19:25 [INFO]: Epoch 006 - training loss: 4459.0991, validation loss: 1.1000
2024-06-03 10:19:28 [INFO]: Epoch 007 - training loss: 4489.4214, validation loss: 0.9083
2024-06-03 10:19:30 [INFO]: Epoch 008 - training loss: 4462.9293, validation loss: 0.8911
2024-06-03 10:19:32 [INFO]: Epoch 009 - training loss: 4477.5648, validation loss: 0.9327
2024-06-03 10:19:34 [INFO]: Epoch 010 - training loss: 4468.3748, validation loss: 0.9195
2024-06-03 10:19:36 [INFO]: Epoch 011 - training loss: 4456.9930, validation loss: 0.9009
2024-06-03 10:19:39 [INFO]: Epoch 012 - training loss: 4440.2356, validation loss: 0.8296
2024-06-03 10:19:41 [INFO]: Epoch 013 - training loss: 4434.3760, validation loss: 0.9155
2024-06-03 10:19:43 [INFO]: Epoch 014 - training loss: 4441.0179, validation loss: 0.8755
2024-06-03 10:19:46 [INFO]: Epoch 015 - training loss: 4437.6059, validation loss: 0.8510
2024-06-03 10:19:47 [INFO]: Epoch 016 - training loss: 4431.8668, validation loss: 0.8260
2024-06-03 10:19:49 [INFO]: Epoch 017 - training loss: 4428.9556, validation loss: 0.8127
2024-06-03 10:19:52 [INFO]: Epoch 018 - training loss: 4429.0621, validation loss: 0.8169
2024-06-03 10:19:54 [INFO]: Epoch 019 - training loss: 4425.0819, validation loss: 0.7752
2024-06-03 10:19:56 [INFO]: Epoch 020 - training loss: 4423.1258, validation loss: 0.8100
2024-06-03 10:19:58 [INFO]: Epoch 021 - training loss: 4423.6639, validation loss: 0.8044
2024-06-03 10:20:00 [INFO]: Epoch 022 - training loss: 4421.6628, validation loss: 0.7480
2024-06-03 10:20:02 [INFO]: Epoch 023 - training loss: 4421.9785, validation loss: 0.7032
2024-06-03 10:20:04 [INFO]: Epoch 024 - training loss: 4421.4429, validation loss: 0.7224
2024-06-03 10:20:06 [INFO]: Epoch 025 - training loss: 4420.6482, validation loss: 0.7188
2024-06-03 10:20:09 [INFO]: Epoch 026 - training loss: 4421.4826, validation loss: 0.7368
2024-06-03 10:20:11 [INFO]: Epoch 027 - training loss: 4420.9488, validation loss: 0.7096
2024-06-03 10:20:13 [INFO]: Epoch 028 - training loss: 4419.5903, validation loss: 0.6449
2024-06-03 10:20:15 [INFO]: Epoch 029 - training loss: 4419.7976, validation loss: 0.6416
2024-06-03 10:20:17 [INFO]: Epoch 030 - training loss: 4417.8199, validation loss: 0.6489
2024-06-03 10:20:20 [INFO]: Epoch 031 - training loss: 4417.7869, validation loss: 0.6775
2024-06-03 10:20:22 [INFO]: Epoch 032 - training loss: 4416.7570, validation loss: 0.5958
2024-06-03 10:20:24 [INFO]: Epoch 033 - training loss: 4414.7128, validation loss: 0.6216
2024-06-03 10:20:26 [INFO]: Epoch 034 - training loss: 4414.2587, validation loss: 0.6082
2024-06-03 10:20:28 [INFO]: Epoch 035 - training loss: 4414.1165, validation loss: 0.6086
2024-06-03 10:20:30 [INFO]: Epoch 036 - training loss: 4415.0176, validation loss: 0.6467
2024-06-03 10:20:32 [INFO]: Epoch 037 - training loss: 4414.7114, validation loss: 0.6282
2024-06-03 10:20:35 [INFO]: Epoch 038 - training loss: 4413.5015, validation loss: 0.6201
2024-06-03 10:20:37 [INFO]: Epoch 039 - training loss: 4413.9832, validation loss: 0.5964
2024-06-03 10:20:39 [INFO]: Epoch 040 - training loss: 4414.1721, validation loss: 0.5578
2024-06-03 10:20:42 [INFO]: Epoch 041 - training loss: 4412.9545, validation loss: 0.5947
2024-06-03 10:20:44 [INFO]: Epoch 042 - training loss: 4413.7995, validation loss: 0.6005
2024-06-03 10:20:46 [INFO]: Epoch 043 - training loss: 4412.2051, validation loss: 0.6184
2024-06-03 10:20:48 [INFO]: Epoch 044 - training loss: 4412.4816, validation loss: 0.5878
2024-06-03 10:20:51 [INFO]: Epoch 045 - training loss: 4412.4839, validation loss: 0.5757
2024-06-03 10:20:53 [INFO]: Epoch 046 - training loss: 4412.8778, validation loss: 0.5850
2024-06-03 10:20:55 [INFO]: Epoch 047 - training loss: 4412.7854, validation loss: 0.6190
2024-06-03 10:20:58 [INFO]: Epoch 048 - training loss: 4412.2588, validation loss: 0.5544
2024-06-03 10:21:00 [INFO]: Epoch 049 - training loss: 4411.2342, validation loss: 0.5933
2024-06-03 10:21:02 [INFO]: Epoch 050 - training loss: 4411.3795, validation loss: 0.5858
2024-06-03 10:21:04 [INFO]: Epoch 051 - training loss: 4412.4088, validation loss: 0.5753
2024-06-03 10:21:06 [INFO]: Epoch 052 - training loss: 4410.9080, validation loss: 0.5537
2024-06-03 10:21:08 [INFO]: Epoch 053 - training loss: 4411.2250, validation loss: 0.6440
2024-06-03 10:21:10 [INFO]: Epoch 054 - training loss: 4411.4856, validation loss: 0.6085
2024-06-03 10:21:12 [INFO]: Epoch 055 - training loss: 4411.1152, validation loss: 0.5905
2024-06-03 10:21:13 [INFO]: Epoch 056 - training loss: 4413.1401, validation loss: 0.5876
2024-06-03 10:21:15 [INFO]: Epoch 057 - training loss: 4412.4536, validation loss: 0.5960
2024-06-03 10:21:17 [INFO]: Epoch 058 - training loss: 4411.8793, validation loss: 0.5793
2024-06-03 10:21:19 [INFO]: Epoch 059 - training loss: 4411.3786, validation loss: 0.5915
2024-06-03 10:21:22 [INFO]: Epoch 060 - training loss: 4410.4916, validation loss: 0.6691
2024-06-03 10:21:24 [INFO]: Epoch 061 - training loss: 4411.1458, validation loss: 0.5847
2024-06-03 10:21:26 [INFO]: Epoch 062 - training loss: 4410.3463, validation loss: 0.5615
2024-06-03 10:21:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:26 [INFO]: Finished training. The best model is from epoch#52.
2024-06-03 10:21:26 [INFO]: Saved the model to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_1/20240603_T101914/GPVAE.pypots
2024-06-03 10:21:28 [INFO]: Successfully saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_1/imputation.pkl
2024-06-03 10:21:28 [INFO]: Round1 - GPVAE on ETT_h1: MAE=0.5873, MSE=0.6737, MRE=0.7292
2024-06-03 10:21:28 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:21:28 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:29 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_2/20240603_T102128
2024-06-03 10:21:29 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_2/20240603_T102128/tensorboard
2024-06-03 10:21:29 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 384,796
2024-06-03 10:21:30 [INFO]: Epoch 001 - training loss: 7224.2917, validation loss: 0.9636
2024-06-03 10:21:32 [INFO]: Epoch 002 - training loss: 4485.5833, validation loss: 0.9067
2024-06-03 10:21:34 [INFO]: Epoch 003 - training loss: 4477.3288, validation loss: 1.0007
2024-06-03 10:21:36 [INFO]: Epoch 004 - training loss: 4498.4113, validation loss: 0.9062
2024-06-03 10:21:37 [INFO]: Epoch 005 - training loss: 4479.2136, validation loss: 0.8852
2024-06-03 10:21:39 [INFO]: Epoch 006 - training loss: 4530.8952, validation loss: 0.8800
2024-06-03 10:21:40 [INFO]: Epoch 007 - training loss: 4479.7121, validation loss: 0.9330
2024-06-03 10:21:42 [INFO]: Epoch 008 - training loss: 4473.4825, validation loss: 0.8715
2024-06-03 10:21:44 [INFO]: Epoch 009 - training loss: 4464.7905, validation loss: 0.8265
2024-06-03 10:21:47 [INFO]: Epoch 010 - training loss: 4450.7188, validation loss: 0.9277
2024-06-03 10:21:49 [INFO]: Epoch 011 - training loss: 4443.3302, validation loss: 0.8270
2024-06-03 10:21:51 [INFO]: Epoch 012 - training loss: 4439.3647, validation loss: 0.8250
2024-06-03 10:21:53 [INFO]: Epoch 013 - training loss: 4432.9644, validation loss: 0.8795
2024-06-03 10:21:55 [INFO]: Epoch 014 - training loss: 4431.2577, validation loss: 0.8690
2024-06-03 10:21:56 [INFO]: Epoch 015 - training loss: 4430.3336, validation loss: 0.8328
2024-06-03 10:21:58 [INFO]: Epoch 016 - training loss: 4430.2160, validation loss: 0.8525
2024-06-03 10:22:00 [INFO]: Epoch 017 - training loss: 4427.4622, validation loss: 0.8701
2024-06-03 10:22:02 [INFO]: Epoch 018 - training loss: 4426.7166, validation loss: 0.8659
2024-06-03 10:22:04 [INFO]: Epoch 019 - training loss: 4429.8162, validation loss: 0.9035
2024-06-03 10:22:06 [INFO]: Epoch 020 - training loss: 4427.7279, validation loss: 0.8824
2024-06-03 10:22:08 [INFO]: Epoch 021 - training loss: 4428.1620, validation loss: 0.8266
2024-06-03 10:22:10 [INFO]: Epoch 022 - training loss: 4427.8847, validation loss: 0.8141
2024-06-03 10:22:12 [INFO]: Epoch 023 - training loss: 4425.3734, validation loss: 0.7759
2024-06-03 10:22:14 [INFO]: Epoch 024 - training loss: 4421.7093, validation loss: 0.7855
2024-06-03 10:22:15 [INFO]: Epoch 025 - training loss: 4420.5799, validation loss: 0.7466
2024-06-03 10:22:17 [INFO]: Epoch 026 - training loss: 4420.0435, validation loss: 0.7692
2024-06-03 10:22:19 [INFO]: Epoch 027 - training loss: 4418.7558, validation loss: 0.7173
2024-06-03 10:22:21 [INFO]: Epoch 028 - training loss: 4418.3913, validation loss: 0.7098
2024-06-03 10:22:23 [INFO]: Epoch 029 - training loss: 4418.4093, validation loss: 0.7520
2024-06-03 10:22:25 [INFO]: Epoch 030 - training loss: 4418.0281, validation loss: 0.7404
2024-06-03 10:22:27 [INFO]: Epoch 031 - training loss: 4417.7377, validation loss: 0.7325
2024-06-03 10:22:29 [INFO]: Epoch 032 - training loss: 4415.7706, validation loss: 0.6810
2024-06-03 10:22:30 [INFO]: Epoch 033 - training loss: 4416.5444, validation loss: 0.6473
2024-06-03 10:22:32 [INFO]: Epoch 034 - training loss: 4416.1838, validation loss: 0.6380
2024-06-03 10:22:34 [INFO]: Epoch 035 - training loss: 4416.1932, validation loss: 0.6536
2024-06-03 10:22:36 [INFO]: Epoch 036 - training loss: 4415.6726, validation loss: 0.6480
2024-06-03 10:22:38 [INFO]: Epoch 037 - training loss: 4415.2520, validation loss: 0.6276
2024-06-03 10:22:39 [INFO]: Epoch 038 - training loss: 4414.4376, validation loss: 0.5974
2024-06-03 10:22:41 [INFO]: Epoch 039 - training loss: 4417.8186, validation loss: 0.6626
2024-06-03 10:22:43 [INFO]: Epoch 040 - training loss: 4416.1341, validation loss: 0.6799
2024-06-03 10:22:45 [INFO]: Epoch 041 - training loss: 4416.2456, validation loss: 0.6362
2024-06-03 10:22:47 [INFO]: Epoch 042 - training loss: 4415.3955, validation loss: 0.6457
2024-06-03 10:22:49 [INFO]: Epoch 043 - training loss: 4416.3292, validation loss: 0.6433
2024-06-03 10:22:50 [INFO]: Epoch 044 - training loss: 4415.5663, validation loss: 0.6106
2024-06-03 10:22:52 [INFO]: Epoch 045 - training loss: 4414.4166, validation loss: 0.6056
2024-06-03 10:22:54 [INFO]: Epoch 046 - training loss: 4414.3366, validation loss: 0.6529
2024-06-03 10:22:56 [INFO]: Epoch 047 - training loss: 4414.5759, validation loss: 0.6205
2024-06-03 10:22:57 [INFO]: Epoch 048 - training loss: 4413.0452, validation loss: 0.5909
2024-06-03 10:22:59 [INFO]: Epoch 049 - training loss: 4412.5741, validation loss: 0.6192
2024-06-03 10:23:01 [INFO]: Epoch 050 - training loss: 4412.9818, validation loss: 0.6214
2024-06-03 10:23:03 [INFO]: Epoch 051 - training loss: 4412.5838, validation loss: 0.5863
2024-06-03 10:23:05 [INFO]: Epoch 052 - training loss: 4413.1272, validation loss: 0.5833
2024-06-03 10:23:07 [INFO]: Epoch 053 - training loss: 4412.9314, validation loss: 0.6021
2024-06-03 10:23:09 [INFO]: Epoch 054 - training loss: 4411.9942, validation loss: 0.5871
2024-06-03 10:23:11 [INFO]: Epoch 055 - training loss: 4412.9312, validation loss: 0.6021
2024-06-03 10:23:13 [INFO]: Epoch 056 - training loss: 4412.8778, validation loss: 0.6064
2024-06-03 10:23:15 [INFO]: Epoch 057 - training loss: 4413.2598, validation loss: 0.6133
2024-06-03 10:23:16 [INFO]: Epoch 058 - training loss: 4413.1257, validation loss: 0.5598
2024-06-03 10:23:18 [INFO]: Epoch 059 - training loss: 4413.2401, validation loss: 0.5836
2024-06-03 10:23:20 [INFO]: Epoch 060 - training loss: 4412.7946, validation loss: 0.6841
2024-06-03 10:23:22 [INFO]: Epoch 061 - training loss: 4411.6948, validation loss: 0.7193
2024-06-03 10:23:24 [INFO]: Epoch 062 - training loss: 4413.1712, validation loss: 0.6297
2024-06-03 10:23:26 [INFO]: Epoch 063 - training loss: 4414.0487, validation loss: 0.6023
2024-06-03 10:23:28 [INFO]: Epoch 064 - training loss: 4412.1317, validation loss: 0.5988
2024-06-03 10:23:29 [INFO]: Epoch 065 - training loss: 4412.1232, validation loss: 0.6010
2024-06-03 10:23:30 [INFO]: Epoch 066 - training loss: 4411.8745, validation loss: 0.5910
2024-06-03 10:23:32 [INFO]: Epoch 067 - training loss: 4411.2330, validation loss: 0.5677
2024-06-03 10:23:34 [INFO]: Epoch 068 - training loss: 4411.9327, validation loss: 0.5686
2024-06-03 10:23:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:23:34 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 10:23:34 [INFO]: Saved the model to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_2/20240603_T102128/GPVAE.pypots
2024-06-03 10:23:36 [INFO]: Successfully saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_2/imputation.pkl
2024-06-03 10:23:36 [INFO]: Round2 - GPVAE on ETT_h1: MAE=0.5944, MSE=0.7166, MRE=0.7381
2024-06-03 10:23:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:23:36 [INFO]: Using the given device: cuda:0
2024-06-03 10:23:36 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_3/20240603_T102336
2024-06-03 10:23:36 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_3/20240603_T102336/tensorboard
2024-06-03 10:23:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 384,796
2024-06-03 10:23:38 [INFO]: Epoch 001 - training loss: 7099.8329, validation loss: 0.9983
2024-06-03 10:23:39 [INFO]: Epoch 002 - training loss: 4507.1836, validation loss: 0.9594
2024-06-03 10:23:40 [INFO]: Epoch 003 - training loss: 4502.8333, validation loss: 0.9574
2024-06-03 10:23:42 [INFO]: Epoch 004 - training loss: 4505.6821, validation loss: 0.9541
2024-06-03 10:23:44 [INFO]: Epoch 005 - training loss: 4489.1455, validation loss: 0.9509
2024-06-03 10:23:46 [INFO]: Epoch 006 - training loss: 4484.5522, validation loss: 0.9388
2024-06-03 10:23:48 [INFO]: Epoch 007 - training loss: 4519.7434, validation loss: 0.9251
2024-06-03 10:23:50 [INFO]: Epoch 008 - training loss: 4512.0038, validation loss: 0.9295
2024-06-03 10:23:51 [INFO]: Epoch 009 - training loss: 4498.0687, validation loss: 0.9184
2024-06-03 10:23:53 [INFO]: Epoch 010 - training loss: 4489.5813, validation loss: 0.9184
2024-06-03 10:23:55 [INFO]: Epoch 011 - training loss: 4475.3958, validation loss: 0.9205
2024-06-03 10:23:57 [INFO]: Epoch 012 - training loss: 4467.7885, validation loss: 0.9546
2024-06-03 10:23:58 [INFO]: Epoch 013 - training loss: 4486.0184, validation loss: 1.1979
2024-06-03 10:24:00 [INFO]: Epoch 014 - training loss: 4522.0051, validation loss: 0.9849
2024-06-03 10:24:01 [INFO]: Epoch 015 - training loss: 4477.7170, validation loss: 0.9861
2024-06-03 10:24:03 [INFO]: Epoch 016 - training loss: 4465.5580, validation loss: 0.9444
2024-06-03 10:24:04 [INFO]: Epoch 017 - training loss: 4461.2231, validation loss: 0.9604
2024-06-03 10:24:06 [INFO]: Epoch 018 - training loss: 4455.4538, validation loss: 0.9612
2024-06-03 10:24:08 [INFO]: Epoch 019 - training loss: 4453.3024, validation loss: 0.9525
2024-06-03 10:24:09 [INFO]: Epoch 020 - training loss: 4452.4023, validation loss: 0.9577
2024-06-03 10:24:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:09 [INFO]: Finished training. The best model is from epoch#10.
2024-06-03 10:24:09 [INFO]: Saved the model to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_3/20240603_T102336/GPVAE.pypots
2024-06-03 10:24:12 [INFO]: Successfully saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_3/imputation.pkl
2024-06-03 10:24:12 [INFO]: Round3 - GPVAE on ETT_h1: MAE=0.7991, MSE=1.1423, MRE=0.9923
2024-06-03 10:24:12 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:24:12 [INFO]: Using the given device: cuda:0
2024-06-03 10:24:12 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_4/20240603_T102412
2024-06-03 10:24:12 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_4/20240603_T102412/tensorboard
2024-06-03 10:24:12 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 384,796
2024-06-03 10:24:13 [INFO]: Epoch 001 - training loss: 6915.2098, validation loss: 0.9638
2024-06-03 10:24:15 [INFO]: Epoch 002 - training loss: 4499.2769, validation loss: 0.9117
2024-06-03 10:24:17 [INFO]: Epoch 003 - training loss: 4485.8564, validation loss: 0.9443
2024-06-03 10:24:18 [INFO]: Epoch 004 - training loss: 4549.6460, validation loss: 0.8950
2024-06-03 10:24:19 [INFO]: Epoch 005 - training loss: 4498.5394, validation loss: 0.9078
2024-06-03 10:24:21 [INFO]: Epoch 006 - training loss: 4482.1659, validation loss: 0.9312
2024-06-03 10:24:23 [INFO]: Epoch 007 - training loss: 4473.1218, validation loss: 0.8940
2024-06-03 10:24:24 [INFO]: Epoch 008 - training loss: 4463.0262, validation loss: 0.8263
2024-06-03 10:24:26 [INFO]: Epoch 009 - training loss: 4459.6293, validation loss: 1.3462
2024-06-03 10:24:27 [INFO]: Epoch 010 - training loss: 4521.1745, validation loss: 0.9904
2024-06-03 10:24:29 [INFO]: Epoch 011 - training loss: 4472.9900, validation loss: 0.9030
2024-06-03 10:24:31 [INFO]: Epoch 012 - training loss: 4454.9570, validation loss: 0.8609
2024-06-03 10:24:33 [INFO]: Epoch 013 - training loss: 4445.0857, validation loss: 0.8303
2024-06-03 10:24:34 [INFO]: Epoch 014 - training loss: 4443.6643, validation loss: 0.8230
2024-06-03 10:24:36 [INFO]: Epoch 015 - training loss: 4441.5401, validation loss: 0.8272
2024-06-03 10:24:38 [INFO]: Epoch 016 - training loss: 4435.2921, validation loss: 0.8349
2024-06-03 10:24:40 [INFO]: Epoch 017 - training loss: 4429.8716, validation loss: 0.8265
2024-06-03 10:24:41 [INFO]: Epoch 018 - training loss: 4427.1582, validation loss: 0.8153
2024-06-03 10:24:43 [INFO]: Epoch 019 - training loss: 4425.1320, validation loss: 0.7992
2024-06-03 10:24:44 [INFO]: Epoch 020 - training loss: 4423.1563, validation loss: 0.7842
2024-06-03 10:24:45 [INFO]: Epoch 021 - training loss: 4422.0709, validation loss: 0.7905
2024-06-03 10:24:47 [INFO]: Epoch 022 - training loss: 4421.7519, validation loss: 0.7790
2024-06-03 10:24:48 [INFO]: Epoch 023 - training loss: 4420.1326, validation loss: 0.7549
2024-06-03 10:24:50 [INFO]: Epoch 024 - training loss: 4421.8228, validation loss: 0.7349
2024-06-03 10:24:51 [INFO]: Epoch 025 - training loss: 4423.8673, validation loss: 0.7475
2024-06-03 10:24:52 [INFO]: Epoch 026 - training loss: 4421.5586, validation loss: 0.7967
2024-06-03 10:24:53 [INFO]: Epoch 027 - training loss: 4426.8324, validation loss: 0.6949
2024-06-03 10:24:55 [INFO]: Epoch 028 - training loss: 4422.3489, validation loss: 0.7460
2024-06-03 10:24:56 [INFO]: Epoch 029 - training loss: 4420.2016, validation loss: 0.7429
2024-06-03 10:24:58 [INFO]: Epoch 030 - training loss: 4418.4783, validation loss: 0.6930
2024-06-03 10:24:59 [INFO]: Epoch 031 - training loss: 4418.2550, validation loss: 0.6753
2024-06-03 10:25:01 [INFO]: Epoch 032 - training loss: 4414.7868, validation loss: 0.6436
2024-06-03 10:25:02 [INFO]: Epoch 033 - training loss: 4416.0659, validation loss: 0.6794
2024-06-03 10:25:04 [INFO]: Epoch 034 - training loss: 4415.8182, validation loss: 0.6404
2024-06-03 10:25:05 [INFO]: Epoch 035 - training loss: 4417.1011, validation loss: 0.6447
2024-06-03 10:25:06 [INFO]: Epoch 036 - training loss: 4418.6179, validation loss: 0.6644
2024-06-03 10:25:08 [INFO]: Epoch 037 - training loss: 4416.5014, validation loss: 0.7226
2024-06-03 10:25:10 [INFO]: Epoch 038 - training loss: 4416.4864, validation loss: 0.7314
2024-06-03 10:25:11 [INFO]: Epoch 039 - training loss: 4416.4360, validation loss: 0.6795
2024-06-03 10:25:13 [INFO]: Epoch 040 - training loss: 4416.6379, validation loss: 0.6255
2024-06-03 10:25:15 [INFO]: Epoch 041 - training loss: 4416.2466, validation loss: 0.5884
2024-06-03 10:25:16 [INFO]: Epoch 042 - training loss: 4414.1279, validation loss: 0.6914
2024-06-03 10:25:19 [INFO]: Epoch 043 - training loss: 4414.3474, validation loss: 0.6768
2024-06-03 10:25:20 [INFO]: Epoch 044 - training loss: 4415.4918, validation loss: 0.6211
2024-06-03 10:25:22 [INFO]: Epoch 045 - training loss: 4413.6236, validation loss: 0.6458
2024-06-03 10:25:24 [INFO]: Epoch 046 - training loss: 4412.9205, validation loss: 0.6626
2024-06-03 10:25:25 [INFO]: Epoch 047 - training loss: 4413.1629, validation loss: 0.6342
2024-06-03 10:25:27 [INFO]: Epoch 048 - training loss: 4413.2356, validation loss: 0.6232
2024-06-03 10:25:28 [INFO]: Epoch 049 - training loss: 4413.9584, validation loss: 0.6447
2024-06-03 10:25:30 [INFO]: Epoch 050 - training loss: 4414.0287, validation loss: 0.6402
2024-06-03 10:25:32 [INFO]: Epoch 051 - training loss: 4413.3604, validation loss: 0.6426
2024-06-03 10:25:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:25:32 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 10:25:32 [INFO]: Saved the model to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_4/20240603_T102412/GPVAE.pypots
2024-06-03 10:25:34 [INFO]: Successfully saved to results_block_rate05/ETT_h1/GPVAE_ETT_h1/round_4/imputation.pkl
2024-06-03 10:25:34 [INFO]: Round4 - GPVAE on ETT_h1: MAE=0.6374, MSE=0.7653, MRE=0.7915
2024-06-03 10:25:34 [INFO]: Done! Final results:
Averaged GPVAE (384,796 params) on ETT_h1: MAE=0.6506 ± 0.07700452122136352, MSE=0.8119 ± 0.1685419583503275, MRE=0.8078 ± 0.09562205945830286, average inference time=0.68
