2024-06-03 10:17:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:17:23 [INFO]: Using the given device: cuda:0
2024-06-03 10:17:24 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_0/20240603_T101724
2024-06-03 10:17:24 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_0/20240603_T101724/tensorboard
2024-06-03 10:17:30 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 10:17:49 [INFO]: Epoch 001 - training loss: 1.5354, validation loss: 1.0231
2024-06-03 10:17:52 [INFO]: Epoch 002 - training loss: 0.9328, validation loss: 0.7515
2024-06-03 10:17:55 [INFO]: Epoch 003 - training loss: 0.7127, validation loss: 0.5361
2024-06-03 10:17:58 [INFO]: Epoch 004 - training loss: 0.6163, validation loss: 0.4897
2024-06-03 10:18:02 [INFO]: Epoch 005 - training loss: 0.5312, validation loss: 0.4841
2024-06-03 10:18:06 [INFO]: Epoch 006 - training loss: 0.4929, validation loss: 0.4753
2024-06-03 10:18:10 [INFO]: Epoch 007 - training loss: 0.4666, validation loss: 0.4586
2024-06-03 10:18:14 [INFO]: Epoch 008 - training loss: 0.4603, validation loss: 0.4086
2024-06-03 10:18:18 [INFO]: Epoch 009 - training loss: 0.4333, validation loss: 0.3913
2024-06-03 10:18:21 [INFO]: Epoch 010 - training loss: 0.4088, validation loss: 0.3837
2024-06-03 10:18:25 [INFO]: Epoch 011 - training loss: 0.4069, validation loss: 0.3771
2024-06-03 10:18:28 [INFO]: Epoch 012 - training loss: 0.4095, validation loss: 0.3752
2024-06-03 10:18:31 [INFO]: Epoch 013 - training loss: 0.3956, validation loss: 0.3875
2024-06-03 10:18:36 [INFO]: Epoch 014 - training loss: 0.3916, validation loss: 0.3770
2024-06-03 10:18:39 [INFO]: Epoch 015 - training loss: 0.3708, validation loss: 0.3845
2024-06-03 10:18:43 [INFO]: Epoch 016 - training loss: 0.3650, validation loss: 0.3797
2024-06-03 10:18:47 [INFO]: Epoch 017 - training loss: 0.3647, validation loss: 0.3688
2024-06-03 10:18:51 [INFO]: Epoch 018 - training loss: 0.3498, validation loss: 0.3489
2024-06-03 10:18:54 [INFO]: Epoch 019 - training loss: 0.3445, validation loss: 0.3747
2024-06-03 10:18:58 [INFO]: Epoch 020 - training loss: 0.3350, validation loss: 0.3664
2024-06-03 10:19:01 [INFO]: Epoch 021 - training loss: 0.3451, validation loss: 0.3449
2024-06-03 10:19:04 [INFO]: Epoch 022 - training loss: 0.3193, validation loss: 0.3727
2024-06-03 10:19:07 [INFO]: Epoch 023 - training loss: 0.3211, validation loss: 0.3594
2024-06-03 10:19:10 [INFO]: Epoch 024 - training loss: 0.3096, validation loss: 0.3625
2024-06-03 10:19:13 [INFO]: Epoch 025 - training loss: 0.3068, validation loss: 0.3647
2024-06-03 10:19:16 [INFO]: Epoch 026 - training loss: 0.3115, validation loss: 0.3675
2024-06-03 10:19:18 [INFO]: Epoch 027 - training loss: 0.3083, validation loss: 0.3578
2024-06-03 10:19:21 [INFO]: Epoch 028 - training loss: 0.3156, validation loss: 0.3421
2024-06-03 10:19:24 [INFO]: Epoch 029 - training loss: 0.3144, validation loss: 0.3561
2024-06-03 10:19:27 [INFO]: Epoch 030 - training loss: 0.3081, validation loss: 0.3500
2024-06-03 10:19:31 [INFO]: Epoch 031 - training loss: 0.3095, validation loss: 0.3330
2024-06-03 10:19:35 [INFO]: Epoch 032 - training loss: 0.3039, validation loss: 0.3435
2024-06-03 10:19:39 [INFO]: Epoch 033 - training loss: 0.2809, validation loss: 0.3226
2024-06-03 10:19:42 [INFO]: Epoch 034 - training loss: 0.2806, validation loss: 0.3243
2024-06-03 10:19:45 [INFO]: Epoch 035 - training loss: 0.2872, validation loss: 0.3468
2024-06-03 10:19:49 [INFO]: Epoch 036 - training loss: 0.2992, validation loss: 0.3038
2024-06-03 10:19:52 [INFO]: Epoch 037 - training loss: 0.2824, validation loss: 0.3244
2024-06-03 10:19:56 [INFO]: Epoch 038 - training loss: 0.2757, validation loss: 0.3364
2024-06-03 10:20:00 [INFO]: Epoch 039 - training loss: 0.3061, validation loss: 0.3250
2024-06-03 10:20:04 [INFO]: Epoch 040 - training loss: 0.2943, validation loss: 0.3176
2024-06-03 10:20:07 [INFO]: Epoch 041 - training loss: 0.2746, validation loss: 0.3057
2024-06-03 10:20:11 [INFO]: Epoch 042 - training loss: 0.2641, validation loss: 0.3348
2024-06-03 10:20:15 [INFO]: Epoch 043 - training loss: 0.2598, validation loss: 0.3086
2024-06-03 10:20:18 [INFO]: Epoch 044 - training loss: 0.2548, validation loss: 0.3319
2024-06-03 10:20:21 [INFO]: Epoch 045 - training loss: 0.2522, validation loss: 0.3238
2024-06-03 10:20:24 [INFO]: Epoch 046 - training loss: 0.2457, validation loss: 0.3393
2024-06-03 10:20:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:20:24 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 10:20:24 [INFO]: Saved the model to results_block_rate05/ETT_h1/Informer_ETT_h1/round_0/20240603_T101724/Informer.pypots
2024-06-03 10:20:28 [INFO]: Successfully saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_0/imputation.pkl
2024-06-03 10:20:28 [INFO]: Round0 - Informer on ETT_h1: MAE=0.4702, MSE=0.5162, MRE=0.5839
2024-06-03 10:20:28 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:20:28 [INFO]: Using the given device: cuda:0
2024-06-03 10:20:28 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_1/20240603_T102028
2024-06-03 10:20:28 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_1/20240603_T102028/tensorboard
2024-06-03 10:20:28 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 10:20:32 [INFO]: Epoch 001 - training loss: 1.4944, validation loss: 0.9796
2024-06-03 10:20:35 [INFO]: Epoch 002 - training loss: 0.9289, validation loss: 0.6801
2024-06-03 10:20:39 [INFO]: Epoch 003 - training loss: 0.6954, validation loss: 0.4722
2024-06-03 10:20:43 [INFO]: Epoch 004 - training loss: 0.5840, validation loss: 0.5257
2024-06-03 10:20:46 [INFO]: Epoch 005 - training loss: 0.5384, validation loss: 0.4832
2024-06-03 10:20:50 [INFO]: Epoch 006 - training loss: 0.5044, validation loss: 0.4466
2024-06-03 10:20:54 [INFO]: Epoch 007 - training loss: 0.4629, validation loss: 0.4253
2024-06-03 10:20:57 [INFO]: Epoch 008 - training loss: 0.4434, validation loss: 0.4145
2024-06-03 10:21:00 [INFO]: Epoch 009 - training loss: 0.4236, validation loss: 0.4104
2024-06-03 10:21:04 [INFO]: Epoch 010 - training loss: 0.4260, validation loss: 0.4046
2024-06-03 10:21:07 [INFO]: Epoch 011 - training loss: 0.4079, validation loss: 0.3822
2024-06-03 10:21:10 [INFO]: Epoch 012 - training loss: 0.4024, validation loss: 0.3747
2024-06-03 10:21:13 [INFO]: Epoch 013 - training loss: 0.3826, validation loss: 0.3738
2024-06-03 10:21:17 [INFO]: Epoch 014 - training loss: 0.3706, validation loss: 0.3701
2024-06-03 10:21:20 [INFO]: Epoch 015 - training loss: 0.3707, validation loss: 0.3519
2024-06-03 10:21:24 [INFO]: Epoch 016 - training loss: 0.3725, validation loss: 0.3886
2024-06-03 10:21:27 [INFO]: Epoch 017 - training loss: 0.3535, validation loss: 0.3584
2024-06-03 10:21:29 [INFO]: Epoch 018 - training loss: 0.3516, validation loss: 0.3598
2024-06-03 10:21:31 [INFO]: Epoch 019 - training loss: 0.3422, validation loss: 0.3738
2024-06-03 10:21:34 [INFO]: Epoch 020 - training loss: 0.3393, validation loss: 0.3459
2024-06-03 10:21:37 [INFO]: Epoch 021 - training loss: 0.3315, validation loss: 0.3396
2024-06-03 10:21:39 [INFO]: Epoch 022 - training loss: 0.3330, validation loss: 0.3515
2024-06-03 10:21:41 [INFO]: Epoch 023 - training loss: 0.3097, validation loss: 0.3396
2024-06-03 10:21:44 [INFO]: Epoch 024 - training loss: 0.3020, validation loss: 0.3417
2024-06-03 10:21:48 [INFO]: Epoch 025 - training loss: 0.2901, validation loss: 0.3304
2024-06-03 10:21:51 [INFO]: Epoch 026 - training loss: 0.2920, validation loss: 0.3322
2024-06-03 10:21:53 [INFO]: Epoch 027 - training loss: 0.2845, validation loss: 0.3452
2024-06-03 10:21:56 [INFO]: Epoch 028 - training loss: 0.2818, validation loss: 0.3353
2024-06-03 10:21:59 [INFO]: Epoch 029 - training loss: 0.2805, validation loss: 0.3317
2024-06-03 10:22:02 [INFO]: Epoch 030 - training loss: 0.2811, validation loss: 0.3451
2024-06-03 10:22:05 [INFO]: Epoch 031 - training loss: 0.2892, validation loss: 0.3304
2024-06-03 10:22:09 [INFO]: Epoch 032 - training loss: 0.2945, validation loss: 0.3160
2024-06-03 10:22:11 [INFO]: Epoch 033 - training loss: 0.2985, validation loss: 0.3579
2024-06-03 10:22:14 [INFO]: Epoch 034 - training loss: 0.2762, validation loss: 0.3042
2024-06-03 10:22:18 [INFO]: Epoch 035 - training loss: 0.2741, validation loss: 0.3114
2024-06-03 10:22:21 [INFO]: Epoch 036 - training loss: 0.2759, validation loss: 0.3056
2024-06-03 10:22:24 [INFO]: Epoch 037 - training loss: 0.2649, validation loss: 0.2928
2024-06-03 10:22:27 [INFO]: Epoch 038 - training loss: 0.2700, validation loss: 0.3208
2024-06-03 10:22:30 [INFO]: Epoch 039 - training loss: 0.2707, validation loss: 0.3128
2024-06-03 10:22:33 [INFO]: Epoch 040 - training loss: 0.2812, validation loss: 0.3111
2024-06-03 10:22:37 [INFO]: Epoch 041 - training loss: 0.2962, validation loss: 0.3099
2024-06-03 10:22:40 [INFO]: Epoch 042 - training loss: 0.2959, validation loss: 0.3065
2024-06-03 10:22:43 [INFO]: Epoch 043 - training loss: 0.2848, validation loss: 0.3247
2024-06-03 10:22:46 [INFO]: Epoch 044 - training loss: 0.2771, validation loss: 0.3237
2024-06-03 10:22:49 [INFO]: Epoch 045 - training loss: 0.2624, validation loss: 0.2933
2024-06-03 10:22:52 [INFO]: Epoch 046 - training loss: 0.2533, validation loss: 0.3051
2024-06-03 10:22:55 [INFO]: Epoch 047 - training loss: 0.2496, validation loss: 0.3293
2024-06-03 10:22:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:22:55 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 10:22:55 [INFO]: Saved the model to results_block_rate05/ETT_h1/Informer_ETT_h1/round_1/20240603_T102028/Informer.pypots
2024-06-03 10:22:57 [INFO]: Successfully saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_1/imputation.pkl
2024-06-03 10:22:57 [INFO]: Round1 - Informer on ETT_h1: MAE=0.4418, MSE=0.4598, MRE=0.5486
2024-06-03 10:22:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:22:57 [INFO]: Using the given device: cuda:0
2024-06-03 10:22:57 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_2/20240603_T102257
2024-06-03 10:22:57 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_2/20240603_T102257/tensorboard
2024-06-03 10:22:57 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 10:23:01 [INFO]: Epoch 001 - training loss: 1.4465, validation loss: 0.8568
2024-06-03 10:23:04 [INFO]: Epoch 002 - training loss: 0.8552, validation loss: 0.6311
2024-06-03 10:23:07 [INFO]: Epoch 003 - training loss: 0.6665, validation loss: 0.6196
2024-06-03 10:23:10 [INFO]: Epoch 004 - training loss: 0.5855, validation loss: 0.5280
2024-06-03 10:23:13 [INFO]: Epoch 005 - training loss: 0.5312, validation loss: 0.4740
2024-06-03 10:23:16 [INFO]: Epoch 006 - training loss: 0.4957, validation loss: 0.4631
2024-06-03 10:23:18 [INFO]: Epoch 007 - training loss: 0.4674, validation loss: 0.4547
2024-06-03 10:23:22 [INFO]: Epoch 008 - training loss: 0.4428, validation loss: 0.4338
2024-06-03 10:23:25 [INFO]: Epoch 009 - training loss: 0.4303, validation loss: 0.4183
2024-06-03 10:23:28 [INFO]: Epoch 010 - training loss: 0.4228, validation loss: 0.3974
2024-06-03 10:23:30 [INFO]: Epoch 011 - training loss: 0.3958, validation loss: 0.4092
2024-06-03 10:23:34 [INFO]: Epoch 012 - training loss: 0.3830, validation loss: 0.3705
2024-06-03 10:23:36 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.3623
2024-06-03 10:23:38 [INFO]: Epoch 014 - training loss: 0.3744, validation loss: 0.3653
2024-06-03 10:23:40 [INFO]: Epoch 015 - training loss: 0.3572, validation loss: 0.3438
2024-06-03 10:23:43 [INFO]: Epoch 016 - training loss: 0.3447, validation loss: 0.3454
2024-06-03 10:23:47 [INFO]: Epoch 017 - training loss: 0.3455, validation loss: 0.3391
2024-06-03 10:23:50 [INFO]: Epoch 018 - training loss: 0.3453, validation loss: 0.3340
2024-06-03 10:23:53 [INFO]: Epoch 019 - training loss: 0.3263, validation loss: 0.3396
2024-06-03 10:23:55 [INFO]: Epoch 020 - training loss: 0.3267, validation loss: 0.3457
2024-06-03 10:23:58 [INFO]: Epoch 021 - training loss: 0.3180, validation loss: 0.3451
2024-06-03 10:24:00 [INFO]: Epoch 022 - training loss: 0.3245, validation loss: 0.3680
2024-06-03 10:24:03 [INFO]: Epoch 023 - training loss: 0.3141, validation loss: 0.3397
2024-06-03 10:24:06 [INFO]: Epoch 024 - training loss: 0.3225, validation loss: 0.3367
2024-06-03 10:24:08 [INFO]: Epoch 025 - training loss: 0.3154, validation loss: 0.3662
2024-06-03 10:24:10 [INFO]: Epoch 026 - training loss: 0.3139, validation loss: 0.3541
2024-06-03 10:24:13 [INFO]: Epoch 027 - training loss: 0.3036, validation loss: 0.3280
2024-06-03 10:24:16 [INFO]: Epoch 028 - training loss: 0.3133, validation loss: 0.3572
2024-06-03 10:24:18 [INFO]: Epoch 029 - training loss: 0.2976, validation loss: 0.3445
2024-06-03 10:24:21 [INFO]: Epoch 030 - training loss: 0.2945, validation loss: 0.3654
2024-06-03 10:24:24 [INFO]: Epoch 031 - training loss: 0.2974, validation loss: 0.3432
2024-06-03 10:24:26 [INFO]: Epoch 032 - training loss: 0.2901, validation loss: 0.3528
2024-06-03 10:24:30 [INFO]: Epoch 033 - training loss: 0.2823, validation loss: 0.3342
2024-06-03 10:24:32 [INFO]: Epoch 034 - training loss: 0.2792, validation loss: 0.3527
2024-06-03 10:24:36 [INFO]: Epoch 035 - training loss: 0.2735, validation loss: 0.3339
2024-06-03 10:24:38 [INFO]: Epoch 036 - training loss: 0.2692, validation loss: 0.3317
2024-06-03 10:24:41 [INFO]: Epoch 037 - training loss: 0.2759, validation loss: 0.3385
2024-06-03 10:24:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:41 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 10:24:41 [INFO]: Saved the model to results_block_rate05/ETT_h1/Informer_ETT_h1/round_2/20240603_T102257/Informer.pypots
2024-06-03 10:24:43 [INFO]: Successfully saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_2/imputation.pkl
2024-06-03 10:24:43 [INFO]: Round2 - Informer on ETT_h1: MAE=0.4592, MSE=0.4997, MRE=0.5702
2024-06-03 10:24:43 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:24:43 [INFO]: Using the given device: cuda:0
2024-06-03 10:24:43 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_3/20240603_T102443
2024-06-03 10:24:43 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_3/20240603_T102443/tensorboard
2024-06-03 10:24:43 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 10:24:45 [INFO]: Epoch 001 - training loss: 1.5506, validation loss: 0.8835
2024-06-03 10:24:47 [INFO]: Epoch 002 - training loss: 0.9252, validation loss: 0.7876
2024-06-03 10:24:50 [INFO]: Epoch 003 - training loss: 0.6874, validation loss: 0.5751
2024-06-03 10:24:51 [INFO]: Epoch 004 - training loss: 0.5699, validation loss: 0.4599
2024-06-03 10:24:54 [INFO]: Epoch 005 - training loss: 0.5111, validation loss: 0.4739
2024-06-03 10:24:56 [INFO]: Epoch 006 - training loss: 0.4727, validation loss: 0.4052
2024-06-03 10:24:59 [INFO]: Epoch 007 - training loss: 0.4564, validation loss: 0.3724
2024-06-03 10:25:02 [INFO]: Epoch 008 - training loss: 0.4281, validation loss: 0.3745
2024-06-03 10:25:05 [INFO]: Epoch 009 - training loss: 0.4220, validation loss: 0.3627
2024-06-03 10:25:08 [INFO]: Epoch 010 - training loss: 0.3961, validation loss: 0.3578
2024-06-03 10:25:11 [INFO]: Epoch 011 - training loss: 0.3857, validation loss: 0.3513
2024-06-03 10:25:14 [INFO]: Epoch 012 - training loss: 0.3822, validation loss: 0.3311
2024-06-03 10:25:17 [INFO]: Epoch 013 - training loss: 0.3744, validation loss: 0.3308
2024-06-03 10:25:20 [INFO]: Epoch 014 - training loss: 0.3882, validation loss: 0.3459
2024-06-03 10:25:23 [INFO]: Epoch 015 - training loss: 0.3618, validation loss: 0.3212
2024-06-03 10:25:25 [INFO]: Epoch 016 - training loss: 0.3490, validation loss: 0.3212
2024-06-03 10:25:28 [INFO]: Epoch 017 - training loss: 0.3428, validation loss: 0.2992
2024-06-03 10:25:31 [INFO]: Epoch 018 - training loss: 0.3375, validation loss: 0.3401
2024-06-03 10:25:34 [INFO]: Epoch 019 - training loss: 0.3274, validation loss: 0.3165
2024-06-03 10:25:37 [INFO]: Epoch 020 - training loss: 0.3203, validation loss: 0.3160
2024-06-03 10:25:40 [INFO]: Epoch 021 - training loss: 0.3143, validation loss: 0.3077
2024-06-03 10:25:42 [INFO]: Epoch 022 - training loss: 0.3169, validation loss: 0.3278
2024-06-03 10:25:44 [INFO]: Epoch 023 - training loss: 0.3223, validation loss: 0.3346
2024-06-03 10:25:47 [INFO]: Epoch 024 - training loss: 0.3126, validation loss: 0.3287
2024-06-03 10:25:50 [INFO]: Epoch 025 - training loss: 0.3104, validation loss: 0.3250
2024-06-03 10:25:53 [INFO]: Epoch 026 - training loss: 0.3057, validation loss: 0.3204
2024-06-03 10:25:55 [INFO]: Epoch 027 - training loss: 0.2985, validation loss: 0.3444
2024-06-03 10:25:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:25:55 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 10:25:56 [INFO]: Saved the model to results_block_rate05/ETT_h1/Informer_ETT_h1/round_3/20240603_T102443/Informer.pypots
2024-06-03 10:25:58 [INFO]: Successfully saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_3/imputation.pkl
2024-06-03 10:25:58 [INFO]: Round3 - Informer on ETT_h1: MAE=0.4735, MSE=0.5167, MRE=0.5880
2024-06-03 10:25:58 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:25:58 [INFO]: Using the given device: cuda:0
2024-06-03 10:25:58 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_4/20240603_T102558
2024-06-03 10:25:58 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_4/20240603_T102558/tensorboard
2024-06-03 10:25:58 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 1,058,311
2024-06-03 10:26:01 [INFO]: Epoch 001 - training loss: 1.5053, validation loss: 0.8511
2024-06-03 10:26:03 [INFO]: Epoch 002 - training loss: 0.8781, validation loss: 0.5875
2024-06-03 10:26:06 [INFO]: Epoch 003 - training loss: 0.6608, validation loss: 0.5063
2024-06-03 10:26:09 [INFO]: Epoch 004 - training loss: 0.5877, validation loss: 0.4707
2024-06-03 10:26:11 [INFO]: Epoch 005 - training loss: 0.5425, validation loss: 0.4350
2024-06-03 10:26:15 [INFO]: Epoch 006 - training loss: 0.5020, validation loss: 0.4236
2024-06-03 10:26:18 [INFO]: Epoch 007 - training loss: 0.4737, validation loss: 0.4109
2024-06-03 10:26:21 [INFO]: Epoch 008 - training loss: 0.4453, validation loss: 0.3940
2024-06-03 10:26:24 [INFO]: Epoch 009 - training loss: 0.4268, validation loss: 0.3966
2024-06-03 10:26:27 [INFO]: Epoch 010 - training loss: 0.4265, validation loss: 0.3949
2024-06-03 10:26:29 [INFO]: Epoch 011 - training loss: 0.4148, validation loss: 0.3867
2024-06-03 10:26:31 [INFO]: Epoch 012 - training loss: 0.4061, validation loss: 0.3615
2024-06-03 10:26:35 [INFO]: Epoch 013 - training loss: 0.3825, validation loss: 0.3748
2024-06-03 10:26:38 [INFO]: Epoch 014 - training loss: 0.3825, validation loss: 0.3753
2024-06-03 10:26:40 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.3865
2024-06-03 10:26:43 [INFO]: Epoch 016 - training loss: 0.3762, validation loss: 0.3572
2024-06-03 10:26:46 [INFO]: Epoch 017 - training loss: 0.3731, validation loss: 0.3672
2024-06-03 10:26:49 [INFO]: Epoch 018 - training loss: 0.3588, validation loss: 0.3625
2024-06-03 10:26:52 [INFO]: Epoch 019 - training loss: 0.3478, validation loss: 0.3590
2024-06-03 10:26:55 [INFO]: Epoch 020 - training loss: 0.3382, validation loss: 0.3630
2024-06-03 10:26:57 [INFO]: Epoch 021 - training loss: 0.3434, validation loss: 0.3430
2024-06-03 10:27:00 [INFO]: Epoch 022 - training loss: 0.3331, validation loss: 0.3227
2024-06-03 10:27:02 [INFO]: Epoch 023 - training loss: 0.3275, validation loss: 0.3584
2024-06-03 10:27:04 [INFO]: Epoch 024 - training loss: 0.3241, validation loss: 0.3346
2024-06-03 10:27:06 [INFO]: Epoch 025 - training loss: 0.3259, validation loss: 0.3517
2024-06-03 10:27:08 [INFO]: Epoch 026 - training loss: 0.3152, validation loss: 0.3445
2024-06-03 10:27:11 [INFO]: Epoch 027 - training loss: 0.3073, validation loss: 0.3406
2024-06-03 10:27:14 [INFO]: Epoch 028 - training loss: 0.3086, validation loss: 0.3284
2024-06-03 10:27:16 [INFO]: Epoch 029 - training loss: 0.3084, validation loss: 0.3472
2024-06-03 10:27:19 [INFO]: Epoch 030 - training loss: 0.2934, validation loss: 0.3520
2024-06-03 10:27:21 [INFO]: Epoch 031 - training loss: 0.2948, validation loss: 0.3220
2024-06-03 10:27:24 [INFO]: Epoch 032 - training loss: 0.2975, validation loss: 0.3701
2024-06-03 10:27:27 [INFO]: Epoch 033 - training loss: 0.2801, validation loss: 0.3394
2024-06-03 10:27:29 [INFO]: Epoch 034 - training loss: 0.2746, validation loss: 0.3495
2024-06-03 10:27:32 [INFO]: Epoch 035 - training loss: 0.2644, validation loss: 0.3412
2024-06-03 10:27:35 [INFO]: Epoch 036 - training loss: 0.2712, validation loss: 0.3514
2024-06-03 10:27:38 [INFO]: Epoch 037 - training loss: 0.2697, validation loss: 0.3407
2024-06-03 10:27:40 [INFO]: Epoch 038 - training loss: 0.2677, validation loss: 0.3417
2024-06-03 10:27:43 [INFO]: Epoch 039 - training loss: 0.2661, validation loss: 0.3346
2024-06-03 10:27:45 [INFO]: Epoch 040 - training loss: 0.2573, validation loss: 0.3340
2024-06-03 10:27:48 [INFO]: Epoch 041 - training loss: 0.2615, validation loss: 0.3337
2024-06-03 10:27:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:27:48 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 10:27:48 [INFO]: Saved the model to results_block_rate05/ETT_h1/Informer_ETT_h1/round_4/20240603_T102558/Informer.pypots
2024-06-03 10:27:50 [INFO]: Successfully saved to results_block_rate05/ETT_h1/Informer_ETT_h1/round_4/imputation.pkl
2024-06-03 10:27:50 [INFO]: Round4 - Informer on ETT_h1: MAE=0.4571, MSE=0.4748, MRE=0.5676
2024-06-03 10:27:50 [INFO]: Done! Final results:
Averaged Informer (1,058,311 params) on ETT_h1: MAE=0.4604 ± 0.011201188471022899, MSE=0.4934 ± 0.02270242849873387, MRE=0.5717 ± 0.01390932237473165, average inference time=0.55
