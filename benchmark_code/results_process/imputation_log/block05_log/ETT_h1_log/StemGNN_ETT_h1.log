2024-06-03 10:17:21 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:17:21 [INFO]: Using the given device: cuda:0
2024-06-03 10:17:25 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T101725
2024-06-03 10:17:25 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T101725/tensorboard
2024-06-03 10:17:30 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 10:17:42 [INFO]: Epoch 001 - training loss: 1.5368, validation loss: 0.9318
2024-06-03 10:17:47 [INFO]: Epoch 002 - training loss: 1.4480, validation loss: 0.8476
2024-06-03 10:17:51 [INFO]: Epoch 003 - training loss: 1.2031, validation loss: 0.7113
2024-06-03 10:17:56 [INFO]: Epoch 004 - training loss: 0.9350, validation loss: 0.5592
2024-06-03 10:18:01 [INFO]: Epoch 005 - training loss: 0.8434, validation loss: 0.4855
2024-06-03 10:18:05 [INFO]: Epoch 006 - training loss: 0.8081, validation loss: 0.4821
2024-06-03 10:18:10 [INFO]: Epoch 007 - training loss: 0.7780, validation loss: 0.4784
2024-06-03 10:18:15 [INFO]: Epoch 008 - training loss: 0.7211, validation loss: 0.3990
2024-06-03 10:18:19 [INFO]: Epoch 009 - training loss: 0.6828, validation loss: 0.3822
2024-06-03 10:18:24 [INFO]: Epoch 010 - training loss: 0.6208, validation loss: 0.3687
2024-06-03 10:18:29 [INFO]: Epoch 011 - training loss: 0.5960, validation loss: 0.3478
2024-06-03 10:18:34 [INFO]: Epoch 012 - training loss: 0.5773, validation loss: 0.3475
2024-06-03 10:18:38 [INFO]: Epoch 013 - training loss: 0.5697, validation loss: 0.3426
2024-06-03 10:18:43 [INFO]: Epoch 014 - training loss: 0.5537, validation loss: 0.3246
2024-06-03 10:18:47 [INFO]: Epoch 015 - training loss: 0.5515, validation loss: 0.3292
2024-06-03 10:18:52 [INFO]: Epoch 016 - training loss: 0.5383, validation loss: 0.3272
2024-06-03 10:18:56 [INFO]: Epoch 017 - training loss: 0.5317, validation loss: 0.3274
2024-06-03 10:19:01 [INFO]: Epoch 018 - training loss: 0.5253, validation loss: 0.3345
2024-06-03 10:19:06 [INFO]: Epoch 019 - training loss: 0.5257, validation loss: 0.3228
2024-06-03 10:19:10 [INFO]: Epoch 020 - training loss: 0.5202, validation loss: 0.3229
2024-06-03 10:19:14 [INFO]: Epoch 021 - training loss: 0.5133, validation loss: 0.3184
2024-06-03 10:19:18 [INFO]: Epoch 022 - training loss: 0.5085, validation loss: 0.3138
2024-06-03 10:19:22 [INFO]: Epoch 023 - training loss: 0.5047, validation loss: 0.3074
2024-06-03 10:19:27 [INFO]: Epoch 024 - training loss: 0.5009, validation loss: 0.3062
2024-06-03 10:19:31 [INFO]: Epoch 025 - training loss: 0.4953, validation loss: 0.2989
2024-06-03 10:19:36 [INFO]: Epoch 026 - training loss: 0.4951, validation loss: 0.2990
2024-06-03 10:19:41 [INFO]: Epoch 027 - training loss: 0.4802, validation loss: 0.2967
2024-06-03 10:19:45 [INFO]: Epoch 028 - training loss: 0.4849, validation loss: 0.2952
2024-06-03 10:19:50 [INFO]: Epoch 029 - training loss: 0.4901, validation loss: 0.3033
2024-06-03 10:19:54 [INFO]: Epoch 030 - training loss: 0.4782, validation loss: 0.3077
2024-06-03 10:19:59 [INFO]: Epoch 031 - training loss: 0.4706, validation loss: 0.2993
2024-06-03 10:20:03 [INFO]: Epoch 032 - training loss: 0.4668, validation loss: 0.3055
2024-06-03 10:20:08 [INFO]: Epoch 033 - training loss: 0.4637, validation loss: 0.3023
2024-06-03 10:20:12 [INFO]: Epoch 034 - training loss: 0.4697, validation loss: 0.3006
2024-06-03 10:20:17 [INFO]: Epoch 035 - training loss: 0.4659, validation loss: 0.3012
2024-06-03 10:20:21 [INFO]: Epoch 036 - training loss: 0.4582, validation loss: 0.3057
2024-06-03 10:20:25 [INFO]: Epoch 037 - training loss: 0.4434, validation loss: 0.2962
2024-06-03 10:20:30 [INFO]: Epoch 038 - training loss: 0.4502, validation loss: 0.2903
2024-06-03 10:20:34 [INFO]: Epoch 039 - training loss: 0.4431, validation loss: 0.3018
2024-06-03 10:20:39 [INFO]: Epoch 040 - training loss: 0.4430, validation loss: 0.2961
2024-06-03 10:20:43 [INFO]: Epoch 041 - training loss: 0.4498, validation loss: 0.3101
2024-06-03 10:20:48 [INFO]: Epoch 042 - training loss: 0.4447, validation loss: 0.2975
2024-06-03 10:20:52 [INFO]: Epoch 043 - training loss: 0.4428, validation loss: 0.3001
2024-06-03 10:20:57 [INFO]: Epoch 044 - training loss: 0.4295, validation loss: 0.3177
2024-06-03 10:21:01 [INFO]: Epoch 045 - training loss: 0.4325, validation loss: 0.3049
2024-06-03 10:21:04 [INFO]: Epoch 046 - training loss: 0.4329, validation loss: 0.2903
2024-06-03 10:21:09 [INFO]: Epoch 047 - training loss: 0.4331, validation loss: 0.3042
2024-06-03 10:21:13 [INFO]: Epoch 048 - training loss: 0.4349, validation loss: 0.2941
2024-06-03 10:21:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:13 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 10:21:13 [INFO]: Saved the model to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_0/20240603_T101725/StemGNN.pypots
2024-06-03 10:21:17 [INFO]: Successfully saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_0/imputation.pkl
2024-06-03 10:21:17 [INFO]: Round0 - StemGNN on ETT_h1: MAE=0.4362, MSE=0.3904, MRE=0.5416
2024-06-03 10:21:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:21:17 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:17 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T102117
2024-06-03 10:21:17 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T102117/tensorboard
2024-06-03 10:21:17 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 10:21:22 [INFO]: Epoch 001 - training loss: 1.5226, validation loss: 0.9338
2024-06-03 10:21:25 [INFO]: Epoch 002 - training loss: 1.4481, validation loss: 0.8906
2024-06-03 10:21:29 [INFO]: Epoch 003 - training loss: 1.1863, validation loss: 0.6755
2024-06-03 10:21:34 [INFO]: Epoch 004 - training loss: 0.9349, validation loss: 0.5261
2024-06-03 10:21:37 [INFO]: Epoch 005 - training loss: 0.8085, validation loss: 0.4881
2024-06-03 10:21:40 [INFO]: Epoch 006 - training loss: 0.7650, validation loss: 0.4315
2024-06-03 10:21:45 [INFO]: Epoch 007 - training loss: 0.7161, validation loss: 0.4152
2024-06-03 10:21:48 [INFO]: Epoch 008 - training loss: 0.6891, validation loss: 0.3865
2024-06-03 10:21:52 [INFO]: Epoch 009 - training loss: 0.6526, validation loss: 0.3559
2024-06-03 10:21:56 [INFO]: Epoch 010 - training loss: 0.6325, validation loss: 0.3524
2024-06-03 10:22:00 [INFO]: Epoch 011 - training loss: 0.6047, validation loss: 0.3318
2024-06-03 10:22:03 [INFO]: Epoch 012 - training loss: 0.5959, validation loss: 0.3465
2024-06-03 10:22:07 [INFO]: Epoch 013 - training loss: 0.6140, validation loss: 0.3401
2024-06-03 10:22:11 [INFO]: Epoch 014 - training loss: 0.5938, validation loss: 0.3270
2024-06-03 10:22:14 [INFO]: Epoch 015 - training loss: 0.5839, validation loss: 0.3310
2024-06-03 10:22:18 [INFO]: Epoch 016 - training loss: 0.5703, validation loss: 0.3326
2024-06-03 10:22:22 [INFO]: Epoch 017 - training loss: 0.5614, validation loss: 0.3394
2024-06-03 10:22:25 [INFO]: Epoch 018 - training loss: 0.5611, validation loss: 0.3295
2024-06-03 10:22:29 [INFO]: Epoch 019 - training loss: 0.5500, validation loss: 0.3307
2024-06-03 10:22:32 [INFO]: Epoch 020 - training loss: 0.5428, validation loss: 0.3154
2024-06-03 10:22:36 [INFO]: Epoch 021 - training loss: 0.5378, validation loss: 0.3244
2024-06-03 10:22:40 [INFO]: Epoch 022 - training loss: 0.5233, validation loss: 0.3311
2024-06-03 10:22:44 [INFO]: Epoch 023 - training loss: 0.5240, validation loss: 0.3132
2024-06-03 10:22:47 [INFO]: Epoch 024 - training loss: 0.5232, validation loss: 0.3270
2024-06-03 10:22:51 [INFO]: Epoch 025 - training loss: 0.5219, validation loss: 0.3201
2024-06-03 10:22:54 [INFO]: Epoch 026 - training loss: 0.5070, validation loss: 0.3090
2024-06-03 10:22:58 [INFO]: Epoch 027 - training loss: 0.4963, validation loss: 0.3151
2024-06-03 10:23:01 [INFO]: Epoch 028 - training loss: 0.4906, validation loss: 0.3041
2024-06-03 10:23:05 [INFO]: Epoch 029 - training loss: 0.4864, validation loss: 0.3138
2024-06-03 10:23:08 [INFO]: Epoch 030 - training loss: 0.4802, validation loss: 0.2989
2024-06-03 10:23:12 [INFO]: Epoch 031 - training loss: 0.4784, validation loss: 0.2996
2024-06-03 10:23:15 [INFO]: Epoch 032 - training loss: 0.4746, validation loss: 0.3019
2024-06-03 10:23:19 [INFO]: Epoch 033 - training loss: 0.4663, validation loss: 0.3094
2024-06-03 10:23:23 [INFO]: Epoch 034 - training loss: 0.4585, validation loss: 0.3047
2024-06-03 10:23:26 [INFO]: Epoch 035 - training loss: 0.4542, validation loss: 0.3057
2024-06-03 10:23:30 [INFO]: Epoch 036 - training loss: 0.4536, validation loss: 0.3002
2024-06-03 10:23:33 [INFO]: Epoch 037 - training loss: 0.4462, validation loss: 0.2999
2024-06-03 10:23:36 [INFO]: Epoch 038 - training loss: 0.4532, validation loss: 0.3072
2024-06-03 10:23:39 [INFO]: Epoch 039 - training loss: 0.4516, validation loss: 0.2979
2024-06-03 10:23:43 [INFO]: Epoch 040 - training loss: 0.4442, validation loss: 0.3010
2024-06-03 10:23:47 [INFO]: Epoch 041 - training loss: 0.4405, validation loss: 0.3009
2024-06-03 10:23:51 [INFO]: Epoch 042 - training loss: 0.4453, validation loss: 0.3027
2024-06-03 10:23:54 [INFO]: Epoch 043 - training loss: 0.4371, validation loss: 0.3062
2024-06-03 10:23:58 [INFO]: Epoch 044 - training loss: 0.4376, validation loss: 0.2906
2024-06-03 10:24:01 [INFO]: Epoch 045 - training loss: 0.4392, validation loss: 0.2998
2024-06-03 10:24:04 [INFO]: Epoch 046 - training loss: 0.4366, validation loss: 0.3055
2024-06-03 10:24:08 [INFO]: Epoch 047 - training loss: 0.4322, validation loss: 0.2956
2024-06-03 10:24:11 [INFO]: Epoch 048 - training loss: 0.4326, validation loss: 0.2941
2024-06-03 10:24:14 [INFO]: Epoch 049 - training loss: 0.4357, validation loss: 0.2860
2024-06-03 10:24:17 [INFO]: Epoch 050 - training loss: 0.4375, validation loss: 0.2910
2024-06-03 10:24:21 [INFO]: Epoch 051 - training loss: 0.4293, validation loss: 0.3001
2024-06-03 10:24:24 [INFO]: Epoch 052 - training loss: 0.4297, validation loss: 0.2925
2024-06-03 10:24:28 [INFO]: Epoch 053 - training loss: 0.4209, validation loss: 0.2852
2024-06-03 10:24:31 [INFO]: Epoch 054 - training loss: 0.4525, validation loss: 0.2880
2024-06-03 10:24:34 [INFO]: Epoch 055 - training loss: 0.4349, validation loss: 0.2868
2024-06-03 10:24:37 [INFO]: Epoch 056 - training loss: 0.4346, validation loss: 0.2873
2024-06-03 10:24:40 [INFO]: Epoch 057 - training loss: 0.4291, validation loss: 0.2898
2024-06-03 10:24:43 [INFO]: Epoch 058 - training loss: 0.4248, validation loss: 0.2963
2024-06-03 10:24:46 [INFO]: Epoch 059 - training loss: 0.4160, validation loss: 0.3009
2024-06-03 10:24:49 [INFO]: Epoch 060 - training loss: 0.4128, validation loss: 0.2886
2024-06-03 10:24:52 [INFO]: Epoch 061 - training loss: 0.4132, validation loss: 0.2873
2024-06-03 10:24:55 [INFO]: Epoch 062 - training loss: 0.4159, validation loss: 0.2922
2024-06-03 10:24:58 [INFO]: Epoch 063 - training loss: 0.4098, validation loss: 0.2889
2024-06-03 10:24:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:58 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 10:24:59 [INFO]: Saved the model to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_1/20240603_T102117/StemGNN.pypots
2024-06-03 10:25:01 [INFO]: Successfully saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_1/imputation.pkl
2024-06-03 10:25:01 [INFO]: Round1 - StemGNN on ETT_h1: MAE=0.4252, MSE=0.3752, MRE=0.5280
2024-06-03 10:25:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:25:01 [INFO]: Using the given device: cuda:0
2024-06-03 10:25:01 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T102501
2024-06-03 10:25:01 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T102501/tensorboard
2024-06-03 10:25:01 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 10:25:04 [INFO]: Epoch 001 - training loss: 1.5139, validation loss: 0.9083
2024-06-03 10:25:08 [INFO]: Epoch 002 - training loss: 1.2061, validation loss: 0.7265
2024-06-03 10:25:11 [INFO]: Epoch 003 - training loss: 0.9393, validation loss: 0.5329
2024-06-03 10:25:14 [INFO]: Epoch 004 - training loss: 0.8637, validation loss: 0.5191
2024-06-03 10:25:18 [INFO]: Epoch 005 - training loss: 0.8140, validation loss: 0.5494
2024-06-03 10:25:21 [INFO]: Epoch 006 - training loss: 0.8066, validation loss: 0.5103
2024-06-03 10:25:24 [INFO]: Epoch 007 - training loss: 0.7838, validation loss: 0.4625
2024-06-03 10:25:27 [INFO]: Epoch 008 - training loss: 0.7648, validation loss: 0.4409
2024-06-03 10:25:30 [INFO]: Epoch 009 - training loss: 0.7125, validation loss: 0.3960
2024-06-03 10:25:33 [INFO]: Epoch 010 - training loss: 0.6820, validation loss: 0.3683
2024-06-03 10:25:36 [INFO]: Epoch 011 - training loss: 0.6623, validation loss: 0.3709
2024-06-03 10:25:40 [INFO]: Epoch 012 - training loss: 0.6633, validation loss: 0.3586
2024-06-03 10:25:43 [INFO]: Epoch 013 - training loss: 0.6499, validation loss: 0.3641
2024-06-03 10:25:46 [INFO]: Epoch 014 - training loss: 0.6412, validation loss: 0.3405
2024-06-03 10:25:49 [INFO]: Epoch 015 - training loss: 0.6269, validation loss: 0.3437
2024-06-03 10:25:53 [INFO]: Epoch 016 - training loss: 0.6283, validation loss: 0.3325
2024-06-03 10:25:56 [INFO]: Epoch 017 - training loss: 0.6103, validation loss: 0.3216
2024-06-03 10:25:59 [INFO]: Epoch 018 - training loss: 0.5866, validation loss: 0.3350
2024-06-03 10:26:02 [INFO]: Epoch 019 - training loss: 0.5758, validation loss: 0.3361
2024-06-03 10:26:05 [INFO]: Epoch 020 - training loss: 0.5726, validation loss: 0.3310
2024-06-03 10:26:08 [INFO]: Epoch 021 - training loss: 0.5669, validation loss: 0.3318
2024-06-03 10:26:11 [INFO]: Epoch 022 - training loss: 0.5686, validation loss: 0.3295
2024-06-03 10:26:14 [INFO]: Epoch 023 - training loss: 0.5501, validation loss: 0.3333
2024-06-03 10:26:17 [INFO]: Epoch 024 - training loss: 0.5519, validation loss: 0.3457
2024-06-03 10:26:21 [INFO]: Epoch 025 - training loss: 0.5458, validation loss: 0.3245
2024-06-03 10:26:24 [INFO]: Epoch 026 - training loss: 0.5503, validation loss: 0.3244
2024-06-03 10:26:27 [INFO]: Epoch 027 - training loss: 0.5432, validation loss: 0.3239
2024-06-03 10:26:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:26:27 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 10:26:27 [INFO]: Saved the model to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_2/20240603_T102501/StemGNN.pypots
2024-06-03 10:26:29 [INFO]: Successfully saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_2/imputation.pkl
2024-06-03 10:26:29 [INFO]: Round2 - StemGNN on ETT_h1: MAE=0.4509, MSE=0.4037, MRE=0.5599
2024-06-03 10:26:29 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:26:29 [INFO]: Using the given device: cuda:0
2024-06-03 10:26:29 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T102629
2024-06-03 10:26:29 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T102629/tensorboard
2024-06-03 10:26:30 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 10:26:33 [INFO]: Epoch 001 - training loss: 1.5270, validation loss: 0.9323
2024-06-03 10:26:36 [INFO]: Epoch 002 - training loss: 1.4719, validation loss: 0.8688
2024-06-03 10:26:39 [INFO]: Epoch 003 - training loss: 1.2180, validation loss: 0.7656
2024-06-03 10:26:43 [INFO]: Epoch 004 - training loss: 0.9717, validation loss: 0.5440
2024-06-03 10:26:46 [INFO]: Epoch 005 - training loss: 0.8430, validation loss: 0.5158
2024-06-03 10:26:49 [INFO]: Epoch 006 - training loss: 0.7951, validation loss: 0.5176
2024-06-03 10:26:52 [INFO]: Epoch 007 - training loss: 0.7480, validation loss: 0.4606
2024-06-03 10:26:55 [INFO]: Epoch 008 - training loss: 0.7079, validation loss: 0.4010
2024-06-03 10:26:58 [INFO]: Epoch 009 - training loss: 0.6865, validation loss: 0.3663
2024-06-03 10:27:01 [INFO]: Epoch 010 - training loss: 0.6556, validation loss: 0.3411
2024-06-03 10:27:04 [INFO]: Epoch 011 - training loss: 0.6403, validation loss: 0.3396
2024-06-03 10:27:07 [INFO]: Epoch 012 - training loss: 0.6275, validation loss: 0.3415
2024-06-03 10:27:10 [INFO]: Epoch 013 - training loss: 0.6184, validation loss: 0.3438
2024-06-03 10:27:13 [INFO]: Epoch 014 - training loss: 0.5992, validation loss: 0.3404
2024-06-03 10:27:16 [INFO]: Epoch 015 - training loss: 0.5967, validation loss: 0.3443
2024-06-03 10:27:19 [INFO]: Epoch 016 - training loss: 0.6030, validation loss: 0.3378
2024-06-03 10:27:22 [INFO]: Epoch 017 - training loss: 0.5964, validation loss: 0.3489
2024-06-03 10:27:25 [INFO]: Epoch 018 - training loss: 0.5797, validation loss: 0.3387
2024-06-03 10:27:28 [INFO]: Epoch 019 - training loss: 0.5728, validation loss: 0.3383
2024-06-03 10:27:32 [INFO]: Epoch 020 - training loss: 0.5513, validation loss: 0.3498
2024-06-03 10:27:35 [INFO]: Epoch 021 - training loss: 0.5506, validation loss: 0.3319
2024-06-03 10:27:38 [INFO]: Epoch 022 - training loss: 0.5498, validation loss: 0.3350
2024-06-03 10:27:41 [INFO]: Epoch 023 - training loss: 0.5572, validation loss: 0.3219
2024-06-03 10:27:43 [INFO]: Epoch 024 - training loss: 0.5647, validation loss: 0.3310
2024-06-03 10:27:47 [INFO]: Epoch 025 - training loss: 0.5549, validation loss: 0.3321
2024-06-03 10:27:50 [INFO]: Epoch 026 - training loss: 0.5496, validation loss: 0.3335
2024-06-03 10:27:53 [INFO]: Epoch 027 - training loss: 0.5403, validation loss: 0.3394
2024-06-03 10:27:56 [INFO]: Epoch 028 - training loss: 0.5308, validation loss: 0.3327
2024-06-03 10:27:59 [INFO]: Epoch 029 - training loss: 0.5377, validation loss: 0.3275
2024-06-03 10:28:02 [INFO]: Epoch 030 - training loss: 0.5264, validation loss: 0.3216
2024-06-03 10:28:05 [INFO]: Epoch 031 - training loss: 0.5454, validation loss: 0.3319
2024-06-03 10:28:08 [INFO]: Epoch 032 - training loss: 0.5271, validation loss: 0.3182
2024-06-03 10:28:11 [INFO]: Epoch 033 - training loss: 0.5260, validation loss: 0.3175
2024-06-03 10:28:14 [INFO]: Epoch 034 - training loss: 0.5224, validation loss: 0.3239
2024-06-03 10:28:17 [INFO]: Epoch 035 - training loss: 0.5274, validation loss: 0.3171
2024-06-03 10:28:20 [INFO]: Epoch 036 - training loss: 0.5230, validation loss: 0.3080
2024-06-03 10:28:23 [INFO]: Epoch 037 - training loss: 0.5015, validation loss: 0.3126
2024-06-03 10:28:25 [INFO]: Epoch 038 - training loss: 0.5009, validation loss: 0.3130
2024-06-03 10:28:28 [INFO]: Epoch 039 - training loss: 0.4936, validation loss: 0.3113
2024-06-03 10:28:31 [INFO]: Epoch 040 - training loss: 0.5004, validation loss: 0.3153
2024-06-03 10:28:33 [INFO]: Epoch 041 - training loss: 0.4894, validation loss: 0.3077
2024-06-03 10:28:36 [INFO]: Epoch 042 - training loss: 0.4895, validation loss: 0.3137
2024-06-03 10:28:38 [INFO]: Epoch 043 - training loss: 0.4797, validation loss: 0.3058
2024-06-03 10:28:41 [INFO]: Epoch 044 - training loss: 0.4704, validation loss: 0.3033
2024-06-03 10:28:43 [INFO]: Epoch 045 - training loss: 0.4692, validation loss: 0.2999
2024-06-03 10:28:46 [INFO]: Epoch 046 - training loss: 0.4673, validation loss: 0.3030
2024-06-03 10:28:48 [INFO]: Epoch 047 - training loss: 0.4582, validation loss: 0.3030
2024-06-03 10:28:51 [INFO]: Epoch 048 - training loss: 0.4564, validation loss: 0.3089
2024-06-03 10:28:53 [INFO]: Epoch 049 - training loss: 0.4529, validation loss: 0.2979
2024-06-03 10:28:55 [INFO]: Epoch 050 - training loss: 0.4528, validation loss: 0.3044
2024-06-03 10:28:57 [INFO]: Epoch 051 - training loss: 0.4454, validation loss: 0.3088
2024-06-03 10:29:00 [INFO]: Epoch 052 - training loss: 0.4466, validation loss: 0.3133
2024-06-03 10:29:02 [INFO]: Epoch 053 - training loss: 0.4483, validation loss: 0.3023
2024-06-03 10:29:04 [INFO]: Epoch 054 - training loss: 0.4510, validation loss: 0.2947
2024-06-03 10:29:06 [INFO]: Epoch 055 - training loss: 0.4475, validation loss: 0.2899
2024-06-03 10:29:08 [INFO]: Epoch 056 - training loss: 0.4446, validation loss: 0.2973
2024-06-03 10:29:11 [INFO]: Epoch 057 - training loss: 0.4403, validation loss: 0.2917
2024-06-03 10:29:13 [INFO]: Epoch 058 - training loss: 0.4312, validation loss: 0.2885
2024-06-03 10:29:15 [INFO]: Epoch 059 - training loss: 0.4225, validation loss: 0.2838
2024-06-03 10:29:17 [INFO]: Epoch 060 - training loss: 0.4320, validation loss: 0.2811
2024-06-03 10:29:19 [INFO]: Epoch 061 - training loss: 0.4276, validation loss: 0.2871
2024-06-03 10:29:21 [INFO]: Epoch 062 - training loss: 0.4271, validation loss: 0.2875
2024-06-03 10:29:24 [INFO]: Epoch 063 - training loss: 0.4226, validation loss: 0.2870
2024-06-03 10:29:26 [INFO]: Epoch 064 - training loss: 0.4236, validation loss: 0.2822
2024-06-03 10:29:28 [INFO]: Epoch 065 - training loss: 0.4225, validation loss: 0.2733
2024-06-03 10:29:30 [INFO]: Epoch 066 - training loss: 0.4204, validation loss: 0.2876
2024-06-03 10:29:32 [INFO]: Epoch 067 - training loss: 0.4142, validation loss: 0.2798
2024-06-03 10:29:34 [INFO]: Epoch 068 - training loss: 0.4112, validation loss: 0.2812
2024-06-03 10:29:36 [INFO]: Epoch 069 - training loss: 0.4122, validation loss: 0.2925
2024-06-03 10:29:39 [INFO]: Epoch 070 - training loss: 0.4155, validation loss: 0.2929
2024-06-03 10:29:41 [INFO]: Epoch 071 - training loss: 0.4053, validation loss: 0.2940
2024-06-03 10:29:43 [INFO]: Epoch 072 - training loss: 0.4081, validation loss: 0.2843
2024-06-03 10:29:45 [INFO]: Epoch 073 - training loss: 0.4330, validation loss: 0.2873
2024-06-03 10:29:47 [INFO]: Epoch 074 - training loss: 0.4163, validation loss: 0.2882
2024-06-03 10:29:49 [INFO]: Epoch 075 - training loss: 0.4112, validation loss: 0.2769
2024-06-03 10:29:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:29:49 [INFO]: Finished training. The best model is from epoch#65.
2024-06-03 10:29:49 [INFO]: Saved the model to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_3/20240603_T102629/StemGNN.pypots
2024-06-03 10:29:50 [INFO]: Successfully saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_3/imputation.pkl
2024-06-03 10:29:50 [INFO]: Round3 - StemGNN on ETT_h1: MAE=0.4363, MSE=0.3955, MRE=0.5418
2024-06-03 10:29:50 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:29:50 [INFO]: Using the given device: cuda:0
2024-06-03 10:29:50 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T102950
2024-06-03 10:29:50 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T102950/tensorboard
2024-06-03 10:29:51 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 6,397,975
2024-06-03 10:29:53 [INFO]: Epoch 001 - training loss: 1.5366, validation loss: 0.9195
2024-06-03 10:29:55 [INFO]: Epoch 002 - training loss: 1.4656, validation loss: 0.8287
2024-06-03 10:29:57 [INFO]: Epoch 003 - training loss: 1.3833, validation loss: 0.7964
2024-06-03 10:29:59 [INFO]: Epoch 004 - training loss: 1.1039, validation loss: 0.6034
2024-06-03 10:30:01 [INFO]: Epoch 005 - training loss: 0.8592, validation loss: 0.4813
2024-06-03 10:30:03 [INFO]: Epoch 006 - training loss: 0.7620, validation loss: 0.4565
2024-06-03 10:30:05 [INFO]: Epoch 007 - training loss: 0.6886, validation loss: 0.3934
2024-06-03 10:30:07 [INFO]: Epoch 008 - training loss: 0.6551, validation loss: 0.3803
2024-06-03 10:30:09 [INFO]: Epoch 009 - training loss: 0.6528, validation loss: 0.3945
2024-06-03 10:30:11 [INFO]: Epoch 010 - training loss: 0.6262, validation loss: 0.3873
2024-06-03 10:30:13 [INFO]: Epoch 011 - training loss: 0.6121, validation loss: 0.3739
2024-06-03 10:30:15 [INFO]: Epoch 012 - training loss: 0.5735, validation loss: 0.3318
2024-06-03 10:30:17 [INFO]: Epoch 013 - training loss: 0.5601, validation loss: 0.3526
2024-06-03 10:30:20 [INFO]: Epoch 014 - training loss: 0.5540, validation loss: 0.3267
2024-06-03 10:30:22 [INFO]: Epoch 015 - training loss: 0.5604, validation loss: 0.3321
2024-06-03 10:30:24 [INFO]: Epoch 016 - training loss: 0.5552, validation loss: 0.3269
2024-06-03 10:30:26 [INFO]: Epoch 017 - training loss: 0.5419, validation loss: 0.3362
2024-06-03 10:30:28 [INFO]: Epoch 018 - training loss: 0.5381, validation loss: 0.3369
2024-06-03 10:30:30 [INFO]: Epoch 019 - training loss: 0.5304, validation loss: 0.3184
2024-06-03 10:30:32 [INFO]: Epoch 020 - training loss: 0.5343, validation loss: 0.3205
2024-06-03 10:30:34 [INFO]: Epoch 021 - training loss: 0.5203, validation loss: 0.3113
2024-06-03 10:30:36 [INFO]: Epoch 022 - training loss: 0.5154, validation loss: 0.3131
2024-06-03 10:30:38 [INFO]: Epoch 023 - training loss: 0.5187, validation loss: 0.3252
2024-06-03 10:30:40 [INFO]: Epoch 024 - training loss: 0.5150, validation loss: 0.3210
2024-06-03 10:30:42 [INFO]: Epoch 025 - training loss: 0.5036, validation loss: 0.3128
2024-06-03 10:30:44 [INFO]: Epoch 026 - training loss: 0.4868, validation loss: 0.3121
2024-06-03 10:30:46 [INFO]: Epoch 027 - training loss: 0.4851, validation loss: 0.2980
2024-06-03 10:30:48 [INFO]: Epoch 028 - training loss: 0.4855, validation loss: 0.3024
2024-06-03 10:30:50 [INFO]: Epoch 029 - training loss: 0.4792, validation loss: 0.3155
2024-06-03 10:30:52 [INFO]: Epoch 030 - training loss: 0.4718, validation loss: 0.2953
2024-06-03 10:30:54 [INFO]: Epoch 031 - training loss: 0.4630, validation loss: 0.2992
2024-06-03 10:30:55 [INFO]: Epoch 032 - training loss: 0.4579, validation loss: 0.3126
2024-06-03 10:30:57 [INFO]: Epoch 033 - training loss: 0.4570, validation loss: 0.2998
2024-06-03 10:30:59 [INFO]: Epoch 034 - training loss: 0.4584, validation loss: 0.3085
2024-06-03 10:31:01 [INFO]: Epoch 035 - training loss: 0.4554, validation loss: 0.3029
2024-06-03 10:31:03 [INFO]: Epoch 036 - training loss: 0.4525, validation loss: 0.2968
2024-06-03 10:31:05 [INFO]: Epoch 037 - training loss: 0.4411, validation loss: 0.2949
2024-06-03 10:31:07 [INFO]: Epoch 038 - training loss: 0.4415, validation loss: 0.3098
2024-06-03 10:31:09 [INFO]: Epoch 039 - training loss: 0.4329, validation loss: 0.2920
2024-06-03 10:31:10 [INFO]: Epoch 040 - training loss: 0.4272, validation loss: 0.2987
2024-06-03 10:31:12 [INFO]: Epoch 041 - training loss: 0.4198, validation loss: 0.2971
2024-06-03 10:31:14 [INFO]: Epoch 042 - training loss: 0.4206, validation loss: 0.2887
2024-06-03 10:31:16 [INFO]: Epoch 043 - training loss: 0.4196, validation loss: 0.3047
2024-06-03 10:31:18 [INFO]: Epoch 044 - training loss: 0.4058, validation loss: 0.3017
2024-06-03 10:31:20 [INFO]: Epoch 045 - training loss: 0.4140, validation loss: 0.3042
2024-06-03 10:31:22 [INFO]: Epoch 046 - training loss: 0.4047, validation loss: 0.2896
2024-06-03 10:31:24 [INFO]: Epoch 047 - training loss: 0.4039, validation loss: 0.2948
2024-06-03 10:31:26 [INFO]: Epoch 048 - training loss: 0.4039, validation loss: 0.2943
2024-06-03 10:31:28 [INFO]: Epoch 049 - training loss: 0.4031, validation loss: 0.3033
2024-06-03 10:31:30 [INFO]: Epoch 050 - training loss: 0.4093, validation loss: 0.2809
2024-06-03 10:31:32 [INFO]: Epoch 051 - training loss: 0.3991, validation loss: 0.3010
2024-06-03 10:31:34 [INFO]: Epoch 052 - training loss: 0.4027, validation loss: 0.2890
2024-06-03 10:31:36 [INFO]: Epoch 053 - training loss: 0.3934, validation loss: 0.2735
2024-06-03 10:31:38 [INFO]: Epoch 054 - training loss: 0.3977, validation loss: 0.3018
2024-06-03 10:31:40 [INFO]: Epoch 055 - training loss: 0.3967, validation loss: 0.2836
2024-06-03 10:31:42 [INFO]: Epoch 056 - training loss: 0.3896, validation loss: 0.2820
2024-06-03 10:31:44 [INFO]: Epoch 057 - training loss: 0.3827, validation loss: 0.2821
2024-06-03 10:31:45 [INFO]: Epoch 058 - training loss: 0.3794, validation loss: 0.2724
2024-06-03 10:31:47 [INFO]: Epoch 059 - training loss: 0.3797, validation loss: 0.2723
2024-06-03 10:31:49 [INFO]: Epoch 060 - training loss: 0.3769, validation loss: 0.2765
2024-06-03 10:31:51 [INFO]: Epoch 061 - training loss: 0.3717, validation loss: 0.2791
2024-06-03 10:31:52 [INFO]: Epoch 062 - training loss: 0.3762, validation loss: 0.2680
2024-06-03 10:31:54 [INFO]: Epoch 063 - training loss: 0.3754, validation loss: 0.2841
2024-06-03 10:31:56 [INFO]: Epoch 064 - training loss: 0.3749, validation loss: 0.2831
2024-06-03 10:31:58 [INFO]: Epoch 065 - training loss: 0.3745, validation loss: 0.2552
2024-06-03 10:32:00 [INFO]: Epoch 066 - training loss: 0.3717, validation loss: 0.2760
2024-06-03 10:32:02 [INFO]: Epoch 067 - training loss: 0.3718, validation loss: 0.2888
2024-06-03 10:32:04 [INFO]: Epoch 068 - training loss: 0.3661, validation loss: 0.2750
2024-06-03 10:32:07 [INFO]: Epoch 069 - training loss: 0.3717, validation loss: 0.3021
2024-06-03 10:32:09 [INFO]: Epoch 070 - training loss: 0.3734, validation loss: 0.2674
2024-06-03 10:32:11 [INFO]: Epoch 071 - training loss: 0.3680, validation loss: 0.2725
2024-06-03 10:32:13 [INFO]: Epoch 072 - training loss: 0.3708, validation loss: 0.2728
2024-06-03 10:32:15 [INFO]: Epoch 073 - training loss: 0.3627, validation loss: 0.2808
2024-06-03 10:32:17 [INFO]: Epoch 074 - training loss: 0.3708, validation loss: 0.2837
2024-06-03 10:32:19 [INFO]: Epoch 075 - training loss: 0.3683, validation loss: 0.3007
2024-06-03 10:32:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:32:19 [INFO]: Finished training. The best model is from epoch#65.
2024-06-03 10:32:19 [INFO]: Saved the model to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_4/20240603_T102950/StemGNN.pypots
2024-06-03 10:32:20 [INFO]: Successfully saved to results_block_rate05/ETT_h1/StemGNN_ETT_h1/round_4/imputation.pkl
2024-06-03 10:32:20 [INFO]: Round4 - StemGNN on ETT_h1: MAE=0.4189, MSE=0.3569, MRE=0.5202
2024-06-03 10:32:20 [INFO]: Done! Final results:
Averaged StemGNN (6,397,975 params) on ETT_h1: MAE=0.4335 ± 0.010955171396407507, MSE=0.3843 ± 0.01657467383903706, MRE=0.5383 ± 0.01360382525633511, average inference time=0.48
