2024-06-03 10:17:20 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:17:20 [INFO]: Using the given device: cuda:0
2024-06-03 10:17:24 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T101724
2024-06-03 10:17:24 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T101724/tensorboard
2024-06-03 10:17:29 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 10:17:38 [INFO]: Epoch 001 - training loss: 1.6530, validation loss: 1.0394
2024-06-03 10:17:40 [INFO]: Epoch 002 - training loss: 1.4891, validation loss: 0.9435
2024-06-03 10:17:42 [INFO]: Epoch 003 - training loss: 1.2686, validation loss: 0.8156
2024-06-03 10:17:45 [INFO]: Epoch 004 - training loss: 1.0948, validation loss: 0.7825
2024-06-03 10:17:48 [INFO]: Epoch 005 - training loss: 0.9922, validation loss: 0.6835
2024-06-03 10:17:51 [INFO]: Epoch 006 - training loss: 0.9382, validation loss: 0.6558
2024-06-03 10:17:55 [INFO]: Epoch 007 - training loss: 0.9003, validation loss: 0.6378
2024-06-03 10:17:58 [INFO]: Epoch 008 - training loss: 0.8841, validation loss: 0.6299
2024-06-03 10:18:02 [INFO]: Epoch 009 - training loss: 0.8810, validation loss: 0.6529
2024-06-03 10:18:05 [INFO]: Epoch 010 - training loss: 0.8711, validation loss: 0.6479
2024-06-03 10:18:08 [INFO]: Epoch 011 - training loss: 0.8755, validation loss: 0.6363
2024-06-03 10:18:12 [INFO]: Epoch 012 - training loss: 0.8516, validation loss: 0.6366
2024-06-03 10:18:14 [INFO]: Epoch 013 - training loss: 0.8612, validation loss: 0.6207
2024-06-03 10:18:17 [INFO]: Epoch 014 - training loss: 0.8642, validation loss: 0.6312
2024-06-03 10:18:21 [INFO]: Epoch 015 - training loss: 0.8581, validation loss: 0.6228
2024-06-03 10:18:24 [INFO]: Epoch 016 - training loss: 0.8632, validation loss: 0.6294
2024-06-03 10:18:27 [INFO]: Epoch 017 - training loss: 0.8490, validation loss: 0.6292
2024-06-03 10:18:30 [INFO]: Epoch 018 - training loss: 0.8654, validation loss: 0.6328
2024-06-03 10:18:34 [INFO]: Epoch 019 - training loss: 0.8657, validation loss: 0.6237
2024-06-03 10:18:37 [INFO]: Epoch 020 - training loss: 0.8561, validation loss: 0.6353
2024-06-03 10:18:40 [INFO]: Epoch 021 - training loss: 0.8589, validation loss: 0.6311
2024-06-03 10:18:44 [INFO]: Epoch 022 - training loss: 0.8542, validation loss: 0.6365
2024-06-03 10:18:47 [INFO]: Epoch 023 - training loss: 0.8522, validation loss: 0.6292
2024-06-03 10:18:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:18:47 [INFO]: Finished training. The best model is from epoch#13.
2024-06-03 10:18:47 [INFO]: Saved the model to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T101724/FiLM.pypots
2024-06-03 10:18:50 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_0/imputation.pkl
2024-06-03 10:18:50 [INFO]: Round0 - FiLM on ETT_h1: MAE=0.6482, MSE=0.9551, MRE=0.8049
2024-06-03 10:18:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:18:50 [INFO]: Using the given device: cuda:0
2024-06-03 10:18:50 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T101850
2024-06-03 10:18:50 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T101850/tensorboard
2024-06-03 10:18:50 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 10:18:54 [INFO]: Epoch 001 - training loss: 2.3020, validation loss: 1.1826
2024-06-03 10:18:57 [INFO]: Epoch 002 - training loss: 1.7137, validation loss: 0.9022
2024-06-03 10:19:00 [INFO]: Epoch 003 - training loss: 1.4151, validation loss: 0.9816
2024-06-03 10:19:03 [INFO]: Epoch 004 - training loss: 1.1812, validation loss: 0.8968
2024-06-03 10:19:06 [INFO]: Epoch 005 - training loss: 1.0431, validation loss: 0.7012
2024-06-03 10:19:09 [INFO]: Epoch 006 - training loss: 0.9446, validation loss: 0.6530
2024-06-03 10:19:12 [INFO]: Epoch 007 - training loss: 0.8961, validation loss: 0.6408
2024-06-03 10:19:15 [INFO]: Epoch 008 - training loss: 0.8677, validation loss: 0.6330
2024-06-03 10:19:18 [INFO]: Epoch 009 - training loss: 0.8716, validation loss: 0.6370
2024-06-03 10:19:21 [INFO]: Epoch 010 - training loss: 0.8654, validation loss: 0.6322
2024-06-03 10:19:24 [INFO]: Epoch 011 - training loss: 0.8628, validation loss: 0.6464
2024-06-03 10:19:27 [INFO]: Epoch 012 - training loss: 0.8564, validation loss: 0.6153
2024-06-03 10:19:30 [INFO]: Epoch 013 - training loss: 0.8619, validation loss: 0.6399
2024-06-03 10:19:33 [INFO]: Epoch 014 - training loss: 0.8586, validation loss: 0.6202
2024-06-03 10:19:36 [INFO]: Epoch 015 - training loss: 0.8465, validation loss: 0.6355
2024-06-03 10:19:40 [INFO]: Epoch 016 - training loss: 0.8574, validation loss: 0.6267
2024-06-03 10:19:43 [INFO]: Epoch 017 - training loss: 0.8641, validation loss: 0.6458
2024-06-03 10:19:46 [INFO]: Epoch 018 - training loss: 0.8687, validation loss: 0.6281
2024-06-03 10:19:49 [INFO]: Epoch 019 - training loss: 0.8586, validation loss: 0.6278
2024-06-03 10:19:53 [INFO]: Epoch 020 - training loss: 0.8612, validation loss: 0.6496
2024-06-03 10:19:56 [INFO]: Epoch 021 - training loss: 0.8566, validation loss: 0.6290
2024-06-03 10:19:59 [INFO]: Epoch 022 - training loss: 0.8568, validation loss: 0.6435
2024-06-03 10:19:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:19:59 [INFO]: Finished training. The best model is from epoch#12.
2024-06-03 10:19:59 [INFO]: Saved the model to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T101850/FiLM.pypots
2024-06-03 10:20:02 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_1/imputation.pkl
2024-06-03 10:20:02 [INFO]: Round1 - FiLM on ETT_h1: MAE=0.6459, MSE=0.9812, MRE=0.8020
2024-06-03 10:20:02 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:20:02 [INFO]: Using the given device: cuda:0
2024-06-03 10:20:02 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T102002
2024-06-03 10:20:02 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T102002/tensorboard
2024-06-03 10:20:02 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 10:20:05 [INFO]: Epoch 001 - training loss: 1.9235, validation loss: 1.1228
2024-06-03 10:20:09 [INFO]: Epoch 002 - training loss: 1.6342, validation loss: 1.0128
2024-06-03 10:20:12 [INFO]: Epoch 003 - training loss: 1.4690, validation loss: 0.9041
2024-06-03 10:20:15 [INFO]: Epoch 004 - training loss: 1.2525, validation loss: 0.8376
2024-06-03 10:20:19 [INFO]: Epoch 005 - training loss: 1.0858, validation loss: 0.7647
2024-06-03 10:20:22 [INFO]: Epoch 006 - training loss: 0.9700, validation loss: 0.7050
2024-06-03 10:20:26 [INFO]: Epoch 007 - training loss: 0.9194, validation loss: 0.6655
2024-06-03 10:20:29 [INFO]: Epoch 008 - training loss: 0.8900, validation loss: 0.6461
2024-06-03 10:20:32 [INFO]: Epoch 009 - training loss: 0.8820, validation loss: 0.6473
2024-06-03 10:20:35 [INFO]: Epoch 010 - training loss: 0.8703, validation loss: 0.6289
2024-06-03 10:20:39 [INFO]: Epoch 011 - training loss: 0.8790, validation loss: 0.6364
2024-06-03 10:20:42 [INFO]: Epoch 012 - training loss: 0.8573, validation loss: 0.6335
2024-06-03 10:20:45 [INFO]: Epoch 013 - training loss: 0.8608, validation loss: 0.6354
2024-06-03 10:20:48 [INFO]: Epoch 014 - training loss: 0.8605, validation loss: 0.6280
2024-06-03 10:20:52 [INFO]: Epoch 015 - training loss: 0.8551, validation loss: 0.6285
2024-06-03 10:20:55 [INFO]: Epoch 016 - training loss: 0.8589, validation loss: 0.6397
2024-06-03 10:20:57 [INFO]: Epoch 017 - training loss: 0.8525, validation loss: 0.6270
2024-06-03 10:21:01 [INFO]: Epoch 018 - training loss: 0.8524, validation loss: 0.6389
2024-06-03 10:21:04 [INFO]: Epoch 019 - training loss: 0.8540, validation loss: 0.6302
2024-06-03 10:21:07 [INFO]: Epoch 020 - training loss: 0.8627, validation loss: 0.6347
2024-06-03 10:21:10 [INFO]: Epoch 021 - training loss: 0.8546, validation loss: 0.6301
2024-06-03 10:21:13 [INFO]: Epoch 022 - training loss: 0.8532, validation loss: 0.6325
2024-06-03 10:21:16 [INFO]: Epoch 023 - training loss: 0.8474, validation loss: 0.6184
2024-06-03 10:21:19 [INFO]: Epoch 024 - training loss: 0.8586, validation loss: 0.6323
2024-06-03 10:21:22 [INFO]: Epoch 025 - training loss: 0.8522, validation loss: 0.6256
2024-06-03 10:21:25 [INFO]: Epoch 026 - training loss: 0.8441, validation loss: 0.6308
2024-06-03 10:21:27 [INFO]: Epoch 027 - training loss: 0.8548, validation loss: 0.6239
2024-06-03 10:21:29 [INFO]: Epoch 028 - training loss: 0.8448, validation loss: 0.6342
2024-06-03 10:21:32 [INFO]: Epoch 029 - training loss: 0.8380, validation loss: 0.6271
2024-06-03 10:21:34 [INFO]: Epoch 030 - training loss: 0.8422, validation loss: 0.6310
2024-06-03 10:21:36 [INFO]: Epoch 031 - training loss: 0.8421, validation loss: 0.6356
2024-06-03 10:21:39 [INFO]: Epoch 032 - training loss: 0.8547, validation loss: 0.6351
2024-06-03 10:21:41 [INFO]: Epoch 033 - training loss: 0.8349, validation loss: 0.6282
2024-06-03 10:21:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:41 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 10:21:41 [INFO]: Saved the model to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T102002/FiLM.pypots
2024-06-03 10:21:43 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_2/imputation.pkl
2024-06-03 10:21:43 [INFO]: Round2 - FiLM on ETT_h1: MAE=0.6422, MSE=0.9543, MRE=0.7975
2024-06-03 10:21:43 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:21:43 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:43 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T102143
2024-06-03 10:21:43 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T102143/tensorboard
2024-06-03 10:21:43 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 10:21:46 [INFO]: Epoch 001 - training loss: 1.5625, validation loss: 0.9936
2024-06-03 10:21:49 [INFO]: Epoch 002 - training loss: 1.4793, validation loss: 0.9153
2024-06-03 10:21:52 [INFO]: Epoch 003 - training loss: 1.2585, validation loss: 0.8570
2024-06-03 10:21:54 [INFO]: Epoch 004 - training loss: 1.1315, validation loss: 0.7510
2024-06-03 10:21:57 [INFO]: Epoch 005 - training loss: 1.0227, validation loss: 0.6722
2024-06-03 10:22:00 [INFO]: Epoch 006 - training loss: 0.9442, validation loss: 0.6373
2024-06-03 10:22:03 [INFO]: Epoch 007 - training loss: 0.8983, validation loss: 0.6347
2024-06-03 10:22:05 [INFO]: Epoch 008 - training loss: 0.8952, validation loss: 0.6311
2024-06-03 10:22:08 [INFO]: Epoch 009 - training loss: 0.8876, validation loss: 0.6362
2024-06-03 10:22:11 [INFO]: Epoch 010 - training loss: 0.8725, validation loss: 0.6301
2024-06-03 10:22:14 [INFO]: Epoch 011 - training loss: 0.8771, validation loss: 0.6352
2024-06-03 10:22:16 [INFO]: Epoch 012 - training loss: 0.8631, validation loss: 0.6294
2024-06-03 10:22:19 [INFO]: Epoch 013 - training loss: 0.8662, validation loss: 0.6448
2024-06-03 10:22:22 [INFO]: Epoch 014 - training loss: 0.8591, validation loss: 0.6290
2024-06-03 10:22:25 [INFO]: Epoch 015 - training loss: 0.8595, validation loss: 0.6273
2024-06-03 10:22:27 [INFO]: Epoch 016 - training loss: 0.8550, validation loss: 0.6175
2024-06-03 10:22:30 [INFO]: Epoch 017 - training loss: 0.8447, validation loss: 0.6274
2024-06-03 10:22:32 [INFO]: Epoch 018 - training loss: 0.8614, validation loss: 0.6287
2024-06-03 10:22:35 [INFO]: Epoch 019 - training loss: 0.8518, validation loss: 0.6296
2024-06-03 10:22:38 [INFO]: Epoch 020 - training loss: 0.8440, validation loss: 0.6205
2024-06-03 10:22:40 [INFO]: Epoch 021 - training loss: 0.8492, validation loss: 0.6380
2024-06-03 10:22:43 [INFO]: Epoch 022 - training loss: 0.8565, validation loss: 0.6211
2024-06-03 10:22:46 [INFO]: Epoch 023 - training loss: 0.8602, validation loss: 0.6432
2024-06-03 10:22:48 [INFO]: Epoch 024 - training loss: 0.8482, validation loss: 0.6277
2024-06-03 10:22:51 [INFO]: Epoch 025 - training loss: 0.8505, validation loss: 0.6458
2024-06-03 10:22:54 [INFO]: Epoch 026 - training loss: 0.8473, validation loss: 0.6253
2024-06-03 10:22:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:22:54 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 10:22:54 [INFO]: Saved the model to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T102143/FiLM.pypots
2024-06-03 10:22:55 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_3/imputation.pkl
2024-06-03 10:22:55 [INFO]: Round3 - FiLM on ETT_h1: MAE=0.6436, MSE=0.9620, MRE=0.7992
2024-06-03 10:22:55 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:22:55 [INFO]: Using the given device: cuda:0
2024-06-03 10:22:55 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T102255
2024-06-03 10:22:55 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T102255/tensorboard
2024-06-03 10:22:55 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 10:22:58 [INFO]: Epoch 001 - training loss: 1.7417, validation loss: 0.9912
2024-06-03 10:23:01 [INFO]: Epoch 002 - training loss: 1.5710, validation loss: 0.9784
2024-06-03 10:23:04 [INFO]: Epoch 003 - training loss: 1.4703, validation loss: 0.9125
2024-06-03 10:23:06 [INFO]: Epoch 004 - training loss: 1.3122, validation loss: 0.8607
2024-06-03 10:23:09 [INFO]: Epoch 005 - training loss: 1.0810, validation loss: 0.8124
2024-06-03 10:23:11 [INFO]: Epoch 006 - training loss: 1.0069, validation loss: 0.7447
2024-06-03 10:23:14 [INFO]: Epoch 007 - training loss: 0.9408, validation loss: 0.6824
2024-06-03 10:23:16 [INFO]: Epoch 008 - training loss: 0.9307, validation loss: 0.6639
2024-06-03 10:23:19 [INFO]: Epoch 009 - training loss: 0.9101, validation loss: 0.6474
2024-06-03 10:23:22 [INFO]: Epoch 010 - training loss: 0.8833, validation loss: 0.6338
2024-06-03 10:23:24 [INFO]: Epoch 011 - training loss: 0.8702, validation loss: 0.6471
2024-06-03 10:23:27 [INFO]: Epoch 012 - training loss: 0.8703, validation loss: 0.6236
2024-06-03 10:23:29 [INFO]: Epoch 013 - training loss: 0.8731, validation loss: 0.6375
2024-06-03 10:23:31 [INFO]: Epoch 014 - training loss: 0.8575, validation loss: 0.6195
2024-06-03 10:23:34 [INFO]: Epoch 015 - training loss: 0.8527, validation loss: 0.6292
2024-06-03 10:23:36 [INFO]: Epoch 016 - training loss: 0.8525, validation loss: 0.6266
2024-06-03 10:23:38 [INFO]: Epoch 017 - training loss: 0.8579, validation loss: 0.6279
2024-06-03 10:23:40 [INFO]: Epoch 018 - training loss: 0.8533, validation loss: 0.6236
2024-06-03 10:23:43 [INFO]: Epoch 019 - training loss: 0.8568, validation loss: 0.6333
2024-06-03 10:23:45 [INFO]: Epoch 020 - training loss: 0.8558, validation loss: 0.6395
2024-06-03 10:23:48 [INFO]: Epoch 021 - training loss: 0.8585, validation loss: 0.6229
2024-06-03 10:23:50 [INFO]: Epoch 022 - training loss: 0.8527, validation loss: 0.6381
2024-06-03 10:23:53 [INFO]: Epoch 023 - training loss: 0.8447, validation loss: 0.6271
2024-06-03 10:23:55 [INFO]: Epoch 024 - training loss: 0.8479, validation loss: 0.6389
2024-06-03 10:23:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:23:55 [INFO]: Finished training. The best model is from epoch#14.
2024-06-03 10:23:55 [INFO]: Saved the model to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T102255/FiLM.pypots
2024-06-03 10:23:57 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FiLM_ETT_h1/round_4/imputation.pkl
2024-06-03 10:23:57 [INFO]: Round4 - FiLM on ETT_h1: MAE=0.6485, MSE=0.9711, MRE=0.8053
2024-06-03 10:23:57 [INFO]: Done! Final results:
Averaged FiLM (12,490 params) on ETT_h1: MAE=0.6457 ± 0.0024753400298195326, MSE=0.9647 ± 0.010226301537291538, MRE=0.8018 ± 0.0030738079759043283, average inference time=0.40
