2024-06-03 10:17:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:17:24 [INFO]: Using the given device: cuda:0
2024-06-03 10:17:25 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_0/20240603_T101725
2024-06-03 10:17:25 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_0/20240603_T101725/tensorboard
2024-06-03 10:17:30 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-03 10:17:39 [INFO]: Epoch 001 - training loss: 2.3482, validation loss: 1.4799
2024-06-03 10:17:40 [INFO]: Epoch 002 - training loss: 1.4863, validation loss: 0.8616
2024-06-03 10:17:42 [INFO]: Epoch 003 - training loss: 1.0504, validation loss: 0.6757
2024-06-03 10:17:44 [INFO]: Epoch 004 - training loss: 0.8588, validation loss: 0.5898
2024-06-03 10:17:46 [INFO]: Epoch 005 - training loss: 0.7840, validation loss: 0.5949
2024-06-03 10:17:48 [INFO]: Epoch 006 - training loss: 0.7348, validation loss: 0.5276
2024-06-03 10:17:51 [INFO]: Epoch 007 - training loss: 0.6736, validation loss: 0.4953
2024-06-03 10:17:52 [INFO]: Epoch 008 - training loss: 0.6352, validation loss: 0.5111
2024-06-03 10:17:55 [INFO]: Epoch 009 - training loss: 0.6080, validation loss: 0.5255
2024-06-03 10:17:58 [INFO]: Epoch 010 - training loss: 0.5954, validation loss: 0.4942
2024-06-03 10:18:00 [INFO]: Epoch 011 - training loss: 0.5978, validation loss: 0.5535
2024-06-03 10:18:02 [INFO]: Epoch 012 - training loss: 0.5815, validation loss: 0.4879
2024-06-03 10:18:05 [INFO]: Epoch 013 - training loss: 0.5592, validation loss: 0.5467
2024-06-03 10:18:07 [INFO]: Epoch 014 - training loss: 0.5678, validation loss: 0.5599
2024-06-03 10:18:09 [INFO]: Epoch 015 - training loss: 0.5652, validation loss: 0.5573
2024-06-03 10:18:12 [INFO]: Epoch 016 - training loss: 0.5425, validation loss: 0.5578
2024-06-03 10:18:14 [INFO]: Epoch 017 - training loss: 0.5415, validation loss: 0.4862
2024-06-03 10:18:17 [INFO]: Epoch 018 - training loss: 0.5222, validation loss: 0.4987
2024-06-03 10:18:19 [INFO]: Epoch 019 - training loss: 0.5136, validation loss: 0.5021
2024-06-03 10:18:22 [INFO]: Epoch 020 - training loss: 0.5176, validation loss: 0.4874
2024-06-03 10:18:24 [INFO]: Epoch 021 - training loss: 0.5173, validation loss: 0.5037
2024-06-03 10:18:26 [INFO]: Epoch 022 - training loss: 0.5091, validation loss: 0.5400
2024-06-03 10:18:28 [INFO]: Epoch 023 - training loss: 0.4989, validation loss: 0.5405
2024-06-03 10:18:31 [INFO]: Epoch 024 - training loss: 0.5015, validation loss: 0.4896
2024-06-03 10:18:33 [INFO]: Epoch 025 - training loss: 0.4937, validation loss: 0.4784
2024-06-03 10:18:36 [INFO]: Epoch 026 - training loss: 0.5068, validation loss: 0.5157
2024-06-03 10:18:38 [INFO]: Epoch 027 - training loss: 0.4934, validation loss: 0.5075
2024-06-03 10:18:41 [INFO]: Epoch 028 - training loss: 0.4865, validation loss: 0.5176
2024-06-03 10:18:43 [INFO]: Epoch 029 - training loss: 0.4948, validation loss: 0.5371
2024-06-03 10:18:45 [INFO]: Epoch 030 - training loss: 0.4984, validation loss: 0.5293
2024-06-03 10:18:47 [INFO]: Epoch 031 - training loss: 0.4854, validation loss: 0.4783
2024-06-03 10:18:49 [INFO]: Epoch 032 - training loss: 0.4743, validation loss: 0.4898
2024-06-03 10:18:52 [INFO]: Epoch 033 - training loss: 0.4793, validation loss: 0.5031
2024-06-03 10:18:54 [INFO]: Epoch 034 - training loss: 0.4782, validation loss: 0.4554
2024-06-03 10:18:56 [INFO]: Epoch 035 - training loss: 0.4686, validation loss: 0.4679
2024-06-03 10:18:59 [INFO]: Epoch 036 - training loss: 0.4737, validation loss: 0.5048
2024-06-03 10:19:01 [INFO]: Epoch 037 - training loss: 0.4821, validation loss: 0.4961
2024-06-03 10:19:03 [INFO]: Epoch 038 - training loss: 0.4719, validation loss: 0.4608
2024-06-03 10:19:05 [INFO]: Epoch 039 - training loss: 0.4626, validation loss: 0.4728
2024-06-03 10:19:07 [INFO]: Epoch 040 - training loss: 0.4681, validation loss: 0.5085
2024-06-03 10:19:09 [INFO]: Epoch 041 - training loss: 0.4612, validation loss: 0.4459
2024-06-03 10:19:11 [INFO]: Epoch 042 - training loss: 0.4729, validation loss: 0.4618
2024-06-03 10:19:14 [INFO]: Epoch 043 - training loss: 0.4583, validation loss: 0.4895
2024-06-03 10:19:15 [INFO]: Epoch 044 - training loss: 0.4529, validation loss: 0.4769
2024-06-03 10:19:17 [INFO]: Epoch 045 - training loss: 0.4576, validation loss: 0.4406
2024-06-03 10:19:20 [INFO]: Epoch 046 - training loss: 0.4473, validation loss: 0.4365
2024-06-03 10:19:22 [INFO]: Epoch 047 - training loss: 0.4415, validation loss: 0.4283
2024-06-03 10:19:24 [INFO]: Epoch 048 - training loss: 0.4373, validation loss: 0.4634
2024-06-03 10:19:26 [INFO]: Epoch 049 - training loss: 0.4427, validation loss: 0.4636
2024-06-03 10:19:29 [INFO]: Epoch 050 - training loss: 0.4357, validation loss: 0.4615
2024-06-03 10:19:32 [INFO]: Epoch 051 - training loss: 0.4530, validation loss: 0.4566
2024-06-03 10:19:35 [INFO]: Epoch 052 - training loss: 0.4433, validation loss: 0.4988
2024-06-03 10:19:37 [INFO]: Epoch 053 - training loss: 0.4602, validation loss: 0.4670
2024-06-03 10:19:40 [INFO]: Epoch 054 - training loss: 0.4502, validation loss: 0.4509
2024-06-03 10:19:42 [INFO]: Epoch 055 - training loss: 0.4369, validation loss: 0.4560
2024-06-03 10:19:44 [INFO]: Epoch 056 - training loss: 0.4275, validation loss: 0.4676
2024-06-03 10:19:47 [INFO]: Epoch 057 - training loss: 0.4401, validation loss: 0.4480
2024-06-03 10:19:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:19:47 [INFO]: Finished training. The best model is from epoch#47.
2024-06-03 10:19:47 [INFO]: Saved the model to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_0/20240603_T101725/FreTS.pypots
2024-06-03 10:19:48 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_0/imputation.pkl
2024-06-03 10:19:48 [INFO]: Round0 - FreTS on ETT_h1: MAE=0.5300, MSE=0.5746, MRE=0.6582
2024-06-03 10:19:48 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:19:48 [INFO]: Using the given device: cuda:0
2024-06-03 10:19:48 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_1/20240603_T101948
2024-06-03 10:19:48 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_1/20240603_T101948/tensorboard
2024-06-03 10:19:48 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-03 10:19:51 [INFO]: Epoch 001 - training loss: 2.4016, validation loss: 1.2715
2024-06-03 10:19:54 [INFO]: Epoch 002 - training loss: 1.6416, validation loss: 0.8967
2024-06-03 10:19:56 [INFO]: Epoch 003 - training loss: 1.1634, validation loss: 0.6509
2024-06-03 10:19:59 [INFO]: Epoch 004 - training loss: 0.9375, validation loss: 0.6116
2024-06-03 10:20:01 [INFO]: Epoch 005 - training loss: 0.7960, validation loss: 0.5439
2024-06-03 10:20:03 [INFO]: Epoch 006 - training loss: 0.7157, validation loss: 0.5145
2024-06-03 10:20:06 [INFO]: Epoch 007 - training loss: 0.6534, validation loss: 0.4965
2024-06-03 10:20:08 [INFO]: Epoch 008 - training loss: 0.6195, validation loss: 0.4420
2024-06-03 10:20:11 [INFO]: Epoch 009 - training loss: 0.5846, validation loss: 0.4596
2024-06-03 10:20:14 [INFO]: Epoch 010 - training loss: 0.5855, validation loss: 0.4547
2024-06-03 10:20:17 [INFO]: Epoch 011 - training loss: 0.5562, validation loss: 0.4682
2024-06-03 10:20:19 [INFO]: Epoch 012 - training loss: 0.5573, validation loss: 0.4808
2024-06-03 10:20:22 [INFO]: Epoch 013 - training loss: 0.5460, validation loss: 0.4870
2024-06-03 10:20:24 [INFO]: Epoch 014 - training loss: 0.5448, validation loss: 0.4459
2024-06-03 10:20:27 [INFO]: Epoch 015 - training loss: 0.5347, validation loss: 0.4590
2024-06-03 10:20:29 [INFO]: Epoch 016 - training loss: 0.5204, validation loss: 0.4194
2024-06-03 10:20:31 [INFO]: Epoch 017 - training loss: 0.5112, validation loss: 0.4676
2024-06-03 10:20:33 [INFO]: Epoch 018 - training loss: 0.5100, validation loss: 0.4558
2024-06-03 10:20:36 [INFO]: Epoch 019 - training loss: 0.4929, validation loss: 0.4727
2024-06-03 10:20:38 [INFO]: Epoch 020 - training loss: 0.5034, validation loss: 0.4380
2024-06-03 10:20:40 [INFO]: Epoch 021 - training loss: 0.4795, validation loss: 0.4437
2024-06-03 10:20:43 [INFO]: Epoch 022 - training loss: 0.4781, validation loss: 0.4352
2024-06-03 10:20:45 [INFO]: Epoch 023 - training loss: 0.4914, validation loss: 0.4483
2024-06-03 10:20:47 [INFO]: Epoch 024 - training loss: 0.4959, validation loss: 0.4409
2024-06-03 10:20:49 [INFO]: Epoch 025 - training loss: 0.4730, validation loss: 0.4120
2024-06-03 10:20:51 [INFO]: Epoch 026 - training loss: 0.4700, validation loss: 0.4498
2024-06-03 10:20:54 [INFO]: Epoch 027 - training loss: 0.4852, validation loss: 0.4272
2024-06-03 10:20:56 [INFO]: Epoch 028 - training loss: 0.4666, validation loss: 0.4091
2024-06-03 10:20:58 [INFO]: Epoch 029 - training loss: 0.4848, validation loss: 0.4316
2024-06-03 10:21:01 [INFO]: Epoch 030 - training loss: 0.4750, validation loss: 0.3938
2024-06-03 10:21:03 [INFO]: Epoch 031 - training loss: 0.4689, validation loss: 0.4047
2024-06-03 10:21:05 [INFO]: Epoch 032 - training loss: 0.4647, validation loss: 0.4041
2024-06-03 10:21:07 [INFO]: Epoch 033 - training loss: 0.4618, validation loss: 0.3888
2024-06-03 10:21:09 [INFO]: Epoch 034 - training loss: 0.4499, validation loss: 0.4005
2024-06-03 10:21:12 [INFO]: Epoch 035 - training loss: 0.4444, validation loss: 0.4064
2024-06-03 10:21:14 [INFO]: Epoch 036 - training loss: 0.4393, validation loss: 0.4067
2024-06-03 10:21:16 [INFO]: Epoch 037 - training loss: 0.4478, validation loss: 0.4117
2024-06-03 10:21:18 [INFO]: Epoch 038 - training loss: 0.4452, validation loss: 0.3939
2024-06-03 10:21:21 [INFO]: Epoch 039 - training loss: 0.4615, validation loss: 0.4125
2024-06-03 10:21:23 [INFO]: Epoch 040 - training loss: 0.4597, validation loss: 0.4118
2024-06-03 10:21:25 [INFO]: Epoch 041 - training loss: 0.4503, validation loss: 0.3989
2024-06-03 10:21:27 [INFO]: Epoch 042 - training loss: 0.4425, validation loss: 0.3738
2024-06-03 10:21:29 [INFO]: Epoch 043 - training loss: 0.4315, validation loss: 0.4043
2024-06-03 10:21:31 [INFO]: Epoch 044 - training loss: 0.4240, validation loss: 0.3870
2024-06-03 10:21:33 [INFO]: Epoch 045 - training loss: 0.4234, validation loss: 0.4012
2024-06-03 10:21:34 [INFO]: Epoch 046 - training loss: 0.4199, validation loss: 0.3562
2024-06-03 10:21:36 [INFO]: Epoch 047 - training loss: 0.4074, validation loss: 0.3658
2024-06-03 10:21:38 [INFO]: Epoch 048 - training loss: 0.4125, validation loss: 0.3678
2024-06-03 10:21:40 [INFO]: Epoch 049 - training loss: 0.4191, validation loss: 0.3777
2024-06-03 10:21:41 [INFO]: Epoch 050 - training loss: 0.4060, validation loss: 0.3735
2024-06-03 10:21:44 [INFO]: Epoch 051 - training loss: 0.4113, validation loss: 0.4001
2024-06-03 10:21:46 [INFO]: Epoch 052 - training loss: 0.4110, validation loss: 0.3829
2024-06-03 10:21:47 [INFO]: Epoch 053 - training loss: 0.3969, validation loss: 0.3828
2024-06-03 10:21:49 [INFO]: Epoch 054 - training loss: 0.3977, validation loss: 0.3850
2024-06-03 10:21:51 [INFO]: Epoch 055 - training loss: 0.4085, validation loss: 0.4092
2024-06-03 10:21:53 [INFO]: Epoch 056 - training loss: 0.4121, validation loss: 0.3745
2024-06-03 10:21:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:53 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 10:21:53 [INFO]: Saved the model to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_1/20240603_T101948/FreTS.pypots
2024-06-03 10:21:54 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_1/imputation.pkl
2024-06-03 10:21:54 [INFO]: Round1 - FreTS on ETT_h1: MAE=0.4919, MSE=0.4868, MRE=0.6108
2024-06-03 10:21:54 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:21:54 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:54 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_2/20240603_T102154
2024-06-03 10:21:54 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_2/20240603_T102154/tensorboard
2024-06-03 10:21:54 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-03 10:21:56 [INFO]: Epoch 001 - training loss: 2.1172, validation loss: 1.3915
2024-06-03 10:21:57 [INFO]: Epoch 002 - training loss: 1.5496, validation loss: 1.0100
2024-06-03 10:22:00 [INFO]: Epoch 003 - training loss: 1.2074, validation loss: 0.7942
2024-06-03 10:22:02 [INFO]: Epoch 004 - training loss: 0.9610, validation loss: 0.6507
2024-06-03 10:22:04 [INFO]: Epoch 005 - training loss: 0.8032, validation loss: 0.5075
2024-06-03 10:22:06 [INFO]: Epoch 006 - training loss: 0.6950, validation loss: 0.4698
2024-06-03 10:22:07 [INFO]: Epoch 007 - training loss: 0.6292, validation loss: 0.5008
2024-06-03 10:22:09 [INFO]: Epoch 008 - training loss: 0.5925, validation loss: 0.4754
2024-06-03 10:22:11 [INFO]: Epoch 009 - training loss: 0.5682, validation loss: 0.4655
2024-06-03 10:22:13 [INFO]: Epoch 010 - training loss: 0.5483, validation loss: 0.4532
2024-06-03 10:22:15 [INFO]: Epoch 011 - training loss: 0.5414, validation loss: 0.4647
2024-06-03 10:22:17 [INFO]: Epoch 012 - training loss: 0.5244, validation loss: 0.5152
2024-06-03 10:22:19 [INFO]: Epoch 013 - training loss: 0.5231, validation loss: 0.4785
2024-06-03 10:22:21 [INFO]: Epoch 014 - training loss: 0.5133, validation loss: 0.4772
2024-06-03 10:22:24 [INFO]: Epoch 015 - training loss: 0.4991, validation loss: 0.4488
2024-06-03 10:22:26 [INFO]: Epoch 016 - training loss: 0.4970, validation loss: 0.4526
2024-06-03 10:22:28 [INFO]: Epoch 017 - training loss: 0.4792, validation loss: 0.4737
2024-06-03 10:22:30 [INFO]: Epoch 018 - training loss: 0.4779, validation loss: 0.4565
2024-06-03 10:22:31 [INFO]: Epoch 019 - training loss: 0.4753, validation loss: 0.4964
2024-06-03 10:22:34 [INFO]: Epoch 020 - training loss: 0.4895, validation loss: 0.4603
2024-06-03 10:22:36 [INFO]: Epoch 021 - training loss: 0.4960, validation loss: 0.4360
2024-06-03 10:22:38 [INFO]: Epoch 022 - training loss: 0.4760, validation loss: 0.4633
2024-06-03 10:22:40 [INFO]: Epoch 023 - training loss: 0.4587, validation loss: 0.4293
2024-06-03 10:22:42 [INFO]: Epoch 024 - training loss: 0.4533, validation loss: 0.4212
2024-06-03 10:22:44 [INFO]: Epoch 025 - training loss: 0.4468, validation loss: 0.4167
2024-06-03 10:22:45 [INFO]: Epoch 026 - training loss: 0.4575, validation loss: 0.4157
2024-06-03 10:22:47 [INFO]: Epoch 027 - training loss: 0.4515, validation loss: 0.4035
2024-06-03 10:22:49 [INFO]: Epoch 028 - training loss: 0.4460, validation loss: 0.4354
2024-06-03 10:22:51 [INFO]: Epoch 029 - training loss: 0.4469, validation loss: 0.4069
2024-06-03 10:22:53 [INFO]: Epoch 030 - training loss: 0.4547, validation loss: 0.4373
2024-06-03 10:22:55 [INFO]: Epoch 031 - training loss: 0.4494, validation loss: 0.4126
2024-06-03 10:22:57 [INFO]: Epoch 032 - training loss: 0.4366, validation loss: 0.4105
2024-06-03 10:22:59 [INFO]: Epoch 033 - training loss: 0.4521, validation loss: 0.4094
2024-06-03 10:23:01 [INFO]: Epoch 034 - training loss: 0.4364, validation loss: 0.4103
2024-06-03 10:23:03 [INFO]: Epoch 035 - training loss: 0.4338, validation loss: 0.3996
2024-06-03 10:23:05 [INFO]: Epoch 036 - training loss: 0.4339, validation loss: 0.4085
2024-06-03 10:23:07 [INFO]: Epoch 037 - training loss: 0.4273, validation loss: 0.4210
2024-06-03 10:23:09 [INFO]: Epoch 038 - training loss: 0.4210, validation loss: 0.3891
2024-06-03 10:23:11 [INFO]: Epoch 039 - training loss: 0.4256, validation loss: 0.4186
2024-06-03 10:23:13 [INFO]: Epoch 040 - training loss: 0.4262, validation loss: 0.3764
2024-06-03 10:23:15 [INFO]: Epoch 041 - training loss: 0.4118, validation loss: 0.3953
2024-06-03 10:23:17 [INFO]: Epoch 042 - training loss: 0.4037, validation loss: 0.3877
2024-06-03 10:23:19 [INFO]: Epoch 043 - training loss: 0.4030, validation loss: 0.3520
2024-06-03 10:23:22 [INFO]: Epoch 044 - training loss: 0.3976, validation loss: 0.3748
2024-06-03 10:23:24 [INFO]: Epoch 045 - training loss: 0.3883, validation loss: 0.3879
2024-06-03 10:23:26 [INFO]: Epoch 046 - training loss: 0.3936, validation loss: 0.4122
2024-06-03 10:23:28 [INFO]: Epoch 047 - training loss: 0.3947, validation loss: 0.3974
2024-06-03 10:23:29 [INFO]: Epoch 048 - training loss: 0.3911, validation loss: 0.3720
2024-06-03 10:23:31 [INFO]: Epoch 049 - training loss: 0.3836, validation loss: 0.3815
2024-06-03 10:23:33 [INFO]: Epoch 050 - training loss: 0.3919, validation loss: 0.3679
2024-06-03 10:23:35 [INFO]: Epoch 051 - training loss: 0.4000, validation loss: 0.4067
2024-06-03 10:23:36 [INFO]: Epoch 052 - training loss: 0.4053, validation loss: 0.4034
2024-06-03 10:23:38 [INFO]: Epoch 053 - training loss: 0.3953, validation loss: 0.3756
2024-06-03 10:23:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:23:38 [INFO]: Finished training. The best model is from epoch#43.
2024-06-03 10:23:38 [INFO]: Saved the model to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_2/20240603_T102154/FreTS.pypots
2024-06-03 10:23:39 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_2/imputation.pkl
2024-06-03 10:23:39 [INFO]: Round2 - FreTS on ETT_h1: MAE=0.4817, MSE=0.4843, MRE=0.5981
2024-06-03 10:23:39 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:23:39 [INFO]: Using the given device: cuda:0
2024-06-03 10:23:39 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_3/20240603_T102339
2024-06-03 10:23:39 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_3/20240603_T102339/tensorboard
2024-06-03 10:23:39 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-03 10:23:40 [INFO]: Epoch 001 - training loss: 2.2494, validation loss: 1.5408
2024-06-03 10:23:43 [INFO]: Epoch 002 - training loss: 1.6649, validation loss: 0.8436
2024-06-03 10:23:45 [INFO]: Epoch 003 - training loss: 1.1408, validation loss: 0.8136
2024-06-03 10:23:47 [INFO]: Epoch 004 - training loss: 0.9264, validation loss: 0.6225
2024-06-03 10:23:49 [INFO]: Epoch 005 - training loss: 0.7694, validation loss: 0.5329
2024-06-03 10:23:51 [INFO]: Epoch 006 - training loss: 0.6825, validation loss: 0.4969
2024-06-03 10:23:53 [INFO]: Epoch 007 - training loss: 0.6420, validation loss: 0.4748
2024-06-03 10:23:55 [INFO]: Epoch 008 - training loss: 0.6096, validation loss: 0.4885
2024-06-03 10:23:57 [INFO]: Epoch 009 - training loss: 0.5724, validation loss: 0.4500
2024-06-03 10:23:58 [INFO]: Epoch 010 - training loss: 0.5620, validation loss: 0.4562
2024-06-03 10:24:00 [INFO]: Epoch 011 - training loss: 0.5542, validation loss: 0.4822
2024-06-03 10:24:02 [INFO]: Epoch 012 - training loss: 0.5383, validation loss: 0.4719
2024-06-03 10:24:04 [INFO]: Epoch 013 - training loss: 0.5221, validation loss: 0.4589
2024-06-03 10:24:06 [INFO]: Epoch 014 - training loss: 0.5064, validation loss: 0.4320
2024-06-03 10:24:07 [INFO]: Epoch 015 - training loss: 0.5016, validation loss: 0.4291
2024-06-03 10:24:09 [INFO]: Epoch 016 - training loss: 0.5209, validation loss: 0.4275
2024-06-03 10:24:11 [INFO]: Epoch 017 - training loss: 0.5005, validation loss: 0.4194
2024-06-03 10:24:13 [INFO]: Epoch 018 - training loss: 0.4862, validation loss: 0.4436
2024-06-03 10:24:14 [INFO]: Epoch 019 - training loss: 0.4766, validation loss: 0.4152
2024-06-03 10:24:16 [INFO]: Epoch 020 - training loss: 0.4771, validation loss: 0.4339
2024-06-03 10:24:17 [INFO]: Epoch 021 - training loss: 0.4765, validation loss: 0.4375
2024-06-03 10:24:19 [INFO]: Epoch 022 - training loss: 0.4654, validation loss: 0.4383
2024-06-03 10:24:21 [INFO]: Epoch 023 - training loss: 0.4688, validation loss: 0.4019
2024-06-03 10:24:23 [INFO]: Epoch 024 - training loss: 0.4608, validation loss: 0.4137
2024-06-03 10:24:24 [INFO]: Epoch 025 - training loss: 0.4520, validation loss: 0.3896
2024-06-03 10:24:26 [INFO]: Epoch 026 - training loss: 0.4476, validation loss: 0.3693
2024-06-03 10:24:28 [INFO]: Epoch 027 - training loss: 0.4555, validation loss: 0.4131
2024-06-03 10:24:30 [INFO]: Epoch 028 - training loss: 0.4527, validation loss: 0.4018
2024-06-03 10:24:32 [INFO]: Epoch 029 - training loss: 0.4350, validation loss: 0.3870
2024-06-03 10:24:34 [INFO]: Epoch 030 - training loss: 0.4261, validation loss: 0.4026
2024-06-03 10:24:36 [INFO]: Epoch 031 - training loss: 0.4235, validation loss: 0.3697
2024-06-03 10:24:37 [INFO]: Epoch 032 - training loss: 0.4312, validation loss: 0.4056
2024-06-03 10:24:39 [INFO]: Epoch 033 - training loss: 0.4294, validation loss: 0.3770
2024-06-03 10:24:41 [INFO]: Epoch 034 - training loss: 0.4465, validation loss: 0.4032
2024-06-03 10:24:42 [INFO]: Epoch 035 - training loss: 0.4323, validation loss: 0.3795
2024-06-03 10:24:44 [INFO]: Epoch 036 - training loss: 0.4268, validation loss: 0.3936
2024-06-03 10:24:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:44 [INFO]: Finished training. The best model is from epoch#26.
2024-06-03 10:24:44 [INFO]: Saved the model to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_3/20240603_T102339/FreTS.pypots
2024-06-03 10:24:45 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_3/imputation.pkl
2024-06-03 10:24:45 [INFO]: Round3 - FreTS on ETT_h1: MAE=0.5045, MSE=0.5285, MRE=0.6265
2024-06-03 10:24:45 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:24:45 [INFO]: Using the given device: cuda:0
2024-06-03 10:24:45 [INFO]: Model files will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_4/20240603_T102445
2024-06-03 10:24:45 [INFO]: Tensorboard file will be saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_4/20240603_T102445/tensorboard
2024-06-03 10:24:45 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 465,271
2024-06-03 10:24:46 [INFO]: Epoch 001 - training loss: 2.1079, validation loss: 1.3686
2024-06-03 10:24:48 [INFO]: Epoch 002 - training loss: 1.6002, validation loss: 1.0432
2024-06-03 10:24:49 [INFO]: Epoch 003 - training loss: 1.1641, validation loss: 0.7280
2024-06-03 10:24:50 [INFO]: Epoch 004 - training loss: 0.8898, validation loss: 0.6575
2024-06-03 10:24:52 [INFO]: Epoch 005 - training loss: 0.7620, validation loss: 0.5838
2024-06-03 10:24:53 [INFO]: Epoch 006 - training loss: 0.7289, validation loss: 0.5824
2024-06-03 10:24:55 [INFO]: Epoch 007 - training loss: 0.6703, validation loss: 0.5586
2024-06-03 10:24:57 [INFO]: Epoch 008 - training loss: 0.6510, validation loss: 0.5497
2024-06-03 10:24:59 [INFO]: Epoch 009 - training loss: 0.6080, validation loss: 0.5005
2024-06-03 10:25:00 [INFO]: Epoch 010 - training loss: 0.6013, validation loss: 0.5140
2024-06-03 10:25:02 [INFO]: Epoch 011 - training loss: 0.5836, validation loss: 0.5276
2024-06-03 10:25:04 [INFO]: Epoch 012 - training loss: 0.5583, validation loss: 0.4881
2024-06-03 10:25:05 [INFO]: Epoch 013 - training loss: 0.5628, validation loss: 0.4563
2024-06-03 10:25:07 [INFO]: Epoch 014 - training loss: 0.5476, validation loss: 0.4662
2024-06-03 10:25:09 [INFO]: Epoch 015 - training loss: 0.5359, validation loss: 0.4837
2024-06-03 10:25:11 [INFO]: Epoch 016 - training loss: 0.5257, validation loss: 0.4488
2024-06-03 10:25:13 [INFO]: Epoch 017 - training loss: 0.5113, validation loss: 0.4805
2024-06-03 10:25:15 [INFO]: Epoch 018 - training loss: 0.5152, validation loss: 0.4750
2024-06-03 10:25:17 [INFO]: Epoch 019 - training loss: 0.5007, validation loss: 0.4689
2024-06-03 10:25:18 [INFO]: Epoch 020 - training loss: 0.4967, validation loss: 0.4405
2024-06-03 10:25:20 [INFO]: Epoch 021 - training loss: 0.4984, validation loss: 0.4988
2024-06-03 10:25:22 [INFO]: Epoch 022 - training loss: 0.4978, validation loss: 0.4375
2024-06-03 10:25:24 [INFO]: Epoch 023 - training loss: 0.4823, validation loss: 0.4499
2024-06-03 10:25:25 [INFO]: Epoch 024 - training loss: 0.4721, validation loss: 0.4261
2024-06-03 10:25:27 [INFO]: Epoch 025 - training loss: 0.4761, validation loss: 0.4131
2024-06-03 10:25:29 [INFO]: Epoch 026 - training loss: 0.4801, validation loss: 0.4170
2024-06-03 10:25:30 [INFO]: Epoch 027 - training loss: 0.4707, validation loss: 0.4129
2024-06-03 10:25:32 [INFO]: Epoch 028 - training loss: 0.4825, validation loss: 0.4659
2024-06-03 10:25:34 [INFO]: Epoch 029 - training loss: 0.4789, validation loss: 0.4948
2024-06-03 10:25:36 [INFO]: Epoch 030 - training loss: 0.4641, validation loss: 0.4558
2024-06-03 10:25:38 [INFO]: Epoch 031 - training loss: 0.4633, validation loss: 0.4448
2024-06-03 10:25:39 [INFO]: Epoch 032 - training loss: 0.4690, validation loss: 0.4532
2024-06-03 10:25:41 [INFO]: Epoch 033 - training loss: 0.4632, validation loss: 0.4209
2024-06-03 10:25:42 [INFO]: Epoch 034 - training loss: 0.4802, validation loss: 0.4394
2024-06-03 10:25:44 [INFO]: Epoch 035 - training loss: 0.4670, validation loss: 0.4528
2024-06-03 10:25:46 [INFO]: Epoch 036 - training loss: 0.4523, validation loss: 0.4061
2024-06-03 10:25:47 [INFO]: Epoch 037 - training loss: 0.4498, validation loss: 0.4067
2024-06-03 10:25:49 [INFO]: Epoch 038 - training loss: 0.4547, validation loss: 0.4089
2024-06-03 10:25:51 [INFO]: Epoch 039 - training loss: 0.4401, validation loss: 0.4015
2024-06-03 10:25:53 [INFO]: Epoch 040 - training loss: 0.4393, validation loss: 0.4108
2024-06-03 10:25:55 [INFO]: Epoch 041 - training loss: 0.4350, validation loss: 0.3767
2024-06-03 10:25:56 [INFO]: Epoch 042 - training loss: 0.4540, validation loss: 0.3982
2024-06-03 10:25:58 [INFO]: Epoch 043 - training loss: 0.4632, validation loss: 0.4245
2024-06-03 10:25:59 [INFO]: Epoch 044 - training loss: 0.4549, validation loss: 0.4423
2024-06-03 10:26:01 [INFO]: Epoch 045 - training loss: 0.4645, validation loss: 0.3766
2024-06-03 10:26:03 [INFO]: Epoch 046 - training loss: 0.4460, validation loss: 0.4012
2024-06-03 10:26:05 [INFO]: Epoch 047 - training loss: 0.4442, validation loss: 0.3712
2024-06-03 10:26:07 [INFO]: Epoch 048 - training loss: 0.4306, validation loss: 0.3981
2024-06-03 10:26:08 [INFO]: Epoch 049 - training loss: 0.4291, validation loss: 0.3736
2024-06-03 10:26:10 [INFO]: Epoch 050 - training loss: 0.4254, validation loss: 0.3963
2024-06-03 10:26:12 [INFO]: Epoch 051 - training loss: 0.4181, validation loss: 0.3961
2024-06-03 10:26:14 [INFO]: Epoch 052 - training loss: 0.4314, validation loss: 0.3794
2024-06-03 10:26:15 [INFO]: Epoch 053 - training loss: 0.4414, validation loss: 0.4051
2024-06-03 10:26:17 [INFO]: Epoch 054 - training loss: 0.4374, validation loss: 0.4199
2024-06-03 10:26:19 [INFO]: Epoch 055 - training loss: 0.4429, validation loss: 0.3691
2024-06-03 10:26:21 [INFO]: Epoch 056 - training loss: 0.4286, validation loss: 0.3616
2024-06-03 10:26:23 [INFO]: Epoch 057 - training loss: 0.4195, validation loss: 0.3867
2024-06-03 10:26:24 [INFO]: Epoch 058 - training loss: 0.4171, validation loss: 0.3920
2024-06-03 10:26:26 [INFO]: Epoch 059 - training loss: 0.4165, validation loss: 0.3892
2024-06-03 10:26:28 [INFO]: Epoch 060 - training loss: 0.4189, validation loss: 0.3754
2024-06-03 10:26:29 [INFO]: Epoch 061 - training loss: 0.4246, validation loss: 0.3672
2024-06-03 10:26:31 [INFO]: Epoch 062 - training loss: 0.4177, validation loss: 0.3798
2024-06-03 10:26:32 [INFO]: Epoch 063 - training loss: 0.4164, validation loss: 0.3706
2024-06-03 10:26:34 [INFO]: Epoch 064 - training loss: 0.4043, validation loss: 0.3424
2024-06-03 10:26:36 [INFO]: Epoch 065 - training loss: 0.3921, validation loss: 0.3996
2024-06-03 10:26:37 [INFO]: Epoch 066 - training loss: 0.4028, validation loss: 0.4070
2024-06-03 10:26:39 [INFO]: Epoch 067 - training loss: 0.4089, validation loss: 0.3778
2024-06-03 10:26:41 [INFO]: Epoch 068 - training loss: 0.4064, validation loss: 0.3680
2024-06-03 10:26:43 [INFO]: Epoch 069 - training loss: 0.4015, validation loss: 0.3443
2024-06-03 10:26:45 [INFO]: Epoch 070 - training loss: 0.4005, validation loss: 0.3591
2024-06-03 10:26:46 [INFO]: Epoch 071 - training loss: 0.3982, validation loss: 0.3571
2024-06-03 10:26:48 [INFO]: Epoch 072 - training loss: 0.3980, validation loss: 0.3531
2024-06-03 10:26:50 [INFO]: Epoch 073 - training loss: 0.3973, validation loss: 0.4061
2024-06-03 10:26:52 [INFO]: Epoch 074 - training loss: 0.4032, validation loss: 0.3511
2024-06-03 10:26:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:26:52 [INFO]: Finished training. The best model is from epoch#64.
2024-06-03 10:26:52 [INFO]: Saved the model to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_4/20240603_T102445/FreTS.pypots
2024-06-03 10:26:53 [INFO]: Successfully saved to results_block_rate05/ETT_h1/FreTS_ETT_h1/round_4/imputation.pkl
2024-06-03 10:26:53 [INFO]: Round4 - FreTS on ETT_h1: MAE=0.4717, MSE=0.4742, MRE=0.5857
2024-06-03 10:26:53 [INFO]: Done! Final results:
Averaged FreTS (465,271 params) on ETT_h1: MAE=0.4960 ± 0.020224561282849458, MSE=0.5097 ± 0.0373987253499801, MRE=0.6159 ± 0.025114294210690963, average inference time=0.23
