2024-06-03 12:16:17 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:16:17 [INFO]: Using the given device: cuda:0
2024-06-03 12:16:17 [INFO]: Model files will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_0/20240603_T121617
2024-06-03 12:16:17 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_0/20240603_T121617/tensorboard
2024-06-03 12:16:18 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 12:16:26 [INFO]: Epoch 001 - training loss: 1.4789, validation loss: 2.9729
2024-06-03 12:16:33 [INFO]: Epoch 002 - training loss: 1.3211, validation loss: 2.8898
2024-06-03 12:16:40 [INFO]: Epoch 003 - training loss: 1.2395, validation loss: 2.9043
2024-06-03 12:16:47 [INFO]: Epoch 004 - training loss: 1.1634, validation loss: 2.8600
2024-06-03 12:16:55 [INFO]: Epoch 005 - training loss: 1.1376, validation loss: 2.9311
2024-06-03 12:17:02 [INFO]: Epoch 006 - training loss: 1.1210, validation loss: 2.9725
2024-06-03 12:17:09 [INFO]: Epoch 007 - training loss: 1.1100, validation loss: 2.8517
2024-06-03 12:17:16 [INFO]: Epoch 008 - training loss: 1.1021, validation loss: 2.9373
2024-06-03 12:17:24 [INFO]: Epoch 009 - training loss: 1.0931, validation loss: 2.8324
2024-06-03 12:17:32 [INFO]: Epoch 010 - training loss: 1.0856, validation loss: 2.8178
2024-06-03 12:17:38 [INFO]: Epoch 011 - training loss: 1.0790, validation loss: 2.7899
2024-06-03 12:17:46 [INFO]: Epoch 012 - training loss: 1.0743, validation loss: 2.7467
2024-06-03 12:17:53 [INFO]: Epoch 013 - training loss: 1.0759, validation loss: 2.8367
2024-06-03 12:18:01 [INFO]: Epoch 014 - training loss: 1.0678, validation loss: 2.7307
2024-06-03 12:18:08 [INFO]: Epoch 015 - training loss: 1.0639, validation loss: 2.7051
2024-06-03 12:18:15 [INFO]: Epoch 016 - training loss: 1.0651, validation loss: 2.6223
2024-06-03 12:18:23 [INFO]: Epoch 017 - training loss: 1.0598, validation loss: 2.6888
2024-06-03 12:18:30 [INFO]: Epoch 018 - training loss: 1.0566, validation loss: 2.6547
2024-06-03 12:18:38 [INFO]: Epoch 019 - training loss: 1.0557, validation loss: 2.6973
2024-06-03 12:18:45 [INFO]: Epoch 020 - training loss: 1.0517, validation loss: 2.6674
2024-06-03 12:18:52 [INFO]: Epoch 021 - training loss: 1.0501, validation loss: 2.6600
2024-06-03 12:18:59 [INFO]: Epoch 022 - training loss: 1.0472, validation loss: 2.6850
2024-06-03 12:19:06 [INFO]: Epoch 023 - training loss: 1.0459, validation loss: 2.6339
2024-06-03 12:19:14 [INFO]: Epoch 024 - training loss: 1.0459, validation loss: 2.6342
2024-06-03 12:19:21 [INFO]: Epoch 025 - training loss: 1.0428, validation loss: 2.5540
2024-06-03 12:19:28 [INFO]: Epoch 026 - training loss: 1.0436, validation loss: 2.5116
2024-06-03 12:19:35 [INFO]: Epoch 027 - training loss: 1.0433, validation loss: 2.4885
2024-06-03 12:19:42 [INFO]: Epoch 028 - training loss: 1.0393, validation loss: 2.5486
2024-06-03 12:19:49 [INFO]: Epoch 029 - training loss: 1.0394, validation loss: 2.5297
2024-06-03 12:19:56 [INFO]: Epoch 030 - training loss: 1.0398, validation loss: 2.4973
2024-06-03 12:20:04 [INFO]: Epoch 031 - training loss: 1.0400, validation loss: 2.4970
2024-06-03 12:20:11 [INFO]: Epoch 032 - training loss: 1.0383, validation loss: 2.4360
2024-06-03 12:20:18 [INFO]: Epoch 033 - training loss: 1.0350, validation loss: 2.5017
2024-06-03 12:20:26 [INFO]: Epoch 034 - training loss: 1.0341, validation loss: 2.4924
2024-06-03 12:20:33 [INFO]: Epoch 035 - training loss: 1.0334, validation loss: 2.4215
2024-06-03 12:20:40 [INFO]: Epoch 036 - training loss: 1.0311, validation loss: 2.4069
2024-06-03 12:20:48 [INFO]: Epoch 037 - training loss: 1.0328, validation loss: 2.4330
2024-06-03 12:20:55 [INFO]: Epoch 038 - training loss: 1.0297, validation loss: 2.4298
2024-06-03 12:21:02 [INFO]: Epoch 039 - training loss: 1.0292, validation loss: 2.4547
2024-06-03 12:21:09 [INFO]: Epoch 040 - training loss: 1.0313, validation loss: 2.4118
2024-06-03 12:21:17 [INFO]: Epoch 041 - training loss: 1.0288, validation loss: 2.3586
2024-06-03 12:21:24 [INFO]: Epoch 042 - training loss: 1.0274, validation loss: 2.4072
2024-06-03 12:21:30 [INFO]: Epoch 043 - training loss: 1.0309, validation loss: 2.3427
2024-06-03 12:21:37 [INFO]: Epoch 044 - training loss: 1.0289, validation loss: 2.3662
2024-06-03 12:21:43 [INFO]: Epoch 045 - training loss: 1.0259, validation loss: 2.3649
2024-06-03 12:21:50 [INFO]: Epoch 046 - training loss: 1.0249, validation loss: 2.3126
2024-06-03 12:21:58 [INFO]: Epoch 047 - training loss: 1.0233, validation loss: 2.2895
2024-06-03 12:22:05 [INFO]: Epoch 048 - training loss: 1.0238, validation loss: 2.3186
2024-06-03 12:22:12 [INFO]: Epoch 049 - training loss: 1.0243, validation loss: 2.3020
2024-06-03 12:22:20 [INFO]: Epoch 050 - training loss: 1.0231, validation loss: 2.2932
2024-06-03 12:22:27 [INFO]: Epoch 051 - training loss: 1.0220, validation loss: 2.2541
2024-06-03 12:22:34 [INFO]: Epoch 052 - training loss: 1.0218, validation loss: 2.2890
2024-06-03 12:22:42 [INFO]: Epoch 053 - training loss: 1.0219, validation loss: 2.3137
2024-06-03 12:22:49 [INFO]: Epoch 054 - training loss: 1.0219, validation loss: 2.2491
2024-06-03 12:22:56 [INFO]: Epoch 055 - training loss: 1.0205, validation loss: 2.3416
2024-06-03 12:23:04 [INFO]: Epoch 056 - training loss: 1.0185, validation loss: 2.2553
2024-06-03 12:23:11 [INFO]: Epoch 057 - training loss: 1.0188, validation loss: 2.2536
2024-06-03 12:23:19 [INFO]: Epoch 058 - training loss: 1.0188, validation loss: 2.2775
2024-06-03 12:23:26 [INFO]: Epoch 059 - training loss: 1.0189, validation loss: 2.2506
2024-06-03 12:23:33 [INFO]: Epoch 060 - training loss: 1.0223, validation loss: 2.2219
2024-06-03 12:23:41 [INFO]: Epoch 061 - training loss: 1.0200, validation loss: 2.2305
2024-06-03 12:23:48 [INFO]: Epoch 062 - training loss: 1.0174, validation loss: 2.2816
2024-06-03 12:23:56 [INFO]: Epoch 063 - training loss: 1.0166, validation loss: 2.2339
2024-06-03 12:24:03 [INFO]: Epoch 064 - training loss: 1.0164, validation loss: 2.1796
2024-06-03 12:24:10 [INFO]: Epoch 065 - training loss: 1.0151, validation loss: 2.2737
2024-06-03 12:24:18 [INFO]: Epoch 066 - training loss: 1.0149, validation loss: 2.1918
2024-06-03 12:24:25 [INFO]: Epoch 067 - training loss: 1.0155, validation loss: 2.2145
2024-06-03 12:24:32 [INFO]: Epoch 068 - training loss: 1.0147, validation loss: 2.1992
2024-06-03 12:24:39 [INFO]: Epoch 069 - training loss: 1.0140, validation loss: 2.1931
2024-06-03 12:24:47 [INFO]: Epoch 070 - training loss: 1.0127, validation loss: 2.1828
2024-06-03 12:24:54 [INFO]: Epoch 071 - training loss: 1.0133, validation loss: 2.2080
2024-06-03 12:25:01 [INFO]: Epoch 072 - training loss: 1.0126, validation loss: 2.1244
2024-06-03 12:25:08 [INFO]: Epoch 073 - training loss: 1.0137, validation loss: 2.1357
2024-06-03 12:25:16 [INFO]: Epoch 074 - training loss: 1.0135, validation loss: 2.1281
2024-06-03 12:25:23 [INFO]: Epoch 075 - training loss: 1.0136, validation loss: 2.1678
2024-06-03 12:25:30 [INFO]: Epoch 076 - training loss: 1.0120, validation loss: 2.1610
2024-06-03 12:25:37 [INFO]: Epoch 077 - training loss: 1.0132, validation loss: 2.1877
2024-06-03 12:25:44 [INFO]: Epoch 078 - training loss: 1.0116, validation loss: 2.1572
2024-06-03 12:25:52 [INFO]: Epoch 079 - training loss: 1.0116, validation loss: 2.1974
2024-06-03 12:25:59 [INFO]: Epoch 080 - training loss: 1.0102, validation loss: 2.1406
2024-06-03 12:26:06 [INFO]: Epoch 081 - training loss: 1.0098, validation loss: 2.1977
2024-06-03 12:26:13 [INFO]: Epoch 082 - training loss: 1.0084, validation loss: 2.0907
2024-06-03 12:26:19 [INFO]: Epoch 083 - training loss: 1.0084, validation loss: 2.0934
2024-06-03 12:26:26 [INFO]: Epoch 084 - training loss: 1.0081, validation loss: 2.0948
2024-06-03 12:26:33 [INFO]: Epoch 085 - training loss: 1.0085, validation loss: 2.1556
2024-06-03 12:26:40 [INFO]: Epoch 086 - training loss: 1.0072, validation loss: 2.1202
2024-06-03 12:26:48 [INFO]: Epoch 087 - training loss: 1.0066, validation loss: 2.1243
2024-06-03 12:26:55 [INFO]: Epoch 088 - training loss: 1.0063, validation loss: 2.0663
2024-06-03 12:27:02 [INFO]: Epoch 089 - training loss: 1.0062, validation loss: 2.1136
2024-06-03 12:27:10 [INFO]: Epoch 090 - training loss: 1.0040, validation loss: 2.0709
2024-06-03 12:27:17 [INFO]: Epoch 091 - training loss: 1.0038, validation loss: 2.1146
2024-06-03 12:27:24 [INFO]: Epoch 092 - training loss: 1.0033, validation loss: 2.1150
2024-06-03 12:27:32 [INFO]: Epoch 093 - training loss: 1.0018, validation loss: 2.1565
2024-06-03 12:27:39 [INFO]: Epoch 094 - training loss: 1.0003, validation loss: 2.0929
2024-06-03 12:27:46 [INFO]: Epoch 095 - training loss: 1.0008, validation loss: 2.0556
2024-06-03 12:27:54 [INFO]: Epoch 096 - training loss: 0.9999, validation loss: 2.1328
2024-06-03 12:28:01 [INFO]: Epoch 097 - training loss: 0.9994, validation loss: 2.0626
2024-06-03 12:28:08 [INFO]: Epoch 098 - training loss: 0.9986, validation loss: 2.0586
2024-06-03 12:28:16 [INFO]: Epoch 099 - training loss: 0.9985, validation loss: 2.0384
2024-06-03 12:28:23 [INFO]: Epoch 100 - training loss: 0.9960, validation loss: 2.0073
2024-06-03 12:28:23 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 12:28:23 [INFO]: Saved the model to results_block_rate05/Electricity/FiLM_Electricity/round_0/20240603_T121617/FiLM.pypots
2024-06-03 12:28:27 [INFO]: Successfully saved to results_block_rate05/Electricity/FiLM_Electricity/round_0/imputation.pkl
2024-06-03 12:28:27 [INFO]: Round0 - FiLM on Electricity: MAE=1.3444, MSE=3.3902, MRE=0.7216
2024-06-03 12:28:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:28:27 [INFO]: Using the given device: cuda:0
2024-06-03 12:28:27 [INFO]: Model files will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_1/20240603_T122827
2024-06-03 12:28:27 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_1/20240603_T122827/tensorboard
2024-06-03 12:28:28 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 12:28:35 [INFO]: Epoch 001 - training loss: 1.4306, validation loss: 2.8585
2024-06-03 12:28:43 [INFO]: Epoch 002 - training loss: 1.2282, validation loss: 2.7428
2024-06-03 12:28:50 [INFO]: Epoch 003 - training loss: 1.1491, validation loss: 2.5263
2024-06-03 12:28:57 [INFO]: Epoch 004 - training loss: 1.1107, validation loss: 2.4430
2024-06-03 12:29:05 [INFO]: Epoch 005 - training loss: 1.0942, validation loss: 2.3654
2024-06-03 12:29:12 [INFO]: Epoch 006 - training loss: 1.0830, validation loss: 2.3375
2024-06-03 12:29:19 [INFO]: Epoch 007 - training loss: 1.0739, validation loss: 2.3216
2024-06-03 12:29:26 [INFO]: Epoch 008 - training loss: 1.0667, validation loss: 2.2915
2024-06-03 12:29:34 [INFO]: Epoch 009 - training loss: 1.0598, validation loss: 2.3047
2024-06-03 12:29:41 [INFO]: Epoch 010 - training loss: 1.0551, validation loss: 2.2473
2024-06-03 12:29:48 [INFO]: Epoch 011 - training loss: 1.0480, validation loss: 2.2136
2024-06-03 12:29:55 [INFO]: Epoch 012 - training loss: 1.0428, validation loss: 2.1995
2024-06-03 12:30:01 [INFO]: Epoch 013 - training loss: 1.0377, validation loss: 2.1850
2024-06-03 12:30:08 [INFO]: Epoch 014 - training loss: 1.0341, validation loss: 2.1449
2024-06-03 12:30:14 [INFO]: Epoch 015 - training loss: 1.0320, validation loss: 2.1869
2024-06-03 12:30:20 [INFO]: Epoch 016 - training loss: 1.0276, validation loss: 2.1468
2024-06-03 12:30:28 [INFO]: Epoch 017 - training loss: 1.0232, validation loss: 2.1174
2024-06-03 12:30:35 [INFO]: Epoch 018 - training loss: 1.0202, validation loss: 2.1555
2024-06-03 12:30:42 [INFO]: Epoch 019 - training loss: 1.0175, validation loss: 2.1547
2024-06-03 12:30:50 [INFO]: Epoch 020 - training loss: 1.0142, validation loss: 2.0711
2024-06-03 12:30:57 [INFO]: Epoch 021 - training loss: 1.0126, validation loss: 2.0548
2024-06-03 12:31:04 [INFO]: Epoch 022 - training loss: 1.0104, validation loss: 2.0109
2024-06-03 12:31:11 [INFO]: Epoch 023 - training loss: 1.0079, validation loss: 2.0438
2024-06-03 12:31:19 [INFO]: Epoch 024 - training loss: 1.0056, validation loss: 2.0035
2024-06-03 12:31:26 [INFO]: Epoch 025 - training loss: 1.0057, validation loss: 2.0151
2024-06-03 12:31:33 [INFO]: Epoch 026 - training loss: 1.0038, validation loss: 1.9751
2024-06-03 12:31:40 [INFO]: Epoch 027 - training loss: 1.0045, validation loss: 2.0177
2024-06-03 12:31:47 [INFO]: Epoch 028 - training loss: 1.0015, validation loss: 1.9651
2024-06-03 12:31:54 [INFO]: Epoch 029 - training loss: 1.0007, validation loss: 1.9502
2024-06-03 12:32:01 [INFO]: Epoch 030 - training loss: 0.9987, validation loss: 1.9863
2024-06-03 12:32:09 [INFO]: Epoch 031 - training loss: 0.9975, validation loss: 1.9647
2024-06-03 12:32:16 [INFO]: Epoch 032 - training loss: 0.9982, validation loss: 1.9334
2024-06-03 12:32:23 [INFO]: Epoch 033 - training loss: 0.9953, validation loss: 1.9424
2024-06-03 12:32:30 [INFO]: Epoch 034 - training loss: 0.9954, validation loss: 1.8922
2024-06-03 12:32:38 [INFO]: Epoch 035 - training loss: 0.9951, validation loss: 1.9128
2024-06-03 12:32:45 [INFO]: Epoch 036 - training loss: 0.9937, validation loss: 1.9128
2024-06-03 12:32:52 [INFO]: Epoch 037 - training loss: 0.9932, validation loss: 1.9100
2024-06-03 12:32:59 [INFO]: Epoch 038 - training loss: 0.9912, validation loss: 1.9396
2024-06-03 12:33:07 [INFO]: Epoch 039 - training loss: 0.9914, validation loss: 1.8786
2024-06-03 12:33:14 [INFO]: Epoch 040 - training loss: 0.9905, validation loss: 1.8852
2024-06-03 12:33:21 [INFO]: Epoch 041 - training loss: 0.9896, validation loss: 1.8590
2024-06-03 12:33:29 [INFO]: Epoch 042 - training loss: 0.9888, validation loss: 1.8783
2024-06-03 12:33:36 [INFO]: Epoch 043 - training loss: 0.9883, validation loss: 1.8280
2024-06-03 12:33:43 [INFO]: Epoch 044 - training loss: 0.9874, validation loss: 1.8459
2024-06-03 12:33:51 [INFO]: Epoch 045 - training loss: 0.9884, validation loss: 1.8283
2024-06-03 12:33:58 [INFO]: Epoch 046 - training loss: 0.9879, validation loss: 1.8320
2024-06-03 12:34:05 [INFO]: Epoch 047 - training loss: 0.9872, validation loss: 1.8001
2024-06-03 12:34:12 [INFO]: Epoch 048 - training loss: 0.9874, validation loss: 1.8004
2024-06-03 12:34:19 [INFO]: Epoch 049 - training loss: 0.9855, validation loss: 1.8280
2024-06-03 12:34:26 [INFO]: Epoch 050 - training loss: 0.9855, validation loss: 1.8027
2024-06-03 12:34:32 [INFO]: Epoch 051 - training loss: 0.9852, validation loss: 1.8314
2024-06-03 12:34:39 [INFO]: Epoch 052 - training loss: 0.9841, validation loss: 1.8104
2024-06-03 12:34:45 [INFO]: Epoch 053 - training loss: 0.9840, validation loss: 1.7797
2024-06-03 12:34:51 [INFO]: Epoch 054 - training loss: 0.9851, validation loss: 1.7723
2024-06-03 12:34:58 [INFO]: Epoch 055 - training loss: 0.9835, validation loss: 1.7701
2024-06-03 12:35:06 [INFO]: Epoch 056 - training loss: 0.9825, validation loss: 1.7554
2024-06-03 12:35:13 [INFO]: Epoch 057 - training loss: 0.9834, validation loss: 1.7651
2024-06-03 12:35:20 [INFO]: Epoch 058 - training loss: 0.9826, validation loss: 1.7635
2024-06-03 12:35:27 [INFO]: Epoch 059 - training loss: 0.9824, validation loss: 1.7106
2024-06-03 12:35:34 [INFO]: Epoch 060 - training loss: 0.9821, validation loss: 1.7149
2024-06-03 12:35:42 [INFO]: Epoch 061 - training loss: 0.9829, validation loss: 1.7367
2024-06-03 12:35:49 [INFO]: Epoch 062 - training loss: 0.9821, validation loss: 1.7210
2024-06-03 12:35:56 [INFO]: Epoch 063 - training loss: 0.9811, validation loss: 1.7466
2024-06-03 12:36:04 [INFO]: Epoch 064 - training loss: 0.9810, validation loss: 1.7426
2024-06-03 12:36:11 [INFO]: Epoch 065 - training loss: 0.9815, validation loss: 1.7536
2024-06-03 12:36:19 [INFO]: Epoch 066 - training loss: 0.9813, validation loss: 1.7097
2024-06-03 12:36:26 [INFO]: Epoch 067 - training loss: 0.9805, validation loss: 1.7205
2024-06-03 12:36:33 [INFO]: Epoch 068 - training loss: 0.9810, validation loss: 1.7309
2024-06-03 12:36:40 [INFO]: Epoch 069 - training loss: 0.9806, validation loss: 1.7150
2024-06-03 12:36:48 [INFO]: Epoch 070 - training loss: 0.9797, validation loss: 1.7282
2024-06-03 12:36:55 [INFO]: Epoch 071 - training loss: 0.9804, validation loss: 1.7181
2024-06-03 12:37:02 [INFO]: Epoch 072 - training loss: 0.9789, validation loss: 1.7054
2024-06-03 12:37:09 [INFO]: Epoch 073 - training loss: 0.9788, validation loss: 1.6991
2024-06-03 12:37:17 [INFO]: Epoch 074 - training loss: 0.9786, validation loss: 1.7274
2024-06-03 12:37:24 [INFO]: Epoch 075 - training loss: 0.9786, validation loss: 1.7313
2024-06-03 12:37:31 [INFO]: Epoch 076 - training loss: 0.9785, validation loss: 1.6842
2024-06-03 12:37:38 [INFO]: Epoch 077 - training loss: 0.9786, validation loss: 1.7010
2024-06-03 12:37:45 [INFO]: Epoch 078 - training loss: 0.9790, validation loss: 1.7343
2024-06-03 12:37:52 [INFO]: Epoch 079 - training loss: 0.9781, validation loss: 1.6762
2024-06-03 12:37:59 [INFO]: Epoch 080 - training loss: 0.9767, validation loss: 1.6802
2024-06-03 12:38:07 [INFO]: Epoch 081 - training loss: 0.9779, validation loss: 1.7053
2024-06-03 12:38:14 [INFO]: Epoch 082 - training loss: 0.9770, validation loss: 1.6701
2024-06-03 12:38:22 [INFO]: Epoch 083 - training loss: 0.9768, validation loss: 1.6605
2024-06-03 12:38:29 [INFO]: Epoch 084 - training loss: 0.9780, validation loss: 1.6845
2024-06-03 12:38:35 [INFO]: Epoch 085 - training loss: 0.9771, validation loss: 1.6747
2024-06-03 12:38:42 [INFO]: Epoch 086 - training loss: 0.9772, validation loss: 1.6515
2024-06-03 12:38:49 [INFO]: Epoch 087 - training loss: 0.9757, validation loss: 1.6509
2024-06-03 12:38:56 [INFO]: Epoch 088 - training loss: 0.9755, validation loss: 1.6577
2024-06-03 12:39:03 [INFO]: Epoch 089 - training loss: 0.9764, validation loss: 1.6719
2024-06-03 12:39:09 [INFO]: Epoch 090 - training loss: 0.9771, validation loss: 1.6740
2024-06-03 12:39:14 [INFO]: Epoch 091 - training loss: 0.9761, validation loss: 1.6501
2024-06-03 12:39:20 [INFO]: Epoch 092 - training loss: 0.9772, validation loss: 1.6693
2024-06-03 12:39:26 [INFO]: Epoch 093 - training loss: 0.9765, validation loss: 1.6604
2024-06-03 12:39:32 [INFO]: Epoch 094 - training loss: 0.9756, validation loss: 1.6542
2024-06-03 12:39:37 [INFO]: Epoch 095 - training loss: 0.9759, validation loss: 1.6661
2024-06-03 12:39:42 [INFO]: Epoch 096 - training loss: 0.9759, validation loss: 1.6460
2024-06-03 12:39:48 [INFO]: Epoch 097 - training loss: 0.9758, validation loss: 1.6514
2024-06-03 12:39:53 [INFO]: Epoch 098 - training loss: 0.9748, validation loss: 1.6566
2024-06-03 12:39:59 [INFO]: Epoch 099 - training loss: 0.9751, validation loss: 1.6431
2024-06-03 12:40:05 [INFO]: Epoch 100 - training loss: 0.9750, validation loss: 1.6386
2024-06-03 12:40:05 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 12:40:05 [INFO]: Saved the model to results_block_rate05/Electricity/FiLM_Electricity/round_1/20240603_T122827/FiLM.pypots
2024-06-03 12:40:08 [INFO]: Successfully saved to results_block_rate05/Electricity/FiLM_Electricity/round_1/imputation.pkl
2024-06-03 12:40:08 [INFO]: Round1 - FiLM on Electricity: MAE=0.9758, MSE=1.8034, MRE=0.5237
2024-06-03 12:40:08 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:40:08 [INFO]: Using the given device: cuda:0
2024-06-03 12:40:08 [INFO]: Model files will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_2/20240603_T124008
2024-06-03 12:40:08 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_2/20240603_T124008/tensorboard
2024-06-03 12:40:08 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 12:40:15 [INFO]: Epoch 001 - training loss: 1.5019, validation loss: 3.0200
2024-06-03 12:40:20 [INFO]: Epoch 002 - training loss: 1.2430, validation loss: 2.7762
2024-06-03 12:40:26 [INFO]: Epoch 003 - training loss: 1.1435, validation loss: 2.6777
2024-06-03 12:40:32 [INFO]: Epoch 004 - training loss: 1.1166, validation loss: 2.6978
2024-06-03 12:40:37 [INFO]: Epoch 005 - training loss: 1.1043, validation loss: 2.7826
2024-06-03 12:40:43 [INFO]: Epoch 006 - training loss: 1.0951, validation loss: 2.6685
2024-06-03 12:40:48 [INFO]: Epoch 007 - training loss: 1.0861, validation loss: 2.5751
2024-06-03 12:40:53 [INFO]: Epoch 008 - training loss: 1.0816, validation loss: 2.6077
2024-06-03 12:40:57 [INFO]: Epoch 009 - training loss: 1.0735, validation loss: 2.4961
2024-06-03 12:41:00 [INFO]: Epoch 010 - training loss: 1.0670, validation loss: 2.4109
2024-06-03 12:41:04 [INFO]: Epoch 011 - training loss: 1.0621, validation loss: 2.3526
2024-06-03 12:41:08 [INFO]: Epoch 012 - training loss: 1.0553, validation loss: 2.2894
2024-06-03 12:41:12 [INFO]: Epoch 013 - training loss: 1.0488, validation loss: 2.2955
2024-06-03 12:41:15 [INFO]: Epoch 014 - training loss: 1.0431, validation loss: 2.2806
2024-06-03 12:41:19 [INFO]: Epoch 015 - training loss: 1.0379, validation loss: 2.1764
2024-06-03 12:41:23 [INFO]: Epoch 016 - training loss: 1.0327, validation loss: 2.1767
2024-06-03 12:41:27 [INFO]: Epoch 017 - training loss: 1.0296, validation loss: 2.1487
2024-06-03 12:41:31 [INFO]: Epoch 018 - training loss: 1.0253, validation loss: 2.1033
2024-06-03 12:41:35 [INFO]: Epoch 019 - training loss: 1.0207, validation loss: 2.0692
2024-06-03 12:41:39 [INFO]: Epoch 020 - training loss: 1.0186, validation loss: 2.0676
2024-06-03 12:41:43 [INFO]: Epoch 021 - training loss: 1.0155, validation loss: 2.0511
2024-06-03 12:41:47 [INFO]: Epoch 022 - training loss: 1.0130, validation loss: 2.0034
2024-06-03 12:41:50 [INFO]: Epoch 023 - training loss: 1.0116, validation loss: 1.9915
2024-06-03 12:41:54 [INFO]: Epoch 024 - training loss: 1.0090, validation loss: 1.9769
2024-06-03 12:41:58 [INFO]: Epoch 025 - training loss: 1.0078, validation loss: 1.9872
2024-06-03 12:42:02 [INFO]: Epoch 026 - training loss: 1.0046, validation loss: 1.9697
2024-06-03 12:42:06 [INFO]: Epoch 027 - training loss: 1.0042, validation loss: 1.9661
2024-06-03 12:42:10 [INFO]: Epoch 028 - training loss: 1.0018, validation loss: 1.9689
2024-06-03 12:42:13 [INFO]: Epoch 029 - training loss: 1.0006, validation loss: 1.9583
2024-06-03 12:42:17 [INFO]: Epoch 030 - training loss: 1.0003, validation loss: 1.9383
2024-06-03 12:42:21 [INFO]: Epoch 031 - training loss: 0.9984, validation loss: 1.9146
2024-06-03 12:42:25 [INFO]: Epoch 032 - training loss: 0.9968, validation loss: 1.9167
2024-06-03 12:42:29 [INFO]: Epoch 033 - training loss: 0.9964, validation loss: 1.9027
2024-06-03 12:42:33 [INFO]: Epoch 034 - training loss: 0.9956, validation loss: 1.9069
2024-06-03 12:42:36 [INFO]: Epoch 035 - training loss: 0.9944, validation loss: 1.9140
2024-06-03 12:42:40 [INFO]: Epoch 036 - training loss: 0.9919, validation loss: 1.8831
2024-06-03 12:42:44 [INFO]: Epoch 037 - training loss: 0.9922, validation loss: 1.8489
2024-06-03 12:42:48 [INFO]: Epoch 038 - training loss: 0.9924, validation loss: 1.8447
2024-06-03 12:42:52 [INFO]: Epoch 039 - training loss: 0.9933, validation loss: 1.8472
2024-06-03 12:42:56 [INFO]: Epoch 040 - training loss: 0.9940, validation loss: 1.8414
2024-06-03 12:43:00 [INFO]: Epoch 041 - training loss: 0.9904, validation loss: 1.8418
2024-06-03 12:43:03 [INFO]: Epoch 042 - training loss: 0.9891, validation loss: 1.8541
2024-06-03 12:43:07 [INFO]: Epoch 043 - training loss: 0.9888, validation loss: 1.8317
2024-06-03 12:43:11 [INFO]: Epoch 044 - training loss: 0.9882, validation loss: 1.8143
2024-06-03 12:43:15 [INFO]: Epoch 045 - training loss: 0.9878, validation loss: 1.8114
2024-06-03 12:43:19 [INFO]: Epoch 046 - training loss: 0.9875, validation loss: 1.8165
2024-06-03 12:43:22 [INFO]: Epoch 047 - training loss: 0.9861, validation loss: 1.7987
2024-06-03 12:43:26 [INFO]: Epoch 048 - training loss: 0.9861, validation loss: 1.8091
2024-06-03 12:43:30 [INFO]: Epoch 049 - training loss: 0.9861, validation loss: 1.7748
2024-06-03 12:43:34 [INFO]: Epoch 050 - training loss: 0.9847, validation loss: 1.7890
2024-06-03 12:43:38 [INFO]: Epoch 051 - training loss: 0.9850, validation loss: 1.7904
2024-06-03 12:43:42 [INFO]: Epoch 052 - training loss: 0.9839, validation loss: 1.7776
2024-06-03 12:43:46 [INFO]: Epoch 053 - training loss: 0.9852, validation loss: 1.7731
2024-06-03 12:43:50 [INFO]: Epoch 054 - training loss: 0.9833, validation loss: 1.7707
2024-06-03 12:43:54 [INFO]: Epoch 055 - training loss: 0.9837, validation loss: 1.7557
2024-06-03 12:43:58 [INFO]: Epoch 056 - training loss: 0.9846, validation loss: 1.7477
2024-06-03 12:44:01 [INFO]: Epoch 057 - training loss: 0.9833, validation loss: 1.7441
2024-06-03 12:44:05 [INFO]: Epoch 058 - training loss: 0.9824, validation loss: 1.7405
2024-06-03 12:44:09 [INFO]: Epoch 059 - training loss: 0.9823, validation loss: 1.7191
2024-06-03 12:44:13 [INFO]: Epoch 060 - training loss: 0.9818, validation loss: 1.7312
2024-06-03 12:44:17 [INFO]: Epoch 061 - training loss: 0.9819, validation loss: 1.7191
2024-06-03 12:44:20 [INFO]: Epoch 062 - training loss: 0.9815, validation loss: 1.7118
2024-06-03 12:44:24 [INFO]: Epoch 063 - training loss: 0.9819, validation loss: 1.7041
2024-06-03 12:44:28 [INFO]: Epoch 064 - training loss: 0.9815, validation loss: 1.6954
2024-06-03 12:44:32 [INFO]: Epoch 065 - training loss: 0.9811, validation loss: 1.7028
2024-06-03 12:44:36 [INFO]: Epoch 066 - training loss: 0.9804, validation loss: 1.7003
2024-06-03 12:44:40 [INFO]: Epoch 067 - training loss: 0.9818, validation loss: 1.7285
2024-06-03 12:44:44 [INFO]: Epoch 068 - training loss: 0.9799, validation loss: 1.6966
2024-06-03 12:44:48 [INFO]: Epoch 069 - training loss: 0.9796, validation loss: 1.6982
2024-06-03 12:44:52 [INFO]: Epoch 070 - training loss: 0.9800, validation loss: 1.6973
2024-06-03 12:44:55 [INFO]: Epoch 071 - training loss: 0.9793, validation loss: 1.6942
2024-06-03 12:44:59 [INFO]: Epoch 072 - training loss: 0.9797, validation loss: 1.6974
2024-06-03 12:45:03 [INFO]: Epoch 073 - training loss: 0.9790, validation loss: 1.6616
2024-06-03 12:45:07 [INFO]: Epoch 074 - training loss: 0.9793, validation loss: 1.6741
2024-06-03 12:45:11 [INFO]: Epoch 075 - training loss: 0.9801, validation loss: 1.6861
2024-06-03 12:45:15 [INFO]: Epoch 076 - training loss: 0.9779, validation loss: 1.6733
2024-06-03 12:45:19 [INFO]: Epoch 077 - training loss: 0.9777, validation loss: 1.6849
2024-06-03 12:45:23 [INFO]: Epoch 078 - training loss: 0.9783, validation loss: 1.6590
2024-06-03 12:45:27 [INFO]: Epoch 079 - training loss: 0.9779, validation loss: 1.6739
2024-06-03 12:45:31 [INFO]: Epoch 080 - training loss: 0.9780, validation loss: 1.6704
2024-06-03 12:45:35 [INFO]: Epoch 081 - training loss: 0.9780, validation loss: 1.6776
2024-06-03 12:45:39 [INFO]: Epoch 082 - training loss: 0.9775, validation loss: 1.6758
2024-06-03 12:45:42 [INFO]: Epoch 083 - training loss: 0.9778, validation loss: 1.7078
2024-06-03 12:45:46 [INFO]: Epoch 084 - training loss: 0.9772, validation loss: 1.6702
2024-06-03 12:45:50 [INFO]: Epoch 085 - training loss: 0.9759, validation loss: 1.6624
2024-06-03 12:45:54 [INFO]: Epoch 086 - training loss: 0.9765, validation loss: 1.6671
2024-06-03 12:45:58 [INFO]: Epoch 087 - training loss: 0.9766, validation loss: 1.6565
2024-06-03 12:46:02 [INFO]: Epoch 088 - training loss: 0.9768, validation loss: 1.6763
2024-06-03 12:46:05 [INFO]: Epoch 089 - training loss: 0.9766, validation loss: 1.6613
2024-06-03 12:46:09 [INFO]: Epoch 090 - training loss: 0.9767, validation loss: 1.6462
2024-06-03 12:46:13 [INFO]: Epoch 091 - training loss: 0.9759, validation loss: 1.6484
2024-06-03 12:46:17 [INFO]: Epoch 092 - training loss: 0.9756, validation loss: 1.6586
2024-06-03 12:46:21 [INFO]: Epoch 093 - training loss: 0.9760, validation loss: 1.6437
2024-06-03 12:46:25 [INFO]: Epoch 094 - training loss: 0.9767, validation loss: 1.6517
2024-06-03 12:46:28 [INFO]: Epoch 095 - training loss: 0.9763, validation loss: 1.6409
2024-06-03 12:46:33 [INFO]: Epoch 096 - training loss: 0.9755, validation loss: 1.6394
2024-06-03 12:46:36 [INFO]: Epoch 097 - training loss: 0.9758, validation loss: 1.6529
2024-06-03 12:46:40 [INFO]: Epoch 098 - training loss: 0.9757, validation loss: 1.6359
2024-06-03 12:46:44 [INFO]: Epoch 099 - training loss: 0.9749, validation loss: 1.6541
2024-06-03 12:46:48 [INFO]: Epoch 100 - training loss: 0.9753, validation loss: 1.6402
2024-06-03 12:46:48 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 12:46:48 [INFO]: Saved the model to results_block_rate05/Electricity/FiLM_Electricity/round_2/20240603_T124008/FiLM.pypots
2024-06-03 12:46:50 [INFO]: Successfully saved to results_block_rate05/Electricity/FiLM_Electricity/round_2/imputation.pkl
2024-06-03 12:46:50 [INFO]: Round2 - FiLM on Electricity: MAE=0.9381, MSE=1.6983, MRE=0.5035
2024-06-03 12:46:50 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 12:46:50 [INFO]: Using the given device: cuda:0
2024-06-03 12:46:50 [INFO]: Model files will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_3/20240603_T124650
2024-06-03 12:46:50 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_3/20240603_T124650/tensorboard
2024-06-03 12:46:51 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 12:46:55 [INFO]: Epoch 001 - training loss: 1.4497, validation loss: 2.8048
2024-06-03 12:46:59 [INFO]: Epoch 002 - training loss: 1.1809, validation loss: 2.5450
2024-06-03 12:47:02 [INFO]: Epoch 003 - training loss: 1.1201, validation loss: 2.6033
2024-06-03 12:47:06 [INFO]: Epoch 004 - training loss: 1.0985, validation loss: 2.4438
2024-06-03 12:47:10 [INFO]: Epoch 005 - training loss: 1.0894, validation loss: 2.4295
2024-06-03 12:47:14 [INFO]: Epoch 006 - training loss: 1.0784, validation loss: 2.3764
2024-06-03 12:47:18 [INFO]: Epoch 007 - training loss: 1.0695, validation loss: 2.3511
2024-06-03 12:47:22 [INFO]: Epoch 008 - training loss: 1.0611, validation loss: 2.3026
2024-06-03 12:47:26 [INFO]: Epoch 009 - training loss: 1.0543, validation loss: 2.2765
2024-06-03 12:47:30 [INFO]: Epoch 010 - training loss: 1.0472, validation loss: 2.2220
2024-06-03 12:47:34 [INFO]: Epoch 011 - training loss: 1.0420, validation loss: 2.1848
2024-06-03 12:47:37 [INFO]: Epoch 012 - training loss: 1.0359, validation loss: 2.2022
2024-06-03 12:47:41 [INFO]: Epoch 013 - training loss: 1.0322, validation loss: 2.1566
2024-06-03 12:47:45 [INFO]: Epoch 014 - training loss: 1.0277, validation loss: 2.1554
2024-06-03 12:47:49 [INFO]: Epoch 015 - training loss: 1.0229, validation loss: 2.1021
2024-06-03 12:47:53 [INFO]: Epoch 016 - training loss: 1.0202, validation loss: 2.0738
2024-06-03 12:47:57 [INFO]: Epoch 017 - training loss: 1.0178, validation loss: 2.0741
2024-06-03 12:48:01 [INFO]: Epoch 018 - training loss: 1.0159, validation loss: 2.0481
2024-06-03 12:48:05 [INFO]: Epoch 019 - training loss: 1.0128, validation loss: 2.0410
2024-06-03 12:48:09 [INFO]: Epoch 020 - training loss: 1.0098, validation loss: 2.0284
2024-06-03 12:48:13 [INFO]: Epoch 021 - training loss: 1.0089, validation loss: 2.0332
2024-06-03 12:48:17 [INFO]: Epoch 022 - training loss: 1.0075, validation loss: 2.0089
2024-06-03 12:48:21 [INFO]: Epoch 023 - training loss: 1.0072, validation loss: 1.9934
2024-06-03 12:48:25 [INFO]: Epoch 024 - training loss: 1.0041, validation loss: 1.9561
2024-06-03 12:48:29 [INFO]: Epoch 025 - training loss: 1.0011, validation loss: 1.9479
2024-06-03 12:48:33 [INFO]: Epoch 026 - training loss: 1.0012, validation loss: 1.9468
2024-06-03 12:48:36 [INFO]: Epoch 027 - training loss: 1.0010, validation loss: 1.9425
2024-06-03 12:48:40 [INFO]: Epoch 028 - training loss: 0.9981, validation loss: 1.9710
2024-06-03 12:48:44 [INFO]: Epoch 029 - training loss: 0.9973, validation loss: 1.9419
2024-06-03 12:48:48 [INFO]: Epoch 030 - training loss: 0.9962, validation loss: 1.9252
2024-06-03 12:48:52 [INFO]: Epoch 031 - training loss: 0.9963, validation loss: 1.9028
2024-06-03 12:48:56 [INFO]: Epoch 032 - training loss: 0.9941, validation loss: 1.9064
2024-06-03 12:49:00 [INFO]: Epoch 033 - training loss: 0.9931, validation loss: 1.8926
2024-06-03 12:49:04 [INFO]: Epoch 034 - training loss: 0.9925, validation loss: 1.9003
2024-06-03 12:49:08 [INFO]: Epoch 035 - training loss: 0.9927, validation loss: 1.8805
2024-06-03 12:49:11 [INFO]: Epoch 036 - training loss: 0.9919, validation loss: 1.8770
2024-06-03 12:49:15 [INFO]: Epoch 037 - training loss: 0.9899, validation loss: 1.8498
2024-06-03 12:49:19 [INFO]: Epoch 038 - training loss: 0.9902, validation loss: 1.8555
2024-06-03 12:49:23 [INFO]: Epoch 039 - training loss: 0.9907, validation loss: 1.8615
2024-06-03 12:49:27 [INFO]: Epoch 040 - training loss: 0.9891, validation loss: 1.8614
2024-06-03 12:49:31 [INFO]: Epoch 041 - training loss: 0.9886, validation loss: 1.8550
2024-06-03 12:49:35 [INFO]: Epoch 042 - training loss: 0.9885, validation loss: 1.8606
2024-06-03 12:49:39 [INFO]: Epoch 043 - training loss: 0.9875, validation loss: 1.8270
2024-06-03 12:49:43 [INFO]: Epoch 044 - training loss: 0.9873, validation loss: 1.8212
2024-06-03 12:49:47 [INFO]: Epoch 045 - training loss: 0.9873, validation loss: 1.8073
2024-06-03 12:49:51 [INFO]: Epoch 046 - training loss: 0.9863, validation loss: 1.8050
2024-06-03 12:49:55 [INFO]: Epoch 047 - training loss: 0.9853, validation loss: 1.8074
2024-06-03 12:49:58 [INFO]: Epoch 048 - training loss: 0.9843, validation loss: 1.7863
2024-06-03 12:50:02 [INFO]: Epoch 049 - training loss: 0.9853, validation loss: 1.7897
2024-06-03 12:50:06 [INFO]: Epoch 050 - training loss: 0.9841, validation loss: 1.7654
2024-06-03 12:50:10 [INFO]: Epoch 051 - training loss: 0.9847, validation loss: 1.7959
2024-06-03 12:50:14 [INFO]: Epoch 052 - training loss: 0.9839, validation loss: 1.7767
2024-06-03 12:50:18 [INFO]: Epoch 053 - training loss: 0.9832, validation loss: 1.7919
2024-06-03 12:50:21 [INFO]: Epoch 054 - training loss: 0.9829, validation loss: 1.7651
2024-06-03 12:50:25 [INFO]: Epoch 055 - training loss: 0.9828, validation loss: 1.7770
2024-06-03 12:50:29 [INFO]: Epoch 056 - training loss: 0.9823, validation loss: 1.7422
2024-06-03 12:50:33 [INFO]: Epoch 057 - training loss: 0.9818, validation loss: 1.7359
2024-06-03 12:50:37 [INFO]: Epoch 058 - training loss: 0.9823, validation loss: 1.7418
2024-06-03 12:50:41 [INFO]: Epoch 059 - training loss: 0.9811, validation loss: 1.7171
2024-06-03 12:50:45 [INFO]: Epoch 060 - training loss: 0.9807, validation loss: 1.7058
2024-06-03 12:50:49 [INFO]: Epoch 061 - training loss: 0.9808, validation loss: 1.7109
2024-06-03 12:50:52 [INFO]: Epoch 062 - training loss: 0.9800, validation loss: 1.7359
2024-06-03 12:50:56 [INFO]: Epoch 063 - training loss: 0.9812, validation loss: 1.7627
2024-06-03 12:51:00 [INFO]: Epoch 064 - training loss: 0.9802, validation loss: 1.7120
2024-06-03 12:51:04 [INFO]: Epoch 065 - training loss: 0.9798, validation loss: 1.7456
2024-06-03 12:51:08 [INFO]: Epoch 066 - training loss: 0.9799, validation loss: 1.7120
2024-06-03 12:51:12 [INFO]: Epoch 067 - training loss: 0.9793, validation loss: 1.7236
2024-06-03 12:51:16 [INFO]: Epoch 068 - training loss: 0.9810, validation loss: 1.7102
2024-06-03 12:51:19 [INFO]: Epoch 069 - training loss: 0.9804, validation loss: 1.6715
2024-06-03 12:51:23 [INFO]: Epoch 070 - training loss: 0.9790, validation loss: 1.7064
2024-06-03 12:51:27 [INFO]: Epoch 071 - training loss: 0.9789, validation loss: 1.6872
2024-06-03 12:51:31 [INFO]: Epoch 072 - training loss: 0.9786, validation loss: 1.6658
2024-06-03 12:51:35 [INFO]: Epoch 073 - training loss: 0.9791, validation loss: 1.6758
2024-06-03 12:51:39 [INFO]: Epoch 074 - training loss: 0.9779, validation loss: 1.6674
2024-06-03 12:51:43 [INFO]: Epoch 075 - training loss: 0.9778, validation loss: 1.6801
2024-06-03 12:51:47 [INFO]: Epoch 076 - training loss: 0.9776, validation loss: 1.6889
2024-06-03 12:51:51 [INFO]: Epoch 077 - training loss: 0.9785, validation loss: 1.6833
2024-06-03 12:51:55 [INFO]: Epoch 078 - training loss: 0.9770, validation loss: 1.6714
2024-06-03 12:51:59 [INFO]: Epoch 079 - training loss: 0.9774, validation loss: 1.6631
2024-06-03 12:52:03 [INFO]: Epoch 080 - training loss: 0.9783, validation loss: 1.6763
2024-06-03 12:52:07 [INFO]: Epoch 081 - training loss: 0.9773, validation loss: 1.6761
2024-06-03 12:52:11 [INFO]: Epoch 082 - training loss: 0.9773, validation loss: 1.6572
2024-06-03 12:52:14 [INFO]: Epoch 083 - training loss: 0.9779, validation loss: 1.6681
2024-06-03 12:52:18 [INFO]: Epoch 084 - training loss: 0.9769, validation loss: 1.6620
2024-06-03 12:52:22 [INFO]: Epoch 085 - training loss: 0.9765, validation loss: 1.6738
2024-06-03 12:52:26 [INFO]: Epoch 086 - training loss: 0.9764, validation loss: 1.6551
2024-06-03 12:52:30 [INFO]: Epoch 087 - training loss: 0.9769, validation loss: 1.6814
2024-06-03 12:52:34 [INFO]: Epoch 088 - training loss: 0.9761, validation loss: 1.6784
2024-06-03 12:52:37 [INFO]: Epoch 089 - training loss: 0.9759, validation loss: 1.6705
2024-06-03 12:52:41 [INFO]: Epoch 090 - training loss: 0.9760, validation loss: 1.6664
2024-06-03 12:52:45 [INFO]: Epoch 091 - training loss: 0.9757, validation loss: 1.6477
2024-06-03 12:52:49 [INFO]: Epoch 092 - training loss: 0.9759, validation loss: 1.6649
2024-06-03 12:52:53 [INFO]: Epoch 093 - training loss: 0.9748, validation loss: 1.6542
2024-06-03 12:52:56 [INFO]: Epoch 094 - training loss: 0.9763, validation loss: 1.6432
2024-06-03 12:53:00 [INFO]: Epoch 095 - training loss: 0.9756, validation loss: 1.6553
2024-06-03 12:53:04 [INFO]: Epoch 096 - training loss: 0.9757, validation loss: 1.6615
2024-06-03 12:53:08 [INFO]: Epoch 097 - training loss: 0.9756, validation loss: 1.6380
2024-06-03 12:53:12 [INFO]: Epoch 098 - training loss: 0.9767, validation loss: 1.6477
2024-06-03 12:53:16 [INFO]: Epoch 099 - training loss: 0.9744, validation loss: 1.6717
2024-06-03 12:53:19 [INFO]: Epoch 100 - training loss: 0.9749, validation loss: 1.6371
2024-06-03 12:53:19 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 12:53:19 [INFO]: Saved the model to results_block_rate05/Electricity/FiLM_Electricity/round_3/20240603_T124650/FiLM.pypots
2024-06-03 12:53:22 [INFO]: Successfully saved to results_block_rate05/Electricity/FiLM_Electricity/round_3/imputation.pkl
2024-06-03 12:53:22 [INFO]: Round3 - FiLM on Electricity: MAE=0.9461, MSE=1.7210, MRE=0.5078
2024-06-03 12:53:22 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:53:22 [INFO]: Using the given device: cuda:0
2024-06-03 12:53:22 [INFO]: Model files will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_4/20240603_T125322
2024-06-03 12:53:22 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/FiLM_Electricity/round_4/20240603_T125322/tensorboard
2024-06-03 12:53:22 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-03 12:53:26 [INFO]: Epoch 001 - training loss: 1.4339, validation loss: 2.6584
2024-06-03 12:53:30 [INFO]: Epoch 002 - training loss: 1.1676, validation loss: 2.4399
2024-06-03 12:53:34 [INFO]: Epoch 003 - training loss: 1.1261, validation loss: 2.4233
2024-06-03 12:53:38 [INFO]: Epoch 004 - training loss: 1.1066, validation loss: 2.4045
2024-06-03 12:53:42 [INFO]: Epoch 005 - training loss: 1.0945, validation loss: 2.3623
2024-06-03 12:53:46 [INFO]: Epoch 006 - training loss: 1.0866, validation loss: 2.3423
2024-06-03 12:53:50 [INFO]: Epoch 007 - training loss: 1.0774, validation loss: 2.3182
2024-06-03 12:53:53 [INFO]: Epoch 008 - training loss: 1.0724, validation loss: 2.3219
2024-06-03 12:53:57 [INFO]: Epoch 009 - training loss: 1.0644, validation loss: 2.2381
2024-06-03 12:54:01 [INFO]: Epoch 010 - training loss: 1.0572, validation loss: 2.2295
2024-06-03 12:54:05 [INFO]: Epoch 011 - training loss: 1.0530, validation loss: 2.1922
2024-06-03 12:54:09 [INFO]: Epoch 012 - training loss: 1.0465, validation loss: 2.1968
2024-06-03 12:54:12 [INFO]: Epoch 013 - training loss: 1.0421, validation loss: 2.1591
2024-06-03 12:54:16 [INFO]: Epoch 014 - training loss: 1.0377, validation loss: 2.1440
2024-06-03 12:54:19 [INFO]: Epoch 015 - training loss: 1.0327, validation loss: 2.1139
2024-06-03 12:54:22 [INFO]: Epoch 016 - training loss: 1.0286, validation loss: 2.1091
2024-06-03 12:54:25 [INFO]: Epoch 017 - training loss: 1.0257, validation loss: 2.0978
2024-06-03 12:54:28 [INFO]: Epoch 018 - training loss: 1.0227, validation loss: 2.0832
2024-06-03 12:54:31 [INFO]: Epoch 019 - training loss: 1.0190, validation loss: 2.0477
2024-06-03 12:54:34 [INFO]: Epoch 020 - training loss: 1.0180, validation loss: 2.0466
2024-06-03 12:54:37 [INFO]: Epoch 021 - training loss: 1.0145, validation loss: 2.0390
2024-06-03 12:54:40 [INFO]: Epoch 022 - training loss: 1.0117, validation loss: 1.9976
2024-06-03 12:54:43 [INFO]: Epoch 023 - training loss: 1.0104, validation loss: 2.0431
2024-06-03 12:54:46 [INFO]: Epoch 024 - training loss: 1.0096, validation loss: 2.0089
2024-06-03 12:54:49 [INFO]: Epoch 025 - training loss: 1.0095, validation loss: 2.0095
2024-06-03 12:54:52 [INFO]: Epoch 026 - training loss: 1.0052, validation loss: 1.9925
2024-06-03 12:54:55 [INFO]: Epoch 027 - training loss: 1.0038, validation loss: 1.9745
2024-06-03 12:54:58 [INFO]: Epoch 028 - training loss: 1.0024, validation loss: 1.9876
2024-06-03 12:55:01 [INFO]: Epoch 029 - training loss: 1.0010, validation loss: 2.0042
2024-06-03 12:55:04 [INFO]: Epoch 030 - training loss: 1.0020, validation loss: 1.9837
2024-06-03 12:55:07 [INFO]: Epoch 031 - training loss: 1.0015, validation loss: 1.9794
2024-06-03 12:55:10 [INFO]: Epoch 032 - training loss: 0.9981, validation loss: 1.9389
2024-06-03 12:55:14 [INFO]: Epoch 033 - training loss: 0.9982, validation loss: 1.9656
2024-06-03 12:55:16 [INFO]: Epoch 034 - training loss: 0.9972, validation loss: 1.9539
2024-06-03 12:55:19 [INFO]: Epoch 035 - training loss: 0.9951, validation loss: 1.9300
2024-06-03 12:55:22 [INFO]: Epoch 036 - training loss: 0.9945, validation loss: 1.9249
2024-06-03 12:55:25 [INFO]: Epoch 037 - training loss: 0.9941, validation loss: 1.9242
2024-06-03 12:55:28 [INFO]: Epoch 038 - training loss: 0.9936, validation loss: 1.9175
2024-06-03 12:55:31 [INFO]: Epoch 039 - training loss: 0.9927, validation loss: 1.8824
2024-06-03 12:55:34 [INFO]: Epoch 040 - training loss: 0.9913, validation loss: 1.9040
2024-06-03 12:55:37 [INFO]: Epoch 041 - training loss: 0.9913, validation loss: 1.8767
2024-06-03 12:55:40 [INFO]: Epoch 042 - training loss: 0.9893, validation loss: 1.8786
2024-06-03 12:55:43 [INFO]: Epoch 043 - training loss: 0.9900, validation loss: 1.8671
2024-06-03 12:55:47 [INFO]: Epoch 044 - training loss: 0.9897, validation loss: 1.8499
2024-06-03 12:55:50 [INFO]: Epoch 045 - training loss: 0.9882, validation loss: 1.8660
2024-06-03 12:55:53 [INFO]: Epoch 046 - training loss: 0.9886, validation loss: 1.8447
2024-06-03 12:55:56 [INFO]: Epoch 047 - training loss: 0.9888, validation loss: 1.8458
2024-06-03 12:55:59 [INFO]: Epoch 048 - training loss: 0.9870, validation loss: 1.8278
2024-06-03 12:56:02 [INFO]: Epoch 049 - training loss: 0.9871, validation loss: 1.8444
2024-06-03 12:56:05 [INFO]: Epoch 050 - training loss: 0.9872, validation loss: 1.7951
2024-06-03 12:56:08 [INFO]: Epoch 051 - training loss: 0.9873, validation loss: 1.7917
2024-06-03 12:56:11 [INFO]: Epoch 052 - training loss: 0.9850, validation loss: 1.7848
2024-06-03 12:56:14 [INFO]: Epoch 053 - training loss: 0.9845, validation loss: 1.8465
2024-06-03 12:56:17 [INFO]: Epoch 054 - training loss: 0.9846, validation loss: 1.7977
2024-06-03 12:56:20 [INFO]: Epoch 055 - training loss: 0.9862, validation loss: 1.8110
2024-06-03 12:56:23 [INFO]: Epoch 056 - training loss: 0.9842, validation loss: 1.7949
2024-06-03 12:56:26 [INFO]: Epoch 057 - training loss: 0.9830, validation loss: 1.7701
2024-06-03 12:56:29 [INFO]: Epoch 058 - training loss: 0.9834, validation loss: 1.7714
2024-06-03 12:56:32 [INFO]: Epoch 059 - training loss: 0.9829, validation loss: 1.7589
2024-06-03 12:56:35 [INFO]: Epoch 060 - training loss: 0.9827, validation loss: 1.7738
2024-06-03 12:56:38 [INFO]: Epoch 061 - training loss: 0.9829, validation loss: 1.7597
2024-06-03 12:56:41 [INFO]: Epoch 062 - training loss: 0.9812, validation loss: 1.7667
2024-06-03 12:56:44 [INFO]: Epoch 063 - training loss: 0.9818, validation loss: 1.7453
2024-06-03 12:56:47 [INFO]: Epoch 064 - training loss: 0.9816, validation loss: 1.7361
2024-06-03 12:56:50 [INFO]: Epoch 065 - training loss: 0.9809, validation loss: 1.7330
2024-06-03 12:56:53 [INFO]: Epoch 066 - training loss: 0.9810, validation loss: 1.7432
2024-06-03 12:56:56 [INFO]: Epoch 067 - training loss: 0.9809, validation loss: 1.7291
2024-06-03 12:56:59 [INFO]: Epoch 068 - training loss: 0.9809, validation loss: 1.6955
2024-06-03 12:57:02 [INFO]: Epoch 069 - training loss: 0.9798, validation loss: 1.7229
2024-06-03 12:57:05 [INFO]: Epoch 070 - training loss: 0.9796, validation loss: 1.7255
2024-06-03 12:57:09 [INFO]: Epoch 071 - training loss: 0.9796, validation loss: 1.6959
2024-06-03 12:57:12 [INFO]: Epoch 072 - training loss: 0.9796, validation loss: 1.7098
2024-06-03 12:57:15 [INFO]: Epoch 073 - training loss: 0.9793, validation loss: 1.7075
2024-06-03 12:57:18 [INFO]: Epoch 074 - training loss: 0.9799, validation loss: 1.6913
2024-06-03 12:57:21 [INFO]: Epoch 075 - training loss: 0.9793, validation loss: 1.6860
2024-06-03 12:57:24 [INFO]: Epoch 076 - training loss: 0.9787, validation loss: 1.7322
2024-06-03 12:57:28 [INFO]: Epoch 077 - training loss: 0.9785, validation loss: 1.7047
2024-06-03 12:57:31 [INFO]: Epoch 078 - training loss: 0.9787, validation loss: 1.6892
2024-06-03 12:57:34 [INFO]: Epoch 079 - training loss: 0.9795, validation loss: 1.7131
2024-06-03 12:57:37 [INFO]: Epoch 080 - training loss: 0.9780, validation loss: 1.6752
2024-06-03 12:57:40 [INFO]: Epoch 081 - training loss: 0.9774, validation loss: 1.7202
2024-06-03 12:57:43 [INFO]: Epoch 082 - training loss: 0.9772, validation loss: 1.6891
2024-06-03 12:57:46 [INFO]: Epoch 083 - training loss: 0.9774, validation loss: 1.6846
2024-06-03 12:57:48 [INFO]: Epoch 084 - training loss: 0.9764, validation loss: 1.6760
2024-06-03 12:57:51 [INFO]: Epoch 085 - training loss: 0.9776, validation loss: 1.6724
2024-06-03 12:57:54 [INFO]: Epoch 086 - training loss: 0.9771, validation loss: 1.6639
2024-06-03 12:57:57 [INFO]: Epoch 087 - training loss: 0.9763, validation loss: 1.6790
2024-06-03 12:58:00 [INFO]: Epoch 088 - training loss: 0.9762, validation loss: 1.6556
2024-06-03 12:58:04 [INFO]: Epoch 089 - training loss: 0.9769, validation loss: 1.6901
2024-06-03 12:58:07 [INFO]: Epoch 090 - training loss: 0.9766, validation loss: 1.6909
2024-06-03 12:58:10 [INFO]: Epoch 091 - training loss: 0.9771, validation loss: 1.6604
2024-06-03 12:58:13 [INFO]: Epoch 092 - training loss: 0.9766, validation loss: 1.6968
2024-06-03 12:58:16 [INFO]: Epoch 093 - training loss: 0.9762, validation loss: 1.6738
2024-06-03 12:58:19 [INFO]: Epoch 094 - training loss: 0.9759, validation loss: 1.6592
2024-06-03 12:58:21 [INFO]: Epoch 095 - training loss: 0.9757, validation loss: 1.6649
2024-06-03 12:58:23 [INFO]: Epoch 096 - training loss: 0.9765, validation loss: 1.6474
2024-06-03 12:58:25 [INFO]: Epoch 097 - training loss: 0.9744, validation loss: 1.6520
2024-06-03 12:58:26 [INFO]: Epoch 098 - training loss: 0.9755, validation loss: 1.6529
2024-06-03 12:58:28 [INFO]: Epoch 099 - training loss: 0.9758, validation loss: 1.6424
2024-06-03 12:58:30 [INFO]: Epoch 100 - training loss: 0.9751, validation loss: 1.6368
2024-06-03 12:58:30 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 12:58:30 [INFO]: Saved the model to results_block_rate05/Electricity/FiLM_Electricity/round_4/20240603_T125322/FiLM.pypots
2024-06-03 12:58:31 [INFO]: Successfully saved to results_block_rate05/Electricity/FiLM_Electricity/round_4/imputation.pkl
2024-06-03 12:58:31 [INFO]: Round4 - FiLM on Electricity: MAE=0.9556, MSE=1.7234, MRE=0.5129
2024-06-03 12:58:31 [INFO]: Done! Final results:
Averaged FiLM (570,613 params) on Electricity: MAE=1.0320 ± 0.15670350568512798, MSE=2.0673 ± 0.6624528470526699, MRE=0.5539 ± 0.08411058797130926, average inference time=0.52
