2024-06-03 12:16:16 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:16:16 [INFO]: Using the given device: cuda:0
2024-06-03 12:16:17 [INFO]: Model files will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_0/20240603_T121617
2024-06-03 12:16:17 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_0/20240603_T121617/tensorboard
2024-06-03 12:16:18 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 12:16:38 [INFO]: Epoch 001 - training loss: 213294.1447, validation loss: 2.5531
2024-06-03 12:16:55 [INFO]: Epoch 002 - training loss: 184783.5828, validation loss: 2.3475
2024-06-03 12:17:14 [INFO]: Epoch 003 - training loss: 183089.4253, validation loss: 2.2480
2024-06-03 12:17:32 [INFO]: Epoch 004 - training loss: 182614.1609, validation loss: 2.2208
2024-06-03 12:17:50 [INFO]: Epoch 005 - training loss: 182212.5428, validation loss: 2.1936
2024-06-03 12:18:08 [INFO]: Epoch 006 - training loss: 181967.8119, validation loss: 2.1675
2024-06-03 12:18:26 [INFO]: Epoch 007 - training loss: 181889.9074, validation loss: 2.1280
2024-06-03 12:18:44 [INFO]: Epoch 008 - training loss: 181760.5399, validation loss: 2.1507
2024-06-03 12:19:02 [INFO]: Epoch 009 - training loss: 181685.4589, validation loss: 2.1306
2024-06-03 12:19:20 [INFO]: Epoch 010 - training loss: 181615.7697, validation loss: 2.0955
2024-06-03 12:19:38 [INFO]: Epoch 011 - training loss: 181570.6047, validation loss: 2.0971
2024-06-03 12:19:57 [INFO]: Epoch 012 - training loss: 181537.1325, validation loss: 2.0842
2024-06-03 12:20:15 [INFO]: Epoch 013 - training loss: 181497.8912, validation loss: 2.1134
2024-06-03 12:20:33 [INFO]: Epoch 014 - training loss: 181469.2153, validation loss: 2.0725
2024-06-03 12:20:51 [INFO]: Epoch 015 - training loss: 181423.4034, validation loss: 2.0991
2024-06-03 12:21:09 [INFO]: Epoch 016 - training loss: 181420.0926, validation loss: 2.1406
2024-06-03 12:21:26 [INFO]: Epoch 017 - training loss: 181423.5208, validation loss: 2.0746
2024-06-03 12:21:44 [INFO]: Epoch 018 - training loss: 181347.9855, validation loss: 2.0785
2024-06-03 12:22:02 [INFO]: Epoch 019 - training loss: 181316.6273, validation loss: 2.0793
2024-06-03 12:22:19 [INFO]: Epoch 020 - training loss: 181278.0914, validation loss: 2.0437
2024-06-03 12:22:38 [INFO]: Epoch 021 - training loss: 181259.0075, validation loss: 2.0633
2024-06-03 12:22:56 [INFO]: Epoch 022 - training loss: 181250.5480, validation loss: 2.0658
2024-06-03 12:23:15 [INFO]: Epoch 023 - training loss: 181238.8692, validation loss: 2.0631
2024-06-03 12:23:33 [INFO]: Epoch 024 - training loss: 181219.0741, validation loss: 2.0321
2024-06-03 12:23:50 [INFO]: Epoch 025 - training loss: 181209.5093, validation loss: 2.0537
2024-06-03 12:24:09 [INFO]: Epoch 026 - training loss: 181202.3669, validation loss: 2.0492
2024-06-03 12:24:27 [INFO]: Epoch 027 - training loss: 181189.0856, validation loss: 2.0592
2024-06-03 12:24:45 [INFO]: Epoch 028 - training loss: 181169.2616, validation loss: 2.0323
2024-06-03 12:25:04 [INFO]: Epoch 029 - training loss: 181145.8119, validation loss: 2.0330
2024-06-03 12:25:22 [INFO]: Epoch 030 - training loss: 181137.0029, validation loss: 2.0511
2024-06-03 12:25:40 [INFO]: Epoch 031 - training loss: 181117.3785, validation loss: 2.0525
2024-06-03 12:25:59 [INFO]: Epoch 032 - training loss: 181111.3588, validation loss: 2.0278
2024-06-03 12:26:16 [INFO]: Epoch 033 - training loss: 181116.7598, validation loss: 2.0512
2024-06-03 12:26:33 [INFO]: Epoch 034 - training loss: 181112.3692, validation loss: 2.0642
2024-06-03 12:26:51 [INFO]: Epoch 035 - training loss: 181103.3727, validation loss: 2.0200
2024-06-03 12:27:08 [INFO]: Epoch 036 - training loss: 181076.3079, validation loss: 2.0390
2024-06-03 12:27:26 [INFO]: Epoch 037 - training loss: 181060.1186, validation loss: 2.0157
2024-06-03 12:27:45 [INFO]: Epoch 038 - training loss: 181064.8443, validation loss: 2.0369
2024-06-03 12:28:03 [INFO]: Epoch 039 - training loss: 181063.4178, validation loss: 2.0352
2024-06-03 12:28:22 [INFO]: Epoch 040 - training loss: 181044.0822, validation loss: 2.0439
2024-06-03 12:28:40 [INFO]: Epoch 041 - training loss: 181045.0503, validation loss: 2.0340
2024-06-03 12:28:58 [INFO]: Epoch 042 - training loss: 181042.3177, validation loss: 2.0028
2024-06-03 12:29:17 [INFO]: Epoch 043 - training loss: 181032.9091, validation loss: 2.0330
2024-06-03 12:29:35 [INFO]: Epoch 044 - training loss: 181015.1620, validation loss: 2.0178
2024-06-03 12:29:53 [INFO]: Epoch 045 - training loss: 181007.1667, validation loss: 2.0190
2024-06-03 12:30:10 [INFO]: Epoch 046 - training loss: 181002.9977, validation loss: 2.0114
2024-06-03 12:30:28 [INFO]: Epoch 047 - training loss: 181006.9138, validation loss: 2.0173
2024-06-03 12:30:46 [INFO]: Epoch 048 - training loss: 180993.6956, validation loss: 2.0321
2024-06-03 12:31:04 [INFO]: Epoch 049 - training loss: 180992.8258, validation loss: 2.0266
2024-06-03 12:31:23 [INFO]: Epoch 050 - training loss: 180979.6134, validation loss: 2.0068
2024-06-03 12:31:41 [INFO]: Epoch 051 - training loss: 180971.8617, validation loss: 2.0208
2024-06-03 12:32:00 [INFO]: Epoch 052 - training loss: 180978.5422, validation loss: 2.0193
2024-06-03 12:32:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:32:00 [INFO]: Finished training. The best model is from epoch#42.
2024-06-03 12:32:00 [INFO]: Saved the model to results_block_rate05/Electricity/GPVAE_Electricity/round_0/20240603_T121617/GPVAE.pypots
2024-06-03 12:34:49 [INFO]: Successfully saved to results_block_rate05/Electricity/GPVAE_Electricity/round_0/imputation.pkl
2024-06-03 12:34:49 [INFO]: Round0 - GPVAE on Electricity: MAE=1.3581, MSE=3.7012, MRE=0.7290
2024-06-03 12:34:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:34:49 [INFO]: Using the given device: cuda:0
2024-06-03 12:34:49 [INFO]: Model files will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_1/20240603_T123449
2024-06-03 12:34:49 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_1/20240603_T123449/tensorboard
2024-06-03 12:34:49 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 12:35:07 [INFO]: Epoch 001 - training loss: 214597.5168, validation loss: 2.4982
2024-06-03 12:35:25 [INFO]: Epoch 002 - training loss: 184613.9884, validation loss: 2.2996
2024-06-03 12:35:43 [INFO]: Epoch 003 - training loss: 183071.4010, validation loss: 2.2288
2024-06-03 12:36:00 [INFO]: Epoch 004 - training loss: 182428.4219, validation loss: 2.1640
2024-06-03 12:36:18 [INFO]: Epoch 005 - training loss: 182136.5666, validation loss: 2.1937
2024-06-03 12:36:35 [INFO]: Epoch 006 - training loss: 181919.5880, validation loss: 2.1800
2024-06-03 12:36:53 [INFO]: Epoch 007 - training loss: 181800.2367, validation loss: 2.1672
2024-06-03 12:37:11 [INFO]: Epoch 008 - training loss: 181699.0694, validation loss: 2.1301
2024-06-03 12:37:28 [INFO]: Epoch 009 - training loss: 181635.0799, validation loss: 2.1395
2024-06-03 12:37:45 [INFO]: Epoch 010 - training loss: 181584.2384, validation loss: 2.1226
2024-06-03 12:38:03 [INFO]: Epoch 011 - training loss: 181535.5324, validation loss: 2.1343
2024-06-03 12:38:21 [INFO]: Epoch 012 - training loss: 181484.4265, validation loss: 2.1497
2024-06-03 12:38:38 [INFO]: Epoch 013 - training loss: 181453.2025, validation loss: 2.1494
2024-06-03 12:38:55 [INFO]: Epoch 014 - training loss: 181426.8547, validation loss: 2.1134
2024-06-03 12:39:11 [INFO]: Epoch 015 - training loss: 181397.9444, validation loss: 2.1209
2024-06-03 12:39:26 [INFO]: Epoch 016 - training loss: 181358.5648, validation loss: 2.1218
2024-06-03 12:39:41 [INFO]: Epoch 017 - training loss: 181336.0700, validation loss: 2.1288
2024-06-03 12:39:55 [INFO]: Epoch 018 - training loss: 181298.9074, validation loss: 2.1035
2024-06-03 12:40:09 [INFO]: Epoch 019 - training loss: 181277.9184, validation loss: 2.1116
2024-06-03 12:40:24 [INFO]: Epoch 020 - training loss: 181269.2992, validation loss: 2.0861
2024-06-03 12:40:39 [INFO]: Epoch 021 - training loss: 181249.5851, validation loss: 2.1198
2024-06-03 12:40:53 [INFO]: Epoch 022 - training loss: 181219.9144, validation loss: 2.0962
2024-06-03 12:41:05 [INFO]: Epoch 023 - training loss: 181194.8131, validation loss: 2.1126
2024-06-03 12:41:17 [INFO]: Epoch 024 - training loss: 181193.8947, validation loss: 2.1286
2024-06-03 12:41:28 [INFO]: Epoch 025 - training loss: 181162.1140, validation loss: 2.1460
2024-06-03 12:41:39 [INFO]: Epoch 026 - training loss: 181157.6262, validation loss: 2.1059
2024-06-03 12:41:50 [INFO]: Epoch 027 - training loss: 181147.0411, validation loss: 2.1041
2024-06-03 12:42:01 [INFO]: Epoch 028 - training loss: 181132.0127, validation loss: 2.1099
2024-06-03 12:42:12 [INFO]: Epoch 029 - training loss: 181106.9931, validation loss: 2.1152
2024-06-03 12:42:23 [INFO]: Epoch 030 - training loss: 181092.1221, validation loss: 2.0912
2024-06-03 12:42:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:42:23 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 12:42:23 [INFO]: Saved the model to results_block_rate05/Electricity/GPVAE_Electricity/round_1/20240603_T123449/GPVAE.pypots
2024-06-03 12:44:16 [INFO]: Successfully saved to results_block_rate05/Electricity/GPVAE_Electricity/round_1/imputation.pkl
2024-06-03 12:44:16 [INFO]: Round1 - GPVAE on Electricity: MAE=1.3103, MSE=3.6739, MRE=0.7033
2024-06-03 12:44:16 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:44:16 [INFO]: Using the given device: cuda:0
2024-06-03 12:44:16 [INFO]: Model files will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_2/20240603_T124416
2024-06-03 12:44:16 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_2/20240603_T124416/tensorboard
2024-06-03 12:44:16 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 12:44:27 [INFO]: Epoch 001 - training loss: 212705.1580, validation loss: 2.5465
2024-06-03 12:44:38 [INFO]: Epoch 002 - training loss: 185114.2836, validation loss: 2.2983
2024-06-03 12:44:49 [INFO]: Epoch 003 - training loss: 183011.3733, validation loss: 2.2494
2024-06-03 12:45:00 [INFO]: Epoch 004 - training loss: 182476.5532, validation loss: 2.1886
2024-06-03 12:45:11 [INFO]: Epoch 005 - training loss: 182182.4074, validation loss: 2.1622
2024-06-03 12:45:22 [INFO]: Epoch 006 - training loss: 181971.1528, validation loss: 2.1410
2024-06-03 12:45:32 [INFO]: Epoch 007 - training loss: 181859.7876, validation loss: 2.1290
2024-06-03 12:45:43 [INFO]: Epoch 008 - training loss: 181772.9537, validation loss: 2.1186
2024-06-03 12:45:54 [INFO]: Epoch 009 - training loss: 181702.4219, validation loss: 2.1101
2024-06-03 12:46:05 [INFO]: Epoch 010 - training loss: 181640.8166, validation loss: 2.1080
2024-06-03 12:46:16 [INFO]: Epoch 011 - training loss: 181595.1753, validation loss: 2.1195
2024-06-03 12:46:27 [INFO]: Epoch 012 - training loss: 181554.2778, validation loss: 2.1132
2024-06-03 12:46:39 [INFO]: Epoch 013 - training loss: 181530.8929, validation loss: 2.0989
2024-06-03 12:46:50 [INFO]: Epoch 014 - training loss: 181482.0741, validation loss: 2.1105
2024-06-03 12:47:01 [INFO]: Epoch 015 - training loss: 181445.7841, validation loss: 2.1260
2024-06-03 12:47:12 [INFO]: Epoch 016 - training loss: 181402.9647, validation loss: 2.1297
2024-06-03 12:47:23 [INFO]: Epoch 017 - training loss: 181383.6400, validation loss: 2.1166
2024-06-03 12:47:33 [INFO]: Epoch 018 - training loss: 181382.9005, validation loss: 2.0759
2024-06-03 12:47:44 [INFO]: Epoch 019 - training loss: 181339.8160, validation loss: 2.1087
2024-06-03 12:47:55 [INFO]: Epoch 020 - training loss: 181313.7112, validation loss: 2.1004
2024-06-03 12:48:06 [INFO]: Epoch 021 - training loss: 181266.0098, validation loss: 2.1077
2024-06-03 12:48:17 [INFO]: Epoch 022 - training loss: 181267.0920, validation loss: 2.0658
2024-06-03 12:48:28 [INFO]: Epoch 023 - training loss: 181250.7899, validation loss: 2.0859
2024-06-03 12:48:39 [INFO]: Epoch 024 - training loss: 181245.9988, validation loss: 2.0528
2024-06-03 12:48:50 [INFO]: Epoch 025 - training loss: 181225.9172, validation loss: 2.0751
2024-06-03 12:49:01 [INFO]: Epoch 026 - training loss: 181190.3218, validation loss: 2.0413
2024-06-03 12:49:12 [INFO]: Epoch 027 - training loss: 181180.7581, validation loss: 2.0849
2024-06-03 12:49:22 [INFO]: Epoch 028 - training loss: 181164.5162, validation loss: 2.0323
2024-06-03 12:49:33 [INFO]: Epoch 029 - training loss: 181141.7425, validation loss: 2.0527
2024-06-03 12:49:44 [INFO]: Epoch 030 - training loss: 181151.0417, validation loss: 2.0629
2024-06-03 12:49:56 [INFO]: Epoch 031 - training loss: 181154.6615, validation loss: 2.0426
2024-06-03 12:50:08 [INFO]: Epoch 032 - training loss: 181125.3339, validation loss: 2.0195
2024-06-03 12:50:21 [INFO]: Epoch 033 - training loss: 181107.1771, validation loss: 2.0336
2024-06-03 12:50:33 [INFO]: Epoch 034 - training loss: 181108.2135, validation loss: 2.0406
2024-06-03 12:50:45 [INFO]: Epoch 035 - training loss: 181090.9983, validation loss: 2.0320
2024-06-03 12:50:57 [INFO]: Epoch 036 - training loss: 181079.1157, validation loss: 2.0390
2024-06-03 12:51:08 [INFO]: Epoch 037 - training loss: 181088.8536, validation loss: 2.0204
2024-06-03 12:51:20 [INFO]: Epoch 038 - training loss: 181058.8611, validation loss: 2.0006
2024-06-03 12:51:31 [INFO]: Epoch 039 - training loss: 181052.2951, validation loss: 1.9762
2024-06-03 12:51:42 [INFO]: Epoch 040 - training loss: 181042.6881, validation loss: 2.0005
2024-06-03 12:51:53 [INFO]: Epoch 041 - training loss: 181042.7512, validation loss: 2.0031
2024-06-03 12:52:04 [INFO]: Epoch 042 - training loss: 181032.3825, validation loss: 2.0163
2024-06-03 12:52:15 [INFO]: Epoch 043 - training loss: 181019.3883, validation loss: 2.0096
2024-06-03 12:52:27 [INFO]: Epoch 044 - training loss: 181017.7622, validation loss: 2.0053
2024-06-03 12:52:38 [INFO]: Epoch 045 - training loss: 181003.8779, validation loss: 2.0129
2024-06-03 12:52:49 [INFO]: Epoch 046 - training loss: 180992.5943, validation loss: 2.0213
2024-06-03 12:53:00 [INFO]: Epoch 047 - training loss: 180993.1001, validation loss: 2.0100
2024-06-03 12:53:11 [INFO]: Epoch 048 - training loss: 180984.1256, validation loss: 1.9961
2024-06-03 12:53:22 [INFO]: Epoch 049 - training loss: 180974.4207, validation loss: 1.9830
2024-06-03 12:53:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:53:22 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 12:53:22 [INFO]: Saved the model to results_block_rate05/Electricity/GPVAE_Electricity/round_2/20240603_T124416/GPVAE.pypots
2024-06-03 12:54:58 [INFO]: Successfully saved to results_block_rate05/Electricity/GPVAE_Electricity/round_2/imputation.pkl
2024-06-03 12:54:58 [INFO]: Round2 - GPVAE on Electricity: MAE=1.2553, MSE=3.5018, MRE=0.6738
2024-06-03 12:54:58 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 12:54:58 [INFO]: Using the given device: cuda:0
2024-06-03 12:54:58 [INFO]: Model files will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_3/20240603_T125458
2024-06-03 12:54:58 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_3/20240603_T125458/tensorboard
2024-06-03 12:54:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 12:55:07 [INFO]: Epoch 001 - training loss: 213718.4381, validation loss: 2.4703
2024-06-03 12:55:14 [INFO]: Epoch 002 - training loss: 184301.4392, validation loss: 2.2424
2024-06-03 12:55:23 [INFO]: Epoch 003 - training loss: 182712.9184, validation loss: 2.1997
2024-06-03 12:55:31 [INFO]: Epoch 004 - training loss: 182300.4444, validation loss: 2.1709
2024-06-03 12:55:39 [INFO]: Epoch 005 - training loss: 182025.6458, validation loss: 2.1911
2024-06-03 12:55:47 [INFO]: Epoch 006 - training loss: 181875.3079, validation loss: 2.1553
2024-06-03 12:55:55 [INFO]: Epoch 007 - training loss: 181783.6852, validation loss: 2.1437
2024-06-03 12:56:03 [INFO]: Epoch 008 - training loss: 181696.8744, validation loss: 2.1083
2024-06-03 12:56:11 [INFO]: Epoch 009 - training loss: 181649.2234, validation loss: 2.1009
2024-06-03 12:56:19 [INFO]: Epoch 010 - training loss: 181579.2523, validation loss: 2.1057
2024-06-03 12:56:27 [INFO]: Epoch 011 - training loss: 181550.9826, validation loss: 2.1083
2024-06-03 12:56:36 [INFO]: Epoch 012 - training loss: 181506.8819, validation loss: 2.0704
2024-06-03 12:56:45 [INFO]: Epoch 013 - training loss: 181448.5706, validation loss: 2.0876
2024-06-03 12:56:53 [INFO]: Epoch 014 - training loss: 181390.2876, validation loss: 2.1235
2024-06-03 12:57:01 [INFO]: Epoch 015 - training loss: 181367.5648, validation loss: 2.0944
2024-06-03 12:57:09 [INFO]: Epoch 016 - training loss: 181331.7054, validation loss: 2.0943
2024-06-03 12:57:17 [INFO]: Epoch 017 - training loss: 181292.1655, validation loss: 2.0910
2024-06-03 12:57:24 [INFO]: Epoch 018 - training loss: 181272.1233, validation loss: 2.0859
2024-06-03 12:57:32 [INFO]: Epoch 019 - training loss: 181271.6105, validation loss: 2.0979
2024-06-03 12:57:40 [INFO]: Epoch 020 - training loss: 181230.6458, validation loss: 2.0825
2024-06-03 12:57:49 [INFO]: Epoch 021 - training loss: 181227.3791, validation loss: 2.0621
2024-06-03 12:57:57 [INFO]: Epoch 022 - training loss: 181206.5903, validation loss: 2.0630
2024-06-03 12:58:05 [INFO]: Epoch 023 - training loss: 181193.9514, validation loss: 2.0780
2024-06-03 12:58:13 [INFO]: Epoch 024 - training loss: 181175.9740, validation loss: 2.0500
2024-06-03 12:58:21 [INFO]: Epoch 025 - training loss: 181159.4803, validation loss: 2.0346
2024-06-03 12:58:27 [INFO]: Epoch 026 - training loss: 181161.5191, validation loss: 2.1108
2024-06-03 12:58:32 [INFO]: Epoch 027 - training loss: 181152.1013, validation loss: 2.0887
2024-06-03 12:58:36 [INFO]: Epoch 028 - training loss: 181115.9907, validation loss: 2.0724
2024-06-03 12:58:40 [INFO]: Epoch 029 - training loss: 181097.0804, validation loss: 2.0789
2024-06-03 12:58:43 [INFO]: Epoch 030 - training loss: 181102.1424, validation loss: 2.0401
2024-06-03 12:58:47 [INFO]: Epoch 031 - training loss: 181097.6719, validation loss: 2.0653
2024-06-03 12:58:51 [INFO]: Epoch 032 - training loss: 181068.5122, validation loss: 2.0426
2024-06-03 12:58:55 [INFO]: Epoch 033 - training loss: 181053.6944, validation loss: 2.0593
2024-06-03 12:58:59 [INFO]: Epoch 034 - training loss: 181043.8634, validation loss: 2.0650
2024-06-03 12:59:03 [INFO]: Epoch 035 - training loss: 181042.4028, validation loss: 2.0699
2024-06-03 12:59:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:59:03 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 12:59:03 [INFO]: Saved the model to results_block_rate05/Electricity/GPVAE_Electricity/round_3/20240603_T125458/GPVAE.pypots
2024-06-03 12:59:44 [INFO]: Successfully saved to results_block_rate05/Electricity/GPVAE_Electricity/round_3/imputation.pkl
2024-06-03 12:59:44 [INFO]: Round3 - GPVAE on Electricity: MAE=1.3073, MSE=3.6776, MRE=0.7017
2024-06-03 12:59:44 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:59:44 [INFO]: Using the given device: cuda:0
2024-06-03 12:59:44 [INFO]: Model files will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_4/20240603_T125944
2024-06-03 12:59:44 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/GPVAE_Electricity/round_4/20240603_T125944/tensorboard
2024-06-03 12:59:44 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,825,022
2024-06-03 12:59:48 [INFO]: Epoch 001 - training loss: 211533.2512, validation loss: 2.3981
2024-06-03 12:59:52 [INFO]: Epoch 002 - training loss: 185139.0503, validation loss: 2.2830
2024-06-03 12:59:55 [INFO]: Epoch 003 - training loss: 182924.6238, validation loss: 2.2674
2024-06-03 12:59:59 [INFO]: Epoch 004 - training loss: 182368.7500, validation loss: 2.2489
2024-06-03 13:00:03 [INFO]: Epoch 005 - training loss: 182106.1389, validation loss: 2.2265
2024-06-03 13:00:07 [INFO]: Epoch 006 - training loss: 181932.1285, validation loss: 2.2346
2024-06-03 13:00:10 [INFO]: Epoch 007 - training loss: 181882.5683, validation loss: 2.1672
2024-06-03 13:00:14 [INFO]: Epoch 008 - training loss: 181749.7824, validation loss: 2.1937
2024-06-03 13:00:18 [INFO]: Epoch 009 - training loss: 181696.6256, validation loss: 2.1162
2024-06-03 13:00:21 [INFO]: Epoch 010 - training loss: 181613.9491, validation loss: 2.1128
2024-06-03 13:00:25 [INFO]: Epoch 011 - training loss: 181556.7870, validation loss: 2.1378
2024-06-03 13:00:29 [INFO]: Epoch 012 - training loss: 181537.7986, validation loss: 2.1371
2024-06-03 13:00:32 [INFO]: Epoch 013 - training loss: 181492.1701, validation loss: 2.1495
2024-06-03 13:00:36 [INFO]: Epoch 014 - training loss: 181474.4630, validation loss: 2.1057
2024-06-03 13:00:40 [INFO]: Epoch 015 - training loss: 181418.6852, validation loss: 2.1071
2024-06-03 13:00:43 [INFO]: Epoch 016 - training loss: 181383.2969, validation loss: 2.0950
2024-06-03 13:00:47 [INFO]: Epoch 017 - training loss: 181354.8345, validation loss: 2.0903
2024-06-03 13:00:51 [INFO]: Epoch 018 - training loss: 181350.5723, validation loss: 2.0963
2024-06-03 13:00:54 [INFO]: Epoch 019 - training loss: 181320.9832, validation loss: 2.1284
2024-06-03 13:00:58 [INFO]: Epoch 020 - training loss: 181308.1383, validation loss: 2.1398
2024-06-03 13:01:02 [INFO]: Epoch 021 - training loss: 181298.8657, validation loss: 2.1042
2024-06-03 13:01:06 [INFO]: Epoch 022 - training loss: 181248.7135, validation loss: 2.0922
2024-06-03 13:01:09 [INFO]: Epoch 023 - training loss: 181225.1481, validation loss: 2.0866
2024-06-03 13:01:13 [INFO]: Epoch 024 - training loss: 181193.3825, validation loss: 2.0794
2024-06-03 13:01:17 [INFO]: Epoch 025 - training loss: 181185.8299, validation loss: 2.1012
2024-06-03 13:01:20 [INFO]: Epoch 026 - training loss: 181160.3148, validation loss: 2.0975
2024-06-03 13:01:24 [INFO]: Epoch 027 - training loss: 181156.3704, validation loss: 2.1046
2024-06-03 13:01:28 [INFO]: Epoch 028 - training loss: 181131.8299, validation loss: 2.0785
2024-06-03 13:01:31 [INFO]: Epoch 029 - training loss: 181134.6383, validation loss: 2.0827
2024-06-03 13:01:35 [INFO]: Epoch 030 - training loss: 181121.6696, validation loss: 2.1346
2024-06-03 13:01:39 [INFO]: Epoch 031 - training loss: 181107.4346, validation loss: 2.0945
2024-06-03 13:01:42 [INFO]: Epoch 032 - training loss: 181110.1094, validation loss: 2.1002
2024-06-03 13:01:46 [INFO]: Epoch 033 - training loss: 181106.0480, validation loss: 2.0852
2024-06-03 13:01:50 [INFO]: Epoch 034 - training loss: 181085.3872, validation loss: 2.0872
2024-06-03 13:01:53 [INFO]: Epoch 035 - training loss: 181066.6603, validation loss: 2.0913
2024-06-03 13:01:57 [INFO]: Epoch 036 - training loss: 181074.5752, validation loss: 2.0637
2024-06-03 13:02:01 [INFO]: Epoch 037 - training loss: 181053.6626, validation loss: 2.0918
2024-06-03 13:02:05 [INFO]: Epoch 038 - training loss: 181048.7685, validation loss: 2.0884
2024-06-03 13:02:08 [INFO]: Epoch 039 - training loss: 181050.6759, validation loss: 2.1260
2024-06-03 13:02:12 [INFO]: Epoch 040 - training loss: 181044.2714, validation loss: 2.0949
2024-06-03 13:02:16 [INFO]: Epoch 041 - training loss: 181025.6707, validation loss: 2.1209
2024-06-03 13:02:19 [INFO]: Epoch 042 - training loss: 181028.5839, validation loss: 2.0970
2024-06-03 13:02:23 [INFO]: Epoch 043 - training loss: 181005.2882, validation loss: 2.0795
2024-06-03 13:02:27 [INFO]: Epoch 044 - training loss: 180989.1424, validation loss: 2.0641
2024-06-03 13:02:30 [INFO]: Epoch 045 - training loss: 180981.5174, validation loss: 2.0670
2024-06-03 13:02:34 [INFO]: Epoch 046 - training loss: 180973.2309, validation loss: 2.0747
2024-06-03 13:02:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:02:34 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 13:02:34 [INFO]: Saved the model to results_block_rate05/Electricity/GPVAE_Electricity/round_4/20240603_T125944/GPVAE.pypots
2024-06-03 13:03:15 [INFO]: Successfully saved to results_block_rate05/Electricity/GPVAE_Electricity/round_4/imputation.pkl
2024-06-03 13:03:15 [INFO]: Round4 - GPVAE on Electricity: MAE=1.3065, MSE=3.6286, MRE=0.7013
2024-06-03 13:03:15 [INFO]: Done! Final results:
Averaged GPVAE (1,825,022 params) on Electricity: MAE=1.3075 ± 0.032533482255858316, MSE=3.6366 ± 0.07137757585789392, MRE=0.7018 ± 0.017462342717416937, average inference time=19.60
