2024-06-03 12:15:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:15:13 [INFO]: Using the given device: cuda:0
2024-06-03 12:15:13 [INFO]: Model files will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_0/20240603_T121513
2024-06-03 12:15:13 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_0/20240603_T121513/tensorboard
2024-06-03 12:15:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-03 12:24:52 [INFO]: Epoch 001 - training loss: 1.0666, validation loss: 2.3414
2024-06-03 12:34:31 [INFO]: Epoch 002 - training loss: 0.7316, validation loss: 2.1746
2024-06-03 12:41:22 [INFO]: Epoch 003 - training loss: 0.6481, validation loss: 2.0636
2024-06-03 12:47:15 [INFO]: Epoch 004 - training loss: 0.6033, validation loss: 2.0021
2024-06-03 12:53:06 [INFO]: Epoch 005 - training loss: 0.5735, validation loss: 1.9708
2024-06-03 12:58:45 [INFO]: Epoch 006 - training loss: 0.5520, validation loss: 1.9545
2024-06-03 13:04:38 [INFO]: Epoch 007 - training loss: 0.5357, validation loss: 1.9358
2024-06-03 13:10:18 [INFO]: Epoch 008 - training loss: 0.5228, validation loss: 1.9351
2024-06-03 13:12:59 [INFO]: Epoch 009 - training loss: 0.5110, validation loss: 1.9239
2024-06-03 13:15:23 [INFO]: Epoch 010 - training loss: 0.5018, validation loss: 1.9067
2024-06-03 13:17:48 [INFO]: Epoch 011 - training loss: 0.4926, validation loss: 1.9076
2024-06-03 13:20:03 [INFO]: Epoch 012 - training loss: 0.4844, validation loss: 1.9010
2024-06-03 13:22:16 [INFO]: Epoch 013 - training loss: 0.4771, validation loss: 1.8935
2024-06-03 13:24:28 [INFO]: Epoch 014 - training loss: 0.4714, validation loss: 1.8876
2024-06-03 13:26:45 [INFO]: Epoch 015 - training loss: 0.4658, validation loss: 1.8834
2024-06-03 13:29:08 [INFO]: Epoch 016 - training loss: 0.4601, validation loss: 1.8745
2024-06-03 13:31:33 [INFO]: Epoch 017 - training loss: 0.4559, validation loss: 1.8705
2024-06-03 13:33:56 [INFO]: Epoch 018 - training loss: 0.4508, validation loss: 1.8696
2024-06-03 13:36:21 [INFO]: Epoch 019 - training loss: 0.4468, validation loss: 1.8626
2024-06-03 13:38:46 [INFO]: Epoch 020 - training loss: 0.4418, validation loss: 1.8585
2024-06-03 13:41:03 [INFO]: Epoch 021 - training loss: 0.4376, validation loss: 1.8547
2024-06-03 13:43:17 [INFO]: Epoch 022 - training loss: 0.4340, validation loss: 1.8524
2024-06-03 13:45:30 [INFO]: Epoch 023 - training loss: 0.4299, validation loss: 1.8504
2024-06-03 13:47:47 [INFO]: Epoch 024 - training loss: 0.4269, validation loss: 1.8495
2024-06-03 13:50:09 [INFO]: Epoch 025 - training loss: 0.4249, validation loss: 1.8388
2024-06-03 13:52:34 [INFO]: Epoch 026 - training loss: 0.4215, validation loss: 1.8395
2024-06-03 13:54:58 [INFO]: Epoch 027 - training loss: 0.4183, validation loss: 1.8414
2024-06-03 13:57:22 [INFO]: Epoch 028 - training loss: 0.4162, validation loss: 1.8332
2024-06-03 13:59:47 [INFO]: Epoch 029 - training loss: 0.4144, validation loss: 1.8386
2024-06-03 14:02:04 [INFO]: Epoch 030 - training loss: 0.4116, validation loss: 1.8263
2024-06-03 14:04:18 [INFO]: Epoch 031 - training loss: 0.4092, validation loss: 1.8266
2024-06-03 14:06:30 [INFO]: Epoch 032 - training loss: 0.4078, validation loss: 1.8278
2024-06-03 14:08:44 [INFO]: Epoch 033 - training loss: 0.4045, validation loss: 1.8279
2024-06-03 14:11:04 [INFO]: Epoch 034 - training loss: 0.4023, validation loss: 1.8202
2024-06-03 14:13:28 [INFO]: Epoch 035 - training loss: 0.4008, validation loss: 1.8206
2024-06-03 14:15:53 [INFO]: Epoch 036 - training loss: 0.3992, validation loss: 1.8223
2024-06-03 14:18:18 [INFO]: Epoch 037 - training loss: 0.3968, validation loss: 1.8194
2024-06-03 14:20:43 [INFO]: Epoch 038 - training loss: 0.3946, validation loss: 1.8190
2024-06-03 14:23:03 [INFO]: Epoch 039 - training loss: 0.3939, validation loss: 1.8159
2024-06-03 14:25:17 [INFO]: Epoch 040 - training loss: 0.3927, validation loss: 1.8195
2024-06-03 14:27:30 [INFO]: Epoch 041 - training loss: 0.3905, validation loss: 1.8133
2024-06-03 14:29:42 [INFO]: Epoch 042 - training loss: 0.3896, validation loss: 1.8088
2024-06-03 14:32:01 [INFO]: Epoch 043 - training loss: 0.3878, validation loss: 1.8182
2024-06-03 14:34:24 [INFO]: Epoch 044 - training loss: 0.3859, validation loss: 1.8104
2024-06-03 14:36:48 [INFO]: Epoch 045 - training loss: 0.3849, validation loss: 1.8040
2024-06-03 14:39:12 [INFO]: Epoch 046 - training loss: 0.3834, validation loss: 1.8052
2024-06-03 14:41:36 [INFO]: Epoch 047 - training loss: 0.3828, validation loss: 1.8029
2024-06-03 14:43:59 [INFO]: Epoch 048 - training loss: 0.3840, validation loss: 1.8043
2024-06-03 14:46:15 [INFO]: Epoch 049 - training loss: 0.3817, validation loss: 1.8065
2024-06-03 14:48:28 [INFO]: Epoch 050 - training loss: 0.3798, validation loss: 1.8031
2024-06-03 14:50:41 [INFO]: Epoch 051 - training loss: 0.3780, validation loss: 1.8074
2024-06-03 14:52:58 [INFO]: Epoch 052 - training loss: 0.3768, validation loss: 1.8015
2024-06-03 14:55:18 [INFO]: Epoch 053 - training loss: 0.3754, validation loss: 1.7971
2024-06-03 14:57:43 [INFO]: Epoch 054 - training loss: 0.3755, validation loss: 1.8002
2024-06-03 15:00:07 [INFO]: Epoch 055 - training loss: 0.3741, validation loss: 1.7978
2024-06-03 15:02:32 [INFO]: Epoch 056 - training loss: 0.3727, validation loss: 1.7998
2024-06-03 15:04:57 [INFO]: Epoch 057 - training loss: 0.3719, validation loss: 1.7986
2024-06-03 15:07:15 [INFO]: Epoch 058 - training loss: 0.3706, validation loss: 1.8004
2024-06-03 15:09:28 [INFO]: Epoch 059 - training loss: 0.3696, validation loss: 1.7952
2024-06-03 15:11:41 [INFO]: Epoch 060 - training loss: 0.3681, validation loss: 1.7955
2024-06-03 15:13:57 [INFO]: Epoch 061 - training loss: 0.3683, validation loss: 1.7915
2024-06-03 15:16:18 [INFO]: Epoch 062 - training loss: 0.3689, validation loss: 1.7958
2024-06-03 15:18:42 [INFO]: Epoch 063 - training loss: 0.3680, validation loss: 1.7977
2024-06-03 15:21:06 [INFO]: Epoch 064 - training loss: 0.3678, validation loss: 1.7951
2024-06-03 15:23:30 [INFO]: Epoch 065 - training loss: 0.3664, validation loss: 1.7942
2024-06-03 15:25:53 [INFO]: Epoch 066 - training loss: 0.3651, validation loss: 1.7957
2024-06-03 15:28:14 [INFO]: Epoch 067 - training loss: 0.3643, validation loss: 1.7909
2024-06-03 15:30:27 [INFO]: Epoch 068 - training loss: 0.3629, validation loss: 1.7907
2024-06-03 15:32:40 [INFO]: Epoch 069 - training loss: 0.3617, validation loss: 1.7925
2024-06-03 15:34:53 [INFO]: Epoch 070 - training loss: 0.3625, validation loss: 1.7904
2024-06-03 15:37:12 [INFO]: Epoch 071 - training loss: 0.3616, validation loss: 1.7941
2024-06-03 15:39:35 [INFO]: Epoch 072 - training loss: 0.3615, validation loss: 1.7954
2024-06-03 15:41:59 [INFO]: Epoch 073 - training loss: 0.3610, validation loss: 1.7920
2024-06-03 15:44:23 [INFO]: Epoch 074 - training loss: 0.3603, validation loss: 1.7945
2024-06-03 15:46:47 [INFO]: Epoch 075 - training loss: 0.3598, validation loss: 1.7926
2024-06-03 15:49:12 [INFO]: Epoch 076 - training loss: 0.3585, validation loss: 1.7915
2024-06-03 15:51:26 [INFO]: Epoch 077 - training loss: 0.3570, validation loss: 1.7894
2024-06-03 15:53:39 [INFO]: Epoch 078 - training loss: 0.3559, validation loss: 1.7892
2024-06-03 15:56:15 [INFO]: Epoch 079 - training loss: 0.3551, validation loss: 1.7896
2024-06-03 15:58:59 [INFO]: Epoch 080 - training loss: 0.3551, validation loss: 1.7885
2024-06-03 16:01:42 [INFO]: Epoch 081 - training loss: 0.3546, validation loss: 1.7907
2024-06-03 16:04:26 [INFO]: Epoch 082 - training loss: 0.3541, validation loss: 1.7893
2024-06-03 16:07:09 [INFO]: Epoch 083 - training loss: 0.3540, validation loss: 1.7874
2024-06-03 16:09:53 [INFO]: Epoch 084 - training loss: 0.3534, validation loss: 1.7876
2024-06-03 16:12:35 [INFO]: Epoch 085 - training loss: 0.3534, validation loss: 1.7895
2024-06-03 16:15:14 [INFO]: Epoch 086 - training loss: 0.3531, validation loss: 1.7901
2024-06-03 16:17:58 [INFO]: Epoch 087 - training loss: 0.3526, validation loss: 1.7883
2024-06-03 16:20:41 [INFO]: Epoch 088 - training loss: 0.3513, validation loss: 1.7902
2024-06-03 16:23:25 [INFO]: Epoch 089 - training loss: 0.3510, validation loss: 1.7914
2024-06-03 16:26:08 [INFO]: Epoch 090 - training loss: 0.3509, validation loss: 1.7890
2024-06-03 16:28:51 [INFO]: Epoch 091 - training loss: 0.3502, validation loss: 1.7893
2024-06-03 16:31:34 [INFO]: Epoch 092 - training loss: 0.3509, validation loss: 1.7918
2024-06-03 16:34:18 [INFO]: Epoch 093 - training loss: 0.3500, validation loss: 1.7885
2024-06-03 16:34:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 16:34:18 [INFO]: Finished training. The best model is from epoch#83.
2024-06-03 16:34:18 [INFO]: Saved the model to results_block_rate05/Electricity/BRITS_Electricity/round_0/20240603_T121513/BRITS.pypots
2024-06-03 16:37:44 [INFO]: Successfully saved to results_block_rate05/Electricity/BRITS_Electricity/round_0/imputation.pkl
2024-06-03 16:37:44 [INFO]: Round0 - BRITS on Electricity: MAE=1.1152, MSE=3.0861, MRE=0.5986
2024-06-03 16:37:44 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 16:37:44 [INFO]: Using the given device: cuda:0
2024-06-03 16:37:44 [INFO]: Model files will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_1/20240603_T163744
2024-06-03 16:37:44 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_1/20240603_T163744/tensorboard
2024-06-03 16:37:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-03 16:40:31 [INFO]: Epoch 001 - training loss: 1.0551, validation loss: 2.3365
2024-06-03 16:43:15 [INFO]: Epoch 002 - training loss: 0.7225, validation loss: 2.1707
2024-06-03 16:45:58 [INFO]: Epoch 003 - training loss: 0.6419, validation loss: 2.0526
2024-06-03 16:48:42 [INFO]: Epoch 004 - training loss: 0.5993, validation loss: 1.9963
2024-06-03 16:51:25 [INFO]: Epoch 005 - training loss: 0.5705, validation loss: 1.9687
2024-06-03 16:54:09 [INFO]: Epoch 006 - training loss: 0.5495, validation loss: 1.9510
2024-06-03 16:56:52 [INFO]: Epoch 007 - training loss: 0.5332, validation loss: 1.9394
2024-06-03 16:59:36 [INFO]: Epoch 008 - training loss: 0.5205, validation loss: 1.9260
2024-06-03 17:02:11 [INFO]: Epoch 009 - training loss: 0.5085, validation loss: 1.9184
2024-06-03 17:04:54 [INFO]: Epoch 010 - training loss: 0.4987, validation loss: 1.9077
2024-06-03 17:07:38 [INFO]: Epoch 011 - training loss: 0.4912, validation loss: 1.8992
2024-06-03 17:10:21 [INFO]: Epoch 012 - training loss: 0.4829, validation loss: 1.8899
2024-06-03 17:13:05 [INFO]: Epoch 013 - training loss: 0.4767, validation loss: 1.8865
2024-06-03 17:15:48 [INFO]: Epoch 014 - training loss: 0.4696, validation loss: 1.8784
2024-06-03 17:18:09 [INFO]: Epoch 015 - training loss: 0.4633, validation loss: 1.8702
2024-06-03 17:20:22 [INFO]: Epoch 016 - training loss: 0.4583, validation loss: 1.8680
2024-06-03 17:22:35 [INFO]: Epoch 017 - training loss: 0.4537, validation loss: 1.8613
2024-06-03 17:24:51 [INFO]: Epoch 018 - training loss: 0.4498, validation loss: 1.8586
2024-06-03 17:27:13 [INFO]: Epoch 019 - training loss: 0.4448, validation loss: 1.8543
2024-06-03 17:29:37 [INFO]: Epoch 020 - training loss: 0.4398, validation loss: 1.8512
2024-06-03 17:32:01 [INFO]: Epoch 021 - training loss: 0.4367, validation loss: 1.8450
2024-06-03 17:34:26 [INFO]: Epoch 022 - training loss: 0.4335, validation loss: 1.8382
2024-06-03 17:36:51 [INFO]: Epoch 023 - training loss: 0.4297, validation loss: 1.8364
2024-06-03 17:39:10 [INFO]: Epoch 024 - training loss: 0.4260, validation loss: 1.8378
2024-06-03 17:41:23 [INFO]: Epoch 025 - training loss: 0.4228, validation loss: 1.8318
2024-06-03 17:43:36 [INFO]: Epoch 026 - training loss: 0.4202, validation loss: 1.8278
2024-06-03 17:45:53 [INFO]: Epoch 027 - training loss: 0.4184, validation loss: 1.8233
2024-06-03 17:48:15 [INFO]: Epoch 028 - training loss: 0.4161, validation loss: 1.8200
2024-06-03 17:50:39 [INFO]: Epoch 029 - training loss: 0.4125, validation loss: 1.8186
2024-06-03 17:53:01 [INFO]: Epoch 030 - training loss: 0.4096, validation loss: 1.8159
2024-06-03 17:55:26 [INFO]: Epoch 031 - training loss: 0.4076, validation loss: 1.8144
2024-06-03 17:57:52 [INFO]: Epoch 032 - training loss: 0.4056, validation loss: 1.8158
2024-06-03 18:00:10 [INFO]: Epoch 033 - training loss: 0.4027, validation loss: 1.8106
2024-06-03 18:02:24 [INFO]: Epoch 034 - training loss: 0.4004, validation loss: 1.8076
2024-06-03 18:04:37 [INFO]: Epoch 035 - training loss: 0.3997, validation loss: 1.8065
2024-06-03 18:06:50 [INFO]: Epoch 036 - training loss: 0.3988, validation loss: 1.8084
2024-06-03 18:09:11 [INFO]: Epoch 037 - training loss: 0.3958, validation loss: 1.8036
2024-06-03 18:11:35 [INFO]: Epoch 038 - training loss: 0.3944, validation loss: 1.8078
2024-06-03 18:14:00 [INFO]: Epoch 039 - training loss: 0.3927, validation loss: 1.8070
2024-06-03 18:16:24 [INFO]: Epoch 040 - training loss: 0.3936, validation loss: 1.8047
2024-06-03 18:18:49 [INFO]: Epoch 041 - training loss: 0.3901, validation loss: 1.8018
2024-06-03 18:21:10 [INFO]: Epoch 042 - training loss: 0.3877, validation loss: 1.8009
2024-06-03 18:23:25 [INFO]: Epoch 043 - training loss: 0.3861, validation loss: 1.8012
2024-06-03 18:25:37 [INFO]: Epoch 044 - training loss: 0.3846, validation loss: 1.8002
2024-06-03 18:27:50 [INFO]: Epoch 045 - training loss: 0.3835, validation loss: 1.7929
2024-06-03 18:30:10 [INFO]: Epoch 046 - training loss: 0.3822, validation loss: 1.7975
2024-06-03 18:32:32 [INFO]: Epoch 047 - training loss: 0.3815, validation loss: 1.7944
2024-06-03 18:34:56 [INFO]: Epoch 048 - training loss: 0.3807, validation loss: 1.7952
2024-06-03 18:37:22 [INFO]: Epoch 049 - training loss: 0.3798, validation loss: 1.7955
2024-06-03 18:39:47 [INFO]: Epoch 050 - training loss: 0.3791, validation loss: 1.7928
2024-06-03 18:42:11 [INFO]: Epoch 051 - training loss: 0.3779, validation loss: 1.7934
2024-06-03 18:44:24 [INFO]: Epoch 052 - training loss: 0.3760, validation loss: 1.7985
2024-06-03 18:46:37 [INFO]: Epoch 053 - training loss: 0.3755, validation loss: 1.7937
2024-06-03 18:48:49 [INFO]: Epoch 054 - training loss: 0.3747, validation loss: 1.7909
2024-06-03 18:51:06 [INFO]: Epoch 055 - training loss: 0.3734, validation loss: 1.7915
2024-06-03 18:53:28 [INFO]: Epoch 056 - training loss: 0.3721, validation loss: 1.7904
2024-06-03 18:55:53 [INFO]: Epoch 057 - training loss: 0.3707, validation loss: 1.7913
2024-06-03 18:58:17 [INFO]: Epoch 058 - training loss: 0.3699, validation loss: 1.7896
2024-06-03 19:00:43 [INFO]: Epoch 059 - training loss: 0.3689, validation loss: 1.7913
2024-06-03 19:03:08 [INFO]: Epoch 060 - training loss: 0.3681, validation loss: 1.7924
2024-06-03 19:05:25 [INFO]: Epoch 061 - training loss: 0.3672, validation loss: 1.7864
2024-06-03 19:07:38 [INFO]: Epoch 062 - training loss: 0.3667, validation loss: 1.7903
2024-06-03 19:09:51 [INFO]: Epoch 063 - training loss: 0.3657, validation loss: 1.7900
2024-06-03 19:12:08 [INFO]: Epoch 064 - training loss: 0.3664, validation loss: 1.7911
2024-06-03 19:14:30 [INFO]: Epoch 065 - training loss: 0.3656, validation loss: 1.7936
2024-06-03 19:16:55 [INFO]: Epoch 066 - training loss: 0.3650, validation loss: 1.7898
2024-06-03 19:19:21 [INFO]: Epoch 067 - training loss: 0.3642, validation loss: 1.7876
2024-06-03 19:21:46 [INFO]: Epoch 068 - training loss: 0.3631, validation loss: 1.7909
2024-06-03 19:24:11 [INFO]: Epoch 069 - training loss: 0.3615, validation loss: 1.7877
2024-06-03 19:26:27 [INFO]: Epoch 070 - training loss: 0.3605, validation loss: 1.7871
2024-06-03 19:28:41 [INFO]: Epoch 071 - training loss: 0.3611, validation loss: 1.7900
2024-06-03 19:28:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:28:41 [INFO]: Finished training. The best model is from epoch#61.
2024-06-03 19:28:41 [INFO]: Saved the model to results_block_rate05/Electricity/BRITS_Electricity/round_1/20240603_T163744/BRITS.pypots
2024-06-03 19:31:34 [INFO]: Successfully saved to results_block_rate05/Electricity/BRITS_Electricity/round_1/imputation.pkl
2024-06-03 19:31:34 [INFO]: Round1 - BRITS on Electricity: MAE=1.1173, MSE=3.0798, MRE=0.5997
2024-06-03 19:31:34 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 19:31:34 [INFO]: Using the given device: cuda:0
2024-06-03 19:31:34 [INFO]: Model files will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_2/20240603_T193134
2024-06-03 19:31:34 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_2/20240603_T193134/tensorboard
2024-06-03 19:31:34 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-03 19:34:03 [INFO]: Epoch 001 - training loss: 1.0587, validation loss: 2.3449
2024-06-03 19:36:29 [INFO]: Epoch 002 - training loss: 0.7297, validation loss: 2.1730
2024-06-03 19:38:52 [INFO]: Epoch 003 - training loss: 0.6474, validation loss: 2.0573
2024-06-03 19:41:07 [INFO]: Epoch 004 - training loss: 0.6030, validation loss: 1.9997
2024-06-03 19:43:19 [INFO]: Epoch 005 - training loss: 0.5729, validation loss: 1.9694
2024-06-03 19:45:31 [INFO]: Epoch 006 - training loss: 0.5507, validation loss: 1.9510
2024-06-03 19:47:50 [INFO]: Epoch 007 - training loss: 0.5340, validation loss: 1.9380
2024-06-03 19:50:14 [INFO]: Epoch 008 - training loss: 0.5207, validation loss: 1.9277
2024-06-03 19:52:39 [INFO]: Epoch 009 - training loss: 0.5104, validation loss: 1.9184
2024-06-03 19:55:05 [INFO]: Epoch 010 - training loss: 0.4996, validation loss: 1.9082
2024-06-03 19:57:30 [INFO]: Epoch 011 - training loss: 0.4917, validation loss: 1.9025
2024-06-03 19:59:54 [INFO]: Epoch 012 - training loss: 0.4835, validation loss: 1.9001
2024-06-03 20:02:08 [INFO]: Epoch 013 - training loss: 0.4769, validation loss: 1.8901
2024-06-03 20:04:21 [INFO]: Epoch 014 - training loss: 0.4698, validation loss: 1.8900
2024-06-03 20:06:32 [INFO]: Epoch 015 - training loss: 0.4640, validation loss: 1.8790
2024-06-03 20:08:52 [INFO]: Epoch 016 - training loss: 0.4582, validation loss: 1.8795
2024-06-03 20:11:14 [INFO]: Epoch 017 - training loss: 0.4540, validation loss: 1.8759
2024-06-03 20:13:39 [INFO]: Epoch 018 - training loss: 0.4498, validation loss: 1.8719
2024-06-03 20:16:04 [INFO]: Epoch 019 - training loss: 0.4446, validation loss: 1.8662
2024-06-03 20:18:30 [INFO]: Epoch 020 - training loss: 0.4417, validation loss: 1.8679
2024-06-03 20:20:54 [INFO]: Epoch 021 - training loss: 0.4384, validation loss: 1.8600
2024-06-03 20:23:09 [INFO]: Epoch 022 - training loss: 0.4341, validation loss: 1.8565
2024-06-03 20:25:21 [INFO]: Epoch 023 - training loss: 0.4324, validation loss: 1.8513
2024-06-03 20:27:33 [INFO]: Epoch 024 - training loss: 0.4274, validation loss: 1.8515
2024-06-03 20:29:49 [INFO]: Epoch 025 - training loss: 0.4236, validation loss: 1.8455
2024-06-03 20:32:11 [INFO]: Epoch 026 - training loss: 0.4202, validation loss: 1.8457
2024-06-03 20:34:35 [INFO]: Epoch 027 - training loss: 0.4186, validation loss: 1.8357
2024-06-03 20:37:00 [INFO]: Epoch 028 - training loss: 0.4148, validation loss: 1.8365
2024-06-03 20:39:25 [INFO]: Epoch 029 - training loss: 0.4121, validation loss: 1.8330
2024-06-03 20:41:49 [INFO]: Epoch 030 - training loss: 0.4098, validation loss: 1.8280
2024-06-03 20:44:07 [INFO]: Epoch 031 - training loss: 0.4080, validation loss: 1.8256
2024-06-03 20:46:20 [INFO]: Epoch 032 - training loss: 0.4060, validation loss: 1.8226
2024-06-03 20:48:54 [INFO]: Epoch 033 - training loss: 0.4037, validation loss: 1.8237
2024-06-03 20:51:37 [INFO]: Epoch 034 - training loss: 0.4024, validation loss: 1.8212
2024-06-03 20:54:20 [INFO]: Epoch 035 - training loss: 0.4005, validation loss: 1.8144
2024-06-03 20:57:03 [INFO]: Epoch 036 - training loss: 0.3992, validation loss: 1.8135
2024-06-03 20:59:46 [INFO]: Epoch 037 - training loss: 0.3968, validation loss: 1.8172
2024-06-03 21:02:29 [INFO]: Epoch 038 - training loss: 0.3941, validation loss: 1.8134
2024-06-03 21:05:12 [INFO]: Epoch 039 - training loss: 0.3944, validation loss: 1.8119
2024-06-03 21:07:49 [INFO]: Epoch 040 - training loss: 0.3922, validation loss: 1.8117
2024-06-03 21:10:33 [INFO]: Epoch 041 - training loss: 0.3898, validation loss: 1.8093
2024-06-03 21:13:16 [INFO]: Epoch 042 - training loss: 0.3894, validation loss: 1.8078
2024-06-03 21:15:59 [INFO]: Epoch 043 - training loss: 0.3876, validation loss: 1.8070
2024-06-03 21:18:42 [INFO]: Epoch 044 - training loss: 0.3872, validation loss: 1.8091
2024-06-03 21:21:26 [INFO]: Epoch 045 - training loss: 0.3857, validation loss: 1.8021
2024-06-03 21:24:08 [INFO]: Epoch 046 - training loss: 0.3834, validation loss: 1.8077
2024-06-03 21:26:52 [INFO]: Epoch 047 - training loss: 0.3828, validation loss: 1.8096
2024-06-03 21:29:35 [INFO]: Epoch 048 - training loss: 0.3823, validation loss: 1.8080
2024-06-03 21:32:18 [INFO]: Epoch 049 - training loss: 0.3802, validation loss: 1.8013
2024-06-03 21:35:01 [INFO]: Epoch 050 - training loss: 0.3791, validation loss: 1.8050
2024-06-03 21:37:44 [INFO]: Epoch 051 - training loss: 0.3774, validation loss: 1.8020
2024-06-03 21:40:27 [INFO]: Epoch 052 - training loss: 0.3767, validation loss: 1.8001
2024-06-03 21:43:11 [INFO]: Epoch 053 - training loss: 0.3757, validation loss: 1.8032
2024-06-03 21:45:54 [INFO]: Epoch 054 - training loss: 0.3740, validation loss: 1.7942
2024-06-03 21:48:37 [INFO]: Epoch 055 - training loss: 0.3737, validation loss: 1.7987
2024-06-03 21:51:20 [INFO]: Epoch 056 - training loss: 0.3726, validation loss: 1.7996
2024-06-03 21:53:43 [INFO]: Epoch 057 - training loss: 0.3716, validation loss: 1.7987
2024-06-03 21:56:27 [INFO]: Epoch 058 - training loss: 0.3706, validation loss: 1.7968
2024-06-03 21:59:09 [INFO]: Epoch 059 - training loss: 0.3694, validation loss: 1.7950
2024-06-03 22:01:53 [INFO]: Epoch 060 - training loss: 0.3687, validation loss: 1.7990
2024-06-03 22:04:36 [INFO]: Epoch 061 - training loss: 0.3683, validation loss: 1.7971
2024-06-03 22:07:20 [INFO]: Epoch 062 - training loss: 0.3677, validation loss: 1.7961
2024-06-03 22:10:03 [INFO]: Epoch 063 - training loss: 0.3672, validation loss: 1.7959
2024-06-03 22:12:19 [INFO]: Epoch 064 - training loss: 0.3657, validation loss: 1.7946
2024-06-03 22:12:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 22:12:19 [INFO]: Finished training. The best model is from epoch#54.
2024-06-03 22:12:19 [INFO]: Saved the model to results_block_rate05/Electricity/BRITS_Electricity/round_2/20240603_T193134/BRITS.pypots
2024-06-03 22:15:09 [INFO]: Successfully saved to results_block_rate05/Electricity/BRITS_Electricity/round_2/imputation.pkl
2024-06-03 22:15:09 [INFO]: Round2 - BRITS on Electricity: MAE=1.1380, MSE=3.1416, MRE=0.6108
2024-06-03 22:15:09 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 22:15:09 [INFO]: Using the given device: cuda:0
2024-06-03 22:15:09 [INFO]: Model files will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_3/20240603_T221509
2024-06-03 22:15:09 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_3/20240603_T221509/tensorboard
2024-06-03 22:15:09 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-03 22:17:26 [INFO]: Epoch 001 - training loss: 1.0510, validation loss: 2.3131
2024-06-03 22:19:41 [INFO]: Epoch 002 - training loss: 0.7217, validation loss: 2.1452
2024-06-03 22:22:01 [INFO]: Epoch 003 - training loss: 0.6425, validation loss: 2.0426
2024-06-03 22:24:23 [INFO]: Epoch 004 - training loss: 0.5988, validation loss: 1.9905
2024-06-03 22:26:46 [INFO]: Epoch 005 - training loss: 0.5697, validation loss: 1.9604
2024-06-03 22:29:10 [INFO]: Epoch 006 - training loss: 0.5490, validation loss: 1.9465
2024-06-03 22:31:34 [INFO]: Epoch 007 - training loss: 0.5350, validation loss: 1.9341
2024-06-03 22:33:57 [INFO]: Epoch 008 - training loss: 0.5192, validation loss: 1.9207
2024-06-03 22:36:12 [INFO]: Epoch 009 - training loss: 0.5086, validation loss: 1.9099
2024-06-03 22:38:24 [INFO]: Epoch 010 - training loss: 0.4987, validation loss: 1.9060
2024-06-03 22:40:37 [INFO]: Epoch 011 - training loss: 0.4900, validation loss: 1.8944
2024-06-03 22:42:52 [INFO]: Epoch 012 - training loss: 0.4823, validation loss: 1.8919
2024-06-03 22:45:13 [INFO]: Epoch 013 - training loss: 0.4760, validation loss: 1.8842
2024-06-03 22:47:37 [INFO]: Epoch 014 - training loss: 0.4699, validation loss: 1.8775
2024-06-03 22:50:01 [INFO]: Epoch 015 - training loss: 0.4627, validation loss: 1.8760
2024-06-03 22:52:25 [INFO]: Epoch 016 - training loss: 0.4575, validation loss: 1.8675
2024-06-03 22:54:49 [INFO]: Epoch 017 - training loss: 0.4526, validation loss: 1.8731
2024-06-03 22:57:10 [INFO]: Epoch 018 - training loss: 0.4483, validation loss: 1.8687
2024-06-03 22:59:24 [INFO]: Epoch 019 - training loss: 0.4445, validation loss: 1.8593
2024-06-03 23:01:36 [INFO]: Epoch 020 - training loss: 0.4397, validation loss: 1.8604
2024-06-03 23:03:48 [INFO]: Epoch 021 - training loss: 0.4365, validation loss: 1.8583
2024-06-03 23:06:06 [INFO]: Epoch 022 - training loss: 0.4326, validation loss: 1.8529
2024-06-03 23:08:27 [INFO]: Epoch 023 - training loss: 0.4290, validation loss: 1.8461
2024-06-03 23:10:51 [INFO]: Epoch 024 - training loss: 0.4257, validation loss: 1.8441
2024-06-03 23:13:15 [INFO]: Epoch 025 - training loss: 0.4232, validation loss: 1.8392
2024-06-03 23:15:39 [INFO]: Epoch 026 - training loss: 0.4210, validation loss: 1.8427
2024-06-03 23:18:03 [INFO]: Epoch 027 - training loss: 0.4179, validation loss: 1.8342
2024-06-03 23:20:22 [INFO]: Epoch 028 - training loss: 0.4162, validation loss: 1.8359
2024-06-03 23:22:36 [INFO]: Epoch 029 - training loss: 0.4135, validation loss: 1.8336
2024-06-03 23:24:48 [INFO]: Epoch 030 - training loss: 0.4100, validation loss: 1.8256
2024-06-03 23:27:01 [INFO]: Epoch 031 - training loss: 0.4075, validation loss: 1.8231
2024-06-03 23:29:21 [INFO]: Epoch 032 - training loss: 0.4058, validation loss: 1.8228
2024-06-03 23:31:43 [INFO]: Epoch 033 - training loss: 0.4032, validation loss: 1.8203
2024-06-03 23:34:07 [INFO]: Epoch 034 - training loss: 0.4021, validation loss: 1.8217
2024-06-03 23:36:31 [INFO]: Epoch 035 - training loss: 0.3994, validation loss: 1.8164
2024-06-03 23:38:55 [INFO]: Epoch 036 - training loss: 0.3972, validation loss: 1.8184
2024-06-03 23:41:19 [INFO]: Epoch 037 - training loss: 0.3959, validation loss: 1.8186
2024-06-03 23:43:35 [INFO]: Epoch 038 - training loss: 0.3949, validation loss: 1.8166
2024-06-03 23:45:48 [INFO]: Epoch 039 - training loss: 0.3928, validation loss: 1.8152
2024-06-03 23:48:00 [INFO]: Epoch 040 - training loss: 0.3911, validation loss: 1.8089
2024-06-03 23:50:15 [INFO]: Epoch 041 - training loss: 0.3907, validation loss: 1.8122
2024-06-03 23:52:36 [INFO]: Epoch 042 - training loss: 0.3882, validation loss: 1.8109
2024-06-03 23:54:58 [INFO]: Epoch 043 - training loss: 0.3870, validation loss: 1.8092
2024-06-03 23:57:22 [INFO]: Epoch 044 - training loss: 0.3856, validation loss: 1.8066
2024-06-03 23:59:46 [INFO]: Epoch 045 - training loss: 0.3845, validation loss: 1.8067
2024-06-04 00:02:10 [INFO]: Epoch 046 - training loss: 0.3830, validation loss: 1.8067
2024-06-04 00:04:33 [INFO]: Epoch 047 - training loss: 0.3818, validation loss: 1.8031
2024-06-04 00:06:47 [INFO]: Epoch 048 - training loss: 0.3820, validation loss: 1.8058
2024-06-04 00:09:00 [INFO]: Epoch 049 - training loss: 0.3802, validation loss: 1.8026
2024-06-04 00:11:13 [INFO]: Epoch 050 - training loss: 0.3790, validation loss: 1.8003
2024-06-04 00:13:29 [INFO]: Epoch 051 - training loss: 0.3785, validation loss: 1.8053
2024-06-04 00:15:50 [INFO]: Epoch 052 - training loss: 0.3777, validation loss: 1.7998
2024-06-04 00:18:14 [INFO]: Epoch 053 - training loss: 0.3761, validation loss: 1.7991
2024-06-04 00:20:38 [INFO]: Epoch 054 - training loss: 0.3745, validation loss: 1.8018
2024-06-04 00:23:02 [INFO]: Epoch 055 - training loss: 0.3734, validation loss: 1.7987
2024-06-04 00:25:26 [INFO]: Epoch 056 - training loss: 0.3716, validation loss: 1.7955
2024-06-04 00:27:46 [INFO]: Epoch 057 - training loss: 0.3707, validation loss: 1.7969
2024-06-04 00:30:00 [INFO]: Epoch 058 - training loss: 0.3701, validation loss: 1.7951
2024-06-04 00:32:13 [INFO]: Epoch 059 - training loss: 0.3700, validation loss: 1.7939
2024-06-04 00:34:24 [INFO]: Epoch 060 - training loss: 0.3689, validation loss: 1.7947
2024-06-04 00:36:43 [INFO]: Epoch 061 - training loss: 0.3678, validation loss: 1.7938
2024-06-04 00:39:06 [INFO]: Epoch 062 - training loss: 0.3675, validation loss: 1.7946
2024-06-04 00:41:31 [INFO]: Epoch 063 - training loss: 0.3673, validation loss: 1.7937
2024-06-04 00:43:54 [INFO]: Epoch 064 - training loss: 0.3659, validation loss: 1.7933
2024-06-04 00:46:18 [INFO]: Epoch 065 - training loss: 0.3641, validation loss: 1.7918
2024-06-04 00:48:42 [INFO]: Epoch 066 - training loss: 0.3641, validation loss: 1.7942
2024-06-04 00:50:59 [INFO]: Epoch 067 - training loss: 0.3632, validation loss: 1.7940
2024-06-04 00:53:12 [INFO]: Epoch 068 - training loss: 0.3622, validation loss: 1.7985
2024-06-04 00:55:24 [INFO]: Epoch 069 - training loss: 0.3620, validation loss: 1.7926
2024-06-04 00:57:38 [INFO]: Epoch 070 - training loss: 0.3611, validation loss: 1.7936
2024-06-04 00:59:57 [INFO]: Epoch 071 - training loss: 0.3604, validation loss: 1.7918
2024-06-04 01:02:20 [INFO]: Epoch 072 - training loss: 0.3599, validation loss: 1.7961
2024-06-04 01:04:44 [INFO]: Epoch 073 - training loss: 0.3597, validation loss: 1.7933
2024-06-04 01:07:08 [INFO]: Epoch 074 - training loss: 0.3585, validation loss: 1.7920
2024-06-04 01:09:32 [INFO]: Epoch 075 - training loss: 0.3582, validation loss: 1.7946
2024-06-04 01:11:56 [INFO]: Epoch 076 - training loss: 0.3580, validation loss: 1.7909
2024-06-04 01:14:11 [INFO]: Epoch 077 - training loss: 0.3572, validation loss: 1.7907
2024-06-04 01:16:23 [INFO]: Epoch 078 - training loss: 0.3569, validation loss: 1.7931
2024-06-04 01:18:35 [INFO]: Epoch 079 - training loss: 0.3560, validation loss: 1.7943
2024-06-04 01:20:48 [INFO]: Epoch 080 - training loss: 0.3558, validation loss: 1.7922
2024-06-04 01:23:09 [INFO]: Epoch 081 - training loss: 0.3560, validation loss: 1.7879
2024-06-04 01:25:32 [INFO]: Epoch 082 - training loss: 0.3558, validation loss: 1.7925
2024-06-04 01:27:57 [INFO]: Epoch 083 - training loss: 0.3548, validation loss: 1.7957
2024-06-04 01:30:21 [INFO]: Epoch 084 - training loss: 0.3537, validation loss: 1.7913
2024-06-04 01:32:45 [INFO]: Epoch 085 - training loss: 0.3527, validation loss: 1.7862
2024-06-04 01:35:08 [INFO]: Epoch 086 - training loss: 0.3522, validation loss: 1.7935
2024-06-04 01:37:22 [INFO]: Epoch 087 - training loss: 0.3522, validation loss: 1.7920
2024-06-04 01:39:35 [INFO]: Epoch 088 - training loss: 0.3511, validation loss: 1.7949
2024-06-04 01:42:10 [INFO]: Epoch 089 - training loss: 0.3509, validation loss: 1.7963
2024-06-04 01:44:54 [INFO]: Epoch 090 - training loss: 0.3498, validation loss: 1.7927
2024-06-04 01:47:37 [INFO]: Epoch 091 - training loss: 0.3498, validation loss: 1.7955
2024-06-04 01:50:20 [INFO]: Epoch 092 - training loss: 0.3492, validation loss: 1.7984
2024-06-04 01:53:03 [INFO]: Epoch 093 - training loss: 0.3486, validation loss: 1.7919
2024-06-04 01:55:47 [INFO]: Epoch 094 - training loss: 0.3480, validation loss: 1.7927
2024-06-04 01:58:29 [INFO]: Epoch 095 - training loss: 0.3477, validation loss: 1.7917
2024-06-04 01:58:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 01:58:29 [INFO]: Finished training. The best model is from epoch#85.
2024-06-04 01:58:29 [INFO]: Saved the model to results_block_rate05/Electricity/BRITS_Electricity/round_3/20240603_T221509/BRITS.pypots
2024-06-04 02:01:45 [INFO]: Successfully saved to results_block_rate05/Electricity/BRITS_Electricity/round_3/imputation.pkl
2024-06-04 02:01:45 [INFO]: Round3 - BRITS on Electricity: MAE=1.1012, MSE=3.0683, MRE=0.5911
2024-06-04 02:01:45 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 02:01:45 [INFO]: Using the given device: cuda:0
2024-06-04 02:01:45 [INFO]: Model files will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_4/20240604_T020145
2024-06-04 02:01:45 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/BRITS_Electricity/round_4/20240604_T020145/tensorboard
2024-06-04 02:01:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 02:04:32 [INFO]: Epoch 001 - training loss: 1.0570, validation loss: 2.3316
2024-06-04 02:07:15 [INFO]: Epoch 002 - training loss: 0.7232, validation loss: 2.1514
2024-06-04 02:09:59 [INFO]: Epoch 003 - training loss: 0.6431, validation loss: 2.0396
2024-06-04 02:12:42 [INFO]: Epoch 004 - training loss: 0.5997, validation loss: 1.9936
2024-06-04 02:15:25 [INFO]: Epoch 005 - training loss: 0.5709, validation loss: 1.9675
2024-06-04 02:18:09 [INFO]: Epoch 006 - training loss: 0.5496, validation loss: 1.9518
2024-06-04 02:20:51 [INFO]: Epoch 007 - training loss: 0.5337, validation loss: 1.9422
2024-06-04 02:23:35 [INFO]: Epoch 008 - training loss: 0.5211, validation loss: 1.9293
2024-06-04 02:26:18 [INFO]: Epoch 009 - training loss: 0.5086, validation loss: 1.9211
2024-06-04 02:29:01 [INFO]: Epoch 010 - training loss: 0.4985, validation loss: 1.9132
2024-06-04 02:31:44 [INFO]: Epoch 011 - training loss: 0.4903, validation loss: 1.9051
2024-06-04 02:34:28 [INFO]: Epoch 012 - training loss: 0.4823, validation loss: 1.8927
2024-06-04 02:37:10 [INFO]: Epoch 013 - training loss: 0.4747, validation loss: 1.8843
2024-06-04 02:39:54 [INFO]: Epoch 014 - training loss: 0.4684, validation loss: 1.8788
2024-06-04 02:42:37 [INFO]: Epoch 015 - training loss: 0.4627, validation loss: 1.8712
2024-06-04 02:45:20 [INFO]: Epoch 016 - training loss: 0.4576, validation loss: 1.8776
2024-06-04 02:47:55 [INFO]: Epoch 017 - training loss: 0.4513, validation loss: 1.8672
2024-06-04 02:50:38 [INFO]: Epoch 018 - training loss: 0.4477, validation loss: 1.8624
2024-06-04 02:51:19 [INFO]: Finished training. The best model is from epoch#18.
2024-06-04 02:51:19 [INFO]: Successfully created the given path "results_block_rate05/Electricity/BRITS_Electricity/round_4/20240604_T020145".
2024-06-04 02:51:19 [INFO]: Saved the model to results_block_rate05/Electricity/BRITS_Electricity/round_4/20240604_T020145/BRITS.pypots
2024-06-04 02:54:44 [INFO]: Successfully saved to results_block_rate05/Electricity/BRITS_Electricity/round_4/imputation.pkl
2024-06-04 02:54:44 [INFO]: Round4 - BRITS on Electricity: MAE=1.1698, MSE=3.2457, MRE=0.6279
2024-06-04 02:54:44 [INFO]: Done! Final results:
Averaged BRITS (17,082,800 params) on Electricity: MAE=1.1283 ± 0.023870278913045665, MSE=3.1243 ± 0.06573571785426684, MRE=0.6056 ± 0.012812369357260387, average inference time=39.46
