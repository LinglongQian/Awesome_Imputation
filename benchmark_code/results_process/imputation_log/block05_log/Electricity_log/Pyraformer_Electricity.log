2024-06-03 12:21:25 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:21:25 [INFO]: Using the given device: cuda:0
2024-06-03 12:21:25 [INFO]: Model files will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_0/20240603_T122125
2024-06-03 12:21:25 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_0/20240603_T122125/tensorboard
2024-06-03 12:21:26 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-03 12:21:48 [INFO]: Epoch 001 - training loss: 1.0697, validation loss: 2.2739
2024-06-03 12:22:00 [INFO]: Epoch 002 - training loss: 0.8015, validation loss: 2.0947
2024-06-03 12:22:13 [INFO]: Epoch 003 - training loss: 0.7272, validation loss: 2.0493
2024-06-03 12:22:26 [INFO]: Epoch 004 - training loss: 0.6792, validation loss: 2.0117
2024-06-03 12:22:38 [INFO]: Epoch 005 - training loss: 0.6441, validation loss: 2.0174
2024-06-03 12:22:51 [INFO]: Epoch 006 - training loss: 0.6294, validation loss: 2.0198
2024-06-03 12:23:04 [INFO]: Epoch 007 - training loss: 0.6227, validation loss: 1.9979
2024-06-03 12:23:17 [INFO]: Epoch 008 - training loss: 0.5968, validation loss: 1.9963
2024-06-03 12:23:30 [INFO]: Epoch 009 - training loss: 0.5814, validation loss: 1.9817
2024-06-03 12:23:44 [INFO]: Epoch 010 - training loss: 0.5670, validation loss: 1.9886
2024-06-03 12:23:57 [INFO]: Epoch 011 - training loss: 0.5597, validation loss: 1.9872
2024-06-03 12:24:11 [INFO]: Epoch 012 - training loss: 0.5511, validation loss: 1.9660
2024-06-03 12:24:24 [INFO]: Epoch 013 - training loss: 0.5419, validation loss: 1.9592
2024-06-03 12:24:37 [INFO]: Epoch 014 - training loss: 0.5392, validation loss: 1.9621
2024-06-03 12:24:50 [INFO]: Epoch 015 - training loss: 0.5320, validation loss: 1.9750
2024-06-03 12:25:03 [INFO]: Epoch 016 - training loss: 0.5276, validation loss: 1.9413
2024-06-03 12:25:17 [INFO]: Epoch 017 - training loss: 0.5197, validation loss: 1.9488
2024-06-03 12:25:31 [INFO]: Epoch 018 - training loss: 0.5141, validation loss: 1.9275
2024-06-03 12:25:44 [INFO]: Epoch 019 - training loss: 0.5109, validation loss: 1.9237
2024-06-03 12:25:57 [INFO]: Epoch 020 - training loss: 0.5012, validation loss: 1.9297
2024-06-03 12:26:11 [INFO]: Epoch 021 - training loss: 0.4980, validation loss: 1.9324
2024-06-03 12:26:25 [INFO]: Epoch 022 - training loss: 0.4971, validation loss: 1.9199
2024-06-03 12:26:38 [INFO]: Epoch 023 - training loss: 0.4934, validation loss: 1.9221
2024-06-03 12:26:50 [INFO]: Epoch 024 - training loss: 0.4888, validation loss: 1.9088
2024-06-03 12:27:04 [INFO]: Epoch 025 - training loss: 0.4845, validation loss: 1.9083
2024-06-03 12:27:17 [INFO]: Epoch 026 - training loss: 0.4842, validation loss: 1.8958
2024-06-03 12:27:30 [INFO]: Epoch 027 - training loss: 0.4813, validation loss: 1.8905
2024-06-03 12:27:43 [INFO]: Epoch 028 - training loss: 0.4743, validation loss: 1.8900
2024-06-03 12:27:57 [INFO]: Epoch 029 - training loss: 0.4735, validation loss: 1.9036
2024-06-03 12:28:11 [INFO]: Epoch 030 - training loss: 0.4713, validation loss: 1.8828
2024-06-03 12:28:24 [INFO]: Epoch 031 - training loss: 0.4672, validation loss: 1.8912
2024-06-03 12:28:38 [INFO]: Epoch 032 - training loss: 0.4653, validation loss: 1.8926
2024-06-03 12:28:52 [INFO]: Epoch 033 - training loss: 0.4624, validation loss: 1.8881
2024-06-03 12:29:05 [INFO]: Epoch 034 - training loss: 0.4604, validation loss: 1.8727
2024-06-03 12:29:19 [INFO]: Epoch 035 - training loss: 0.4587, validation loss: 1.8799
2024-06-03 12:29:33 [INFO]: Epoch 036 - training loss: 0.4556, validation loss: 1.8824
2024-06-03 12:29:46 [INFO]: Epoch 037 - training loss: 0.4555, validation loss: 1.8661
2024-06-03 12:29:59 [INFO]: Epoch 038 - training loss: 0.4525, validation loss: 1.8656
2024-06-03 12:30:11 [INFO]: Epoch 039 - training loss: 0.4511, validation loss: 1.8670
2024-06-03 12:30:24 [INFO]: Epoch 040 - training loss: 0.4481, validation loss: 1.8688
2024-06-03 12:30:37 [INFO]: Epoch 041 - training loss: 0.4481, validation loss: 1.8781
2024-06-03 12:30:49 [INFO]: Epoch 042 - training loss: 0.4471, validation loss: 1.8716
2024-06-03 12:31:02 [INFO]: Epoch 043 - training loss: 0.4475, validation loss: 1.8685
2024-06-03 12:31:15 [INFO]: Epoch 044 - training loss: 0.4470, validation loss: 1.8689
2024-06-03 12:31:28 [INFO]: Epoch 045 - training loss: 0.4425, validation loss: 1.8493
2024-06-03 12:31:41 [INFO]: Epoch 046 - training loss: 0.4406, validation loss: 1.8572
2024-06-03 12:31:53 [INFO]: Epoch 047 - training loss: 0.4387, validation loss: 1.8691
2024-06-03 12:32:06 [INFO]: Epoch 048 - training loss: 0.4386, validation loss: 1.8622
2024-06-03 12:32:19 [INFO]: Epoch 049 - training loss: 0.4387, validation loss: 1.8571
2024-06-03 12:32:32 [INFO]: Epoch 050 - training loss: 0.4380, validation loss: 1.8676
2024-06-03 12:32:46 [INFO]: Epoch 051 - training loss: 0.4374, validation loss: 1.8639
2024-06-03 12:32:59 [INFO]: Epoch 052 - training loss: 0.4363, validation loss: 1.8701
2024-06-03 12:33:12 [INFO]: Epoch 053 - training loss: 0.4342, validation loss: 1.8539
2024-06-03 12:33:25 [INFO]: Epoch 054 - training loss: 0.4318, validation loss: 1.8303
2024-06-03 12:33:37 [INFO]: Epoch 055 - training loss: 0.4314, validation loss: 1.8433
2024-06-03 12:33:48 [INFO]: Epoch 056 - training loss: 0.4347, validation loss: 1.8661
2024-06-03 12:34:00 [INFO]: Epoch 057 - training loss: 0.4304, validation loss: 1.8473
2024-06-03 12:34:11 [INFO]: Epoch 058 - training loss: 0.4269, validation loss: 1.8470
2024-06-03 12:34:23 [INFO]: Epoch 059 - training loss: 0.4273, validation loss: 1.8483
2024-06-03 12:34:35 [INFO]: Epoch 060 - training loss: 0.4265, validation loss: 1.8413
2024-06-03 12:34:46 [INFO]: Epoch 061 - training loss: 0.4233, validation loss: 1.8517
2024-06-03 12:34:58 [INFO]: Epoch 062 - training loss: 0.4244, validation loss: 1.8351
2024-06-03 12:35:09 [INFO]: Epoch 063 - training loss: 0.4235, validation loss: 1.8431
2024-06-03 12:35:21 [INFO]: Epoch 064 - training loss: 0.4225, validation loss: 1.8602
2024-06-03 12:35:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:35:21 [INFO]: Finished training. The best model is from epoch#54.
2024-06-03 12:35:21 [INFO]: Saved the model to results_block_rate05/Electricity/Pyraformer_Electricity/round_0/20240603_T122125/Pyraformer.pypots
2024-06-03 12:35:29 [INFO]: Successfully saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_0/imputation.pkl
2024-06-03 12:35:29 [INFO]: Round0 - Pyraformer on Electricity: MAE=1.2835, MSE=3.3555, MRE=0.6889
2024-06-03 12:35:29 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:35:29 [INFO]: Using the given device: cuda:0
2024-06-03 12:35:29 [INFO]: Model files will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_1/20240603_T123529
2024-06-03 12:35:29 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_1/20240603_T123529/tensorboard
2024-06-03 12:35:29 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-03 12:35:41 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 2.2640
2024-06-03 12:35:52 [INFO]: Epoch 002 - training loss: 0.7796, validation loss: 2.0978
2024-06-03 12:36:03 [INFO]: Epoch 003 - training loss: 0.7059, validation loss: 2.0434
2024-06-03 12:36:14 [INFO]: Epoch 004 - training loss: 0.6672, validation loss: 2.0217
2024-06-03 12:36:25 [INFO]: Epoch 005 - training loss: 0.6412, validation loss: 2.0042
2024-06-03 12:36:36 [INFO]: Epoch 006 - training loss: 0.6280, validation loss: 1.9969
2024-06-03 12:36:47 [INFO]: Epoch 007 - training loss: 0.6079, validation loss: 1.9959
2024-06-03 12:36:58 [INFO]: Epoch 008 - training loss: 0.5946, validation loss: 1.9984
2024-06-03 12:37:09 [INFO]: Epoch 009 - training loss: 0.5805, validation loss: 1.9888
2024-06-03 12:37:20 [INFO]: Epoch 010 - training loss: 0.5688, validation loss: 1.9629
2024-06-03 12:37:31 [INFO]: Epoch 011 - training loss: 0.5551, validation loss: 1.9614
2024-06-03 12:37:42 [INFO]: Epoch 012 - training loss: 0.5533, validation loss: 1.9424
2024-06-03 12:37:53 [INFO]: Epoch 013 - training loss: 0.5406, validation loss: 1.9483
2024-06-03 12:38:05 [INFO]: Epoch 014 - training loss: 0.5327, validation loss: 1.9528
2024-06-03 12:38:16 [INFO]: Epoch 015 - training loss: 0.5251, validation loss: 1.9336
2024-06-03 12:38:27 [INFO]: Epoch 016 - training loss: 0.5207, validation loss: 1.9287
2024-06-03 12:38:38 [INFO]: Epoch 017 - training loss: 0.5231, validation loss: 1.9208
2024-06-03 12:38:48 [INFO]: Epoch 018 - training loss: 0.5151, validation loss: 1.9279
2024-06-03 12:39:00 [INFO]: Epoch 019 - training loss: 0.5105, validation loss: 1.9294
2024-06-03 12:39:11 [INFO]: Epoch 020 - training loss: 0.5027, validation loss: 1.9393
2024-06-03 12:39:22 [INFO]: Epoch 021 - training loss: 0.5014, validation loss: 1.9225
2024-06-03 12:39:33 [INFO]: Epoch 022 - training loss: 0.4935, validation loss: 1.9057
2024-06-03 12:39:44 [INFO]: Epoch 023 - training loss: 0.4939, validation loss: 1.9173
2024-06-03 12:39:55 [INFO]: Epoch 024 - training loss: 0.4873, validation loss: 1.9113
2024-06-03 12:40:06 [INFO]: Epoch 025 - training loss: 0.4824, validation loss: 1.9176
2024-06-03 12:40:17 [INFO]: Epoch 026 - training loss: 0.4820, validation loss: 1.8871
2024-06-03 12:40:29 [INFO]: Epoch 027 - training loss: 0.4828, validation loss: 1.8950
2024-06-03 12:40:39 [INFO]: Epoch 028 - training loss: 0.4776, validation loss: 1.8948
2024-06-03 12:40:50 [INFO]: Epoch 029 - training loss: 0.4729, validation loss: 1.8944
2024-06-03 12:41:01 [INFO]: Epoch 030 - training loss: 0.4699, validation loss: 1.9022
2024-06-03 12:41:12 [INFO]: Epoch 031 - training loss: 0.4695, validation loss: 1.8763
2024-06-03 12:41:23 [INFO]: Epoch 032 - training loss: 0.4659, validation loss: 1.8837
2024-06-03 12:41:34 [INFO]: Epoch 033 - training loss: 0.4630, validation loss: 1.8822
2024-06-03 12:41:46 [INFO]: Epoch 034 - training loss: 0.4602, validation loss: 1.8758
2024-06-03 12:41:56 [INFO]: Epoch 035 - training loss: 0.4577, validation loss: 1.8749
2024-06-03 12:42:07 [INFO]: Epoch 036 - training loss: 0.4571, validation loss: 1.8757
2024-06-03 12:42:18 [INFO]: Epoch 037 - training loss: 0.4563, validation loss: 1.8798
2024-06-03 12:42:29 [INFO]: Epoch 038 - training loss: 0.4521, validation loss: 1.8847
2024-06-03 12:42:41 [INFO]: Epoch 039 - training loss: 0.4529, validation loss: 1.8752
2024-06-03 12:42:52 [INFO]: Epoch 040 - training loss: 0.4520, validation loss: 1.8682
2024-06-03 12:43:03 [INFO]: Epoch 041 - training loss: 0.4486, validation loss: 1.8781
2024-06-03 12:43:14 [INFO]: Epoch 042 - training loss: 0.4469, validation loss: 1.8583
2024-06-03 12:43:25 [INFO]: Epoch 043 - training loss: 0.4497, validation loss: 1.8775
2024-06-03 12:43:36 [INFO]: Epoch 044 - training loss: 0.4456, validation loss: 1.8602
2024-06-03 12:43:47 [INFO]: Epoch 045 - training loss: 0.4454, validation loss: 1.8795
2024-06-03 12:43:58 [INFO]: Epoch 046 - training loss: 0.4427, validation loss: 1.8773
2024-06-03 12:44:09 [INFO]: Epoch 047 - training loss: 0.4391, validation loss: 1.8803
2024-06-03 12:44:20 [INFO]: Epoch 048 - training loss: 0.4402, validation loss: 1.8792
2024-06-03 12:44:31 [INFO]: Epoch 049 - training loss: 0.4388, validation loss: 1.8582
2024-06-03 12:44:42 [INFO]: Epoch 050 - training loss: 0.4355, validation loss: 1.8659
2024-06-03 12:44:53 [INFO]: Epoch 051 - training loss: 0.4345, validation loss: 1.8678
2024-06-03 12:45:04 [INFO]: Epoch 052 - training loss: 0.4317, validation loss: 1.8678
2024-06-03 12:45:15 [INFO]: Epoch 053 - training loss: 0.4313, validation loss: 1.8662
2024-06-03 12:45:26 [INFO]: Epoch 054 - training loss: 0.4310, validation loss: 1.8757
2024-06-03 12:45:37 [INFO]: Epoch 055 - training loss: 0.4283, validation loss: 1.8753
2024-06-03 12:45:48 [INFO]: Epoch 056 - training loss: 0.4281, validation loss: 1.8737
2024-06-03 12:46:00 [INFO]: Epoch 057 - training loss: 0.4271, validation loss: 1.8529
2024-06-03 12:46:10 [INFO]: Epoch 058 - training loss: 0.4267, validation loss: 1.8481
2024-06-03 12:46:22 [INFO]: Epoch 059 - training loss: 0.4248, validation loss: 1.8638
2024-06-03 12:46:33 [INFO]: Epoch 060 - training loss: 0.4246, validation loss: 1.8572
2024-06-03 12:46:44 [INFO]: Epoch 061 - training loss: 0.4227, validation loss: 1.8512
2024-06-03 12:46:55 [INFO]: Epoch 062 - training loss: 0.4220, validation loss: 1.8576
2024-06-03 12:47:06 [INFO]: Epoch 063 - training loss: 0.4227, validation loss: 1.8660
2024-06-03 12:47:18 [INFO]: Epoch 064 - training loss: 0.4255, validation loss: 1.8718
2024-06-03 12:47:29 [INFO]: Epoch 065 - training loss: 0.4218, validation loss: 1.8673
2024-06-03 12:47:40 [INFO]: Epoch 066 - training loss: 0.4195, validation loss: 1.8465
2024-06-03 12:47:51 [INFO]: Epoch 067 - training loss: 0.4175, validation loss: 1.8368
2024-06-03 12:48:02 [INFO]: Epoch 068 - training loss: 0.4171, validation loss: 1.8454
2024-06-03 12:48:13 [INFO]: Epoch 069 - training loss: 0.4184, validation loss: 1.8513
2024-06-03 12:48:24 [INFO]: Epoch 070 - training loss: 0.4160, validation loss: 1.8670
2024-06-03 12:48:35 [INFO]: Epoch 071 - training loss: 0.4154, validation loss: 1.8539
2024-06-03 12:48:46 [INFO]: Epoch 072 - training loss: 0.4134, validation loss: 1.8566
2024-06-03 12:48:58 [INFO]: Epoch 073 - training loss: 0.4143, validation loss: 1.8365
2024-06-03 12:49:08 [INFO]: Epoch 074 - training loss: 0.4130, validation loss: 1.8305
2024-06-03 12:49:19 [INFO]: Epoch 075 - training loss: 0.4124, validation loss: 1.8519
2024-06-03 12:49:30 [INFO]: Epoch 076 - training loss: 0.4124, validation loss: 1.8455
2024-06-03 12:49:42 [INFO]: Epoch 077 - training loss: 0.4117, validation loss: 1.8396
2024-06-03 12:49:53 [INFO]: Epoch 078 - training loss: 0.4115, validation loss: 1.8238
2024-06-03 12:50:04 [INFO]: Epoch 079 - training loss: 0.4107, validation loss: 1.8331
2024-06-03 12:50:15 [INFO]: Epoch 080 - training loss: 0.4084, validation loss: 1.8376
2024-06-03 12:50:26 [INFO]: Epoch 081 - training loss: 0.4085, validation loss: 1.8376
2024-06-03 12:50:38 [INFO]: Epoch 082 - training loss: 0.4087, validation loss: 1.8308
2024-06-03 12:50:49 [INFO]: Epoch 083 - training loss: 0.4065, validation loss: 1.8244
2024-06-03 12:51:00 [INFO]: Epoch 084 - training loss: 0.4063, validation loss: 1.8417
2024-06-03 12:51:12 [INFO]: Epoch 085 - training loss: 0.4066, validation loss: 1.8512
2024-06-03 12:51:23 [INFO]: Epoch 086 - training loss: 0.4093, validation loss: 1.8139
2024-06-03 12:51:34 [INFO]: Epoch 087 - training loss: 0.4079, validation loss: 1.8169
2024-06-03 12:51:45 [INFO]: Epoch 088 - training loss: 0.4064, validation loss: 1.8335
2024-06-03 12:51:56 [INFO]: Epoch 089 - training loss: 0.4041, validation loss: 1.8301
2024-06-03 12:52:07 [INFO]: Epoch 090 - training loss: 0.4037, validation loss: 1.8365
2024-06-03 12:52:17 [INFO]: Epoch 091 - training loss: 0.4035, validation loss: 1.8263
2024-06-03 12:52:28 [INFO]: Epoch 092 - training loss: 0.4023, validation loss: 1.8213
2024-06-03 12:52:39 [INFO]: Epoch 093 - training loss: 0.4041, validation loss: 1.8291
2024-06-03 12:52:50 [INFO]: Epoch 094 - training loss: 0.4025, validation loss: 1.8227
2024-06-03 12:53:01 [INFO]: Epoch 095 - training loss: 0.4014, validation loss: 1.8321
2024-06-03 12:53:12 [INFO]: Epoch 096 - training loss: 0.4007, validation loss: 1.8168
2024-06-03 12:53:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:53:12 [INFO]: Finished training. The best model is from epoch#86.
2024-06-03 12:53:13 [INFO]: Saved the model to results_block_rate05/Electricity/Pyraformer_Electricity/round_1/20240603_T123529/Pyraformer.pypots
2024-06-03 12:53:20 [INFO]: Successfully saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_1/imputation.pkl
2024-06-03 12:53:20 [INFO]: Round1 - Pyraformer on Electricity: MAE=1.3131, MSE=3.4667, MRE=0.7048
2024-06-03 12:53:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:53:20 [INFO]: Using the given device: cuda:0
2024-06-03 12:53:20 [INFO]: Model files will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_2/20240603_T125320
2024-06-03 12:53:20 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_2/20240603_T125320/tensorboard
2024-06-03 12:53:21 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-03 12:53:33 [INFO]: Epoch 001 - training loss: 1.0751, validation loss: 2.2735
2024-06-03 12:53:44 [INFO]: Epoch 002 - training loss: 0.7825, validation loss: 2.1018
2024-06-03 12:53:54 [INFO]: Epoch 003 - training loss: 0.7121, validation loss: 2.0287
2024-06-03 12:54:05 [INFO]: Epoch 004 - training loss: 0.6726, validation loss: 2.0268
2024-06-03 12:54:16 [INFO]: Epoch 005 - training loss: 0.6413, validation loss: 2.0266
2024-06-03 12:54:28 [INFO]: Epoch 006 - training loss: 0.6248, validation loss: 1.9890
2024-06-03 12:54:39 [INFO]: Epoch 007 - training loss: 0.6133, validation loss: 1.9671
2024-06-03 12:54:50 [INFO]: Epoch 008 - training loss: 0.5927, validation loss: 1.9679
2024-06-03 12:55:01 [INFO]: Epoch 009 - training loss: 0.5821, validation loss: 1.9640
2024-06-03 12:55:12 [INFO]: Epoch 010 - training loss: 0.5734, validation loss: 1.9475
2024-06-03 12:55:23 [INFO]: Epoch 011 - training loss: 0.5623, validation loss: 1.9478
2024-06-03 12:55:34 [INFO]: Epoch 012 - training loss: 0.5501, validation loss: 1.9492
2024-06-03 12:55:45 [INFO]: Epoch 013 - training loss: 0.5403, validation loss: 1.9458
2024-06-03 12:55:57 [INFO]: Epoch 014 - training loss: 0.5395, validation loss: 1.9711
2024-06-03 12:56:08 [INFO]: Epoch 015 - training loss: 0.5306, validation loss: 1.9557
2024-06-03 12:56:20 [INFO]: Epoch 016 - training loss: 0.5260, validation loss: 1.9477
2024-06-03 12:56:32 [INFO]: Epoch 017 - training loss: 0.5161, validation loss: 1.9394
2024-06-03 12:56:44 [INFO]: Epoch 018 - training loss: 0.5151, validation loss: 1.9213
2024-06-03 12:56:55 [INFO]: Epoch 019 - training loss: 0.5097, validation loss: 1.9344
2024-06-03 12:57:07 [INFO]: Epoch 020 - training loss: 0.5059, validation loss: 1.9138
2024-06-03 12:57:19 [INFO]: Epoch 021 - training loss: 0.4976, validation loss: 1.9106
2024-06-03 12:57:31 [INFO]: Epoch 022 - training loss: 0.4946, validation loss: 1.9085
2024-06-03 12:57:42 [INFO]: Epoch 023 - training loss: 0.4899, validation loss: 1.8998
2024-06-03 12:57:54 [INFO]: Epoch 024 - training loss: 0.4866, validation loss: 1.9164
2024-06-03 12:58:06 [INFO]: Epoch 025 - training loss: 0.4875, validation loss: 1.8826
2024-06-03 12:58:18 [INFO]: Epoch 026 - training loss: 0.4850, validation loss: 1.8894
2024-06-03 12:58:30 [INFO]: Epoch 027 - training loss: 0.4791, validation loss: 1.9130
2024-06-03 12:58:41 [INFO]: Epoch 028 - training loss: 0.4769, validation loss: 1.8940
2024-06-03 12:58:53 [INFO]: Epoch 029 - training loss: 0.4743, validation loss: 1.9016
2024-06-03 12:59:05 [INFO]: Epoch 030 - training loss: 0.4692, validation loss: 1.8966
2024-06-03 12:59:16 [INFO]: Epoch 031 - training loss: 0.4671, validation loss: 1.8888
2024-06-03 12:59:28 [INFO]: Epoch 032 - training loss: 0.4684, validation loss: 1.8968
2024-06-03 12:59:40 [INFO]: Epoch 033 - training loss: 0.4659, validation loss: 1.8837
2024-06-03 12:59:51 [INFO]: Epoch 034 - training loss: 0.4605, validation loss: 1.8953
2024-06-03 13:00:03 [INFO]: Epoch 035 - training loss: 0.4577, validation loss: 1.8709
2024-06-03 13:00:15 [INFO]: Epoch 036 - training loss: 0.4570, validation loss: 1.8921
2024-06-03 13:00:27 [INFO]: Epoch 037 - training loss: 0.4557, validation loss: 1.8765
2024-06-03 13:00:39 [INFO]: Epoch 038 - training loss: 0.4538, validation loss: 1.8657
2024-06-03 13:00:50 [INFO]: Epoch 039 - training loss: 0.4530, validation loss: 1.8912
2024-06-03 13:01:02 [INFO]: Epoch 040 - training loss: 0.4517, validation loss: 1.8891
2024-06-03 13:01:14 [INFO]: Epoch 041 - training loss: 0.4508, validation loss: 1.8693
2024-06-03 13:01:25 [INFO]: Epoch 042 - training loss: 0.4473, validation loss: 1.8709
2024-06-03 13:01:37 [INFO]: Epoch 043 - training loss: 0.4452, validation loss: 1.8857
2024-06-03 13:01:49 [INFO]: Epoch 044 - training loss: 0.4438, validation loss: 1.8717
2024-06-03 13:02:01 [INFO]: Epoch 045 - training loss: 0.4433, validation loss: 1.8696
2024-06-03 13:02:12 [INFO]: Epoch 046 - training loss: 0.4399, validation loss: 1.8540
2024-06-03 13:02:24 [INFO]: Epoch 047 - training loss: 0.4389, validation loss: 1.8753
2024-06-03 13:02:36 [INFO]: Epoch 048 - training loss: 0.4384, validation loss: 1.8699
2024-06-03 13:02:47 [INFO]: Epoch 049 - training loss: 0.4373, validation loss: 1.8885
2024-06-03 13:02:59 [INFO]: Epoch 050 - training loss: 0.4367, validation loss: 1.8602
2024-06-03 13:03:11 [INFO]: Epoch 051 - training loss: 0.4352, validation loss: 1.8831
2024-06-03 13:03:23 [INFO]: Epoch 052 - training loss: 0.4335, validation loss: 1.8661
2024-06-03 13:03:35 [INFO]: Epoch 053 - training loss: 0.4323, validation loss: 1.8660
2024-06-03 13:03:47 [INFO]: Epoch 054 - training loss: 0.4319, validation loss: 1.8680
2024-06-03 13:03:58 [INFO]: Epoch 055 - training loss: 0.4308, validation loss: 1.8499
2024-06-03 13:04:10 [INFO]: Epoch 056 - training loss: 0.4287, validation loss: 1.8626
2024-06-03 13:04:22 [INFO]: Epoch 057 - training loss: 0.4300, validation loss: 1.8588
2024-06-03 13:04:34 [INFO]: Epoch 058 - training loss: 0.4313, validation loss: 1.8590
2024-06-03 13:04:45 [INFO]: Epoch 059 - training loss: 0.4299, validation loss: 1.8871
2024-06-03 13:04:57 [INFO]: Epoch 060 - training loss: 0.4257, validation loss: 1.8623
2024-06-03 13:05:08 [INFO]: Epoch 061 - training loss: 0.4249, validation loss: 1.8635
2024-06-03 13:05:20 [INFO]: Epoch 062 - training loss: 0.4248, validation loss: 1.8667
2024-06-03 13:05:32 [INFO]: Epoch 063 - training loss: 0.4217, validation loss: 1.8579
2024-06-03 13:05:44 [INFO]: Epoch 064 - training loss: 0.4215, validation loss: 1.8782
2024-06-03 13:05:55 [INFO]: Epoch 065 - training loss: 0.4207, validation loss: 1.8518
2024-06-03 13:05:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:05:55 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 13:05:56 [INFO]: Saved the model to results_block_rate05/Electricity/Pyraformer_Electricity/round_2/20240603_T125320/Pyraformer.pypots
2024-06-03 13:06:04 [INFO]: Successfully saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_2/imputation.pkl
2024-06-03 13:06:04 [INFO]: Round2 - Pyraformer on Electricity: MAE=1.3039, MSE=3.3446, MRE=0.6999
2024-06-03 13:06:04 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 13:06:04 [INFO]: Using the given device: cuda:0
2024-06-03 13:06:04 [INFO]: Model files will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_3/20240603_T130604
2024-06-03 13:06:04 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_3/20240603_T130604/tensorboard
2024-06-03 13:06:05 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-03 13:06:17 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 2.2212
2024-06-03 13:06:28 [INFO]: Epoch 002 - training loss: 0.7921, validation loss: 2.1113
2024-06-03 13:06:39 [INFO]: Epoch 003 - training loss: 0.7136, validation loss: 2.0168
2024-06-03 13:06:51 [INFO]: Epoch 004 - training loss: 0.6758, validation loss: 1.9942
2024-06-03 13:07:02 [INFO]: Epoch 005 - training loss: 0.6490, validation loss: 1.9833
2024-06-03 13:07:14 [INFO]: Epoch 006 - training loss: 0.6268, validation loss: 1.9805
2024-06-03 13:07:25 [INFO]: Epoch 007 - training loss: 0.6095, validation loss: 1.9553
2024-06-03 13:07:37 [INFO]: Epoch 008 - training loss: 0.5916, validation loss: 1.9484
2024-06-03 13:07:48 [INFO]: Epoch 009 - training loss: 0.5818, validation loss: 1.9536
2024-06-03 13:08:00 [INFO]: Epoch 010 - training loss: 0.5809, validation loss: 1.9477
2024-06-03 13:08:11 [INFO]: Epoch 011 - training loss: 0.5634, validation loss: 1.9397
2024-06-03 13:08:23 [INFO]: Epoch 012 - training loss: 0.5485, validation loss: 1.9281
2024-06-03 13:08:34 [INFO]: Epoch 013 - training loss: 0.5412, validation loss: 1.9185
2024-06-03 13:08:46 [INFO]: Epoch 014 - training loss: 0.5345, validation loss: 1.8978
2024-06-03 13:08:57 [INFO]: Epoch 015 - training loss: 0.5336, validation loss: 1.9085
2024-06-03 13:09:08 [INFO]: Epoch 016 - training loss: 0.5235, validation loss: 1.8980
2024-06-03 13:09:20 [INFO]: Epoch 017 - training loss: 0.5187, validation loss: 1.9155
2024-06-03 13:09:32 [INFO]: Epoch 018 - training loss: 0.5150, validation loss: 1.8990
2024-06-03 13:09:43 [INFO]: Epoch 019 - training loss: 0.5116, validation loss: 1.9034
2024-06-03 13:09:55 [INFO]: Epoch 020 - training loss: 0.5063, validation loss: 1.8774
2024-06-03 13:10:06 [INFO]: Epoch 021 - training loss: 0.5006, validation loss: 1.8874
2024-06-03 13:10:17 [INFO]: Epoch 022 - training loss: 0.4965, validation loss: 1.8809
2024-06-03 13:10:29 [INFO]: Epoch 023 - training loss: 0.4940, validation loss: 1.8822
2024-06-03 13:10:40 [INFO]: Epoch 024 - training loss: 0.4903, validation loss: 1.8662
2024-06-03 13:10:52 [INFO]: Epoch 025 - training loss: 0.4867, validation loss: 1.8781
2024-06-03 13:11:03 [INFO]: Epoch 026 - training loss: 0.4833, validation loss: 1.8685
2024-06-03 13:11:14 [INFO]: Epoch 027 - training loss: 0.4797, validation loss: 1.8710
2024-06-03 13:11:25 [INFO]: Epoch 028 - training loss: 0.4759, validation loss: 1.8703
2024-06-03 13:11:37 [INFO]: Epoch 029 - training loss: 0.4740, validation loss: 1.8715
2024-06-03 13:11:49 [INFO]: Epoch 030 - training loss: 0.4727, validation loss: 1.8534
2024-06-03 13:12:00 [INFO]: Epoch 031 - training loss: 0.4702, validation loss: 1.8595
2024-06-03 13:12:11 [INFO]: Epoch 032 - training loss: 0.4663, validation loss: 1.8483
2024-06-03 13:12:23 [INFO]: Epoch 033 - training loss: 0.4671, validation loss: 1.8589
2024-06-03 13:12:34 [INFO]: Epoch 034 - training loss: 0.4642, validation loss: 1.8381
2024-06-03 13:12:45 [INFO]: Epoch 035 - training loss: 0.4624, validation loss: 1.8397
2024-06-03 13:12:57 [INFO]: Epoch 036 - training loss: 0.4602, validation loss: 1.8834
2024-06-03 13:13:08 [INFO]: Epoch 037 - training loss: 0.4581, validation loss: 1.8533
2024-06-03 13:13:19 [INFO]: Epoch 038 - training loss: 0.4549, validation loss: 1.8718
2024-06-03 13:13:30 [INFO]: Epoch 039 - training loss: 0.4536, validation loss: 1.8676
2024-06-03 13:13:42 [INFO]: Epoch 040 - training loss: 0.4504, validation loss: 1.8433
2024-06-03 13:13:53 [INFO]: Epoch 041 - training loss: 0.4477, validation loss: 1.8405
2024-06-03 13:14:05 [INFO]: Epoch 042 - training loss: 0.4465, validation loss: 1.8483
2024-06-03 13:14:16 [INFO]: Epoch 043 - training loss: 0.4462, validation loss: 1.8521
2024-06-03 13:14:28 [INFO]: Epoch 044 - training loss: 0.4428, validation loss: 1.8487
2024-06-03 13:14:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:14:28 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 13:14:28 [INFO]: Saved the model to results_block_rate05/Electricity/Pyraformer_Electricity/round_3/20240603_T130604/Pyraformer.pypots
2024-06-03 13:14:36 [INFO]: Successfully saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_3/imputation.pkl
2024-06-03 13:14:36 [INFO]: Round3 - Pyraformer on Electricity: MAE=1.2824, MSE=3.3072, MRE=0.6883
2024-06-03 13:14:36 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 13:14:36 [INFO]: Using the given device: cuda:0
2024-06-03 13:14:36 [INFO]: Model files will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_4/20240603_T131436
2024-06-03 13:14:36 [INFO]: Tensorboard file will be saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_4/20240603_T131436/tensorboard
2024-06-03 13:14:37 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-03 13:14:49 [INFO]: Epoch 001 - training loss: 1.0658, validation loss: 2.2414
2024-06-03 13:15:00 [INFO]: Epoch 002 - training loss: 0.7903, validation loss: 2.0917
2024-06-03 13:15:11 [INFO]: Epoch 003 - training loss: 0.7138, validation loss: 2.0429
2024-06-03 13:15:22 [INFO]: Epoch 004 - training loss: 0.6763, validation loss: 2.0250
2024-06-03 13:15:34 [INFO]: Epoch 005 - training loss: 0.6432, validation loss: 2.0242
2024-06-03 13:15:45 [INFO]: Epoch 006 - training loss: 0.6264, validation loss: 2.0040
2024-06-03 13:15:57 [INFO]: Epoch 007 - training loss: 0.6119, validation loss: 2.0011
2024-06-03 13:16:08 [INFO]: Epoch 008 - training loss: 0.5951, validation loss: 1.9980
2024-06-03 13:16:20 [INFO]: Epoch 009 - training loss: 0.5779, validation loss: 1.9831
2024-06-03 13:16:31 [INFO]: Epoch 010 - training loss: 0.5688, validation loss: 1.9759
2024-06-03 13:16:43 [INFO]: Epoch 011 - training loss: 0.5651, validation loss: 1.9636
2024-06-03 13:16:54 [INFO]: Epoch 012 - training loss: 0.5516, validation loss: 1.9507
2024-06-03 13:17:05 [INFO]: Epoch 013 - training loss: 0.5447, validation loss: 1.9534
2024-06-03 13:17:16 [INFO]: Epoch 014 - training loss: 0.5391, validation loss: 1.9410
2024-06-03 13:17:28 [INFO]: Epoch 015 - training loss: 0.5345, validation loss: 1.9484
2024-06-03 13:17:39 [INFO]: Epoch 016 - training loss: 0.5238, validation loss: 1.9196
2024-06-03 13:17:50 [INFO]: Epoch 017 - training loss: 0.5232, validation loss: 1.9281
2024-06-03 13:18:02 [INFO]: Epoch 018 - training loss: 0.5149, validation loss: 1.9189
2024-06-03 13:18:14 [INFO]: Epoch 019 - training loss: 0.5087, validation loss: 1.9067
2024-06-03 13:18:25 [INFO]: Epoch 020 - training loss: 0.5047, validation loss: 1.9144
2024-06-03 13:18:37 [INFO]: Epoch 021 - training loss: 0.5032, validation loss: 1.9074
2024-06-03 13:18:48 [INFO]: Epoch 022 - training loss: 0.4967, validation loss: 1.8877
2024-06-03 13:19:00 [INFO]: Epoch 023 - training loss: 0.4900, validation loss: 1.8851
2024-06-03 13:19:12 [INFO]: Epoch 024 - training loss: 0.4884, validation loss: 1.8899
2024-06-03 13:19:23 [INFO]: Epoch 025 - training loss: 0.4876, validation loss: 1.8809
2024-06-03 13:19:35 [INFO]: Epoch 026 - training loss: 0.4855, validation loss: 1.8829
2024-06-03 13:19:46 [INFO]: Epoch 027 - training loss: 0.4794, validation loss: 1.8852
2024-06-03 13:19:57 [INFO]: Epoch 028 - training loss: 0.4764, validation loss: 1.8767
2024-06-03 13:20:09 [INFO]: Epoch 029 - training loss: 0.4743, validation loss: 1.8678
2024-06-03 13:20:20 [INFO]: Epoch 030 - training loss: 0.4692, validation loss: 1.8611
2024-06-03 13:20:32 [INFO]: Epoch 031 - training loss: 0.4694, validation loss: 1.8486
2024-06-03 13:20:43 [INFO]: Epoch 032 - training loss: 0.4660, validation loss: 1.8729
2024-06-03 13:20:55 [INFO]: Epoch 033 - training loss: 0.4624, validation loss: 1.8562
2024-06-03 13:21:06 [INFO]: Epoch 034 - training loss: 0.4606, validation loss: 1.8621
2024-06-03 13:21:17 [INFO]: Epoch 035 - training loss: 0.4580, validation loss: 1.8675
2024-06-03 13:21:28 [INFO]: Epoch 036 - training loss: 0.4567, validation loss: 1.8680
2024-06-03 13:21:40 [INFO]: Epoch 037 - training loss: 0.4571, validation loss: 1.8678
2024-06-03 13:21:50 [INFO]: Epoch 038 - training loss: 0.4553, validation loss: 1.8783
2024-06-03 13:22:00 [INFO]: Epoch 039 - training loss: 0.4517, validation loss: 1.8815
2024-06-03 13:22:11 [INFO]: Epoch 040 - training loss: 0.4512, validation loss: 1.8538
2024-06-03 13:22:20 [INFO]: Epoch 041 - training loss: 0.4481, validation loss: 1.8668
2024-06-03 13:22:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 13:22:20 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 13:22:20 [INFO]: Saved the model to results_block_rate05/Electricity/Pyraformer_Electricity/round_4/20240603_T131436/Pyraformer.pypots
2024-06-03 13:22:27 [INFO]: Successfully saved to results_block_rate05/Electricity/Pyraformer_Electricity/round_4/imputation.pkl
2024-06-03 13:22:27 [INFO]: Round4 - Pyraformer on Electricity: MAE=1.2655, MSE=3.3069, MRE=0.6793
2024-06-03 13:22:27 [INFO]: Done! Final results:
Averaged Pyraformer (15,940,914 params) on Electricity: MAE=1.2897 ± 0.016874850937795293, MSE=3.3562 ± 0.05859556302255378, MRE=0.6922 ± 0.009057574226566025, average inference time=1.47
