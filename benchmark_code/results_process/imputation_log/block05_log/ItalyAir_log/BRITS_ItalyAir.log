2024-06-03 10:00:02 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:00:02 [INFO]: Using the given device: cuda:0
2024-06-03 10:00:07 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_0/20240603_T100007
2024-06-03 10:00:07 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_0/20240603_T100007/tensorboard
2024-06-03 10:00:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-03 10:01:28 [INFO]: Epoch 001 - training loss: 1.1385, validation loss: 1.7004
2024-06-03 10:02:38 [INFO]: Epoch 002 - training loss: 0.9286, validation loss: 1.2560
2024-06-03 10:03:45 [INFO]: Epoch 003 - training loss: 0.7978, validation loss: 0.9535
2024-06-03 10:04:56 [INFO]: Epoch 004 - training loss: 0.7005, validation loss: 0.7758
2024-06-03 10:06:02 [INFO]: Epoch 005 - training loss: 0.6365, validation loss: 0.7638
2024-06-03 10:07:11 [INFO]: Epoch 006 - training loss: 0.5952, validation loss: 0.6688
2024-06-03 10:08:20 [INFO]: Epoch 007 - training loss: 0.5590, validation loss: 0.6413
2024-06-03 10:09:30 [INFO]: Epoch 008 - training loss: 0.5365, validation loss: 0.6414
2024-06-03 10:10:36 [INFO]: Epoch 009 - training loss: 0.5138, validation loss: 0.6108
2024-06-03 10:11:40 [INFO]: Epoch 010 - training loss: 0.5013, validation loss: 0.6142
2024-06-03 10:12:47 [INFO]: Epoch 011 - training loss: 0.4821, validation loss: 0.5982
2024-06-03 10:13:49 [INFO]: Epoch 012 - training loss: 0.4721, validation loss: 0.5936
2024-06-03 10:14:48 [INFO]: Epoch 013 - training loss: 0.4619, validation loss: 0.5886
2024-06-03 10:15:50 [INFO]: Epoch 014 - training loss: 0.4524, validation loss: 0.6033
2024-06-03 10:16:50 [INFO]: Epoch 015 - training loss: 0.4456, validation loss: 0.5884
2024-06-03 10:17:53 [INFO]: Epoch 016 - training loss: 0.4390, validation loss: 0.5841
2024-06-03 10:18:25 [INFO]: Epoch 017 - training loss: 0.4380, validation loss: 0.6282
2024-06-03 10:18:49 [INFO]: Epoch 018 - training loss: 0.4384, validation loss: 0.5892
2024-06-03 10:19:12 [INFO]: Epoch 019 - training loss: 0.4200, validation loss: 0.5752
2024-06-03 10:19:35 [INFO]: Epoch 020 - training loss: 0.4176, validation loss: 0.5816
2024-06-03 10:19:58 [INFO]: Epoch 021 - training loss: 0.4164, validation loss: 0.5813
2024-06-03 10:20:15 [INFO]: Epoch 022 - training loss: 0.4105, validation loss: 0.5742
2024-06-03 10:20:33 [INFO]: Epoch 023 - training loss: 0.4046, validation loss: 0.5662
2024-06-03 10:20:51 [INFO]: Epoch 024 - training loss: 0.4007, validation loss: 0.5646
2024-06-03 10:21:10 [INFO]: Epoch 025 - training loss: 0.4000, validation loss: 0.5693
2024-06-03 10:21:26 [INFO]: Epoch 026 - training loss: 0.3948, validation loss: 0.5577
2024-06-03 10:21:43 [INFO]: Epoch 027 - training loss: 0.3923, validation loss: 0.5891
2024-06-03 10:22:01 [INFO]: Epoch 028 - training loss: 0.3871, validation loss: 0.5532
2024-06-03 10:22:19 [INFO]: Epoch 029 - training loss: 0.3833, validation loss: 0.5587
2024-06-03 10:22:37 [INFO]: Epoch 030 - training loss: 0.3857, validation loss: 0.5567
2024-06-03 10:22:54 [INFO]: Epoch 031 - training loss: 0.3822, validation loss: 0.5482
2024-06-03 10:23:12 [INFO]: Epoch 032 - training loss: 0.3802, validation loss: 0.5558
2024-06-03 10:23:30 [INFO]: Epoch 033 - training loss: 0.3808, validation loss: 0.5446
2024-06-03 10:23:44 [INFO]: Epoch 034 - training loss: 0.3740, validation loss: 0.5486
2024-06-03 10:23:59 [INFO]: Epoch 035 - training loss: 0.3717, validation loss: 0.5361
2024-06-03 10:24:15 [INFO]: Epoch 036 - training loss: 0.3734, validation loss: 0.5505
2024-06-03 10:24:30 [INFO]: Epoch 037 - training loss: 0.3677, validation loss: 0.5274
2024-06-03 10:24:45 [INFO]: Epoch 038 - training loss: 0.3657, validation loss: 0.5259
2024-06-03 10:24:56 [INFO]: Epoch 039 - training loss: 0.3628, validation loss: 0.5276
2024-06-03 10:25:09 [INFO]: Epoch 040 - training loss: 0.3611, validation loss: 0.5360
2024-06-03 10:25:20 [INFO]: Epoch 041 - training loss: 0.3572, validation loss: 0.5275
2024-06-03 10:25:33 [INFO]: Epoch 042 - training loss: 0.3563, validation loss: 0.5267
2024-06-03 10:25:42 [INFO]: Epoch 043 - training loss: 0.3499, validation loss: 0.5270
2024-06-03 10:25:53 [INFO]: Epoch 044 - training loss: 0.3507, validation loss: 0.5253
2024-06-03 10:26:04 [INFO]: Epoch 045 - training loss: 0.3476, validation loss: 0.5238
2024-06-03 10:26:11 [INFO]: Epoch 046 - training loss: 0.3498, validation loss: 0.5188
2024-06-03 10:26:18 [INFO]: Epoch 047 - training loss: 0.3508, validation loss: 0.5341
2024-06-03 10:26:26 [INFO]: Epoch 048 - training loss: 0.3449, validation loss: 0.5345
2024-06-03 10:26:34 [INFO]: Epoch 049 - training loss: 0.3415, validation loss: 0.5131
2024-06-03 10:26:40 [INFO]: Epoch 050 - training loss: 0.3430, validation loss: 0.5077
2024-06-03 10:26:46 [INFO]: Epoch 051 - training loss: 0.3394, validation loss: 0.5199
2024-06-03 10:26:52 [INFO]: Epoch 052 - training loss: 0.3396, validation loss: 0.5101
2024-06-03 10:26:58 [INFO]: Epoch 053 - training loss: 0.3375, validation loss: 0.5102
2024-06-03 10:27:04 [INFO]: Epoch 054 - training loss: 0.3389, validation loss: 0.5176
2024-06-03 10:27:11 [INFO]: Epoch 055 - training loss: 0.3348, validation loss: 0.5175
2024-06-03 10:27:18 [INFO]: Epoch 056 - training loss: 0.3290, validation loss: 0.5069
2024-06-03 10:27:25 [INFO]: Epoch 057 - training loss: 0.3266, validation loss: 0.4975
2024-06-03 10:27:30 [INFO]: Epoch 058 - training loss: 0.3262, validation loss: 0.5115
2024-06-03 10:27:36 [INFO]: Epoch 059 - training loss: 0.3264, validation loss: 0.4927
2024-06-03 10:27:42 [INFO]: Epoch 060 - training loss: 0.3251, validation loss: 0.5031
2024-06-03 10:27:47 [INFO]: Epoch 061 - training loss: 0.3199, validation loss: 0.4944
2024-06-03 10:27:53 [INFO]: Epoch 062 - training loss: 0.3198, validation loss: 0.5025
2024-06-03 10:27:59 [INFO]: Epoch 063 - training loss: 0.3171, validation loss: 0.4981
2024-06-03 10:28:05 [INFO]: Epoch 064 - training loss: 0.3166, validation loss: 0.4951
2024-06-03 10:28:10 [INFO]: Epoch 065 - training loss: 0.3168, validation loss: 0.4944
2024-06-03 10:28:16 [INFO]: Epoch 066 - training loss: 0.3185, validation loss: 0.4945
2024-06-03 10:28:22 [INFO]: Epoch 067 - training loss: 0.3124, validation loss: 0.5095
2024-06-03 10:28:28 [INFO]: Epoch 068 - training loss: 0.3139, validation loss: 0.5048
2024-06-03 10:28:33 [INFO]: Epoch 069 - training loss: 0.3120, validation loss: 0.4986
2024-06-03 10:28:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:28:33 [INFO]: Finished training. The best model is from epoch#59.
2024-06-03 10:28:33 [INFO]: Saved the model to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_0/20240603_T100007/BRITS.pypots
2024-06-03 10:28:42 [INFO]: Successfully saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_0/imputation.pkl
2024-06-03 10:28:42 [INFO]: Round0 - BRITS on ItalyAir: MAE=0.4547, MSE=0.4562, MRE=0.5557
2024-06-03 10:28:42 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:28:42 [INFO]: Using the given device: cuda:0
2024-06-03 10:28:42 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_1/20240603_T102842
2024-06-03 10:28:42 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_1/20240603_T102842/tensorboard
2024-06-03 10:28:42 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-03 10:28:48 [INFO]: Epoch 001 - training loss: 1.1554, validation loss: 1.6163
2024-06-03 10:28:54 [INFO]: Epoch 002 - training loss: 0.9234, validation loss: 1.0835
2024-06-03 10:29:00 [INFO]: Epoch 003 - training loss: 0.7917, validation loss: 0.8245
2024-06-03 10:29:07 [INFO]: Epoch 004 - training loss: 0.7045, validation loss: 0.6988
2024-06-03 10:29:12 [INFO]: Epoch 005 - training loss: 0.6445, validation loss: 0.6366
2024-06-03 10:29:17 [INFO]: Epoch 006 - training loss: 0.5947, validation loss: 0.6680
2024-06-03 10:29:23 [INFO]: Epoch 007 - training loss: 0.5607, validation loss: 0.5984
2024-06-03 10:29:28 [INFO]: Epoch 008 - training loss: 0.5368, validation loss: 0.6104
2024-06-03 10:29:33 [INFO]: Epoch 009 - training loss: 0.5253, validation loss: 0.5833
2024-06-03 10:29:39 [INFO]: Epoch 010 - training loss: 0.5043, validation loss: 0.5736
2024-06-03 10:29:44 [INFO]: Epoch 011 - training loss: 0.4893, validation loss: 0.5666
2024-06-03 10:29:49 [INFO]: Epoch 012 - training loss: 0.4800, validation loss: 0.5799
2024-06-03 10:29:56 [INFO]: Epoch 013 - training loss: 0.4685, validation loss: 0.5736
2024-06-03 10:30:01 [INFO]: Epoch 014 - training loss: 0.4611, validation loss: 0.5889
2024-06-03 10:30:07 [INFO]: Epoch 015 - training loss: 0.4509, validation loss: 0.5575
2024-06-03 10:30:13 [INFO]: Epoch 016 - training loss: 0.4431, validation loss: 0.5617
2024-06-03 10:30:18 [INFO]: Epoch 017 - training loss: 0.4337, validation loss: 0.5713
2024-06-03 10:30:23 [INFO]: Epoch 018 - training loss: 0.4284, validation loss: 0.5539
2024-06-03 10:30:28 [INFO]: Epoch 019 - training loss: 0.4222, validation loss: 0.5689
2024-06-03 10:30:33 [INFO]: Epoch 020 - training loss: 0.4163, validation loss: 0.5653
2024-06-03 10:30:39 [INFO]: Epoch 021 - training loss: 0.4116, validation loss: 0.5388
2024-06-03 10:30:44 [INFO]: Epoch 022 - training loss: 0.4052, validation loss: 0.5496
2024-06-03 10:30:50 [INFO]: Epoch 023 - training loss: 0.4046, validation loss: 0.5428
2024-06-03 10:30:56 [INFO]: Epoch 024 - training loss: 0.3981, validation loss: 0.5420
2024-06-03 10:31:01 [INFO]: Epoch 025 - training loss: 0.3986, validation loss: 0.5469
2024-06-03 10:31:06 [INFO]: Epoch 026 - training loss: 0.3952, validation loss: 0.5391
2024-06-03 10:31:11 [INFO]: Epoch 027 - training loss: 0.3933, validation loss: 0.5383
2024-06-03 10:31:17 [INFO]: Epoch 028 - training loss: 0.3846, validation loss: 0.5430
2024-06-03 10:31:22 [INFO]: Epoch 029 - training loss: 0.3822, validation loss: 0.5441
2024-06-03 10:31:28 [INFO]: Epoch 030 - training loss: 0.3856, validation loss: 0.5394
2024-06-03 10:31:33 [INFO]: Epoch 031 - training loss: 0.3828, validation loss: 0.5256
2024-06-03 10:31:39 [INFO]: Epoch 032 - training loss: 0.3783, validation loss: 0.5457
2024-06-03 10:31:44 [INFO]: Epoch 033 - training loss: 0.3845, validation loss: 0.5304
2024-06-03 10:31:49 [INFO]: Epoch 034 - training loss: 0.3716, validation loss: 0.5297
2024-06-03 10:31:54 [INFO]: Epoch 035 - training loss: 0.3707, validation loss: 0.5397
2024-06-03 10:32:00 [INFO]: Epoch 036 - training loss: 0.3744, validation loss: 0.5164
2024-06-03 10:32:06 [INFO]: Epoch 037 - training loss: 0.3673, validation loss: 0.5273
2024-06-03 10:32:11 [INFO]: Epoch 038 - training loss: 0.3653, validation loss: 0.5207
2024-06-03 10:32:16 [INFO]: Epoch 039 - training loss: 0.3621, validation loss: 0.5226
2024-06-03 10:32:21 [INFO]: Epoch 040 - training loss: 0.3588, validation loss: 0.5077
2024-06-03 10:32:26 [INFO]: Epoch 041 - training loss: 0.3542, validation loss: 0.5118
2024-06-03 10:32:31 [INFO]: Epoch 042 - training loss: 0.3524, validation loss: 0.4935
2024-06-03 10:32:35 [INFO]: Epoch 043 - training loss: 0.3487, validation loss: 0.5161
2024-06-03 10:32:41 [INFO]: Epoch 044 - training loss: 0.3526, validation loss: 0.5010
2024-06-03 10:32:46 [INFO]: Epoch 045 - training loss: 0.3488, validation loss: 0.5117
2024-06-03 10:32:51 [INFO]: Epoch 046 - training loss: 0.3452, validation loss: 0.4870
2024-06-03 10:32:56 [INFO]: Epoch 047 - training loss: 0.3464, validation loss: 0.5033
2024-06-03 10:33:01 [INFO]: Epoch 048 - training loss: 0.3453, validation loss: 0.4983
2024-06-03 10:33:06 [INFO]: Epoch 049 - training loss: 0.3417, validation loss: 0.5068
2024-06-03 10:33:11 [INFO]: Epoch 050 - training loss: 0.3394, validation loss: 0.4938
2024-06-03 10:33:16 [INFO]: Epoch 051 - training loss: 0.3404, validation loss: 0.4949
2024-06-03 10:33:21 [INFO]: Epoch 052 - training loss: 0.3341, validation loss: 0.5006
2024-06-03 10:33:27 [INFO]: Epoch 053 - training loss: 0.3349, validation loss: 0.4977
2024-06-03 10:33:32 [INFO]: Epoch 054 - training loss: 0.3337, validation loss: 0.4900
2024-06-03 10:33:38 [INFO]: Epoch 055 - training loss: 0.3280, validation loss: 0.4996
2024-06-03 10:33:43 [INFO]: Epoch 056 - training loss: 0.3278, validation loss: 0.5045
2024-06-03 10:33:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:33:43 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 10:33:43 [INFO]: Saved the model to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_1/20240603_T102842/BRITS.pypots
2024-06-03 10:33:50 [INFO]: Successfully saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_1/imputation.pkl
2024-06-03 10:33:50 [INFO]: Round1 - BRITS on ItalyAir: MAE=0.4463, MSE=0.4447, MRE=0.5454
2024-06-03 10:33:50 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:33:50 [INFO]: Using the given device: cuda:0
2024-06-03 10:33:50 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_2/20240603_T103350
2024-06-03 10:33:50 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_2/20240603_T103350/tensorboard
2024-06-03 10:33:50 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-03 10:33:56 [INFO]: Epoch 001 - training loss: 1.1484, validation loss: 1.6476
2024-06-03 10:34:02 [INFO]: Epoch 002 - training loss: 0.9290, validation loss: 1.1870
2024-06-03 10:34:08 [INFO]: Epoch 003 - training loss: 0.8000, validation loss: 0.9721
2024-06-03 10:34:14 [INFO]: Epoch 004 - training loss: 0.7136, validation loss: 0.7957
2024-06-03 10:34:19 [INFO]: Epoch 005 - training loss: 0.6511, validation loss: 0.7236
2024-06-03 10:34:26 [INFO]: Epoch 006 - training loss: 0.5985, validation loss: 0.6791
2024-06-03 10:34:31 [INFO]: Epoch 007 - training loss: 0.5640, validation loss: 0.6879
2024-06-03 10:34:37 [INFO]: Epoch 008 - training loss: 0.5416, validation loss: 0.6340
2024-06-03 10:34:42 [INFO]: Epoch 009 - training loss: 0.5258, validation loss: 0.6274
2024-06-03 10:34:48 [INFO]: Epoch 010 - training loss: 0.5028, validation loss: 0.6209
2024-06-03 10:34:54 [INFO]: Epoch 011 - training loss: 0.4888, validation loss: 0.6062
2024-06-03 10:35:01 [INFO]: Epoch 012 - training loss: 0.4750, validation loss: 0.6097
2024-06-03 10:35:06 [INFO]: Epoch 013 - training loss: 0.4669, validation loss: 0.5895
2024-06-03 10:35:12 [INFO]: Epoch 014 - training loss: 0.4586, validation loss: 0.5975
2024-06-03 10:35:16 [INFO]: Epoch 015 - training loss: 0.4455, validation loss: 0.6117
2024-06-03 10:35:21 [INFO]: Epoch 016 - training loss: 0.4424, validation loss: 0.6029
2024-06-03 10:35:27 [INFO]: Epoch 017 - training loss: 0.4363, validation loss: 0.6014
2024-06-03 10:35:32 [INFO]: Epoch 018 - training loss: 0.4327, validation loss: 0.6381
2024-06-03 10:35:39 [INFO]: Epoch 019 - training loss: 0.4266, validation loss: 0.6040
2024-06-03 10:35:45 [INFO]: Epoch 020 - training loss: 0.4210, validation loss: 0.5933
2024-06-03 10:35:50 [INFO]: Epoch 021 - training loss: 0.4148, validation loss: 0.5937
2024-06-03 10:35:55 [INFO]: Epoch 022 - training loss: 0.4094, validation loss: 0.5819
2024-06-03 10:36:01 [INFO]: Epoch 023 - training loss: 0.4067, validation loss: 0.5891
2024-06-03 10:36:06 [INFO]: Epoch 024 - training loss: 0.4069, validation loss: 0.5935
2024-06-03 10:36:11 [INFO]: Epoch 025 - training loss: 0.3974, validation loss: 0.5993
2024-06-03 10:36:16 [INFO]: Epoch 026 - training loss: 0.3976, validation loss: 0.5973
2024-06-03 10:36:22 [INFO]: Epoch 027 - training loss: 0.3915, validation loss: 0.5965
2024-06-03 10:36:27 [INFO]: Epoch 028 - training loss: 0.3877, validation loss: 0.5846
2024-06-03 10:36:32 [INFO]: Epoch 029 - training loss: 0.3885, validation loss: 0.5971
2024-06-03 10:36:38 [INFO]: Epoch 030 - training loss: 0.3852, validation loss: 0.5778
2024-06-03 10:36:43 [INFO]: Epoch 031 - training loss: 0.3845, validation loss: 0.5806
2024-06-03 10:36:49 [INFO]: Epoch 032 - training loss: 0.3811, validation loss: 0.5894
2024-06-03 10:36:54 [INFO]: Epoch 033 - training loss: 0.3802, validation loss: 0.5939
2024-06-03 10:37:00 [INFO]: Epoch 034 - training loss: 0.3809, validation loss: 0.5740
2024-06-03 10:37:05 [INFO]: Epoch 035 - training loss: 0.3799, validation loss: 0.5803
2024-06-03 10:37:10 [INFO]: Epoch 036 - training loss: 0.3722, validation loss: 0.5742
2024-06-03 10:37:15 [INFO]: Epoch 037 - training loss: 0.3711, validation loss: 0.5718
2024-06-03 10:37:20 [INFO]: Epoch 038 - training loss: 0.3677, validation loss: 0.5689
2024-06-03 10:37:25 [INFO]: Epoch 039 - training loss: 0.3632, validation loss: 0.5757
2024-06-03 10:37:30 [INFO]: Epoch 040 - training loss: 0.3615, validation loss: 0.5781
2024-06-03 10:37:35 [INFO]: Epoch 041 - training loss: 0.3616, validation loss: 0.5561
2024-06-03 10:37:41 [INFO]: Epoch 042 - training loss: 0.3593, validation loss: 0.5526
2024-06-03 10:37:46 [INFO]: Epoch 043 - training loss: 0.3591, validation loss: 0.5617
2024-06-03 10:37:52 [INFO]: Epoch 044 - training loss: 0.3570, validation loss: 0.5567
2024-06-03 10:37:57 [INFO]: Epoch 045 - training loss: 0.3571, validation loss: 0.5620
2024-06-03 10:38:03 [INFO]: Epoch 046 - training loss: 0.3535, validation loss: 0.5593
2024-06-03 10:38:07 [INFO]: Epoch 047 - training loss: 0.3495, validation loss: 0.5500
2024-06-03 10:38:13 [INFO]: Epoch 048 - training loss: 0.3462, validation loss: 0.5458
2024-06-03 10:38:17 [INFO]: Epoch 049 - training loss: 0.3448, validation loss: 0.5476
2024-06-03 10:38:23 [INFO]: Epoch 050 - training loss: 0.3463, validation loss: 0.5308
2024-06-03 10:38:28 [INFO]: Epoch 051 - training loss: 0.3444, validation loss: 0.5418
2024-06-03 10:38:34 [INFO]: Epoch 052 - training loss: 0.3427, validation loss: 0.5560
2024-06-03 10:38:39 [INFO]: Epoch 053 - training loss: 0.3404, validation loss: 0.5417
2024-06-03 10:38:45 [INFO]: Epoch 054 - training loss: 0.3385, validation loss: 0.5392
2024-06-03 10:38:51 [INFO]: Epoch 055 - training loss: 0.3366, validation loss: 0.5454
2024-06-03 10:38:57 [INFO]: Epoch 056 - training loss: 0.3333, validation loss: 0.5398
2024-06-03 10:39:02 [INFO]: Epoch 057 - training loss: 0.3343, validation loss: 0.5461
2024-06-03 10:39:08 [INFO]: Epoch 058 - training loss: 0.3314, validation loss: 0.5249
2024-06-03 10:39:13 [INFO]: Epoch 059 - training loss: 0.3278, validation loss: 0.5312
2024-06-03 10:39:18 [INFO]: Epoch 060 - training loss: 0.3266, validation loss: 0.5316
2024-06-03 10:39:24 [INFO]: Epoch 061 - training loss: 0.3275, validation loss: 0.5215
2024-06-03 10:39:29 [INFO]: Epoch 062 - training loss: 0.3231, validation loss: 0.5321
2024-06-03 10:39:35 [INFO]: Epoch 063 - training loss: 0.3200, validation loss: 0.5420
2024-06-03 10:39:40 [INFO]: Epoch 064 - training loss: 0.3204, validation loss: 0.5284
2024-06-03 10:39:46 [INFO]: Epoch 065 - training loss: 0.3186, validation loss: 0.5353
2024-06-03 10:39:52 [INFO]: Epoch 066 - training loss: 0.3141, validation loss: 0.5203
2024-06-03 10:39:58 [INFO]: Epoch 067 - training loss: 0.3135, validation loss: 0.5239
2024-06-03 10:40:03 [INFO]: Epoch 068 - training loss: 0.3091, validation loss: 0.5343
2024-06-03 10:40:08 [INFO]: Epoch 069 - training loss: 0.3079, validation loss: 0.5182
2024-06-03 10:40:14 [INFO]: Epoch 070 - training loss: 0.3084, validation loss: 0.5210
2024-06-03 10:40:18 [INFO]: Epoch 071 - training loss: 0.3074, validation loss: 0.5286
2024-06-03 10:40:23 [INFO]: Epoch 072 - training loss: 0.3067, validation loss: 0.5116
2024-06-03 10:40:29 [INFO]: Epoch 073 - training loss: 0.3039, validation loss: 0.5175
2024-06-03 10:40:34 [INFO]: Epoch 074 - training loss: 0.3041, validation loss: 0.5193
2024-06-03 10:40:41 [INFO]: Epoch 075 - training loss: 0.3043, validation loss: 0.5143
2024-06-03 10:40:46 [INFO]: Epoch 076 - training loss: 0.3023, validation loss: 0.5021
2024-06-03 10:40:52 [INFO]: Epoch 077 - training loss: 0.2974, validation loss: 0.5243
2024-06-03 10:40:57 [INFO]: Epoch 078 - training loss: 0.2970, validation loss: 0.5023
2024-06-03 10:41:03 [INFO]: Epoch 079 - training loss: 0.2981, validation loss: 0.5140
2024-06-03 10:41:08 [INFO]: Epoch 080 - training loss: 0.2945, validation loss: 0.5128
2024-06-03 10:41:14 [INFO]: Epoch 081 - training loss: 0.2961, validation loss: 0.5031
2024-06-03 10:41:19 [INFO]: Epoch 082 - training loss: 0.2946, validation loss: 0.5112
2024-06-03 10:41:24 [INFO]: Epoch 083 - training loss: 0.2977, validation loss: 0.5262
2024-06-03 10:41:29 [INFO]: Epoch 084 - training loss: 0.2949, validation loss: 0.5067
2024-06-03 10:41:34 [INFO]: Epoch 085 - training loss: 0.2920, validation loss: 0.5147
2024-06-03 10:41:39 [INFO]: Epoch 086 - training loss: 0.2902, validation loss: 0.5169
2024-06-03 10:41:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:41:39 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 10:41:39 [INFO]: Saved the model to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_2/20240603_T103350/BRITS.pypots
2024-06-03 10:41:47 [INFO]: Successfully saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_2/imputation.pkl
2024-06-03 10:41:47 [INFO]: Round2 - BRITS on ItalyAir: MAE=0.4596, MSE=0.4644, MRE=0.5617
2024-06-03 10:41:47 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:41:47 [INFO]: Using the given device: cuda:0
2024-06-03 10:41:47 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_3/20240603_T104147
2024-06-03 10:41:47 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_3/20240603_T104147/tensorboard
2024-06-03 10:41:47 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-03 10:41:53 [INFO]: Epoch 001 - training loss: 1.1416, validation loss: 1.5891
2024-06-03 10:41:59 [INFO]: Epoch 002 - training loss: 0.9219, validation loss: 1.1668
2024-06-03 10:42:04 [INFO]: Epoch 003 - training loss: 0.7856, validation loss: 0.8517
2024-06-03 10:42:10 [INFO]: Epoch 004 - training loss: 0.6887, validation loss: 0.6974
2024-06-03 10:42:15 [INFO]: Epoch 005 - training loss: 0.6372, validation loss: 0.6756
2024-06-03 10:42:21 [INFO]: Epoch 006 - training loss: 0.5959, validation loss: 0.6667
2024-06-03 10:42:26 [INFO]: Epoch 007 - training loss: 0.5592, validation loss: 0.6393
2024-06-03 10:42:32 [INFO]: Epoch 008 - training loss: 0.5338, validation loss: 0.5987
2024-06-03 10:42:38 [INFO]: Epoch 009 - training loss: 0.5103, validation loss: 0.5914
2024-06-03 10:42:43 [INFO]: Epoch 010 - training loss: 0.4994, validation loss: 0.5839
2024-06-03 10:42:47 [INFO]: Epoch 011 - training loss: 0.4881, validation loss: 0.5903
2024-06-03 10:42:52 [INFO]: Epoch 012 - training loss: 0.4774, validation loss: 0.5719
2024-06-03 10:42:58 [INFO]: Epoch 013 - training loss: 0.4605, validation loss: 0.5858
2024-06-03 10:43:03 [INFO]: Epoch 014 - training loss: 0.4488, validation loss: 0.5778
2024-06-03 10:43:08 [INFO]: Epoch 015 - training loss: 0.4440, validation loss: 0.5582
2024-06-03 10:43:14 [INFO]: Epoch 016 - training loss: 0.4363, validation loss: 0.5703
2024-06-03 10:43:19 [INFO]: Epoch 017 - training loss: 0.4293, validation loss: 0.5638
2024-06-03 10:43:24 [INFO]: Epoch 018 - training loss: 0.4221, validation loss: 0.5635
2024-06-03 10:43:30 [INFO]: Epoch 019 - training loss: 0.4161, validation loss: 0.5441
2024-06-03 10:43:34 [INFO]: Epoch 020 - training loss: 0.4139, validation loss: 0.5645
2024-06-03 10:43:40 [INFO]: Epoch 021 - training loss: 0.4112, validation loss: 0.5392
2024-06-03 10:43:45 [INFO]: Epoch 022 - training loss: 0.4036, validation loss: 0.5496
2024-06-03 10:43:50 [INFO]: Epoch 023 - training loss: 0.3999, validation loss: 0.5279
2024-06-03 10:43:56 [INFO]: Epoch 024 - training loss: 0.3994, validation loss: 0.5448
2024-06-03 10:44:01 [INFO]: Epoch 025 - training loss: 0.3964, validation loss: 0.5360
2024-06-03 10:44:07 [INFO]: Epoch 026 - training loss: 0.3935, validation loss: 0.5532
2024-06-03 10:44:12 [INFO]: Epoch 027 - training loss: 0.3915, validation loss: 0.5338
2024-06-03 10:44:17 [INFO]: Epoch 028 - training loss: 0.3858, validation loss: 0.5374
2024-06-03 10:44:22 [INFO]: Epoch 029 - training loss: 0.3824, validation loss: 0.5365
2024-06-03 10:44:27 [INFO]: Epoch 030 - training loss: 0.3789, validation loss: 0.5284
2024-06-03 10:44:32 [INFO]: Epoch 031 - training loss: 0.3776, validation loss: 0.5334
2024-06-03 10:44:37 [INFO]: Epoch 032 - training loss: 0.3768, validation loss: 0.5265
2024-06-03 10:44:43 [INFO]: Epoch 033 - training loss: 0.3764, validation loss: 0.5110
2024-06-03 10:44:48 [INFO]: Epoch 034 - training loss: 0.3726, validation loss: 0.5271
2024-06-03 10:44:54 [INFO]: Epoch 035 - training loss: 0.3685, validation loss: 0.5036
2024-06-03 10:44:59 [INFO]: Epoch 036 - training loss: 0.3669, validation loss: 0.5501
2024-06-03 10:45:05 [INFO]: Epoch 037 - training loss: 0.3652, validation loss: 0.5238
2024-06-03 10:45:10 [INFO]: Epoch 038 - training loss: 0.3601, validation loss: 0.5256
2024-06-03 10:45:15 [INFO]: Epoch 039 - training loss: 0.3603, validation loss: 0.5179
2024-06-03 10:45:21 [INFO]: Epoch 040 - training loss: 0.3611, validation loss: 0.5266
2024-06-03 10:45:26 [INFO]: Epoch 041 - training loss: 0.3588, validation loss: 0.5025
2024-06-03 10:45:32 [INFO]: Epoch 042 - training loss: 0.3566, validation loss: 0.5159
2024-06-03 10:45:38 [INFO]: Epoch 043 - training loss: 0.3526, validation loss: 0.5199
2024-06-03 10:45:44 [INFO]: Epoch 044 - training loss: 0.3530, validation loss: 0.5021
2024-06-03 10:45:49 [INFO]: Epoch 045 - training loss: 0.3469, validation loss: 0.5101
2024-06-03 10:45:55 [INFO]: Epoch 046 - training loss: 0.3442, validation loss: 0.5196
2024-06-03 10:46:01 [INFO]: Epoch 047 - training loss: 0.3395, validation loss: 0.5031
2024-06-03 10:46:07 [INFO]: Epoch 048 - training loss: 0.3387, validation loss: 0.5137
2024-06-03 10:46:12 [INFO]: Epoch 049 - training loss: 0.3424, validation loss: 0.5012
2024-06-03 10:46:19 [INFO]: Epoch 050 - training loss: 0.3389, validation loss: 0.4994
2024-06-03 10:46:24 [INFO]: Epoch 051 - training loss: 0.3336, validation loss: 0.5023
2024-06-03 10:46:30 [INFO]: Epoch 052 - training loss: 0.3325, validation loss: 0.4972
2024-06-03 10:46:35 [INFO]: Epoch 053 - training loss: 0.3340, validation loss: 0.4906
2024-06-03 10:46:40 [INFO]: Epoch 054 - training loss: 0.3299, validation loss: 0.4997
2024-06-03 10:46:47 [INFO]: Epoch 055 - training loss: 0.3274, validation loss: 0.4988
2024-06-03 10:46:53 [INFO]: Epoch 056 - training loss: 0.3261, validation loss: 0.4898
2024-06-03 10:46:58 [INFO]: Epoch 057 - training loss: 0.3256, validation loss: 0.4963
2024-06-03 10:47:02 [INFO]: Epoch 058 - training loss: 0.3284, validation loss: 0.4903
2024-06-03 10:47:08 [INFO]: Epoch 059 - training loss: 0.3243, validation loss: 0.4854
2024-06-03 10:47:13 [INFO]: Epoch 060 - training loss: 0.3242, validation loss: 0.5021
2024-06-03 10:47:19 [INFO]: Epoch 061 - training loss: 0.3191, validation loss: 0.4892
2024-06-03 10:47:24 [INFO]: Epoch 062 - training loss: 0.3210, validation loss: 0.4863
2024-06-03 10:47:29 [INFO]: Epoch 063 - training loss: 0.3143, validation loss: 0.4845
2024-06-03 10:47:34 [INFO]: Epoch 064 - training loss: 0.3123, validation loss: 0.4929
2024-06-03 10:47:39 [INFO]: Epoch 065 - training loss: 0.3131, validation loss: 0.4906
2024-06-03 10:47:44 [INFO]: Epoch 066 - training loss: 0.3102, validation loss: 0.4877
2024-06-03 10:47:50 [INFO]: Epoch 067 - training loss: 0.3108, validation loss: 0.4824
2024-06-03 10:47:55 [INFO]: Epoch 068 - training loss: 0.3099, validation loss: 0.4747
2024-06-03 10:48:00 [INFO]: Epoch 069 - training loss: 0.3089, validation loss: 0.4830
2024-06-03 10:48:06 [INFO]: Epoch 070 - training loss: 0.3033, validation loss: 0.4858
2024-06-03 10:48:11 [INFO]: Epoch 071 - training loss: 0.3039, validation loss: 0.4833
2024-06-03 10:48:16 [INFO]: Epoch 072 - training loss: 0.3048, validation loss: 0.4854
2024-06-03 10:48:22 [INFO]: Epoch 073 - training loss: 0.2995, validation loss: 0.4904
2024-06-03 10:48:27 [INFO]: Epoch 074 - training loss: 0.2996, validation loss: 0.4912
2024-06-03 10:48:32 [INFO]: Epoch 075 - training loss: 0.3059, validation loss: 0.4887
2024-06-03 10:48:36 [INFO]: Epoch 076 - training loss: 0.2976, validation loss: 0.4996
2024-06-03 10:48:40 [INFO]: Epoch 077 - training loss: 0.2967, validation loss: 0.4875
2024-06-03 10:48:45 [INFO]: Epoch 078 - training loss: 0.2946, validation loss: 0.4774
2024-06-03 10:48:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:48:45 [INFO]: Finished training. The best model is from epoch#68.
2024-06-03 10:48:45 [INFO]: Saved the model to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_3/20240603_T104147/BRITS.pypots
2024-06-03 10:48:51 [INFO]: Successfully saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_3/imputation.pkl
2024-06-03 10:48:51 [INFO]: Round3 - BRITS on ItalyAir: MAE=0.4473, MSE=0.4390, MRE=0.5467
2024-06-03 10:48:51 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:48:51 [INFO]: Using the given device: cuda:0
2024-06-03 10:48:51 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_4/20240603_T104851
2024-06-03 10:48:51 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_4/20240603_T104851/tensorboard
2024-06-03 10:48:51 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 596,912
2024-06-03 10:48:56 [INFO]: Epoch 001 - training loss: 1.1551, validation loss: 1.7778
2024-06-03 10:49:00 [INFO]: Epoch 002 - training loss: 0.9321, validation loss: 1.3070
2024-06-03 10:49:05 [INFO]: Epoch 003 - training loss: 0.7987, validation loss: 0.9155
2024-06-03 10:49:10 [INFO]: Epoch 004 - training loss: 0.7073, validation loss: 0.7476
2024-06-03 10:49:14 [INFO]: Epoch 005 - training loss: 0.6505, validation loss: 0.7401
2024-06-03 10:49:19 [INFO]: Epoch 006 - training loss: 0.6071, validation loss: 0.6632
2024-06-03 10:49:24 [INFO]: Epoch 007 - training loss: 0.5740, validation loss: 0.6634
2024-06-03 10:49:28 [INFO]: Epoch 008 - training loss: 0.5506, validation loss: 0.5998
2024-06-03 10:49:33 [INFO]: Epoch 009 - training loss: 0.5276, validation loss: 0.6219
2024-06-03 10:49:38 [INFO]: Epoch 010 - training loss: 0.5127, validation loss: 0.6203
2024-06-03 10:49:42 [INFO]: Epoch 011 - training loss: 0.5060, validation loss: 0.5861
2024-06-03 10:49:47 [INFO]: Epoch 012 - training loss: 0.4835, validation loss: 0.5729
2024-06-03 10:49:51 [INFO]: Epoch 013 - training loss: 0.4730, validation loss: 0.5697
2024-06-03 10:49:56 [INFO]: Epoch 014 - training loss: 0.4636, validation loss: 0.5702
2024-06-03 10:50:01 [INFO]: Epoch 015 - training loss: 0.4513, validation loss: 0.5486
2024-06-03 10:50:05 [INFO]: Epoch 016 - training loss: 0.4435, validation loss: 0.5535
2024-06-03 10:50:10 [INFO]: Epoch 017 - training loss: 0.4376, validation loss: 0.5539
2024-06-03 10:50:15 [INFO]: Epoch 018 - training loss: 0.4318, validation loss: 0.5553
2024-06-03 10:50:19 [INFO]: Epoch 019 - training loss: 0.4315, validation loss: 0.5637
2024-06-03 10:50:24 [INFO]: Epoch 020 - training loss: 0.4229, validation loss: 0.5529
2024-06-03 10:50:28 [INFO]: Epoch 021 - training loss: 0.4181, validation loss: 0.5471
2024-06-03 10:50:33 [INFO]: Epoch 022 - training loss: 0.4147, validation loss: 0.5500
2024-06-03 10:50:38 [INFO]: Epoch 023 - training loss: 0.4087, validation loss: 0.5368
2024-06-03 10:50:43 [INFO]: Epoch 024 - training loss: 0.4071, validation loss: 0.5598
2024-06-03 10:50:48 [INFO]: Epoch 025 - training loss: 0.4002, validation loss: 0.5554
2024-06-03 10:50:52 [INFO]: Epoch 026 - training loss: 0.3983, validation loss: 0.5581
2024-06-03 10:50:57 [INFO]: Epoch 027 - training loss: 0.3989, validation loss: 0.5392
2024-06-03 10:51:01 [INFO]: Epoch 028 - training loss: 0.3940, validation loss: 0.5381
2024-06-03 10:51:05 [INFO]: Epoch 029 - training loss: 0.3908, validation loss: 0.5364
2024-06-03 10:51:11 [INFO]: Epoch 030 - training loss: 0.3888, validation loss: 0.5375
2024-06-03 10:51:16 [INFO]: Epoch 031 - training loss: 0.3859, validation loss: 0.5481
2024-06-03 10:51:21 [INFO]: Epoch 032 - training loss: 0.3795, validation loss: 0.5399
2024-06-03 10:51:26 [INFO]: Epoch 033 - training loss: 0.3821, validation loss: 0.5369
2024-06-03 10:51:31 [INFO]: Epoch 034 - training loss: 0.3797, validation loss: 0.5219
2024-06-03 10:51:36 [INFO]: Epoch 035 - training loss: 0.3734, validation loss: 0.5291
2024-06-03 10:51:41 [INFO]: Epoch 036 - training loss: 0.3713, validation loss: 0.5167
2024-06-03 10:51:46 [INFO]: Epoch 037 - training loss: 0.3675, validation loss: 0.5352
2024-06-03 10:51:51 [INFO]: Epoch 038 - training loss: 0.3666, validation loss: 0.5169
2024-06-03 10:51:55 [INFO]: Epoch 039 - training loss: 0.3650, validation loss: 0.5105
2024-06-03 10:52:00 [INFO]: Epoch 040 - training loss: 0.3628, validation loss: 0.5143
2024-06-03 10:52:05 [INFO]: Epoch 041 - training loss: 0.3594, validation loss: 0.5081
2024-06-03 10:52:09 [INFO]: Epoch 042 - training loss: 0.3592, validation loss: 0.5091
2024-06-03 10:52:14 [INFO]: Epoch 043 - training loss: 0.3540, validation loss: 0.5128
2024-06-03 10:52:19 [INFO]: Epoch 044 - training loss: 0.3513, validation loss: 0.5146
2024-06-03 10:52:25 [INFO]: Epoch 045 - training loss: 0.3491, validation loss: 0.5084
2024-06-03 10:52:30 [INFO]: Epoch 046 - training loss: 0.3500, validation loss: 0.5063
2024-06-03 10:52:35 [INFO]: Epoch 047 - training loss: 0.3437, validation loss: 0.5062
2024-06-03 10:52:38 [INFO]: Epoch 048 - training loss: 0.3405, validation loss: 0.5028
2024-06-03 10:52:40 [INFO]: Epoch 049 - training loss: 0.3455, validation loss: 0.4897
2024-06-03 10:52:43 [INFO]: Epoch 050 - training loss: 0.3421, validation loss: 0.4986
2024-06-03 10:52:45 [INFO]: Epoch 051 - training loss: 0.3420, validation loss: 0.5098
2024-06-03 10:52:47 [INFO]: Epoch 052 - training loss: 0.3373, validation loss: 0.4955
2024-06-03 10:52:49 [INFO]: Epoch 053 - training loss: 0.3356, validation loss: 0.4940
2024-06-03 10:52:50 [INFO]: Epoch 054 - training loss: 0.3336, validation loss: 0.4973
2024-06-03 10:52:50 [INFO]: Epoch 055 - training loss: 0.3300, validation loss: 0.4844
2024-06-03 10:52:51 [INFO]: Epoch 056 - training loss: 0.3279, validation loss: 0.5034
2024-06-03 10:52:52 [INFO]: Epoch 057 - training loss: 0.3283, validation loss: 0.4828
2024-06-03 10:52:52 [INFO]: Epoch 058 - training loss: 0.3275, validation loss: 0.4782
2024-06-03 10:52:53 [INFO]: Epoch 059 - training loss: 0.3253, validation loss: 0.4938
2024-06-03 10:52:53 [INFO]: Epoch 060 - training loss: 0.3229, validation loss: 0.4806
2024-06-03 10:52:54 [INFO]: Epoch 061 - training loss: 0.3254, validation loss: 0.4827
2024-06-03 10:52:55 [INFO]: Epoch 062 - training loss: 0.3239, validation loss: 0.4893
2024-06-03 10:52:55 [INFO]: Epoch 063 - training loss: 0.3190, validation loss: 0.4864
2024-06-03 10:52:56 [INFO]: Epoch 064 - training loss: 0.3160, validation loss: 0.4922
2024-06-03 10:52:56 [INFO]: Epoch 065 - training loss: 0.3164, validation loss: 0.4801
2024-06-03 10:52:57 [INFO]: Epoch 066 - training loss: 0.3114, validation loss: 0.4852
2024-06-03 10:52:58 [INFO]: Epoch 067 - training loss: 0.3132, validation loss: 0.4824
2024-06-03 10:52:58 [INFO]: Epoch 068 - training loss: 0.3093, validation loss: 0.5000
2024-06-03 10:52:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:52:58 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 10:52:58 [INFO]: Saved the model to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_4/20240603_T104851/BRITS.pypots
2024-06-03 10:52:59 [INFO]: Successfully saved to results_block_rate05/ItalyAir/BRITS_ItalyAir/round_4/imputation.pkl
2024-06-03 10:52:59 [INFO]: Round4 - BRITS on ItalyAir: MAE=0.4502, MSE=0.4528, MRE=0.5501
2024-06-03 10:52:59 [INFO]: Done! Final results:
Averaged BRITS (596,912 params) on ItalyAir: MAE=0.4516 ± 0.004943091027408941, MSE=0.4514 ± 0.008868174242798503, MRE=0.5519 ± 0.006040638314827873, average inference time=1.07
