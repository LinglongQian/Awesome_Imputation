2024-06-03 10:00:03 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:00:03 [INFO]: Using the given device: cuda:0
2024-06-03 10:00:07 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T100007
2024-06-03 10:00:07 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T100007/tensorboard
2024-06-03 10:00:12 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 10:00:24 [INFO]: Epoch 001 - training loss: 1.2223, validation loss: 2.3120
2024-06-03 10:00:32 [INFO]: Epoch 002 - training loss: 1.1203, validation loss: 2.0878
2024-06-03 10:00:39 [INFO]: Epoch 003 - training loss: 0.9808, validation loss: 1.3584
2024-06-03 10:00:48 [INFO]: Epoch 004 - training loss: 0.7449, validation loss: 1.1511
2024-06-03 10:00:56 [INFO]: Epoch 005 - training loss: 0.6414, validation loss: 0.9452
2024-06-03 10:01:03 [INFO]: Epoch 006 - training loss: 0.5612, validation loss: 0.7373
2024-06-03 10:01:11 [INFO]: Epoch 007 - training loss: 0.5185, validation loss: 0.7039
2024-06-03 10:01:19 [INFO]: Epoch 008 - training loss: 0.5073, validation loss: 0.7525
2024-06-03 10:01:26 [INFO]: Epoch 009 - training loss: 0.4874, validation loss: 0.7332
2024-06-03 10:01:33 [INFO]: Epoch 010 - training loss: 0.4796, validation loss: 0.7162
2024-06-03 10:01:40 [INFO]: Epoch 011 - training loss: 0.4470, validation loss: 0.7130
2024-06-03 10:01:49 [INFO]: Epoch 012 - training loss: 0.4571, validation loss: 0.6786
2024-06-03 10:01:57 [INFO]: Epoch 013 - training loss: 0.4432, validation loss: 0.6645
2024-06-03 10:02:04 [INFO]: Epoch 014 - training loss: 0.4265, validation loss: 0.6986
2024-06-03 10:02:12 [INFO]: Epoch 015 - training loss: 0.4322, validation loss: 0.7105
2024-06-03 10:02:19 [INFO]: Epoch 016 - training loss: 0.4159, validation loss: 0.7149
2024-06-03 10:02:26 [INFO]: Epoch 017 - training loss: 0.4180, validation loss: 0.6250
2024-06-03 10:02:34 [INFO]: Epoch 018 - training loss: 0.4167, validation loss: 0.6502
2024-06-03 10:02:41 [INFO]: Epoch 019 - training loss: 0.4197, validation loss: 0.6549
2024-06-03 10:02:50 [INFO]: Epoch 020 - training loss: 0.4120, validation loss: 0.6587
2024-06-03 10:02:56 [INFO]: Epoch 021 - training loss: 0.4133, validation loss: 0.6213
2024-06-03 10:03:05 [INFO]: Epoch 022 - training loss: 0.4044, validation loss: 0.6604
2024-06-03 10:03:12 [INFO]: Epoch 023 - training loss: 0.3914, validation loss: 0.6607
2024-06-03 10:03:20 [INFO]: Epoch 024 - training loss: 0.3941, validation loss: 0.6211
2024-06-03 10:03:27 [INFO]: Epoch 025 - training loss: 0.3943, validation loss: 0.6781
2024-06-03 10:03:35 [INFO]: Epoch 026 - training loss: 0.3869, validation loss: 0.6318
2024-06-03 10:03:43 [INFO]: Epoch 027 - training loss: 0.3886, validation loss: 0.6413
2024-06-03 10:03:50 [INFO]: Epoch 028 - training loss: 0.3968, validation loss: 0.6517
2024-06-03 10:03:58 [INFO]: Epoch 029 - training loss: 0.3816, validation loss: 0.6320
2024-06-03 10:04:05 [INFO]: Epoch 030 - training loss: 0.3726, validation loss: 0.6091
2024-06-03 10:04:14 [INFO]: Epoch 031 - training loss: 0.3628, validation loss: 0.6221
2024-06-03 10:04:21 [INFO]: Epoch 032 - training loss: 0.3639, validation loss: 0.5969
2024-06-03 10:04:29 [INFO]: Epoch 033 - training loss: 0.3687, validation loss: 0.6029
2024-06-03 10:04:36 [INFO]: Epoch 034 - training loss: 0.3594, validation loss: 0.6134
2024-06-03 10:04:44 [INFO]: Epoch 035 - training loss: 0.3630, validation loss: 0.6063
2024-06-03 10:04:52 [INFO]: Epoch 036 - training loss: 0.3557, validation loss: 0.6193
2024-06-03 10:05:00 [INFO]: Epoch 037 - training loss: 0.3420, validation loss: 0.5871
2024-06-03 10:05:07 [INFO]: Epoch 038 - training loss: 0.3470, validation loss: 0.6202
2024-06-03 10:05:14 [INFO]: Epoch 039 - training loss: 0.3343, validation loss: 0.6345
2024-06-03 10:05:22 [INFO]: Epoch 040 - training loss: 0.3431, validation loss: 0.6359
2024-06-03 10:05:30 [INFO]: Epoch 041 - training loss: 0.3519, validation loss: 0.6040
2024-06-03 10:05:37 [INFO]: Epoch 042 - training loss: 0.3408, validation loss: 0.5681
2024-06-03 10:05:45 [INFO]: Epoch 043 - training loss: 0.3351, validation loss: 0.6104
2024-06-03 10:05:53 [INFO]: Epoch 044 - training loss: 0.3277, validation loss: 0.5615
2024-06-03 10:06:01 [INFO]: Epoch 045 - training loss: 0.3253, validation loss: 0.6179
2024-06-03 10:06:09 [INFO]: Epoch 046 - training loss: 0.3247, validation loss: 0.6062
2024-06-03 10:06:16 [INFO]: Epoch 047 - training loss: 0.3204, validation loss: 0.5982
2024-06-03 10:06:24 [INFO]: Epoch 048 - training loss: 0.3290, validation loss: 0.6019
2024-06-03 10:06:31 [INFO]: Epoch 049 - training loss: 0.3220, validation loss: 0.5697
2024-06-03 10:06:38 [INFO]: Epoch 050 - training loss: 0.3191, validation loss: 0.5671
2024-06-03 10:06:46 [INFO]: Epoch 051 - training loss: 0.3150, validation loss: 0.5648
2024-06-03 10:06:53 [INFO]: Epoch 052 - training loss: 0.3148, validation loss: 0.5790
2024-06-03 10:07:01 [INFO]: Epoch 053 - training loss: 0.3171, validation loss: 0.5585
2024-06-03 10:07:08 [INFO]: Epoch 054 - training loss: 0.3106, validation loss: 0.5496
2024-06-03 10:07:15 [INFO]: Epoch 055 - training loss: 0.3104, validation loss: 0.5713
2024-06-03 10:07:22 [INFO]: Epoch 056 - training loss: 0.3099, validation loss: 0.5625
2024-06-03 10:07:29 [INFO]: Epoch 057 - training loss: 0.3008, validation loss: 0.5485
2024-06-03 10:07:37 [INFO]: Epoch 058 - training loss: 0.2940, validation loss: 0.5908
2024-06-03 10:07:44 [INFO]: Epoch 059 - training loss: 0.3001, validation loss: 0.5834
2024-06-03 10:07:52 [INFO]: Epoch 060 - training loss: 0.3029, validation loss: 0.5521
2024-06-03 10:08:00 [INFO]: Epoch 061 - training loss: 0.2999, validation loss: 0.5935
2024-06-03 10:08:06 [INFO]: Epoch 062 - training loss: 0.2942, validation loss: 0.5581
2024-06-03 10:08:14 [INFO]: Epoch 063 - training loss: 0.2952, validation loss: 0.5540
2024-06-03 10:08:20 [INFO]: Epoch 064 - training loss: 0.2893, validation loss: 0.5475
2024-06-03 10:08:28 [INFO]: Epoch 065 - training loss: 0.2812, validation loss: 0.5430
2024-06-03 10:08:36 [INFO]: Epoch 066 - training loss: 0.2924, validation loss: 0.5427
2024-06-03 10:08:43 [INFO]: Epoch 067 - training loss: 0.2936, validation loss: 0.5455
2024-06-03 10:08:51 [INFO]: Epoch 068 - training loss: 0.2893, validation loss: 0.5724
2024-06-03 10:08:58 [INFO]: Epoch 069 - training loss: 0.2903, validation loss: 0.5616
2024-06-03 10:09:05 [INFO]: Epoch 070 - training loss: 0.2928, validation loss: 0.5671
2024-06-03 10:09:13 [INFO]: Epoch 071 - training loss: 0.2838, validation loss: 0.5529
2024-06-03 10:09:20 [INFO]: Epoch 072 - training loss: 0.2716, validation loss: 0.5692
2024-06-03 10:09:27 [INFO]: Epoch 073 - training loss: 0.2729, validation loss: 0.5569
2024-06-03 10:09:34 [INFO]: Epoch 074 - training loss: 0.2820, validation loss: 0.5663
2024-06-03 10:09:41 [INFO]: Epoch 075 - training loss: 0.2830, validation loss: 0.5662
2024-06-03 10:09:49 [INFO]: Epoch 076 - training loss: 0.2837, validation loss: 0.5699
2024-06-03 10:09:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:09:49 [INFO]: Finished training. The best model is from epoch#66.
2024-06-03 10:09:49 [INFO]: Saved the model to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_0/20240603_T100007/Crossformer.pypots
2024-06-03 10:09:52 [INFO]: Successfully saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_0/imputation.pkl
2024-06-03 10:09:52 [INFO]: Round0 - Crossformer on ItalyAir: MAE=0.4428, MSE=0.4482, MRE=0.5412
2024-06-03 10:09:52 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:09:52 [INFO]: Using the given device: cuda:0
2024-06-03 10:09:52 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T100952
2024-06-03 10:09:52 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T100952/tensorboard
2024-06-03 10:09:53 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 10:10:00 [INFO]: Epoch 001 - training loss: 1.2516, validation loss: 2.2924
2024-06-03 10:10:07 [INFO]: Epoch 002 - training loss: 1.1240, validation loss: 2.2314
2024-06-03 10:10:14 [INFO]: Epoch 003 - training loss: 1.0201, validation loss: 1.5685
2024-06-03 10:10:21 [INFO]: Epoch 004 - training loss: 0.7957, validation loss: 1.1398
2024-06-03 10:10:28 [INFO]: Epoch 005 - training loss: 0.6639, validation loss: 0.9013
2024-06-03 10:10:34 [INFO]: Epoch 006 - training loss: 0.5922, validation loss: 0.7796
2024-06-03 10:10:40 [INFO]: Epoch 007 - training loss: 0.5539, validation loss: 0.8392
2024-06-03 10:10:48 [INFO]: Epoch 008 - training loss: 0.5185, validation loss: 0.7149
2024-06-03 10:10:55 [INFO]: Epoch 009 - training loss: 0.4862, validation loss: 0.7230
2024-06-03 10:11:02 [INFO]: Epoch 010 - training loss: 0.4824, validation loss: 0.6846
2024-06-03 10:11:09 [INFO]: Epoch 011 - training loss: 0.4572, validation loss: 0.7743
2024-06-03 10:11:16 [INFO]: Epoch 012 - training loss: 0.4388, validation loss: 0.7459
2024-06-03 10:11:22 [INFO]: Epoch 013 - training loss: 0.4292, validation loss: 0.6684
2024-06-03 10:11:29 [INFO]: Epoch 014 - training loss: 0.4476, validation loss: 0.8008
2024-06-03 10:11:36 [INFO]: Epoch 015 - training loss: 0.4254, validation loss: 0.6352
2024-06-03 10:11:43 [INFO]: Epoch 016 - training loss: 0.4252, validation loss: 0.6938
2024-06-03 10:11:50 [INFO]: Epoch 017 - training loss: 0.4168, validation loss: 0.6973
2024-06-03 10:11:57 [INFO]: Epoch 018 - training loss: 0.4218, validation loss: 0.7247
2024-06-03 10:12:03 [INFO]: Epoch 019 - training loss: 0.4003, validation loss: 0.6662
2024-06-03 10:12:10 [INFO]: Epoch 020 - training loss: 0.3936, validation loss: 0.6521
2024-06-03 10:12:17 [INFO]: Epoch 021 - training loss: 0.3871, validation loss: 0.6465
2024-06-03 10:12:24 [INFO]: Epoch 022 - training loss: 0.3813, validation loss: 0.6275
2024-06-03 10:12:31 [INFO]: Epoch 023 - training loss: 0.3907, validation loss: 0.6703
2024-06-03 10:12:37 [INFO]: Epoch 024 - training loss: 0.3829, validation loss: 0.5789
2024-06-03 10:12:44 [INFO]: Epoch 025 - training loss: 0.3798, validation loss: 0.7007
2024-06-03 10:12:51 [INFO]: Epoch 026 - training loss: 0.3687, validation loss: 0.6047
2024-06-03 10:12:57 [INFO]: Epoch 027 - training loss: 0.3680, validation loss: 0.6433
2024-06-03 10:13:04 [INFO]: Epoch 028 - training loss: 0.3658, validation loss: 0.6348
2024-06-03 10:13:11 [INFO]: Epoch 029 - training loss: 0.3503, validation loss: 0.6147
2024-06-03 10:13:17 [INFO]: Epoch 030 - training loss: 0.3713, validation loss: 0.6387
2024-06-03 10:13:24 [INFO]: Epoch 031 - training loss: 0.3458, validation loss: 0.6041
2024-06-03 10:13:30 [INFO]: Epoch 032 - training loss: 0.3430, validation loss: 0.6371
2024-06-03 10:13:37 [INFO]: Epoch 033 - training loss: 0.3469, validation loss: 0.5976
2024-06-03 10:13:43 [INFO]: Epoch 034 - training loss: 0.3489, validation loss: 0.6212
2024-06-03 10:13:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:13:43 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 10:13:44 [INFO]: Saved the model to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_1/20240603_T100952/Crossformer.pypots
2024-06-03 10:13:46 [INFO]: Successfully saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_1/imputation.pkl
2024-06-03 10:13:46 [INFO]: Round1 - Crossformer on ItalyAir: MAE=0.4922, MSE=0.5180, MRE=0.6015
2024-06-03 10:13:46 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:13:46 [INFO]: Using the given device: cuda:0
2024-06-03 10:13:46 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T101346
2024-06-03 10:13:46 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T101346/tensorboard
2024-06-03 10:13:47 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 10:13:53 [INFO]: Epoch 001 - training loss: 1.2377, validation loss: 2.1959
2024-06-03 10:13:58 [INFO]: Epoch 002 - training loss: 1.0885, validation loss: 1.7649
2024-06-03 10:14:05 [INFO]: Epoch 003 - training loss: 0.8887, validation loss: 1.1490
2024-06-03 10:14:11 [INFO]: Epoch 004 - training loss: 0.7195, validation loss: 1.0355
2024-06-03 10:14:17 [INFO]: Epoch 005 - training loss: 0.6053, validation loss: 0.8530
2024-06-03 10:14:23 [INFO]: Epoch 006 - training loss: 0.5482, validation loss: 0.7685
2024-06-03 10:14:29 [INFO]: Epoch 007 - training loss: 0.5230, validation loss: 0.8143
2024-06-03 10:14:35 [INFO]: Epoch 008 - training loss: 0.4932, validation loss: 0.8210
2024-06-03 10:14:42 [INFO]: Epoch 009 - training loss: 0.4797, validation loss: 0.6662
2024-06-03 10:14:49 [INFO]: Epoch 010 - training loss: 0.4634, validation loss: 0.7498
2024-06-03 10:14:55 [INFO]: Epoch 011 - training loss: 0.4474, validation loss: 0.7560
2024-06-03 10:15:01 [INFO]: Epoch 012 - training loss: 0.4374, validation loss: 0.6797
2024-06-03 10:15:07 [INFO]: Epoch 013 - training loss: 0.4318, validation loss: 0.7317
2024-06-03 10:15:14 [INFO]: Epoch 014 - training loss: 0.4413, validation loss: 0.6603
2024-06-03 10:15:20 [INFO]: Epoch 015 - training loss: 0.4375, validation loss: 0.6455
2024-06-03 10:15:26 [INFO]: Epoch 016 - training loss: 0.4310, validation loss: 0.6965
2024-06-03 10:15:32 [INFO]: Epoch 017 - training loss: 0.4341, validation loss: 0.7002
2024-06-03 10:15:39 [INFO]: Epoch 018 - training loss: 0.4180, validation loss: 0.6443
2024-06-03 10:15:44 [INFO]: Epoch 019 - training loss: 0.4138, validation loss: 0.6121
2024-06-03 10:15:51 [INFO]: Epoch 020 - training loss: 0.4000, validation loss: 0.6546
2024-06-03 10:15:57 [INFO]: Epoch 021 - training loss: 0.3953, validation loss: 0.6330
2024-06-03 10:16:03 [INFO]: Epoch 022 - training loss: 0.3975, validation loss: 0.7611
2024-06-03 10:16:10 [INFO]: Epoch 023 - training loss: 0.3954, validation loss: 0.6008
2024-06-03 10:16:16 [INFO]: Epoch 024 - training loss: 0.3851, validation loss: 0.6459
2024-06-03 10:16:22 [INFO]: Epoch 025 - training loss: 0.3785, validation loss: 0.7143
2024-06-03 10:16:28 [INFO]: Epoch 026 - training loss: 0.3826, validation loss: 0.6330
2024-06-03 10:16:34 [INFO]: Epoch 027 - training loss: 0.3786, validation loss: 0.6117
2024-06-03 10:16:39 [INFO]: Epoch 028 - training loss: 0.3770, validation loss: 0.6414
2024-06-03 10:16:45 [INFO]: Epoch 029 - training loss: 0.3558, validation loss: 0.6123
2024-06-03 10:16:51 [INFO]: Epoch 030 - training loss: 0.3579, validation loss: 0.5920
2024-06-03 10:16:57 [INFO]: Epoch 031 - training loss: 0.3571, validation loss: 0.6263
2024-06-03 10:17:03 [INFO]: Epoch 032 - training loss: 0.3494, validation loss: 0.5795
2024-06-03 10:17:09 [INFO]: Epoch 033 - training loss: 0.3493, validation loss: 0.5910
2024-06-03 10:17:16 [INFO]: Epoch 034 - training loss: 0.3540, validation loss: 0.6019
2024-06-03 10:17:22 [INFO]: Epoch 035 - training loss: 0.3502, validation loss: 0.6198
2024-06-03 10:17:29 [INFO]: Epoch 036 - training loss: 0.3490, validation loss: 0.5851
2024-06-03 10:17:35 [INFO]: Epoch 037 - training loss: 0.3532, validation loss: 0.6080
2024-06-03 10:17:41 [INFO]: Epoch 038 - training loss: 0.3519, validation loss: 0.6079
2024-06-03 10:17:48 [INFO]: Epoch 039 - training loss: 0.3379, validation loss: 0.5930
2024-06-03 10:17:54 [INFO]: Epoch 040 - training loss: 0.3355, validation loss: 0.5832
2024-06-03 10:18:00 [INFO]: Epoch 041 - training loss: 0.3287, validation loss: 0.6052
2024-06-03 10:18:06 [INFO]: Epoch 042 - training loss: 0.3391, validation loss: 0.5518
2024-06-03 10:18:10 [INFO]: Epoch 043 - training loss: 0.3224, validation loss: 0.5674
2024-06-03 10:18:14 [INFO]: Epoch 044 - training loss: 0.3252, validation loss: 0.5924
2024-06-03 10:18:18 [INFO]: Epoch 045 - training loss: 0.3180, validation loss: 0.5610
2024-06-03 10:18:21 [INFO]: Epoch 046 - training loss: 0.3228, validation loss: 0.5672
2024-06-03 10:18:25 [INFO]: Epoch 047 - training loss: 0.3140, validation loss: 0.5714
2024-06-03 10:18:28 [INFO]: Epoch 048 - training loss: 0.3212, validation loss: 0.5742
2024-06-03 10:18:31 [INFO]: Epoch 049 - training loss: 0.3076, validation loss: 0.5613
2024-06-03 10:18:35 [INFO]: Epoch 050 - training loss: 0.3037, validation loss: 0.5534
2024-06-03 10:18:39 [INFO]: Epoch 051 - training loss: 0.3116, validation loss: 0.5962
2024-06-03 10:18:43 [INFO]: Epoch 052 - training loss: 0.3154, validation loss: 0.6022
2024-06-03 10:18:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:18:43 [INFO]: Finished training. The best model is from epoch#42.
2024-06-03 10:18:43 [INFO]: Saved the model to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_2/20240603_T101346/Crossformer.pypots
2024-06-03 10:18:45 [INFO]: Successfully saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_2/imputation.pkl
2024-06-03 10:18:45 [INFO]: Round2 - Crossformer on ItalyAir: MAE=0.4593, MSE=0.4808, MRE=0.5613
2024-06-03 10:18:45 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:18:45 [INFO]: Using the given device: cuda:0
2024-06-03 10:18:45 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T101845
2024-06-03 10:18:45 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T101845/tensorboard
2024-06-03 10:18:45 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 10:18:49 [INFO]: Epoch 001 - training loss: 1.2025, validation loss: 2.2182
2024-06-03 10:18:52 [INFO]: Epoch 002 - training loss: 1.0990, validation loss: 2.0883
2024-06-03 10:18:56 [INFO]: Epoch 003 - training loss: 0.9583, validation loss: 1.4425
2024-06-03 10:18:59 [INFO]: Epoch 004 - training loss: 0.7502, validation loss: 1.1006
2024-06-03 10:19:02 [INFO]: Epoch 005 - training loss: 0.6513, validation loss: 0.8698
2024-06-03 10:19:06 [INFO]: Epoch 006 - training loss: 0.5645, validation loss: 0.7980
2024-06-03 10:19:09 [INFO]: Epoch 007 - training loss: 0.5262, validation loss: 0.7622
2024-06-03 10:19:12 [INFO]: Epoch 008 - training loss: 0.4871, validation loss: 0.7346
2024-06-03 10:19:15 [INFO]: Epoch 009 - training loss: 0.5070, validation loss: 0.8163
2024-06-03 10:19:18 [INFO]: Epoch 010 - training loss: 0.4651, validation loss: 0.7193
2024-06-03 10:19:21 [INFO]: Epoch 011 - training loss: 0.4498, validation loss: 0.7600
2024-06-03 10:19:24 [INFO]: Epoch 012 - training loss: 0.4439, validation loss: 0.7816
2024-06-03 10:19:27 [INFO]: Epoch 013 - training loss: 0.4369, validation loss: 0.6951
2024-06-03 10:19:30 [INFO]: Epoch 014 - training loss: 0.4317, validation loss: 0.7137
2024-06-03 10:19:33 [INFO]: Epoch 015 - training loss: 0.4292, validation loss: 0.7261
2024-06-03 10:19:36 [INFO]: Epoch 016 - training loss: 0.4211, validation loss: 0.7256
2024-06-03 10:19:39 [INFO]: Epoch 017 - training loss: 0.4198, validation loss: 0.7045
2024-06-03 10:19:42 [INFO]: Epoch 018 - training loss: 0.4146, validation loss: 0.7223
2024-06-03 10:19:45 [INFO]: Epoch 019 - training loss: 0.4103, validation loss: 0.6639
2024-06-03 10:19:48 [INFO]: Epoch 020 - training loss: 0.3945, validation loss: 0.7108
2024-06-03 10:19:51 [INFO]: Epoch 021 - training loss: 0.4074, validation loss: 0.7187
2024-06-03 10:19:55 [INFO]: Epoch 022 - training loss: 0.4042, validation loss: 0.7115
2024-06-03 10:19:58 [INFO]: Epoch 023 - training loss: 0.4000, validation loss: 0.6736
2024-06-03 10:20:01 [INFO]: Epoch 024 - training loss: 0.3867, validation loss: 0.6571
2024-06-03 10:20:04 [INFO]: Epoch 025 - training loss: 0.3872, validation loss: 0.7781
2024-06-03 10:20:07 [INFO]: Epoch 026 - training loss: 0.3956, validation loss: 0.6891
2024-06-03 10:20:10 [INFO]: Epoch 027 - training loss: 0.3878, validation loss: 0.6447
2024-06-03 10:20:12 [INFO]: Epoch 028 - training loss: 0.3796, validation loss: 0.6673
2024-06-03 10:20:15 [INFO]: Epoch 029 - training loss: 0.3825, validation loss: 0.6827
2024-06-03 10:20:18 [INFO]: Epoch 030 - training loss: 0.3807, validation loss: 0.6162
2024-06-03 10:20:21 [INFO]: Epoch 031 - training loss: 0.3775, validation loss: 0.6569
2024-06-03 10:20:24 [INFO]: Epoch 032 - training loss: 0.3669, validation loss: 0.6161
2024-06-03 10:20:27 [INFO]: Epoch 033 - training loss: 0.3710, validation loss: 0.6507
2024-06-03 10:20:30 [INFO]: Epoch 034 - training loss: 0.3650, validation loss: 0.6016
2024-06-03 10:20:32 [INFO]: Epoch 035 - training loss: 0.3601, validation loss: 0.6518
2024-06-03 10:20:35 [INFO]: Epoch 036 - training loss: 0.3636, validation loss: 0.6149
2024-06-03 10:20:38 [INFO]: Epoch 037 - training loss: 0.3491, validation loss: 0.6433
2024-06-03 10:20:41 [INFO]: Epoch 038 - training loss: 0.3459, validation loss: 0.6361
2024-06-03 10:20:44 [INFO]: Epoch 039 - training loss: 0.3493, validation loss: 0.6239
2024-06-03 10:20:47 [INFO]: Epoch 040 - training loss: 0.3446, validation loss: 0.5968
2024-06-03 10:20:49 [INFO]: Epoch 041 - training loss: 0.3428, validation loss: 0.6393
2024-06-03 10:20:52 [INFO]: Epoch 042 - training loss: 0.3415, validation loss: 0.6002
2024-06-03 10:20:54 [INFO]: Epoch 043 - training loss: 0.3324, validation loss: 0.6314
2024-06-03 10:20:57 [INFO]: Epoch 044 - training loss: 0.3362, validation loss: 0.6249
2024-06-03 10:21:00 [INFO]: Epoch 045 - training loss: 0.3296, validation loss: 0.6151
2024-06-03 10:21:03 [INFO]: Epoch 046 - training loss: 0.3356, validation loss: 0.5827
2024-06-03 10:21:06 [INFO]: Epoch 047 - training loss: 0.3281, validation loss: 0.6554
2024-06-03 10:21:08 [INFO]: Epoch 048 - training loss: 0.3245, validation loss: 0.6111
2024-06-03 10:21:11 [INFO]: Epoch 049 - training loss: 0.3124, validation loss: 0.5926
2024-06-03 10:21:14 [INFO]: Epoch 050 - training loss: 0.3086, validation loss: 0.6072
2024-06-03 10:21:16 [INFO]: Epoch 051 - training loss: 0.3091, validation loss: 0.5786
2024-06-03 10:21:19 [INFO]: Epoch 052 - training loss: 0.3146, validation loss: 0.5727
2024-06-03 10:21:22 [INFO]: Epoch 053 - training loss: 0.3160, validation loss: 0.5715
2024-06-03 10:21:24 [INFO]: Epoch 054 - training loss: 0.3123, validation loss: 0.5866
2024-06-03 10:21:27 [INFO]: Epoch 055 - training loss: 0.3154, validation loss: 0.5911
2024-06-03 10:21:29 [INFO]: Epoch 056 - training loss: 0.3188, validation loss: 0.5624
2024-06-03 10:21:32 [INFO]: Epoch 057 - training loss: 0.3111, validation loss: 0.5830
2024-06-03 10:21:35 [INFO]: Epoch 058 - training loss: 0.3009, validation loss: 0.5409
2024-06-03 10:21:38 [INFO]: Epoch 059 - training loss: 0.2946, validation loss: 0.5792
2024-06-03 10:21:40 [INFO]: Epoch 060 - training loss: 0.2960, validation loss: 0.5786
2024-06-03 10:21:43 [INFO]: Epoch 061 - training loss: 0.2970, validation loss: 0.5869
2024-06-03 10:21:45 [INFO]: Epoch 062 - training loss: 0.2903, validation loss: 0.5729
2024-06-03 10:21:48 [INFO]: Epoch 063 - training loss: 0.2878, validation loss: 0.5777
2024-06-03 10:21:50 [INFO]: Epoch 064 - training loss: 0.2904, validation loss: 0.5328
2024-06-03 10:21:53 [INFO]: Epoch 065 - training loss: 0.2865, validation loss: 0.5978
2024-06-03 10:21:56 [INFO]: Epoch 066 - training loss: 0.2861, validation loss: 0.5965
2024-06-03 10:21:58 [INFO]: Epoch 067 - training loss: 0.2962, validation loss: 0.5288
2024-06-03 10:22:01 [INFO]: Epoch 068 - training loss: 0.2895, validation loss: 0.5452
2024-06-03 10:22:04 [INFO]: Epoch 069 - training loss: 0.2770, validation loss: 0.5429
2024-06-03 10:22:06 [INFO]: Epoch 070 - training loss: 0.2715, validation loss: 0.5637
2024-06-03 10:22:09 [INFO]: Epoch 071 - training loss: 0.2739, validation loss: 0.5358
2024-06-03 10:22:11 [INFO]: Epoch 072 - training loss: 0.2697, validation loss: 0.5287
2024-06-03 10:22:14 [INFO]: Epoch 073 - training loss: 0.2712, validation loss: 0.5248
2024-06-03 10:22:17 [INFO]: Epoch 074 - training loss: 0.2693, validation loss: 0.5656
2024-06-03 10:22:20 [INFO]: Epoch 075 - training loss: 0.2786, validation loss: 0.5399
2024-06-03 10:22:22 [INFO]: Epoch 076 - training loss: 0.2660, validation loss: 0.5479
2024-06-03 10:22:25 [INFO]: Epoch 077 - training loss: 0.2660, validation loss: 0.5643
2024-06-03 10:22:27 [INFO]: Epoch 078 - training loss: 0.2674, validation loss: 0.5669
2024-06-03 10:22:30 [INFO]: Epoch 079 - training loss: 0.2663, validation loss: 0.5060
2024-06-03 10:22:32 [INFO]: Epoch 080 - training loss: 0.2694, validation loss: 0.5515
2024-06-03 10:22:35 [INFO]: Epoch 081 - training loss: 0.2701, validation loss: 0.5163
2024-06-03 10:22:38 [INFO]: Epoch 082 - training loss: 0.2512, validation loss: 0.5401
2024-06-03 10:22:40 [INFO]: Epoch 083 - training loss: 0.2594, validation loss: 0.5423
2024-06-03 10:22:43 [INFO]: Epoch 084 - training loss: 0.2665, validation loss: 0.5129
2024-06-03 10:22:45 [INFO]: Epoch 085 - training loss: 0.2617, validation loss: 0.5401
2024-06-03 10:22:48 [INFO]: Epoch 086 - training loss: 0.2526, validation loss: 0.5401
2024-06-03 10:22:51 [INFO]: Epoch 087 - training loss: 0.2679, validation loss: 0.5599
2024-06-03 10:22:53 [INFO]: Epoch 088 - training loss: 0.2682, validation loss: 0.5968
2024-06-03 10:22:56 [INFO]: Epoch 089 - training loss: 0.2677, validation loss: 0.5553
2024-06-03 10:22:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:22:56 [INFO]: Finished training. The best model is from epoch#79.
2024-06-03 10:22:56 [INFO]: Saved the model to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_3/20240603_T101845/Crossformer.pypots
2024-06-03 10:22:57 [INFO]: Successfully saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_3/imputation.pkl
2024-06-03 10:22:57 [INFO]: Round3 - Crossformer on ItalyAir: MAE=0.4439, MSE=0.4564, MRE=0.5424
2024-06-03 10:22:57 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:22:57 [INFO]: Using the given device: cuda:0
2024-06-03 10:22:57 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T102257
2024-06-03 10:22:57 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T102257/tensorboard
2024-06-03 10:22:57 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 2,908,185
2024-06-03 10:23:00 [INFO]: Epoch 001 - training loss: 1.2238, validation loss: 2.1553
2024-06-03 10:23:03 [INFO]: Epoch 002 - training loss: 1.0399, validation loss: 1.5749
2024-06-03 10:23:05 [INFO]: Epoch 003 - training loss: 0.8127, validation loss: 1.0455
2024-06-03 10:23:08 [INFO]: Epoch 004 - training loss: 0.6770, validation loss: 0.9306
2024-06-03 10:23:10 [INFO]: Epoch 005 - training loss: 0.5857, validation loss: 0.7841
2024-06-03 10:23:13 [INFO]: Epoch 006 - training loss: 0.5261, validation loss: 0.6905
2024-06-03 10:23:16 [INFO]: Epoch 007 - training loss: 0.5186, validation loss: 0.7829
2024-06-03 10:23:19 [INFO]: Epoch 008 - training loss: 0.5053, validation loss: 0.6882
2024-06-03 10:23:22 [INFO]: Epoch 009 - training loss: 0.4929, validation loss: 0.7760
2024-06-03 10:23:24 [INFO]: Epoch 010 - training loss: 0.4808, validation loss: 0.7380
2024-06-03 10:23:27 [INFO]: Epoch 011 - training loss: 0.4618, validation loss: 0.7337
2024-06-03 10:23:29 [INFO]: Epoch 012 - training loss: 0.4401, validation loss: 0.7220
2024-06-03 10:23:32 [INFO]: Epoch 013 - training loss: 0.4419, validation loss: 0.7584
2024-06-03 10:23:35 [INFO]: Epoch 014 - training loss: 0.4345, validation loss: 0.7163
2024-06-03 10:23:37 [INFO]: Epoch 015 - training loss: 0.4145, validation loss: 0.7219
2024-06-03 10:23:39 [INFO]: Epoch 016 - training loss: 0.4188, validation loss: 0.7734
2024-06-03 10:23:41 [INFO]: Epoch 017 - training loss: 0.4240, validation loss: 0.6758
2024-06-03 10:23:44 [INFO]: Epoch 018 - training loss: 0.4083, validation loss: 0.6662
2024-06-03 10:23:46 [INFO]: Epoch 019 - training loss: 0.4079, validation loss: 0.6619
2024-06-03 10:23:49 [INFO]: Epoch 020 - training loss: 0.4048, validation loss: 0.6475
2024-06-03 10:23:51 [INFO]: Epoch 021 - training loss: 0.3998, validation loss: 0.6804
2024-06-03 10:23:53 [INFO]: Epoch 022 - training loss: 0.3936, validation loss: 0.6645
2024-06-03 10:23:56 [INFO]: Epoch 023 - training loss: 0.3996, validation loss: 0.7183
2024-06-03 10:23:58 [INFO]: Epoch 024 - training loss: 0.3981, validation loss: 0.6458
2024-06-03 10:24:00 [INFO]: Epoch 025 - training loss: 0.3845, validation loss: 0.6596
2024-06-03 10:24:03 [INFO]: Epoch 026 - training loss: 0.3761, validation loss: 0.6025
2024-06-03 10:24:05 [INFO]: Epoch 027 - training loss: 0.3715, validation loss: 0.6101
2024-06-03 10:24:08 [INFO]: Epoch 028 - training loss: 0.3762, validation loss: 0.6101
2024-06-03 10:24:10 [INFO]: Epoch 029 - training loss: 0.3661, validation loss: 0.6233
2024-06-03 10:24:13 [INFO]: Epoch 030 - training loss: 0.3635, validation loss: 0.6286
2024-06-03 10:24:15 [INFO]: Epoch 031 - training loss: 0.3787, validation loss: 0.6019
2024-06-03 10:24:18 [INFO]: Epoch 032 - training loss: 0.3566, validation loss: 0.6400
2024-06-03 10:24:20 [INFO]: Epoch 033 - training loss: 0.3533, validation loss: 0.6169
2024-06-03 10:24:23 [INFO]: Epoch 034 - training loss: 0.3488, validation loss: 0.5904
2024-06-03 10:24:25 [INFO]: Epoch 035 - training loss: 0.3514, validation loss: 0.6469
2024-06-03 10:24:28 [INFO]: Epoch 036 - training loss: 0.3497, validation loss: 0.5674
2024-06-03 10:24:30 [INFO]: Epoch 037 - training loss: 0.3440, validation loss: 0.5859
2024-06-03 10:24:32 [INFO]: Epoch 038 - training loss: 0.3402, validation loss: 0.5908
2024-06-03 10:24:35 [INFO]: Epoch 039 - training loss: 0.3302, validation loss: 0.5632
2024-06-03 10:24:37 [INFO]: Epoch 040 - training loss: 0.3352, validation loss: 0.6011
2024-06-03 10:24:39 [INFO]: Epoch 041 - training loss: 0.3264, validation loss: 0.5741
2024-06-03 10:24:42 [INFO]: Epoch 042 - training loss: 0.3186, validation loss: 0.5439
2024-06-03 10:24:44 [INFO]: Epoch 043 - training loss: 0.3295, validation loss: 0.5434
2024-06-03 10:24:46 [INFO]: Epoch 044 - training loss: 0.3164, validation loss: 0.5752
2024-06-03 10:24:48 [INFO]: Epoch 045 - training loss: 0.3101, validation loss: 0.5712
2024-06-03 10:24:50 [INFO]: Epoch 046 - training loss: 0.3119, validation loss: 0.5769
2024-06-03 10:24:52 [INFO]: Epoch 047 - training loss: 0.3068, validation loss: 0.5365
2024-06-03 10:24:54 [INFO]: Epoch 048 - training loss: 0.3120, validation loss: 0.5522
2024-06-03 10:24:56 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.5341
2024-06-03 10:24:58 [INFO]: Epoch 050 - training loss: 0.3127, validation loss: 0.5826
2024-06-03 10:25:00 [INFO]: Epoch 051 - training loss: 0.3089, validation loss: 0.5327
2024-06-03 10:25:02 [INFO]: Epoch 052 - training loss: 0.3055, validation loss: 0.5570
2024-06-03 10:25:04 [INFO]: Epoch 053 - training loss: 0.3054, validation loss: 0.5255
2024-06-03 10:25:06 [INFO]: Epoch 054 - training loss: 0.3009, validation loss: 0.5333
2024-06-03 10:25:08 [INFO]: Epoch 055 - training loss: 0.2938, validation loss: 0.5644
2024-06-03 10:25:10 [INFO]: Epoch 056 - training loss: 0.3009, validation loss: 0.5148
2024-06-03 10:25:12 [INFO]: Epoch 057 - training loss: 0.2918, validation loss: 0.5366
2024-06-03 10:25:14 [INFO]: Epoch 058 - training loss: 0.2898, validation loss: 0.5451
2024-06-03 10:25:16 [INFO]: Epoch 059 - training loss: 0.2853, validation loss: 0.5243
2024-06-03 10:25:18 [INFO]: Epoch 060 - training loss: 0.2792, validation loss: 0.5290
2024-06-03 10:25:20 [INFO]: Epoch 061 - training loss: 0.2867, validation loss: 0.5407
2024-06-03 10:25:21 [INFO]: Epoch 062 - training loss: 0.2817, validation loss: 0.5437
2024-06-03 10:25:23 [INFO]: Epoch 063 - training loss: 0.2786, validation loss: 0.5093
2024-06-03 10:25:25 [INFO]: Epoch 064 - training loss: 0.2757, validation loss: 0.5214
2024-06-03 10:25:27 [INFO]: Epoch 065 - training loss: 0.2830, validation loss: 0.5114
2024-06-03 10:25:30 [INFO]: Epoch 066 - training loss: 0.2844, validation loss: 0.5493
2024-06-03 10:25:32 [INFO]: Epoch 067 - training loss: 0.2860, validation loss: 0.5190
2024-06-03 10:25:33 [INFO]: Epoch 068 - training loss: 0.2799, validation loss: 0.5665
2024-06-03 10:25:35 [INFO]: Epoch 069 - training loss: 0.2742, validation loss: 0.5110
2024-06-03 10:25:37 [INFO]: Epoch 070 - training loss: 0.2694, validation loss: 0.5045
2024-06-03 10:25:39 [INFO]: Epoch 071 - training loss: 0.2772, validation loss: 0.5311
2024-06-03 10:25:41 [INFO]: Epoch 072 - training loss: 0.2734, validation loss: 0.4911
2024-06-03 10:25:42 [INFO]: Epoch 073 - training loss: 0.2652, validation loss: 0.5306
2024-06-03 10:25:44 [INFO]: Epoch 074 - training loss: 0.2608, validation loss: 0.5276
2024-06-03 10:25:45 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.5111
2024-06-03 10:25:47 [INFO]: Epoch 076 - training loss: 0.2643, validation loss: 0.4909
2024-06-03 10:25:49 [INFO]: Epoch 077 - training loss: 0.2585, validation loss: 0.5134
2024-06-03 10:25:51 [INFO]: Epoch 078 - training loss: 0.2649, validation loss: 0.5003
2024-06-03 10:25:52 [INFO]: Epoch 079 - training loss: 0.2529, validation loss: 0.5231
2024-06-03 10:25:54 [INFO]: Epoch 080 - training loss: 0.2612, validation loss: 0.5224
2024-06-03 10:25:56 [INFO]: Epoch 081 - training loss: 0.2606, validation loss: 0.5268
2024-06-03 10:25:57 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.5209
2024-06-03 10:25:59 [INFO]: Epoch 083 - training loss: 0.2624, validation loss: 0.5567
2024-06-03 10:26:01 [INFO]: Epoch 084 - training loss: 0.2606, validation loss: 0.4996
2024-06-03 10:26:02 [INFO]: Epoch 085 - training loss: 0.2597, validation loss: 0.5337
2024-06-03 10:26:04 [INFO]: Epoch 086 - training loss: 0.2554, validation loss: 0.5038
2024-06-03 10:26:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:26:04 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 10:26:04 [INFO]: Saved the model to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_4/20240603_T102257/Crossformer.pypots
2024-06-03 10:26:05 [INFO]: Successfully saved to results_block_rate05/ItalyAir/Crossformer_ItalyAir/round_4/imputation.pkl
2024-06-03 10:26:05 [INFO]: Round4 - Crossformer on ItalyAir: MAE=0.4429, MSE=0.4513, MRE=0.5412
2024-06-03 10:26:05 [INFO]: Done! Final results:
Averaged Crossformer (2,908,185 params) on ItalyAir: MAE=0.4562 ± 0.019039233155040008, MSE=0.4709 ± 0.026173258152193804, MRE=0.5575 ± 0.02326664037614555, average inference time=0.39
