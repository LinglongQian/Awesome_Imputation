2024-06-03 10:00:06 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:00:06 [INFO]: Using the given device: cuda:0
2024-06-03 10:00:08 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_0/20240603_T100008
2024-06-03 10:00:08 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_0/20240603_T100008/tensorboard
2024-06-03 10:00:08 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=128
2024-06-03 10:00:08 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-03 10:00:08 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 16,628,642
2024-06-03 10:00:34 [INFO]: Epoch 001 - training loss: 1.1844, validation loss: 2.0142
2024-06-03 10:00:43 [INFO]: Epoch 002 - training loss: 1.0028, validation loss: 1.7354
2024-06-03 10:00:52 [INFO]: Epoch 003 - training loss: 0.8648, validation loss: 1.4581
2024-06-03 10:01:01 [INFO]: Epoch 004 - training loss: 0.7931, validation loss: 1.2822
2024-06-03 10:01:11 [INFO]: Epoch 005 - training loss: 0.7404, validation loss: 1.1069
2024-06-03 10:01:20 [INFO]: Epoch 006 - training loss: 0.7162, validation loss: 1.0275
2024-06-03 10:01:29 [INFO]: Epoch 007 - training loss: 0.6931, validation loss: 0.8719
2024-06-03 10:01:38 [INFO]: Epoch 008 - training loss: 0.6579, validation loss: 0.7675
2024-06-03 10:01:45 [INFO]: Epoch 009 - training loss: 0.6416, validation loss: 0.7065
2024-06-03 10:01:54 [INFO]: Epoch 010 - training loss: 0.6162, validation loss: 0.6748
2024-06-03 10:02:03 [INFO]: Epoch 011 - training loss: 0.6001, validation loss: 0.6564
2024-06-03 10:02:13 [INFO]: Epoch 012 - training loss: 0.5928, validation loss: 0.6017
2024-06-03 10:02:22 [INFO]: Epoch 013 - training loss: 0.5744, validation loss: 0.6140
2024-06-03 10:02:32 [INFO]: Epoch 014 - training loss: 0.5672, validation loss: 0.5757
2024-06-03 10:02:41 [INFO]: Epoch 015 - training loss: 0.5597, validation loss: 0.5969
2024-06-03 10:02:50 [INFO]: Epoch 016 - training loss: 0.5418, validation loss: 0.5499
2024-06-03 10:02:58 [INFO]: Epoch 017 - training loss: 0.5365, validation loss: 0.6287
2024-06-03 10:03:07 [INFO]: Epoch 018 - training loss: 0.5345, validation loss: 0.5103
2024-06-03 10:03:17 [INFO]: Epoch 019 - training loss: 0.5337, validation loss: 0.5412
2024-06-03 10:03:25 [INFO]: Epoch 020 - training loss: 0.5220, validation loss: 0.5603
2024-06-03 10:03:34 [INFO]: Epoch 021 - training loss: 0.5117, validation loss: 0.5493
2024-06-03 10:03:43 [INFO]: Epoch 022 - training loss: 0.5101, validation loss: 0.5527
2024-06-03 10:03:51 [INFO]: Epoch 023 - training loss: 0.5054, validation loss: 0.5507
2024-06-03 10:04:00 [INFO]: Epoch 024 - training loss: 0.5037, validation loss: 0.6849
2024-06-03 10:04:09 [INFO]: Epoch 025 - training loss: 0.4993, validation loss: 0.4960
2024-06-03 10:04:19 [INFO]: Epoch 026 - training loss: 0.4921, validation loss: 0.5198
2024-06-03 10:04:27 [INFO]: Epoch 027 - training loss: 0.4813, validation loss: 0.5131
2024-06-03 10:04:36 [INFO]: Epoch 028 - training loss: 0.4785, validation loss: 0.5323
2024-06-03 10:04:45 [INFO]: Epoch 029 - training loss: 0.4787, validation loss: 0.4890
2024-06-03 10:04:55 [INFO]: Epoch 030 - training loss: 0.4784, validation loss: 0.4983
2024-06-03 10:05:04 [INFO]: Epoch 031 - training loss: 0.4652, validation loss: 0.4670
2024-06-03 10:05:13 [INFO]: Epoch 032 - training loss: 0.4696, validation loss: 0.5556
2024-06-03 10:05:22 [INFO]: Epoch 033 - training loss: 0.4677, validation loss: 0.5495
2024-06-03 10:05:31 [INFO]: Epoch 034 - training loss: 0.4589, validation loss: 0.5002
2024-06-03 10:05:39 [INFO]: Epoch 035 - training loss: 0.4563, validation loss: 0.5146
2024-06-03 10:05:48 [INFO]: Epoch 036 - training loss: 0.4508, validation loss: 0.5149
2024-06-03 10:05:57 [INFO]: Epoch 037 - training loss: 0.4416, validation loss: 0.5066
2024-06-03 10:06:06 [INFO]: Epoch 038 - training loss: 0.4407, validation loss: 0.4506
2024-06-03 10:06:14 [INFO]: Epoch 039 - training loss: 0.4394, validation loss: 0.4770
2024-06-03 10:06:22 [INFO]: Epoch 040 - training loss: 0.4324, validation loss: 0.4518
2024-06-03 10:06:30 [INFO]: Epoch 041 - training loss: 0.4253, validation loss: 0.4645
2024-06-03 10:06:39 [INFO]: Epoch 042 - training loss: 0.4345, validation loss: 0.4629
2024-06-03 10:06:48 [INFO]: Epoch 043 - training loss: 0.4240, validation loss: 0.4949
2024-06-03 10:06:57 [INFO]: Epoch 044 - training loss: 0.4244, validation loss: 0.4333
2024-06-03 10:07:06 [INFO]: Epoch 045 - training loss: 0.4213, validation loss: 0.4561
2024-06-03 10:07:14 [INFO]: Epoch 046 - training loss: 0.4171, validation loss: 0.4454
2024-06-03 10:07:23 [INFO]: Epoch 047 - training loss: 0.4137, validation loss: 0.4766
2024-06-03 10:07:32 [INFO]: Epoch 048 - training loss: 0.4072, validation loss: 0.4348
2024-06-03 10:07:41 [INFO]: Epoch 049 - training loss: 0.4142, validation loss: 0.4385
2024-06-03 10:07:49 [INFO]: Epoch 050 - training loss: 0.4047, validation loss: 0.4826
2024-06-03 10:07:57 [INFO]: Epoch 051 - training loss: 0.4043, validation loss: 0.4183
2024-06-03 10:08:05 [INFO]: Epoch 052 - training loss: 0.3971, validation loss: 0.4282
2024-06-03 10:08:14 [INFO]: Epoch 053 - training loss: 0.4037, validation loss: 0.4320
2024-06-03 10:08:23 [INFO]: Epoch 054 - training loss: 0.3986, validation loss: 0.4148
2024-06-03 10:08:32 [INFO]: Epoch 055 - training loss: 0.3919, validation loss: 0.4430
2024-06-03 10:08:40 [INFO]: Epoch 056 - training loss: 0.3856, validation loss: 0.4709
2024-06-03 10:08:50 [INFO]: Epoch 057 - training loss: 0.3878, validation loss: 0.4332
2024-06-03 10:08:58 [INFO]: Epoch 058 - training loss: 0.3791, validation loss: 0.3992
2024-06-03 10:09:07 [INFO]: Epoch 059 - training loss: 0.3728, validation loss: 0.4028
2024-06-03 10:09:15 [INFO]: Epoch 060 - training loss: 0.3726, validation loss: 0.4938
2024-06-03 10:09:24 [INFO]: Epoch 061 - training loss: 0.3719, validation loss: 0.4690
2024-06-03 10:09:32 [INFO]: Epoch 062 - training loss: 0.3631, validation loss: 0.4057
2024-06-03 10:09:41 [INFO]: Epoch 063 - training loss: 0.3648, validation loss: 0.4565
2024-06-03 10:09:49 [INFO]: Epoch 064 - training loss: 0.3545, validation loss: 0.4345
2024-06-03 10:09:58 [INFO]: Epoch 065 - training loss: 0.3551, validation loss: 0.4406
2024-06-03 10:10:06 [INFO]: Epoch 066 - training loss: 0.3505, validation loss: 0.4714
2024-06-03 10:10:14 [INFO]: Epoch 067 - training loss: 0.3498, validation loss: 0.4026
2024-06-03 10:10:22 [INFO]: Epoch 068 - training loss: 0.3513, validation loss: 0.4437
2024-06-03 10:10:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:10:22 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 10:10:23 [INFO]: Saved the model to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_0/20240603_T100008/SAITS.pypots
2024-06-03 10:10:26 [INFO]: Successfully saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_0/imputation.pkl
2024-06-03 10:10:26 [INFO]: Round0 - SAITS on ItalyAir: MAE=0.4175, MSE=0.4049, MRE=0.5102
2024-06-03 10:10:26 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:10:26 [INFO]: Using the given device: cuda:0
2024-06-03 10:10:26 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_1/20240603_T101026
2024-06-03 10:10:26 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_1/20240603_T101026/tensorboard
2024-06-03 10:10:26 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=128
2024-06-03 10:10:26 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-03 10:10:28 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 16,628,642
2024-06-03 10:10:36 [INFO]: Epoch 001 - training loss: 1.2096, validation loss: 1.9706
2024-06-03 10:10:43 [INFO]: Epoch 002 - training loss: 1.0040, validation loss: 1.6877
2024-06-03 10:10:52 [INFO]: Epoch 003 - training loss: 0.8846, validation loss: 1.4644
2024-06-03 10:11:00 [INFO]: Epoch 004 - training loss: 0.8027, validation loss: 1.3198
2024-06-03 10:11:08 [INFO]: Epoch 005 - training loss: 0.7705, validation loss: 1.1390
2024-06-03 10:11:16 [INFO]: Epoch 006 - training loss: 0.7335, validation loss: 1.0798
2024-06-03 10:11:24 [INFO]: Epoch 007 - training loss: 0.7012, validation loss: 0.9762
2024-06-03 10:11:33 [INFO]: Epoch 008 - training loss: 0.6665, validation loss: 0.8988
2024-06-03 10:11:41 [INFO]: Epoch 009 - training loss: 0.6617, validation loss: 0.8575
2024-06-03 10:11:49 [INFO]: Epoch 010 - training loss: 0.6307, validation loss: 0.7600
2024-06-03 10:11:58 [INFO]: Epoch 011 - training loss: 0.6241, validation loss: 0.7697
2024-06-03 10:12:06 [INFO]: Epoch 012 - training loss: 0.6043, validation loss: 0.7362
2024-06-03 10:12:14 [INFO]: Epoch 013 - training loss: 0.6024, validation loss: 0.7132
2024-06-03 10:12:22 [INFO]: Epoch 014 - training loss: 0.5959, validation loss: 0.7342
2024-06-03 10:12:30 [INFO]: Epoch 015 - training loss: 0.5939, validation loss: 0.7499
2024-06-03 10:12:38 [INFO]: Epoch 016 - training loss: 0.5819, validation loss: 0.6991
2024-06-03 10:12:45 [INFO]: Epoch 017 - training loss: 0.5692, validation loss: 0.6759
2024-06-03 10:12:53 [INFO]: Epoch 018 - training loss: 0.5608, validation loss: 0.6332
2024-06-03 10:13:01 [INFO]: Epoch 019 - training loss: 0.5596, validation loss: 0.6669
2024-06-03 10:13:09 [INFO]: Epoch 020 - training loss: 0.5437, validation loss: 0.6525
2024-06-03 10:13:17 [INFO]: Epoch 021 - training loss: 0.5326, validation loss: 0.6419
2024-06-03 10:13:25 [INFO]: Epoch 022 - training loss: 0.5329, validation loss: 0.6288
2024-06-03 10:13:33 [INFO]: Epoch 023 - training loss: 0.5329, validation loss: 0.5956
2024-06-03 10:13:40 [INFO]: Epoch 024 - training loss: 0.5167, validation loss: 0.5687
2024-06-03 10:13:48 [INFO]: Epoch 025 - training loss: 0.5021, validation loss: 0.5480
2024-06-03 10:13:56 [INFO]: Epoch 026 - training loss: 0.5031, validation loss: 0.5645
2024-06-03 10:14:04 [INFO]: Epoch 027 - training loss: 0.4895, validation loss: 0.5381
2024-06-03 10:14:11 [INFO]: Epoch 028 - training loss: 0.4973, validation loss: 0.5391
2024-06-03 10:14:19 [INFO]: Epoch 029 - training loss: 0.4747, validation loss: 0.5407
2024-06-03 10:14:25 [INFO]: Epoch 030 - training loss: 0.4704, validation loss: 0.5132
2024-06-03 10:14:32 [INFO]: Epoch 031 - training loss: 0.4744, validation loss: 0.5497
2024-06-03 10:14:39 [INFO]: Epoch 032 - training loss: 0.4560, validation loss: 0.5434
2024-06-03 10:14:47 [INFO]: Epoch 033 - training loss: 0.4456, validation loss: 0.5185
2024-06-03 10:14:54 [INFO]: Epoch 034 - training loss: 0.4482, validation loss: 0.5153
2024-06-03 10:15:02 [INFO]: Epoch 035 - training loss: 0.4351, validation loss: 0.5045
2024-06-03 10:15:09 [INFO]: Epoch 036 - training loss: 0.4236, validation loss: 0.5271
2024-06-03 10:15:17 [INFO]: Epoch 037 - training loss: 0.4107, validation loss: 0.4985
2024-06-03 10:15:25 [INFO]: Epoch 038 - training loss: 0.4137, validation loss: 0.5169
2024-06-03 10:15:33 [INFO]: Epoch 039 - training loss: 0.4145, validation loss: 0.4764
2024-06-03 10:15:40 [INFO]: Epoch 040 - training loss: 0.4143, validation loss: 0.4767
2024-06-03 10:15:47 [INFO]: Epoch 041 - training loss: 0.4041, validation loss: 0.4409
2024-06-03 10:15:55 [INFO]: Epoch 042 - training loss: 0.3966, validation loss: 0.4313
2024-06-03 10:16:02 [INFO]: Epoch 043 - training loss: 0.3954, validation loss: 0.4856
2024-06-03 10:16:10 [INFO]: Epoch 044 - training loss: 0.3928, validation loss: 0.5082
2024-06-03 10:16:16 [INFO]: Epoch 045 - training loss: 0.3908, validation loss: 0.4975
2024-06-03 10:16:23 [INFO]: Epoch 046 - training loss: 0.3918, validation loss: 0.4971
2024-06-03 10:16:31 [INFO]: Epoch 047 - training loss: 0.3881, validation loss: 0.4830
2024-06-03 10:16:38 [INFO]: Epoch 048 - training loss: 0.3854, validation loss: 0.4814
2024-06-03 10:16:45 [INFO]: Epoch 049 - training loss: 0.3834, validation loss: 0.4728
2024-06-03 10:16:52 [INFO]: Epoch 050 - training loss: 0.3669, validation loss: 0.4386
2024-06-03 10:17:00 [INFO]: Epoch 051 - training loss: 0.3686, validation loss: 0.4253
2024-06-03 10:17:07 [INFO]: Epoch 052 - training loss: 0.3694, validation loss: 0.4756
2024-06-03 10:17:14 [INFO]: Epoch 053 - training loss: 0.3679, validation loss: 0.4652
2024-06-03 10:17:22 [INFO]: Epoch 054 - training loss: 0.3619, validation loss: 0.4410
2024-06-03 10:17:30 [INFO]: Epoch 055 - training loss: 0.3587, validation loss: 0.4651
2024-06-03 10:17:37 [INFO]: Epoch 056 - training loss: 0.3618, validation loss: 0.4376
2024-06-03 10:17:45 [INFO]: Epoch 057 - training loss: 0.3571, validation loss: 0.4326
2024-06-03 10:17:52 [INFO]: Epoch 058 - training loss: 0.3590, validation loss: 0.4597
2024-06-03 10:17:59 [INFO]: Epoch 059 - training loss: 0.3512, validation loss: 0.4541
2024-06-03 10:18:05 [INFO]: Epoch 060 - training loss: 0.3501, validation loss: 0.4338
2024-06-03 10:18:10 [INFO]: Epoch 061 - training loss: 0.3457, validation loss: 0.5050
2024-06-03 10:18:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:18:10 [INFO]: Finished training. The best model is from epoch#51.
2024-06-03 10:18:11 [INFO]: Saved the model to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_1/20240603_T101026/SAITS.pypots
2024-06-03 10:18:13 [INFO]: Successfully saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_1/imputation.pkl
2024-06-03 10:18:13 [INFO]: Round1 - SAITS on ItalyAir: MAE=0.4373, MSE=0.4381, MRE=0.5344
2024-06-03 10:18:13 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:18:13 [INFO]: Using the given device: cuda:0
2024-06-03 10:18:13 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_2/20240603_T101813
2024-06-03 10:18:13 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_2/20240603_T101813/tensorboard
2024-06-03 10:18:13 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=128
2024-06-03 10:18:13 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-03 10:18:14 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 16,628,642
2024-06-03 10:18:18 [INFO]: Epoch 001 - training loss: 1.1481, validation loss: 1.9286
2024-06-03 10:18:22 [INFO]: Epoch 002 - training loss: 0.9405, validation loss: 1.6146
2024-06-03 10:18:26 [INFO]: Epoch 003 - training loss: 0.8436, validation loss: 1.4148
2024-06-03 10:18:30 [INFO]: Epoch 004 - training loss: 0.7827, validation loss: 1.2894
2024-06-03 10:18:35 [INFO]: Epoch 005 - training loss: 0.7368, validation loss: 1.1911
2024-06-03 10:18:39 [INFO]: Epoch 006 - training loss: 0.7174, validation loss: 1.0860
2024-06-03 10:18:43 [INFO]: Epoch 007 - training loss: 0.6877, validation loss: 1.0405
2024-06-03 10:18:47 [INFO]: Epoch 008 - training loss: 0.6687, validation loss: 0.9290
2024-06-03 10:18:51 [INFO]: Epoch 009 - training loss: 0.6453, validation loss: 0.8846
2024-06-03 10:18:55 [INFO]: Epoch 010 - training loss: 0.6403, validation loss: 0.8488
2024-06-03 10:18:58 [INFO]: Epoch 011 - training loss: 0.6077, validation loss: 0.7381
2024-06-03 10:19:01 [INFO]: Epoch 012 - training loss: 0.5998, validation loss: 0.7626
2024-06-03 10:19:05 [INFO]: Epoch 013 - training loss: 0.6006, validation loss: 0.7071
2024-06-03 10:19:09 [INFO]: Epoch 014 - training loss: 0.5726, validation loss: 0.6668
2024-06-03 10:19:13 [INFO]: Epoch 015 - training loss: 0.5559, validation loss: 0.6623
2024-06-03 10:19:16 [INFO]: Epoch 016 - training loss: 0.5487, validation loss: 0.5872
2024-06-03 10:19:19 [INFO]: Epoch 017 - training loss: 0.5393, validation loss: 0.6072
2024-06-03 10:19:23 [INFO]: Epoch 018 - training loss: 0.5364, validation loss: 0.6096
2024-06-03 10:19:26 [INFO]: Epoch 019 - training loss: 0.5274, validation loss: 0.5677
2024-06-03 10:19:30 [INFO]: Epoch 020 - training loss: 0.5135, validation loss: 0.6163
2024-06-03 10:19:33 [INFO]: Epoch 021 - training loss: 0.4927, validation loss: 0.5279
2024-06-03 10:19:37 [INFO]: Epoch 022 - training loss: 0.4829, validation loss: 0.5069
2024-06-03 10:19:40 [INFO]: Epoch 023 - training loss: 0.4791, validation loss: 0.5362
2024-06-03 10:19:44 [INFO]: Epoch 024 - training loss: 0.4643, validation loss: 0.4850
2024-06-03 10:19:48 [INFO]: Epoch 025 - training loss: 0.4587, validation loss: 0.5078
2024-06-03 10:19:51 [INFO]: Epoch 026 - training loss: 0.4662, validation loss: 0.4944
2024-06-03 10:19:55 [INFO]: Epoch 027 - training loss: 0.4521, validation loss: 0.4921
2024-06-03 10:19:58 [INFO]: Epoch 028 - training loss: 0.4387, validation loss: 0.4743
2024-06-03 10:20:01 [INFO]: Epoch 029 - training loss: 0.4313, validation loss: 0.4496
2024-06-03 10:20:04 [INFO]: Epoch 030 - training loss: 0.4347, validation loss: 0.4531
2024-06-03 10:20:07 [INFO]: Epoch 031 - training loss: 0.4233, validation loss: 0.4735
2024-06-03 10:20:10 [INFO]: Epoch 032 - training loss: 0.4235, validation loss: 0.4358
2024-06-03 10:20:13 [INFO]: Epoch 033 - training loss: 0.4172, validation loss: 0.4318
2024-06-03 10:20:16 [INFO]: Epoch 034 - training loss: 0.4033, validation loss: 0.4206
2024-06-03 10:20:19 [INFO]: Epoch 035 - training loss: 0.4007, validation loss: 0.4345
2024-06-03 10:20:22 [INFO]: Epoch 036 - training loss: 0.3952, validation loss: 0.4375
2024-06-03 10:20:25 [INFO]: Epoch 037 - training loss: 0.3942, validation loss: 0.4674
2024-06-03 10:20:28 [INFO]: Epoch 038 - training loss: 0.3853, validation loss: 0.4326
2024-06-03 10:20:31 [INFO]: Epoch 039 - training loss: 0.3776, validation loss: 0.3901
2024-06-03 10:20:34 [INFO]: Epoch 040 - training loss: 0.3845, validation loss: 0.4337
2024-06-03 10:20:36 [INFO]: Epoch 041 - training loss: 0.3769, validation loss: 0.4523
2024-06-03 10:20:39 [INFO]: Epoch 042 - training loss: 0.3742, validation loss: 0.4543
2024-06-03 10:20:42 [INFO]: Epoch 043 - training loss: 0.3699, validation loss: 0.4288
2024-06-03 10:20:45 [INFO]: Epoch 044 - training loss: 0.3664, validation loss: 0.4045
2024-06-03 10:20:48 [INFO]: Epoch 045 - training loss: 0.3611, validation loss: 0.4691
2024-06-03 10:20:51 [INFO]: Epoch 046 - training loss: 0.3629, validation loss: 0.4522
2024-06-03 10:20:54 [INFO]: Epoch 047 - training loss: 0.3588, validation loss: 0.4479
2024-06-03 10:20:57 [INFO]: Epoch 048 - training loss: 0.3586, validation loss: 0.3843
2024-06-03 10:21:00 [INFO]: Epoch 049 - training loss: 0.3565, validation loss: 0.3911
2024-06-03 10:21:03 [INFO]: Epoch 050 - training loss: 0.3509, validation loss: 0.4132
2024-06-03 10:21:07 [INFO]: Epoch 051 - training loss: 0.3470, validation loss: 0.4133
2024-06-03 10:21:09 [INFO]: Epoch 052 - training loss: 0.3472, validation loss: 0.4465
2024-06-03 10:21:12 [INFO]: Epoch 053 - training loss: 0.3497, validation loss: 0.4091
2024-06-03 10:21:15 [INFO]: Epoch 054 - training loss: 0.3429, validation loss: 0.3969
2024-06-03 10:21:18 [INFO]: Epoch 055 - training loss: 0.3419, validation loss: 0.4086
2024-06-03 10:21:21 [INFO]: Epoch 056 - training loss: 0.3389, validation loss: 0.4044
2024-06-03 10:21:24 [INFO]: Epoch 057 - training loss: 0.3366, validation loss: 0.3918
2024-06-03 10:21:27 [INFO]: Epoch 058 - training loss: 0.3382, validation loss: 0.4005
2024-06-03 10:21:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:21:27 [INFO]: Finished training. The best model is from epoch#48.
2024-06-03 10:21:28 [INFO]: Saved the model to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_2/20240603_T101813/SAITS.pypots
2024-06-03 10:21:29 [INFO]: Successfully saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_2/imputation.pkl
2024-06-03 10:21:29 [INFO]: Round2 - SAITS on ItalyAir: MAE=0.3995, MSE=0.3540, MRE=0.4882
2024-06-03 10:21:29 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:21:29 [INFO]: Using the given device: cuda:0
2024-06-03 10:21:29 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_3/20240603_T102129
2024-06-03 10:21:29 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_3/20240603_T102129/tensorboard
2024-06-03 10:21:29 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=128
2024-06-03 10:21:29 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-03 10:21:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 16,628,642
2024-06-03 10:21:33 [INFO]: Epoch 001 - training loss: 1.1371, validation loss: 1.9650
2024-06-03 10:21:35 [INFO]: Epoch 002 - training loss: 0.9466, validation loss: 1.6944
2024-06-03 10:21:38 [INFO]: Epoch 003 - training loss: 0.8501, validation loss: 1.5329
2024-06-03 10:21:41 [INFO]: Epoch 004 - training loss: 0.8031, validation loss: 1.4244
2024-06-03 10:21:44 [INFO]: Epoch 005 - training loss: 0.7491, validation loss: 1.3173
2024-06-03 10:21:47 [INFO]: Epoch 006 - training loss: 0.7293, validation loss: 1.1896
2024-06-03 10:21:50 [INFO]: Epoch 007 - training loss: 0.6998, validation loss: 1.1408
2024-06-03 10:21:52 [INFO]: Epoch 008 - training loss: 0.6621, validation loss: 1.0728
2024-06-03 10:21:55 [INFO]: Epoch 009 - training loss: 0.6541, validation loss: 0.9605
2024-06-03 10:21:58 [INFO]: Epoch 010 - training loss: 0.6400, validation loss: 0.9388
2024-06-03 10:22:01 [INFO]: Epoch 011 - training loss: 0.6149, validation loss: 0.9005
2024-06-03 10:22:04 [INFO]: Epoch 012 - training loss: 0.6092, validation loss: 0.8739
2024-06-03 10:22:07 [INFO]: Epoch 013 - training loss: 0.6102, validation loss: 0.8223
2024-06-03 10:22:10 [INFO]: Epoch 014 - training loss: 0.5888, validation loss: 0.7883
2024-06-03 10:22:13 [INFO]: Epoch 015 - training loss: 0.5774, validation loss: 0.8264
2024-06-03 10:22:16 [INFO]: Epoch 016 - training loss: 0.5647, validation loss: 0.8177
2024-06-03 10:22:19 [INFO]: Epoch 017 - training loss: 0.5532, validation loss: 0.7634
2024-06-03 10:22:21 [INFO]: Epoch 018 - training loss: 0.5439, validation loss: 0.7469
2024-06-03 10:22:24 [INFO]: Epoch 019 - training loss: 0.5314, validation loss: 0.7647
2024-06-03 10:22:27 [INFO]: Epoch 020 - training loss: 0.5311, validation loss: 0.7562
2024-06-03 10:22:30 [INFO]: Epoch 021 - training loss: 0.5165, validation loss: 0.7323
2024-06-03 10:22:33 [INFO]: Epoch 022 - training loss: 0.5139, validation loss: 0.6975
2024-06-03 10:22:36 [INFO]: Epoch 023 - training loss: 0.4979, validation loss: 0.6785
2024-06-03 10:22:39 [INFO]: Epoch 024 - training loss: 0.4933, validation loss: 0.6788
2024-06-03 10:22:42 [INFO]: Epoch 025 - training loss: 0.5021, validation loss: 0.6340
2024-06-03 10:22:44 [INFO]: Epoch 026 - training loss: 0.4771, validation loss: 0.6268
2024-06-03 10:22:47 [INFO]: Epoch 027 - training loss: 0.4790, validation loss: 0.6042
2024-06-03 10:22:49 [INFO]: Epoch 028 - training loss: 0.4652, validation loss: 0.5949
2024-06-03 10:22:52 [INFO]: Epoch 029 - training loss: 0.4634, validation loss: 0.5937
2024-06-03 10:22:55 [INFO]: Epoch 030 - training loss: 0.4648, validation loss: 0.5503
2024-06-03 10:22:58 [INFO]: Epoch 031 - training loss: 0.4576, validation loss: 0.5990
2024-06-03 10:23:01 [INFO]: Epoch 032 - training loss: 0.4420, validation loss: 0.5399
2024-06-03 10:23:04 [INFO]: Epoch 033 - training loss: 0.4484, validation loss: 0.5334
2024-06-03 10:23:06 [INFO]: Epoch 034 - training loss: 0.4382, validation loss: 0.5312
2024-06-03 10:23:09 [INFO]: Epoch 035 - training loss: 0.4489, validation loss: 0.5436
2024-06-03 10:23:12 [INFO]: Epoch 036 - training loss: 0.4375, validation loss: 0.5133
2024-06-03 10:23:15 [INFO]: Epoch 037 - training loss: 0.4306, validation loss: 0.5192
2024-06-03 10:23:17 [INFO]: Epoch 038 - training loss: 0.4184, validation loss: 0.4960
2024-06-03 10:23:20 [INFO]: Epoch 039 - training loss: 0.4125, validation loss: 0.4927
2024-06-03 10:23:23 [INFO]: Epoch 040 - training loss: 0.4146, validation loss: 0.5036
2024-06-03 10:23:26 [INFO]: Epoch 041 - training loss: 0.4068, validation loss: 0.4696
2024-06-03 10:23:29 [INFO]: Epoch 042 - training loss: 0.4066, validation loss: 0.4676
2024-06-03 10:23:31 [INFO]: Epoch 043 - training loss: 0.4086, validation loss: 0.4800
2024-06-03 10:23:34 [INFO]: Epoch 044 - training loss: 0.3997, validation loss: 0.4646
2024-06-03 10:23:36 [INFO]: Epoch 045 - training loss: 0.3948, validation loss: 0.4911
2024-06-03 10:23:39 [INFO]: Epoch 046 - training loss: 0.3938, validation loss: 0.4961
2024-06-03 10:23:41 [INFO]: Epoch 047 - training loss: 0.3901, validation loss: 0.4300
2024-06-03 10:23:43 [INFO]: Epoch 048 - training loss: 0.3894, validation loss: 0.4519
2024-06-03 10:23:46 [INFO]: Epoch 049 - training loss: 0.3908, validation loss: 0.4502
2024-06-03 10:23:48 [INFO]: Epoch 050 - training loss: 0.3831, validation loss: 0.4315
2024-06-03 10:23:51 [INFO]: Epoch 051 - training loss: 0.3865, validation loss: 0.4387
2024-06-03 10:23:53 [INFO]: Epoch 052 - training loss: 0.3756, validation loss: 0.4026
2024-06-03 10:23:55 [INFO]: Epoch 053 - training loss: 0.3811, validation loss: 0.4437
2024-06-03 10:23:58 [INFO]: Epoch 054 - training loss: 0.3760, validation loss: 0.4509
2024-06-03 10:24:01 [INFO]: Epoch 055 - training loss: 0.3749, validation loss: 0.4646
2024-06-03 10:24:03 [INFO]: Epoch 056 - training loss: 0.3746, validation loss: 0.4598
2024-06-03 10:24:05 [INFO]: Epoch 057 - training loss: 0.3690, validation loss: 0.4638
2024-06-03 10:24:08 [INFO]: Epoch 058 - training loss: 0.3646, validation loss: 0.4249
2024-06-03 10:24:10 [INFO]: Epoch 059 - training loss: 0.3575, validation loss: 0.4185
2024-06-03 10:24:13 [INFO]: Epoch 060 - training loss: 0.3654, validation loss: 0.4348
2024-06-03 10:24:15 [INFO]: Epoch 061 - training loss: 0.3594, validation loss: 0.4207
2024-06-03 10:24:17 [INFO]: Epoch 062 - training loss: 0.3591, validation loss: 0.3650
2024-06-03 10:24:19 [INFO]: Epoch 063 - training loss: 0.3618, validation loss: 0.3900
2024-06-03 10:24:22 [INFO]: Epoch 064 - training loss: 0.3523, validation loss: 0.3800
2024-06-03 10:24:24 [INFO]: Epoch 065 - training loss: 0.3526, validation loss: 0.4127
2024-06-03 10:24:27 [INFO]: Epoch 066 - training loss: 0.3450, validation loss: 0.4258
2024-06-03 10:24:29 [INFO]: Epoch 067 - training loss: 0.3547, validation loss: 0.3913
2024-06-03 10:24:32 [INFO]: Epoch 068 - training loss: 0.3401, validation loss: 0.3919
2024-06-03 10:24:34 [INFO]: Epoch 069 - training loss: 0.3343, validation loss: 0.4044
2024-06-03 10:24:36 [INFO]: Epoch 070 - training loss: 0.3404, validation loss: 0.4042
2024-06-03 10:24:39 [INFO]: Epoch 071 - training loss: 0.3416, validation loss: 0.4228
2024-06-03 10:24:41 [INFO]: Epoch 072 - training loss: 0.3390, validation loss: 0.4324
2024-06-03 10:24:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:24:41 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 10:24:42 [INFO]: Saved the model to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_3/20240603_T102129/SAITS.pypots
2024-06-03 10:24:43 [INFO]: Successfully saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_3/imputation.pkl
2024-06-03 10:24:43 [INFO]: Round3 - SAITS on ItalyAir: MAE=0.4109, MSE=0.3807, MRE=0.5021
2024-06-03 10:24:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:24:43 [INFO]: Using the given device: cuda:0
2024-06-03 10:24:43 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_4/20240603_T102443
2024-06-03 10:24:43 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_4/20240603_T102443/tensorboard
2024-06-03 10:24:43 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=128
2024-06-03 10:24:43 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (8) * d_k (128)
2024-06-03 10:24:43 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 16,628,642
2024-06-03 10:24:46 [INFO]: Epoch 001 - training loss: 1.1588, validation loss: 1.9247
2024-06-03 10:24:47 [INFO]: Epoch 002 - training loss: 0.9501, validation loss: 1.5809
2024-06-03 10:24:49 [INFO]: Epoch 003 - training loss: 0.8533, validation loss: 1.3302
2024-06-03 10:24:51 [INFO]: Epoch 004 - training loss: 0.7881, validation loss: 1.1739
2024-06-03 10:24:53 [INFO]: Epoch 005 - training loss: 0.7481, validation loss: 1.0392
2024-06-03 10:24:55 [INFO]: Epoch 006 - training loss: 0.7045, validation loss: 0.9452
2024-06-03 10:24:57 [INFO]: Epoch 007 - training loss: 0.6782, validation loss: 0.8837
2024-06-03 10:25:00 [INFO]: Epoch 008 - training loss: 0.6491, validation loss: 0.8053
2024-06-03 10:25:01 [INFO]: Epoch 009 - training loss: 0.6347, validation loss: 0.7603
2024-06-03 10:25:03 [INFO]: Epoch 010 - training loss: 0.6172, validation loss: 0.7400
2024-06-03 10:25:05 [INFO]: Epoch 011 - training loss: 0.5995, validation loss: 0.6940
2024-06-03 10:25:07 [INFO]: Epoch 012 - training loss: 0.5880, validation loss: 0.6526
2024-06-03 10:25:09 [INFO]: Epoch 013 - training loss: 0.5779, validation loss: 0.6469
2024-06-03 10:25:11 [INFO]: Epoch 014 - training loss: 0.5691, validation loss: 0.6260
2024-06-03 10:25:13 [INFO]: Epoch 015 - training loss: 0.5623, validation loss: 0.6089
2024-06-03 10:25:15 [INFO]: Epoch 016 - training loss: 0.5501, validation loss: 0.5862
2024-06-03 10:25:17 [INFO]: Epoch 017 - training loss: 0.5357, validation loss: 0.5782
2024-06-03 10:25:19 [INFO]: Epoch 018 - training loss: 0.5425, validation loss: 0.5961
2024-06-03 10:25:21 [INFO]: Epoch 019 - training loss: 0.5347, validation loss: 0.5568
2024-06-03 10:25:23 [INFO]: Epoch 020 - training loss: 0.5191, validation loss: 0.5935
2024-06-03 10:25:25 [INFO]: Epoch 021 - training loss: 0.5127, validation loss: 0.5953
2024-06-03 10:25:26 [INFO]: Epoch 022 - training loss: 0.5172, validation loss: 0.5553
2024-06-03 10:25:28 [INFO]: Epoch 023 - training loss: 0.5092, validation loss: 0.5402
2024-06-03 10:25:30 [INFO]: Epoch 024 - training loss: 0.5063, validation loss: 0.5688
2024-06-03 10:25:32 [INFO]: Epoch 025 - training loss: 0.4995, validation loss: 0.5452
2024-06-03 10:25:34 [INFO]: Epoch 026 - training loss: 0.4983, validation loss: 0.5704
2024-06-03 10:25:36 [INFO]: Epoch 027 - training loss: 0.4921, validation loss: 0.5275
2024-06-03 10:25:38 [INFO]: Epoch 028 - training loss: 0.4854, validation loss: 0.4933
2024-06-03 10:25:40 [INFO]: Epoch 029 - training loss: 0.4772, validation loss: 0.5098
2024-06-03 10:25:41 [INFO]: Epoch 030 - training loss: 0.4748, validation loss: 0.5191
2024-06-03 10:25:43 [INFO]: Epoch 031 - training loss: 0.4747, validation loss: 0.5158
2024-06-03 10:25:44 [INFO]: Epoch 032 - training loss: 0.4711, validation loss: 0.5436
2024-06-03 10:25:46 [INFO]: Epoch 033 - training loss: 0.4641, validation loss: 0.4848
2024-06-03 10:25:48 [INFO]: Epoch 034 - training loss: 0.4568, validation loss: 0.5280
2024-06-03 10:25:50 [INFO]: Epoch 035 - training loss: 0.4565, validation loss: 0.4848
2024-06-03 10:25:51 [INFO]: Epoch 036 - training loss: 0.4583, validation loss: 0.4668
2024-06-03 10:25:53 [INFO]: Epoch 037 - training loss: 0.4472, validation loss: 0.4640
2024-06-03 10:25:55 [INFO]: Epoch 038 - training loss: 0.4472, validation loss: 0.4957
2024-06-03 10:25:57 [INFO]: Epoch 039 - training loss: 0.4399, validation loss: 0.5057
2024-06-03 10:25:58 [INFO]: Epoch 040 - training loss: 0.4369, validation loss: 0.4795
2024-06-03 10:26:00 [INFO]: Epoch 041 - training loss: 0.4266, validation loss: 0.4610
2024-06-03 10:26:02 [INFO]: Epoch 042 - training loss: 0.4395, validation loss: 0.5030
2024-06-03 10:26:03 [INFO]: Epoch 043 - training loss: 0.4333, validation loss: 0.4682
2024-06-03 10:26:05 [INFO]: Epoch 044 - training loss: 0.4288, validation loss: 0.4442
2024-06-03 10:26:06 [INFO]: Epoch 045 - training loss: 0.4300, validation loss: 0.4954
2024-06-03 10:26:07 [INFO]: Epoch 046 - training loss: 0.4194, validation loss: 0.5105
2024-06-03 10:26:09 [INFO]: Epoch 047 - training loss: 0.4196, validation loss: 0.4601
2024-06-03 10:26:10 [INFO]: Epoch 048 - training loss: 0.4151, validation loss: 0.4452
2024-06-03 10:26:11 [INFO]: Epoch 049 - training loss: 0.4226, validation loss: 0.4523
2024-06-03 10:26:12 [INFO]: Epoch 050 - training loss: 0.4148, validation loss: 0.4159
2024-06-03 10:26:13 [INFO]: Epoch 051 - training loss: 0.4140, validation loss: 0.4441
2024-06-03 10:26:14 [INFO]: Epoch 052 - training loss: 0.4145, validation loss: 0.4749
2024-06-03 10:26:15 [INFO]: Epoch 053 - training loss: 0.4041, validation loss: 0.4790
2024-06-03 10:26:16 [INFO]: Epoch 054 - training loss: 0.4033, validation loss: 0.4380
2024-06-03 10:26:17 [INFO]: Epoch 055 - training loss: 0.3960, validation loss: 0.4211
2024-06-03 10:26:19 [INFO]: Epoch 056 - training loss: 0.3946, validation loss: 0.4335
2024-06-03 10:26:19 [INFO]: Epoch 057 - training loss: 0.3954, validation loss: 0.4098
2024-06-03 10:26:21 [INFO]: Epoch 058 - training loss: 0.3905, validation loss: 0.4560
2024-06-03 10:26:22 [INFO]: Epoch 059 - training loss: 0.3986, validation loss: 0.4798
2024-06-03 10:26:23 [INFO]: Epoch 060 - training loss: 0.3921, validation loss: 0.4022
2024-06-03 10:26:24 [INFO]: Epoch 061 - training loss: 0.3846, validation loss: 0.3983
2024-06-03 10:26:25 [INFO]: Epoch 062 - training loss: 0.3855, validation loss: 0.4210
2024-06-03 10:26:26 [INFO]: Epoch 063 - training loss: 0.3820, validation loss: 0.4143
2024-06-03 10:26:27 [INFO]: Epoch 064 - training loss: 0.3812, validation loss: 0.4401
2024-06-03 10:26:29 [INFO]: Epoch 065 - training loss: 0.3794, validation loss: 0.4353
2024-06-03 10:26:30 [INFO]: Epoch 066 - training loss: 0.3825, validation loss: 0.4248
2024-06-03 10:26:31 [INFO]: Epoch 067 - training loss: 0.3787, validation loss: 0.4114
2024-06-03 10:26:32 [INFO]: Epoch 068 - training loss: 0.3638, validation loss: 0.4122
2024-06-03 10:26:33 [INFO]: Epoch 069 - training loss: 0.3653, validation loss: 0.4228
2024-06-03 10:26:34 [INFO]: Epoch 070 - training loss: 0.3708, validation loss: 0.3991
2024-06-03 10:26:35 [INFO]: Epoch 071 - training loss: 0.3638, validation loss: 0.4019
2024-06-03 10:26:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:26:35 [INFO]: Finished training. The best model is from epoch#61.
2024-06-03 10:26:36 [INFO]: Saved the model to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_4/20240603_T102443/SAITS.pypots
2024-06-03 10:26:36 [INFO]: Successfully saved to results_block_rate05/ItalyAir/SAITS_ItalyAir/round_4/imputation.pkl
2024-06-03 10:26:36 [INFO]: Round4 - SAITS on ItalyAir: MAE=0.4142, MSE=0.3772, MRE=0.5061
2024-06-03 10:26:36 [INFO]: Done! Final results:
Averaged SAITS (16,628,642 params) on ItalyAir: MAE=0.4159 ± 0.012307972668033232, MSE=0.3910 ± 0.02855349001543988, MRE=0.5082 ± 0.01504079347600995, average inference time=0.29
