2024-06-03 10:00:03 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:00:03 [INFO]: Using the given device: cuda:0
2024-06-03 10:00:07 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240603_T100007
2024-06-03 10:00:07 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240603_T100007/tensorboard
2024-06-03 10:00:07 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-03 10:00:07 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-03 10:00:14 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-03 10:00:27 [INFO]: Epoch 001 - training loss: 1.1616, validation loss: 1.5555
2024-06-03 10:00:34 [INFO]: Epoch 002 - training loss: 0.6389, validation loss: 1.2521
2024-06-03 10:00:41 [INFO]: Epoch 003 - training loss: 0.5557, validation loss: 1.2024
2024-06-03 10:00:49 [INFO]: Epoch 004 - training loss: 0.5201, validation loss: 1.1839
2024-06-03 10:00:56 [INFO]: Epoch 005 - training loss: 0.5056, validation loss: 1.0824
2024-06-03 10:01:03 [INFO]: Epoch 006 - training loss: 0.4792, validation loss: 1.0735
2024-06-03 10:01:10 [INFO]: Epoch 007 - training loss: 0.4652, validation loss: 1.0984
2024-06-03 10:01:18 [INFO]: Epoch 008 - training loss: 0.4561, validation loss: 1.0300
2024-06-03 10:01:26 [INFO]: Epoch 009 - training loss: 0.4448, validation loss: 1.0112
2024-06-03 10:01:32 [INFO]: Epoch 010 - training loss: 0.4302, validation loss: 1.0295
2024-06-03 10:01:40 [INFO]: Epoch 011 - training loss: 0.4137, validation loss: 1.0428
2024-06-03 10:01:48 [INFO]: Epoch 012 - training loss: 0.4031, validation loss: 1.0436
2024-06-03 10:01:55 [INFO]: Epoch 013 - training loss: 0.3979, validation loss: 0.9501
2024-06-03 10:02:02 [INFO]: Epoch 014 - training loss: 0.4100, validation loss: 0.9680
2024-06-03 10:02:09 [INFO]: Epoch 015 - training loss: 0.4112, validation loss: 1.0120
2024-06-03 10:02:17 [INFO]: Epoch 016 - training loss: 0.3923, validation loss: 0.9663
2024-06-03 10:02:25 [INFO]: Epoch 017 - training loss: 0.3875, validation loss: 0.9268
2024-06-03 10:02:33 [INFO]: Epoch 018 - training loss: 0.3860, validation loss: 0.8934
2024-06-03 10:02:40 [INFO]: Epoch 019 - training loss: 0.3748, validation loss: 1.0462
2024-06-03 10:02:48 [INFO]: Epoch 020 - training loss: 0.3651, validation loss: 0.9319
2024-06-03 10:02:56 [INFO]: Epoch 021 - training loss: 0.3664, validation loss: 0.9504
2024-06-03 10:03:04 [INFO]: Epoch 022 - training loss: 0.3795, validation loss: 0.9419
2024-06-03 10:03:12 [INFO]: Epoch 023 - training loss: 0.3721, validation loss: 0.9487
2024-06-03 10:03:19 [INFO]: Epoch 024 - training loss: 0.3723, validation loss: 0.9455
2024-06-03 10:03:27 [INFO]: Epoch 025 - training loss: 0.3646, validation loss: 0.8714
2024-06-03 10:03:33 [INFO]: Epoch 026 - training loss: 0.3420, validation loss: 0.9073
2024-06-03 10:03:41 [INFO]: Epoch 027 - training loss: 0.3433, validation loss: 0.8925
2024-06-03 10:03:48 [INFO]: Epoch 028 - training loss: 0.3458, validation loss: 0.9241
2024-06-03 10:03:55 [INFO]: Epoch 029 - training loss: 0.3361, validation loss: 0.8686
2024-06-03 10:04:02 [INFO]: Epoch 030 - training loss: 0.3478, validation loss: 0.8952
2024-06-03 10:04:10 [INFO]: Epoch 031 - training loss: 0.3457, validation loss: 0.9325
2024-06-03 10:04:18 [INFO]: Epoch 032 - training loss: 0.3310, validation loss: 0.8815
2024-06-03 10:04:26 [INFO]: Epoch 033 - training loss: 0.3297, validation loss: 0.8826
2024-06-03 10:04:33 [INFO]: Epoch 034 - training loss: 0.3368, validation loss: 0.8592
2024-06-03 10:04:41 [INFO]: Epoch 035 - training loss: 0.3282, validation loss: 0.8957
2024-06-03 10:04:49 [INFO]: Epoch 036 - training loss: 0.3387, validation loss: 0.8749
2024-06-03 10:04:56 [INFO]: Epoch 037 - training loss: 0.3333, validation loss: 0.8353
2024-06-03 10:05:04 [INFO]: Epoch 038 - training loss: 0.3259, validation loss: 0.8606
2024-06-03 10:05:11 [INFO]: Epoch 039 - training loss: 0.3276, validation loss: 0.9832
2024-06-03 10:05:18 [INFO]: Epoch 040 - training loss: 0.3238, validation loss: 0.8607
2024-06-03 10:05:26 [INFO]: Epoch 041 - training loss: 0.3207, validation loss: 0.8472
2024-06-03 10:05:33 [INFO]: Epoch 042 - training loss: 0.3203, validation loss: 0.8382
2024-06-03 10:05:40 [INFO]: Epoch 043 - training loss: 0.3121, validation loss: 0.8527
2024-06-03 10:05:49 [INFO]: Epoch 044 - training loss: 0.3165, validation loss: 0.8307
2024-06-03 10:05:56 [INFO]: Epoch 045 - training loss: 0.3084, validation loss: 0.8438
2024-06-03 10:06:04 [INFO]: Epoch 046 - training loss: 0.3202, validation loss: 0.8706
2024-06-03 10:06:11 [INFO]: Epoch 047 - training loss: 0.3040, validation loss: 0.8499
2024-06-03 10:06:18 [INFO]: Epoch 048 - training loss: 0.3073, validation loss: 0.8487
2024-06-03 10:06:25 [INFO]: Epoch 049 - training loss: 0.3158, validation loss: 0.8335
2024-06-03 10:06:33 [INFO]: Epoch 050 - training loss: 0.3126, validation loss: 0.8129
2024-06-03 10:06:40 [INFO]: Epoch 051 - training loss: 0.3097, validation loss: 0.8344
2024-06-03 10:06:47 [INFO]: Epoch 052 - training loss: 0.3062, validation loss: 0.8006
2024-06-03 10:06:55 [INFO]: Epoch 053 - training loss: 0.3020, validation loss: 0.8071
2024-06-03 10:07:02 [INFO]: Epoch 054 - training loss: 0.2962, validation loss: 0.8235
2024-06-03 10:07:09 [INFO]: Epoch 055 - training loss: 0.3054, validation loss: 0.8130
2024-06-03 10:07:16 [INFO]: Epoch 056 - training loss: 0.3174, validation loss: 0.8273
2024-06-03 10:07:22 [INFO]: Epoch 057 - training loss: 0.3096, validation loss: 0.7964
2024-06-03 10:07:30 [INFO]: Epoch 058 - training loss: 0.2987, validation loss: 0.7877
2024-06-03 10:07:36 [INFO]: Epoch 059 - training loss: 0.2980, validation loss: 0.8147
2024-06-03 10:07:44 [INFO]: Epoch 060 - training loss: 0.3004, validation loss: 0.7791
2024-06-03 10:07:51 [INFO]: Epoch 061 - training loss: 0.2891, validation loss: 0.7900
2024-06-03 10:07:57 [INFO]: Epoch 062 - training loss: 0.3010, validation loss: 0.8073
2024-06-03 10:08:04 [INFO]: Epoch 063 - training loss: 0.2912, validation loss: 0.8098
2024-06-03 10:08:12 [INFO]: Epoch 064 - training loss: 0.2920, validation loss: 0.8491
2024-06-03 10:08:20 [INFO]: Epoch 065 - training loss: 0.2943, validation loss: 0.8252
2024-06-03 10:08:27 [INFO]: Epoch 066 - training loss: 0.2931, validation loss: 0.7971
2024-06-03 10:08:34 [INFO]: Epoch 067 - training loss: 0.2897, validation loss: 0.8188
2024-06-03 10:08:41 [INFO]: Epoch 068 - training loss: 0.2927, validation loss: 0.7888
2024-06-03 10:08:49 [INFO]: Epoch 069 - training loss: 0.2977, validation loss: 0.7824
2024-06-03 10:08:56 [INFO]: Epoch 070 - training loss: 0.2810, validation loss: 0.7864
2024-06-03 10:08:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:08:56 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 10:08:57 [INFO]: Saved the model to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240603_T100007/iTransformer.pypots
2024-06-03 10:08:59 [INFO]: Successfully saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_0/imputation.pkl
2024-06-03 10:08:59 [INFO]: Round0 - iTransformer on ItalyAir: MAE=0.4902, MSE=0.5690, MRE=0.5991
2024-06-03 10:08:59 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:08:59 [INFO]: Using the given device: cuda:0
2024-06-03 10:08:59 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240603_T100859
2024-06-03 10:08:59 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240603_T100859/tensorboard
2024-06-03 10:08:59 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-03 10:08:59 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-03 10:09:02 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-03 10:09:09 [INFO]: Epoch 001 - training loss: 1.1246, validation loss: 1.4335
2024-06-03 10:09:16 [INFO]: Epoch 002 - training loss: 0.6306, validation loss: 1.3608
2024-06-03 10:09:22 [INFO]: Epoch 003 - training loss: 0.5500, validation loss: 1.1889
2024-06-03 10:09:29 [INFO]: Epoch 004 - training loss: 0.5304, validation loss: 1.1656
2024-06-03 10:09:36 [INFO]: Epoch 005 - training loss: 0.4856, validation loss: 1.1574
2024-06-03 10:09:43 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 1.0568
2024-06-03 10:09:50 [INFO]: Epoch 007 - training loss: 0.4608, validation loss: 1.0085
2024-06-03 10:09:57 [INFO]: Epoch 008 - training loss: 0.4592, validation loss: 1.0399
2024-06-03 10:10:04 [INFO]: Epoch 009 - training loss: 0.4422, validation loss: 1.0549
2024-06-03 10:10:11 [INFO]: Epoch 010 - training loss: 0.4117, validation loss: 1.0259
2024-06-03 10:10:17 [INFO]: Epoch 011 - training loss: 0.4076, validation loss: 1.0045
2024-06-03 10:10:24 [INFO]: Epoch 012 - training loss: 0.4234, validation loss: 0.9373
2024-06-03 10:10:31 [INFO]: Epoch 013 - training loss: 0.4129, validation loss: 0.9781
2024-06-03 10:10:38 [INFO]: Epoch 014 - training loss: 0.4128, validation loss: 0.9137
2024-06-03 10:10:44 [INFO]: Epoch 015 - training loss: 0.3850, validation loss: 0.9274
2024-06-03 10:10:50 [INFO]: Epoch 016 - training loss: 0.3845, validation loss: 0.9500
2024-06-03 10:10:57 [INFO]: Epoch 017 - training loss: 0.3753, validation loss: 0.8772
2024-06-03 10:11:04 [INFO]: Epoch 018 - training loss: 0.3677, validation loss: 0.9479
2024-06-03 10:11:11 [INFO]: Epoch 019 - training loss: 0.3748, validation loss: 0.8778
2024-06-03 10:11:18 [INFO]: Epoch 020 - training loss: 0.3542, validation loss: 0.8580
2024-06-03 10:11:24 [INFO]: Epoch 021 - training loss: 0.3623, validation loss: 0.9060
2024-06-03 10:11:32 [INFO]: Epoch 022 - training loss: 0.3627, validation loss: 0.8530
2024-06-03 10:11:39 [INFO]: Epoch 023 - training loss: 0.3536, validation loss: 0.8387
2024-06-03 10:11:46 [INFO]: Epoch 024 - training loss: 0.3523, validation loss: 0.9218
2024-06-03 10:11:53 [INFO]: Epoch 025 - training loss: 0.3557, validation loss: 0.8387
2024-06-03 10:11:59 [INFO]: Epoch 026 - training loss: 0.3503, validation loss: 0.9141
2024-06-03 10:12:06 [INFO]: Epoch 027 - training loss: 0.3434, validation loss: 0.9555
2024-06-03 10:12:13 [INFO]: Epoch 028 - training loss: 0.3432, validation loss: 0.9134
2024-06-03 10:12:20 [INFO]: Epoch 029 - training loss: 0.3454, validation loss: 0.8892
2024-06-03 10:12:26 [INFO]: Epoch 030 - training loss: 0.3568, validation loss: 0.8182
2024-06-03 10:12:33 [INFO]: Epoch 031 - training loss: 0.3396, validation loss: 0.8746
2024-06-03 10:12:40 [INFO]: Epoch 032 - training loss: 0.3397, validation loss: 0.8431
2024-06-03 10:12:46 [INFO]: Epoch 033 - training loss: 0.3438, validation loss: 0.8292
2024-06-03 10:12:53 [INFO]: Epoch 034 - training loss: 0.3466, validation loss: 0.8844
2024-06-03 10:12:59 [INFO]: Epoch 035 - training loss: 0.3401, validation loss: 0.8334
2024-06-03 10:13:06 [INFO]: Epoch 036 - training loss: 0.3227, validation loss: 0.8629
2024-06-03 10:13:13 [INFO]: Epoch 037 - training loss: 0.3199, validation loss: 0.8337
2024-06-03 10:13:20 [INFO]: Epoch 038 - training loss: 0.3230, validation loss: 0.8705
2024-06-03 10:13:25 [INFO]: Epoch 039 - training loss: 0.3249, validation loss: 0.7972
2024-06-03 10:13:31 [INFO]: Epoch 040 - training loss: 0.3095, validation loss: 0.8500
2024-06-03 10:13:38 [INFO]: Epoch 041 - training loss: 0.3084, validation loss: 0.8112
2024-06-03 10:13:44 [INFO]: Epoch 042 - training loss: 0.3107, validation loss: 0.8343
2024-06-03 10:13:50 [INFO]: Epoch 043 - training loss: 0.3201, validation loss: 0.8734
2024-06-03 10:13:56 [INFO]: Epoch 044 - training loss: 0.3329, validation loss: 0.8527
2024-06-03 10:14:02 [INFO]: Epoch 045 - training loss: 0.3174, validation loss: 0.8322
2024-06-03 10:14:09 [INFO]: Epoch 046 - training loss: 0.3213, validation loss: 0.8511
2024-06-03 10:14:16 [INFO]: Epoch 047 - training loss: 0.3039, validation loss: 0.8080
2024-06-03 10:14:21 [INFO]: Epoch 048 - training loss: 0.3119, validation loss: 0.8350
2024-06-03 10:14:27 [INFO]: Epoch 049 - training loss: 0.3182, validation loss: 0.8246
2024-06-03 10:14:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:14:27 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 10:14:28 [INFO]: Saved the model to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240603_T100859/iTransformer.pypots
2024-06-03 10:14:31 [INFO]: Successfully saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_1/imputation.pkl
2024-06-03 10:14:31 [INFO]: Round1 - iTransformer on ItalyAir: MAE=0.4965, MSE=0.5974, MRE=0.6067
2024-06-03 10:14:31 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:14:31 [INFO]: Using the given device: cuda:0
2024-06-03 10:14:31 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240603_T101431
2024-06-03 10:14:31 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240603_T101431/tensorboard
2024-06-03 10:14:31 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-03 10:14:31 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-03 10:14:33 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-03 10:14:39 [INFO]: Epoch 001 - training loss: 1.1336, validation loss: 1.4220
2024-06-03 10:14:45 [INFO]: Epoch 002 - training loss: 0.6216, validation loss: 1.2838
2024-06-03 10:14:51 [INFO]: Epoch 003 - training loss: 0.5452, validation loss: 1.1452
2024-06-03 10:14:57 [INFO]: Epoch 004 - training loss: 0.5203, validation loss: 1.1269
2024-06-03 10:15:04 [INFO]: Epoch 005 - training loss: 0.5104, validation loss: 1.1012
2024-06-03 10:15:10 [INFO]: Epoch 006 - training loss: 0.4959, validation loss: 0.9970
2024-06-03 10:15:16 [INFO]: Epoch 007 - training loss: 0.4655, validation loss: 1.0700
2024-06-03 10:15:22 [INFO]: Epoch 008 - training loss: 0.4442, validation loss: 1.1878
2024-06-03 10:15:28 [INFO]: Epoch 009 - training loss: 0.4403, validation loss: 1.0189
2024-06-03 10:15:35 [INFO]: Epoch 010 - training loss: 0.4269, validation loss: 1.0789
2024-06-03 10:15:40 [INFO]: Epoch 011 - training loss: 0.4387, validation loss: 0.9528
2024-06-03 10:15:46 [INFO]: Epoch 012 - training loss: 0.4253, validation loss: 1.0389
2024-06-03 10:15:51 [INFO]: Epoch 013 - training loss: 0.3988, validation loss: 0.9421
2024-06-03 10:15:58 [INFO]: Epoch 014 - training loss: 0.4064, validation loss: 0.9448
2024-06-03 10:16:04 [INFO]: Epoch 015 - training loss: 0.4049, validation loss: 1.0606
2024-06-03 10:16:10 [INFO]: Epoch 016 - training loss: 0.3819, validation loss: 1.0091
2024-06-03 10:16:15 [INFO]: Epoch 017 - training loss: 0.3888, validation loss: 0.9323
2024-06-03 10:16:21 [INFO]: Epoch 018 - training loss: 0.3767, validation loss: 0.9204
2024-06-03 10:16:28 [INFO]: Epoch 019 - training loss: 0.3739, validation loss: 1.0170
2024-06-03 10:16:34 [INFO]: Epoch 020 - training loss: 0.3709, validation loss: 0.9476
2024-06-03 10:16:39 [INFO]: Epoch 021 - training loss: 0.3593, validation loss: 0.9350
2024-06-03 10:16:45 [INFO]: Epoch 022 - training loss: 0.3635, validation loss: 0.8862
2024-06-03 10:16:51 [INFO]: Epoch 023 - training loss: 0.3836, validation loss: 0.9956
2024-06-03 10:16:57 [INFO]: Epoch 024 - training loss: 0.3717, validation loss: 0.8563
2024-06-03 10:17:03 [INFO]: Epoch 025 - training loss: 0.3582, validation loss: 1.0311
2024-06-03 10:17:09 [INFO]: Epoch 026 - training loss: 0.3670, validation loss: 0.9179
2024-06-03 10:17:15 [INFO]: Epoch 027 - training loss: 0.3640, validation loss: 0.8691
2024-06-03 10:17:21 [INFO]: Epoch 028 - training loss: 0.3558, validation loss: 0.8336
2024-06-03 10:17:28 [INFO]: Epoch 029 - training loss: 0.3533, validation loss: 0.8882
2024-06-03 10:17:33 [INFO]: Epoch 030 - training loss: 0.3469, validation loss: 0.8502
2024-06-03 10:17:40 [INFO]: Epoch 031 - training loss: 0.3322, validation loss: 0.8724
2024-06-03 10:17:45 [INFO]: Epoch 032 - training loss: 0.3434, validation loss: 0.8657
2024-06-03 10:17:51 [INFO]: Epoch 033 - training loss: 0.3242, validation loss: 0.9011
2024-06-03 10:17:57 [INFO]: Epoch 034 - training loss: 0.3330, validation loss: 0.8470
2024-06-03 10:18:03 [INFO]: Epoch 035 - training loss: 0.3275, validation loss: 0.8515
2024-06-03 10:18:08 [INFO]: Epoch 036 - training loss: 0.3321, validation loss: 0.8469
2024-06-03 10:18:12 [INFO]: Epoch 037 - training loss: 0.3249, validation loss: 0.8738
2024-06-03 10:18:15 [INFO]: Epoch 038 - training loss: 0.3243, validation loss: 0.8285
2024-06-03 10:18:18 [INFO]: Epoch 039 - training loss: 0.3263, validation loss: 0.8636
2024-06-03 10:18:22 [INFO]: Epoch 040 - training loss: 0.3131, validation loss: 0.8259
2024-06-03 10:18:26 [INFO]: Epoch 041 - training loss: 0.3178, validation loss: 0.8421
2024-06-03 10:18:29 [INFO]: Epoch 042 - training loss: 0.3155, validation loss: 0.8342
2024-06-03 10:18:32 [INFO]: Epoch 043 - training loss: 0.3186, validation loss: 0.8379
2024-06-03 10:18:35 [INFO]: Epoch 044 - training loss: 0.3089, validation loss: 0.8669
2024-06-03 10:18:39 [INFO]: Epoch 045 - training loss: 0.3050, validation loss: 0.8264
2024-06-03 10:18:42 [INFO]: Epoch 046 - training loss: 0.3055, validation loss: 0.8305
2024-06-03 10:18:46 [INFO]: Epoch 047 - training loss: 0.3091, validation loss: 0.8560
2024-06-03 10:18:49 [INFO]: Epoch 048 - training loss: 0.3088, validation loss: 0.8546
2024-06-03 10:18:52 [INFO]: Epoch 049 - training loss: 0.3183, validation loss: 0.8236
2024-06-03 10:18:55 [INFO]: Epoch 050 - training loss: 0.3129, validation loss: 0.7970
2024-06-03 10:18:59 [INFO]: Epoch 051 - training loss: 0.3090, validation loss: 0.8330
2024-06-03 10:19:02 [INFO]: Epoch 052 - training loss: 0.3024, validation loss: 0.8565
2024-06-03 10:19:05 [INFO]: Epoch 053 - training loss: 0.3004, validation loss: 0.8273
2024-06-03 10:19:08 [INFO]: Epoch 054 - training loss: 0.2982, validation loss: 0.8021
2024-06-03 10:19:11 [INFO]: Epoch 055 - training loss: 0.2920, validation loss: 0.7995
2024-06-03 10:19:15 [INFO]: Epoch 056 - training loss: 0.3042, validation loss: 0.8165
2024-06-03 10:19:18 [INFO]: Epoch 057 - training loss: 0.3098, validation loss: 0.8368
2024-06-03 10:19:21 [INFO]: Epoch 058 - training loss: 0.3003, validation loss: 0.8462
2024-06-03 10:19:24 [INFO]: Epoch 059 - training loss: 0.3023, validation loss: 0.7985
2024-06-03 10:19:27 [INFO]: Epoch 060 - training loss: 0.2971, validation loss: 0.7869
2024-06-03 10:19:30 [INFO]: Epoch 061 - training loss: 0.3064, validation loss: 0.7869
2024-06-03 10:19:33 [INFO]: Epoch 062 - training loss: 0.2939, validation loss: 0.8455
2024-06-03 10:19:36 [INFO]: Epoch 063 - training loss: 0.2939, validation loss: 0.8400
2024-06-03 10:19:39 [INFO]: Epoch 064 - training loss: 0.2832, validation loss: 0.8027
2024-06-03 10:19:43 [INFO]: Epoch 065 - training loss: 0.2939, validation loss: 0.8414
2024-06-03 10:19:46 [INFO]: Epoch 066 - training loss: 0.2764, validation loss: 0.8110
2024-06-03 10:19:49 [INFO]: Epoch 067 - training loss: 0.2800, validation loss: 0.7816
2024-06-03 10:19:53 [INFO]: Epoch 068 - training loss: 0.2884, validation loss: 0.8036
2024-06-03 10:19:56 [INFO]: Epoch 069 - training loss: 0.2902, validation loss: 0.8062
2024-06-03 10:19:59 [INFO]: Epoch 070 - training loss: 0.2933, validation loss: 0.8237
2024-06-03 10:20:02 [INFO]: Epoch 071 - training loss: 0.2823, validation loss: 0.7839
2024-06-03 10:20:05 [INFO]: Epoch 072 - training loss: 0.2923, validation loss: 0.8117
2024-06-03 10:20:08 [INFO]: Epoch 073 - training loss: 0.2847, validation loss: 0.8070
2024-06-03 10:20:10 [INFO]: Epoch 074 - training loss: 0.2934, validation loss: 0.8207
2024-06-03 10:20:13 [INFO]: Epoch 075 - training loss: 0.2779, validation loss: 0.8030
2024-06-03 10:20:15 [INFO]: Epoch 076 - training loss: 0.2833, validation loss: 0.7915
2024-06-03 10:20:18 [INFO]: Epoch 077 - training loss: 0.2904, validation loss: 0.7712
2024-06-03 10:20:21 [INFO]: Epoch 078 - training loss: 0.2885, validation loss: 0.8166
2024-06-03 10:20:23 [INFO]: Epoch 079 - training loss: 0.2810, validation loss: 0.8247
2024-06-03 10:20:26 [INFO]: Epoch 080 - training loss: 0.2771, validation loss: 0.8293
2024-06-03 10:20:29 [INFO]: Epoch 081 - training loss: 0.2721, validation loss: 0.8020
2024-06-03 10:20:31 [INFO]: Epoch 082 - training loss: 0.2801, validation loss: 0.8041
2024-06-03 10:20:34 [INFO]: Epoch 083 - training loss: 0.2707, validation loss: 0.8229
2024-06-03 10:20:37 [INFO]: Epoch 084 - training loss: 0.2712, validation loss: 0.8016
2024-06-03 10:20:39 [INFO]: Epoch 085 - training loss: 0.2711, validation loss: 0.8097
2024-06-03 10:20:42 [INFO]: Epoch 086 - training loss: 0.2787, validation loss: 0.8168
2024-06-03 10:20:45 [INFO]: Epoch 087 - training loss: 0.2692, validation loss: 0.8085
2024-06-03 10:20:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:20:45 [INFO]: Finished training. The best model is from epoch#77.
2024-06-03 10:20:46 [INFO]: Saved the model to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240603_T101431/iTransformer.pypots
2024-06-03 10:20:47 [INFO]: Successfully saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_2/imputation.pkl
2024-06-03 10:20:47 [INFO]: Round2 - iTransformer on ItalyAir: MAE=0.4969, MSE=0.5944, MRE=0.6073
2024-06-03 10:20:47 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:20:47 [INFO]: Using the given device: cuda:0
2024-06-03 10:20:47 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240603_T102047
2024-06-03 10:20:47 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240603_T102047/tensorboard
2024-06-03 10:20:47 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-03 10:20:47 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-03 10:20:48 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-03 10:20:51 [INFO]: Epoch 001 - training loss: 1.1821, validation loss: 1.4806
2024-06-03 10:20:54 [INFO]: Epoch 002 - training loss: 0.6485, validation loss: 1.2853
2024-06-03 10:20:56 [INFO]: Epoch 003 - training loss: 0.5534, validation loss: 1.1224
2024-06-03 10:20:59 [INFO]: Epoch 004 - training loss: 0.5249, validation loss: 1.1516
2024-06-03 10:21:01 [INFO]: Epoch 005 - training loss: 0.4865, validation loss: 1.0978
2024-06-03 10:21:04 [INFO]: Epoch 006 - training loss: 0.4789, validation loss: 1.0926
2024-06-03 10:21:06 [INFO]: Epoch 007 - training loss: 0.4670, validation loss: 0.9938
2024-06-03 10:21:09 [INFO]: Epoch 008 - training loss: 0.4449, validation loss: 1.0416
2024-06-03 10:21:12 [INFO]: Epoch 009 - training loss: 0.4195, validation loss: 1.0120
2024-06-03 10:21:14 [INFO]: Epoch 010 - training loss: 0.4239, validation loss: 1.0607
2024-06-03 10:21:17 [INFO]: Epoch 011 - training loss: 0.4203, validation loss: 0.9685
2024-06-03 10:21:20 [INFO]: Epoch 012 - training loss: 0.4022, validation loss: 0.9610
2024-06-03 10:21:22 [INFO]: Epoch 013 - training loss: 0.4012, validation loss: 0.9591
2024-06-03 10:21:25 [INFO]: Epoch 014 - training loss: 0.3933, validation loss: 0.9512
2024-06-03 10:21:27 [INFO]: Epoch 015 - training loss: 0.4084, validation loss: 0.9441
2024-06-03 10:21:30 [INFO]: Epoch 016 - training loss: 0.3949, validation loss: 0.8898
2024-06-03 10:21:32 [INFO]: Epoch 017 - training loss: 0.3833, validation loss: 0.9255
2024-06-03 10:21:35 [INFO]: Epoch 018 - training loss: 0.3860, validation loss: 0.8908
2024-06-03 10:21:37 [INFO]: Epoch 019 - training loss: 0.3958, validation loss: 0.9362
2024-06-03 10:21:40 [INFO]: Epoch 020 - training loss: 0.3876, validation loss: 0.9220
2024-06-03 10:21:42 [INFO]: Epoch 021 - training loss: 0.3694, validation loss: 0.9055
2024-06-03 10:21:45 [INFO]: Epoch 022 - training loss: 0.3705, validation loss: 0.9249
2024-06-03 10:21:47 [INFO]: Epoch 023 - training loss: 0.3582, validation loss: 0.8423
2024-06-03 10:21:50 [INFO]: Epoch 024 - training loss: 0.3538, validation loss: 0.8802
2024-06-03 10:21:52 [INFO]: Epoch 025 - training loss: 0.3535, validation loss: 0.8601
2024-06-03 10:21:55 [INFO]: Epoch 026 - training loss: 0.3542, validation loss: 0.8221
2024-06-03 10:21:57 [INFO]: Epoch 027 - training loss: 0.3602, validation loss: 0.8341
2024-06-03 10:22:00 [INFO]: Epoch 028 - training loss: 0.3459, validation loss: 0.8441
2024-06-03 10:22:02 [INFO]: Epoch 029 - training loss: 0.3394, validation loss: 0.8391
2024-06-03 10:22:05 [INFO]: Epoch 030 - training loss: 0.3531, validation loss: 0.8880
2024-06-03 10:22:07 [INFO]: Epoch 031 - training loss: 0.3362, validation loss: 0.8312
2024-06-03 10:22:10 [INFO]: Epoch 032 - training loss: 0.3364, validation loss: 0.8836
2024-06-03 10:22:12 [INFO]: Epoch 033 - training loss: 0.3342, validation loss: 0.8573
2024-06-03 10:22:15 [INFO]: Epoch 034 - training loss: 0.3435, validation loss: 0.8145
2024-06-03 10:22:17 [INFO]: Epoch 035 - training loss: 0.3264, validation loss: 0.8873
2024-06-03 10:22:20 [INFO]: Epoch 036 - training loss: 0.3252, validation loss: 0.8021
2024-06-03 10:22:22 [INFO]: Epoch 037 - training loss: 0.3266, validation loss: 0.8304
2024-06-03 10:22:25 [INFO]: Epoch 038 - training loss: 0.3150, validation loss: 0.8119
2024-06-03 10:22:27 [INFO]: Epoch 039 - training loss: 0.3273, validation loss: 0.8657
2024-06-03 10:22:30 [INFO]: Epoch 040 - training loss: 0.3399, validation loss: 0.8138
2024-06-03 10:22:32 [INFO]: Epoch 041 - training loss: 0.3195, validation loss: 0.7887
2024-06-03 10:22:35 [INFO]: Epoch 042 - training loss: 0.3249, validation loss: 0.8303
2024-06-03 10:22:37 [INFO]: Epoch 043 - training loss: 0.3201, validation loss: 0.8648
2024-06-03 10:22:39 [INFO]: Epoch 044 - training loss: 0.3171, validation loss: 0.8388
2024-06-03 10:22:42 [INFO]: Epoch 045 - training loss: 0.3130, validation loss: 0.8088
2024-06-03 10:22:44 [INFO]: Epoch 046 - training loss: 0.3196, validation loss: 0.8171
2024-06-03 10:22:46 [INFO]: Epoch 047 - training loss: 0.3210, validation loss: 0.8421
2024-06-03 10:22:49 [INFO]: Epoch 048 - training loss: 0.3034, validation loss: 0.7843
2024-06-03 10:22:52 [INFO]: Epoch 049 - training loss: 0.3152, validation loss: 0.7899
2024-06-03 10:22:54 [INFO]: Epoch 050 - training loss: 0.3070, validation loss: 0.7697
2024-06-03 10:22:57 [INFO]: Epoch 051 - training loss: 0.3098, validation loss: 0.8326
2024-06-03 10:22:59 [INFO]: Epoch 052 - training loss: 0.3149, validation loss: 0.7997
2024-06-03 10:23:02 [INFO]: Epoch 053 - training loss: 0.3055, validation loss: 0.7812
2024-06-03 10:23:04 [INFO]: Epoch 054 - training loss: 0.3107, validation loss: 0.7937
2024-06-03 10:23:07 [INFO]: Epoch 055 - training loss: 0.3043, validation loss: 0.7647
2024-06-03 10:23:10 [INFO]: Epoch 056 - training loss: 0.3009, validation loss: 0.7767
2024-06-03 10:23:12 [INFO]: Epoch 057 - training loss: 0.2983, validation loss: 0.9114
2024-06-03 10:23:15 [INFO]: Epoch 058 - training loss: 0.3133, validation loss: 0.7772
2024-06-03 10:23:17 [INFO]: Epoch 059 - training loss: 0.3149, validation loss: 0.8484
2024-06-03 10:23:20 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.7855
2024-06-03 10:23:22 [INFO]: Epoch 061 - training loss: 0.2909, validation loss: 0.8110
2024-06-03 10:23:25 [INFO]: Epoch 062 - training loss: 0.2962, validation loss: 0.7773
2024-06-03 10:23:27 [INFO]: Epoch 063 - training loss: 0.2977, validation loss: 0.7751
2024-06-03 10:23:30 [INFO]: Epoch 064 - training loss: 0.2896, validation loss: 0.7846
2024-06-03 10:23:32 [INFO]: Epoch 065 - training loss: 0.2905, validation loss: 0.7984
2024-06-03 10:23:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:23:32 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 10:23:33 [INFO]: Saved the model to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240603_T102047/iTransformer.pypots
2024-06-03 10:23:33 [INFO]: Successfully saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_3/imputation.pkl
2024-06-03 10:23:33 [INFO]: Round3 - iTransformer on ItalyAir: MAE=0.5000, MSE=0.5819, MRE=0.6110
2024-06-03 10:23:33 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:23:33 [INFO]: Using the given device: cuda:0
2024-06-03 10:23:33 [INFO]: Model files will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240603_T102333
2024-06-03 10:23:33 [INFO]: Tensorboard file will be saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240603_T102333/tensorboard
2024-06-03 10:23:33 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-03 10:23:33 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-03 10:23:34 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-03 10:23:37 [INFO]: Epoch 001 - training loss: 1.1971, validation loss: 1.4722
2024-06-03 10:23:39 [INFO]: Epoch 002 - training loss: 0.6521, validation loss: 1.3160
2024-06-03 10:23:41 [INFO]: Epoch 003 - training loss: 0.5461, validation loss: 1.1741
2024-06-03 10:23:43 [INFO]: Epoch 004 - training loss: 0.5179, validation loss: 1.0896
2024-06-03 10:23:45 [INFO]: Epoch 005 - training loss: 0.4855, validation loss: 1.0823
2024-06-03 10:23:48 [INFO]: Epoch 006 - training loss: 0.4808, validation loss: 1.0725
2024-06-03 10:23:50 [INFO]: Epoch 007 - training loss: 0.4666, validation loss: 1.0396
2024-06-03 10:23:52 [INFO]: Epoch 008 - training loss: 0.4375, validation loss: 1.0986
2024-06-03 10:23:54 [INFO]: Epoch 009 - training loss: 0.4446, validation loss: 0.9638
2024-06-03 10:23:56 [INFO]: Epoch 010 - training loss: 0.4207, validation loss: 0.9939
2024-06-03 10:23:58 [INFO]: Epoch 011 - training loss: 0.4303, validation loss: 0.9716
2024-06-03 10:24:00 [INFO]: Epoch 012 - training loss: 0.4214, validation loss: 0.9194
2024-06-03 10:24:03 [INFO]: Epoch 013 - training loss: 0.3983, validation loss: 0.9384
2024-06-03 10:24:05 [INFO]: Epoch 014 - training loss: 0.4039, validation loss: 0.9259
2024-06-03 10:24:07 [INFO]: Epoch 015 - training loss: 0.4081, validation loss: 0.8840
2024-06-03 10:24:09 [INFO]: Epoch 016 - training loss: 0.4026, validation loss: 0.8566
2024-06-03 10:24:11 [INFO]: Epoch 017 - training loss: 0.3880, validation loss: 0.9904
2024-06-03 10:24:13 [INFO]: Epoch 018 - training loss: 0.3723, validation loss: 0.8759
2024-06-03 10:24:15 [INFO]: Epoch 019 - training loss: 0.3658, validation loss: 0.8892
2024-06-03 10:24:17 [INFO]: Epoch 020 - training loss: 0.3581, validation loss: 0.9760
2024-06-03 10:24:19 [INFO]: Epoch 021 - training loss: 0.3734, validation loss: 0.8738
2024-06-03 10:24:21 [INFO]: Epoch 022 - training loss: 0.3643, validation loss: 0.8973
2024-06-03 10:24:23 [INFO]: Epoch 023 - training loss: 0.3550, validation loss: 0.8506
2024-06-03 10:24:26 [INFO]: Epoch 024 - training loss: 0.3516, validation loss: 0.8799
2024-06-03 10:24:28 [INFO]: Epoch 025 - training loss: 0.3656, validation loss: 0.8727
2024-06-03 10:24:30 [INFO]: Epoch 026 - training loss: 0.3572, validation loss: 0.8966
2024-06-03 10:24:32 [INFO]: Epoch 027 - training loss: 0.3454, validation loss: 0.8496
2024-06-03 10:24:34 [INFO]: Epoch 028 - training loss: 0.3501, validation loss: 0.8476
2024-06-03 10:24:36 [INFO]: Epoch 029 - training loss: 0.3465, validation loss: 0.8421
2024-06-03 10:24:38 [INFO]: Epoch 030 - training loss: 0.3469, validation loss: 0.8547
2024-06-03 10:24:40 [INFO]: Epoch 031 - training loss: 0.3424, validation loss: 0.8050
2024-06-03 10:24:43 [INFO]: Epoch 032 - training loss: 0.3372, validation loss: 0.8372
2024-06-03 10:24:45 [INFO]: Epoch 033 - training loss: 0.3352, validation loss: 0.8304
2024-06-03 10:24:46 [INFO]: Epoch 034 - training loss: 0.3330, validation loss: 0.8216
2024-06-03 10:24:48 [INFO]: Epoch 035 - training loss: 0.3205, validation loss: 0.8345
2024-06-03 10:24:50 [INFO]: Epoch 036 - training loss: 0.3419, validation loss: 0.8411
2024-06-03 10:24:52 [INFO]: Epoch 037 - training loss: 0.3250, validation loss: 0.8301
2024-06-03 10:24:54 [INFO]: Epoch 038 - training loss: 0.3382, validation loss: 0.8386
2024-06-03 10:24:56 [INFO]: Epoch 039 - training loss: 0.3211, validation loss: 0.8034
2024-06-03 10:24:57 [INFO]: Epoch 040 - training loss: 0.3259, validation loss: 0.8226
2024-06-03 10:24:59 [INFO]: Epoch 041 - training loss: 0.3243, validation loss: 0.8005
2024-06-03 10:25:01 [INFO]: Epoch 042 - training loss: 0.3270, validation loss: 0.8181
2024-06-03 10:25:02 [INFO]: Epoch 043 - training loss: 0.3230, validation loss: 0.9448
2024-06-03 10:25:04 [INFO]: Epoch 044 - training loss: 0.3320, validation loss: 0.8237
2024-06-03 10:25:06 [INFO]: Epoch 045 - training loss: 0.3154, validation loss: 0.8085
2024-06-03 10:25:08 [INFO]: Epoch 046 - training loss: 0.3106, validation loss: 0.8270
2024-06-03 10:25:09 [INFO]: Epoch 047 - training loss: 0.3179, validation loss: 0.7889
2024-06-03 10:25:11 [INFO]: Epoch 048 - training loss: 0.3148, validation loss: 0.7957
2024-06-03 10:25:13 [INFO]: Epoch 049 - training loss: 0.3093, validation loss: 0.7904
2024-06-03 10:25:15 [INFO]: Epoch 050 - training loss: 0.3048, validation loss: 0.7694
2024-06-03 10:25:17 [INFO]: Epoch 051 - training loss: 0.3153, validation loss: 0.7895
2024-06-03 10:25:19 [INFO]: Epoch 052 - training loss: 0.3161, validation loss: 0.7906
2024-06-03 10:25:21 [INFO]: Epoch 053 - training loss: 0.3210, validation loss: 0.7886
2024-06-03 10:25:23 [INFO]: Epoch 054 - training loss: 0.3106, validation loss: 0.7992
2024-06-03 10:25:24 [INFO]: Epoch 055 - training loss: 0.3040, validation loss: 0.8602
2024-06-03 10:25:26 [INFO]: Epoch 056 - training loss: 0.3007, validation loss: 0.7832
2024-06-03 10:25:28 [INFO]: Epoch 057 - training loss: 0.2996, validation loss: 0.7922
2024-06-03 10:25:29 [INFO]: Epoch 058 - training loss: 0.3191, validation loss: 0.7744
2024-06-03 10:25:31 [INFO]: Epoch 059 - training loss: 0.2967, validation loss: 0.7749
2024-06-03 10:25:33 [INFO]: Epoch 060 - training loss: 0.2891, validation loss: 0.7713
2024-06-03 10:25:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:25:33 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 10:25:34 [INFO]: Saved the model to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240603_T102333/iTransformer.pypots
2024-06-03 10:25:34 [INFO]: Successfully saved to results_block_rate05/ItalyAir/iTransformer_ItalyAir/round_4/imputation.pkl
2024-06-03 10:25:34 [INFO]: Round4 - iTransformer on ItalyAir: MAE=0.4840, MSE=0.5508, MRE=0.5915
2024-06-03 10:25:34 [INFO]: Done! Final results:
Averaged iTransformer (18,932,236 params) on ItalyAir: MAE=0.4935 ± 0.0057225449339432495, MSE=0.5787 ± 0.017191338506325936, MRE=0.6031 ± 0.00699315954220274, average inference time=0.33
