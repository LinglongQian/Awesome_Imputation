2024-06-02 19:38:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:38:47 [INFO]: Using the given device: cuda:0
2024-06-02 19:38:47 [INFO]: Model files will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_0/20240602_T193847
2024-06-02 19:38:47 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_0/20240602_T193847/tensorboard
2024-06-02 19:38:48 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 5,301,100
2024-06-02 19:38:52 [INFO]: Epoch 001 - training loss: 2.5138, validation loss: 1.0864
2024-06-02 19:38:54 [INFO]: Epoch 002 - training loss: 0.9065, validation loss: 0.7920
2024-06-02 19:38:56 [INFO]: Epoch 003 - training loss: 0.6644, validation loss: 0.6571
2024-06-02 19:38:59 [INFO]: Epoch 004 - training loss: 0.5540, validation loss: 0.5954
2024-06-02 19:39:01 [INFO]: Epoch 005 - training loss: 0.5202, validation loss: 0.5716
2024-06-02 19:39:04 [INFO]: Epoch 006 - training loss: 0.4912, validation loss: 0.5421
2024-06-02 19:39:07 [INFO]: Epoch 007 - training loss: 0.4687, validation loss: 0.5366
2024-06-02 19:39:10 [INFO]: Epoch 008 - training loss: 0.4557, validation loss: 0.5290
2024-06-02 19:39:13 [INFO]: Epoch 009 - training loss: 0.4433, validation loss: 0.5262
2024-06-02 19:39:16 [INFO]: Epoch 010 - training loss: 0.4330, validation loss: 0.5067
2024-06-02 19:39:19 [INFO]: Epoch 011 - training loss: 0.4200, validation loss: 0.5103
2024-06-02 19:39:21 [INFO]: Epoch 012 - training loss: 0.4106, validation loss: 0.4952
2024-06-02 19:39:25 [INFO]: Epoch 013 - training loss: 0.4121, validation loss: 0.4922
2024-06-02 19:39:28 [INFO]: Epoch 014 - training loss: 0.4066, validation loss: 0.4841
2024-06-02 19:39:30 [INFO]: Epoch 015 - training loss: 0.3963, validation loss: 0.4982
2024-06-02 19:39:33 [INFO]: Epoch 016 - training loss: 0.3885, validation loss: 0.4839
2024-06-02 19:39:36 [INFO]: Epoch 017 - training loss: 0.3839, validation loss: 0.4929
2024-06-02 19:39:39 [INFO]: Epoch 018 - training loss: 0.3751, validation loss: 0.4813
2024-06-02 19:39:42 [INFO]: Epoch 019 - training loss: 0.3755, validation loss: 0.4680
2024-06-02 19:39:45 [INFO]: Epoch 020 - training loss: 0.3756, validation loss: 0.4757
2024-06-02 19:39:47 [INFO]: Epoch 021 - training loss: 0.3682, validation loss: 0.4824
2024-06-02 19:39:50 [INFO]: Epoch 022 - training loss: 0.3613, validation loss: 0.4805
2024-06-02 19:39:52 [INFO]: Epoch 023 - training loss: 0.3599, validation loss: 0.4580
2024-06-02 19:39:55 [INFO]: Epoch 024 - training loss: 0.3809, validation loss: 0.4700
2024-06-02 19:39:58 [INFO]: Epoch 025 - training loss: 0.3666, validation loss: 0.4609
2024-06-02 19:40:01 [INFO]: Epoch 026 - training loss: 0.3595, validation loss: 0.4681
2024-06-02 19:40:04 [INFO]: Epoch 027 - training loss: 0.3515, validation loss: 0.4705
2024-06-02 19:40:06 [INFO]: Epoch 028 - training loss: 0.3479, validation loss: 0.4662
2024-06-02 19:40:09 [INFO]: Epoch 029 - training loss: 0.3486, validation loss: 0.4621
2024-06-02 19:40:12 [INFO]: Epoch 030 - training loss: 0.3525, validation loss: 0.4569
2024-06-02 19:40:16 [INFO]: Epoch 031 - training loss: 0.3461, validation loss: 0.4691
2024-06-02 19:40:19 [INFO]: Epoch 032 - training loss: 0.3443, validation loss: 0.4644
2024-06-02 19:40:22 [INFO]: Epoch 033 - training loss: 0.3436, validation loss: 0.4581
2024-06-02 19:40:25 [INFO]: Epoch 034 - training loss: 0.3390, validation loss: 0.4608
2024-06-02 19:40:27 [INFO]: Epoch 035 - training loss: 0.3345, validation loss: 0.4535
2024-06-02 19:40:30 [INFO]: Epoch 036 - training loss: 0.3352, validation loss: 0.4487
2024-06-02 19:40:33 [INFO]: Epoch 037 - training loss: 0.3359, validation loss: 0.4571
2024-06-02 19:40:36 [INFO]: Epoch 038 - training loss: 0.3343, validation loss: 0.4550
2024-06-02 19:40:39 [INFO]: Epoch 039 - training loss: 0.3347, validation loss: 0.4584
2024-06-02 19:40:41 [INFO]: Epoch 040 - training loss: 0.3319, validation loss: 0.4504
2024-06-02 19:40:44 [INFO]: Epoch 041 - training loss: 0.3309, validation loss: 0.4615
2024-06-02 19:40:47 [INFO]: Epoch 042 - training loss: 0.3322, validation loss: 0.4546
2024-06-02 19:40:49 [INFO]: Epoch 043 - training loss: 0.3326, validation loss: 0.4500
2024-06-02 19:40:52 [INFO]: Epoch 044 - training loss: 0.3298, validation loss: 0.4507
2024-06-02 19:40:55 [INFO]: Epoch 045 - training loss: 0.3268, validation loss: 0.4467
2024-06-02 19:40:58 [INFO]: Epoch 046 - training loss: 0.3246, validation loss: 0.4578
2024-06-02 19:41:01 [INFO]: Epoch 047 - training loss: 0.3250, validation loss: 0.4540
2024-06-02 19:41:04 [INFO]: Epoch 048 - training loss: 0.3220, validation loss: 0.4474
2024-06-02 19:41:07 [INFO]: Epoch 049 - training loss: 0.3219, validation loss: 0.4452
2024-06-02 19:41:09 [INFO]: Epoch 050 - training loss: 0.3247, validation loss: 0.4555
2024-06-02 19:41:12 [INFO]: Epoch 051 - training loss: 0.3276, validation loss: 0.4441
2024-06-02 19:41:15 [INFO]: Epoch 052 - training loss: 0.3229, validation loss: 0.4378
2024-06-02 19:41:18 [INFO]: Epoch 053 - training loss: 0.3191, validation loss: 0.4436
2024-06-02 19:41:21 [INFO]: Epoch 054 - training loss: 0.3195, validation loss: 0.4429
2024-06-02 19:41:24 [INFO]: Epoch 055 - training loss: 0.3207, validation loss: 0.4412
2024-06-02 19:41:27 [INFO]: Epoch 056 - training loss: 0.3209, validation loss: 0.4425
2024-06-02 19:41:30 [INFO]: Epoch 057 - training loss: 0.3199, validation loss: 0.4457
2024-06-02 19:41:33 [INFO]: Epoch 058 - training loss: 0.3177, validation loss: 0.4441
2024-06-02 19:41:36 [INFO]: Epoch 059 - training loss: 0.3165, validation loss: 0.4372
2024-06-02 19:41:38 [INFO]: Epoch 060 - training loss: 0.3180, validation loss: 0.4485
2024-06-02 19:41:41 [INFO]: Epoch 061 - training loss: 0.3121, validation loss: 0.4479
2024-06-02 19:41:44 [INFO]: Epoch 062 - training loss: 0.3123, validation loss: 0.4461
2024-06-02 19:41:46 [INFO]: Epoch 063 - training loss: 0.3152, validation loss: 0.4413
2024-06-02 19:41:49 [INFO]: Epoch 064 - training loss: 0.3127, validation loss: 0.4411
2024-06-02 19:41:52 [INFO]: Epoch 065 - training loss: 0.3143, validation loss: 0.4400
2024-06-02 19:41:55 [INFO]: Epoch 066 - training loss: 0.3152, validation loss: 0.4388
2024-06-02 19:41:58 [INFO]: Epoch 067 - training loss: 0.3152, validation loss: 0.4411
2024-06-02 19:42:01 [INFO]: Epoch 068 - training loss: 0.3107, validation loss: 0.4392
2024-06-02 19:42:04 [INFO]: Epoch 069 - training loss: 0.3098, validation loss: 0.4455
2024-06-02 19:42:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:42:04 [INFO]: Finished training. The best model is from epoch#59.
2024-06-02 19:42:04 [INFO]: Saved the model to results_point_rate05/PeMS/DLinear_PeMS/round_0/20240602_T193847/DLinear.pypots
2024-06-02 19:42:05 [INFO]: Successfully saved to results_point_rate05/PeMS/DLinear_PeMS/round_0/imputation.pkl
2024-06-02 19:42:05 [INFO]: Round0 - DLinear on PeMS: MAE=0.4148, MSE=0.6418, MRE=0.5147
2024-06-02 19:42:05 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:42:05 [INFO]: Using the given device: cuda:0
2024-06-02 19:42:05 [INFO]: Model files will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_1/20240602_T194205
2024-06-02 19:42:05 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_1/20240602_T194205/tensorboard
2024-06-02 19:42:06 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 5,301,100
2024-06-02 19:42:08 [INFO]: Epoch 001 - training loss: 2.3636, validation loss: 1.0462
2024-06-02 19:42:11 [INFO]: Epoch 002 - training loss: 0.8798, validation loss: 0.7398
2024-06-02 19:42:14 [INFO]: Epoch 003 - training loss: 0.6494, validation loss: 0.6116
2024-06-02 19:42:17 [INFO]: Epoch 004 - training loss: 0.5507, validation loss: 0.5818
2024-06-02 19:42:20 [INFO]: Epoch 005 - training loss: 0.5102, validation loss: 0.5463
2024-06-02 19:42:23 [INFO]: Epoch 006 - training loss: 0.4755, validation loss: 0.5248
2024-06-02 19:42:25 [INFO]: Epoch 007 - training loss: 0.4612, validation loss: 0.5176
2024-06-02 19:42:28 [INFO]: Epoch 008 - training loss: 0.4430, validation loss: 0.5104
2024-06-02 19:42:30 [INFO]: Epoch 009 - training loss: 0.4323, validation loss: 0.4883
2024-06-02 19:42:33 [INFO]: Epoch 010 - training loss: 0.4178, validation loss: 0.4864
2024-06-02 19:42:36 [INFO]: Epoch 011 - training loss: 0.4027, validation loss: 0.4927
2024-06-02 19:42:39 [INFO]: Epoch 012 - training loss: 0.3986, validation loss: 0.4843
2024-06-02 19:42:41 [INFO]: Epoch 013 - training loss: 0.3908, validation loss: 0.4676
2024-06-02 19:42:44 [INFO]: Epoch 014 - training loss: 0.3839, validation loss: 0.4842
2024-06-02 19:42:47 [INFO]: Epoch 015 - training loss: 0.3869, validation loss: 0.4657
2024-06-02 19:42:50 [INFO]: Epoch 016 - training loss: 0.3790, validation loss: 0.4684
2024-06-02 19:42:53 [INFO]: Epoch 017 - training loss: 0.3689, validation loss: 0.4567
2024-06-02 19:42:56 [INFO]: Epoch 018 - training loss: 0.3646, validation loss: 0.4502
2024-06-02 19:42:59 [INFO]: Epoch 019 - training loss: 0.3656, validation loss: 0.4513
2024-06-02 19:43:01 [INFO]: Epoch 020 - training loss: 0.3642, validation loss: 0.4524
2024-06-02 19:43:04 [INFO]: Epoch 021 - training loss: 0.3582, validation loss: 0.4452
2024-06-02 19:43:07 [INFO]: Epoch 022 - training loss: 0.3522, validation loss: 0.4447
2024-06-02 19:43:10 [INFO]: Epoch 023 - training loss: 0.3531, validation loss: 0.4623
2024-06-02 19:43:13 [INFO]: Epoch 024 - training loss: 0.3515, validation loss: 0.4391
2024-06-02 19:43:15 [INFO]: Epoch 025 - training loss: 0.3462, validation loss: 0.4339
2024-06-02 19:43:18 [INFO]: Epoch 026 - training loss: 0.3484, validation loss: 0.4406
2024-06-02 19:43:21 [INFO]: Epoch 027 - training loss: 0.3396, validation loss: 0.4294
2024-06-02 19:43:23 [INFO]: Epoch 028 - training loss: 0.3357, validation loss: 0.4310
2024-06-02 19:43:26 [INFO]: Epoch 029 - training loss: 0.3376, validation loss: 0.4244
2024-06-02 19:43:28 [INFO]: Epoch 030 - training loss: 0.3388, validation loss: 0.4291
2024-06-02 19:43:31 [INFO]: Epoch 031 - training loss: 0.3341, validation loss: 0.4426
2024-06-02 19:43:34 [INFO]: Epoch 032 - training loss: 0.3349, validation loss: 0.4283
2024-06-02 19:43:37 [INFO]: Epoch 033 - training loss: 0.3263, validation loss: 0.4241
2024-06-02 19:43:40 [INFO]: Epoch 034 - training loss: 0.3289, validation loss: 0.4359
2024-06-02 19:43:43 [INFO]: Epoch 035 - training loss: 0.3273, validation loss: 0.4285
2024-06-02 19:43:46 [INFO]: Epoch 036 - training loss: 0.3232, validation loss: 0.4164
2024-06-02 19:43:48 [INFO]: Epoch 037 - training loss: 0.3297, validation loss: 0.4307
2024-06-02 19:43:51 [INFO]: Epoch 038 - training loss: 0.3271, validation loss: 0.4235
2024-06-02 19:43:54 [INFO]: Epoch 039 - training loss: 0.3211, validation loss: 0.4202
2024-06-02 19:43:57 [INFO]: Epoch 040 - training loss: 0.3206, validation loss: 0.4203
2024-06-02 19:44:00 [INFO]: Epoch 041 - training loss: 0.3202, validation loss: 0.4280
2024-06-02 19:44:03 [INFO]: Epoch 042 - training loss: 0.3205, validation loss: 0.4228
2024-06-02 19:44:06 [INFO]: Epoch 043 - training loss: 0.3251, validation loss: 0.4209
2024-06-02 19:44:08 [INFO]: Epoch 044 - training loss: 0.3173, validation loss: 0.4190
2024-06-02 19:44:11 [INFO]: Epoch 045 - training loss: 0.3141, validation loss: 0.4212
2024-06-02 19:44:13 [INFO]: Epoch 046 - training loss: 0.3137, validation loss: 0.4183
2024-06-02 19:44:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:44:13 [INFO]: Finished training. The best model is from epoch#36.
2024-06-02 19:44:13 [INFO]: Saved the model to results_point_rate05/PeMS/DLinear_PeMS/round_1/20240602_T194205/DLinear.pypots
2024-06-02 19:44:14 [INFO]: Successfully saved to results_point_rate05/PeMS/DLinear_PeMS/round_1/imputation.pkl
2024-06-02 19:44:14 [INFO]: Round1 - DLinear on PeMS: MAE=0.3764, MSE=0.5915, MRE=0.4670
2024-06-02 19:44:14 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:44:14 [INFO]: Using the given device: cuda:0
2024-06-02 19:44:14 [INFO]: Model files will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_2/20240602_T194414
2024-06-02 19:44:14 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_2/20240602_T194414/tensorboard
2024-06-02 19:44:15 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 5,301,100
2024-06-02 19:44:17 [INFO]: Epoch 001 - training loss: 2.3687, validation loss: 1.0870
2024-06-02 19:44:20 [INFO]: Epoch 002 - training loss: 0.9035, validation loss: 0.7866
2024-06-02 19:44:23 [INFO]: Epoch 003 - training loss: 0.6701, validation loss: 0.6643
2024-06-02 19:44:26 [INFO]: Epoch 004 - training loss: 0.5625, validation loss: 0.6003
2024-06-02 19:44:28 [INFO]: Epoch 005 - training loss: 0.5137, validation loss: 0.5477
2024-06-02 19:44:31 [INFO]: Epoch 006 - training loss: 0.4782, validation loss: 0.5166
2024-06-02 19:44:34 [INFO]: Epoch 007 - training loss: 0.4492, validation loss: 0.5065
2024-06-02 19:44:37 [INFO]: Epoch 008 - training loss: 0.4335, validation loss: 0.4935
2024-06-02 19:44:40 [INFO]: Epoch 009 - training loss: 0.4224, validation loss: 0.4833
2024-06-02 19:44:43 [INFO]: Epoch 010 - training loss: 0.4087, validation loss: 0.4861
2024-06-02 19:44:45 [INFO]: Epoch 011 - training loss: 0.4019, validation loss: 0.4719
2024-06-02 19:44:48 [INFO]: Epoch 012 - training loss: 0.3989, validation loss: 0.4695
2024-06-02 19:44:51 [INFO]: Epoch 013 - training loss: 0.3856, validation loss: 0.4661
2024-06-02 19:44:54 [INFO]: Epoch 014 - training loss: 0.3772, validation loss: 0.4620
2024-06-02 19:44:57 [INFO]: Epoch 015 - training loss: 0.3754, validation loss: 0.4560
2024-06-02 19:44:59 [INFO]: Epoch 016 - training loss: 0.3687, validation loss: 0.4548
2024-06-02 19:45:02 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.4522
2024-06-02 19:45:05 [INFO]: Epoch 018 - training loss: 0.3634, validation loss: 0.4521
2024-06-02 19:45:07 [INFO]: Epoch 019 - training loss: 0.3583, validation loss: 0.4553
2024-06-02 19:45:09 [INFO]: Epoch 020 - training loss: 0.3561, validation loss: 0.4506
2024-06-02 19:45:12 [INFO]: Epoch 021 - training loss: 0.3547, validation loss: 0.4460
2024-06-02 19:45:14 [INFO]: Epoch 022 - training loss: 0.3558, validation loss: 0.4469
2024-06-02 19:45:17 [INFO]: Epoch 023 - training loss: 0.3471, validation loss: 0.4481
2024-06-02 19:45:19 [INFO]: Epoch 024 - training loss: 0.3478, validation loss: 0.4346
2024-06-02 19:45:22 [INFO]: Epoch 025 - training loss: 0.3437, validation loss: 0.4390
2024-06-02 19:45:25 [INFO]: Epoch 026 - training loss: 0.3436, validation loss: 0.4434
2024-06-02 19:45:27 [INFO]: Epoch 027 - training loss: 0.3435, validation loss: 0.4358
2024-06-02 19:45:30 [INFO]: Epoch 028 - training loss: 0.3379, validation loss: 0.4424
2024-06-02 19:45:32 [INFO]: Epoch 029 - training loss: 0.3419, validation loss: 0.4356
2024-06-02 19:45:35 [INFO]: Epoch 030 - training loss: 0.3353, validation loss: 0.4301
2024-06-02 19:45:37 [INFO]: Epoch 031 - training loss: 0.3329, validation loss: 0.4297
2024-06-02 19:45:40 [INFO]: Epoch 032 - training loss: 0.3310, validation loss: 0.4282
2024-06-02 19:45:42 [INFO]: Epoch 033 - training loss: 0.3283, validation loss: 0.4206
2024-06-02 19:45:45 [INFO]: Epoch 034 - training loss: 0.3314, validation loss: 0.4282
2024-06-02 19:45:47 [INFO]: Epoch 035 - training loss: 0.3349, validation loss: 0.4246
2024-06-02 19:45:50 [INFO]: Epoch 036 - training loss: 0.3297, validation loss: 0.4281
2024-06-02 19:45:52 [INFO]: Epoch 037 - training loss: 0.3250, validation loss: 0.4243
2024-06-02 19:45:54 [INFO]: Epoch 038 - training loss: 0.3239, validation loss: 0.4250
2024-06-02 19:45:57 [INFO]: Epoch 039 - training loss: 0.3250, validation loss: 0.4217
2024-06-02 19:45:59 [INFO]: Epoch 040 - training loss: 0.3243, validation loss: 0.4192
2024-06-02 19:46:01 [INFO]: Epoch 041 - training loss: 0.3239, validation loss: 0.4150
2024-06-02 19:46:04 [INFO]: Epoch 042 - training loss: 0.3208, validation loss: 0.4206
2024-06-02 19:46:06 [INFO]: Epoch 043 - training loss: 0.3195, validation loss: 0.4155
2024-06-02 19:46:09 [INFO]: Epoch 044 - training loss: 0.3202, validation loss: 0.4163
2024-06-02 19:46:12 [INFO]: Epoch 045 - training loss: 0.3195, validation loss: 0.4242
2024-06-02 19:46:14 [INFO]: Epoch 046 - training loss: 0.3184, validation loss: 0.4203
2024-06-02 19:46:17 [INFO]: Epoch 047 - training loss: 0.3200, validation loss: 0.4237
2024-06-02 19:46:19 [INFO]: Epoch 048 - training loss: 0.3178, validation loss: 0.4171
2024-06-02 19:46:21 [INFO]: Epoch 049 - training loss: 0.3166, validation loss: 0.4154
2024-06-02 19:46:24 [INFO]: Epoch 050 - training loss: 0.3123, validation loss: 0.4164
2024-06-02 19:46:26 [INFO]: Epoch 051 - training loss: 0.3119, validation loss: 0.4190
2024-06-02 19:46:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:46:26 [INFO]: Finished training. The best model is from epoch#41.
2024-06-02 19:46:27 [INFO]: Saved the model to results_point_rate05/PeMS/DLinear_PeMS/round_2/20240602_T194414/DLinear.pypots
2024-06-02 19:46:27 [INFO]: Successfully saved to results_point_rate05/PeMS/DLinear_PeMS/round_2/imputation.pkl
2024-06-02 19:46:27 [INFO]: Round2 - DLinear on PeMS: MAE=0.3838, MSE=0.5948, MRE=0.4762
2024-06-02 19:46:27 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:46:27 [INFO]: Using the given device: cuda:0
2024-06-02 19:46:27 [INFO]: Model files will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_3/20240602_T194627
2024-06-02 19:46:27 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_3/20240602_T194627/tensorboard
2024-06-02 19:46:28 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 5,301,100
2024-06-02 19:46:30 [INFO]: Epoch 001 - training loss: 2.4221, validation loss: 1.1860
2024-06-02 19:46:33 [INFO]: Epoch 002 - training loss: 0.8985, validation loss: 0.8128
2024-06-02 19:46:36 [INFO]: Epoch 003 - training loss: 0.6852, validation loss: 0.6492
2024-06-02 19:46:38 [INFO]: Epoch 004 - training loss: 0.5817, validation loss: 0.5885
2024-06-02 19:46:41 [INFO]: Epoch 005 - training loss: 0.5192, validation loss: 0.5563
2024-06-02 19:46:43 [INFO]: Epoch 006 - training loss: 0.4884, validation loss: 0.5456
2024-06-02 19:46:45 [INFO]: Epoch 007 - training loss: 0.4666, validation loss: 0.5324
2024-06-02 19:46:48 [INFO]: Epoch 008 - training loss: 0.4459, validation loss: 0.5133
2024-06-02 19:46:50 [INFO]: Epoch 009 - training loss: 0.4287, validation loss: 0.5106
2024-06-02 19:46:53 [INFO]: Epoch 010 - training loss: 0.4233, validation loss: 0.5162
2024-06-02 19:46:55 [INFO]: Epoch 011 - training loss: 0.4131, validation loss: 0.5064
2024-06-02 19:46:58 [INFO]: Epoch 012 - training loss: 0.4103, validation loss: 0.4867
2024-06-02 19:47:00 [INFO]: Epoch 013 - training loss: 0.4027, validation loss: 0.4976
2024-06-02 19:47:03 [INFO]: Epoch 014 - training loss: 0.3981, validation loss: 0.4755
2024-06-02 19:47:05 [INFO]: Epoch 015 - training loss: 0.3947, validation loss: 0.4848
2024-06-02 19:47:08 [INFO]: Epoch 016 - training loss: 0.3872, validation loss: 0.5003
2024-06-02 19:47:10 [INFO]: Epoch 017 - training loss: 0.3811, validation loss: 0.4702
2024-06-02 19:47:13 [INFO]: Epoch 018 - training loss: 0.3782, validation loss: 0.4718
2024-06-02 19:47:15 [INFO]: Epoch 019 - training loss: 0.3699, validation loss: 0.4661
2024-06-02 19:47:18 [INFO]: Epoch 020 - training loss: 0.3718, validation loss: 0.4625
2024-06-02 19:47:21 [INFO]: Epoch 021 - training loss: 0.3760, validation loss: 0.4736
2024-06-02 19:47:23 [INFO]: Epoch 022 - training loss: 0.3705, validation loss: 0.4751
2024-06-02 19:47:25 [INFO]: Epoch 023 - training loss: 0.3683, validation loss: 0.4667
2024-06-02 19:47:28 [INFO]: Epoch 024 - training loss: 0.3603, validation loss: 0.4585
2024-06-02 19:47:31 [INFO]: Epoch 025 - training loss: 0.3606, validation loss: 0.4686
2024-06-02 19:47:33 [INFO]: Epoch 026 - training loss: 0.3563, validation loss: 0.4498
2024-06-02 19:47:36 [INFO]: Epoch 027 - training loss: 0.3535, validation loss: 0.4584
2024-06-02 19:47:38 [INFO]: Epoch 028 - training loss: 0.3521, validation loss: 0.4566
2024-06-02 19:47:40 [INFO]: Epoch 029 - training loss: 0.3462, validation loss: 0.4572
2024-06-02 19:47:42 [INFO]: Epoch 030 - training loss: 0.3534, validation loss: 0.4497
2024-06-02 19:47:45 [INFO]: Epoch 031 - training loss: 0.3469, validation loss: 0.4541
2024-06-02 19:47:47 [INFO]: Epoch 032 - training loss: 0.3453, validation loss: 0.4519
2024-06-02 19:47:50 [INFO]: Epoch 033 - training loss: 0.3427, validation loss: 0.4489
2024-06-02 19:47:53 [INFO]: Epoch 034 - training loss: 0.3422, validation loss: 0.4567
2024-06-02 19:47:55 [INFO]: Epoch 035 - training loss: 0.3366, validation loss: 0.4475
2024-06-02 19:47:58 [INFO]: Epoch 036 - training loss: 0.3339, validation loss: 0.4375
2024-06-02 19:48:00 [INFO]: Epoch 037 - training loss: 0.3377, validation loss: 0.4341
2024-06-02 19:48:03 [INFO]: Epoch 038 - training loss: 0.3416, validation loss: 0.4468
2024-06-02 19:48:05 [INFO]: Epoch 039 - training loss: 0.3321, validation loss: 0.4392
2024-06-02 19:48:08 [INFO]: Epoch 040 - training loss: 0.3310, validation loss: 0.4524
2024-06-02 19:48:10 [INFO]: Epoch 041 - training loss: 0.3321, validation loss: 0.4375
2024-06-02 19:48:13 [INFO]: Epoch 042 - training loss: 0.3263, validation loss: 0.4404
2024-06-02 19:48:16 [INFO]: Epoch 043 - training loss: 0.3233, validation loss: 0.4376
2024-06-02 19:48:18 [INFO]: Epoch 044 - training loss: 0.3238, validation loss: 0.4423
2024-06-02 19:48:21 [INFO]: Epoch 045 - training loss: 0.3244, validation loss: 0.4262
2024-06-02 19:48:23 [INFO]: Epoch 046 - training loss: 0.3218, validation loss: 0.4239
2024-06-02 19:48:26 [INFO]: Epoch 047 - training loss: 0.3228, validation loss: 0.4347
2024-06-02 19:48:28 [INFO]: Epoch 048 - training loss: 0.3201, validation loss: 0.4305
2024-06-02 19:48:30 [INFO]: Epoch 049 - training loss: 0.3196, validation loss: 0.4328
2024-06-02 19:48:32 [INFO]: Epoch 050 - training loss: 0.3196, validation loss: 0.4285
2024-06-02 19:48:35 [INFO]: Epoch 051 - training loss: 0.3192, validation loss: 0.4225
2024-06-02 19:48:37 [INFO]: Epoch 052 - training loss: 0.3206, validation loss: 0.4230
2024-06-02 19:48:40 [INFO]: Epoch 053 - training loss: 0.3194, validation loss: 0.4314
2024-06-02 19:48:42 [INFO]: Epoch 054 - training loss: 0.3143, validation loss: 0.4282
2024-06-02 19:48:45 [INFO]: Epoch 055 - training loss: 0.3164, validation loss: 0.4286
2024-06-02 19:48:47 [INFO]: Epoch 056 - training loss: 0.3165, validation loss: 0.4367
2024-06-02 19:48:50 [INFO]: Epoch 057 - training loss: 0.3160, validation loss: 0.4197
2024-06-02 19:48:52 [INFO]: Epoch 058 - training loss: 0.3133, validation loss: 0.4233
2024-06-02 19:48:55 [INFO]: Epoch 059 - training loss: 0.3134, validation loss: 0.4300
2024-06-02 19:48:57 [INFO]: Epoch 060 - training loss: 0.3146, validation loss: 0.4292
2024-06-02 19:49:00 [INFO]: Epoch 061 - training loss: 0.3132, validation loss: 0.4192
2024-06-02 19:49:03 [INFO]: Epoch 062 - training loss: 0.3150, validation loss: 0.4208
2024-06-02 19:49:05 [INFO]: Epoch 063 - training loss: 0.3107, validation loss: 0.4257
2024-06-02 19:49:08 [INFO]: Epoch 064 - training loss: 0.3095, validation loss: 0.4192
2024-06-02 19:49:10 [INFO]: Epoch 065 - training loss: 0.3112, validation loss: 0.4270
2024-06-02 19:49:12 [INFO]: Epoch 066 - training loss: 0.3164, validation loss: 0.4259
2024-06-02 19:49:15 [INFO]: Epoch 067 - training loss: 0.3070, validation loss: 0.4188
2024-06-02 19:49:17 [INFO]: Epoch 068 - training loss: 0.3074, validation loss: 0.4246
2024-06-02 19:49:19 [INFO]: Epoch 069 - training loss: 0.3109, validation loss: 0.4191
2024-06-02 19:49:21 [INFO]: Epoch 070 - training loss: 0.3089, validation loss: 0.4168
2024-06-02 19:49:24 [INFO]: Epoch 071 - training loss: 0.3076, validation loss: 0.4180
2024-06-02 19:49:26 [INFO]: Epoch 072 - training loss: 0.3059, validation loss: 0.4171
2024-06-02 19:49:29 [INFO]: Epoch 073 - training loss: 0.3028, validation loss: 0.4202
2024-06-02 19:49:32 [INFO]: Epoch 074 - training loss: 0.3047, validation loss: 0.4246
2024-06-02 19:49:34 [INFO]: Epoch 075 - training loss: 0.3048, validation loss: 0.4149
2024-06-02 19:49:37 [INFO]: Epoch 076 - training loss: 0.3129, validation loss: 0.4181
2024-06-02 19:49:39 [INFO]: Epoch 077 - training loss: 0.3073, validation loss: 0.4189
2024-06-02 19:49:42 [INFO]: Epoch 078 - training loss: 0.3052, validation loss: 0.4218
2024-06-02 19:49:44 [INFO]: Epoch 079 - training loss: 0.3041, validation loss: 0.4151
2024-06-02 19:49:47 [INFO]: Epoch 080 - training loss: 0.3066, validation loss: 0.4301
2024-06-02 19:49:49 [INFO]: Epoch 081 - training loss: 0.3057, validation loss: 0.4164
2024-06-02 19:49:52 [INFO]: Epoch 082 - training loss: 0.3029, validation loss: 0.4161
2024-06-02 19:49:54 [INFO]: Epoch 083 - training loss: 0.3035, validation loss: 0.4193
2024-06-02 19:49:56 [INFO]: Epoch 084 - training loss: 0.3016, validation loss: 0.4229
2024-06-02 19:49:59 [INFO]: Epoch 085 - training loss: 0.3045, validation loss: 0.4142
2024-06-02 19:50:02 [INFO]: Epoch 086 - training loss: 0.3020, validation loss: 0.4183
2024-06-02 19:50:04 [INFO]: Epoch 087 - training loss: 0.3052, validation loss: 0.4231
2024-06-02 19:50:06 [INFO]: Epoch 088 - training loss: 0.3044, validation loss: 0.4133
2024-06-02 19:50:09 [INFO]: Epoch 089 - training loss: 0.3001, validation loss: 0.4131
2024-06-02 19:50:11 [INFO]: Epoch 090 - training loss: 0.3023, validation loss: 0.4228
2024-06-02 19:50:13 [INFO]: Epoch 091 - training loss: 0.3013, validation loss: 0.4156
2024-06-02 19:50:16 [INFO]: Epoch 092 - training loss: 0.3052, validation loss: 0.4205
2024-06-02 19:50:18 [INFO]: Epoch 093 - training loss: 0.3033, validation loss: 0.4233
2024-06-02 19:50:20 [INFO]: Epoch 094 - training loss: 0.3026, validation loss: 0.4171
2024-06-02 19:50:23 [INFO]: Epoch 095 - training loss: 0.3017, validation loss: 0.4269
2024-06-02 19:50:25 [INFO]: Epoch 096 - training loss: 0.3007, validation loss: 0.4133
2024-06-02 19:50:28 [INFO]: Epoch 097 - training loss: 0.3061, validation loss: 0.4166
2024-06-02 19:50:30 [INFO]: Epoch 098 - training loss: 0.3016, validation loss: 0.4236
2024-06-02 19:50:33 [INFO]: Epoch 099 - training loss: 0.3029, validation loss: 0.4152
2024-06-02 19:50:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:50:33 [INFO]: Finished training. The best model is from epoch#89.
2024-06-02 19:50:33 [INFO]: Saved the model to results_point_rate05/PeMS/DLinear_PeMS/round_3/20240602_T194627/DLinear.pypots
2024-06-02 19:50:33 [INFO]: Successfully saved to results_point_rate05/PeMS/DLinear_PeMS/round_3/imputation.pkl
2024-06-02 19:50:33 [INFO]: Round3 - DLinear on PeMS: MAE=0.3849, MSE=0.5867, MRE=0.4776
2024-06-02 19:50:33 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:50:33 [INFO]: Using the given device: cuda:0
2024-06-02 19:50:33 [INFO]: Model files will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_4/20240602_T195033
2024-06-02 19:50:33 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/DLinear_PeMS/round_4/20240602_T195033/tensorboard
2024-06-02 19:50:34 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 5,301,100
2024-06-02 19:50:36 [INFO]: Epoch 001 - training loss: 2.7802, validation loss: 1.2441
2024-06-02 19:50:39 [INFO]: Epoch 002 - training loss: 0.9377, validation loss: 0.8416
2024-06-02 19:50:41 [INFO]: Epoch 003 - training loss: 0.6720, validation loss: 0.7023
2024-06-02 19:50:44 [INFO]: Epoch 004 - training loss: 0.5665, validation loss: 0.6471
2024-06-02 19:50:46 [INFO]: Epoch 005 - training loss: 0.5220, validation loss: 0.5961
2024-06-02 19:50:49 [INFO]: Epoch 006 - training loss: 0.4936, validation loss: 0.5771
2024-06-02 19:50:52 [INFO]: Epoch 007 - training loss: 0.4752, validation loss: 0.5757
2024-06-02 19:50:54 [INFO]: Epoch 008 - training loss: 0.4587, validation loss: 0.5355
2024-06-02 19:50:57 [INFO]: Epoch 009 - training loss: 0.4383, validation loss: 0.5098
2024-06-02 19:50:59 [INFO]: Epoch 010 - training loss: 0.4335, validation loss: 0.5230
2024-06-02 19:51:01 [INFO]: Epoch 011 - training loss: 0.4275, validation loss: 0.5101
2024-06-02 19:51:03 [INFO]: Epoch 012 - training loss: 0.4145, validation loss: 0.4966
2024-06-02 19:51:06 [INFO]: Epoch 013 - training loss: 0.4092, validation loss: 0.4854
2024-06-02 19:51:08 [INFO]: Epoch 014 - training loss: 0.4059, validation loss: 0.5056
2024-06-02 19:51:11 [INFO]: Epoch 015 - training loss: 0.3956, validation loss: 0.4746
2024-06-02 19:51:13 [INFO]: Epoch 016 - training loss: 0.3816, validation loss: 0.4791
2024-06-02 19:51:16 [INFO]: Epoch 017 - training loss: 0.3801, validation loss: 0.4712
2024-06-02 19:51:18 [INFO]: Epoch 018 - training loss: 0.3757, validation loss: 0.4630
2024-06-02 19:51:21 [INFO]: Epoch 019 - training loss: 0.3713, validation loss: 0.4569
2024-06-02 19:51:23 [INFO]: Epoch 020 - training loss: 0.3703, validation loss: 0.4545
2024-06-02 19:51:26 [INFO]: Epoch 021 - training loss: 0.3678, validation loss: 0.4512
2024-06-02 19:51:28 [INFO]: Epoch 022 - training loss: 0.3627, validation loss: 0.4629
2024-06-02 19:51:31 [INFO]: Epoch 023 - training loss: 0.3645, validation loss: 0.4600
2024-06-02 19:51:33 [INFO]: Epoch 024 - training loss: 0.3573, validation loss: 0.4467
2024-06-02 19:51:36 [INFO]: Epoch 025 - training loss: 0.3534, validation loss: 0.4458
2024-06-02 19:51:38 [INFO]: Epoch 026 - training loss: 0.3510, validation loss: 0.4429
2024-06-02 19:51:41 [INFO]: Epoch 027 - training loss: 0.3476, validation loss: 0.4409
2024-06-02 19:51:43 [INFO]: Epoch 028 - training loss: 0.3466, validation loss: 0.4503
2024-06-02 19:51:46 [INFO]: Epoch 029 - training loss: 0.3442, validation loss: 0.4391
2024-06-02 19:51:48 [INFO]: Epoch 030 - training loss: 0.3469, validation loss: 0.4478
2024-06-02 19:51:51 [INFO]: Epoch 031 - training loss: 0.3374, validation loss: 0.4362
2024-06-02 19:51:53 [INFO]: Epoch 032 - training loss: 0.3353, validation loss: 0.4370
2024-06-02 19:51:55 [INFO]: Epoch 033 - training loss: 0.3374, validation loss: 0.4317
2024-06-02 19:51:57 [INFO]: Epoch 034 - training loss: 0.3392, validation loss: 0.4322
2024-06-02 19:51:59 [INFO]: Epoch 035 - training loss: 0.3324, validation loss: 0.4386
2024-06-02 19:52:01 [INFO]: Epoch 036 - training loss: 0.3298, validation loss: 0.4304
2024-06-02 19:52:04 [INFO]: Epoch 037 - training loss: 0.3304, validation loss: 0.4331
2024-06-02 19:52:06 [INFO]: Epoch 038 - training loss: 0.3265, validation loss: 0.4278
2024-06-02 19:52:08 [INFO]: Epoch 039 - training loss: 0.3249, validation loss: 0.4209
2024-06-02 19:52:10 [INFO]: Epoch 040 - training loss: 0.3282, validation loss: 0.4315
2024-06-02 19:52:12 [INFO]: Epoch 041 - training loss: 0.3281, validation loss: 0.4304
2024-06-02 19:52:14 [INFO]: Epoch 042 - training loss: 0.3287, validation loss: 0.4262
2024-06-02 19:52:17 [INFO]: Epoch 043 - training loss: 0.3222, validation loss: 0.4381
2024-06-02 19:52:19 [INFO]: Epoch 044 - training loss: 0.3223, validation loss: 0.4234
2024-06-02 19:52:21 [INFO]: Epoch 045 - training loss: 0.3199, validation loss: 0.4328
2024-06-02 19:52:23 [INFO]: Epoch 046 - training loss: 0.3182, validation loss: 0.4219
2024-06-02 19:52:26 [INFO]: Epoch 047 - training loss: 0.3163, validation loss: 0.4217
2024-06-02 19:52:28 [INFO]: Epoch 048 - training loss: 0.3206, validation loss: 0.4374
2024-06-02 19:52:30 [INFO]: Epoch 049 - training loss: 0.3241, validation loss: 0.4226
2024-06-02 19:52:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:52:30 [INFO]: Finished training. The best model is from epoch#39.
2024-06-02 19:52:30 [INFO]: Saved the model to results_point_rate05/PeMS/DLinear_PeMS/round_4/20240602_T195033/DLinear.pypots
2024-06-02 19:52:31 [INFO]: Successfully saved to results_point_rate05/PeMS/DLinear_PeMS/round_4/imputation.pkl
2024-06-02 19:52:31 [INFO]: Round4 - DLinear on PeMS: MAE=0.3845, MSE=0.6027, MRE=0.4772
2024-06-02 19:52:31 [INFO]: Done! Final results:
Averaged DLinear (5,301,100 params) on PeMS: MAE=0.3889 ± 0.013339688467765192, MSE=0.6035 ± 0.019857217766550365, MRE=0.4826 ± 0.016553421842240713, average inference time=0.13
