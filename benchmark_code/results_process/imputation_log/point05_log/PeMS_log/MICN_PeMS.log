2024-06-03 02:07:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:07:41 [INFO]: Using the given device: cuda:0
2024-06-03 02:07:41 [INFO]: Model files will be saved to results_point_rate05/PeMS/MICN_PeMS/round_0/20240603_T020741
2024-06-03 02:07:41 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MICN_PeMS/round_0/20240603_T020741/tensorboard
2024-06-03 02:07:42 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 02:07:52 [INFO]: Epoch 001 - training loss: 0.9011, validation loss: 0.5349
2024-06-03 02:07:54 [INFO]: Epoch 002 - training loss: 0.6087, validation loss: 0.5016
2024-06-03 02:07:56 [INFO]: Epoch 003 - training loss: 0.5693, validation loss: 0.4875
2024-06-03 02:07:59 [INFO]: Epoch 004 - training loss: 0.5394, validation loss: 0.4816
2024-06-03 02:08:01 [INFO]: Epoch 005 - training loss: 0.5222, validation loss: 0.4802
2024-06-03 02:08:03 [INFO]: Epoch 006 - training loss: 0.5095, validation loss: 0.4710
2024-06-03 02:08:05 [INFO]: Epoch 007 - training loss: 0.5023, validation loss: 0.4682
2024-06-03 02:08:07 [INFO]: Epoch 008 - training loss: 0.5003, validation loss: 0.4371
2024-06-03 02:08:10 [INFO]: Epoch 009 - training loss: 0.4979, validation loss: 0.4344
2024-06-03 02:08:13 [INFO]: Epoch 010 - training loss: 0.4936, validation loss: 0.4373
2024-06-03 02:08:16 [INFO]: Epoch 011 - training loss: 0.4892, validation loss: 0.4262
2024-06-03 02:08:19 [INFO]: Epoch 012 - training loss: 0.4878, validation loss: 0.4187
2024-06-03 02:08:22 [INFO]: Epoch 013 - training loss: 0.4892, validation loss: 0.4322
2024-06-03 02:08:25 [INFO]: Epoch 014 - training loss: 0.4863, validation loss: 0.4225
2024-06-03 02:08:28 [INFO]: Epoch 015 - training loss: 0.4784, validation loss: 0.4213
2024-06-03 02:08:31 [INFO]: Epoch 016 - training loss: 0.4781, validation loss: 0.4126
2024-06-03 02:08:34 [INFO]: Epoch 017 - training loss: 0.4799, validation loss: 0.4238
2024-06-03 02:08:37 [INFO]: Epoch 018 - training loss: 0.4812, validation loss: 0.4128
2024-06-03 02:08:40 [INFO]: Epoch 019 - training loss: 0.4774, validation loss: 0.4132
2024-06-03 02:08:43 [INFO]: Epoch 020 - training loss: 0.4728, validation loss: 0.4229
2024-06-03 02:08:46 [INFO]: Epoch 021 - training loss: 0.4754, validation loss: 0.4151
2024-06-03 02:08:50 [INFO]: Epoch 022 - training loss: 0.4706, validation loss: 0.4087
2024-06-03 02:08:52 [INFO]: Epoch 023 - training loss: 0.4682, validation loss: 0.4090
2024-06-03 02:08:56 [INFO]: Epoch 024 - training loss: 0.4706, validation loss: 0.4129
2024-06-03 02:08:58 [INFO]: Epoch 025 - training loss: 0.4698, validation loss: 0.4109
2024-06-03 02:09:01 [INFO]: Epoch 026 - training loss: 0.4671, validation loss: 0.4100
2024-06-03 02:09:04 [INFO]: Epoch 027 - training loss: 0.4675, validation loss: 0.4067
2024-06-03 02:09:07 [INFO]: Epoch 028 - training loss: 0.4651, validation loss: 0.4128
2024-06-03 02:09:10 [INFO]: Epoch 029 - training loss: 0.4632, validation loss: 0.4087
2024-06-03 02:09:13 [INFO]: Epoch 030 - training loss: 0.4624, validation loss: 0.4082
2024-06-03 02:09:16 [INFO]: Epoch 031 - training loss: 0.4591, validation loss: 0.4117
2024-06-03 02:09:19 [INFO]: Epoch 032 - training loss: 0.4613, validation loss: 0.4040
2024-06-03 02:09:22 [INFO]: Epoch 033 - training loss: 0.4581, validation loss: 0.4107
2024-06-03 02:09:25 [INFO]: Epoch 034 - training loss: 0.4590, validation loss: 0.4073
2024-06-03 02:09:28 [INFO]: Epoch 035 - training loss: 0.4539, validation loss: 0.4048
2024-06-03 02:09:31 [INFO]: Epoch 036 - training loss: 0.4573, validation loss: 0.4126
2024-06-03 02:09:33 [INFO]: Epoch 037 - training loss: 0.4527, validation loss: 0.4079
2024-06-03 02:09:36 [INFO]: Epoch 038 - training loss: 0.4519, validation loss: 0.4068
2024-06-03 02:09:40 [INFO]: Epoch 039 - training loss: 0.4521, validation loss: 0.4077
2024-06-03 02:09:43 [INFO]: Epoch 040 - training loss: 0.4513, validation loss: 0.4086
2024-06-03 02:09:46 [INFO]: Epoch 041 - training loss: 0.4515, validation loss: 0.4066
2024-06-03 02:09:49 [INFO]: Epoch 042 - training loss: 0.4498, validation loss: 0.4101
2024-06-03 02:09:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:09:49 [INFO]: Finished training. The best model is from epoch#32.
2024-06-03 02:09:49 [INFO]: Saved the model to results_point_rate05/PeMS/MICN_PeMS/round_0/20240603_T020741/MICN.pypots
2024-06-03 02:09:50 [INFO]: Successfully saved to results_point_rate05/PeMS/MICN_PeMS/round_0/imputation.pkl
2024-06-03 02:09:50 [INFO]: Round0 - MICN on PeMS: MAE=0.3922, MSE=0.6028, MRE=0.4867
2024-06-03 02:09:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:09:50 [INFO]: Using the given device: cuda:0
2024-06-03 02:09:50 [INFO]: Model files will be saved to results_point_rate05/PeMS/MICN_PeMS/round_1/20240603_T020950
2024-06-03 02:09:50 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MICN_PeMS/round_1/20240603_T020950/tensorboard
2024-06-03 02:09:51 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 02:09:54 [INFO]: Epoch 001 - training loss: 0.8975, validation loss: 0.5302
2024-06-03 02:09:57 [INFO]: Epoch 002 - training loss: 0.6148, validation loss: 0.5086
2024-06-03 02:10:00 [INFO]: Epoch 003 - training loss: 0.5659, validation loss: 0.5096
2024-06-03 02:10:03 [INFO]: Epoch 004 - training loss: 0.5315, validation loss: 0.4879
2024-06-03 02:10:06 [INFO]: Epoch 005 - training loss: 0.5206, validation loss: 0.4705
2024-06-03 02:10:09 [INFO]: Epoch 006 - training loss: 0.5085, validation loss: 0.4792
2024-06-03 02:10:12 [INFO]: Epoch 007 - training loss: 0.5014, validation loss: 0.4687
2024-06-03 02:10:15 [INFO]: Epoch 008 - training loss: 0.4991, validation loss: 0.4477
2024-06-03 02:10:18 [INFO]: Epoch 009 - training loss: 0.4970, validation loss: 0.4548
2024-06-03 02:10:21 [INFO]: Epoch 010 - training loss: 0.4914, validation loss: 0.4537
2024-06-03 02:10:24 [INFO]: Epoch 011 - training loss: 0.4891, validation loss: 0.4321
2024-06-03 02:10:27 [INFO]: Epoch 012 - training loss: 0.4837, validation loss: 0.4260
2024-06-03 02:10:30 [INFO]: Epoch 013 - training loss: 0.4847, validation loss: 0.4308
2024-06-03 02:10:33 [INFO]: Epoch 014 - training loss: 0.4843, validation loss: 0.4340
2024-06-03 02:10:36 [INFO]: Epoch 015 - training loss: 0.4820, validation loss: 0.4269
2024-06-03 02:10:40 [INFO]: Epoch 016 - training loss: 0.4788, validation loss: 0.4198
2024-06-03 02:10:43 [INFO]: Epoch 017 - training loss: 0.4763, validation loss: 0.4263
2024-06-03 02:10:46 [INFO]: Epoch 018 - training loss: 0.4744, validation loss: 0.4311
2024-06-03 02:10:49 [INFO]: Epoch 019 - training loss: 0.4764, validation loss: 0.4204
2024-06-03 02:10:52 [INFO]: Epoch 020 - training loss: 0.4720, validation loss: 0.4207
2024-06-03 02:10:55 [INFO]: Epoch 021 - training loss: 0.4662, validation loss: 0.4219
2024-06-03 02:10:58 [INFO]: Epoch 022 - training loss: 0.4726, validation loss: 0.4191
2024-06-03 02:11:01 [INFO]: Epoch 023 - training loss: 0.4668, validation loss: 0.4269
2024-06-03 02:11:04 [INFO]: Epoch 024 - training loss: 0.4661, validation loss: 0.4199
2024-06-03 02:11:07 [INFO]: Epoch 025 - training loss: 0.4654, validation loss: 0.4194
2024-06-03 02:11:10 [INFO]: Epoch 026 - training loss: 0.4679, validation loss: 0.4214
2024-06-03 02:11:12 [INFO]: Epoch 027 - training loss: 0.4635, validation loss: 0.4208
2024-06-03 02:11:15 [INFO]: Epoch 028 - training loss: 0.4634, validation loss: 0.4193
2024-06-03 02:11:18 [INFO]: Epoch 029 - training loss: 0.4597, validation loss: 0.4309
2024-06-03 02:11:21 [INFO]: Epoch 030 - training loss: 0.4597, validation loss: 0.4221
2024-06-03 02:11:24 [INFO]: Epoch 031 - training loss: 0.4614, validation loss: 0.4117
2024-06-03 02:11:27 [INFO]: Epoch 032 - training loss: 0.4574, validation loss: 0.4220
2024-06-03 02:11:29 [INFO]: Epoch 033 - training loss: 0.4570, validation loss: 0.4289
2024-06-03 02:11:32 [INFO]: Epoch 034 - training loss: 0.4542, validation loss: 0.4204
2024-06-03 02:11:35 [INFO]: Epoch 035 - training loss: 0.4534, validation loss: 0.4300
2024-06-03 02:11:37 [INFO]: Epoch 036 - training loss: 0.4527, validation loss: 0.4232
2024-06-03 02:11:40 [INFO]: Epoch 037 - training loss: 0.4496, validation loss: 0.4222
2024-06-03 02:11:43 [INFO]: Epoch 038 - training loss: 0.4509, validation loss: 0.4206
2024-06-03 02:11:46 [INFO]: Epoch 039 - training loss: 0.4498, validation loss: 0.4205
2024-06-03 02:11:49 [INFO]: Epoch 040 - training loss: 0.4514, validation loss: 0.4184
2024-06-03 02:11:52 [INFO]: Epoch 041 - training loss: 0.4503, validation loss: 0.4243
2024-06-03 02:11:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:11:52 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 02:11:52 [INFO]: Saved the model to results_point_rate05/PeMS/MICN_PeMS/round_1/20240603_T020950/MICN.pypots
2024-06-03 02:11:53 [INFO]: Successfully saved to results_point_rate05/PeMS/MICN_PeMS/round_1/imputation.pkl
2024-06-03 02:11:53 [INFO]: Round1 - MICN on PeMS: MAE=0.3961, MSE=0.6215, MRE=0.4915
2024-06-03 02:11:53 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 02:11:53 [INFO]: Using the given device: cuda:0
2024-06-03 02:11:53 [INFO]: Model files will be saved to results_point_rate05/PeMS/MICN_PeMS/round_2/20240603_T021153
2024-06-03 02:11:53 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MICN_PeMS/round_2/20240603_T021153/tensorboard
2024-06-03 02:11:54 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 02:11:57 [INFO]: Epoch 001 - training loss: 0.9106, validation loss: 0.5392
2024-06-03 02:12:00 [INFO]: Epoch 002 - training loss: 0.6168, validation loss: 0.5062
2024-06-03 02:12:03 [INFO]: Epoch 003 - training loss: 0.5700, validation loss: 0.4799
2024-06-03 02:12:06 [INFO]: Epoch 004 - training loss: 0.5361, validation loss: 0.4779
2024-06-03 02:12:09 [INFO]: Epoch 005 - training loss: 0.5187, validation loss: 0.4724
2024-06-03 02:12:12 [INFO]: Epoch 006 - training loss: 0.5152, validation loss: 0.4628
2024-06-03 02:12:15 [INFO]: Epoch 007 - training loss: 0.5048, validation loss: 0.4483
2024-06-03 02:12:18 [INFO]: Epoch 008 - training loss: 0.5013, validation loss: 0.4488
2024-06-03 02:12:21 [INFO]: Epoch 009 - training loss: 0.4978, validation loss: 0.4387
2024-06-03 02:12:24 [INFO]: Epoch 010 - training loss: 0.4906, validation loss: 0.4320
2024-06-03 02:12:27 [INFO]: Epoch 011 - training loss: 0.4870, validation loss: 0.4308
2024-06-03 02:12:30 [INFO]: Epoch 012 - training loss: 0.4870, validation loss: 0.4257
2024-06-03 02:12:33 [INFO]: Epoch 013 - training loss: 0.4838, validation loss: 0.4299
2024-06-03 02:12:35 [INFO]: Epoch 014 - training loss: 0.4805, validation loss: 0.4283
2024-06-03 02:12:38 [INFO]: Epoch 015 - training loss: 0.4822, validation loss: 0.4215
2024-06-03 02:12:41 [INFO]: Epoch 016 - training loss: 0.4766, validation loss: 0.4122
2024-06-03 02:12:44 [INFO]: Epoch 017 - training loss: 0.4787, validation loss: 0.4226
2024-06-03 02:12:47 [INFO]: Epoch 018 - training loss: 0.4713, validation loss: 0.4161
2024-06-03 02:12:50 [INFO]: Epoch 019 - training loss: 0.4716, validation loss: 0.4257
2024-06-03 02:12:53 [INFO]: Epoch 020 - training loss: 0.4753, validation loss: 0.4121
2024-06-03 02:12:56 [INFO]: Epoch 021 - training loss: 0.4726, validation loss: 0.4150
2024-06-03 02:12:59 [INFO]: Epoch 022 - training loss: 0.4675, validation loss: 0.4138
2024-06-03 02:13:02 [INFO]: Epoch 023 - training loss: 0.4662, validation loss: 0.4175
2024-06-03 02:13:05 [INFO]: Epoch 024 - training loss: 0.4657, validation loss: 0.4168
2024-06-03 02:13:08 [INFO]: Epoch 025 - training loss: 0.4669, validation loss: 0.4109
2024-06-03 02:13:11 [INFO]: Epoch 026 - training loss: 0.4627, validation loss: 0.4123
2024-06-03 02:13:14 [INFO]: Epoch 027 - training loss: 0.4607, validation loss: 0.4113
2024-06-03 02:13:17 [INFO]: Epoch 028 - training loss: 0.4606, validation loss: 0.4074
2024-06-03 02:13:20 [INFO]: Epoch 029 - training loss: 0.4590, validation loss: 0.4118
2024-06-03 02:13:23 [INFO]: Epoch 030 - training loss: 0.4590, validation loss: 0.4102
2024-06-03 02:13:25 [INFO]: Epoch 031 - training loss: 0.4565, validation loss: 0.4081
2024-06-03 02:13:28 [INFO]: Epoch 032 - training loss: 0.4568, validation loss: 0.4074
2024-06-03 02:13:32 [INFO]: Epoch 033 - training loss: 0.4556, validation loss: 0.4124
2024-06-03 02:13:34 [INFO]: Epoch 034 - training loss: 0.4534, validation loss: 0.4078
2024-06-03 02:13:37 [INFO]: Epoch 035 - training loss: 0.4552, validation loss: 0.4050
2024-06-03 02:13:40 [INFO]: Epoch 036 - training loss: 0.4531, validation loss: 0.4135
2024-06-03 02:13:43 [INFO]: Epoch 037 - training loss: 0.4537, validation loss: 0.4116
2024-06-03 02:13:46 [INFO]: Epoch 038 - training loss: 0.4491, validation loss: 0.4084
2024-06-03 02:13:49 [INFO]: Epoch 039 - training loss: 0.4457, validation loss: 0.4084
2024-06-03 02:13:52 [INFO]: Epoch 040 - training loss: 0.4471, validation loss: 0.4069
2024-06-03 02:13:55 [INFO]: Epoch 041 - training loss: 0.4485, validation loss: 0.4060
2024-06-03 02:13:58 [INFO]: Epoch 042 - training loss: 0.4447, validation loss: 0.4059
2024-06-03 02:14:01 [INFO]: Epoch 043 - training loss: 0.4410, validation loss: 0.4092
2024-06-03 02:14:04 [INFO]: Epoch 044 - training loss: 0.4437, validation loss: 0.4082
2024-06-03 02:14:07 [INFO]: Epoch 045 - training loss: 0.4416, validation loss: 0.4058
2024-06-03 02:14:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:14:07 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 02:14:07 [INFO]: Saved the model to results_point_rate05/PeMS/MICN_PeMS/round_2/20240603_T021153/MICN.pypots
2024-06-03 02:14:08 [INFO]: Successfully saved to results_point_rate05/PeMS/MICN_PeMS/round_2/imputation.pkl
2024-06-03 02:14:08 [INFO]: Round2 - MICN on PeMS: MAE=0.3861, MSE=0.5977, MRE=0.4792
2024-06-03 02:14:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 02:14:08 [INFO]: Using the given device: cuda:0
2024-06-03 02:14:08 [INFO]: Model files will be saved to results_point_rate05/PeMS/MICN_PeMS/round_3/20240603_T021408
2024-06-03 02:14:08 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MICN_PeMS/round_3/20240603_T021408/tensorboard
2024-06-03 02:14:09 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 02:14:12 [INFO]: Epoch 001 - training loss: 0.8970, validation loss: 0.5740
2024-06-03 02:14:15 [INFO]: Epoch 002 - training loss: 0.6084, validation loss: 0.5065
2024-06-03 02:14:18 [INFO]: Epoch 003 - training loss: 0.5633, validation loss: 0.5001
2024-06-03 02:14:21 [INFO]: Epoch 004 - training loss: 0.5412, validation loss: 0.4984
2024-06-03 02:14:24 [INFO]: Epoch 005 - training loss: 0.5246, validation loss: 0.5105
2024-06-03 02:14:27 [INFO]: Epoch 006 - training loss: 0.5148, validation loss: 0.5004
2024-06-03 02:14:30 [INFO]: Epoch 007 - training loss: 0.5056, validation loss: 0.4892
2024-06-03 02:14:34 [INFO]: Epoch 008 - training loss: 0.5011, validation loss: 0.4712
2024-06-03 02:14:37 [INFO]: Epoch 009 - training loss: 0.4954, validation loss: 0.4619
2024-06-03 02:14:40 [INFO]: Epoch 010 - training loss: 0.4946, validation loss: 0.4672
2024-06-03 02:14:43 [INFO]: Epoch 011 - training loss: 0.4918, validation loss: 0.4525
2024-06-03 02:14:45 [INFO]: Epoch 012 - training loss: 0.4889, validation loss: 0.4530
2024-06-03 02:14:48 [INFO]: Epoch 013 - training loss: 0.4875, validation loss: 0.4631
2024-06-03 02:14:51 [INFO]: Epoch 014 - training loss: 0.4866, validation loss: 0.4496
2024-06-03 02:14:54 [INFO]: Epoch 015 - training loss: 0.4813, validation loss: 0.4527
2024-06-03 02:14:57 [INFO]: Epoch 016 - training loss: 0.4801, validation loss: 0.4424
2024-06-03 02:15:00 [INFO]: Epoch 017 - training loss: 0.4805, validation loss: 0.4562
2024-06-03 02:15:03 [INFO]: Epoch 018 - training loss: 0.4804, validation loss: 0.4393
2024-06-03 02:15:06 [INFO]: Epoch 019 - training loss: 0.4731, validation loss: 0.4533
2024-06-03 02:15:10 [INFO]: Epoch 020 - training loss: 0.4758, validation loss: 0.4354
2024-06-03 02:15:12 [INFO]: Epoch 021 - training loss: 0.4748, validation loss: 0.4348
2024-06-03 02:15:15 [INFO]: Epoch 022 - training loss: 0.4708, validation loss: 0.4476
2024-06-03 02:15:18 [INFO]: Epoch 023 - training loss: 0.4721, validation loss: 0.4357
2024-06-03 02:15:21 [INFO]: Epoch 024 - training loss: 0.4692, validation loss: 0.4349
2024-06-03 02:15:23 [INFO]: Epoch 025 - training loss: 0.4655, validation loss: 0.4261
2024-06-03 02:15:26 [INFO]: Epoch 026 - training loss: 0.4656, validation loss: 0.4257
2024-06-03 02:15:29 [INFO]: Epoch 027 - training loss: 0.4667, validation loss: 0.4298
2024-06-03 02:15:32 [INFO]: Epoch 028 - training loss: 0.4636, validation loss: 0.4400
2024-06-03 02:15:35 [INFO]: Epoch 029 - training loss: 0.4654, validation loss: 0.4324
2024-06-03 02:15:38 [INFO]: Epoch 030 - training loss: 0.4631, validation loss: 0.4324
2024-06-03 02:15:42 [INFO]: Epoch 031 - training loss: 0.4625, validation loss: 0.4213
2024-06-03 02:15:45 [INFO]: Epoch 032 - training loss: 0.4620, validation loss: 0.4244
2024-06-03 02:15:48 [INFO]: Epoch 033 - training loss: 0.4575, validation loss: 0.4259
2024-06-03 02:15:51 [INFO]: Epoch 034 - training loss: 0.4570, validation loss: 0.4284
2024-06-03 02:15:54 [INFO]: Epoch 035 - training loss: 0.4588, validation loss: 0.4268
2024-06-03 02:15:57 [INFO]: Epoch 036 - training loss: 0.4550, validation loss: 0.4299
2024-06-03 02:15:59 [INFO]: Epoch 037 - training loss: 0.4588, validation loss: 0.4241
2024-06-03 02:16:02 [INFO]: Epoch 038 - training loss: 0.4570, validation loss: 0.4259
2024-06-03 02:16:05 [INFO]: Epoch 039 - training loss: 0.4567, validation loss: 0.4240
2024-06-03 02:16:08 [INFO]: Epoch 040 - training loss: 0.4544, validation loss: 0.4266
2024-06-03 02:16:11 [INFO]: Epoch 041 - training loss: 0.4506, validation loss: 0.4311
2024-06-03 02:16:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:16:11 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 02:16:11 [INFO]: Saved the model to results_point_rate05/PeMS/MICN_PeMS/round_3/20240603_T021408/MICN.pypots
2024-06-03 02:16:12 [INFO]: Successfully saved to results_point_rate05/PeMS/MICN_PeMS/round_3/imputation.pkl
2024-06-03 02:16:12 [INFO]: Round3 - MICN on PeMS: MAE=0.3999, MSE=0.6187, MRE=0.4962
2024-06-03 02:16:12 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:16:12 [INFO]: Using the given device: cuda:0
2024-06-03 02:16:13 [INFO]: Model files will be saved to results_point_rate05/PeMS/MICN_PeMS/round_4/20240603_T021612
2024-06-03 02:16:13 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MICN_PeMS/round_4/20240603_T021612/tensorboard
2024-06-03 02:16:13 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 02:16:16 [INFO]: Epoch 001 - training loss: 0.8942, validation loss: 0.5250
2024-06-03 02:16:19 [INFO]: Epoch 002 - training loss: 0.6102, validation loss: 0.5021
2024-06-03 02:16:22 [INFO]: Epoch 003 - training loss: 0.5597, validation loss: 0.4818
2024-06-03 02:16:25 [INFO]: Epoch 004 - training loss: 0.5362, validation loss: 0.4677
2024-06-03 02:16:28 [INFO]: Epoch 005 - training loss: 0.5239, validation loss: 0.4789
2024-06-03 02:16:31 [INFO]: Epoch 006 - training loss: 0.5091, validation loss: 0.4762
2024-06-03 02:16:34 [INFO]: Epoch 007 - training loss: 0.5027, validation loss: 0.4606
2024-06-03 02:16:37 [INFO]: Epoch 008 - training loss: 0.4979, validation loss: 0.4517
2024-06-03 02:16:40 [INFO]: Epoch 009 - training loss: 0.4926, validation loss: 0.4445
2024-06-03 02:16:43 [INFO]: Epoch 010 - training loss: 0.4936, validation loss: 0.4424
2024-06-03 02:16:46 [INFO]: Epoch 011 - training loss: 0.4901, validation loss: 0.4399
2024-06-03 02:16:49 [INFO]: Epoch 012 - training loss: 0.4832, validation loss: 0.4302
2024-06-03 02:16:52 [INFO]: Epoch 013 - training loss: 0.4839, validation loss: 0.4321
2024-06-03 02:16:55 [INFO]: Epoch 014 - training loss: 0.4819, validation loss: 0.4330
2024-06-03 02:16:58 [INFO]: Epoch 015 - training loss: 0.4772, validation loss: 0.4235
2024-06-03 02:17:01 [INFO]: Epoch 016 - training loss: 0.4749, validation loss: 0.4280
2024-06-03 02:17:04 [INFO]: Epoch 017 - training loss: 0.4711, validation loss: 0.4281
2024-06-03 02:17:06 [INFO]: Epoch 018 - training loss: 0.4728, validation loss: 0.4203
2024-06-03 02:17:09 [INFO]: Epoch 019 - training loss: 0.4757, validation loss: 0.4225
2024-06-03 02:17:12 [INFO]: Epoch 020 - training loss: 0.4701, validation loss: 0.4157
2024-06-03 02:17:15 [INFO]: Epoch 021 - training loss: 0.4720, validation loss: 0.4184
2024-06-03 02:17:18 [INFO]: Epoch 022 - training loss: 0.4701, validation loss: 0.4155
2024-06-03 02:17:21 [INFO]: Epoch 023 - training loss: 0.4667, validation loss: 0.4157
2024-06-03 02:17:24 [INFO]: Epoch 024 - training loss: 0.4663, validation loss: 0.4157
2024-06-03 02:17:27 [INFO]: Epoch 025 - training loss: 0.4629, validation loss: 0.4089
2024-06-03 02:17:30 [INFO]: Epoch 026 - training loss: 0.4606, validation loss: 0.4159
2024-06-03 02:17:33 [INFO]: Epoch 027 - training loss: 0.4615, validation loss: 0.4110
2024-06-03 02:17:36 [INFO]: Epoch 028 - training loss: 0.4615, validation loss: 0.4116
2024-06-03 02:17:39 [INFO]: Epoch 029 - training loss: 0.4621, validation loss: 0.4066
2024-06-03 02:17:42 [INFO]: Epoch 030 - training loss: 0.4597, validation loss: 0.4068
2024-06-03 02:17:45 [INFO]: Epoch 031 - training loss: 0.4608, validation loss: 0.4100
2024-06-03 02:17:48 [INFO]: Epoch 032 - training loss: 0.4528, validation loss: 0.4091
2024-06-03 02:17:51 [INFO]: Epoch 033 - training loss: 0.4533, validation loss: 0.4100
2024-06-03 02:17:54 [INFO]: Epoch 034 - training loss: 0.4545, validation loss: 0.4116
2024-06-03 02:17:57 [INFO]: Epoch 035 - training loss: 0.4524, validation loss: 0.4075
2024-06-03 02:18:00 [INFO]: Epoch 036 - training loss: 0.4475, validation loss: 0.4072
2024-06-03 02:18:03 [INFO]: Epoch 037 - training loss: 0.4518, validation loss: 0.4141
2024-06-03 02:18:06 [INFO]: Epoch 038 - training loss: 0.4511, validation loss: 0.4122
2024-06-03 02:18:08 [INFO]: Epoch 039 - training loss: 0.4509, validation loss: 0.4116
2024-06-03 02:18:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:18:08 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 02:18:09 [INFO]: Saved the model to results_point_rate05/PeMS/MICN_PeMS/round_4/20240603_T021612/MICN.pypots
2024-06-03 02:18:10 [INFO]: Successfully saved to results_point_rate05/PeMS/MICN_PeMS/round_4/imputation.pkl
2024-06-03 02:18:10 [INFO]: Round4 - MICN on PeMS: MAE=0.3839, MSE=0.5972, MRE=0.4763
2024-06-03 02:18:10 [INFO]: Done! Final results:
Averaged MICN (15,490,402 params) on PeMS: MAE=0.3916 ± 0.005981289759201838, MSE=0.6076 ± 0.010442625737184588, MRE=0.4860 ± 0.007422273225045546, average inference time=0.17
