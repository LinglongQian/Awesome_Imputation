2024-06-03 02:07:41 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:07:41 [INFO]: Using the given device: cuda:0
2024-06-03 02:07:41 [INFO]: Model files will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T020741
2024-06-03 02:07:41 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T020741/tensorboard
2024-06-03 02:07:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 02:07:56 [INFO]: Epoch 001 - training loss: 0.4692, validation loss: 0.5044
2024-06-03 02:07:58 [INFO]: Epoch 002 - training loss: 0.2612, validation loss: 0.4849
2024-06-03 02:08:01 [INFO]: Epoch 003 - training loss: 0.2398, validation loss: 0.4774
2024-06-03 02:08:04 [INFO]: Epoch 004 - training loss: 0.2328, validation loss: 0.4721
2024-06-03 02:08:07 [INFO]: Epoch 005 - training loss: 0.2340, validation loss: 0.4731
2024-06-03 02:08:10 [INFO]: Epoch 006 - training loss: 0.2219, validation loss: 0.4681
2024-06-03 02:08:14 [INFO]: Epoch 007 - training loss: 0.2181, validation loss: 0.4743
2024-06-03 02:08:18 [INFO]: Epoch 008 - training loss: 0.2157, validation loss: 0.4631
2024-06-03 02:08:21 [INFO]: Epoch 009 - training loss: 0.2083, validation loss: 0.4674
2024-06-03 02:08:25 [INFO]: Epoch 010 - training loss: 0.2095, validation loss: 0.4580
2024-06-03 02:08:29 [INFO]: Epoch 011 - training loss: 0.2007, validation loss: 0.4495
2024-06-03 02:08:32 [INFO]: Epoch 012 - training loss: 0.1977, validation loss: 0.4443
2024-06-03 02:08:36 [INFO]: Epoch 013 - training loss: 0.1890, validation loss: 0.4431
2024-06-03 02:08:39 [INFO]: Epoch 014 - training loss: 0.1886, validation loss: 0.4409
2024-06-03 02:08:43 [INFO]: Epoch 015 - training loss: 0.1803, validation loss: 0.4309
2024-06-03 02:08:46 [INFO]: Epoch 016 - training loss: 0.1741, validation loss: 0.4373
2024-06-03 02:08:50 [INFO]: Epoch 017 - training loss: 0.1735, validation loss: 0.4509
2024-06-03 02:08:53 [INFO]: Epoch 018 - training loss: 0.1707, validation loss: 0.4354
2024-06-03 02:08:57 [INFO]: Epoch 019 - training loss: 0.1608, validation loss: 0.4285
2024-06-03 02:09:00 [INFO]: Epoch 020 - training loss: 0.1568, validation loss: 0.4210
2024-06-03 02:09:04 [INFO]: Epoch 021 - training loss: 0.1534, validation loss: 0.4211
2024-06-03 02:09:08 [INFO]: Epoch 022 - training loss: 0.1490, validation loss: 0.4225
2024-06-03 02:09:11 [INFO]: Epoch 023 - training loss: 0.1467, validation loss: 0.4189
2024-06-03 02:09:15 [INFO]: Epoch 024 - training loss: 0.1459, validation loss: 0.4158
2024-06-03 02:09:18 [INFO]: Epoch 025 - training loss: 0.1411, validation loss: 0.4151
2024-06-03 02:09:22 [INFO]: Epoch 026 - training loss: 0.1366, validation loss: 0.4191
2024-06-03 02:09:26 [INFO]: Epoch 027 - training loss: 0.1357, validation loss: 0.4127
2024-06-03 02:09:29 [INFO]: Epoch 028 - training loss: 0.1336, validation loss: 0.4117
2024-06-03 02:09:33 [INFO]: Epoch 029 - training loss: 0.1306, validation loss: 0.4287
2024-06-03 02:09:36 [INFO]: Epoch 030 - training loss: 0.1272, validation loss: 0.4149
2024-06-03 02:09:40 [INFO]: Epoch 031 - training loss: 0.1255, validation loss: 0.4084
2024-06-03 02:09:44 [INFO]: Epoch 032 - training loss: 0.1220, validation loss: 0.4092
2024-06-03 02:09:47 [INFO]: Epoch 033 - training loss: 0.1198, validation loss: 0.4118
2024-06-03 02:09:51 [INFO]: Epoch 034 - training loss: 0.1166, validation loss: 0.4139
2024-06-03 02:09:55 [INFO]: Epoch 035 - training loss: 0.1146, validation loss: 0.4107
2024-06-03 02:09:58 [INFO]: Epoch 036 - training loss: 0.1138, validation loss: 0.4101
2024-06-03 02:10:02 [INFO]: Epoch 037 - training loss: 0.1091, validation loss: 0.4072
2024-06-03 02:10:06 [INFO]: Epoch 038 - training loss: 0.1084, validation loss: 0.4111
2024-06-03 02:10:09 [INFO]: Epoch 039 - training loss: 0.1084, validation loss: 0.4078
2024-06-03 02:10:13 [INFO]: Epoch 040 - training loss: 0.1066, validation loss: 0.4086
2024-06-03 02:10:17 [INFO]: Epoch 041 - training loss: 0.1045, validation loss: 0.3984
2024-06-03 02:10:20 [INFO]: Epoch 042 - training loss: 0.1044, validation loss: 0.4102
2024-06-03 02:10:24 [INFO]: Epoch 043 - training loss: 0.1040, validation loss: 0.4002
2024-06-03 02:10:27 [INFO]: Epoch 044 - training loss: 0.1012, validation loss: 0.3996
2024-06-03 02:10:31 [INFO]: Epoch 045 - training loss: 0.0994, validation loss: 0.4008
2024-06-03 02:10:34 [INFO]: Epoch 046 - training loss: 0.0977, validation loss: 0.4004
2024-06-03 02:10:38 [INFO]: Epoch 047 - training loss: 0.0947, validation loss: 0.4018
2024-06-03 02:10:42 [INFO]: Epoch 048 - training loss: 0.0898, validation loss: 0.4057
2024-06-03 02:10:46 [INFO]: Epoch 049 - training loss: 0.0894, validation loss: 0.3952
2024-06-03 02:10:49 [INFO]: Epoch 050 - training loss: 0.0906, validation loss: 0.4044
2024-06-03 02:10:53 [INFO]: Epoch 051 - training loss: 0.0874, validation loss: 0.4032
2024-06-03 02:10:56 [INFO]: Epoch 052 - training loss: 0.0840, validation loss: 0.4060
2024-06-03 02:11:00 [INFO]: Epoch 053 - training loss: 0.0842, validation loss: 0.4016
2024-06-03 02:11:04 [INFO]: Epoch 054 - training loss: 0.0829, validation loss: 0.4087
2024-06-03 02:11:07 [INFO]: Epoch 055 - training loss: 0.0822, validation loss: 0.4085
2024-06-03 02:11:11 [INFO]: Epoch 056 - training loss: 0.0822, validation loss: 0.4045
2024-06-03 02:11:15 [INFO]: Epoch 057 - training loss: 0.0786, validation loss: 0.3973
2024-06-03 02:11:18 [INFO]: Epoch 058 - training loss: 0.0772, validation loss: 0.4023
2024-06-03 02:11:22 [INFO]: Epoch 059 - training loss: 0.0763, validation loss: 0.4006
2024-06-03 02:11:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:11:22 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 02:11:25 [INFO]: Saved the model to results_point_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T020741/TimesNet.pypots
2024-06-03 02:11:27 [INFO]: Successfully saved to results_point_rate05/PeMS/TimesNet_PeMS/round_0/imputation.pkl
2024-06-03 02:11:27 [INFO]: Round0 - TimesNet on PeMS: MAE=0.3457, MSE=0.5655, MRE=0.4290
2024-06-03 02:11:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:11:27 [INFO]: Using the given device: cuda:0
2024-06-03 02:11:27 [INFO]: Model files will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T021127
2024-06-03 02:11:27 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T021127/tensorboard
2024-06-03 02:11:33 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 02:11:37 [INFO]: Epoch 001 - training loss: 0.4697, validation loss: 0.5143
2024-06-03 02:11:40 [INFO]: Epoch 002 - training loss: 0.2587, validation loss: 0.4834
2024-06-03 02:11:43 [INFO]: Epoch 003 - training loss: 0.2404, validation loss: 0.4682
2024-06-03 02:11:47 [INFO]: Epoch 004 - training loss: 0.2367, validation loss: 0.4711
2024-06-03 02:11:51 [INFO]: Epoch 005 - training loss: 0.2337, validation loss: 0.4741
2024-06-03 02:11:54 [INFO]: Epoch 006 - training loss: 0.2318, validation loss: 0.4606
2024-06-03 02:11:58 [INFO]: Epoch 007 - training loss: 0.2232, validation loss: 0.4636
2024-06-03 02:12:01 [INFO]: Epoch 008 - training loss: 0.2191, validation loss: 0.4516
2024-06-03 02:12:05 [INFO]: Epoch 009 - training loss: 0.2103, validation loss: 0.4461
2024-06-03 02:12:08 [INFO]: Epoch 010 - training loss: 0.2020, validation loss: 0.4520
2024-06-03 02:12:12 [INFO]: Epoch 011 - training loss: 0.2029, validation loss: 0.4424
2024-06-03 02:12:16 [INFO]: Epoch 012 - training loss: 0.1964, validation loss: 0.4401
2024-06-03 02:12:19 [INFO]: Epoch 013 - training loss: 0.1869, validation loss: 0.4443
2024-06-03 02:12:23 [INFO]: Epoch 014 - training loss: 0.1842, validation loss: 0.4450
2024-06-03 02:12:27 [INFO]: Epoch 015 - training loss: 0.1793, validation loss: 0.4322
2024-06-03 02:12:30 [INFO]: Epoch 016 - training loss: 0.1749, validation loss: 0.4508
2024-06-03 02:12:34 [INFO]: Epoch 017 - training loss: 0.1691, validation loss: 0.4368
2024-06-03 02:12:38 [INFO]: Epoch 018 - training loss: 0.1685, validation loss: 0.4380
2024-06-03 02:12:41 [INFO]: Epoch 019 - training loss: 0.1600, validation loss: 0.4295
2024-06-03 02:12:45 [INFO]: Epoch 020 - training loss: 0.1539, validation loss: 0.4166
2024-06-03 02:12:48 [INFO]: Epoch 021 - training loss: 0.1535, validation loss: 0.4236
2024-06-03 02:12:52 [INFO]: Epoch 022 - training loss: 0.1471, validation loss: 0.4219
2024-06-03 02:12:56 [INFO]: Epoch 023 - training loss: 0.1476, validation loss: 0.4170
2024-06-03 02:12:59 [INFO]: Epoch 024 - training loss: 0.1470, validation loss: 0.4182
2024-06-03 02:13:03 [INFO]: Epoch 025 - training loss: 0.1403, validation loss: 0.4144
2024-06-03 02:13:06 [INFO]: Epoch 026 - training loss: 0.1424, validation loss: 0.4178
2024-06-03 02:13:10 [INFO]: Epoch 027 - training loss: 0.1373, validation loss: 0.4118
2024-06-03 02:13:14 [INFO]: Epoch 028 - training loss: 0.1366, validation loss: 0.4118
2024-06-03 02:13:17 [INFO]: Epoch 029 - training loss: 0.1294, validation loss: 0.4125
2024-06-03 02:13:21 [INFO]: Epoch 030 - training loss: 0.1295, validation loss: 0.4144
2024-06-03 02:13:25 [INFO]: Epoch 031 - training loss: 0.1245, validation loss: 0.4094
2024-06-03 02:13:29 [INFO]: Epoch 032 - training loss: 0.1232, validation loss: 0.4087
2024-06-03 02:13:32 [INFO]: Epoch 033 - training loss: 0.1194, validation loss: 0.4185
2024-06-03 02:13:36 [INFO]: Epoch 034 - training loss: 0.1175, validation loss: 0.4101
2024-06-03 02:13:39 [INFO]: Epoch 035 - training loss: 0.1138, validation loss: 0.4071
2024-06-03 02:13:43 [INFO]: Epoch 036 - training loss: 0.1128, validation loss: 0.4120
2024-06-03 02:13:46 [INFO]: Epoch 037 - training loss: 0.1131, validation loss: 0.4044
2024-06-03 02:13:50 [INFO]: Epoch 038 - training loss: 0.1090, validation loss: 0.4018
2024-06-03 02:13:53 [INFO]: Epoch 039 - training loss: 0.1077, validation loss: 0.4071
2024-06-03 02:13:57 [INFO]: Epoch 040 - training loss: 0.1049, validation loss: 0.4034
2024-06-03 02:14:00 [INFO]: Epoch 041 - training loss: 0.1030, validation loss: 0.4089
2024-06-03 02:14:03 [INFO]: Epoch 042 - training loss: 0.1048, validation loss: 0.4015
2024-06-03 02:14:07 [INFO]: Epoch 043 - training loss: 0.1001, validation loss: 0.3977
2024-06-03 02:14:10 [INFO]: Epoch 044 - training loss: 0.0995, validation loss: 0.4000
2024-06-03 02:14:14 [INFO]: Epoch 045 - training loss: 0.0980, validation loss: 0.3970
2024-06-03 02:14:18 [INFO]: Epoch 046 - training loss: 0.0951, validation loss: 0.3999
2024-06-03 02:14:21 [INFO]: Epoch 047 - training loss: 0.0956, validation loss: 0.3993
2024-06-03 02:14:25 [INFO]: Epoch 048 - training loss: 0.0944, validation loss: 0.3929
2024-06-03 02:14:29 [INFO]: Epoch 049 - training loss: 0.0919, validation loss: 0.3971
2024-06-03 02:14:32 [INFO]: Epoch 050 - training loss: 0.0924, validation loss: 0.4021
2024-06-03 02:14:35 [INFO]: Epoch 051 - training loss: 0.0902, validation loss: 0.4014
2024-06-03 02:14:39 [INFO]: Epoch 052 - training loss: 0.0869, validation loss: 0.3912
2024-06-03 02:14:42 [INFO]: Epoch 053 - training loss: 0.0876, validation loss: 0.3963
2024-06-03 02:14:46 [INFO]: Epoch 054 - training loss: 0.0849, validation loss: 0.3964
2024-06-03 02:14:49 [INFO]: Epoch 055 - training loss: 0.0812, validation loss: 0.3957
2024-06-03 02:14:53 [INFO]: Epoch 056 - training loss: 0.0795, validation loss: 0.3964
2024-06-03 02:14:57 [INFO]: Epoch 057 - training loss: 0.0781, validation loss: 0.3963
2024-06-03 02:15:00 [INFO]: Epoch 058 - training loss: 0.0777, validation loss: 0.3929
2024-06-03 02:15:03 [INFO]: Epoch 059 - training loss: 0.0749, validation loss: 0.3963
2024-06-03 02:15:07 [INFO]: Epoch 060 - training loss: 0.0748, validation loss: 0.3950
2024-06-03 02:15:11 [INFO]: Epoch 061 - training loss: 0.0733, validation loss: 0.3955
2024-06-03 02:15:14 [INFO]: Epoch 062 - training loss: 0.0720, validation loss: 0.3974
2024-06-03 02:15:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:15:14 [INFO]: Finished training. The best model is from epoch#52.
2024-06-03 02:15:16 [INFO]: Saved the model to results_point_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T021127/TimesNet.pypots
2024-06-03 02:15:18 [INFO]: Successfully saved to results_point_rate05/PeMS/TimesNet_PeMS/round_1/imputation.pkl
2024-06-03 02:15:18 [INFO]: Round1 - TimesNet on PeMS: MAE=0.3519, MSE=0.5680, MRE=0.4367
2024-06-03 02:15:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 02:15:18 [INFO]: Using the given device: cuda:0
2024-06-03 02:15:18 [INFO]: Model files will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T021518
2024-06-03 02:15:18 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T021518/tensorboard
2024-06-03 02:15:24 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 02:15:27 [INFO]: Epoch 001 - training loss: 0.4597, validation loss: 0.5097
2024-06-03 02:15:31 [INFO]: Epoch 002 - training loss: 0.2617, validation loss: 0.4836
2024-06-03 02:15:34 [INFO]: Epoch 003 - training loss: 0.2447, validation loss: 0.4765
2024-06-03 02:15:38 [INFO]: Epoch 004 - training loss: 0.2372, validation loss: 0.4700
2024-06-03 02:15:41 [INFO]: Epoch 005 - training loss: 0.2346, validation loss: 0.4707
2024-06-03 02:15:45 [INFO]: Epoch 006 - training loss: 0.2304, validation loss: 0.4661
2024-06-03 02:15:48 [INFO]: Epoch 007 - training loss: 0.2139, validation loss: 0.4576
2024-06-03 02:15:52 [INFO]: Epoch 008 - training loss: 0.2162, validation loss: 0.4534
2024-06-03 02:15:55 [INFO]: Epoch 009 - training loss: 0.2101, validation loss: 0.4554
2024-06-03 02:15:59 [INFO]: Epoch 010 - training loss: 0.2048, validation loss: 0.4533
2024-06-03 02:16:02 [INFO]: Epoch 011 - training loss: 0.2053, validation loss: 0.4504
2024-06-03 02:16:06 [INFO]: Epoch 012 - training loss: 0.1975, validation loss: 0.4355
2024-06-03 02:16:10 [INFO]: Epoch 013 - training loss: 0.1891, validation loss: 0.4399
2024-06-03 02:16:13 [INFO]: Epoch 014 - training loss: 0.1828, validation loss: 0.4537
2024-06-03 02:16:17 [INFO]: Epoch 015 - training loss: 0.1827, validation loss: 0.4325
2024-06-03 02:16:20 [INFO]: Epoch 016 - training loss: 0.1766, validation loss: 0.4397
2024-06-03 02:16:24 [INFO]: Epoch 017 - training loss: 0.1731, validation loss: 0.4389
2024-06-03 02:16:28 [INFO]: Epoch 018 - training loss: 0.1629, validation loss: 0.4300
2024-06-03 02:16:31 [INFO]: Epoch 019 - training loss: 0.1591, validation loss: 0.4288
2024-06-03 02:16:35 [INFO]: Epoch 020 - training loss: 0.1528, validation loss: 0.4275
2024-06-03 02:16:39 [INFO]: Epoch 021 - training loss: 0.1521, validation loss: 0.4268
2024-06-03 02:16:42 [INFO]: Epoch 022 - training loss: 0.1507, validation loss: 0.4189
2024-06-03 02:16:46 [INFO]: Epoch 023 - training loss: 0.1467, validation loss: 0.4138
2024-06-03 02:16:49 [INFO]: Epoch 024 - training loss: 0.1459, validation loss: 0.4208
2024-06-03 02:16:52 [INFO]: Epoch 025 - training loss: 0.1408, validation loss: 0.4173
2024-06-03 02:16:56 [INFO]: Epoch 026 - training loss: 0.1370, validation loss: 0.4161
2024-06-03 02:17:00 [INFO]: Epoch 027 - training loss: 0.1348, validation loss: 0.4129
2024-06-03 02:17:03 [INFO]: Epoch 028 - training loss: 0.1336, validation loss: 0.4051
2024-06-03 02:17:07 [INFO]: Epoch 029 - training loss: 0.1298, validation loss: 0.4068
2024-06-03 02:17:10 [INFO]: Epoch 030 - training loss: 0.1273, validation loss: 0.4109
2024-06-03 02:17:14 [INFO]: Epoch 031 - training loss: 0.1236, validation loss: 0.4083
2024-06-03 02:17:17 [INFO]: Epoch 032 - training loss: 0.1219, validation loss: 0.4098
2024-06-03 02:17:21 [INFO]: Epoch 033 - training loss: 0.1212, validation loss: 0.4059
2024-06-03 02:17:24 [INFO]: Epoch 034 - training loss: 0.1178, validation loss: 0.4095
2024-06-03 02:17:28 [INFO]: Epoch 035 - training loss: 0.1167, validation loss: 0.3985
2024-06-03 02:17:31 [INFO]: Epoch 036 - training loss: 0.1129, validation loss: 0.4075
2024-06-03 02:17:35 [INFO]: Epoch 037 - training loss: 0.1131, validation loss: 0.4097
2024-06-03 02:17:38 [INFO]: Epoch 038 - training loss: 0.1121, validation loss: 0.4117
2024-06-03 02:17:42 [INFO]: Epoch 039 - training loss: 0.1093, validation loss: 0.4104
2024-06-03 02:17:46 [INFO]: Epoch 040 - training loss: 0.1097, validation loss: 0.4088
2024-06-03 02:17:49 [INFO]: Epoch 041 - training loss: 0.1059, validation loss: 0.4030
2024-06-03 02:17:53 [INFO]: Epoch 042 - training loss: 0.1027, validation loss: 0.4070
2024-06-03 02:17:56 [INFO]: Epoch 043 - training loss: 0.1019, validation loss: 0.4002
2024-06-03 02:18:00 [INFO]: Epoch 044 - training loss: 0.0980, validation loss: 0.4000
2024-06-03 02:18:03 [INFO]: Epoch 045 - training loss: 0.0967, validation loss: 0.3996
2024-06-03 02:18:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:18:03 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 02:18:06 [INFO]: Saved the model to results_point_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T021518/TimesNet.pypots
2024-06-03 02:18:08 [INFO]: Successfully saved to results_point_rate05/PeMS/TimesNet_PeMS/round_2/imputation.pkl
2024-06-03 02:18:08 [INFO]: Round2 - TimesNet on PeMS: MAE=0.3466, MSE=0.5684, MRE=0.4302
2024-06-03 02:18:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 02:18:08 [INFO]: Using the given device: cuda:0
2024-06-03 02:18:08 [INFO]: Model files will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T021808
2024-06-03 02:18:08 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T021808/tensorboard
2024-06-03 02:18:13 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 02:18:17 [INFO]: Epoch 001 - training loss: 0.4779, validation loss: 0.5127
2024-06-03 02:18:20 [INFO]: Epoch 002 - training loss: 0.2629, validation loss: 0.4775
2024-06-03 02:18:24 [INFO]: Epoch 003 - training loss: 0.2427, validation loss: 0.4789
2024-06-03 02:18:27 [INFO]: Epoch 004 - training loss: 0.2391, validation loss: 0.4667
2024-06-03 02:18:30 [INFO]: Epoch 005 - training loss: 0.2330, validation loss: 0.4677
2024-06-03 02:18:34 [INFO]: Epoch 006 - training loss: 0.2326, validation loss: 0.4637
2024-06-03 02:18:37 [INFO]: Epoch 007 - training loss: 0.2221, validation loss: 0.4606
2024-06-03 02:18:41 [INFO]: Epoch 008 - training loss: 0.2188, validation loss: 0.4604
2024-06-03 02:18:44 [INFO]: Epoch 009 - training loss: 0.2097, validation loss: 0.4593
2024-06-03 02:18:47 [INFO]: Epoch 010 - training loss: 0.2059, validation loss: 0.4551
2024-06-03 02:18:50 [INFO]: Epoch 011 - training loss: 0.1971, validation loss: 0.4398
2024-06-03 02:18:52 [INFO]: Epoch 012 - training loss: 0.1951, validation loss: 0.4409
2024-06-03 02:18:54 [INFO]: Epoch 013 - training loss: 0.1892, validation loss: 0.4457
2024-06-03 02:18:57 [INFO]: Epoch 014 - training loss: 0.1884, validation loss: 0.4533
2024-06-03 02:18:59 [INFO]: Epoch 015 - training loss: 0.1804, validation loss: 0.4302
2024-06-03 02:19:01 [INFO]: Epoch 016 - training loss: 0.1755, validation loss: 0.4341
2024-06-03 02:19:04 [INFO]: Epoch 017 - training loss: 0.1667, validation loss: 0.4289
2024-06-03 02:19:06 [INFO]: Epoch 018 - training loss: 0.1668, validation loss: 0.4410
2024-06-03 02:19:09 [INFO]: Epoch 019 - training loss: 0.1630, validation loss: 0.4294
2024-06-03 02:19:11 [INFO]: Epoch 020 - training loss: 0.1606, validation loss: 0.4208
2024-06-03 02:19:13 [INFO]: Epoch 021 - training loss: 0.1549, validation loss: 0.4256
2024-06-03 02:19:16 [INFO]: Epoch 022 - training loss: 0.1510, validation loss: 0.4211
2024-06-03 02:19:19 [INFO]: Epoch 023 - training loss: 0.1453, validation loss: 0.4177
2024-06-03 02:19:21 [INFO]: Epoch 024 - training loss: 0.1430, validation loss: 0.4174
2024-06-03 02:19:24 [INFO]: Epoch 025 - training loss: 0.1412, validation loss: 0.4088
2024-06-03 02:19:26 [INFO]: Epoch 026 - training loss: 0.1396, validation loss: 0.4097
2024-06-03 02:19:29 [INFO]: Epoch 027 - training loss: 0.1365, validation loss: 0.4116
2024-06-03 02:19:31 [INFO]: Epoch 028 - training loss: 0.1351, validation loss: 0.4079
2024-06-03 02:19:33 [INFO]: Epoch 029 - training loss: 0.1326, validation loss: 0.4124
2024-06-03 02:19:36 [INFO]: Epoch 030 - training loss: 0.1262, validation loss: 0.4047
2024-06-03 02:19:38 [INFO]: Epoch 031 - training loss: 0.1262, validation loss: 0.4086
2024-06-03 02:19:40 [INFO]: Epoch 032 - training loss: 0.1242, validation loss: 0.4115
2024-06-03 02:19:43 [INFO]: Epoch 033 - training loss: 0.1229, validation loss: 0.4045
2024-06-03 02:19:45 [INFO]: Epoch 034 - training loss: 0.1199, validation loss: 0.4030
2024-06-03 02:19:47 [INFO]: Epoch 035 - training loss: 0.1180, validation loss: 0.4146
2024-06-03 02:19:50 [INFO]: Epoch 036 - training loss: 0.1173, validation loss: 0.4084
2024-06-03 02:19:52 [INFO]: Epoch 037 - training loss: 0.1130, validation loss: 0.4072
2024-06-03 02:19:54 [INFO]: Epoch 038 - training loss: 0.1094, validation loss: 0.4055
2024-06-03 02:19:58 [INFO]: Epoch 039 - training loss: 0.1084, validation loss: 0.3985
2024-06-03 02:20:01 [INFO]: Epoch 040 - training loss: 0.1062, validation loss: 0.4022
2024-06-03 02:20:04 [INFO]: Epoch 041 - training loss: 0.1039, validation loss: 0.4036
2024-06-03 02:20:07 [INFO]: Epoch 042 - training loss: 0.1020, validation loss: 0.4025
2024-06-03 02:20:11 [INFO]: Epoch 043 - training loss: 0.1010, validation loss: 0.3962
2024-06-03 02:20:14 [INFO]: Epoch 044 - training loss: 0.0992, validation loss: 0.3911
2024-06-03 02:20:17 [INFO]: Epoch 045 - training loss: 0.1007, validation loss: 0.4014
2024-06-03 02:20:21 [INFO]: Epoch 046 - training loss: 0.0947, validation loss: 0.3983
2024-06-03 02:20:24 [INFO]: Epoch 047 - training loss: 0.0943, validation loss: 0.3996
2024-06-03 02:20:27 [INFO]: Epoch 048 - training loss: 0.0923, validation loss: 0.3984
2024-06-03 02:20:31 [INFO]: Epoch 049 - training loss: 0.0919, validation loss: 0.3960
2024-06-03 02:20:34 [INFO]: Epoch 050 - training loss: 0.0908, validation loss: 0.3941
2024-06-03 02:20:37 [INFO]: Epoch 051 - training loss: 0.0877, validation loss: 0.3922
2024-06-03 02:20:40 [INFO]: Epoch 052 - training loss: 0.0879, validation loss: 0.3911
2024-06-03 02:20:44 [INFO]: Epoch 053 - training loss: 0.0830, validation loss: 0.3925
2024-06-03 02:20:47 [INFO]: Epoch 054 - training loss: 0.0840, validation loss: 0.3923
2024-06-03 02:20:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:20:47 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 02:20:49 [INFO]: Saved the model to results_point_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T021808/TimesNet.pypots
2024-06-03 02:20:51 [INFO]: Successfully saved to results_point_rate05/PeMS/TimesNet_PeMS/round_3/imputation.pkl
2024-06-03 02:20:51 [INFO]: Round3 - TimesNet on PeMS: MAE=0.3479, MSE=0.5653, MRE=0.4317
2024-06-03 02:20:51 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:20:51 [INFO]: Using the given device: cuda:0
2024-06-03 02:20:51 [INFO]: Model files will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T022051
2024-06-03 02:20:51 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T022051/tensorboard
2024-06-03 02:20:56 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 02:20:59 [INFO]: Epoch 001 - training loss: 0.4579, validation loss: 0.5141
2024-06-03 02:21:03 [INFO]: Epoch 002 - training loss: 0.2580, validation loss: 0.4866
2024-06-03 02:21:06 [INFO]: Epoch 003 - training loss: 0.2431, validation loss: 0.4735
2024-06-03 02:21:09 [INFO]: Epoch 004 - training loss: 0.2365, validation loss: 0.4675
2024-06-03 02:21:12 [INFO]: Epoch 005 - training loss: 0.2351, validation loss: 0.4757
2024-06-03 02:21:16 [INFO]: Epoch 006 - training loss: 0.2302, validation loss: 0.4664
2024-06-03 02:21:19 [INFO]: Epoch 007 - training loss: 0.2278, validation loss: 0.4701
2024-06-03 02:21:22 [INFO]: Epoch 008 - training loss: 0.2203, validation loss: 0.4624
2024-06-03 02:21:26 [INFO]: Epoch 009 - training loss: 0.2091, validation loss: 0.4572
2024-06-03 02:21:29 [INFO]: Epoch 010 - training loss: 0.2028, validation loss: 0.4619
2024-06-03 02:21:33 [INFO]: Epoch 011 - training loss: 0.1975, validation loss: 0.4536
2024-06-03 02:21:36 [INFO]: Epoch 012 - training loss: 0.1942, validation loss: 0.4475
2024-06-03 02:21:40 [INFO]: Epoch 013 - training loss: 0.1877, validation loss: 0.4379
2024-06-03 02:21:43 [INFO]: Epoch 014 - training loss: 0.1817, validation loss: 0.4378
2024-06-03 02:21:46 [INFO]: Epoch 015 - training loss: 0.1840, validation loss: 0.4398
2024-06-03 02:21:50 [INFO]: Epoch 016 - training loss: 0.1798, validation loss: 0.4411
2024-06-03 02:21:53 [INFO]: Epoch 017 - training loss: 0.1690, validation loss: 0.4459
2024-06-03 02:21:57 [INFO]: Epoch 018 - training loss: 0.1681, validation loss: 0.4288
2024-06-03 02:22:00 [INFO]: Epoch 019 - training loss: 0.1658, validation loss: 0.4265
2024-06-03 02:22:03 [INFO]: Epoch 020 - training loss: 0.1574, validation loss: 0.4188
2024-06-03 02:22:06 [INFO]: Epoch 021 - training loss: 0.1559, validation loss: 0.4158
2024-06-03 02:22:09 [INFO]: Epoch 022 - training loss: 0.1467, validation loss: 0.4146
2024-06-03 02:22:13 [INFO]: Epoch 023 - training loss: 0.1493, validation loss: 0.4211
2024-06-03 02:22:16 [INFO]: Epoch 024 - training loss: 0.1454, validation loss: 0.4135
2024-06-03 02:22:20 [INFO]: Epoch 025 - training loss: 0.1414, validation loss: 0.4164
2024-06-03 02:22:23 [INFO]: Epoch 026 - training loss: 0.1363, validation loss: 0.4089
2024-06-03 02:22:26 [INFO]: Epoch 027 - training loss: 0.1348, validation loss: 0.4172
2024-06-03 02:22:30 [INFO]: Epoch 028 - training loss: 0.1337, validation loss: 0.4192
2024-06-03 02:22:33 [INFO]: Epoch 029 - training loss: 0.1287, validation loss: 0.4193
2024-06-03 02:22:36 [INFO]: Epoch 030 - training loss: 0.1291, validation loss: 0.4236
2024-06-03 02:22:40 [INFO]: Epoch 031 - training loss: 0.1276, validation loss: 0.4146
2024-06-03 02:22:43 [INFO]: Epoch 032 - training loss: 0.1225, validation loss: 0.4097
2024-06-03 02:22:46 [INFO]: Epoch 033 - training loss: 0.1206, validation loss: 0.4033
2024-06-03 02:22:50 [INFO]: Epoch 034 - training loss: 0.1153, validation loss: 0.3983
2024-06-03 02:22:53 [INFO]: Epoch 035 - training loss: 0.1184, validation loss: 0.4074
2024-06-03 02:22:57 [INFO]: Epoch 036 - training loss: 0.1133, validation loss: 0.4140
2024-06-03 02:23:00 [INFO]: Epoch 037 - training loss: 0.1110, validation loss: 0.4061
2024-06-03 02:23:03 [INFO]: Epoch 038 - training loss: 0.1107, validation loss: 0.4062
2024-06-03 02:23:07 [INFO]: Epoch 039 - training loss: 0.1085, validation loss: 0.4060
2024-06-03 02:23:10 [INFO]: Epoch 040 - training loss: 0.1069, validation loss: 0.4138
2024-06-03 02:23:13 [INFO]: Epoch 041 - training loss: 0.1034, validation loss: 0.4037
2024-06-03 02:23:17 [INFO]: Epoch 042 - training loss: 0.1008, validation loss: 0.4077
2024-06-03 02:23:20 [INFO]: Epoch 043 - training loss: 0.1008, validation loss: 0.3991
2024-06-03 02:23:24 [INFO]: Epoch 044 - training loss: 0.0987, validation loss: 0.4031
2024-06-03 02:23:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:23:24 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 02:23:26 [INFO]: Saved the model to results_point_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T022051/TimesNet.pypots
2024-06-03 02:23:27 [INFO]: Successfully saved to results_point_rate05/PeMS/TimesNet_PeMS/round_4/imputation.pkl
2024-06-03 02:23:27 [INFO]: Round4 - TimesNet on PeMS: MAE=0.3472, MSE=0.5688, MRE=0.4308
2024-06-03 02:23:27 [INFO]: Done! Final results:
Averaged TimesNet (91,622,238 params) on PeMS: MAE=0.3479 ± 0.002161971645750418, MSE=0.5672 ± 0.0014715866297993787, MRE=0.4317 ± 0.0026828234219675156, average inference time=0.37
