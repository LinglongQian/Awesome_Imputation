2024-06-03 00:45:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:45:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:09 [INFO]: Model files will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T004508
2024-06-03 00:45:09 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T004508/tensorboard
2024-06-03 00:45:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 00:45:27 [INFO]: Epoch 001 - training loss: 636175.4167, validation loss: 1.1253
2024-06-03 00:45:34 [INFO]: Epoch 002 - training loss: 377968.5521, validation loss: 0.7097
2024-06-03 00:45:42 [INFO]: Epoch 003 - training loss: 281668.0667, validation loss: 0.5561
2024-06-03 00:45:50 [INFO]: Epoch 004 - training loss: 266084.6583, validation loss: 0.5176
2024-06-03 00:45:58 [INFO]: Epoch 005 - training loss: 262379.1740, validation loss: 0.5183
2024-06-03 00:46:06 [INFO]: Epoch 006 - training loss: 260914.4000, validation loss: 0.4966
2024-06-03 00:46:13 [INFO]: Epoch 007 - training loss: 260164.3031, validation loss: 0.4989
2024-06-03 00:46:21 [INFO]: Epoch 008 - training loss: 259791.8146, validation loss: 0.4956
2024-06-03 00:46:28 [INFO]: Epoch 009 - training loss: 259590.2177, validation loss: 0.5094
2024-06-03 00:46:36 [INFO]: Epoch 010 - training loss: 259499.9333, validation loss: 0.4715
2024-06-03 00:46:43 [INFO]: Epoch 011 - training loss: 259329.1187, validation loss: 0.4682
2024-06-03 00:46:51 [INFO]: Epoch 012 - training loss: 259268.9031, validation loss: 0.4858
2024-06-03 00:46:59 [INFO]: Epoch 013 - training loss: 259209.9042, validation loss: 0.4675
2024-06-03 00:47:06 [INFO]: Epoch 014 - training loss: 259177.7021, validation loss: 0.4615
2024-06-03 00:47:14 [INFO]: Epoch 015 - training loss: 259136.9312, validation loss: 0.4684
2024-06-03 00:47:23 [INFO]: Epoch 016 - training loss: 259099.5562, validation loss: 0.4591
2024-06-03 00:47:30 [INFO]: Epoch 017 - training loss: 259037.3813, validation loss: 0.4737
2024-06-03 00:47:38 [INFO]: Epoch 018 - training loss: 259048.4062, validation loss: 0.4613
2024-06-03 00:47:46 [INFO]: Epoch 019 - training loss: 259025.6219, validation loss: 0.4519
2024-06-03 00:47:54 [INFO]: Epoch 020 - training loss: 259010.7552, validation loss: 0.4584
2024-06-03 00:48:01 [INFO]: Epoch 021 - training loss: 259000.8021, validation loss: 0.4586
2024-06-03 00:48:09 [INFO]: Epoch 022 - training loss: 259005.1667, validation loss: 0.4665
2024-06-03 00:48:17 [INFO]: Epoch 023 - training loss: 259080.2740, validation loss: 0.4527
2024-06-03 00:48:24 [INFO]: Epoch 024 - training loss: 259190.0625, validation loss: 0.4570
2024-06-03 00:48:32 [INFO]: Epoch 025 - training loss: 259407.4625, validation loss: 0.4739
2024-06-03 00:48:39 [INFO]: Epoch 026 - training loss: 259254.4896, validation loss: 0.4630
2024-06-03 00:48:47 [INFO]: Epoch 027 - training loss: 259688.5917, validation loss: 0.4493
2024-06-03 00:48:55 [INFO]: Epoch 028 - training loss: 259361.1250, validation loss: 0.4568
2024-06-03 00:49:03 [INFO]: Epoch 029 - training loss: 259234.0146, validation loss: 0.4486
2024-06-03 00:49:10 [INFO]: Epoch 030 - training loss: 259305.4750, validation loss: 0.4449
2024-06-03 00:49:18 [INFO]: Epoch 031 - training loss: 259143.1854, validation loss: 0.4673
2024-06-03 00:49:25 [INFO]: Epoch 032 - training loss: 259227.8083, validation loss: 0.4467
2024-06-03 00:49:33 [INFO]: Epoch 033 - training loss: 259057.7375, validation loss: 0.4483
2024-06-03 00:49:41 [INFO]: Epoch 034 - training loss: 258994.4510, validation loss: 0.4476
2024-06-03 00:49:49 [INFO]: Epoch 035 - training loss: 258955.7958, validation loss: 0.4440
2024-06-03 00:49:57 [INFO]: Epoch 036 - training loss: 259006.2250, validation loss: 0.4432
2024-06-03 00:50:05 [INFO]: Epoch 037 - training loss: 258960.1073, validation loss: 0.4542
2024-06-03 00:50:13 [INFO]: Epoch 038 - training loss: 258990.6771, validation loss: 0.4442
2024-06-03 00:50:20 [INFO]: Epoch 039 - training loss: 258908.1479, validation loss: 0.4456
2024-06-03 00:50:29 [INFO]: Epoch 040 - training loss: 258927.1333, validation loss: 0.4483
2024-06-03 00:50:36 [INFO]: Epoch 041 - training loss: 258972.3646, validation loss: 0.4392
2024-06-03 00:50:44 [INFO]: Epoch 042 - training loss: 258869.1323, validation loss: 0.4548
2024-06-03 00:50:52 [INFO]: Epoch 043 - training loss: 258825.4365, validation loss: 0.4547
2024-06-03 00:50:59 [INFO]: Epoch 044 - training loss: 258845.1281, validation loss: 0.4475
2024-06-03 00:51:07 [INFO]: Epoch 045 - training loss: 258795.4135, validation loss: 0.4424
2024-06-03 00:51:15 [INFO]: Epoch 046 - training loss: 258771.7479, validation loss: 0.4407
2024-06-03 00:51:22 [INFO]: Epoch 047 - training loss: 258752.7313, validation loss: 0.4445
2024-06-03 00:51:30 [INFO]: Epoch 048 - training loss: 258755.6760, validation loss: 0.4653
2024-06-03 00:51:38 [INFO]: Epoch 049 - training loss: 258834.8958, validation loss: 0.4461
2024-06-03 00:51:46 [INFO]: Epoch 050 - training loss: 259213.1927, validation loss: 0.4461
2024-06-03 00:51:54 [INFO]: Epoch 051 - training loss: 258918.0427, validation loss: 0.4427
2024-06-03 00:51:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:51:54 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 00:51:54 [INFO]: Saved the model to results_point_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T004508/GPVAE.pypots
2024-06-03 00:52:47 [INFO]: Successfully saved to results_point_rate05/PeMS/GPVAE_PeMS/round_0/imputation.pkl
2024-06-03 00:52:47 [INFO]: Round0 - GPVAE on PeMS: MAE=0.3418, MSE=0.6092, MRE=0.4242
2024-06-03 00:52:47 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:52:47 [INFO]: Using the given device: cuda:0
2024-06-03 00:52:47 [INFO]: Model files will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T005247
2024-06-03 00:52:47 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T005247/tensorboard
2024-06-03 00:52:48 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 00:52:54 [INFO]: Epoch 001 - training loss: 643926.4958, validation loss: 1.1362
2024-06-03 00:53:01 [INFO]: Epoch 002 - training loss: 379992.1562, validation loss: 0.7127
2024-06-03 00:53:07 [INFO]: Epoch 003 - training loss: 282133.3396, validation loss: 0.5730
2024-06-03 00:53:13 [INFO]: Epoch 004 - training loss: 265925.0000, validation loss: 0.5489
2024-06-03 00:53:19 [INFO]: Epoch 005 - training loss: 262140.3458, validation loss: 0.5056
2024-06-03 00:53:26 [INFO]: Epoch 006 - training loss: 260669.3990, validation loss: 0.5031
2024-06-03 00:53:32 [INFO]: Epoch 007 - training loss: 260095.5781, validation loss: 0.4918
2024-06-03 00:53:38 [INFO]: Epoch 008 - training loss: 259861.9948, validation loss: 0.4766
2024-06-03 00:53:45 [INFO]: Epoch 009 - training loss: 259622.8813, validation loss: 0.4722
2024-06-03 00:53:51 [INFO]: Epoch 010 - training loss: 259548.6969, validation loss: 0.4742
2024-06-03 00:53:57 [INFO]: Epoch 011 - training loss: 259343.1844, validation loss: 0.4841
2024-06-03 00:54:03 [INFO]: Epoch 012 - training loss: 259307.0917, validation loss: 0.4936
2024-06-03 00:54:09 [INFO]: Epoch 013 - training loss: 259220.5333, validation loss: 0.4711
2024-06-03 00:54:16 [INFO]: Epoch 014 - training loss: 259130.1271, validation loss: 0.4639
2024-06-03 00:54:22 [INFO]: Epoch 015 - training loss: 259094.2448, validation loss: 0.4732
2024-06-03 00:54:28 [INFO]: Epoch 016 - training loss: 259077.4219, validation loss: 0.4747
2024-06-03 00:54:34 [INFO]: Epoch 017 - training loss: 259041.2156, validation loss: 0.4627
2024-06-03 00:54:40 [INFO]: Epoch 018 - training loss: 258994.0760, validation loss: 0.4697
2024-06-03 00:54:47 [INFO]: Epoch 019 - training loss: 259012.4750, validation loss: 0.4597
2024-06-03 00:54:53 [INFO]: Epoch 020 - training loss: 258991.0792, validation loss: 0.4637
2024-06-03 00:54:59 [INFO]: Epoch 021 - training loss: 258974.7250, validation loss: 0.4587
2024-06-03 00:55:05 [INFO]: Epoch 022 - training loss: 258946.6156, validation loss: 0.4634
2024-06-03 00:55:12 [INFO]: Epoch 023 - training loss: 258934.9156, validation loss: 0.4583
2024-06-03 00:55:18 [INFO]: Epoch 024 - training loss: 258943.3729, validation loss: 0.4742
2024-06-03 00:55:24 [INFO]: Epoch 025 - training loss: 258941.4823, validation loss: 0.4546
2024-06-03 00:55:31 [INFO]: Epoch 026 - training loss: 258989.5187, validation loss: 0.4894
2024-06-03 00:55:37 [INFO]: Epoch 027 - training loss: 259013.3219, validation loss: 0.4545
2024-06-03 00:55:43 [INFO]: Epoch 028 - training loss: 258972.1604, validation loss: 0.4554
2024-06-03 00:55:49 [INFO]: Epoch 029 - training loss: 258958.1823, validation loss: 0.4562
2024-06-03 00:55:55 [INFO]: Epoch 030 - training loss: 259000.4698, validation loss: 0.4557
2024-06-03 00:56:01 [INFO]: Epoch 031 - training loss: 259138.2052, validation loss: 0.4828
2024-06-03 00:56:08 [INFO]: Epoch 032 - training loss: 259395.6333, validation loss: 0.4540
2024-06-03 00:56:13 [INFO]: Epoch 033 - training loss: 259273.9979, validation loss: 0.4488
2024-06-03 00:56:19 [INFO]: Epoch 034 - training loss: 259263.0688, validation loss: 0.4621
2024-06-03 00:56:25 [INFO]: Epoch 035 - training loss: 259244.2313, validation loss: 0.4570
2024-06-03 00:56:31 [INFO]: Epoch 036 - training loss: 259271.3094, validation loss: 0.4526
2024-06-03 00:56:36 [INFO]: Epoch 037 - training loss: 259468.7719, validation loss: 0.4601
2024-06-03 00:56:42 [INFO]: Epoch 038 - training loss: 259830.7292, validation loss: 0.4543
2024-06-03 00:56:47 [INFO]: Epoch 039 - training loss: 259186.8146, validation loss: 0.4485
2024-06-03 00:56:53 [INFO]: Epoch 040 - training loss: 259011.5323, validation loss: 0.4635
2024-06-03 00:56:59 [INFO]: Epoch 041 - training loss: 258930.1177, validation loss: 0.4597
2024-06-03 00:57:05 [INFO]: Epoch 042 - training loss: 258894.9115, validation loss: 0.4438
2024-06-03 00:57:10 [INFO]: Epoch 043 - training loss: 258828.2729, validation loss: 0.4536
2024-06-03 00:57:16 [INFO]: Epoch 044 - training loss: 258816.2062, validation loss: 0.4507
2024-06-03 00:57:22 [INFO]: Epoch 045 - training loss: 258833.9990, validation loss: 0.4616
2024-06-03 00:57:27 [INFO]: Epoch 046 - training loss: 258813.3719, validation loss: 0.4435
2024-06-03 00:57:33 [INFO]: Epoch 047 - training loss: 258794.2656, validation loss: 0.4446
2024-06-03 00:57:38 [INFO]: Epoch 048 - training loss: 258757.7125, validation loss: 0.4519
2024-06-03 00:57:44 [INFO]: Epoch 049 - training loss: 258785.9667, validation loss: 0.4474
2024-06-03 00:57:50 [INFO]: Epoch 050 - training loss: 258797.9948, validation loss: 0.4598
2024-06-03 00:57:55 [INFO]: Epoch 051 - training loss: 258782.7094, validation loss: 0.4456
2024-06-03 00:58:00 [INFO]: Epoch 052 - training loss: 258727.7333, validation loss: 0.4479
2024-06-03 00:58:06 [INFO]: Epoch 053 - training loss: 258725.1281, validation loss: 0.4436
2024-06-03 00:58:12 [INFO]: Epoch 054 - training loss: 258730.2510, validation loss: 0.4450
2024-06-03 00:58:17 [INFO]: Epoch 055 - training loss: 258711.8365, validation loss: 0.4427
2024-06-03 00:58:23 [INFO]: Epoch 056 - training loss: 258724.3594, validation loss: 0.4439
2024-06-03 00:58:28 [INFO]: Epoch 057 - training loss: 258707.7667, validation loss: 0.4374
2024-06-03 00:58:34 [INFO]: Epoch 058 - training loss: 258688.6646, validation loss: 0.4407
2024-06-03 00:58:40 [INFO]: Epoch 059 - training loss: 258688.1448, validation loss: 0.4403
2024-06-03 00:58:46 [INFO]: Epoch 060 - training loss: 258701.5052, validation loss: 0.4477
2024-06-03 00:58:52 [INFO]: Epoch 061 - training loss: 258714.6875, validation loss: 0.4391
2024-06-03 00:58:58 [INFO]: Epoch 062 - training loss: 258698.0260, validation loss: 0.4546
2024-06-03 00:59:03 [INFO]: Epoch 063 - training loss: 258686.2094, validation loss: 0.4422
2024-06-03 00:59:09 [INFO]: Epoch 064 - training loss: 258694.8760, validation loss: 0.4423
2024-06-03 00:59:15 [INFO]: Epoch 065 - training loss: 258699.7958, validation loss: 0.4443
2024-06-03 00:59:21 [INFO]: Epoch 066 - training loss: 258673.7896, validation loss: 0.4393
2024-06-03 00:59:27 [INFO]: Epoch 067 - training loss: 258663.7635, validation loss: 0.4369
2024-06-03 00:59:33 [INFO]: Epoch 068 - training loss: 258681.0000, validation loss: 0.4420
2024-06-03 00:59:39 [INFO]: Epoch 069 - training loss: 258700.7979, validation loss: 0.4344
2024-06-03 00:59:45 [INFO]: Epoch 070 - training loss: 258709.9365, validation loss: 0.4368
2024-06-03 00:59:51 [INFO]: Epoch 071 - training loss: 258686.8031, validation loss: 0.4352
2024-06-03 00:59:57 [INFO]: Epoch 072 - training loss: 258697.0333, validation loss: 0.4649
2024-06-03 01:00:03 [INFO]: Epoch 073 - training loss: 258743.0417, validation loss: 0.4390
2024-06-03 01:00:09 [INFO]: Epoch 074 - training loss: 258733.4083, validation loss: 0.4345
2024-06-03 01:00:14 [INFO]: Epoch 075 - training loss: 258799.8719, validation loss: 0.4395
2024-06-03 01:00:21 [INFO]: Epoch 076 - training loss: 258723.6896, validation loss: 0.4372
2024-06-03 01:00:27 [INFO]: Epoch 077 - training loss: 258699.0396, validation loss: 0.4336
2024-06-03 01:00:33 [INFO]: Epoch 078 - training loss: 258732.6781, validation loss: 0.4366
2024-06-03 01:00:39 [INFO]: Epoch 079 - training loss: 258702.0458, validation loss: 0.4386
2024-06-03 01:00:45 [INFO]: Epoch 080 - training loss: 258672.0042, validation loss: 0.4348
2024-06-03 01:00:51 [INFO]: Epoch 081 - training loss: 258662.7750, validation loss: 0.4362
2024-06-03 01:00:57 [INFO]: Epoch 082 - training loss: 258669.2896, validation loss: 0.4351
2024-06-03 01:01:03 [INFO]: Epoch 083 - training loss: 258682.7604, validation loss: 0.4384
2024-06-03 01:01:09 [INFO]: Epoch 084 - training loss: 258679.1667, validation loss: 0.4368
2024-06-03 01:01:15 [INFO]: Epoch 085 - training loss: 258669.8896, validation loss: 0.4362
2024-06-03 01:01:20 [INFO]: Epoch 086 - training loss: 258699.3958, validation loss: 0.4341
2024-06-03 01:01:26 [INFO]: Epoch 087 - training loss: 258670.5969, validation loss: 0.4307
2024-06-03 01:01:32 [INFO]: Epoch 088 - training loss: 258667.0719, validation loss: 0.4335
2024-06-03 01:01:37 [INFO]: Epoch 089 - training loss: 258643.9729, validation loss: 0.4322
2024-06-03 01:01:43 [INFO]: Epoch 090 - training loss: 258637.6771, validation loss: 0.4360
2024-06-03 01:01:48 [INFO]: Epoch 091 - training loss: 258645.3854, validation loss: 0.4292
2024-06-03 01:01:54 [INFO]: Epoch 092 - training loss: 258615.5260, validation loss: 0.4312
2024-06-03 01:01:59 [INFO]: Epoch 093 - training loss: 258630.7646, validation loss: 0.4386
2024-06-03 01:02:05 [INFO]: Epoch 094 - training loss: 258640.2490, validation loss: 0.4522
2024-06-03 01:02:11 [INFO]: Epoch 095 - training loss: 258665.9375, validation loss: 0.4391
2024-06-03 01:02:17 [INFO]: Epoch 096 - training loss: 258621.5990, validation loss: 0.4377
2024-06-03 01:02:23 [INFO]: Epoch 097 - training loss: 258613.9875, validation loss: 0.4332
2024-06-03 01:02:28 [INFO]: Epoch 098 - training loss: 258620.6656, validation loss: 0.4325
2024-06-03 01:02:35 [INFO]: Epoch 099 - training loss: 258620.3417, validation loss: 0.4315
2024-06-03 01:02:40 [INFO]: Epoch 100 - training loss: 258615.6271, validation loss: 0.4300
2024-06-03 01:02:40 [INFO]: Finished training. The best model is from epoch#91.
2024-06-03 01:02:40 [INFO]: Saved the model to results_point_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T005247/GPVAE.pypots
2024-06-03 01:03:27 [INFO]: Successfully saved to results_point_rate05/PeMS/GPVAE_PeMS/round_1/imputation.pkl
2024-06-03 01:03:27 [INFO]: Round1 - GPVAE on PeMS: MAE=0.3288, MSE=0.5997, MRE=0.4080
2024-06-03 01:03:27 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:03:27 [INFO]: Using the given device: cuda:0
2024-06-03 01:03:27 [INFO]: Model files will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T010327
2024-06-03 01:03:27 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T010327/tensorboard
2024-06-03 01:03:27 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 01:03:33 [INFO]: Epoch 001 - training loss: 634777.0542, validation loss: 1.1024
2024-06-03 01:03:39 [INFO]: Epoch 002 - training loss: 375083.2250, validation loss: 0.6779
2024-06-03 01:03:45 [INFO]: Epoch 003 - training loss: 280202.5938, validation loss: 0.5656
2024-06-03 01:03:50 [INFO]: Epoch 004 - training loss: 266578.4062, validation loss: 0.5778
2024-06-03 01:03:57 [INFO]: Epoch 005 - training loss: 262889.8927, validation loss: 0.5110
2024-06-03 01:04:03 [INFO]: Epoch 006 - training loss: 261000.1521, validation loss: 0.5091
2024-06-03 01:04:09 [INFO]: Epoch 007 - training loss: 260245.9448, validation loss: 0.4922
2024-06-03 01:04:14 [INFO]: Epoch 008 - training loss: 259798.0271, validation loss: 0.5031
2024-06-03 01:04:20 [INFO]: Epoch 009 - training loss: 259596.9052, validation loss: 0.4887
2024-06-03 01:04:26 [INFO]: Epoch 010 - training loss: 259455.2719, validation loss: 0.4945
2024-06-03 01:04:32 [INFO]: Epoch 011 - training loss: 259353.1365, validation loss: 0.4880
2024-06-03 01:04:38 [INFO]: Epoch 012 - training loss: 259255.2281, validation loss: 0.4955
2024-06-03 01:04:44 [INFO]: Epoch 013 - training loss: 259200.1010, validation loss: 0.4668
2024-06-03 01:04:49 [INFO]: Epoch 014 - training loss: 259165.4490, validation loss: 0.4839
2024-06-03 01:04:55 [INFO]: Epoch 015 - training loss: 259158.9344, validation loss: 0.4691
2024-06-03 01:05:01 [INFO]: Epoch 016 - training loss: 259116.9479, validation loss: 0.4677
2024-06-03 01:05:06 [INFO]: Epoch 017 - training loss: 259053.4531, validation loss: 0.4824
2024-06-03 01:05:12 [INFO]: Epoch 018 - training loss: 259043.3125, validation loss: 0.4679
2024-06-03 01:05:19 [INFO]: Epoch 019 - training loss: 259032.4802, validation loss: 0.4767
2024-06-03 01:05:24 [INFO]: Epoch 020 - training loss: 259007.2135, validation loss: 0.4567
2024-06-03 01:05:30 [INFO]: Epoch 021 - training loss: 259035.8365, validation loss: 0.4672
2024-06-03 01:05:35 [INFO]: Epoch 022 - training loss: 259039.8271, validation loss: 0.4770
2024-06-03 01:05:41 [INFO]: Epoch 023 - training loss: 259062.5948, validation loss: 0.4632
2024-06-03 01:05:47 [INFO]: Epoch 024 - training loss: 259053.6281, validation loss: 0.4588
2024-06-03 01:05:53 [INFO]: Epoch 025 - training loss: 259110.9344, validation loss: 0.4638
2024-06-03 01:05:59 [INFO]: Epoch 026 - training loss: 259148.6417, validation loss: 0.4719
2024-06-03 01:06:04 [INFO]: Epoch 027 - training loss: 259223.3635, validation loss: 0.4734
2024-06-03 01:06:10 [INFO]: Epoch 028 - training loss: 259398.9094, validation loss: 0.4781
2024-06-03 01:06:15 [INFO]: Epoch 029 - training loss: 259436.4625, validation loss: 0.4548
2024-06-03 01:06:21 [INFO]: Epoch 030 - training loss: 259258.6427, validation loss: 0.4537
2024-06-03 01:06:27 [INFO]: Epoch 031 - training loss: 259451.4781, validation loss: 0.4601
2024-06-03 01:06:33 [INFO]: Epoch 032 - training loss: 259304.6000, validation loss: 0.4712
2024-06-03 01:06:38 [INFO]: Epoch 033 - training loss: 259246.5417, validation loss: 0.4654
2024-06-03 01:06:44 [INFO]: Epoch 034 - training loss: 259112.4094, validation loss: 0.4647
2024-06-03 01:06:49 [INFO]: Epoch 035 - training loss: 259115.8219, validation loss: 0.4691
2024-06-03 01:06:55 [INFO]: Epoch 036 - training loss: 259038.0677, validation loss: 0.4600
2024-06-03 01:07:00 [INFO]: Epoch 037 - training loss: 259008.1292, validation loss: 0.4653
2024-06-03 01:07:06 [INFO]: Epoch 038 - training loss: 258989.9510, validation loss: 0.4515
2024-06-03 01:07:12 [INFO]: Epoch 039 - training loss: 258882.4271, validation loss: 0.4500
2024-06-03 01:07:18 [INFO]: Epoch 040 - training loss: 258894.9688, validation loss: 0.4611
2024-06-03 01:07:23 [INFO]: Epoch 041 - training loss: 259029.4531, validation loss: 0.4560
2024-06-03 01:07:29 [INFO]: Epoch 042 - training loss: 259218.1396, validation loss: 0.4583
2024-06-03 01:07:34 [INFO]: Epoch 043 - training loss: 258951.7604, validation loss: 0.4586
2024-06-03 01:07:40 [INFO]: Epoch 044 - training loss: 258879.8698, validation loss: 0.4501
2024-06-03 01:07:45 [INFO]: Epoch 045 - training loss: 258819.6552, validation loss: 0.4549
2024-06-03 01:07:51 [INFO]: Epoch 046 - training loss: 258807.4375, validation loss: 0.4597
2024-06-03 01:07:57 [INFO]: Epoch 047 - training loss: 258817.2219, validation loss: 0.4518
2024-06-03 01:08:03 [INFO]: Epoch 048 - training loss: 258794.6552, validation loss: 0.4539
2024-06-03 01:08:08 [INFO]: Epoch 049 - training loss: 258802.6083, validation loss: 0.4619
2024-06-03 01:08:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:08:08 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 01:08:08 [INFO]: Saved the model to results_point_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T010327/GPVAE.pypots
2024-06-03 01:08:55 [INFO]: Successfully saved to results_point_rate05/PeMS/GPVAE_PeMS/round_2/imputation.pkl
2024-06-03 01:08:55 [INFO]: Round2 - GPVAE on PeMS: MAE=0.3546, MSE=0.6237, MRE=0.4401
2024-06-03 01:08:55 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:08:55 [INFO]: Using the given device: cuda:0
2024-06-03 01:08:55 [INFO]: Model files will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T010855
2024-06-03 01:08:55 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T010855/tensorboard
2024-06-03 01:08:55 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 01:09:01 [INFO]: Epoch 001 - training loss: 638760.0188, validation loss: 1.1014
2024-06-03 01:09:07 [INFO]: Epoch 002 - training loss: 384173.4833, validation loss: 0.7082
2024-06-03 01:09:13 [INFO]: Epoch 003 - training loss: 283888.3125, validation loss: 0.5801
2024-06-03 01:09:18 [INFO]: Epoch 004 - training loss: 267156.6562, validation loss: 0.5376
2024-06-03 01:09:24 [INFO]: Epoch 005 - training loss: 263174.3667, validation loss: 0.5106
2024-06-03 01:09:30 [INFO]: Epoch 006 - training loss: 260854.5312, validation loss: 0.4962
2024-06-03 01:09:35 [INFO]: Epoch 007 - training loss: 260144.8427, validation loss: 0.4909
2024-06-03 01:09:41 [INFO]: Epoch 008 - training loss: 259739.2260, validation loss: 0.4813
2024-06-03 01:09:46 [INFO]: Epoch 009 - training loss: 259516.4219, validation loss: 0.4774
2024-06-03 01:09:52 [INFO]: Epoch 010 - training loss: 259411.3458, validation loss: 0.4808
2024-06-03 01:09:58 [INFO]: Epoch 011 - training loss: 259351.3198, validation loss: 0.4690
2024-06-03 01:10:03 [INFO]: Epoch 012 - training loss: 259250.1875, validation loss: 0.4710
2024-06-03 01:10:09 [INFO]: Epoch 013 - training loss: 259197.1333, validation loss: 0.4760
2024-06-03 01:10:14 [INFO]: Epoch 014 - training loss: 259149.8240, validation loss: 0.4651
2024-06-03 01:10:20 [INFO]: Epoch 015 - training loss: 259113.7333, validation loss: 0.4690
2024-06-03 01:10:26 [INFO]: Epoch 016 - training loss: 259088.8135, validation loss: 0.4581
2024-06-03 01:10:32 [INFO]: Epoch 017 - training loss: 259198.5240, validation loss: 0.4756
2024-06-03 01:10:37 [INFO]: Epoch 018 - training loss: 259110.4156, validation loss: 0.4628
2024-06-03 01:10:43 [INFO]: Epoch 019 - training loss: 259093.7771, validation loss: 0.4579
2024-06-03 01:10:49 [INFO]: Epoch 020 - training loss: 259167.8927, validation loss: 0.4588
2024-06-03 01:10:54 [INFO]: Epoch 021 - training loss: 259201.2698, validation loss: 0.4524
2024-06-03 01:11:00 [INFO]: Epoch 022 - training loss: 259115.5281, validation loss: 0.4550
2024-06-03 01:11:06 [INFO]: Epoch 023 - training loss: 259058.5938, validation loss: 0.4539
2024-06-03 01:11:11 [INFO]: Epoch 024 - training loss: 259040.1771, validation loss: 0.4542
2024-06-03 01:11:17 [INFO]: Epoch 025 - training loss: 259033.0365, validation loss: 0.4553
2024-06-03 01:11:23 [INFO]: Epoch 026 - training loss: 258985.6427, validation loss: 0.4586
2024-06-03 01:11:28 [INFO]: Epoch 027 - training loss: 259030.3958, validation loss: 0.4534
2024-06-03 01:11:34 [INFO]: Epoch 028 - training loss: 259022.0771, validation loss: 0.4514
2024-06-03 01:11:40 [INFO]: Epoch 029 - training loss: 259038.7531, validation loss: 0.4503
2024-06-03 01:11:46 [INFO]: Epoch 030 - training loss: 259021.3021, validation loss: 0.4568
2024-06-03 01:11:51 [INFO]: Epoch 031 - training loss: 259237.4302, validation loss: 0.4514
2024-06-03 01:11:56 [INFO]: Epoch 032 - training loss: 259275.8177, validation loss: 0.4485
2024-06-03 01:12:02 [INFO]: Epoch 033 - training loss: 259124.2125, validation loss: 0.4508
2024-06-03 01:12:07 [INFO]: Epoch 034 - training loss: 259044.0042, validation loss: 0.4482
2024-06-03 01:12:12 [INFO]: Epoch 035 - training loss: 258996.2760, validation loss: 0.4522
2024-06-03 01:12:18 [INFO]: Epoch 036 - training loss: 258967.1677, validation loss: 0.4547
2024-06-03 01:12:23 [INFO]: Epoch 037 - training loss: 258934.3510, validation loss: 0.4620
2024-06-03 01:12:29 [INFO]: Epoch 038 - training loss: 258956.0396, validation loss: 0.4680
2024-06-03 01:12:34 [INFO]: Epoch 039 - training loss: 258916.5292, validation loss: 0.4457
2024-06-03 01:12:39 [INFO]: Epoch 040 - training loss: 258867.0031, validation loss: 0.4485
2024-06-03 01:12:45 [INFO]: Epoch 041 - training loss: 258843.6594, validation loss: 0.4543
2024-06-03 01:12:50 [INFO]: Epoch 042 - training loss: 258862.9052, validation loss: 0.4453
2024-06-03 01:12:56 [INFO]: Epoch 043 - training loss: 258859.1656, validation loss: 0.4432
2024-06-03 01:13:01 [INFO]: Epoch 044 - training loss: 258844.4188, validation loss: 0.4470
2024-06-03 01:13:07 [INFO]: Epoch 045 - training loss: 258826.0573, validation loss: 0.4508
2024-06-03 01:13:13 [INFO]: Epoch 046 - training loss: 258835.8448, validation loss: 0.4480
2024-06-03 01:13:19 [INFO]: Epoch 047 - training loss: 258822.9823, validation loss: 0.4410
2024-06-03 01:13:24 [INFO]: Epoch 048 - training loss: 258781.1844, validation loss: 0.4419
2024-06-03 01:13:30 [INFO]: Epoch 049 - training loss: 258808.5312, validation loss: 0.4550
2024-06-03 01:13:36 [INFO]: Epoch 050 - training loss: 258798.3312, validation loss: 0.4406
2024-06-03 01:13:41 [INFO]: Epoch 051 - training loss: 258790.0042, validation loss: 0.4406
2024-06-03 01:13:47 [INFO]: Epoch 052 - training loss: 258774.5479, validation loss: 0.4450
2024-06-03 01:13:52 [INFO]: Epoch 053 - training loss: 258770.1604, validation loss: 0.4390
2024-06-03 01:13:58 [INFO]: Epoch 054 - training loss: 258740.3833, validation loss: 0.4405
2024-06-03 01:14:04 [INFO]: Epoch 055 - training loss: 258763.6031, validation loss: 0.4440
2024-06-03 01:14:09 [INFO]: Epoch 056 - training loss: 258765.7687, validation loss: 0.4423
2024-06-03 01:14:14 [INFO]: Epoch 057 - training loss: 258756.0427, validation loss: 0.4354
2024-06-03 01:14:20 [INFO]: Epoch 058 - training loss: 258764.8125, validation loss: 0.4484
2024-06-03 01:14:26 [INFO]: Epoch 059 - training loss: 258760.0583, validation loss: 0.4390
2024-06-03 01:14:32 [INFO]: Epoch 060 - training loss: 258795.2781, validation loss: 0.4488
2024-06-03 01:14:37 [INFO]: Epoch 061 - training loss: 258851.1844, validation loss: 0.4414
2024-06-03 01:14:42 [INFO]: Epoch 062 - training loss: 258839.9438, validation loss: 0.4359
2024-06-03 01:14:48 [INFO]: Epoch 063 - training loss: 258824.9104, validation loss: 0.4472
2024-06-03 01:14:53 [INFO]: Epoch 064 - training loss: 258804.6052, validation loss: 0.4408
2024-06-03 01:14:58 [INFO]: Epoch 065 - training loss: 258803.6948, validation loss: 0.4421
2024-06-03 01:15:03 [INFO]: Epoch 066 - training loss: 258784.9240, validation loss: 0.4422
2024-06-03 01:15:09 [INFO]: Epoch 067 - training loss: 258791.3292, validation loss: 0.4387
2024-06-03 01:15:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:15:09 [INFO]: Finished training. The best model is from epoch#57.
2024-06-03 01:15:09 [INFO]: Saved the model to results_point_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T010855/GPVAE.pypots
2024-06-03 01:15:53 [INFO]: Successfully saved to results_point_rate05/PeMS/GPVAE_PeMS/round_3/imputation.pkl
2024-06-03 01:15:53 [INFO]: Round3 - GPVAE on PeMS: MAE=0.3346, MSE=0.6110, MRE=0.4152
2024-06-03 01:15:53 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:15:53 [INFO]: Using the given device: cuda:0
2024-06-03 01:15:53 [INFO]: Model files will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T011553
2024-06-03 01:15:53 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T011553/tensorboard
2024-06-03 01:15:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 01:15:59 [INFO]: Epoch 001 - training loss: 642793.3833, validation loss: 1.1355
2024-06-03 01:16:04 [INFO]: Epoch 002 - training loss: 389951.1917, validation loss: 0.7369
2024-06-03 01:16:10 [INFO]: Epoch 003 - training loss: 284302.8667, validation loss: 0.5857
2024-06-03 01:16:15 [INFO]: Epoch 004 - training loss: 266840.7708, validation loss: 0.5420
2024-06-03 01:16:20 [INFO]: Epoch 005 - training loss: 262805.9031, validation loss: 0.5211
2024-06-03 01:16:25 [INFO]: Epoch 006 - training loss: 261298.8708, validation loss: 0.4952
2024-06-03 01:16:30 [INFO]: Epoch 007 - training loss: 260317.2177, validation loss: 0.4839
2024-06-03 01:16:35 [INFO]: Epoch 008 - training loss: 259909.3625, validation loss: 0.4900
2024-06-03 01:16:40 [INFO]: Epoch 009 - training loss: 259671.9521, validation loss: 0.4799
2024-06-03 01:16:44 [INFO]: Epoch 010 - training loss: 259501.5677, validation loss: 0.4769
2024-06-03 01:16:49 [INFO]: Epoch 011 - training loss: 259364.5948, validation loss: 0.4641
2024-06-03 01:16:54 [INFO]: Epoch 012 - training loss: 259276.0229, validation loss: 0.4679
2024-06-03 01:16:59 [INFO]: Epoch 013 - training loss: 259211.7656, validation loss: 0.4662
2024-06-03 01:17:04 [INFO]: Epoch 014 - training loss: 259180.9177, validation loss: 0.4665
2024-06-03 01:17:09 [INFO]: Epoch 015 - training loss: 259129.8500, validation loss: 0.4632
2024-06-03 01:17:13 [INFO]: Epoch 016 - training loss: 259104.5302, validation loss: 0.4726
2024-06-03 01:17:18 [INFO]: Epoch 017 - training loss: 259063.0844, validation loss: 0.4597
2024-06-03 01:17:23 [INFO]: Epoch 018 - training loss: 259055.4875, validation loss: 0.4587
2024-06-03 01:17:28 [INFO]: Epoch 019 - training loss: 259001.5115, validation loss: 0.4571
2024-06-03 01:17:32 [INFO]: Epoch 020 - training loss: 259008.0156, validation loss: 0.4711
2024-06-03 01:17:37 [INFO]: Epoch 021 - training loss: 258993.5135, validation loss: 0.4556
2024-06-03 01:17:42 [INFO]: Epoch 022 - training loss: 259036.1479, validation loss: 0.4544
2024-06-03 01:17:46 [INFO]: Epoch 023 - training loss: 259042.9885, validation loss: 0.4867
2024-06-03 01:17:51 [INFO]: Epoch 024 - training loss: 259051.8094, validation loss: 0.4617
2024-06-03 01:17:56 [INFO]: Epoch 025 - training loss: 259135.0448, validation loss: 0.4529
2024-06-03 01:18:01 [INFO]: Epoch 026 - training loss: 259283.8969, validation loss: 0.4540
2024-06-03 01:18:06 [INFO]: Epoch 027 - training loss: 259510.2458, validation loss: 0.4568
2024-06-03 01:18:11 [INFO]: Epoch 028 - training loss: 259204.4948, validation loss: 0.4663
2024-06-03 01:18:16 [INFO]: Epoch 029 - training loss: 259200.8729, validation loss: 0.4557
2024-06-03 01:18:20 [INFO]: Epoch 030 - training loss: 259059.6594, validation loss: 0.4555
2024-06-03 01:18:25 [INFO]: Epoch 031 - training loss: 259102.1885, validation loss: 0.4541
2024-06-03 01:18:29 [INFO]: Epoch 032 - training loss: 259086.9802, validation loss: 0.4576
2024-06-03 01:18:34 [INFO]: Epoch 033 - training loss: 259026.7156, validation loss: 0.4769
2024-06-03 01:18:39 [INFO]: Epoch 034 - training loss: 258998.5979, validation loss: 0.4600
2024-06-03 01:18:44 [INFO]: Epoch 035 - training loss: 258989.2979, validation loss: 0.4733
2024-06-03 01:18:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:18:44 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 01:18:44 [INFO]: Saved the model to results_point_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T011553/GPVAE.pypots
2024-06-03 01:19:20 [INFO]: Successfully saved to results_point_rate05/PeMS/GPVAE_PeMS/round_4/imputation.pkl
2024-06-03 01:19:20 [INFO]: Round4 - GPVAE on PeMS: MAE=0.3710, MSE=0.6428, MRE=0.4603
2024-06-03 01:19:20 [INFO]: Done! Final results:
Averaged GPVAE (2,396,536 params) on PeMS: MAE=0.3462 ± 0.015108713767916612, MSE=0.6173 ± 0.014883745499729949, MRE=0.4296 ± 0.01874863218120517, average inference time=9.52
