2024-06-03 00:45:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:45:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:08 [INFO]: Model files will be saved to results_point_rate05/PeMS/Informer_PeMS/round_0/20240603_T004508
2024-06-03 00:45:08 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Informer_PeMS/round_0/20240603_T004508/tensorboard
2024-06-03 00:45:10 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 00:45:26 [INFO]: Epoch 001 - training loss: 0.9440, validation loss: 0.5885
2024-06-03 00:45:32 [INFO]: Epoch 002 - training loss: 0.6263, validation loss: 0.5503
2024-06-03 00:45:38 [INFO]: Epoch 003 - training loss: 0.5706, validation loss: 0.5076
2024-06-03 00:45:45 [INFO]: Epoch 004 - training loss: 0.5330, validation loss: 0.5010
2024-06-03 00:45:50 [INFO]: Epoch 005 - training loss: 0.5177, validation loss: 0.4955
2024-06-03 00:45:56 [INFO]: Epoch 006 - training loss: 0.5037, validation loss: 0.4891
2024-06-03 00:46:02 [INFO]: Epoch 007 - training loss: 0.5006, validation loss: 0.4801
2024-06-03 00:46:09 [INFO]: Epoch 008 - training loss: 0.4929, validation loss: 0.4751
2024-06-03 00:46:15 [INFO]: Epoch 009 - training loss: 0.4849, validation loss: 0.4781
2024-06-03 00:46:21 [INFO]: Epoch 010 - training loss: 0.4719, validation loss: 0.4773
2024-06-03 00:46:26 [INFO]: Epoch 011 - training loss: 0.4633, validation loss: 0.4721
2024-06-03 00:46:32 [INFO]: Epoch 012 - training loss: 0.4546, validation loss: 0.4728
2024-06-03 00:46:38 [INFO]: Epoch 013 - training loss: 0.4486, validation loss: 0.4720
2024-06-03 00:46:43 [INFO]: Epoch 014 - training loss: 0.4441, validation loss: 0.4684
2024-06-03 00:46:49 [INFO]: Epoch 015 - training loss: 0.4396, validation loss: 0.4646
2024-06-03 00:46:54 [INFO]: Epoch 016 - training loss: 0.4326, validation loss: 0.4628
2024-06-03 00:47:00 [INFO]: Epoch 017 - training loss: 0.4288, validation loss: 0.4610
2024-06-03 00:47:06 [INFO]: Epoch 018 - training loss: 0.4234, validation loss: 0.4589
2024-06-03 00:47:12 [INFO]: Epoch 019 - training loss: 0.4150, validation loss: 0.4599
2024-06-03 00:47:19 [INFO]: Epoch 020 - training loss: 0.4118, validation loss: 0.4589
2024-06-03 00:47:25 [INFO]: Epoch 021 - training loss: 0.4092, validation loss: 0.4530
2024-06-03 00:47:31 [INFO]: Epoch 022 - training loss: 0.4061, validation loss: 0.4606
2024-06-03 00:47:37 [INFO]: Epoch 023 - training loss: 0.3987, validation loss: 0.4537
2024-06-03 00:47:42 [INFO]: Epoch 024 - training loss: 0.3956, validation loss: 0.4501
2024-06-03 00:47:48 [INFO]: Epoch 025 - training loss: 0.3935, validation loss: 0.4496
2024-06-03 00:47:54 [INFO]: Epoch 026 - training loss: 0.3879, validation loss: 0.4460
2024-06-03 00:48:00 [INFO]: Epoch 027 - training loss: 0.3856, validation loss: 0.4456
2024-06-03 00:48:05 [INFO]: Epoch 028 - training loss: 0.3830, validation loss: 0.4499
2024-06-03 00:48:11 [INFO]: Epoch 029 - training loss: 0.3795, validation loss: 0.4462
2024-06-03 00:48:17 [INFO]: Epoch 030 - training loss: 0.3798, validation loss: 0.4472
2024-06-03 00:48:23 [INFO]: Epoch 031 - training loss: 0.3692, validation loss: 0.4435
2024-06-03 00:48:29 [INFO]: Epoch 032 - training loss: 0.3630, validation loss: 0.4401
2024-06-03 00:48:35 [INFO]: Epoch 033 - training loss: 0.3689, validation loss: 0.4424
2024-06-03 00:48:41 [INFO]: Epoch 034 - training loss: 0.3666, validation loss: 0.4447
2024-06-03 00:48:46 [INFO]: Epoch 035 - training loss: 0.3618, validation loss: 0.4492
2024-06-03 00:48:52 [INFO]: Epoch 036 - training loss: 0.3623, validation loss: 0.4474
2024-06-03 00:48:59 [INFO]: Epoch 037 - training loss: 0.3565, validation loss: 0.4431
2024-06-03 00:49:04 [INFO]: Epoch 038 - training loss: 0.3566, validation loss: 0.4396
2024-06-03 00:49:10 [INFO]: Epoch 039 - training loss: 0.3518, validation loss: 0.4412
2024-06-03 00:49:16 [INFO]: Epoch 040 - training loss: 0.3461, validation loss: 0.4350
2024-06-03 00:49:21 [INFO]: Epoch 041 - training loss: 0.3430, validation loss: 0.4347
2024-06-03 00:49:26 [INFO]: Epoch 042 - training loss: 0.3454, validation loss: 0.4381
2024-06-03 00:49:31 [INFO]: Epoch 043 - training loss: 0.3446, validation loss: 0.4373
2024-06-03 00:49:37 [INFO]: Epoch 044 - training loss: 0.3460, validation loss: 0.4379
2024-06-03 00:49:43 [INFO]: Epoch 045 - training loss: 0.3440, validation loss: 0.4351
2024-06-03 00:49:49 [INFO]: Epoch 046 - training loss: 0.3383, validation loss: 0.4427
2024-06-03 00:49:54 [INFO]: Epoch 047 - training loss: 0.3391, validation loss: 0.4369
2024-06-03 00:50:00 [INFO]: Epoch 048 - training loss: 0.3307, validation loss: 0.4364
2024-06-03 00:50:07 [INFO]: Epoch 049 - training loss: 0.3327, validation loss: 0.4319
2024-06-03 00:50:13 [INFO]: Epoch 050 - training loss: 0.3298, validation loss: 0.4346
2024-06-03 00:50:19 [INFO]: Epoch 051 - training loss: 0.3287, validation loss: 0.4283
2024-06-03 00:50:25 [INFO]: Epoch 052 - training loss: 0.3302, validation loss: 0.4383
2024-06-03 00:50:31 [INFO]: Epoch 053 - training loss: 0.3267, validation loss: 0.4286
2024-06-03 00:50:37 [INFO]: Epoch 054 - training loss: 0.3256, validation loss: 0.4295
2024-06-03 00:50:42 [INFO]: Epoch 055 - training loss: 0.3255, validation loss: 0.4309
2024-06-03 00:50:47 [INFO]: Epoch 056 - training loss: 0.3254, validation loss: 0.4284
2024-06-03 00:50:53 [INFO]: Epoch 057 - training loss: 0.3245, validation loss: 0.4295
2024-06-03 00:50:58 [INFO]: Epoch 058 - training loss: 0.3213, validation loss: 0.4330
2024-06-03 00:51:04 [INFO]: Epoch 059 - training loss: 0.3238, validation loss: 0.4291
2024-06-03 00:51:09 [INFO]: Epoch 060 - training loss: 0.3190, validation loss: 0.4304
2024-06-03 00:51:14 [INFO]: Epoch 061 - training loss: 0.3217, validation loss: 0.4312
2024-06-03 00:51:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:51:14 [INFO]: Finished training. The best model is from epoch#51.
2024-06-03 00:51:15 [INFO]: Saved the model to results_point_rate05/PeMS/Informer_PeMS/round_0/20240603_T004508/Informer.pypots
2024-06-03 00:51:19 [INFO]: Successfully saved to results_point_rate05/PeMS/Informer_PeMS/round_0/imputation.pkl
2024-06-03 00:51:19 [INFO]: Round0 - Informer on PeMS: MAE=0.3283, MSE=0.6060, MRE=0.4074
2024-06-03 00:51:19 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:51:19 [INFO]: Using the given device: cuda:0
2024-06-03 00:51:19 [INFO]: Model files will be saved to results_point_rate05/PeMS/Informer_PeMS/round_1/20240603_T005119
2024-06-03 00:51:19 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Informer_PeMS/round_1/20240603_T005119/tensorboard
2024-06-03 00:51:20 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 00:51:25 [INFO]: Epoch 001 - training loss: 0.9323, validation loss: 0.5804
2024-06-03 00:51:31 [INFO]: Epoch 002 - training loss: 0.6332, validation loss: 0.5417
2024-06-03 00:51:37 [INFO]: Epoch 003 - training loss: 0.5700, validation loss: 0.5098
2024-06-03 00:51:43 [INFO]: Epoch 004 - training loss: 0.5423, validation loss: 0.5016
2024-06-03 00:51:48 [INFO]: Epoch 005 - training loss: 0.5225, validation loss: 0.4920
2024-06-03 00:51:53 [INFO]: Epoch 006 - training loss: 0.5152, validation loss: 0.4920
2024-06-03 00:51:58 [INFO]: Epoch 007 - training loss: 0.5024, validation loss: 0.4847
2024-06-03 00:52:03 [INFO]: Epoch 008 - training loss: 0.4920, validation loss: 0.4760
2024-06-03 00:52:08 [INFO]: Epoch 009 - training loss: 0.4814, validation loss: 0.4750
2024-06-03 00:52:12 [INFO]: Epoch 010 - training loss: 0.4715, validation loss: 0.4698
2024-06-03 00:52:17 [INFO]: Epoch 011 - training loss: 0.4623, validation loss: 0.4722
2024-06-03 00:52:23 [INFO]: Epoch 012 - training loss: 0.4550, validation loss: 0.4741
2024-06-03 00:52:28 [INFO]: Epoch 013 - training loss: 0.4479, validation loss: 0.4753
2024-06-03 00:52:33 [INFO]: Epoch 014 - training loss: 0.4428, validation loss: 0.4649
2024-06-03 00:52:38 [INFO]: Epoch 015 - training loss: 0.4358, validation loss: 0.4619
2024-06-03 00:52:43 [INFO]: Epoch 016 - training loss: 0.4307, validation loss: 0.4666
2024-06-03 00:52:48 [INFO]: Epoch 017 - training loss: 0.4265, validation loss: 0.4681
2024-06-03 00:52:54 [INFO]: Epoch 018 - training loss: 0.4219, validation loss: 0.4658
2024-06-03 00:52:58 [INFO]: Epoch 019 - training loss: 0.4138, validation loss: 0.4649
2024-06-03 00:53:03 [INFO]: Epoch 020 - training loss: 0.4191, validation loss: 0.4633
2024-06-03 00:53:09 [INFO]: Epoch 021 - training loss: 0.4114, validation loss: 0.4636
2024-06-03 00:53:15 [INFO]: Epoch 022 - training loss: 0.4003, validation loss: 0.4565
2024-06-03 00:53:20 [INFO]: Epoch 023 - training loss: 0.3958, validation loss: 0.4525
2024-06-03 00:53:24 [INFO]: Epoch 024 - training loss: 0.3912, validation loss: 0.4534
2024-06-03 00:53:29 [INFO]: Epoch 025 - training loss: 0.3881, validation loss: 0.4522
2024-06-03 00:53:34 [INFO]: Epoch 026 - training loss: 0.3858, validation loss: 0.4473
2024-06-03 00:53:39 [INFO]: Epoch 027 - training loss: 0.3779, validation loss: 0.4497
2024-06-03 00:53:43 [INFO]: Epoch 028 - training loss: 0.3763, validation loss: 0.4459
2024-06-03 00:53:48 [INFO]: Epoch 029 - training loss: 0.3739, validation loss: 0.4446
2024-06-03 00:53:53 [INFO]: Epoch 030 - training loss: 0.3756, validation loss: 0.4525
2024-06-03 00:53:58 [INFO]: Epoch 031 - training loss: 0.3705, validation loss: 0.4536
2024-06-03 00:54:03 [INFO]: Epoch 032 - training loss: 0.3683, validation loss: 0.4413
2024-06-03 00:54:08 [INFO]: Epoch 033 - training loss: 0.3649, validation loss: 0.4393
2024-06-03 00:54:13 [INFO]: Epoch 034 - training loss: 0.3602, validation loss: 0.4466
2024-06-03 00:54:18 [INFO]: Epoch 035 - training loss: 0.3591, validation loss: 0.4383
2024-06-03 00:54:23 [INFO]: Epoch 036 - training loss: 0.3612, validation loss: 0.4392
2024-06-03 00:54:28 [INFO]: Epoch 037 - training loss: 0.3544, validation loss: 0.4439
2024-06-03 00:54:33 [INFO]: Epoch 038 - training loss: 0.3530, validation loss: 0.4386
2024-06-03 00:54:37 [INFO]: Epoch 039 - training loss: 0.3478, validation loss: 0.4378
2024-06-03 00:54:42 [INFO]: Epoch 040 - training loss: 0.3520, validation loss: 0.4395
2024-06-03 00:54:47 [INFO]: Epoch 041 - training loss: 0.3490, validation loss: 0.4396
2024-06-03 00:54:52 [INFO]: Epoch 042 - training loss: 0.3445, validation loss: 0.4351
2024-06-03 00:54:57 [INFO]: Epoch 043 - training loss: 0.3398, validation loss: 0.4409
2024-06-03 00:55:02 [INFO]: Epoch 044 - training loss: 0.3406, validation loss: 0.4325
2024-06-03 00:55:06 [INFO]: Epoch 045 - training loss: 0.3396, validation loss: 0.4327
2024-06-03 00:55:11 [INFO]: Epoch 046 - training loss: 0.3380, validation loss: 0.4304
2024-06-03 00:55:15 [INFO]: Epoch 047 - training loss: 0.3352, validation loss: 0.4376
2024-06-03 00:55:20 [INFO]: Epoch 048 - training loss: 0.3341, validation loss: 0.4299
2024-06-03 00:55:25 [INFO]: Epoch 049 - training loss: 0.3343, validation loss: 0.4320
2024-06-03 00:55:30 [INFO]: Epoch 050 - training loss: 0.3309, validation loss: 0.4272
2024-06-03 00:55:35 [INFO]: Epoch 051 - training loss: 0.3297, validation loss: 0.4315
2024-06-03 00:55:40 [INFO]: Epoch 052 - training loss: 0.3320, validation loss: 0.4316
2024-06-03 00:55:45 [INFO]: Epoch 053 - training loss: 0.3243, validation loss: 0.4310
2024-06-03 00:55:50 [INFO]: Epoch 054 - training loss: 0.3221, validation loss: 0.4276
2024-06-03 00:55:55 [INFO]: Epoch 055 - training loss: 0.3248, validation loss: 0.4250
2024-06-03 00:56:00 [INFO]: Epoch 056 - training loss: 0.3214, validation loss: 0.4319
2024-06-03 00:56:04 [INFO]: Epoch 057 - training loss: 0.3212, validation loss: 0.4281
2024-06-03 00:56:09 [INFO]: Epoch 058 - training loss: 0.3180, validation loss: 0.4203
2024-06-03 00:56:13 [INFO]: Epoch 059 - training loss: 0.3205, validation loss: 0.4217
2024-06-03 00:56:18 [INFO]: Epoch 060 - training loss: 0.3198, validation loss: 0.4256
2024-06-03 00:56:23 [INFO]: Epoch 061 - training loss: 0.3196, validation loss: 0.4207
2024-06-03 00:56:27 [INFO]: Epoch 062 - training loss: 0.3123, validation loss: 0.4289
2024-06-03 00:56:32 [INFO]: Epoch 063 - training loss: 0.3136, validation loss: 0.4236
2024-06-03 00:56:38 [INFO]: Epoch 064 - training loss: 0.3122, validation loss: 0.4194
2024-06-03 00:56:43 [INFO]: Epoch 065 - training loss: 0.3170, validation loss: 0.4198
2024-06-03 00:56:48 [INFO]: Epoch 066 - training loss: 0.3136, validation loss: 0.4253
2024-06-03 00:56:52 [INFO]: Epoch 067 - training loss: 0.3146, validation loss: 0.4273
2024-06-03 00:56:58 [INFO]: Epoch 068 - training loss: 0.3102, validation loss: 0.4251
2024-06-03 00:57:03 [INFO]: Epoch 069 - training loss: 0.3069, validation loss: 0.4206
2024-06-03 00:57:07 [INFO]: Epoch 070 - training loss: 0.3080, validation loss: 0.4193
2024-06-03 00:57:12 [INFO]: Epoch 071 - training loss: 0.3052, validation loss: 0.4266
2024-06-03 00:57:17 [INFO]: Epoch 072 - training loss: 0.3069, validation loss: 0.4235
2024-06-03 00:57:22 [INFO]: Epoch 073 - training loss: 0.3033, validation loss: 0.4239
2024-06-03 00:57:27 [INFO]: Epoch 074 - training loss: 0.3038, validation loss: 0.4204
2024-06-03 00:57:32 [INFO]: Epoch 075 - training loss: 0.2988, validation loss: 0.4219
2024-06-03 00:57:37 [INFO]: Epoch 076 - training loss: 0.2995, validation loss: 0.4193
2024-06-03 00:57:42 [INFO]: Epoch 077 - training loss: 0.2994, validation loss: 0.4223
2024-06-03 00:57:47 [INFO]: Epoch 078 - training loss: 0.3018, validation loss: 0.4303
2024-06-03 00:57:52 [INFO]: Epoch 079 - training loss: 0.2989, validation loss: 0.4227
2024-06-03 00:57:58 [INFO]: Epoch 080 - training loss: 0.2976, validation loss: 0.4208
2024-06-03 00:57:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:57:58 [INFO]: Finished training. The best model is from epoch#70.
2024-06-03 00:57:58 [INFO]: Saved the model to results_point_rate05/PeMS/Informer_PeMS/round_1/20240603_T005119/Informer.pypots
2024-06-03 00:58:01 [INFO]: Successfully saved to results_point_rate05/PeMS/Informer_PeMS/round_1/imputation.pkl
2024-06-03 00:58:01 [INFO]: Round1 - Informer on PeMS: MAE=0.3223, MSE=0.5905, MRE=0.4000
2024-06-03 00:58:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 00:58:01 [INFO]: Using the given device: cuda:0
2024-06-03 00:58:01 [INFO]: Model files will be saved to results_point_rate05/PeMS/Informer_PeMS/round_2/20240603_T005801
2024-06-03 00:58:01 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Informer_PeMS/round_2/20240603_T005801/tensorboard
2024-06-03 00:58:01 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 00:58:06 [INFO]: Epoch 001 - training loss: 0.9407, validation loss: 0.5972
2024-06-03 00:58:11 [INFO]: Epoch 002 - training loss: 0.6298, validation loss: 0.5368
2024-06-03 00:58:16 [INFO]: Epoch 003 - training loss: 0.5776, validation loss: 0.5228
2024-06-03 00:58:21 [INFO]: Epoch 004 - training loss: 0.5444, validation loss: 0.5058
2024-06-03 00:58:25 [INFO]: Epoch 005 - training loss: 0.5222, validation loss: 0.4937
2024-06-03 00:58:29 [INFO]: Epoch 006 - training loss: 0.5136, validation loss: 0.4887
2024-06-03 00:58:34 [INFO]: Epoch 007 - training loss: 0.4979, validation loss: 0.4856
2024-06-03 00:58:39 [INFO]: Epoch 008 - training loss: 0.4894, validation loss: 0.4822
2024-06-03 00:58:44 [INFO]: Epoch 009 - training loss: 0.4818, validation loss: 0.4774
2024-06-03 00:58:49 [INFO]: Epoch 010 - training loss: 0.4682, validation loss: 0.4732
2024-06-03 00:58:54 [INFO]: Epoch 011 - training loss: 0.4616, validation loss: 0.4716
2024-06-03 00:58:59 [INFO]: Epoch 012 - training loss: 0.4596, validation loss: 0.4717
2024-06-03 00:59:04 [INFO]: Epoch 013 - training loss: 0.4501, validation loss: 0.4640
2024-06-03 00:59:09 [INFO]: Epoch 014 - training loss: 0.4448, validation loss: 0.4673
2024-06-03 00:59:14 [INFO]: Epoch 015 - training loss: 0.4345, validation loss: 0.4634
2024-06-03 00:59:18 [INFO]: Epoch 016 - training loss: 0.4294, validation loss: 0.4593
2024-06-03 00:59:23 [INFO]: Epoch 017 - training loss: 0.4245, validation loss: 0.4607
2024-06-03 00:59:28 [INFO]: Epoch 018 - training loss: 0.4236, validation loss: 0.4563
2024-06-03 00:59:33 [INFO]: Epoch 019 - training loss: 0.4147, validation loss: 0.4577
2024-06-03 00:59:38 [INFO]: Epoch 020 - training loss: 0.4082, validation loss: 0.4541
2024-06-03 00:59:43 [INFO]: Epoch 021 - training loss: 0.4017, validation loss: 0.4544
2024-06-03 00:59:48 [INFO]: Epoch 022 - training loss: 0.4015, validation loss: 0.4498
2024-06-03 00:59:53 [INFO]: Epoch 023 - training loss: 0.3945, validation loss: 0.4614
2024-06-03 00:59:58 [INFO]: Epoch 024 - training loss: 0.3930, validation loss: 0.4464
2024-06-03 01:00:03 [INFO]: Epoch 025 - training loss: 0.3851, validation loss: 0.4477
2024-06-03 01:00:08 [INFO]: Epoch 026 - training loss: 0.3816, validation loss: 0.4473
2024-06-03 01:00:12 [INFO]: Epoch 027 - training loss: 0.3801, validation loss: 0.4488
2024-06-03 01:00:17 [INFO]: Epoch 028 - training loss: 0.3821, validation loss: 0.4419
2024-06-03 01:00:23 [INFO]: Epoch 029 - training loss: 0.3736, validation loss: 0.4405
2024-06-03 01:00:28 [INFO]: Epoch 030 - training loss: 0.3650, validation loss: 0.4440
2024-06-03 01:00:34 [INFO]: Epoch 031 - training loss: 0.3678, validation loss: 0.4463
2024-06-03 01:00:39 [INFO]: Epoch 032 - training loss: 0.3756, validation loss: 0.4498
2024-06-03 01:00:44 [INFO]: Epoch 033 - training loss: 0.3631, validation loss: 0.4408
2024-06-03 01:00:48 [INFO]: Epoch 034 - training loss: 0.3591, validation loss: 0.4355
2024-06-03 01:00:53 [INFO]: Epoch 035 - training loss: 0.3565, validation loss: 0.4386
2024-06-03 01:00:58 [INFO]: Epoch 036 - training loss: 0.3530, validation loss: 0.4416
2024-06-03 01:01:03 [INFO]: Epoch 037 - training loss: 0.3532, validation loss: 0.4373
2024-06-03 01:01:07 [INFO]: Epoch 038 - training loss: 0.3457, validation loss: 0.4354
2024-06-03 01:01:12 [INFO]: Epoch 039 - training loss: 0.3468, validation loss: 0.4386
2024-06-03 01:01:16 [INFO]: Epoch 040 - training loss: 0.3473, validation loss: 0.4346
2024-06-03 01:01:21 [INFO]: Epoch 041 - training loss: 0.3461, validation loss: 0.4327
2024-06-03 01:01:25 [INFO]: Epoch 042 - training loss: 0.3412, validation loss: 0.4314
2024-06-03 01:01:30 [INFO]: Epoch 043 - training loss: 0.3398, validation loss: 0.4335
2024-06-03 01:01:35 [INFO]: Epoch 044 - training loss: 0.3390, validation loss: 0.4322
2024-06-03 01:01:39 [INFO]: Epoch 045 - training loss: 0.3381, validation loss: 0.4346
2024-06-03 01:01:44 [INFO]: Epoch 046 - training loss: 0.3446, validation loss: 0.4283
2024-06-03 01:01:49 [INFO]: Epoch 047 - training loss: 0.3350, validation loss: 0.4408
2024-06-03 01:01:54 [INFO]: Epoch 048 - training loss: 0.3306, validation loss: 0.4419
2024-06-03 01:01:58 [INFO]: Epoch 049 - training loss: 0.3347, validation loss: 0.4268
2024-06-03 01:02:02 [INFO]: Epoch 050 - training loss: 0.3287, validation loss: 0.4291
2024-06-03 01:02:06 [INFO]: Epoch 051 - training loss: 0.3334, validation loss: 0.4332
2024-06-03 01:02:11 [INFO]: Epoch 052 - training loss: 0.3275, validation loss: 0.4256
2024-06-03 01:02:16 [INFO]: Epoch 053 - training loss: 0.3251, validation loss: 0.4272
2024-06-03 01:02:21 [INFO]: Epoch 054 - training loss: 0.3264, validation loss: 0.4278
2024-06-03 01:02:25 [INFO]: Epoch 055 - training loss: 0.3260, validation loss: 0.4316
2024-06-03 01:02:30 [INFO]: Epoch 056 - training loss: 0.3235, validation loss: 0.4315
2024-06-03 01:02:35 [INFO]: Epoch 057 - training loss: 0.3203, validation loss: 0.4271
2024-06-03 01:02:40 [INFO]: Epoch 058 - training loss: 0.3225, validation loss: 0.4240
2024-06-03 01:02:45 [INFO]: Epoch 059 - training loss: 0.3208, validation loss: 0.4234
2024-06-03 01:02:50 [INFO]: Epoch 060 - training loss: 0.3195, validation loss: 0.4228
2024-06-03 01:02:55 [INFO]: Epoch 061 - training loss: 0.3182, validation loss: 0.4226
2024-06-03 01:03:00 [INFO]: Epoch 062 - training loss: 0.3141, validation loss: 0.4238
2024-06-03 01:03:05 [INFO]: Epoch 063 - training loss: 0.3114, validation loss: 0.4246
2024-06-03 01:03:10 [INFO]: Epoch 064 - training loss: 0.3161, validation loss: 0.4214
2024-06-03 01:03:14 [INFO]: Epoch 065 - training loss: 0.3120, validation loss: 0.4229
2024-06-03 01:03:19 [INFO]: Epoch 066 - training loss: 0.3107, validation loss: 0.4249
2024-06-03 01:03:24 [INFO]: Epoch 067 - training loss: 0.3087, validation loss: 0.4222
2024-06-03 01:03:29 [INFO]: Epoch 068 - training loss: 0.3085, validation loss: 0.4262
2024-06-03 01:03:33 [INFO]: Epoch 069 - training loss: 0.3084, validation loss: 0.4263
2024-06-03 01:03:38 [INFO]: Epoch 070 - training loss: 0.3084, validation loss: 0.4235
2024-06-03 01:03:43 [INFO]: Epoch 071 - training loss: 0.3091, validation loss: 0.4235
2024-06-03 01:03:48 [INFO]: Epoch 072 - training loss: 0.3092, validation loss: 0.4169
2024-06-03 01:03:53 [INFO]: Epoch 073 - training loss: 0.3041, validation loss: 0.4216
2024-06-03 01:03:59 [INFO]: Epoch 074 - training loss: 0.3007, validation loss: 0.4215
2024-06-03 01:04:03 [INFO]: Epoch 075 - training loss: 0.3008, validation loss: 0.4187
2024-06-03 01:04:08 [INFO]: Epoch 076 - training loss: 0.3005, validation loss: 0.4199
2024-06-03 01:04:13 [INFO]: Epoch 077 - training loss: 0.3009, validation loss: 0.4184
2024-06-03 01:04:18 [INFO]: Epoch 078 - training loss: 0.3003, validation loss: 0.4144
2024-06-03 01:04:23 [INFO]: Epoch 079 - training loss: 0.2982, validation loss: 0.4164
2024-06-03 01:04:28 [INFO]: Epoch 080 - training loss: 0.2986, validation loss: 0.4153
2024-06-03 01:04:33 [INFO]: Epoch 081 - training loss: 0.2984, validation loss: 0.4147
2024-06-03 01:04:38 [INFO]: Epoch 082 - training loss: 0.2971, validation loss: 0.4195
2024-06-03 01:04:43 [INFO]: Epoch 083 - training loss: 0.2945, validation loss: 0.4168
2024-06-03 01:04:47 [INFO]: Epoch 084 - training loss: 0.2931, validation loss: 0.4163
2024-06-03 01:04:52 [INFO]: Epoch 085 - training loss: 0.2944, validation loss: 0.4154
2024-06-03 01:04:57 [INFO]: Epoch 086 - training loss: 0.2962, validation loss: 0.4136
2024-06-03 01:05:02 [INFO]: Epoch 087 - training loss: 0.2967, validation loss: 0.4159
2024-06-03 01:05:08 [INFO]: Epoch 088 - training loss: 0.2964, validation loss: 0.4134
2024-06-03 01:05:12 [INFO]: Epoch 089 - training loss: 0.2962, validation loss: 0.4177
2024-06-03 01:05:18 [INFO]: Epoch 090 - training loss: 0.2945, validation loss: 0.4150
2024-06-03 01:05:23 [INFO]: Epoch 091 - training loss: 0.2929, validation loss: 0.4185
2024-06-03 01:05:27 [INFO]: Epoch 092 - training loss: 0.2896, validation loss: 0.4187
2024-06-03 01:05:32 [INFO]: Epoch 093 - training loss: 0.2854, validation loss: 0.4163
2024-06-03 01:05:37 [INFO]: Epoch 094 - training loss: 0.2854, validation loss: 0.4158
2024-06-03 01:05:42 [INFO]: Epoch 095 - training loss: 0.2856, validation loss: 0.4158
2024-06-03 01:05:47 [INFO]: Epoch 096 - training loss: 0.2861, validation loss: 0.4163
2024-06-03 01:05:52 [INFO]: Epoch 097 - training loss: 0.2845, validation loss: 0.4123
2024-06-03 01:05:56 [INFO]: Epoch 098 - training loss: 0.2847, validation loss: 0.4166
2024-06-03 01:06:01 [INFO]: Epoch 099 - training loss: 0.2880, validation loss: 0.4192
2024-06-03 01:06:06 [INFO]: Epoch 100 - training loss: 0.2839, validation loss: 0.4129
2024-06-03 01:06:06 [INFO]: Finished training. The best model is from epoch#97.
2024-06-03 01:06:06 [INFO]: Saved the model to results_point_rate05/PeMS/Informer_PeMS/round_2/20240603_T005801/Informer.pypots
2024-06-03 01:06:10 [INFO]: Successfully saved to results_point_rate05/PeMS/Informer_PeMS/round_2/imputation.pkl
2024-06-03 01:06:10 [INFO]: Round2 - Informer on PeMS: MAE=0.3312, MSE=0.5875, MRE=0.4110
2024-06-03 01:06:10 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:06:10 [INFO]: Using the given device: cuda:0
2024-06-03 01:06:10 [INFO]: Model files will be saved to results_point_rate05/PeMS/Informer_PeMS/round_3/20240603_T010610
2024-06-03 01:06:10 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Informer_PeMS/round_3/20240603_T010610/tensorboard
2024-06-03 01:06:10 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 01:06:16 [INFO]: Epoch 001 - training loss: 0.9342, validation loss: 0.5956
2024-06-03 01:06:20 [INFO]: Epoch 002 - training loss: 0.6207, validation loss: 0.5372
2024-06-03 01:06:25 [INFO]: Epoch 003 - training loss: 0.5651, validation loss: 0.5071
2024-06-03 01:06:30 [INFO]: Epoch 004 - training loss: 0.5347, validation loss: 0.5020
2024-06-03 01:06:35 [INFO]: Epoch 005 - training loss: 0.5206, validation loss: 0.4884
2024-06-03 01:06:40 [INFO]: Epoch 006 - training loss: 0.5096, validation loss: 0.4896
2024-06-03 01:06:46 [INFO]: Epoch 007 - training loss: 0.4965, validation loss: 0.4881
2024-06-03 01:06:50 [INFO]: Epoch 008 - training loss: 0.4889, validation loss: 0.4794
2024-06-03 01:06:55 [INFO]: Epoch 009 - training loss: 0.4749, validation loss: 0.4782
2024-06-03 01:07:00 [INFO]: Epoch 010 - training loss: 0.4682, validation loss: 0.4729
2024-06-03 01:07:04 [INFO]: Epoch 011 - training loss: 0.4600, validation loss: 0.4768
2024-06-03 01:07:09 [INFO]: Epoch 012 - training loss: 0.4511, validation loss: 0.4678
2024-06-03 01:07:14 [INFO]: Epoch 013 - training loss: 0.4467, validation loss: 0.4715
2024-06-03 01:07:19 [INFO]: Epoch 014 - training loss: 0.4434, validation loss: 0.4758
2024-06-03 01:07:23 [INFO]: Epoch 015 - training loss: 0.4353, validation loss: 0.4707
2024-06-03 01:07:27 [INFO]: Epoch 016 - training loss: 0.4305, validation loss: 0.4723
2024-06-03 01:07:32 [INFO]: Epoch 017 - training loss: 0.4342, validation loss: 0.4621
2024-06-03 01:07:37 [INFO]: Epoch 018 - training loss: 0.4229, validation loss: 0.4619
2024-06-03 01:07:42 [INFO]: Epoch 019 - training loss: 0.4160, validation loss: 0.4648
2024-06-03 01:07:47 [INFO]: Epoch 020 - training loss: 0.4092, validation loss: 0.4601
2024-06-03 01:07:51 [INFO]: Epoch 021 - training loss: 0.4061, validation loss: 0.4568
2024-06-03 01:07:57 [INFO]: Epoch 022 - training loss: 0.4042, validation loss: 0.4590
2024-06-03 01:08:01 [INFO]: Epoch 023 - training loss: 0.4015, validation loss: 0.4570
2024-06-03 01:08:06 [INFO]: Epoch 024 - training loss: 0.3923, validation loss: 0.4499
2024-06-03 01:08:11 [INFO]: Epoch 025 - training loss: 0.3915, validation loss: 0.4705
2024-06-03 01:08:16 [INFO]: Epoch 026 - training loss: 0.3875, validation loss: 0.4544
2024-06-03 01:08:20 [INFO]: Epoch 027 - training loss: 0.3799, validation loss: 0.4522
2024-06-03 01:08:24 [INFO]: Epoch 028 - training loss: 0.3739, validation loss: 0.4466
2024-06-03 01:08:29 [INFO]: Epoch 029 - training loss: 0.3715, validation loss: 0.4472
2024-06-03 01:08:34 [INFO]: Epoch 030 - training loss: 0.3739, validation loss: 0.4499
2024-06-03 01:08:39 [INFO]: Epoch 031 - training loss: 0.3718, validation loss: 0.4509
2024-06-03 01:08:44 [INFO]: Epoch 032 - training loss: 0.3653, validation loss: 0.4484
2024-06-03 01:08:48 [INFO]: Epoch 033 - training loss: 0.3640, validation loss: 0.4449
2024-06-03 01:08:53 [INFO]: Epoch 034 - training loss: 0.3646, validation loss: 0.4478
2024-06-03 01:08:57 [INFO]: Epoch 035 - training loss: 0.3633, validation loss: 0.4434
2024-06-03 01:09:01 [INFO]: Epoch 036 - training loss: 0.3564, validation loss: 0.4429
2024-06-03 01:09:06 [INFO]: Epoch 037 - training loss: 0.3575, validation loss: 0.4411
2024-06-03 01:09:10 [INFO]: Epoch 038 - training loss: 0.3480, validation loss: 0.4413
2024-06-03 01:09:15 [INFO]: Epoch 039 - training loss: 0.3518, validation loss: 0.4473
2024-06-03 01:09:20 [INFO]: Epoch 040 - training loss: 0.3448, validation loss: 0.4394
2024-06-03 01:09:25 [INFO]: Epoch 041 - training loss: 0.3414, validation loss: 0.4364
2024-06-03 01:09:30 [INFO]: Epoch 042 - training loss: 0.3501, validation loss: 0.4424
2024-06-03 01:09:33 [INFO]: Epoch 043 - training loss: 0.3565, validation loss: 0.4469
2024-06-03 01:09:38 [INFO]: Epoch 044 - training loss: 0.3461, validation loss: 0.4480
2024-06-03 01:09:43 [INFO]: Epoch 045 - training loss: 0.3420, validation loss: 0.4478
2024-06-03 01:09:48 [INFO]: Epoch 046 - training loss: 0.3374, validation loss: 0.4433
2024-06-03 01:09:53 [INFO]: Epoch 047 - training loss: 0.3335, validation loss: 0.4386
2024-06-03 01:09:57 [INFO]: Epoch 048 - training loss: 0.3325, validation loss: 0.4492
2024-06-03 01:10:02 [INFO]: Epoch 049 - training loss: 0.3322, validation loss: 0.4424
2024-06-03 01:10:07 [INFO]: Epoch 050 - training loss: 0.3264, validation loss: 0.4393
2024-06-03 01:10:12 [INFO]: Epoch 051 - training loss: 0.3283, validation loss: 0.4381
2024-06-03 01:10:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:10:12 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 01:10:12 [INFO]: Saved the model to results_point_rate05/PeMS/Informer_PeMS/round_3/20240603_T010610/Informer.pypots
2024-06-03 01:10:16 [INFO]: Successfully saved to results_point_rate05/PeMS/Informer_PeMS/round_3/imputation.pkl
2024-06-03 01:10:16 [INFO]: Round3 - Informer on PeMS: MAE=0.3274, MSE=0.6064, MRE=0.4063
2024-06-03 01:10:16 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:10:16 [INFO]: Using the given device: cuda:0
2024-06-03 01:10:16 [INFO]: Model files will be saved to results_point_rate05/PeMS/Informer_PeMS/round_4/20240603_T011016
2024-06-03 01:10:16 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Informer_PeMS/round_4/20240603_T011016/tensorboard
2024-06-03 01:10:16 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 01:10:21 [INFO]: Epoch 001 - training loss: 0.9499, validation loss: 0.5987
2024-06-03 01:10:26 [INFO]: Epoch 002 - training loss: 0.6346, validation loss: 0.5350
2024-06-03 01:10:31 [INFO]: Epoch 003 - training loss: 0.5771, validation loss: 0.5074
2024-06-03 01:10:35 [INFO]: Epoch 004 - training loss: 0.5368, validation loss: 0.5021
2024-06-03 01:10:41 [INFO]: Epoch 005 - training loss: 0.5216, validation loss: 0.4906
2024-06-03 01:10:46 [INFO]: Epoch 006 - training loss: 0.5116, validation loss: 0.4938
2024-06-03 01:10:51 [INFO]: Epoch 007 - training loss: 0.5006, validation loss: 0.4874
2024-06-03 01:10:56 [INFO]: Epoch 008 - training loss: 0.4857, validation loss: 0.4864
2024-06-03 01:11:00 [INFO]: Epoch 009 - training loss: 0.4739, validation loss: 0.4797
2024-06-03 01:11:05 [INFO]: Epoch 010 - training loss: 0.4642, validation loss: 0.4784
2024-06-03 01:11:10 [INFO]: Epoch 011 - training loss: 0.4584, validation loss: 0.4713
2024-06-03 01:11:15 [INFO]: Epoch 012 - training loss: 0.4484, validation loss: 0.4706
2024-06-03 01:11:20 [INFO]: Epoch 013 - training loss: 0.4476, validation loss: 0.4808
2024-06-03 01:11:25 [INFO]: Epoch 014 - training loss: 0.4421, validation loss: 0.4628
2024-06-03 01:11:30 [INFO]: Epoch 015 - training loss: 0.4383, validation loss: 0.4666
2024-06-03 01:11:35 [INFO]: Epoch 016 - training loss: 0.4317, validation loss: 0.4762
2024-06-03 01:11:40 [INFO]: Epoch 017 - training loss: 0.4304, validation loss: 0.4670
2024-06-03 01:11:45 [INFO]: Epoch 018 - training loss: 0.4254, validation loss: 0.4627
2024-06-03 01:11:50 [INFO]: Epoch 019 - training loss: 0.4152, validation loss: 0.4665
2024-06-03 01:11:55 [INFO]: Epoch 020 - training loss: 0.4127, validation loss: 0.4685
2024-06-03 01:12:00 [INFO]: Epoch 021 - training loss: 0.4102, validation loss: 0.4553
2024-06-03 01:12:05 [INFO]: Epoch 022 - training loss: 0.4009, validation loss: 0.4534
2024-06-03 01:12:09 [INFO]: Epoch 023 - training loss: 0.3998, validation loss: 0.4603
2024-06-03 01:12:14 [INFO]: Epoch 024 - training loss: 0.3981, validation loss: 0.4480
2024-06-03 01:12:20 [INFO]: Epoch 025 - training loss: 0.3928, validation loss: 0.4527
2024-06-03 01:12:24 [INFO]: Epoch 026 - training loss: 0.3954, validation loss: 0.4529
2024-06-03 01:12:29 [INFO]: Epoch 027 - training loss: 0.3836, validation loss: 0.4487
2024-06-03 01:12:33 [INFO]: Epoch 028 - training loss: 0.3787, validation loss: 0.4560
2024-06-03 01:12:38 [INFO]: Epoch 029 - training loss: 0.3794, validation loss: 0.4504
2024-06-03 01:12:43 [INFO]: Epoch 030 - training loss: 0.3729, validation loss: 0.4491
2024-06-03 01:12:48 [INFO]: Epoch 031 - training loss: 0.3698, validation loss: 0.4420
2024-06-03 01:12:53 [INFO]: Epoch 032 - training loss: 0.3642, validation loss: 0.4437
2024-06-03 01:12:58 [INFO]: Epoch 033 - training loss: 0.3636, validation loss: 0.4441
2024-06-03 01:13:03 [INFO]: Epoch 034 - training loss: 0.3647, validation loss: 0.4458
2024-06-03 01:13:07 [INFO]: Epoch 035 - training loss: 0.3629, validation loss: 0.4514
2024-06-03 01:13:12 [INFO]: Epoch 036 - training loss: 0.3549, validation loss: 0.4401
2024-06-03 01:13:17 [INFO]: Epoch 037 - training loss: 0.3540, validation loss: 0.4394
2024-06-03 01:13:21 [INFO]: Epoch 038 - training loss: 0.3508, validation loss: 0.4350
2024-06-03 01:13:26 [INFO]: Epoch 039 - training loss: 0.3520, validation loss: 0.4406
2024-06-03 01:13:30 [INFO]: Epoch 040 - training loss: 0.3511, validation loss: 0.4409
2024-06-03 01:13:34 [INFO]: Epoch 041 - training loss: 0.3457, validation loss: 0.4416
2024-06-03 01:13:39 [INFO]: Epoch 042 - training loss: 0.3434, validation loss: 0.4414
2024-06-03 01:13:44 [INFO]: Epoch 043 - training loss: 0.3422, validation loss: 0.4374
2024-06-03 01:13:48 [INFO]: Epoch 044 - training loss: 0.3480, validation loss: 0.4383
2024-06-03 01:13:53 [INFO]: Epoch 045 - training loss: 0.3399, validation loss: 0.4430
2024-06-03 01:13:57 [INFO]: Epoch 046 - training loss: 0.3387, validation loss: 0.4375
2024-06-03 01:14:03 [INFO]: Epoch 047 - training loss: 0.3352, validation loss: 0.4304
2024-06-03 01:14:08 [INFO]: Epoch 048 - training loss: 0.3343, validation loss: 0.4365
2024-06-03 01:14:12 [INFO]: Epoch 049 - training loss: 0.3333, validation loss: 0.4347
2024-06-03 01:14:17 [INFO]: Epoch 050 - training loss: 0.3288, validation loss: 0.4319
2024-06-03 01:14:22 [INFO]: Epoch 051 - training loss: 0.3321, validation loss: 0.4418
2024-06-03 01:14:26 [INFO]: Epoch 052 - training loss: 0.3289, validation loss: 0.4338
2024-06-03 01:14:31 [INFO]: Epoch 053 - training loss: 0.3283, validation loss: 0.4348
2024-06-03 01:14:36 [INFO]: Epoch 054 - training loss: 0.3238, validation loss: 0.4303
2024-06-03 01:14:41 [INFO]: Epoch 055 - training loss: 0.3223, validation loss: 0.4257
2024-06-03 01:14:46 [INFO]: Epoch 056 - training loss: 0.3208, validation loss: 0.4312
2024-06-03 01:14:52 [INFO]: Epoch 057 - training loss: 0.3210, validation loss: 0.4292
2024-06-03 01:14:56 [INFO]: Epoch 058 - training loss: 0.3179, validation loss: 0.4323
2024-06-03 01:15:01 [INFO]: Epoch 059 - training loss: 0.3191, validation loss: 0.4269
2024-06-03 01:15:06 [INFO]: Epoch 060 - training loss: 0.3179, validation loss: 0.4328
2024-06-03 01:15:11 [INFO]: Epoch 061 - training loss: 0.3130, validation loss: 0.4318
2024-06-03 01:15:16 [INFO]: Epoch 062 - training loss: 0.3164, validation loss: 0.4322
2024-06-03 01:15:20 [INFO]: Epoch 063 - training loss: 0.3158, validation loss: 0.4217
2024-06-03 01:15:25 [INFO]: Epoch 064 - training loss: 0.3199, validation loss: 0.4288
2024-06-03 01:15:30 [INFO]: Epoch 065 - training loss: 0.3171, validation loss: 0.4270
2024-06-03 01:15:34 [INFO]: Epoch 066 - training loss: 0.3160, validation loss: 0.4316
2024-06-03 01:15:39 [INFO]: Epoch 067 - training loss: 0.3089, validation loss: 0.4333
2024-06-03 01:15:44 [INFO]: Epoch 068 - training loss: 0.3080, validation loss: 0.4302
2024-06-03 01:15:48 [INFO]: Epoch 069 - training loss: 0.3068, validation loss: 0.4317
2024-06-03 01:15:53 [INFO]: Epoch 070 - training loss: 0.3061, validation loss: 0.4290
2024-06-03 01:15:58 [INFO]: Epoch 071 - training loss: 0.3072, validation loss: 0.4293
2024-06-03 01:16:03 [INFO]: Epoch 072 - training loss: 0.3034, validation loss: 0.4256
2024-06-03 01:16:08 [INFO]: Epoch 073 - training loss: 0.3017, validation loss: 0.4342
2024-06-03 01:16:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:16:08 [INFO]: Finished training. The best model is from epoch#63.
2024-06-03 01:16:08 [INFO]: Saved the model to results_point_rate05/PeMS/Informer_PeMS/round_4/20240603_T011016/Informer.pypots
2024-06-03 01:16:11 [INFO]: Successfully saved to results_point_rate05/PeMS/Informer_PeMS/round_4/imputation.pkl
2024-06-03 01:16:11 [INFO]: Round4 - Informer on PeMS: MAE=0.3383, MSE=0.6084, MRE=0.4198
2024-06-03 01:16:11 [INFO]: Done! Final results:
Averaged Informer (13,149,022 params) on PeMS: MAE=0.3295 ± 0.0052269363418380186, MSE=0.5997 ± 0.008876834900619923, MRE=0.4089 ± 0.006486184622531787, average inference time=0.81
