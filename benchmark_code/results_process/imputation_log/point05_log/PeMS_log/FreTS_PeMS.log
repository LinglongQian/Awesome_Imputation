2024-06-02 19:38:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:38:47 [INFO]: Using the given device: cuda:0
2024-06-02 19:38:47 [INFO]: Model files will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_0/20240602_T193847
2024-06-02 19:38:47 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_0/20240602_T193847/tensorboard
2024-06-02 19:38:48 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-02 19:38:52 [INFO]: Epoch 001 - training loss: 1.1870, validation loss: 0.8761
2024-06-02 19:38:55 [INFO]: Epoch 002 - training loss: 0.7624, validation loss: 0.7039
2024-06-02 19:38:58 [INFO]: Epoch 003 - training loss: 0.6521, validation loss: 0.6635
2024-06-02 19:39:01 [INFO]: Epoch 004 - training loss: 0.5858, validation loss: 0.6018
2024-06-02 19:39:04 [INFO]: Epoch 005 - training loss: 0.5816, validation loss: 0.5946
2024-06-02 19:39:07 [INFO]: Epoch 006 - training loss: 0.5489, validation loss: 0.5991
2024-06-02 19:39:11 [INFO]: Epoch 007 - training loss: 0.5299, validation loss: 0.5782
2024-06-02 19:39:14 [INFO]: Epoch 008 - training loss: 0.5150, validation loss: 0.5780
2024-06-02 19:39:17 [INFO]: Epoch 009 - training loss: 0.5057, validation loss: 0.5441
2024-06-02 19:39:21 [INFO]: Epoch 010 - training loss: 0.4877, validation loss: 0.5455
2024-06-02 19:39:24 [INFO]: Epoch 011 - training loss: 0.4758, validation loss: 0.5542
2024-06-02 19:39:27 [INFO]: Epoch 012 - training loss: 0.4721, validation loss: 0.5497
2024-06-02 19:39:31 [INFO]: Epoch 013 - training loss: 0.4670, validation loss: 0.5218
2024-06-02 19:39:34 [INFO]: Epoch 014 - training loss: 0.4616, validation loss: 0.5420
2024-06-02 19:39:38 [INFO]: Epoch 015 - training loss: 0.4554, validation loss: 0.5051
2024-06-02 19:39:41 [INFO]: Epoch 016 - training loss: 0.4605, validation loss: 0.5729
2024-06-02 19:39:44 [INFO]: Epoch 017 - training loss: 0.4508, validation loss: 0.5169
2024-06-02 19:39:48 [INFO]: Epoch 018 - training loss: 0.4384, validation loss: 0.5459
2024-06-02 19:39:51 [INFO]: Epoch 019 - training loss: 0.4399, validation loss: 0.5363
2024-06-02 19:39:54 [INFO]: Epoch 020 - training loss: 0.4226, validation loss: 0.5230
2024-06-02 19:39:57 [INFO]: Epoch 021 - training loss: 0.4195, validation loss: 0.5015
2024-06-02 19:40:01 [INFO]: Epoch 022 - training loss: 0.4153, validation loss: 0.5058
2024-06-02 19:40:04 [INFO]: Epoch 023 - training loss: 0.4189, validation loss: 0.4974
2024-06-02 19:40:07 [INFO]: Epoch 024 - training loss: 0.4118, validation loss: 0.5020
2024-06-02 19:40:10 [INFO]: Epoch 025 - training loss: 0.4037, validation loss: 0.4961
2024-06-02 19:40:14 [INFO]: Epoch 026 - training loss: 0.4006, validation loss: 0.5027
2024-06-02 19:40:17 [INFO]: Epoch 027 - training loss: 0.3939, validation loss: 0.4966
2024-06-02 19:40:20 [INFO]: Epoch 028 - training loss: 0.3939, validation loss: 0.4915
2024-06-02 19:40:24 [INFO]: Epoch 029 - training loss: 0.3952, validation loss: 0.4881
2024-06-02 19:40:27 [INFO]: Epoch 030 - training loss: 0.3935, validation loss: 0.5037
2024-06-02 19:40:31 [INFO]: Epoch 031 - training loss: 0.3941, validation loss: 0.4772
2024-06-02 19:40:34 [INFO]: Epoch 032 - training loss: 0.3865, validation loss: 0.5052
2024-06-02 19:40:37 [INFO]: Epoch 033 - training loss: 0.3998, validation loss: 0.5206
2024-06-02 19:40:40 [INFO]: Epoch 034 - training loss: 0.4010, validation loss: 0.5056
2024-06-02 19:40:43 [INFO]: Epoch 035 - training loss: 0.3871, validation loss: 0.5104
2024-06-02 19:40:47 [INFO]: Epoch 036 - training loss: 0.3805, validation loss: 0.5058
2024-06-02 19:40:50 [INFO]: Epoch 037 - training loss: 0.3834, validation loss: 0.4886
2024-06-02 19:40:53 [INFO]: Epoch 038 - training loss: 0.3846, validation loss: 0.4718
2024-06-02 19:40:57 [INFO]: Epoch 039 - training loss: 0.3803, validation loss: 0.4846
2024-06-02 19:41:00 [INFO]: Epoch 040 - training loss: 0.3705, validation loss: 0.4722
2024-06-02 19:41:03 [INFO]: Epoch 041 - training loss: 0.3722, validation loss: 0.4857
2024-06-02 19:41:06 [INFO]: Epoch 042 - training loss: 0.3731, validation loss: 0.4760
2024-06-02 19:41:10 [INFO]: Epoch 043 - training loss: 0.3749, validation loss: 0.4747
2024-06-02 19:41:13 [INFO]: Epoch 044 - training loss: 0.3800, validation loss: 0.4895
2024-06-02 19:41:16 [INFO]: Epoch 045 - training loss: 0.3742, validation loss: 0.4705
2024-06-02 19:41:20 [INFO]: Epoch 046 - training loss: 0.3647, validation loss: 0.4671
2024-06-02 19:41:23 [INFO]: Epoch 047 - training loss: 0.3644, validation loss: 0.4758
2024-06-02 19:41:27 [INFO]: Epoch 048 - training loss: 0.3614, validation loss: 0.4851
2024-06-02 19:41:30 [INFO]: Epoch 049 - training loss: 0.3676, validation loss: 0.4780
2024-06-02 19:41:33 [INFO]: Epoch 050 - training loss: 0.3625, validation loss: 0.4788
2024-06-02 19:41:36 [INFO]: Epoch 051 - training loss: 0.3514, validation loss: 0.4629
2024-06-02 19:41:39 [INFO]: Epoch 052 - training loss: 0.3554, validation loss: 0.4774
2024-06-02 19:41:42 [INFO]: Epoch 053 - training loss: 0.3500, validation loss: 0.4853
2024-06-02 19:41:46 [INFO]: Epoch 054 - training loss: 0.3584, validation loss: 0.4698
2024-06-02 19:41:49 [INFO]: Epoch 055 - training loss: 0.3654, validation loss: 0.4699
2024-06-02 19:41:52 [INFO]: Epoch 056 - training loss: 0.3649, validation loss: 0.4813
2024-06-02 19:41:56 [INFO]: Epoch 057 - training loss: 0.3637, validation loss: 0.4725
2024-06-02 19:41:59 [INFO]: Epoch 058 - training loss: 0.3542, validation loss: 0.4755
2024-06-02 19:42:03 [INFO]: Epoch 059 - training loss: 0.3477, validation loss: 0.4844
2024-06-02 19:42:06 [INFO]: Epoch 060 - training loss: 0.3485, validation loss: 0.4770
2024-06-02 19:42:09 [INFO]: Epoch 061 - training loss: 0.3427, validation loss: 0.4822
2024-06-02 19:42:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:42:09 [INFO]: Finished training. The best model is from epoch#51.
2024-06-02 19:42:09 [INFO]: Saved the model to results_point_rate05/PeMS/FreTS_PeMS/round_0/20240602_T193847/FreTS.pypots
2024-06-02 19:42:10 [INFO]: Successfully saved to results_point_rate05/PeMS/FreTS_PeMS/round_0/imputation.pkl
2024-06-02 19:42:10 [INFO]: Round0 - FreTS on PeMS: MAE=0.4101, MSE=0.6687, MRE=0.5089
2024-06-02 19:42:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:42:10 [INFO]: Using the given device: cuda:0
2024-06-02 19:42:10 [INFO]: Model files will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_1/20240602_T194210
2024-06-02 19:42:10 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_1/20240602_T194210/tensorboard
2024-06-02 19:42:10 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-02 19:42:14 [INFO]: Epoch 001 - training loss: 1.1235, validation loss: 0.8526
2024-06-02 19:42:17 [INFO]: Epoch 002 - training loss: 0.7205, validation loss: 0.6765
2024-06-02 19:42:20 [INFO]: Epoch 003 - training loss: 0.6298, validation loss: 0.6343
2024-06-02 19:42:24 [INFO]: Epoch 004 - training loss: 0.5887, validation loss: 0.6416
2024-06-02 19:42:27 [INFO]: Epoch 005 - training loss: 0.5728, validation loss: 0.6261
2024-06-02 19:42:30 [INFO]: Epoch 006 - training loss: 0.5435, validation loss: 0.6179
2024-06-02 19:42:33 [INFO]: Epoch 007 - training loss: 0.5238, validation loss: 0.6021
2024-06-02 19:42:36 [INFO]: Epoch 008 - training loss: 0.5068, validation loss: 0.5676
2024-06-02 19:42:40 [INFO]: Epoch 009 - training loss: 0.4928, validation loss: 0.5713
2024-06-02 19:42:43 [INFO]: Epoch 010 - training loss: 0.4851, validation loss: 0.5470
2024-06-02 19:42:46 [INFO]: Epoch 011 - training loss: 0.4794, validation loss: 0.5586
2024-06-02 19:42:50 [INFO]: Epoch 012 - training loss: 0.4714, validation loss: 0.5824
2024-06-02 19:42:53 [INFO]: Epoch 013 - training loss: 0.4677, validation loss: 0.5504
2024-06-02 19:42:56 [INFO]: Epoch 014 - training loss: 0.4503, validation loss: 0.5380
2024-06-02 19:42:59 [INFO]: Epoch 015 - training loss: 0.4452, validation loss: 0.5624
2024-06-02 19:43:03 [INFO]: Epoch 016 - training loss: 0.4573, validation loss: 0.5596
2024-06-02 19:43:06 [INFO]: Epoch 017 - training loss: 0.4401, validation loss: 0.5243
2024-06-02 19:43:09 [INFO]: Epoch 018 - training loss: 0.4315, validation loss: 0.5356
2024-06-02 19:43:12 [INFO]: Epoch 019 - training loss: 0.4335, validation loss: 0.5373
2024-06-02 19:43:16 [INFO]: Epoch 020 - training loss: 0.4256, validation loss: 0.5382
2024-06-02 19:43:19 [INFO]: Epoch 021 - training loss: 0.4206, validation loss: 0.5516
2024-06-02 19:43:22 [INFO]: Epoch 022 - training loss: 0.4153, validation loss: 0.5346
2024-06-02 19:43:25 [INFO]: Epoch 023 - training loss: 0.4055, validation loss: 0.5116
2024-06-02 19:43:28 [INFO]: Epoch 024 - training loss: 0.4114, validation loss: 0.5187
2024-06-02 19:43:31 [INFO]: Epoch 025 - training loss: 0.4064, validation loss: 0.5020
2024-06-02 19:43:34 [INFO]: Epoch 026 - training loss: 0.4097, validation loss: 0.5028
2024-06-02 19:43:37 [INFO]: Epoch 027 - training loss: 0.4020, validation loss: 0.5145
2024-06-02 19:43:41 [INFO]: Epoch 028 - training loss: 0.4044, validation loss: 0.5469
2024-06-02 19:43:44 [INFO]: Epoch 029 - training loss: 0.3945, validation loss: 0.5204
2024-06-02 19:43:47 [INFO]: Epoch 030 - training loss: 0.3942, validation loss: 0.5001
2024-06-02 19:43:51 [INFO]: Epoch 031 - training loss: 0.3872, validation loss: 0.5167
2024-06-02 19:43:54 [INFO]: Epoch 032 - training loss: 0.3892, validation loss: 0.4928
2024-06-02 19:43:57 [INFO]: Epoch 033 - training loss: 0.3842, validation loss: 0.5070
2024-06-02 19:44:01 [INFO]: Epoch 034 - training loss: 0.3748, validation loss: 0.5037
2024-06-02 19:44:04 [INFO]: Epoch 035 - training loss: 0.3828, validation loss: 0.5000
2024-06-02 19:44:07 [INFO]: Epoch 036 - training loss: 0.3768, validation loss: 0.5018
2024-06-02 19:44:10 [INFO]: Epoch 037 - training loss: 0.3717, validation loss: 0.5354
2024-06-02 19:44:13 [INFO]: Epoch 038 - training loss: 0.4014, validation loss: 0.5244
2024-06-02 19:44:17 [INFO]: Epoch 039 - training loss: 0.3885, validation loss: 0.5027
2024-06-02 19:44:20 [INFO]: Epoch 040 - training loss: 0.3703, validation loss: 0.5044
2024-06-02 19:44:23 [INFO]: Epoch 041 - training loss: 0.3710, validation loss: 0.5103
2024-06-02 19:44:27 [INFO]: Epoch 042 - training loss: 0.3754, validation loss: 0.4970
2024-06-02 19:44:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:44:27 [INFO]: Finished training. The best model is from epoch#32.
2024-06-02 19:44:27 [INFO]: Saved the model to results_point_rate05/PeMS/FreTS_PeMS/round_1/20240602_T194210/FreTS.pypots
2024-06-02 19:44:28 [INFO]: Successfully saved to results_point_rate05/PeMS/FreTS_PeMS/round_1/imputation.pkl
2024-06-02 19:44:28 [INFO]: Round1 - FreTS on PeMS: MAE=0.4371, MSE=0.6985, MRE=0.5424
2024-06-02 19:44:28 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:44:28 [INFO]: Using the given device: cuda:0
2024-06-02 19:44:28 [INFO]: Model files will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_2/20240602_T194428
2024-06-02 19:44:28 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_2/20240602_T194428/tensorboard
2024-06-02 19:44:28 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-02 19:44:31 [INFO]: Epoch 001 - training loss: 1.0947, validation loss: 0.8374
2024-06-02 19:44:35 [INFO]: Epoch 002 - training loss: 0.7408, validation loss: 0.7229
2024-06-02 19:44:38 [INFO]: Epoch 003 - training loss: 0.6312, validation loss: 0.7019
2024-06-02 19:44:41 [INFO]: Epoch 004 - training loss: 0.6108, validation loss: 0.6720
2024-06-02 19:44:44 [INFO]: Epoch 005 - training loss: 0.5861, validation loss: 0.6292
2024-06-02 19:44:48 [INFO]: Epoch 006 - training loss: 0.5584, validation loss: 0.6122
2024-06-02 19:44:51 [INFO]: Epoch 007 - training loss: 0.5489, validation loss: 0.5706
2024-06-02 19:44:55 [INFO]: Epoch 008 - training loss: 0.5353, validation loss: 0.5976
2024-06-02 19:44:58 [INFO]: Epoch 009 - training loss: 0.5210, validation loss: 0.5696
2024-06-02 19:45:01 [INFO]: Epoch 010 - training loss: 0.4962, validation loss: 0.5546
2024-06-02 19:45:04 [INFO]: Epoch 011 - training loss: 0.5078, validation loss: 0.5534
2024-06-02 19:45:07 [INFO]: Epoch 012 - training loss: 0.4998, validation loss: 0.6055
2024-06-02 19:45:09 [INFO]: Epoch 013 - training loss: 0.4860, validation loss: 0.5487
2024-06-02 19:45:12 [INFO]: Epoch 014 - training loss: 0.4832, validation loss: 0.5798
2024-06-02 19:45:15 [INFO]: Epoch 015 - training loss: 0.4645, validation loss: 0.5339
2024-06-02 19:45:18 [INFO]: Epoch 016 - training loss: 0.4505, validation loss: 0.5403
2024-06-02 19:45:21 [INFO]: Epoch 017 - training loss: 0.4439, validation loss: 0.5275
2024-06-02 19:45:23 [INFO]: Epoch 018 - training loss: 0.4396, validation loss: 0.5428
2024-06-02 19:45:26 [INFO]: Epoch 019 - training loss: 0.4429, validation loss: 0.5359
2024-06-02 19:45:29 [INFO]: Epoch 020 - training loss: 0.4374, validation loss: 0.5398
2024-06-02 19:45:32 [INFO]: Epoch 021 - training loss: 0.4321, validation loss: 0.5249
2024-06-02 19:45:35 [INFO]: Epoch 022 - training loss: 0.4263, validation loss: 0.5388
2024-06-02 19:45:38 [INFO]: Epoch 023 - training loss: 0.4236, validation loss: 0.5216
2024-06-02 19:45:41 [INFO]: Epoch 024 - training loss: 0.4167, validation loss: 0.5291
2024-06-02 19:45:44 [INFO]: Epoch 025 - training loss: 0.4187, validation loss: 0.5228
2024-06-02 19:45:47 [INFO]: Epoch 026 - training loss: 0.4115, validation loss: 0.5151
2024-06-02 19:45:50 [INFO]: Epoch 027 - training loss: 0.4152, validation loss: 0.5280
2024-06-02 19:45:53 [INFO]: Epoch 028 - training loss: 0.4131, validation loss: 0.5274
2024-06-02 19:45:55 [INFO]: Epoch 029 - training loss: 0.4031, validation loss: 0.5188
2024-06-02 19:45:58 [INFO]: Epoch 030 - training loss: 0.3970, validation loss: 0.5248
2024-06-02 19:46:01 [INFO]: Epoch 031 - training loss: 0.3970, validation loss: 0.5169
2024-06-02 19:46:04 [INFO]: Epoch 032 - training loss: 0.4042, validation loss: 0.5189
2024-06-02 19:46:07 [INFO]: Epoch 033 - training loss: 0.3941, validation loss: 0.4989
2024-06-02 19:46:10 [INFO]: Epoch 034 - training loss: 0.3922, validation loss: 0.5200
2024-06-02 19:46:13 [INFO]: Epoch 035 - training loss: 0.3837, validation loss: 0.5073
2024-06-02 19:46:16 [INFO]: Epoch 036 - training loss: 0.3964, validation loss: 0.5104
2024-06-02 19:46:19 [INFO]: Epoch 037 - training loss: 0.3856, validation loss: 0.5158
2024-06-02 19:46:22 [INFO]: Epoch 038 - training loss: 0.3832, validation loss: 0.5008
2024-06-02 19:46:25 [INFO]: Epoch 039 - training loss: 0.3872, validation loss: 0.5095
2024-06-02 19:46:28 [INFO]: Epoch 040 - training loss: 0.3877, validation loss: 0.5185
2024-06-02 19:46:31 [INFO]: Epoch 041 - training loss: 0.3789, validation loss: 0.5161
2024-06-02 19:46:34 [INFO]: Epoch 042 - training loss: 0.3745, validation loss: 0.5097
2024-06-02 19:46:37 [INFO]: Epoch 043 - training loss: 0.3739, validation loss: 0.5021
2024-06-02 19:46:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:46:37 [INFO]: Finished training. The best model is from epoch#33.
2024-06-02 19:46:37 [INFO]: Saved the model to results_point_rate05/PeMS/FreTS_PeMS/round_2/20240602_T194428/FreTS.pypots
2024-06-02 19:46:38 [INFO]: Successfully saved to results_point_rate05/PeMS/FreTS_PeMS/round_2/imputation.pkl
2024-06-02 19:46:38 [INFO]: Round2 - FreTS on PeMS: MAE=0.4131, MSE=0.7119, MRE=0.5126
2024-06-02 19:46:38 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:46:38 [INFO]: Using the given device: cuda:0
2024-06-02 19:46:38 [INFO]: Model files will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_3/20240602_T194638
2024-06-02 19:46:38 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_3/20240602_T194638/tensorboard
2024-06-02 19:46:38 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-02 19:46:41 [INFO]: Epoch 001 - training loss: 1.0869, validation loss: 0.7329
2024-06-02 19:46:44 [INFO]: Epoch 002 - training loss: 0.7140, validation loss: 0.7053
2024-06-02 19:46:47 [INFO]: Epoch 003 - training loss: 0.6391, validation loss: 0.5950
2024-06-02 19:46:49 [INFO]: Epoch 004 - training loss: 0.5956, validation loss: 0.6041
2024-06-02 19:46:52 [INFO]: Epoch 005 - training loss: 0.5564, validation loss: 0.5693
2024-06-02 19:46:55 [INFO]: Epoch 006 - training loss: 0.5474, validation loss: 0.5624
2024-06-02 19:46:58 [INFO]: Epoch 007 - training loss: 0.5236, validation loss: 0.5467
2024-06-02 19:47:02 [INFO]: Epoch 008 - training loss: 0.5041, validation loss: 0.5741
2024-06-02 19:47:04 [INFO]: Epoch 009 - training loss: 0.4924, validation loss: 0.5673
2024-06-02 19:47:07 [INFO]: Epoch 010 - training loss: 0.4970, validation loss: 0.5500
2024-06-02 19:47:10 [INFO]: Epoch 011 - training loss: 0.4712, validation loss: 0.5146
2024-06-02 19:47:13 [INFO]: Epoch 012 - training loss: 0.4617, validation loss: 0.5124
2024-06-02 19:47:16 [INFO]: Epoch 013 - training loss: 0.4499, validation loss: 0.5330
2024-06-02 19:47:19 [INFO]: Epoch 014 - training loss: 0.4459, validation loss: 0.5135
2024-06-02 19:47:22 [INFO]: Epoch 015 - training loss: 0.4431, validation loss: 0.5043
2024-06-02 19:47:25 [INFO]: Epoch 016 - training loss: 0.4347, validation loss: 0.5127
2024-06-02 19:47:28 [INFO]: Epoch 017 - training loss: 0.4334, validation loss: 0.5012
2024-06-02 19:47:31 [INFO]: Epoch 018 - training loss: 0.4262, validation loss: 0.4875
2024-06-02 19:47:33 [INFO]: Epoch 019 - training loss: 0.4167, validation loss: 0.4888
2024-06-02 19:47:36 [INFO]: Epoch 020 - training loss: 0.4254, validation loss: 0.5059
2024-06-02 19:47:39 [INFO]: Epoch 021 - training loss: 0.4124, validation loss: 0.5027
2024-06-02 19:47:41 [INFO]: Epoch 022 - training loss: 0.4043, validation loss: 0.4948
2024-06-02 19:47:44 [INFO]: Epoch 023 - training loss: 0.4157, validation loss: 0.5154
2024-06-02 19:47:47 [INFO]: Epoch 024 - training loss: 0.4073, validation loss: 0.4692
2024-06-02 19:47:51 [INFO]: Epoch 025 - training loss: 0.4104, validation loss: 0.4980
2024-06-02 19:47:54 [INFO]: Epoch 026 - training loss: 0.4074, validation loss: 0.4898
2024-06-02 19:47:57 [INFO]: Epoch 027 - training loss: 0.3901, validation loss: 0.4860
2024-06-02 19:48:00 [INFO]: Epoch 028 - training loss: 0.3822, validation loss: 0.4647
2024-06-02 19:48:03 [INFO]: Epoch 029 - training loss: 0.3890, validation loss: 0.4731
2024-06-02 19:48:06 [INFO]: Epoch 030 - training loss: 0.3814, validation loss: 0.4900
2024-06-02 19:48:09 [INFO]: Epoch 031 - training loss: 0.3832, validation loss: 0.4649
2024-06-02 19:48:12 [INFO]: Epoch 032 - training loss: 0.4024, validation loss: 0.4710
2024-06-02 19:48:15 [INFO]: Epoch 033 - training loss: 0.3924, validation loss: 0.4697
2024-06-02 19:48:18 [INFO]: Epoch 034 - training loss: 0.3819, validation loss: 0.4734
2024-06-02 19:48:20 [INFO]: Epoch 035 - training loss: 0.3780, validation loss: 0.4666
2024-06-02 19:48:23 [INFO]: Epoch 036 - training loss: 0.3783, validation loss: 0.4656
2024-06-02 19:48:26 [INFO]: Epoch 037 - training loss: 0.3731, validation loss: 0.4815
2024-06-02 19:48:29 [INFO]: Epoch 038 - training loss: 0.3722, validation loss: 0.4664
2024-06-02 19:48:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:48:29 [INFO]: Finished training. The best model is from epoch#28.
2024-06-02 19:48:29 [INFO]: Saved the model to results_point_rate05/PeMS/FreTS_PeMS/round_3/20240602_T194638/FreTS.pypots
2024-06-02 19:48:30 [INFO]: Successfully saved to results_point_rate05/PeMS/FreTS_PeMS/round_3/imputation.pkl
2024-06-02 19:48:30 [INFO]: Round3 - FreTS on PeMS: MAE=0.4004, MSE=0.6412, MRE=0.4968
2024-06-02 19:48:30 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:48:30 [INFO]: Using the given device: cuda:0
2024-06-02 19:48:30 [INFO]: Model files will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_4/20240602_T194830
2024-06-02 19:48:30 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/FreTS_PeMS/round_4/20240602_T194830/tensorboard
2024-06-02 19:48:30 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-02 19:48:33 [INFO]: Epoch 001 - training loss: 1.0744, validation loss: 0.7652
2024-06-02 19:48:36 [INFO]: Epoch 002 - training loss: 0.6974, validation loss: 0.6644
2024-06-02 19:48:39 [INFO]: Epoch 003 - training loss: 0.6387, validation loss: 0.6245
2024-06-02 19:48:42 [INFO]: Epoch 004 - training loss: 0.5902, validation loss: 0.6389
2024-06-02 19:48:45 [INFO]: Epoch 005 - training loss: 0.5750, validation loss: 0.5812
2024-06-02 19:48:48 [INFO]: Epoch 006 - training loss: 0.5605, validation loss: 0.5828
2024-06-02 19:48:51 [INFO]: Epoch 007 - training loss: 0.5258, validation loss: 0.5723
2024-06-02 19:48:54 [INFO]: Epoch 008 - training loss: 0.5183, validation loss: 0.5792
2024-06-02 19:48:57 [INFO]: Epoch 009 - training loss: 0.5087, validation loss: 0.6101
2024-06-02 19:49:00 [INFO]: Epoch 010 - training loss: 0.4886, validation loss: 0.5508
2024-06-02 19:49:03 [INFO]: Epoch 011 - training loss: 0.4778, validation loss: 0.5502
2024-06-02 19:49:06 [INFO]: Epoch 012 - training loss: 0.4621, validation loss: 0.5395
2024-06-02 19:49:09 [INFO]: Epoch 013 - training loss: 0.4728, validation loss: 0.5307
2024-06-02 19:49:12 [INFO]: Epoch 014 - training loss: 0.4564, validation loss: 0.5375
2024-06-02 19:49:15 [INFO]: Epoch 015 - training loss: 0.4562, validation loss: 0.5392
2024-06-02 19:49:18 [INFO]: Epoch 016 - training loss: 0.4438, validation loss: 0.5311
2024-06-02 19:49:20 [INFO]: Epoch 017 - training loss: 0.4351, validation loss: 0.5096
2024-06-02 19:49:23 [INFO]: Epoch 018 - training loss: 0.4289, validation loss: 0.5284
2024-06-02 19:49:26 [INFO]: Epoch 019 - training loss: 0.4181, validation loss: 0.5196
2024-06-02 19:49:29 [INFO]: Epoch 020 - training loss: 0.4199, validation loss: 0.5112
2024-06-02 19:49:32 [INFO]: Epoch 021 - training loss: 0.4204, validation loss: 0.5136
2024-06-02 19:49:35 [INFO]: Epoch 022 - training loss: 0.4175, validation loss: 0.5323
2024-06-02 19:49:38 [INFO]: Epoch 023 - training loss: 0.4233, validation loss: 0.5127
2024-06-02 19:49:41 [INFO]: Epoch 024 - training loss: 0.4054, validation loss: 0.5176
2024-06-02 19:49:44 [INFO]: Epoch 025 - training loss: 0.4070, validation loss: 0.4952
2024-06-02 19:49:47 [INFO]: Epoch 026 - training loss: 0.3985, validation loss: 0.5011
2024-06-02 19:49:50 [INFO]: Epoch 027 - training loss: 0.4033, validation loss: 0.5073
2024-06-02 19:49:53 [INFO]: Epoch 028 - training loss: 0.3979, validation loss: 0.5002
2024-06-02 19:49:56 [INFO]: Epoch 029 - training loss: 0.4087, validation loss: 0.5171
2024-06-02 19:49:59 [INFO]: Epoch 030 - training loss: 0.4005, validation loss: 0.5107
2024-06-02 19:50:02 [INFO]: Epoch 031 - training loss: 0.3899, validation loss: 0.5011
2024-06-02 19:50:05 [INFO]: Epoch 032 - training loss: 0.3819, validation loss: 0.4932
2024-06-02 19:50:08 [INFO]: Epoch 033 - training loss: 0.3863, validation loss: 0.5016
2024-06-02 19:50:11 [INFO]: Epoch 034 - training loss: 0.3966, validation loss: 0.5095
2024-06-02 19:50:14 [INFO]: Epoch 035 - training loss: 0.3819, validation loss: 0.4807
2024-06-02 19:50:16 [INFO]: Epoch 036 - training loss: 0.3734, validation loss: 0.4899
2024-06-02 19:50:19 [INFO]: Epoch 037 - training loss: 0.3741, validation loss: 0.4859
2024-06-02 19:50:22 [INFO]: Epoch 038 - training loss: 0.3726, validation loss: 0.4846
2024-06-02 19:50:25 [INFO]: Epoch 039 - training loss: 0.3731, validation loss: 0.4973
2024-06-02 19:50:28 [INFO]: Epoch 040 - training loss: 0.3762, validation loss: 0.4946
2024-06-02 19:50:31 [INFO]: Epoch 041 - training loss: 0.3686, validation loss: 0.4834
2024-06-02 19:50:34 [INFO]: Epoch 042 - training loss: 0.3627, validation loss: 0.4764
2024-06-02 19:50:37 [INFO]: Epoch 043 - training loss: 0.3603, validation loss: 0.4814
2024-06-02 19:50:40 [INFO]: Epoch 044 - training loss: 0.3620, validation loss: 0.4933
2024-06-02 19:50:43 [INFO]: Epoch 045 - training loss: 0.3623, validation loss: 0.4833
2024-06-02 19:50:46 [INFO]: Epoch 046 - training loss: 0.3748, validation loss: 0.5145
2024-06-02 19:50:49 [INFO]: Epoch 047 - training loss: 0.3736, validation loss: 0.4905
2024-06-02 19:50:52 [INFO]: Epoch 048 - training loss: 0.3590, validation loss: 0.4838
2024-06-02 19:50:55 [INFO]: Epoch 049 - training loss: 0.3588, validation loss: 0.4819
2024-06-02 19:50:58 [INFO]: Epoch 050 - training loss: 0.3565, validation loss: 0.4835
2024-06-02 19:51:01 [INFO]: Epoch 051 - training loss: 0.3529, validation loss: 0.4724
2024-06-02 19:51:03 [INFO]: Epoch 052 - training loss: 0.3492, validation loss: 0.4804
2024-06-02 19:51:06 [INFO]: Epoch 053 - training loss: 0.3487, validation loss: 0.4869
2024-06-02 19:51:09 [INFO]: Epoch 054 - training loss: 0.3545, validation loss: 0.4698
2024-06-02 19:51:12 [INFO]: Epoch 055 - training loss: 0.3555, validation loss: 0.4784
2024-06-02 19:51:15 [INFO]: Epoch 056 - training loss: 0.3556, validation loss: 0.4759
2024-06-02 19:51:18 [INFO]: Epoch 057 - training loss: 0.3521, validation loss: 0.4596
2024-06-02 19:51:21 [INFO]: Epoch 058 - training loss: 0.3488, validation loss: 0.4803
2024-06-02 19:51:24 [INFO]: Epoch 059 - training loss: 0.3481, validation loss: 0.4735
2024-06-02 19:51:27 [INFO]: Epoch 060 - training loss: 0.3474, validation loss: 0.4799
2024-06-02 19:51:30 [INFO]: Epoch 061 - training loss: 0.3428, validation loss: 0.4829
2024-06-02 19:51:33 [INFO]: Epoch 062 - training loss: 0.3520, validation loss: 0.4768
2024-06-02 19:51:36 [INFO]: Epoch 063 - training loss: 0.3435, validation loss: 0.4723
2024-06-02 19:51:39 [INFO]: Epoch 064 - training loss: 0.3479, validation loss: 0.4762
2024-06-02 19:51:42 [INFO]: Epoch 065 - training loss: 0.3459, validation loss: 0.4773
2024-06-02 19:51:45 [INFO]: Epoch 066 - training loss: 0.3434, validation loss: 0.4695
2024-06-02 19:51:48 [INFO]: Epoch 067 - training loss: 0.3482, validation loss: 0.4846
2024-06-02 19:51:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:51:48 [INFO]: Finished training. The best model is from epoch#57.
2024-06-02 19:51:48 [INFO]: Saved the model to results_point_rate05/PeMS/FreTS_PeMS/round_4/20240602_T194830/FreTS.pypots
2024-06-02 19:51:49 [INFO]: Successfully saved to results_point_rate05/PeMS/FreTS_PeMS/round_4/imputation.pkl
2024-06-02 19:51:49 [INFO]: Round4 - FreTS on PeMS: MAE=0.4516, MSE=0.7103, MRE=0.5604
2024-06-02 19:51:49 [INFO]: Done! Final results:
Averaged FreTS (1,715,958 params) on PeMS: MAE=0.4225 ± 0.018937815121512633, MSE=0.6861 ± 0.027301879786604293, MRE=0.5242 ± 0.023500222155434104, average inference time=0.16
