2024-06-02 19:38:47 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:38:47 [INFO]: Using the given device: cuda:0
2024-06-02 19:38:47 [INFO]: Model files will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_0/20240602_T193847
2024-06-02 19:38:47 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_0/20240602_T193847/tensorboard
2024-06-02 19:38:48 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-02 19:38:56 [INFO]: Epoch 001 - training loss: 1.7315, validation loss: 1.5506
2024-06-02 19:39:02 [INFO]: Epoch 002 - training loss: 1.6470, validation loss: 1.4103
2024-06-02 19:39:08 [INFO]: Epoch 003 - training loss: 1.5508, validation loss: 1.3322
2024-06-02 19:39:16 [INFO]: Epoch 004 - training loss: 1.5003, validation loss: 1.3008
2024-06-02 19:39:23 [INFO]: Epoch 005 - training loss: 1.4733, validation loss: 1.2873
2024-06-02 19:39:31 [INFO]: Epoch 006 - training loss: 1.4573, validation loss: 1.2785
2024-06-02 19:39:39 [INFO]: Epoch 007 - training loss: 1.4374, validation loss: 1.2800
2024-06-02 19:39:46 [INFO]: Epoch 008 - training loss: 1.4061, validation loss: 1.2623
2024-06-02 19:39:52 [INFO]: Epoch 009 - training loss: 1.3500, validation loss: 1.2210
2024-06-02 19:39:58 [INFO]: Epoch 010 - training loss: 1.2334, validation loss: 1.1770
2024-06-02 19:40:05 [INFO]: Epoch 011 - training loss: 1.1182, validation loss: 1.1183
2024-06-02 19:40:13 [INFO]: Epoch 012 - training loss: 1.0348, validation loss: 1.0614
2024-06-02 19:40:21 [INFO]: Epoch 013 - training loss: 0.9685, validation loss: 0.9919
2024-06-02 19:40:29 [INFO]: Epoch 014 - training loss: 0.9344, validation loss: 0.9742
2024-06-02 19:40:36 [INFO]: Epoch 015 - training loss: 0.8976, validation loss: 0.9323
2024-06-02 19:40:43 [INFO]: Epoch 016 - training loss: 0.8742, validation loss: 0.8915
2024-06-02 19:40:48 [INFO]: Epoch 017 - training loss: 0.8578, validation loss: 0.8763
2024-06-02 19:40:55 [INFO]: Epoch 018 - training loss: 0.8491, validation loss: 0.8763
2024-06-02 19:41:02 [INFO]: Epoch 019 - training loss: 0.8493, validation loss: 0.8757
2024-06-02 19:41:10 [INFO]: Epoch 020 - training loss: 0.8424, validation loss: 0.8673
2024-06-02 19:41:17 [INFO]: Epoch 021 - training loss: 0.8404, validation loss: 0.8692
2024-06-02 19:41:25 [INFO]: Epoch 022 - training loss: 0.8300, validation loss: 0.8634
2024-06-02 19:41:31 [INFO]: Epoch 023 - training loss: 0.8278, validation loss: 0.8678
2024-06-02 19:41:37 [INFO]: Epoch 024 - training loss: 0.8298, validation loss: 0.8490
2024-06-02 19:41:43 [INFO]: Epoch 025 - training loss: 0.8263, validation loss: 0.8549
2024-06-02 19:41:51 [INFO]: Epoch 026 - training loss: 0.8212, validation loss: 0.8451
2024-06-02 19:41:59 [INFO]: Epoch 027 - training loss: 0.8203, validation loss: 0.8456
2024-06-02 19:42:06 [INFO]: Epoch 028 - training loss: 0.8141, validation loss: 0.8412
2024-06-02 19:42:13 [INFO]: Epoch 029 - training loss: 0.8117, validation loss: 0.8333
2024-06-02 19:42:20 [INFO]: Epoch 030 - training loss: 0.8091, validation loss: 0.8377
2024-06-02 19:42:27 [INFO]: Epoch 031 - training loss: 0.8076, validation loss: 0.8331
2024-06-02 19:42:33 [INFO]: Epoch 032 - training loss: 0.8004, validation loss: 0.8330
2024-06-02 19:42:40 [INFO]: Epoch 033 - training loss: 0.8029, validation loss: 0.8300
2024-06-02 19:42:48 [INFO]: Epoch 034 - training loss: 0.8057, validation loss: 0.8274
2024-06-02 19:42:56 [INFO]: Epoch 035 - training loss: 0.8011, validation loss: 0.8259
2024-06-02 19:43:03 [INFO]: Epoch 036 - training loss: 0.8011, validation loss: 0.8264
2024-06-02 19:43:11 [INFO]: Epoch 037 - training loss: 0.7970, validation loss: 0.8258
2024-06-02 19:43:18 [INFO]: Epoch 038 - training loss: 0.7951, validation loss: 0.8260
2024-06-02 19:43:24 [INFO]: Epoch 039 - training loss: 0.7922, validation loss: 0.8249
2024-06-02 19:43:32 [INFO]: Epoch 040 - training loss: 0.7900, validation loss: 0.8252
2024-06-02 19:43:40 [INFO]: Epoch 041 - training loss: 0.7952, validation loss: 0.8187
2024-06-02 19:43:48 [INFO]: Epoch 042 - training loss: 0.7914, validation loss: 0.8189
2024-06-02 19:43:56 [INFO]: Epoch 043 - training loss: 0.7971, validation loss: 0.8189
2024-06-02 19:44:03 [INFO]: Epoch 044 - training loss: 0.7942, validation loss: 0.8195
2024-06-02 19:44:11 [INFO]: Epoch 045 - training loss: 0.7853, validation loss: 0.8207
2024-06-02 19:44:17 [INFO]: Epoch 046 - training loss: 0.7854, validation loss: 0.8159
2024-06-02 19:44:24 [INFO]: Epoch 047 - training loss: 0.7874, validation loss: 0.8172
2024-06-02 19:44:32 [INFO]: Epoch 048 - training loss: 0.7845, validation loss: 0.8171
2024-06-02 19:44:40 [INFO]: Epoch 049 - training loss: 0.7880, validation loss: 0.8183
2024-06-02 19:44:47 [INFO]: Epoch 050 - training loss: 0.7817, validation loss: 0.8164
2024-06-02 19:44:55 [INFO]: Epoch 051 - training loss: 0.7865, validation loss: 0.8139
2024-06-02 19:45:02 [INFO]: Epoch 052 - training loss: 0.7872, validation loss: 0.8169
2024-06-02 19:45:07 [INFO]: Epoch 053 - training loss: 0.7829, validation loss: 0.8126
2024-06-02 19:45:13 [INFO]: Epoch 054 - training loss: 0.7837, validation loss: 0.8173
2024-06-02 19:45:20 [INFO]: Epoch 055 - training loss: 0.7789, validation loss: 0.8133
2024-06-02 19:45:26 [INFO]: Epoch 056 - training loss: 0.7823, validation loss: 0.8138
2024-06-02 19:45:33 [INFO]: Epoch 057 - training loss: 0.7782, validation loss: 0.8127
2024-06-02 19:45:39 [INFO]: Epoch 058 - training loss: 0.7824, validation loss: 0.8125
2024-06-02 19:45:45 [INFO]: Epoch 059 - training loss: 0.7738, validation loss: 0.8194
2024-06-02 19:45:52 [INFO]: Epoch 060 - training loss: 0.7798, validation loss: 0.8120
2024-06-02 19:45:58 [INFO]: Epoch 061 - training loss: 0.7804, validation loss: 0.8139
2024-06-02 19:46:03 [INFO]: Epoch 062 - training loss: 0.7702, validation loss: 0.8147
2024-06-02 19:46:10 [INFO]: Epoch 063 - training loss: 0.7824, validation loss: 0.8129
2024-06-02 19:46:16 [INFO]: Epoch 064 - training loss: 0.7783, validation loss: 0.8124
2024-06-02 19:46:22 [INFO]: Epoch 065 - training loss: 0.7734, validation loss: 0.8114
2024-06-02 19:46:29 [INFO]: Epoch 066 - training loss: 0.7722, validation loss: 0.8089
2024-06-02 19:46:37 [INFO]: Epoch 067 - training loss: 0.7772, validation loss: 0.8145
2024-06-02 19:46:43 [INFO]: Epoch 068 - training loss: 0.7689, validation loss: 0.8136
2024-06-02 19:46:48 [INFO]: Epoch 069 - training loss: 0.7727, validation loss: 0.8123
2024-06-02 19:46:55 [INFO]: Epoch 070 - training loss: 0.7742, validation loss: 0.8139
2024-06-02 19:47:01 [INFO]: Epoch 071 - training loss: 0.7725, validation loss: 0.8109
2024-06-02 19:47:08 [INFO]: Epoch 072 - training loss: 0.7711, validation loss: 0.8161
2024-06-02 19:47:14 [INFO]: Epoch 073 - training loss: 0.7736, validation loss: 0.8111
2024-06-02 19:47:20 [INFO]: Epoch 074 - training loss: 0.7700, validation loss: 0.8088
2024-06-02 19:47:27 [INFO]: Epoch 075 - training loss: 0.7669, validation loss: 0.8113
2024-06-02 19:47:33 [INFO]: Epoch 076 - training loss: 0.7690, validation loss: 0.8106
2024-06-02 19:47:38 [INFO]: Epoch 077 - training loss: 0.7697, validation loss: 0.8092
2024-06-02 19:47:44 [INFO]: Epoch 078 - training loss: 0.7658, validation loss: 0.8077
2024-06-02 19:47:51 [INFO]: Epoch 079 - training loss: 0.7712, validation loss: 0.8098
2024-06-02 19:47:58 [INFO]: Epoch 080 - training loss: 0.7709, validation loss: 0.8109
2024-06-02 19:48:05 [INFO]: Epoch 081 - training loss: 0.7722, validation loss: 0.8097
2024-06-02 19:48:12 [INFO]: Epoch 082 - training loss: 0.7705, validation loss: 0.8096
2024-06-02 19:48:19 [INFO]: Epoch 083 - training loss: 0.7709, validation loss: 0.8091
2024-06-02 19:48:25 [INFO]: Epoch 084 - training loss: 0.7669, validation loss: 0.8082
2024-06-02 19:48:30 [INFO]: Epoch 085 - training loss: 0.7691, validation loss: 0.8098
2024-06-02 19:48:37 [INFO]: Epoch 086 - training loss: 0.7702, validation loss: 0.8089
2024-06-02 19:48:44 [INFO]: Epoch 087 - training loss: 0.7677, validation loss: 0.8095
2024-06-02 19:48:51 [INFO]: Epoch 088 - training loss: 0.7681, validation loss: 0.8092
2024-06-02 19:48:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:48:51 [INFO]: Finished training. The best model is from epoch#78.
2024-06-02 19:48:51 [INFO]: Saved the model to results_point_rate05/PeMS/Autoformer_PeMS/round_0/20240602_T193847/Autoformer.pypots
2024-06-02 19:48:53 [INFO]: Successfully saved to results_point_rate05/PeMS/Autoformer_PeMS/round_0/imputation.pkl
2024-06-02 19:48:53 [INFO]: Round0 - Autoformer on PeMS: MAE=0.5149, MSE=1.0416, MRE=0.6389
2024-06-02 19:48:53 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:48:53 [INFO]: Using the given device: cuda:0
2024-06-02 19:48:53 [INFO]: Model files will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_1/20240602_T194853
2024-06-02 19:48:53 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_1/20240602_T194853/tensorboard
2024-06-02 19:48:53 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-02 19:49:00 [INFO]: Epoch 001 - training loss: 1.7272, validation loss: 1.5510
2024-06-02 19:49:06 [INFO]: Epoch 002 - training loss: 1.6495, validation loss: 1.4282
2024-06-02 19:49:13 [INFO]: Epoch 003 - training loss: 1.5591, validation loss: 1.3430
2024-06-02 19:49:19 [INFO]: Epoch 004 - training loss: 1.5008, validation loss: 1.3054
2024-06-02 19:49:24 [INFO]: Epoch 005 - training loss: 1.4856, validation loss: 1.2899
2024-06-02 19:49:31 [INFO]: Epoch 006 - training loss: 1.4642, validation loss: 1.2878
2024-06-02 19:49:37 [INFO]: Epoch 007 - training loss: 1.4593, validation loss: 1.2878
2024-06-02 19:49:44 [INFO]: Epoch 008 - training loss: 1.4552, validation loss: 1.2891
2024-06-02 19:49:50 [INFO]: Epoch 009 - training loss: 1.4370, validation loss: 1.2807
2024-06-02 19:49:57 [INFO]: Epoch 010 - training loss: 1.4223, validation loss: 1.2619
2024-06-02 19:50:04 [INFO]: Epoch 011 - training loss: 1.3920, validation loss: 1.2484
2024-06-02 19:50:10 [INFO]: Epoch 012 - training loss: 1.3599, validation loss: 1.2373
2024-06-02 19:50:16 [INFO]: Epoch 013 - training loss: 1.3275, validation loss: 1.2302
2024-06-02 19:50:22 [INFO]: Epoch 014 - training loss: 1.2833, validation loss: 1.2216
2024-06-02 19:50:28 [INFO]: Epoch 015 - training loss: 1.2200, validation loss: 1.2021
2024-06-02 19:50:35 [INFO]: Epoch 016 - training loss: 1.1693, validation loss: 1.1963
2024-06-02 19:50:42 [INFO]: Epoch 017 - training loss: 1.1031, validation loss: 1.1696
2024-06-02 19:50:48 [INFO]: Epoch 018 - training loss: 1.0602, validation loss: 1.1683
2024-06-02 19:50:55 [INFO]: Epoch 019 - training loss: 1.0463, validation loss: 1.1686
2024-06-02 19:51:01 [INFO]: Epoch 020 - training loss: 1.0321, validation loss: 1.1869
2024-06-02 19:51:06 [INFO]: Epoch 021 - training loss: 1.0219, validation loss: 1.1783
2024-06-02 19:51:13 [INFO]: Epoch 022 - training loss: 1.0215, validation loss: 1.1821
2024-06-02 19:51:19 [INFO]: Epoch 023 - training loss: 1.0078, validation loss: 1.1862
2024-06-02 19:51:25 [INFO]: Epoch 024 - training loss: 1.0029, validation loss: 1.1819
2024-06-02 19:51:32 [INFO]: Epoch 025 - training loss: 1.0002, validation loss: 1.1858
2024-06-02 19:51:39 [INFO]: Epoch 026 - training loss: 0.9947, validation loss: 1.1726
2024-06-02 19:51:45 [INFO]: Epoch 027 - training loss: 0.9910, validation loss: 1.1648
2024-06-02 19:51:51 [INFO]: Epoch 028 - training loss: 0.9877, validation loss: 1.1628
2024-06-02 19:51:56 [INFO]: Epoch 029 - training loss: 0.9845, validation loss: 1.1575
2024-06-02 19:52:02 [INFO]: Epoch 030 - training loss: 0.9835, validation loss: 1.1473
2024-06-02 19:52:08 [INFO]: Epoch 031 - training loss: 0.9787, validation loss: 1.1388
2024-06-02 19:52:14 [INFO]: Epoch 032 - training loss: 0.9743, validation loss: 1.1412
2024-06-02 19:52:20 [INFO]: Epoch 033 - training loss: 0.9660, validation loss: 1.1277
2024-06-02 19:52:25 [INFO]: Epoch 034 - training loss: 0.9618, validation loss: 1.1103
2024-06-02 19:52:31 [INFO]: Epoch 035 - training loss: 0.9608, validation loss: 1.1065
2024-06-02 19:52:36 [INFO]: Epoch 036 - training loss: 0.9546, validation loss: 1.0995
2024-06-02 19:52:40 [INFO]: Epoch 037 - training loss: 0.9534, validation loss: 1.0988
2024-06-02 19:52:44 [INFO]: Epoch 038 - training loss: 0.9581, validation loss: 1.1060
2024-06-02 19:52:49 [INFO]: Epoch 039 - training loss: 0.9395, validation loss: 1.0937
2024-06-02 19:52:54 [INFO]: Epoch 040 - training loss: 0.9352, validation loss: 1.0877
2024-06-02 19:52:58 [INFO]: Epoch 041 - training loss: 0.9321, validation loss: 1.0888
2024-06-02 19:53:03 [INFO]: Epoch 042 - training loss: 0.9407, validation loss: 1.0850
2024-06-02 19:53:08 [INFO]: Epoch 043 - training loss: 0.9327, validation loss: 1.0768
2024-06-02 19:53:14 [INFO]: Epoch 044 - training loss: 0.9257, validation loss: 1.0815
2024-06-02 19:53:19 [INFO]: Epoch 045 - training loss: 0.9296, validation loss: 1.0767
2024-06-02 19:53:24 [INFO]: Epoch 046 - training loss: 0.9268, validation loss: 1.0813
2024-06-02 19:53:29 [INFO]: Epoch 047 - training loss: 0.9286, validation loss: 1.0695
2024-06-02 19:53:33 [INFO]: Epoch 048 - training loss: 0.9183, validation loss: 1.0671
2024-06-02 19:53:39 [INFO]: Epoch 049 - training loss: 0.9250, validation loss: 1.0697
2024-06-02 19:53:44 [INFO]: Epoch 050 - training loss: 0.9162, validation loss: 1.0641
2024-06-02 19:53:49 [INFO]: Epoch 051 - training loss: 0.9215, validation loss: 1.0647
2024-06-02 19:53:54 [INFO]: Epoch 052 - training loss: 0.9122, validation loss: 1.0641
2024-06-02 19:54:00 [INFO]: Epoch 053 - training loss: 0.9158, validation loss: 1.0726
2024-06-02 19:54:05 [INFO]: Epoch 054 - training loss: 0.9016, validation loss: 1.0674
2024-06-02 19:54:10 [INFO]: Epoch 055 - training loss: 0.9072, validation loss: 1.0780
2024-06-02 19:54:14 [INFO]: Epoch 056 - training loss: 0.9250, validation loss: 1.0644
2024-06-02 19:54:19 [INFO]: Epoch 057 - training loss: 0.9031, validation loss: 1.0597
2024-06-02 19:54:24 [INFO]: Epoch 058 - training loss: 0.9035, validation loss: 1.0729
2024-06-02 19:54:29 [INFO]: Epoch 059 - training loss: 0.9090, validation loss: 1.0566
2024-06-02 19:54:35 [INFO]: Epoch 060 - training loss: 0.8983, validation loss: 1.0587
2024-06-02 19:54:40 [INFO]: Epoch 061 - training loss: 0.9021, validation loss: 1.0566
2024-06-02 19:54:45 [INFO]: Epoch 062 - training loss: 0.9090, validation loss: 1.0678
2024-06-02 19:54:50 [INFO]: Epoch 063 - training loss: 0.9047, validation loss: 1.0522
2024-06-02 19:54:55 [INFO]: Epoch 064 - training loss: 0.8978, validation loss: 1.0642
2024-06-02 19:54:59 [INFO]: Epoch 065 - training loss: 0.9047, validation loss: 1.0598
2024-06-02 19:55:03 [INFO]: Epoch 066 - training loss: 0.9020, validation loss: 1.0504
2024-06-02 19:55:08 [INFO]: Epoch 067 - training loss: 0.8856, validation loss: 1.0544
2024-06-02 19:55:13 [INFO]: Epoch 068 - training loss: 0.8931, validation loss: 1.0563
2024-06-02 19:55:18 [INFO]: Epoch 069 - training loss: 0.8902, validation loss: 1.0454
2024-06-02 19:55:23 [INFO]: Epoch 070 - training loss: 0.8971, validation loss: 1.0493
2024-06-02 19:55:28 [INFO]: Epoch 071 - training loss: 0.9015, validation loss: 1.0545
2024-06-02 19:55:33 [INFO]: Epoch 072 - training loss: 0.8897, validation loss: 1.0515
2024-06-02 19:55:38 [INFO]: Epoch 073 - training loss: 0.8795, validation loss: 1.0435
2024-06-02 19:55:43 [INFO]: Epoch 074 - training loss: 0.8860, validation loss: 1.0433
2024-06-02 19:55:48 [INFO]: Epoch 075 - training loss: 0.8806, validation loss: 1.0431
2024-06-02 19:55:52 [INFO]: Epoch 076 - training loss: 0.8900, validation loss: 1.0454
2024-06-02 19:55:57 [INFO]: Epoch 077 - training loss: 0.8799, validation loss: 1.0489
2024-06-02 19:56:02 [INFO]: Epoch 078 - training loss: 0.8794, validation loss: 1.0433
2024-06-02 19:56:07 [INFO]: Epoch 079 - training loss: 0.8834, validation loss: 1.0400
2024-06-02 19:56:13 [INFO]: Epoch 080 - training loss: 0.8781, validation loss: 1.0436
2024-06-02 19:56:18 [INFO]: Epoch 081 - training loss: 0.8809, validation loss: 1.0481
2024-06-02 19:56:23 [INFO]: Epoch 082 - training loss: 0.8867, validation loss: 1.0518
2024-06-02 19:56:28 [INFO]: Epoch 083 - training loss: 0.8778, validation loss: 1.0365
2024-06-02 19:56:32 [INFO]: Epoch 084 - training loss: 0.8690, validation loss: 1.0407
2024-06-02 19:56:37 [INFO]: Epoch 085 - training loss: 0.8755, validation loss: 1.0401
2024-06-02 19:56:42 [INFO]: Epoch 086 - training loss: 0.8688, validation loss: 1.0486
2024-06-02 19:56:47 [INFO]: Epoch 087 - training loss: 0.8712, validation loss: 1.0421
2024-06-02 19:56:53 [INFO]: Epoch 088 - training loss: 0.8640, validation loss: 1.0342
2024-06-02 19:56:58 [INFO]: Epoch 089 - training loss: 0.8786, validation loss: 1.0430
2024-06-02 19:57:03 [INFO]: Epoch 090 - training loss: 0.8789, validation loss: 1.0485
2024-06-02 19:57:08 [INFO]: Epoch 091 - training loss: 0.8830, validation loss: 1.0422
2024-06-02 19:57:13 [INFO]: Epoch 092 - training loss: 0.8632, validation loss: 1.0353
2024-06-02 19:57:18 [INFO]: Epoch 093 - training loss: 0.8594, validation loss: 1.0278
2024-06-02 19:57:22 [INFO]: Epoch 094 - training loss: 0.8749, validation loss: 1.0335
2024-06-02 19:57:26 [INFO]: Epoch 095 - training loss: 0.8674, validation loss: 1.0288
2024-06-02 19:57:31 [INFO]: Epoch 096 - training loss: 0.8609, validation loss: 1.0268
2024-06-02 19:57:36 [INFO]: Epoch 097 - training loss: 0.8663, validation loss: 1.0299
2024-06-02 19:57:41 [INFO]: Epoch 098 - training loss: 0.8737, validation loss: 1.0227
2024-06-02 19:57:46 [INFO]: Epoch 099 - training loss: 0.8556, validation loss: 1.0282
2024-06-02 19:57:52 [INFO]: Epoch 100 - training loss: 0.8647, validation loss: 1.0305
2024-06-02 19:57:52 [INFO]: Finished training. The best model is from epoch#98.
2024-06-02 19:57:52 [INFO]: Saved the model to results_point_rate05/PeMS/Autoformer_PeMS/round_1/20240602_T194853/Autoformer.pypots
2024-06-02 19:57:53 [INFO]: Successfully saved to results_point_rate05/PeMS/Autoformer_PeMS/round_1/imputation.pkl
2024-06-02 19:57:53 [INFO]: Round1 - Autoformer on PeMS: MAE=0.6341, MSE=1.2887, MRE=0.7869
2024-06-02 19:57:53 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:57:53 [INFO]: Using the given device: cuda:0
2024-06-02 19:57:53 [INFO]: Model files will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_2/20240602_T195753
2024-06-02 19:57:53 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_2/20240602_T195753/tensorboard
2024-06-02 19:57:53 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-02 19:57:58 [INFO]: Epoch 001 - training loss: 1.7271, validation loss: 1.5443
2024-06-02 19:58:03 [INFO]: Epoch 002 - training loss: 1.6443, validation loss: 1.4124
2024-06-02 19:58:07 [INFO]: Epoch 003 - training loss: 1.5361, validation loss: 1.3287
2024-06-02 19:58:12 [INFO]: Epoch 004 - training loss: 1.4944, validation loss: 1.2931
2024-06-02 19:58:17 [INFO]: Epoch 005 - training loss: 1.4762, validation loss: 1.2775
2024-06-02 19:58:22 [INFO]: Epoch 006 - training loss: 1.4500, validation loss: 1.2768
2024-06-02 19:58:27 [INFO]: Epoch 007 - training loss: 1.4172, validation loss: 1.2726
2024-06-02 19:58:32 [INFO]: Epoch 008 - training loss: 1.3565, validation loss: 1.2280
2024-06-02 19:58:37 [INFO]: Epoch 009 - training loss: 1.2525, validation loss: 1.1568
2024-06-02 19:58:42 [INFO]: Epoch 010 - training loss: 1.1221, validation loss: 1.1110
2024-06-02 19:58:47 [INFO]: Epoch 011 - training loss: 1.0320, validation loss: 1.0032
2024-06-02 19:58:52 [INFO]: Epoch 012 - training loss: 0.9701, validation loss: 0.9810
2024-06-02 19:58:57 [INFO]: Epoch 013 - training loss: 0.9272, validation loss: 0.9477
2024-06-02 19:59:01 [INFO]: Epoch 014 - training loss: 0.8977, validation loss: 0.9207
2024-06-02 19:59:06 [INFO]: Epoch 015 - training loss: 0.8794, validation loss: 0.9032
2024-06-02 19:59:12 [INFO]: Epoch 016 - training loss: 0.8681, validation loss: 0.8870
2024-06-02 19:59:17 [INFO]: Epoch 017 - training loss: 0.8505, validation loss: 0.8592
2024-06-02 19:59:22 [INFO]: Epoch 018 - training loss: 0.8382, validation loss: 0.8526
2024-06-02 19:59:27 [INFO]: Epoch 019 - training loss: 0.8422, validation loss: 0.8411
2024-06-02 19:59:32 [INFO]: Epoch 020 - training loss: 0.8337, validation loss: 0.8320
2024-06-02 19:59:37 [INFO]: Epoch 021 - training loss: 0.8331, validation loss: 0.8247
2024-06-02 19:59:41 [INFO]: Epoch 022 - training loss: 0.8241, validation loss: 0.8192
2024-06-02 19:59:46 [INFO]: Epoch 023 - training loss: 0.8210, validation loss: 0.8158
2024-06-02 19:59:51 [INFO]: Epoch 024 - training loss: 0.8114, validation loss: 0.8103
2024-06-02 19:59:55 [INFO]: Epoch 025 - training loss: 0.8161, validation loss: 0.8079
2024-06-02 20:00:01 [INFO]: Epoch 026 - training loss: 0.8077, validation loss: 0.8047
2024-06-02 20:00:06 [INFO]: Epoch 027 - training loss: 0.8110, validation loss: 0.8054
2024-06-02 20:00:10 [INFO]: Epoch 028 - training loss: 0.8096, validation loss: 0.8007
2024-06-02 20:00:16 [INFO]: Epoch 029 - training loss: 0.8037, validation loss: 0.8005
2024-06-02 20:00:21 [INFO]: Epoch 030 - training loss: 0.8031, validation loss: 0.7973
2024-06-02 20:00:26 [INFO]: Epoch 031 - training loss: 0.8006, validation loss: 0.7977
2024-06-02 20:00:30 [INFO]: Epoch 032 - training loss: 0.8036, validation loss: 0.7955
2024-06-02 20:00:35 [INFO]: Epoch 033 - training loss: 0.7978, validation loss: 0.7949
2024-06-02 20:00:41 [INFO]: Epoch 034 - training loss: 0.8000, validation loss: 0.7936
2024-06-02 20:00:45 [INFO]: Epoch 035 - training loss: 0.8030, validation loss: 0.7943
2024-06-02 20:00:50 [INFO]: Epoch 036 - training loss: 0.7962, validation loss: 0.7920
2024-06-02 20:00:55 [INFO]: Epoch 037 - training loss: 0.7959, validation loss: 0.7923
2024-06-02 20:01:00 [INFO]: Epoch 038 - training loss: 0.7923, validation loss: 0.7918
2024-06-02 20:01:05 [INFO]: Epoch 039 - training loss: 0.7891, validation loss: 0.7933
2024-06-02 20:01:10 [INFO]: Epoch 040 - training loss: 0.7914, validation loss: 0.7923
2024-06-02 20:01:15 [INFO]: Epoch 041 - training loss: 0.7899, validation loss: 0.7899
2024-06-02 20:01:19 [INFO]: Epoch 042 - training loss: 0.7906, validation loss: 0.7920
2024-06-02 20:01:23 [INFO]: Epoch 043 - training loss: 0.7899, validation loss: 0.7916
2024-06-02 20:01:28 [INFO]: Epoch 044 - training loss: 0.7889, validation loss: 0.7914
2024-06-02 20:01:33 [INFO]: Epoch 045 - training loss: 0.7809, validation loss: 0.7930
2024-06-02 20:01:38 [INFO]: Epoch 046 - training loss: 0.7900, validation loss: 0.7912
2024-06-02 20:01:43 [INFO]: Epoch 047 - training loss: 0.7799, validation loss: 0.7927
2024-06-02 20:01:49 [INFO]: Epoch 048 - training loss: 0.7889, validation loss: 0.7924
2024-06-02 20:01:54 [INFO]: Epoch 049 - training loss: 0.7841, validation loss: 0.7921
2024-06-02 20:01:59 [INFO]: Epoch 050 - training loss: 0.7824, validation loss: 0.7902
2024-06-02 20:02:04 [INFO]: Epoch 051 - training loss: 0.7798, validation loss: 0.7919
2024-06-02 20:02:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:02:04 [INFO]: Finished training. The best model is from epoch#41.
2024-06-02 20:02:04 [INFO]: Saved the model to results_point_rate05/PeMS/Autoformer_PeMS/round_2/20240602_T195753/Autoformer.pypots
2024-06-02 20:02:05 [INFO]: Successfully saved to results_point_rate05/PeMS/Autoformer_PeMS/round_2/imputation.pkl
2024-06-02 20:02:05 [INFO]: Round2 - Autoformer on PeMS: MAE=0.5272, MSE=1.0376, MRE=0.6542
2024-06-02 20:02:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:02:05 [INFO]: Using the given device: cuda:0
2024-06-02 20:02:05 [INFO]: Model files will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_3/20240602_T200205
2024-06-02 20:02:05 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_3/20240602_T200205/tensorboard
2024-06-02 20:02:05 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-02 20:02:09 [INFO]: Epoch 001 - training loss: 1.7310, validation loss: 1.5538
2024-06-02 20:02:13 [INFO]: Epoch 002 - training loss: 1.6816, validation loss: 1.5042
2024-06-02 20:02:18 [INFO]: Epoch 003 - training loss: 1.6219, validation loss: 1.4146
2024-06-02 20:02:22 [INFO]: Epoch 004 - training loss: 1.5378, validation loss: 1.3283
2024-06-02 20:02:26 [INFO]: Epoch 005 - training loss: 1.4891, validation loss: 1.2963
2024-06-02 20:02:30 [INFO]: Epoch 006 - training loss: 1.4781, validation loss: 1.2856
2024-06-02 20:02:35 [INFO]: Epoch 007 - training loss: 1.4578, validation loss: 1.2847
2024-06-02 20:02:39 [INFO]: Epoch 008 - training loss: 1.4497, validation loss: 1.2812
2024-06-02 20:02:43 [INFO]: Epoch 009 - training loss: 1.4393, validation loss: 1.2808
2024-06-02 20:02:47 [INFO]: Epoch 010 - training loss: 1.4173, validation loss: 1.2799
2024-06-02 20:02:51 [INFO]: Epoch 011 - training loss: 1.3856, validation loss: 1.2750
2024-06-02 20:02:55 [INFO]: Epoch 012 - training loss: 1.3580, validation loss: 1.2723
2024-06-02 20:02:59 [INFO]: Epoch 013 - training loss: 1.3275, validation loss: 1.2851
2024-06-02 20:03:03 [INFO]: Epoch 014 - training loss: 1.2969, validation loss: 1.2937
2024-06-02 20:03:08 [INFO]: Epoch 015 - training loss: 1.2886, validation loss: 1.2790
2024-06-02 20:03:12 [INFO]: Epoch 016 - training loss: 1.2630, validation loss: 1.2302
2024-06-02 20:03:16 [INFO]: Epoch 017 - training loss: 1.2322, validation loss: 1.1931
2024-06-02 20:03:21 [INFO]: Epoch 018 - training loss: 1.2050, validation loss: 1.1573
2024-06-02 20:03:25 [INFO]: Epoch 019 - training loss: 1.1733, validation loss: 1.1593
2024-06-02 20:03:29 [INFO]: Epoch 020 - training loss: 1.1622, validation loss: 1.1597
2024-06-02 20:03:33 [INFO]: Epoch 021 - training loss: 1.1469, validation loss: 1.1591
2024-06-02 20:03:37 [INFO]: Epoch 022 - training loss: 1.1406, validation loss: 1.1583
2024-06-02 20:03:41 [INFO]: Epoch 023 - training loss: 1.1283, validation loss: 1.1584
2024-06-02 20:03:45 [INFO]: Epoch 024 - training loss: 1.1237, validation loss: 1.1534
2024-06-02 20:03:49 [INFO]: Epoch 025 - training loss: 1.1153, validation loss: 1.1523
2024-06-02 20:03:53 [INFO]: Epoch 026 - training loss: 1.1058, validation loss: 1.1502
2024-06-02 20:03:58 [INFO]: Epoch 027 - training loss: 1.1011, validation loss: 1.1480
2024-06-02 20:04:02 [INFO]: Epoch 028 - training loss: 1.0980, validation loss: 1.1480
2024-06-02 20:04:06 [INFO]: Epoch 029 - training loss: 1.0914, validation loss: 1.1446
2024-06-02 20:04:11 [INFO]: Epoch 030 - training loss: 1.0904, validation loss: 1.1474
2024-06-02 20:04:15 [INFO]: Epoch 031 - training loss: 1.0770, validation loss: 1.1450
2024-06-02 20:04:19 [INFO]: Epoch 032 - training loss: 1.0781, validation loss: 1.1426
2024-06-02 20:04:23 [INFO]: Epoch 033 - training loss: 1.0708, validation loss: 1.1367
2024-06-02 20:04:27 [INFO]: Epoch 034 - training loss: 1.0582, validation loss: 1.1375
2024-06-02 20:04:30 [INFO]: Epoch 035 - training loss: 1.0780, validation loss: 1.1580
2024-06-02 20:04:35 [INFO]: Epoch 036 - training loss: 1.0545, validation loss: 1.1270
2024-06-02 20:04:39 [INFO]: Epoch 037 - training loss: 1.0299, validation loss: 1.1370
2024-06-02 20:04:43 [INFO]: Epoch 038 - training loss: 1.0233, validation loss: 1.1447
2024-06-02 20:04:48 [INFO]: Epoch 039 - training loss: 1.0154, validation loss: 1.1656
2024-06-02 20:04:52 [INFO]: Epoch 040 - training loss: 1.0210, validation loss: 1.1616
2024-06-02 20:04:56 [INFO]: Epoch 041 - training loss: 1.0129, validation loss: 1.1505
2024-06-02 20:05:00 [INFO]: Epoch 042 - training loss: 1.0025, validation loss: 1.1553
2024-06-02 20:05:05 [INFO]: Epoch 043 - training loss: 0.9997, validation loss: 1.1545
2024-06-02 20:05:09 [INFO]: Epoch 044 - training loss: 0.9975, validation loss: 1.1560
2024-06-02 20:05:13 [INFO]: Epoch 045 - training loss: 0.9983, validation loss: 1.1528
2024-06-02 20:05:17 [INFO]: Epoch 046 - training loss: 0.9907, validation loss: 1.1592
2024-06-02 20:05:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:05:17 [INFO]: Finished training. The best model is from epoch#36.
2024-06-02 20:05:17 [INFO]: Saved the model to results_point_rate05/PeMS/Autoformer_PeMS/round_3/20240602_T200205/Autoformer.pypots
2024-06-02 20:05:18 [INFO]: Successfully saved to results_point_rate05/PeMS/Autoformer_PeMS/round_3/imputation.pkl
2024-06-02 20:05:18 [INFO]: Round3 - Autoformer on PeMS: MAE=0.6566, MSE=1.4104, MRE=0.8148
2024-06-02 20:05:18 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:05:18 [INFO]: Using the given device: cuda:0
2024-06-02 20:05:18 [INFO]: Model files will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_4/20240602_T200518
2024-06-02 20:05:18 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Autoformer_PeMS/round_4/20240602_T200518/tensorboard
2024-06-02 20:05:18 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 608,926
2024-06-02 20:05:22 [INFO]: Epoch 001 - training loss: 1.7328, validation loss: 1.5573
2024-06-02 20:05:26 [INFO]: Epoch 002 - training loss: 1.6718, validation loss: 1.4749
2024-06-02 20:05:31 [INFO]: Epoch 003 - training loss: 1.5923, validation loss: 1.3681
2024-06-02 20:05:35 [INFO]: Epoch 004 - training loss: 1.5161, validation loss: 1.3161
2024-06-02 20:05:39 [INFO]: Epoch 005 - training loss: 1.4783, validation loss: 1.3008
2024-06-02 20:05:43 [INFO]: Epoch 006 - training loss: 1.4603, validation loss: 1.2985
2024-06-02 20:05:47 [INFO]: Epoch 007 - training loss: 1.4525, validation loss: 1.2918
2024-06-02 20:05:51 [INFO]: Epoch 008 - training loss: 1.4340, validation loss: 1.2839
2024-06-02 20:05:55 [INFO]: Epoch 009 - training loss: 1.4093, validation loss: 1.2770
2024-06-02 20:05:59 [INFO]: Epoch 010 - training loss: 1.4001, validation loss: 1.2836
2024-06-02 20:06:03 [INFO]: Epoch 011 - training loss: 1.3624, validation loss: 1.2784
2024-06-02 20:06:07 [INFO]: Epoch 012 - training loss: 1.3484, validation loss: 1.2471
2024-06-02 20:06:12 [INFO]: Epoch 013 - training loss: 1.3250, validation loss: 1.2308
2024-06-02 20:06:16 [INFO]: Epoch 014 - training loss: 1.2972, validation loss: 1.2328
2024-06-02 20:06:20 [INFO]: Epoch 015 - training loss: 1.2625, validation loss: 1.2393
2024-06-02 20:06:24 [INFO]: Epoch 016 - training loss: 1.2356, validation loss: 1.2155
2024-06-02 20:06:28 [INFO]: Epoch 017 - training loss: 1.2017, validation loss: 1.1873
2024-06-02 20:06:32 [INFO]: Epoch 018 - training loss: 1.1688, validation loss: 1.1810
2024-06-02 20:06:36 [INFO]: Epoch 019 - training loss: 1.1476, validation loss: 1.1731
2024-06-02 20:06:40 [INFO]: Epoch 020 - training loss: 1.1151, validation loss: 1.1812
2024-06-02 20:06:44 [INFO]: Epoch 021 - training loss: 1.0946, validation loss: 1.1769
2024-06-02 20:06:48 [INFO]: Epoch 022 - training loss: 1.0752, validation loss: 1.1807
2024-06-02 20:06:52 [INFO]: Epoch 023 - training loss: 1.0698, validation loss: 1.1740
2024-06-02 20:06:56 [INFO]: Epoch 024 - training loss: 1.0563, validation loss: 1.1755
2024-06-02 20:07:00 [INFO]: Epoch 025 - training loss: 1.0495, validation loss: 1.1781
2024-06-02 20:07:05 [INFO]: Epoch 026 - training loss: 1.0542, validation loss: 1.1729
2024-06-02 20:07:09 [INFO]: Epoch 027 - training loss: 1.0450, validation loss: 1.1736
2024-06-02 20:07:13 [INFO]: Epoch 028 - training loss: 1.0455, validation loss: 1.1770
2024-06-02 20:07:17 [INFO]: Epoch 029 - training loss: 1.0513, validation loss: 1.1793
2024-06-02 20:07:21 [INFO]: Epoch 030 - training loss: 1.0392, validation loss: 1.1745
2024-06-02 20:07:25 [INFO]: Epoch 031 - training loss: 1.0329, validation loss: 1.1769
2024-06-02 20:07:29 [INFO]: Epoch 032 - training loss: 1.0302, validation loss: 1.1786
2024-06-02 20:07:33 [INFO]: Epoch 033 - training loss: 1.0298, validation loss: 1.1762
2024-06-02 20:07:37 [INFO]: Epoch 034 - training loss: 1.0260, validation loss: 1.1792
2024-06-02 20:07:41 [INFO]: Epoch 035 - training loss: 1.0195, validation loss: 1.1754
2024-06-02 20:07:46 [INFO]: Epoch 036 - training loss: 1.0274, validation loss: 1.1772
2024-06-02 20:07:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:07:46 [INFO]: Finished training. The best model is from epoch#26.
2024-06-02 20:07:46 [INFO]: Saved the model to results_point_rate05/PeMS/Autoformer_PeMS/round_4/20240602_T200518/Autoformer.pypots
2024-06-02 20:07:46 [INFO]: Successfully saved to results_point_rate05/PeMS/Autoformer_PeMS/round_4/imputation.pkl
2024-06-02 20:07:46 [INFO]: Round4 - Autoformer on PeMS: MAE=0.6769, MSE=1.4326, MRE=0.8399
2024-06-02 20:07:46 [INFO]: Done! Final results:
Averaged Autoformer (608,926 params) on PeMS: MAE=0.6019 ± 0.06754148457393856, MSE=1.2422 ± 0.17252194088135298, MRE=0.7469 ± 0.083813253113467, average inference time=0.22
