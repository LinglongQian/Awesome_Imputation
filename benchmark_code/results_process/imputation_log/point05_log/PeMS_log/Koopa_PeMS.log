2024-06-03 00:45:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:45:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:08 [INFO]: Model files will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_0/20240603_T004508
2024-06-03 00:45:08 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_0/20240603_T004508/tensorboard
2024-06-03 00:45:10 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 00:45:30 [INFO]: Epoch 001 - training loss: 1.0569, validation loss: 0.9206
2024-06-03 00:45:41 [INFO]: Epoch 002 - training loss: 0.8111, validation loss: 0.9384
2024-06-03 00:45:53 [INFO]: Epoch 003 - training loss: 0.7609, validation loss: 0.9650
2024-06-03 00:46:04 [INFO]: Epoch 004 - training loss: 0.6862, validation loss: 0.9823
2024-06-03 00:46:17 [INFO]: Epoch 005 - training loss: 0.6383, validation loss: 0.7721
2024-06-03 00:46:29 [INFO]: Epoch 006 - training loss: 0.5907, validation loss: 0.7269
2024-06-03 00:46:41 [INFO]: Epoch 007 - training loss: 0.5663, validation loss: 0.6627
2024-06-03 00:46:53 [INFO]: Epoch 008 - training loss: 0.5351, validation loss: 0.6534
2024-06-03 00:47:06 [INFO]: Epoch 009 - training loss: 0.5211, validation loss: 0.6245
2024-06-03 00:47:15 [INFO]: Epoch 010 - training loss: 0.4930, validation loss: 0.6027
2024-06-03 00:47:27 [INFO]: Epoch 011 - training loss: 0.4772, validation loss: 0.5816
2024-06-03 00:47:37 [INFO]: Epoch 012 - training loss: 0.4580, validation loss: 0.5913
2024-06-03 00:47:48 [INFO]: Epoch 013 - training loss: 0.4498, validation loss: 0.5556
2024-06-03 00:47:58 [INFO]: Epoch 014 - training loss: 0.4464, validation loss: 0.5635
2024-06-03 00:48:10 [INFO]: Epoch 015 - training loss: 0.4406, validation loss: 0.5468
2024-06-03 00:48:22 [INFO]: Epoch 016 - training loss: 0.4341, validation loss: 0.5475
2024-06-03 00:48:34 [INFO]: Epoch 017 - training loss: 0.4233, validation loss: 0.5514
2024-06-03 00:48:48 [INFO]: Epoch 018 - training loss: 0.4212, validation loss: 0.5478
2024-06-03 00:48:58 [INFO]: Epoch 019 - training loss: 0.4122, validation loss: 0.5401
2024-06-03 00:49:11 [INFO]: Epoch 020 - training loss: 0.4068, validation loss: 0.5317
2024-06-03 00:49:24 [INFO]: Epoch 021 - training loss: 0.4019, validation loss: 0.5333
2024-06-03 00:49:36 [INFO]: Epoch 022 - training loss: 0.4003, validation loss: 0.5245
2024-06-03 00:49:47 [INFO]: Epoch 023 - training loss: 0.3998, validation loss: 0.5271
2024-06-03 00:49:59 [INFO]: Epoch 024 - training loss: 0.3990, validation loss: 0.5307
2024-06-03 00:50:11 [INFO]: Epoch 025 - training loss: 0.3977, validation loss: 0.5171
2024-06-03 00:50:23 [INFO]: Epoch 026 - training loss: 0.3968, validation loss: 0.5163
2024-06-03 00:50:34 [INFO]: Epoch 027 - training loss: 2.4328, validation loss: 9.3431
2024-06-03 00:50:45 [INFO]: Epoch 028 - training loss: 3.6467, validation loss: 4.5329
2024-06-03 00:50:55 [INFO]: Epoch 029 - training loss: 2.6927, validation loss: 2.6294
2024-06-03 00:51:07 [INFO]: Epoch 030 - training loss: 2.0367, validation loss: 1.7729
2024-06-03 00:51:20 [INFO]: Epoch 031 - training loss: 1.6696, validation loss: 1.3602
2024-06-03 00:51:32 [INFO]: Epoch 032 - training loss: 1.4493, validation loss: 1.1839
2024-06-03 00:51:42 [INFO]: Epoch 033 - training loss: 1.3196, validation loss: 1.0548
2024-06-03 00:51:52 [INFO]: Epoch 034 - training loss: 1.2508, validation loss: 0.9550
2024-06-03 00:52:02 [INFO]: Epoch 035 - training loss: 1.1863, validation loss: 0.9406
2024-06-03 00:52:12 [INFO]: Epoch 036 - training loss: 1.1508, validation loss: 0.9089
2024-06-03 00:52:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 00:52:12 [INFO]: Finished training. The best model is from epoch#26.
2024-06-03 00:52:13 [INFO]: Saved the model to results_point_rate05/PeMS/Koopa_PeMS/round_0/20240603_T004508/Koopa.pypots
2024-06-03 00:52:15 [INFO]: Successfully saved to results_point_rate05/PeMS/Koopa_PeMS/round_0/imputation.pkl
2024-06-03 00:52:15 [INFO]: Round0 - Koopa on PeMS: MAE=0.7321, MSE=1.2156, MRE=0.9085
2024-06-03 00:52:15 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 00:52:15 [INFO]: Using the given device: cuda:0
2024-06-03 00:52:15 [INFO]: Model files will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_1/20240603_T005215
2024-06-03 00:52:15 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_1/20240603_T005215/tensorboard
2024-06-03 00:52:15 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 00:52:26 [INFO]: Epoch 001 - training loss: 1.1689, validation loss: 1.0164
2024-06-03 00:52:37 [INFO]: Epoch 002 - training loss: 0.8465, validation loss: 0.9174
2024-06-03 00:52:47 [INFO]: Epoch 003 - training loss: 0.7754, validation loss: 0.8868
2024-06-03 00:52:58 [INFO]: Epoch 004 - training loss: 0.6895, validation loss: 0.8019
2024-06-03 00:53:08 [INFO]: Epoch 005 - training loss: 0.6301, validation loss: 0.7491
2024-06-03 00:53:17 [INFO]: Epoch 006 - training loss: 0.5805, validation loss: 0.7270
2024-06-03 00:53:27 [INFO]: Epoch 007 - training loss: 0.5466, validation loss: 0.6739
2024-06-03 00:53:38 [INFO]: Epoch 008 - training loss: 0.5268, validation loss: 0.6564
2024-06-03 00:53:47 [INFO]: Epoch 009 - training loss: 0.5083, validation loss: 0.6420
2024-06-03 00:53:57 [INFO]: Epoch 010 - training loss: 0.4951, validation loss: 0.5950
2024-06-03 00:54:06 [INFO]: Epoch 011 - training loss: 0.4909, validation loss: 0.6051
2024-06-03 00:54:16 [INFO]: Epoch 012 - training loss: 0.4768, validation loss: 0.6064
2024-06-03 00:54:26 [INFO]: Epoch 013 - training loss: 0.4643, validation loss: 0.5712
2024-06-03 00:54:36 [INFO]: Epoch 014 - training loss: 0.4522, validation loss: 0.5751
2024-06-03 00:54:47 [INFO]: Epoch 015 - training loss: 0.4446, validation loss: 0.5564
2024-06-03 00:54:58 [INFO]: Epoch 016 - training loss: 0.4367, validation loss: 0.5592
2024-06-03 00:55:09 [INFO]: Epoch 017 - training loss: 0.4316, validation loss: 0.5472
2024-06-03 00:55:19 [INFO]: Epoch 018 - training loss: 0.4255, validation loss: 0.5480
2024-06-03 00:55:29 [INFO]: Epoch 019 - training loss: 0.4285, validation loss: 0.5320
2024-06-03 00:55:38 [INFO]: Epoch 020 - training loss: 0.4169, validation loss: 0.5351
2024-06-03 00:55:49 [INFO]: Epoch 021 - training loss: 0.4150, validation loss: 0.5363
2024-06-03 00:56:00 [INFO]: Epoch 022 - training loss: 0.4094, validation loss: 0.5236
2024-06-03 00:56:10 [INFO]: Epoch 023 - training loss: 0.4043, validation loss: 0.5210
2024-06-03 00:56:20 [INFO]: Epoch 024 - training loss: 0.4016, validation loss: 0.5140
2024-06-03 00:56:31 [INFO]: Epoch 025 - training loss: 0.3957, validation loss: 0.5132
2024-06-03 00:56:41 [INFO]: Epoch 026 - training loss: 0.3897, validation loss: 0.5130
2024-06-03 00:56:52 [INFO]: Epoch 027 - training loss: 0.3882, validation loss: 0.5067
2024-06-03 00:57:03 [INFO]: Epoch 028 - training loss: 0.3917, validation loss: 0.5064
2024-06-03 00:57:12 [INFO]: Epoch 029 - training loss: 0.3832, validation loss: 0.5176
2024-06-03 00:57:22 [INFO]: Epoch 030 - training loss: 0.3815, validation loss: 0.4988
2024-06-03 00:57:32 [INFO]: Epoch 031 - training loss: 0.3794, validation loss: 0.5087
2024-06-03 00:57:44 [INFO]: Epoch 032 - training loss: 0.3914, validation loss: 0.5031
2024-06-03 00:57:54 [INFO]: Epoch 033 - training loss: 0.3795, validation loss: 0.5023
2024-06-03 00:58:04 [INFO]: Epoch 034 - training loss: 0.3741, validation loss: 0.5016
2024-06-03 00:58:16 [INFO]: Epoch 035 - training loss: 0.3691, validation loss: 0.5011
2024-06-03 00:58:26 [INFO]: Epoch 036 - training loss: 0.3683, validation loss: 0.4826
2024-06-03 00:58:37 [INFO]: Epoch 037 - training loss: 0.3748, validation loss: 0.4972
2024-06-03 00:58:47 [INFO]: Epoch 038 - training loss: 0.3642, validation loss: 0.5058
2024-06-03 00:58:59 [INFO]: Epoch 039 - training loss: 0.3739, validation loss: 0.5094
2024-06-03 00:59:08 [INFO]: Epoch 040 - training loss: 0.3780, validation loss: 0.4875
2024-06-03 00:59:19 [INFO]: Epoch 041 - training loss: 0.3655, validation loss: 0.4880
2024-06-03 00:59:28 [INFO]: Epoch 042 - training loss: 0.3596, validation loss: 0.4877
2024-06-03 00:59:38 [INFO]: Epoch 043 - training loss: 0.3609, validation loss: 0.4866
2024-06-03 00:59:49 [INFO]: Epoch 044 - training loss: 0.3733, validation loss: 0.4916
2024-06-03 01:00:00 [INFO]: Epoch 045 - training loss: 0.3630, validation loss: 0.4844
2024-06-03 01:00:09 [INFO]: Epoch 046 - training loss: 0.3615, validation loss: 0.4895
2024-06-03 01:00:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:00:09 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 01:00:09 [INFO]: Saved the model to results_point_rate05/PeMS/Koopa_PeMS/round_1/20240603_T005215/Koopa.pypots
2024-06-03 01:00:11 [INFO]: Successfully saved to results_point_rate05/PeMS/Koopa_PeMS/round_1/imputation.pkl
2024-06-03 01:00:11 [INFO]: Round1 - Koopa on PeMS: MAE=0.4402, MSE=0.7323, MRE=0.5463
2024-06-03 01:00:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:00:11 [INFO]: Using the given device: cuda:0
2024-06-03 01:00:11 [INFO]: Model files will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_2/20240603_T010011
2024-06-03 01:00:11 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_2/20240603_T010011/tensorboard
2024-06-03 01:00:12 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 01:00:25 [INFO]: Epoch 001 - training loss: 1.0988, validation loss: 0.9625
2024-06-03 01:00:36 [INFO]: Epoch 002 - training loss: 0.8526, validation loss: 0.9119
2024-06-03 01:00:46 [INFO]: Epoch 003 - training loss: 0.7768, validation loss: 0.8560
2024-06-03 01:00:56 [INFO]: Epoch 004 - training loss: 0.7022, validation loss: 0.8116
2024-06-03 01:01:07 [INFO]: Epoch 005 - training loss: 0.6503, validation loss: 0.7871
2024-06-03 01:01:17 [INFO]: Epoch 006 - training loss: 0.6137, validation loss: 0.7392
2024-06-03 01:01:27 [INFO]: Epoch 007 - training loss: 0.5861, validation loss: 0.7024
2024-06-03 01:01:39 [INFO]: Epoch 008 - training loss: 0.5591, validation loss: 0.6569
2024-06-03 01:01:49 [INFO]: Epoch 009 - training loss: 0.5371, validation loss: 0.6409
2024-06-03 01:01:59 [INFO]: Epoch 010 - training loss: 0.5213, validation loss: 0.6638
2024-06-03 01:02:09 [INFO]: Epoch 011 - training loss: 0.5168, validation loss: 0.6291
2024-06-03 01:02:19 [INFO]: Epoch 012 - training loss: 0.5043, validation loss: 0.6282
2024-06-03 01:02:30 [INFO]: Epoch 013 - training loss: 0.4926, validation loss: 0.6275
2024-06-03 01:02:39 [INFO]: Epoch 014 - training loss: 0.4754, validation loss: 0.6162
2024-06-03 01:02:50 [INFO]: Epoch 015 - training loss: 0.4636, validation loss: 0.6007
2024-06-03 01:03:00 [INFO]: Epoch 016 - training loss: 0.4597, validation loss: 0.5889
2024-06-03 01:03:09 [INFO]: Epoch 017 - training loss: 0.4560, validation loss: 0.5848
2024-06-03 01:03:19 [INFO]: Epoch 018 - training loss: 0.4474, validation loss: 0.5834
2024-06-03 01:03:29 [INFO]: Epoch 019 - training loss: 0.4528, validation loss: 0.5979
2024-06-03 01:03:39 [INFO]: Epoch 020 - training loss: 0.4436, validation loss: 0.5851
2024-06-03 01:03:49 [INFO]: Epoch 021 - training loss: 0.4371, validation loss: 0.5841
2024-06-03 01:04:01 [INFO]: Epoch 022 - training loss: 0.4415, validation loss: 0.5925
2024-06-03 01:04:12 [INFO]: Epoch 023 - training loss: 0.4302, validation loss: 0.5731
2024-06-03 01:04:24 [INFO]: Epoch 024 - training loss: 0.4264, validation loss: 0.5631
2024-06-03 01:04:35 [INFO]: Epoch 025 - training loss: 0.4295, validation loss: 0.5682
2024-06-03 01:04:45 [INFO]: Epoch 026 - training loss: 0.4229, validation loss: 0.5525
2024-06-03 01:04:55 [INFO]: Epoch 027 - training loss: 0.4239, validation loss: 0.5637
2024-06-03 01:05:07 [INFO]: Epoch 028 - training loss: 0.4179, validation loss: 0.5581
2024-06-03 01:05:19 [INFO]: Epoch 029 - training loss: 0.4139, validation loss: 0.5443
2024-06-03 01:05:30 [INFO]: Epoch 030 - training loss: 0.4122, validation loss: 0.5691
2024-06-03 01:05:41 [INFO]: Epoch 031 - training loss: 0.4133, validation loss: 0.5508
2024-06-03 01:05:50 [INFO]: Epoch 032 - training loss: 0.4133, validation loss: 0.5610
2024-06-03 01:06:01 [INFO]: Epoch 033 - training loss: 0.4113, validation loss: 0.5499
2024-06-03 01:06:12 [INFO]: Epoch 034 - training loss: 0.4087, validation loss: 0.5524
2024-06-03 01:06:21 [INFO]: Epoch 035 - training loss: 0.4065, validation loss: 0.5595
2024-06-03 01:06:33 [INFO]: Epoch 036 - training loss: 0.4075, validation loss: 0.5374
2024-06-03 01:06:43 [INFO]: Epoch 037 - training loss: 0.4049, validation loss: 0.5656
2024-06-03 01:06:54 [INFO]: Epoch 038 - training loss: 0.4013, validation loss: 0.5425
2024-06-03 01:07:05 [INFO]: Epoch 039 - training loss: 0.4032, validation loss: 0.5531
2024-06-03 01:07:17 [INFO]: Epoch 040 - training loss: 0.4002, validation loss: 0.5536
2024-06-03 01:07:28 [INFO]: Epoch 041 - training loss: 0.3963, validation loss: 0.5324
2024-06-03 01:07:39 [INFO]: Epoch 042 - training loss: 0.3940, validation loss: 0.5539
2024-06-03 01:07:50 [INFO]: Epoch 043 - training loss: 0.3978, validation loss: 0.5384
2024-06-03 01:08:01 [INFO]: Epoch 044 - training loss: 0.3923, validation loss: 0.5348
2024-06-03 01:08:13 [INFO]: Epoch 045 - training loss: 0.3872, validation loss: 0.5449
2024-06-03 01:08:23 [INFO]: Epoch 046 - training loss: 0.3893, validation loss: 0.5501
2024-06-03 01:08:32 [INFO]: Epoch 047 - training loss: 0.3911, validation loss: 0.5425
2024-06-03 01:08:41 [INFO]: Epoch 048 - training loss: 0.3884, validation loss: 0.5488
2024-06-03 01:08:50 [INFO]: Epoch 049 - training loss: 0.3873, validation loss: 0.5398
2024-06-03 01:09:00 [INFO]: Epoch 050 - training loss: 0.3953, validation loss: 0.5554
2024-06-03 01:09:09 [INFO]: Epoch 051 - training loss: 0.3879, validation loss: 0.5387
2024-06-03 01:09:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:09:09 [INFO]: Finished training. The best model is from epoch#41.
2024-06-03 01:09:10 [INFO]: Saved the model to results_point_rate05/PeMS/Koopa_PeMS/round_2/20240603_T010011/Koopa.pypots
2024-06-03 01:09:12 [INFO]: Successfully saved to results_point_rate05/PeMS/Koopa_PeMS/round_2/imputation.pkl
2024-06-03 01:09:12 [INFO]: Round2 - Koopa on PeMS: MAE=0.4637, MSE=0.8021, MRE=0.5754
2024-06-03 01:09:12 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:09:12 [INFO]: Using the given device: cuda:0
2024-06-03 01:09:12 [INFO]: Model files will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_3/20240603_T010912
2024-06-03 01:09:12 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_3/20240603_T010912/tensorboard
2024-06-03 01:09:12 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 01:09:23 [INFO]: Epoch 001 - training loss: 1.0929, validation loss: 0.9431
2024-06-03 01:09:33 [INFO]: Epoch 002 - training loss: 0.8264, validation loss: 0.9556
2024-06-03 01:09:45 [INFO]: Epoch 003 - training loss: 0.7696, validation loss: 0.9176
2024-06-03 01:09:56 [INFO]: Epoch 004 - training loss: 0.7013, validation loss: 0.8647
2024-06-03 01:10:05 [INFO]: Epoch 005 - training loss: 0.6432, validation loss: 0.7733
2024-06-03 01:10:15 [INFO]: Epoch 006 - training loss: 0.5950, validation loss: 0.7130
2024-06-03 01:10:26 [INFO]: Epoch 007 - training loss: 0.5624, validation loss: 0.7776
2024-06-03 01:10:36 [INFO]: Epoch 008 - training loss: 0.5551, validation loss: 0.6605
2024-06-03 01:10:47 [INFO]: Epoch 009 - training loss: 0.5309, validation loss: 0.6516
2024-06-03 01:10:57 [INFO]: Epoch 010 - training loss: 0.5085, validation loss: 0.6108
2024-06-03 01:11:07 [INFO]: Epoch 011 - training loss: 0.4955, validation loss: 0.5959
2024-06-03 01:11:19 [INFO]: Epoch 012 - training loss: 0.4876, validation loss: 0.5921
2024-06-03 01:11:29 [INFO]: Epoch 013 - training loss: 0.4773, validation loss: 0.5890
2024-06-03 01:11:40 [INFO]: Epoch 014 - training loss: 0.4602, validation loss: 0.5680
2024-06-03 01:11:53 [INFO]: Epoch 015 - training loss: 0.4536, validation loss: 0.5811
2024-06-03 01:12:05 [INFO]: Epoch 016 - training loss: 0.4486, validation loss: 0.5618
2024-06-03 01:12:14 [INFO]: Epoch 017 - training loss: 0.4416, validation loss: 0.5481
2024-06-03 01:12:27 [INFO]: Epoch 018 - training loss: 0.4414, validation loss: 0.5385
2024-06-03 01:12:37 [INFO]: Epoch 019 - training loss: 0.4294, validation loss: 0.5357
2024-06-03 01:12:48 [INFO]: Epoch 020 - training loss: 0.4278, validation loss: 0.5399
2024-06-03 01:12:59 [INFO]: Epoch 021 - training loss: 0.4296, validation loss: 0.5334
2024-06-03 01:13:10 [INFO]: Epoch 022 - training loss: 0.4231, validation loss: 0.5384
2024-06-03 01:13:21 [INFO]: Epoch 023 - training loss: 0.4163, validation loss: 0.5243
2024-06-03 01:13:30 [INFO]: Epoch 024 - training loss: 0.4110, validation loss: 0.5215
2024-06-03 01:13:42 [INFO]: Epoch 025 - training loss: 0.4103, validation loss: 0.5394
2024-06-03 01:13:53 [INFO]: Epoch 026 - training loss: 0.4060, validation loss: 0.5275
2024-06-03 01:14:04 [INFO]: Epoch 027 - training loss: 0.4001, validation loss: 0.5102
2024-06-03 01:14:14 [INFO]: Epoch 028 - training loss: 0.3986, validation loss: 0.5149
2024-06-03 01:14:25 [INFO]: Epoch 029 - training loss: 0.3952, validation loss: 0.5111
2024-06-03 01:14:36 [INFO]: Epoch 030 - training loss: 0.3967, validation loss: 0.5073
2024-06-03 01:14:46 [INFO]: Epoch 031 - training loss: 0.3941, validation loss: 0.5125
2024-06-03 01:14:57 [INFO]: Epoch 032 - training loss: 0.3882, validation loss: 0.5074
2024-06-03 01:15:08 [INFO]: Epoch 033 - training loss: 0.3948, validation loss: 0.5059
2024-06-03 01:15:18 [INFO]: Epoch 034 - training loss: 0.3861, validation loss: 0.5119
2024-06-03 01:15:28 [INFO]: Epoch 035 - training loss: 0.3852, validation loss: 0.5101
2024-06-03 01:15:38 [INFO]: Epoch 036 - training loss: 0.3866, validation loss: 0.5222
2024-06-03 01:15:49 [INFO]: Epoch 037 - training loss: 0.3820, validation loss: 0.5102
2024-06-03 01:15:58 [INFO]: Epoch 038 - training loss: 0.3816, validation loss: 0.4978
2024-06-03 01:16:09 [INFO]: Epoch 039 - training loss: 0.3819, validation loss: 0.5158
2024-06-03 01:16:19 [INFO]: Epoch 040 - training loss: 0.3840, validation loss: 0.5076
2024-06-03 01:16:29 [INFO]: Epoch 041 - training loss: 0.3765, validation loss: 0.4993
2024-06-03 01:16:40 [INFO]: Epoch 042 - training loss: 0.3752, validation loss: 0.4936
2024-06-03 01:16:50 [INFO]: Epoch 043 - training loss: 0.3750, validation loss: 0.4898
2024-06-03 01:17:02 [INFO]: Epoch 044 - training loss: 0.3714, validation loss: 0.4975
2024-06-03 01:17:12 [INFO]: Epoch 045 - training loss: 0.3728, validation loss: 0.4875
2024-06-03 01:17:22 [INFO]: Epoch 046 - training loss: 0.3716, validation loss: 0.4919
2024-06-03 01:17:32 [INFO]: Epoch 047 - training loss: 0.3706, validation loss: 0.4979
2024-06-03 01:17:42 [INFO]: Epoch 048 - training loss: 0.3667, validation loss: 0.5054
2024-06-03 01:17:51 [INFO]: Epoch 049 - training loss: 0.3681, validation loss: 0.4934
2024-06-03 01:18:02 [INFO]: Epoch 050 - training loss: 0.3664, validation loss: 0.4936
2024-06-03 01:18:13 [INFO]: Epoch 051 - training loss: 0.3675, validation loss: 0.4903
2024-06-03 01:18:22 [INFO]: Epoch 052 - training loss: 0.3661, validation loss: 0.5083
2024-06-03 01:18:32 [INFO]: Epoch 053 - training loss: 0.3681, validation loss: 0.4919
2024-06-03 01:18:42 [INFO]: Epoch 054 - training loss: 0.3681, validation loss: 0.4855
2024-06-03 01:18:53 [INFO]: Epoch 055 - training loss: 0.3625, validation loss: 0.4877
2024-06-03 01:19:03 [INFO]: Epoch 056 - training loss: 0.3644, validation loss: 0.4851
2024-06-03 01:19:12 [INFO]: Epoch 057 - training loss: 0.3635, validation loss: 0.4897
2024-06-03 01:19:21 [INFO]: Epoch 058 - training loss: 0.3612, validation loss: 0.4840
2024-06-03 01:19:32 [INFO]: Epoch 059 - training loss: 0.3651, validation loss: 0.4815
2024-06-03 01:19:43 [INFO]: Epoch 060 - training loss: 0.3615, validation loss: 0.4902
2024-06-03 01:19:54 [INFO]: Epoch 061 - training loss: 0.3583, validation loss: 0.4918
2024-06-03 01:20:04 [INFO]: Epoch 062 - training loss: 0.3562, validation loss: 0.4821
2024-06-03 01:20:15 [INFO]: Epoch 063 - training loss: 0.3620, validation loss: 0.4896
2024-06-03 01:20:27 [INFO]: Epoch 064 - training loss: 0.3542, validation loss: 0.4814
2024-06-03 01:20:38 [INFO]: Epoch 065 - training loss: 0.3549, validation loss: 0.4867
2024-06-03 01:20:48 [INFO]: Epoch 066 - training loss: 0.3569, validation loss: 0.4762
2024-06-03 01:20:59 [INFO]: Epoch 067 - training loss: 0.3526, validation loss: 0.4834
2024-06-03 01:21:09 [INFO]: Epoch 068 - training loss: 0.3511, validation loss: 0.4819
2024-06-03 01:21:20 [INFO]: Epoch 069 - training loss: 0.3541, validation loss: 0.4766
2024-06-03 01:21:31 [INFO]: Epoch 070 - training loss: 0.3531, validation loss: 0.4867
2024-06-03 01:21:42 [INFO]: Epoch 071 - training loss: 0.3501, validation loss: 0.4759
2024-06-03 01:21:53 [INFO]: Epoch 072 - training loss: 0.3537, validation loss: 0.4867
2024-06-03 01:22:04 [INFO]: Epoch 073 - training loss: 0.3607, validation loss: 0.4768
2024-06-03 01:22:15 [INFO]: Epoch 074 - training loss: 0.3582, validation loss: 0.4807
2024-06-03 01:22:27 [INFO]: Epoch 075 - training loss: 0.3507, validation loss: 0.4821
2024-06-03 01:22:38 [INFO]: Epoch 076 - training loss: 0.3488, validation loss: 0.4890
2024-06-03 01:22:49 [INFO]: Epoch 077 - training loss: 0.3516, validation loss: 0.4790
2024-06-03 01:23:00 [INFO]: Epoch 078 - training loss: 0.3477, validation loss: 0.4792
2024-06-03 01:23:12 [INFO]: Epoch 079 - training loss: 0.3515, validation loss: 0.5069
2024-06-03 01:23:24 [INFO]: Epoch 080 - training loss: 0.3666, validation loss: 0.4982
2024-06-03 01:23:36 [INFO]: Epoch 081 - training loss: 0.3597, validation loss: 0.4831
2024-06-03 01:23:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:23:36 [INFO]: Finished training. The best model is from epoch#71.
2024-06-03 01:23:36 [INFO]: Saved the model to results_point_rate05/PeMS/Koopa_PeMS/round_3/20240603_T010912/Koopa.pypots
2024-06-03 01:23:38 [INFO]: Successfully saved to results_point_rate05/PeMS/Koopa_PeMS/round_3/imputation.pkl
2024-06-03 01:23:38 [INFO]: Round3 - Koopa on PeMS: MAE=0.4279, MSE=0.7151, MRE=0.5309
2024-06-03 01:23:38 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:23:38 [INFO]: Using the given device: cuda:0
2024-06-03 01:23:38 [INFO]: Model files will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_4/20240603_T012338
2024-06-03 01:23:38 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/Koopa_PeMS/round_4/20240603_T012338/tensorboard
2024-06-03 01:23:38 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 13,306,214
2024-06-03 01:23:45 [INFO]: Epoch 001 - training loss: 1.0798, validation loss: 0.9691
2024-06-03 01:23:52 [INFO]: Epoch 002 - training loss: 0.8742, validation loss: 0.9203
2024-06-03 01:23:57 [INFO]: Epoch 003 - training loss: 0.8102, validation loss: 0.8803
2024-06-03 01:24:03 [INFO]: Epoch 004 - training loss: 0.7520, validation loss: 0.8792
2024-06-03 01:24:09 [INFO]: Epoch 005 - training loss: 0.6866, validation loss: 0.7825
2024-06-03 01:24:15 [INFO]: Epoch 006 - training loss: 0.6362, validation loss: 0.7425
2024-06-03 01:24:21 [INFO]: Epoch 007 - training loss: 0.6023, validation loss: 0.7531
2024-06-03 01:24:27 [INFO]: Epoch 008 - training loss: 0.5776, validation loss: 0.7660
2024-06-03 01:24:32 [INFO]: Epoch 009 - training loss: 0.5621, validation loss: 0.7574
2024-06-03 01:24:39 [INFO]: Epoch 010 - training loss: 0.5573, validation loss: 0.7469
2024-06-03 01:24:45 [INFO]: Epoch 011 - training loss: 0.5394, validation loss: 0.7177
2024-06-03 01:24:52 [INFO]: Epoch 012 - training loss: 0.5236, validation loss: 0.6734
2024-06-03 01:24:58 [INFO]: Epoch 013 - training loss: 0.5094, validation loss: 0.6777
2024-06-03 01:25:05 [INFO]: Epoch 014 - training loss: 0.4983, validation loss: 0.6992
2024-06-03 01:25:10 [INFO]: Epoch 015 - training loss: 0.4903, validation loss: 0.6556
2024-06-03 01:25:17 [INFO]: Epoch 016 - training loss: 0.4875, validation loss: 0.6540
2024-06-03 01:25:22 [INFO]: Epoch 017 - training loss: 0.4809, validation loss: 0.6512
2024-06-03 01:25:28 [INFO]: Epoch 018 - training loss: 0.4753, validation loss: 0.6519
2024-06-03 01:25:35 [INFO]: Epoch 019 - training loss: 0.4754, validation loss: 0.6338
2024-06-03 01:25:40 [INFO]: Epoch 020 - training loss: 0.4692, validation loss: 0.6309
2024-06-03 01:25:46 [INFO]: Epoch 021 - training loss: 0.4572, validation loss: 0.6090
2024-06-03 01:25:52 [INFO]: Epoch 022 - training loss: 0.4526, validation loss: 0.6096
2024-06-03 01:25:59 [INFO]: Epoch 023 - training loss: 0.5053, validation loss: 1.4239
2024-06-03 01:26:04 [INFO]: Epoch 024 - training loss: 2.7950, validation loss: 2.5667
2024-06-03 01:26:10 [INFO]: Epoch 025 - training loss: 1.1972, validation loss: 0.6742
2024-06-03 01:26:15 [INFO]: Epoch 026 - training loss: 0.5825, validation loss: 0.6448
2024-06-03 01:26:21 [INFO]: Epoch 027 - training loss: 0.4759, validation loss: 0.5965
2024-06-03 01:26:27 [INFO]: Epoch 028 - training loss: 0.4526, validation loss: 0.6043
2024-06-03 01:26:32 [INFO]: Epoch 029 - training loss: 0.4429, validation loss: 0.5788
2024-06-03 01:26:38 [INFO]: Epoch 030 - training loss: 0.4389, validation loss: 0.5893
2024-06-03 01:26:43 [INFO]: Epoch 031 - training loss: 0.4373, validation loss: 0.5901
2024-06-03 01:26:49 [INFO]: Epoch 032 - training loss: 0.4319, validation loss: 0.5904
2024-06-03 01:26:55 [INFO]: Epoch 033 - training loss: 0.4265, validation loss: 0.5730
2024-06-03 01:27:01 [INFO]: Epoch 034 - training loss: 0.4294, validation loss: 0.5876
2024-06-03 01:27:07 [INFO]: Epoch 035 - training loss: 0.4378, validation loss: 0.5805
2024-06-03 01:27:13 [INFO]: Epoch 036 - training loss: 0.4290, validation loss: 0.5816
2024-06-03 01:27:18 [INFO]: Epoch 037 - training loss: 0.4211, validation loss: 0.5671
2024-06-03 01:27:24 [INFO]: Epoch 038 - training loss: 0.4212, validation loss: 0.5767
2024-06-03 01:27:30 [INFO]: Epoch 039 - training loss: 0.4207, validation loss: 0.5743
2024-06-03 01:27:36 [INFO]: Epoch 040 - training loss: 0.4186, validation loss: 0.5655
2024-06-03 01:27:42 [INFO]: Epoch 041 - training loss: 0.4155, validation loss: 0.5649
2024-06-03 01:27:48 [INFO]: Epoch 042 - training loss: 0.4127, validation loss: 0.5590
2024-06-03 01:27:54 [INFO]: Epoch 043 - training loss: 0.4129, validation loss: 0.5607
2024-06-03 01:28:00 [INFO]: Epoch 044 - training loss: 0.4111, validation loss: 0.5682
2024-06-03 01:28:05 [INFO]: Epoch 045 - training loss: 0.4142, validation loss: 0.5643
2024-06-03 01:28:10 [INFO]: Epoch 046 - training loss: 0.4175, validation loss: 0.5591
2024-06-03 01:28:16 [INFO]: Epoch 047 - training loss: 0.4083, validation loss: 0.5712
2024-06-03 01:28:22 [INFO]: Epoch 048 - training loss: 0.4222, validation loss: 0.5551
2024-06-03 01:28:28 [INFO]: Epoch 049 - training loss: 0.4082, validation loss: 0.5588
2024-06-03 01:28:34 [INFO]: Epoch 050 - training loss: 0.4056, validation loss: 0.5752
2024-06-03 01:28:39 [INFO]: Epoch 051 - training loss: 0.4027, validation loss: 0.5599
2024-06-03 01:28:45 [INFO]: Epoch 052 - training loss: 0.4031, validation loss: 0.5682
2024-06-03 01:28:51 [INFO]: Epoch 053 - training loss: 0.4128, validation loss: 0.5541
2024-06-03 01:28:57 [INFO]: Epoch 054 - training loss: 0.4132, validation loss: 0.5505
2024-06-03 01:29:04 [INFO]: Epoch 055 - training loss: 0.4115, validation loss: 0.5570
2024-06-03 01:29:09 [INFO]: Epoch 056 - training loss: 0.4048, validation loss: 0.5574
2024-06-03 01:29:15 [INFO]: Epoch 057 - training loss: 0.3971, validation loss: 0.5529
2024-06-03 01:29:21 [INFO]: Epoch 058 - training loss: 0.3962, validation loss: 0.5508
2024-06-03 01:29:27 [INFO]: Epoch 059 - training loss: 0.3952, validation loss: 0.5575
2024-06-03 01:29:32 [INFO]: Epoch 060 - training loss: 0.4009, validation loss: 0.5539
2024-06-03 01:29:38 [INFO]: Epoch 061 - training loss: 0.4031, validation loss: 0.5580
2024-06-03 01:29:44 [INFO]: Epoch 062 - training loss: 0.4036, validation loss: 0.5443
2024-06-03 01:29:49 [INFO]: Epoch 063 - training loss: 0.3994, validation loss: 0.5497
2024-06-03 01:29:55 [INFO]: Epoch 064 - training loss: 0.3955, validation loss: 0.5505
2024-06-03 01:30:00 [INFO]: Epoch 065 - training loss: 0.3914, validation loss: 0.5474
2024-06-03 01:30:06 [INFO]: Epoch 066 - training loss: 0.3905, validation loss: 0.5618
2024-06-03 01:30:13 [INFO]: Epoch 067 - training loss: 0.3877, validation loss: 0.5476
2024-06-03 01:30:18 [INFO]: Epoch 068 - training loss: 0.3954, validation loss: 0.5628
2024-06-03 01:30:20 [INFO]: Epoch 069 - training loss: 0.3970, validation loss: 0.5547
2024-06-03 01:30:22 [INFO]: Epoch 070 - training loss: 0.3954, validation loss: 0.5480
2024-06-03 01:30:24 [INFO]: Epoch 071 - training loss: 0.3959, validation loss: 0.5561
2024-06-03 01:30:26 [INFO]: Epoch 072 - training loss: 0.3894, validation loss: 0.5494
2024-06-03 01:30:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:30:26 [INFO]: Finished training. The best model is from epoch#62.
2024-06-03 01:30:26 [INFO]: Saved the model to results_point_rate05/PeMS/Koopa_PeMS/round_4/20240603_T012338/Koopa.pypots
2024-06-03 01:30:27 [INFO]: Successfully saved to results_point_rate05/PeMS/Koopa_PeMS/round_4/imputation.pkl
2024-06-03 01:30:27 [INFO]: Round4 - Koopa on PeMS: MAE=0.4680, MSE=0.8080, MRE=0.5808
2024-06-03 01:30:27 [INFO]: Done! Final results:
Averaged Koopa (13,306,214 params) on PeMS: MAE=0.5064 ± 0.11382426104255146, MSE=0.8546 ± 0.18419849029545132, MRE=0.6284 ± 0.14124625274958474, average inference time=0.32
