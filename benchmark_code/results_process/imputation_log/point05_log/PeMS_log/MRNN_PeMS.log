2024-06-03 00:45:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 00:45:08 [INFO]: Using the given device: cuda:0
2024-06-03 00:45:08 [INFO]: Model files will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_0/20240603_T004508
2024-06-03 00:45:08 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_0/20240603_T004508/tensorboard
2024-06-03 00:45:10 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 3,076,301
2024-06-03 00:46:36 [INFO]: Epoch 001 - training loss: 1.5323, validation loss: 1.0020
2024-06-03 00:47:47 [INFO]: Epoch 002 - training loss: 1.1765, validation loss: 0.9722
2024-06-03 00:48:58 [INFO]: Epoch 003 - training loss: 0.8781, validation loss: 0.9304
2024-06-03 00:50:09 [INFO]: Epoch 004 - training loss: 0.7102, validation loss: 0.9077
2024-06-03 00:51:21 [INFO]: Epoch 005 - training loss: 0.6804, validation loss: 0.9003
2024-06-03 00:52:28 [INFO]: Epoch 006 - training loss: 0.6665, validation loss: 0.8912
2024-06-03 00:53:28 [INFO]: Epoch 007 - training loss: 0.6630, validation loss: 0.8836
2024-06-03 00:54:28 [INFO]: Epoch 008 - training loss: 0.6536, validation loss: 0.8783
2024-06-03 00:55:28 [INFO]: Epoch 009 - training loss: 0.6472, validation loss: 0.8754
2024-06-03 00:56:23 [INFO]: Epoch 010 - training loss: 0.6487, validation loss: 0.8729
2024-06-03 00:57:12 [INFO]: Epoch 011 - training loss: 0.6456, validation loss: 0.8706
2024-06-03 00:58:01 [INFO]: Epoch 012 - training loss: 0.6450, validation loss: 0.8684
2024-06-03 00:58:51 [INFO]: Epoch 013 - training loss: 0.6358, validation loss: 0.8666
2024-06-03 00:59:41 [INFO]: Epoch 014 - training loss: 0.6356, validation loss: 0.8655
2024-06-03 01:00:29 [INFO]: Epoch 015 - training loss: 0.6314, validation loss: 0.8635
2024-06-03 01:01:19 [INFO]: Epoch 016 - training loss: 0.6434, validation loss: 0.8643
2024-06-03 01:02:09 [INFO]: Epoch 017 - training loss: 0.6345, validation loss: 0.8625
2024-06-03 01:02:59 [INFO]: Epoch 018 - training loss: 0.6301, validation loss: 0.8608
2024-06-03 01:03:49 [INFO]: Epoch 019 - training loss: 0.6246, validation loss: 0.8607
2024-06-03 01:04:39 [INFO]: Epoch 020 - training loss: 0.6207, validation loss: 0.8605
2024-06-03 01:05:27 [INFO]: Epoch 021 - training loss: 0.6191, validation loss: 0.8592
2024-06-03 01:06:16 [INFO]: Epoch 022 - training loss: 0.6183, validation loss: 0.8584
2024-06-03 01:07:05 [INFO]: Epoch 023 - training loss: 0.6178, validation loss: 0.8581
2024-06-03 01:07:55 [INFO]: Epoch 024 - training loss: 0.6166, validation loss: 0.8589
2024-06-03 01:08:45 [INFO]: Epoch 025 - training loss: 0.6163, validation loss: 0.8564
2024-06-03 01:09:35 [INFO]: Epoch 026 - training loss: 0.6127, validation loss: 0.8573
2024-06-03 01:10:24 [INFO]: Epoch 027 - training loss: 0.6130, validation loss: 0.8557
2024-06-03 01:11:13 [INFO]: Epoch 028 - training loss: 0.6190, validation loss: 0.8579
2024-06-03 01:12:02 [INFO]: Epoch 029 - training loss: 0.6175, validation loss: 0.8621
2024-06-03 01:12:52 [INFO]: Epoch 030 - training loss: 0.6083, validation loss: 0.8556
2024-06-03 01:13:41 [INFO]: Epoch 031 - training loss: 0.6083, validation loss: 0.8539
2024-06-03 01:14:31 [INFO]: Epoch 032 - training loss: 0.6204, validation loss: 0.8535
2024-06-03 01:15:21 [INFO]: Epoch 033 - training loss: 0.6190, validation loss: 0.8519
2024-06-03 01:16:10 [INFO]: Epoch 034 - training loss: 0.6134, validation loss: 0.8541
2024-06-03 01:16:50 [INFO]: Epoch 035 - training loss: 0.6126, validation loss: 0.8547
2024-06-03 01:17:30 [INFO]: Epoch 036 - training loss: 0.6051, validation loss: 0.8544
2024-06-03 01:18:09 [INFO]: Epoch 037 - training loss: 0.6074, validation loss: 0.8573
2024-06-03 01:18:49 [INFO]: Epoch 038 - training loss: 0.6001, validation loss: 0.8557
2024-06-03 01:19:28 [INFO]: Epoch 039 - training loss: 0.6061, validation loss: 0.8548
2024-06-03 01:19:58 [INFO]: Epoch 040 - training loss: 0.6003, validation loss: 0.8518
2024-06-03 01:20:28 [INFO]: Epoch 041 - training loss: 0.5943, validation loss: 0.8530
2024-06-03 01:20:59 [INFO]: Epoch 042 - training loss: 0.5974, validation loss: 0.8539
2024-06-03 01:21:29 [INFO]: Epoch 043 - training loss: 0.5938, validation loss: 0.8520
2024-06-03 01:22:00 [INFO]: Epoch 044 - training loss: 0.5912, validation loss: 0.8518
2024-06-03 01:22:30 [INFO]: Epoch 045 - training loss: 0.5946, validation loss: 0.8534
2024-06-03 01:23:01 [INFO]: Epoch 046 - training loss: 0.6012, validation loss: 0.8634
2024-06-03 01:23:30 [INFO]: Epoch 047 - training loss: 0.6009, validation loss: 0.8586
2024-06-03 01:23:55 [INFO]: Epoch 048 - training loss: 0.5970, validation loss: 0.8579
2024-06-03 01:24:17 [INFO]: Epoch 049 - training loss: 0.5927, validation loss: 0.8517
2024-06-03 01:24:39 [INFO]: Epoch 050 - training loss: 0.5981, validation loss: 0.8493
2024-06-03 01:25:01 [INFO]: Epoch 051 - training loss: 0.5939, validation loss: 0.8520
2024-06-03 01:25:24 [INFO]: Epoch 052 - training loss: 0.5913, validation loss: 0.8546
2024-06-03 01:25:46 [INFO]: Epoch 053 - training loss: 0.5919, validation loss: 0.8523
2024-06-03 01:26:09 [INFO]: Epoch 054 - training loss: 0.5911, validation loss: 0.8560
2024-06-03 01:26:31 [INFO]: Epoch 055 - training loss: 0.5994, validation loss: 0.8530
2024-06-03 01:26:54 [INFO]: Epoch 056 - training loss: 0.5956, validation loss: 0.8573
2024-06-03 01:27:16 [INFO]: Epoch 057 - training loss: 0.5916, validation loss: 0.8520
2024-06-03 01:27:39 [INFO]: Epoch 058 - training loss: 0.5821, validation loss: 0.8547
2024-06-03 01:28:01 [INFO]: Epoch 059 - training loss: 0.5837, validation loss: 0.8542
2024-06-03 01:28:24 [INFO]: Epoch 060 - training loss: 0.5813, validation loss: 0.8525
2024-06-03 01:28:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:28:24 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 01:28:24 [INFO]: Saved the model to results_point_rate05/PeMS/MRNN_PeMS/round_0/20240603_T004508/MRNN.pypots
2024-06-03 01:28:37 [INFO]: Successfully saved to results_point_rate05/PeMS/MRNN_PeMS/round_0/imputation.pkl
2024-06-03 01:28:37 [INFO]: Round0 - MRNN on PeMS: MAE=0.6442, MSE=1.0700, MRE=0.7994
2024-06-03 01:28:37 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 01:28:37 [INFO]: Using the given device: cuda:0
2024-06-03 01:28:38 [INFO]: Model files will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_1/20240603_T012837
2024-06-03 01:28:38 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_1/20240603_T012837/tensorboard
2024-06-03 01:28:38 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 3,076,301
2024-06-03 01:29:01 [INFO]: Epoch 001 - training loss: 1.5618, validation loss: 1.0032
2024-06-03 01:29:23 [INFO]: Epoch 002 - training loss: 1.2116, validation loss: 0.9832
2024-06-03 01:29:45 [INFO]: Epoch 003 - training loss: 0.9217, validation loss: 0.9509
2024-06-03 01:30:08 [INFO]: Epoch 004 - training loss: 0.7379, validation loss: 0.9263
2024-06-03 01:30:27 [INFO]: Epoch 005 - training loss: 0.6883, validation loss: 0.9116
2024-06-03 01:30:38 [INFO]: Epoch 006 - training loss: 0.6755, validation loss: 0.9001
2024-06-03 01:30:48 [INFO]: Epoch 007 - training loss: 0.6681, validation loss: 0.8913
2024-06-03 01:30:59 [INFO]: Epoch 008 - training loss: 0.6594, validation loss: 0.8848
2024-06-03 01:31:10 [INFO]: Epoch 009 - training loss: 0.6543, validation loss: 0.8801
2024-06-03 01:31:20 [INFO]: Epoch 010 - training loss: 0.6514, validation loss: 0.8762
2024-06-03 01:31:31 [INFO]: Epoch 011 - training loss: 0.6471, validation loss: 0.8735
2024-06-03 01:31:42 [INFO]: Epoch 012 - training loss: 0.6455, validation loss: 0.8710
2024-06-03 01:31:52 [INFO]: Epoch 013 - training loss: 0.6427, validation loss: 0.8683
2024-06-03 01:32:03 [INFO]: Epoch 014 - training loss: 0.6433, validation loss: 0.8685
2024-06-03 01:32:14 [INFO]: Epoch 015 - training loss: 0.6407, validation loss: 0.8659
2024-06-03 01:32:24 [INFO]: Epoch 016 - training loss: 0.6332, validation loss: 0.8636
2024-06-03 01:32:35 [INFO]: Epoch 017 - training loss: 0.6325, validation loss: 0.8624
2024-06-03 01:32:45 [INFO]: Epoch 018 - training loss: 0.6388, validation loss: 0.8621
2024-06-03 01:32:56 [INFO]: Epoch 019 - training loss: 0.6305, validation loss: 0.8627
2024-06-03 01:33:07 [INFO]: Epoch 020 - training loss: 0.6303, validation loss: 0.8607
2024-06-03 01:33:17 [INFO]: Epoch 021 - training loss: 0.6258, validation loss: 0.8608
2024-06-03 01:33:28 [INFO]: Epoch 022 - training loss: 0.6252, validation loss: 0.8600
2024-06-03 01:33:39 [INFO]: Epoch 023 - training loss: 0.6237, validation loss: 0.8585
2024-06-03 01:33:49 [INFO]: Epoch 024 - training loss: 0.6198, validation loss: 0.8596
2024-06-03 01:34:00 [INFO]: Epoch 025 - training loss: 0.6197, validation loss: 0.8587
2024-06-03 01:34:11 [INFO]: Epoch 026 - training loss: 0.6151, validation loss: 0.8582
2024-06-03 01:34:21 [INFO]: Epoch 027 - training loss: 0.6126, validation loss: 0.8574
2024-06-03 01:34:32 [INFO]: Epoch 028 - training loss: 0.6151, validation loss: 0.8577
2024-06-03 01:34:43 [INFO]: Epoch 029 - training loss: 0.6217, validation loss: 0.8511
2024-06-03 01:34:53 [INFO]: Epoch 030 - training loss: 0.6306, validation loss: 0.8552
2024-06-03 01:35:04 [INFO]: Epoch 031 - training loss: 0.6182, validation loss: 0.8558
2024-06-03 01:35:14 [INFO]: Epoch 032 - training loss: 0.6138, validation loss: 0.8560
2024-06-03 01:35:25 [INFO]: Epoch 033 - training loss: 0.6115, validation loss: 0.8550
2024-06-03 01:35:36 [INFO]: Epoch 034 - training loss: 0.6056, validation loss: 0.8546
2024-06-03 01:35:46 [INFO]: Epoch 035 - training loss: 0.6057, validation loss: 0.8544
2024-06-03 01:35:57 [INFO]: Epoch 036 - training loss: 0.6031, validation loss: 0.8543
2024-06-03 01:36:08 [INFO]: Epoch 037 - training loss: 0.6039, validation loss: 0.8540
2024-06-03 01:36:18 [INFO]: Epoch 038 - training loss: 0.6023, validation loss: 0.8531
2024-06-03 01:36:29 [INFO]: Epoch 039 - training loss: 0.6031, validation loss: 0.8564
2024-06-03 01:36:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:36:29 [INFO]: Finished training. The best model is from epoch#29.
2024-06-03 01:36:29 [INFO]: Saved the model to results_point_rate05/PeMS/MRNN_PeMS/round_1/20240603_T012837/MRNN.pypots
2024-06-03 01:36:36 [INFO]: Successfully saved to results_point_rate05/PeMS/MRNN_PeMS/round_1/imputation.pkl
2024-06-03 01:36:36 [INFO]: Round1 - MRNN on PeMS: MAE=0.6450, MSE=1.0728, MRE=0.8004
2024-06-03 01:36:36 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:36:36 [INFO]: Using the given device: cuda:0
2024-06-03 01:36:36 [INFO]: Model files will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_2/20240603_T013636
2024-06-03 01:36:36 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_2/20240603_T013636/tensorboard
2024-06-03 01:36:36 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 3,076,301
2024-06-03 01:36:47 [INFO]: Epoch 001 - training loss: 1.5768, validation loss: 1.0032
2024-06-03 01:36:57 [INFO]: Epoch 002 - training loss: 1.2236, validation loss: 0.9788
2024-06-03 01:37:08 [INFO]: Epoch 003 - training loss: 0.9132, validation loss: 0.9385
2024-06-03 01:37:19 [INFO]: Epoch 004 - training loss: 0.7292, validation loss: 0.9135
2024-06-03 01:37:29 [INFO]: Epoch 005 - training loss: 0.6842, validation loss: 0.9027
2024-06-03 01:37:40 [INFO]: Epoch 006 - training loss: 0.6716, validation loss: 0.8938
2024-06-03 01:37:51 [INFO]: Epoch 007 - training loss: 0.6702, validation loss: 0.8863
2024-06-03 01:38:01 [INFO]: Epoch 008 - training loss: 0.6633, validation loss: 0.8811
2024-06-03 01:38:12 [INFO]: Epoch 009 - training loss: 0.6566, validation loss: 0.8775
2024-06-03 01:38:22 [INFO]: Epoch 010 - training loss: 0.6514, validation loss: 0.8732
2024-06-03 01:38:33 [INFO]: Epoch 011 - training loss: 0.6543, validation loss: 0.8721
2024-06-03 01:38:44 [INFO]: Epoch 012 - training loss: 0.6558, validation loss: 0.8692
2024-06-03 01:38:54 [INFO]: Epoch 013 - training loss: 0.6455, validation loss: 0.8675
2024-06-03 01:39:05 [INFO]: Epoch 014 - training loss: 0.6390, validation loss: 0.8659
2024-06-03 01:39:16 [INFO]: Epoch 015 - training loss: 0.6350, validation loss: 0.8649
2024-06-03 01:39:26 [INFO]: Epoch 016 - training loss: 0.6327, validation loss: 0.8633
2024-06-03 01:39:37 [INFO]: Epoch 017 - training loss: 0.6368, validation loss: 0.8630
2024-06-03 01:39:48 [INFO]: Epoch 018 - training loss: 0.6305, validation loss: 0.8621
2024-06-03 01:39:58 [INFO]: Epoch 019 - training loss: 0.6274, validation loss: 0.8612
2024-06-03 01:40:09 [INFO]: Epoch 020 - training loss: 0.6274, validation loss: 0.8608
2024-06-03 01:40:20 [INFO]: Epoch 021 - training loss: 0.6429, validation loss: 0.8585
2024-06-03 01:40:30 [INFO]: Epoch 022 - training loss: 0.6258, validation loss: 0.8662
2024-06-03 01:40:41 [INFO]: Epoch 023 - training loss: 0.6208, validation loss: 0.8595
2024-06-03 01:40:52 [INFO]: Epoch 024 - training loss: 0.6215, validation loss: 0.8587
2024-06-03 01:41:02 [INFO]: Epoch 025 - training loss: 0.6385, validation loss: 0.8567
2024-06-03 01:41:13 [INFO]: Epoch 026 - training loss: 0.6310, validation loss: 0.8582
2024-06-03 01:41:24 [INFO]: Epoch 027 - training loss: 0.6185, validation loss: 0.8583
2024-06-03 01:41:34 [INFO]: Epoch 028 - training loss: 0.6198, validation loss: 0.8571
2024-06-03 01:41:45 [INFO]: Epoch 029 - training loss: 0.6250, validation loss: 0.8577
2024-06-03 01:41:56 [INFO]: Epoch 030 - training loss: 0.6230, validation loss: 0.8545
2024-06-03 01:42:06 [INFO]: Epoch 031 - training loss: 0.6127, validation loss: 0.8548
2024-06-03 01:42:17 [INFO]: Epoch 032 - training loss: 0.6112, validation loss: 0.8553
2024-06-03 01:42:28 [INFO]: Epoch 033 - training loss: 0.6093, validation loss: 0.8557
2024-06-03 01:42:38 [INFO]: Epoch 034 - training loss: 0.6053, validation loss: 0.8548
2024-06-03 01:42:49 [INFO]: Epoch 035 - training loss: 0.6034, validation loss: 0.8548
2024-06-03 01:43:00 [INFO]: Epoch 036 - training loss: 0.6044, validation loss: 0.8546
2024-06-03 01:43:10 [INFO]: Epoch 037 - training loss: 0.6030, validation loss: 0.8547
2024-06-03 01:43:21 [INFO]: Epoch 038 - training loss: 0.6031, validation loss: 0.8552
2024-06-03 01:43:32 [INFO]: Epoch 039 - training loss: 0.6013, validation loss: 0.8533
2024-06-03 01:43:42 [INFO]: Epoch 040 - training loss: 0.6024, validation loss: 0.8531
2024-06-03 01:43:53 [INFO]: Epoch 041 - training loss: 0.6004, validation loss: 0.8548
2024-06-03 01:44:04 [INFO]: Epoch 042 - training loss: 0.5966, validation loss: 0.8565
2024-06-03 01:44:14 [INFO]: Epoch 043 - training loss: 0.6002, validation loss: 0.8525
2024-06-03 01:44:25 [INFO]: Epoch 044 - training loss: 0.6079, validation loss: 0.8497
2024-06-03 01:44:35 [INFO]: Epoch 045 - training loss: 0.6050, validation loss: 0.8632
2024-06-03 01:44:46 [INFO]: Epoch 046 - training loss: 0.6065, validation loss: 0.8646
2024-06-03 01:44:57 [INFO]: Epoch 047 - training loss: 0.6027, validation loss: 0.8557
2024-06-03 01:45:07 [INFO]: Epoch 048 - training loss: 0.6014, validation loss: 0.8501
2024-06-03 01:45:18 [INFO]: Epoch 049 - training loss: 0.6024, validation loss: 0.8521
2024-06-03 01:45:29 [INFO]: Epoch 050 - training loss: 0.5966, validation loss: 0.8550
2024-06-03 01:45:39 [INFO]: Epoch 051 - training loss: 0.5993, validation loss: 0.8573
2024-06-03 01:45:50 [INFO]: Epoch 052 - training loss: 0.5936, validation loss: 0.8562
2024-06-03 01:46:01 [INFO]: Epoch 053 - training loss: 0.5959, validation loss: 0.8530
2024-06-03 01:46:11 [INFO]: Epoch 054 - training loss: 0.5896, validation loss: 0.8583
2024-06-03 01:46:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:46:11 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 01:46:11 [INFO]: Saved the model to results_point_rate05/PeMS/MRNN_PeMS/round_2/20240603_T013636/MRNN.pypots
2024-06-03 01:46:18 [INFO]: Successfully saved to results_point_rate05/PeMS/MRNN_PeMS/round_2/imputation.pkl
2024-06-03 01:46:18 [INFO]: Round2 - MRNN on PeMS: MAE=0.6466, MSE=1.0763, MRE=0.8024
2024-06-03 01:46:18 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:46:18 [INFO]: Using the given device: cuda:0
2024-06-03 01:46:18 [INFO]: Model files will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_3/20240603_T014618
2024-06-03 01:46:18 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_3/20240603_T014618/tensorboard
2024-06-03 01:46:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 3,076,301
2024-06-03 01:46:29 [INFO]: Epoch 001 - training loss: 1.6069, validation loss: 1.0050
2024-06-03 01:46:40 [INFO]: Epoch 002 - training loss: 1.2675, validation loss: 0.9913
2024-06-03 01:46:50 [INFO]: Epoch 003 - training loss: 0.9520, validation loss: 0.9602
2024-06-03 01:47:01 [INFO]: Epoch 004 - training loss: 0.7413, validation loss: 0.9341
2024-06-03 01:47:12 [INFO]: Epoch 005 - training loss: 0.6858, validation loss: 0.9209
2024-06-03 01:47:22 [INFO]: Epoch 006 - training loss: 0.6696, validation loss: 0.9084
2024-06-03 01:47:33 [INFO]: Epoch 007 - training loss: 0.6601, validation loss: 0.8985
2024-06-03 01:47:44 [INFO]: Epoch 008 - training loss: 0.6578, validation loss: 0.8897
2024-06-03 01:47:54 [INFO]: Epoch 009 - training loss: 0.6530, validation loss: 0.8841
2024-06-03 01:48:05 [INFO]: Epoch 010 - training loss: 0.6481, validation loss: 0.8794
2024-06-03 01:48:16 [INFO]: Epoch 011 - training loss: 0.6440, validation loss: 0.8762
2024-06-03 01:48:26 [INFO]: Epoch 012 - training loss: 0.6424, validation loss: 0.8735
2024-06-03 01:48:37 [INFO]: Epoch 013 - training loss: 0.6387, validation loss: 0.8707
2024-06-03 01:48:48 [INFO]: Epoch 014 - training loss: 0.6404, validation loss: 0.8686
2024-06-03 01:48:58 [INFO]: Epoch 015 - training loss: 0.6383, validation loss: 0.8666
2024-06-03 01:49:09 [INFO]: Epoch 016 - training loss: 0.6313, validation loss: 0.8647
2024-06-03 01:49:20 [INFO]: Epoch 017 - training loss: 0.6339, validation loss: 0.8638
2024-06-03 01:49:30 [INFO]: Epoch 018 - training loss: 0.6261, validation loss: 0.8636
2024-06-03 01:49:41 [INFO]: Epoch 019 - training loss: 0.6226, validation loss: 0.8625
2024-06-03 01:49:52 [INFO]: Epoch 020 - training loss: 0.6224, validation loss: 0.8614
2024-06-03 01:50:02 [INFO]: Epoch 021 - training loss: 0.6214, validation loss: 0.8615
2024-06-03 01:50:13 [INFO]: Epoch 022 - training loss: 0.6197, validation loss: 0.8608
2024-06-03 01:50:24 [INFO]: Epoch 023 - training loss: 0.6262, validation loss: 0.8617
2024-06-03 01:50:34 [INFO]: Epoch 024 - training loss: 0.6258, validation loss: 0.8614
2024-06-03 01:50:45 [INFO]: Epoch 025 - training loss: 0.6151, validation loss: 0.8589
2024-06-03 01:50:56 [INFO]: Epoch 026 - training loss: 0.6187, validation loss: 0.8569
2024-06-03 01:51:06 [INFO]: Epoch 027 - training loss: 0.6126, validation loss: 0.8582
2024-06-03 01:51:17 [INFO]: Epoch 028 - training loss: 0.6090, validation loss: 0.8569
2024-06-03 01:51:28 [INFO]: Epoch 029 - training loss: 0.6121, validation loss: 0.8565
2024-06-03 01:51:38 [INFO]: Epoch 030 - training loss: 0.6188, validation loss: 0.8601
2024-06-03 01:51:49 [INFO]: Epoch 031 - training loss: 0.6192, validation loss: 0.8580
2024-06-03 01:52:00 [INFO]: Epoch 032 - training loss: 0.6150, validation loss: 0.8549
2024-06-03 01:52:10 [INFO]: Epoch 033 - training loss: 0.6120, validation loss: 0.8551
2024-06-03 01:52:21 [INFO]: Epoch 034 - training loss: 0.6058, validation loss: 0.8542
2024-06-03 01:52:31 [INFO]: Epoch 035 - training loss: 0.6031, validation loss: 0.8535
2024-06-03 01:52:42 [INFO]: Epoch 036 - training loss: 0.6028, validation loss: 0.8553
2024-06-03 01:52:53 [INFO]: Epoch 037 - training loss: 0.6018, validation loss: 0.8540
2024-06-03 01:53:03 [INFO]: Epoch 038 - training loss: 0.6028, validation loss: 0.8542
2024-06-03 01:53:14 [INFO]: Epoch 039 - training loss: 0.6028, validation loss: 0.8527
2024-06-03 01:53:25 [INFO]: Epoch 040 - training loss: 0.5987, validation loss: 0.8525
2024-06-03 01:53:35 [INFO]: Epoch 041 - training loss: 0.5972, validation loss: 0.8560
2024-06-03 01:53:46 [INFO]: Epoch 042 - training loss: 0.5942, validation loss: 0.8561
2024-06-03 01:53:57 [INFO]: Epoch 043 - training loss: 0.5978, validation loss: 0.8542
2024-06-03 01:54:07 [INFO]: Epoch 044 - training loss: 0.6034, validation loss: 0.8476
2024-06-03 01:54:18 [INFO]: Epoch 045 - training loss: 0.5940, validation loss: 0.8579
2024-06-03 01:54:29 [INFO]: Epoch 046 - training loss: 0.5996, validation loss: 0.8556
2024-06-03 01:54:39 [INFO]: Epoch 047 - training loss: 0.5976, validation loss: 0.8496
2024-06-03 01:54:50 [INFO]: Epoch 048 - training loss: 0.5981, validation loss: 0.8561
2024-06-03 01:55:01 [INFO]: Epoch 049 - training loss: 0.6146, validation loss: 0.8570
2024-06-03 01:55:11 [INFO]: Epoch 050 - training loss: 0.6037, validation loss: 0.8477
2024-06-03 01:55:22 [INFO]: Epoch 051 - training loss: 0.5968, validation loss: 0.8517
2024-06-03 01:55:33 [INFO]: Epoch 052 - training loss: 0.5919, validation loss: 0.8530
2024-06-03 01:55:43 [INFO]: Epoch 053 - training loss: 0.5929, validation loss: 0.8511
2024-06-03 01:55:54 [INFO]: Epoch 054 - training loss: 0.5875, validation loss: 0.8522
2024-06-03 01:55:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:55:54 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 01:55:54 [INFO]: Saved the model to results_point_rate05/PeMS/MRNN_PeMS/round_3/20240603_T014618/MRNN.pypots
2024-06-03 01:56:01 [INFO]: Successfully saved to results_point_rate05/PeMS/MRNN_PeMS/round_3/imputation.pkl
2024-06-03 01:56:01 [INFO]: Round3 - MRNN on PeMS: MAE=0.6440, MSE=1.0701, MRE=0.7991
2024-06-03 01:56:01 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 01:56:01 [INFO]: Using the given device: cuda:0
2024-06-03 01:56:01 [INFO]: Model files will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_4/20240603_T015601
2024-06-03 01:56:01 [INFO]: Tensorboard file will be saved to results_point_rate05/PeMS/MRNN_PeMS/round_4/20240603_T015601/tensorboard
2024-06-03 01:56:01 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 3,076,301
2024-06-03 01:56:12 [INFO]: Epoch 001 - training loss: 1.5391, validation loss: 1.0031
2024-06-03 01:56:22 [INFO]: Epoch 002 - training loss: 1.1838, validation loss: 0.9821
2024-06-03 01:56:33 [INFO]: Epoch 003 - training loss: 0.8901, validation loss: 0.9489
2024-06-03 01:56:43 [INFO]: Epoch 004 - training loss: 0.7184, validation loss: 0.9251
2024-06-03 01:56:54 [INFO]: Epoch 005 - training loss: 0.6800, validation loss: 0.9110
2024-06-03 01:57:05 [INFO]: Epoch 006 - training loss: 0.6670, validation loss: 0.9006
2024-06-03 01:57:15 [INFO]: Epoch 007 - training loss: 0.6643, validation loss: 0.8915
2024-06-03 01:57:26 [INFO]: Epoch 008 - training loss: 0.6564, validation loss: 0.8853
2024-06-03 01:57:37 [INFO]: Epoch 009 - training loss: 0.6503, validation loss: 0.8798
2024-06-03 01:57:47 [INFO]: Epoch 010 - training loss: 0.6447, validation loss: 0.8757
2024-06-03 01:57:58 [INFO]: Epoch 011 - training loss: 0.6471, validation loss: 0.8736
2024-06-03 01:58:08 [INFO]: Epoch 012 - training loss: 0.6558, validation loss: 0.8699
2024-06-03 01:58:19 [INFO]: Epoch 013 - training loss: 0.6417, validation loss: 0.8685
2024-06-03 01:58:30 [INFO]: Epoch 014 - training loss: 0.6377, validation loss: 0.8672
2024-06-03 01:58:40 [INFO]: Epoch 015 - training loss: 0.6362, validation loss: 0.8656
2024-06-03 01:58:51 [INFO]: Epoch 016 - training loss: 0.6323, validation loss: 0.8647
2024-06-03 01:59:01 [INFO]: Epoch 017 - training loss: 0.6326, validation loss: 0.8631
2024-06-03 01:59:12 [INFO]: Epoch 018 - training loss: 0.6267, validation loss: 0.8626
2024-06-03 01:59:23 [INFO]: Epoch 019 - training loss: 0.6246, validation loss: 0.8624
2024-06-03 01:59:33 [INFO]: Epoch 020 - training loss: 0.6223, validation loss: 0.8606
2024-06-03 01:59:44 [INFO]: Epoch 021 - training loss: 0.6255, validation loss: 0.8605
2024-06-03 01:59:55 [INFO]: Epoch 022 - training loss: 0.6203, validation loss: 0.8604
2024-06-03 02:00:05 [INFO]: Epoch 023 - training loss: 0.6174, validation loss: 0.8602
2024-06-03 02:00:16 [INFO]: Epoch 024 - training loss: 0.6173, validation loss: 0.8586
2024-06-03 02:00:26 [INFO]: Epoch 025 - training loss: 0.6168, validation loss: 0.8572
2024-06-03 02:00:37 [INFO]: Epoch 026 - training loss: 0.6136, validation loss: 0.8583
2024-06-03 02:00:48 [INFO]: Epoch 027 - training loss: 0.6157, validation loss: 0.8576
2024-06-03 02:00:58 [INFO]: Epoch 028 - training loss: 0.6104, validation loss: 0.8574
2024-06-03 02:01:09 [INFO]: Epoch 029 - training loss: 0.6156, validation loss: 0.8643
2024-06-03 02:01:19 [INFO]: Epoch 030 - training loss: 0.6226, validation loss: 0.8564
2024-06-03 02:01:30 [INFO]: Epoch 031 - training loss: 0.6129, validation loss: 0.8548
2024-06-03 02:01:41 [INFO]: Epoch 032 - training loss: 0.6108, validation loss: 0.8596
2024-06-03 02:01:51 [INFO]: Epoch 033 - training loss: 0.6104, validation loss: 0.8580
2024-06-03 02:02:02 [INFO]: Epoch 034 - training loss: 0.6107, validation loss: 0.8579
2024-06-03 02:02:13 [INFO]: Epoch 035 - training loss: 0.6119, validation loss: 0.8621
2024-06-03 02:02:23 [INFO]: Epoch 036 - training loss: 0.6100, validation loss: 0.8527
2024-06-03 02:02:34 [INFO]: Epoch 037 - training loss: 0.6045, validation loss: 0.8544
2024-06-03 02:02:44 [INFO]: Epoch 038 - training loss: 0.5994, validation loss: 0.8549
2024-06-03 02:02:55 [INFO]: Epoch 039 - training loss: 0.5989, validation loss: 0.8538
2024-06-03 02:03:06 [INFO]: Epoch 040 - training loss: 0.5984, validation loss: 0.8544
2024-06-03 02:03:16 [INFO]: Epoch 041 - training loss: 0.5960, validation loss: 0.8537
2024-06-03 02:03:27 [INFO]: Epoch 042 - training loss: 0.5960, validation loss: 0.8540
2024-06-03 02:03:37 [INFO]: Epoch 043 - training loss: 0.5950, validation loss: 0.8533
2024-06-03 02:03:48 [INFO]: Epoch 044 - training loss: 0.6054, validation loss: 0.8570
2024-06-03 02:03:59 [INFO]: Epoch 045 - training loss: 0.6040, validation loss: 0.8669
2024-06-03 02:04:09 [INFO]: Epoch 046 - training loss: 0.5925, validation loss: 0.8481
2024-06-03 02:04:20 [INFO]: Epoch 047 - training loss: 0.5925, validation loss: 0.8563
2024-06-03 02:04:31 [INFO]: Epoch 048 - training loss: 0.5908, validation loss: 0.8547
2024-06-03 02:04:41 [INFO]: Epoch 049 - training loss: 0.5936, validation loss: 0.8530
2024-06-03 02:04:52 [INFO]: Epoch 050 - training loss: 0.5904, validation loss: 0.8528
2024-06-03 02:05:02 [INFO]: Epoch 051 - training loss: 0.5946, validation loss: 0.8508
2024-06-03 02:05:13 [INFO]: Epoch 052 - training loss: 0.5922, validation loss: 0.8505
2024-06-03 02:05:24 [INFO]: Epoch 053 - training loss: 0.5925, validation loss: 0.8529
2024-06-03 02:05:34 [INFO]: Epoch 054 - training loss: 0.5867, validation loss: 0.8538
2024-06-03 02:05:45 [INFO]: Epoch 055 - training loss: 0.5875, validation loss: 0.8540
2024-06-03 02:05:55 [INFO]: Epoch 056 - training loss: 0.5856, validation loss: 0.8516
2024-06-03 02:05:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:05:55 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 02:05:55 [INFO]: Saved the model to results_point_rate05/PeMS/MRNN_PeMS/round_4/20240603_T015601/MRNN.pypots
2024-06-03 02:06:02 [INFO]: Successfully saved to results_point_rate05/PeMS/MRNN_PeMS/round_4/imputation.pkl
2024-06-03 02:06:02 [INFO]: Round4 - MRNN on PeMS: MAE=0.6443, MSE=1.0693, MRE=0.7995
2024-06-03 02:06:02 [INFO]: Done! Final results:
Averaged MRNN (3,076,301 params) on PeMS: MAE=0.6448 ± 0.0009684246522609381, MSE=1.0717 ± 0.002581122367297571, MRE=0.8002 ± 0.0012017328463133688, average inference time=1.57
