2024-06-02 19:39:16 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:39:16 [INFO]: Using the given device: cuda:0
2024-06-02 19:39:17 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240602_T193917
2024-06-02 19:39:17 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240602_T193917/tensorboard
2024-06-02 19:39:18 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-02 19:39:21 [INFO]: Epoch 001 - training loss: 1.6862, validation loss: 1.1560
2024-06-02 19:39:22 [INFO]: Epoch 002 - training loss: 1.5065, validation loss: 0.9430
2024-06-02 19:39:22 [INFO]: Epoch 003 - training loss: 1.2903, validation loss: 0.8740
2024-06-02 19:39:23 [INFO]: Epoch 004 - training loss: 1.0909, validation loss: 0.7534
2024-06-02 19:39:24 [INFO]: Epoch 005 - training loss: 0.9877, validation loss: 0.6584
2024-06-02 19:39:25 [INFO]: Epoch 006 - training loss: 0.9195, validation loss: 0.5846
2024-06-02 19:39:26 [INFO]: Epoch 007 - training loss: 0.8685, validation loss: 0.5541
2024-06-02 19:39:27 [INFO]: Epoch 008 - training loss: 0.8751, validation loss: 0.5548
2024-06-02 19:39:27 [INFO]: Epoch 009 - training loss: 0.8397, validation loss: 0.5396
2024-06-02 19:39:28 [INFO]: Epoch 010 - training loss: 0.8198, validation loss: 0.5549
2024-06-02 19:39:29 [INFO]: Epoch 011 - training loss: 0.8293, validation loss: 0.5483
2024-06-02 19:39:30 [INFO]: Epoch 012 - training loss: 0.8189, validation loss: 0.5592
2024-06-02 19:39:31 [INFO]: Epoch 013 - training loss: 0.8236, validation loss: 0.5422
2024-06-02 19:39:32 [INFO]: Epoch 014 - training loss: 0.8172, validation loss: 0.5537
2024-06-02 19:39:33 [INFO]: Epoch 015 - training loss: 0.8151, validation loss: 0.5391
2024-06-02 19:39:34 [INFO]: Epoch 016 - training loss: 0.8283, validation loss: 0.5476
2024-06-02 19:39:34 [INFO]: Epoch 017 - training loss: 0.8199, validation loss: 0.5421
2024-06-02 19:39:35 [INFO]: Epoch 018 - training loss: 0.8242, validation loss: 0.5414
2024-06-02 19:39:36 [INFO]: Epoch 019 - training loss: 0.8288, validation loss: 0.5475
2024-06-02 19:39:37 [INFO]: Epoch 020 - training loss: 0.8225, validation loss: 0.5397
2024-06-02 19:39:38 [INFO]: Epoch 021 - training loss: 0.8172, validation loss: 0.5485
2024-06-02 19:39:38 [INFO]: Epoch 022 - training loss: 0.8191, validation loss: 0.5515
2024-06-02 19:39:39 [INFO]: Epoch 023 - training loss: 0.8176, validation loss: 0.5422
2024-06-02 19:39:40 [INFO]: Epoch 024 - training loss: 0.8260, validation loss: 0.5577
2024-06-02 19:39:41 [INFO]: Epoch 025 - training loss: 0.8295, validation loss: 0.5367
2024-06-02 19:39:42 [INFO]: Epoch 026 - training loss: 0.8205, validation loss: 0.5496
2024-06-02 19:39:43 [INFO]: Epoch 027 - training loss: 0.8273, validation loss: 0.5428
2024-06-02 19:39:44 [INFO]: Epoch 028 - training loss: 0.8176, validation loss: 0.5541
2024-06-02 19:39:44 [INFO]: Epoch 029 - training loss: 0.8230, validation loss: 0.5425
2024-06-02 19:39:45 [INFO]: Epoch 030 - training loss: 0.8080, validation loss: 0.5508
2024-06-02 19:39:46 [INFO]: Epoch 031 - training loss: 0.8300, validation loss: 0.5438
2024-06-02 19:39:47 [INFO]: Epoch 032 - training loss: 0.8269, validation loss: 0.5414
2024-06-02 19:39:48 [INFO]: Epoch 033 - training loss: 0.8279, validation loss: 0.5436
2024-06-02 19:39:49 [INFO]: Epoch 034 - training loss: 0.8260, validation loss: 0.5575
2024-06-02 19:39:50 [INFO]: Epoch 035 - training loss: 0.8377, validation loss: 0.5455
2024-06-02 19:39:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:39:50 [INFO]: Finished training. The best model is from epoch#25.
2024-06-02 19:39:50 [INFO]: Saved the model to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240602_T193917/FiLM.pypots
2024-06-02 19:39:50 [INFO]: Successfully saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_0/imputation.pkl
2024-06-02 19:39:50 [INFO]: Round0 - FiLM on ETT_h1: MAE=0.5938, MSE=0.7902, MRE=0.7025
2024-06-02 19:39:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:39:50 [INFO]: Using the given device: cuda:0
2024-06-02 19:39:50 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240602_T193950
2024-06-02 19:39:50 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240602_T193950/tensorboard
2024-06-02 19:39:50 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-02 19:39:51 [INFO]: Epoch 001 - training loss: 2.3046, validation loss: 1.1393
2024-06-02 19:39:52 [INFO]: Epoch 002 - training loss: 1.7160, validation loss: 1.0483
2024-06-02 19:39:53 [INFO]: Epoch 003 - training loss: 1.4725, validation loss: 1.0712
2024-06-02 19:39:54 [INFO]: Epoch 004 - training loss: 1.2141, validation loss: 0.9807
2024-06-02 19:39:55 [INFO]: Epoch 005 - training loss: 1.0503, validation loss: 0.6120
2024-06-02 19:39:55 [INFO]: Epoch 006 - training loss: 0.9291, validation loss: 0.5961
2024-06-02 19:39:56 [INFO]: Epoch 007 - training loss: 0.8805, validation loss: 0.5564
2024-06-02 19:39:57 [INFO]: Epoch 008 - training loss: 0.8422, validation loss: 0.5410
2024-06-02 19:39:58 [INFO]: Epoch 009 - training loss: 0.8437, validation loss: 0.5528
2024-06-02 19:39:59 [INFO]: Epoch 010 - training loss: 0.8360, validation loss: 0.5456
2024-06-02 19:40:00 [INFO]: Epoch 011 - training loss: 0.8231, validation loss: 0.5419
2024-06-02 19:40:01 [INFO]: Epoch 012 - training loss: 0.8191, validation loss: 0.5436
2024-06-02 19:40:02 [INFO]: Epoch 013 - training loss: 0.8310, validation loss: 0.5432
2024-06-02 19:40:03 [INFO]: Epoch 014 - training loss: 0.8179, validation loss: 0.5472
2024-06-02 19:40:03 [INFO]: Epoch 015 - training loss: 0.8253, validation loss: 0.5478
2024-06-02 19:40:04 [INFO]: Epoch 016 - training loss: 0.8245, validation loss: 0.5401
2024-06-02 19:40:05 [INFO]: Epoch 017 - training loss: 0.8248, validation loss: 0.5481
2024-06-02 19:40:06 [INFO]: Epoch 018 - training loss: 0.8237, validation loss: 0.5452
2024-06-02 19:40:07 [INFO]: Epoch 019 - training loss: 0.8163, validation loss: 0.5415
2024-06-02 19:40:08 [INFO]: Epoch 020 - training loss: 0.8314, validation loss: 0.5394
2024-06-02 19:40:09 [INFO]: Epoch 021 - training loss: 0.8265, validation loss: 0.5452
2024-06-02 19:40:10 [INFO]: Epoch 022 - training loss: 0.8253, validation loss: 0.5413
2024-06-02 19:40:11 [INFO]: Epoch 023 - training loss: 0.8146, validation loss: 0.5428
2024-06-02 19:40:11 [INFO]: Epoch 024 - training loss: 0.8248, validation loss: 0.5461
2024-06-02 19:40:12 [INFO]: Epoch 025 - training loss: 0.8231, validation loss: 0.5475
2024-06-02 19:40:13 [INFO]: Epoch 026 - training loss: 0.8264, validation loss: 0.5440
2024-06-02 19:40:14 [INFO]: Epoch 027 - training loss: 0.8213, validation loss: 0.5484
2024-06-02 19:40:15 [INFO]: Epoch 028 - training loss: 0.8233, validation loss: 0.5501
2024-06-02 19:40:16 [INFO]: Epoch 029 - training loss: 0.8189, validation loss: 0.5404
2024-06-02 19:40:16 [INFO]: Epoch 030 - training loss: 0.8226, validation loss: 0.5514
2024-06-02 19:40:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:40:16 [INFO]: Finished training. The best model is from epoch#20.
2024-06-02 19:40:16 [INFO]: Saved the model to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240602_T193950/FiLM.pypots
2024-06-02 19:40:17 [INFO]: Successfully saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_1/imputation.pkl
2024-06-02 19:40:17 [INFO]: Round1 - FiLM on ETT_h1: MAE=0.5884, MSE=0.7973, MRE=0.6961
2024-06-02 19:40:17 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:40:17 [INFO]: Using the given device: cuda:0
2024-06-02 19:40:17 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240602_T194017
2024-06-02 19:40:17 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240602_T194017/tensorboard
2024-06-02 19:40:17 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-02 19:40:18 [INFO]: Epoch 001 - training loss: 1.8175, validation loss: 1.1504
2024-06-02 19:40:19 [INFO]: Epoch 002 - training loss: 1.5818, validation loss: 0.9780
2024-06-02 19:40:20 [INFO]: Epoch 003 - training loss: 1.4475, validation loss: 1.0082
2024-06-02 19:40:21 [INFO]: Epoch 004 - training loss: 1.2166, validation loss: 0.8306
2024-06-02 19:40:21 [INFO]: Epoch 005 - training loss: 1.0550, validation loss: 0.6679
2024-06-02 19:40:22 [INFO]: Epoch 006 - training loss: 0.9495, validation loss: 0.5966
2024-06-02 19:40:23 [INFO]: Epoch 007 - training loss: 0.8928, validation loss: 0.5768
2024-06-02 19:40:24 [INFO]: Epoch 008 - training loss: 0.8601, validation loss: 0.5572
2024-06-02 19:40:25 [INFO]: Epoch 009 - training loss: 0.8492, validation loss: 0.5613
2024-06-02 19:40:26 [INFO]: Epoch 010 - training loss: 0.8374, validation loss: 0.5495
2024-06-02 19:40:26 [INFO]: Epoch 011 - training loss: 0.8503, validation loss: 0.5548
2024-06-02 19:40:27 [INFO]: Epoch 012 - training loss: 0.8319, validation loss: 0.5439
2024-06-02 19:40:28 [INFO]: Epoch 013 - training loss: 0.8239, validation loss: 0.5462
2024-06-02 19:40:29 [INFO]: Epoch 014 - training loss: 0.8271, validation loss: 0.5433
2024-06-02 19:40:29 [INFO]: Epoch 015 - training loss: 0.8256, validation loss: 0.5349
2024-06-02 19:40:30 [INFO]: Epoch 016 - training loss: 0.8245, validation loss: 0.5406
2024-06-02 19:40:31 [INFO]: Epoch 017 - training loss: 0.8195, validation loss: 0.5498
2024-06-02 19:40:32 [INFO]: Epoch 018 - training loss: 0.8264, validation loss: 0.5414
2024-06-02 19:40:32 [INFO]: Epoch 019 - training loss: 0.8219, validation loss: 0.5427
2024-06-02 19:40:33 [INFO]: Epoch 020 - training loss: 0.8217, validation loss: 0.5436
2024-06-02 19:40:34 [INFO]: Epoch 021 - training loss: 0.8197, validation loss: 0.5381
2024-06-02 19:40:35 [INFO]: Epoch 022 - training loss: 0.8115, validation loss: 0.5381
2024-06-02 19:40:36 [INFO]: Epoch 023 - training loss: 0.8129, validation loss: 0.5336
2024-06-02 19:40:36 [INFO]: Epoch 024 - training loss: 0.8223, validation loss: 0.5431
2024-06-02 19:40:37 [INFO]: Epoch 025 - training loss: 0.8182, validation loss: 0.5444
2024-06-02 19:40:38 [INFO]: Epoch 026 - training loss: 0.8209, validation loss: 0.5387
2024-06-02 19:40:39 [INFO]: Epoch 027 - training loss: 0.8232, validation loss: 0.5467
2024-06-02 19:40:39 [INFO]: Epoch 028 - training loss: 0.8186, validation loss: 0.5443
2024-06-02 19:40:40 [INFO]: Epoch 029 - training loss: 0.8185, validation loss: 0.5430
2024-06-02 19:40:41 [INFO]: Epoch 030 - training loss: 0.8178, validation loss: 0.5457
2024-06-02 19:40:41 [INFO]: Epoch 031 - training loss: 0.8053, validation loss: 0.5582
2024-06-02 19:40:42 [INFO]: Epoch 032 - training loss: 0.8245, validation loss: 0.5423
2024-06-02 19:40:43 [INFO]: Epoch 033 - training loss: 0.8186, validation loss: 0.5512
2024-06-02 19:40:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:40:43 [INFO]: Finished training. The best model is from epoch#23.
2024-06-02 19:40:43 [INFO]: Saved the model to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240602_T194017/FiLM.pypots
2024-06-02 19:40:43 [INFO]: Successfully saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_2/imputation.pkl
2024-06-02 19:40:43 [INFO]: Round2 - FiLM on ETT_h1: MAE=0.5943, MSE=0.7887, MRE=0.7030
2024-06-02 19:40:43 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:40:43 [INFO]: Using the given device: cuda:0
2024-06-02 19:40:43 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240602_T194043
2024-06-02 19:40:43 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240602_T194043/tensorboard
2024-06-02 19:40:43 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-02 19:40:44 [INFO]: Epoch 001 - training loss: 1.5798, validation loss: 1.0896
2024-06-02 19:40:45 [INFO]: Epoch 002 - training loss: 1.4728, validation loss: 0.9730
2024-06-02 19:40:46 [INFO]: Epoch 003 - training loss: 1.2561, validation loss: 0.8927
2024-06-02 19:40:47 [INFO]: Epoch 004 - training loss: 1.0941, validation loss: 0.7057
2024-06-02 19:40:48 [INFO]: Epoch 005 - training loss: 0.9888, validation loss: 0.6062
2024-06-02 19:40:48 [INFO]: Epoch 006 - training loss: 0.8939, validation loss: 0.5758
2024-06-02 19:40:49 [INFO]: Epoch 007 - training loss: 0.8615, validation loss: 0.5563
2024-06-02 19:40:50 [INFO]: Epoch 008 - training loss: 0.8560, validation loss: 0.5681
2024-06-02 19:40:51 [INFO]: Epoch 009 - training loss: 0.8276, validation loss: 0.5575
2024-06-02 19:40:51 [INFO]: Epoch 010 - training loss: 0.8282, validation loss: 0.5497
2024-06-02 19:40:52 [INFO]: Epoch 011 - training loss: 0.8255, validation loss: 0.5491
2024-06-02 19:40:53 [INFO]: Epoch 012 - training loss: 0.8210, validation loss: 0.5400
2024-06-02 19:40:54 [INFO]: Epoch 013 - training loss: 0.8265, validation loss: 0.5399
2024-06-02 19:40:54 [INFO]: Epoch 014 - training loss: 0.8213, validation loss: 0.5409
2024-06-02 19:40:55 [INFO]: Epoch 015 - training loss: 0.8305, validation loss: 0.5417
2024-06-02 19:40:56 [INFO]: Epoch 016 - training loss: 0.8217, validation loss: 0.5377
2024-06-02 19:40:57 [INFO]: Epoch 017 - training loss: 0.8134, validation loss: 0.5590
2024-06-02 19:40:57 [INFO]: Epoch 018 - training loss: 0.8267, validation loss: 0.5488
2024-06-02 19:40:58 [INFO]: Epoch 019 - training loss: 0.8259, validation loss: 0.5545
2024-06-02 19:40:59 [INFO]: Epoch 020 - training loss: 0.8124, validation loss: 0.5445
2024-06-02 19:41:00 [INFO]: Epoch 021 - training loss: 0.8259, validation loss: 0.5404
2024-06-02 19:41:01 [INFO]: Epoch 022 - training loss: 0.8275, validation loss: 0.5561
2024-06-02 19:41:01 [INFO]: Epoch 023 - training loss: 0.8267, validation loss: 0.5458
2024-06-02 19:41:02 [INFO]: Epoch 024 - training loss: 0.8269, validation loss: 0.5597
2024-06-02 19:41:03 [INFO]: Epoch 025 - training loss: 0.8171, validation loss: 0.5734
2024-06-02 19:41:03 [INFO]: Epoch 026 - training loss: 0.8193, validation loss: 0.5500
2024-06-02 19:41:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:41:03 [INFO]: Finished training. The best model is from epoch#16.
2024-06-02 19:41:03 [INFO]: Saved the model to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240602_T194043/FiLM.pypots
2024-06-02 19:41:04 [INFO]: Successfully saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_3/imputation.pkl
2024-06-02 19:41:04 [INFO]: Round3 - FiLM on ETT_h1: MAE=0.5833, MSE=0.7953, MRE=0.6901
2024-06-02 19:41:04 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:41:04 [INFO]: Using the given device: cuda:0
2024-06-02 19:41:04 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240602_T194104
2024-06-02 19:41:04 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240602_T194104/tensorboard
2024-06-02 19:41:04 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-02 19:41:05 [INFO]: Epoch 001 - training loss: 1.7690, validation loss: 1.0814
2024-06-02 19:41:05 [INFO]: Epoch 002 - training loss: 1.5615, validation loss: 1.0005
2024-06-02 19:41:06 [INFO]: Epoch 003 - training loss: 1.4809, validation loss: 1.0486
2024-06-02 19:41:06 [INFO]: Epoch 004 - training loss: 1.3703, validation loss: 0.8976
2024-06-02 19:41:07 [INFO]: Epoch 005 - training loss: 1.1228, validation loss: 0.8594
2024-06-02 19:41:08 [INFO]: Epoch 006 - training loss: 1.0187, validation loss: 0.6706
2024-06-02 19:41:08 [INFO]: Epoch 007 - training loss: 0.9347, validation loss: 0.6013
2024-06-02 19:41:09 [INFO]: Epoch 008 - training loss: 0.8879, validation loss: 0.5627
2024-06-02 19:41:10 [INFO]: Epoch 009 - training loss: 0.8579, validation loss: 0.5523
2024-06-02 19:41:10 [INFO]: Epoch 010 - training loss: 0.8403, validation loss: 0.5543
2024-06-02 19:41:11 [INFO]: Epoch 011 - training loss: 0.8380, validation loss: 0.5527
2024-06-02 19:41:12 [INFO]: Epoch 012 - training loss: 0.8352, validation loss: 0.5482
2024-06-02 19:41:13 [INFO]: Epoch 013 - training loss: 0.8308, validation loss: 0.5359
2024-06-02 19:41:13 [INFO]: Epoch 014 - training loss: 0.8237, validation loss: 0.5481
2024-06-02 19:41:14 [INFO]: Epoch 015 - training loss: 0.8264, validation loss: 0.5427
2024-06-02 19:41:15 [INFO]: Epoch 016 - training loss: 0.8203, validation loss: 0.5399
2024-06-02 19:41:15 [INFO]: Epoch 017 - training loss: 0.8228, validation loss: 0.5347
2024-06-02 19:41:16 [INFO]: Epoch 018 - training loss: 0.8277, validation loss: 0.5401
2024-06-02 19:41:17 [INFO]: Epoch 019 - training loss: 0.8308, validation loss: 0.5374
2024-06-02 19:41:18 [INFO]: Epoch 020 - training loss: 0.8239, validation loss: 0.5547
2024-06-02 19:41:18 [INFO]: Epoch 021 - training loss: 0.8247, validation loss: 0.5389
2024-06-02 19:41:19 [INFO]: Epoch 022 - training loss: 0.8200, validation loss: 0.5416
2024-06-02 19:41:20 [INFO]: Epoch 023 - training loss: 0.8178, validation loss: 0.5381
2024-06-02 19:41:21 [INFO]: Epoch 024 - training loss: 0.8142, validation loss: 0.5569
2024-06-02 19:41:22 [INFO]: Epoch 025 - training loss: 0.8190, validation loss: 0.5404
2024-06-02 19:41:22 [INFO]: Epoch 026 - training loss: 0.8171, validation loss: 0.5391
2024-06-02 19:41:23 [INFO]: Epoch 027 - training loss: 0.8351, validation loss: 0.5429
2024-06-02 19:41:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:41:23 [INFO]: Finished training. The best model is from epoch#17.
2024-06-02 19:41:23 [INFO]: Saved the model to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240602_T194104/FiLM.pypots
2024-06-02 19:41:23 [INFO]: Successfully saved to results_point_rate05/ETT_h1/FiLM_ETT_h1/round_4/imputation.pkl
2024-06-02 19:41:23 [INFO]: Round4 - FiLM on ETT_h1: MAE=0.5846, MSE=0.7934, MRE=0.6915
2024-06-02 19:41:23 [INFO]: Done! Final results:
Averaged FiLM (12,490 params) on ETT_h1: MAE=0.5889 ± 0.004542532500540486, MSE=0.7930 ± 0.0031616424088891384, MRE=0.6966 ± 0.005373801174905715, average inference time=0.11
