2024-06-02 20:03:17 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:03:17 [INFO]: Using the given device: cuda:0
2024-06-02 20:03:18 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_0/20240602_T200318
2024-06-02 20:03:18 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_0/20240602_T200318/tensorboard
2024-06-02 20:03:19 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-02 20:03:24 [INFO]: Epoch 001 - training loss: 1.5831, validation loss: 1.1407
2024-06-02 20:03:24 [INFO]: Epoch 002 - training loss: 1.4748, validation loss: 0.9978
2024-06-02 20:03:25 [INFO]: Epoch 003 - training loss: 1.3358, validation loss: 0.9860
2024-06-02 20:03:26 [INFO]: Epoch 004 - training loss: 1.1252, validation loss: 0.9126
2024-06-02 20:03:28 [INFO]: Epoch 005 - training loss: 1.0071, validation loss: 0.7270
2024-06-02 20:03:29 [INFO]: Epoch 006 - training loss: 0.8882, validation loss: 0.5499
2024-06-02 20:03:30 [INFO]: Epoch 007 - training loss: 0.7692, validation loss: 0.3749
2024-06-02 20:03:31 [INFO]: Epoch 008 - training loss: 0.7021, validation loss: 0.2535
2024-06-02 20:03:32 [INFO]: Epoch 009 - training loss: 0.6280, validation loss: 0.2174
2024-06-02 20:03:33 [INFO]: Epoch 010 - training loss: 0.6000, validation loss: 0.1937
2024-06-02 20:03:34 [INFO]: Epoch 011 - training loss: 0.5767, validation loss: 0.1810
2024-06-02 20:03:35 [INFO]: Epoch 012 - training loss: 0.5554, validation loss: 0.1847
2024-06-02 20:03:36 [INFO]: Epoch 013 - training loss: 0.5393, validation loss: 0.1809
2024-06-02 20:03:37 [INFO]: Epoch 014 - training loss: 0.5217, validation loss: 0.1705
2024-06-02 20:03:38 [INFO]: Epoch 015 - training loss: 0.5178, validation loss: 0.1692
2024-06-02 20:03:39 [INFO]: Epoch 016 - training loss: 0.5177, validation loss: 0.1569
2024-06-02 20:03:40 [INFO]: Epoch 017 - training loss: 0.5030, validation loss: 0.1623
2024-06-02 20:03:41 [INFO]: Epoch 018 - training loss: 0.5057, validation loss: 0.1622
2024-06-02 20:03:43 [INFO]: Epoch 019 - training loss: 0.4943, validation loss: 0.1651
2024-06-02 20:03:44 [INFO]: Epoch 020 - training loss: 0.4946, validation loss: 0.1585
2024-06-02 20:03:45 [INFO]: Epoch 021 - training loss: 0.4849, validation loss: 0.1601
2024-06-02 20:03:46 [INFO]: Epoch 022 - training loss: 0.4852, validation loss: 0.1637
2024-06-02 20:03:47 [INFO]: Epoch 023 - training loss: 0.4848, validation loss: 0.1591
2024-06-02 20:03:48 [INFO]: Epoch 024 - training loss: 0.4821, validation loss: 0.1555
2024-06-02 20:03:49 [INFO]: Epoch 025 - training loss: 0.4872, validation loss: 0.1579
2024-06-02 20:03:50 [INFO]: Epoch 026 - training loss: 0.4828, validation loss: 0.1631
2024-06-02 20:03:51 [INFO]: Epoch 027 - training loss: 0.4863, validation loss: 0.1626
2024-06-02 20:03:52 [INFO]: Epoch 028 - training loss: 0.4762, validation loss: 0.1547
2024-06-02 20:03:53 [INFO]: Epoch 029 - training loss: 0.4810, validation loss: 0.1617
2024-06-02 20:03:54 [INFO]: Epoch 030 - training loss: 0.4764, validation loss: 0.1635
2024-06-02 20:03:55 [INFO]: Epoch 031 - training loss: 0.4863, validation loss: 0.1709
2024-06-02 20:03:56 [INFO]: Epoch 032 - training loss: 0.4769, validation loss: 0.1785
2024-06-02 20:03:57 [INFO]: Epoch 033 - training loss: 0.4775, validation loss: 0.1635
2024-06-02 20:03:58 [INFO]: Epoch 034 - training loss: 0.4702, validation loss: 0.1652
2024-06-02 20:03:59 [INFO]: Epoch 035 - training loss: 0.4688, validation loss: 0.1529
2024-06-02 20:04:00 [INFO]: Epoch 036 - training loss: 0.4769, validation loss: 0.1541
2024-06-02 20:04:02 [INFO]: Epoch 037 - training loss: 0.4764, validation loss: 0.1613
2024-06-02 20:04:03 [INFO]: Epoch 038 - training loss: 0.4740, validation loss: 0.1580
2024-06-02 20:04:04 [INFO]: Epoch 039 - training loss: 0.4720, validation loss: 0.1556
2024-06-02 20:04:05 [INFO]: Epoch 040 - training loss: 0.4688, validation loss: 0.1741
2024-06-02 20:04:06 [INFO]: Epoch 041 - training loss: 0.4756, validation loss: 0.1766
2024-06-02 20:04:07 [INFO]: Epoch 042 - training loss: 0.4678, validation loss: 0.1600
2024-06-02 20:04:08 [INFO]: Epoch 043 - training loss: 0.4680, validation loss: 0.1584
2024-06-02 20:04:09 [INFO]: Epoch 044 - training loss: 0.4666, validation loss: 0.1508
2024-06-02 20:04:10 [INFO]: Epoch 045 - training loss: 0.4695, validation loss: 0.1562
2024-06-02 20:04:11 [INFO]: Epoch 046 - training loss: 0.4730, validation loss: 0.1585
2024-06-02 20:04:12 [INFO]: Epoch 047 - training loss: 0.4683, validation loss: 0.1633
2024-06-02 20:04:12 [INFO]: Epoch 048 - training loss: 0.4620, validation loss: 0.1589
2024-06-02 20:04:14 [INFO]: Epoch 049 - training loss: 0.4662, validation loss: 0.1752
2024-06-02 20:04:14 [INFO]: Epoch 050 - training loss: 0.4638, validation loss: 0.1607
2024-06-02 20:04:15 [INFO]: Epoch 051 - training loss: 0.4639, validation loss: 0.1593
2024-06-02 20:04:16 [INFO]: Epoch 052 - training loss: 0.4570, validation loss: 0.1559
2024-06-02 20:04:17 [INFO]: Epoch 053 - training loss: 0.4615, validation loss: 0.1722
2024-06-02 20:04:18 [INFO]: Epoch 054 - training loss: 0.4585, validation loss: 0.1526
2024-06-02 20:04:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:04:18 [INFO]: Finished training. The best model is from epoch#44.
2024-06-02 20:04:18 [INFO]: Saved the model to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_0/20240602_T200318/SCINet.pypots
2024-06-02 20:04:19 [INFO]: Successfully saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_0/imputation.pkl
2024-06-02 20:04:19 [INFO]: Round0 - SCINet on ETT_h1: MAE=0.3156, MSE=0.1861, MRE=0.3733
2024-06-02 20:04:19 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:04:19 [INFO]: Using the given device: cuda:0
2024-06-02 20:04:19 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_1/20240602_T200419
2024-06-02 20:04:19 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_1/20240602_T200419/tensorboard
2024-06-02 20:04:19 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-02 20:04:20 [INFO]: Epoch 001 - training loss: 1.5734, validation loss: 0.9928
2024-06-02 20:04:21 [INFO]: Epoch 002 - training loss: 1.4591, validation loss: 0.8792
2024-06-02 20:04:22 [INFO]: Epoch 003 - training loss: 1.2757, validation loss: 0.8887
2024-06-02 20:04:24 [INFO]: Epoch 004 - training loss: 1.0401, validation loss: 0.6809
2024-06-02 20:04:24 [INFO]: Epoch 005 - training loss: 0.9010, validation loss: 0.5173
2024-06-02 20:04:26 [INFO]: Epoch 006 - training loss: 0.7948, validation loss: 0.3931
2024-06-02 20:04:26 [INFO]: Epoch 007 - training loss: 0.7052, validation loss: 0.2933
2024-06-02 20:04:28 [INFO]: Epoch 008 - training loss: 0.6451, validation loss: 0.2212
2024-06-02 20:04:29 [INFO]: Epoch 009 - training loss: 0.6125, validation loss: 0.2085
2024-06-02 20:04:30 [INFO]: Epoch 010 - training loss: 0.5708, validation loss: 0.2109
2024-06-02 20:04:31 [INFO]: Epoch 011 - training loss: 0.5504, validation loss: 0.1950
2024-06-02 20:04:32 [INFO]: Epoch 012 - training loss: 0.5339, validation loss: 0.1897
2024-06-02 20:04:33 [INFO]: Epoch 013 - training loss: 0.5274, validation loss: 0.1844
2024-06-02 20:04:34 [INFO]: Epoch 014 - training loss: 0.5228, validation loss: 0.1934
2024-06-02 20:04:35 [INFO]: Epoch 015 - training loss: 0.5228, validation loss: 0.1905
2024-06-02 20:04:36 [INFO]: Epoch 016 - training loss: 0.5215, validation loss: 0.1760
2024-06-02 20:04:37 [INFO]: Epoch 017 - training loss: 0.5031, validation loss: 0.1861
2024-06-02 20:04:38 [INFO]: Epoch 018 - training loss: 0.5035, validation loss: 0.1787
2024-06-02 20:04:39 [INFO]: Epoch 019 - training loss: 0.5014, validation loss: 0.1828
2024-06-02 20:04:40 [INFO]: Epoch 020 - training loss: 0.5056, validation loss: 0.1870
2024-06-02 20:04:41 [INFO]: Epoch 021 - training loss: 0.5029, validation loss: 0.1716
2024-06-02 20:04:43 [INFO]: Epoch 022 - training loss: 0.4907, validation loss: 0.1749
2024-06-02 20:04:44 [INFO]: Epoch 023 - training loss: 0.4958, validation loss: 0.1688
2024-06-02 20:04:45 [INFO]: Epoch 024 - training loss: 0.4816, validation loss: 0.1711
2024-06-02 20:04:46 [INFO]: Epoch 025 - training loss: 0.4767, validation loss: 0.1589
2024-06-02 20:04:47 [INFO]: Epoch 026 - training loss: 0.4804, validation loss: 0.1794
2024-06-02 20:04:48 [INFO]: Epoch 027 - training loss: 0.4861, validation loss: 0.1594
2024-06-02 20:04:49 [INFO]: Epoch 028 - training loss: 0.4726, validation loss: 0.1747
2024-06-02 20:04:50 [INFO]: Epoch 029 - training loss: 0.4799, validation loss: 0.1580
2024-06-02 20:04:51 [INFO]: Epoch 030 - training loss: 0.4796, validation loss: 0.1648
2024-06-02 20:04:52 [INFO]: Epoch 031 - training loss: 0.4835, validation loss: 0.1670
2024-06-02 20:04:53 [INFO]: Epoch 032 - training loss: 0.4769, validation loss: 0.1623
2024-06-02 20:04:54 [INFO]: Epoch 033 - training loss: 0.4855, validation loss: 0.1750
2024-06-02 20:04:55 [INFO]: Epoch 034 - training loss: 0.4779, validation loss: 0.1696
2024-06-02 20:04:56 [INFO]: Epoch 035 - training loss: 0.4819, validation loss: 0.1621
2024-06-02 20:04:57 [INFO]: Epoch 036 - training loss: 0.4647, validation loss: 0.1686
2024-06-02 20:04:58 [INFO]: Epoch 037 - training loss: 0.4674, validation loss: 0.1594
2024-06-02 20:04:59 [INFO]: Epoch 038 - training loss: 0.4697, validation loss: 0.1599
2024-06-02 20:05:00 [INFO]: Epoch 039 - training loss: 0.4649, validation loss: 0.1551
2024-06-02 20:05:01 [INFO]: Epoch 040 - training loss: 0.4628, validation loss: 0.1619
2024-06-02 20:05:02 [INFO]: Epoch 041 - training loss: 0.4606, validation loss: 0.1629
2024-06-02 20:05:03 [INFO]: Epoch 042 - training loss: 0.4686, validation loss: 0.1585
2024-06-02 20:05:05 [INFO]: Epoch 043 - training loss: 0.4522, validation loss: 0.1565
2024-06-02 20:05:06 [INFO]: Epoch 044 - training loss: 0.4632, validation loss: 0.1644
2024-06-02 20:05:07 [INFO]: Epoch 045 - training loss: 0.4596, validation loss: 0.1552
2024-06-02 20:05:08 [INFO]: Epoch 046 - training loss: 0.4601, validation loss: 0.1562
2024-06-02 20:05:09 [INFO]: Epoch 047 - training loss: 0.4468, validation loss: 0.1596
2024-06-02 20:05:10 [INFO]: Epoch 048 - training loss: 0.4544, validation loss: 0.1671
2024-06-02 20:05:11 [INFO]: Epoch 049 - training loss: 0.4505, validation loss: 0.1537
2024-06-02 20:05:12 [INFO]: Epoch 050 - training loss: 0.4493, validation loss: 0.1619
2024-06-02 20:05:13 [INFO]: Epoch 051 - training loss: 0.4531, validation loss: 0.1535
2024-06-02 20:05:14 [INFO]: Epoch 052 - training loss: 0.4644, validation loss: 0.1659
2024-06-02 20:05:15 [INFO]: Epoch 053 - training loss: 0.4548, validation loss: 0.1596
2024-06-02 20:05:17 [INFO]: Epoch 054 - training loss: 0.4534, validation loss: 0.1637
2024-06-02 20:05:18 [INFO]: Epoch 055 - training loss: 0.4566, validation loss: 0.1443
2024-06-02 20:05:18 [INFO]: Epoch 056 - training loss: 0.4496, validation loss: 0.1625
2024-06-02 20:05:19 [INFO]: Epoch 057 - training loss: 0.4501, validation loss: 0.1505
2024-06-02 20:05:21 [INFO]: Epoch 058 - training loss: 0.4536, validation loss: 0.1568
2024-06-02 20:05:21 [INFO]: Epoch 059 - training loss: 0.4430, validation loss: 0.1453
2024-06-02 20:05:22 [INFO]: Epoch 060 - training loss: 0.4372, validation loss: 0.1475
2024-06-02 20:05:23 [INFO]: Epoch 061 - training loss: 0.4400, validation loss: 0.1476
2024-06-02 20:05:24 [INFO]: Epoch 062 - training loss: 0.4422, validation loss: 0.1555
2024-06-02 20:05:24 [INFO]: Epoch 063 - training loss: 0.4366, validation loss: 0.1529
2024-06-02 20:05:25 [INFO]: Epoch 064 - training loss: 0.4313, validation loss: 0.1518
2024-06-02 20:05:26 [INFO]: Epoch 065 - training loss: 0.4322, validation loss: 0.1560
2024-06-02 20:05:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:05:26 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 20:05:26 [INFO]: Saved the model to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_1/20240602_T200419/SCINet.pypots
2024-06-02 20:05:26 [INFO]: Successfully saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_1/imputation.pkl
2024-06-02 20:05:26 [INFO]: Round1 - SCINet on ETT_h1: MAE=0.3166, MSE=0.1806, MRE=0.3745
2024-06-02 20:05:26 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:05:26 [INFO]: Using the given device: cuda:0
2024-06-02 20:05:26 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_2/20240602_T200526
2024-06-02 20:05:26 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_2/20240602_T200526/tensorboard
2024-06-02 20:05:27 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-02 20:05:28 [INFO]: Epoch 001 - training loss: 1.4836, validation loss: 0.9849
2024-06-02 20:05:28 [INFO]: Epoch 002 - training loss: 1.2253, validation loss: 0.8738
2024-06-02 20:05:30 [INFO]: Epoch 003 - training loss: 1.0836, validation loss: 0.7567
2024-06-02 20:05:31 [INFO]: Epoch 004 - training loss: 0.9621, validation loss: 0.6656
2024-06-02 20:05:32 [INFO]: Epoch 005 - training loss: 0.8692, validation loss: 0.4854
2024-06-02 20:05:33 [INFO]: Epoch 006 - training loss: 0.7829, validation loss: 0.3684
2024-06-02 20:05:33 [INFO]: Epoch 007 - training loss: 0.7353, validation loss: 0.3387
2024-06-02 20:05:35 [INFO]: Epoch 008 - training loss: 0.6923, validation loss: 0.2649
2024-06-02 20:05:36 [INFO]: Epoch 009 - training loss: 0.6663, validation loss: 0.2842
2024-06-02 20:05:37 [INFO]: Epoch 010 - training loss: 0.6477, validation loss: 0.2691
2024-06-02 20:05:38 [INFO]: Epoch 011 - training loss: 0.6197, validation loss: 0.2269
2024-06-02 20:05:39 [INFO]: Epoch 012 - training loss: 0.6087, validation loss: 0.2490
2024-06-02 20:05:40 [INFO]: Epoch 013 - training loss: 0.5827, validation loss: 0.2065
2024-06-02 20:05:41 [INFO]: Epoch 014 - training loss: 0.5758, validation loss: 0.2065
2024-06-02 20:05:42 [INFO]: Epoch 015 - training loss: 0.5823, validation loss: 0.2727
2024-06-02 20:05:43 [INFO]: Epoch 016 - training loss: 0.5855, validation loss: 0.1940
2024-06-02 20:05:44 [INFO]: Epoch 017 - training loss: 0.5549, validation loss: 0.2266
2024-06-02 20:05:45 [INFO]: Epoch 018 - training loss: 0.5544, validation loss: 0.1926
2024-06-02 20:05:47 [INFO]: Epoch 019 - training loss: 0.5551, validation loss: 0.2120
2024-06-02 20:05:48 [INFO]: Epoch 020 - training loss: 0.5583, validation loss: 0.1970
2024-06-02 20:05:49 [INFO]: Epoch 021 - training loss: 0.5392, validation loss: 0.2070
2024-06-02 20:05:49 [INFO]: Epoch 022 - training loss: 0.5419, validation loss: 0.1829
2024-06-02 20:05:51 [INFO]: Epoch 023 - training loss: 0.5254, validation loss: 0.2062
2024-06-02 20:05:52 [INFO]: Epoch 024 - training loss: 0.5268, validation loss: 0.1959
2024-06-02 20:05:53 [INFO]: Epoch 025 - training loss: 0.5124, validation loss: 0.2024
2024-06-02 20:05:54 [INFO]: Epoch 026 - training loss: 0.5245, validation loss: 0.1850
2024-06-02 20:05:55 [INFO]: Epoch 027 - training loss: 0.5181, validation loss: 0.1834
2024-06-02 20:05:56 [INFO]: Epoch 028 - training loss: 0.5147, validation loss: 0.2037
2024-06-02 20:05:57 [INFO]: Epoch 029 - training loss: 0.5166, validation loss: 0.1836
2024-06-02 20:05:58 [INFO]: Epoch 030 - training loss: 0.5178, validation loss: 0.1999
2024-06-02 20:05:59 [INFO]: Epoch 031 - training loss: 0.5103, validation loss: 0.1927
2024-06-02 20:06:01 [INFO]: Epoch 032 - training loss: 0.5118, validation loss: 0.1838
2024-06-02 20:06:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:01 [INFO]: Finished training. The best model is from epoch#22.
2024-06-02 20:06:01 [INFO]: Saved the model to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_2/20240602_T200526/SCINet.pypots
2024-06-02 20:06:01 [INFO]: Successfully saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_2/imputation.pkl
2024-06-02 20:06:01 [INFO]: Round2 - SCINet on ETT_h1: MAE=0.3522, MSE=0.2195, MRE=0.4166
2024-06-02 20:06:01 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:06:01 [INFO]: Using the given device: cuda:0
2024-06-02 20:06:01 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_3/20240602_T200601
2024-06-02 20:06:01 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_3/20240602_T200601/tensorboard
2024-06-02 20:06:01 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-02 20:06:02 [INFO]: Epoch 001 - training loss: 1.5714, validation loss: 1.0369
2024-06-02 20:06:03 [INFO]: Epoch 002 - training loss: 1.4133, validation loss: 0.8780
2024-06-02 20:06:04 [INFO]: Epoch 003 - training loss: 1.1866, validation loss: 0.9718
2024-06-02 20:06:05 [INFO]: Epoch 004 - training loss: 1.0333, validation loss: 0.7142
2024-06-02 20:06:06 [INFO]: Epoch 005 - training loss: 0.9072, validation loss: 0.5367
2024-06-02 20:06:08 [INFO]: Epoch 006 - training loss: 0.7853, validation loss: 0.4064
2024-06-02 20:06:09 [INFO]: Epoch 007 - training loss: 0.7100, validation loss: 0.3401
2024-06-02 20:06:10 [INFO]: Epoch 008 - training loss: 0.6665, validation loss: 0.2631
2024-06-02 20:06:11 [INFO]: Epoch 009 - training loss: 0.6158, validation loss: 0.2114
2024-06-02 20:06:12 [INFO]: Epoch 010 - training loss: 0.5734, validation loss: 0.2111
2024-06-02 20:06:13 [INFO]: Epoch 011 - training loss: 0.5532, validation loss: 0.1906
2024-06-02 20:06:14 [INFO]: Epoch 012 - training loss: 0.5395, validation loss: 0.1853
2024-06-02 20:06:15 [INFO]: Epoch 013 - training loss: 0.5318, validation loss: 0.2126
2024-06-02 20:06:16 [INFO]: Epoch 014 - training loss: 0.5218, validation loss: 0.1993
2024-06-02 20:06:16 [INFO]: Epoch 015 - training loss: 0.5200, validation loss: 0.1879
2024-06-02 20:06:18 [INFO]: Epoch 016 - training loss: 0.4996, validation loss: 0.1684
2024-06-02 20:06:19 [INFO]: Epoch 017 - training loss: 0.4941, validation loss: 0.1771
2024-06-02 20:06:20 [INFO]: Epoch 018 - training loss: 0.4872, validation loss: 0.1667
2024-06-02 20:06:21 [INFO]: Epoch 019 - training loss: 0.4960, validation loss: 0.1758
2024-06-02 20:06:22 [INFO]: Epoch 020 - training loss: 0.4844, validation loss: 0.1657
2024-06-02 20:06:23 [INFO]: Epoch 021 - training loss: 0.4853, validation loss: 0.1725
2024-06-02 20:06:24 [INFO]: Epoch 022 - training loss: 0.4762, validation loss: 0.1616
2024-06-02 20:06:25 [INFO]: Epoch 023 - training loss: 0.4785, validation loss: 0.1647
2024-06-02 20:06:26 [INFO]: Epoch 024 - training loss: 0.4783, validation loss: 0.1684
2024-06-02 20:06:27 [INFO]: Epoch 025 - training loss: 0.4688, validation loss: 0.1600
2024-06-02 20:06:28 [INFO]: Epoch 026 - training loss: 0.4723, validation loss: 0.1550
2024-06-02 20:06:29 [INFO]: Epoch 027 - training loss: 0.4785, validation loss: 0.1625
2024-06-02 20:06:30 [INFO]: Epoch 028 - training loss: 0.4763, validation loss: 0.1599
2024-06-02 20:06:32 [INFO]: Epoch 029 - training loss: 0.4791, validation loss: 0.1592
2024-06-02 20:06:33 [INFO]: Epoch 030 - training loss: 0.4796, validation loss: 0.1691
2024-06-02 20:06:34 [INFO]: Epoch 031 - training loss: 0.4786, validation loss: 0.1594
2024-06-02 20:06:35 [INFO]: Epoch 032 - training loss: 0.4730, validation loss: 0.1482
2024-06-02 20:06:35 [INFO]: Epoch 033 - training loss: 0.4680, validation loss: 0.1718
2024-06-02 20:06:37 [INFO]: Epoch 034 - training loss: 0.4646, validation loss: 0.1644
2024-06-02 20:06:38 [INFO]: Epoch 035 - training loss: 0.4752, validation loss: 0.1577
2024-06-02 20:06:39 [INFO]: Epoch 036 - training loss: 0.4602, validation loss: 0.1573
2024-06-02 20:06:40 [INFO]: Epoch 037 - training loss: 0.4534, validation loss: 0.1566
2024-06-02 20:06:41 [INFO]: Epoch 038 - training loss: 0.4538, validation loss: 0.1459
2024-06-02 20:06:42 [INFO]: Epoch 039 - training loss: 0.4627, validation loss: 0.1514
2024-06-02 20:06:43 [INFO]: Epoch 040 - training loss: 0.4602, validation loss: 0.1504
2024-06-02 20:06:44 [INFO]: Epoch 041 - training loss: 0.4601, validation loss: 0.1530
2024-06-02 20:06:45 [INFO]: Epoch 042 - training loss: 0.4568, validation loss: 0.1513
2024-06-02 20:06:46 [INFO]: Epoch 043 - training loss: 0.4599, validation loss: 0.1470
2024-06-02 20:06:47 [INFO]: Epoch 044 - training loss: 0.4594, validation loss: 0.1575
2024-06-02 20:06:48 [INFO]: Epoch 045 - training loss: 0.4503, validation loss: 0.1619
2024-06-02 20:06:49 [INFO]: Epoch 046 - training loss: 0.4490, validation loss: 0.1491
2024-06-02 20:06:50 [INFO]: Epoch 047 - training loss: 0.4466, validation loss: 0.1501
2024-06-02 20:06:51 [INFO]: Epoch 048 - training loss: 0.4490, validation loss: 0.1563
2024-06-02 20:06:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:51 [INFO]: Finished training. The best model is from epoch#38.
2024-06-02 20:06:51 [INFO]: Saved the model to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_3/20240602_T200601/SCINet.pypots
2024-06-02 20:06:51 [INFO]: Successfully saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_3/imputation.pkl
2024-06-02 20:06:51 [INFO]: Round3 - SCINet on ETT_h1: MAE=0.3260, MSE=0.1923, MRE=0.3856
2024-06-02 20:06:51 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:06:51 [INFO]: Using the given device: cuda:0
2024-06-02 20:06:51 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_4/20240602_T200651
2024-06-02 20:06:51 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_4/20240602_T200651/tensorboard
2024-06-02 20:06:51 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 79,493
2024-06-02 20:06:52 [INFO]: Epoch 001 - training loss: 1.5288, validation loss: 0.9856
2024-06-02 20:06:53 [INFO]: Epoch 002 - training loss: 1.2974, validation loss: 0.9266
2024-06-02 20:06:54 [INFO]: Epoch 003 - training loss: 1.1516, validation loss: 0.8740
2024-06-02 20:06:55 [INFO]: Epoch 004 - training loss: 1.0572, validation loss: 0.8472
2024-06-02 20:06:56 [INFO]: Epoch 005 - training loss: 0.9719, validation loss: 0.7163
2024-06-02 20:06:57 [INFO]: Epoch 006 - training loss: 0.8884, validation loss: 0.5888
2024-06-02 20:06:58 [INFO]: Epoch 007 - training loss: 0.8226, validation loss: 0.5217
2024-06-02 20:06:59 [INFO]: Epoch 008 - training loss: 0.7547, validation loss: 0.4746
2024-06-02 20:07:00 [INFO]: Epoch 009 - training loss: 0.7016, validation loss: 0.3683
2024-06-02 20:07:01 [INFO]: Epoch 010 - training loss: 0.6693, validation loss: 0.3310
2024-06-02 20:07:02 [INFO]: Epoch 011 - training loss: 0.6411, validation loss: 0.2862
2024-06-02 20:07:02 [INFO]: Epoch 012 - training loss: 0.6103, validation loss: 0.2590
2024-06-02 20:07:03 [INFO]: Epoch 013 - training loss: 0.5892, validation loss: 0.2417
2024-06-02 20:07:04 [INFO]: Epoch 014 - training loss: 0.5606, validation loss: 0.2423
2024-06-02 20:07:05 [INFO]: Epoch 015 - training loss: 0.5622, validation loss: 0.2228
2024-06-02 20:07:05 [INFO]: Epoch 016 - training loss: 0.5474, validation loss: 0.2172
2024-06-02 20:07:06 [INFO]: Epoch 017 - training loss: 0.5516, validation loss: 0.2242
2024-06-02 20:07:07 [INFO]: Epoch 018 - training loss: 0.5435, validation loss: 0.2129
2024-06-02 20:07:08 [INFO]: Epoch 019 - training loss: 0.5294, validation loss: 0.2152
2024-06-02 20:07:09 [INFO]: Epoch 020 - training loss: 0.5170, validation loss: 0.2014
2024-06-02 20:07:10 [INFO]: Epoch 021 - training loss: 0.5193, validation loss: 0.2056
2024-06-02 20:07:11 [INFO]: Epoch 022 - training loss: 0.5140, validation loss: 0.2023
2024-06-02 20:07:11 [INFO]: Epoch 023 - training loss: 0.5072, validation loss: 0.2100
2024-06-02 20:07:13 [INFO]: Epoch 024 - training loss: 0.5070, validation loss: 0.2023
2024-06-02 20:07:14 [INFO]: Epoch 025 - training loss: 0.4975, validation loss: 0.1983
2024-06-02 20:07:15 [INFO]: Epoch 026 - training loss: 0.4937, validation loss: 0.1975
2024-06-02 20:07:16 [INFO]: Epoch 027 - training loss: 0.5066, validation loss: 0.2002
2024-06-02 20:07:16 [INFO]: Epoch 028 - training loss: 0.4852, validation loss: 0.2007
2024-06-02 20:07:18 [INFO]: Epoch 029 - training loss: 0.4933, validation loss: 0.1824
2024-06-02 20:07:18 [INFO]: Epoch 030 - training loss: 0.4958, validation loss: 0.1833
2024-06-02 20:07:19 [INFO]: Epoch 031 - training loss: 0.4882, validation loss: 0.1913
2024-06-02 20:07:20 [INFO]: Epoch 032 - training loss: 0.4886, validation loss: 0.1861
2024-06-02 20:07:21 [INFO]: Epoch 033 - training loss: 0.4987, validation loss: 0.1988
2024-06-02 20:07:22 [INFO]: Epoch 034 - training loss: 0.4837, validation loss: 0.1922
2024-06-02 20:07:23 [INFO]: Epoch 035 - training loss: 0.4887, validation loss: 0.1894
2024-06-02 20:07:24 [INFO]: Epoch 036 - training loss: 0.4872, validation loss: 0.1757
2024-06-02 20:07:25 [INFO]: Epoch 037 - training loss: 0.4935, validation loss: 0.1971
2024-06-02 20:07:26 [INFO]: Epoch 038 - training loss: 0.4789, validation loss: 0.1789
2024-06-02 20:07:27 [INFO]: Epoch 039 - training loss: 0.4759, validation loss: 0.1863
2024-06-02 20:07:28 [INFO]: Epoch 040 - training loss: 0.4858, validation loss: 0.1865
2024-06-02 20:07:29 [INFO]: Epoch 041 - training loss: 0.4755, validation loss: 0.1761
2024-06-02 20:07:30 [INFO]: Epoch 042 - training loss: 0.4652, validation loss: 0.1755
2024-06-02 20:07:31 [INFO]: Epoch 043 - training loss: 0.4677, validation loss: 0.1788
2024-06-02 20:07:32 [INFO]: Epoch 044 - training loss: 0.4721, validation loss: 0.1804
2024-06-02 20:07:32 [INFO]: Epoch 045 - training loss: 0.4746, validation loss: 0.1942
2024-06-02 20:07:33 [INFO]: Epoch 046 - training loss: 0.4649, validation loss: 0.1833
2024-06-02 20:07:34 [INFO]: Epoch 047 - training loss: 0.4639, validation loss: 0.1694
2024-06-02 20:07:35 [INFO]: Epoch 048 - training loss: 0.4605, validation loss: 0.1633
2024-06-02 20:07:36 [INFO]: Epoch 049 - training loss: 0.4567, validation loss: 0.1679
2024-06-02 20:07:37 [INFO]: Epoch 050 - training loss: 0.4600, validation loss: 0.1656
2024-06-02 20:07:38 [INFO]: Epoch 051 - training loss: 0.4547, validation loss: 0.1812
2024-06-02 20:07:39 [INFO]: Epoch 052 - training loss: 0.4596, validation loss: 0.1613
2024-06-02 20:07:40 [INFO]: Epoch 053 - training loss: 0.4571, validation loss: 0.1670
2024-06-02 20:07:41 [INFO]: Epoch 054 - training loss: 0.4560, validation loss: 0.1594
2024-06-02 20:07:42 [INFO]: Epoch 055 - training loss: 0.4607, validation loss: 0.1828
2024-06-02 20:07:43 [INFO]: Epoch 056 - training loss: 0.4653, validation loss: 0.1640
2024-06-02 20:07:44 [INFO]: Epoch 057 - training loss: 0.4567, validation loss: 0.1628
2024-06-02 20:07:45 [INFO]: Epoch 058 - training loss: 0.4583, validation loss: 0.1655
2024-06-02 20:07:46 [INFO]: Epoch 059 - training loss: 0.4558, validation loss: 0.1697
2024-06-02 20:07:47 [INFO]: Epoch 060 - training loss: 0.4621, validation loss: 0.1600
2024-06-02 20:07:48 [INFO]: Epoch 061 - training loss: 0.4563, validation loss: 0.1624
2024-06-02 20:07:49 [INFO]: Epoch 062 - training loss: 0.4478, validation loss: 0.1602
2024-06-02 20:07:50 [INFO]: Epoch 063 - training loss: 0.4532, validation loss: 0.1670
2024-06-02 20:07:51 [INFO]: Epoch 064 - training loss: 0.4506, validation loss: 0.1642
2024-06-02 20:07:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:07:51 [INFO]: Finished training. The best model is from epoch#54.
2024-06-02 20:07:51 [INFO]: Saved the model to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_4/20240602_T200651/SCINet.pypots
2024-06-02 20:07:51 [INFO]: Successfully saved to results_point_rate05/ETT_h1/SCINet_ETT_h1/round_4/imputation.pkl
2024-06-02 20:07:51 [INFO]: Round4 - SCINet on ETT_h1: MAE=0.3208, MSE=0.1923, MRE=0.3795
2024-06-02 20:07:51 [INFO]: Done! Final results:
Averaged SCINet (79,493 params) on ETT_h1: MAE=0.3262 ± 0.013501579894970726, MSE=0.1942 ± 0.013411739403409595, MRE=0.3859 ± 0.015972325105884012, average inference time=0.09
