2024-06-02 19:58:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:58:24 [INFO]: Using the given device: cuda:0
2024-06-02 19:58:26 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_0/20240602_T195826
2024-06-02 19:58:26 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_0/20240602_T195826/tensorboard
2024-06-02 19:58:27 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-02 19:58:31 [INFO]: Epoch 001 - training loss: 0.7847, validation loss: 0.7860
2024-06-02 19:58:32 [INFO]: Epoch 002 - training loss: 0.5001, validation loss: 0.6088
2024-06-02 19:58:34 [INFO]: Epoch 003 - training loss: 0.3730, validation loss: 0.4434
2024-06-02 19:58:35 [INFO]: Epoch 004 - training loss: 0.3105, validation loss: 0.3750
2024-06-02 19:58:36 [INFO]: Epoch 005 - training loss: 0.2791, validation loss: 0.3722
2024-06-02 19:58:37 [INFO]: Epoch 006 - training loss: 0.2599, validation loss: 0.3348
2024-06-02 19:58:39 [INFO]: Epoch 007 - training loss: 0.2483, validation loss: 0.3558
2024-06-02 19:58:40 [INFO]: Epoch 008 - training loss: 0.2379, validation loss: 0.3289
2024-06-02 19:58:41 [INFO]: Epoch 009 - training loss: 0.2317, validation loss: 0.3056
2024-06-02 19:58:42 [INFO]: Epoch 010 - training loss: 0.2197, validation loss: 0.3120
2024-06-02 19:58:44 [INFO]: Epoch 011 - training loss: 0.2090, validation loss: 0.3075
2024-06-02 19:58:45 [INFO]: Epoch 012 - training loss: 0.2038, validation loss: 0.2987
2024-06-02 19:58:46 [INFO]: Epoch 013 - training loss: 0.1982, validation loss: 0.3080
2024-06-02 19:58:47 [INFO]: Epoch 014 - training loss: 0.2021, validation loss: 0.3216
2024-06-02 19:58:48 [INFO]: Epoch 015 - training loss: 0.1902, validation loss: 0.2768
2024-06-02 19:58:50 [INFO]: Epoch 016 - training loss: 0.1857, validation loss: 0.3014
2024-06-02 19:58:51 [INFO]: Epoch 017 - training loss: 0.1803, validation loss: 0.2964
2024-06-02 19:58:52 [INFO]: Epoch 018 - training loss: 0.1841, validation loss: 0.3081
2024-06-02 19:58:53 [INFO]: Epoch 019 - training loss: 0.1801, validation loss: 0.2811
2024-06-02 19:58:55 [INFO]: Epoch 020 - training loss: 0.1715, validation loss: 0.2950
2024-06-02 19:58:56 [INFO]: Epoch 021 - training loss: 0.1683, validation loss: 0.2996
2024-06-02 19:58:57 [INFO]: Epoch 022 - training loss: 0.1679, validation loss: 0.2734
2024-06-02 19:58:58 [INFO]: Epoch 023 - training loss: 0.1666, validation loss: 0.3135
2024-06-02 19:58:59 [INFO]: Epoch 024 - training loss: 0.1661, validation loss: 0.2821
2024-06-02 19:59:01 [INFO]: Epoch 025 - training loss: 0.1637, validation loss: 0.2930
2024-06-02 19:59:02 [INFO]: Epoch 026 - training loss: 0.1558, validation loss: 0.2697
2024-06-02 19:59:03 [INFO]: Epoch 027 - training loss: 0.1522, validation loss: 0.2648
2024-06-02 19:59:04 [INFO]: Epoch 028 - training loss: 0.1449, validation loss: 0.2721
2024-06-02 19:59:06 [INFO]: Epoch 029 - training loss: 0.1419, validation loss: 0.2628
2024-06-02 19:59:07 [INFO]: Epoch 030 - training loss: 0.1412, validation loss: 0.2766
2024-06-02 19:59:08 [INFO]: Epoch 031 - training loss: 0.1398, validation loss: 0.2570
2024-06-02 19:59:09 [INFO]: Epoch 032 - training loss: 0.1384, validation loss: 0.2710
2024-06-02 19:59:11 [INFO]: Epoch 033 - training loss: 0.1353, validation loss: 0.2524
2024-06-02 19:59:12 [INFO]: Epoch 034 - training loss: 0.1334, validation loss: 0.2701
2024-06-02 19:59:13 [INFO]: Epoch 035 - training loss: 0.1336, validation loss: 0.2526
2024-06-02 19:59:14 [INFO]: Epoch 036 - training loss: 0.1356, validation loss: 0.2724
2024-06-02 19:59:15 [INFO]: Epoch 037 - training loss: 0.1332, validation loss: 0.2754
2024-06-02 19:59:17 [INFO]: Epoch 038 - training loss: 0.1323, validation loss: 0.2593
2024-06-02 19:59:18 [INFO]: Epoch 039 - training loss: 0.1260, validation loss: 0.2571
2024-06-02 19:59:19 [INFO]: Epoch 040 - training loss: 0.1238, validation loss: 0.2553
2024-06-02 19:59:20 [INFO]: Epoch 041 - training loss: 0.1204, validation loss: 0.2588
2024-06-02 19:59:22 [INFO]: Epoch 042 - training loss: 0.1190, validation loss: 0.2646
2024-06-02 19:59:23 [INFO]: Epoch 043 - training loss: 0.1160, validation loss: 0.2576
2024-06-02 19:59:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:59:23 [INFO]: Finished training. The best model is from epoch#33.
2024-06-02 19:59:23 [INFO]: Saved the model to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_0/20240602_T195826/GRUD.pypots
2024-06-02 19:59:25 [INFO]: Successfully saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_0/imputation.pkl
2024-06-02 19:59:25 [INFO]: Round0 - GRUD on ETT_h1: MAE=0.4060, MSE=0.3154, MRE=0.4803
2024-06-02 19:59:25 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:59:25 [INFO]: Using the given device: cuda:0
2024-06-02 19:59:25 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_1/20240602_T195925
2024-06-02 19:59:25 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_1/20240602_T195925/tensorboard
2024-06-02 19:59:25 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-02 19:59:28 [INFO]: Epoch 001 - training loss: 0.8166, validation loss: 0.7331
2024-06-02 19:59:29 [INFO]: Epoch 002 - training loss: 0.5038, validation loss: 0.5602
2024-06-02 19:59:30 [INFO]: Epoch 003 - training loss: 0.3739, validation loss: 0.4452
2024-06-02 19:59:31 [INFO]: Epoch 004 - training loss: 0.3188, validation loss: 0.3866
2024-06-02 19:59:33 [INFO]: Epoch 005 - training loss: 0.2850, validation loss: 0.3644
2024-06-02 19:59:34 [INFO]: Epoch 006 - training loss: 0.2659, validation loss: 0.3483
2024-06-02 19:59:35 [INFO]: Epoch 007 - training loss: 0.2500, validation loss: 0.3217
2024-06-02 19:59:37 [INFO]: Epoch 008 - training loss: 0.2406, validation loss: 0.3318
2024-06-02 19:59:38 [INFO]: Epoch 009 - training loss: 0.2255, validation loss: 0.2915
2024-06-02 19:59:39 [INFO]: Epoch 010 - training loss: 0.2223, validation loss: 0.3083
2024-06-02 19:59:40 [INFO]: Epoch 011 - training loss: 0.2136, validation loss: 0.3043
2024-06-02 19:59:41 [INFO]: Epoch 012 - training loss: 0.2084, validation loss: 0.2983
2024-06-02 19:59:43 [INFO]: Epoch 013 - training loss: 0.2031, validation loss: 0.2910
2024-06-02 19:59:44 [INFO]: Epoch 014 - training loss: 0.1956, validation loss: 0.2824
2024-06-02 19:59:45 [INFO]: Epoch 015 - training loss: 0.1944, validation loss: 0.3008
2024-06-02 19:59:46 [INFO]: Epoch 016 - training loss: 0.1874, validation loss: 0.2850
2024-06-02 19:59:48 [INFO]: Epoch 017 - training loss: 0.1848, validation loss: 0.2974
2024-06-02 19:59:49 [INFO]: Epoch 018 - training loss: 0.1801, validation loss: 0.2724
2024-06-02 19:59:50 [INFO]: Epoch 019 - training loss: 0.1727, validation loss: 0.2989
2024-06-02 19:59:51 [INFO]: Epoch 020 - training loss: 0.1708, validation loss: 0.2779
2024-06-02 19:59:52 [INFO]: Epoch 021 - training loss: 0.1708, validation loss: 0.2802
2024-06-02 19:59:54 [INFO]: Epoch 022 - training loss: 0.1648, validation loss: 0.2699
2024-06-02 19:59:55 [INFO]: Epoch 023 - training loss: 0.1578, validation loss: 0.2421
2024-06-02 19:59:56 [INFO]: Epoch 024 - training loss: 0.1595, validation loss: 0.2538
2024-06-02 19:59:57 [INFO]: Epoch 025 - training loss: 0.1548, validation loss: 0.2677
2024-06-02 19:59:59 [INFO]: Epoch 026 - training loss: 0.1505, validation loss: 0.2564
2024-06-02 20:00:00 [INFO]: Epoch 027 - training loss: 0.1519, validation loss: 0.2508
2024-06-02 20:00:01 [INFO]: Epoch 028 - training loss: 0.1506, validation loss: 0.2617
2024-06-02 20:00:02 [INFO]: Epoch 029 - training loss: 0.1463, validation loss: 0.2676
2024-06-02 20:00:04 [INFO]: Epoch 030 - training loss: 0.1426, validation loss: 0.2764
2024-06-02 20:00:05 [INFO]: Epoch 031 - training loss: 0.1394, validation loss: 0.2555
2024-06-02 20:00:06 [INFO]: Epoch 032 - training loss: 0.1378, validation loss: 0.2598
2024-06-02 20:00:07 [INFO]: Epoch 033 - training loss: 0.1338, validation loss: 0.2789
2024-06-02 20:00:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:00:07 [INFO]: Finished training. The best model is from epoch#23.
2024-06-02 20:00:07 [INFO]: Saved the model to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_1/20240602_T195925/GRUD.pypots
2024-06-02 20:00:09 [INFO]: Successfully saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_1/imputation.pkl
2024-06-02 20:00:09 [INFO]: Round1 - GRUD on ETT_h1: MAE=0.4133, MSE=0.3301, MRE=0.4889
2024-06-02 20:00:09 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:00:09 [INFO]: Using the given device: cuda:0
2024-06-02 20:00:09 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_2/20240602_T200009
2024-06-02 20:00:09 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_2/20240602_T200009/tensorboard
2024-06-02 20:00:09 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-02 20:00:11 [INFO]: Epoch 001 - training loss: 0.9098, validation loss: 0.7586
2024-06-02 20:00:13 [INFO]: Epoch 002 - training loss: 0.6296, validation loss: 0.7016
2024-06-02 20:00:14 [INFO]: Epoch 003 - training loss: 0.4783, validation loss: 0.5403
2024-06-02 20:00:15 [INFO]: Epoch 004 - training loss: 0.3709, validation loss: 0.4599
2024-06-02 20:00:16 [INFO]: Epoch 005 - training loss: 0.3084, validation loss: 0.4026
2024-06-02 20:00:17 [INFO]: Epoch 006 - training loss: 0.2825, validation loss: 0.3711
2024-06-02 20:00:18 [INFO]: Epoch 007 - training loss: 0.2606, validation loss: 0.3330
2024-06-02 20:00:19 [INFO]: Epoch 008 - training loss: 0.2481, validation loss: 0.3119
2024-06-02 20:00:20 [INFO]: Epoch 009 - training loss: 0.2403, validation loss: 0.3169
2024-06-02 20:00:21 [INFO]: Epoch 010 - training loss: 0.2308, validation loss: 0.3024
2024-06-02 20:00:22 [INFO]: Epoch 011 - training loss: 0.2204, validation loss: 0.3158
2024-06-02 20:00:23 [INFO]: Epoch 012 - training loss: 0.2132, validation loss: 0.2925
2024-06-02 20:00:24 [INFO]: Epoch 013 - training loss: 0.2059, validation loss: 0.2922
2024-06-02 20:00:25 [INFO]: Epoch 014 - training loss: 0.2011, validation loss: 0.3215
2024-06-02 20:00:26 [INFO]: Epoch 015 - training loss: 0.2020, validation loss: 0.2785
2024-06-02 20:00:27 [INFO]: Epoch 016 - training loss: 0.2017, validation loss: 0.2767
2024-06-02 20:00:28 [INFO]: Epoch 017 - training loss: 0.1990, validation loss: 0.2924
2024-06-02 20:00:30 [INFO]: Epoch 018 - training loss: 0.1931, validation loss: 0.2812
2024-06-02 20:00:31 [INFO]: Epoch 019 - training loss: 0.1889, validation loss: 0.2981
2024-06-02 20:00:32 [INFO]: Epoch 020 - training loss: 0.1818, validation loss: 0.2777
2024-06-02 20:00:33 [INFO]: Epoch 021 - training loss: 0.1736, validation loss: 0.2741
2024-06-02 20:00:34 [INFO]: Epoch 022 - training loss: 0.1686, validation loss: 0.2999
2024-06-02 20:00:35 [INFO]: Epoch 023 - training loss: 0.1710, validation loss: 0.2624
2024-06-02 20:00:36 [INFO]: Epoch 024 - training loss: 0.1678, validation loss: 0.2702
2024-06-02 20:00:37 [INFO]: Epoch 025 - training loss: 0.1617, validation loss: 0.2694
2024-06-02 20:00:38 [INFO]: Epoch 026 - training loss: 0.1607, validation loss: 0.2747
2024-06-02 20:00:39 [INFO]: Epoch 027 - training loss: 0.1560, validation loss: 0.2533
2024-06-02 20:00:41 [INFO]: Epoch 028 - training loss: 0.1521, validation loss: 0.2535
2024-06-02 20:00:42 [INFO]: Epoch 029 - training loss: 0.1471, validation loss: 0.2742
2024-06-02 20:00:43 [INFO]: Epoch 030 - training loss: 0.1508, validation loss: 0.2777
2024-06-02 20:00:44 [INFO]: Epoch 031 - training loss: 0.1577, validation loss: 0.2571
2024-06-02 20:00:45 [INFO]: Epoch 032 - training loss: 0.1584, validation loss: 0.2692
2024-06-02 20:00:46 [INFO]: Epoch 033 - training loss: 0.1531, validation loss: 0.2700
2024-06-02 20:00:47 [INFO]: Epoch 034 - training loss: 0.1478, validation loss: 0.2784
2024-06-02 20:00:48 [INFO]: Epoch 035 - training loss: 0.1451, validation loss: 0.2697
2024-06-02 20:00:49 [INFO]: Epoch 036 - training loss: 0.1442, validation loss: 0.2562
2024-06-02 20:00:50 [INFO]: Epoch 037 - training loss: 0.1403, validation loss: 0.2644
2024-06-02 20:00:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:00:50 [INFO]: Finished training. The best model is from epoch#27.
2024-06-02 20:00:50 [INFO]: Saved the model to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_2/20240602_T200009/GRUD.pypots
2024-06-02 20:00:53 [INFO]: Successfully saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_2/imputation.pkl
2024-06-02 20:00:53 [INFO]: Round2 - GRUD on ETT_h1: MAE=0.4152, MSE=0.3333, MRE=0.4912
2024-06-02 20:00:53 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:00:53 [INFO]: Using the given device: cuda:0
2024-06-02 20:00:53 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_3/20240602_T200053
2024-06-02 20:00:53 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_3/20240602_T200053/tensorboard
2024-06-02 20:00:53 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-02 20:00:55 [INFO]: Epoch 001 - training loss: 0.8697, validation loss: 0.8007
2024-06-02 20:00:56 [INFO]: Epoch 002 - training loss: 0.5636, validation loss: 0.6544
2024-06-02 20:00:57 [INFO]: Epoch 003 - training loss: 0.3845, validation loss: 0.5075
2024-06-02 20:00:58 [INFO]: Epoch 004 - training loss: 0.3182, validation loss: 0.3842
2024-06-02 20:00:59 [INFO]: Epoch 005 - training loss: 0.2834, validation loss: 0.3914
2024-06-02 20:01:00 [INFO]: Epoch 006 - training loss: 0.2588, validation loss: 0.3316
2024-06-02 20:01:01 [INFO]: Epoch 007 - training loss: 0.2471, validation loss: 0.3275
2024-06-02 20:01:02 [INFO]: Epoch 008 - training loss: 0.2347, validation loss: 0.3203
2024-06-02 20:01:03 [INFO]: Epoch 009 - training loss: 0.2237, validation loss: 0.2921
2024-06-02 20:01:04 [INFO]: Epoch 010 - training loss: 0.2164, validation loss: 0.3115
2024-06-02 20:01:05 [INFO]: Epoch 011 - training loss: 0.2098, validation loss: 0.3109
2024-06-02 20:01:06 [INFO]: Epoch 012 - training loss: 0.2061, validation loss: 0.3006
2024-06-02 20:01:07 [INFO]: Epoch 013 - training loss: 0.2062, validation loss: 0.3104
2024-06-02 20:01:08 [INFO]: Epoch 014 - training loss: 0.1954, validation loss: 0.3026
2024-06-02 20:01:09 [INFO]: Epoch 015 - training loss: 0.1951, validation loss: 0.2668
2024-06-02 20:01:11 [INFO]: Epoch 016 - training loss: 0.1854, validation loss: 0.2856
2024-06-02 20:01:12 [INFO]: Epoch 017 - training loss: 0.1799, validation loss: 0.2836
2024-06-02 20:01:13 [INFO]: Epoch 018 - training loss: 0.1746, validation loss: 0.2891
2024-06-02 20:01:14 [INFO]: Epoch 019 - training loss: 0.1717, validation loss: 0.2884
2024-06-02 20:01:15 [INFO]: Epoch 020 - training loss: 0.1742, validation loss: 0.2827
2024-06-02 20:01:16 [INFO]: Epoch 021 - training loss: 0.1673, validation loss: 0.2607
2024-06-02 20:01:17 [INFO]: Epoch 022 - training loss: 0.1645, validation loss: 0.2693
2024-06-02 20:01:18 [INFO]: Epoch 023 - training loss: 0.1602, validation loss: 0.2506
2024-06-02 20:01:19 [INFO]: Epoch 024 - training loss: 0.1565, validation loss: 0.2643
2024-06-02 20:01:20 [INFO]: Epoch 025 - training loss: 0.1548, validation loss: 0.2803
2024-06-02 20:01:21 [INFO]: Epoch 026 - training loss: 0.1554, validation loss: 0.2690
2024-06-02 20:01:23 [INFO]: Epoch 027 - training loss: 0.1600, validation loss: 0.2784
2024-06-02 20:01:24 [INFO]: Epoch 028 - training loss: 0.1528, validation loss: 0.2687
2024-06-02 20:01:25 [INFO]: Epoch 029 - training loss: 0.1456, validation loss: 0.2712
2024-06-02 20:01:26 [INFO]: Epoch 030 - training loss: 0.1460, validation loss: 0.2788
2024-06-02 20:01:27 [INFO]: Epoch 031 - training loss: 0.1424, validation loss: 0.2608
2024-06-02 20:01:28 [INFO]: Epoch 032 - training loss: 0.1392, validation loss: 0.2762
2024-06-02 20:01:29 [INFO]: Epoch 033 - training loss: 0.1392, validation loss: 0.2543
2024-06-02 20:01:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:01:29 [INFO]: Finished training. The best model is from epoch#23.
2024-06-02 20:01:29 [INFO]: Saved the model to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_3/20240602_T200053/GRUD.pypots
2024-06-02 20:01:31 [INFO]: Successfully saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_3/imputation.pkl
2024-06-02 20:01:31 [INFO]: Round3 - GRUD on ETT_h1: MAE=0.4206, MSE=0.3491, MRE=0.4976
2024-06-02 20:01:31 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:01:31 [INFO]: Using the given device: cuda:0
2024-06-02 20:01:31 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_4/20240602_T200131
2024-06-02 20:01:31 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_4/20240602_T200131/tensorboard
2024-06-02 20:01:31 [INFO]: GRUD initialized with the given hyperparameters, the number of trainable parameters: 409,407
2024-06-02 20:01:33 [INFO]: Epoch 001 - training loss: 0.7876, validation loss: 0.8074
2024-06-02 20:01:34 [INFO]: Epoch 002 - training loss: 0.5022, validation loss: 0.6173
2024-06-02 20:01:35 [INFO]: Epoch 003 - training loss: 0.3978, validation loss: 0.4904
2024-06-02 20:01:36 [INFO]: Epoch 004 - training loss: 0.3266, validation loss: 0.4113
2024-06-02 20:01:37 [INFO]: Epoch 005 - training loss: 0.2885, validation loss: 0.3566
2024-06-02 20:01:38 [INFO]: Epoch 006 - training loss: 0.2663, validation loss: 0.3698
2024-06-02 20:01:39 [INFO]: Epoch 007 - training loss: 0.2475, validation loss: 0.3301
2024-06-02 20:01:39 [INFO]: Epoch 008 - training loss: 0.2365, validation loss: 0.3136
2024-06-02 20:01:40 [INFO]: Epoch 009 - training loss: 0.2248, validation loss: 0.3195
2024-06-02 20:01:41 [INFO]: Epoch 010 - training loss: 0.2175, validation loss: 0.3154
2024-06-02 20:01:42 [INFO]: Epoch 011 - training loss: 0.2094, validation loss: 0.2987
2024-06-02 20:01:43 [INFO]: Epoch 012 - training loss: 0.2040, validation loss: 0.2940
2024-06-02 20:01:43 [INFO]: Epoch 013 - training loss: 0.2021, validation loss: 0.2963
2024-06-02 20:01:44 [INFO]: Epoch 014 - training loss: 0.1983, validation loss: 0.3048
2024-06-02 20:01:45 [INFO]: Epoch 015 - training loss: 0.1913, validation loss: 0.2673
2024-06-02 20:01:45 [INFO]: Epoch 016 - training loss: 0.1852, validation loss: 0.3067
2024-06-02 20:01:46 [INFO]: Epoch 017 - training loss: 0.1858, validation loss: 0.2707
2024-06-02 20:01:47 [INFO]: Epoch 018 - training loss: 0.1786, validation loss: 0.2726
2024-06-02 20:01:47 [INFO]: Epoch 019 - training loss: 0.1694, validation loss: 0.2738
2024-06-02 20:01:48 [INFO]: Epoch 020 - training loss: 0.1676, validation loss: 0.2637
2024-06-02 20:01:49 [INFO]: Epoch 021 - training loss: 0.1635, validation loss: 0.2966
2024-06-02 20:01:49 [INFO]: Epoch 022 - training loss: 0.1616, validation loss: 0.2797
2024-06-02 20:01:50 [INFO]: Epoch 023 - training loss: 0.1562, validation loss: 0.2862
2024-06-02 20:01:51 [INFO]: Epoch 024 - training loss: 0.1552, validation loss: 0.2714
2024-06-02 20:01:51 [INFO]: Epoch 025 - training loss: 0.1547, validation loss: 0.2566
2024-06-02 20:01:52 [INFO]: Epoch 026 - training loss: 0.1556, validation loss: 0.2738
2024-06-02 20:01:53 [INFO]: Epoch 027 - training loss: 0.1525, validation loss: 0.2805
2024-06-02 20:01:53 [INFO]: Epoch 028 - training loss: 0.1569, validation loss: 0.2779
2024-06-02 20:01:54 [INFO]: Epoch 029 - training loss: 0.1485, validation loss: 0.2684
2024-06-02 20:01:54 [INFO]: Epoch 030 - training loss: 0.1476, validation loss: 0.2726
2024-06-02 20:01:55 [INFO]: Epoch 031 - training loss: 0.1403, validation loss: 0.2557
2024-06-02 20:01:55 [INFO]: Epoch 032 - training loss: 0.1352, validation loss: 0.2480
2024-06-02 20:01:56 [INFO]: Epoch 033 - training loss: 0.1308, validation loss: 0.2741
2024-06-02 20:01:57 [INFO]: Epoch 034 - training loss: 0.1288, validation loss: 0.2588
2024-06-02 20:01:57 [INFO]: Epoch 035 - training loss: 0.1294, validation loss: 0.2596
2024-06-02 20:01:58 [INFO]: Epoch 036 - training loss: 0.1342, validation loss: 0.2788
2024-06-02 20:01:59 [INFO]: Epoch 037 - training loss: 0.1275, validation loss: 0.2700
2024-06-02 20:01:59 [INFO]: Epoch 038 - training loss: 0.1229, validation loss: 0.2520
2024-06-02 20:02:00 [INFO]: Epoch 039 - training loss: 0.1207, validation loss: 0.2828
2024-06-02 20:02:00 [INFO]: Epoch 040 - training loss: 0.1190, validation loss: 0.2713
2024-06-02 20:02:01 [INFO]: Epoch 041 - training loss: 0.1168, validation loss: 0.2546
2024-06-02 20:02:02 [INFO]: Epoch 042 - training loss: 0.1194, validation loss: 0.2912
2024-06-02 20:02:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:02:02 [INFO]: Finished training. The best model is from epoch#32.
2024-06-02 20:02:02 [INFO]: Saved the model to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_4/20240602_T200131/GRUD.pypots
2024-06-02 20:02:03 [INFO]: Successfully saved to results_point_rate05/ETT_h1/GRUD_ETT_h1/round_4/imputation.pkl
2024-06-02 20:02:03 [INFO]: Round4 - GRUD on ETT_h1: MAE=0.4307, MSE=0.3547, MRE=0.5095
2024-06-02 20:02:03 [INFO]: Done! Final results:
Averaged GRUD (409,407 params) on ETT_h1: MAE=0.4171 ± 0.00823130375897658, MSE=0.3365 ± 0.014035547924567316, MRE=0.4935 ± 0.00973760557700604, average inference time=0.42
