2024-06-02 20:03:17 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:03:17 [INFO]: Using the given device: cuda:0
2024-06-02 20:03:18 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_0/20240602_T200318
2024-06-02 20:03:18 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_0/20240602_T200318/tensorboard
2024-06-02 20:03:19 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 3,153,163
2024-06-02 20:03:24 [INFO]: Epoch 001 - training loss: 1.1530, validation loss: 0.6327
2024-06-02 20:03:25 [INFO]: Epoch 002 - training loss: 0.9324, validation loss: 0.5906
2024-06-02 20:03:26 [INFO]: Epoch 003 - training loss: 0.9009, validation loss: 0.5859
2024-06-02 20:03:28 [INFO]: Epoch 004 - training loss: 0.8733, validation loss: 0.6001
2024-06-02 20:03:29 [INFO]: Epoch 005 - training loss: 0.8596, validation loss: 0.6298
2024-06-02 20:03:31 [INFO]: Epoch 006 - training loss: 0.8235, validation loss: 0.6355
2024-06-02 20:03:32 [INFO]: Epoch 007 - training loss: 0.8212, validation loss: 0.6377
2024-06-02 20:03:33 [INFO]: Epoch 008 - training loss: 0.8032, validation loss: 0.6263
2024-06-02 20:03:35 [INFO]: Epoch 009 - training loss: 0.7697, validation loss: 0.6192
2024-06-02 20:03:36 [INFO]: Epoch 010 - training loss: 0.7878, validation loss: 0.6130
2024-06-02 20:03:37 [INFO]: Epoch 011 - training loss: 0.7603, validation loss: 0.6367
2024-06-02 20:03:38 [INFO]: Epoch 012 - training loss: 0.7499, validation loss: 0.6213
2024-06-02 20:03:39 [INFO]: Epoch 013 - training loss: 0.7555, validation loss: 0.6296
2024-06-02 20:03:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:03:39 [INFO]: Finished training. The best model is from epoch#3.
2024-06-02 20:03:40 [INFO]: Saved the model to results_point_rate05/ETT_h1/MICN_ETT_h1/round_0/20240602_T200318/MICN.pypots
2024-06-02 20:03:40 [INFO]: Successfully saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_0/imputation.pkl
2024-06-02 20:03:40 [INFO]: Round0 - MICN on ETT_h1: MAE=0.6473, MSE=0.7857, MRE=0.7657
2024-06-02 20:03:40 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:03:40 [INFO]: Using the given device: cuda:0
2024-06-02 20:03:40 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_1/20240602_T200340
2024-06-02 20:03:40 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_1/20240602_T200340/tensorboard
2024-06-02 20:03:41 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 3,153,163
2024-06-02 20:03:42 [INFO]: Epoch 001 - training loss: 1.1918, validation loss: 0.6292
2024-06-02 20:03:43 [INFO]: Epoch 002 - training loss: 0.9242, validation loss: 0.5856
2024-06-02 20:03:45 [INFO]: Epoch 003 - training loss: 0.8932, validation loss: 0.5904
2024-06-02 20:03:46 [INFO]: Epoch 004 - training loss: 0.8630, validation loss: 0.5785
2024-06-02 20:03:47 [INFO]: Epoch 005 - training loss: 0.8360, validation loss: 0.6177
2024-06-02 20:03:49 [INFO]: Epoch 006 - training loss: 0.8099, validation loss: 0.5957
2024-06-02 20:03:50 [INFO]: Epoch 007 - training loss: 0.8088, validation loss: 0.6145
2024-06-02 20:03:51 [INFO]: Epoch 008 - training loss: 0.7702, validation loss: 0.6083
2024-06-02 20:03:53 [INFO]: Epoch 009 - training loss: 0.7832, validation loss: 0.6052
2024-06-02 20:03:54 [INFO]: Epoch 010 - training loss: 0.7625, validation loss: 0.6295
2024-06-02 20:03:56 [INFO]: Epoch 011 - training loss: 0.7660, validation loss: 0.6073
2024-06-02 20:03:57 [INFO]: Epoch 012 - training loss: 0.7551, validation loss: 0.5877
2024-06-02 20:03:58 [INFO]: Epoch 013 - training loss: 0.7287, validation loss: 0.6568
2024-06-02 20:03:59 [INFO]: Epoch 014 - training loss: 0.7364, validation loss: 0.5600
2024-06-02 20:04:01 [INFO]: Epoch 015 - training loss: 0.7129, validation loss: 0.6221
2024-06-02 20:04:02 [INFO]: Epoch 016 - training loss: 0.7144, validation loss: 0.6043
2024-06-02 20:04:03 [INFO]: Epoch 017 - training loss: 0.7012, validation loss: 0.5616
2024-06-02 20:04:04 [INFO]: Epoch 018 - training loss: 0.6898, validation loss: 0.6240
2024-06-02 20:04:06 [INFO]: Epoch 019 - training loss: 0.6962, validation loss: 0.5439
2024-06-02 20:04:07 [INFO]: Epoch 020 - training loss: 0.6891, validation loss: 0.5898
2024-06-02 20:04:08 [INFO]: Epoch 021 - training loss: 0.6738, validation loss: 0.5576
2024-06-02 20:04:09 [INFO]: Epoch 022 - training loss: 0.6698, validation loss: 0.5639
2024-06-02 20:04:11 [INFO]: Epoch 023 - training loss: 0.6621, validation loss: 0.5528
2024-06-02 20:04:12 [INFO]: Epoch 024 - training loss: 0.6668, validation loss: 0.5758
2024-06-02 20:04:14 [INFO]: Epoch 025 - training loss: 0.6663, validation loss: 0.5624
2024-06-02 20:04:15 [INFO]: Epoch 026 - training loss: 0.6643, validation loss: 0.5458
2024-06-02 20:04:16 [INFO]: Epoch 027 - training loss: 0.6381, validation loss: 0.5392
2024-06-02 20:04:17 [INFO]: Epoch 028 - training loss: 0.6421, validation loss: 0.5272
2024-06-02 20:04:19 [INFO]: Epoch 029 - training loss: 0.6400, validation loss: 0.5338
2024-06-02 20:04:20 [INFO]: Epoch 030 - training loss: 0.6158, validation loss: 0.5423
2024-06-02 20:04:21 [INFO]: Epoch 031 - training loss: 0.6258, validation loss: 0.5083
2024-06-02 20:04:23 [INFO]: Epoch 032 - training loss: 0.6155, validation loss: 0.5446
2024-06-02 20:04:24 [INFO]: Epoch 033 - training loss: 0.6144, validation loss: 0.4936
2024-06-02 20:04:25 [INFO]: Epoch 034 - training loss: 0.6117, validation loss: 0.5227
2024-06-02 20:04:27 [INFO]: Epoch 035 - training loss: 0.5953, validation loss: 0.5140
2024-06-02 20:04:28 [INFO]: Epoch 036 - training loss: 0.6080, validation loss: 0.5144
2024-06-02 20:04:29 [INFO]: Epoch 037 - training loss: 0.6016, validation loss: 0.5571
2024-06-02 20:04:31 [INFO]: Epoch 038 - training loss: 0.5962, validation loss: 0.4914
2024-06-02 20:04:32 [INFO]: Epoch 039 - training loss: 0.5995, validation loss: 0.5088
2024-06-02 20:04:33 [INFO]: Epoch 040 - training loss: 0.5886, validation loss: 0.4660
2024-06-02 20:04:35 [INFO]: Epoch 041 - training loss: 0.5916, validation loss: 0.5234
2024-06-02 20:04:36 [INFO]: Epoch 042 - training loss: 0.5900, validation loss: 0.4787
2024-06-02 20:04:37 [INFO]: Epoch 043 - training loss: 0.5908, validation loss: 0.4966
2024-06-02 20:04:39 [INFO]: Epoch 044 - training loss: 0.5876, validation loss: 0.4670
2024-06-02 20:04:40 [INFO]: Epoch 045 - training loss: 0.5847, validation loss: 0.4597
2024-06-02 20:04:41 [INFO]: Epoch 046 - training loss: 0.5831, validation loss: 0.4632
2024-06-02 20:04:42 [INFO]: Epoch 047 - training loss: 0.5729, validation loss: 0.4872
2024-06-02 20:04:44 [INFO]: Epoch 048 - training loss: 0.5746, validation loss: 0.4506
2024-06-02 20:04:45 [INFO]: Epoch 049 - training loss: 0.5753, validation loss: 0.4271
2024-06-02 20:04:46 [INFO]: Epoch 050 - training loss: 0.5604, validation loss: 0.4517
2024-06-02 20:04:48 [INFO]: Epoch 051 - training loss: 0.5701, validation loss: 0.4405
2024-06-02 20:04:49 [INFO]: Epoch 052 - training loss: 0.5539, validation loss: 0.4356
2024-06-02 20:04:50 [INFO]: Epoch 053 - training loss: 0.5583, validation loss: 0.4311
2024-06-02 20:04:51 [INFO]: Epoch 054 - training loss: 0.5429, validation loss: 0.4386
2024-06-02 20:04:52 [INFO]: Epoch 055 - training loss: 0.5437, validation loss: 0.4143
2024-06-02 20:04:53 [INFO]: Epoch 056 - training loss: 0.5471, validation loss: 0.4048
2024-06-02 20:04:55 [INFO]: Epoch 057 - training loss: 0.5451, validation loss: 0.4138
2024-06-02 20:04:56 [INFO]: Epoch 058 - training loss: 0.5375, validation loss: 0.4355
2024-06-02 20:04:57 [INFO]: Epoch 059 - training loss: 0.5309, validation loss: 0.4008
2024-06-02 20:04:59 [INFO]: Epoch 060 - training loss: 0.5360, validation loss: 0.3825
2024-06-02 20:05:00 [INFO]: Epoch 061 - training loss: 0.5303, validation loss: 0.3980
2024-06-02 20:05:01 [INFO]: Epoch 062 - training loss: 0.5309, validation loss: 0.3946
2024-06-02 20:05:02 [INFO]: Epoch 063 - training loss: 0.5389, validation loss: 0.3831
2024-06-02 20:05:04 [INFO]: Epoch 064 - training loss: 0.5320, validation loss: 0.3872
2024-06-02 20:05:05 [INFO]: Epoch 065 - training loss: 0.5310, validation loss: 0.3592
2024-06-02 20:05:06 [INFO]: Epoch 066 - training loss: 0.5351, validation loss: 0.3674
2024-06-02 20:05:08 [INFO]: Epoch 067 - training loss: 0.5211, validation loss: 0.3673
2024-06-02 20:05:09 [INFO]: Epoch 068 - training loss: 0.5140, validation loss: 0.3561
2024-06-02 20:05:11 [INFO]: Epoch 069 - training loss: 0.5233, validation loss: 0.3638
2024-06-02 20:05:12 [INFO]: Epoch 070 - training loss: 0.5190, validation loss: 0.3774
2024-06-02 20:05:13 [INFO]: Epoch 071 - training loss: 0.5174, validation loss: 0.3698
2024-06-02 20:05:14 [INFO]: Epoch 072 - training loss: 0.5123, validation loss: 0.4014
2024-06-02 20:05:15 [INFO]: Epoch 073 - training loss: 0.5156, validation loss: 0.3983
2024-06-02 20:05:17 [INFO]: Epoch 074 - training loss: 0.5188, validation loss: 0.3557
2024-06-02 20:05:18 [INFO]: Epoch 075 - training loss: 0.5156, validation loss: 0.3533
2024-06-02 20:05:19 [INFO]: Epoch 076 - training loss: 0.5013, validation loss: 0.3479
2024-06-02 20:05:21 [INFO]: Epoch 077 - training loss: 0.5059, validation loss: 0.3748
2024-06-02 20:05:22 [INFO]: Epoch 078 - training loss: 0.5086, validation loss: 0.3808
2024-06-02 20:05:23 [INFO]: Epoch 079 - training loss: 0.4988, validation loss: 0.3568
2024-06-02 20:05:24 [INFO]: Epoch 080 - training loss: 0.5046, validation loss: 0.3605
2024-06-02 20:05:25 [INFO]: Epoch 081 - training loss: 0.5021, validation loss: 0.3472
2024-06-02 20:05:26 [INFO]: Epoch 082 - training loss: 0.4969, validation loss: 0.3386
2024-06-02 20:05:27 [INFO]: Epoch 083 - training loss: 0.4952, validation loss: 0.3420
2024-06-02 20:05:28 [INFO]: Epoch 084 - training loss: 0.4958, validation loss: 0.3542
2024-06-02 20:05:30 [INFO]: Epoch 085 - training loss: 0.4938, validation loss: 0.3396
2024-06-02 20:05:31 [INFO]: Epoch 086 - training loss: 0.4923, validation loss: 0.3599
2024-06-02 20:05:32 [INFO]: Epoch 087 - training loss: 0.5045, validation loss: 0.3483
2024-06-02 20:05:33 [INFO]: Epoch 088 - training loss: 0.4906, validation loss: 0.3354
2024-06-02 20:05:35 [INFO]: Epoch 089 - training loss: 0.4914, validation loss: 0.3532
2024-06-02 20:05:36 [INFO]: Epoch 090 - training loss: 0.4838, validation loss: 0.3371
2024-06-02 20:05:37 [INFO]: Epoch 091 - training loss: 0.4731, validation loss: 0.3289
2024-06-02 20:05:39 [INFO]: Epoch 092 - training loss: 0.4800, validation loss: 0.3228
2024-06-02 20:05:40 [INFO]: Epoch 093 - training loss: 0.4849, validation loss: 0.3297
2024-06-02 20:05:41 [INFO]: Epoch 094 - training loss: 0.4867, validation loss: 0.3668
2024-06-02 20:05:43 [INFO]: Epoch 095 - training loss: 0.4792, validation loss: 0.3583
2024-06-02 20:05:44 [INFO]: Epoch 096 - training loss: 0.4824, validation loss: 0.3378
2024-06-02 20:05:45 [INFO]: Epoch 097 - training loss: 0.4777, validation loss: 0.3176
2024-06-02 20:05:46 [INFO]: Epoch 098 - training loss: 0.4715, validation loss: 0.3223
2024-06-02 20:05:48 [INFO]: Epoch 099 - training loss: 0.4694, validation loss: 0.3341
2024-06-02 20:05:49 [INFO]: Epoch 100 - training loss: 0.4733, validation loss: 0.3519
2024-06-02 20:05:49 [INFO]: Finished training. The best model is from epoch#97.
2024-06-02 20:05:49 [INFO]: Saved the model to results_point_rate05/ETT_h1/MICN_ETT_h1/round_1/20240602_T200340/MICN.pypots
2024-06-02 20:05:50 [INFO]: Successfully saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_1/imputation.pkl
2024-06-02 20:05:50 [INFO]: Round1 - MICN on ETT_h1: MAE=0.4604, MSE=0.3859, MRE=0.5446
2024-06-02 20:05:50 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:05:50 [INFO]: Using the given device: cuda:0
2024-06-02 20:05:50 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_2/20240602_T200550
2024-06-02 20:05:50 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_2/20240602_T200550/tensorboard
2024-06-02 20:05:50 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 3,153,163
2024-06-02 20:05:51 [INFO]: Epoch 001 - training loss: 1.2465, validation loss: 0.6416
2024-06-02 20:05:53 [INFO]: Epoch 002 - training loss: 0.9265, validation loss: 0.6022
2024-06-02 20:05:54 [INFO]: Epoch 003 - training loss: 0.8877, validation loss: 0.6267
2024-06-02 20:05:56 [INFO]: Epoch 004 - training loss: 0.8537, validation loss: 0.6096
2024-06-02 20:05:57 [INFO]: Epoch 005 - training loss: 0.8526, validation loss: 0.6165
2024-06-02 20:05:58 [INFO]: Epoch 006 - training loss: 0.8254, validation loss: 0.6072
2024-06-02 20:06:00 [INFO]: Epoch 007 - training loss: 0.8043, validation loss: 0.6045
2024-06-02 20:06:01 [INFO]: Epoch 008 - training loss: 0.7873, validation loss: 0.6105
2024-06-02 20:06:02 [INFO]: Epoch 009 - training loss: 0.7851, validation loss: 0.6237
2024-06-02 20:06:04 [INFO]: Epoch 010 - training loss: 0.7883, validation loss: 0.6028
2024-06-02 20:06:05 [INFO]: Epoch 011 - training loss: 0.7641, validation loss: 0.6672
2024-06-02 20:06:06 [INFO]: Epoch 012 - training loss: 0.7534, validation loss: 0.6071
2024-06-02 20:06:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:06 [INFO]: Finished training. The best model is from epoch#2.
2024-06-02 20:06:06 [INFO]: Saved the model to results_point_rate05/ETT_h1/MICN_ETT_h1/round_2/20240602_T200550/MICN.pypots
2024-06-02 20:06:07 [INFO]: Successfully saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_2/imputation.pkl
2024-06-02 20:06:07 [INFO]: Round2 - MICN on ETT_h1: MAE=0.6328, MSE=0.7515, MRE=0.7486
2024-06-02 20:06:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:06:07 [INFO]: Using the given device: cuda:0
2024-06-02 20:06:07 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_3/20240602_T200607
2024-06-02 20:06:07 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_3/20240602_T200607/tensorboard
2024-06-02 20:06:07 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 3,153,163
2024-06-02 20:06:08 [INFO]: Epoch 001 - training loss: 1.1900, validation loss: 0.5895
2024-06-02 20:06:09 [INFO]: Epoch 002 - training loss: 0.9094, validation loss: 0.5715
2024-06-02 20:06:11 [INFO]: Epoch 003 - training loss: 0.8906, validation loss: 0.5815
2024-06-02 20:06:12 [INFO]: Epoch 004 - training loss: 0.8700, validation loss: 0.6194
2024-06-02 20:06:13 [INFO]: Epoch 005 - training loss: 0.8604, validation loss: 0.6375
2024-06-02 20:06:14 [INFO]: Epoch 006 - training loss: 0.8421, validation loss: 0.6501
2024-06-02 20:06:16 [INFO]: Epoch 007 - training loss: 0.8072, validation loss: 0.6300
2024-06-02 20:06:17 [INFO]: Epoch 008 - training loss: 0.7976, validation loss: 0.6472
2024-06-02 20:06:18 [INFO]: Epoch 009 - training loss: 0.7761, validation loss: 0.6761
2024-06-02 20:06:19 [INFO]: Epoch 010 - training loss: 0.7680, validation loss: 0.6796
2024-06-02 20:06:21 [INFO]: Epoch 011 - training loss: 0.7697, validation loss: 0.6347
2024-06-02 20:06:22 [INFO]: Epoch 012 - training loss: 0.7640, validation loss: 0.6359
2024-06-02 20:06:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:22 [INFO]: Finished training. The best model is from epoch#2.
2024-06-02 20:06:22 [INFO]: Saved the model to results_point_rate05/ETT_h1/MICN_ETT_h1/round_3/20240602_T200607/MICN.pypots
2024-06-02 20:06:23 [INFO]: Successfully saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_3/imputation.pkl
2024-06-02 20:06:23 [INFO]: Round3 - MICN on ETT_h1: MAE=0.6531, MSE=0.7808, MRE=0.7726
2024-06-02 20:06:23 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:06:23 [INFO]: Using the given device: cuda:0
2024-06-02 20:06:23 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_4/20240602_T200623
2024-06-02 20:06:23 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_4/20240602_T200623/tensorboard
2024-06-02 20:06:23 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 3,153,163
2024-06-02 20:06:24 [INFO]: Epoch 001 - training loss: 1.1821, validation loss: 0.6117
2024-06-02 20:06:26 [INFO]: Epoch 002 - training loss: 0.9176, validation loss: 0.5937
2024-06-02 20:06:27 [INFO]: Epoch 003 - training loss: 0.8826, validation loss: 0.5979
2024-06-02 20:06:28 [INFO]: Epoch 004 - training loss: 0.8490, validation loss: 0.6329
2024-06-02 20:06:29 [INFO]: Epoch 005 - training loss: 0.8354, validation loss: 0.6023
2024-06-02 20:06:31 [INFO]: Epoch 006 - training loss: 0.8155, validation loss: 0.6170
2024-06-02 20:06:32 [INFO]: Epoch 007 - training loss: 0.8031, validation loss: 0.6415
2024-06-02 20:06:33 [INFO]: Epoch 008 - training loss: 0.7837, validation loss: 0.6317
2024-06-02 20:06:35 [INFO]: Epoch 009 - training loss: 0.7659, validation loss: 0.6488
2024-06-02 20:06:36 [INFO]: Epoch 010 - training loss: 0.7556, validation loss: 0.6329
2024-06-02 20:06:37 [INFO]: Epoch 011 - training loss: 0.7465, validation loss: 0.6451
2024-06-02 20:06:38 [INFO]: Epoch 012 - training loss: 0.7503, validation loss: 0.6146
2024-06-02 20:06:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:38 [INFO]: Finished training. The best model is from epoch#2.
2024-06-02 20:06:38 [INFO]: Saved the model to results_point_rate05/ETT_h1/MICN_ETT_h1/round_4/20240602_T200623/MICN.pypots
2024-06-02 20:06:39 [INFO]: Successfully saved to results_point_rate05/ETT_h1/MICN_ETT_h1/round_4/imputation.pkl
2024-06-02 20:06:39 [INFO]: Round4 - MICN on ETT_h1: MAE=0.6353, MSE=0.7338, MRE=0.7516
2024-06-02 20:06:39 [INFO]: Done! Final results:
Averaged MICN (3,153,163 params) on ETT_h1: MAE=0.6058 ± 0.07307789989853809, MSE=0.6876 ± 0.15202640993860783, MRE=0.7166 ± 0.08645091791587187, average inference time=0.15
