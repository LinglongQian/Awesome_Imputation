2024-06-02 19:39:15 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:39:15 [INFO]: Using the given device: cuda:0
2024-06-02 19:39:17 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_0/20240602_T193917
2024-06-02 19:39:17 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_0/20240602_T193917/tensorboard
2024-06-02 19:39:18 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 7,534
2024-06-02 19:39:20 [INFO]: Epoch 001 - training loss: 1.4569, validation loss: 0.9706
2024-06-02 19:39:21 [INFO]: Epoch 002 - training loss: 1.2353, validation loss: 0.7850
2024-06-02 19:39:21 [INFO]: Epoch 003 - training loss: 1.0204, validation loss: 0.6545
2024-06-02 19:39:21 [INFO]: Epoch 004 - training loss: 0.8827, validation loss: 0.4719
2024-06-02 19:39:21 [INFO]: Epoch 005 - training loss: 0.7523, validation loss: 0.3348
2024-06-02 19:39:22 [INFO]: Epoch 006 - training loss: 0.6777, validation loss: 0.2904
2024-06-02 19:39:22 [INFO]: Epoch 007 - training loss: 0.6207, validation loss: 0.2418
2024-06-02 19:39:22 [INFO]: Epoch 008 - training loss: 0.5935, validation loss: 0.1966
2024-06-02 19:39:23 [INFO]: Epoch 009 - training loss: 0.5669, validation loss: 0.1830
2024-06-02 19:39:23 [INFO]: Epoch 010 - training loss: 0.5472, validation loss: 0.1821
2024-06-02 19:39:23 [INFO]: Epoch 011 - training loss: 0.5430, validation loss: 0.1770
2024-06-02 19:39:24 [INFO]: Epoch 012 - training loss: 0.5253, validation loss: 0.1713
2024-06-02 19:39:24 [INFO]: Epoch 013 - training loss: 0.5242, validation loss: 0.1712
2024-06-02 19:39:25 [INFO]: Epoch 014 - training loss: 0.5011, validation loss: 0.1733
2024-06-02 19:39:25 [INFO]: Epoch 015 - training loss: 0.5064, validation loss: 0.1562
2024-06-02 19:39:25 [INFO]: Epoch 016 - training loss: 0.5066, validation loss: 0.1592
2024-06-02 19:39:26 [INFO]: Epoch 017 - training loss: 0.4981, validation loss: 0.1542
2024-06-02 19:39:27 [INFO]: Epoch 018 - training loss: 0.4929, validation loss: 0.1555
2024-06-02 19:39:27 [INFO]: Epoch 019 - training loss: 0.4801, validation loss: 0.1530
2024-06-02 19:39:27 [INFO]: Epoch 020 - training loss: 0.4909, validation loss: 0.1516
2024-06-02 19:39:28 [INFO]: Epoch 021 - training loss: 0.4832, validation loss: 0.1538
2024-06-02 19:39:29 [INFO]: Epoch 022 - training loss: 0.4888, validation loss: 0.1518
2024-06-02 19:39:29 [INFO]: Epoch 023 - training loss: 0.4867, validation loss: 0.1498
2024-06-02 19:39:29 [INFO]: Epoch 024 - training loss: 0.4856, validation loss: 0.1510
2024-06-02 19:39:30 [INFO]: Epoch 025 - training loss: 0.4771, validation loss: 0.1531
2024-06-02 19:39:30 [INFO]: Epoch 026 - training loss: 0.4840, validation loss: 0.1528
2024-06-02 19:39:31 [INFO]: Epoch 027 - training loss: 0.4792, validation loss: 0.1526
2024-06-02 19:39:31 [INFO]: Epoch 028 - training loss: 0.4809, validation loss: 0.1562
2024-06-02 19:39:31 [INFO]: Epoch 029 - training loss: 0.4837, validation loss: 0.1517
2024-06-02 19:39:32 [INFO]: Epoch 030 - training loss: 0.4883, validation loss: 0.1497
2024-06-02 19:39:32 [INFO]: Epoch 031 - training loss: 0.4710, validation loss: 0.1507
2024-06-02 19:39:33 [INFO]: Epoch 032 - training loss: 0.4806, validation loss: 0.1528
2024-06-02 19:39:33 [INFO]: Epoch 033 - training loss: 0.4733, validation loss: 0.1499
2024-06-02 19:39:34 [INFO]: Epoch 034 - training loss: 0.4830, validation loss: 0.1528
2024-06-02 19:39:34 [INFO]: Epoch 035 - training loss: 0.4742, validation loss: 0.1484
2024-06-02 19:39:34 [INFO]: Epoch 036 - training loss: 0.4839, validation loss: 0.1523
2024-06-02 19:39:35 [INFO]: Epoch 037 - training loss: 0.4816, validation loss: 0.1513
2024-06-02 19:39:35 [INFO]: Epoch 038 - training loss: 0.4793, validation loss: 0.1517
2024-06-02 19:39:36 [INFO]: Epoch 039 - training loss: 0.4772, validation loss: 0.1520
2024-06-02 19:39:36 [INFO]: Epoch 040 - training loss: 0.4754, validation loss: 0.1542
2024-06-02 19:39:37 [INFO]: Epoch 041 - training loss: 0.4820, validation loss: 0.1485
2024-06-02 19:39:37 [INFO]: Epoch 042 - training loss: 0.4777, validation loss: 0.1519
2024-06-02 19:39:38 [INFO]: Epoch 043 - training loss: 0.4732, validation loss: 0.1481
2024-06-02 19:39:38 [INFO]: Epoch 044 - training loss: 0.4764, validation loss: 0.1535
2024-06-02 19:39:38 [INFO]: Epoch 045 - training loss: 0.4824, validation loss: 0.1532
2024-06-02 19:39:39 [INFO]: Epoch 046 - training loss: 0.4838, validation loss: 0.1495
2024-06-02 19:39:39 [INFO]: Epoch 047 - training loss: 0.4728, validation loss: 0.1465
2024-06-02 19:39:40 [INFO]: Epoch 048 - training loss: 0.4853, validation loss: 0.1491
2024-06-02 19:39:40 [INFO]: Epoch 049 - training loss: 0.4817, validation loss: 0.1484
2024-06-02 19:39:41 [INFO]: Epoch 050 - training loss: 0.4814, validation loss: 0.1527
2024-06-02 19:39:41 [INFO]: Epoch 051 - training loss: 0.4794, validation loss: 0.1530
2024-06-02 19:39:41 [INFO]: Epoch 052 - training loss: 0.4682, validation loss: 0.1460
2024-06-02 19:39:42 [INFO]: Epoch 053 - training loss: 0.4725, validation loss: 0.1484
2024-06-02 19:39:42 [INFO]: Epoch 054 - training loss: 0.4774, validation loss: 0.1481
2024-06-02 19:39:43 [INFO]: Epoch 055 - training loss: 0.4775, validation loss: 0.1479
2024-06-02 19:39:43 [INFO]: Epoch 056 - training loss: 0.4774, validation loss: 0.1471
2024-06-02 19:39:43 [INFO]: Epoch 057 - training loss: 0.4726, validation loss: 0.1482
2024-06-02 19:39:44 [INFO]: Epoch 058 - training loss: 0.4771, validation loss: 0.1482
2024-06-02 19:39:44 [INFO]: Epoch 059 - training loss: 0.4742, validation loss: 0.1472
2024-06-02 19:39:44 [INFO]: Epoch 060 - training loss: 0.4762, validation loss: 0.1466
2024-06-02 19:39:45 [INFO]: Epoch 061 - training loss: 0.4743, validation loss: 0.1507
2024-06-02 19:39:46 [INFO]: Epoch 062 - training loss: 0.4799, validation loss: 0.1504
2024-06-02 19:39:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:39:46 [INFO]: Finished training. The best model is from epoch#52.
2024-06-02 19:39:46 [INFO]: Saved the model to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_0/20240602_T193917/DLinear.pypots
2024-06-02 19:39:46 [INFO]: Successfully saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_0/imputation.pkl
2024-06-02 19:39:46 [INFO]: Round0 - DLinear on ETT_h1: MAE=0.3078, MSE=0.1847, MRE=0.3641
2024-06-02 19:39:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 19:39:46 [INFO]: Using the given device: cuda:0
2024-06-02 19:39:46 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_1/20240602_T193946
2024-06-02 19:39:46 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_1/20240602_T193946/tensorboard
2024-06-02 19:39:46 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 7,534
2024-06-02 19:39:46 [INFO]: Epoch 001 - training loss: 1.4172, validation loss: 0.8344
2024-06-02 19:39:47 [INFO]: Epoch 002 - training loss: 1.1548, validation loss: 0.6516
2024-06-02 19:39:47 [INFO]: Epoch 003 - training loss: 0.9494, validation loss: 0.5333
2024-06-02 19:39:48 [INFO]: Epoch 004 - training loss: 0.8123, validation loss: 0.4251
2024-06-02 19:39:48 [INFO]: Epoch 005 - training loss: 0.7483, validation loss: 0.3726
2024-06-02 19:39:49 [INFO]: Epoch 006 - training loss: 0.7053, validation loss: 0.3539
2024-06-02 19:39:49 [INFO]: Epoch 007 - training loss: 0.6608, validation loss: 0.2811
2024-06-02 19:39:49 [INFO]: Epoch 008 - training loss: 0.6189, validation loss: 0.2457
2024-06-02 19:39:50 [INFO]: Epoch 009 - training loss: 0.5804, validation loss: 0.1999
2024-06-02 19:39:50 [INFO]: Epoch 010 - training loss: 0.5662, validation loss: 0.1973
2024-06-02 19:39:51 [INFO]: Epoch 011 - training loss: 0.5426, validation loss: 0.1879
2024-06-02 19:39:51 [INFO]: Epoch 012 - training loss: 0.5380, validation loss: 0.1721
2024-06-02 19:39:51 [INFO]: Epoch 013 - training loss: 0.5208, validation loss: 0.1713
2024-06-02 19:39:52 [INFO]: Epoch 014 - training loss: 0.5230, validation loss: 0.1643
2024-06-02 19:39:52 [INFO]: Epoch 015 - training loss: 0.5151, validation loss: 0.1610
2024-06-02 19:39:53 [INFO]: Epoch 016 - training loss: 0.5060, validation loss: 0.1555
2024-06-02 19:39:53 [INFO]: Epoch 017 - training loss: 0.4992, validation loss: 0.1525
2024-06-02 19:39:53 [INFO]: Epoch 018 - training loss: 0.4870, validation loss: 0.1555
2024-06-02 19:39:54 [INFO]: Epoch 019 - training loss: 0.4897, validation loss: 0.1490
2024-06-02 19:39:54 [INFO]: Epoch 020 - training loss: 0.4791, validation loss: 0.1510
2024-06-02 19:39:55 [INFO]: Epoch 021 - training loss: 0.4839, validation loss: 0.1505
2024-06-02 19:39:55 [INFO]: Epoch 022 - training loss: 0.4859, validation loss: 0.1485
2024-06-02 19:39:55 [INFO]: Epoch 023 - training loss: 0.4828, validation loss: 0.1476
2024-06-02 19:39:56 [INFO]: Epoch 024 - training loss: 0.4785, validation loss: 0.1507
2024-06-02 19:39:56 [INFO]: Epoch 025 - training loss: 0.4871, validation loss: 0.1527
2024-06-02 19:39:57 [INFO]: Epoch 026 - training loss: 0.4781, validation loss: 0.1501
2024-06-02 19:39:57 [INFO]: Epoch 027 - training loss: 0.4818, validation loss: 0.1502
2024-06-02 19:39:58 [INFO]: Epoch 028 - training loss: 0.4765, validation loss: 0.1485
2024-06-02 19:39:58 [INFO]: Epoch 029 - training loss: 0.4872, validation loss: 0.1524
2024-06-02 19:39:59 [INFO]: Epoch 030 - training loss: 0.4755, validation loss: 0.1493
2024-06-02 19:39:59 [INFO]: Epoch 031 - training loss: 0.4791, validation loss: 0.1563
2024-06-02 19:40:00 [INFO]: Epoch 032 - training loss: 0.4833, validation loss: 0.1472
2024-06-02 19:40:00 [INFO]: Epoch 033 - training loss: 0.4813, validation loss: 0.1522
2024-06-02 19:40:01 [INFO]: Epoch 034 - training loss: 0.4811, validation loss: 0.1511
2024-06-02 19:40:01 [INFO]: Epoch 035 - training loss: 0.4778, validation loss: 0.1477
2024-06-02 19:40:02 [INFO]: Epoch 036 - training loss: 0.4797, validation loss: 0.1537
2024-06-02 19:40:02 [INFO]: Epoch 037 - training loss: 0.4780, validation loss: 0.1561
2024-06-02 19:40:02 [INFO]: Epoch 038 - training loss: 0.4815, validation loss: 0.1521
2024-06-02 19:40:03 [INFO]: Epoch 039 - training loss: 0.4733, validation loss: 0.1486
2024-06-02 19:40:03 [INFO]: Epoch 040 - training loss: 0.4737, validation loss: 0.1525
2024-06-02 19:40:04 [INFO]: Epoch 041 - training loss: 0.4859, validation loss: 0.1479
2024-06-02 19:40:04 [INFO]: Epoch 042 - training loss: 0.4764, validation loss: 0.1540
2024-06-02 19:40:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:40:04 [INFO]: Finished training. The best model is from epoch#32.
2024-06-02 19:40:04 [INFO]: Saved the model to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_1/20240602_T193946/DLinear.pypots
2024-06-02 19:40:04 [INFO]: Successfully saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_1/imputation.pkl
2024-06-02 19:40:04 [INFO]: Round1 - DLinear on ETT_h1: MAE=0.3151, MSE=0.1887, MRE=0.3728
2024-06-02 19:40:04 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 19:40:04 [INFO]: Using the given device: cuda:0
2024-06-02 19:40:05 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_2/20240602_T194004
2024-06-02 19:40:05 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_2/20240602_T194004/tensorboard
2024-06-02 19:40:05 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 7,534
2024-06-02 19:40:05 [INFO]: Epoch 001 - training loss: 1.4375, validation loss: 0.8944
2024-06-02 19:40:05 [INFO]: Epoch 002 - training loss: 1.1960, validation loss: 0.6663
2024-06-02 19:40:06 [INFO]: Epoch 003 - training loss: 0.9439, validation loss: 0.5976
2024-06-02 19:40:06 [INFO]: Epoch 004 - training loss: 0.8187, validation loss: 0.4326
2024-06-02 19:40:07 [INFO]: Epoch 005 - training loss: 0.7384, validation loss: 0.3576
2024-06-02 19:40:07 [INFO]: Epoch 006 - training loss: 0.6647, validation loss: 0.2863
2024-06-02 19:40:08 [INFO]: Epoch 007 - training loss: 0.6220, validation loss: 0.2334
2024-06-02 19:40:08 [INFO]: Epoch 008 - training loss: 0.6007, validation loss: 0.2165
2024-06-02 19:40:09 [INFO]: Epoch 009 - training loss: 0.5775, validation loss: 0.2127
2024-06-02 19:40:09 [INFO]: Epoch 010 - training loss: 0.5675, validation loss: 0.2011
2024-06-02 19:40:09 [INFO]: Epoch 011 - training loss: 0.5548, validation loss: 0.1920
2024-06-02 19:40:10 [INFO]: Epoch 012 - training loss: 0.5494, validation loss: 0.1934
2024-06-02 19:40:10 [INFO]: Epoch 013 - training loss: 0.5399, validation loss: 0.1942
2024-06-02 19:40:10 [INFO]: Epoch 014 - training loss: 0.5331, validation loss: 0.1873
2024-06-02 19:40:11 [INFO]: Epoch 015 - training loss: 0.5271, validation loss: 0.1862
2024-06-02 19:40:11 [INFO]: Epoch 016 - training loss: 0.5265, validation loss: 0.1789
2024-06-02 19:40:12 [INFO]: Epoch 017 - training loss: 0.5206, validation loss: 0.1889
2024-06-02 19:40:12 [INFO]: Epoch 018 - training loss: 0.5256, validation loss: 0.1812
2024-06-02 19:40:13 [INFO]: Epoch 019 - training loss: 0.5119, validation loss: 0.1778
2024-06-02 19:40:13 [INFO]: Epoch 020 - training loss: 0.5096, validation loss: 0.1772
2024-06-02 19:40:13 [INFO]: Epoch 021 - training loss: 0.5154, validation loss: 0.1766
2024-06-02 19:40:14 [INFO]: Epoch 022 - training loss: 0.5119, validation loss: 0.1685
2024-06-02 19:40:14 [INFO]: Epoch 023 - training loss: 0.5072, validation loss: 0.1750
2024-06-02 19:40:15 [INFO]: Epoch 024 - training loss: 0.5141, validation loss: 0.1676
2024-06-02 19:40:15 [INFO]: Epoch 025 - training loss: 0.5028, validation loss: 0.1691
2024-06-02 19:40:15 [INFO]: Epoch 026 - training loss: 0.5039, validation loss: 0.1646
2024-06-02 19:40:16 [INFO]: Epoch 027 - training loss: 0.5030, validation loss: 0.1644
2024-06-02 19:40:16 [INFO]: Epoch 028 - training loss: 0.4950, validation loss: 0.1638
2024-06-02 19:40:17 [INFO]: Epoch 029 - training loss: 0.4967, validation loss: 0.1602
2024-06-02 19:40:17 [INFO]: Epoch 030 - training loss: 0.5032, validation loss: 0.1607
2024-06-02 19:40:18 [INFO]: Epoch 031 - training loss: 0.4940, validation loss: 0.1596
2024-06-02 19:40:18 [INFO]: Epoch 032 - training loss: 0.4894, validation loss: 0.1614
2024-06-02 19:40:18 [INFO]: Epoch 033 - training loss: 0.4881, validation loss: 0.1557
2024-06-02 19:40:19 [INFO]: Epoch 034 - training loss: 0.4916, validation loss: 0.1582
2024-06-02 19:40:19 [INFO]: Epoch 035 - training loss: 0.4867, validation loss: 0.1547
2024-06-02 19:40:20 [INFO]: Epoch 036 - training loss: 0.4866, validation loss: 0.1539
2024-06-02 19:40:20 [INFO]: Epoch 037 - training loss: 0.4877, validation loss: 0.1490
2024-06-02 19:40:20 [INFO]: Epoch 038 - training loss: 0.4861, validation loss: 0.1509
2024-06-02 19:40:21 [INFO]: Epoch 039 - training loss: 0.4939, validation loss: 0.1518
2024-06-02 19:40:21 [INFO]: Epoch 040 - training loss: 0.4879, validation loss: 0.1493
2024-06-02 19:40:21 [INFO]: Epoch 041 - training loss: 0.4790, validation loss: 0.1515
2024-06-02 19:40:22 [INFO]: Epoch 042 - training loss: 0.4853, validation loss: 0.1507
2024-06-02 19:40:22 [INFO]: Epoch 043 - training loss: 0.4742, validation loss: 0.1482
2024-06-02 19:40:22 [INFO]: Epoch 044 - training loss: 0.4754, validation loss: 0.1493
2024-06-02 19:40:23 [INFO]: Epoch 045 - training loss: 0.4739, validation loss: 0.1508
2024-06-02 19:40:23 [INFO]: Epoch 046 - training loss: 0.4764, validation loss: 0.1493
2024-06-02 19:40:23 [INFO]: Epoch 047 - training loss: 0.4822, validation loss: 0.1524
2024-06-02 19:40:24 [INFO]: Epoch 048 - training loss: 0.4807, validation loss: 0.1497
2024-06-02 19:40:24 [INFO]: Epoch 049 - training loss: 0.4848, validation loss: 0.1478
2024-06-02 19:40:24 [INFO]: Epoch 050 - training loss: 0.4704, validation loss: 0.1540
2024-06-02 19:40:25 [INFO]: Epoch 051 - training loss: 0.4758, validation loss: 0.1497
2024-06-02 19:40:25 [INFO]: Epoch 052 - training loss: 0.4762, validation loss: 0.1494
2024-06-02 19:40:25 [INFO]: Epoch 053 - training loss: 0.4674, validation loss: 0.1462
2024-06-02 19:40:26 [INFO]: Epoch 054 - training loss: 0.4777, validation loss: 0.1500
2024-06-02 19:40:26 [INFO]: Epoch 055 - training loss: 0.4767, validation loss: 0.1504
2024-06-02 19:40:26 [INFO]: Epoch 056 - training loss: 0.4769, validation loss: 0.1538
2024-06-02 19:40:27 [INFO]: Epoch 057 - training loss: 0.4779, validation loss: 0.1500
2024-06-02 19:40:27 [INFO]: Epoch 058 - training loss: 0.4670, validation loss: 0.1498
2024-06-02 19:40:28 [INFO]: Epoch 059 - training loss: 0.4775, validation loss: 0.1507
2024-06-02 19:40:28 [INFO]: Epoch 060 - training loss: 0.4739, validation loss: 0.1520
2024-06-02 19:40:28 [INFO]: Epoch 061 - training loss: 0.4714, validation loss: 0.1480
2024-06-02 19:40:29 [INFO]: Epoch 062 - training loss: 0.4720, validation loss: 0.1532
2024-06-02 19:40:29 [INFO]: Epoch 063 - training loss: 0.4741, validation loss: 0.1518
2024-06-02 19:40:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:40:29 [INFO]: Finished training. The best model is from epoch#53.
2024-06-02 19:40:29 [INFO]: Saved the model to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_2/20240602_T194004/DLinear.pypots
2024-06-02 19:40:29 [INFO]: Successfully saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_2/imputation.pkl
2024-06-02 19:40:29 [INFO]: Round2 - DLinear on ETT_h1: MAE=0.3108, MSE=0.1852, MRE=0.3677
2024-06-02 19:40:29 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 19:40:29 [INFO]: Using the given device: cuda:0
2024-06-02 19:40:29 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_3/20240602_T194029
2024-06-02 19:40:29 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_3/20240602_T194029/tensorboard
2024-06-02 19:40:30 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 7,534
2024-06-02 19:40:30 [INFO]: Epoch 001 - training loss: 1.4250, validation loss: 0.8913
2024-06-02 19:40:30 [INFO]: Epoch 002 - training loss: 1.1619, validation loss: 0.6870
2024-06-02 19:40:31 [INFO]: Epoch 003 - training loss: 0.9424, validation loss: 0.4817
2024-06-02 19:40:31 [INFO]: Epoch 004 - training loss: 0.8176, validation loss: 0.4005
2024-06-02 19:40:31 [INFO]: Epoch 005 - training loss: 0.7526, validation loss: 0.3513
2024-06-02 19:40:32 [INFO]: Epoch 006 - training loss: 0.6879, validation loss: 0.3190
2024-06-02 19:40:32 [INFO]: Epoch 007 - training loss: 0.6569, validation loss: 0.2822
2024-06-02 19:40:32 [INFO]: Epoch 008 - training loss: 0.6195, validation loss: 0.2421
2024-06-02 19:40:33 [INFO]: Epoch 009 - training loss: 0.5915, validation loss: 0.2211
2024-06-02 19:40:33 [INFO]: Epoch 010 - training loss: 0.5580, validation loss: 0.1960
2024-06-02 19:40:34 [INFO]: Epoch 011 - training loss: 0.5398, validation loss: 0.1815
2024-06-02 19:40:34 [INFO]: Epoch 012 - training loss: 0.5120, validation loss: 0.1739
2024-06-02 19:40:35 [INFO]: Epoch 013 - training loss: 0.5164, validation loss: 0.1625
2024-06-02 19:40:35 [INFO]: Epoch 014 - training loss: 0.5030, validation loss: 0.1616
2024-06-02 19:40:35 [INFO]: Epoch 015 - training loss: 0.4899, validation loss: 0.1579
2024-06-02 19:40:36 [INFO]: Epoch 016 - training loss: 0.4934, validation loss: 0.1590
2024-06-02 19:40:36 [INFO]: Epoch 017 - training loss: 0.4853, validation loss: 0.1572
2024-06-02 19:40:37 [INFO]: Epoch 018 - training loss: 0.4902, validation loss: 0.1574
2024-06-02 19:40:37 [INFO]: Epoch 019 - training loss: 0.4878, validation loss: 0.1563
2024-06-02 19:40:37 [INFO]: Epoch 020 - training loss: 0.4912, validation loss: 0.1529
2024-06-02 19:40:38 [INFO]: Epoch 021 - training loss: 0.4821, validation loss: 0.1537
2024-06-02 19:40:38 [INFO]: Epoch 022 - training loss: 0.4855, validation loss: 0.1552
2024-06-02 19:40:38 [INFO]: Epoch 023 - training loss: 0.4891, validation loss: 0.1547
2024-06-02 19:40:39 [INFO]: Epoch 024 - training loss: 0.4827, validation loss: 0.1549
2024-06-02 19:40:39 [INFO]: Epoch 025 - training loss: 0.4820, validation loss: 0.1519
2024-06-02 19:40:40 [INFO]: Epoch 026 - training loss: 0.4800, validation loss: 0.1550
2024-06-02 19:40:40 [INFO]: Epoch 027 - training loss: 0.4987, validation loss: 0.1615
2024-06-02 19:40:41 [INFO]: Epoch 028 - training loss: 0.4869, validation loss: 0.1595
2024-06-02 19:40:41 [INFO]: Epoch 029 - training loss: 0.4876, validation loss: 0.1572
2024-06-02 19:40:41 [INFO]: Epoch 030 - training loss: 0.4896, validation loss: 0.1553
2024-06-02 19:40:41 [INFO]: Epoch 031 - training loss: 0.4792, validation loss: 0.1516
2024-06-02 19:40:42 [INFO]: Epoch 032 - training loss: 0.4774, validation loss: 0.1527
2024-06-02 19:40:42 [INFO]: Epoch 033 - training loss: 0.4811, validation loss: 0.1521
2024-06-02 19:40:43 [INFO]: Epoch 034 - training loss: 0.4781, validation loss: 0.1497
2024-06-02 19:40:43 [INFO]: Epoch 035 - training loss: 0.4789, validation loss: 0.1534
2024-06-02 19:40:44 [INFO]: Epoch 036 - training loss: 0.4828, validation loss: 0.1523
2024-06-02 19:40:44 [INFO]: Epoch 037 - training loss: 0.4733, validation loss: 0.1490
2024-06-02 19:40:44 [INFO]: Epoch 038 - training loss: 0.4902, validation loss: 0.1500
2024-06-02 19:40:45 [INFO]: Epoch 039 - training loss: 0.4778, validation loss: 0.1502
2024-06-02 19:40:45 [INFO]: Epoch 040 - training loss: 0.4720, validation loss: 0.1438
2024-06-02 19:40:46 [INFO]: Epoch 041 - training loss: 0.4827, validation loss: 0.1482
2024-06-02 19:40:46 [INFO]: Epoch 042 - training loss: 0.4707, validation loss: 0.1508
2024-06-02 19:40:46 [INFO]: Epoch 043 - training loss: 0.4798, validation loss: 0.1494
2024-06-02 19:40:47 [INFO]: Epoch 044 - training loss: 0.4779, validation loss: 0.1517
2024-06-02 19:40:47 [INFO]: Epoch 045 - training loss: 0.4790, validation loss: 0.1516
2024-06-02 19:40:47 [INFO]: Epoch 046 - training loss: 0.4909, validation loss: 0.1484
2024-06-02 19:40:48 [INFO]: Epoch 047 - training loss: 0.4806, validation loss: 0.1494
2024-06-02 19:40:48 [INFO]: Epoch 048 - training loss: 0.4769, validation loss: 0.1487
2024-06-02 19:40:49 [INFO]: Epoch 049 - training loss: 0.4795, validation loss: 0.1520
2024-06-02 19:40:49 [INFO]: Epoch 050 - training loss: 0.4797, validation loss: 0.1481
2024-06-02 19:40:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:40:49 [INFO]: Finished training. The best model is from epoch#40.
2024-06-02 19:40:49 [INFO]: Saved the model to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_3/20240602_T194029/DLinear.pypots
2024-06-02 19:40:49 [INFO]: Successfully saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_3/imputation.pkl
2024-06-02 19:40:49 [INFO]: Round3 - DLinear on ETT_h1: MAE=0.3074, MSE=0.1824, MRE=0.3636
2024-06-02 19:40:49 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 19:40:49 [INFO]: Using the given device: cuda:0
2024-06-02 19:40:49 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_4/20240602_T194049
2024-06-02 19:40:49 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_4/20240602_T194049/tensorboard
2024-06-02 19:40:49 [INFO]: DLinear initialized with the given hyperparameters, the number of trainable parameters: 7,534
2024-06-02 19:40:49 [INFO]: Epoch 001 - training loss: 1.4267, validation loss: 1.0092
2024-06-02 19:40:50 [INFO]: Epoch 002 - training loss: 1.1419, validation loss: 0.7384
2024-06-02 19:40:50 [INFO]: Epoch 003 - training loss: 0.9362, validation loss: 0.6718
2024-06-02 19:40:51 [INFO]: Epoch 004 - training loss: 0.8335, validation loss: 0.4740
2024-06-02 19:40:51 [INFO]: Epoch 005 - training loss: 0.7366, validation loss: 0.3748
2024-06-02 19:40:51 [INFO]: Epoch 006 - training loss: 0.6537, validation loss: 0.2696
2024-06-02 19:40:52 [INFO]: Epoch 007 - training loss: 0.6024, validation loss: 0.2246
2024-06-02 19:40:52 [INFO]: Epoch 008 - training loss: 0.5659, validation loss: 0.2010
2024-06-02 19:40:53 [INFO]: Epoch 009 - training loss: 0.5582, validation loss: 0.1892
2024-06-02 19:40:53 [INFO]: Epoch 010 - training loss: 0.5374, validation loss: 0.1800
2024-06-02 19:40:53 [INFO]: Epoch 011 - training loss: 0.5346, validation loss: 0.1811
2024-06-02 19:40:53 [INFO]: Epoch 012 - training loss: 0.5294, validation loss: 0.1723
2024-06-02 19:40:54 [INFO]: Epoch 013 - training loss: 0.5117, validation loss: 0.1716
2024-06-02 19:40:54 [INFO]: Epoch 014 - training loss: 0.5074, validation loss: 0.1613
2024-06-02 19:40:55 [INFO]: Epoch 015 - training loss: 0.5038, validation loss: 0.1693
2024-06-02 19:40:55 [INFO]: Epoch 016 - training loss: 0.5020, validation loss: 0.1567
2024-06-02 19:40:56 [INFO]: Epoch 017 - training loss: 0.4907, validation loss: 0.1584
2024-06-02 19:40:56 [INFO]: Epoch 018 - training loss: 0.4823, validation loss: 0.1525
2024-06-02 19:40:56 [INFO]: Epoch 019 - training loss: 0.4868, validation loss: 0.1570
2024-06-02 19:40:57 [INFO]: Epoch 020 - training loss: 0.4844, validation loss: 0.1571
2024-06-02 19:40:57 [INFO]: Epoch 021 - training loss: 0.4810, validation loss: 0.1548
2024-06-02 19:40:57 [INFO]: Epoch 022 - training loss: 0.4824, validation loss: 0.1557
2024-06-02 19:40:58 [INFO]: Epoch 023 - training loss: 0.4832, validation loss: 0.1489
2024-06-02 19:40:58 [INFO]: Epoch 024 - training loss: 0.4831, validation loss: 0.1520
2024-06-02 19:40:59 [INFO]: Epoch 025 - training loss: 0.4840, validation loss: 0.1540
2024-06-02 19:40:59 [INFO]: Epoch 026 - training loss: 0.4832, validation loss: 0.1500
2024-06-02 19:40:59 [INFO]: Epoch 027 - training loss: 0.4771, validation loss: 0.1524
2024-06-02 19:41:00 [INFO]: Epoch 028 - training loss: 0.4812, validation loss: 0.1493
2024-06-02 19:41:00 [INFO]: Epoch 029 - training loss: 0.4791, validation loss: 0.1524
2024-06-02 19:41:00 [INFO]: Epoch 030 - training loss: 0.4778, validation loss: 0.1496
2024-06-02 19:41:01 [INFO]: Epoch 031 - training loss: 0.4845, validation loss: 0.1531
2024-06-02 19:41:01 [INFO]: Epoch 032 - training loss: 0.4791, validation loss: 0.1517
2024-06-02 19:41:02 [INFO]: Epoch 033 - training loss: 0.4858, validation loss: 0.1546
2024-06-02 19:41:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 19:41:02 [INFO]: Finished training. The best model is from epoch#23.
2024-06-02 19:41:02 [INFO]: Saved the model to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_4/20240602_T194049/DLinear.pypots
2024-06-02 19:41:02 [INFO]: Successfully saved to results_point_rate05/ETT_h1/DLinear_ETT_h1/round_4/imputation.pkl
2024-06-02 19:41:02 [INFO]: Round4 - DLinear on ETT_h1: MAE=0.3148, MSE=0.1916, MRE=0.3725
2024-06-02 19:41:02 [INFO]: Done! Final results:
Averaged DLinear (7,534 params) on ETT_h1: MAE=0.3112 ± 0.003319953328549756, MSE=0.1865 ± 0.0032662379810942392, MRE=0.3682 ± 0.003927493990515212, average inference time=0.03
