2024-06-02 20:03:16 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:03:16 [INFO]: Using the given device: cuda:0
2024-06-02 20:03:17 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_0/20240602_T200317
2024-06-02 20:03:17 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_0/20240602_T200317/tensorboard
2024-06-02 20:03:19 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-02 20:03:26 [INFO]: Epoch 001 - training loss: 2.0541, validation loss: 0.4886
2024-06-02 20:03:28 [INFO]: Epoch 002 - training loss: 1.0946, validation loss: 0.5024
2024-06-02 20:03:30 [INFO]: Epoch 003 - training loss: 0.8571, validation loss: 0.3340
2024-06-02 20:03:33 [INFO]: Epoch 004 - training loss: 0.7439, validation loss: 0.3373
2024-06-02 20:03:35 [INFO]: Epoch 005 - training loss: 0.7048, validation loss: 0.2721
2024-06-02 20:03:37 [INFO]: Epoch 006 - training loss: 0.6723, validation loss: 0.2439
2024-06-02 20:03:39 [INFO]: Epoch 007 - training loss: 0.7141, validation loss: 0.2828
2024-06-02 20:03:42 [INFO]: Epoch 008 - training loss: 0.6817, validation loss: 0.2887
2024-06-02 20:03:44 [INFO]: Epoch 009 - training loss: 0.6553, validation loss: 0.3074
2024-06-02 20:03:46 [INFO]: Epoch 010 - training loss: 0.6174, validation loss: 0.2326
2024-06-02 20:03:48 [INFO]: Epoch 011 - training loss: 0.6195, validation loss: 0.2319
2024-06-02 20:03:50 [INFO]: Epoch 012 - training loss: 0.6035, validation loss: 0.2173
2024-06-02 20:03:53 [INFO]: Epoch 013 - training loss: 0.6145, validation loss: 0.2677
2024-06-02 20:03:55 [INFO]: Epoch 014 - training loss: 0.5832, validation loss: 0.2060
2024-06-02 20:03:57 [INFO]: Epoch 015 - training loss: 0.5662, validation loss: 0.2444
2024-06-02 20:03:59 [INFO]: Epoch 016 - training loss: 0.5913, validation loss: 0.2496
2024-06-02 20:04:01 [INFO]: Epoch 017 - training loss: 0.6046, validation loss: 0.2017
2024-06-02 20:04:03 [INFO]: Epoch 018 - training loss: 0.5694, validation loss: 0.2045
2024-06-02 20:04:06 [INFO]: Epoch 019 - training loss: 0.5369, validation loss: 0.2174
2024-06-02 20:04:08 [INFO]: Epoch 020 - training loss: 0.5576, validation loss: 0.1924
2024-06-02 20:04:10 [INFO]: Epoch 021 - training loss: 0.5136, validation loss: 0.1697
2024-06-02 20:04:12 [INFO]: Epoch 022 - training loss: 0.4959, validation loss: 0.1901
2024-06-02 20:04:15 [INFO]: Epoch 023 - training loss: 0.5072, validation loss: 0.1933
2024-06-02 20:04:17 [INFO]: Epoch 024 - training loss: 0.4809, validation loss: 0.1615
2024-06-02 20:04:19 [INFO]: Epoch 025 - training loss: 0.4488, validation loss: 0.1559
2024-06-02 20:04:21 [INFO]: Epoch 026 - training loss: 0.4592, validation loss: 0.1563
2024-06-02 20:04:23 [INFO]: Epoch 027 - training loss: 0.4487, validation loss: 0.1639
2024-06-02 20:04:25 [INFO]: Epoch 028 - training loss: 0.4529, validation loss: 0.1566
2024-06-02 20:04:27 [INFO]: Epoch 029 - training loss: 0.4383, validation loss: 0.1402
2024-06-02 20:04:29 [INFO]: Epoch 030 - training loss: 0.4212, validation loss: 0.1603
2024-06-02 20:04:32 [INFO]: Epoch 031 - training loss: 0.4246, validation loss: 0.1533
2024-06-02 20:04:34 [INFO]: Epoch 032 - training loss: 0.4126, validation loss: 0.1636
2024-06-02 20:04:36 [INFO]: Epoch 033 - training loss: 0.4121, validation loss: 0.1647
2024-06-02 20:04:38 [INFO]: Epoch 034 - training loss: 0.4138, validation loss: 0.1535
2024-06-02 20:04:40 [INFO]: Epoch 035 - training loss: 0.4440, validation loss: 0.1515
2024-06-02 20:04:43 [INFO]: Epoch 036 - training loss: 0.3931, validation loss: 0.1393
2024-06-02 20:04:45 [INFO]: Epoch 037 - training loss: 0.4015, validation loss: 0.1324
2024-06-02 20:04:47 [INFO]: Epoch 038 - training loss: 0.4154, validation loss: 0.1341
2024-06-02 20:04:49 [INFO]: Epoch 039 - training loss: 0.4073, validation loss: 0.1422
2024-06-02 20:04:51 [INFO]: Epoch 040 - training loss: 0.3934, validation loss: 0.1519
2024-06-02 20:04:53 [INFO]: Epoch 041 - training loss: 0.4034, validation loss: 0.1315
2024-06-02 20:04:55 [INFO]: Epoch 042 - training loss: 0.3827, validation loss: 0.1274
2024-06-02 20:04:58 [INFO]: Epoch 043 - training loss: 0.3980, validation loss: 0.1197
2024-06-02 20:05:00 [INFO]: Epoch 044 - training loss: 0.3862, validation loss: 0.1241
2024-06-02 20:05:02 [INFO]: Epoch 045 - training loss: 0.3634, validation loss: 0.1146
2024-06-02 20:05:04 [INFO]: Epoch 046 - training loss: 0.3740, validation loss: 0.1201
2024-06-02 20:05:06 [INFO]: Epoch 047 - training loss: 0.3709, validation loss: 0.1347
2024-06-02 20:05:09 [INFO]: Epoch 048 - training loss: 0.3561, validation loss: 0.1199
2024-06-02 20:05:11 [INFO]: Epoch 049 - training loss: 0.3545, validation loss: 0.1186
2024-06-02 20:05:13 [INFO]: Epoch 050 - training loss: 0.3401, validation loss: 0.1216
2024-06-02 20:05:15 [INFO]: Epoch 051 - training loss: 0.3464, validation loss: 0.1120
2024-06-02 20:05:18 [INFO]: Epoch 052 - training loss: 0.3476, validation loss: 0.1255
2024-06-02 20:05:20 [INFO]: Epoch 053 - training loss: 0.3360, validation loss: 0.1122
2024-06-02 20:05:22 [INFO]: Epoch 054 - training loss: 0.3369, validation loss: 0.1172
2024-06-02 20:05:24 [INFO]: Epoch 055 - training loss: 0.3491, validation loss: 0.1206
2024-06-02 20:05:26 [INFO]: Epoch 056 - training loss: 0.3526, validation loss: 0.1087
2024-06-02 20:05:28 [INFO]: Epoch 057 - training loss: 0.3391, validation loss: 0.1298
2024-06-02 20:05:30 [INFO]: Epoch 058 - training loss: 0.3326, validation loss: 0.1376
2024-06-02 20:05:32 [INFO]: Epoch 059 - training loss: 0.3412, validation loss: 0.1125
2024-06-02 20:05:34 [INFO]: Epoch 060 - training loss: 0.3389, validation loss: 0.1155
2024-06-02 20:05:36 [INFO]: Epoch 061 - training loss: 0.3451, validation loss: 0.1143
2024-06-02 20:05:39 [INFO]: Epoch 062 - training loss: 0.3423, validation loss: 0.1126
2024-06-02 20:05:41 [INFO]: Epoch 063 - training loss: 0.3437, validation loss: 0.1105
2024-06-02 20:05:43 [INFO]: Epoch 064 - training loss: 0.3304, validation loss: 0.1074
2024-06-02 20:05:45 [INFO]: Epoch 065 - training loss: 0.3213, validation loss: 0.1177
2024-06-02 20:05:47 [INFO]: Epoch 066 - training loss: 0.3238, validation loss: 0.1130
2024-06-02 20:05:49 [INFO]: Epoch 067 - training loss: 0.3202, validation loss: 0.1065
2024-06-02 20:05:51 [INFO]: Epoch 068 - training loss: 0.3113, validation loss: 0.1161
2024-06-02 20:05:54 [INFO]: Epoch 069 - training loss: 0.3126, validation loss: 0.1070
2024-06-02 20:05:56 [INFO]: Epoch 070 - training loss: 0.3273, validation loss: 0.1270
2024-06-02 20:05:58 [INFO]: Epoch 071 - training loss: 0.3168, validation loss: 0.1123
2024-06-02 20:06:00 [INFO]: Epoch 072 - training loss: 0.3269, validation loss: 0.1144
2024-06-02 20:06:02 [INFO]: Epoch 073 - training loss: 0.3351, validation loss: 0.1174
2024-06-02 20:06:04 [INFO]: Epoch 074 - training loss: 0.3391, validation loss: 0.1429
2024-06-02 20:06:06 [INFO]: Epoch 075 - training loss: 0.3522, validation loss: 0.1273
2024-06-02 20:06:08 [INFO]: Epoch 076 - training loss: 0.3514, validation loss: 0.1207
2024-06-02 20:06:11 [INFO]: Epoch 077 - training loss: 0.3169, validation loss: 0.1110
2024-06-02 20:06:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:06:11 [INFO]: Finished training. The best model is from epoch#67.
2024-06-02 20:06:11 [INFO]: Saved the model to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_0/20240602_T200317/Pyraformer.pypots
2024-06-02 20:06:13 [INFO]: Successfully saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_0/imputation.pkl
2024-06-02 20:06:13 [INFO]: Round0 - Pyraformer on ETT_h1: MAE=0.2775, MSE=0.1563, MRE=0.3283
2024-06-02 20:06:13 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:06:13 [INFO]: Using the given device: cuda:0
2024-06-02 20:06:13 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_1/20240602_T200613
2024-06-02 20:06:13 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_1/20240602_T200613/tensorboard
2024-06-02 20:06:13 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-02 20:06:16 [INFO]: Epoch 001 - training loss: 2.0398, validation loss: 0.8086
2024-06-02 20:06:18 [INFO]: Epoch 002 - training loss: 1.0799, validation loss: 0.4284
2024-06-02 20:06:20 [INFO]: Epoch 003 - training loss: 0.8875, validation loss: 0.3446
2024-06-02 20:06:22 [INFO]: Epoch 004 - training loss: 0.7840, validation loss: 0.3615
2024-06-02 20:06:24 [INFO]: Epoch 005 - training loss: 0.7099, validation loss: 0.2752
2024-06-02 20:06:27 [INFO]: Epoch 006 - training loss: 0.7531, validation loss: 0.2887
2024-06-02 20:06:29 [INFO]: Epoch 007 - training loss: 0.6729, validation loss: 0.2491
2024-06-02 20:06:31 [INFO]: Epoch 008 - training loss: 0.6465, validation loss: 0.2383
2024-06-02 20:06:33 [INFO]: Epoch 009 - training loss: 0.5850, validation loss: 0.2349
2024-06-02 20:06:35 [INFO]: Epoch 010 - training loss: 0.5951, validation loss: 0.2291
2024-06-02 20:06:37 [INFO]: Epoch 011 - training loss: 0.5924, validation loss: 0.2038
2024-06-02 20:06:40 [INFO]: Epoch 012 - training loss: 0.5741, validation loss: 0.2156
2024-06-02 20:06:42 [INFO]: Epoch 013 - training loss: 0.5926, validation loss: 0.2096
2024-06-02 20:06:44 [INFO]: Epoch 014 - training loss: 0.6067, validation loss: 0.2323
2024-06-02 20:06:46 [INFO]: Epoch 015 - training loss: 0.5888, validation loss: 0.2300
2024-06-02 20:06:48 [INFO]: Epoch 016 - training loss: 0.5750, validation loss: 0.2062
2024-06-02 20:06:50 [INFO]: Epoch 017 - training loss: 0.5551, validation loss: 0.2324
2024-06-02 20:06:52 [INFO]: Epoch 018 - training loss: 0.5431, validation loss: 0.2101
2024-06-02 20:06:54 [INFO]: Epoch 019 - training loss: 0.5418, validation loss: 0.2026
2024-06-02 20:06:56 [INFO]: Epoch 020 - training loss: 0.5476, validation loss: 0.1967
2024-06-02 20:06:58 [INFO]: Epoch 021 - training loss: 0.5090, validation loss: 0.1748
2024-06-02 20:07:00 [INFO]: Epoch 022 - training loss: 0.4856, validation loss: 0.1716
2024-06-02 20:07:02 [INFO]: Epoch 023 - training loss: 0.4837, validation loss: 0.1775
2024-06-02 20:07:03 [INFO]: Epoch 024 - training loss: 0.4875, validation loss: 0.1764
2024-06-02 20:07:05 [INFO]: Epoch 025 - training loss: 0.4924, validation loss: 0.1649
2024-06-02 20:07:07 [INFO]: Epoch 026 - training loss: 0.4863, validation loss: 0.1480
2024-06-02 20:07:09 [INFO]: Epoch 027 - training loss: 0.4527, validation loss: 0.1563
2024-06-02 20:07:11 [INFO]: Epoch 028 - training loss: 0.4446, validation loss: 0.1498
2024-06-02 20:07:13 [INFO]: Epoch 029 - training loss: 0.4505, validation loss: 0.1650
2024-06-02 20:07:14 [INFO]: Epoch 030 - training loss: 0.4382, validation loss: 0.1479
2024-06-02 20:07:16 [INFO]: Epoch 031 - training loss: 0.4187, validation loss: 0.1434
2024-06-02 20:07:18 [INFO]: Epoch 032 - training loss: 0.4432, validation loss: 0.1572
2024-06-02 20:07:20 [INFO]: Epoch 033 - training loss: 0.4448, validation loss: 0.1516
2024-06-02 20:07:22 [INFO]: Epoch 034 - training loss: 0.4218, validation loss: 0.1713
2024-06-02 20:07:24 [INFO]: Epoch 035 - training loss: 0.4315, validation loss: 0.1586
2024-06-02 20:07:26 [INFO]: Epoch 036 - training loss: 0.4220, validation loss: 0.1362
2024-06-02 20:07:28 [INFO]: Epoch 037 - training loss: 0.4199, validation loss: 0.1325
2024-06-02 20:07:30 [INFO]: Epoch 038 - training loss: 0.4036, validation loss: 0.1358
2024-06-02 20:07:32 [INFO]: Epoch 039 - training loss: 0.3912, validation loss: 0.1369
2024-06-02 20:07:34 [INFO]: Epoch 040 - training loss: 0.3838, validation loss: 0.1442
2024-06-02 20:07:36 [INFO]: Epoch 041 - training loss: 0.3827, validation loss: 0.1623
2024-06-02 20:07:38 [INFO]: Epoch 042 - training loss: 0.4189, validation loss: 0.1391
2024-06-02 20:07:40 [INFO]: Epoch 043 - training loss: 0.4059, validation loss: 0.1305
2024-06-02 20:07:42 [INFO]: Epoch 044 - training loss: 0.3912, validation loss: 0.1271
2024-06-02 20:07:44 [INFO]: Epoch 045 - training loss: 0.3936, validation loss: 0.1418
2024-06-02 20:07:46 [INFO]: Epoch 046 - training loss: 0.3727, validation loss: 0.1381
2024-06-02 20:07:49 [INFO]: Epoch 047 - training loss: 0.3772, validation loss: 0.1499
2024-06-02 20:07:50 [INFO]: Epoch 048 - training loss: 0.3762, validation loss: 0.1361
2024-06-02 20:07:52 [INFO]: Epoch 049 - training loss: 0.3692, validation loss: 0.1310
2024-06-02 20:07:54 [INFO]: Epoch 050 - training loss: 0.3886, validation loss: 0.1321
2024-06-02 20:07:56 [INFO]: Epoch 051 - training loss: 0.3945, validation loss: 0.1225
2024-06-02 20:07:58 [INFO]: Epoch 052 - training loss: 0.3745, validation loss: 0.1279
2024-06-02 20:07:59 [INFO]: Epoch 053 - training loss: 0.3584, validation loss: 0.1199
2024-06-02 20:08:01 [INFO]: Epoch 054 - training loss: 0.3497, validation loss: 0.1179
2024-06-02 20:08:02 [INFO]: Epoch 055 - training loss: 0.3505, validation loss: 0.1156
2024-06-02 20:08:04 [INFO]: Epoch 056 - training loss: 0.3549, validation loss: 0.1282
2024-06-02 20:08:05 [INFO]: Epoch 057 - training loss: 0.3616, validation loss: 0.1101
2024-06-02 20:08:07 [INFO]: Epoch 058 - training loss: 0.3361, validation loss: 0.1180
2024-06-02 20:08:08 [INFO]: Epoch 059 - training loss: 0.3514, validation loss: 0.1398
2024-06-02 20:08:10 [INFO]: Epoch 060 - training loss: 0.3550, validation loss: 0.1180
2024-06-02 20:08:11 [INFO]: Epoch 061 - training loss: 0.3464, validation loss: 0.1194
2024-06-02 20:08:12 [INFO]: Epoch 062 - training loss: 0.3459, validation loss: 0.1249
2024-06-02 20:08:14 [INFO]: Epoch 063 - training loss: 0.3579, validation loss: 0.1138
2024-06-02 20:08:15 [INFO]: Epoch 064 - training loss: 0.3609, validation loss: 0.1157
2024-06-02 20:08:16 [INFO]: Epoch 065 - training loss: 0.3567, validation loss: 0.1235
2024-06-02 20:08:18 [INFO]: Epoch 066 - training loss: 0.3410, validation loss: 0.1283
2024-06-02 20:08:19 [INFO]: Epoch 067 - training loss: 0.3323, validation loss: 0.1191
2024-06-02 20:08:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:08:19 [INFO]: Finished training. The best model is from epoch#57.
2024-06-02 20:08:20 [INFO]: Saved the model to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_1/20240602_T200613/Pyraformer.pypots
2024-06-02 20:08:20 [INFO]: Successfully saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_1/imputation.pkl
2024-06-02 20:08:20 [INFO]: Round1 - Pyraformer on ETT_h1: MAE=0.2943, MSE=0.1689, MRE=0.3482
2024-06-02 20:08:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:08:20 [INFO]: Using the given device: cuda:0
2024-06-02 20:08:20 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_2/20240602_T200820
2024-06-02 20:08:20 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_2/20240602_T200820/tensorboard
2024-06-02 20:08:21 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-02 20:08:22 [INFO]: Epoch 001 - training loss: 2.1554, validation loss: 0.8682
2024-06-02 20:08:23 [INFO]: Epoch 002 - training loss: 1.1188, validation loss: 0.3989
2024-06-02 20:08:25 [INFO]: Epoch 003 - training loss: 0.8478, validation loss: 0.3682
2024-06-02 20:08:26 [INFO]: Epoch 004 - training loss: 0.8402, validation loss: 0.3305
2024-06-02 20:08:28 [INFO]: Epoch 005 - training loss: 0.7280, validation loss: 0.2666
2024-06-02 20:08:29 [INFO]: Epoch 006 - training loss: 0.6713, validation loss: 0.2595
2024-06-02 20:08:30 [INFO]: Epoch 007 - training loss: 0.6347, validation loss: 0.2622
2024-06-02 20:08:31 [INFO]: Epoch 008 - training loss: 0.6079, validation loss: 0.2216
2024-06-02 20:08:33 [INFO]: Epoch 009 - training loss: 0.5785, validation loss: 0.2275
2024-06-02 20:08:34 [INFO]: Epoch 010 - training loss: 0.5848, validation loss: 0.2249
2024-06-02 20:08:35 [INFO]: Epoch 011 - training loss: 0.6026, validation loss: 0.2148
2024-06-02 20:08:36 [INFO]: Epoch 012 - training loss: 0.5940, validation loss: 0.2400
2024-06-02 20:08:38 [INFO]: Epoch 013 - training loss: 0.6033, validation loss: 0.2300
2024-06-02 20:08:39 [INFO]: Epoch 014 - training loss: 0.5451, validation loss: 0.2251
2024-06-02 20:08:40 [INFO]: Epoch 015 - training loss: 0.5714, validation loss: 0.1926
2024-06-02 20:08:42 [INFO]: Epoch 016 - training loss: 0.5439, validation loss: 0.2363
2024-06-02 20:08:43 [INFO]: Epoch 017 - training loss: 0.5260, validation loss: 0.1901
2024-06-02 20:08:44 [INFO]: Epoch 018 - training loss: 0.5321, validation loss: 0.1794
2024-06-02 20:08:46 [INFO]: Epoch 019 - training loss: 0.5103, validation loss: 0.1777
2024-06-02 20:08:47 [INFO]: Epoch 020 - training loss: 0.5101, validation loss: 0.1740
2024-06-02 20:08:48 [INFO]: Epoch 021 - training loss: 0.5202, validation loss: 0.1795
2024-06-02 20:08:50 [INFO]: Epoch 022 - training loss: 0.4771, validation loss: 0.2096
2024-06-02 20:08:51 [INFO]: Epoch 023 - training loss: 0.4918, validation loss: 0.1716
2024-06-02 20:08:52 [INFO]: Epoch 024 - training loss: 0.4929, validation loss: 0.1720
2024-06-02 20:08:54 [INFO]: Epoch 025 - training loss: 0.4691, validation loss: 0.1545
2024-06-02 20:08:55 [INFO]: Epoch 026 - training loss: 0.4497, validation loss: 0.1507
2024-06-02 20:08:56 [INFO]: Epoch 027 - training loss: 0.4452, validation loss: 0.1458
2024-06-02 20:08:58 [INFO]: Epoch 028 - training loss: 0.4462, validation loss: 0.1613
2024-06-02 20:08:59 [INFO]: Epoch 029 - training loss: 0.4248, validation loss: 0.1414
2024-06-02 20:09:00 [INFO]: Epoch 030 - training loss: 0.4153, validation loss: 0.1403
2024-06-02 20:09:02 [INFO]: Epoch 031 - training loss: 0.4146, validation loss: 0.1449
2024-06-02 20:09:03 [INFO]: Epoch 032 - training loss: 0.4067, validation loss: 0.1433
2024-06-02 20:09:04 [INFO]: Epoch 033 - training loss: 0.4172, validation loss: 0.1451
2024-06-02 20:09:05 [INFO]: Epoch 034 - training loss: 0.4177, validation loss: 0.1437
2024-06-02 20:09:07 [INFO]: Epoch 035 - training loss: 0.4011, validation loss: 0.1400
2024-06-02 20:09:08 [INFO]: Epoch 036 - training loss: 0.3965, validation loss: 0.1628
2024-06-02 20:09:10 [INFO]: Epoch 037 - training loss: 0.4109, validation loss: 0.1476
2024-06-02 20:09:11 [INFO]: Epoch 038 - training loss: 0.4228, validation loss: 0.1322
2024-06-02 20:09:12 [INFO]: Epoch 039 - training loss: 0.3998, validation loss: 0.1751
2024-06-02 20:09:14 [INFO]: Epoch 040 - training loss: 0.4176, validation loss: 0.1497
2024-06-02 20:09:15 [INFO]: Epoch 041 - training loss: 0.4046, validation loss: 0.1526
2024-06-02 20:09:16 [INFO]: Epoch 042 - training loss: 0.4131, validation loss: 0.1537
2024-06-02 20:09:18 [INFO]: Epoch 043 - training loss: 0.4127, validation loss: 0.1592
2024-06-02 20:09:19 [INFO]: Epoch 044 - training loss: 0.4124, validation loss: 0.1512
2024-06-02 20:09:21 [INFO]: Epoch 045 - training loss: 0.4021, validation loss: 0.1777
2024-06-02 20:09:22 [INFO]: Epoch 046 - training loss: 0.4485, validation loss: 0.1342
2024-06-02 20:09:23 [INFO]: Epoch 047 - training loss: 0.4033, validation loss: 0.1365
2024-06-02 20:09:25 [INFO]: Epoch 048 - training loss: 0.3942, validation loss: 0.1589
2024-06-02 20:09:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:09:25 [INFO]: Finished training. The best model is from epoch#38.
2024-06-02 20:09:25 [INFO]: Saved the model to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_2/20240602_T200820/Pyraformer.pypots
2024-06-02 20:09:26 [INFO]: Successfully saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_2/imputation.pkl
2024-06-02 20:09:26 [INFO]: Round2 - Pyraformer on ETT_h1: MAE=0.3390, MSE=0.2055, MRE=0.4010
2024-06-02 20:09:26 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:09:26 [INFO]: Using the given device: cuda:0
2024-06-02 20:09:26 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_3/20240602_T200926
2024-06-02 20:09:26 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_3/20240602_T200926/tensorboard
2024-06-02 20:09:26 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-02 20:09:27 [INFO]: Epoch 001 - training loss: 1.9733, validation loss: 0.5978
2024-06-02 20:09:29 [INFO]: Epoch 002 - training loss: 0.9976, validation loss: 0.3372
2024-06-02 20:09:30 [INFO]: Epoch 003 - training loss: 0.8612, validation loss: 0.3403
2024-06-02 20:09:31 [INFO]: Epoch 004 - training loss: 0.7762, validation loss: 0.3291
2024-06-02 20:09:33 [INFO]: Epoch 005 - training loss: 0.7032, validation loss: 0.2991
2024-06-02 20:09:34 [INFO]: Epoch 006 - training loss: 0.7025, validation loss: 0.2580
2024-06-02 20:09:35 [INFO]: Epoch 007 - training loss: 0.6506, validation loss: 0.2484
2024-06-02 20:09:37 [INFO]: Epoch 008 - training loss: 0.6309, validation loss: 0.2475
2024-06-02 20:09:38 [INFO]: Epoch 009 - training loss: 0.6198, validation loss: 0.2541
2024-06-02 20:09:39 [INFO]: Epoch 010 - training loss: 0.5962, validation loss: 0.2240
2024-06-02 20:09:40 [INFO]: Epoch 011 - training loss: 0.5845, validation loss: 0.2056
2024-06-02 20:09:42 [INFO]: Epoch 012 - training loss: 0.5354, validation loss: 0.2121
2024-06-02 20:09:43 [INFO]: Epoch 013 - training loss: 0.5428, validation loss: 0.1920
2024-06-02 20:09:44 [INFO]: Epoch 014 - training loss: 0.5234, validation loss: 0.1840
2024-06-02 20:09:46 [INFO]: Epoch 015 - training loss: 0.5144, validation loss: 0.2002
2024-06-02 20:09:47 [INFO]: Epoch 016 - training loss: 0.5413, validation loss: 0.1860
2024-06-02 20:09:48 [INFO]: Epoch 017 - training loss: 0.5386, validation loss: 0.1996
2024-06-02 20:09:49 [INFO]: Epoch 018 - training loss: 0.5511, validation loss: 0.1978
2024-06-02 20:09:51 [INFO]: Epoch 019 - training loss: 0.5056, validation loss: 0.1980
2024-06-02 20:09:52 [INFO]: Epoch 020 - training loss: 0.5056, validation loss: 0.1949
2024-06-02 20:09:53 [INFO]: Epoch 021 - training loss: 0.5000, validation loss: 0.1758
2024-06-02 20:09:54 [INFO]: Epoch 022 - training loss: 0.5262, validation loss: 0.1746
2024-06-02 20:09:56 [INFO]: Epoch 023 - training loss: 0.4939, validation loss: 0.1910
2024-06-02 20:09:57 [INFO]: Epoch 024 - training loss: 0.5036, validation loss: 0.1824
2024-06-02 20:09:58 [INFO]: Epoch 025 - training loss: 0.4912, validation loss: 0.1510
2024-06-02 20:10:00 [INFO]: Epoch 026 - training loss: 0.4672, validation loss: 0.1932
2024-06-02 20:10:01 [INFO]: Epoch 027 - training loss: 0.4747, validation loss: 0.1461
2024-06-02 20:10:02 [INFO]: Epoch 028 - training loss: 0.4658, validation loss: 0.1435
2024-06-02 20:10:03 [INFO]: Epoch 029 - training loss: 0.4649, validation loss: 0.1398
2024-06-02 20:10:05 [INFO]: Epoch 030 - training loss: 0.4407, validation loss: 0.1487
2024-06-02 20:10:06 [INFO]: Epoch 031 - training loss: 0.4387, validation loss: 0.1360
2024-06-02 20:10:07 [INFO]: Epoch 032 - training loss: 0.4275, validation loss: 0.1351
2024-06-02 20:10:09 [INFO]: Epoch 033 - training loss: 0.4345, validation loss: 0.1482
2024-06-02 20:10:10 [INFO]: Epoch 034 - training loss: 0.4245, validation loss: 0.1296
2024-06-02 20:10:11 [INFO]: Epoch 035 - training loss: 0.4125, validation loss: 0.1518
2024-06-02 20:10:13 [INFO]: Epoch 036 - training loss: 0.4032, validation loss: 0.1683
2024-06-02 20:10:14 [INFO]: Epoch 037 - training loss: 0.4048, validation loss: 0.1429
2024-06-02 20:10:15 [INFO]: Epoch 038 - training loss: 0.4101, validation loss: 0.1436
2024-06-02 20:10:17 [INFO]: Epoch 039 - training loss: 0.3869, validation loss: 0.1429
2024-06-02 20:10:18 [INFO]: Epoch 040 - training loss: 0.4000, validation loss: 0.1486
2024-06-02 20:10:20 [INFO]: Epoch 041 - training loss: 0.4248, validation loss: 0.1333
2024-06-02 20:10:21 [INFO]: Epoch 042 - training loss: 0.3728, validation loss: 0.1370
2024-06-02 20:10:22 [INFO]: Epoch 043 - training loss: 0.3668, validation loss: 0.1392
2024-06-02 20:10:23 [INFO]: Epoch 044 - training loss: 0.3543, validation loss: 0.1183
2024-06-02 20:10:25 [INFO]: Epoch 045 - training loss: 0.3558, validation loss: 0.1181
2024-06-02 20:10:26 [INFO]: Epoch 046 - training loss: 0.3537, validation loss: 0.1349
2024-06-02 20:10:27 [INFO]: Epoch 047 - training loss: 0.3715, validation loss: 0.1273
2024-06-02 20:10:28 [INFO]: Epoch 048 - training loss: 0.3581, validation loss: 0.1250
2024-06-02 20:10:30 [INFO]: Epoch 049 - training loss: 0.3587, validation loss: 0.1296
2024-06-02 20:10:31 [INFO]: Epoch 050 - training loss: 0.3554, validation loss: 0.1198
2024-06-02 20:10:32 [INFO]: Epoch 051 - training loss: 0.3574, validation loss: 0.1261
2024-06-02 20:10:33 [INFO]: Epoch 052 - training loss: 0.3588, validation loss: 0.1512
2024-06-02 20:10:34 [INFO]: Epoch 053 - training loss: 0.3659, validation loss: 0.1267
2024-06-02 20:10:35 [INFO]: Epoch 054 - training loss: 0.3489, validation loss: 0.1170
2024-06-02 20:10:37 [INFO]: Epoch 055 - training loss: 0.3503, validation loss: 0.1163
2024-06-02 20:10:38 [INFO]: Epoch 056 - training loss: 0.3473, validation loss: 0.1324
2024-06-02 20:10:39 [INFO]: Epoch 057 - training loss: 0.3414, validation loss: 0.1236
2024-06-02 20:10:41 [INFO]: Epoch 058 - training loss: 0.3581, validation loss: 0.1238
2024-06-02 20:10:42 [INFO]: Epoch 059 - training loss: 0.3517, validation loss: 0.1233
2024-06-02 20:10:43 [INFO]: Epoch 060 - training loss: 0.3481, validation loss: 0.1203
2024-06-02 20:10:44 [INFO]: Epoch 061 - training loss: 0.3471, validation loss: 0.1100
2024-06-02 20:10:46 [INFO]: Epoch 062 - training loss: 0.3453, validation loss: 0.1079
2024-06-02 20:10:47 [INFO]: Epoch 063 - training loss: 0.3359, validation loss: 0.1118
2024-06-02 20:10:48 [INFO]: Epoch 064 - training loss: 0.3343, validation loss: 0.1126
2024-06-02 20:10:50 [INFO]: Epoch 065 - training loss: 0.3488, validation loss: 0.1081
2024-06-02 20:10:51 [INFO]: Epoch 066 - training loss: 0.3261, validation loss: 0.1214
2024-06-02 20:10:52 [INFO]: Epoch 067 - training loss: 0.3285, validation loss: 0.1033
2024-06-02 20:10:53 [INFO]: Epoch 068 - training loss: 0.3318, validation loss: 0.1076
2024-06-02 20:10:55 [INFO]: Epoch 069 - training loss: 0.3199, validation loss: 0.1159
2024-06-02 20:10:56 [INFO]: Epoch 070 - training loss: 0.3272, validation loss: 0.1026
2024-06-02 20:10:57 [INFO]: Epoch 071 - training loss: 0.3163, validation loss: 0.1082
2024-06-02 20:10:59 [INFO]: Epoch 072 - training loss: 0.3208, validation loss: 0.1106
2024-06-02 20:11:00 [INFO]: Epoch 073 - training loss: 0.3089, validation loss: 0.1110
2024-06-02 20:11:01 [INFO]: Epoch 074 - training loss: 0.3254, validation loss: 0.1150
2024-06-02 20:11:02 [INFO]: Epoch 075 - training loss: 0.3255, validation loss: 0.1244
2024-06-02 20:11:03 [INFO]: Epoch 076 - training loss: 0.3211, validation loss: 0.1268
2024-06-02 20:11:05 [INFO]: Epoch 077 - training loss: 0.3104, validation loss: 0.1054
2024-06-02 20:11:06 [INFO]: Epoch 078 - training loss: 0.3022, validation loss: 0.1055
2024-06-02 20:11:07 [INFO]: Epoch 079 - training loss: 0.3067, validation loss: 0.1069
2024-06-02 20:11:09 [INFO]: Epoch 080 - training loss: 0.3071, validation loss: 0.0996
2024-06-02 20:11:10 [INFO]: Epoch 081 - training loss: 0.3084, validation loss: 0.1030
2024-06-02 20:11:12 [INFO]: Epoch 082 - training loss: 0.3071, validation loss: 0.0960
2024-06-02 20:11:13 [INFO]: Epoch 083 - training loss: 0.3014, validation loss: 0.1017
2024-06-02 20:11:14 [INFO]: Epoch 084 - training loss: 0.3081, validation loss: 0.1042
2024-06-02 20:11:16 [INFO]: Epoch 085 - training loss: 0.2985, validation loss: 0.1123
2024-06-02 20:11:17 [INFO]: Epoch 086 - training loss: 0.2870, validation loss: 0.0999
2024-06-02 20:11:18 [INFO]: Epoch 087 - training loss: 0.2891, validation loss: 0.1106
2024-06-02 20:11:20 [INFO]: Epoch 088 - training loss: 0.3105, validation loss: 0.1105
2024-06-02 20:11:21 [INFO]: Epoch 089 - training loss: 0.2986, validation loss: 0.1120
2024-06-02 20:11:22 [INFO]: Epoch 090 - training loss: 0.2957, validation loss: 0.1044
2024-06-02 20:11:24 [INFO]: Epoch 091 - training loss: 0.2945, validation loss: 0.1117
2024-06-02 20:11:25 [INFO]: Epoch 092 - training loss: 0.2994, validation loss: 0.1044
2024-06-02 20:11:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:11:25 [INFO]: Finished training. The best model is from epoch#82.
2024-06-02 20:11:25 [INFO]: Saved the model to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_3/20240602_T200926/Pyraformer.pypots
2024-06-02 20:11:26 [INFO]: Successfully saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_3/imputation.pkl
2024-06-02 20:11:26 [INFO]: Round3 - Pyraformer on ETT_h1: MAE=0.2616, MSE=0.1445, MRE=0.3094
2024-06-02 20:11:26 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:11:26 [INFO]: Using the given device: cuda:0
2024-06-02 20:11:26 [INFO]: Model files will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_4/20240602_T201126
2024-06-02 20:11:26 [INFO]: Tensorboard file will be saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_4/20240602_T201126/tensorboard
2024-06-02 20:11:26 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,262,215
2024-06-02 20:11:28 [INFO]: Epoch 001 - training loss: 2.0128, validation loss: 0.5432
2024-06-02 20:11:29 [INFO]: Epoch 002 - training loss: 1.0185, validation loss: 0.3539
2024-06-02 20:11:30 [INFO]: Epoch 003 - training loss: 0.8096, validation loss: 0.2736
2024-06-02 20:11:32 [INFO]: Epoch 004 - training loss: 0.7248, validation loss: 0.2765
2024-06-02 20:11:33 [INFO]: Epoch 005 - training loss: 0.6673, validation loss: 0.2457
2024-06-02 20:11:34 [INFO]: Epoch 006 - training loss: 0.6853, validation loss: 0.2346
2024-06-02 20:11:36 [INFO]: Epoch 007 - training loss: 0.6483, validation loss: 0.2390
2024-06-02 20:11:37 [INFO]: Epoch 008 - training loss: 0.6130, validation loss: 0.2560
2024-06-02 20:11:38 [INFO]: Epoch 009 - training loss: 0.5988, validation loss: 0.2416
2024-06-02 20:11:40 [INFO]: Epoch 010 - training loss: 0.5689, validation loss: 0.2279
2024-06-02 20:11:41 [INFO]: Epoch 011 - training loss: 0.5928, validation loss: 0.2083
2024-06-02 20:11:42 [INFO]: Epoch 012 - training loss: 0.5625, validation loss: 0.2338
2024-06-02 20:11:43 [INFO]: Epoch 013 - training loss: 0.5479, validation loss: 0.2137
2024-06-02 20:11:45 [INFO]: Epoch 014 - training loss: 0.5733, validation loss: 0.2150
2024-06-02 20:11:46 [INFO]: Epoch 015 - training loss: 0.5485, validation loss: 0.2175
2024-06-02 20:11:47 [INFO]: Epoch 016 - training loss: 0.5308, validation loss: 0.1839
2024-06-02 20:11:48 [INFO]: Epoch 017 - training loss: 0.5324, validation loss: 0.1967
2024-06-02 20:11:50 [INFO]: Epoch 018 - training loss: 0.5331, validation loss: 0.2243
2024-06-02 20:11:51 [INFO]: Epoch 019 - training loss: 0.5303, validation loss: 0.2015
2024-06-02 20:11:53 [INFO]: Epoch 020 - training loss: 0.5172, validation loss: 0.1850
2024-06-02 20:11:54 [INFO]: Epoch 021 - training loss: 0.5116, validation loss: 0.1791
2024-06-02 20:11:55 [INFO]: Epoch 022 - training loss: 0.5207, validation loss: 0.1707
2024-06-02 20:11:57 [INFO]: Epoch 023 - training loss: 0.4732, validation loss: 0.1526
2024-06-02 20:11:58 [INFO]: Epoch 024 - training loss: 0.4424, validation loss: 0.1676
2024-06-02 20:11:59 [INFO]: Epoch 025 - training loss: 0.4388, validation loss: 0.1596
2024-06-02 20:12:01 [INFO]: Epoch 026 - training loss: 0.4455, validation loss: 0.1473
2024-06-02 20:12:02 [INFO]: Epoch 027 - training loss: 0.4409, validation loss: 0.1435
2024-06-02 20:12:03 [INFO]: Epoch 028 - training loss: 0.4321, validation loss: 0.1392
2024-06-02 20:12:04 [INFO]: Epoch 029 - training loss: 0.4386, validation loss: 0.1590
2024-06-02 20:12:06 [INFO]: Epoch 030 - training loss: 0.4120, validation loss: 0.1586
2024-06-02 20:12:07 [INFO]: Epoch 031 - training loss: 0.4121, validation loss: 0.1479
2024-06-02 20:12:08 [INFO]: Epoch 032 - training loss: 0.3904, validation loss: 0.1398
2024-06-02 20:12:10 [INFO]: Epoch 033 - training loss: 0.3894, validation loss: 0.1401
2024-06-02 20:12:11 [INFO]: Epoch 034 - training loss: 0.4234, validation loss: 0.1499
2024-06-02 20:12:12 [INFO]: Epoch 035 - training loss: 0.4315, validation loss: 0.1533
2024-06-02 20:12:14 [INFO]: Epoch 036 - training loss: 0.4296, validation loss: 0.1430
2024-06-02 20:12:15 [INFO]: Epoch 037 - training loss: 0.3917, validation loss: 0.1395
2024-06-02 20:12:16 [INFO]: Epoch 038 - training loss: 0.3952, validation loss: 0.1377
2024-06-02 20:12:18 [INFO]: Epoch 039 - training loss: 0.4003, validation loss: 0.1387
2024-06-02 20:12:19 [INFO]: Epoch 040 - training loss: 0.3907, validation loss: 0.1353
2024-06-02 20:12:20 [INFO]: Epoch 041 - training loss: 0.3743, validation loss: 0.1468
2024-06-02 20:12:22 [INFO]: Epoch 042 - training loss: 0.3826, validation loss: 0.1388
2024-06-02 20:12:23 [INFO]: Epoch 043 - training loss: 0.3705, validation loss: 0.1312
2024-06-02 20:12:24 [INFO]: Epoch 044 - training loss: 0.3556, validation loss: 0.1285
2024-06-02 20:12:26 [INFO]: Epoch 045 - training loss: 0.3860, validation loss: 0.1416
2024-06-02 20:12:27 [INFO]: Epoch 046 - training loss: 0.3919, validation loss: 0.1317
2024-06-02 20:12:28 [INFO]: Epoch 047 - training loss: 0.3886, validation loss: 0.1286
2024-06-02 20:12:30 [INFO]: Epoch 048 - training loss: 0.3709, validation loss: 0.1263
2024-06-02 20:12:31 [INFO]: Epoch 049 - training loss: 0.3763, validation loss: 0.1321
2024-06-02 20:12:32 [INFO]: Epoch 050 - training loss: 0.3795, validation loss: 0.1312
2024-06-02 20:12:33 [INFO]: Epoch 051 - training loss: 0.3911, validation loss: 0.1222
2024-06-02 20:12:35 [INFO]: Epoch 052 - training loss: 0.3616, validation loss: 0.1172
2024-06-02 20:12:36 [INFO]: Epoch 053 - training loss: 0.3579, validation loss: 0.1217
2024-06-02 20:12:38 [INFO]: Epoch 054 - training loss: 0.3411, validation loss: 0.1121
2024-06-02 20:12:39 [INFO]: Epoch 055 - training loss: 0.3548, validation loss: 0.1066
2024-06-02 20:12:40 [INFO]: Epoch 056 - training loss: 0.3467, validation loss: 0.1175
2024-06-02 20:12:42 [INFO]: Epoch 057 - training loss: 0.3408, validation loss: 0.1211
2024-06-02 20:12:43 [INFO]: Epoch 058 - training loss: 0.3589, validation loss: 0.1200
2024-06-02 20:12:44 [INFO]: Epoch 059 - training loss: 0.3512, validation loss: 0.1187
2024-06-02 20:12:46 [INFO]: Epoch 060 - training loss: 0.3547, validation loss: 0.1232
2024-06-02 20:12:47 [INFO]: Epoch 061 - training loss: 0.3341, validation loss: 0.1110
2024-06-02 20:12:48 [INFO]: Epoch 062 - training loss: 0.3415, validation loss: 0.1224
2024-06-02 20:12:49 [INFO]: Epoch 063 - training loss: 0.3444, validation loss: 0.1267
2024-06-02 20:12:50 [INFO]: Epoch 064 - training loss: 0.3260, validation loss: 0.1099
2024-06-02 20:12:51 [INFO]: Epoch 065 - training loss: 0.3247, validation loss: 0.1093
2024-06-02 20:12:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:12:51 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 20:12:51 [INFO]: Saved the model to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_4/20240602_T201126/Pyraformer.pypots
2024-06-02 20:12:52 [INFO]: Successfully saved to results_point_rate05/ETT_h1/Pyraformer_ETT_h1/round_4/imputation.pkl
2024-06-02 20:12:52 [INFO]: Round4 - Pyraformer on ETT_h1: MAE=0.2841, MSE=0.1615, MRE=0.3361
2024-06-02 20:12:52 [INFO]: Done! Final results:
Averaged Pyraformer (15,262,215 params) on ETT_h1: MAE=0.2913 ± 0.02611216672888326, MSE=0.1673 ± 0.020684713437971763, MRE=0.3446 ± 0.03089060831822571, average inference time=0.21
