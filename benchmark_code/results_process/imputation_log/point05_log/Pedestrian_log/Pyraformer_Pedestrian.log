2024-06-02 21:04:44 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 21:04:44 [INFO]: Using the given device: cuda:0
2024-06-02 21:04:46 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_0/20240602_T210446
2024-06-02 21:04:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_0/20240602_T210446/tensorboard
2024-06-02 21:04:47 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 957,057
2024-06-02 21:04:53 [INFO]: Epoch 001 - training loss: 1.0030, validation loss: 0.6667
2024-06-02 21:04:56 [INFO]: Epoch 002 - training loss: 0.7083, validation loss: 0.6416
2024-06-02 21:04:58 [INFO]: Epoch 003 - training loss: 0.7158, validation loss: 0.6088
2024-06-02 21:05:01 [INFO]: Epoch 004 - training loss: 0.6241, validation loss: 0.6092
2024-06-02 21:05:03 [INFO]: Epoch 005 - training loss: 0.5755, validation loss: 0.5907
2024-06-02 21:05:06 [INFO]: Epoch 006 - training loss: 0.5623, validation loss: 0.5498
2024-06-02 21:05:09 [INFO]: Epoch 007 - training loss: 0.5033, validation loss: 0.5724
2024-06-02 21:05:11 [INFO]: Epoch 008 - training loss: 0.4708, validation loss: 0.5449
2024-06-02 21:05:14 [INFO]: Epoch 009 - training loss: 0.4785, validation loss: 0.5593
2024-06-02 21:05:17 [INFO]: Epoch 010 - training loss: 0.4423, validation loss: 0.5314
2024-06-02 21:05:20 [INFO]: Epoch 011 - training loss: 0.4493, validation loss: 0.5419
2024-06-02 21:05:23 [INFO]: Epoch 012 - training loss: 0.4578, validation loss: 0.5440
2024-06-02 21:05:26 [INFO]: Epoch 013 - training loss: 0.4316, validation loss: 0.5239
2024-06-02 21:05:28 [INFO]: Epoch 014 - training loss: 0.4326, validation loss: 0.5104
2024-06-02 21:05:31 [INFO]: Epoch 015 - training loss: 0.4138, validation loss: 0.5365
2024-06-02 21:05:34 [INFO]: Epoch 016 - training loss: 0.4207, validation loss: 0.5573
2024-06-02 21:05:36 [INFO]: Epoch 017 - training loss: 0.3959, validation loss: 0.5129
2024-06-02 21:05:39 [INFO]: Epoch 018 - training loss: 0.3903, validation loss: 0.5111
2024-06-02 21:05:42 [INFO]: Epoch 019 - training loss: 0.4194, validation loss: 0.4990
2024-06-02 21:05:45 [INFO]: Epoch 020 - training loss: 0.4077, validation loss: 0.5318
2024-06-02 21:05:47 [INFO]: Epoch 021 - training loss: 0.4102, validation loss: 0.4721
2024-06-02 21:05:50 [INFO]: Epoch 022 - training loss: 0.3869, validation loss: 0.4651
2024-06-02 21:05:53 [INFO]: Epoch 023 - training loss: 0.3881, validation loss: 0.4712
2024-06-02 21:05:56 [INFO]: Epoch 024 - training loss: 0.3804, validation loss: 0.4673
2024-06-02 21:05:58 [INFO]: Epoch 025 - training loss: 0.3703, validation loss: 0.4481
2024-06-02 21:06:01 [INFO]: Epoch 026 - training loss: 0.3693, validation loss: 0.4651
2024-06-02 21:06:03 [INFO]: Epoch 027 - training loss: 0.3575, validation loss: 0.4313
2024-06-02 21:06:06 [INFO]: Epoch 028 - training loss: 0.3608, validation loss: 0.4507
2024-06-02 21:06:09 [INFO]: Epoch 029 - training loss: 0.3667, validation loss: 0.4350
2024-06-02 21:06:12 [INFO]: Epoch 030 - training loss: 0.3521, validation loss: 0.4451
2024-06-02 21:06:15 [INFO]: Epoch 031 - training loss: 0.3431, validation loss: 0.4248
2024-06-02 21:06:17 [INFO]: Epoch 032 - training loss: 0.3372, validation loss: 0.4202
2024-06-02 21:06:20 [INFO]: Epoch 033 - training loss: 0.3321, validation loss: 0.4113
2024-06-02 21:06:23 [INFO]: Epoch 034 - training loss: 0.3356, validation loss: 0.4100
2024-06-02 21:06:26 [INFO]: Epoch 035 - training loss: 0.3240, validation loss: 0.4017
2024-06-02 21:06:28 [INFO]: Epoch 036 - training loss: 0.3292, validation loss: 0.4042
2024-06-02 21:06:31 [INFO]: Epoch 037 - training loss: 0.3200, validation loss: 0.4093
2024-06-02 21:06:34 [INFO]: Epoch 038 - training loss: 0.3360, validation loss: 0.3882
2024-06-02 21:06:36 [INFO]: Epoch 039 - training loss: 0.3323, validation loss: 0.3903
2024-06-02 21:06:39 [INFO]: Epoch 040 - training loss: 0.3251, validation loss: 0.3799
2024-06-02 21:06:42 [INFO]: Epoch 041 - training loss: 0.3167, validation loss: 0.3736
2024-06-02 21:06:45 [INFO]: Epoch 042 - training loss: 0.3106, validation loss: 0.3951
2024-06-02 21:06:47 [INFO]: Epoch 043 - training loss: 0.3226, validation loss: 0.3983
2024-06-02 21:06:50 [INFO]: Epoch 044 - training loss: 0.3301, validation loss: 0.3634
2024-06-02 21:06:53 [INFO]: Epoch 045 - training loss: 0.3155, validation loss: 0.3688
2024-06-02 21:06:56 [INFO]: Epoch 046 - training loss: 0.3166, validation loss: 0.3592
2024-06-02 21:06:58 [INFO]: Epoch 047 - training loss: 0.3130, validation loss: 0.3515
2024-06-02 21:07:01 [INFO]: Epoch 048 - training loss: 0.2817, validation loss: 0.3628
2024-06-02 21:07:03 [INFO]: Epoch 049 - training loss: 0.2941, validation loss: 0.3582
2024-06-02 21:07:06 [INFO]: Epoch 050 - training loss: 0.2873, validation loss: 0.3508
2024-06-02 21:07:09 [INFO]: Epoch 051 - training loss: 0.2910, validation loss: 0.3426
2024-06-02 21:07:12 [INFO]: Epoch 052 - training loss: 0.2959, validation loss: 0.3329
2024-06-02 21:07:15 [INFO]: Epoch 053 - training loss: 0.2843, validation loss: 0.3347
2024-06-02 21:07:18 [INFO]: Epoch 054 - training loss: 0.2828, validation loss: 0.3442
2024-06-02 21:07:21 [INFO]: Epoch 055 - training loss: 0.2917, validation loss: 0.3467
2024-06-02 21:07:23 [INFO]: Epoch 056 - training loss: 0.2738, validation loss: 0.3386
2024-06-02 21:07:26 [INFO]: Epoch 057 - training loss: 0.2691, validation loss: 0.3357
2024-06-02 21:07:29 [INFO]: Epoch 058 - training loss: 0.2747, validation loss: 0.3514
2024-06-02 21:07:31 [INFO]: Epoch 059 - training loss: 0.2646, validation loss: 0.3570
2024-06-02 21:07:34 [INFO]: Epoch 060 - training loss: 0.2741, validation loss: 0.3377
2024-06-02 21:07:37 [INFO]: Epoch 061 - training loss: 0.2667, validation loss: 0.3357
2024-06-02 21:07:39 [INFO]: Epoch 062 - training loss: 0.2685, validation loss: 0.3326
2024-06-02 21:07:42 [INFO]: Epoch 063 - training loss: 0.2840, validation loss: 0.3455
2024-06-02 21:07:45 [INFO]: Epoch 064 - training loss: 0.2621, validation loss: 0.3220
2024-06-02 21:07:48 [INFO]: Epoch 065 - training loss: 0.2582, validation loss: 0.3274
2024-06-02 21:07:50 [INFO]: Epoch 066 - training loss: 0.2937, validation loss: 0.3345
2024-06-02 21:07:53 [INFO]: Epoch 067 - training loss: 0.2514, validation loss: 0.3416
2024-06-02 21:07:56 [INFO]: Epoch 068 - training loss: 0.2575, validation loss: 0.3307
2024-06-02 21:07:59 [INFO]: Epoch 069 - training loss: 0.2490, validation loss: 0.3196
2024-06-02 21:08:01 [INFO]: Epoch 070 - training loss: 0.2589, validation loss: 0.3363
2024-06-02 21:08:04 [INFO]: Epoch 071 - training loss: 0.2589, validation loss: 0.3365
2024-06-02 21:08:07 [INFO]: Epoch 072 - training loss: 0.2607, validation loss: 0.3321
2024-06-02 21:08:10 [INFO]: Epoch 073 - training loss: 0.2581, validation loss: 0.3386
2024-06-02 21:08:12 [INFO]: Epoch 074 - training loss: 0.2443, validation loss: 0.3432
2024-06-02 21:08:15 [INFO]: Epoch 075 - training loss: 0.2582, validation loss: 0.3235
2024-06-02 21:08:18 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.3324
2024-06-02 21:08:20 [INFO]: Epoch 077 - training loss: 0.2441, validation loss: 0.3269
2024-06-02 21:08:23 [INFO]: Epoch 078 - training loss: 0.2696, validation loss: 0.3296
2024-06-02 21:08:25 [INFO]: Epoch 079 - training loss: 0.2503, validation loss: 0.3237
2024-06-02 21:08:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:08:25 [INFO]: Finished training. The best model is from epoch#69.
2024-06-02 21:08:25 [INFO]: Saved the model to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_0/20240602_T210446/Pyraformer.pypots
2024-06-02 21:08:29 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_0/imputation.pkl
2024-06-02 21:08:29 [INFO]: Round0 - Pyraformer on Pedestrian: MAE=0.2045, MSE=0.3692, MRE=0.2690
2024-06-02 21:08:29 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 21:08:29 [INFO]: Using the given device: cuda:0
2024-06-02 21:08:29 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_1/20240602_T210829
2024-06-02 21:08:29 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_1/20240602_T210829/tensorboard
2024-06-02 21:08:29 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 957,057
2024-06-02 21:08:32 [INFO]: Epoch 001 - training loss: 1.0274, validation loss: 0.7093
2024-06-02 21:08:34 [INFO]: Epoch 002 - training loss: 0.6877, validation loss: 0.6226
2024-06-02 21:08:37 [INFO]: Epoch 003 - training loss: 0.6284, validation loss: 0.6009
2024-06-02 21:08:40 [INFO]: Epoch 004 - training loss: 0.5709, validation loss: 0.5582
2024-06-02 21:08:43 [INFO]: Epoch 005 - training loss: 0.5370, validation loss: 0.5615
2024-06-02 21:08:45 [INFO]: Epoch 006 - training loss: 0.5210, validation loss: 0.5410
2024-06-02 21:08:48 [INFO]: Epoch 007 - training loss: 0.4898, validation loss: 0.5303
2024-06-02 21:08:51 [INFO]: Epoch 008 - training loss: 0.5128, validation loss: 0.5358
2024-06-02 21:08:54 [INFO]: Epoch 009 - training loss: 0.4762, validation loss: 0.5340
2024-06-02 21:08:56 [INFO]: Epoch 010 - training loss: 0.4850, validation loss: 0.5152
2024-06-02 21:08:59 [INFO]: Epoch 011 - training loss: 0.4554, validation loss: 0.5291
2024-06-02 21:09:02 [INFO]: Epoch 012 - training loss: 0.4415, validation loss: 0.5478
2024-06-02 21:09:05 [INFO]: Epoch 013 - training loss: 0.4457, validation loss: 0.5138
2024-06-02 21:09:08 [INFO]: Epoch 014 - training loss: 0.4367, validation loss: 0.5089
2024-06-02 21:09:10 [INFO]: Epoch 015 - training loss: 0.4555, validation loss: 0.5268
2024-06-02 21:09:13 [INFO]: Epoch 016 - training loss: 0.4262, validation loss: 0.5088
2024-06-02 21:09:16 [INFO]: Epoch 017 - training loss: 0.4167, validation loss: 0.5032
2024-06-02 21:09:19 [INFO]: Epoch 018 - training loss: 0.3944, validation loss: 0.4943
2024-06-02 21:09:22 [INFO]: Epoch 019 - training loss: 0.4175, validation loss: 0.4875
2024-06-02 21:09:24 [INFO]: Epoch 020 - training loss: 0.3965, validation loss: 0.4769
2024-06-02 21:09:27 [INFO]: Epoch 021 - training loss: 0.3880, validation loss: 0.4842
2024-06-02 21:09:30 [INFO]: Epoch 022 - training loss: 0.3695, validation loss: 0.4691
2024-06-02 21:09:33 [INFO]: Epoch 023 - training loss: 0.3823, validation loss: 0.4534
2024-06-02 21:09:35 [INFO]: Epoch 024 - training loss: 0.3772, validation loss: 0.4624
2024-06-02 21:09:38 [INFO]: Epoch 025 - training loss: 0.3954, validation loss: 0.4408
2024-06-02 21:09:41 [INFO]: Epoch 026 - training loss: 0.3575, validation loss: 0.4442
2024-06-02 21:09:44 [INFO]: Epoch 027 - training loss: 0.3828, validation loss: 0.4704
2024-06-02 21:09:46 [INFO]: Epoch 028 - training loss: 0.3733, validation loss: 0.4498
2024-06-02 21:09:49 [INFO]: Epoch 029 - training loss: 0.3545, validation loss: 0.4371
2024-06-02 21:09:52 [INFO]: Epoch 030 - training loss: 0.3626, validation loss: 0.4393
2024-06-02 21:09:55 [INFO]: Epoch 031 - training loss: 0.3636, validation loss: 0.4393
2024-06-02 21:09:57 [INFO]: Epoch 032 - training loss: 0.3543, validation loss: 0.4290
2024-06-02 21:10:00 [INFO]: Epoch 033 - training loss: 0.3419, validation loss: 0.4154
2024-06-02 21:10:03 [INFO]: Epoch 034 - training loss: 0.3422, validation loss: 0.4072
2024-06-02 21:10:06 [INFO]: Epoch 035 - training loss: 0.3424, validation loss: 0.4168
2024-06-02 21:10:08 [INFO]: Epoch 036 - training loss: 0.3243, validation loss: 0.4545
2024-06-02 21:10:11 [INFO]: Epoch 037 - training loss: 0.3273, validation loss: 0.4119
2024-06-02 21:10:14 [INFO]: Epoch 038 - training loss: 0.3218, validation loss: 0.4306
2024-06-02 21:10:16 [INFO]: Epoch 039 - training loss: 0.3319, validation loss: 0.4247
2024-06-02 21:10:19 [INFO]: Epoch 040 - training loss: 0.3504, validation loss: 0.3990
2024-06-02 21:10:22 [INFO]: Epoch 041 - training loss: 0.3148, validation loss: 0.3987
2024-06-02 21:10:25 [INFO]: Epoch 042 - training loss: 0.3215, validation loss: 0.4051
2024-06-02 21:10:27 [INFO]: Epoch 043 - training loss: 0.3171, validation loss: 0.3854
2024-06-02 21:10:30 [INFO]: Epoch 044 - training loss: 0.3108, validation loss: 0.3907
2024-06-02 21:10:33 [INFO]: Epoch 045 - training loss: 0.3069, validation loss: 0.3861
2024-06-02 21:10:36 [INFO]: Epoch 046 - training loss: 0.3301, validation loss: 0.3919
2024-06-02 21:10:39 [INFO]: Epoch 047 - training loss: 0.3118, validation loss: 0.3722
2024-06-02 21:10:41 [INFO]: Epoch 048 - training loss: 0.3297, validation loss: 0.3789
2024-06-02 21:10:44 [INFO]: Epoch 049 - training loss: 0.3150, validation loss: 0.3760
2024-06-02 21:10:47 [INFO]: Epoch 050 - training loss: 0.2959, validation loss: 0.3681
2024-06-02 21:10:50 [INFO]: Epoch 051 - training loss: 0.3078, validation loss: 0.3773
2024-06-02 21:10:52 [INFO]: Epoch 052 - training loss: 0.3048, validation loss: 0.3671
2024-06-02 21:10:55 [INFO]: Epoch 053 - training loss: 0.3036, validation loss: 0.3618
2024-06-02 21:10:58 [INFO]: Epoch 054 - training loss: 0.2863, validation loss: 0.3989
2024-06-02 21:11:00 [INFO]: Epoch 055 - training loss: 0.2915, validation loss: 0.3684
2024-06-02 21:11:03 [INFO]: Epoch 056 - training loss: 0.3016, validation loss: 0.3680
2024-06-02 21:11:06 [INFO]: Epoch 057 - training loss: 0.3087, validation loss: 0.3609
2024-06-02 21:11:09 [INFO]: Epoch 058 - training loss: 0.2974, validation loss: 0.3469
2024-06-02 21:11:12 [INFO]: Epoch 059 - training loss: 0.2849, validation loss: 0.3606
2024-06-02 21:11:14 [INFO]: Epoch 060 - training loss: 0.2757, validation loss: 0.3742
2024-06-02 21:11:17 [INFO]: Epoch 061 - training loss: 0.2809, validation loss: 0.3544
2024-06-02 21:11:20 [INFO]: Epoch 062 - training loss: 0.2762, validation loss: 0.3482
2024-06-02 21:11:22 [INFO]: Epoch 063 - training loss: 0.2772, validation loss: 0.3519
2024-06-02 21:11:25 [INFO]: Epoch 064 - training loss: 0.2691, validation loss: 0.3468
2024-06-02 21:11:28 [INFO]: Epoch 065 - training loss: 0.2785, validation loss: 0.3476
2024-06-02 21:11:31 [INFO]: Epoch 066 - training loss: 0.2757, validation loss: 0.3538
2024-06-02 21:11:33 [INFO]: Epoch 067 - training loss: 0.2743, validation loss: 0.3455
2024-06-02 21:11:36 [INFO]: Epoch 068 - training loss: 0.2827, validation loss: 0.3333
2024-06-02 21:11:39 [INFO]: Epoch 069 - training loss: 0.2583, validation loss: 0.3591
2024-06-02 21:11:42 [INFO]: Epoch 070 - training loss: 0.2807, validation loss: 0.3453
2024-06-02 21:11:45 [INFO]: Epoch 071 - training loss: 0.2671, validation loss: 0.3515
2024-06-02 21:11:48 [INFO]: Epoch 072 - training loss: 0.2701, validation loss: 0.3369
2024-06-02 21:11:50 [INFO]: Epoch 073 - training loss: 0.2644, validation loss: 0.3362
2024-06-02 21:11:53 [INFO]: Epoch 074 - training loss: 0.2671, validation loss: 0.3362
2024-06-02 21:11:56 [INFO]: Epoch 075 - training loss: 0.2505, validation loss: 0.3409
2024-06-02 21:11:58 [INFO]: Epoch 076 - training loss: 0.2630, validation loss: 0.3393
2024-06-02 21:12:01 [INFO]: Epoch 077 - training loss: 0.2584, validation loss: 0.3490
2024-06-02 21:12:04 [INFO]: Epoch 078 - training loss: 0.2688, validation loss: 0.3416
2024-06-02 21:12:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:12:04 [INFO]: Finished training. The best model is from epoch#68.
2024-06-02 21:12:04 [INFO]: Saved the model to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_1/20240602_T210829/Pyraformer.pypots
2024-06-02 21:12:07 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_1/imputation.pkl
2024-06-02 21:12:07 [INFO]: Round1 - Pyraformer on Pedestrian: MAE=0.2117, MSE=0.3912, MRE=0.2786
2024-06-02 21:12:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 21:12:07 [INFO]: Using the given device: cuda:0
2024-06-02 21:12:07 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_2/20240602_T211207
2024-06-02 21:12:07 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_2/20240602_T211207/tensorboard
2024-06-02 21:12:07 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 957,057
2024-06-02 21:12:10 [INFO]: Epoch 001 - training loss: 1.0048, validation loss: 0.7595
2024-06-02 21:12:12 [INFO]: Epoch 002 - training loss: 0.6896, validation loss: 0.6605
2024-06-02 21:12:15 [INFO]: Epoch 003 - training loss: 0.6100, validation loss: 0.6350
2024-06-02 21:12:18 [INFO]: Epoch 004 - training loss: 0.5481, validation loss: 0.5722
2024-06-02 21:12:21 [INFO]: Epoch 005 - training loss: 0.5146, validation loss: 0.5723
2024-06-02 21:12:23 [INFO]: Epoch 006 - training loss: 0.4906, validation loss: 0.6065
2024-06-02 21:12:26 [INFO]: Epoch 007 - training loss: 0.5110, validation loss: 0.5622
2024-06-02 21:12:28 [INFO]: Epoch 008 - training loss: 0.4784, validation loss: 0.5943
2024-06-02 21:12:31 [INFO]: Epoch 009 - training loss: 0.4728, validation loss: 0.5625
2024-06-02 21:12:33 [INFO]: Epoch 010 - training loss: 0.4515, validation loss: 0.5755
2024-06-02 21:12:36 [INFO]: Epoch 011 - training loss: 0.4415, validation loss: 0.5589
2024-06-02 21:12:39 [INFO]: Epoch 012 - training loss: 0.4246, validation loss: 0.5856
2024-06-02 21:12:42 [INFO]: Epoch 013 - training loss: 0.4391, validation loss: 0.5482
2024-06-02 21:12:44 [INFO]: Epoch 014 - training loss: 0.4177, validation loss: 0.5396
2024-06-02 21:12:47 [INFO]: Epoch 015 - training loss: 0.4237, validation loss: 0.5359
2024-06-02 21:12:50 [INFO]: Epoch 016 - training loss: 0.4226, validation loss: 0.5521
2024-06-02 21:12:53 [INFO]: Epoch 017 - training loss: 0.4279, validation loss: 0.5250
2024-06-02 21:12:55 [INFO]: Epoch 018 - training loss: 0.4101, validation loss: 0.5215
2024-06-02 21:12:58 [INFO]: Epoch 019 - training loss: 0.4101, validation loss: 0.5163
2024-06-02 21:13:00 [INFO]: Epoch 020 - training loss: 0.3775, validation loss: 0.5068
2024-06-02 21:13:04 [INFO]: Epoch 021 - training loss: 0.4002, validation loss: 0.5004
2024-06-02 21:13:06 [INFO]: Epoch 022 - training loss: 0.3894, validation loss: 0.5191
2024-06-02 21:13:09 [INFO]: Epoch 023 - training loss: 0.3772, validation loss: 0.4655
2024-06-02 21:13:11 [INFO]: Epoch 024 - training loss: 0.3826, validation loss: 0.4707
2024-06-02 21:13:14 [INFO]: Epoch 025 - training loss: 0.3716, validation loss: 0.4646
2024-06-02 21:13:17 [INFO]: Epoch 026 - training loss: 0.3533, validation loss: 0.4604
2024-06-02 21:13:20 [INFO]: Epoch 027 - training loss: 0.3585, validation loss: 0.4583
2024-06-02 21:13:22 [INFO]: Epoch 028 - training loss: 0.3733, validation loss: 0.4557
2024-06-02 21:13:25 [INFO]: Epoch 029 - training loss: 0.3433, validation loss: 0.4622
2024-06-02 21:13:28 [INFO]: Epoch 030 - training loss: 0.3436, validation loss: 0.4547
2024-06-02 21:13:31 [INFO]: Epoch 031 - training loss: 0.3669, validation loss: 0.4387
2024-06-02 21:13:33 [INFO]: Epoch 032 - training loss: 0.3469, validation loss: 0.4266
2024-06-02 21:13:35 [INFO]: Epoch 033 - training loss: 0.3522, validation loss: 0.4253
2024-06-02 21:13:38 [INFO]: Epoch 034 - training loss: 0.3316, validation loss: 0.4430
2024-06-02 21:13:41 [INFO]: Epoch 035 - training loss: 0.3447, validation loss: 0.4405
2024-06-02 21:13:44 [INFO]: Epoch 036 - training loss: 0.3161, validation loss: 0.4494
2024-06-02 21:13:46 [INFO]: Epoch 037 - training loss: 0.3271, validation loss: 0.4332
2024-06-02 21:13:48 [INFO]: Epoch 038 - training loss: 0.3059, validation loss: 0.4056
2024-06-02 21:13:51 [INFO]: Epoch 039 - training loss: 0.3002, validation loss: 0.4425
2024-06-02 21:13:53 [INFO]: Epoch 040 - training loss: 0.3181, validation loss: 0.3986
2024-06-02 21:13:56 [INFO]: Epoch 041 - training loss: 0.3299, validation loss: 0.4118
2024-06-02 21:13:59 [INFO]: Epoch 042 - training loss: 0.3169, validation loss: 0.3814
2024-06-02 21:14:02 [INFO]: Epoch 043 - training loss: 0.3157, validation loss: 0.4186
2024-06-02 21:14:05 [INFO]: Epoch 044 - training loss: 0.3022, validation loss: 0.4003
2024-06-02 21:14:08 [INFO]: Epoch 045 - training loss: 0.2984, validation loss: 0.4006
2024-06-02 21:14:11 [INFO]: Epoch 046 - training loss: 0.3051, validation loss: 0.4008
2024-06-02 21:14:13 [INFO]: Epoch 047 - training loss: 0.2950, validation loss: 0.3872
2024-06-02 21:14:16 [INFO]: Epoch 048 - training loss: 0.2853, validation loss: 0.3996
2024-06-02 21:14:19 [INFO]: Epoch 049 - training loss: 0.2903, validation loss: 0.3822
2024-06-02 21:14:21 [INFO]: Epoch 050 - training loss: 0.2888, validation loss: 0.3753
2024-06-02 21:14:24 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.3748
2024-06-02 21:14:27 [INFO]: Epoch 052 - training loss: 0.2931, validation loss: 0.4138
2024-06-02 21:14:29 [INFO]: Epoch 053 - training loss: 0.2633, validation loss: 0.3818
2024-06-02 21:14:32 [INFO]: Epoch 054 - training loss: 0.3019, validation loss: 0.3565
2024-06-02 21:14:35 [INFO]: Epoch 055 - training loss: 0.2694, validation loss: 0.3801
2024-06-02 21:14:38 [INFO]: Epoch 056 - training loss: 0.2725, validation loss: 0.3910
2024-06-02 21:14:41 [INFO]: Epoch 057 - training loss: 0.2758, validation loss: 0.3616
2024-06-02 21:14:43 [INFO]: Epoch 058 - training loss: 0.2688, validation loss: 0.3660
2024-06-02 21:14:46 [INFO]: Epoch 059 - training loss: 0.2634, validation loss: 0.3658
2024-06-02 21:14:49 [INFO]: Epoch 060 - training loss: 0.2658, validation loss: 0.3653
2024-06-02 21:14:51 [INFO]: Epoch 061 - training loss: 0.2632, validation loss: 0.3636
2024-06-02 21:14:54 [INFO]: Epoch 062 - training loss: 0.2646, validation loss: 0.3440
2024-06-02 21:14:57 [INFO]: Epoch 063 - training loss: 0.2759, validation loss: 0.3462
2024-06-02 21:15:00 [INFO]: Epoch 064 - training loss: 0.2740, validation loss: 0.3458
2024-06-02 21:15:02 [INFO]: Epoch 065 - training loss: 0.2744, validation loss: 0.3554
2024-06-02 21:15:05 [INFO]: Epoch 066 - training loss: 0.2574, validation loss: 0.3637
2024-06-02 21:15:07 [INFO]: Epoch 067 - training loss: 0.2528, validation loss: 0.3598
2024-06-02 21:15:10 [INFO]: Epoch 068 - training loss: 0.2619, validation loss: 0.3547
2024-06-02 21:15:13 [INFO]: Epoch 069 - training loss: 0.2593, validation loss: 0.3487
2024-06-02 21:15:16 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.3563
2024-06-02 21:15:18 [INFO]: Epoch 071 - training loss: 0.2630, validation loss: 0.3354
2024-06-02 21:15:21 [INFO]: Epoch 072 - training loss: 0.2432, validation loss: 0.3545
2024-06-02 21:15:24 [INFO]: Epoch 073 - training loss: 0.2488, validation loss: 0.3519
2024-06-02 21:15:27 [INFO]: Epoch 074 - training loss: 0.2636, validation loss: 0.3409
2024-06-02 21:15:29 [INFO]: Epoch 075 - training loss: 0.2710, validation loss: 0.3863
2024-06-02 21:15:32 [INFO]: Epoch 076 - training loss: 0.2374, validation loss: 0.3517
2024-06-02 21:15:34 [INFO]: Epoch 077 - training loss: 0.2447, validation loss: 0.3447
2024-06-02 21:15:37 [INFO]: Epoch 078 - training loss: 0.2528, validation loss: 0.3410
2024-06-02 21:15:40 [INFO]: Epoch 079 - training loss: 0.2415, validation loss: 0.3425
2024-06-02 21:15:43 [INFO]: Epoch 080 - training loss: 0.2413, validation loss: 0.3396
2024-06-02 21:15:45 [INFO]: Epoch 081 - training loss: 0.2348, validation loss: 0.3327
2024-06-02 21:15:48 [INFO]: Epoch 082 - training loss: 0.2425, validation loss: 0.3342
2024-06-02 21:15:51 [INFO]: Epoch 083 - training loss: 0.2470, validation loss: 0.3251
2024-06-02 21:15:53 [INFO]: Epoch 084 - training loss: 0.2461, validation loss: 0.3277
2024-06-02 21:15:56 [INFO]: Epoch 085 - training loss: 0.2368, validation loss: 0.3448
2024-06-02 21:15:59 [INFO]: Epoch 086 - training loss: 0.2497, validation loss: 0.3334
2024-06-02 21:16:02 [INFO]: Epoch 087 - training loss: 0.2287, validation loss: 0.3486
2024-06-02 21:16:04 [INFO]: Epoch 088 - training loss: 0.2331, validation loss: 0.3402
2024-06-02 21:16:07 [INFO]: Epoch 089 - training loss: 0.2561, validation loss: 0.3226
2024-06-02 21:16:10 [INFO]: Epoch 090 - training loss: 0.2528, validation loss: 0.3258
2024-06-02 21:16:13 [INFO]: Epoch 091 - training loss: 0.2438, validation loss: 0.3377
2024-06-02 21:16:16 [INFO]: Epoch 092 - training loss: 0.2387, validation loss: 0.3259
2024-06-02 21:16:18 [INFO]: Epoch 093 - training loss: 0.2459, validation loss: 0.3248
2024-06-02 21:16:21 [INFO]: Epoch 094 - training loss: 0.2402, validation loss: 0.3350
2024-06-02 21:16:24 [INFO]: Epoch 095 - training loss: 0.2345, validation loss: 0.3203
2024-06-02 21:16:27 [INFO]: Epoch 096 - training loss: 0.2342, validation loss: 0.3367
2024-06-02 21:16:29 [INFO]: Epoch 097 - training loss: 0.2358, validation loss: 0.3418
2024-06-02 21:16:32 [INFO]: Epoch 098 - training loss: 0.2395, validation loss: 0.3333
2024-06-02 21:16:35 [INFO]: Epoch 099 - training loss: 0.2225, validation loss: 0.3307
2024-06-02 21:16:37 [INFO]: Epoch 100 - training loss: 0.2290, validation loss: 0.3481
2024-06-02 21:16:37 [INFO]: Finished training. The best model is from epoch#95.
2024-06-02 21:16:37 [INFO]: Saved the model to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_2/20240602_T211207/Pyraformer.pypots
2024-06-02 21:16:40 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_2/imputation.pkl
2024-06-02 21:16:40 [INFO]: Round2 - Pyraformer on Pedestrian: MAE=0.1965, MSE=0.3831, MRE=0.2585
2024-06-02 21:16:40 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 21:16:40 [INFO]: Using the given device: cuda:0
2024-06-02 21:16:40 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_3/20240602_T211640
2024-06-02 21:16:40 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_3/20240602_T211640/tensorboard
2024-06-02 21:16:40 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 957,057
2024-06-02 21:16:43 [INFO]: Epoch 001 - training loss: 0.9554, validation loss: 0.7492
2024-06-02 21:16:46 [INFO]: Epoch 002 - training loss: 0.8173, validation loss: 0.6961
2024-06-02 21:16:48 [INFO]: Epoch 003 - training loss: 0.6612, validation loss: 0.6341
2024-06-02 21:16:51 [INFO]: Epoch 004 - training loss: 0.5886, validation loss: 0.6204
2024-06-02 21:16:53 [INFO]: Epoch 005 - training loss: 0.5552, validation loss: 0.6114
2024-06-02 21:16:56 [INFO]: Epoch 006 - training loss: 0.5268, validation loss: 0.5754
2024-06-02 21:16:58 [INFO]: Epoch 007 - training loss: 0.4984, validation loss: 0.5858
2024-06-02 21:17:00 [INFO]: Epoch 008 - training loss: 0.4732, validation loss: 0.5664
2024-06-02 21:17:03 [INFO]: Epoch 009 - training loss: 0.4658, validation loss: 0.6007
2024-06-02 21:17:05 [INFO]: Epoch 010 - training loss: 0.4387, validation loss: 0.5639
2024-06-02 21:17:07 [INFO]: Epoch 011 - training loss: 0.4492, validation loss: 0.5627
2024-06-02 21:17:09 [INFO]: Epoch 012 - training loss: 0.4516, validation loss: 0.5546
2024-06-02 21:17:12 [INFO]: Epoch 013 - training loss: 0.4231, validation loss: 0.5567
2024-06-02 21:17:14 [INFO]: Epoch 014 - training loss: 0.4375, validation loss: 0.5768
2024-06-02 21:17:16 [INFO]: Epoch 015 - training loss: 0.4169, validation loss: 0.5336
2024-06-02 21:17:19 [INFO]: Epoch 016 - training loss: 0.4190, validation loss: 0.5629
2024-06-02 21:17:21 [INFO]: Epoch 017 - training loss: 0.4121, validation loss: 0.5225
2024-06-02 21:17:24 [INFO]: Epoch 018 - training loss: 0.3940, validation loss: 0.5155
2024-06-02 21:17:26 [INFO]: Epoch 019 - training loss: 0.3843, validation loss: 0.5175
2024-06-02 21:17:29 [INFO]: Epoch 020 - training loss: 0.3988, validation loss: 0.5335
2024-06-02 21:17:31 [INFO]: Epoch 021 - training loss: 0.3776, validation loss: 0.5554
2024-06-02 21:17:34 [INFO]: Epoch 022 - training loss: 0.3758, validation loss: 0.4823
2024-06-02 21:17:36 [INFO]: Epoch 023 - training loss: 0.4094, validation loss: 0.4864
2024-06-02 21:17:38 [INFO]: Epoch 024 - training loss: 0.3885, validation loss: 0.4816
2024-06-02 21:17:41 [INFO]: Epoch 025 - training loss: 0.3714, validation loss: 0.4760
2024-06-02 21:17:43 [INFO]: Epoch 026 - training loss: 0.3638, validation loss: 0.4703
2024-06-02 21:17:45 [INFO]: Epoch 027 - training loss: 0.3620, validation loss: 0.4706
2024-06-02 21:17:47 [INFO]: Epoch 028 - training loss: 0.3577, validation loss: 0.5042
2024-06-02 21:17:49 [INFO]: Epoch 029 - training loss: 0.3607, validation loss: 0.4476
2024-06-02 21:17:51 [INFO]: Epoch 030 - training loss: 0.3398, validation loss: 0.4653
2024-06-02 21:17:52 [INFO]: Epoch 031 - training loss: 0.3385, validation loss: 0.5315
2024-06-02 21:17:54 [INFO]: Epoch 032 - training loss: 0.3393, validation loss: 0.4344
2024-06-02 21:17:56 [INFO]: Epoch 033 - training loss: 0.3308, validation loss: 0.4594
2024-06-02 21:17:57 [INFO]: Epoch 034 - training loss: 0.3423, validation loss: 0.4459
2024-06-02 21:17:59 [INFO]: Epoch 035 - training loss: 0.3250, validation loss: 0.4461
2024-06-02 21:18:01 [INFO]: Epoch 036 - training loss: 0.3453, validation loss: 0.4750
2024-06-02 21:18:02 [INFO]: Epoch 037 - training loss: 0.3409, validation loss: 0.4245
2024-06-02 21:18:04 [INFO]: Epoch 038 - training loss: 0.3428, validation loss: 0.4144
2024-06-02 21:18:05 [INFO]: Epoch 039 - training loss: 0.3247, validation loss: 0.4049
2024-06-02 21:18:07 [INFO]: Epoch 040 - training loss: 0.3092, validation loss: 0.4208
2024-06-02 21:18:08 [INFO]: Epoch 041 - training loss: 0.3247, validation loss: 0.4041
2024-06-02 21:18:10 [INFO]: Epoch 042 - training loss: 0.3076, validation loss: 0.4074
2024-06-02 21:18:12 [INFO]: Epoch 043 - training loss: 0.3005, validation loss: 0.3942
2024-06-02 21:18:13 [INFO]: Epoch 044 - training loss: 0.3139, validation loss: 0.3929
2024-06-02 21:18:15 [INFO]: Epoch 045 - training loss: 0.3035, validation loss: 0.3986
2024-06-02 21:18:16 [INFO]: Epoch 046 - training loss: 0.3040, validation loss: 0.3818
2024-06-02 21:18:18 [INFO]: Epoch 047 - training loss: 0.3112, validation loss: 0.3833
2024-06-02 21:18:20 [INFO]: Epoch 048 - training loss: 0.3075, validation loss: 0.3834
2024-06-02 21:18:21 [INFO]: Epoch 049 - training loss: 0.2982, validation loss: 0.3787
2024-06-02 21:18:23 [INFO]: Epoch 050 - training loss: 0.3063, validation loss: 0.4047
2024-06-02 21:18:24 [INFO]: Epoch 051 - training loss: 0.2955, validation loss: 0.3768
2024-06-02 21:18:26 [INFO]: Epoch 052 - training loss: 0.2927, validation loss: 0.3714
2024-06-02 21:18:28 [INFO]: Epoch 053 - training loss: 0.3049, validation loss: 0.3614
2024-06-02 21:18:29 [INFO]: Epoch 054 - training loss: 0.2920, validation loss: 0.3813
2024-06-02 21:18:31 [INFO]: Epoch 055 - training loss: 0.2791, validation loss: 0.3845
2024-06-02 21:18:33 [INFO]: Epoch 056 - training loss: 0.2948, validation loss: 0.3626
2024-06-02 21:18:34 [INFO]: Epoch 057 - training loss: 0.2698, validation loss: 0.3795
2024-06-02 21:18:36 [INFO]: Epoch 058 - training loss: 0.2820, validation loss: 0.3548
2024-06-02 21:18:37 [INFO]: Epoch 059 - training loss: 0.2966, validation loss: 0.3708
2024-06-02 21:18:39 [INFO]: Epoch 060 - training loss: 0.2693, validation loss: 0.3654
2024-06-02 21:18:40 [INFO]: Epoch 061 - training loss: 0.2680, validation loss: 0.3541
2024-06-02 21:18:42 [INFO]: Epoch 062 - training loss: 0.2673, validation loss: 0.3696
2024-06-02 21:18:43 [INFO]: Epoch 063 - training loss: 0.2938, validation loss: 0.3866
2024-06-02 21:18:45 [INFO]: Epoch 064 - training loss: 0.2753, validation loss: 0.3619
2024-06-02 21:18:46 [INFO]: Epoch 065 - training loss: 0.2644, validation loss: 0.3621
2024-06-02 21:18:48 [INFO]: Epoch 066 - training loss: 0.2704, validation loss: 0.3733
2024-06-02 21:18:49 [INFO]: Epoch 067 - training loss: 0.2676, validation loss: 0.3545
2024-06-02 21:18:51 [INFO]: Epoch 068 - training loss: 0.2606, validation loss: 0.3942
2024-06-02 21:18:52 [INFO]: Epoch 069 - training loss: 0.2580, validation loss: 0.3486
2024-06-02 21:18:54 [INFO]: Epoch 070 - training loss: 0.2632, validation loss: 0.3454
2024-06-02 21:18:56 [INFO]: Epoch 071 - training loss: 0.2679, validation loss: 0.3518
2024-06-02 21:18:57 [INFO]: Epoch 072 - training loss: 0.2677, validation loss: 0.3518
2024-06-02 21:18:59 [INFO]: Epoch 073 - training loss: 0.2792, validation loss: 0.3677
2024-06-02 21:19:00 [INFO]: Epoch 074 - training loss: 0.2698, validation loss: 0.3510
2024-06-02 21:19:02 [INFO]: Epoch 075 - training loss: 0.2504, validation loss: 0.3436
2024-06-02 21:19:03 [INFO]: Epoch 076 - training loss: 0.2534, validation loss: 0.3386
2024-06-02 21:19:05 [INFO]: Epoch 077 - training loss: 0.2518, validation loss: 0.3501
2024-06-02 21:19:07 [INFO]: Epoch 078 - training loss: 0.2545, validation loss: 0.3749
2024-06-02 21:19:08 [INFO]: Epoch 079 - training loss: 0.2441, validation loss: 0.3509
2024-06-02 21:19:10 [INFO]: Epoch 080 - training loss: 0.2476, validation loss: 0.3445
2024-06-02 21:19:11 [INFO]: Epoch 081 - training loss: 0.2432, validation loss: 0.3415
2024-06-02 21:19:12 [INFO]: Epoch 082 - training loss: 0.2560, validation loss: 0.3476
2024-06-02 21:19:14 [INFO]: Epoch 083 - training loss: 0.2563, validation loss: 0.3719
2024-06-02 21:19:16 [INFO]: Epoch 084 - training loss: 0.2593, validation loss: 0.3639
2024-06-02 21:19:17 [INFO]: Epoch 085 - training loss: 0.2572, validation loss: 0.3366
2024-06-02 21:19:18 [INFO]: Epoch 086 - training loss: 0.2456, validation loss: 0.3465
2024-06-02 21:19:20 [INFO]: Epoch 087 - training loss: 0.2414, validation loss: 0.3404
2024-06-02 21:19:21 [INFO]: Epoch 088 - training loss: 0.2515, validation loss: 0.3424
2024-06-02 21:19:23 [INFO]: Epoch 089 - training loss: 0.2470, validation loss: 0.3337
2024-06-02 21:19:24 [INFO]: Epoch 090 - training loss: 0.2527, validation loss: 0.3432
2024-06-02 21:19:26 [INFO]: Epoch 091 - training loss: 0.2365, validation loss: 0.3432
2024-06-02 21:19:28 [INFO]: Epoch 092 - training loss: 0.2337, validation loss: 0.3449
2024-06-02 21:19:29 [INFO]: Epoch 093 - training loss: 0.2376, validation loss: 0.3476
2024-06-02 21:19:31 [INFO]: Epoch 094 - training loss: 0.2436, validation loss: 0.3328
2024-06-02 21:19:33 [INFO]: Epoch 095 - training loss: 0.2521, validation loss: 0.3653
2024-06-02 21:19:34 [INFO]: Epoch 096 - training loss: 0.2654, validation loss: 0.3481
2024-06-02 21:19:36 [INFO]: Epoch 097 - training loss: 0.2417, validation loss: 0.3287
2024-06-02 21:19:38 [INFO]: Epoch 098 - training loss: 0.2454, validation loss: 0.3329
2024-06-02 21:19:39 [INFO]: Epoch 099 - training loss: 0.2385, validation loss: 0.3266
2024-06-02 21:19:41 [INFO]: Epoch 100 - training loss: 0.2267, validation loss: 0.3341
2024-06-02 21:19:41 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 21:19:41 [INFO]: Saved the model to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_3/20240602_T211640/Pyraformer.pypots
2024-06-02 21:19:43 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_3/imputation.pkl
2024-06-02 21:19:43 [INFO]: Round3 - Pyraformer on Pedestrian: MAE=0.1987, MSE=0.3787, MRE=0.2614
2024-06-02 21:19:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 21:19:43 [INFO]: Using the given device: cuda:0
2024-06-02 21:19:43 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_4/20240602_T211943
2024-06-02 21:19:43 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_4/20240602_T211943/tensorboard
2024-06-02 21:19:43 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 957,057
2024-06-02 21:19:45 [INFO]: Epoch 001 - training loss: 0.9517, validation loss: 0.7512
2024-06-02 21:19:46 [INFO]: Epoch 002 - training loss: 0.7125, validation loss: 0.7314
2024-06-02 21:19:48 [INFO]: Epoch 003 - training loss: 0.6285, validation loss: 0.6315
2024-06-02 21:19:49 [INFO]: Epoch 004 - training loss: 0.6051, validation loss: 0.6333
2024-06-02 21:19:51 [INFO]: Epoch 005 - training loss: 0.5132, validation loss: 0.5675
2024-06-02 21:19:52 [INFO]: Epoch 006 - training loss: 0.4879, validation loss: 0.5641
2024-06-02 21:19:53 [INFO]: Epoch 007 - training loss: 0.4857, validation loss: 0.5603
2024-06-02 21:19:55 [INFO]: Epoch 008 - training loss: 0.4935, validation loss: 0.5712
2024-06-02 21:19:57 [INFO]: Epoch 009 - training loss: 0.4747, validation loss: 0.5550
2024-06-02 21:19:58 [INFO]: Epoch 010 - training loss: 0.4567, validation loss: 0.5353
2024-06-02 21:20:00 [INFO]: Epoch 011 - training loss: 0.4418, validation loss: 0.5728
2024-06-02 21:20:01 [INFO]: Epoch 012 - training loss: 0.4369, validation loss: 0.5424
2024-06-02 21:20:03 [INFO]: Epoch 013 - training loss: 0.4199, validation loss: 0.5384
2024-06-02 21:20:04 [INFO]: Epoch 014 - training loss: 0.4087, validation loss: 0.5270
2024-06-02 21:20:05 [INFO]: Epoch 015 - training loss: 0.4121, validation loss: 0.5678
2024-06-02 21:20:06 [INFO]: Epoch 016 - training loss: 0.3926, validation loss: 0.5199
2024-06-02 21:20:08 [INFO]: Epoch 017 - training loss: 0.3931, validation loss: 0.5102
2024-06-02 21:20:10 [INFO]: Epoch 018 - training loss: 0.3968, validation loss: 0.5204
2024-06-02 21:20:11 [INFO]: Epoch 019 - training loss: 0.3935, validation loss: 0.4964
2024-06-02 21:20:13 [INFO]: Epoch 020 - training loss: 0.3746, validation loss: 0.5384
2024-06-02 21:20:15 [INFO]: Epoch 021 - training loss: 0.3935, validation loss: 0.4639
2024-06-02 21:20:16 [INFO]: Epoch 022 - training loss: 0.3748, validation loss: 0.4671
2024-06-02 21:20:18 [INFO]: Epoch 023 - training loss: 0.3619, validation loss: 0.4573
2024-06-02 21:20:20 [INFO]: Epoch 024 - training loss: 0.3608, validation loss: 0.4510
2024-06-02 21:20:21 [INFO]: Epoch 025 - training loss: 0.3521, validation loss: 0.4554
2024-06-02 21:20:23 [INFO]: Epoch 026 - training loss: 0.3626, validation loss: 0.4439
2024-06-02 21:20:24 [INFO]: Epoch 027 - training loss: 0.3402, validation loss: 0.4454
2024-06-02 21:20:26 [INFO]: Epoch 028 - training loss: 0.3612, validation loss: 0.4264
2024-06-02 21:20:27 [INFO]: Epoch 029 - training loss: 0.3490, validation loss: 0.4374
2024-06-02 21:20:29 [INFO]: Epoch 030 - training loss: 0.3312, validation loss: 0.4162
2024-06-02 21:20:30 [INFO]: Epoch 031 - training loss: 0.3353, validation loss: 0.3984
2024-06-02 21:20:31 [INFO]: Epoch 032 - training loss: 0.3337, validation loss: 0.4246
2024-06-02 21:20:33 [INFO]: Epoch 033 - training loss: 0.3296, validation loss: 0.4028
2024-06-02 21:20:34 [INFO]: Epoch 034 - training loss: 0.3054, validation loss: 0.4137
2024-06-02 21:20:36 [INFO]: Epoch 035 - training loss: 0.3130, validation loss: 0.4026
2024-06-02 21:20:37 [INFO]: Epoch 036 - training loss: 0.3254, validation loss: 0.3956
2024-06-02 21:20:39 [INFO]: Epoch 037 - training loss: 0.3069, validation loss: 0.3880
2024-06-02 21:20:41 [INFO]: Epoch 038 - training loss: 0.3066, validation loss: 0.3868
2024-06-02 21:20:42 [INFO]: Epoch 039 - training loss: 0.2932, validation loss: 0.3682
2024-06-02 21:20:44 [INFO]: Epoch 040 - training loss: 0.2915, validation loss: 0.3837
2024-06-02 21:20:46 [INFO]: Epoch 041 - training loss: 0.2926, validation loss: 0.4051
2024-06-02 21:20:47 [INFO]: Epoch 042 - training loss: 0.2780, validation loss: 0.4058
2024-06-02 21:20:49 [INFO]: Epoch 043 - training loss: 0.2932, validation loss: 0.3919
2024-06-02 21:20:51 [INFO]: Epoch 044 - training loss: 0.2925, validation loss: 0.3714
2024-06-02 21:20:52 [INFO]: Epoch 045 - training loss: 0.2804, validation loss: 0.3554
2024-06-02 21:20:54 [INFO]: Epoch 046 - training loss: 0.2889, validation loss: 0.3820
2024-06-02 21:20:55 [INFO]: Epoch 047 - training loss: 0.2856, validation loss: 0.3602
2024-06-02 21:20:57 [INFO]: Epoch 048 - training loss: 0.2765, validation loss: 0.3844
2024-06-02 21:20:58 [INFO]: Epoch 049 - training loss: 0.2788, validation loss: 0.3772
2024-06-02 21:21:00 [INFO]: Epoch 050 - training loss: 0.2916, validation loss: 0.3564
2024-06-02 21:21:01 [INFO]: Epoch 051 - training loss: 0.2859, validation loss: 0.3554
2024-06-02 21:21:03 [INFO]: Epoch 052 - training loss: 0.2722, validation loss: 0.3533
2024-06-02 21:21:05 [INFO]: Epoch 053 - training loss: 0.2726, validation loss: 0.3588
2024-06-02 21:21:07 [INFO]: Epoch 054 - training loss: 0.2772, validation loss: 0.3699
2024-06-02 21:21:08 [INFO]: Epoch 055 - training loss: 0.2692, validation loss: 0.3608
2024-06-02 21:21:10 [INFO]: Epoch 056 - training loss: 0.2784, validation loss: 0.3511
2024-06-02 21:21:11 [INFO]: Epoch 057 - training loss: 0.2616, validation loss: 0.3547
2024-06-02 21:21:13 [INFO]: Epoch 058 - training loss: 0.2661, validation loss: 0.3705
2024-06-02 21:21:14 [INFO]: Epoch 059 - training loss: 0.2589, validation loss: 0.3519
2024-06-02 21:21:16 [INFO]: Epoch 060 - training loss: 0.2641, validation loss: 0.3391
2024-06-02 21:21:17 [INFO]: Epoch 061 - training loss: 0.2727, validation loss: 0.3523
2024-06-02 21:21:19 [INFO]: Epoch 062 - training loss: 0.2595, validation loss: 0.3489
2024-06-02 21:21:20 [INFO]: Epoch 063 - training loss: 0.2687, validation loss: 0.3470
2024-06-02 21:21:21 [INFO]: Epoch 064 - training loss: 0.2540, validation loss: 0.3448
2024-06-02 21:21:22 [INFO]: Epoch 065 - training loss: 0.2597, validation loss: 0.3394
2024-06-02 21:21:23 [INFO]: Epoch 066 - training loss: 0.2592, validation loss: 0.3397
2024-06-02 21:21:25 [INFO]: Epoch 067 - training loss: 0.2614, validation loss: 0.3422
2024-06-02 21:21:26 [INFO]: Epoch 068 - training loss: 0.2505, validation loss: 0.3453
2024-06-02 21:21:27 [INFO]: Epoch 069 - training loss: 0.2479, validation loss: 0.3510
2024-06-02 21:21:28 [INFO]: Epoch 070 - training loss: 0.2488, validation loss: 0.3496
2024-06-02 21:21:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:21:28 [INFO]: Finished training. The best model is from epoch#60.
2024-06-02 21:21:28 [INFO]: Saved the model to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_4/20240602_T211943/Pyraformer.pypots
2024-06-02 21:21:29 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Pyraformer_Pedestrian/round_4/imputation.pkl
2024-06-02 21:21:29 [INFO]: Round4 - Pyraformer on Pedestrian: MAE=0.1979, MSE=0.3850, MRE=0.2604
2024-06-02 21:21:29 [INFO]: Done! Final results:
Averaged Pyraformer (957,057 params) on Pedestrian: MAE=0.2018 ± 0.00562898762410643, MSE=0.3814 ± 0.007332426929918634, MRE=0.2656 ± 0.0074072148078937194, average inference time=1.71
