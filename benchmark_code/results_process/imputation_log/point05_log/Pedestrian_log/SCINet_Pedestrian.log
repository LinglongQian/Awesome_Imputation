2024-06-02 21:04:45 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 21:04:45 [INFO]: Using the given device: cuda:0
2024-06-02 21:04:46 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_0/20240602_T210446
2024-06-02 21:04:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_0/20240602_T210446/tensorboard
2024-06-02 21:04:47 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-02 21:04:52 [INFO]: Epoch 001 - training loss: 1.5276, validation loss: 1.3861
2024-06-02 21:04:54 [INFO]: Epoch 002 - training loss: 1.4654, validation loss: 1.4129
2024-06-02 21:04:57 [INFO]: Epoch 003 - training loss: 1.4084, validation loss: 1.4423
2024-06-02 21:04:59 [INFO]: Epoch 004 - training loss: 1.3984, validation loss: 1.4498
2024-06-02 21:05:02 [INFO]: Epoch 005 - training loss: 1.3734, validation loss: 1.4551
2024-06-02 21:05:05 [INFO]: Epoch 006 - training loss: 1.3733, validation loss: 1.4450
2024-06-02 21:05:08 [INFO]: Epoch 007 - training loss: 1.3709, validation loss: 1.4448
2024-06-02 21:05:11 [INFO]: Epoch 008 - training loss: 1.3787, validation loss: 1.4484
2024-06-02 21:05:13 [INFO]: Epoch 009 - training loss: 1.3846, validation loss: 1.4274
2024-06-02 21:05:16 [INFO]: Epoch 010 - training loss: 1.3443, validation loss: 1.2711
2024-06-02 21:05:19 [INFO]: Epoch 011 - training loss: 1.1934, validation loss: 1.0137
2024-06-02 21:05:22 [INFO]: Epoch 012 - training loss: 0.9650, validation loss: 0.8289
2024-06-02 21:05:25 [INFO]: Epoch 013 - training loss: 0.8760, validation loss: 0.8078
2024-06-02 21:05:27 [INFO]: Epoch 014 - training loss: 0.8357, validation loss: 0.7838
2024-06-02 21:05:30 [INFO]: Epoch 015 - training loss: 0.7875, validation loss: 0.7616
2024-06-02 21:05:33 [INFO]: Epoch 016 - training loss: 0.7643, validation loss: 0.7628
2024-06-02 21:05:36 [INFO]: Epoch 017 - training loss: 0.7661, validation loss: 0.7433
2024-06-02 21:05:39 [INFO]: Epoch 018 - training loss: 0.7489, validation loss: 0.7318
2024-06-02 21:05:42 [INFO]: Epoch 019 - training loss: 0.7425, validation loss: 0.7075
2024-06-02 21:05:44 [INFO]: Epoch 020 - training loss: 0.7377, validation loss: 0.6990
2024-06-02 21:05:47 [INFO]: Epoch 021 - training loss: 0.7113, validation loss: 0.6741
2024-06-02 21:05:50 [INFO]: Epoch 022 - training loss: 0.6780, validation loss: 0.6675
2024-06-02 21:05:53 [INFO]: Epoch 023 - training loss: 0.6679, validation loss: 0.6540
2024-06-02 21:05:56 [INFO]: Epoch 024 - training loss: 0.6886, validation loss: 0.6487
2024-06-02 21:05:59 [INFO]: Epoch 025 - training loss: 0.6547, validation loss: 0.6366
2024-06-02 21:06:02 [INFO]: Epoch 026 - training loss: 0.6379, validation loss: 0.6651
2024-06-02 21:06:04 [INFO]: Epoch 027 - training loss: 0.6734, validation loss: 0.6094
2024-06-02 21:06:07 [INFO]: Epoch 028 - training loss: 0.6096, validation loss: 0.5957
2024-06-02 21:06:10 [INFO]: Epoch 029 - training loss: 0.6155, validation loss: 0.5942
2024-06-02 21:06:13 [INFO]: Epoch 030 - training loss: 0.6035, validation loss: 0.5683
2024-06-02 21:06:15 [INFO]: Epoch 031 - training loss: 0.6015, validation loss: 0.5555
2024-06-02 21:06:18 [INFO]: Epoch 032 - training loss: 0.5755, validation loss: 0.5406
2024-06-02 21:06:21 [INFO]: Epoch 033 - training loss: 0.5749, validation loss: 0.5523
2024-06-02 21:06:24 [INFO]: Epoch 034 - training loss: 0.5544, validation loss: 0.5182
2024-06-02 21:06:26 [INFO]: Epoch 035 - training loss: 0.5604, validation loss: 0.4990
2024-06-02 21:06:29 [INFO]: Epoch 036 - training loss: 0.5293, validation loss: 0.4285
2024-06-02 21:06:32 [INFO]: Epoch 037 - training loss: 0.5190, validation loss: 0.4631
2024-06-02 21:06:35 [INFO]: Epoch 038 - training loss: 0.5341, validation loss: 0.4393
2024-06-02 21:06:38 [INFO]: Epoch 039 - training loss: 0.5310, validation loss: 0.4146
2024-06-02 21:06:41 [INFO]: Epoch 040 - training loss: 0.5336, validation loss: 0.4304
2024-06-02 21:06:43 [INFO]: Epoch 041 - training loss: 0.5123, validation loss: 0.4184
2024-06-02 21:06:46 [INFO]: Epoch 042 - training loss: 0.5011, validation loss: 0.4144
2024-06-02 21:06:49 [INFO]: Epoch 043 - training loss: 0.4867, validation loss: 0.4192
2024-06-02 21:06:52 [INFO]: Epoch 044 - training loss: 0.5250, validation loss: 0.4118
2024-06-02 21:06:55 [INFO]: Epoch 045 - training loss: 0.4979, validation loss: 0.4227
2024-06-02 21:06:57 [INFO]: Epoch 046 - training loss: 0.5043, validation loss: 0.4108
2024-06-02 21:07:00 [INFO]: Epoch 047 - training loss: 0.4988, validation loss: 0.3965
2024-06-02 21:07:03 [INFO]: Epoch 048 - training loss: 0.4956, validation loss: 0.3973
2024-06-02 21:07:05 [INFO]: Epoch 049 - training loss: 0.4745, validation loss: 0.3941
2024-06-02 21:07:09 [INFO]: Epoch 050 - training loss: 0.4942, validation loss: 0.3756
2024-06-02 21:07:11 [INFO]: Epoch 051 - training loss: 0.4652, validation loss: 0.4017
2024-06-02 21:07:14 [INFO]: Epoch 052 - training loss: 0.4798, validation loss: 0.4040
2024-06-02 21:07:17 [INFO]: Epoch 053 - training loss: 0.4911, validation loss: 0.3975
2024-06-02 21:07:19 [INFO]: Epoch 054 - training loss: 0.4808, validation loss: 0.3904
2024-06-02 21:07:22 [INFO]: Epoch 055 - training loss: 0.4741, validation loss: 0.3842
2024-06-02 21:07:25 [INFO]: Epoch 056 - training loss: 0.4707, validation loss: 0.3800
2024-06-02 21:07:28 [INFO]: Epoch 057 - training loss: 0.4724, validation loss: 0.3662
2024-06-02 21:07:31 [INFO]: Epoch 058 - training loss: 0.4640, validation loss: 0.3997
2024-06-02 21:07:34 [INFO]: Epoch 059 - training loss: 0.4724, validation loss: 0.3916
2024-06-02 21:07:37 [INFO]: Epoch 060 - training loss: 0.4736, validation loss: 0.3750
2024-06-02 21:07:39 [INFO]: Epoch 061 - training loss: 0.4811, validation loss: 0.3652
2024-06-02 21:07:42 [INFO]: Epoch 062 - training loss: 0.4782, validation loss: 0.3703
2024-06-02 21:07:45 [INFO]: Epoch 063 - training loss: 0.4795, validation loss: 0.3758
2024-06-02 21:07:48 [INFO]: Epoch 064 - training loss: 0.4551, validation loss: 0.3697
2024-06-02 21:07:51 [INFO]: Epoch 065 - training loss: 0.4620, validation loss: 0.3884
2024-06-02 21:07:53 [INFO]: Epoch 066 - training loss: 0.4562, validation loss: 0.3796
2024-06-02 21:07:56 [INFO]: Epoch 067 - training loss: 0.4686, validation loss: 0.3643
2024-06-02 21:07:59 [INFO]: Epoch 068 - training loss: 0.4512, validation loss: 0.3619
2024-06-02 21:08:02 [INFO]: Epoch 069 - training loss: 0.4676, validation loss: 0.3741
2024-06-02 21:08:04 [INFO]: Epoch 070 - training loss: 0.4550, validation loss: 0.3601
2024-06-02 21:08:07 [INFO]: Epoch 071 - training loss: 0.4798, validation loss: 0.3630
2024-06-02 21:08:10 [INFO]: Epoch 072 - training loss: 0.4570, validation loss: 0.3653
2024-06-02 21:08:13 [INFO]: Epoch 073 - training loss: 0.4560, validation loss: 0.3578
2024-06-02 21:08:16 [INFO]: Epoch 074 - training loss: 0.4636, validation loss: 0.3641
2024-06-02 21:08:19 [INFO]: Epoch 075 - training loss: 0.4648, validation loss: 0.3714
2024-06-02 21:08:22 [INFO]: Epoch 076 - training loss: 0.4654, validation loss: 0.3628
2024-06-02 21:08:24 [INFO]: Epoch 077 - training loss: 0.4315, validation loss: 0.3529
2024-06-02 21:08:27 [INFO]: Epoch 078 - training loss: 0.4472, validation loss: 0.3499
2024-06-02 21:08:30 [INFO]: Epoch 079 - training loss: 0.4737, validation loss: 0.3577
2024-06-02 21:08:33 [INFO]: Epoch 080 - training loss: 0.4681, validation loss: 0.3639
2024-06-02 21:08:36 [INFO]: Epoch 081 - training loss: 0.4437, validation loss: 0.3555
2024-06-02 21:08:38 [INFO]: Epoch 082 - training loss: 0.4507, validation loss: 0.3614
2024-06-02 21:08:41 [INFO]: Epoch 083 - training loss: 0.4420, validation loss: 0.3595
2024-06-02 21:08:44 [INFO]: Epoch 084 - training loss: 0.4484, validation loss: 0.3944
2024-06-02 21:08:47 [INFO]: Epoch 085 - training loss: 0.4976, validation loss: 0.3484
2024-06-02 21:08:49 [INFO]: Epoch 086 - training loss: 0.4435, validation loss: 0.3451
2024-06-02 21:08:52 [INFO]: Epoch 087 - training loss: 0.4658, validation loss: 0.3589
2024-06-02 21:08:55 [INFO]: Epoch 088 - training loss: 0.4581, validation loss: 0.3522
2024-06-02 21:08:58 [INFO]: Epoch 089 - training loss: 0.4468, validation loss: 0.3583
2024-06-02 21:09:00 [INFO]: Epoch 090 - training loss: 0.4343, validation loss: 0.3700
2024-06-02 21:09:03 [INFO]: Epoch 091 - training loss: 0.4637, validation loss: 0.3555
2024-06-02 21:09:06 [INFO]: Epoch 092 - training loss: 0.4631, validation loss: 0.3623
2024-06-02 21:09:09 [INFO]: Epoch 093 - training loss: 0.4561, validation loss: 0.3510
2024-06-02 21:09:12 [INFO]: Epoch 094 - training loss: 0.4699, validation loss: 0.3639
2024-06-02 21:09:14 [INFO]: Epoch 095 - training loss: 0.4504, validation loss: 0.3558
2024-06-02 21:09:17 [INFO]: Epoch 096 - training loss: 0.4539, validation loss: 0.3477
2024-06-02 21:09:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:09:17 [INFO]: Finished training. The best model is from epoch#86.
2024-06-02 21:09:17 [INFO]: Saved the model to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_0/20240602_T210446/SCINet.pypots
2024-06-02 21:09:21 [INFO]: Successfully saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_0/imputation.pkl
2024-06-02 21:09:21 [INFO]: Round0 - SCINet on Pedestrian: MAE=0.2510, MSE=0.3927, MRE=0.3303
2024-06-02 21:09:21 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 21:09:21 [INFO]: Using the given device: cuda:0
2024-06-02 21:09:21 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_1/20240602_T210921
2024-06-02 21:09:21 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_1/20240602_T210921/tensorboard
2024-06-02 21:09:21 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-02 21:09:24 [INFO]: Epoch 001 - training loss: 1.4749, validation loss: 1.3311
2024-06-02 21:09:27 [INFO]: Epoch 002 - training loss: 1.3327, validation loss: 1.1866
2024-06-02 21:09:29 [INFO]: Epoch 003 - training loss: 1.1340, validation loss: 0.9470
2024-06-02 21:09:32 [INFO]: Epoch 004 - training loss: 0.9421, validation loss: 0.8060
2024-06-02 21:09:35 [INFO]: Epoch 005 - training loss: 0.8310, validation loss: 0.7545
2024-06-02 21:09:38 [INFO]: Epoch 006 - training loss: 0.7843, validation loss: 0.7146
2024-06-02 21:09:40 [INFO]: Epoch 007 - training loss: 0.7514, validation loss: 0.6922
2024-06-02 21:09:43 [INFO]: Epoch 008 - training loss: 0.7168, validation loss: 0.6802
2024-06-02 21:09:46 [INFO]: Epoch 009 - training loss: 0.7101, validation loss: 0.6724
2024-06-02 21:09:49 [INFO]: Epoch 010 - training loss: 0.6821, validation loss: 0.6420
2024-06-02 21:09:52 [INFO]: Epoch 011 - training loss: 0.6638, validation loss: 0.6296
2024-06-02 21:09:54 [INFO]: Epoch 012 - training loss: 0.6464, validation loss: 0.5984
2024-06-02 21:09:57 [INFO]: Epoch 013 - training loss: 0.6533, validation loss: 0.6040
2024-06-02 21:10:00 [INFO]: Epoch 014 - training loss: 0.6191, validation loss: 0.5814
2024-06-02 21:10:03 [INFO]: Epoch 015 - training loss: 0.6157, validation loss: 0.5701
2024-06-02 21:10:06 [INFO]: Epoch 016 - training loss: 0.5895, validation loss: 0.5495
2024-06-02 21:10:09 [INFO]: Epoch 017 - training loss: 0.5877, validation loss: 0.5286
2024-06-02 21:10:11 [INFO]: Epoch 018 - training loss: 0.5631, validation loss: 0.5399
2024-06-02 21:10:14 [INFO]: Epoch 019 - training loss: 0.5755, validation loss: 0.5278
2024-06-02 21:10:17 [INFO]: Epoch 020 - training loss: 0.5318, validation loss: 0.5157
2024-06-02 21:10:20 [INFO]: Epoch 021 - training loss: 0.5208, validation loss: 0.5099
2024-06-02 21:10:23 [INFO]: Epoch 022 - training loss: 0.5220, validation loss: 0.4905
2024-06-02 21:10:26 [INFO]: Epoch 023 - training loss: 0.5228, validation loss: 0.4806
2024-06-02 21:10:28 [INFO]: Epoch 024 - training loss: 0.5129, validation loss: 0.4775
2024-06-02 21:10:31 [INFO]: Epoch 025 - training loss: 0.4917, validation loss: 0.4708
2024-06-02 21:10:34 [INFO]: Epoch 026 - training loss: 0.4960, validation loss: 0.4618
2024-06-02 21:10:38 [INFO]: Epoch 027 - training loss: 0.5077, validation loss: 0.4487
2024-06-02 21:10:40 [INFO]: Epoch 028 - training loss: 0.5269, validation loss: 0.4445
2024-06-02 21:10:43 [INFO]: Epoch 029 - training loss: 0.4946, validation loss: 0.4327
2024-06-02 21:10:46 [INFO]: Epoch 030 - training loss: 0.5026, validation loss: 0.4325
2024-06-02 21:10:49 [INFO]: Epoch 031 - training loss: 0.4784, validation loss: 0.4305
2024-06-02 21:10:52 [INFO]: Epoch 032 - training loss: 0.4780, validation loss: 0.4305
2024-06-02 21:10:55 [INFO]: Epoch 033 - training loss: 0.4883, validation loss: 0.4358
2024-06-02 21:10:58 [INFO]: Epoch 034 - training loss: 0.4849, validation loss: 0.4124
2024-06-02 21:11:01 [INFO]: Epoch 035 - training loss: 0.4987, validation loss: 0.4171
2024-06-02 21:11:03 [INFO]: Epoch 036 - training loss: 0.4614, validation loss: 0.4230
2024-06-02 21:11:06 [INFO]: Epoch 037 - training loss: 0.4685, validation loss: 0.4102
2024-06-02 21:11:09 [INFO]: Epoch 038 - training loss: 0.4689, validation loss: 0.3986
2024-06-02 21:11:12 [INFO]: Epoch 039 - training loss: 0.4691, validation loss: 0.3900
2024-06-02 21:11:15 [INFO]: Epoch 040 - training loss: 0.4691, validation loss: 0.3966
2024-06-02 21:11:18 [INFO]: Epoch 041 - training loss: 0.4581, validation loss: 0.3853
2024-06-02 21:11:21 [INFO]: Epoch 042 - training loss: 0.4511, validation loss: 0.3926
2024-06-02 21:11:24 [INFO]: Epoch 043 - training loss: 0.4550, validation loss: 0.3889
2024-06-02 21:11:27 [INFO]: Epoch 044 - training loss: 0.4544, validation loss: 0.3758
2024-06-02 21:11:29 [INFO]: Epoch 045 - training loss: 0.4467, validation loss: 0.3766
2024-06-02 21:11:32 [INFO]: Epoch 046 - training loss: 0.4617, validation loss: 0.3833
2024-06-02 21:11:35 [INFO]: Epoch 047 - training loss: 0.4533, validation loss: 0.3643
2024-06-02 21:11:37 [INFO]: Epoch 048 - training loss: 0.4330, validation loss: 0.3813
2024-06-02 21:11:40 [INFO]: Epoch 049 - training loss: 0.4367, validation loss: 0.3691
2024-06-02 21:11:43 [INFO]: Epoch 050 - training loss: 0.4431, validation loss: 0.3647
2024-06-02 21:11:46 [INFO]: Epoch 051 - training loss: 0.4155, validation loss: 0.3683
2024-06-02 21:11:49 [INFO]: Epoch 052 - training loss: 0.4383, validation loss: 0.3753
2024-06-02 21:11:52 [INFO]: Epoch 053 - training loss: 0.4424, validation loss: 0.3914
2024-06-02 21:11:55 [INFO]: Epoch 054 - training loss: 0.4269, validation loss: 0.3676
2024-06-02 21:11:57 [INFO]: Epoch 055 - training loss: 0.4370, validation loss: 0.3696
2024-06-02 21:12:00 [INFO]: Epoch 056 - training loss: 0.4228, validation loss: 0.3734
2024-06-02 21:12:03 [INFO]: Epoch 057 - training loss: 0.4387, validation loss: 0.3716
2024-06-02 21:12:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:12:03 [INFO]: Finished training. The best model is from epoch#47.
2024-06-02 21:12:03 [INFO]: Saved the model to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_1/20240602_T210921/SCINet.pypots
2024-06-02 21:12:07 [INFO]: Successfully saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_1/imputation.pkl
2024-06-02 21:12:07 [INFO]: Round1 - SCINet on Pedestrian: MAE=0.2485, MSE=0.4066, MRE=0.3270
2024-06-02 21:12:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 21:12:07 [INFO]: Using the given device: cuda:0
2024-06-02 21:12:07 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_2/20240602_T211207
2024-06-02 21:12:07 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_2/20240602_T211207/tensorboard
2024-06-02 21:12:07 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-02 21:12:10 [INFO]: Epoch 001 - training loss: 1.5109, validation loss: 1.3649
2024-06-02 21:12:13 [INFO]: Epoch 002 - training loss: 1.3886, validation loss: 1.2339
2024-06-02 21:12:16 [INFO]: Epoch 003 - training loss: 1.1123, validation loss: 0.9587
2024-06-02 21:12:18 [INFO]: Epoch 004 - training loss: 0.8903, validation loss: 0.8505
2024-06-02 21:12:21 [INFO]: Epoch 005 - training loss: 0.8071, validation loss: 0.8048
2024-06-02 21:12:24 [INFO]: Epoch 006 - training loss: 0.7687, validation loss: 0.7729
2024-06-02 21:12:27 [INFO]: Epoch 007 - training loss: 0.7554, validation loss: 0.7467
2024-06-02 21:12:29 [INFO]: Epoch 008 - training loss: 0.7330, validation loss: 0.7217
2024-06-02 21:12:32 [INFO]: Epoch 009 - training loss: 0.7105, validation loss: 0.7031
2024-06-02 21:12:35 [INFO]: Epoch 010 - training loss: 0.6965, validation loss: 0.6697
2024-06-02 21:12:38 [INFO]: Epoch 011 - training loss: 0.6622, validation loss: 0.6510
2024-06-02 21:12:41 [INFO]: Epoch 012 - training loss: 0.6518, validation loss: 0.6345
2024-06-02 21:12:44 [INFO]: Epoch 013 - training loss: 0.6205, validation loss: 0.5979
2024-06-02 21:12:47 [INFO]: Epoch 014 - training loss: 0.6064, validation loss: 0.5816
2024-06-02 21:12:49 [INFO]: Epoch 015 - training loss: 0.5886, validation loss: 0.5642
2024-06-02 21:12:52 [INFO]: Epoch 016 - training loss: 0.5668, validation loss: 0.5523
2024-06-02 21:12:55 [INFO]: Epoch 017 - training loss: 0.5384, validation loss: 0.5340
2024-06-02 21:12:58 [INFO]: Epoch 018 - training loss: 0.5459, validation loss: 0.5318
2024-06-02 21:13:01 [INFO]: Epoch 019 - training loss: 0.5264, validation loss: 0.5066
2024-06-02 21:13:04 [INFO]: Epoch 020 - training loss: 0.5076, validation loss: 0.4926
2024-06-02 21:13:06 [INFO]: Epoch 021 - training loss: 0.5082, validation loss: 0.4836
2024-06-02 21:13:09 [INFO]: Epoch 022 - training loss: 0.5201, validation loss: 0.4754
2024-06-02 21:13:12 [INFO]: Epoch 023 - training loss: 0.5223, validation loss: 0.4517
2024-06-02 21:13:15 [INFO]: Epoch 024 - training loss: 0.5071, validation loss: 0.4523
2024-06-02 21:13:17 [INFO]: Epoch 025 - training loss: 0.4915, validation loss: 0.4419
2024-06-02 21:13:20 [INFO]: Epoch 026 - training loss: 0.4968, validation loss: 0.4273
2024-06-02 21:13:23 [INFO]: Epoch 027 - training loss: 0.4805, validation loss: 0.4199
2024-06-02 21:13:26 [INFO]: Epoch 028 - training loss: 0.4664, validation loss: 0.4191
2024-06-02 21:13:29 [INFO]: Epoch 029 - training loss: 0.4915, validation loss: 0.4161
2024-06-02 21:13:31 [INFO]: Epoch 030 - training loss: 0.4770, validation loss: 0.3971
2024-06-02 21:13:34 [INFO]: Epoch 031 - training loss: 0.4519, validation loss: 0.4055
2024-06-02 21:13:37 [INFO]: Epoch 032 - training loss: 0.4625, validation loss: 0.3983
2024-06-02 21:13:40 [INFO]: Epoch 033 - training loss: 0.4773, validation loss: 0.3898
2024-06-02 21:13:43 [INFO]: Epoch 034 - training loss: 0.4632, validation loss: 0.3850
2024-06-02 21:13:46 [INFO]: Epoch 035 - training loss: 0.4529, validation loss: 0.4049
2024-06-02 21:13:48 [INFO]: Epoch 036 - training loss: 0.4650, validation loss: 0.4001
2024-06-02 21:13:51 [INFO]: Epoch 037 - training loss: 0.4503, validation loss: 0.3851
2024-06-02 21:13:54 [INFO]: Epoch 038 - training loss: 0.4596, validation loss: 0.3759
2024-06-02 21:13:56 [INFO]: Epoch 039 - training loss: 0.4565, validation loss: 0.3703
2024-06-02 21:13:59 [INFO]: Epoch 040 - training loss: 0.4431, validation loss: 0.3719
2024-06-02 21:14:02 [INFO]: Epoch 041 - training loss: 0.4445, validation loss: 0.3668
2024-06-02 21:14:05 [INFO]: Epoch 042 - training loss: 0.4386, validation loss: 0.3732
2024-06-02 21:14:07 [INFO]: Epoch 043 - training loss: 0.4500, validation loss: 0.3679
2024-06-02 21:14:10 [INFO]: Epoch 044 - training loss: 0.4498, validation loss: 0.3745
2024-06-02 21:14:13 [INFO]: Epoch 045 - training loss: 0.4535, validation loss: 0.3621
2024-06-02 21:14:16 [INFO]: Epoch 046 - training loss: 0.4421, validation loss: 0.3590
2024-06-02 21:14:18 [INFO]: Epoch 047 - training loss: 0.4517, validation loss: 0.3649
2024-06-02 21:14:21 [INFO]: Epoch 048 - training loss: 0.4411, validation loss: 0.3679
2024-06-02 21:14:25 [INFO]: Epoch 049 - training loss: 0.4296, validation loss: 0.3592
2024-06-02 21:14:27 [INFO]: Epoch 050 - training loss: 0.4249, validation loss: 0.3743
2024-06-02 21:14:30 [INFO]: Epoch 051 - training loss: 0.4181, validation loss: 0.3523
2024-06-02 21:14:34 [INFO]: Epoch 052 - training loss: 0.4292, validation loss: 0.3578
2024-06-02 21:14:36 [INFO]: Epoch 053 - training loss: 0.4387, validation loss: 0.3622
2024-06-02 21:14:39 [INFO]: Epoch 054 - training loss: 0.4360, validation loss: 0.3549
2024-06-02 21:14:42 [INFO]: Epoch 055 - training loss: 0.4210, validation loss: 0.3539
2024-06-02 21:14:44 [INFO]: Epoch 056 - training loss: 0.4367, validation loss: 0.3595
2024-06-02 21:14:47 [INFO]: Epoch 057 - training loss: 0.4103, validation loss: 0.3564
2024-06-02 21:14:50 [INFO]: Epoch 058 - training loss: 0.4279, validation loss: 0.3519
2024-06-02 21:14:53 [INFO]: Epoch 059 - training loss: 0.4322, validation loss: 0.3523
2024-06-02 21:14:56 [INFO]: Epoch 060 - training loss: 0.4141, validation loss: 0.3611
2024-06-02 21:14:59 [INFO]: Epoch 061 - training loss: 0.4157, validation loss: 0.3506
2024-06-02 21:15:02 [INFO]: Epoch 062 - training loss: 0.4275, validation loss: 0.3556
2024-06-02 21:15:05 [INFO]: Epoch 063 - training loss: 0.4265, validation loss: 0.3508
2024-06-02 21:15:08 [INFO]: Epoch 064 - training loss: 0.4162, validation loss: 0.3437
2024-06-02 21:15:10 [INFO]: Epoch 065 - training loss: 0.4132, validation loss: 0.3446
2024-06-02 21:15:13 [INFO]: Epoch 066 - training loss: 0.4076, validation loss: 0.3471
2024-06-02 21:15:16 [INFO]: Epoch 067 - training loss: 0.4204, validation loss: 0.3624
2024-06-02 21:15:19 [INFO]: Epoch 068 - training loss: 0.4350, validation loss: 0.3488
2024-06-02 21:15:22 [INFO]: Epoch 069 - training loss: 0.4135, validation loss: 0.3531
2024-06-02 21:15:25 [INFO]: Epoch 070 - training loss: 0.4194, validation loss: 0.3543
2024-06-02 21:15:28 [INFO]: Epoch 071 - training loss: 0.4022, validation loss: 0.3505
2024-06-02 21:15:30 [INFO]: Epoch 072 - training loss: 0.4032, validation loss: 0.3334
2024-06-02 21:15:33 [INFO]: Epoch 073 - training loss: 0.4040, validation loss: 0.3291
2024-06-02 21:15:36 [INFO]: Epoch 074 - training loss: 0.4172, validation loss: 0.3296
2024-06-02 21:15:39 [INFO]: Epoch 075 - training loss: 0.4130, validation loss: 0.3381
2024-06-02 21:15:42 [INFO]: Epoch 076 - training loss: 0.4052, validation loss: 0.3484
2024-06-02 21:15:44 [INFO]: Epoch 077 - training loss: 0.4055, validation loss: 0.3463
2024-06-02 21:15:48 [INFO]: Epoch 078 - training loss: 0.4035, validation loss: 0.3489
2024-06-02 21:15:50 [INFO]: Epoch 079 - training loss: 0.4013, validation loss: 0.3299
2024-06-02 21:15:53 [INFO]: Epoch 080 - training loss: 0.4032, validation loss: 0.3350
2024-06-02 21:15:56 [INFO]: Epoch 081 - training loss: 0.4023, validation loss: 0.3336
2024-06-02 21:15:59 [INFO]: Epoch 082 - training loss: 0.4160, validation loss: 0.3411
2024-06-02 21:16:02 [INFO]: Epoch 083 - training loss: 0.4176, validation loss: 0.3479
2024-06-02 21:16:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:16:02 [INFO]: Finished training. The best model is from epoch#73.
2024-06-02 21:16:02 [INFO]: Saved the model to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_2/20240602_T211207/SCINet.pypots
2024-06-02 21:16:06 [INFO]: Successfully saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_2/imputation.pkl
2024-06-02 21:16:06 [INFO]: Round2 - SCINet on Pedestrian: MAE=0.2500, MSE=0.3935, MRE=0.3289
2024-06-02 21:16:06 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 21:16:06 [INFO]: Using the given device: cuda:0
2024-06-02 21:16:06 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_3/20240602_T211606
2024-06-02 21:16:06 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_3/20240602_T211606/tensorboard
2024-06-02 21:16:06 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-02 21:16:09 [INFO]: Epoch 001 - training loss: 1.4492, validation loss: 1.2312
2024-06-02 21:16:11 [INFO]: Epoch 002 - training loss: 1.2402, validation loss: 1.0364
2024-06-02 21:16:14 [INFO]: Epoch 003 - training loss: 1.0127, validation loss: 0.8532
2024-06-02 21:16:17 [INFO]: Epoch 004 - training loss: 0.8984, validation loss: 0.8138
2024-06-02 21:16:20 [INFO]: Epoch 005 - training loss: 0.8181, validation loss: 0.7654
2024-06-02 21:16:23 [INFO]: Epoch 006 - training loss: 0.7875, validation loss: 0.8171
2024-06-02 21:16:26 [INFO]: Epoch 007 - training loss: 0.7596, validation loss: 0.7287
2024-06-02 21:16:28 [INFO]: Epoch 008 - training loss: 0.7182, validation loss: 0.6951
2024-06-02 21:16:31 [INFO]: Epoch 009 - training loss: 0.6979, validation loss: 0.6342
2024-06-02 21:16:34 [INFO]: Epoch 010 - training loss: 0.6666, validation loss: 0.6028
2024-06-02 21:16:37 [INFO]: Epoch 011 - training loss: 0.6390, validation loss: 0.5873
2024-06-02 21:16:40 [INFO]: Epoch 012 - training loss: 0.6149, validation loss: 0.5782
2024-06-02 21:16:42 [INFO]: Epoch 013 - training loss: 0.5883, validation loss: 0.5629
2024-06-02 21:16:45 [INFO]: Epoch 014 - training loss: 0.6076, validation loss: 0.5463
2024-06-02 21:16:48 [INFO]: Epoch 015 - training loss: 0.5692, validation loss: 0.5457
2024-06-02 21:16:51 [INFO]: Epoch 016 - training loss: 0.5746, validation loss: 0.5192
2024-06-02 21:16:54 [INFO]: Epoch 017 - training loss: 0.5702, validation loss: 0.5149
2024-06-02 21:16:56 [INFO]: Epoch 018 - training loss: 0.5703, validation loss: 0.5035
2024-06-02 21:16:59 [INFO]: Epoch 019 - training loss: 0.5496, validation loss: 0.4913
2024-06-02 21:17:01 [INFO]: Epoch 020 - training loss: 0.5436, validation loss: 0.4692
2024-06-02 21:17:03 [INFO]: Epoch 021 - training loss: 0.5384, validation loss: 0.4780
2024-06-02 21:17:06 [INFO]: Epoch 022 - training loss: 0.5360, validation loss: 0.4636
2024-06-02 21:17:08 [INFO]: Epoch 023 - training loss: 0.5202, validation loss: 0.4613
2024-06-02 21:17:11 [INFO]: Epoch 024 - training loss: 0.5164, validation loss: 0.4607
2024-06-02 21:17:14 [INFO]: Epoch 025 - training loss: 0.5088, validation loss: 0.4283
2024-06-02 21:17:16 [INFO]: Epoch 026 - training loss: 0.4974, validation loss: 0.4187
2024-06-02 21:17:19 [INFO]: Epoch 027 - training loss: 0.5042, validation loss: 0.4211
2024-06-02 21:17:21 [INFO]: Epoch 028 - training loss: 0.4886, validation loss: 0.4102
2024-06-02 21:17:24 [INFO]: Epoch 029 - training loss: 0.5026, validation loss: 0.4145
2024-06-02 21:17:26 [INFO]: Epoch 030 - training loss: 0.5004, validation loss: 0.4135
2024-06-02 21:17:29 [INFO]: Epoch 031 - training loss: 0.4813, validation loss: 0.4060
2024-06-02 21:17:32 [INFO]: Epoch 032 - training loss: 0.4846, validation loss: 0.4134
2024-06-02 21:17:34 [INFO]: Epoch 033 - training loss: 0.4886, validation loss: 0.4018
2024-06-02 21:17:37 [INFO]: Epoch 034 - training loss: 0.5080, validation loss: 0.4159
2024-06-02 21:17:39 [INFO]: Epoch 035 - training loss: 0.4842, validation loss: 0.4016
2024-06-02 21:17:41 [INFO]: Epoch 036 - training loss: 0.4845, validation loss: 0.3918
2024-06-02 21:17:43 [INFO]: Epoch 037 - training loss: 0.4712, validation loss: 0.3930
2024-06-02 21:17:45 [INFO]: Epoch 038 - training loss: 0.4892, validation loss: 0.3868
2024-06-02 21:17:47 [INFO]: Epoch 039 - training loss: 0.4625, validation loss: 0.3859
2024-06-02 21:17:49 [INFO]: Epoch 040 - training loss: 0.4828, validation loss: 0.3931
2024-06-02 21:17:50 [INFO]: Epoch 041 - training loss: 0.4726, validation loss: 0.3890
2024-06-02 21:17:52 [INFO]: Epoch 042 - training loss: 0.4768, validation loss: 0.3770
2024-06-02 21:17:54 [INFO]: Epoch 043 - training loss: 0.4655, validation loss: 0.3741
2024-06-02 21:17:56 [INFO]: Epoch 044 - training loss: 0.4667, validation loss: 0.3806
2024-06-02 21:17:58 [INFO]: Epoch 045 - training loss: 0.4559, validation loss: 0.3751
2024-06-02 21:17:59 [INFO]: Epoch 046 - training loss: 0.4639, validation loss: 0.3750
2024-06-02 21:18:01 [INFO]: Epoch 047 - training loss: 0.4737, validation loss: 0.3808
2024-06-02 21:18:03 [INFO]: Epoch 048 - training loss: 0.4589, validation loss: 0.3692
2024-06-02 21:18:04 [INFO]: Epoch 049 - training loss: 0.4618, validation loss: 0.3721
2024-06-02 21:18:06 [INFO]: Epoch 050 - training loss: 0.4622, validation loss: 0.3608
2024-06-02 21:18:08 [INFO]: Epoch 051 - training loss: 0.4679, validation loss: 0.3627
2024-06-02 21:18:09 [INFO]: Epoch 052 - training loss: 0.4515, validation loss: 0.3660
2024-06-02 21:18:11 [INFO]: Epoch 053 - training loss: 0.4432, validation loss: 0.3586
2024-06-02 21:18:12 [INFO]: Epoch 054 - training loss: 0.4380, validation loss: 0.3666
2024-06-02 21:18:14 [INFO]: Epoch 055 - training loss: 0.4367, validation loss: 0.3568
2024-06-02 21:18:15 [INFO]: Epoch 056 - training loss: 0.4400, validation loss: 0.3517
2024-06-02 21:18:17 [INFO]: Epoch 057 - training loss: 0.4424, validation loss: 0.3504
2024-06-02 21:18:19 [INFO]: Epoch 058 - training loss: 0.4446, validation loss: 0.3553
2024-06-02 21:18:20 [INFO]: Epoch 059 - training loss: 0.4616, validation loss: 0.3557
2024-06-02 21:18:22 [INFO]: Epoch 060 - training loss: 0.4452, validation loss: 0.3573
2024-06-02 21:18:23 [INFO]: Epoch 061 - training loss: 0.4381, validation loss: 0.3565
2024-06-02 21:18:25 [INFO]: Epoch 062 - training loss: 0.4423, validation loss: 0.3568
2024-06-02 21:18:26 [INFO]: Epoch 063 - training loss: 0.4471, validation loss: 0.3504
2024-06-02 21:18:28 [INFO]: Epoch 064 - training loss: 0.4420, validation loss: 0.3556
2024-06-02 21:18:30 [INFO]: Epoch 065 - training loss: 0.4356, validation loss: 0.3585
2024-06-02 21:18:31 [INFO]: Epoch 066 - training loss: 0.4375, validation loss: 0.3559
2024-06-02 21:18:33 [INFO]: Epoch 067 - training loss: 0.4433, validation loss: 0.3480
2024-06-02 21:18:35 [INFO]: Epoch 068 - training loss: 0.4509, validation loss: 0.3519
2024-06-02 21:18:36 [INFO]: Epoch 069 - training loss: 0.4463, validation loss: 0.3563
2024-06-02 21:18:38 [INFO]: Epoch 070 - training loss: 0.4391, validation loss: 0.3466
2024-06-02 21:18:39 [INFO]: Epoch 071 - training loss: 0.4339, validation loss: 0.3503
2024-06-02 21:18:41 [INFO]: Epoch 072 - training loss: 0.4150, validation loss: 0.3466
2024-06-02 21:18:43 [INFO]: Epoch 073 - training loss: 0.4256, validation loss: 0.3513
2024-06-02 21:18:44 [INFO]: Epoch 074 - training loss: 0.4284, validation loss: 0.3578
2024-06-02 21:18:46 [INFO]: Epoch 075 - training loss: 0.4463, validation loss: 0.3543
2024-06-02 21:18:47 [INFO]: Epoch 076 - training loss: 0.4271, validation loss: 0.3603
2024-06-02 21:18:49 [INFO]: Epoch 077 - training loss: 0.4321, validation loss: 0.3520
2024-06-02 21:18:50 [INFO]: Epoch 078 - training loss: 0.4180, validation loss: 0.3527
2024-06-02 21:18:52 [INFO]: Epoch 079 - training loss: 0.4313, validation loss: 0.3639
2024-06-02 21:18:54 [INFO]: Epoch 080 - training loss: 0.4259, validation loss: 0.3590
2024-06-02 21:18:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:18:54 [INFO]: Finished training. The best model is from epoch#70.
2024-06-02 21:18:54 [INFO]: Saved the model to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_3/20240602_T211606/SCINet.pypots
2024-06-02 21:18:56 [INFO]: Successfully saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_3/imputation.pkl
2024-06-02 21:18:56 [INFO]: Round3 - SCINet on Pedestrian: MAE=0.2609, MSE=0.3969, MRE=0.3434
2024-06-02 21:18:56 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 21:18:56 [INFO]: Using the given device: cuda:0
2024-06-02 21:18:56 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_4/20240602_T211856
2024-06-02 21:18:56 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_4/20240602_T211856/tensorboard
2024-06-02 21:18:56 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 43,783
2024-06-02 21:18:57 [INFO]: Epoch 001 - training loss: 1.4913, validation loss: 1.3683
2024-06-02 21:18:59 [INFO]: Epoch 002 - training loss: 1.3271, validation loss: 1.1350
2024-06-02 21:19:00 [INFO]: Epoch 003 - training loss: 1.0443, validation loss: 0.9268
2024-06-02 21:19:02 [INFO]: Epoch 004 - training loss: 0.8755, validation loss: 0.7958
2024-06-02 21:19:03 [INFO]: Epoch 005 - training loss: 0.8267, validation loss: 0.8070
2024-06-02 21:19:05 [INFO]: Epoch 006 - training loss: 0.8029, validation loss: 0.7462
2024-06-02 21:19:06 [INFO]: Epoch 007 - training loss: 0.7745, validation loss: 0.7220
2024-06-02 21:19:08 [INFO]: Epoch 008 - training loss: 0.7411, validation loss: 0.7067
2024-06-02 21:19:10 [INFO]: Epoch 009 - training loss: 0.7238, validation loss: 0.6863
2024-06-02 21:19:11 [INFO]: Epoch 010 - training loss: 0.7092, validation loss: 0.6700
2024-06-02 21:19:13 [INFO]: Epoch 011 - training loss: 0.6864, validation loss: 0.6483
2024-06-02 21:19:14 [INFO]: Epoch 012 - training loss: 0.6663, validation loss: 0.6212
2024-06-02 21:19:16 [INFO]: Epoch 013 - training loss: 0.6552, validation loss: 0.6026
2024-06-02 21:19:18 [INFO]: Epoch 014 - training loss: 0.6479, validation loss: 0.5749
2024-06-02 21:19:19 [INFO]: Epoch 015 - training loss: 0.6268, validation loss: 0.5729
2024-06-02 21:19:21 [INFO]: Epoch 016 - training loss: 0.5999, validation loss: 0.5711
2024-06-02 21:19:23 [INFO]: Epoch 017 - training loss: 0.6151, validation loss: 0.5274
2024-06-02 21:19:24 [INFO]: Epoch 018 - training loss: 0.5753, validation loss: 0.5339
2024-06-02 21:19:26 [INFO]: Epoch 019 - training loss: 0.5740, validation loss: 0.4967
2024-06-02 21:19:27 [INFO]: Epoch 020 - training loss: 0.5669, validation loss: 0.5030
2024-06-02 21:19:29 [INFO]: Epoch 021 - training loss: 0.5661, validation loss: 0.4716
2024-06-02 21:19:30 [INFO]: Epoch 022 - training loss: 0.5720, validation loss: 0.4824
2024-06-02 21:19:31 [INFO]: Epoch 023 - training loss: 0.5657, validation loss: 0.4703
2024-06-02 21:19:33 [INFO]: Epoch 024 - training loss: 0.5457, validation loss: 0.4591
2024-06-02 21:19:35 [INFO]: Epoch 025 - training loss: 0.5343, validation loss: 0.4522
2024-06-02 21:19:37 [INFO]: Epoch 026 - training loss: 0.5424, validation loss: 0.4514
2024-06-02 21:19:38 [INFO]: Epoch 027 - training loss: 0.5405, validation loss: 0.4542
2024-06-02 21:19:40 [INFO]: Epoch 028 - training loss: 0.5306, validation loss: 0.4573
2024-06-02 21:19:42 [INFO]: Epoch 029 - training loss: 0.5226, validation loss: 0.4330
2024-06-02 21:19:43 [INFO]: Epoch 030 - training loss: 0.5113, validation loss: 0.4272
2024-06-02 21:19:45 [INFO]: Epoch 031 - training loss: 0.5246, validation loss: 0.4360
2024-06-02 21:19:47 [INFO]: Epoch 032 - training loss: 0.5369, validation loss: 0.4227
2024-06-02 21:19:48 [INFO]: Epoch 033 - training loss: 0.4906, validation loss: 0.4328
2024-06-02 21:19:50 [INFO]: Epoch 034 - training loss: 0.5123, validation loss: 0.4047
2024-06-02 21:19:52 [INFO]: Epoch 035 - training loss: 0.5385, validation loss: 0.4014
2024-06-02 21:19:53 [INFO]: Epoch 036 - training loss: 0.5128, validation loss: 0.3998
2024-06-02 21:19:55 [INFO]: Epoch 037 - training loss: 0.5297, validation loss: 0.4027
2024-06-02 21:19:57 [INFO]: Epoch 038 - training loss: 0.5130, validation loss: 0.3953
2024-06-02 21:19:58 [INFO]: Epoch 039 - training loss: 0.4949, validation loss: 0.3975
2024-06-02 21:20:00 [INFO]: Epoch 040 - training loss: 0.5070, validation loss: 0.3936
2024-06-02 21:20:02 [INFO]: Epoch 041 - training loss: 0.4775, validation loss: 0.3969
2024-06-02 21:20:03 [INFO]: Epoch 042 - training loss: 0.4994, validation loss: 0.3861
2024-06-02 21:20:05 [INFO]: Epoch 043 - training loss: 0.5045, validation loss: 0.3797
2024-06-02 21:20:06 [INFO]: Epoch 044 - training loss: 0.4847, validation loss: 0.4145
2024-06-02 21:20:08 [INFO]: Epoch 045 - training loss: 0.4818, validation loss: 0.3892
2024-06-02 21:20:09 [INFO]: Epoch 046 - training loss: 0.4723, validation loss: 0.3709
2024-06-02 21:20:11 [INFO]: Epoch 047 - training loss: 0.4974, validation loss: 0.3654
2024-06-02 21:20:13 [INFO]: Epoch 048 - training loss: 0.5055, validation loss: 0.3746
2024-06-02 21:20:15 [INFO]: Epoch 049 - training loss: 0.4945, validation loss: 0.3841
2024-06-02 21:20:17 [INFO]: Epoch 050 - training loss: 0.4775, validation loss: 0.3639
2024-06-02 21:20:18 [INFO]: Epoch 051 - training loss: 0.4878, validation loss: 0.3817
2024-06-02 21:20:20 [INFO]: Epoch 052 - training loss: 0.4747, validation loss: 0.4122
2024-06-02 21:20:21 [INFO]: Epoch 053 - training loss: 0.4779, validation loss: 0.3801
2024-06-02 21:20:23 [INFO]: Epoch 054 - training loss: 0.4776, validation loss: 0.3407
2024-06-02 21:20:25 [INFO]: Epoch 055 - training loss: 0.4799, validation loss: 0.3466
2024-06-02 21:20:26 [INFO]: Epoch 056 - training loss: 0.4721, validation loss: 0.3539
2024-06-02 21:20:28 [INFO]: Epoch 057 - training loss: 0.4725, validation loss: 0.3311
2024-06-02 21:20:29 [INFO]: Epoch 058 - training loss: 0.4747, validation loss: 0.3638
2024-06-02 21:20:31 [INFO]: Epoch 059 - training loss: 0.4907, validation loss: 0.3548
2024-06-02 21:20:32 [INFO]: Epoch 060 - training loss: 0.4616, validation loss: 0.3541
2024-06-02 21:20:34 [INFO]: Epoch 061 - training loss: 0.4613, validation loss: 0.3685
2024-06-02 21:20:35 [INFO]: Epoch 062 - training loss: 0.4670, validation loss: 0.3401
2024-06-02 21:20:37 [INFO]: Epoch 063 - training loss: 0.4467, validation loss: 0.3377
2024-06-02 21:20:39 [INFO]: Epoch 064 - training loss: 0.4666, validation loss: 0.3612
2024-06-02 21:20:41 [INFO]: Epoch 065 - training loss: 0.4532, validation loss: 0.3567
2024-06-02 21:20:43 [INFO]: Epoch 066 - training loss: 0.4665, validation loss: 0.3550
2024-06-02 21:20:44 [INFO]: Epoch 067 - training loss: 0.4395, validation loss: 0.3220
2024-06-02 21:20:46 [INFO]: Epoch 068 - training loss: 0.4412, validation loss: 0.3413
2024-06-02 21:20:48 [INFO]: Epoch 069 - training loss: 0.4526, validation loss: 0.3446
2024-06-02 21:20:49 [INFO]: Epoch 070 - training loss: 0.4302, validation loss: 0.3311
2024-06-02 21:20:51 [INFO]: Epoch 071 - training loss: 0.4443, validation loss: 0.3404
2024-06-02 21:20:53 [INFO]: Epoch 072 - training loss: 0.4521, validation loss: 0.3494
2024-06-02 21:20:54 [INFO]: Epoch 073 - training loss: 0.4578, validation loss: 0.3357
2024-06-02 21:20:56 [INFO]: Epoch 074 - training loss: 0.4465, validation loss: 0.3155
2024-06-02 21:20:58 [INFO]: Epoch 075 - training loss: 0.4651, validation loss: 0.3372
2024-06-02 21:21:00 [INFO]: Epoch 076 - training loss: 0.4535, validation loss: 0.3052
2024-06-02 21:21:01 [INFO]: Epoch 077 - training loss: 0.4416, validation loss: 0.3396
2024-06-02 21:21:03 [INFO]: Epoch 078 - training loss: 0.4447, validation loss: 0.3275
2024-06-02 21:21:05 [INFO]: Epoch 079 - training loss: 0.4384, validation loss: 0.3375
2024-06-02 21:21:06 [INFO]: Epoch 080 - training loss: 0.4235, validation loss: 0.3083
2024-06-02 21:21:08 [INFO]: Epoch 081 - training loss: 0.4131, validation loss: 0.3254
2024-06-02 21:21:10 [INFO]: Epoch 082 - training loss: 0.4326, validation loss: 0.3516
2024-06-02 21:21:11 [INFO]: Epoch 083 - training loss: 0.4598, validation loss: 0.3333
2024-06-02 21:21:13 [INFO]: Epoch 084 - training loss: 0.4295, validation loss: 0.3272
2024-06-02 21:21:14 [INFO]: Epoch 085 - training loss: 0.4467, validation loss: 0.3089
2024-06-02 21:21:16 [INFO]: Epoch 086 - training loss: 0.4238, validation loss: 0.3219
2024-06-02 21:21:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:21:16 [INFO]: Finished training. The best model is from epoch#76.
2024-06-02 21:21:16 [INFO]: Saved the model to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_4/20240602_T211856/SCINet.pypots
2024-06-02 21:21:18 [INFO]: Successfully saved to results_point_rate05/Pedestrian/SCINet_Pedestrian/round_4/imputation.pkl
2024-06-02 21:21:18 [INFO]: Round4 - SCINet on Pedestrian: MAE=0.2465, MSE=0.3626, MRE=0.3243
2024-06-02 21:21:18 [INFO]: Done! Final results:
Averaged SCINet (43,783 params) on Pedestrian: MAE=0.2514 ± 0.005022691664115949, MSE=0.3905 ± 0.01477858346017712, MRE=0.3308 ± 0.006609386723572668, average inference time=1.98
