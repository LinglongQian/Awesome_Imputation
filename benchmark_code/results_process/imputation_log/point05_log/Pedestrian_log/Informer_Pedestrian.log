2024-06-02 20:52:35 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:52:35 [INFO]: Using the given device: cuda:0
2024-06-02 20:52:35 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_0/20240602_T205235
2024-06-02 20:52:35 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_0/20240602_T205235/tensorboard
2024-06-02 20:52:36 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 446,785
2024-06-02 20:52:50 [INFO]: Epoch 001 - training loss: 1.1159, validation loss: 1.0484
2024-06-02 20:52:54 [INFO]: Epoch 002 - training loss: 0.7098, validation loss: 0.8005
2024-06-02 20:52:57 [INFO]: Epoch 003 - training loss: 0.6078, validation loss: 0.7641
2024-06-02 20:53:01 [INFO]: Epoch 004 - training loss: 0.5545, validation loss: 0.7610
2024-06-02 20:53:04 [INFO]: Epoch 005 - training loss: 0.5217, validation loss: 0.7527
2024-06-02 20:53:08 [INFO]: Epoch 006 - training loss: 0.4862, validation loss: 0.7391
2024-06-02 20:53:12 [INFO]: Epoch 007 - training loss: 0.5120, validation loss: 0.7404
2024-06-02 20:53:15 [INFO]: Epoch 008 - training loss: 0.4908, validation loss: 0.7309
2024-06-02 20:53:19 [INFO]: Epoch 009 - training loss: 0.4751, validation loss: 0.7164
2024-06-02 20:53:22 [INFO]: Epoch 010 - training loss: 0.4912, validation loss: 0.7449
2024-06-02 20:53:25 [INFO]: Epoch 011 - training loss: 0.4690, validation loss: 0.7223
2024-06-02 20:53:28 [INFO]: Epoch 012 - training loss: 0.4653, validation loss: 0.7495
2024-06-02 20:53:31 [INFO]: Epoch 013 - training loss: 0.4405, validation loss: 0.6694
2024-06-02 20:53:35 [INFO]: Epoch 014 - training loss: 0.4439, validation loss: 0.6871
2024-06-02 20:53:38 [INFO]: Epoch 015 - training loss: 0.4446, validation loss: 0.6578
2024-06-02 20:53:41 [INFO]: Epoch 016 - training loss: 0.4408, validation loss: 0.6556
2024-06-02 20:53:44 [INFO]: Epoch 017 - training loss: 0.4106, validation loss: 0.6397
2024-06-02 20:53:48 [INFO]: Epoch 018 - training loss: 0.4205, validation loss: 0.6422
2024-06-02 20:53:52 [INFO]: Epoch 019 - training loss: 0.4084, validation loss: 0.6400
2024-06-02 20:53:55 [INFO]: Epoch 020 - training loss: 0.4264, validation loss: 0.6042
2024-06-02 20:53:59 [INFO]: Epoch 021 - training loss: 0.4102, validation loss: 0.6094
2024-06-02 20:54:03 [INFO]: Epoch 022 - training loss: 0.3794, validation loss: 0.5848
2024-06-02 20:54:06 [INFO]: Epoch 023 - training loss: 0.3866, validation loss: 0.5786
2024-06-02 20:54:10 [INFO]: Epoch 024 - training loss: 0.3748, validation loss: 0.6010
2024-06-02 20:54:13 [INFO]: Epoch 025 - training loss: 0.3758, validation loss: 0.5823
2024-06-02 20:54:17 [INFO]: Epoch 026 - training loss: 0.3593, validation loss: 0.5590
2024-06-02 20:54:20 [INFO]: Epoch 027 - training loss: 0.3680, validation loss: 0.5594
2024-06-02 20:54:23 [INFO]: Epoch 028 - training loss: 0.3642, validation loss: 0.5316
2024-06-02 20:54:26 [INFO]: Epoch 029 - training loss: 0.3592, validation loss: 0.5224
2024-06-02 20:54:29 [INFO]: Epoch 030 - training loss: 0.3562, validation loss: 0.5093
2024-06-02 20:54:32 [INFO]: Epoch 031 - training loss: 0.3379, validation loss: 0.4853
2024-06-02 20:54:35 [INFO]: Epoch 032 - training loss: 0.3466, validation loss: 0.4344
2024-06-02 20:54:39 [INFO]: Epoch 033 - training loss: 0.3540, validation loss: 0.4499
2024-06-02 20:54:42 [INFO]: Epoch 034 - training loss: 0.3386, validation loss: 0.4529
2024-06-02 20:54:46 [INFO]: Epoch 035 - training loss: 0.3330, validation loss: 0.4444
2024-06-02 20:54:49 [INFO]: Epoch 036 - training loss: 0.3360, validation loss: 0.4058
2024-06-02 20:54:53 [INFO]: Epoch 037 - training loss: 0.3214, validation loss: 0.3823
2024-06-02 20:54:56 [INFO]: Epoch 038 - training loss: 0.3272, validation loss: 0.3984
2024-06-02 20:55:00 [INFO]: Epoch 039 - training loss: 0.3313, validation loss: 0.3936
2024-06-02 20:55:03 [INFO]: Epoch 040 - training loss: 0.3306, validation loss: 0.3782
2024-06-02 20:55:07 [INFO]: Epoch 041 - training loss: 0.3323, validation loss: 0.3999
2024-06-02 20:55:10 [INFO]: Epoch 042 - training loss: 0.3374, validation loss: 0.3634
2024-06-02 20:55:14 [INFO]: Epoch 043 - training loss: 0.3145, validation loss: 0.3728
2024-06-02 20:55:17 [INFO]: Epoch 044 - training loss: 0.3219, validation loss: 0.3492
2024-06-02 20:55:21 [INFO]: Epoch 045 - training loss: 0.3298, validation loss: 0.3725
2024-06-02 20:55:24 [INFO]: Epoch 046 - training loss: 0.3179, validation loss: 0.3567
2024-06-02 20:55:27 [INFO]: Epoch 047 - training loss: 0.3225, validation loss: 0.3588
2024-06-02 20:55:30 [INFO]: Epoch 048 - training loss: 0.3208, validation loss: 0.3617
2024-06-02 20:55:33 [INFO]: Epoch 049 - training loss: 0.3274, validation loss: 0.3486
2024-06-02 20:55:36 [INFO]: Epoch 050 - training loss: 0.3109, validation loss: 0.3438
2024-06-02 20:55:40 [INFO]: Epoch 051 - training loss: 0.3196, validation loss: 0.3382
2024-06-02 20:55:43 [INFO]: Epoch 052 - training loss: 0.3041, validation loss: 0.3558
2024-06-02 20:55:46 [INFO]: Epoch 053 - training loss: 0.3154, validation loss: 0.3523
2024-06-02 20:55:50 [INFO]: Epoch 054 - training loss: 0.3066, validation loss: 0.3457
2024-06-02 20:55:53 [INFO]: Epoch 055 - training loss: 0.3214, validation loss: 0.3284
2024-06-02 20:55:56 [INFO]: Epoch 056 - training loss: 0.3116, validation loss: 0.3434
2024-06-02 20:55:58 [INFO]: Epoch 057 - training loss: 0.3067, validation loss: 0.3735
2024-06-02 20:56:01 [INFO]: Epoch 058 - training loss: 0.3164, validation loss: 0.3421
2024-06-02 20:56:04 [INFO]: Epoch 059 - training loss: 0.2987, validation loss: 0.3366
2024-06-02 20:56:07 [INFO]: Epoch 060 - training loss: 0.3125, validation loss: 0.3324
2024-06-02 20:56:10 [INFO]: Epoch 061 - training loss: 0.3037, validation loss: 0.3509
2024-06-02 20:56:13 [INFO]: Epoch 062 - training loss: 0.3133, validation loss: 0.3587
2024-06-02 20:56:16 [INFO]: Epoch 063 - training loss: 0.3017, validation loss: 0.3325
2024-06-02 20:56:19 [INFO]: Epoch 064 - training loss: 0.3119, validation loss: 0.3411
2024-06-02 20:56:22 [INFO]: Epoch 065 - training loss: 0.3193, validation loss: 0.3444
2024-06-02 20:56:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:56:22 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 20:56:22 [INFO]: Saved the model to results_point_rate05/Pedestrian/Informer_Pedestrian/round_0/20240602_T205235/Informer.pypots
2024-06-02 20:56:26 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_0/imputation.pkl
2024-06-02 20:56:26 [INFO]: Round0 - Informer on Pedestrian: MAE=0.2165, MSE=0.3850, MRE=0.2850
2024-06-02 20:56:26 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:56:26 [INFO]: Using the given device: cuda:0
2024-06-02 20:56:26 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_1/20240602_T205626
2024-06-02 20:56:26 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_1/20240602_T205626/tensorboard
2024-06-02 20:56:26 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 446,785
2024-06-02 20:56:28 [INFO]: Epoch 001 - training loss: 0.8301, validation loss: 0.9249
2024-06-02 20:56:30 [INFO]: Epoch 002 - training loss: 0.6670, validation loss: 0.7732
2024-06-02 20:56:33 [INFO]: Epoch 003 - training loss: 0.5675, validation loss: 0.7828
2024-06-02 20:56:35 [INFO]: Epoch 004 - training loss: 0.5446, validation loss: 0.7770
2024-06-02 20:56:37 [INFO]: Epoch 005 - training loss: 0.5466, validation loss: 0.7471
2024-06-02 20:56:40 [INFO]: Epoch 006 - training loss: 0.5112, validation loss: 0.7439
2024-06-02 20:56:42 [INFO]: Epoch 007 - training loss: 0.5085, validation loss: 0.7484
2024-06-02 20:56:45 [INFO]: Epoch 008 - training loss: 0.4710, validation loss: 0.7356
2024-06-02 20:56:48 [INFO]: Epoch 009 - training loss: 0.4698, validation loss: 0.6979
2024-06-02 20:56:51 [INFO]: Epoch 010 - training loss: 0.4861, validation loss: 0.7063
2024-06-02 20:56:54 [INFO]: Epoch 011 - training loss: 0.4398, validation loss: 0.7101
2024-06-02 20:56:56 [INFO]: Epoch 012 - training loss: 0.4795, validation loss: 0.7168
2024-06-02 20:56:59 [INFO]: Epoch 013 - training loss: 0.4625, validation loss: 0.7082
2024-06-02 20:57:01 [INFO]: Epoch 014 - training loss: 0.4553, validation loss: 0.7065
2024-06-02 20:57:03 [INFO]: Epoch 015 - training loss: 0.4367, validation loss: 0.6728
2024-06-02 20:57:06 [INFO]: Epoch 016 - training loss: 0.4246, validation loss: 0.6524
2024-06-02 20:57:08 [INFO]: Epoch 017 - training loss: 0.4473, validation loss: 0.6324
2024-06-02 20:57:10 [INFO]: Epoch 018 - training loss: 0.4276, validation loss: 0.6134
2024-06-02 20:57:13 [INFO]: Epoch 019 - training loss: 0.3943, validation loss: 0.6385
2024-06-02 20:57:15 [INFO]: Epoch 020 - training loss: 0.3987, validation loss: 0.5994
2024-06-02 20:57:17 [INFO]: Epoch 021 - training loss: 0.3923, validation loss: 0.5658
2024-06-02 20:57:19 [INFO]: Epoch 022 - training loss: 0.3790, validation loss: 0.5511
2024-06-02 20:57:22 [INFO]: Epoch 023 - training loss: 0.3652, validation loss: 0.5073
2024-06-02 20:57:24 [INFO]: Epoch 024 - training loss: 0.3720, validation loss: 0.4965
2024-06-02 20:57:26 [INFO]: Epoch 025 - training loss: 0.3725, validation loss: 0.4723
2024-06-02 20:57:29 [INFO]: Epoch 026 - training loss: 0.3570, validation loss: 0.4366
2024-06-02 20:57:31 [INFO]: Epoch 027 - training loss: 0.3653, validation loss: 0.4066
2024-06-02 20:57:33 [INFO]: Epoch 028 - training loss: 0.3497, validation loss: 0.4188
2024-06-02 20:57:35 [INFO]: Epoch 029 - training loss: 0.3626, validation loss: 0.3972
2024-06-02 20:57:38 [INFO]: Epoch 030 - training loss: 0.3440, validation loss: 0.3719
2024-06-02 20:57:40 [INFO]: Epoch 031 - training loss: 0.3395, validation loss: 0.3848
2024-06-02 20:57:42 [INFO]: Epoch 032 - training loss: 0.3488, validation loss: 0.4894
2024-06-02 20:57:44 [INFO]: Epoch 033 - training loss: 0.3413, validation loss: 0.3995
2024-06-02 20:57:47 [INFO]: Epoch 034 - training loss: 0.3457, validation loss: 0.3917
2024-06-02 20:57:49 [INFO]: Epoch 035 - training loss: 0.3390, validation loss: 0.3869
2024-06-02 20:57:51 [INFO]: Epoch 036 - training loss: 0.3427, validation loss: 0.3846
2024-06-02 20:57:54 [INFO]: Epoch 037 - training loss: 0.3371, validation loss: 0.3827
2024-06-02 20:57:56 [INFO]: Epoch 038 - training loss: 0.3263, validation loss: 0.3681
2024-06-02 20:57:58 [INFO]: Epoch 039 - training loss: 0.3199, validation loss: 0.3825
2024-06-02 20:58:00 [INFO]: Epoch 040 - training loss: 0.3305, validation loss: 0.4012
2024-06-02 20:58:02 [INFO]: Epoch 041 - training loss: 0.3299, validation loss: 0.3805
2024-06-02 20:58:04 [INFO]: Epoch 042 - training loss: 0.3232, validation loss: 0.3648
2024-06-02 20:58:07 [INFO]: Epoch 043 - training loss: 0.3242, validation loss: 0.3835
2024-06-02 20:58:09 [INFO]: Epoch 044 - training loss: 0.3095, validation loss: 0.3688
2024-06-02 20:58:12 [INFO]: Epoch 045 - training loss: 0.3386, validation loss: 0.3833
2024-06-02 20:58:14 [INFO]: Epoch 046 - training loss: 0.3420, validation loss: 0.3740
2024-06-02 20:58:16 [INFO]: Epoch 047 - training loss: 0.3270, validation loss: 0.3761
2024-06-02 20:58:18 [INFO]: Epoch 048 - training loss: 0.3139, validation loss: 0.3711
2024-06-02 20:58:20 [INFO]: Epoch 049 - training loss: 0.3001, validation loss: 0.3665
2024-06-02 20:58:21 [INFO]: Epoch 050 - training loss: 0.3327, validation loss: 0.3903
2024-06-02 20:58:23 [INFO]: Epoch 051 - training loss: 0.3267, validation loss: 0.3734
2024-06-02 20:58:25 [INFO]: Epoch 052 - training loss: 0.3224, validation loss: 0.3560
2024-06-02 20:58:27 [INFO]: Epoch 053 - training loss: 0.3046, validation loss: 0.3528
2024-06-02 20:58:30 [INFO]: Epoch 054 - training loss: 0.3132, validation loss: 0.3544
2024-06-02 20:58:32 [INFO]: Epoch 055 - training loss: 0.3038, validation loss: 0.3313
2024-06-02 20:58:34 [INFO]: Epoch 056 - training loss: 0.3185, validation loss: 0.3384
2024-06-02 20:58:37 [INFO]: Epoch 057 - training loss: 0.3136, validation loss: 0.3391
2024-06-02 20:58:39 [INFO]: Epoch 058 - training loss: 0.2912, validation loss: 0.3465
2024-06-02 20:58:41 [INFO]: Epoch 059 - training loss: 0.3098, validation loss: 0.3525
2024-06-02 20:58:44 [INFO]: Epoch 060 - training loss: 0.3174, validation loss: 0.3635
2024-06-02 20:58:46 [INFO]: Epoch 061 - training loss: 0.3223, validation loss: 0.3783
2024-06-02 20:58:48 [INFO]: Epoch 062 - training loss: 0.3107, validation loss: 0.3540
2024-06-02 20:58:50 [INFO]: Epoch 063 - training loss: 0.3153, validation loss: 0.3511
2024-06-02 20:58:53 [INFO]: Epoch 064 - training loss: 0.3030, validation loss: 0.3736
2024-06-02 20:58:55 [INFO]: Epoch 065 - training loss: 0.3124, validation loss: 0.3623
2024-06-02 20:58:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:58:55 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 20:58:55 [INFO]: Saved the model to results_point_rate05/Pedestrian/Informer_Pedestrian/round_1/20240602_T205626/Informer.pypots
2024-06-02 20:58:59 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_1/imputation.pkl
2024-06-02 20:58:59 [INFO]: Round1 - Informer on Pedestrian: MAE=0.2103, MSE=0.3964, MRE=0.2767
2024-06-02 20:58:59 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:58:59 [INFO]: Using the given device: cuda:0
2024-06-02 20:58:59 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_2/20240602_T205859
2024-06-02 20:58:59 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_2/20240602_T205859/tensorboard
2024-06-02 20:58:59 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 446,785
2024-06-02 20:59:01 [INFO]: Epoch 001 - training loss: 0.9301, validation loss: 0.9267
2024-06-02 20:59:04 [INFO]: Epoch 002 - training loss: 0.6598, validation loss: 0.7538
2024-06-02 20:59:06 [INFO]: Epoch 003 - training loss: 0.6019, validation loss: 0.7646
2024-06-02 20:59:09 [INFO]: Epoch 004 - training loss: 0.5539, validation loss: 0.7666
2024-06-02 20:59:11 [INFO]: Epoch 005 - training loss: 0.5311, validation loss: 0.7600
2024-06-02 20:59:13 [INFO]: Epoch 006 - training loss: 0.5200, validation loss: 0.7442
2024-06-02 20:59:15 [INFO]: Epoch 007 - training loss: 0.5118, validation loss: 0.7615
2024-06-02 20:59:17 [INFO]: Epoch 008 - training loss: 0.4793, validation loss: 0.7389
2024-06-02 20:59:19 [INFO]: Epoch 009 - training loss: 0.4802, validation loss: 0.7546
2024-06-02 20:59:21 [INFO]: Epoch 010 - training loss: 0.4679, validation loss: 0.7255
2024-06-02 20:59:23 [INFO]: Epoch 011 - training loss: 0.4722, validation loss: 0.7010
2024-06-02 20:59:24 [INFO]: Epoch 012 - training loss: 0.4715, validation loss: 0.6782
2024-06-02 20:59:26 [INFO]: Epoch 013 - training loss: 0.4405, validation loss: 0.6667
2024-06-02 20:59:27 [INFO]: Epoch 014 - training loss: 0.4441, validation loss: 0.6615
2024-06-02 20:59:29 [INFO]: Epoch 015 - training loss: 0.4250, validation loss: 0.6322
2024-06-02 20:59:31 [INFO]: Epoch 016 - training loss: 0.4208, validation loss: 0.6405
2024-06-02 20:59:32 [INFO]: Epoch 017 - training loss: 0.4215, validation loss: 0.6090
2024-06-02 20:59:34 [INFO]: Epoch 018 - training loss: 0.3896, validation loss: 0.6010
2024-06-02 20:59:36 [INFO]: Epoch 019 - training loss: 0.4044, validation loss: 0.6016
2024-06-02 20:59:37 [INFO]: Epoch 020 - training loss: 0.3961, validation loss: 0.5753
2024-06-02 20:59:39 [INFO]: Epoch 021 - training loss: 0.3892, validation loss: 0.5683
2024-06-02 20:59:41 [INFO]: Epoch 022 - training loss: 0.3842, validation loss: 0.5952
2024-06-02 20:59:42 [INFO]: Epoch 023 - training loss: 0.3539, validation loss: 0.5469
2024-06-02 20:59:44 [INFO]: Epoch 024 - training loss: 0.4231, validation loss: 0.5328
2024-06-02 20:59:46 [INFO]: Epoch 025 - training loss: 0.3570, validation loss: 0.5224
2024-06-02 20:59:47 [INFO]: Epoch 026 - training loss: 0.3559, validation loss: 0.5056
2024-06-02 20:59:49 [INFO]: Epoch 027 - training loss: 0.3421, validation loss: 0.4831
2024-06-02 20:59:51 [INFO]: Epoch 028 - training loss: 0.3451, validation loss: 0.4870
2024-06-02 20:59:52 [INFO]: Epoch 029 - training loss: 0.3525, validation loss: 0.4161
2024-06-02 20:59:54 [INFO]: Epoch 030 - training loss: 0.3395, validation loss: 0.4071
2024-06-02 20:59:56 [INFO]: Epoch 031 - training loss: 0.3493, validation loss: 0.3778
2024-06-02 20:59:57 [INFO]: Epoch 032 - training loss: 0.3326, validation loss: 0.4099
2024-06-02 20:59:59 [INFO]: Epoch 033 - training loss: 0.3215, validation loss: 0.3912
2024-06-02 21:00:01 [INFO]: Epoch 034 - training loss: 0.3351, validation loss: 0.3615
2024-06-02 21:00:02 [INFO]: Epoch 035 - training loss: 0.3235, validation loss: 0.3930
2024-06-02 21:00:04 [INFO]: Epoch 036 - training loss: 0.3326, validation loss: 0.3759
2024-06-02 21:00:06 [INFO]: Epoch 037 - training loss: 0.3341, validation loss: 0.3752
2024-06-02 21:00:07 [INFO]: Epoch 038 - training loss: 0.3367, validation loss: 0.3762
2024-06-02 21:00:09 [INFO]: Epoch 039 - training loss: 0.3253, validation loss: 0.3946
2024-06-02 21:00:11 [INFO]: Epoch 040 - training loss: 0.3441, validation loss: 0.3672
2024-06-02 21:00:12 [INFO]: Epoch 041 - training loss: 0.2892, validation loss: 0.3749
2024-06-02 21:00:14 [INFO]: Epoch 042 - training loss: 0.3221, validation loss: 0.3580
2024-06-02 21:00:15 [INFO]: Epoch 043 - training loss: 0.3083, validation loss: 0.3523
2024-06-02 21:00:17 [INFO]: Epoch 044 - training loss: 0.3063, validation loss: 0.3426
2024-06-02 21:00:19 [INFO]: Epoch 045 - training loss: 0.3123, validation loss: 0.3348
2024-06-02 21:00:20 [INFO]: Epoch 046 - training loss: 0.3318, validation loss: 0.3314
2024-06-02 21:00:22 [INFO]: Epoch 047 - training loss: 0.3043, validation loss: 0.3354
2024-06-02 21:00:23 [INFO]: Epoch 048 - training loss: 0.3208, validation loss: 0.3472
2024-06-02 21:00:25 [INFO]: Epoch 049 - training loss: 0.3107, validation loss: 0.3493
2024-06-02 21:00:27 [INFO]: Epoch 050 - training loss: 0.3159, validation loss: 0.3307
2024-06-02 21:00:28 [INFO]: Epoch 051 - training loss: 0.3116, validation loss: 0.4060
2024-06-02 21:00:30 [INFO]: Epoch 052 - training loss: 0.3169, validation loss: 0.3493
2024-06-02 21:00:32 [INFO]: Epoch 053 - training loss: 0.2971, validation loss: 0.3475
2024-06-02 21:00:34 [INFO]: Epoch 054 - training loss: 0.3209, validation loss: 0.3474
2024-06-02 21:00:35 [INFO]: Epoch 055 - training loss: 0.3026, validation loss: 0.3476
2024-06-02 21:00:37 [INFO]: Epoch 056 - training loss: 0.3053, validation loss: 0.3272
2024-06-02 21:00:38 [INFO]: Epoch 057 - training loss: 0.2951, validation loss: 0.3177
2024-06-02 21:00:40 [INFO]: Epoch 058 - training loss: 0.3029, validation loss: 0.3558
2024-06-02 21:00:41 [INFO]: Epoch 059 - training loss: 0.3167, validation loss: 0.3398
2024-06-02 21:00:43 [INFO]: Epoch 060 - training loss: 0.3158, validation loss: 0.3526
2024-06-02 21:00:44 [INFO]: Epoch 061 - training loss: 0.2925, validation loss: 0.3555
2024-06-02 21:00:45 [INFO]: Epoch 062 - training loss: 0.2936, validation loss: 0.3334
2024-06-02 21:00:47 [INFO]: Epoch 063 - training loss: 0.2972, validation loss: 0.3378
2024-06-02 21:00:48 [INFO]: Epoch 064 - training loss: 0.2954, validation loss: 0.3569
2024-06-02 21:00:50 [INFO]: Epoch 065 - training loss: 0.2908, validation loss: 0.3249
2024-06-02 21:00:51 [INFO]: Epoch 066 - training loss: 0.2974, validation loss: 0.3172
2024-06-02 21:00:53 [INFO]: Epoch 067 - training loss: 0.2908, validation loss: 0.3291
2024-06-02 21:00:54 [INFO]: Epoch 068 - training loss: 0.2896, validation loss: 0.3149
2024-06-02 21:00:56 [INFO]: Epoch 069 - training loss: 0.2930, validation loss: 0.3278
2024-06-02 21:00:57 [INFO]: Epoch 070 - training loss: 0.2941, validation loss: 0.3374
2024-06-02 21:00:59 [INFO]: Epoch 071 - training loss: 0.2953, validation loss: 0.3427
2024-06-02 21:01:00 [INFO]: Epoch 072 - training loss: 0.2937, validation loss: 0.3305
2024-06-02 21:01:02 [INFO]: Epoch 073 - training loss: 0.2901, validation loss: 0.3710
2024-06-02 21:01:03 [INFO]: Epoch 074 - training loss: 0.2876, validation loss: 0.3286
2024-06-02 21:01:04 [INFO]: Epoch 075 - training loss: 0.2991, validation loss: 0.3231
2024-06-02 21:01:05 [INFO]: Epoch 076 - training loss: 0.2928, validation loss: 0.3081
2024-06-02 21:01:07 [INFO]: Epoch 077 - training loss: 0.2944, validation loss: 0.3114
2024-06-02 21:01:08 [INFO]: Epoch 078 - training loss: 0.3065, validation loss: 0.3416
2024-06-02 21:01:09 [INFO]: Epoch 079 - training loss: 0.2956, validation loss: 0.3148
2024-06-02 21:01:10 [INFO]: Epoch 080 - training loss: 0.2965, validation loss: 0.4132
2024-06-02 21:01:11 [INFO]: Epoch 081 - training loss: 0.2836, validation loss: 0.3144
2024-06-02 21:01:12 [INFO]: Epoch 082 - training loss: 0.2862, validation loss: 0.3150
2024-06-02 21:01:13 [INFO]: Epoch 083 - training loss: 0.2746, validation loss: 0.3137
2024-06-02 21:01:14 [INFO]: Epoch 084 - training loss: 0.3019, validation loss: 0.3013
2024-06-02 21:01:15 [INFO]: Epoch 085 - training loss: 0.2787, validation loss: 0.2965
2024-06-02 21:01:17 [INFO]: Epoch 086 - training loss: 0.2686, validation loss: 0.3131
2024-06-02 21:01:18 [INFO]: Epoch 087 - training loss: 0.2994, validation loss: 0.3341
2024-06-02 21:01:20 [INFO]: Epoch 088 - training loss: 0.2823, validation loss: 0.3358
2024-06-02 21:01:21 [INFO]: Epoch 089 - training loss: 0.2753, validation loss: 0.3297
2024-06-02 21:01:22 [INFO]: Epoch 090 - training loss: 0.2780, validation loss: 0.3335
2024-06-02 21:01:23 [INFO]: Epoch 091 - training loss: 0.2803, validation loss: 0.3196
2024-06-02 21:01:24 [INFO]: Epoch 092 - training loss: 0.3002, validation loss: 0.3177
2024-06-02 21:01:25 [INFO]: Epoch 093 - training loss: 0.2861, validation loss: 0.3198
2024-06-02 21:01:26 [INFO]: Epoch 094 - training loss: 0.2763, validation loss: 0.3070
2024-06-02 21:01:27 [INFO]: Epoch 095 - training loss: 0.2856, validation loss: 0.3008
2024-06-02 21:01:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:01:27 [INFO]: Finished training. The best model is from epoch#85.
2024-06-02 21:01:27 [INFO]: Saved the model to results_point_rate05/Pedestrian/Informer_Pedestrian/round_2/20240602_T205859/Informer.pypots
2024-06-02 21:01:28 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_2/imputation.pkl
2024-06-02 21:01:28 [INFO]: Round2 - Informer on Pedestrian: MAE=0.2000, MSE=0.3477, MRE=0.2631
2024-06-02 21:01:28 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 21:01:28 [INFO]: Using the given device: cuda:0
2024-06-02 21:01:28 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_3/20240602_T210128
2024-06-02 21:01:28 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_3/20240602_T210128/tensorboard
2024-06-02 21:01:28 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 446,785
2024-06-02 21:01:29 [INFO]: Epoch 001 - training loss: 0.9690, validation loss: 0.9119
2024-06-02 21:01:30 [INFO]: Epoch 002 - training loss: 0.7006, validation loss: 0.7525
2024-06-02 21:01:31 [INFO]: Epoch 003 - training loss: 0.6095, validation loss: 0.7326
2024-06-02 21:01:32 [INFO]: Epoch 004 - training loss: 0.5646, validation loss: 0.7403
2024-06-02 21:01:33 [INFO]: Epoch 005 - training loss: 0.5387, validation loss: 0.7540
2024-06-02 21:01:34 [INFO]: Epoch 006 - training loss: 0.5121, validation loss: 0.7351
2024-06-02 21:01:35 [INFO]: Epoch 007 - training loss: 0.5002, validation loss: 0.7210
2024-06-02 21:01:36 [INFO]: Epoch 008 - training loss: 0.4973, validation loss: 0.7247
2024-06-02 21:01:37 [INFO]: Epoch 009 - training loss: 0.5005, validation loss: 0.7121
2024-06-02 21:01:38 [INFO]: Epoch 010 - training loss: 0.4891, validation loss: 0.7159
2024-06-02 21:01:39 [INFO]: Epoch 011 - training loss: 0.4826, validation loss: 0.6879
2024-06-02 21:01:40 [INFO]: Epoch 012 - training loss: 0.4623, validation loss: 0.6793
2024-06-02 21:01:41 [INFO]: Epoch 013 - training loss: 0.4724, validation loss: 0.6844
2024-06-02 21:01:42 [INFO]: Epoch 014 - training loss: 0.4461, validation loss: 0.6429
2024-06-02 21:01:42 [INFO]: Epoch 015 - training loss: 0.4408, validation loss: 0.6611
2024-06-02 21:01:43 [INFO]: Epoch 016 - training loss: 0.4495, validation loss: 0.6387
2024-06-02 21:01:44 [INFO]: Epoch 017 - training loss: 0.4172, validation loss: 0.6376
2024-06-02 21:01:45 [INFO]: Epoch 018 - training loss: 0.4001, validation loss: 0.6267
2024-06-02 21:01:46 [INFO]: Epoch 019 - training loss: 0.3991, validation loss: 0.5693
2024-06-02 21:01:47 [INFO]: Epoch 020 - training loss: 0.4013, validation loss: 0.5811
2024-06-02 21:01:48 [INFO]: Epoch 021 - training loss: 0.3981, validation loss: 0.5575
2024-06-02 21:01:49 [INFO]: Epoch 022 - training loss: 0.3650, validation loss: 0.5141
2024-06-02 21:01:50 [INFO]: Epoch 023 - training loss: 0.3737, validation loss: 0.5096
2024-06-02 21:01:51 [INFO]: Epoch 024 - training loss: 0.3668, validation loss: 0.4909
2024-06-02 21:01:52 [INFO]: Epoch 025 - training loss: 0.3726, validation loss: 0.4243
2024-06-02 21:01:53 [INFO]: Epoch 026 - training loss: 0.3642, validation loss: 0.4375
2024-06-02 21:01:54 [INFO]: Epoch 027 - training loss: 0.3409, validation loss: 0.4060
2024-06-02 21:01:55 [INFO]: Epoch 028 - training loss: 0.3583, validation loss: 0.4036
2024-06-02 21:01:56 [INFO]: Epoch 029 - training loss: 0.3489, validation loss: 0.3972
2024-06-02 21:01:57 [INFO]: Epoch 030 - training loss: 0.3547, validation loss: 0.3854
2024-06-02 21:01:58 [INFO]: Epoch 031 - training loss: 0.3304, validation loss: 0.3974
2024-06-02 21:01:59 [INFO]: Epoch 032 - training loss: 0.3334, validation loss: 0.3886
2024-06-02 21:01:59 [INFO]: Epoch 033 - training loss: 0.3413, validation loss: 0.4040
2024-06-02 21:02:00 [INFO]: Epoch 034 - training loss: 0.3382, validation loss: 0.3891
2024-06-02 21:02:01 [INFO]: Epoch 035 - training loss: 0.3307, validation loss: 0.3825
2024-06-02 21:02:02 [INFO]: Epoch 036 - training loss: 0.3501, validation loss: 0.3729
2024-06-02 21:02:03 [INFO]: Epoch 037 - training loss: 0.3297, validation loss: 0.3853
2024-06-02 21:02:04 [INFO]: Epoch 038 - training loss: 0.3359, validation loss: 0.3641
2024-06-02 21:02:05 [INFO]: Epoch 039 - training loss: 0.3226, validation loss: 0.4077
2024-06-02 21:02:06 [INFO]: Epoch 040 - training loss: 0.3251, validation loss: 0.4069
2024-06-02 21:02:07 [INFO]: Epoch 041 - training loss: 0.3376, validation loss: 0.3776
2024-06-02 21:02:08 [INFO]: Epoch 042 - training loss: 0.3169, validation loss: 0.3780
2024-06-02 21:02:09 [INFO]: Epoch 043 - training loss: 0.3110, validation loss: 0.3978
2024-06-02 21:02:10 [INFO]: Epoch 044 - training loss: 0.3290, validation loss: 0.3804
2024-06-02 21:02:11 [INFO]: Epoch 045 - training loss: 0.3192, validation loss: 0.3814
2024-06-02 21:02:12 [INFO]: Epoch 046 - training loss: 0.3322, validation loss: 0.3930
2024-06-02 21:02:13 [INFO]: Epoch 047 - training loss: 0.3285, validation loss: 0.3767
2024-06-02 21:02:14 [INFO]: Epoch 048 - training loss: 0.3178, validation loss: 0.3736
2024-06-02 21:02:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:02:14 [INFO]: Finished training. The best model is from epoch#38.
2024-06-02 21:02:14 [INFO]: Saved the model to results_point_rate05/Pedestrian/Informer_Pedestrian/round_3/20240602_T210128/Informer.pypots
2024-06-02 21:02:15 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_3/imputation.pkl
2024-06-02 21:02:15 [INFO]: Round3 - Informer on Pedestrian: MAE=0.2140, MSE=0.4029, MRE=0.2816
2024-06-02 21:02:15 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 21:02:15 [INFO]: Using the given device: cuda:0
2024-06-02 21:02:15 [INFO]: Model files will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_4/20240602_T210215
2024-06-02 21:02:15 [INFO]: Tensorboard file will be saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_4/20240602_T210215/tensorboard
2024-06-02 21:02:15 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 446,785
2024-06-02 21:02:16 [INFO]: Epoch 001 - training loss: 0.9214, validation loss: 0.9199
2024-06-02 21:02:17 [INFO]: Epoch 002 - training loss: 0.6929, validation loss: 0.9245
2024-06-02 21:02:18 [INFO]: Epoch 003 - training loss: 0.6206, validation loss: 0.7405
2024-06-02 21:02:19 [INFO]: Epoch 004 - training loss: 0.5602, validation loss: 0.7520
2024-06-02 21:02:20 [INFO]: Epoch 005 - training loss: 0.5325, validation loss: 0.7655
2024-06-02 21:02:21 [INFO]: Epoch 006 - training loss: 0.5148, validation loss: 0.7425
2024-06-02 21:02:22 [INFO]: Epoch 007 - training loss: 0.4899, validation loss: 0.7545
2024-06-02 21:02:23 [INFO]: Epoch 008 - training loss: 0.4918, validation loss: 0.7257
2024-06-02 21:02:24 [INFO]: Epoch 009 - training loss: 0.4870, validation loss: 0.7202
2024-06-02 21:02:25 [INFO]: Epoch 010 - training loss: 0.4717, validation loss: 0.7262
2024-06-02 21:02:25 [INFO]: Epoch 011 - training loss: 0.4618, validation loss: 0.7148
2024-06-02 21:02:26 [INFO]: Epoch 012 - training loss: 0.4559, validation loss: 0.7129
2024-06-02 21:02:27 [INFO]: Epoch 013 - training loss: 0.4583, validation loss: 0.7012
2024-06-02 21:02:28 [INFO]: Epoch 014 - training loss: 0.4351, validation loss: 0.7053
2024-06-02 21:02:29 [INFO]: Epoch 015 - training loss: 0.4296, validation loss: 0.6784
2024-06-02 21:02:30 [INFO]: Epoch 016 - training loss: 0.4319, validation loss: 0.6257
2024-06-02 21:02:31 [INFO]: Epoch 017 - training loss: 0.4211, validation loss: 0.6414
2024-06-02 21:02:32 [INFO]: Epoch 018 - training loss: 0.4010, validation loss: 0.6258
2024-06-02 21:02:33 [INFO]: Epoch 019 - training loss: 0.4117, validation loss: 0.5997
2024-06-02 21:02:34 [INFO]: Epoch 020 - training loss: 0.4118, validation loss: 0.5728
2024-06-02 21:02:35 [INFO]: Epoch 021 - training loss: 0.3756, validation loss: 0.5148
2024-06-02 21:02:36 [INFO]: Epoch 022 - training loss: 0.3599, validation loss: 0.4365
2024-06-02 21:02:37 [INFO]: Epoch 023 - training loss: 0.3757, validation loss: 0.5065
2024-06-02 21:02:38 [INFO]: Epoch 024 - training loss: 0.3733, validation loss: 0.4182
2024-06-02 21:02:39 [INFO]: Epoch 025 - training loss: 0.3451, validation loss: 0.4179
2024-06-02 21:02:40 [INFO]: Epoch 026 - training loss: 0.3550, validation loss: 0.4280
2024-06-02 21:02:41 [INFO]: Epoch 027 - training loss: 0.3599, validation loss: 0.4319
2024-06-02 21:02:42 [INFO]: Epoch 028 - training loss: 0.3719, validation loss: 0.4064
2024-06-02 21:02:42 [INFO]: Epoch 029 - training loss: 0.3432, validation loss: 0.3879
2024-06-02 21:02:43 [INFO]: Epoch 030 - training loss: 0.3443, validation loss: 0.3964
2024-06-02 21:02:44 [INFO]: Epoch 031 - training loss: 0.3397, validation loss: 0.3933
2024-06-02 21:02:45 [INFO]: Epoch 032 - training loss: 0.3508, validation loss: 0.4108
2024-06-02 21:02:46 [INFO]: Epoch 033 - training loss: 0.3379, validation loss: 0.3761
2024-06-02 21:02:47 [INFO]: Epoch 034 - training loss: 0.3422, validation loss: 0.3693
2024-06-02 21:02:48 [INFO]: Epoch 035 - training loss: 0.3222, validation loss: 0.3864
2024-06-02 21:02:49 [INFO]: Epoch 036 - training loss: 0.3433, validation loss: 0.3796
2024-06-02 21:02:50 [INFO]: Epoch 037 - training loss: 0.3231, validation loss: 0.4001
2024-06-02 21:02:51 [INFO]: Epoch 038 - training loss: 0.3384, validation loss: 0.4008
2024-06-02 21:02:52 [INFO]: Epoch 039 - training loss: 0.3375, validation loss: 0.3648
2024-06-02 21:02:53 [INFO]: Epoch 040 - training loss: 0.3266, validation loss: 0.3885
2024-06-02 21:02:54 [INFO]: Epoch 041 - training loss: 0.3539, validation loss: 0.3710
2024-06-02 21:02:55 [INFO]: Epoch 042 - training loss: 0.3211, validation loss: 0.3861
2024-06-02 21:02:56 [INFO]: Epoch 043 - training loss: 0.3146, validation loss: 0.3701
2024-06-02 21:02:57 [INFO]: Epoch 044 - training loss: 0.3216, validation loss: 0.3668
2024-06-02 21:02:58 [INFO]: Epoch 045 - training loss: 0.3139, validation loss: 0.3700
2024-06-02 21:02:59 [INFO]: Epoch 046 - training loss: 0.3140, validation loss: 0.3766
2024-06-02 21:03:00 [INFO]: Epoch 047 - training loss: 0.3390, validation loss: 0.3687
2024-06-02 21:03:01 [INFO]: Epoch 048 - training loss: 0.3242, validation loss: 0.3817
2024-06-02 21:03:01 [INFO]: Epoch 049 - training loss: 0.3259, validation loss: 0.3607
2024-06-02 21:03:02 [INFO]: Epoch 050 - training loss: 0.3241, validation loss: 0.3632
2024-06-02 21:03:03 [INFO]: Epoch 051 - training loss: 0.3212, validation loss: 0.3707
2024-06-02 21:03:04 [INFO]: Epoch 052 - training loss: 0.3067, validation loss: 0.3775
2024-06-02 21:03:05 [INFO]: Epoch 053 - training loss: 0.2995, validation loss: 0.3775
2024-06-02 21:03:06 [INFO]: Epoch 054 - training loss: 0.3194, validation loss: 0.3710
2024-06-02 21:03:07 [INFO]: Epoch 055 - training loss: 0.3075, validation loss: 0.3718
2024-06-02 21:03:08 [INFO]: Epoch 056 - training loss: 0.3207, validation loss: 0.3628
2024-06-02 21:03:09 [INFO]: Epoch 057 - training loss: 0.3059, validation loss: 0.3607
2024-06-02 21:03:10 [INFO]: Epoch 058 - training loss: 0.3136, validation loss: 0.3701
2024-06-02 21:03:11 [INFO]: Epoch 059 - training loss: 0.3100, validation loss: 0.3626
2024-06-02 21:03:12 [INFO]: Epoch 060 - training loss: 0.3135, validation loss: 0.3643
2024-06-02 21:03:13 [INFO]: Epoch 061 - training loss: 0.3003, validation loss: 0.3692
2024-06-02 21:03:14 [INFO]: Epoch 062 - training loss: 0.3016, validation loss: 0.3709
2024-06-02 21:03:15 [INFO]: Epoch 063 - training loss: 0.3017, validation loss: 0.3664
2024-06-02 21:03:16 [INFO]: Epoch 064 - training loss: 0.3118, validation loss: 0.3693
2024-06-02 21:03:17 [INFO]: Epoch 065 - training loss: 0.3077, validation loss: 0.3575
2024-06-02 21:03:18 [INFO]: Epoch 066 - training loss: 0.2891, validation loss: 0.3622
2024-06-02 21:03:19 [INFO]: Epoch 067 - training loss: 0.3141, validation loss: 0.3896
2024-06-02 21:03:19 [INFO]: Epoch 068 - training loss: 0.3135, validation loss: 0.3622
2024-06-02 21:03:20 [INFO]: Epoch 069 - training loss: 0.3079, validation loss: 0.3612
2024-06-02 21:03:21 [INFO]: Epoch 070 - training loss: 0.3111, validation loss: 0.3535
2024-06-02 21:03:22 [INFO]: Epoch 071 - training loss: 0.3012, validation loss: 0.3601
2024-06-02 21:03:23 [INFO]: Epoch 072 - training loss: 0.2920, validation loss: 0.3395
2024-06-02 21:03:24 [INFO]: Epoch 073 - training loss: 0.3122, validation loss: 0.3605
2024-06-02 21:03:25 [INFO]: Epoch 074 - training loss: 0.3007, validation loss: 0.3432
2024-06-02 21:03:26 [INFO]: Epoch 075 - training loss: 0.2891, validation loss: 0.3493
2024-06-02 21:03:27 [INFO]: Epoch 076 - training loss: 0.2983, validation loss: 0.3604
2024-06-02 21:03:28 [INFO]: Epoch 077 - training loss: 0.3025, validation loss: 0.3485
2024-06-02 21:03:29 [INFO]: Epoch 078 - training loss: 0.2908, validation loss: 0.3522
2024-06-02 21:03:30 [INFO]: Epoch 079 - training loss: 0.2891, validation loss: 0.3504
2024-06-02 21:03:31 [INFO]: Epoch 080 - training loss: 0.2917, validation loss: 0.3599
2024-06-02 21:03:32 [INFO]: Epoch 081 - training loss: 0.2992, validation loss: 0.3536
2024-06-02 21:03:33 [INFO]: Epoch 082 - training loss: 0.2838, validation loss: 0.3417
2024-06-02 21:03:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:03:33 [INFO]: Finished training. The best model is from epoch#72.
2024-06-02 21:03:33 [INFO]: Saved the model to results_point_rate05/Pedestrian/Informer_Pedestrian/round_4/20240602_T210215/Informer.pypots
2024-06-02 21:03:34 [INFO]: Successfully saved to results_point_rate05/Pedestrian/Informer_Pedestrian/round_4/imputation.pkl
2024-06-02 21:03:34 [INFO]: Round4 - Informer on Pedestrian: MAE=0.2110, MSE=0.3598, MRE=0.2777
2024-06-02 21:03:34 [INFO]: Done! Final results:
Averaged Informer (446,785 params) on Pedestrian: MAE=0.2104 ± 0.005655867551410302, MSE=0.3784 ± 0.021244627597969714, MRE=0.2768 ± 0.007442586247459104, average inference time=1.66
