2024-06-03 11:16:53 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 11:16:53 [INFO]: Using the given device: cuda:0
2024-06-03 11:16:54 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_0/20240603_T111654
2024-06-03 11:16:54 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_0/20240603_T111654/tensorboard
2024-06-03 11:16:55 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-03 11:17:09 [INFO]: Epoch 001 - training loss: 1.1090, validation loss: 0.5109
2024-06-03 11:17:15 [INFO]: Epoch 002 - training loss: 0.7219, validation loss: 0.4099
2024-06-03 11:17:21 [INFO]: Epoch 003 - training loss: 0.6065, validation loss: 0.3615
2024-06-03 11:17:27 [INFO]: Epoch 004 - training loss: 0.5530, validation loss: 0.3297
2024-06-03 11:17:32 [INFO]: Epoch 005 - training loss: 0.5199, validation loss: 0.3178
2024-06-03 11:17:38 [INFO]: Epoch 006 - training loss: 0.4838, validation loss: 0.2983
2024-06-03 11:17:44 [INFO]: Epoch 007 - training loss: 0.4641, validation loss: 0.2941
2024-06-03 11:17:50 [INFO]: Epoch 008 - training loss: 0.4506, validation loss: 0.2822
2024-06-03 11:17:55 [INFO]: Epoch 009 - training loss: 0.4337, validation loss: 0.2781
2024-06-03 11:18:01 [INFO]: Epoch 010 - training loss: 0.4245, validation loss: 0.2759
2024-06-03 11:18:07 [INFO]: Epoch 011 - training loss: 0.4186, validation loss: 0.2715
2024-06-03 11:18:13 [INFO]: Epoch 012 - training loss: 0.4090, validation loss: 0.2677
2024-06-03 11:18:19 [INFO]: Epoch 013 - training loss: 0.4032, validation loss: 0.2691
2024-06-03 11:18:24 [INFO]: Epoch 014 - training loss: 0.4020, validation loss: 0.2662
2024-06-03 11:18:30 [INFO]: Epoch 015 - training loss: 0.3961, validation loss: 0.2657
2024-06-03 11:18:36 [INFO]: Epoch 016 - training loss: 0.3921, validation loss: 0.2627
2024-06-03 11:18:42 [INFO]: Epoch 017 - training loss: 0.3862, validation loss: 0.2636
2024-06-03 11:18:48 [INFO]: Epoch 018 - training loss: 0.3822, validation loss: 0.2610
2024-06-03 11:18:54 [INFO]: Epoch 019 - training loss: 0.3799, validation loss: 0.2630
2024-06-03 11:19:00 [INFO]: Epoch 020 - training loss: 0.3816, validation loss: 0.2595
2024-06-03 11:19:05 [INFO]: Epoch 021 - training loss: 0.3747, validation loss: 0.2601
2024-06-03 11:19:11 [INFO]: Epoch 022 - training loss: 0.3705, validation loss: 0.2618
2024-06-03 11:19:16 [INFO]: Epoch 023 - training loss: 0.3737, validation loss: 0.2608
2024-06-03 11:19:22 [INFO]: Epoch 024 - training loss: 0.3666, validation loss: 0.2579
2024-06-03 11:19:28 [INFO]: Epoch 025 - training loss: 0.3617, validation loss: 0.2574
2024-06-03 11:19:34 [INFO]: Epoch 026 - training loss: 0.3627, validation loss: 0.2576
2024-06-03 11:19:40 [INFO]: Epoch 027 - training loss: 0.3601, validation loss: 0.2548
2024-06-03 11:19:46 [INFO]: Epoch 028 - training loss: 0.3555, validation loss: 0.2576
2024-06-03 11:19:52 [INFO]: Epoch 029 - training loss: 0.3554, validation loss: 0.2546
2024-06-03 11:19:57 [INFO]: Epoch 030 - training loss: 0.3543, validation loss: 0.2574
2024-06-03 11:20:03 [INFO]: Epoch 031 - training loss: 0.3519, validation loss: 0.2553
2024-06-03 11:20:09 [INFO]: Epoch 032 - training loss: 0.3502, validation loss: 0.2533
2024-06-03 11:20:15 [INFO]: Epoch 033 - training loss: 0.3454, validation loss: 0.2554
2024-06-03 11:20:21 [INFO]: Epoch 034 - training loss: 0.3509, validation loss: 0.2560
2024-06-03 11:20:26 [INFO]: Epoch 035 - training loss: 0.3446, validation loss: 0.2540
2024-06-03 11:20:32 [INFO]: Epoch 036 - training loss: 0.3453, validation loss: 0.2529
2024-06-03 11:20:38 [INFO]: Epoch 037 - training loss: 0.3437, validation loss: 0.2523
2024-06-03 11:20:44 [INFO]: Epoch 038 - training loss: 0.3427, validation loss: 0.2522
2024-06-03 11:20:49 [INFO]: Epoch 039 - training loss: 0.3375, validation loss: 0.2502
2024-06-03 11:20:55 [INFO]: Epoch 040 - training loss: 0.3395, validation loss: 0.2535
2024-06-03 11:21:01 [INFO]: Epoch 041 - training loss: 0.3409, validation loss: 0.2515
2024-06-03 11:21:07 [INFO]: Epoch 042 - training loss: 0.3348, validation loss: 0.2518
2024-06-03 11:21:12 [INFO]: Epoch 043 - training loss: 0.3330, validation loss: 0.2488
2024-06-03 11:21:18 [INFO]: Epoch 044 - training loss: 0.3334, validation loss: 0.2489
2024-06-03 11:21:24 [INFO]: Epoch 045 - training loss: 0.3299, validation loss: 0.2479
2024-06-03 11:21:30 [INFO]: Epoch 046 - training loss: 0.3288, validation loss: 0.2495
2024-06-03 11:21:36 [INFO]: Epoch 047 - training loss: 0.3312, validation loss: 0.2490
2024-06-03 11:21:41 [INFO]: Epoch 048 - training loss: 0.3270, validation loss: 0.2484
2024-06-03 11:21:47 [INFO]: Epoch 049 - training loss: 0.3264, validation loss: 0.2471
2024-06-03 11:21:53 [INFO]: Epoch 050 - training loss: 0.3269, validation loss: 0.2488
2024-06-03 11:21:59 [INFO]: Epoch 051 - training loss: 0.3271, validation loss: 0.2473
2024-06-03 11:22:04 [INFO]: Epoch 052 - training loss: 0.3233, validation loss: 0.2469
2024-06-03 11:22:10 [INFO]: Epoch 053 - training loss: 0.3256, validation loss: 0.2459
2024-06-03 11:22:15 [INFO]: Epoch 054 - training loss: 0.3233, validation loss: 0.2465
2024-06-03 11:22:22 [INFO]: Epoch 055 - training loss: 0.3187, validation loss: 0.2461
2024-06-03 11:22:27 [INFO]: Epoch 056 - training loss: 0.3198, validation loss: 0.2460
2024-06-03 11:22:33 [INFO]: Epoch 057 - training loss: 0.3195, validation loss: 0.2455
2024-06-03 11:22:39 [INFO]: Epoch 058 - training loss: 0.3168, validation loss: 0.2456
2024-06-03 11:22:44 [INFO]: Epoch 059 - training loss: 0.3184, validation loss: 0.2449
2024-06-03 11:22:50 [INFO]: Epoch 060 - training loss: 0.3151, validation loss: 0.2445
2024-06-03 11:22:56 [INFO]: Epoch 061 - training loss: 0.3130, validation loss: 0.2450
2024-06-03 11:23:02 [INFO]: Epoch 062 - training loss: 0.3134, validation loss: 0.2456
2024-06-03 11:23:08 [INFO]: Epoch 063 - training loss: 0.3136, validation loss: 0.2441
2024-06-03 11:23:13 [INFO]: Epoch 064 - training loss: 0.3121, validation loss: 0.2439
2024-06-03 11:23:19 [INFO]: Epoch 065 - training loss: 0.3103, validation loss: 0.2424
2024-06-03 11:23:25 [INFO]: Epoch 066 - training loss: 0.3090, validation loss: 0.2427
2024-06-03 11:23:30 [INFO]: Epoch 067 - training loss: 0.3111, validation loss: 0.2433
2024-06-03 11:23:36 [INFO]: Epoch 068 - training loss: 0.3133, validation loss: 0.2417
2024-06-03 11:23:41 [INFO]: Epoch 069 - training loss: 0.3127, validation loss: 0.2421
2024-06-03 11:23:47 [INFO]: Epoch 070 - training loss: 0.3081, validation loss: 0.2421
2024-06-03 11:23:53 [INFO]: Epoch 071 - training loss: 0.3078, validation loss: 0.2418
2024-06-03 11:23:59 [INFO]: Epoch 072 - training loss: 0.3059, validation loss: 0.2410
2024-06-03 11:24:04 [INFO]: Epoch 073 - training loss: 0.3067, validation loss: 0.2428
2024-06-03 11:24:10 [INFO]: Epoch 074 - training loss: 0.3071, validation loss: 0.2412
2024-06-03 11:24:15 [INFO]: Epoch 075 - training loss: 0.3046, validation loss: 0.2401
2024-06-03 11:24:21 [INFO]: Epoch 076 - training loss: 0.3010, validation loss: 0.2412
2024-06-03 11:24:26 [INFO]: Epoch 077 - training loss: 0.3028, validation loss: 0.2410
2024-06-03 11:24:31 [INFO]: Epoch 078 - training loss: 0.3065, validation loss: 0.2399
2024-06-03 11:24:37 [INFO]: Epoch 079 - training loss: 0.3042, validation loss: 0.2401
2024-06-03 11:24:43 [INFO]: Epoch 080 - training loss: 0.3059, validation loss: 0.2418
2024-06-03 11:24:49 [INFO]: Epoch 081 - training loss: 0.3045, validation loss: 0.2401
2024-06-03 11:24:54 [INFO]: Epoch 082 - training loss: 0.3039, validation loss: 0.2408
2024-06-03 11:25:00 [INFO]: Epoch 083 - training loss: 0.2994, validation loss: 0.2391
2024-06-03 11:25:06 [INFO]: Epoch 084 - training loss: 0.2979, validation loss: 0.2392
2024-06-03 11:25:12 [INFO]: Epoch 085 - training loss: 0.2974, validation loss: 0.2397
2024-06-03 11:25:18 [INFO]: Epoch 086 - training loss: 0.3006, validation loss: 0.2399
2024-06-03 11:25:23 [INFO]: Epoch 087 - training loss: 0.2983, validation loss: 0.2382
2024-06-03 11:25:29 [INFO]: Epoch 088 - training loss: 0.2976, validation loss: 0.2396
2024-06-03 11:25:35 [INFO]: Epoch 089 - training loss: 0.3002, validation loss: 0.2417
2024-06-03 11:25:41 [INFO]: Epoch 090 - training loss: 0.2999, validation loss: 0.2415
2024-06-03 11:25:47 [INFO]: Epoch 091 - training loss: 0.2980, validation loss: 0.2390
2024-06-03 11:25:53 [INFO]: Epoch 092 - training loss: 0.2985, validation loss: 0.2397
2024-06-03 11:25:58 [INFO]: Epoch 093 - training loss: 0.2976, validation loss: 0.2364
2024-06-03 11:26:04 [INFO]: Epoch 094 - training loss: 0.2952, validation loss: 0.2372
2024-06-03 11:26:08 [INFO]: Epoch 095 - training loss: 0.2953, validation loss: 0.2382
2024-06-03 11:26:13 [INFO]: Epoch 096 - training loss: 0.2945, validation loss: 0.2378
2024-06-03 11:26:17 [INFO]: Epoch 097 - training loss: 0.2964, validation loss: 0.2370
2024-06-03 11:26:23 [INFO]: Epoch 098 - training loss: 0.2930, validation loss: 0.2359
2024-06-03 11:26:29 [INFO]: Epoch 099 - training loss: 0.2898, validation loss: 0.2364
2024-06-03 11:26:35 [INFO]: Epoch 100 - training loss: 0.2932, validation loss: 0.2367
2024-06-03 11:26:35 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 11:26:35 [INFO]: Saved the model to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_0/20240603_T111654/StemGNN.pypots
2024-06-03 11:26:38 [INFO]: Successfully saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_0/imputation.pkl
2024-06-03 11:26:38 [INFO]: Round0 - StemGNN on BeijingAir: MAE=0.1917, MSE=0.2665, MRE=0.2610
2024-06-03 11:26:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 11:26:38 [INFO]: Using the given device: cuda:0
2024-06-03 11:26:38 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_1/20240603_T112638
2024-06-03 11:26:38 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_1/20240603_T112638/tensorboard
2024-06-03 11:26:38 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-03 11:26:44 [INFO]: Epoch 001 - training loss: 1.1396, validation loss: 0.5255
2024-06-03 11:26:50 [INFO]: Epoch 002 - training loss: 0.7280, validation loss: 0.3968
2024-06-03 11:26:55 [INFO]: Epoch 003 - training loss: 0.5881, validation loss: 0.3487
2024-06-03 11:27:02 [INFO]: Epoch 004 - training loss: 0.5262, validation loss: 0.3210
2024-06-03 11:27:07 [INFO]: Epoch 005 - training loss: 0.4975, validation loss: 0.3046
2024-06-03 11:27:13 [INFO]: Epoch 006 - training loss: 0.4731, validation loss: 0.2919
2024-06-03 11:27:18 [INFO]: Epoch 007 - training loss: 0.4616, validation loss: 0.2876
2024-06-03 11:27:24 [INFO]: Epoch 008 - training loss: 0.4451, validation loss: 0.2800
2024-06-03 11:27:30 [INFO]: Epoch 009 - training loss: 0.4354, validation loss: 0.2775
2024-06-03 11:27:35 [INFO]: Epoch 010 - training loss: 0.4309, validation loss: 0.2733
2024-06-03 11:27:41 [INFO]: Epoch 011 - training loss: 0.4219, validation loss: 0.2732
2024-06-03 11:27:47 [INFO]: Epoch 012 - training loss: 0.4196, validation loss: 0.2736
2024-06-03 11:27:53 [INFO]: Epoch 013 - training loss: 0.4113, validation loss: 0.2692
2024-06-03 11:27:59 [INFO]: Epoch 014 - training loss: 0.4059, validation loss: 0.2660
2024-06-03 11:28:04 [INFO]: Epoch 015 - training loss: 0.4028, validation loss: 0.2702
2024-06-03 11:28:10 [INFO]: Epoch 016 - training loss: 0.3994, validation loss: 0.2677
2024-06-03 11:28:16 [INFO]: Epoch 017 - training loss: 0.3934, validation loss: 0.2648
2024-06-03 11:28:22 [INFO]: Epoch 018 - training loss: 0.3883, validation loss: 0.2642
2024-06-03 11:28:28 [INFO]: Epoch 019 - training loss: 0.3859, validation loss: 0.2645
2024-06-03 11:28:34 [INFO]: Epoch 020 - training loss: 0.3847, validation loss: 0.2610
2024-06-03 11:28:39 [INFO]: Epoch 021 - training loss: 0.3810, validation loss: 0.2599
2024-06-03 11:28:45 [INFO]: Epoch 022 - training loss: 0.3794, validation loss: 0.2612
2024-06-03 11:28:51 [INFO]: Epoch 023 - training loss: 0.3766, validation loss: 0.2606
2024-06-03 11:28:56 [INFO]: Epoch 024 - training loss: 0.3724, validation loss: 0.2603
2024-06-03 11:29:02 [INFO]: Epoch 025 - training loss: 0.3713, validation loss: 0.2569
2024-06-03 11:29:07 [INFO]: Epoch 026 - training loss: 0.3656, validation loss: 0.2592
2024-06-03 11:29:13 [INFO]: Epoch 027 - training loss: 0.3649, validation loss: 0.2597
2024-06-03 11:29:18 [INFO]: Epoch 028 - training loss: 0.3630, validation loss: 0.2565
2024-06-03 11:29:24 [INFO]: Epoch 029 - training loss: 0.3609, validation loss: 0.2571
2024-06-03 11:29:29 [INFO]: Epoch 030 - training loss: 0.3613, validation loss: 0.2580
2024-06-03 11:29:34 [INFO]: Epoch 031 - training loss: 0.3588, validation loss: 0.2554
2024-06-03 11:29:39 [INFO]: Epoch 032 - training loss: 0.3554, validation loss: 0.2566
2024-06-03 11:29:45 [INFO]: Epoch 033 - training loss: 0.3540, validation loss: 0.2542
2024-06-03 11:29:50 [INFO]: Epoch 034 - training loss: 0.3517, validation loss: 0.2584
2024-06-03 11:29:56 [INFO]: Epoch 035 - training loss: 0.3507, validation loss: 0.2545
2024-06-03 11:30:01 [INFO]: Epoch 036 - training loss: 0.3510, validation loss: 0.2584
2024-06-03 11:30:06 [INFO]: Epoch 037 - training loss: 0.3473, validation loss: 0.2533
2024-06-03 11:30:11 [INFO]: Epoch 038 - training loss: 0.3457, validation loss: 0.2528
2024-06-03 11:30:17 [INFO]: Epoch 039 - training loss: 0.3407, validation loss: 0.2534
2024-06-03 11:30:22 [INFO]: Epoch 040 - training loss: 0.3419, validation loss: 0.2550
2024-06-03 11:30:27 [INFO]: Epoch 041 - training loss: 0.3406, validation loss: 0.2537
2024-06-03 11:30:33 [INFO]: Epoch 042 - training loss: 0.3397, validation loss: 0.2542
2024-06-03 11:30:38 [INFO]: Epoch 043 - training loss: 0.3381, validation loss: 0.2510
2024-06-03 11:30:43 [INFO]: Epoch 044 - training loss: 0.3374, validation loss: 0.2523
2024-06-03 11:30:49 [INFO]: Epoch 045 - training loss: 0.3365, validation loss: 0.2509
2024-06-03 11:30:54 [INFO]: Epoch 046 - training loss: 0.3366, validation loss: 0.2536
2024-06-03 11:30:59 [INFO]: Epoch 047 - training loss: 0.3338, validation loss: 0.2518
2024-06-03 11:31:04 [INFO]: Epoch 048 - training loss: 0.3308, validation loss: 0.2524
2024-06-03 11:31:09 [INFO]: Epoch 049 - training loss: 0.3301, validation loss: 0.2564
2024-06-03 11:31:14 [INFO]: Epoch 050 - training loss: 0.3322, validation loss: 0.2514
2024-06-03 11:31:19 [INFO]: Epoch 051 - training loss: 0.3291, validation loss: 0.2498
2024-06-03 11:31:24 [INFO]: Epoch 052 - training loss: 0.3269, validation loss: 0.2493
2024-06-03 11:31:29 [INFO]: Epoch 053 - training loss: 0.3277, validation loss: 0.2494
2024-06-03 11:31:35 [INFO]: Epoch 054 - training loss: 0.3261, validation loss: 0.2496
2024-06-03 11:31:40 [INFO]: Epoch 055 - training loss: 0.3258, validation loss: 0.2520
2024-06-03 11:31:45 [INFO]: Epoch 056 - training loss: 0.3252, validation loss: 0.2529
2024-06-03 11:31:51 [INFO]: Epoch 057 - training loss: 0.3257, validation loss: 0.2505
2024-06-03 11:31:56 [INFO]: Epoch 058 - training loss: 0.3247, validation loss: 0.2490
2024-06-03 11:32:01 [INFO]: Epoch 059 - training loss: 0.3217, validation loss: 0.2491
2024-06-03 11:32:07 [INFO]: Epoch 060 - training loss: 0.3218, validation loss: 0.2497
2024-06-03 11:32:12 [INFO]: Epoch 061 - training loss: 0.3216, validation loss: 0.2483
2024-06-03 11:32:17 [INFO]: Epoch 062 - training loss: 0.3185, validation loss: 0.2472
2024-06-03 11:32:22 [INFO]: Epoch 063 - training loss: 0.3181, validation loss: 0.2455
2024-06-03 11:32:27 [INFO]: Epoch 064 - training loss: 0.3167, validation loss: 0.2471
2024-06-03 11:32:32 [INFO]: Epoch 065 - training loss: 0.3173, validation loss: 0.2493
2024-06-03 11:32:38 [INFO]: Epoch 066 - training loss: 0.3206, validation loss: 0.2482
2024-06-03 11:32:43 [INFO]: Epoch 067 - training loss: 0.3175, validation loss: 0.2476
2024-06-03 11:32:48 [INFO]: Epoch 068 - training loss: 0.3153, validation loss: 0.2470
2024-06-03 11:32:53 [INFO]: Epoch 069 - training loss: 0.3143, validation loss: 0.2508
2024-06-03 11:32:58 [INFO]: Epoch 070 - training loss: 0.3195, validation loss: 0.2488
2024-06-03 11:33:04 [INFO]: Epoch 071 - training loss: 0.3137, validation loss: 0.2479
2024-06-03 11:33:09 [INFO]: Epoch 072 - training loss: 0.3102, validation loss: 0.2466
2024-06-03 11:33:14 [INFO]: Epoch 073 - training loss: 0.3129, validation loss: 0.2490
2024-06-03 11:33:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:33:14 [INFO]: Finished training. The best model is from epoch#63.
2024-06-03 11:33:14 [INFO]: Saved the model to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_1/20240603_T112638/StemGNN.pypots
2024-06-03 11:33:17 [INFO]: Successfully saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_1/imputation.pkl
2024-06-03 11:33:17 [INFO]: Round1 - StemGNN on BeijingAir: MAE=0.2007, MSE=0.2782, MRE=0.2733
2024-06-03 11:33:17 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 11:33:17 [INFO]: Using the given device: cuda:0
2024-06-03 11:33:17 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_2/20240603_T113317
2024-06-03 11:33:17 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_2/20240603_T113317/tensorboard
2024-06-03 11:33:17 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-03 11:33:23 [INFO]: Epoch 001 - training loss: 1.1379, validation loss: 0.5189
2024-06-03 11:33:28 [INFO]: Epoch 002 - training loss: 0.7140, validation loss: 0.3993
2024-06-03 11:33:33 [INFO]: Epoch 003 - training loss: 0.6109, validation loss: 0.3664
2024-06-03 11:33:38 [INFO]: Epoch 004 - training loss: 0.5502, validation loss: 0.3307
2024-06-03 11:33:43 [INFO]: Epoch 005 - training loss: 0.5048, validation loss: 0.3102
2024-06-03 11:33:49 [INFO]: Epoch 006 - training loss: 0.4806, validation loss: 0.3032
2024-06-03 11:33:54 [INFO]: Epoch 007 - training loss: 0.4671, validation loss: 0.2935
2024-06-03 11:33:59 [INFO]: Epoch 008 - training loss: 0.4528, validation loss: 0.2892
2024-06-03 11:34:04 [INFO]: Epoch 009 - training loss: 0.4423, validation loss: 0.2859
2024-06-03 11:34:09 [INFO]: Epoch 010 - training loss: 0.4320, validation loss: 0.2798
2024-06-03 11:34:15 [INFO]: Epoch 011 - training loss: 0.4255, validation loss: 0.2776
2024-06-03 11:34:20 [INFO]: Epoch 012 - training loss: 0.4168, validation loss: 0.2745
2024-06-03 11:34:25 [INFO]: Epoch 013 - training loss: 0.4153, validation loss: 0.2725
2024-06-03 11:34:31 [INFO]: Epoch 014 - training loss: 0.4083, validation loss: 0.2698
2024-06-03 11:34:36 [INFO]: Epoch 015 - training loss: 0.4053, validation loss: 0.2715
2024-06-03 11:34:41 [INFO]: Epoch 016 - training loss: 0.4000, validation loss: 0.2710
2024-06-03 11:34:47 [INFO]: Epoch 017 - training loss: 0.3966, validation loss: 0.2685
2024-06-03 11:34:52 [INFO]: Epoch 018 - training loss: 0.3916, validation loss: 0.2665
2024-06-03 11:34:57 [INFO]: Epoch 019 - training loss: 0.3866, validation loss: 0.2672
2024-06-03 11:35:02 [INFO]: Epoch 020 - training loss: 0.3861, validation loss: 0.2653
2024-06-03 11:35:07 [INFO]: Epoch 021 - training loss: 0.3839, validation loss: 0.2657
2024-06-03 11:35:12 [INFO]: Epoch 022 - training loss: 0.3815, validation loss: 0.2651
2024-06-03 11:35:17 [INFO]: Epoch 023 - training loss: 0.3786, validation loss: 0.2640
2024-06-03 11:35:23 [INFO]: Epoch 024 - training loss: 0.3781, validation loss: 0.2658
2024-06-03 11:35:28 [INFO]: Epoch 025 - training loss: 0.3727, validation loss: 0.2637
2024-06-03 11:35:33 [INFO]: Epoch 026 - training loss: 0.3704, validation loss: 0.2613
2024-06-03 11:35:38 [INFO]: Epoch 027 - training loss: 0.3654, validation loss: 0.2596
2024-06-03 11:35:43 [INFO]: Epoch 028 - training loss: 0.3655, validation loss: 0.2618
2024-06-03 11:35:48 [INFO]: Epoch 029 - training loss: 0.3633, validation loss: 0.2615
2024-06-03 11:35:54 [INFO]: Epoch 030 - training loss: 0.3613, validation loss: 0.2588
2024-06-03 11:35:58 [INFO]: Epoch 031 - training loss: 0.3585, validation loss: 0.2646
2024-06-03 11:36:04 [INFO]: Epoch 032 - training loss: 0.3590, validation loss: 0.2584
2024-06-03 11:36:09 [INFO]: Epoch 033 - training loss: 0.3563, validation loss: 0.2614
2024-06-03 11:36:14 [INFO]: Epoch 034 - training loss: 0.3542, validation loss: 0.2603
2024-06-03 11:36:19 [INFO]: Epoch 035 - training loss: 0.3522, validation loss: 0.2607
2024-06-03 11:36:23 [INFO]: Epoch 036 - training loss: 0.3477, validation loss: 0.2610
2024-06-03 11:36:27 [INFO]: Epoch 037 - training loss: 0.3511, validation loss: 0.2570
2024-06-03 11:36:31 [INFO]: Epoch 038 - training loss: 0.3537, validation loss: 0.2563
2024-06-03 11:36:36 [INFO]: Epoch 039 - training loss: 0.3468, validation loss: 0.2554
2024-06-03 11:36:42 [INFO]: Epoch 040 - training loss: 0.3428, validation loss: 0.2558
2024-06-03 11:36:47 [INFO]: Epoch 041 - training loss: 0.3423, validation loss: 0.2543
2024-06-03 11:36:52 [INFO]: Epoch 042 - training loss: 0.3396, validation loss: 0.2546
2024-06-03 11:36:57 [INFO]: Epoch 043 - training loss: 0.3364, validation loss: 0.2549
2024-06-03 11:37:02 [INFO]: Epoch 044 - training loss: 0.3403, validation loss: 0.2539
2024-06-03 11:37:08 [INFO]: Epoch 045 - training loss: 0.3390, validation loss: 0.2534
2024-06-03 11:37:13 [INFO]: Epoch 046 - training loss: 0.3363, validation loss: 0.2544
2024-06-03 11:37:19 [INFO]: Epoch 047 - training loss: 0.3362, validation loss: 0.2551
2024-06-03 11:37:24 [INFO]: Epoch 048 - training loss: 0.3342, validation loss: 0.2535
2024-06-03 11:37:29 [INFO]: Epoch 049 - training loss: 0.3325, validation loss: 0.2524
2024-06-03 11:37:35 [INFO]: Epoch 050 - training loss: 0.3356, validation loss: 0.2525
2024-06-03 11:37:39 [INFO]: Epoch 051 - training loss: 0.3313, validation loss: 0.2532
2024-06-03 11:37:45 [INFO]: Epoch 052 - training loss: 0.3323, validation loss: 0.2529
2024-06-03 11:37:50 [INFO]: Epoch 053 - training loss: 0.3275, validation loss: 0.2510
2024-06-03 11:37:55 [INFO]: Epoch 054 - training loss: 0.3277, validation loss: 0.2507
2024-06-03 11:38:00 [INFO]: Epoch 055 - training loss: 0.3262, validation loss: 0.2510
2024-06-03 11:38:05 [INFO]: Epoch 056 - training loss: 0.3266, validation loss: 0.2495
2024-06-03 11:38:09 [INFO]: Epoch 057 - training loss: 0.3284, validation loss: 0.2492
2024-06-03 11:38:14 [INFO]: Epoch 058 - training loss: 0.3238, validation loss: 0.2494
2024-06-03 11:38:19 [INFO]: Epoch 059 - training loss: 0.3211, validation loss: 0.2521
2024-06-03 11:38:24 [INFO]: Epoch 060 - training loss: 0.3205, validation loss: 0.2496
2024-06-03 11:38:28 [INFO]: Epoch 061 - training loss: 0.3198, validation loss: 0.2485
2024-06-03 11:38:33 [INFO]: Epoch 062 - training loss: 0.3192, validation loss: 0.2487
2024-06-03 11:38:38 [INFO]: Epoch 063 - training loss: 0.3173, validation loss: 0.2475
2024-06-03 11:38:43 [INFO]: Epoch 064 - training loss: 0.3198, validation loss: 0.2480
2024-06-03 11:38:48 [INFO]: Epoch 065 - training loss: 0.3174, validation loss: 0.2463
2024-06-03 11:38:52 [INFO]: Epoch 066 - training loss: 0.3191, validation loss: 0.2485
2024-06-03 11:38:57 [INFO]: Epoch 067 - training loss: 0.3163, validation loss: 0.2477
2024-06-03 11:39:02 [INFO]: Epoch 068 - training loss: 0.3158, validation loss: 0.2470
2024-06-03 11:39:06 [INFO]: Epoch 069 - training loss: 0.3153, validation loss: 0.2478
2024-06-03 11:39:11 [INFO]: Epoch 070 - training loss: 0.3173, validation loss: 0.2478
2024-06-03 11:39:16 [INFO]: Epoch 071 - training loss: 0.3165, validation loss: 0.2474
2024-06-03 11:39:20 [INFO]: Epoch 072 - training loss: 0.3162, validation loss: 0.2461
2024-06-03 11:39:25 [INFO]: Epoch 073 - training loss: 0.3104, validation loss: 0.2475
2024-06-03 11:39:30 [INFO]: Epoch 074 - training loss: 0.3125, validation loss: 0.2471
2024-06-03 11:39:35 [INFO]: Epoch 075 - training loss: 0.3143, validation loss: 0.2470
2024-06-03 11:39:40 [INFO]: Epoch 076 - training loss: 0.3115, validation loss: 0.2458
2024-06-03 11:39:45 [INFO]: Epoch 077 - training loss: 0.3142, validation loss: 0.2453
2024-06-03 11:39:50 [INFO]: Epoch 078 - training loss: 0.3137, validation loss: 0.2500
2024-06-03 11:39:55 [INFO]: Epoch 079 - training loss: 0.3120, validation loss: 0.2456
2024-06-03 11:39:59 [INFO]: Epoch 080 - training loss: 0.3085, validation loss: 0.2452
2024-06-03 11:40:04 [INFO]: Epoch 081 - training loss: 0.3065, validation loss: 0.2468
2024-06-03 11:40:09 [INFO]: Epoch 082 - training loss: 0.3076, validation loss: 0.2446
2024-06-03 11:40:14 [INFO]: Epoch 083 - training loss: 0.3075, validation loss: 0.2452
2024-06-03 11:40:18 [INFO]: Epoch 084 - training loss: 0.3058, validation loss: 0.2458
2024-06-03 11:40:22 [INFO]: Epoch 085 - training loss: 0.3073, validation loss: 0.2454
2024-06-03 11:40:26 [INFO]: Epoch 086 - training loss: 0.3064, validation loss: 0.2454
2024-06-03 11:40:30 [INFO]: Epoch 087 - training loss: 0.3064, validation loss: 0.2457
2024-06-03 11:40:35 [INFO]: Epoch 088 - training loss: 0.3052, validation loss: 0.2451
2024-06-03 11:40:40 [INFO]: Epoch 089 - training loss: 0.3049, validation loss: 0.2434
2024-06-03 11:40:44 [INFO]: Epoch 090 - training loss: 0.3067, validation loss: 0.2438
2024-06-03 11:40:49 [INFO]: Epoch 091 - training loss: 0.3054, validation loss: 0.2431
2024-06-03 11:40:54 [INFO]: Epoch 092 - training loss: 0.3035, validation loss: 0.2437
2024-06-03 11:40:59 [INFO]: Epoch 093 - training loss: 0.3015, validation loss: 0.2434
2024-06-03 11:41:04 [INFO]: Epoch 094 - training loss: 0.3019, validation loss: 0.2430
2024-06-03 11:41:09 [INFO]: Epoch 095 - training loss: 0.3020, validation loss: 0.2443
2024-06-03 11:41:14 [INFO]: Epoch 096 - training loss: 0.2998, validation loss: 0.2436
2024-06-03 11:41:19 [INFO]: Epoch 097 - training loss: 0.2998, validation loss: 0.2466
2024-06-03 11:41:23 [INFO]: Epoch 098 - training loss: 0.3044, validation loss: 0.2444
2024-06-03 11:41:28 [INFO]: Epoch 099 - training loss: 0.2998, validation loss: 0.2426
2024-06-03 11:41:33 [INFO]: Epoch 100 - training loss: 0.2988, validation loss: 0.2454
2024-06-03 11:41:33 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 11:41:33 [INFO]: Saved the model to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_2/20240603_T113317/StemGNN.pypots
2024-06-03 11:41:35 [INFO]: Successfully saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_2/imputation.pkl
2024-06-03 11:41:35 [INFO]: Round2 - StemGNN on BeijingAir: MAE=0.1996, MSE=0.2748, MRE=0.2717
2024-06-03 11:41:35 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 11:41:35 [INFO]: Using the given device: cuda:0
2024-06-03 11:41:35 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_3/20240603_T114135
2024-06-03 11:41:35 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_3/20240603_T114135/tensorboard
2024-06-03 11:41:35 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-03 11:41:39 [INFO]: Epoch 001 - training loss: 1.1457, validation loss: 0.5155
2024-06-03 11:41:42 [INFO]: Epoch 002 - training loss: 0.7139, validation loss: 0.4105
2024-06-03 11:41:46 [INFO]: Epoch 003 - training loss: 0.6054, validation loss: 0.3526
2024-06-03 11:41:50 [INFO]: Epoch 004 - training loss: 0.5516, validation loss: 0.3278
2024-06-03 11:41:54 [INFO]: Epoch 005 - training loss: 0.5109, validation loss: 0.3108
2024-06-03 11:41:57 [INFO]: Epoch 006 - training loss: 0.4847, validation loss: 0.3007
2024-06-03 11:42:01 [INFO]: Epoch 007 - training loss: 0.4637, validation loss: 0.2904
2024-06-03 11:42:05 [INFO]: Epoch 008 - training loss: 0.4513, validation loss: 0.2853
2024-06-03 11:42:09 [INFO]: Epoch 009 - training loss: 0.4397, validation loss: 0.2805
2024-06-03 11:42:12 [INFO]: Epoch 010 - training loss: 0.4314, validation loss: 0.2827
2024-06-03 11:42:16 [INFO]: Epoch 011 - training loss: 0.4254, validation loss: 0.2768
2024-06-03 11:42:20 [INFO]: Epoch 012 - training loss: 0.4176, validation loss: 0.2723
2024-06-03 11:42:24 [INFO]: Epoch 013 - training loss: 0.4137, validation loss: 0.2710
2024-06-03 11:42:27 [INFO]: Epoch 014 - training loss: 0.4057, validation loss: 0.2692
2024-06-03 11:42:31 [INFO]: Epoch 015 - training loss: 0.4026, validation loss: 0.2696
2024-06-03 11:42:35 [INFO]: Epoch 016 - training loss: 0.3942, validation loss: 0.2672
2024-06-03 11:42:38 [INFO]: Epoch 017 - training loss: 0.3933, validation loss: 0.2691
2024-06-03 11:42:42 [INFO]: Epoch 018 - training loss: 0.3901, validation loss: 0.2663
2024-06-03 11:42:45 [INFO]: Epoch 019 - training loss: 0.3896, validation loss: 0.2649
2024-06-03 11:42:49 [INFO]: Epoch 020 - training loss: 0.3817, validation loss: 0.2643
2024-06-03 11:42:52 [INFO]: Epoch 021 - training loss: 0.3782, validation loss: 0.2638
2024-06-03 11:42:56 [INFO]: Epoch 022 - training loss: 0.3768, validation loss: 0.2628
2024-06-03 11:42:59 [INFO]: Epoch 023 - training loss: 0.3734, validation loss: 0.2623
2024-06-03 11:43:03 [INFO]: Epoch 024 - training loss: 0.3699, validation loss: 0.2621
2024-06-03 11:43:07 [INFO]: Epoch 025 - training loss: 0.3678, validation loss: 0.2618
2024-06-03 11:43:10 [INFO]: Epoch 026 - training loss: 0.3637, validation loss: 0.2591
2024-06-03 11:43:13 [INFO]: Epoch 027 - training loss: 0.3633, validation loss: 0.2614
2024-06-03 11:43:16 [INFO]: Epoch 028 - training loss: 0.3635, validation loss: 0.2617
2024-06-03 11:43:20 [INFO]: Epoch 029 - training loss: 0.3580, validation loss: 0.2610
2024-06-03 11:43:23 [INFO]: Epoch 030 - training loss: 0.3583, validation loss: 0.2578
2024-06-03 11:43:27 [INFO]: Epoch 031 - training loss: 0.3525, validation loss: 0.2569
2024-06-03 11:43:30 [INFO]: Epoch 032 - training loss: 0.3535, validation loss: 0.2568
2024-06-03 11:43:34 [INFO]: Epoch 033 - training loss: 0.3491, validation loss: 0.2562
2024-06-03 11:43:37 [INFO]: Epoch 034 - training loss: 0.3481, validation loss: 0.2554
2024-06-03 11:43:41 [INFO]: Epoch 035 - training loss: 0.3471, validation loss: 0.2564
2024-06-03 11:43:44 [INFO]: Epoch 036 - training loss: 0.3482, validation loss: 0.2590
2024-06-03 11:43:48 [INFO]: Epoch 037 - training loss: 0.3477, validation loss: 0.2563
2024-06-03 11:43:51 [INFO]: Epoch 038 - training loss: 0.3441, validation loss: 0.2553
2024-06-03 11:43:55 [INFO]: Epoch 039 - training loss: 0.3418, validation loss: 0.2555
2024-06-03 11:43:59 [INFO]: Epoch 040 - training loss: 0.3404, validation loss: 0.2535
2024-06-03 11:44:02 [INFO]: Epoch 041 - training loss: 0.3396, validation loss: 0.2554
2024-06-03 11:44:06 [INFO]: Epoch 042 - training loss: 0.3390, validation loss: 0.2554
2024-06-03 11:44:09 [INFO]: Epoch 043 - training loss: 0.3359, validation loss: 0.2528
2024-06-03 11:44:13 [INFO]: Epoch 044 - training loss: 0.3345, validation loss: 0.2553
2024-06-03 11:44:16 [INFO]: Epoch 045 - training loss: 0.3334, validation loss: 0.2542
2024-06-03 11:44:20 [INFO]: Epoch 046 - training loss: 0.3355, validation loss: 0.2538
2024-06-03 11:44:23 [INFO]: Epoch 047 - training loss: 0.3347, validation loss: 0.2537
2024-06-03 11:44:27 [INFO]: Epoch 048 - training loss: 0.3310, validation loss: 0.2517
2024-06-03 11:44:30 [INFO]: Epoch 049 - training loss: 0.3297, validation loss: 0.2526
2024-06-03 11:44:34 [INFO]: Epoch 050 - training loss: 0.3290, validation loss: 0.2512
2024-06-03 11:44:37 [INFO]: Epoch 051 - training loss: 0.3290, validation loss: 0.2523
2024-06-03 11:44:41 [INFO]: Epoch 052 - training loss: 0.3262, validation loss: 0.2524
2024-06-03 11:44:44 [INFO]: Epoch 053 - training loss: 0.3248, validation loss: 0.2510
2024-06-03 11:44:48 [INFO]: Epoch 054 - training loss: 0.3269, validation loss: 0.2506
2024-06-03 11:44:51 [INFO]: Epoch 055 - training loss: 0.3269, validation loss: 0.2524
2024-06-03 11:44:55 [INFO]: Epoch 056 - training loss: 0.3240, validation loss: 0.2527
2024-06-03 11:44:58 [INFO]: Epoch 057 - training loss: 0.3224, validation loss: 0.2517
2024-06-03 11:45:02 [INFO]: Epoch 058 - training loss: 0.3202, validation loss: 0.2499
2024-06-03 11:45:05 [INFO]: Epoch 059 - training loss: 0.3208, validation loss: 0.2509
2024-06-03 11:45:09 [INFO]: Epoch 060 - training loss: 0.3205, validation loss: 0.2512
2024-06-03 11:45:12 [INFO]: Epoch 061 - training loss: 0.3191, validation loss: 0.2497
2024-06-03 11:45:16 [INFO]: Epoch 062 - training loss: 0.3196, validation loss: 0.2493
2024-06-03 11:45:19 [INFO]: Epoch 063 - training loss: 0.3164, validation loss: 0.2510
2024-06-03 11:45:23 [INFO]: Epoch 064 - training loss: 0.3176, validation loss: 0.2498
2024-06-03 11:45:26 [INFO]: Epoch 065 - training loss: 0.3137, validation loss: 0.2494
2024-06-03 11:45:30 [INFO]: Epoch 066 - training loss: 0.3146, validation loss: 0.2491
2024-06-03 11:45:33 [INFO]: Epoch 067 - training loss: 0.3151, validation loss: 0.2511
2024-06-03 11:45:36 [INFO]: Epoch 068 - training loss: 0.3161, validation loss: 0.2501
2024-06-03 11:45:40 [INFO]: Epoch 069 - training loss: 0.3159, validation loss: 0.2503
2024-06-03 11:45:44 [INFO]: Epoch 070 - training loss: 0.3166, validation loss: 0.2498
2024-06-03 11:45:47 [INFO]: Epoch 071 - training loss: 0.3134, validation loss: 0.2482
2024-06-03 11:45:50 [INFO]: Epoch 072 - training loss: 0.3117, validation loss: 0.2469
2024-06-03 11:45:54 [INFO]: Epoch 073 - training loss: 0.3100, validation loss: 0.2462
2024-06-03 11:45:57 [INFO]: Epoch 074 - training loss: 0.3111, validation loss: 0.2458
2024-06-03 11:46:01 [INFO]: Epoch 075 - training loss: 0.3096, validation loss: 0.2463
2024-06-03 11:46:04 [INFO]: Epoch 076 - training loss: 0.3091, validation loss: 0.2471
2024-06-03 11:46:08 [INFO]: Epoch 077 - training loss: 0.3085, validation loss: 0.2465
2024-06-03 11:46:12 [INFO]: Epoch 078 - training loss: 0.3079, validation loss: 0.2449
2024-06-03 11:46:15 [INFO]: Epoch 079 - training loss: 0.3057, validation loss: 0.2449
2024-06-03 11:46:19 [INFO]: Epoch 080 - training loss: 0.3114, validation loss: 0.2471
2024-06-03 11:46:22 [INFO]: Epoch 081 - training loss: 0.3062, validation loss: 0.2475
2024-06-03 11:46:26 [INFO]: Epoch 082 - training loss: 0.3071, validation loss: 0.2472
2024-06-03 11:46:28 [INFO]: Epoch 083 - training loss: 0.3062, validation loss: 0.2457
2024-06-03 11:46:31 [INFO]: Epoch 084 - training loss: 0.3063, validation loss: 0.2469
2024-06-03 11:46:33 [INFO]: Epoch 085 - training loss: 0.3048, validation loss: 0.2442
2024-06-03 11:46:37 [INFO]: Epoch 086 - training loss: 0.3056, validation loss: 0.2442
2024-06-03 11:46:40 [INFO]: Epoch 087 - training loss: 0.3034, validation loss: 0.2440
2024-06-03 11:46:44 [INFO]: Epoch 088 - training loss: 0.3028, validation loss: 0.2449
2024-06-03 11:46:48 [INFO]: Epoch 089 - training loss: 0.3030, validation loss: 0.2459
2024-06-03 11:46:51 [INFO]: Epoch 090 - training loss: 0.3032, validation loss: 0.2436
2024-06-03 11:46:54 [INFO]: Epoch 091 - training loss: 0.3032, validation loss: 0.2451
2024-06-03 11:46:58 [INFO]: Epoch 092 - training loss: 0.3000, validation loss: 0.2438
2024-06-03 11:47:01 [INFO]: Epoch 093 - training loss: 0.3000, validation loss: 0.2445
2024-06-03 11:47:05 [INFO]: Epoch 094 - training loss: 0.3013, validation loss: 0.2441
2024-06-03 11:47:08 [INFO]: Epoch 095 - training loss: 0.3022, validation loss: 0.2450
2024-06-03 11:47:12 [INFO]: Epoch 096 - training loss: 0.3002, validation loss: 0.2424
2024-06-03 11:47:16 [INFO]: Epoch 097 - training loss: 0.3002, validation loss: 0.2460
2024-06-03 11:47:19 [INFO]: Epoch 098 - training loss: 0.2968, validation loss: 0.2423
2024-06-03 11:47:23 [INFO]: Epoch 099 - training loss: 0.2995, validation loss: 0.2445
2024-06-03 11:47:26 [INFO]: Epoch 100 - training loss: 0.2976, validation loss: 0.2442
2024-06-03 11:47:26 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 11:47:26 [INFO]: Saved the model to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_3/20240603_T114135/StemGNN.pypots
2024-06-03 11:47:28 [INFO]: Successfully saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_3/imputation.pkl
2024-06-03 11:47:28 [INFO]: Round3 - StemGNN on BeijingAir: MAE=0.1950, MSE=0.2735, MRE=0.2655
2024-06-03 11:47:28 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 11:47:28 [INFO]: Using the given device: cuda:0
2024-06-03 11:47:28 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_4/20240603_T114728
2024-06-03 11:47:28 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_4/20240603_T114728/tensorboard
2024-06-03 11:47:28 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,645,628
2024-06-03 11:47:31 [INFO]: Epoch 001 - training loss: 1.1667, validation loss: 0.5457
2024-06-03 11:47:35 [INFO]: Epoch 002 - training loss: 0.7502, validation loss: 0.4093
2024-06-03 11:47:38 [INFO]: Epoch 003 - training loss: 0.6002, validation loss: 0.3454
2024-06-03 11:47:42 [INFO]: Epoch 004 - training loss: 0.5291, validation loss: 0.3197
2024-06-03 11:47:45 [INFO]: Epoch 005 - training loss: 0.4920, validation loss: 0.3050
2024-06-03 11:47:49 [INFO]: Epoch 006 - training loss: 0.4737, validation loss: 0.2955
2024-06-03 11:47:52 [INFO]: Epoch 007 - training loss: 0.4586, validation loss: 0.2920
2024-06-03 11:47:56 [INFO]: Epoch 008 - training loss: 0.4490, validation loss: 0.2815
2024-06-03 11:47:59 [INFO]: Epoch 009 - training loss: 0.4324, validation loss: 0.2812
2024-06-03 11:48:03 [INFO]: Epoch 010 - training loss: 0.4241, validation loss: 0.2737
2024-06-03 11:48:06 [INFO]: Epoch 011 - training loss: 0.4172, validation loss: 0.2777
2024-06-03 11:48:10 [INFO]: Epoch 012 - training loss: 0.4115, validation loss: 0.2691
2024-06-03 11:48:13 [INFO]: Epoch 013 - training loss: 0.4052, validation loss: 0.2697
2024-06-03 11:48:17 [INFO]: Epoch 014 - training loss: 0.4034, validation loss: 0.2693
2024-06-03 11:48:20 [INFO]: Epoch 015 - training loss: 0.4014, validation loss: 0.2683
2024-06-03 11:48:24 [INFO]: Epoch 016 - training loss: 0.3938, validation loss: 0.2664
2024-06-03 11:48:27 [INFO]: Epoch 017 - training loss: 0.3927, validation loss: 0.2679
2024-06-03 11:48:31 [INFO]: Epoch 018 - training loss: 0.3869, validation loss: 0.2644
2024-06-03 11:48:34 [INFO]: Epoch 019 - training loss: 0.3833, validation loss: 0.2652
2024-06-03 11:48:38 [INFO]: Epoch 020 - training loss: 0.3813, validation loss: 0.2647
2024-06-03 11:48:41 [INFO]: Epoch 021 - training loss: 0.3779, validation loss: 0.2615
2024-06-03 11:48:45 [INFO]: Epoch 022 - training loss: 0.3760, validation loss: 0.2592
2024-06-03 11:48:48 [INFO]: Epoch 023 - training loss: 0.3702, validation loss: 0.2619
2024-06-03 11:48:52 [INFO]: Epoch 024 - training loss: 0.3711, validation loss: 0.2609
2024-06-03 11:48:55 [INFO]: Epoch 025 - training loss: 0.3695, validation loss: 0.2600
2024-06-03 11:48:58 [INFO]: Epoch 026 - training loss: 0.3663, validation loss: 0.2589
2024-06-03 11:49:02 [INFO]: Epoch 027 - training loss: 0.3647, validation loss: 0.2608
2024-06-03 11:49:05 [INFO]: Epoch 028 - training loss: 0.3579, validation loss: 0.2578
2024-06-03 11:49:09 [INFO]: Epoch 029 - training loss: 0.3581, validation loss: 0.2576
2024-06-03 11:49:12 [INFO]: Epoch 030 - training loss: 0.3573, validation loss: 0.2576
2024-06-03 11:49:16 [INFO]: Epoch 031 - training loss: 0.3553, validation loss: 0.2594
2024-06-03 11:49:20 [INFO]: Epoch 032 - training loss: 0.3542, validation loss: 0.2558
2024-06-03 11:49:23 [INFO]: Epoch 033 - training loss: 0.3506, validation loss: 0.2574
2024-06-03 11:49:27 [INFO]: Epoch 034 - training loss: 0.3473, validation loss: 0.2550
2024-06-03 11:49:30 [INFO]: Epoch 035 - training loss: 0.3456, validation loss: 0.2531
2024-06-03 11:49:33 [INFO]: Epoch 036 - training loss: 0.3444, validation loss: 0.2549
2024-06-03 11:49:37 [INFO]: Epoch 037 - training loss: 0.3428, validation loss: 0.2535
2024-06-03 11:49:40 [INFO]: Epoch 038 - training loss: 0.3382, validation loss: 0.2526
2024-06-03 11:49:44 [INFO]: Epoch 039 - training loss: 0.3423, validation loss: 0.2555
2024-06-03 11:49:47 [INFO]: Epoch 040 - training loss: 0.3415, validation loss: 0.2528
2024-06-03 11:49:51 [INFO]: Epoch 041 - training loss: 0.3405, validation loss: 0.2556
2024-06-03 11:49:54 [INFO]: Epoch 042 - training loss: 0.3368, validation loss: 0.2526
2024-06-03 11:49:58 [INFO]: Epoch 043 - training loss: 0.3361, validation loss: 0.2521
2024-06-03 11:50:01 [INFO]: Epoch 044 - training loss: 0.3337, validation loss: 0.2523
2024-06-03 11:50:05 [INFO]: Epoch 045 - training loss: 0.3363, validation loss: 0.2535
2024-06-03 11:50:08 [INFO]: Epoch 046 - training loss: 0.3332, validation loss: 0.2512
2024-06-03 11:50:12 [INFO]: Epoch 047 - training loss: 0.3329, validation loss: 0.2524
2024-06-03 11:50:15 [INFO]: Epoch 048 - training loss: 0.3286, validation loss: 0.2506
2024-06-03 11:50:19 [INFO]: Epoch 049 - training loss: 0.3283, validation loss: 0.2484
2024-06-03 11:50:22 [INFO]: Epoch 050 - training loss: 0.3267, validation loss: 0.2506
2024-06-03 11:50:26 [INFO]: Epoch 051 - training loss: 0.3271, validation loss: 0.2517
2024-06-03 11:50:29 [INFO]: Epoch 052 - training loss: 0.3263, validation loss: 0.2499
2024-06-03 11:50:33 [INFO]: Epoch 053 - training loss: 0.3293, validation loss: 0.2497
2024-06-03 11:50:36 [INFO]: Epoch 054 - training loss: 0.3237, validation loss: 0.2497
2024-06-03 11:50:39 [INFO]: Epoch 055 - training loss: 0.3250, validation loss: 0.2500
2024-06-03 11:50:43 [INFO]: Epoch 056 - training loss: 0.3221, validation loss: 0.2476
2024-06-03 11:50:46 [INFO]: Epoch 057 - training loss: 0.3207, validation loss: 0.2476
2024-06-03 11:50:50 [INFO]: Epoch 058 - training loss: 0.3228, validation loss: 0.2499
2024-06-03 11:50:54 [INFO]: Epoch 059 - training loss: 0.3195, validation loss: 0.2487
2024-06-03 11:50:57 [INFO]: Epoch 060 - training loss: 0.3184, validation loss: 0.2483
2024-06-03 11:51:01 [INFO]: Epoch 061 - training loss: 0.3185, validation loss: 0.2488
2024-06-03 11:51:04 [INFO]: Epoch 062 - training loss: 0.3172, validation loss: 0.2482
2024-06-03 11:51:08 [INFO]: Epoch 063 - training loss: 0.3172, validation loss: 0.2501
2024-06-03 11:51:11 [INFO]: Epoch 064 - training loss: 0.3169, validation loss: 0.2499
2024-06-03 11:51:15 [INFO]: Epoch 065 - training loss: 0.3173, validation loss: 0.2474
2024-06-03 11:51:18 [INFO]: Epoch 066 - training loss: 0.3136, validation loss: 0.2469
2024-06-03 11:51:22 [INFO]: Epoch 067 - training loss: 0.3124, validation loss: 0.2474
2024-06-03 11:51:25 [INFO]: Epoch 068 - training loss: 0.3156, validation loss: 0.2478
2024-06-03 11:51:29 [INFO]: Epoch 069 - training loss: 0.3123, validation loss: 0.2473
2024-06-03 11:51:32 [INFO]: Epoch 070 - training loss: 0.3103, validation loss: 0.2463
2024-06-03 11:51:35 [INFO]: Epoch 071 - training loss: 0.3158, validation loss: 0.2469
2024-06-03 11:51:38 [INFO]: Epoch 072 - training loss: 0.3134, validation loss: 0.2470
2024-06-03 11:51:40 [INFO]: Epoch 073 - training loss: 0.3125, validation loss: 0.2446
2024-06-03 11:51:42 [INFO]: Epoch 074 - training loss: 0.3090, validation loss: 0.2471
2024-06-03 11:51:43 [INFO]: Epoch 075 - training loss: 0.3100, validation loss: 0.2456
2024-06-03 11:51:45 [INFO]: Epoch 076 - training loss: 0.3105, validation loss: 0.2462
2024-06-03 11:51:47 [INFO]: Epoch 077 - training loss: 0.3078, validation loss: 0.2467
2024-06-03 11:51:49 [INFO]: Epoch 078 - training loss: 0.3105, validation loss: 0.2453
2024-06-03 11:51:51 [INFO]: Epoch 079 - training loss: 0.3074, validation loss: 0.2446
2024-06-03 11:51:52 [INFO]: Epoch 080 - training loss: 0.3063, validation loss: 0.2446
2024-06-03 11:51:54 [INFO]: Epoch 081 - training loss: 0.3106, validation loss: 0.2454
2024-06-03 11:51:56 [INFO]: Epoch 082 - training loss: 0.3069, validation loss: 0.2453
2024-06-03 11:51:58 [INFO]: Epoch 083 - training loss: 0.3035, validation loss: 0.2444
2024-06-03 11:51:59 [INFO]: Epoch 084 - training loss: 0.3050, validation loss: 0.2457
2024-06-03 11:52:01 [INFO]: Epoch 085 - training loss: 0.3074, validation loss: 0.2435
2024-06-03 11:52:03 [INFO]: Epoch 086 - training loss: 0.3033, validation loss: 0.2443
2024-06-03 11:52:05 [INFO]: Epoch 087 - training loss: 0.3047, validation loss: 0.2454
2024-06-03 11:52:06 [INFO]: Epoch 088 - training loss: 0.3031, validation loss: 0.2438
2024-06-03 11:52:08 [INFO]: Epoch 089 - training loss: 0.3014, validation loss: 0.2406
2024-06-03 11:52:10 [INFO]: Epoch 090 - training loss: 0.3023, validation loss: 0.2450
2024-06-03 11:52:12 [INFO]: Epoch 091 - training loss: 0.3007, validation loss: 0.2439
2024-06-03 11:52:14 [INFO]: Epoch 092 - training loss: 0.3037, validation loss: 0.2455
2024-06-03 11:52:15 [INFO]: Epoch 093 - training loss: 0.3028, validation loss: 0.2438
2024-06-03 11:52:17 [INFO]: Epoch 094 - training loss: 0.3004, validation loss: 0.2434
2024-06-03 11:52:19 [INFO]: Epoch 095 - training loss: 0.2996, validation loss: 0.2422
2024-06-03 11:52:21 [INFO]: Epoch 096 - training loss: 0.2987, validation loss: 0.2421
2024-06-03 11:52:22 [INFO]: Epoch 097 - training loss: 0.2972, validation loss: 0.2426
2024-06-03 11:52:24 [INFO]: Epoch 098 - training loss: 0.2997, validation loss: 0.2428
2024-06-03 11:52:26 [INFO]: Epoch 099 - training loss: 0.2976, validation loss: 0.2419
2024-06-03 11:52:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:52:26 [INFO]: Finished training. The best model is from epoch#89.
2024-06-03 11:52:26 [INFO]: Saved the model to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_4/20240603_T114728/StemGNN.pypots
2024-06-03 11:52:27 [INFO]: Successfully saved to results_point_rate05/BeijingAir/StemGNN_BeijingAir/round_4/imputation.pkl
2024-06-03 11:52:27 [INFO]: Round4 - StemGNN on BeijingAir: MAE=0.1956, MSE=0.2718, MRE=0.2662
2024-06-03 11:52:27 [INFO]: Done! Final results:
Averaged StemGNN (2,645,628 params) on BeijingAir: MAE=0.1859 ± 0.0036808445339508856, MSE=0.2634 ± 0.004573708450729903, MRE=0.2464 ± 0.004878711030082855, average inference time=0.41