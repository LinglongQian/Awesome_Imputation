2024-06-03 05:54:03 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 05:54:03 [INFO]: Using the given device: cuda:0
2024-06-03 05:54:03 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_0/20240603_T055403
2024-06-03 05:54:03 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_0/20240603_T055403/tensorboard
2024-06-03 05:54:04 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,013,913
2024-06-03 05:54:18 [INFO]: Epoch 001 - training loss: 4555.4686, validation loss: 0.5108
2024-06-03 05:54:24 [INFO]: Epoch 002 - training loss: 3811.1976, validation loss: 0.4009
2024-06-03 05:54:30 [INFO]: Epoch 003 - training loss: 3765.7850, validation loss: 0.3950
2024-06-03 05:54:37 [INFO]: Epoch 004 - training loss: 3749.0117, validation loss: 0.3800
2024-06-03 05:54:43 [INFO]: Epoch 005 - training loss: 3742.9086, validation loss: 0.3715
2024-06-03 05:54:50 [INFO]: Epoch 006 - training loss: 3724.1995, validation loss: 0.3715
2024-06-03 05:54:56 [INFO]: Epoch 007 - training loss: 3722.9001, validation loss: 0.3632
2024-06-03 05:55:02 [INFO]: Epoch 008 - training loss: 3713.9626, validation loss: 0.3260
2024-06-03 05:55:09 [INFO]: Epoch 009 - training loss: 3699.1440, validation loss: 0.3213
2024-06-03 05:55:15 [INFO]: Epoch 010 - training loss: 3690.3840, validation loss: 0.3123
2024-06-03 05:55:21 [INFO]: Epoch 011 - training loss: 3694.0557, validation loss: 0.3395
2024-06-03 05:55:28 [INFO]: Epoch 012 - training loss: 3690.6370, validation loss: 0.3092
2024-06-03 05:55:34 [INFO]: Epoch 013 - training loss: 3677.6104, validation loss: 0.2955
2024-06-03 05:55:40 [INFO]: Epoch 014 - training loss: 3674.1483, validation loss: 0.3029
2024-06-03 05:55:46 [INFO]: Epoch 015 - training loss: 3674.9415, validation loss: 0.2953
2024-06-03 05:55:53 [INFO]: Epoch 016 - training loss: 3672.1401, validation loss: 0.2990
2024-06-03 05:55:59 [INFO]: Epoch 017 - training loss: 3664.4244, validation loss: 0.2879
2024-06-03 05:56:05 [INFO]: Epoch 018 - training loss: 3662.1250, validation loss: 0.2840
2024-06-03 05:56:12 [INFO]: Epoch 019 - training loss: 3664.3429, validation loss: 0.2868
2024-06-03 05:56:18 [INFO]: Epoch 020 - training loss: 3658.9277, validation loss: 0.2909
2024-06-03 05:56:25 [INFO]: Epoch 021 - training loss: 3661.8741, validation loss: 0.2871
2024-06-03 05:56:31 [INFO]: Epoch 022 - training loss: 3653.4003, validation loss: 0.2821
2024-06-03 05:56:38 [INFO]: Epoch 023 - training loss: 3656.1948, validation loss: 0.2866
2024-06-03 05:56:44 [INFO]: Epoch 024 - training loss: 3660.3479, validation loss: 0.2862
2024-06-03 05:56:51 [INFO]: Epoch 025 - training loss: 3655.8338, validation loss: 0.2809
2024-06-03 05:56:57 [INFO]: Epoch 026 - training loss: 3659.1042, validation loss: 0.2798
2024-06-03 05:57:03 [INFO]: Epoch 027 - training loss: 3659.8406, validation loss: 0.2793
2024-06-03 05:57:10 [INFO]: Epoch 028 - training loss: 3666.4978, validation loss: 0.2899
2024-06-03 05:57:16 [INFO]: Epoch 029 - training loss: 3664.6181, validation loss: 0.2872
2024-06-03 05:57:22 [INFO]: Epoch 030 - training loss: 3653.6550, validation loss: 0.2811
2024-06-03 05:57:28 [INFO]: Epoch 031 - training loss: 3646.0126, validation loss: 0.2816
2024-06-03 05:57:35 [INFO]: Epoch 032 - training loss: 3648.6605, validation loss: 0.2721
2024-06-03 05:57:41 [INFO]: Epoch 033 - training loss: 3646.7976, validation loss: 0.2881
2024-06-03 05:57:47 [INFO]: Epoch 034 - training loss: 3683.9315, validation loss: 0.3109
2024-06-03 05:57:53 [INFO]: Epoch 035 - training loss: 3674.1724, validation loss: 0.2778
2024-06-03 05:58:00 [INFO]: Epoch 036 - training loss: 3656.8537, validation loss: 0.2759
2024-06-03 05:58:06 [INFO]: Epoch 037 - training loss: 3651.4822, validation loss: 0.2826
2024-06-03 05:58:12 [INFO]: Epoch 038 - training loss: 3662.3034, validation loss: 0.2759
2024-06-03 05:58:19 [INFO]: Epoch 039 - training loss: 3648.3289, validation loss: 0.2705
2024-06-03 05:58:25 [INFO]: Epoch 040 - training loss: 3641.4566, validation loss: 0.2597
2024-06-03 05:58:31 [INFO]: Epoch 041 - training loss: 3640.9537, validation loss: 0.2894
2024-06-03 05:58:38 [INFO]: Epoch 042 - training loss: 3642.2583, validation loss: 0.2740
2024-06-03 05:58:44 [INFO]: Epoch 043 - training loss: 3648.1242, validation loss: 0.2748
2024-06-03 05:58:50 [INFO]: Epoch 044 - training loss: 3638.3490, validation loss: 0.2803
2024-06-03 05:58:57 [INFO]: Epoch 045 - training loss: 3635.4599, validation loss: 0.2693
2024-06-03 05:59:03 [INFO]: Epoch 046 - training loss: 3634.1099, validation loss: 0.2903
2024-06-03 05:59:09 [INFO]: Epoch 047 - training loss: 3634.5228, validation loss: 0.2690
2024-06-03 05:59:16 [INFO]: Epoch 048 - training loss: 3631.9225, validation loss: 0.2614
2024-06-03 05:59:22 [INFO]: Epoch 049 - training loss: 3637.5621, validation loss: 0.2808
2024-06-03 05:59:28 [INFO]: Epoch 050 - training loss: 3636.9843, validation loss: 0.2646
2024-06-03 05:59:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:59:28 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 05:59:28 [INFO]: Saved the model to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_0/20240603_T055403/GPVAE.pypots
2024-06-03 05:59:36 [INFO]: Successfully saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_0/imputation.pkl
2024-06-03 05:59:36 [INFO]: Round0 - GPVAE on BeijingAir: MAE=0.2619, MSE=0.2365, MRE=0.3565
2024-06-03 05:59:36 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 05:59:36 [INFO]: Using the given device: cuda:0
2024-06-03 05:59:36 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_1/20240603_T055936
2024-06-03 05:59:36 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_1/20240603_T055936/tensorboard
2024-06-03 05:59:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,013,913
2024-06-03 05:59:43 [INFO]: Epoch 001 - training loss: 4613.7254, validation loss: 0.4929
2024-06-03 05:59:49 [INFO]: Epoch 002 - training loss: 3810.1813, validation loss: 0.4288
2024-06-03 05:59:55 [INFO]: Epoch 003 - training loss: 3771.8708, validation loss: 0.3958
2024-06-03 06:00:02 [INFO]: Epoch 004 - training loss: 3742.4256, validation loss: 0.3739
2024-06-03 06:00:08 [INFO]: Epoch 005 - training loss: 3738.4039, validation loss: 0.3847
2024-06-03 06:00:14 [INFO]: Epoch 006 - training loss: 3748.1790, validation loss: 0.3859
2024-06-03 06:00:21 [INFO]: Epoch 007 - training loss: 3725.1045, validation loss: 0.3532
2024-06-03 06:00:27 [INFO]: Epoch 008 - training loss: 3718.6787, validation loss: 0.3506
2024-06-03 06:00:34 [INFO]: Epoch 009 - training loss: 3713.9387, validation loss: 0.3273
2024-06-03 06:00:41 [INFO]: Epoch 010 - training loss: 3711.0069, validation loss: 0.3343
2024-06-03 06:00:47 [INFO]: Epoch 011 - training loss: 3698.4473, validation loss: 0.3185
2024-06-03 06:00:53 [INFO]: Epoch 012 - training loss: 3683.2280, validation loss: 0.3083
2024-06-03 06:00:59 [INFO]: Epoch 013 - training loss: 3675.8237, validation loss: 0.3079
2024-06-03 06:01:06 [INFO]: Epoch 014 - training loss: 3681.8010, validation loss: 0.3110
2024-06-03 06:01:12 [INFO]: Epoch 015 - training loss: 3678.9510, validation loss: 0.3063
2024-06-03 06:01:18 [INFO]: Epoch 016 - training loss: 3670.3153, validation loss: 0.2962
2024-06-03 06:01:25 [INFO]: Epoch 017 - training loss: 3666.1522, validation loss: 0.2925
2024-06-03 06:01:31 [INFO]: Epoch 018 - training loss: 3666.0910, validation loss: 0.2993
2024-06-03 06:01:38 [INFO]: Epoch 019 - training loss: 3668.8983, validation loss: 0.2929
2024-06-03 06:01:44 [INFO]: Epoch 020 - training loss: 3662.2701, validation loss: 0.2933
2024-06-03 06:01:51 [INFO]: Epoch 021 - training loss: 3667.5601, validation loss: 0.3447
2024-06-03 06:01:57 [INFO]: Epoch 022 - training loss: 3664.9024, validation loss: 0.2820
2024-06-03 06:02:04 [INFO]: Epoch 023 - training loss: 3656.6773, validation loss: 0.2797
2024-06-03 06:02:10 [INFO]: Epoch 024 - training loss: 3655.9130, validation loss: 0.2836
2024-06-03 06:02:16 [INFO]: Epoch 025 - training loss: 3650.8401, validation loss: 0.2752
2024-06-03 06:02:22 [INFO]: Epoch 026 - training loss: 3653.9658, validation loss: 0.2824
2024-06-03 06:02:29 [INFO]: Epoch 027 - training loss: 3655.3340, validation loss: 0.2801
2024-06-03 06:02:35 [INFO]: Epoch 028 - training loss: 3648.0342, validation loss: 0.2825
2024-06-03 06:02:42 [INFO]: Epoch 029 - training loss: 3648.8866, validation loss: 0.2709
2024-06-03 06:02:48 [INFO]: Epoch 030 - training loss: 3650.9042, validation loss: 0.2856
2024-06-03 06:02:54 [INFO]: Epoch 031 - training loss: 3646.2392, validation loss: 0.2731
2024-06-03 06:03:01 [INFO]: Epoch 032 - training loss: 3649.1512, validation loss: 0.2728
2024-06-03 06:03:07 [INFO]: Epoch 033 - training loss: 3645.8536, validation loss: 0.2715
2024-06-03 06:03:13 [INFO]: Epoch 034 - training loss: 3646.7890, validation loss: 0.2716
2024-06-03 06:03:19 [INFO]: Epoch 035 - training loss: 3644.0126, validation loss: 0.2813
2024-06-03 06:03:25 [INFO]: Epoch 036 - training loss: 3645.9936, validation loss: 0.2603
2024-06-03 06:03:32 [INFO]: Epoch 037 - training loss: 3645.9796, validation loss: 0.2674
2024-06-03 06:03:38 [INFO]: Epoch 038 - training loss: 3645.1557, validation loss: 0.2749
2024-06-03 06:03:45 [INFO]: Epoch 039 - training loss: 3658.0239, validation loss: 0.2687
2024-06-03 06:03:51 [INFO]: Epoch 040 - training loss: 3647.4256, validation loss: 0.2634
2024-06-03 06:03:57 [INFO]: Epoch 041 - training loss: 3639.6268, validation loss: 0.2630
2024-06-03 06:04:03 [INFO]: Epoch 042 - training loss: 3634.3685, validation loss: 0.2708
2024-06-03 06:04:10 [INFO]: Epoch 043 - training loss: 3634.7230, validation loss: 0.2622
2024-06-03 06:04:16 [INFO]: Epoch 044 - training loss: 3633.2173, validation loss: 0.2670
2024-06-03 06:04:23 [INFO]: Epoch 045 - training loss: 3637.7449, validation loss: 0.2642
2024-06-03 06:04:29 [INFO]: Epoch 046 - training loss: 3633.4534, validation loss: 0.2530
2024-06-03 06:04:35 [INFO]: Epoch 047 - training loss: 3631.1623, validation loss: 0.2651
2024-06-03 06:04:42 [INFO]: Epoch 048 - training loss: 3628.8601, validation loss: 0.2653
2024-06-03 06:04:48 [INFO]: Epoch 049 - training loss: 3626.0465, validation loss: 0.2645
2024-06-03 06:04:55 [INFO]: Epoch 050 - training loss: 3628.1882, validation loss: 0.2586
2024-06-03 06:05:01 [INFO]: Epoch 051 - training loss: 3628.6231, validation loss: 0.2594
2024-06-03 06:05:07 [INFO]: Epoch 052 - training loss: 3626.4454, validation loss: 0.2580
2024-06-03 06:05:14 [INFO]: Epoch 053 - training loss: 3626.8761, validation loss: 0.2617
2024-06-03 06:05:20 [INFO]: Epoch 054 - training loss: 3624.7780, validation loss: 0.2665
2024-06-03 06:05:26 [INFO]: Epoch 055 - training loss: 3634.1733, validation loss: 0.2578
2024-06-03 06:05:32 [INFO]: Epoch 056 - training loss: 3637.7015, validation loss: 0.2703
2024-06-03 06:05:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:05:32 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 06:05:32 [INFO]: Saved the model to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_1/20240603_T055936/GPVAE.pypots
2024-06-03 06:05:38 [INFO]: Successfully saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_1/imputation.pkl
2024-06-03 06:05:38 [INFO]: Round1 - GPVAE on BeijingAir: MAE=0.2690, MSE=0.2443, MRE=0.3662
2024-06-03 06:05:38 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 06:05:38 [INFO]: Using the given device: cuda:0
2024-06-03 06:05:38 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_2/20240603_T060538
2024-06-03 06:05:38 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_2/20240603_T060538/tensorboard
2024-06-03 06:05:38 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,013,913
2024-06-03 06:05:44 [INFO]: Epoch 001 - training loss: 4563.5338, validation loss: 0.4935
2024-06-03 06:05:50 [INFO]: Epoch 002 - training loss: 3818.6990, validation loss: 0.4193
2024-06-03 06:05:55 [INFO]: Epoch 003 - training loss: 3771.2484, validation loss: 0.3943
2024-06-03 06:06:00 [INFO]: Epoch 004 - training loss: 3742.0164, validation loss: 0.3784
2024-06-03 06:06:06 [INFO]: Epoch 005 - training loss: 3737.9709, validation loss: 0.3868
2024-06-03 06:06:12 [INFO]: Epoch 006 - training loss: 3725.9855, validation loss: 0.3510
2024-06-03 06:06:17 [INFO]: Epoch 007 - training loss: 3715.9323, validation loss: 0.3434
2024-06-03 06:06:23 [INFO]: Epoch 008 - training loss: 3704.6598, validation loss: 0.3277
2024-06-03 06:06:29 [INFO]: Epoch 009 - training loss: 3695.5632, validation loss: 0.3222
2024-06-03 06:06:34 [INFO]: Epoch 010 - training loss: 3694.0396, validation loss: 0.3181
2024-06-03 06:06:39 [INFO]: Epoch 011 - training loss: 3684.4224, validation loss: 0.3085
2024-06-03 06:06:45 [INFO]: Epoch 012 - training loss: 3679.0356, validation loss: 0.2965
2024-06-03 06:06:51 [INFO]: Epoch 013 - training loss: 3679.0322, validation loss: 0.3010
2024-06-03 06:06:56 [INFO]: Epoch 014 - training loss: 3675.2346, validation loss: 0.2951
2024-06-03 06:07:02 [INFO]: Epoch 015 - training loss: 3670.3823, validation loss: 0.3117
2024-06-03 06:07:08 [INFO]: Epoch 016 - training loss: 3673.0878, validation loss: 0.2950
2024-06-03 06:07:13 [INFO]: Epoch 017 - training loss: 3689.1298, validation loss: 0.3076
2024-06-03 06:07:19 [INFO]: Epoch 018 - training loss: 3671.6364, validation loss: 0.2897
2024-06-03 06:07:24 [INFO]: Epoch 019 - training loss: 3662.1510, validation loss: 0.2790
2024-06-03 06:07:30 [INFO]: Epoch 020 - training loss: 3657.2726, validation loss: 0.2806
2024-06-03 06:07:35 [INFO]: Epoch 021 - training loss: 3656.5031, validation loss: 0.2781
2024-06-03 06:07:41 [INFO]: Epoch 022 - training loss: 3654.0427, validation loss: 0.2782
2024-06-03 06:07:46 [INFO]: Epoch 023 - training loss: 3651.3079, validation loss: 0.2768
2024-06-03 06:07:52 [INFO]: Epoch 024 - training loss: 3656.2879, validation loss: 0.2690
2024-06-03 06:07:57 [INFO]: Epoch 025 - training loss: 3653.5516, validation loss: 0.2887
2024-06-03 06:08:02 [INFO]: Epoch 026 - training loss: 3669.4982, validation loss: 0.2784
2024-06-03 06:08:08 [INFO]: Epoch 027 - training loss: 3655.1896, validation loss: 0.2772
2024-06-03 06:08:13 [INFO]: Epoch 028 - training loss: 3650.1328, validation loss: 0.2752
2024-06-03 06:08:19 [INFO]: Epoch 029 - training loss: 3651.7552, validation loss: 0.2724
2024-06-03 06:08:24 [INFO]: Epoch 030 - training loss: 3650.2526, validation loss: 0.2959
2024-06-03 06:08:30 [INFO]: Epoch 031 - training loss: 3671.4958, validation loss: 0.2750
2024-06-03 06:08:35 [INFO]: Epoch 032 - training loss: 3659.0611, validation loss: 0.2745
2024-06-03 06:08:40 [INFO]: Epoch 033 - training loss: 3653.7869, validation loss: 0.2733
2024-06-03 06:08:46 [INFO]: Epoch 034 - training loss: 3650.7207, validation loss: 0.2745
2024-06-03 06:08:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:08:46 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 06:08:46 [INFO]: Saved the model to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_2/20240603_T060538/GPVAE.pypots
2024-06-03 06:08:53 [INFO]: Successfully saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_2/imputation.pkl
2024-06-03 06:08:53 [INFO]: Round2 - GPVAE on BeijingAir: MAE=0.2703, MSE=0.2433, MRE=0.3680
2024-06-03 06:08:53 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 06:08:53 [INFO]: Using the given device: cuda:0
2024-06-03 06:08:53 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_3/20240603_T060853
2024-06-03 06:08:53 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_3/20240603_T060853/tensorboard
2024-06-03 06:08:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,013,913
2024-06-03 06:08:58 [INFO]: Epoch 001 - training loss: 4583.1998, validation loss: 0.4852
2024-06-03 06:09:04 [INFO]: Epoch 002 - training loss: 3819.8109, validation loss: 0.4763
2024-06-03 06:09:09 [INFO]: Epoch 003 - training loss: 3777.5842, validation loss: 0.3939
2024-06-03 06:09:15 [INFO]: Epoch 004 - training loss: 3749.7473, validation loss: 0.3882
2024-06-03 06:09:20 [INFO]: Epoch 005 - training loss: 3730.2696, validation loss: 0.3647
2024-06-03 06:09:26 [INFO]: Epoch 006 - training loss: 3720.7501, validation loss: 0.3639
2024-06-03 06:09:31 [INFO]: Epoch 007 - training loss: 3718.6246, validation loss: 0.3529
2024-06-03 06:09:37 [INFO]: Epoch 008 - training loss: 3706.9607, validation loss: 0.3288
2024-06-03 06:09:43 [INFO]: Epoch 009 - training loss: 3701.3354, validation loss: 0.3387
2024-06-03 06:09:48 [INFO]: Epoch 010 - training loss: 3700.2340, validation loss: 0.3212
2024-06-03 06:09:54 [INFO]: Epoch 011 - training loss: 3690.8067, validation loss: 0.3089
2024-06-03 06:10:00 [INFO]: Epoch 012 - training loss: 3679.6303, validation loss: 0.3023
2024-06-03 06:10:05 [INFO]: Epoch 013 - training loss: 3674.2730, validation loss: 0.2941
2024-06-03 06:10:11 [INFO]: Epoch 014 - training loss: 3672.1554, validation loss: 0.2985
2024-06-03 06:10:16 [INFO]: Epoch 015 - training loss: 3669.2636, validation loss: 0.2914
2024-06-03 06:10:22 [INFO]: Epoch 016 - training loss: 3668.5209, validation loss: 0.2924
2024-06-03 06:10:28 [INFO]: Epoch 017 - training loss: 3665.7514, validation loss: 0.2847
2024-06-03 06:10:33 [INFO]: Epoch 018 - training loss: 3662.5744, validation loss: 0.2922
2024-06-03 06:10:39 [INFO]: Epoch 019 - training loss: 3656.3172, validation loss: 0.2773
2024-06-03 06:10:44 [INFO]: Epoch 020 - training loss: 3658.8399, validation loss: 0.2800
2024-06-03 06:10:49 [INFO]: Epoch 021 - training loss: 3671.3278, validation loss: 0.2765
2024-06-03 06:10:55 [INFO]: Epoch 022 - training loss: 3658.0199, validation loss: 0.2797
2024-06-03 06:11:00 [INFO]: Epoch 023 - training loss: 3654.4208, validation loss: 0.2845
2024-06-03 06:11:06 [INFO]: Epoch 024 - training loss: 3649.3112, validation loss: 0.2781
2024-06-03 06:11:11 [INFO]: Epoch 025 - training loss: 3647.3060, validation loss: 0.2724
2024-06-03 06:11:17 [INFO]: Epoch 026 - training loss: 3646.4895, validation loss: 0.2837
2024-06-03 06:11:23 [INFO]: Epoch 027 - training loss: 3648.6877, validation loss: 0.2711
2024-06-03 06:11:28 [INFO]: Epoch 028 - training loss: 3656.7186, validation loss: 0.2929
2024-06-03 06:11:34 [INFO]: Epoch 029 - training loss: 3663.3645, validation loss: 0.2789
2024-06-03 06:11:40 [INFO]: Epoch 030 - training loss: 3662.3614, validation loss: 0.3093
2024-06-03 06:11:45 [INFO]: Epoch 031 - training loss: 3664.0558, validation loss: 0.2865
2024-06-03 06:11:51 [INFO]: Epoch 032 - training loss: 3656.7298, validation loss: 0.2739
2024-06-03 06:11:56 [INFO]: Epoch 033 - training loss: 3650.2734, validation loss: 0.2710
2024-06-03 06:12:02 [INFO]: Epoch 034 - training loss: 3645.8473, validation loss: 0.2700
2024-06-03 06:12:07 [INFO]: Epoch 035 - training loss: 3639.3763, validation loss: 0.2668
2024-06-03 06:12:13 [INFO]: Epoch 036 - training loss: 3637.1402, validation loss: 0.2672
2024-06-03 06:12:18 [INFO]: Epoch 037 - training loss: 3638.6509, validation loss: 0.2790
2024-06-03 06:12:23 [INFO]: Epoch 038 - training loss: 3639.9695, validation loss: 0.2704
2024-06-03 06:12:29 [INFO]: Epoch 039 - training loss: 3635.8918, validation loss: 0.2709
2024-06-03 06:12:35 [INFO]: Epoch 040 - training loss: 3633.9079, validation loss: 0.2674
2024-06-03 06:12:40 [INFO]: Epoch 041 - training loss: 3639.7219, validation loss: 0.2732
2024-06-03 06:12:46 [INFO]: Epoch 042 - training loss: 3636.7240, validation loss: 0.2639
2024-06-03 06:12:51 [INFO]: Epoch 043 - training loss: 3633.8148, validation loss: 0.2740
2024-06-03 06:12:57 [INFO]: Epoch 044 - training loss: 3636.9586, validation loss: 0.2611
2024-06-03 06:13:02 [INFO]: Epoch 045 - training loss: 3637.9149, validation loss: 0.2675
2024-06-03 06:13:08 [INFO]: Epoch 046 - training loss: 3635.3016, validation loss: 0.2886
2024-06-03 06:13:13 [INFO]: Epoch 047 - training loss: 3635.4802, validation loss: 0.2618
2024-06-03 06:13:19 [INFO]: Epoch 048 - training loss: 3644.1960, validation loss: 0.2766
2024-06-03 06:13:24 [INFO]: Epoch 049 - training loss: 3651.3499, validation loss: 0.2858
2024-06-03 06:13:30 [INFO]: Epoch 050 - training loss: 3653.3192, validation loss: 0.2816
2024-06-03 06:13:36 [INFO]: Epoch 051 - training loss: 3646.3265, validation loss: 0.2776
2024-06-03 06:13:41 [INFO]: Epoch 052 - training loss: 3637.4568, validation loss: 0.2631
2024-06-03 06:13:47 [INFO]: Epoch 053 - training loss: 3632.4938, validation loss: 0.2591
2024-06-03 06:13:52 [INFO]: Epoch 054 - training loss: 3634.3903, validation loss: 0.2675
2024-06-03 06:13:58 [INFO]: Epoch 055 - training loss: 3647.4294, validation loss: 0.2646
2024-06-03 06:14:03 [INFO]: Epoch 056 - training loss: 3640.5603, validation loss: 0.2624
2024-06-03 06:14:09 [INFO]: Epoch 057 - training loss: 3641.7566, validation loss: 0.2609
2024-06-03 06:14:15 [INFO]: Epoch 058 - training loss: 3635.9825, validation loss: 0.2653
2024-06-03 06:14:20 [INFO]: Epoch 059 - training loss: 3634.8677, validation loss: 0.2735
2024-06-03 06:14:26 [INFO]: Epoch 060 - training loss: 3634.0305, validation loss: 0.3077
2024-06-03 06:14:31 [INFO]: Epoch 061 - training loss: 3632.7816, validation loss: 0.2700
2024-06-03 06:14:37 [INFO]: Epoch 062 - training loss: 3628.9767, validation loss: 0.2671
2024-06-03 06:14:43 [INFO]: Epoch 063 - training loss: 3622.0467, validation loss: 0.2651
2024-06-03 06:14:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:14:43 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 06:14:43 [INFO]: Saved the model to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_3/20240603_T060853/GPVAE.pypots
2024-06-03 06:14:49 [INFO]: Successfully saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_3/imputation.pkl
2024-06-03 06:14:49 [INFO]: Round3 - GPVAE on BeijingAir: MAE=0.2623, MSE=0.2419, MRE=0.3571
2024-06-03 06:14:49 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 06:14:49 [INFO]: Using the given device: cuda:0
2024-06-03 06:14:49 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_4/20240603_T061449
2024-06-03 06:14:49 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_4/20240603_T061449/tensorboard
2024-06-03 06:14:49 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,013,913
2024-06-03 06:14:54 [INFO]: Epoch 001 - training loss: 4510.9464, validation loss: 0.4818
2024-06-03 06:15:00 [INFO]: Epoch 002 - training loss: 3782.7394, validation loss: 0.3996
2024-06-03 06:15:05 [INFO]: Epoch 003 - training loss: 3751.2713, validation loss: 0.4055
2024-06-03 06:15:10 [INFO]: Epoch 004 - training loss: 3753.0327, validation loss: 0.3734
2024-06-03 06:15:16 [INFO]: Epoch 005 - training loss: 3736.9046, validation loss: 0.3646
2024-06-03 06:15:22 [INFO]: Epoch 006 - training loss: 3729.5904, validation loss: 0.3462
2024-06-03 06:15:28 [INFO]: Epoch 007 - training loss: 3714.5740, validation loss: 0.3344
2024-06-03 06:15:33 [INFO]: Epoch 008 - training loss: 3699.0647, validation loss: 0.3228
2024-06-03 06:15:39 [INFO]: Epoch 009 - training loss: 3689.2518, validation loss: 0.3164
2024-06-03 06:15:45 [INFO]: Epoch 010 - training loss: 3689.9433, validation loss: 0.3369
2024-06-03 06:15:50 [INFO]: Epoch 011 - training loss: 3684.8236, validation loss: 0.3138
2024-06-03 06:15:55 [INFO]: Epoch 012 - training loss: 3675.2940, validation loss: 0.3096
2024-06-03 06:16:01 [INFO]: Epoch 013 - training loss: 3674.8051, validation loss: 0.3105
2024-06-03 06:16:07 [INFO]: Epoch 014 - training loss: 3671.1209, validation loss: 0.3025
2024-06-03 06:16:13 [INFO]: Epoch 015 - training loss: 3669.1596, validation loss: 0.2846
2024-06-03 06:16:18 [INFO]: Epoch 016 - training loss: 3665.6687, validation loss: 0.2895
2024-06-03 06:16:23 [INFO]: Epoch 017 - training loss: 3659.1514, validation loss: 0.2888
2024-06-03 06:16:29 [INFO]: Epoch 018 - training loss: 3658.3741, validation loss: 0.2864
2024-06-03 06:16:35 [INFO]: Epoch 019 - training loss: 3658.2223, validation loss: 0.2782
2024-06-03 06:16:40 [INFO]: Epoch 020 - training loss: 3656.3961, validation loss: 0.2719
2024-06-03 06:16:46 [INFO]: Epoch 021 - training loss: 3660.1095, validation loss: 0.2959
2024-06-03 06:16:51 [INFO]: Epoch 022 - training loss: 3655.3514, validation loss: 0.2947
2024-06-03 06:16:57 [INFO]: Epoch 023 - training loss: 3666.6934, validation loss: 0.2893
2024-06-03 06:17:02 [INFO]: Epoch 024 - training loss: 3660.0314, validation loss: 0.2681
2024-06-03 06:17:08 [INFO]: Epoch 025 - training loss: 3664.3123, validation loss: 0.2782
2024-06-03 06:17:13 [INFO]: Epoch 026 - training loss: 3656.1374, validation loss: 0.2761
2024-06-03 06:17:19 [INFO]: Epoch 027 - training loss: 3655.0152, validation loss: 0.2848
2024-06-03 06:17:24 [INFO]: Epoch 028 - training loss: 3654.2376, validation loss: 0.2859
2024-06-03 06:17:30 [INFO]: Epoch 029 - training loss: 3660.1909, validation loss: 0.2707
2024-06-03 06:17:35 [INFO]: Epoch 030 - training loss: 3647.3479, validation loss: 0.2761
2024-06-03 06:17:41 [INFO]: Epoch 031 - training loss: 3645.4378, validation loss: 0.2730
2024-06-03 06:17:47 [INFO]: Epoch 032 - training loss: 3639.7690, validation loss: 0.2643
2024-06-03 06:17:52 [INFO]: Epoch 033 - training loss: 3636.3474, validation loss: 0.2645
2024-06-03 06:17:58 [INFO]: Epoch 034 - training loss: 3637.9409, validation loss: 0.2753
2024-06-03 06:18:04 [INFO]: Epoch 035 - training loss: 3638.4397, validation loss: 0.2603
2024-06-03 06:18:09 [INFO]: Epoch 036 - training loss: 3637.0913, validation loss: 0.2707
2024-06-03 06:18:15 [INFO]: Epoch 037 - training loss: 3642.1652, validation loss: 0.2722
2024-06-03 06:18:21 [INFO]: Epoch 038 - training loss: 3642.9544, validation loss: 0.3036
2024-06-03 06:18:26 [INFO]: Epoch 039 - training loss: 3658.6280, validation loss: 0.2667
2024-06-03 06:18:32 [INFO]: Epoch 040 - training loss: 3650.6462, validation loss: 0.2807
2024-06-03 06:18:38 [INFO]: Epoch 041 - training loss: 3648.1625, validation loss: 0.2736
2024-06-03 06:18:43 [INFO]: Epoch 042 - training loss: 3643.1753, validation loss: 0.2721
2024-06-03 06:18:48 [INFO]: Epoch 043 - training loss: 3639.3475, validation loss: 0.2710
2024-06-03 06:18:54 [INFO]: Epoch 044 - training loss: 3638.5885, validation loss: 0.2633
2024-06-03 06:18:59 [INFO]: Epoch 045 - training loss: 3635.7703, validation loss: 0.2767
2024-06-03 06:18:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:18:59 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 06:18:59 [INFO]: Saved the model to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_4/20240603_T061449/GPVAE.pypots
2024-06-03 06:19:05 [INFO]: Successfully saved to results_point_rate05/BeijingAir/GPVAE_BeijingAir/round_4/imputation.pkl
2024-06-03 06:19:05 [INFO]: Round4 - GPVAE on BeijingAir: MAE=0.2683, MSE=0.2571, MRE=0.3653
2024-06-03 06:19:05 [INFO]: Done! Final results:
Averaged GPVAE (1,013,913 params) on BeijingAir: MAE=0.2584 ± 0.003823459089602078, MSE=0.2338 ± 0.007732569252893504, MRE=0.3425 ± 0.00506773699933755, average inference time=1.38