2024-06-02 20:59:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:59:58 [INFO]: Using the given device: cuda:0
2024-06-02 20:59:58 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240602_T205958
2024-06-02 20:59:58 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240602_T205958/tensorboard
2024-06-02 21:00:00 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-02 21:01:23 [INFO]: Epoch 001 - training loss: 1.2267, validation loss: 0.5288
2024-06-02 21:02:42 [INFO]: Epoch 002 - training loss: 0.7891, validation loss: 0.4483
2024-06-02 21:04:02 [INFO]: Epoch 003 - training loss: 0.6754, validation loss: 0.3734
2024-06-02 21:05:21 [INFO]: Epoch 004 - training loss: 0.6197, validation loss: 0.3699
2024-06-02 21:06:40 [INFO]: Epoch 005 - training loss: 0.5716, validation loss: 0.3347
2024-06-02 21:07:59 [INFO]: Epoch 006 - training loss: 0.5413, validation loss: 0.3250
2024-06-02 21:09:18 [INFO]: Epoch 007 - training loss: 0.5233, validation loss: 0.3125
2024-06-02 21:10:37 [INFO]: Epoch 008 - training loss: 0.4976, validation loss: 0.3022
2024-06-02 21:11:56 [INFO]: Epoch 009 - training loss: 0.4819, validation loss: 0.2745
2024-06-02 21:13:14 [INFO]: Epoch 010 - training loss: 0.4680, validation loss: 0.2866
2024-06-02 21:14:32 [INFO]: Epoch 011 - training loss: 0.4578, validation loss: 0.2711
2024-06-02 21:15:50 [INFO]: Epoch 012 - training loss: 0.4516, validation loss: 0.2988
2024-06-02 21:17:04 [INFO]: Epoch 013 - training loss: 0.4446, validation loss: 0.2733
2024-06-02 21:18:15 [INFO]: Epoch 014 - training loss: 0.4327, validation loss: 0.2589
2024-06-02 21:19:28 [INFO]: Epoch 015 - training loss: 0.4262, validation loss: 0.2578
2024-06-02 21:20:40 [INFO]: Epoch 016 - training loss: 0.4300, validation loss: 0.2500
2024-06-02 21:21:51 [INFO]: Epoch 017 - training loss: 0.4230, validation loss: 0.2619
2024-06-02 21:23:04 [INFO]: Epoch 018 - training loss: 0.4200, validation loss: 0.2674
2024-06-02 21:24:16 [INFO]: Epoch 019 - training loss: 0.4100, validation loss: 0.2522
2024-06-02 21:25:28 [INFO]: Epoch 020 - training loss: 0.4066, validation loss: 0.2508
2024-06-02 21:26:40 [INFO]: Epoch 021 - training loss: 0.4026, validation loss: 0.2505
2024-06-02 21:27:52 [INFO]: Epoch 022 - training loss: 0.3999, validation loss: 0.2441
2024-06-02 21:29:04 [INFO]: Epoch 023 - training loss: 0.3998, validation loss: 0.2545
2024-06-02 21:30:16 [INFO]: Epoch 024 - training loss: 0.4003, validation loss: 0.2559
2024-06-02 21:31:28 [INFO]: Epoch 025 - training loss: 0.3931, validation loss: 0.2454
2024-06-02 21:32:41 [INFO]: Epoch 026 - training loss: 0.3919, validation loss: 0.2625
2024-06-02 21:33:53 [INFO]: Epoch 027 - training loss: 0.3952, validation loss: 0.2415
2024-06-02 21:35:05 [INFO]: Epoch 028 - training loss: 0.3878, validation loss: 0.2436
2024-06-02 21:36:17 [INFO]: Epoch 029 - training loss: 0.3851, validation loss: 0.2490
2024-06-02 21:37:29 [INFO]: Epoch 030 - training loss: 0.3829, validation loss: 0.2351
2024-06-02 21:38:42 [INFO]: Epoch 031 - training loss: 0.3845, validation loss: 0.2473
2024-06-02 21:39:53 [INFO]: Epoch 032 - training loss: 0.3792, validation loss: 0.2390
2024-06-02 21:41:05 [INFO]: Epoch 033 - training loss: 0.3781, validation loss: 0.2435
2024-06-02 21:42:17 [INFO]: Epoch 034 - training loss: 0.3773, validation loss: 0.2336
2024-06-02 21:43:29 [INFO]: Epoch 035 - training loss: 0.3760, validation loss: 0.2355
2024-06-02 21:44:41 [INFO]: Epoch 036 - training loss: 0.3734, validation loss: 0.2388
2024-06-02 21:45:53 [INFO]: Epoch 037 - training loss: 0.3722, validation loss: 0.2354
2024-06-02 21:47:05 [INFO]: Epoch 038 - training loss: 0.3715, validation loss: 0.2359
2024-06-02 21:48:17 [INFO]: Epoch 039 - training loss: 0.3701, validation loss: 0.2373
2024-06-02 21:49:29 [INFO]: Epoch 040 - training loss: 0.3703, validation loss: 0.2405
2024-06-02 21:50:41 [INFO]: Epoch 041 - training loss: 0.3719, validation loss: 0.2452
2024-06-02 21:51:53 [INFO]: Epoch 042 - training loss: 0.3707, validation loss: 0.2338
2024-06-02 21:53:05 [INFO]: Epoch 043 - training loss: 0.3663, validation loss: 0.2404
2024-06-02 21:54:17 [INFO]: Epoch 044 - training loss: 0.3670, validation loss: 0.2362
2024-06-02 21:54:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:54:17 [INFO]: Finished training. The best model is from epoch#34.
2024-06-02 21:54:18 [INFO]: Saved the model to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240602_T205958/Crossformer.pypots
2024-06-02 21:54:51 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_0/imputation.pkl
2024-06-02 21:54:51 [INFO]: Round0 - Crossformer on BeijingAir: MAE=0.2289, MSE=0.2410, MRE=0.3116
2024-06-02 21:54:51 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 21:54:51 [INFO]: Using the given device: cuda:0
2024-06-02 21:54:51 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240602_T215451
2024-06-02 21:54:51 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240602_T215451/tensorboard
2024-06-02 21:54:53 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-02 21:56:04 [INFO]: Epoch 001 - training loss: 1.2811, validation loss: 0.5520
2024-06-02 21:57:16 [INFO]: Epoch 002 - training loss: 0.8036, validation loss: 0.4255
2024-06-02 21:58:28 [INFO]: Epoch 003 - training loss: 0.6828, validation loss: 0.4042
2024-06-02 21:59:39 [INFO]: Epoch 004 - training loss: 0.6137, validation loss: 0.3322
2024-06-02 22:00:51 [INFO]: Epoch 005 - training loss: 0.5718, validation loss: 0.3243
2024-06-02 22:02:04 [INFO]: Epoch 006 - training loss: 0.5381, validation loss: 0.2964
2024-06-02 22:03:16 [INFO]: Epoch 007 - training loss: 0.5172, validation loss: 0.3132
2024-06-02 22:04:28 [INFO]: Epoch 008 - training loss: 0.4940, validation loss: 0.3218
2024-06-02 22:05:39 [INFO]: Epoch 009 - training loss: 0.4829, validation loss: 0.2808
2024-06-02 22:06:51 [INFO]: Epoch 010 - training loss: 0.4724, validation loss: 0.2644
2024-06-02 22:08:02 [INFO]: Epoch 011 - training loss: 0.4612, validation loss: 0.2742
2024-06-02 22:09:14 [INFO]: Epoch 012 - training loss: 0.4479, validation loss: 0.2759
2024-06-02 22:10:26 [INFO]: Epoch 013 - training loss: 0.4424, validation loss: 0.2706
2024-06-02 22:11:38 [INFO]: Epoch 014 - training loss: 0.4356, validation loss: 0.2852
2024-06-02 22:12:50 [INFO]: Epoch 015 - training loss: 0.4293, validation loss: 0.2620
2024-06-02 22:14:02 [INFO]: Epoch 016 - training loss: 0.4224, validation loss: 0.2587
2024-06-02 22:15:15 [INFO]: Epoch 017 - training loss: 0.4175, validation loss: 0.2614
2024-06-02 22:16:26 [INFO]: Epoch 018 - training loss: 0.4135, validation loss: 0.2811
2024-06-02 22:17:38 [INFO]: Epoch 019 - training loss: 0.4141, validation loss: 0.2494
2024-06-02 22:18:50 [INFO]: Epoch 020 - training loss: 0.4073, validation loss: 0.2477
2024-06-02 22:20:02 [INFO]: Epoch 021 - training loss: 0.4057, validation loss: 0.2589
2024-06-02 22:21:14 [INFO]: Epoch 022 - training loss: 0.4035, validation loss: 0.2612
2024-06-02 22:22:26 [INFO]: Epoch 023 - training loss: 0.3980, validation loss: 0.2487
2024-06-02 22:23:38 [INFO]: Epoch 024 - training loss: 0.3954, validation loss: 0.2397
2024-06-02 22:24:50 [INFO]: Epoch 025 - training loss: 0.3939, validation loss: 0.2502
2024-06-02 22:26:02 [INFO]: Epoch 026 - training loss: 0.3900, validation loss: 0.2418
2024-06-02 22:27:14 [INFO]: Epoch 027 - training loss: 0.3886, validation loss: 0.2562
2024-06-02 22:28:25 [INFO]: Epoch 028 - training loss: 0.3904, validation loss: 0.2483
2024-06-02 22:29:33 [INFO]: Epoch 029 - training loss: 0.3866, validation loss: 0.2455
2024-06-02 22:30:42 [INFO]: Epoch 030 - training loss: 0.3832, validation loss: 0.2530
2024-06-02 22:31:51 [INFO]: Epoch 031 - training loss: 0.3852, validation loss: 0.2472
2024-06-02 22:33:00 [INFO]: Epoch 032 - training loss: 0.3805, validation loss: 0.2388
2024-06-02 22:34:09 [INFO]: Epoch 033 - training loss: 0.3778, validation loss: 0.2361
2024-06-02 22:35:17 [INFO]: Epoch 034 - training loss: 0.3789, validation loss: 0.2359
2024-06-02 22:36:26 [INFO]: Epoch 035 - training loss: 0.3766, validation loss: 0.2339
2024-06-02 22:37:35 [INFO]: Epoch 036 - training loss: 0.3744, validation loss: 0.2354
2024-06-02 22:38:43 [INFO]: Epoch 037 - training loss: 0.3730, validation loss: 0.2331
2024-06-02 22:39:52 [INFO]: Epoch 038 - training loss: 0.3756, validation loss: 0.2326
2024-06-02 22:41:01 [INFO]: Epoch 039 - training loss: 0.3753, validation loss: 0.2378
2024-06-02 22:42:10 [INFO]: Epoch 040 - training loss: 0.3736, validation loss: 0.2388
2024-06-02 22:43:19 [INFO]: Epoch 041 - training loss: 0.3701, validation loss: 0.2387
2024-06-02 22:44:27 [INFO]: Epoch 042 - training loss: 0.3674, validation loss: 0.2305
2024-06-02 22:45:36 [INFO]: Epoch 043 - training loss: 0.3663, validation loss: 0.2326
2024-06-02 22:46:45 [INFO]: Epoch 044 - training loss: 0.3672, validation loss: 0.2313
2024-06-02 22:47:54 [INFO]: Epoch 045 - training loss: 0.3639, validation loss: 0.2339
2024-06-02 22:49:03 [INFO]: Epoch 046 - training loss: 0.3623, validation loss: 0.2326
2024-06-02 22:50:12 [INFO]: Epoch 047 - training loss: 0.3631, validation loss: 0.2336
2024-06-02 22:51:21 [INFO]: Epoch 048 - training loss: 0.3624, validation loss: 0.2394
2024-06-02 22:52:29 [INFO]: Epoch 049 - training loss: 0.3646, validation loss: 0.2301
2024-06-02 22:53:38 [INFO]: Epoch 050 - training loss: 0.3588, validation loss: 0.2304
2024-06-02 22:54:47 [INFO]: Epoch 051 - training loss: 0.3590, validation loss: 0.2265
2024-06-02 22:55:58 [INFO]: Epoch 052 - training loss: 0.3607, validation loss: 0.2406
2024-06-02 22:57:09 [INFO]: Epoch 053 - training loss: 0.3607, validation loss: 0.2276
2024-06-02 22:58:20 [INFO]: Epoch 054 - training loss: 0.3560, validation loss: 0.2331
2024-06-02 22:59:31 [INFO]: Epoch 055 - training loss: 0.3541, validation loss: 0.2283
2024-06-02 23:00:43 [INFO]: Epoch 056 - training loss: 0.3535, validation loss: 0.2302
2024-06-02 23:01:53 [INFO]: Epoch 057 - training loss: 0.3539, validation loss: 0.2315
2024-06-02 23:03:03 [INFO]: Epoch 058 - training loss: 0.3518, validation loss: 0.2262
2024-06-02 23:04:14 [INFO]: Epoch 059 - training loss: 0.3508, validation loss: 0.2290
2024-06-02 23:05:25 [INFO]: Epoch 060 - training loss: 0.3533, validation loss: 0.2371
2024-06-02 23:06:35 [INFO]: Epoch 061 - training loss: 0.3532, validation loss: 0.2257
2024-06-02 23:07:46 [INFO]: Epoch 062 - training loss: 0.3494, validation loss: 0.2245
2024-06-02 23:08:57 [INFO]: Epoch 063 - training loss: 0.3491, validation loss: 0.2251
2024-06-02 23:10:08 [INFO]: Epoch 064 - training loss: 0.3498, validation loss: 0.2333
2024-06-02 23:11:19 [INFO]: Epoch 065 - training loss: 0.3494, validation loss: 0.2270
2024-06-02 23:12:30 [INFO]: Epoch 066 - training loss: 0.3484, validation loss: 0.2237
2024-06-02 23:13:41 [INFO]: Epoch 067 - training loss: 0.3450, validation loss: 0.2248
2024-06-02 23:14:52 [INFO]: Epoch 068 - training loss: 0.3456, validation loss: 0.2260
2024-06-02 23:16:03 [INFO]: Epoch 069 - training loss: 0.3433, validation loss: 0.2277
2024-06-02 23:17:15 [INFO]: Epoch 070 - training loss: 0.3423, validation loss: 0.2264
2024-06-02 23:18:26 [INFO]: Epoch 071 - training loss: 0.3428, validation loss: 0.2263
2024-06-02 23:19:37 [INFO]: Epoch 072 - training loss: 0.3417, validation loss: 0.2231
2024-06-02 23:20:48 [INFO]: Epoch 073 - training loss: 0.3417, validation loss: 0.2216
2024-06-02 23:21:59 [INFO]: Epoch 074 - training loss: 0.3388, validation loss: 0.2257
2024-06-02 23:23:10 [INFO]: Epoch 075 - training loss: 0.3383, validation loss: 0.2245
2024-06-02 23:24:21 [INFO]: Epoch 076 - training loss: 0.3411, validation loss: 0.2277
2024-06-02 23:25:32 [INFO]: Epoch 077 - training loss: 0.3392, validation loss: 0.2242
2024-06-02 23:26:43 [INFO]: Epoch 078 - training loss: 0.3417, validation loss: 0.2274
2024-06-02 23:27:54 [INFO]: Epoch 079 - training loss: 0.3371, validation loss: 0.2215
2024-06-02 23:29:05 [INFO]: Epoch 080 - training loss: 0.3340, validation loss: 0.2237
2024-06-02 23:30:16 [INFO]: Epoch 081 - training loss: 0.3340, validation loss: 0.2238
2024-06-02 23:31:26 [INFO]: Epoch 082 - training loss: 0.3339, validation loss: 0.2243
2024-06-02 23:32:37 [INFO]: Epoch 083 - training loss: 0.3345, validation loss: 0.2230
2024-06-02 23:33:48 [INFO]: Epoch 084 - training loss: 0.3333, validation loss: 0.2250
2024-06-02 23:34:59 [INFO]: Epoch 085 - training loss: 0.3312, validation loss: 0.2230
2024-06-02 23:36:07 [INFO]: Epoch 086 - training loss: 0.3320, validation loss: 0.2258
2024-06-02 23:37:16 [INFO]: Epoch 087 - training loss: 0.3312, validation loss: 0.2224
2024-06-02 23:38:25 [INFO]: Epoch 088 - training loss: 0.3298, validation loss: 0.2221
2024-06-02 23:39:35 [INFO]: Epoch 089 - training loss: 0.3286, validation loss: 0.2236
2024-06-02 23:39:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 23:39:35 [INFO]: Finished training. The best model is from epoch#79.
2024-06-02 23:39:35 [INFO]: Saved the model to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240602_T215451/Crossformer.pypots
2024-06-02 23:40:07 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_1/imputation.pkl
2024-06-02 23:40:07 [INFO]: Round1 - Crossformer on BeijingAir: MAE=0.2133, MSE=0.2304, MRE=0.2904
2024-06-02 23:40:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 23:40:07 [INFO]: Using the given device: cuda:0
2024-06-02 23:40:08 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240602_T234007
2024-06-02 23:40:08 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240602_T234007/tensorboard
2024-06-02 23:40:08 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-02 23:41:17 [INFO]: Epoch 001 - training loss: 1.2988, validation loss: 0.5658
2024-06-02 23:42:25 [INFO]: Epoch 002 - training loss: 0.8114, validation loss: 0.4177
2024-06-02 23:43:34 [INFO]: Epoch 003 - training loss: 0.6798, validation loss: 0.3877
2024-06-02 23:44:43 [INFO]: Epoch 004 - training loss: 0.6153, validation loss: 0.3395
2024-06-02 23:45:51 [INFO]: Epoch 005 - training loss: 0.5858, validation loss: 0.3352
2024-06-02 23:47:00 [INFO]: Epoch 006 - training loss: 0.5524, validation loss: 0.2996
2024-06-02 23:48:10 [INFO]: Epoch 007 - training loss: 0.5249, validation loss: 0.3040
2024-06-02 23:49:18 [INFO]: Epoch 008 - training loss: 0.5042, validation loss: 0.3295
2024-06-02 23:50:27 [INFO]: Epoch 009 - training loss: 0.4860, validation loss: 0.2896
2024-06-02 23:51:36 [INFO]: Epoch 010 - training loss: 0.4701, validation loss: 0.2884
2024-06-02 23:52:44 [INFO]: Epoch 011 - training loss: 0.4640, validation loss: 0.2942
2024-06-02 23:53:53 [INFO]: Epoch 012 - training loss: 0.4539, validation loss: 0.2664
2024-06-02 23:55:02 [INFO]: Epoch 013 - training loss: 0.4445, validation loss: 0.2830
2024-06-02 23:56:10 [INFO]: Epoch 014 - training loss: 0.4347, validation loss: 0.2609
2024-06-02 23:57:19 [INFO]: Epoch 015 - training loss: 0.4292, validation loss: 0.2595
2024-06-02 23:58:28 [INFO]: Epoch 016 - training loss: 0.4239, validation loss: 0.2627
2024-06-02 23:59:37 [INFO]: Epoch 017 - training loss: 0.4179, validation loss: 0.2536
2024-06-03 00:00:46 [INFO]: Epoch 018 - training loss: 0.4237, validation loss: 0.2495
2024-06-03 00:01:55 [INFO]: Epoch 019 - training loss: 0.4158, validation loss: 0.2625
2024-06-03 00:03:04 [INFO]: Epoch 020 - training loss: 0.4103, validation loss: 0.2430
2024-06-03 00:04:13 [INFO]: Epoch 021 - training loss: 0.4062, validation loss: 0.2488
2024-06-03 00:05:22 [INFO]: Epoch 022 - training loss: 0.4032, validation loss: 0.2550
2024-06-03 00:06:31 [INFO]: Epoch 023 - training loss: 0.4009, validation loss: 0.2493
2024-06-03 00:07:40 [INFO]: Epoch 024 - training loss: 0.3966, validation loss: 0.2463
2024-06-03 00:08:48 [INFO]: Epoch 025 - training loss: 0.3947, validation loss: 0.2409
2024-06-03 00:09:57 [INFO]: Epoch 026 - training loss: 0.3901, validation loss: 0.2511
2024-06-03 00:11:06 [INFO]: Epoch 027 - training loss: 0.3901, validation loss: 0.2464
2024-06-03 00:12:14 [INFO]: Epoch 028 - training loss: 0.3884, validation loss: 0.2411
2024-06-03 00:13:23 [INFO]: Epoch 029 - training loss: 0.3856, validation loss: 0.2386
2024-06-03 00:14:32 [INFO]: Epoch 030 - training loss: 0.3845, validation loss: 0.2367
2024-06-03 00:15:41 [INFO]: Epoch 031 - training loss: 0.3856, validation loss: 0.2382
2024-06-03 00:16:50 [INFO]: Epoch 032 - training loss: 0.3824, validation loss: 0.2420
2024-06-03 00:17:59 [INFO]: Epoch 033 - training loss: 0.3794, validation loss: 0.2395
2024-06-03 00:19:08 [INFO]: Epoch 034 - training loss: 0.3820, validation loss: 0.2323
2024-06-03 00:20:17 [INFO]: Epoch 035 - training loss: 0.3774, validation loss: 0.2321
2024-06-03 00:21:26 [INFO]: Epoch 036 - training loss: 0.3790, validation loss: 0.2324
2024-06-03 00:22:35 [INFO]: Epoch 037 - training loss: 0.3732, validation loss: 0.2385
2024-06-03 00:23:44 [INFO]: Epoch 038 - training loss: 0.3731, validation loss: 0.2317
2024-06-03 00:24:52 [INFO]: Epoch 039 - training loss: 0.3733, validation loss: 0.2377
2024-06-03 00:26:01 [INFO]: Epoch 040 - training loss: 0.3743, validation loss: 0.2314
2024-06-03 00:27:09 [INFO]: Epoch 041 - training loss: 0.3695, validation loss: 0.2351
2024-06-03 00:28:18 [INFO]: Epoch 042 - training loss: 0.3682, validation loss: 0.2312
2024-06-03 00:29:27 [INFO]: Epoch 043 - training loss: 0.3678, validation loss: 0.2299
2024-06-03 00:30:36 [INFO]: Epoch 044 - training loss: 0.3655, validation loss: 0.2339
2024-06-03 00:31:45 [INFO]: Epoch 045 - training loss: 0.3672, validation loss: 0.2376
2024-06-03 00:32:54 [INFO]: Epoch 046 - training loss: 0.3645, validation loss: 0.2299
2024-06-03 00:34:03 [INFO]: Epoch 047 - training loss: 0.3626, validation loss: 0.2353
2024-06-03 00:35:12 [INFO]: Epoch 048 - training loss: 0.3612, validation loss: 0.2299
2024-06-03 00:36:20 [INFO]: Epoch 049 - training loss: 0.3626, validation loss: 0.2274
2024-06-03 00:37:29 [INFO]: Epoch 050 - training loss: 0.3617, validation loss: 0.2334
2024-06-03 00:38:37 [INFO]: Epoch 051 - training loss: 0.3594, validation loss: 0.2298
2024-06-03 00:39:46 [INFO]: Epoch 052 - training loss: 0.3579, validation loss: 0.2302
2024-06-03 00:40:55 [INFO]: Epoch 053 - training loss: 0.3590, validation loss: 0.2325
2024-06-03 00:42:04 [INFO]: Epoch 054 - training loss: 0.3584, validation loss: 0.2315
2024-06-03 00:43:13 [INFO]: Epoch 055 - training loss: 0.3576, validation loss: 0.2288
2024-06-03 00:44:22 [INFO]: Epoch 056 - training loss: 0.3555, validation loss: 0.2256
2024-06-03 00:45:31 [INFO]: Epoch 057 - training loss: 0.3560, validation loss: 0.2276
2024-06-03 00:46:40 [INFO]: Epoch 058 - training loss: 0.3545, validation loss: 0.2273
2024-06-03 00:47:49 [INFO]: Epoch 059 - training loss: 0.3544, validation loss: 0.2292
2024-06-03 00:48:58 [INFO]: Epoch 060 - training loss: 0.3520, validation loss: 0.2289
2024-06-03 00:50:07 [INFO]: Epoch 061 - training loss: 0.3503, validation loss: 0.2311
2024-06-03 00:51:16 [INFO]: Epoch 062 - training loss: 0.3491, validation loss: 0.2280
2024-06-03 00:52:25 [INFO]: Epoch 063 - training loss: 0.3489, validation loss: 0.2292
2024-06-03 00:53:34 [INFO]: Epoch 064 - training loss: 0.3484, validation loss: 0.2255
2024-06-03 00:54:42 [INFO]: Epoch 065 - training loss: 0.3510, validation loss: 0.2279
2024-06-03 00:55:51 [INFO]: Epoch 066 - training loss: 0.3484, validation loss: 0.2273
2024-06-03 00:57:00 [INFO]: Epoch 067 - training loss: 0.3468, validation loss: 0.2249
2024-06-03 00:58:09 [INFO]: Epoch 068 - training loss: 0.3474, validation loss: 0.2344
2024-06-03 00:59:17 [INFO]: Epoch 069 - training loss: 0.3478, validation loss: 0.2252
2024-06-03 01:00:26 [INFO]: Epoch 070 - training loss: 0.3467, validation loss: 0.2280
2024-06-03 01:01:35 [INFO]: Epoch 071 - training loss: 0.3433, validation loss: 0.2252
2024-06-03 01:02:44 [INFO]: Epoch 072 - training loss: 0.3429, validation loss: 0.2281
2024-06-03 01:03:53 [INFO]: Epoch 073 - training loss: 0.3437, validation loss: 0.2286
2024-06-03 01:05:02 [INFO]: Epoch 074 - training loss: 0.3434, validation loss: 0.2311
2024-06-03 01:06:10 [INFO]: Epoch 075 - training loss: 0.3417, validation loss: 0.2261
2024-06-03 01:07:21 [INFO]: Epoch 076 - training loss: 0.3387, validation loss: 0.2245
2024-06-03 01:08:32 [INFO]: Epoch 077 - training loss: 0.3393, validation loss: 0.2282
2024-06-03 01:09:43 [INFO]: Epoch 078 - training loss: 0.3383, validation loss: 0.2252
2024-06-03 01:10:54 [INFO]: Epoch 079 - training loss: 0.3381, validation loss: 0.2210
2024-06-03 01:12:05 [INFO]: Epoch 080 - training loss: 0.3377, validation loss: 0.2247
2024-06-03 01:13:16 [INFO]: Epoch 081 - training loss: 0.3352, validation loss: 0.2227
2024-06-03 01:14:27 [INFO]: Epoch 082 - training loss: 0.3356, validation loss: 0.2254
2024-06-03 01:15:37 [INFO]: Epoch 083 - training loss: 0.3361, validation loss: 0.2226
2024-06-03 01:16:48 [INFO]: Epoch 084 - training loss: 0.3357, validation loss: 0.2292
2024-06-03 01:17:58 [INFO]: Epoch 085 - training loss: 0.3327, validation loss: 0.2227
2024-06-03 01:19:10 [INFO]: Epoch 086 - training loss: 0.3337, validation loss: 0.2248
2024-06-03 01:20:21 [INFO]: Epoch 087 - training loss: 0.3303, validation loss: 0.2233
2024-06-03 01:21:31 [INFO]: Epoch 088 - training loss: 0.3300, validation loss: 0.2252
2024-06-03 01:22:42 [INFO]: Epoch 089 - training loss: 0.3293, validation loss: 0.2275
2024-06-03 01:22:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:22:42 [INFO]: Finished training. The best model is from epoch#79.
2024-06-03 01:22:43 [INFO]: Saved the model to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240602_T234007/Crossformer.pypots
2024-06-03 01:23:16 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_2/imputation.pkl
2024-06-03 01:23:16 [INFO]: Round2 - Crossformer on BeijingAir: MAE=0.2214, MSE=0.2336, MRE=0.3014
2024-06-03 01:23:16 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 01:23:16 [INFO]: Using the given device: cuda:0
2024-06-03 01:23:16 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T012316
2024-06-03 01:23:16 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T012316/tensorboard
2024-06-03 01:23:17 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 01:24:28 [INFO]: Epoch 001 - training loss: 1.3813, validation loss: 0.6847
2024-06-03 01:25:39 [INFO]: Epoch 002 - training loss: 0.8667, validation loss: 0.4576
2024-06-03 01:26:49 [INFO]: Epoch 003 - training loss: 0.7004, validation loss: 0.3779
2024-06-03 01:28:00 [INFO]: Epoch 004 - training loss: 0.6234, validation loss: 0.3380
2024-06-03 01:29:11 [INFO]: Epoch 005 - training loss: 0.5805, validation loss: 0.3083
2024-06-03 01:30:22 [INFO]: Epoch 006 - training loss: 0.5492, validation loss: 0.3111
2024-06-03 01:31:31 [INFO]: Epoch 007 - training loss: 0.5268, validation loss: 0.3038
2024-06-03 01:32:41 [INFO]: Epoch 008 - training loss: 0.5008, validation loss: 0.2744
2024-06-03 01:33:51 [INFO]: Epoch 009 - training loss: 0.4881, validation loss: 0.2874
2024-06-03 01:35:01 [INFO]: Epoch 010 - training loss: 0.4683, validation loss: 0.2854
2024-06-03 01:36:11 [INFO]: Epoch 011 - training loss: 0.4700, validation loss: 0.2759
2024-06-03 01:37:21 [INFO]: Epoch 012 - training loss: 0.4556, validation loss: 0.2744
2024-06-03 01:38:30 [INFO]: Epoch 013 - training loss: 0.4443, validation loss: 0.2732
2024-06-03 01:39:40 [INFO]: Epoch 014 - training loss: 0.4360, validation loss: 0.2615
2024-06-03 01:40:50 [INFO]: Epoch 015 - training loss: 0.4306, validation loss: 0.2656
2024-06-03 01:42:00 [INFO]: Epoch 016 - training loss: 0.4255, validation loss: 0.2741
2024-06-03 01:43:10 [INFO]: Epoch 017 - training loss: 0.4183, validation loss: 0.2542
2024-06-03 01:44:19 [INFO]: Epoch 018 - training loss: 0.4156, validation loss: 0.2498
2024-06-03 01:45:29 [INFO]: Epoch 019 - training loss: 0.4114, validation loss: 0.2597
2024-06-03 01:46:39 [INFO]: Epoch 020 - training loss: 0.4087, validation loss: 0.2597
2024-06-03 01:47:46 [INFO]: Epoch 021 - training loss: 0.4084, validation loss: 0.2431
2024-06-03 01:48:54 [INFO]: Epoch 022 - training loss: 0.4074, validation loss: 0.2475
2024-06-03 01:50:03 [INFO]: Epoch 023 - training loss: 0.3985, validation loss: 0.2453
2024-06-03 01:51:11 [INFO]: Epoch 024 - training loss: 0.3939, validation loss: 0.2480
2024-06-03 01:52:19 [INFO]: Epoch 025 - training loss: 0.3926, validation loss: 0.2449
2024-06-03 01:53:27 [INFO]: Epoch 026 - training loss: 0.3891, validation loss: 0.2442
2024-06-03 01:54:35 [INFO]: Epoch 027 - training loss: 0.3885, validation loss: 0.2416
2024-06-03 01:55:43 [INFO]: Epoch 028 - training loss: 0.3866, validation loss: 0.2556
2024-06-03 01:56:51 [INFO]: Epoch 029 - training loss: 0.3940, validation loss: 0.2387
2024-06-03 01:57:59 [INFO]: Epoch 030 - training loss: 0.3821, validation loss: 0.2337
2024-06-03 01:59:08 [INFO]: Epoch 031 - training loss: 0.3823, validation loss: 0.2390
2024-06-03 02:00:16 [INFO]: Epoch 032 - training loss: 0.3794, validation loss: 0.2356
2024-06-03 02:01:24 [INFO]: Epoch 033 - training loss: 0.3780, validation loss: 0.2335
2024-06-03 02:02:32 [INFO]: Epoch 034 - training loss: 0.3787, validation loss: 0.2320
2024-06-03 02:03:40 [INFO]: Epoch 035 - training loss: 0.3755, validation loss: 0.2366
2024-06-03 02:04:48 [INFO]: Epoch 036 - training loss: 0.3758, validation loss: 0.2332
2024-06-03 02:05:56 [INFO]: Epoch 037 - training loss: 0.3745, validation loss: 0.2320
2024-06-03 02:07:04 [INFO]: Epoch 038 - training loss: 0.3713, validation loss: 0.2312
2024-06-03 02:08:12 [INFO]: Epoch 039 - training loss: 0.3735, validation loss: 0.2349
2024-06-03 02:09:21 [INFO]: Epoch 040 - training loss: 0.3726, validation loss: 0.2392
2024-06-03 02:10:29 [INFO]: Epoch 041 - training loss: 0.3717, validation loss: 0.2328
2024-06-03 02:11:37 [INFO]: Epoch 042 - training loss: 0.3672, validation loss: 0.2330
2024-06-03 02:12:45 [INFO]: Epoch 043 - training loss: 0.3667, validation loss: 0.2346
2024-06-03 02:13:53 [INFO]: Epoch 044 - training loss: 0.3653, validation loss: 0.2337
2024-06-03 02:15:01 [INFO]: Epoch 045 - training loss: 0.3660, validation loss: 0.2324
2024-06-03 02:16:09 [INFO]: Epoch 046 - training loss: 0.3651, validation loss: 0.2357
2024-06-03 02:17:17 [INFO]: Epoch 047 - training loss: 0.3639, validation loss: 0.2323
2024-06-03 02:18:25 [INFO]: Epoch 048 - training loss: 0.3616, validation loss: 0.2357
2024-06-03 02:18:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:18:25 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 02:18:26 [INFO]: Saved the model to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T012316/Crossformer.pypots
2024-06-03 02:18:58 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_3/imputation.pkl
2024-06-03 02:18:58 [INFO]: Round3 - Crossformer on BeijingAir: MAE=0.2313, MSE=0.2412, MRE=0.3148
2024-06-03 02:18:58 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 02:18:58 [INFO]: Using the given device: cuda:0
2024-06-03 02:18:58 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T021858
2024-06-03 02:18:58 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T021858/tensorboard
2024-06-03 02:18:58 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 02:20:06 [INFO]: Epoch 001 - training loss: 1.2374, validation loss: 0.5689
2024-06-03 02:21:14 [INFO]: Epoch 002 - training loss: 0.7873, validation loss: 0.4247
2024-06-03 02:22:23 [INFO]: Epoch 003 - training loss: 0.6665, validation loss: 0.3814
2024-06-03 02:23:31 [INFO]: Epoch 004 - training loss: 0.6095, validation loss: 0.3632
2024-06-03 02:24:39 [INFO]: Epoch 005 - training loss: 0.5745, validation loss: 0.3175
2024-06-03 02:25:47 [INFO]: Epoch 006 - training loss: 0.5340, validation loss: 0.2915
2024-06-03 02:26:55 [INFO]: Epoch 007 - training loss: 0.5138, validation loss: 0.2919
2024-06-03 02:28:03 [INFO]: Epoch 008 - training loss: 0.4905, validation loss: 0.3187
2024-06-03 02:29:11 [INFO]: Epoch 009 - training loss: 0.4776, validation loss: 0.2824
2024-06-03 02:30:19 [INFO]: Epoch 010 - training loss: 0.4680, validation loss: 0.2720
2024-06-03 02:31:27 [INFO]: Epoch 011 - training loss: 0.4593, validation loss: 0.2670
2024-06-03 02:32:35 [INFO]: Epoch 012 - training loss: 0.4484, validation loss: 0.2638
2024-06-03 02:33:43 [INFO]: Epoch 013 - training loss: 0.4424, validation loss: 0.2592
2024-06-03 02:34:52 [INFO]: Epoch 014 - training loss: 0.4335, validation loss: 0.2590
2024-06-03 02:36:00 [INFO]: Epoch 015 - training loss: 0.4337, validation loss: 0.2595
2024-06-03 02:37:08 [INFO]: Epoch 016 - training loss: 0.4230, validation loss: 0.2605
2024-06-03 02:38:16 [INFO]: Epoch 017 - training loss: 0.4181, validation loss: 0.2608
2024-06-03 02:39:24 [INFO]: Epoch 018 - training loss: 0.4149, validation loss: 0.2716
2024-06-03 02:40:32 [INFO]: Epoch 019 - training loss: 0.4104, validation loss: 0.2516
2024-06-03 02:41:40 [INFO]: Epoch 020 - training loss: 0.4053, validation loss: 0.2543
2024-06-03 02:42:49 [INFO]: Epoch 021 - training loss: 0.4026, validation loss: 0.2503
2024-06-03 02:43:57 [INFO]: Epoch 022 - training loss: 0.4010, validation loss: 0.2634
2024-06-03 02:45:05 [INFO]: Epoch 023 - training loss: 0.4024, validation loss: 0.2568
2024-06-03 02:46:13 [INFO]: Epoch 024 - training loss: 0.3966, validation loss: 0.2535
2024-06-03 02:47:21 [INFO]: Epoch 025 - training loss: 0.3923, validation loss: 0.2400
2024-06-03 02:48:29 [INFO]: Epoch 026 - training loss: 0.3917, validation loss: 0.2356
2024-06-03 02:49:37 [INFO]: Epoch 027 - training loss: 0.3931, validation loss: 0.2536
2024-06-03 02:50:45 [INFO]: Epoch 028 - training loss: 0.3903, validation loss: 0.2467
2024-06-03 02:51:54 [INFO]: Epoch 029 - training loss: 0.3868, validation loss: 0.2425
2024-06-03 02:53:02 [INFO]: Epoch 030 - training loss: 0.3851, validation loss: 0.2399
2024-06-03 02:54:10 [INFO]: Epoch 031 - training loss: 0.3817, validation loss: 0.2368
2024-06-03 02:55:18 [INFO]: Epoch 032 - training loss: 0.3820, validation loss: 0.2364
2024-06-03 02:56:26 [INFO]: Epoch 033 - training loss: 0.3813, validation loss: 0.2375
2024-06-03 02:57:34 [INFO]: Epoch 034 - training loss: 0.3799, validation loss: 0.2324
2024-06-03 02:58:42 [INFO]: Epoch 035 - training loss: 0.3788, validation loss: 0.2381
2024-06-03 02:59:50 [INFO]: Epoch 036 - training loss: 0.3745, validation loss: 0.2355
2024-06-03 03:00:59 [INFO]: Epoch 037 - training loss: 0.3737, validation loss: 0.2361
2024-06-03 03:02:07 [INFO]: Epoch 038 - training loss: 0.3724, validation loss: 0.2322
2024-06-03 03:03:15 [INFO]: Epoch 039 - training loss: 0.3725, validation loss: 0.2320
2024-06-03 03:04:23 [INFO]: Epoch 040 - training loss: 0.3722, validation loss: 0.2361
2024-06-03 03:05:31 [INFO]: Epoch 041 - training loss: 0.3689, validation loss: 0.2301
2024-06-03 03:06:39 [INFO]: Epoch 042 - training loss: 0.3702, validation loss: 0.2374
2024-06-03 03:07:47 [INFO]: Epoch 043 - training loss: 0.3687, validation loss: 0.2349
2024-06-03 03:08:55 [INFO]: Epoch 044 - training loss: 0.3652, validation loss: 0.2348
2024-06-03 03:10:04 [INFO]: Epoch 045 - training loss: 0.3648, validation loss: 0.2310
2024-06-03 03:11:12 [INFO]: Epoch 046 - training loss: 0.3637, validation loss: 0.2313
2024-06-03 03:12:20 [INFO]: Epoch 047 - training loss: 0.3628, validation loss: 0.2327
2024-06-03 03:13:28 [INFO]: Epoch 048 - training loss: 0.3638, validation loss: 0.2266
2024-06-03 03:14:36 [INFO]: Epoch 049 - training loss: 0.3642, validation loss: 0.2297
2024-06-03 03:15:44 [INFO]: Epoch 050 - training loss: 0.3610, validation loss: 0.2298
2024-06-03 03:16:52 [INFO]: Epoch 051 - training loss: 0.3603, validation loss: 0.2289
2024-06-03 03:18:00 [INFO]: Epoch 052 - training loss: 0.3587, validation loss: 0.2346
2024-06-03 03:19:09 [INFO]: Epoch 053 - training loss: 0.3583, validation loss: 0.2265
2024-06-03 03:20:17 [INFO]: Epoch 054 - training loss: 0.3560, validation loss: 0.2304
2024-06-03 03:21:25 [INFO]: Epoch 055 - training loss: 0.3579, validation loss: 0.2340
2024-06-03 03:22:33 [INFO]: Epoch 056 - training loss: 0.3581, validation loss: 0.2266
2024-06-03 03:23:41 [INFO]: Epoch 057 - training loss: 0.3544, validation loss: 0.2308
2024-06-03 03:24:49 [INFO]: Epoch 058 - training loss: 0.3528, validation loss: 0.2299
2024-06-03 03:25:57 [INFO]: Epoch 059 - training loss: 0.3534, validation loss: 0.2320
2024-06-03 03:27:07 [INFO]: Epoch 060 - training loss: 0.3514, validation loss: 0.2226
2024-06-03 03:28:17 [INFO]: Epoch 061 - training loss: 0.3534, validation loss: 0.2270
2024-06-03 03:29:26 [INFO]: Epoch 062 - training loss: 0.3531, validation loss: 0.2260
2024-06-03 03:30:36 [INFO]: Epoch 063 - training loss: 0.3514, validation loss: 0.2260
2024-06-03 03:31:46 [INFO]: Epoch 064 - training loss: 0.3482, validation loss: 0.2299
2024-06-03 03:32:56 [INFO]: Epoch 065 - training loss: 0.3497, validation loss: 0.2250
2024-06-03 03:34:06 [INFO]: Epoch 066 - training loss: 0.3488, validation loss: 0.2272
2024-06-03 03:35:16 [INFO]: Epoch 067 - training loss: 0.3485, validation loss: 0.2261
2024-06-03 03:36:25 [INFO]: Epoch 068 - training loss: 0.3453, validation loss: 0.2311
2024-06-03 03:37:35 [INFO]: Epoch 069 - training loss: 0.3425, validation loss: 0.2257
2024-06-03 03:38:45 [INFO]: Epoch 070 - training loss: 0.3462, validation loss: 0.2324
2024-06-03 03:38:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:38:45 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 03:38:45 [INFO]: Saved the model to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T021858/Crossformer.pypots
2024-06-03 03:39:18 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Crossformer_BeijingAir/round_4/imputation.pkl
2024-06-03 03:39:18 [INFO]: Round4 - Crossformer on BeijingAir: MAE=0.2314, MSE=0.2330, MRE=0.3151
2024-06-03 03:39:18 [INFO]: Done! Final results:
Averaged Crossformer (52,933,788 params) on BeijingAir: MAE=0.2154 ± 0.007020037644914879, MSE=0.2243 ± 0.0042248260801559965, MRE=0.2855 ± 0.009304586155145709, average inference time=6.83