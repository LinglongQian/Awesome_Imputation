2024-06-02 20:59:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:59:58 [INFO]: Using the given device: cuda:0
2024-06-02 20:59:58 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240602_T205958
2024-06-02 20:59:58 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240602_T205958/tensorboard
2024-06-02 20:59:59 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-02 21:01:30 [INFO]: Epoch 001 - training loss: 0.5644, validation loss: 0.3912
2024-06-02 21:02:50 [INFO]: Epoch 002 - training loss: 0.3781, validation loss: 0.3642
2024-06-02 21:04:09 [INFO]: Epoch 003 - training loss: 0.3184, validation loss: 0.3709
2024-06-02 21:05:30 [INFO]: Epoch 004 - training loss: 0.3537, validation loss: 0.3462
2024-06-02 21:06:50 [INFO]: Epoch 005 - training loss: 0.3011, validation loss: 0.3443
2024-06-02 21:08:09 [INFO]: Epoch 006 - training loss: 0.2940, validation loss: 0.3311
2024-06-02 21:09:29 [INFO]: Epoch 007 - training loss: 0.2787, validation loss: 0.2960
2024-06-02 21:10:48 [INFO]: Epoch 008 - training loss: 0.2676, validation loss: 0.2556
2024-06-02 21:12:06 [INFO]: Epoch 009 - training loss: 0.2535, validation loss: 0.2825
2024-06-02 21:13:24 [INFO]: Epoch 010 - training loss: 0.2719, validation loss: 0.2385
2024-06-02 21:14:41 [INFO]: Epoch 011 - training loss: 0.2589, validation loss: 0.2171
2024-06-02 21:15:57 [INFO]: Epoch 012 - training loss: 0.2364, validation loss: 0.2073
2024-06-02 21:17:08 [INFO]: Epoch 013 - training loss: 0.2383, validation loss: 0.1992
2024-06-02 21:18:16 [INFO]: Epoch 014 - training loss: 0.2316, validation loss: 0.1845
2024-06-02 21:19:25 [INFO]: Epoch 015 - training loss: 0.2228, validation loss: 0.1860
2024-06-02 21:20:33 [INFO]: Epoch 016 - training loss: 0.2089, validation loss: 0.1809
2024-06-02 21:21:42 [INFO]: Epoch 017 - training loss: 0.2223, validation loss: 0.1911
2024-06-02 21:22:50 [INFO]: Epoch 018 - training loss: 0.2308, validation loss: 0.1720
2024-06-02 21:23:58 [INFO]: Epoch 019 - training loss: 0.2285, validation loss: 0.1721
2024-06-02 21:25:07 [INFO]: Epoch 020 - training loss: 0.2048, validation loss: 0.1687
2024-06-02 21:26:15 [INFO]: Epoch 021 - training loss: 0.2077, validation loss: 0.1675
2024-06-02 21:27:24 [INFO]: Epoch 022 - training loss: 0.1882, validation loss: 0.1590
2024-06-02 21:28:32 [INFO]: Epoch 023 - training loss: 0.1980, validation loss: 0.1610
2024-06-02 21:29:41 [INFO]: Epoch 024 - training loss: 0.1940, validation loss: 0.1562
2024-06-02 21:30:49 [INFO]: Epoch 025 - training loss: 0.2008, validation loss: 0.1518
2024-06-02 21:31:57 [INFO]: Epoch 026 - training loss: 0.1859, validation loss: 0.1538
2024-06-02 21:33:06 [INFO]: Epoch 027 - training loss: 0.2032, validation loss: 0.1639
2024-06-02 21:34:14 [INFO]: Epoch 028 - training loss: 0.2110, validation loss: 0.1573
2024-06-02 21:35:23 [INFO]: Epoch 029 - training loss: 0.1978, validation loss: 0.1565
2024-06-02 21:36:32 [INFO]: Epoch 030 - training loss: 0.1968, validation loss: 0.1592
2024-06-02 21:37:40 [INFO]: Epoch 031 - training loss: 0.2014, validation loss: 0.1520
2024-06-02 21:38:48 [INFO]: Epoch 032 - training loss: 0.1847, validation loss: 0.1452
2024-06-02 21:39:56 [INFO]: Epoch 033 - training loss: 0.1793, validation loss: 0.1414
2024-06-02 21:41:05 [INFO]: Epoch 034 - training loss: 0.1844, validation loss: 0.1450
2024-06-02 21:42:14 [INFO]: Epoch 035 - training loss: 0.1696, validation loss: 0.1436
2024-06-02 21:43:22 [INFO]: Epoch 036 - training loss: 0.1859, validation loss: 0.1599
2024-06-02 21:44:31 [INFO]: Epoch 037 - training loss: 0.1810, validation loss: 0.1454
2024-06-02 21:45:40 [INFO]: Epoch 038 - training loss: 0.1841, validation loss: 0.1423
2024-06-02 21:46:49 [INFO]: Epoch 039 - training loss: 0.1753, validation loss: 0.1451
2024-06-02 21:47:57 [INFO]: Epoch 040 - training loss: 0.1696, validation loss: 0.1421
2024-06-02 21:49:06 [INFO]: Epoch 041 - training loss: 0.1674, validation loss: 0.1456
2024-06-02 21:50:14 [INFO]: Epoch 042 - training loss: 0.1754, validation loss: 0.1382
2024-06-02 21:51:23 [INFO]: Epoch 043 - training loss: 0.1836, validation loss: 0.1368
2024-06-02 21:52:31 [INFO]: Epoch 044 - training loss: 0.1605, validation loss: 0.1412
2024-06-02 21:53:40 [INFO]: Epoch 045 - training loss: 0.1823, validation loss: 0.1363
2024-06-02 21:54:48 [INFO]: Epoch 046 - training loss: 0.1849, validation loss: 0.1352
2024-06-02 21:55:56 [INFO]: Epoch 047 - training loss: 0.1796, validation loss: 0.1364
2024-06-02 21:57:05 [INFO]: Epoch 048 - training loss: 0.1784, validation loss: 0.1333
2024-06-02 21:58:14 [INFO]: Epoch 049 - training loss: 0.1704, validation loss: 0.1336
2024-06-02 21:59:23 [INFO]: Epoch 050 - training loss: 0.1825, validation loss: 0.1334
2024-06-02 22:00:31 [INFO]: Epoch 051 - training loss: 0.1676, validation loss: 0.1337
2024-06-02 22:01:40 [INFO]: Epoch 052 - training loss: 0.1803, validation loss: 0.1332
2024-06-02 22:02:48 [INFO]: Epoch 053 - training loss: 0.1603, validation loss: 0.1287
2024-06-02 22:03:56 [INFO]: Epoch 054 - training loss: 0.1714, validation loss: 0.1306
2024-06-02 22:05:05 [INFO]: Epoch 055 - training loss: 0.1585, validation loss: 0.1298
2024-06-02 22:06:15 [INFO]: Epoch 056 - training loss: 0.1752, validation loss: 0.1318
2024-06-02 22:07:23 [INFO]: Epoch 057 - training loss: 0.1737, validation loss: 0.1282
2024-06-02 22:08:32 [INFO]: Epoch 058 - training loss: 0.1516, validation loss: 0.1332
2024-06-02 22:09:40 [INFO]: Epoch 059 - training loss: 0.1637, validation loss: 0.1289
2024-06-02 22:10:49 [INFO]: Epoch 060 - training loss: 0.1779, validation loss: 0.1305
2024-06-02 22:11:57 [INFO]: Epoch 061 - training loss: 0.1679, validation loss: 0.1282
2024-06-02 22:13:06 [INFO]: Epoch 062 - training loss: 0.1611, validation loss: 0.1273
2024-06-02 22:14:14 [INFO]: Epoch 063 - training loss: 0.1796, validation loss: 0.1248
2024-06-02 22:15:23 [INFO]: Epoch 064 - training loss: 0.1733, validation loss: 0.1240
2024-06-02 22:16:32 [INFO]: Epoch 065 - training loss: 0.1626, validation loss: 0.1253
2024-06-02 22:17:41 [INFO]: Epoch 066 - training loss: 0.1410, validation loss: 0.1224
2024-06-02 22:18:50 [INFO]: Epoch 067 - training loss: 0.1623, validation loss: 0.1232
2024-06-02 22:19:58 [INFO]: Epoch 068 - training loss: 0.1575, validation loss: 0.1297
2024-06-02 22:21:07 [INFO]: Epoch 069 - training loss: 0.1656, validation loss: 0.1218
2024-06-02 22:22:15 [INFO]: Epoch 070 - training loss: 0.1641, validation loss: 0.1276
2024-06-02 22:23:24 [INFO]: Epoch 071 - training loss: 0.1619, validation loss: 0.1255
2024-06-02 22:24:32 [INFO]: Epoch 072 - training loss: 0.1661, validation loss: 0.1216
2024-06-02 22:25:41 [INFO]: Epoch 073 - training loss: 0.1639, validation loss: 0.1225
2024-06-02 22:26:49 [INFO]: Epoch 074 - training loss: 0.1543, validation loss: 0.1245
2024-06-02 22:27:58 [INFO]: Epoch 075 - training loss: 0.1582, validation loss: 0.1207
2024-06-02 22:29:02 [INFO]: Epoch 076 - training loss: 0.1713, validation loss: 0.1212
2024-06-02 22:30:06 [INFO]: Epoch 077 - training loss: 0.1628, validation loss: 0.1213
2024-06-02 22:31:09 [INFO]: Epoch 078 - training loss: 0.1595, validation loss: 0.1210
2024-06-02 22:32:13 [INFO]: Epoch 079 - training loss: 0.1586, validation loss: 0.1203
2024-06-02 22:33:17 [INFO]: Epoch 080 - training loss: 0.1514, validation loss: 0.1208
2024-06-02 22:34:21 [INFO]: Epoch 081 - training loss: 0.1342, validation loss: 0.1194
2024-06-02 22:35:25 [INFO]: Epoch 082 - training loss: 0.1371, validation loss: 0.1232
2024-06-02 22:36:29 [INFO]: Epoch 083 - training loss: 0.1677, validation loss: 0.1197
2024-06-02 22:37:33 [INFO]: Epoch 084 - training loss: 0.1639, validation loss: 0.1196
2024-06-02 22:38:37 [INFO]: Epoch 085 - training loss: 0.1450, validation loss: 0.1209
2024-06-02 22:39:41 [INFO]: Epoch 086 - training loss: 0.1591, validation loss: 0.1206
2024-06-02 22:40:45 [INFO]: Epoch 087 - training loss: 0.1522, validation loss: 0.1182
2024-06-02 22:41:49 [INFO]: Epoch 088 - training loss: 0.1510, validation loss: 0.1186
2024-06-02 22:42:53 [INFO]: Epoch 089 - training loss: 0.1563, validation loss: 0.1205
2024-06-02 22:43:57 [INFO]: Epoch 090 - training loss: 0.1482, validation loss: 0.1200
2024-06-02 22:45:01 [INFO]: Epoch 091 - training loss: 0.1634, validation loss: 0.1213
2024-06-02 22:46:05 [INFO]: Epoch 092 - training loss: 0.1492, validation loss: 0.1230
2024-06-02 22:47:08 [INFO]: Epoch 093 - training loss: 0.1479, validation loss: 0.1202
2024-06-02 22:48:12 [INFO]: Epoch 094 - training loss: 0.1495, validation loss: 0.1193
2024-06-02 22:49:16 [INFO]: Epoch 095 - training loss: 0.1476, validation loss: 0.1167
2024-06-02 22:50:20 [INFO]: Epoch 096 - training loss: 0.1420, validation loss: 0.1166
2024-06-02 22:51:24 [INFO]: Epoch 097 - training loss: 0.1490, validation loss: 0.1176
2024-06-02 22:52:28 [INFO]: Epoch 098 - training loss: 0.1499, validation loss: 0.1230
2024-06-02 22:53:31 [INFO]: Epoch 099 - training loss: 0.1551, validation loss: 0.1193
2024-06-02 22:54:35 [INFO]: Epoch 100 - training loss: 0.1448, validation loss: 0.1151
2024-06-02 22:54:35 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 22:54:35 [INFO]: Saved the model to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240602_T205958/CSDI.pypots
2024-06-02 23:35:54 [INFO]: Successfully saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_0/imputation.pkl
2024-06-02 23:35:54 [INFO]: Round0 - CSDI on BeijingAir: MAE=0.1614, MSE=0.7050, MRE=0.2197
2024-06-02 23:35:54 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 23:35:54 [INFO]: Using the given device: cuda:0
2024-06-02 23:35:54 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240602_T233554
2024-06-02 23:35:54 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240602_T233554/tensorboard
2024-06-02 23:35:54 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-02 23:36:59 [INFO]: Epoch 001 - training loss: 0.5376, validation loss: 0.4021
2024-06-02 23:38:02 [INFO]: Epoch 002 - training loss: 0.3696, validation loss: 0.3383
2024-06-02 23:39:05 [INFO]: Epoch 003 - training loss: 0.3533, validation loss: 0.3362
2024-06-02 23:40:08 [INFO]: Epoch 004 - training loss: 0.3320, validation loss: 0.3286
2024-06-02 23:41:12 [INFO]: Epoch 005 - training loss: 0.3001, validation loss: 0.3005
2024-06-02 23:42:16 [INFO]: Epoch 006 - training loss: 0.2819, validation loss: 0.2649
2024-06-02 23:43:20 [INFO]: Epoch 007 - training loss: 0.2800, validation loss: 0.2396
2024-06-02 23:44:25 [INFO]: Epoch 008 - training loss: 0.2526, validation loss: 0.2297
2024-06-02 23:45:28 [INFO]: Epoch 009 - training loss: 0.2453, validation loss: 0.2222
2024-06-02 23:46:32 [INFO]: Epoch 010 - training loss: 0.2386, validation loss: 0.2030
2024-06-02 23:47:36 [INFO]: Epoch 011 - training loss: 0.2405, validation loss: 0.1923
2024-06-02 23:48:40 [INFO]: Epoch 012 - training loss: 0.2141, validation loss: 0.1889
2024-06-02 23:49:44 [INFO]: Epoch 013 - training loss: 0.2145, validation loss: 0.1837
2024-06-02 23:50:48 [INFO]: Epoch 014 - training loss: 0.2284, validation loss: 0.1842
2024-06-02 23:51:52 [INFO]: Epoch 015 - training loss: 0.2148, validation loss: 0.1889
2024-06-02 23:52:56 [INFO]: Epoch 016 - training loss: 0.2101, validation loss: 0.1750
2024-06-02 23:53:59 [INFO]: Epoch 017 - training loss: 0.2093, validation loss: 0.1683
2024-06-02 23:55:03 [INFO]: Epoch 018 - training loss: 0.2020, validation loss: 0.1707
2024-06-02 23:56:06 [INFO]: Epoch 019 - training loss: 0.2067, validation loss: 0.1731
2024-06-02 23:57:10 [INFO]: Epoch 020 - training loss: 0.2081, validation loss: 0.1662
2024-06-02 23:58:14 [INFO]: Epoch 021 - training loss: 0.2120, validation loss: 0.1623
2024-06-02 23:59:17 [INFO]: Epoch 022 - training loss: 0.2134, validation loss: 0.1621
2024-06-03 00:00:21 [INFO]: Epoch 023 - training loss: 0.1928, validation loss: 0.1630
2024-06-03 00:01:25 [INFO]: Epoch 024 - training loss: 0.1788, validation loss: 0.1586
2024-06-03 00:02:29 [INFO]: Epoch 025 - training loss: 0.1864, validation loss: 0.1649
2024-06-03 00:03:32 [INFO]: Epoch 026 - training loss: 0.1959, validation loss: 0.1589
2024-06-03 00:04:36 [INFO]: Epoch 027 - training loss: 0.1882, validation loss: 0.1586
2024-06-03 00:05:40 [INFO]: Epoch 028 - training loss: 0.1719, validation loss: 0.1549
2024-06-03 00:06:43 [INFO]: Epoch 029 - training loss: 0.1916, validation loss: 0.1605
2024-06-03 00:07:47 [INFO]: Epoch 030 - training loss: 0.2129, validation loss: 0.1534
2024-06-03 00:08:51 [INFO]: Epoch 031 - training loss: 0.2030, validation loss: 0.1495
2024-06-03 00:09:55 [INFO]: Epoch 032 - training loss: 0.1832, validation loss: 0.1525
2024-06-03 00:10:59 [INFO]: Epoch 033 - training loss: 0.1865, validation loss: 0.1481
2024-06-03 00:12:03 [INFO]: Epoch 034 - training loss: 0.1730, validation loss: 0.1468
2024-06-03 00:13:07 [INFO]: Epoch 035 - training loss: 0.1701, validation loss: 0.1503
2024-06-03 00:14:11 [INFO]: Epoch 036 - training loss: 0.1955, validation loss: 0.1540
2024-06-03 00:15:15 [INFO]: Epoch 037 - training loss: 0.1789, validation loss: 0.1480
2024-06-03 00:16:18 [INFO]: Epoch 038 - training loss: 0.1704, validation loss: 0.1529
2024-06-03 00:17:22 [INFO]: Epoch 039 - training loss: 0.1831, validation loss: 0.1453
2024-06-03 00:18:26 [INFO]: Epoch 040 - training loss: 0.1678, validation loss: 0.1420
2024-06-03 00:19:29 [INFO]: Epoch 041 - training loss: 0.1867, validation loss: 0.1403
2024-06-03 00:20:33 [INFO]: Epoch 042 - training loss: 0.1822, validation loss: 0.1400
2024-06-03 00:21:37 [INFO]: Epoch 043 - training loss: 0.1716, validation loss: 0.1375
2024-06-03 00:22:40 [INFO]: Epoch 044 - training loss: 0.1815, validation loss: 0.1424
2024-06-03 00:23:44 [INFO]: Epoch 045 - training loss: 0.1596, validation loss: 0.1379
2024-06-03 00:24:48 [INFO]: Epoch 046 - training loss: 0.1528, validation loss: 0.1469
2024-06-03 00:25:52 [INFO]: Epoch 047 - training loss: 0.1669, validation loss: 0.1403
2024-06-03 00:26:56 [INFO]: Epoch 048 - training loss: 0.1794, validation loss: 0.1401
2024-06-03 00:28:00 [INFO]: Epoch 049 - training loss: 0.1650, validation loss: 0.1339
2024-06-03 00:29:04 [INFO]: Epoch 050 - training loss: 0.1629, validation loss: 0.1331
2024-06-03 00:30:08 [INFO]: Epoch 051 - training loss: 0.1616, validation loss: 0.1329
2024-06-03 00:31:11 [INFO]: Epoch 052 - training loss: 0.1650, validation loss: 0.1366
2024-06-03 00:32:15 [INFO]: Epoch 053 - training loss: 0.1550, validation loss: 0.1438
2024-06-03 00:33:19 [INFO]: Epoch 054 - training loss: 0.1673, validation loss: 0.1364
2024-06-03 00:34:23 [INFO]: Epoch 055 - training loss: 0.1728, validation loss: 0.1342
2024-06-03 00:35:27 [INFO]: Epoch 056 - training loss: 0.1575, validation loss: 0.1323
2024-06-03 00:36:31 [INFO]: Epoch 057 - training loss: 0.1771, validation loss: 0.1342
2024-06-03 00:37:34 [INFO]: Epoch 058 - training loss: 0.1663, validation loss: 0.1310
2024-06-03 00:38:38 [INFO]: Epoch 059 - training loss: 0.1814, validation loss: 0.1354
2024-06-03 00:39:42 [INFO]: Epoch 060 - training loss: 0.1671, validation loss: 0.1352
2024-06-03 00:40:46 [INFO]: Epoch 061 - training loss: 0.1686, validation loss: 0.1307
2024-06-03 00:41:49 [INFO]: Epoch 062 - training loss: 0.1602, validation loss: 0.1322
2024-06-03 00:42:53 [INFO]: Epoch 063 - training loss: 0.1724, validation loss: 0.1312
2024-06-03 00:43:57 [INFO]: Epoch 064 - training loss: 0.1759, validation loss: 0.1317
2024-06-03 00:45:00 [INFO]: Epoch 065 - training loss: 0.1760, validation loss: 0.1294
2024-06-03 00:46:04 [INFO]: Epoch 066 - training loss: 0.1781, validation loss: 0.1313
2024-06-03 00:47:08 [INFO]: Epoch 067 - training loss: 0.1656, validation loss: 0.1269
2024-06-03 00:48:11 [INFO]: Epoch 068 - training loss: 0.1574, validation loss: 0.1285
2024-06-03 00:49:15 [INFO]: Epoch 069 - training loss: 0.1755, validation loss: 0.1271
2024-06-03 00:50:18 [INFO]: Epoch 070 - training loss: 0.1578, validation loss: 0.1304
2024-06-03 00:51:22 [INFO]: Epoch 071 - training loss: 0.1736, validation loss: 0.1274
2024-06-03 00:52:26 [INFO]: Epoch 072 - training loss: 0.1532, validation loss: 0.1277
2024-06-03 00:53:30 [INFO]: Epoch 073 - training loss: 0.1715, validation loss: 0.1277
2024-06-03 00:54:34 [INFO]: Epoch 074 - training loss: 0.1682, validation loss: 0.1269
2024-06-03 00:55:38 [INFO]: Epoch 075 - training loss: 0.1674, validation loss: 0.1238
2024-06-03 00:56:41 [INFO]: Epoch 076 - training loss: 0.1621, validation loss: 0.1255
2024-06-03 00:57:45 [INFO]: Epoch 077 - training loss: 0.1558, validation loss: 0.1242
2024-06-03 00:58:49 [INFO]: Epoch 078 - training loss: 0.1777, validation loss: 0.1325
2024-06-03 00:59:53 [INFO]: Epoch 079 - training loss: 0.1757, validation loss: 0.1292
2024-06-03 01:00:57 [INFO]: Epoch 080 - training loss: 0.1746, validation loss: 0.1252
2024-06-03 01:02:01 [INFO]: Epoch 081 - training loss: 0.1696, validation loss: 0.1240
2024-06-03 01:03:05 [INFO]: Epoch 082 - training loss: 0.1558, validation loss: 0.1271
2024-06-03 01:04:09 [INFO]: Epoch 083 - training loss: 0.1587, validation loss: 0.1245
2024-06-03 01:05:13 [INFO]: Epoch 084 - training loss: 0.1594, validation loss: 0.1267
2024-06-03 01:06:17 [INFO]: Epoch 085 - training loss: 0.1686, validation loss: 0.1254
2024-06-03 01:06:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 01:06:17 [INFO]: Finished training. The best model is from epoch#75.
2024-06-03 01:06:17 [INFO]: Saved the model to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240602_T233554/CSDI.pypots
2024-06-03 01:46:40 [INFO]: Successfully saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_1/imputation.pkl
2024-06-03 01:46:40 [INFO]: Round1 - CSDI on BeijingAir: MAE=0.1701, MSE=0.5610, MRE=0.2315
2024-06-03 01:46:40 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 01:46:40 [INFO]: Using the given device: cuda:0
2024-06-03 01:46:40 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T014640
2024-06-03 01:46:40 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T014640/tensorboard
2024-06-03 01:46:40 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 01:47:40 [INFO]: Epoch 001 - training loss: 0.5289, validation loss: 0.3798
2024-06-03 01:48:40 [INFO]: Epoch 002 - training loss: 0.3556, validation loss: 0.3426
2024-06-03 01:49:40 [INFO]: Epoch 003 - training loss: 0.3362, validation loss: 0.3413
2024-06-03 01:50:40 [INFO]: Epoch 004 - training loss: 0.2859, validation loss: 0.3180
2024-06-03 01:51:39 [INFO]: Epoch 005 - training loss: 0.2981, validation loss: 0.2838
2024-06-03 01:52:39 [INFO]: Epoch 006 - training loss: 0.3053, validation loss: 0.3014
2024-06-03 01:53:39 [INFO]: Epoch 007 - training loss: 0.2539, validation loss: 0.2510
2024-06-03 01:54:39 [INFO]: Epoch 008 - training loss: 0.2639, validation loss: 0.2360
2024-06-03 01:55:38 [INFO]: Epoch 009 - training loss: 0.2559, validation loss: 0.2508
2024-06-03 01:56:38 [INFO]: Epoch 010 - training loss: 0.2551, validation loss: 0.2301
2024-06-03 01:57:38 [INFO]: Epoch 011 - training loss: 0.2426, validation loss: 0.2294
2024-06-03 01:58:38 [INFO]: Epoch 012 - training loss: 0.2255, validation loss: 0.2006
2024-06-03 01:59:38 [INFO]: Epoch 013 - training loss: 0.2282, validation loss: 0.2048
2024-06-03 02:00:37 [INFO]: Epoch 014 - training loss: 0.2276, validation loss: 0.2038
2024-06-03 02:01:37 [INFO]: Epoch 015 - training loss: 0.2267, validation loss: 0.1941
2024-06-03 02:02:37 [INFO]: Epoch 016 - training loss: 0.2349, validation loss: 0.1827
2024-06-03 02:03:36 [INFO]: Epoch 017 - training loss: 0.2186, validation loss: 0.1850
2024-06-03 02:04:36 [INFO]: Epoch 018 - training loss: 0.2191, validation loss: 0.1794
2024-06-03 02:05:36 [INFO]: Epoch 019 - training loss: 0.2039, validation loss: 0.1745
2024-06-03 02:06:36 [INFO]: Epoch 020 - training loss: 0.2105, validation loss: 0.1697
2024-06-03 02:07:35 [INFO]: Epoch 021 - training loss: 0.2139, validation loss: 0.1712
2024-06-03 02:08:35 [INFO]: Epoch 022 - training loss: 0.1955, validation loss: 0.1674
2024-06-03 02:09:35 [INFO]: Epoch 023 - training loss: 0.2021, validation loss: 0.1687
2024-06-03 02:10:35 [INFO]: Epoch 024 - training loss: 0.2109, validation loss: 0.1685
2024-06-03 02:11:34 [INFO]: Epoch 025 - training loss: 0.2137, validation loss: 0.1570
2024-06-03 02:12:34 [INFO]: Epoch 026 - training loss: 0.1939, validation loss: 0.1595
2024-06-03 02:13:34 [INFO]: Epoch 027 - training loss: 0.1904, validation loss: 0.1650
2024-06-03 02:14:34 [INFO]: Epoch 028 - training loss: 0.1933, validation loss: 0.1539
2024-06-03 02:15:33 [INFO]: Epoch 029 - training loss: 0.2031, validation loss: 0.1624
2024-06-03 02:16:33 [INFO]: Epoch 030 - training loss: 0.1934, validation loss: 0.1533
2024-06-03 02:17:33 [INFO]: Epoch 031 - training loss: 0.2067, validation loss: 0.1517
2024-06-03 02:18:32 [INFO]: Epoch 032 - training loss: 0.1897, validation loss: 0.1536
2024-06-03 02:19:32 [INFO]: Epoch 033 - training loss: 0.1922, validation loss: 0.1507
2024-06-03 02:20:32 [INFO]: Epoch 034 - training loss: 0.1862, validation loss: 0.1507
2024-06-03 02:21:31 [INFO]: Epoch 035 - training loss: 0.1826, validation loss: 0.1673
2024-06-03 02:22:31 [INFO]: Epoch 036 - training loss: 0.1703, validation loss: 0.1527
2024-06-03 02:23:31 [INFO]: Epoch 037 - training loss: 0.1789, validation loss: 0.1505
2024-06-03 02:24:30 [INFO]: Epoch 038 - training loss: 0.1601, validation loss: 0.1520
2024-06-03 02:25:30 [INFO]: Epoch 039 - training loss: 0.1873, validation loss: 0.1454
2024-06-03 02:26:30 [INFO]: Epoch 040 - training loss: 0.1635, validation loss: 0.1458
2024-06-03 02:27:30 [INFO]: Epoch 041 - training loss: 0.1878, validation loss: 0.1463
2024-06-03 02:28:29 [INFO]: Epoch 042 - training loss: 0.1811, validation loss: 0.1475
2024-06-03 02:29:29 [INFO]: Epoch 043 - training loss: 0.1667, validation loss: 0.1449
2024-06-03 02:30:29 [INFO]: Epoch 044 - training loss: 0.1595, validation loss: 0.1460
2024-06-03 02:31:29 [INFO]: Epoch 045 - training loss: 0.1831, validation loss: 0.1397
2024-06-03 02:32:28 [INFO]: Epoch 046 - training loss: 0.1860, validation loss: 0.1472
2024-06-03 02:33:28 [INFO]: Epoch 047 - training loss: 0.1665, validation loss: 0.1420
2024-06-03 02:34:28 [INFO]: Epoch 048 - training loss: 0.1549, validation loss: 0.1429
2024-06-03 02:35:28 [INFO]: Epoch 049 - training loss: 0.1654, validation loss: 0.1366
2024-06-03 02:36:27 [INFO]: Epoch 050 - training loss: 0.2022, validation loss: 0.1435
2024-06-03 02:37:27 [INFO]: Epoch 051 - training loss: 0.1688, validation loss: 0.1437
2024-06-03 02:38:27 [INFO]: Epoch 052 - training loss: 0.1787, validation loss: 0.1394
2024-06-03 02:39:27 [INFO]: Epoch 053 - training loss: 0.1633, validation loss: 0.1358
2024-06-03 02:40:26 [INFO]: Epoch 054 - training loss: 0.1722, validation loss: 0.1354
2024-06-03 02:41:26 [INFO]: Epoch 055 - training loss: 0.1790, validation loss: 0.1453
2024-06-03 02:42:26 [INFO]: Epoch 056 - training loss: 0.1854, validation loss: 0.1410
2024-06-03 02:43:26 [INFO]: Epoch 057 - training loss: 0.1590, validation loss: 0.1329
2024-06-03 02:44:25 [INFO]: Epoch 058 - training loss: 0.1884, validation loss: 0.1394
2024-06-03 02:45:25 [INFO]: Epoch 059 - training loss: 0.1664, validation loss: 0.1365
2024-06-03 02:46:25 [INFO]: Epoch 060 - training loss: 0.1808, validation loss: 0.1388
2024-06-03 02:47:24 [INFO]: Epoch 061 - training loss: 0.1449, validation loss: 0.1421
2024-06-03 02:48:24 [INFO]: Epoch 062 - training loss: 0.1498, validation loss: 0.1331
2024-06-03 02:49:24 [INFO]: Epoch 063 - training loss: 0.1618, validation loss: 0.1294
2024-06-03 02:50:24 [INFO]: Epoch 064 - training loss: 0.1542, validation loss: 0.1268
2024-06-03 02:51:23 [INFO]: Epoch 065 - training loss: 0.1477, validation loss: 0.1274
2024-06-03 02:52:23 [INFO]: Epoch 066 - training loss: 0.1686, validation loss: 0.1313
2024-06-03 02:53:23 [INFO]: Epoch 067 - training loss: 0.1537, validation loss: 0.1292
2024-06-03 02:54:23 [INFO]: Epoch 068 - training loss: 0.1573, validation loss: 0.1322
2024-06-03 02:55:22 [INFO]: Epoch 069 - training loss: 0.1884, validation loss: 0.1278
2024-06-03 02:56:22 [INFO]: Epoch 070 - training loss: 0.1454, validation loss: 0.1261
2024-06-03 02:57:22 [INFO]: Epoch 071 - training loss: 0.1612, validation loss: 0.1272
2024-06-03 02:58:22 [INFO]: Epoch 072 - training loss: 0.1404, validation loss: 0.1323
2024-06-03 02:59:21 [INFO]: Epoch 073 - training loss: 0.1617, validation loss: 0.1281
2024-06-03 03:00:21 [INFO]: Epoch 074 - training loss: 0.1520, validation loss: 0.1324
2024-06-03 03:01:21 [INFO]: Epoch 075 - training loss: 0.1649, validation loss: 0.1254
2024-06-03 03:02:21 [INFO]: Epoch 076 - training loss: 0.1552, validation loss: 0.1350
2024-06-03 03:03:20 [INFO]: Epoch 077 - training loss: 0.1683, validation loss: 0.1342
2024-06-03 03:04:20 [INFO]: Epoch 078 - training loss: 0.1658, validation loss: 0.1267
2024-06-03 03:05:20 [INFO]: Epoch 079 - training loss: 0.1622, validation loss: 0.1256
2024-06-03 03:06:20 [INFO]: Epoch 080 - training loss: 0.1525, validation loss: 0.1326
2024-06-03 03:07:19 [INFO]: Epoch 081 - training loss: 0.1820, validation loss: 0.1356
2024-06-03 03:08:19 [INFO]: Epoch 082 - training loss: 0.1718, validation loss: 0.1264
2024-06-03 03:09:19 [INFO]: Epoch 083 - training loss: 0.1519, validation loss: 0.1272
2024-06-03 03:10:19 [INFO]: Epoch 084 - training loss: 0.1715, validation loss: 0.1261
2024-06-03 03:11:18 [INFO]: Epoch 085 - training loss: 0.1566, validation loss: 0.1221
2024-06-03 03:12:18 [INFO]: Epoch 086 - training loss: 0.1706, validation loss: 0.1254
2024-06-03 03:13:18 [INFO]: Epoch 087 - training loss: 0.1456, validation loss: 0.1249
2024-06-03 03:14:18 [INFO]: Epoch 088 - training loss: 0.1537, validation loss: 0.1214
2024-06-03 03:15:17 [INFO]: Epoch 089 - training loss: 0.1656, validation loss: 0.1210
2024-06-03 03:16:17 [INFO]: Epoch 090 - training loss: 0.1670, validation loss: 0.1199
2024-06-03 03:17:17 [INFO]: Epoch 091 - training loss: 0.1573, validation loss: 0.1235
2024-06-03 03:18:17 [INFO]: Epoch 092 - training loss: 0.1517, validation loss: 0.1282
2024-06-03 03:19:16 [INFO]: Epoch 093 - training loss: 0.1565, validation loss: 0.1268
2024-06-03 03:20:16 [INFO]: Epoch 094 - training loss: 0.1574, validation loss: 0.1282
2024-06-03 03:21:16 [INFO]: Epoch 095 - training loss: 0.1494, validation loss: 0.1207
2024-06-03 03:22:16 [INFO]: Epoch 096 - training loss: 0.1723, validation loss: 0.1236
2024-06-03 03:23:15 [INFO]: Epoch 097 - training loss: 0.1477, validation loss: 0.1242
2024-06-03 03:24:15 [INFO]: Epoch 098 - training loss: 0.1522, validation loss: 0.1281
2024-06-03 03:25:15 [INFO]: Epoch 099 - training loss: 0.1443, validation loss: 0.1223
2024-06-03 03:26:15 [INFO]: Epoch 100 - training loss: 0.1529, validation loss: 0.1249
2024-06-03 03:26:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:26:15 [INFO]: Finished training. The best model is from epoch#90.
2024-06-03 03:26:15 [INFO]: Saved the model to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T014640/CSDI.pypots
2024-06-03 03:50:50 [INFO]: Successfully saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_2/imputation.pkl
2024-06-03 03:50:50 [INFO]: Round2 - CSDI on BeijingAir: MAE=0.1708, MSE=0.6612, MRE=0.2326
2024-06-03 03:50:50 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:50:50 [INFO]: Using the given device: cuda:0
2024-06-03 03:50:50 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T035050
2024-06-03 03:50:50 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T035050/tensorboard
2024-06-03 03:50:50 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 03:51:16 [INFO]: Epoch 001 - training loss: 0.5693, validation loss: 0.4004
2024-06-03 03:51:43 [INFO]: Epoch 002 - training loss: 0.3774, validation loss: 0.3577
2024-06-03 03:52:09 [INFO]: Epoch 003 - training loss: 0.3466, validation loss: 0.3626
2024-06-03 03:52:35 [INFO]: Epoch 004 - training loss: 0.3309, validation loss: 0.3137
2024-06-03 03:53:01 [INFO]: Epoch 005 - training loss: 0.2925, validation loss: 0.3467
2024-06-03 03:53:27 [INFO]: Epoch 006 - training loss: 0.2898, validation loss: 0.2995
2024-06-03 03:53:53 [INFO]: Epoch 007 - training loss: 0.2895, validation loss: 0.2803
2024-06-03 03:54:19 [INFO]: Epoch 008 - training loss: 0.2674, validation loss: 0.2665
2024-06-03 03:54:45 [INFO]: Epoch 009 - training loss: 0.2499, validation loss: 0.2510
2024-06-03 03:55:12 [INFO]: Epoch 010 - training loss: 0.2515, validation loss: 0.2816
2024-06-03 03:55:38 [INFO]: Epoch 011 - training loss: 0.2421, validation loss: 0.2262
2024-06-03 03:56:04 [INFO]: Epoch 012 - training loss: 0.2245, validation loss: 0.2132
2024-06-03 03:56:30 [INFO]: Epoch 013 - training loss: 0.2467, validation loss: 0.2090
2024-06-03 03:56:56 [INFO]: Epoch 014 - training loss: 0.2381, validation loss: 0.1981
2024-06-03 03:57:22 [INFO]: Epoch 015 - training loss: 0.2277, validation loss: 0.1968
2024-06-03 03:57:48 [INFO]: Epoch 016 - training loss: 0.2238, validation loss: 0.1877
2024-06-03 03:58:14 [INFO]: Epoch 017 - training loss: 0.2213, validation loss: 0.1871
2024-06-03 03:58:40 [INFO]: Epoch 018 - training loss: 0.1974, validation loss: 0.1847
2024-06-03 03:59:07 [INFO]: Epoch 019 - training loss: 0.2046, validation loss: 0.1909
2024-06-03 03:59:33 [INFO]: Epoch 020 - training loss: 0.2148, validation loss: 0.1848
2024-06-03 03:59:59 [INFO]: Epoch 021 - training loss: 0.2008, validation loss: 0.1725
2024-06-03 04:00:25 [INFO]: Epoch 022 - training loss: 0.1841, validation loss: 0.1754
2024-06-03 04:00:51 [INFO]: Epoch 023 - training loss: 0.2107, validation loss: 0.1634
2024-06-03 04:01:17 [INFO]: Epoch 024 - training loss: 0.1989, validation loss: 0.1794
2024-06-03 04:01:43 [INFO]: Epoch 025 - training loss: 0.1757, validation loss: 0.1602
2024-06-03 04:02:09 [INFO]: Epoch 026 - training loss: 0.1810, validation loss: 0.1650
2024-06-03 04:02:35 [INFO]: Epoch 027 - training loss: 0.1943, validation loss: 0.1530
2024-06-03 04:03:02 [INFO]: Epoch 028 - training loss: 0.1902, validation loss: 0.1677
2024-06-03 04:03:28 [INFO]: Epoch 029 - training loss: 0.1855, validation loss: 0.1548
2024-06-03 04:03:54 [INFO]: Epoch 030 - training loss: 0.1908, validation loss: 0.1491
2024-06-03 04:04:20 [INFO]: Epoch 031 - training loss: 0.1906, validation loss: 0.1510
2024-06-03 04:04:46 [INFO]: Epoch 032 - training loss: 0.2026, validation loss: 0.1472
2024-06-03 04:05:12 [INFO]: Epoch 033 - training loss: 0.1869, validation loss: 0.1425
2024-06-03 04:05:38 [INFO]: Epoch 034 - training loss: 0.1807, validation loss: 0.1506
2024-06-03 04:06:04 [INFO]: Epoch 035 - training loss: 0.1909, validation loss: 0.1451
2024-06-03 04:06:31 [INFO]: Epoch 036 - training loss: 0.1882, validation loss: 0.1446
2024-06-03 04:06:57 [INFO]: Epoch 037 - training loss: 0.1875, validation loss: 0.1476
2024-06-03 04:07:23 [INFO]: Epoch 038 - training loss: 0.1775, validation loss: 0.1473
2024-06-03 04:07:49 [INFO]: Epoch 039 - training loss: 0.1667, validation loss: 0.1468
2024-06-03 04:08:15 [INFO]: Epoch 040 - training loss: 0.1846, validation loss: 0.1445
2024-06-03 04:08:41 [INFO]: Epoch 041 - training loss: 0.1822, validation loss: 0.1365
2024-06-03 04:09:07 [INFO]: Epoch 042 - training loss: 0.1506, validation loss: 0.1484
2024-06-03 04:09:33 [INFO]: Epoch 043 - training loss: 0.1843, validation loss: 0.1363
2024-06-03 04:09:59 [INFO]: Epoch 044 - training loss: 0.1696, validation loss: 0.1380
2024-06-03 04:10:26 [INFO]: Epoch 045 - training loss: 0.1752, validation loss: 0.1355
2024-06-03 04:10:52 [INFO]: Epoch 046 - training loss: 0.1694, validation loss: 0.1336
2024-06-03 04:11:18 [INFO]: Epoch 047 - training loss: 0.1833, validation loss: 0.1361
2024-06-03 04:11:44 [INFO]: Epoch 048 - training loss: 0.1602, validation loss: 0.1375
2024-06-03 04:12:10 [INFO]: Epoch 049 - training loss: 0.1813, validation loss: 0.1405
2024-06-03 04:12:36 [INFO]: Epoch 050 - training loss: 0.1707, validation loss: 0.1439
2024-06-03 04:13:02 [INFO]: Epoch 051 - training loss: 0.1461, validation loss: 0.1317
2024-06-03 04:13:28 [INFO]: Epoch 052 - training loss: 0.1828, validation loss: 0.1376
2024-06-03 04:13:54 [INFO]: Epoch 053 - training loss: 0.1562, validation loss: 0.1318
2024-06-03 04:14:21 [INFO]: Epoch 054 - training loss: 0.1612, validation loss: 0.1325
2024-06-03 04:14:47 [INFO]: Epoch 055 - training loss: 0.1759, validation loss: 0.1437
2024-06-03 04:15:13 [INFO]: Epoch 056 - training loss: 0.1457, validation loss: 0.1364
2024-06-03 04:15:39 [INFO]: Epoch 057 - training loss: 0.1665, validation loss: 0.1291
2024-06-03 04:16:05 [INFO]: Epoch 058 - training loss: 0.1567, validation loss: 0.1308
2024-06-03 04:16:31 [INFO]: Epoch 059 - training loss: 0.1826, validation loss: 0.1306
2024-06-03 04:16:57 [INFO]: Epoch 060 - training loss: 0.1612, validation loss: 0.1380
2024-06-03 04:17:24 [INFO]: Epoch 061 - training loss: 0.1793, validation loss: 0.1319
2024-06-03 04:17:50 [INFO]: Epoch 062 - training loss: 0.1864, validation loss: 0.1261
2024-06-03 04:18:16 [INFO]: Epoch 063 - training loss: 0.1661, validation loss: 0.1293
2024-06-03 04:18:42 [INFO]: Epoch 064 - training loss: 0.1658, validation loss: 0.1323
2024-06-03 04:19:08 [INFO]: Epoch 065 - training loss: 0.1682, validation loss: 0.1272
2024-06-03 04:19:34 [INFO]: Epoch 066 - training loss: 0.1715, validation loss: 0.1275
2024-06-03 04:20:00 [INFO]: Epoch 067 - training loss: 0.1695, validation loss: 0.1265
2024-06-03 04:20:26 [INFO]: Epoch 068 - training loss: 0.1661, validation loss: 0.1274
2024-06-03 04:20:53 [INFO]: Epoch 069 - training loss: 0.1490, validation loss: 0.1302
2024-06-03 04:21:19 [INFO]: Epoch 070 - training loss: 0.1607, validation loss: 0.1284
2024-06-03 04:21:45 [INFO]: Epoch 071 - training loss: 0.1813, validation loss: 0.1307
2024-06-03 04:22:11 [INFO]: Epoch 072 - training loss: 0.1583, validation loss: 0.1254
2024-06-03 04:22:37 [INFO]: Epoch 073 - training loss: 0.1647, validation loss: 0.1293
2024-06-03 04:23:03 [INFO]: Epoch 074 - training loss: 0.1671, validation loss: 0.1290
2024-06-03 04:23:29 [INFO]: Epoch 075 - training loss: 0.1714, validation loss: 0.1295
2024-06-03 04:23:55 [INFO]: Epoch 076 - training loss: 0.1620, validation loss: 0.1275
2024-06-03 04:24:22 [INFO]: Epoch 077 - training loss: 0.1631, validation loss: 0.1250
2024-06-03 04:24:48 [INFO]: Epoch 078 - training loss: 0.1493, validation loss: 0.1255
2024-06-03 04:25:14 [INFO]: Epoch 079 - training loss: 0.1757, validation loss: 0.1269
2024-06-03 04:25:40 [INFO]: Epoch 080 - training loss: 0.1640, validation loss: 0.1272
2024-06-03 04:26:06 [INFO]: Epoch 081 - training loss: 0.1493, validation loss: 0.1265
2024-06-03 04:26:32 [INFO]: Epoch 082 - training loss: 0.1512, validation loss: 0.1236
2024-06-03 04:26:58 [INFO]: Epoch 083 - training loss: 0.1479, validation loss: 0.1259
2024-06-03 04:27:25 [INFO]: Epoch 084 - training loss: 0.1751, validation loss: 0.1232
2024-06-03 04:27:51 [INFO]: Epoch 085 - training loss: 0.1546, validation loss: 0.1233
2024-06-03 04:28:17 [INFO]: Epoch 086 - training loss: 0.1577, validation loss: 0.1299
2024-06-03 04:28:43 [INFO]: Epoch 087 - training loss: 0.1752, validation loss: 0.1238
2024-06-03 04:29:09 [INFO]: Epoch 088 - training loss: 0.1501, validation loss: 0.1269
2024-06-03 04:29:35 [INFO]: Epoch 089 - training loss: 0.1691, validation loss: 0.1226
2024-06-03 04:30:01 [INFO]: Epoch 090 - training loss: 0.1581, validation loss: 0.1249
2024-06-03 04:30:27 [INFO]: Epoch 091 - training loss: 0.1457, validation loss: 0.1202
2024-06-03 04:30:54 [INFO]: Epoch 092 - training loss: 0.1647, validation loss: 0.1255
2024-06-03 04:31:20 [INFO]: Epoch 093 - training loss: 0.1428, validation loss: 0.1227
2024-06-03 04:31:46 [INFO]: Epoch 094 - training loss: 0.1694, validation loss: 0.1240
2024-06-03 04:32:12 [INFO]: Epoch 095 - training loss: 0.1467, validation loss: 0.1233
2024-06-03 04:32:38 [INFO]: Epoch 096 - training loss: 0.1538, validation loss: 0.1245
2024-06-03 04:33:04 [INFO]: Epoch 097 - training loss: 0.1551, validation loss: 0.1254
2024-06-03 04:33:30 [INFO]: Epoch 098 - training loss: 0.1628, validation loss: 0.1236
2024-06-03 04:33:57 [INFO]: Epoch 099 - training loss: 0.1582, validation loss: 0.1225
2024-06-03 04:34:23 [INFO]: Epoch 100 - training loss: 0.1727, validation loss: 0.1280
2024-06-03 04:34:23 [INFO]: Finished training. The best model is from epoch#91.
2024-06-03 04:34:23 [INFO]: Saved the model to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T035050/CSDI.pypots
2024-06-03 04:51:44 [INFO]: Successfully saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_3/imputation.pkl
2024-06-03 04:51:44 [INFO]: Round3 - CSDI on BeijingAir: MAE=0.1644, MSE=0.3338, MRE=0.2238
2024-06-03 04:51:44 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:51:44 [INFO]: Using the given device: cuda:0
2024-06-03 04:51:44 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T045144
2024-06-03 04:51:44 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T045144/tensorboard
2024-06-03 04:51:45 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 04:52:11 [INFO]: Epoch 001 - training loss: 0.5276, validation loss: 0.4193
2024-06-03 04:52:37 [INFO]: Epoch 002 - training loss: 0.3526, validation loss: 0.3624
2024-06-03 04:53:03 [INFO]: Epoch 003 - training loss: 0.3323, validation loss: 0.3353
2024-06-03 04:53:29 [INFO]: Epoch 004 - training loss: 0.3056, validation loss: 0.3106
2024-06-03 04:53:55 [INFO]: Epoch 005 - training loss: 0.2859, validation loss: 0.2899
2024-06-03 04:54:21 [INFO]: Epoch 006 - training loss: 0.2711, validation loss: 0.2758
2024-06-03 04:54:47 [INFO]: Epoch 007 - training loss: 0.2547, validation loss: 0.2459
2024-06-03 04:55:13 [INFO]: Epoch 008 - training loss: 0.2726, validation loss: 0.2191
2024-06-03 04:55:40 [INFO]: Epoch 009 - training loss: 0.2361, validation loss: 0.2217
2024-06-03 04:56:06 [INFO]: Epoch 010 - training loss: 0.2370, validation loss: 0.2058
2024-06-03 04:56:32 [INFO]: Epoch 011 - training loss: 0.2307, validation loss: 0.1917
2024-06-03 04:56:58 [INFO]: Epoch 012 - training loss: 0.2199, validation loss: 0.1850
2024-06-03 04:57:24 [INFO]: Epoch 013 - training loss: 0.2169, validation loss: 0.1753
2024-06-03 04:57:50 [INFO]: Epoch 014 - training loss: 0.2159, validation loss: 0.1844
2024-06-03 04:58:16 [INFO]: Epoch 015 - training loss: 0.2161, validation loss: 0.1803
2024-06-03 04:58:42 [INFO]: Epoch 016 - training loss: 0.2171, validation loss: 0.1684
2024-06-03 04:59:08 [INFO]: Epoch 017 - training loss: 0.2249, validation loss: 0.1718
2024-06-03 04:59:35 [INFO]: Epoch 018 - training loss: 0.2110, validation loss: 0.1671
2024-06-03 05:00:01 [INFO]: Epoch 019 - training loss: 0.2109, validation loss: 0.1602
2024-06-03 05:00:27 [INFO]: Epoch 020 - training loss: 0.2065, validation loss: 0.1634
2024-06-03 05:00:53 [INFO]: Epoch 021 - training loss: 0.2068, validation loss: 0.1610
2024-06-03 05:01:19 [INFO]: Epoch 022 - training loss: 0.1989, validation loss: 0.1599
2024-06-03 05:01:45 [INFO]: Epoch 023 - training loss: 0.1995, validation loss: 0.1555
2024-06-03 05:02:11 [INFO]: Epoch 024 - training loss: 0.2130, validation loss: 0.1569
2024-06-03 05:02:37 [INFO]: Epoch 025 - training loss: 0.1990, validation loss: 0.1518
2024-06-03 05:03:04 [INFO]: Epoch 026 - training loss: 0.2059, validation loss: 0.1625
2024-06-03 05:03:30 [INFO]: Epoch 027 - training loss: 0.2028, validation loss: 0.1545
2024-06-03 05:03:56 [INFO]: Epoch 028 - training loss: 0.1958, validation loss: 0.1493
2024-06-03 05:04:22 [INFO]: Epoch 029 - training loss: 0.1875, validation loss: 0.1524
2024-06-03 05:04:48 [INFO]: Epoch 030 - training loss: 0.2100, validation loss: 0.1484
2024-06-03 05:05:14 [INFO]: Epoch 031 - training loss: 0.1997, validation loss: 0.1475
2024-06-03 05:05:40 [INFO]: Epoch 032 - training loss: 0.1834, validation loss: 0.1499
2024-06-03 05:06:06 [INFO]: Epoch 033 - training loss: 0.1689, validation loss: 0.1473
2024-06-03 05:06:32 [INFO]: Epoch 034 - training loss: 0.1795, validation loss: 0.1467
2024-06-03 05:06:59 [INFO]: Epoch 035 - training loss: 0.1856, validation loss: 0.1443
2024-06-03 05:07:25 [INFO]: Epoch 036 - training loss: 0.1828, validation loss: 0.1430
2024-06-03 05:07:51 [INFO]: Epoch 037 - training loss: 0.1807, validation loss: 0.1443
2024-06-03 05:08:17 [INFO]: Epoch 038 - training loss: 0.1804, validation loss: 0.1391
2024-06-03 05:08:43 [INFO]: Epoch 039 - training loss: 0.1836, validation loss: 0.1418
2024-06-03 05:09:09 [INFO]: Epoch 040 - training loss: 0.1865, validation loss: 0.1391
2024-06-03 05:09:35 [INFO]: Epoch 041 - training loss: 0.1755, validation loss: 0.1440
2024-06-03 05:10:01 [INFO]: Epoch 042 - training loss: 0.1905, validation loss: 0.1447
2024-06-03 05:10:27 [INFO]: Epoch 043 - training loss: 0.1955, validation loss: 0.1446
2024-06-03 05:10:54 [INFO]: Epoch 044 - training loss: 0.1596, validation loss: 0.1351
2024-06-03 05:11:20 [INFO]: Epoch 045 - training loss: 0.1802, validation loss: 0.1340
2024-06-03 05:11:46 [INFO]: Epoch 046 - training loss: 0.1590, validation loss: 0.1393
2024-06-03 05:12:12 [INFO]: Epoch 047 - training loss: 0.1584, validation loss: 0.1343
2024-06-03 05:12:38 [INFO]: Epoch 048 - training loss: 0.1659, validation loss: 0.1382
2024-06-03 05:13:04 [INFO]: Epoch 049 - training loss: 0.1756, validation loss: 0.1374
2024-06-03 05:13:30 [INFO]: Epoch 050 - training loss: 0.1828, validation loss: 0.1354
2024-06-03 05:13:56 [INFO]: Epoch 051 - training loss: 0.1623, validation loss: 0.1345
2024-06-03 05:14:22 [INFO]: Epoch 052 - training loss: 0.1814, validation loss: 0.1328
2024-06-03 05:14:49 [INFO]: Epoch 053 - training loss: 0.1627, validation loss: 0.1343
2024-06-03 05:15:15 [INFO]: Epoch 054 - training loss: 0.1804, validation loss: 0.1330
2024-06-03 05:15:41 [INFO]: Epoch 055 - training loss: 0.1834, validation loss: 0.1292
2024-06-03 05:16:07 [INFO]: Epoch 056 - training loss: 0.1670, validation loss: 0.1314
2024-06-03 05:16:33 [INFO]: Epoch 057 - training loss: 0.1581, validation loss: 0.1345
2024-06-03 05:16:59 [INFO]: Epoch 058 - training loss: 0.1643, validation loss: 0.1317
2024-06-03 05:17:25 [INFO]: Epoch 059 - training loss: 0.1741, validation loss: 0.1322
2024-06-03 05:17:51 [INFO]: Epoch 060 - training loss: 0.1597, validation loss: 0.1259
2024-06-03 05:18:17 [INFO]: Epoch 061 - training loss: 0.1673, validation loss: 0.1308
2024-06-03 05:18:44 [INFO]: Epoch 062 - training loss: 0.1771, validation loss: 0.1300
2024-06-03 05:19:10 [INFO]: Epoch 063 - training loss: 0.1512, validation loss: 0.1260
2024-06-03 05:19:36 [INFO]: Epoch 064 - training loss: 0.1520, validation loss: 0.1251
2024-06-03 05:20:02 [INFO]: Epoch 065 - training loss: 0.1484, validation loss: 0.1296
2024-06-03 05:20:28 [INFO]: Epoch 066 - training loss: 0.1476, validation loss: 0.1290
2024-06-03 05:20:54 [INFO]: Epoch 067 - training loss: 0.1627, validation loss: 0.1324
2024-06-03 05:21:20 [INFO]: Epoch 068 - training loss: 0.1718, validation loss: 0.1248
2024-06-03 05:21:46 [INFO]: Epoch 069 - training loss: 0.1641, validation loss: 0.1244
2024-06-03 05:22:13 [INFO]: Epoch 070 - training loss: 0.1612, validation loss: 0.1257
2024-06-03 05:22:39 [INFO]: Epoch 071 - training loss: 0.1632, validation loss: 0.1246
2024-06-03 05:23:05 [INFO]: Epoch 072 - training loss: 0.1562, validation loss: 0.1229
2024-06-03 05:23:31 [INFO]: Epoch 073 - training loss: 0.1538, validation loss: 0.1235
2024-06-03 05:23:57 [INFO]: Epoch 074 - training loss: 0.1721, validation loss: 0.1244
2024-06-03 05:24:23 [INFO]: Epoch 075 - training loss: 0.1787, validation loss: 0.1274
2024-06-03 05:24:49 [INFO]: Epoch 076 - training loss: 0.1721, validation loss: 0.1221
2024-06-03 05:25:15 [INFO]: Epoch 077 - training loss: 0.1628, validation loss: 0.1252
2024-06-03 05:25:41 [INFO]: Epoch 078 - training loss: 0.1696, validation loss: 0.1254
2024-06-03 05:26:08 [INFO]: Epoch 079 - training loss: 0.1535, validation loss: 0.1253
2024-06-03 05:26:34 [INFO]: Epoch 080 - training loss: 0.1591, validation loss: 0.1217
2024-06-03 05:27:00 [INFO]: Epoch 081 - training loss: 0.1569, validation loss: 0.1233
2024-06-03 05:27:26 [INFO]: Epoch 082 - training loss: 0.1434, validation loss: 0.1204
2024-06-03 05:27:52 [INFO]: Epoch 083 - training loss: 0.1738, validation loss: 0.1219
2024-06-03 05:28:18 [INFO]: Epoch 084 - training loss: 0.1538, validation loss: 0.1201
2024-06-03 05:28:44 [INFO]: Epoch 085 - training loss: 0.1578, validation loss: 0.1229
2024-06-03 05:29:10 [INFO]: Epoch 086 - training loss: 0.1541, validation loss: 0.1243
2024-06-03 05:29:36 [INFO]: Epoch 087 - training loss: 0.1686, validation loss: 0.1246
2024-06-03 05:30:02 [INFO]: Epoch 088 - training loss: 0.1394, validation loss: 0.1215
2024-06-03 05:30:29 [INFO]: Epoch 089 - training loss: 0.1527, validation loss: 0.1208
2024-06-03 05:30:55 [INFO]: Epoch 090 - training loss: 0.1565, validation loss: 0.1204
2024-06-03 05:31:21 [INFO]: Epoch 091 - training loss: 0.1557, validation loss: 0.1200
2024-06-03 05:31:47 [INFO]: Epoch 092 - training loss: 0.1679, validation loss: 0.1201
2024-06-03 05:32:13 [INFO]: Epoch 093 - training loss: 0.1459, validation loss: 0.1191
2024-06-03 05:32:39 [INFO]: Epoch 094 - training loss: 0.1445, validation loss: 0.1202
2024-06-03 05:33:05 [INFO]: Epoch 095 - training loss: 0.1638, validation loss: 0.1194
2024-06-03 05:33:31 [INFO]: Epoch 096 - training loss: 0.1419, validation loss: 0.1208
2024-06-03 05:33:57 [INFO]: Epoch 097 - training loss: 0.1488, validation loss: 0.1196
2024-06-03 05:34:24 [INFO]: Epoch 098 - training loss: 0.1609, validation loss: 0.1195
2024-06-03 05:34:50 [INFO]: Epoch 099 - training loss: 0.1519, validation loss: 0.1215
2024-06-03 05:35:16 [INFO]: Epoch 100 - training loss: 0.1677, validation loss: 0.1190
2024-06-03 05:35:16 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 05:35:16 [INFO]: Saved the model to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T045144/CSDI.pypots
2024-06-03 05:52:36 [INFO]: Successfully saved to results_point_rate05/BeijingAir/CSDI_BeijingAir/round_4/imputation.pkl
2024-06-03 05:52:36 [INFO]: Round4 - CSDI on BeijingAir: MAE=0.1506, MSE=0.3042, MRE=0.2050
2024-06-03 05:52:36 [INFO]: Done! Final results:
Averaged CSDI (244,833 params) on BeijingAir: MAE=0.1445 ± 0.00714076585044619, MSE=0.4724 ± 0.15547735146988825, MRE=0.1916 ± 0.009464603244304193, average inference time=390.62