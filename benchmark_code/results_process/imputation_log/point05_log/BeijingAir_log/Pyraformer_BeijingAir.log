2024-06-03 11:16:53 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 11:16:53 [INFO]: Using the given device: cuda:0
2024-06-03 11:16:54 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T111654
2024-06-03 11:16:54 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T111654/tensorboard
2024-06-03 11:16:55 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 11:17:09 [INFO]: Epoch 001 - training loss: 1.0555, validation loss: 0.4445
2024-06-03 11:17:14 [INFO]: Epoch 002 - training loss: 0.7446, validation loss: 0.3645
2024-06-03 11:17:18 [INFO]: Epoch 003 - training loss: 0.6317, validation loss: 0.3484
2024-06-03 11:17:22 [INFO]: Epoch 004 - training loss: 0.5973, validation loss: 0.3423
2024-06-03 11:17:26 [INFO]: Epoch 005 - training loss: 0.5609, validation loss: 0.3148
2024-06-03 11:17:31 [INFO]: Epoch 006 - training loss: 0.5339, validation loss: 0.3162
2024-06-03 11:17:36 [INFO]: Epoch 007 - training loss: 0.5011, validation loss: 0.3071
2024-06-03 11:17:40 [INFO]: Epoch 008 - training loss: 0.4906, validation loss: 0.2988
2024-06-03 11:17:44 [INFO]: Epoch 009 - training loss: 0.4907, validation loss: 0.3052
2024-06-03 11:17:49 [INFO]: Epoch 010 - training loss: 0.4846, validation loss: 0.3159
2024-06-03 11:17:53 [INFO]: Epoch 011 - training loss: 0.4745, validation loss: 0.2881
2024-06-03 11:17:57 [INFO]: Epoch 012 - training loss: 0.4587, validation loss: 0.2868
2024-06-03 11:18:01 [INFO]: Epoch 013 - training loss: 0.4425, validation loss: 0.2785
2024-06-03 11:18:06 [INFO]: Epoch 014 - training loss: 0.4379, validation loss: 0.2760
2024-06-03 11:18:10 [INFO]: Epoch 015 - training loss: 0.4331, validation loss: 0.2839
2024-06-03 11:18:14 [INFO]: Epoch 016 - training loss: 0.4255, validation loss: 0.2714
2024-06-03 11:18:18 [INFO]: Epoch 017 - training loss: 0.4214, validation loss: 0.2721
2024-06-03 11:18:22 [INFO]: Epoch 018 - training loss: 0.4251, validation loss: 0.2663
2024-06-03 11:18:26 [INFO]: Epoch 019 - training loss: 0.4100, validation loss: 0.2688
2024-06-03 11:18:30 [INFO]: Epoch 020 - training loss: 0.4107, validation loss: 0.2607
2024-06-03 11:18:35 [INFO]: Epoch 021 - training loss: 0.4094, validation loss: 0.2673
2024-06-03 11:18:39 [INFO]: Epoch 022 - training loss: 0.4071, validation loss: 0.2665
2024-06-03 11:18:43 [INFO]: Epoch 023 - training loss: 0.4021, validation loss: 0.2675
2024-06-03 11:18:47 [INFO]: Epoch 024 - training loss: 0.3957, validation loss: 0.2614
2024-06-03 11:18:52 [INFO]: Epoch 025 - training loss: 0.3919, validation loss: 0.2623
2024-06-03 11:18:56 [INFO]: Epoch 026 - training loss: 0.3939, validation loss: 0.2557
2024-06-03 11:19:00 [INFO]: Epoch 027 - training loss: 0.3926, validation loss: 0.2624
2024-06-03 11:19:04 [INFO]: Epoch 028 - training loss: 0.3984, validation loss: 0.2579
2024-06-03 11:19:08 [INFO]: Epoch 029 - training loss: 0.4105, validation loss: 0.2582
2024-06-03 11:19:12 [INFO]: Epoch 030 - training loss: 0.3967, validation loss: 0.2529
2024-06-03 11:19:16 [INFO]: Epoch 031 - training loss: 0.3912, validation loss: 0.2654
2024-06-03 11:19:20 [INFO]: Epoch 032 - training loss: 0.3845, validation loss: 0.2444
2024-06-03 11:19:25 [INFO]: Epoch 033 - training loss: 0.3785, validation loss: 0.2469
2024-06-03 11:19:29 [INFO]: Epoch 034 - training loss: 0.3777, validation loss: 0.2508
2024-06-03 11:19:33 [INFO]: Epoch 035 - training loss: 0.3722, validation loss: 0.2430
2024-06-03 11:19:37 [INFO]: Epoch 036 - training loss: 0.3796, validation loss: 0.2558
2024-06-03 11:19:42 [INFO]: Epoch 037 - training loss: 0.3758, validation loss: 0.2487
2024-06-03 11:19:46 [INFO]: Epoch 038 - training loss: 0.3731, validation loss: 0.2441
2024-06-03 11:19:50 [INFO]: Epoch 039 - training loss: 0.3681, validation loss: 0.2448
2024-06-03 11:19:54 [INFO]: Epoch 040 - training loss: 0.3664, validation loss: 0.2495
2024-06-03 11:19:59 [INFO]: Epoch 041 - training loss: 0.3764, validation loss: 0.2435
2024-06-03 11:20:03 [INFO]: Epoch 042 - training loss: 0.3687, validation loss: 0.2462
2024-06-03 11:20:08 [INFO]: Epoch 043 - training loss: 0.3633, validation loss: 0.2445
2024-06-03 11:20:12 [INFO]: Epoch 044 - training loss: 0.3615, validation loss: 0.2383
2024-06-03 11:20:17 [INFO]: Epoch 045 - training loss: 0.3584, validation loss: 0.2435
2024-06-03 11:20:21 [INFO]: Epoch 046 - training loss: 0.3621, validation loss: 0.2434
2024-06-03 11:20:25 [INFO]: Epoch 047 - training loss: 0.3554, validation loss: 0.2389
2024-06-03 11:20:29 [INFO]: Epoch 048 - training loss: 0.3591, validation loss: 0.2446
2024-06-03 11:20:33 [INFO]: Epoch 049 - training loss: 0.3584, validation loss: 0.2412
2024-06-03 11:20:38 [INFO]: Epoch 050 - training loss: 0.3549, validation loss: 0.2370
2024-06-03 11:20:42 [INFO]: Epoch 051 - training loss: 0.3591, validation loss: 0.2398
2024-06-03 11:20:46 [INFO]: Epoch 052 - training loss: 0.3620, validation loss: 0.2404
2024-06-03 11:20:51 [INFO]: Epoch 053 - training loss: 0.3537, validation loss: 0.2360
2024-06-03 11:20:55 [INFO]: Epoch 054 - training loss: 0.3512, validation loss: 0.2422
2024-06-03 11:20:59 [INFO]: Epoch 055 - training loss: 0.3482, validation loss: 0.2406
2024-06-03 11:21:04 [INFO]: Epoch 056 - training loss: 0.3502, validation loss: 0.2342
2024-06-03 11:21:08 [INFO]: Epoch 057 - training loss: 0.3478, validation loss: 0.2431
2024-06-03 11:21:13 [INFO]: Epoch 058 - training loss: 0.3472, validation loss: 0.2377
2024-06-03 11:21:17 [INFO]: Epoch 059 - training loss: 0.3454, validation loss: 0.2394
2024-06-03 11:21:21 [INFO]: Epoch 060 - training loss: 0.3464, validation loss: 0.2422
2024-06-03 11:21:26 [INFO]: Epoch 061 - training loss: 0.3579, validation loss: 0.2355
2024-06-03 11:21:30 [INFO]: Epoch 062 - training loss: 0.3485, validation loss: 0.2429
2024-06-03 11:21:34 [INFO]: Epoch 063 - training loss: 0.3468, validation loss: 0.2355
2024-06-03 11:21:38 [INFO]: Epoch 064 - training loss: 0.3415, validation loss: 0.2377
2024-06-03 11:21:42 [INFO]: Epoch 065 - training loss: 0.3436, validation loss: 0.2370
2024-06-03 11:21:47 [INFO]: Epoch 066 - training loss: 0.3398, validation loss: 0.2357
2024-06-03 11:21:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:21:47 [INFO]: Finished training. The best model is from epoch#56.
2024-06-03 11:21:47 [INFO]: Saved the model to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T111654/Pyraformer.pypots
2024-06-03 11:21:49 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/imputation.pkl
2024-06-03 11:21:49 [INFO]: Round0 - Pyraformer on BeijingAir: MAE=0.2120, MSE=0.2473, MRE=0.2886
2024-06-03 11:21:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 11:21:49 [INFO]: Using the given device: cuda:0
2024-06-03 11:21:49 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T112149
2024-06-03 11:21:49 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T112149/tensorboard
2024-06-03 11:21:49 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 11:21:53 [INFO]: Epoch 001 - training loss: 1.0509, validation loss: 0.4391
2024-06-03 11:21:58 [INFO]: Epoch 002 - training loss: 0.7043, validation loss: 0.3785
2024-06-03 11:22:02 [INFO]: Epoch 003 - training loss: 0.6196, validation loss: 0.3512
2024-06-03 11:22:06 [INFO]: Epoch 004 - training loss: 0.5709, validation loss: 0.3177
2024-06-03 11:22:10 [INFO]: Epoch 005 - training loss: 0.5577, validation loss: 0.3177
2024-06-03 11:22:15 [INFO]: Epoch 006 - training loss: 0.5310, validation loss: 0.2984
2024-06-03 11:22:19 [INFO]: Epoch 007 - training loss: 0.5093, validation loss: 0.3034
2024-06-03 11:22:23 [INFO]: Epoch 008 - training loss: 0.5076, validation loss: 0.2900
2024-06-03 11:22:28 [INFO]: Epoch 009 - training loss: 0.4891, validation loss: 0.2887
2024-06-03 11:22:32 [INFO]: Epoch 010 - training loss: 0.4683, validation loss: 0.2808
2024-06-03 11:22:36 [INFO]: Epoch 011 - training loss: 0.4660, validation loss: 0.2796
2024-06-03 11:22:40 [INFO]: Epoch 012 - training loss: 0.4517, validation loss: 0.2725
2024-06-03 11:22:45 [INFO]: Epoch 013 - training loss: 0.4607, validation loss: 0.2851
2024-06-03 11:22:49 [INFO]: Epoch 014 - training loss: 0.4590, validation loss: 0.2701
2024-06-03 11:22:54 [INFO]: Epoch 015 - training loss: 0.4473, validation loss: 0.2788
2024-06-03 11:22:58 [INFO]: Epoch 016 - training loss: 0.4309, validation loss: 0.2717
2024-06-03 11:23:02 [INFO]: Epoch 017 - training loss: 0.4263, validation loss: 0.2696
2024-06-03 11:23:07 [INFO]: Epoch 018 - training loss: 0.4310, validation loss: 0.2648
2024-06-03 11:23:11 [INFO]: Epoch 019 - training loss: 0.4169, validation loss: 0.2662
2024-06-03 11:23:16 [INFO]: Epoch 020 - training loss: 0.4129, validation loss: 0.2617
2024-06-03 11:23:20 [INFO]: Epoch 021 - training loss: 0.4079, validation loss: 0.2570
2024-06-03 11:23:24 [INFO]: Epoch 022 - training loss: 0.4077, validation loss: 0.2607
2024-06-03 11:23:29 [INFO]: Epoch 023 - training loss: 0.3975, validation loss: 0.2569
2024-06-03 11:23:33 [INFO]: Epoch 024 - training loss: 0.4137, validation loss: 0.2643
2024-06-03 11:23:37 [INFO]: Epoch 025 - training loss: 0.4055, validation loss: 0.2585
2024-06-03 11:23:42 [INFO]: Epoch 026 - training loss: 0.4132, validation loss: 0.2596
2024-06-03 11:23:46 [INFO]: Epoch 027 - training loss: 0.3977, validation loss: 0.2576
2024-06-03 11:23:50 [INFO]: Epoch 028 - training loss: 0.4044, validation loss: 0.2513
2024-06-03 11:23:54 [INFO]: Epoch 029 - training loss: 0.3968, validation loss: 0.2528
2024-06-03 11:23:59 [INFO]: Epoch 030 - training loss: 0.3955, validation loss: 0.2610
2024-06-03 11:24:03 [INFO]: Epoch 031 - training loss: 0.3895, validation loss: 0.2427
2024-06-03 11:24:07 [INFO]: Epoch 032 - training loss: 0.3884, validation loss: 0.2488
2024-06-03 11:24:12 [INFO]: Epoch 033 - training loss: 0.3811, validation loss: 0.2480
2024-06-03 11:24:16 [INFO]: Epoch 034 - training loss: 0.3790, validation loss: 0.2495
2024-06-03 11:24:20 [INFO]: Epoch 035 - training loss: 0.3758, validation loss: 0.2396
2024-06-03 11:24:24 [INFO]: Epoch 036 - training loss: 0.3821, validation loss: 0.2470
2024-06-03 11:24:28 [INFO]: Epoch 037 - training loss: 0.3710, validation loss: 0.2395
2024-06-03 11:24:32 [INFO]: Epoch 038 - training loss: 0.3696, validation loss: 0.2448
2024-06-03 11:24:37 [INFO]: Epoch 039 - training loss: 0.3648, validation loss: 0.2452
2024-06-03 11:24:41 [INFO]: Epoch 040 - training loss: 0.3714, validation loss: 0.2492
2024-06-03 11:24:45 [INFO]: Epoch 041 - training loss: 0.3702, validation loss: 0.2434
2024-06-03 11:24:49 [INFO]: Epoch 042 - training loss: 0.3658, validation loss: 0.2392
2024-06-03 11:24:54 [INFO]: Epoch 043 - training loss: 0.3690, validation loss: 0.2441
2024-06-03 11:24:58 [INFO]: Epoch 044 - training loss: 0.3645, validation loss: 0.2407
2024-06-03 11:25:02 [INFO]: Epoch 045 - training loss: 0.3618, validation loss: 0.2518
2024-06-03 11:25:07 [INFO]: Epoch 046 - training loss: 0.3709, validation loss: 0.2499
2024-06-03 11:25:11 [INFO]: Epoch 047 - training loss: 0.3626, validation loss: 0.2461
2024-06-03 11:25:15 [INFO]: Epoch 048 - training loss: 0.3583, validation loss: 0.2370
2024-06-03 11:25:19 [INFO]: Epoch 049 - training loss: 0.3653, validation loss: 0.2409
2024-06-03 11:25:24 [INFO]: Epoch 050 - training loss: 0.3586, validation loss: 0.2403
2024-06-03 11:25:28 [INFO]: Epoch 051 - training loss: 0.3519, validation loss: 0.2395
2024-06-03 11:25:32 [INFO]: Epoch 052 - training loss: 0.3535, validation loss: 0.2416
2024-06-03 11:25:37 [INFO]: Epoch 053 - training loss: 0.3529, validation loss: 0.2380
2024-06-03 11:25:41 [INFO]: Epoch 054 - training loss: 0.3513, validation loss: 0.2364
2024-06-03 11:25:45 [INFO]: Epoch 055 - training loss: 0.3472, validation loss: 0.2354
2024-06-03 11:25:49 [INFO]: Epoch 056 - training loss: 0.3434, validation loss: 0.2382
2024-06-03 11:25:54 [INFO]: Epoch 057 - training loss: 0.3522, validation loss: 0.2407
2024-06-03 11:25:58 [INFO]: Epoch 058 - training loss: 0.3487, validation loss: 0.2421
2024-06-03 11:26:02 [INFO]: Epoch 059 - training loss: 0.3498, validation loss: 0.2352
2024-06-03 11:26:05 [INFO]: Epoch 060 - training loss: 0.3460, validation loss: 0.2400
2024-06-03 11:26:08 [INFO]: Epoch 061 - training loss: 0.3470, validation loss: 0.2413
2024-06-03 11:26:11 [INFO]: Epoch 062 - training loss: 0.3467, validation loss: 0.2373
2024-06-03 11:26:14 [INFO]: Epoch 063 - training loss: 0.3445, validation loss: 0.2425
2024-06-03 11:26:17 [INFO]: Epoch 064 - training loss: 0.3469, validation loss: 0.2417
2024-06-03 11:26:22 [INFO]: Epoch 065 - training loss: 0.3409, validation loss: 0.2415
2024-06-03 11:26:26 [INFO]: Epoch 066 - training loss: 0.3402, validation loss: 0.2396
2024-06-03 11:26:30 [INFO]: Epoch 067 - training loss: 0.3413, validation loss: 0.2355
2024-06-03 11:26:35 [INFO]: Epoch 068 - training loss: 0.3404, validation loss: 0.2321
2024-06-03 11:26:39 [INFO]: Epoch 069 - training loss: 0.3375, validation loss: 0.2339
2024-06-03 11:26:43 [INFO]: Epoch 070 - training loss: 0.3377, validation loss: 0.2449
2024-06-03 11:26:48 [INFO]: Epoch 071 - training loss: 0.3395, validation loss: 0.2330
2024-06-03 11:26:52 [INFO]: Epoch 072 - training loss: 0.3403, validation loss: 0.2348
2024-06-03 11:26:56 [INFO]: Epoch 073 - training loss: 0.3373, validation loss: 0.2337
2024-06-03 11:27:00 [INFO]: Epoch 074 - training loss: 0.3359, validation loss: 0.2358
2024-06-03 11:27:04 [INFO]: Epoch 075 - training loss: 0.3404, validation loss: 0.2344
2024-06-03 11:27:09 [INFO]: Epoch 076 - training loss: 0.3387, validation loss: 0.2347
2024-06-03 11:27:13 [INFO]: Epoch 077 - training loss: 0.3373, validation loss: 0.2318
2024-06-03 11:27:18 [INFO]: Epoch 078 - training loss: 0.3340, validation loss: 0.2359
2024-06-03 11:27:22 [INFO]: Epoch 079 - training loss: 0.3301, validation loss: 0.2324
2024-06-03 11:27:26 [INFO]: Epoch 080 - training loss: 0.3317, validation loss: 0.2343
2024-06-03 11:27:30 [INFO]: Epoch 081 - training loss: 0.3338, validation loss: 0.2349
2024-06-03 11:27:35 [INFO]: Epoch 082 - training loss: 0.3357, validation loss: 0.2357
2024-06-03 11:27:39 [INFO]: Epoch 083 - training loss: 0.3288, validation loss: 0.2343
2024-06-03 11:27:44 [INFO]: Epoch 084 - training loss: 0.3324, validation loss: 0.2307
2024-06-03 11:27:48 [INFO]: Epoch 085 - training loss: 0.3278, validation loss: 0.2300
2024-06-03 11:27:52 [INFO]: Epoch 086 - training loss: 0.3295, validation loss: 0.2380
2024-06-03 11:27:57 [INFO]: Epoch 087 - training loss: 0.3288, validation loss: 0.2297
2024-06-03 11:28:01 [INFO]: Epoch 088 - training loss: 0.3321, validation loss: 0.2312
2024-06-03 11:28:06 [INFO]: Epoch 089 - training loss: 0.3282, validation loss: 0.2255
2024-06-03 11:28:10 [INFO]: Epoch 090 - training loss: 0.3279, validation loss: 0.2307
2024-06-03 11:28:14 [INFO]: Epoch 091 - training loss: 0.3288, validation loss: 0.2311
2024-06-03 11:28:18 [INFO]: Epoch 092 - training loss: 0.3271, validation loss: 0.2330
2024-06-03 11:28:23 [INFO]: Epoch 093 - training loss: 0.3259, validation loss: 0.2303
2024-06-03 11:28:27 [INFO]: Epoch 094 - training loss: 0.3261, validation loss: 0.2320
2024-06-03 11:28:31 [INFO]: Epoch 095 - training loss: 0.3234, validation loss: 0.2291
2024-06-03 11:28:35 [INFO]: Epoch 096 - training loss: 0.3232, validation loss: 0.2286
2024-06-03 11:28:39 [INFO]: Epoch 097 - training loss: 0.3220, validation loss: 0.2247
2024-06-03 11:28:44 [INFO]: Epoch 098 - training loss: 0.3208, validation loss: 0.2217
2024-06-03 11:28:48 [INFO]: Epoch 099 - training loss: 0.3202, validation loss: 0.2242
2024-06-03 11:28:52 [INFO]: Epoch 100 - training loss: 0.3192, validation loss: 0.2286
2024-06-03 11:28:52 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 11:28:52 [INFO]: Saved the model to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T112149/Pyraformer.pypots
2024-06-03 11:28:54 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/imputation.pkl
2024-06-03 11:28:54 [INFO]: Round1 - Pyraformer on BeijingAir: MAE=0.2029, MSE=0.2241, MRE=0.2762
2024-06-03 11:28:54 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 11:28:54 [INFO]: Using the given device: cuda:0
2024-06-03 11:28:54 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T112854
2024-06-03 11:28:54 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T112854/tensorboard
2024-06-03 11:28:54 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 11:28:58 [INFO]: Epoch 001 - training loss: 1.0657, validation loss: 0.4482
2024-06-03 11:29:02 [INFO]: Epoch 002 - training loss: 0.7270, validation loss: 0.3748
2024-06-03 11:29:07 [INFO]: Epoch 003 - training loss: 0.6117, validation loss: 0.3551
2024-06-03 11:29:10 [INFO]: Epoch 004 - training loss: 0.5825, validation loss: 0.3213
2024-06-03 11:29:14 [INFO]: Epoch 005 - training loss: 0.5461, validation loss: 0.3174
2024-06-03 11:29:18 [INFO]: Epoch 006 - training loss: 0.5262, validation loss: 0.3029
2024-06-03 11:29:22 [INFO]: Epoch 007 - training loss: 0.5141, validation loss: 0.3028
2024-06-03 11:29:25 [INFO]: Epoch 008 - training loss: 0.4952, validation loss: 0.2963
2024-06-03 11:29:29 [INFO]: Epoch 009 - training loss: 0.4903, validation loss: 0.2865
2024-06-03 11:29:32 [INFO]: Epoch 010 - training loss: 0.4716, validation loss: 0.2854
2024-06-03 11:29:36 [INFO]: Epoch 011 - training loss: 0.4533, validation loss: 0.2905
2024-06-03 11:29:40 [INFO]: Epoch 012 - training loss: 0.4506, validation loss: 0.2821
2024-06-03 11:29:44 [INFO]: Epoch 013 - training loss: 0.4491, validation loss: 0.2736
2024-06-03 11:29:47 [INFO]: Epoch 014 - training loss: 0.4432, validation loss: 0.2724
2024-06-03 11:29:51 [INFO]: Epoch 015 - training loss: 0.4542, validation loss: 0.2823
2024-06-03 11:29:55 [INFO]: Epoch 016 - training loss: 0.4334, validation loss: 0.2698
2024-06-03 11:29:58 [INFO]: Epoch 017 - training loss: 0.4227, validation loss: 0.2692
2024-06-03 11:30:02 [INFO]: Epoch 018 - training loss: 0.4220, validation loss: 0.2692
2024-06-03 11:30:06 [INFO]: Epoch 019 - training loss: 0.4104, validation loss: 0.2682
2024-06-03 11:30:10 [INFO]: Epoch 020 - training loss: 0.4161, validation loss: 0.2602
2024-06-03 11:30:13 [INFO]: Epoch 021 - training loss: 0.4155, validation loss: 0.2600
2024-06-03 11:30:18 [INFO]: Epoch 022 - training loss: 0.4082, validation loss: 0.2527
2024-06-03 11:30:21 [INFO]: Epoch 023 - training loss: 0.4065, validation loss: 0.2540
2024-06-03 11:30:25 [INFO]: Epoch 024 - training loss: 0.4034, validation loss: 0.2556
2024-06-03 11:30:28 [INFO]: Epoch 025 - training loss: 0.3989, validation loss: 0.2548
2024-06-03 11:30:32 [INFO]: Epoch 026 - training loss: 0.3961, validation loss: 0.2524
2024-06-03 11:30:36 [INFO]: Epoch 027 - training loss: 0.3904, validation loss: 0.2494
2024-06-03 11:30:39 [INFO]: Epoch 028 - training loss: 0.3947, validation loss: 0.2559
2024-06-03 11:30:43 [INFO]: Epoch 029 - training loss: 0.3828, validation loss: 0.2512
2024-06-03 11:30:47 [INFO]: Epoch 030 - training loss: 0.3883, validation loss: 0.2454
2024-06-03 11:30:50 [INFO]: Epoch 031 - training loss: 0.3799, validation loss: 0.2502
2024-06-03 11:30:54 [INFO]: Epoch 032 - training loss: 0.3833, validation loss: 0.2433
2024-06-03 11:30:58 [INFO]: Epoch 033 - training loss: 0.3792, validation loss: 0.2449
2024-06-03 11:31:02 [INFO]: Epoch 034 - training loss: 0.3766, validation loss: 0.2418
2024-06-03 11:31:06 [INFO]: Epoch 035 - training loss: 0.3748, validation loss: 0.2471
2024-06-03 11:31:10 [INFO]: Epoch 036 - training loss: 0.3750, validation loss: 0.2472
2024-06-03 11:31:13 [INFO]: Epoch 037 - training loss: 0.3754, validation loss: 0.2450
2024-06-03 11:31:17 [INFO]: Epoch 038 - training loss: 0.3684, validation loss: 0.2410
2024-06-03 11:31:20 [INFO]: Epoch 039 - training loss: 0.3697, validation loss: 0.2476
2024-06-03 11:31:24 [INFO]: Epoch 040 - training loss: 0.3796, validation loss: 0.2433
2024-06-03 11:31:28 [INFO]: Epoch 041 - training loss: 0.3736, validation loss: 0.2529
2024-06-03 11:31:31 [INFO]: Epoch 042 - training loss: 0.3672, validation loss: 0.2425
2024-06-03 11:31:35 [INFO]: Epoch 043 - training loss: 0.3649, validation loss: 0.2376
2024-06-03 11:31:39 [INFO]: Epoch 044 - training loss: 0.3566, validation loss: 0.2456
2024-06-03 11:31:43 [INFO]: Epoch 045 - training loss: 0.3626, validation loss: 0.2424
2024-06-03 11:31:46 [INFO]: Epoch 046 - training loss: 0.3660, validation loss: 0.2389
2024-06-03 11:31:50 [INFO]: Epoch 047 - training loss: 0.3662, validation loss: 0.2408
2024-06-03 11:31:54 [INFO]: Epoch 048 - training loss: 0.3591, validation loss: 0.2423
2024-06-03 11:31:57 [INFO]: Epoch 049 - training loss: 0.3628, validation loss: 0.2395
2024-06-03 11:32:01 [INFO]: Epoch 050 - training loss: 0.3626, validation loss: 0.2430
2024-06-03 11:32:04 [INFO]: Epoch 051 - training loss: 0.3608, validation loss: 0.2380
2024-06-03 11:32:08 [INFO]: Epoch 052 - training loss: 0.3528, validation loss: 0.2393
2024-06-03 11:32:12 [INFO]: Epoch 053 - training loss: 0.3560, validation loss: 0.2390
2024-06-03 11:32:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:32:12 [INFO]: Finished training. The best model is from epoch#43.
2024-06-03 11:32:12 [INFO]: Saved the model to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T112854/Pyraformer.pypots
2024-06-03 11:32:13 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/imputation.pkl
2024-06-03 11:32:13 [INFO]: Round2 - Pyraformer on BeijingAir: MAE=0.2139, MSE=0.2490, MRE=0.2912
2024-06-03 11:32:13 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 11:32:13 [INFO]: Using the given device: cuda:0
2024-06-03 11:32:13 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T113213
2024-06-03 11:32:13 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T113213/tensorboard
2024-06-03 11:32:14 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 11:32:17 [INFO]: Epoch 001 - training loss: 1.0200, validation loss: 0.4210
2024-06-03 11:32:21 [INFO]: Epoch 002 - training loss: 0.7186, validation loss: 0.3925
2024-06-03 11:32:24 [INFO]: Epoch 003 - training loss: 0.6325, validation loss: 0.3439
2024-06-03 11:32:28 [INFO]: Epoch 004 - training loss: 0.5737, validation loss: 0.3346
2024-06-03 11:32:32 [INFO]: Epoch 005 - training loss: 0.5494, validation loss: 0.3016
2024-06-03 11:32:36 [INFO]: Epoch 006 - training loss: 0.5300, validation loss: 0.3100
2024-06-03 11:32:39 [INFO]: Epoch 007 - training loss: 0.5013, validation loss: 0.3006
2024-06-03 11:32:43 [INFO]: Epoch 008 - training loss: 0.4907, validation loss: 0.3111
2024-06-03 11:32:46 [INFO]: Epoch 009 - training loss: 0.4774, validation loss: 0.2958
2024-06-03 11:32:50 [INFO]: Epoch 010 - training loss: 0.4748, validation loss: 0.2917
2024-06-03 11:32:54 [INFO]: Epoch 011 - training loss: 0.4622, validation loss: 0.2823
2024-06-03 11:32:57 [INFO]: Epoch 012 - training loss: 0.4464, validation loss: 0.2796
2024-06-03 11:33:01 [INFO]: Epoch 013 - training loss: 0.4393, validation loss: 0.2741
2024-06-03 11:33:05 [INFO]: Epoch 014 - training loss: 0.4368, validation loss: 0.2791
2024-06-03 11:33:09 [INFO]: Epoch 015 - training loss: 0.4288, validation loss: 0.2714
2024-06-03 11:33:12 [INFO]: Epoch 016 - training loss: 0.4215, validation loss: 0.2764
2024-06-03 11:33:16 [INFO]: Epoch 017 - training loss: 0.4341, validation loss: 0.2793
2024-06-03 11:33:20 [INFO]: Epoch 018 - training loss: 0.4314, validation loss: 0.2732
2024-06-03 11:33:23 [INFO]: Epoch 019 - training loss: 0.4167, validation loss: 0.2619
2024-06-03 11:33:27 [INFO]: Epoch 020 - training loss: 0.4092, validation loss: 0.2628
2024-06-03 11:33:31 [INFO]: Epoch 021 - training loss: 0.4171, validation loss: 0.2914
2024-06-03 11:33:34 [INFO]: Epoch 022 - training loss: 0.4218, validation loss: 0.2514
2024-06-03 11:33:38 [INFO]: Epoch 023 - training loss: 0.4060, validation loss: 0.2607
2024-06-03 11:33:42 [INFO]: Epoch 024 - training loss: 0.3997, validation loss: 0.2513
2024-06-03 11:33:46 [INFO]: Epoch 025 - training loss: 0.3974, validation loss: 0.2495
2024-06-03 11:33:49 [INFO]: Epoch 026 - training loss: 0.3962, validation loss: 0.2489
2024-06-03 11:33:53 [INFO]: Epoch 027 - training loss: 0.3944, validation loss: 0.2493
2024-06-03 11:33:57 [INFO]: Epoch 028 - training loss: 0.3887, validation loss: 0.2543
2024-06-03 11:34:01 [INFO]: Epoch 029 - training loss: 0.3893, validation loss: 0.2502
2024-06-03 11:34:05 [INFO]: Epoch 030 - training loss: 0.3831, validation loss: 0.2565
2024-06-03 11:34:09 [INFO]: Epoch 031 - training loss: 0.3905, validation loss: 0.2496
2024-06-03 11:34:12 [INFO]: Epoch 032 - training loss: 0.3865, validation loss: 0.2467
2024-06-03 11:34:16 [INFO]: Epoch 033 - training loss: 0.3775, validation loss: 0.2444
2024-06-03 11:34:20 [INFO]: Epoch 034 - training loss: 0.3806, validation loss: 0.2450
2024-06-03 11:34:24 [INFO]: Epoch 035 - training loss: 0.3724, validation loss: 0.2391
2024-06-03 11:34:28 [INFO]: Epoch 036 - training loss: 0.3719, validation loss: 0.2412
2024-06-03 11:34:31 [INFO]: Epoch 037 - training loss: 0.3642, validation loss: 0.2387
2024-06-03 11:34:36 [INFO]: Epoch 038 - training loss: 0.3661, validation loss: 0.2470
2024-06-03 11:34:39 [INFO]: Epoch 039 - training loss: 0.3665, validation loss: 0.2406
2024-06-03 11:34:43 [INFO]: Epoch 040 - training loss: 0.3690, validation loss: 0.2413
2024-06-03 11:34:47 [INFO]: Epoch 041 - training loss: 0.3755, validation loss: 0.2461
2024-06-03 11:34:51 [INFO]: Epoch 042 - training loss: 0.3684, validation loss: 0.2498
2024-06-03 11:34:55 [INFO]: Epoch 043 - training loss: 0.3655, validation loss: 0.2373
2024-06-03 11:34:59 [INFO]: Epoch 044 - training loss: 0.3604, validation loss: 0.2427
2024-06-03 11:35:03 [INFO]: Epoch 045 - training loss: 0.3623, validation loss: 0.2423
2024-06-03 11:35:07 [INFO]: Epoch 046 - training loss: 0.3573, validation loss: 0.2378
2024-06-03 11:35:10 [INFO]: Epoch 047 - training loss: 0.3675, validation loss: 0.2429
2024-06-03 11:35:14 [INFO]: Epoch 048 - training loss: 0.3602, validation loss: 0.2443
2024-06-03 11:35:18 [INFO]: Epoch 049 - training loss: 0.3613, validation loss: 0.2410
2024-06-03 11:35:22 [INFO]: Epoch 050 - training loss: 0.3582, validation loss: 0.2370
2024-06-03 11:35:25 [INFO]: Epoch 051 - training loss: 0.3503, validation loss: 0.2359
2024-06-03 11:35:29 [INFO]: Epoch 052 - training loss: 0.3525, validation loss: 0.2401
2024-06-03 11:35:33 [INFO]: Epoch 053 - training loss: 0.3497, validation loss: 0.2377
2024-06-03 11:35:37 [INFO]: Epoch 054 - training loss: 0.3531, validation loss: 0.2415
2024-06-03 11:35:41 [INFO]: Epoch 055 - training loss: 0.3571, validation loss: 0.2429
2024-06-03 11:35:44 [INFO]: Epoch 056 - training loss: 0.3505, validation loss: 0.2427
2024-06-03 11:35:48 [INFO]: Epoch 057 - training loss: 0.3458, validation loss: 0.2341
2024-06-03 11:35:52 [INFO]: Epoch 058 - training loss: 0.3464, validation loss: 0.2400
2024-06-03 11:35:56 [INFO]: Epoch 059 - training loss: 0.3512, validation loss: 0.2441
2024-06-03 11:35:59 [INFO]: Epoch 060 - training loss: 0.3496, validation loss: 0.2373
2024-06-03 11:36:03 [INFO]: Epoch 061 - training loss: 0.3456, validation loss: 0.2371
2024-06-03 11:36:07 [INFO]: Epoch 062 - training loss: 0.3433, validation loss: 0.2345
2024-06-03 11:36:10 [INFO]: Epoch 063 - training loss: 0.3422, validation loss: 0.2358
2024-06-03 11:36:14 [INFO]: Epoch 064 - training loss: 0.3375, validation loss: 0.2314
2024-06-03 11:36:18 [INFO]: Epoch 065 - training loss: 0.3388, validation loss: 0.2343
2024-06-03 11:36:21 [INFO]: Epoch 066 - training loss: 0.3365, validation loss: 0.2369
2024-06-03 11:36:24 [INFO]: Epoch 067 - training loss: 0.3371, validation loss: 0.2338
2024-06-03 11:36:27 [INFO]: Epoch 068 - training loss: 0.3456, validation loss: 0.2370
2024-06-03 11:36:29 [INFO]: Epoch 069 - training loss: 0.3425, validation loss: 0.2356
2024-06-03 11:36:32 [INFO]: Epoch 070 - training loss: 0.3397, validation loss: 0.2325
2024-06-03 11:36:36 [INFO]: Epoch 071 - training loss: 0.3336, validation loss: 0.2324
2024-06-03 11:36:40 [INFO]: Epoch 072 - training loss: 0.3394, validation loss: 0.2410
2024-06-03 11:36:43 [INFO]: Epoch 073 - training loss: 0.3385, validation loss: 0.2277
2024-06-03 11:36:47 [INFO]: Epoch 074 - training loss: 0.3385, validation loss: 0.2343
2024-06-03 11:36:51 [INFO]: Epoch 075 - training loss: 0.3387, validation loss: 0.2308
2024-06-03 11:36:54 [INFO]: Epoch 076 - training loss: 0.3381, validation loss: 0.2328
2024-06-03 11:36:58 [INFO]: Epoch 077 - training loss: 0.3345, validation loss: 0.2325
2024-06-03 11:37:02 [INFO]: Epoch 078 - training loss: 0.3382, validation loss: 0.2278
2024-06-03 11:37:06 [INFO]: Epoch 079 - training loss: 0.3332, validation loss: 0.2310
2024-06-03 11:37:09 [INFO]: Epoch 080 - training loss: 0.3315, validation loss: 0.2340
2024-06-03 11:37:13 [INFO]: Epoch 081 - training loss: 0.3313, validation loss: 0.2285
2024-06-03 11:37:17 [INFO]: Epoch 082 - training loss: 0.3303, validation loss: 0.2301
2024-06-03 11:37:20 [INFO]: Epoch 083 - training loss: 0.3328, validation loss: 0.2325
2024-06-03 11:37:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 11:37:20 [INFO]: Finished training. The best model is from epoch#73.
2024-06-03 11:37:21 [INFO]: Saved the model to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T113213/Pyraformer.pypots
2024-06-03 11:37:22 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/imputation.pkl
2024-06-03 11:37:22 [INFO]: Round3 - Pyraformer on BeijingAir: MAE=0.2096, MSE=0.2301, MRE=0.2854
2024-06-03 11:37:22 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 11:37:22 [INFO]: Using the given device: cuda:0
2024-06-03 11:37:22 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T113722
2024-06-03 11:37:22 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T113722/tensorboard
2024-06-03 11:37:22 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 11:37:26 [INFO]: Epoch 001 - training loss: 1.0729, validation loss: 0.4465
2024-06-03 11:37:30 [INFO]: Epoch 002 - training loss: 0.7427, validation loss: 0.3754
2024-06-03 11:37:34 [INFO]: Epoch 003 - training loss: 0.6645, validation loss: 0.3627
2024-06-03 11:37:37 [INFO]: Epoch 004 - training loss: 0.6192, validation loss: 0.3211
2024-06-03 11:37:42 [INFO]: Epoch 005 - training loss: 0.5667, validation loss: 0.3223
2024-06-03 11:37:45 [INFO]: Epoch 006 - training loss: 0.5433, validation loss: 0.3178
2024-06-03 11:37:49 [INFO]: Epoch 007 - training loss: 0.5112, validation loss: 0.3044
2024-06-03 11:37:53 [INFO]: Epoch 008 - training loss: 0.5064, validation loss: 0.2996
2024-06-03 11:37:56 [INFO]: Epoch 009 - training loss: 0.4886, validation loss: 0.2994
2024-06-03 11:38:00 [INFO]: Epoch 010 - training loss: 0.4879, validation loss: 0.2872
2024-06-03 11:38:03 [INFO]: Epoch 011 - training loss: 0.4724, validation loss: 0.2829
2024-06-03 11:38:06 [INFO]: Epoch 012 - training loss: 0.4546, validation loss: 0.2828
2024-06-03 11:38:09 [INFO]: Epoch 013 - training loss: 0.4538, validation loss: 0.2805
2024-06-03 11:38:12 [INFO]: Epoch 014 - training loss: 0.4462, validation loss: 0.2767
2024-06-03 11:38:15 [INFO]: Epoch 015 - training loss: 0.4448, validation loss: 0.2789
2024-06-03 11:38:19 [INFO]: Epoch 016 - training loss: 0.4362, validation loss: 0.2759
2024-06-03 11:38:22 [INFO]: Epoch 017 - training loss: 0.4301, validation loss: 0.2657
2024-06-03 11:38:26 [INFO]: Epoch 018 - training loss: 0.4185, validation loss: 0.2661
2024-06-03 11:38:29 [INFO]: Epoch 019 - training loss: 0.4201, validation loss: 0.2617
2024-06-03 11:38:33 [INFO]: Epoch 020 - training loss: 0.4229, validation loss: 0.2602
2024-06-03 11:38:36 [INFO]: Epoch 021 - training loss: 0.4160, validation loss: 0.2615
2024-06-03 11:38:39 [INFO]: Epoch 022 - training loss: 0.4042, validation loss: 0.2541
2024-06-03 11:38:43 [INFO]: Epoch 023 - training loss: 0.4051, validation loss: 0.2501
2024-06-03 11:38:46 [INFO]: Epoch 024 - training loss: 0.4002, validation loss: 0.2501
2024-06-03 11:38:49 [INFO]: Epoch 025 - training loss: 0.3974, validation loss: 0.2490
2024-06-03 11:38:53 [INFO]: Epoch 026 - training loss: 0.3956, validation loss: 0.2465
2024-06-03 11:38:56 [INFO]: Epoch 027 - training loss: 0.3950, validation loss: 0.2495
2024-06-03 11:38:59 [INFO]: Epoch 028 - training loss: 0.3891, validation loss: 0.2469
2024-06-03 11:39:02 [INFO]: Epoch 029 - training loss: 0.3867, validation loss: 0.2466
2024-06-03 11:39:05 [INFO]: Epoch 030 - training loss: 0.3825, validation loss: 0.2486
2024-06-03 11:39:09 [INFO]: Epoch 031 - training loss: 0.3785, validation loss: 0.2450
2024-06-03 11:39:12 [INFO]: Epoch 032 - training loss: 0.3819, validation loss: 0.2445
2024-06-03 11:39:15 [INFO]: Epoch 033 - training loss: 0.3784, validation loss: 0.2457
2024-06-03 11:39:19 [INFO]: Epoch 034 - training loss: 0.3712, validation loss: 0.2519
2024-06-03 11:39:22 [INFO]: Epoch 035 - training loss: 0.3745, validation loss: 0.2430
2024-06-03 11:39:25 [INFO]: Epoch 036 - training loss: 0.3715, validation loss: 0.2381
2024-06-03 11:39:29 [INFO]: Epoch 037 - training loss: 0.3689, validation loss: 0.2397
2024-06-03 11:39:32 [INFO]: Epoch 038 - training loss: 0.3748, validation loss: 0.2402
2024-06-03 11:39:36 [INFO]: Epoch 039 - training loss: 0.3653, validation loss: 0.2423
2024-06-03 11:39:39 [INFO]: Epoch 040 - training loss: 0.3725, validation loss: 0.2397
2024-06-03 11:39:43 [INFO]: Epoch 041 - training loss: 0.3652, validation loss: 0.2485
2024-06-03 11:39:46 [INFO]: Epoch 042 - training loss: 0.3688, validation loss: 0.2432
2024-06-03 11:39:50 [INFO]: Epoch 043 - training loss: 0.3653, validation loss: 0.2411
2024-06-03 11:39:53 [INFO]: Epoch 044 - training loss: 0.3601, validation loss: 0.2405
2024-06-03 11:39:57 [INFO]: Epoch 045 - training loss: 0.3586, validation loss: 0.2381
2024-06-03 11:40:00 [INFO]: Epoch 046 - training loss: 0.3559, validation loss: 0.2372
2024-06-03 11:40:04 [INFO]: Epoch 047 - training loss: 0.3533, validation loss: 0.2404
2024-06-03 11:40:07 [INFO]: Epoch 048 - training loss: 0.3571, validation loss: 0.2406
2024-06-03 11:40:10 [INFO]: Epoch 049 - training loss: 0.3536, validation loss: 0.2419
2024-06-03 11:40:14 [INFO]: Epoch 050 - training loss: 0.3542, validation loss: 0.2350
2024-06-03 11:40:17 [INFO]: Epoch 051 - training loss: 0.3562, validation loss: 0.2461
2024-06-03 11:40:19 [INFO]: Epoch 052 - training loss: 0.3580, validation loss: 0.2369
2024-06-03 11:40:22 [INFO]: Epoch 053 - training loss: 0.3520, validation loss: 0.2433
2024-06-03 11:40:25 [INFO]: Epoch 054 - training loss: 0.3526, validation loss: 0.2410
2024-06-03 11:40:27 [INFO]: Epoch 055 - training loss: 0.3462, validation loss: 0.2357
2024-06-03 11:40:30 [INFO]: Epoch 056 - training loss: 0.3483, validation loss: 0.2333
2024-06-03 11:40:33 [INFO]: Epoch 057 - training loss: 0.3469, validation loss: 0.2385
2024-06-03 11:40:37 [INFO]: Epoch 058 - training loss: 0.3479, validation loss: 0.2358
2024-06-03 11:40:40 [INFO]: Epoch 059 - training loss: 0.3475, validation loss: 0.2354
2024-06-03 11:40:44 [INFO]: Epoch 060 - training loss: 0.3435, validation loss: 0.2370
2024-06-03 11:40:47 [INFO]: Epoch 061 - training loss: 0.3435, validation loss: 0.2372
2024-06-03 11:40:50 [INFO]: Epoch 062 - training loss: 0.3421, validation loss: 0.2333
2024-06-03 11:40:54 [INFO]: Epoch 063 - training loss: 0.3428, validation loss: 0.2371
2024-06-03 11:40:57 [INFO]: Epoch 064 - training loss: 0.3434, validation loss: 0.2328
2024-06-03 11:41:01 [INFO]: Epoch 065 - training loss: 0.3408, validation loss: 0.2369
2024-06-03 11:41:04 [INFO]: Epoch 066 - training loss: 0.3344, validation loss: 0.2351
2024-06-03 11:41:07 [INFO]: Epoch 067 - training loss: 0.3373, validation loss: 0.2354
2024-06-03 11:41:11 [INFO]: Epoch 068 - training loss: 0.3392, validation loss: 0.2346
2024-06-03 11:41:14 [INFO]: Epoch 069 - training loss: 0.3419, validation loss: 0.2336
2024-06-03 11:41:17 [INFO]: Epoch 070 - training loss: 0.3376, validation loss: 0.2332
2024-06-03 11:41:21 [INFO]: Epoch 071 - training loss: 0.3324, validation loss: 0.2335
2024-06-03 11:41:24 [INFO]: Epoch 072 - training loss: 0.3376, validation loss: 0.2318
2024-06-03 11:41:27 [INFO]: Epoch 073 - training loss: 0.3310, validation loss: 0.2338
2024-06-03 11:41:30 [INFO]: Epoch 074 - training loss: 0.3340, validation loss: 0.2320
2024-06-03 11:41:33 [INFO]: Epoch 075 - training loss: 0.3315, validation loss: 0.2305
2024-06-03 11:41:35 [INFO]: Epoch 076 - training loss: 0.3326, validation loss: 0.2331
2024-06-03 11:41:38 [INFO]: Epoch 077 - training loss: 0.3322, validation loss: 0.2308
2024-06-03 11:41:40 [INFO]: Epoch 078 - training loss: 0.3273, validation loss: 0.2270
2024-06-03 11:41:43 [INFO]: Epoch 079 - training loss: 0.3279, validation loss: 0.2261
2024-06-03 11:41:45 [INFO]: Epoch 080 - training loss: 0.3282, validation loss: 0.2316
2024-06-03 11:41:48 [INFO]: Epoch 081 - training loss: 0.3315, validation loss: 0.2250
2024-06-03 11:41:50 [INFO]: Epoch 082 - training loss: 0.3281, validation loss: 0.2283
2024-06-03 11:41:53 [INFO]: Epoch 083 - training loss: 0.3256, validation loss: 0.2227
2024-06-03 11:41:55 [INFO]: Epoch 084 - training loss: 0.3289, validation loss: 0.2304
2024-06-03 11:41:57 [INFO]: Epoch 085 - training loss: 0.3319, validation loss: 0.2266
2024-06-03 11:42:00 [INFO]: Epoch 086 - training loss: 0.3280, validation loss: 0.2264
2024-06-03 11:42:02 [INFO]: Epoch 087 - training loss: 0.3262, validation loss: 0.2261
2024-06-03 11:42:05 [INFO]: Epoch 088 - training loss: 0.3263, validation loss: 0.2238
2024-06-03 11:42:07 [INFO]: Epoch 089 - training loss: 0.3227, validation loss: 0.2220
2024-06-03 11:42:09 [INFO]: Epoch 090 - training loss: 0.3214, validation loss: 0.2250
2024-06-03 11:42:12 [INFO]: Epoch 091 - training loss: 0.3210, validation loss: 0.2230
2024-06-03 11:42:14 [INFO]: Epoch 092 - training loss: 0.3206, validation loss: 0.2212
2024-06-03 11:42:16 [INFO]: Epoch 093 - training loss: 0.3220, validation loss: 0.2252
2024-06-03 11:42:19 [INFO]: Epoch 094 - training loss: 0.3219, validation loss: 0.2190
2024-06-03 11:42:21 [INFO]: Epoch 095 - training loss: 0.3201, validation loss: 0.2225
2024-06-03 11:42:24 [INFO]: Epoch 096 - training loss: 0.3191, validation loss: 0.2220
2024-06-03 11:42:26 [INFO]: Epoch 097 - training loss: 0.3181, validation loss: 0.2244
2024-06-03 11:42:28 [INFO]: Epoch 098 - training loss: 0.3210, validation loss: 0.2215
2024-06-03 11:42:31 [INFO]: Epoch 099 - training loss: 0.3181, validation loss: 0.2228
2024-06-03 11:42:33 [INFO]: Epoch 100 - training loss: 0.3192, validation loss: 0.2259
2024-06-03 11:42:33 [INFO]: Finished training. The best model is from epoch#94.
2024-06-03 11:42:33 [INFO]: Saved the model to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T113722/Pyraformer.pypots
2024-06-03 11:42:34 [INFO]: Successfully saved to results_point_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/imputation.pkl
2024-06-03 11:42:34 [INFO]: Round4 - Pyraformer on BeijingAir: MAE=0.2034, MSE=0.2262, MRE=0.2770
2024-06-03 11:42:34 [INFO]: Done! Final results:
Averaged Pyraformer (3,230,212 params) on BeijingAir: MAE=0.1981 ± 0.004791311120839996, MSE=0.2231 ± 0.01140552751100604, MRE=0.2626 ± 0.006350559551807653, average inference time=0.33