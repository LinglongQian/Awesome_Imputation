2024-06-02 20:59:58 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:59:58 [INFO]: Using the given device: cuda:0
2024-06-02 20:59:58 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240602_T205958
2024-06-02 20:59:58 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240602_T205958/tensorboard
2024-06-02 21:00:00 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-02 21:00:25 [INFO]: Epoch 001 - training loss: 1.0827, validation loss: 0.5980
2024-06-02 21:00:41 [INFO]: Epoch 002 - training loss: 0.8559, validation loss: 0.4674
2024-06-02 21:00:58 [INFO]: Epoch 003 - training loss: 0.7464, validation loss: 0.4302
2024-06-02 21:01:14 [INFO]: Epoch 004 - training loss: 0.6909, validation loss: 0.4072
2024-06-02 21:01:30 [INFO]: Epoch 005 - training loss: 0.6541, validation loss: 0.3940
2024-06-02 21:01:47 [INFO]: Epoch 006 - training loss: 0.6298, validation loss: 0.3778
2024-06-02 21:02:03 [INFO]: Epoch 007 - training loss: 0.6069, validation loss: 0.3676
2024-06-02 21:02:19 [INFO]: Epoch 008 - training loss: 0.5877, validation loss: 0.3572
2024-06-02 21:02:35 [INFO]: Epoch 009 - training loss: 0.5725, validation loss: 0.3496
2024-06-02 21:02:52 [INFO]: Epoch 010 - training loss: 0.5593, validation loss: 0.3436
2024-06-02 21:03:08 [INFO]: Epoch 011 - training loss: 0.5483, validation loss: 0.3356
2024-06-02 21:03:24 [INFO]: Epoch 012 - training loss: 0.5365, validation loss: 0.3335
2024-06-02 21:03:40 [INFO]: Epoch 013 - training loss: 0.5287, validation loss: 0.3296
2024-06-02 21:03:56 [INFO]: Epoch 014 - training loss: 0.5209, validation loss: 0.3249
2024-06-02 21:04:12 [INFO]: Epoch 015 - training loss: 0.5152, validation loss: 0.3220
2024-06-02 21:04:29 [INFO]: Epoch 016 - training loss: 0.5091, validation loss: 0.3197
2024-06-02 21:04:45 [INFO]: Epoch 017 - training loss: 0.5046, validation loss: 0.3178
2024-06-02 21:05:01 [INFO]: Epoch 018 - training loss: 0.4971, validation loss: 0.3168
2024-06-02 21:05:17 [INFO]: Epoch 019 - training loss: 0.4938, validation loss: 0.3134
2024-06-02 21:05:34 [INFO]: Epoch 020 - training loss: 0.4898, validation loss: 0.3117
2024-06-02 21:05:50 [INFO]: Epoch 021 - training loss: 0.4851, validation loss: 0.3098
2024-06-02 21:06:07 [INFO]: Epoch 022 - training loss: 0.4812, validation loss: 0.3109
2024-06-02 21:06:23 [INFO]: Epoch 023 - training loss: 0.4790, validation loss: 0.3074
2024-06-02 21:06:40 [INFO]: Epoch 024 - training loss: 0.4781, validation loss: 0.3063
2024-06-02 21:06:56 [INFO]: Epoch 025 - training loss: 0.4745, validation loss: 0.3050
2024-06-02 21:07:12 [INFO]: Epoch 026 - training loss: 0.4719, validation loss: 0.3048
2024-06-02 21:07:28 [INFO]: Epoch 027 - training loss: 0.4684, validation loss: 0.3027
2024-06-02 21:07:44 [INFO]: Epoch 028 - training loss: 0.4675, validation loss: 0.3011
2024-06-02 21:08:01 [INFO]: Epoch 029 - training loss: 0.4663, validation loss: 0.3003
2024-06-02 21:08:17 [INFO]: Epoch 030 - training loss: 0.4629, validation loss: 0.2979
2024-06-02 21:08:33 [INFO]: Epoch 031 - training loss: 0.4634, validation loss: 0.2976
2024-06-02 21:08:49 [INFO]: Epoch 032 - training loss: 0.4604, validation loss: 0.2979
2024-06-02 21:09:05 [INFO]: Epoch 033 - training loss: 0.4583, validation loss: 0.2976
2024-06-02 21:09:21 [INFO]: Epoch 034 - training loss: 0.4571, validation loss: 0.2967
2024-06-02 21:09:37 [INFO]: Epoch 035 - training loss: 0.4565, validation loss: 0.2957
2024-06-02 21:09:53 [INFO]: Epoch 036 - training loss: 0.4547, validation loss: 0.2935
2024-06-02 21:10:09 [INFO]: Epoch 037 - training loss: 0.4528, validation loss: 0.2957
2024-06-02 21:10:24 [INFO]: Epoch 038 - training loss: 0.4516, validation loss: 0.2911
2024-06-02 21:10:39 [INFO]: Epoch 039 - training loss: 0.4513, validation loss: 0.2931
2024-06-02 21:10:53 [INFO]: Epoch 040 - training loss: 0.4502, validation loss: 0.2914
2024-06-02 21:11:08 [INFO]: Epoch 041 - training loss: 0.4483, validation loss: 0.2911
2024-06-02 21:11:23 [INFO]: Epoch 042 - training loss: 0.4470, validation loss: 0.2901
2024-06-02 21:11:38 [INFO]: Epoch 043 - training loss: 0.4470, validation loss: 0.2908
2024-06-02 21:11:53 [INFO]: Epoch 044 - training loss: 0.4443, validation loss: 0.2896
2024-06-02 21:12:08 [INFO]: Epoch 045 - training loss: 0.4445, validation loss: 0.2890
2024-06-02 21:12:23 [INFO]: Epoch 046 - training loss: 0.4418, validation loss: 0.2888
2024-06-02 21:12:38 [INFO]: Epoch 047 - training loss: 0.4428, validation loss: 0.2872
2024-06-02 21:12:53 [INFO]: Epoch 048 - training loss: 0.4410, validation loss: 0.2872
2024-06-02 21:13:08 [INFO]: Epoch 049 - training loss: 0.4396, validation loss: 0.2865
2024-06-02 21:13:22 [INFO]: Epoch 050 - training loss: 0.4402, validation loss: 0.2854
2024-06-02 21:13:36 [INFO]: Epoch 051 - training loss: 0.4389, validation loss: 0.2846
2024-06-02 21:13:49 [INFO]: Epoch 052 - training loss: 0.4383, validation loss: 0.2828
2024-06-02 21:14:03 [INFO]: Epoch 053 - training loss: 0.4363, validation loss: 0.2840
2024-06-02 21:14:16 [INFO]: Epoch 054 - training loss: 0.4342, validation loss: 0.2833
2024-06-02 21:14:31 [INFO]: Epoch 055 - training loss: 0.4339, validation loss: 0.2839
2024-06-02 21:14:44 [INFO]: Epoch 056 - training loss: 0.4332, validation loss: 0.2804
2024-06-02 21:14:57 [INFO]: Epoch 057 - training loss: 0.4327, validation loss: 0.2800
2024-06-02 21:15:12 [INFO]: Epoch 058 - training loss: 0.4324, validation loss: 0.2810
2024-06-02 21:15:25 [INFO]: Epoch 059 - training loss: 0.4330, validation loss: 0.2804
2024-06-02 21:15:37 [INFO]: Epoch 060 - training loss: 0.4310, validation loss: 0.2792
2024-06-02 21:15:49 [INFO]: Epoch 061 - training loss: 0.4304, validation loss: 0.2785
2024-06-02 21:16:01 [INFO]: Epoch 062 - training loss: 0.4286, validation loss: 0.2788
2024-06-02 21:16:13 [INFO]: Epoch 063 - training loss: 0.4281, validation loss: 0.2784
2024-06-02 21:16:25 [INFO]: Epoch 064 - training loss: 0.4289, validation loss: 0.2780
2024-06-02 21:16:36 [INFO]: Epoch 065 - training loss: 0.4285, validation loss: 0.2787
2024-06-02 21:16:46 [INFO]: Epoch 066 - training loss: 0.4294, validation loss: 0.2790
2024-06-02 21:16:56 [INFO]: Epoch 067 - training loss: 0.4270, validation loss: 0.2765
2024-06-02 21:17:06 [INFO]: Epoch 068 - training loss: 0.4277, validation loss: 0.2771
2024-06-02 21:17:15 [INFO]: Epoch 069 - training loss: 0.4239, validation loss: 0.2784
2024-06-02 21:17:25 [INFO]: Epoch 070 - training loss: 0.4243, validation loss: 0.2781
2024-06-02 21:17:34 [INFO]: Epoch 071 - training loss: 0.4236, validation loss: 0.2745
2024-06-02 21:17:44 [INFO]: Epoch 072 - training loss: 0.4237, validation loss: 0.2767
2024-06-02 21:17:54 [INFO]: Epoch 073 - training loss: 0.4240, validation loss: 0.2761
2024-06-02 21:18:04 [INFO]: Epoch 074 - training loss: 0.4228, validation loss: 0.2765
2024-06-02 21:18:14 [INFO]: Epoch 075 - training loss: 0.4241, validation loss: 0.2752
2024-06-02 21:18:23 [INFO]: Epoch 076 - training loss: 0.4225, validation loss: 0.2744
2024-06-02 21:18:33 [INFO]: Epoch 077 - training loss: 0.4219, validation loss: 0.2737
2024-06-02 21:18:43 [INFO]: Epoch 078 - training loss: 0.4207, validation loss: 0.2733
2024-06-02 21:18:53 [INFO]: Epoch 079 - training loss: 0.4196, validation loss: 0.2745
2024-06-02 21:19:03 [INFO]: Epoch 080 - training loss: 0.4191, validation loss: 0.2732
2024-06-02 21:19:12 [INFO]: Epoch 081 - training loss: 0.4205, validation loss: 0.2752
2024-06-02 21:19:22 [INFO]: Epoch 082 - training loss: 0.4184, validation loss: 0.2734
2024-06-02 21:19:32 [INFO]: Epoch 083 - training loss: 0.4184, validation loss: 0.2729
2024-06-02 21:19:41 [INFO]: Epoch 084 - training loss: 0.4175, validation loss: 0.2725
2024-06-02 21:19:52 [INFO]: Epoch 085 - training loss: 0.4177, validation loss: 0.2727
2024-06-02 21:20:01 [INFO]: Epoch 086 - training loss: 0.4179, validation loss: 0.2731
2024-06-02 21:20:11 [INFO]: Epoch 087 - training loss: 0.4166, validation loss: 0.2725
2024-06-02 21:20:21 [INFO]: Epoch 088 - training loss: 0.4167, validation loss: 0.2718
2024-06-02 21:20:31 [INFO]: Epoch 089 - training loss: 0.4153, validation loss: 0.2737
2024-06-02 21:20:41 [INFO]: Epoch 090 - training loss: 0.4165, validation loss: 0.2718
2024-06-02 21:20:50 [INFO]: Epoch 091 - training loss: 0.4157, validation loss: 0.2697
2024-06-02 21:21:00 [INFO]: Epoch 092 - training loss: 0.4149, validation loss: 0.2718
2024-06-02 21:21:11 [INFO]: Epoch 093 - training loss: 0.4127, validation loss: 0.2721
2024-06-02 21:21:21 [INFO]: Epoch 094 - training loss: 0.4147, validation loss: 0.2707
2024-06-02 21:21:31 [INFO]: Epoch 095 - training loss: 0.4132, validation loss: 0.2711
2024-06-02 21:21:40 [INFO]: Epoch 096 - training loss: 0.4117, validation loss: 0.2704
2024-06-02 21:21:50 [INFO]: Epoch 097 - training loss: 0.4109, validation loss: 0.2692
2024-06-02 21:22:00 [INFO]: Epoch 098 - training loss: 0.4126, validation loss: 0.2685
2024-06-02 21:22:10 [INFO]: Epoch 099 - training loss: 0.4118, validation loss: 0.2696
2024-06-02 21:22:20 [INFO]: Epoch 100 - training loss: 0.4115, validation loss: 0.2692
2024-06-02 21:22:20 [INFO]: Finished training. The best model is from epoch#98.
2024-06-02 21:22:20 [INFO]: Saved the model to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240602_T205958/ETSformer.pypots
2024-06-02 21:22:28 [INFO]: Successfully saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_0/imputation.pkl
2024-06-02 21:22:28 [INFO]: Round0 - ETSformer on BeijingAir: MAE=0.2538, MSE=0.2579, MRE=0.3456
2024-06-02 21:22:28 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 21:22:28 [INFO]: Using the given device: cuda:0
2024-06-02 21:22:28 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240602_T212228
2024-06-02 21:22:28 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240602_T212228/tensorboard
2024-06-02 21:22:28 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-02 21:22:38 [INFO]: Epoch 001 - training loss: 1.0641, validation loss: 0.5894
2024-06-02 21:22:48 [INFO]: Epoch 002 - training loss: 0.8770, validation loss: 0.4631
2024-06-02 21:22:58 [INFO]: Epoch 003 - training loss: 0.7051, validation loss: 0.3934
2024-06-02 21:23:08 [INFO]: Epoch 004 - training loss: 0.6459, validation loss: 0.3787
2024-06-02 21:23:18 [INFO]: Epoch 005 - training loss: 0.6176, validation loss: 0.3640
2024-06-02 21:23:28 [INFO]: Epoch 006 - training loss: 0.5960, validation loss: 0.3571
2024-06-02 21:23:38 [INFO]: Epoch 007 - training loss: 0.5776, validation loss: 0.3510
2024-06-02 21:23:47 [INFO]: Epoch 008 - training loss: 0.5624, validation loss: 0.3449
2024-06-02 21:23:57 [INFO]: Epoch 009 - training loss: 0.5511, validation loss: 0.3415
2024-06-02 21:24:07 [INFO]: Epoch 010 - training loss: 0.5407, validation loss: 0.3381
2024-06-02 21:24:17 [INFO]: Epoch 011 - training loss: 0.5332, validation loss: 0.3324
2024-06-02 21:24:27 [INFO]: Epoch 012 - training loss: 0.5231, validation loss: 0.3315
2024-06-02 21:24:37 [INFO]: Epoch 013 - training loss: 0.5199, validation loss: 0.3279
2024-06-02 21:24:46 [INFO]: Epoch 014 - training loss: 0.5126, validation loss: 0.3268
2024-06-02 21:24:57 [INFO]: Epoch 015 - training loss: 0.5059, validation loss: 0.3244
2024-06-02 21:25:06 [INFO]: Epoch 016 - training loss: 0.5019, validation loss: 0.3225
2024-06-02 21:25:16 [INFO]: Epoch 017 - training loss: 0.4974, validation loss: 0.3210
2024-06-02 21:25:26 [INFO]: Epoch 018 - training loss: 0.4948, validation loss: 0.3186
2024-06-02 21:25:36 [INFO]: Epoch 019 - training loss: 0.4922, validation loss: 0.3163
2024-06-02 21:25:46 [INFO]: Epoch 020 - training loss: 0.4851, validation loss: 0.3147
2024-06-02 21:25:55 [INFO]: Epoch 021 - training loss: 0.4817, validation loss: 0.3140
2024-06-02 21:26:05 [INFO]: Epoch 022 - training loss: 0.4799, validation loss: 0.3131
2024-06-02 21:26:15 [INFO]: Epoch 023 - training loss: 0.4782, validation loss: 0.3105
2024-06-02 21:26:25 [INFO]: Epoch 024 - training loss: 0.4755, validation loss: 0.3098
2024-06-02 21:26:35 [INFO]: Epoch 025 - training loss: 0.4753, validation loss: 0.3103
2024-06-02 21:26:45 [INFO]: Epoch 026 - training loss: 0.4708, validation loss: 0.3097
2024-06-02 21:26:55 [INFO]: Epoch 027 - training loss: 0.4681, validation loss: 0.3053
2024-06-02 21:27:05 [INFO]: Epoch 028 - training loss: 0.4660, validation loss: 0.3058
2024-06-02 21:27:14 [INFO]: Epoch 029 - training loss: 0.4685, validation loss: 0.3066
2024-06-02 21:27:24 [INFO]: Epoch 030 - training loss: 0.4657, validation loss: 0.3040
2024-06-02 21:27:34 [INFO]: Epoch 031 - training loss: 0.4620, validation loss: 0.3020
2024-06-02 21:27:44 [INFO]: Epoch 032 - training loss: 0.4600, validation loss: 0.3013
2024-06-02 21:27:54 [INFO]: Epoch 033 - training loss: 0.4605, validation loss: 0.3035
2024-06-02 21:28:04 [INFO]: Epoch 034 - training loss: 0.4570, validation loss: 0.3012
2024-06-02 21:28:13 [INFO]: Epoch 035 - training loss: 0.4566, validation loss: 0.3014
2024-06-02 21:28:24 [INFO]: Epoch 036 - training loss: 0.4575, validation loss: 0.3009
2024-06-02 21:28:33 [INFO]: Epoch 037 - training loss: 0.4531, validation loss: 0.2995
2024-06-02 21:28:43 [INFO]: Epoch 038 - training loss: 0.4515, validation loss: 0.2971
2024-06-02 21:28:53 [INFO]: Epoch 039 - training loss: 0.4530, validation loss: 0.2965
2024-06-02 21:29:03 [INFO]: Epoch 040 - training loss: 0.4506, validation loss: 0.2961
2024-06-02 21:29:12 [INFO]: Epoch 041 - training loss: 0.4506, validation loss: 0.2973
2024-06-02 21:29:22 [INFO]: Epoch 042 - training loss: 0.4490, validation loss: 0.2944
2024-06-02 21:29:31 [INFO]: Epoch 043 - training loss: 0.4483, validation loss: 0.2924
2024-06-02 21:29:41 [INFO]: Epoch 044 - training loss: 0.4461, validation loss: 0.2937
2024-06-02 21:29:50 [INFO]: Epoch 045 - training loss: 0.4463, validation loss: 0.2938
2024-06-02 21:30:00 [INFO]: Epoch 046 - training loss: 0.4453, validation loss: 0.2934
2024-06-02 21:30:10 [INFO]: Epoch 047 - training loss: 0.4441, validation loss: 0.2928
2024-06-02 21:30:20 [INFO]: Epoch 048 - training loss: 0.4446, validation loss: 0.2931
2024-06-02 21:30:30 [INFO]: Epoch 049 - training loss: 0.4440, validation loss: 0.2918
2024-06-02 21:30:40 [INFO]: Epoch 050 - training loss: 0.4425, validation loss: 0.2883
2024-06-02 21:30:49 [INFO]: Epoch 051 - training loss: 0.4420, validation loss: 0.2913
2024-06-02 21:30:59 [INFO]: Epoch 052 - training loss: 0.4408, validation loss: 0.2896
2024-06-02 21:31:09 [INFO]: Epoch 053 - training loss: 0.4405, validation loss: 0.2873
2024-06-02 21:31:18 [INFO]: Epoch 054 - training loss: 0.4385, validation loss: 0.2887
2024-06-02 21:31:28 [INFO]: Epoch 055 - training loss: 0.4393, validation loss: 0.2857
2024-06-02 21:31:38 [INFO]: Epoch 056 - training loss: 0.4377, validation loss: 0.2883
2024-06-02 21:31:48 [INFO]: Epoch 057 - training loss: 0.4389, validation loss: 0.2870
2024-06-02 21:31:58 [INFO]: Epoch 058 - training loss: 0.4364, validation loss: 0.2865
2024-06-02 21:32:08 [INFO]: Epoch 059 - training loss: 0.4367, validation loss: 0.2863
2024-06-02 21:32:18 [INFO]: Epoch 060 - training loss: 0.4350, validation loss: 0.2875
2024-06-02 21:32:28 [INFO]: Epoch 061 - training loss: 0.4340, validation loss: 0.2851
2024-06-02 21:32:37 [INFO]: Epoch 062 - training loss: 0.4340, validation loss: 0.2854
2024-06-02 21:32:47 [INFO]: Epoch 063 - training loss: 0.4348, validation loss: 0.2859
2024-06-02 21:32:57 [INFO]: Epoch 064 - training loss: 0.4340, validation loss: 0.2860
2024-06-02 21:33:07 [INFO]: Epoch 065 - training loss: 0.4329, validation loss: 0.2854
2024-06-02 21:33:17 [INFO]: Epoch 066 - training loss: 0.4342, validation loss: 0.2868
2024-06-02 21:33:26 [INFO]: Epoch 067 - training loss: 0.4307, validation loss: 0.2847
2024-06-02 21:33:36 [INFO]: Epoch 068 - training loss: 0.4325, validation loss: 0.2829
2024-06-02 21:33:46 [INFO]: Epoch 069 - training loss: 0.4323, validation loss: 0.2834
2024-06-02 21:33:56 [INFO]: Epoch 070 - training loss: 0.4313, validation loss: 0.2826
2024-06-02 21:34:06 [INFO]: Epoch 071 - training loss: 0.4303, validation loss: 0.2811
2024-06-02 21:34:15 [INFO]: Epoch 072 - training loss: 0.4320, validation loss: 0.2824
2024-06-02 21:34:25 [INFO]: Epoch 073 - training loss: 0.4299, validation loss: 0.2824
2024-06-02 21:34:35 [INFO]: Epoch 074 - training loss: 0.4295, validation loss: 0.2801
2024-06-02 21:34:45 [INFO]: Epoch 075 - training loss: 0.4288, validation loss: 0.2794
2024-06-02 21:34:54 [INFO]: Epoch 076 - training loss: 0.4288, validation loss: 0.2795
2024-06-02 21:35:04 [INFO]: Epoch 077 - training loss: 0.4275, validation loss: 0.2780
2024-06-02 21:35:14 [INFO]: Epoch 078 - training loss: 0.4256, validation loss: 0.2807
2024-06-02 21:35:23 [INFO]: Epoch 079 - training loss: 0.4274, validation loss: 0.2813
2024-06-02 21:35:33 [INFO]: Epoch 080 - training loss: 0.4262, validation loss: 0.2786
2024-06-02 21:35:43 [INFO]: Epoch 081 - training loss: 0.4262, validation loss: 0.2781
2024-06-02 21:35:53 [INFO]: Epoch 082 - training loss: 0.4244, validation loss: 0.2778
2024-06-02 21:36:03 [INFO]: Epoch 083 - training loss: 0.4253, validation loss: 0.2782
2024-06-02 21:36:13 [INFO]: Epoch 084 - training loss: 0.4251, validation loss: 0.2767
2024-06-02 21:36:23 [INFO]: Epoch 085 - training loss: 0.4243, validation loss: 0.2777
2024-06-02 21:36:33 [INFO]: Epoch 086 - training loss: 0.4251, validation loss: 0.2771
2024-06-02 21:36:42 [INFO]: Epoch 087 - training loss: 0.4256, validation loss: 0.2768
2024-06-02 21:36:52 [INFO]: Epoch 088 - training loss: 0.4224, validation loss: 0.2764
2024-06-02 21:37:02 [INFO]: Epoch 089 - training loss: 0.4205, validation loss: 0.2754
2024-06-02 21:37:11 [INFO]: Epoch 090 - training loss: 0.4229, validation loss: 0.2749
2024-06-02 21:37:21 [INFO]: Epoch 091 - training loss: 0.4208, validation loss: 0.2757
2024-06-02 21:37:31 [INFO]: Epoch 092 - training loss: 0.4212, validation loss: 0.2766
2024-06-02 21:37:41 [INFO]: Epoch 093 - training loss: 0.4207, validation loss: 0.2749
2024-06-02 21:37:50 [INFO]: Epoch 094 - training loss: 0.4201, validation loss: 0.2745
2024-06-02 21:38:00 [INFO]: Epoch 095 - training loss: 0.4205, validation loss: 0.2727
2024-06-02 21:38:10 [INFO]: Epoch 096 - training loss: 0.4206, validation loss: 0.2738
2024-06-02 21:38:20 [INFO]: Epoch 097 - training loss: 0.4177, validation loss: 0.2742
2024-06-02 21:38:30 [INFO]: Epoch 098 - training loss: 0.4191, validation loss: 0.2733
2024-06-02 21:38:40 [INFO]: Epoch 099 - training loss: 0.4195, validation loss: 0.2734
2024-06-02 21:38:49 [INFO]: Epoch 100 - training loss: 0.4182, validation loss: 0.2738
2024-06-02 21:38:49 [INFO]: Finished training. The best model is from epoch#95.
2024-06-02 21:38:49 [INFO]: Saved the model to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240602_T212228/ETSformer.pypots
2024-06-02 21:38:57 [INFO]: Successfully saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_1/imputation.pkl
2024-06-02 21:38:57 [INFO]: Round1 - ETSformer on BeijingAir: MAE=0.2546, MSE=0.2655, MRE=0.3466
2024-06-02 21:38:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 21:38:57 [INFO]: Using the given device: cuda:0
2024-06-02 21:38:57 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240602_T213857
2024-06-02 21:38:57 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240602_T213857/tensorboard
2024-06-02 21:38:57 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-02 21:39:07 [INFO]: Epoch 001 - training loss: 1.0637, validation loss: 0.6022
2024-06-02 21:39:17 [INFO]: Epoch 002 - training loss: 0.8818, validation loss: 0.4904
2024-06-02 21:39:26 [INFO]: Epoch 003 - training loss: 0.7144, validation loss: 0.4097
2024-06-02 21:39:36 [INFO]: Epoch 004 - training loss: 0.6555, validation loss: 0.3883
2024-06-02 21:39:46 [INFO]: Epoch 005 - training loss: 0.6239, validation loss: 0.3789
2024-06-02 21:39:56 [INFO]: Epoch 006 - training loss: 0.5995, validation loss: 0.3714
2024-06-02 21:40:05 [INFO]: Epoch 007 - training loss: 0.5825, validation loss: 0.3624
2024-06-02 21:40:15 [INFO]: Epoch 008 - training loss: 0.5697, validation loss: 0.3566
2024-06-02 21:40:25 [INFO]: Epoch 009 - training loss: 0.5558, validation loss: 0.3494
2024-06-02 21:40:35 [INFO]: Epoch 010 - training loss: 0.5466, validation loss: 0.3443
2024-06-02 21:40:44 [INFO]: Epoch 011 - training loss: 0.5361, validation loss: 0.3433
2024-06-02 21:40:54 [INFO]: Epoch 012 - training loss: 0.5275, validation loss: 0.3366
2024-06-02 21:41:04 [INFO]: Epoch 013 - training loss: 0.5211, validation loss: 0.3350
2024-06-02 21:41:13 [INFO]: Epoch 014 - training loss: 0.5153, validation loss: 0.3326
2024-06-02 21:41:23 [INFO]: Epoch 015 - training loss: 0.5093, validation loss: 0.3307
2024-06-02 21:41:33 [INFO]: Epoch 016 - training loss: 0.5039, validation loss: 0.3282
2024-06-02 21:41:43 [INFO]: Epoch 017 - training loss: 0.4995, validation loss: 0.3258
2024-06-02 21:41:53 [INFO]: Epoch 018 - training loss: 0.4942, validation loss: 0.3232
2024-06-02 21:42:03 [INFO]: Epoch 019 - training loss: 0.4916, validation loss: 0.3238
2024-06-02 21:42:12 [INFO]: Epoch 020 - training loss: 0.4876, validation loss: 0.3199
2024-06-02 21:42:22 [INFO]: Epoch 021 - training loss: 0.4835, validation loss: 0.3195
2024-06-02 21:42:32 [INFO]: Epoch 022 - training loss: 0.4832, validation loss: 0.3169
2024-06-02 21:42:42 [INFO]: Epoch 023 - training loss: 0.4790, validation loss: 0.3165
2024-06-02 21:42:51 [INFO]: Epoch 024 - training loss: 0.4766, validation loss: 0.3148
2024-06-02 21:43:01 [INFO]: Epoch 025 - training loss: 0.4752, validation loss: 0.3163
2024-06-02 21:43:11 [INFO]: Epoch 026 - training loss: 0.4716, validation loss: 0.3143
2024-06-02 21:43:21 [INFO]: Epoch 027 - training loss: 0.4701, validation loss: 0.3120
2024-06-02 21:43:30 [INFO]: Epoch 028 - training loss: 0.4684, validation loss: 0.3097
2024-06-02 21:43:40 [INFO]: Epoch 029 - training loss: 0.4656, validation loss: 0.3105
2024-06-02 21:43:50 [INFO]: Epoch 030 - training loss: 0.4636, validation loss: 0.3083
2024-06-02 21:43:59 [INFO]: Epoch 031 - training loss: 0.4633, validation loss: 0.3081
2024-06-02 21:44:09 [INFO]: Epoch 032 - training loss: 0.4601, validation loss: 0.3074
2024-06-02 21:44:19 [INFO]: Epoch 033 - training loss: 0.4588, validation loss: 0.3051
2024-06-02 21:44:28 [INFO]: Epoch 034 - training loss: 0.4575, validation loss: 0.3039
2024-06-02 21:44:38 [INFO]: Epoch 035 - training loss: 0.4569, validation loss: 0.3067
2024-06-02 21:44:48 [INFO]: Epoch 036 - training loss: 0.4552, validation loss: 0.3057
2024-06-02 21:44:58 [INFO]: Epoch 037 - training loss: 0.4559, validation loss: 0.3051
2024-06-02 21:45:08 [INFO]: Epoch 038 - training loss: 0.4552, validation loss: 0.3022
2024-06-02 21:45:18 [INFO]: Epoch 039 - training loss: 0.4526, validation loss: 0.3038
2024-06-02 21:45:27 [INFO]: Epoch 040 - training loss: 0.4530, validation loss: 0.3004
2024-06-02 21:45:37 [INFO]: Epoch 041 - training loss: 0.4512, validation loss: 0.3007
2024-06-02 21:45:47 [INFO]: Epoch 042 - training loss: 0.4511, validation loss: 0.2981
2024-06-02 21:45:57 [INFO]: Epoch 043 - training loss: 0.4473, validation loss: 0.2982
2024-06-02 21:46:06 [INFO]: Epoch 044 - training loss: 0.4493, validation loss: 0.2977
2024-06-02 21:46:16 [INFO]: Epoch 045 - training loss: 0.4484, validation loss: 0.2957
2024-06-02 21:46:26 [INFO]: Epoch 046 - training loss: 0.4468, validation loss: 0.2960
2024-06-02 21:46:36 [INFO]: Epoch 047 - training loss: 0.4437, validation loss: 0.2966
2024-06-02 21:46:46 [INFO]: Epoch 048 - training loss: 0.4450, validation loss: 0.2948
2024-06-02 21:46:56 [INFO]: Epoch 049 - training loss: 0.4436, validation loss: 0.2922
2024-06-02 21:47:05 [INFO]: Epoch 050 - training loss: 0.4453, validation loss: 0.2935
2024-06-02 21:47:15 [INFO]: Epoch 051 - training loss: 0.4406, validation loss: 0.2943
2024-06-02 21:47:25 [INFO]: Epoch 052 - training loss: 0.4436, validation loss: 0.2901
2024-06-02 21:47:35 [INFO]: Epoch 053 - training loss: 0.4418, validation loss: 0.2914
2024-06-02 21:47:45 [INFO]: Epoch 054 - training loss: 0.4417, validation loss: 0.2910
2024-06-02 21:47:54 [INFO]: Epoch 055 - training loss: 0.4390, validation loss: 0.2915
2024-06-02 21:48:04 [INFO]: Epoch 056 - training loss: 0.4362, validation loss: 0.2880
2024-06-02 21:48:13 [INFO]: Epoch 057 - training loss: 0.4401, validation loss: 0.2905
2024-06-02 21:48:23 [INFO]: Epoch 058 - training loss: 0.4371, validation loss: 0.2892
2024-06-02 21:48:33 [INFO]: Epoch 059 - training loss: 0.4361, validation loss: 0.2903
2024-06-02 21:48:42 [INFO]: Epoch 060 - training loss: 0.4346, validation loss: 0.2898
2024-06-02 21:48:52 [INFO]: Epoch 061 - training loss: 0.4359, validation loss: 0.2881
2024-06-02 21:49:02 [INFO]: Epoch 062 - training loss: 0.4356, validation loss: 0.2873
2024-06-02 21:49:11 [INFO]: Epoch 063 - training loss: 0.4348, validation loss: 0.2863
2024-06-02 21:49:21 [INFO]: Epoch 064 - training loss: 0.4325, validation loss: 0.2881
2024-06-02 21:49:31 [INFO]: Epoch 065 - training loss: 0.4338, validation loss: 0.2879
2024-06-02 21:49:41 [INFO]: Epoch 066 - training loss: 0.4317, validation loss: 0.2872
2024-06-02 21:49:50 [INFO]: Epoch 067 - training loss: 0.4314, validation loss: 0.2848
2024-06-02 21:50:00 [INFO]: Epoch 068 - training loss: 0.4325, validation loss: 0.2869
2024-06-02 21:50:10 [INFO]: Epoch 069 - training loss: 0.4305, validation loss: 0.2842
2024-06-02 21:50:19 [INFO]: Epoch 070 - training loss: 0.4297, validation loss: 0.2832
2024-06-02 21:50:29 [INFO]: Epoch 071 - training loss: 0.4299, validation loss: 0.2822
2024-06-02 21:50:39 [INFO]: Epoch 072 - training loss: 0.4297, validation loss: 0.2828
2024-06-02 21:50:48 [INFO]: Epoch 073 - training loss: 0.4282, validation loss: 0.2827
2024-06-02 21:50:58 [INFO]: Epoch 074 - training loss: 0.4276, validation loss: 0.2835
2024-06-02 21:51:08 [INFO]: Epoch 075 - training loss: 0.4277, validation loss: 0.2817
2024-06-02 21:51:18 [INFO]: Epoch 076 - training loss: 0.4273, validation loss: 0.2796
2024-06-02 21:51:28 [INFO]: Epoch 077 - training loss: 0.4264, validation loss: 0.2804
2024-06-02 21:51:37 [INFO]: Epoch 078 - training loss: 0.4256, validation loss: 0.2808
2024-06-02 21:51:47 [INFO]: Epoch 079 - training loss: 0.4258, validation loss: 0.2826
2024-06-02 21:51:57 [INFO]: Epoch 080 - training loss: 0.4250, validation loss: 0.2801
2024-06-02 21:52:06 [INFO]: Epoch 081 - training loss: 0.4241, validation loss: 0.2781
2024-06-02 21:52:16 [INFO]: Epoch 082 - training loss: 0.4243, validation loss: 0.2792
2024-06-02 21:52:26 [INFO]: Epoch 083 - training loss: 0.4238, validation loss: 0.2800
2024-06-02 21:52:35 [INFO]: Epoch 084 - training loss: 0.4242, validation loss: 0.2783
2024-06-02 21:52:45 [INFO]: Epoch 085 - training loss: 0.4229, validation loss: 0.2793
2024-06-02 21:52:55 [INFO]: Epoch 086 - training loss: 0.4233, validation loss: 0.2792
2024-06-02 21:53:04 [INFO]: Epoch 087 - training loss: 0.4222, validation loss: 0.2783
2024-06-02 21:53:14 [INFO]: Epoch 088 - training loss: 0.4246, validation loss: 0.2786
2024-06-02 21:53:24 [INFO]: Epoch 089 - training loss: 0.4223, validation loss: 0.2782
2024-06-02 21:53:34 [INFO]: Epoch 090 - training loss: 0.4212, validation loss: 0.2765
2024-06-02 21:53:44 [INFO]: Epoch 091 - training loss: 0.4217, validation loss: 0.2772
2024-06-02 21:53:53 [INFO]: Epoch 092 - training loss: 0.4225, validation loss: 0.2766
2024-06-02 21:54:03 [INFO]: Epoch 093 - training loss: 0.4223, validation loss: 0.2764
2024-06-02 21:54:13 [INFO]: Epoch 094 - training loss: 0.4212, validation loss: 0.2760
2024-06-02 21:54:22 [INFO]: Epoch 095 - training loss: 0.4193, validation loss: 0.2755
2024-06-02 21:54:32 [INFO]: Epoch 096 - training loss: 0.4184, validation loss: 0.2748
2024-06-02 21:54:42 [INFO]: Epoch 097 - training loss: 0.4176, validation loss: 0.2753
2024-06-02 21:54:51 [INFO]: Epoch 098 - training loss: 0.4178, validation loss: 0.2762
2024-06-02 21:54:59 [INFO]: Epoch 099 - training loss: 0.4187, validation loss: 0.2746
2024-06-02 21:55:09 [INFO]: Epoch 100 - training loss: 0.4178, validation loss: 0.2742
2024-06-02 21:55:09 [INFO]: Finished training. The best model is from epoch#100.
2024-06-02 21:55:09 [INFO]: Saved the model to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240602_T213857/ETSformer.pypots
2024-06-02 21:55:17 [INFO]: Successfully saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_2/imputation.pkl
2024-06-02 21:55:17 [INFO]: Round2 - ETSformer on BeijingAir: MAE=0.2559, MSE=0.2670, MRE=0.3484
2024-06-02 21:55:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 21:55:17 [INFO]: Using the given device: cuda:0
2024-06-02 21:55:17 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240602_T215517
2024-06-02 21:55:17 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240602_T215517/tensorboard
2024-06-02 21:55:17 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-02 21:55:27 [INFO]: Epoch 001 - training loss: 1.0867, validation loss: 0.6046
2024-06-02 21:55:37 [INFO]: Epoch 002 - training loss: 0.9176, validation loss: 0.5340
2024-06-02 21:55:47 [INFO]: Epoch 003 - training loss: 0.7683, validation loss: 0.4315
2024-06-02 21:55:56 [INFO]: Epoch 004 - training loss: 0.6780, validation loss: 0.4001
2024-06-02 21:56:06 [INFO]: Epoch 005 - training loss: 0.6393, validation loss: 0.3845
2024-06-02 21:56:16 [INFO]: Epoch 006 - training loss: 0.6136, validation loss: 0.3726
2024-06-02 21:56:25 [INFO]: Epoch 007 - training loss: 0.5984, validation loss: 0.3672
2024-06-02 21:56:35 [INFO]: Epoch 008 - training loss: 0.5828, validation loss: 0.3632
2024-06-02 21:56:45 [INFO]: Epoch 009 - training loss: 0.5684, validation loss: 0.3616
2024-06-02 21:56:55 [INFO]: Epoch 010 - training loss: 0.5610, validation loss: 0.3518
2024-06-02 21:57:05 [INFO]: Epoch 011 - training loss: 0.5489, validation loss: 0.3505
2024-06-02 21:57:14 [INFO]: Epoch 012 - training loss: 0.5406, validation loss: 0.3474
2024-06-02 21:57:24 [INFO]: Epoch 013 - training loss: 0.5337, validation loss: 0.3438
2024-06-02 21:57:34 [INFO]: Epoch 014 - training loss: 0.5284, validation loss: 0.3418
2024-06-02 21:57:44 [INFO]: Epoch 015 - training loss: 0.5229, validation loss: 0.3411
2024-06-02 21:57:54 [INFO]: Epoch 016 - training loss: 0.5155, validation loss: 0.3364
2024-06-02 21:58:03 [INFO]: Epoch 017 - training loss: 0.5123, validation loss: 0.3360
2024-06-02 21:58:13 [INFO]: Epoch 018 - training loss: 0.5073, validation loss: 0.3326
2024-06-02 21:58:22 [INFO]: Epoch 019 - training loss: 0.5038, validation loss: 0.3332
2024-06-02 21:58:32 [INFO]: Epoch 020 - training loss: 0.4999, validation loss: 0.3311
2024-06-02 21:58:42 [INFO]: Epoch 021 - training loss: 0.4953, validation loss: 0.3292
2024-06-02 21:58:52 [INFO]: Epoch 022 - training loss: 0.4946, validation loss: 0.3309
2024-06-02 21:59:01 [INFO]: Epoch 023 - training loss: 0.4912, validation loss: 0.3294
2024-06-02 21:59:11 [INFO]: Epoch 024 - training loss: 0.4879, validation loss: 0.3284
2024-06-02 21:59:20 [INFO]: Epoch 025 - training loss: 0.4882, validation loss: 0.3265
2024-06-02 21:59:30 [INFO]: Epoch 026 - training loss: 0.4853, validation loss: 0.3256
2024-06-02 21:59:40 [INFO]: Epoch 027 - training loss: 0.4800, validation loss: 0.3245
2024-06-02 21:59:50 [INFO]: Epoch 028 - training loss: 0.4800, validation loss: 0.3244
2024-06-02 22:00:00 [INFO]: Epoch 029 - training loss: 0.4777, validation loss: 0.3217
2024-06-02 22:00:10 [INFO]: Epoch 030 - training loss: 0.4749, validation loss: 0.3219
2024-06-02 22:00:19 [INFO]: Epoch 031 - training loss: 0.4769, validation loss: 0.3229
2024-06-02 22:00:29 [INFO]: Epoch 032 - training loss: 0.4739, validation loss: 0.3194
2024-06-02 22:00:38 [INFO]: Epoch 033 - training loss: 0.4693, validation loss: 0.3186
2024-06-02 22:00:48 [INFO]: Epoch 034 - training loss: 0.4691, validation loss: 0.3190
2024-06-02 22:00:58 [INFO]: Epoch 035 - training loss: 0.4665, validation loss: 0.3178
2024-06-02 22:01:07 [INFO]: Epoch 036 - training loss: 0.4649, validation loss: 0.3171
2024-06-02 22:01:17 [INFO]: Epoch 037 - training loss: 0.4639, validation loss: 0.3172
2024-06-02 22:01:27 [INFO]: Epoch 038 - training loss: 0.4613, validation loss: 0.3150
2024-06-02 22:01:37 [INFO]: Epoch 039 - training loss: 0.4621, validation loss: 0.3133
2024-06-02 22:01:47 [INFO]: Epoch 040 - training loss: 0.4619, validation loss: 0.3138
2024-06-02 22:01:56 [INFO]: Epoch 041 - training loss: 0.4584, validation loss: 0.3139
2024-06-02 22:02:06 [INFO]: Epoch 042 - training loss: 0.4594, validation loss: 0.3116
2024-06-02 22:02:16 [INFO]: Epoch 043 - training loss: 0.4562, validation loss: 0.3121
2024-06-02 22:02:26 [INFO]: Epoch 044 - training loss: 0.4560, validation loss: 0.3140
2024-06-02 22:02:36 [INFO]: Epoch 045 - training loss: 0.4545, validation loss: 0.3101
2024-06-02 22:02:46 [INFO]: Epoch 046 - training loss: 0.4541, validation loss: 0.3100
2024-06-02 22:02:55 [INFO]: Epoch 047 - training loss: 0.4538, validation loss: 0.3085
2024-06-02 22:03:05 [INFO]: Epoch 048 - training loss: 0.4531, validation loss: 0.3081
2024-06-02 22:03:15 [INFO]: Epoch 049 - training loss: 0.4520, validation loss: 0.3089
2024-06-02 22:03:25 [INFO]: Epoch 050 - training loss: 0.4503, validation loss: 0.3077
2024-06-02 22:03:34 [INFO]: Epoch 051 - training loss: 0.4488, validation loss: 0.3077
2024-06-02 22:03:44 [INFO]: Epoch 052 - training loss: 0.4502, validation loss: 0.3059
2024-06-02 22:03:54 [INFO]: Epoch 053 - training loss: 0.4480, validation loss: 0.3065
2024-06-02 22:04:03 [INFO]: Epoch 054 - training loss: 0.4495, validation loss: 0.3057
2024-06-02 22:04:13 [INFO]: Epoch 055 - training loss: 0.4471, validation loss: 0.3030
2024-06-02 22:04:23 [INFO]: Epoch 056 - training loss: 0.4486, validation loss: 0.3015
2024-06-02 22:04:32 [INFO]: Epoch 057 - training loss: 0.4461, validation loss: 0.3029
2024-06-02 22:04:42 [INFO]: Epoch 058 - training loss: 0.4456, validation loss: 0.3026
2024-06-02 22:04:52 [INFO]: Epoch 059 - training loss: 0.4443, validation loss: 0.3023
2024-06-02 22:05:02 [INFO]: Epoch 060 - training loss: 0.4445, validation loss: 0.3030
2024-06-02 22:05:12 [INFO]: Epoch 061 - training loss: 0.4431, validation loss: 0.3018
2024-06-02 22:05:21 [INFO]: Epoch 062 - training loss: 0.4431, validation loss: 0.3023
2024-06-02 22:05:31 [INFO]: Epoch 063 - training loss: 0.4428, validation loss: 0.3005
2024-06-02 22:05:40 [INFO]: Epoch 064 - training loss: 0.4409, validation loss: 0.3048
2024-06-02 22:05:49 [INFO]: Epoch 065 - training loss: 0.4411, validation loss: 0.3001
2024-06-02 22:05:59 [INFO]: Epoch 066 - training loss: 0.4405, validation loss: 0.3014
2024-06-02 22:06:09 [INFO]: Epoch 067 - training loss: 0.4401, validation loss: 0.2989
2024-06-02 22:06:19 [INFO]: Epoch 068 - training loss: 0.4397, validation loss: 0.3005
2024-06-02 22:06:29 [INFO]: Epoch 069 - training loss: 0.4400, validation loss: 0.2983
2024-06-02 22:06:39 [INFO]: Epoch 070 - training loss: 0.4394, validation loss: 0.2969
2024-06-02 22:06:48 [INFO]: Epoch 071 - training loss: 0.4372, validation loss: 0.2976
2024-06-02 22:06:58 [INFO]: Epoch 072 - training loss: 0.4372, validation loss: 0.2986
2024-06-02 22:07:08 [INFO]: Epoch 073 - training loss: 0.4362, validation loss: 0.2963
2024-06-02 22:07:17 [INFO]: Epoch 074 - training loss: 0.4367, validation loss: 0.2959
2024-06-02 22:07:27 [INFO]: Epoch 075 - training loss: 0.4371, validation loss: 0.2967
2024-06-02 22:07:36 [INFO]: Epoch 076 - training loss: 0.4365, validation loss: 0.2968
2024-06-02 22:07:46 [INFO]: Epoch 077 - training loss: 0.4353, validation loss: 0.2969
2024-06-02 22:07:56 [INFO]: Epoch 078 - training loss: 0.4351, validation loss: 0.2933
2024-06-02 22:08:06 [INFO]: Epoch 079 - training loss: 0.4343, validation loss: 0.2969
2024-06-02 22:08:16 [INFO]: Epoch 080 - training loss: 0.4329, validation loss: 0.2936
2024-06-02 22:08:25 [INFO]: Epoch 081 - training loss: 0.4321, validation loss: 0.2960
2024-06-02 22:08:35 [INFO]: Epoch 082 - training loss: 0.4327, validation loss: 0.2940
2024-06-02 22:08:44 [INFO]: Epoch 083 - training loss: 0.4310, validation loss: 0.2934
2024-06-02 22:08:54 [INFO]: Epoch 084 - training loss: 0.4332, validation loss: 0.2943
2024-06-02 22:09:04 [INFO]: Epoch 085 - training loss: 0.4306, validation loss: 0.2934
2024-06-02 22:09:13 [INFO]: Epoch 086 - training loss: 0.4316, validation loss: 0.2938
2024-06-02 22:09:23 [INFO]: Epoch 087 - training loss: 0.4298, validation loss: 0.2930
2024-06-02 22:09:33 [INFO]: Epoch 088 - training loss: 0.4308, validation loss: 0.2914
2024-06-02 22:09:43 [INFO]: Epoch 089 - training loss: 0.4300, validation loss: 0.2927
2024-06-02 22:09:52 [INFO]: Epoch 090 - training loss: 0.4310, validation loss: 0.2924
2024-06-02 22:10:02 [INFO]: Epoch 091 - training loss: 0.4273, validation loss: 0.2921
2024-06-02 22:10:12 [INFO]: Epoch 092 - training loss: 0.4297, validation loss: 0.2919
2024-06-02 22:10:21 [INFO]: Epoch 093 - training loss: 0.4288, validation loss: 0.2904
2024-06-02 22:10:31 [INFO]: Epoch 094 - training loss: 0.4307, validation loss: 0.2899
2024-06-02 22:10:41 [INFO]: Epoch 095 - training loss: 0.4271, validation loss: 0.2918
2024-06-02 22:10:50 [INFO]: Epoch 096 - training loss: 0.4257, validation loss: 0.2909
2024-06-02 22:11:01 [INFO]: Epoch 097 - training loss: 0.4278, validation loss: 0.2897
2024-06-02 22:11:10 [INFO]: Epoch 098 - training loss: 0.4264, validation loss: 0.2894
2024-06-02 22:11:20 [INFO]: Epoch 099 - training loss: 0.4261, validation loss: 0.2894
2024-06-02 22:11:30 [INFO]: Epoch 100 - training loss: 0.4260, validation loss: 0.2899
2024-06-02 22:11:30 [INFO]: Finished training. The best model is from epoch#98.
2024-06-02 22:11:30 [INFO]: Saved the model to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240602_T215517/ETSformer.pypots
2024-06-02 22:11:37 [INFO]: Successfully saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_3/imputation.pkl
2024-06-02 22:11:37 [INFO]: Round3 - ETSformer on BeijingAir: MAE=0.2637, MSE=0.2814, MRE=0.3589
2024-06-02 22:11:37 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 22:11:37 [INFO]: Using the given device: cuda:0
2024-06-02 22:11:37 [INFO]: Model files will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240602_T221137
2024-06-02 22:11:37 [INFO]: Tensorboard file will be saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240602_T221137/tensorboard
2024-06-02 22:11:38 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-02 22:11:48 [INFO]: Epoch 001 - training loss: 1.0744, validation loss: 0.6104
2024-06-02 22:11:57 [INFO]: Epoch 002 - training loss: 0.9060, validation loss: 0.5210
2024-06-02 22:12:07 [INFO]: Epoch 003 - training loss: 0.7417, validation loss: 0.4252
2024-06-02 22:12:17 [INFO]: Epoch 004 - training loss: 0.6671, validation loss: 0.3984
2024-06-02 22:12:27 [INFO]: Epoch 005 - training loss: 0.6290, validation loss: 0.3862
2024-06-02 22:12:37 [INFO]: Epoch 006 - training loss: 0.6073, validation loss: 0.3769
2024-06-02 22:12:47 [INFO]: Epoch 007 - training loss: 0.5880, validation loss: 0.3672
2024-06-02 22:12:57 [INFO]: Epoch 008 - training loss: 0.5683, validation loss: 0.3593
2024-06-02 22:13:06 [INFO]: Epoch 009 - training loss: 0.5577, validation loss: 0.3551
2024-06-02 22:13:16 [INFO]: Epoch 010 - training loss: 0.5476, validation loss: 0.3498
2024-06-02 22:13:25 [INFO]: Epoch 011 - training loss: 0.5364, validation loss: 0.3468
2024-06-02 22:13:35 [INFO]: Epoch 012 - training loss: 0.5273, validation loss: 0.3419
2024-06-02 22:13:45 [INFO]: Epoch 013 - training loss: 0.5185, validation loss: 0.3372
2024-06-02 22:13:55 [INFO]: Epoch 014 - training loss: 0.5109, validation loss: 0.3335
2024-06-02 22:14:04 [INFO]: Epoch 015 - training loss: 0.5070, validation loss: 0.3318
2024-06-02 22:14:14 [INFO]: Epoch 016 - training loss: 0.4990, validation loss: 0.3293
2024-06-02 22:14:24 [INFO]: Epoch 017 - training loss: 0.4956, validation loss: 0.3268
2024-06-02 22:14:33 [INFO]: Epoch 018 - training loss: 0.4920, validation loss: 0.3245
2024-06-02 22:14:43 [INFO]: Epoch 019 - training loss: 0.4904, validation loss: 0.3232
2024-06-02 22:14:53 [INFO]: Epoch 020 - training loss: 0.4855, validation loss: 0.3201
2024-06-02 22:15:03 [INFO]: Epoch 021 - training loss: 0.4795, validation loss: 0.3185
2024-06-02 22:15:13 [INFO]: Epoch 022 - training loss: 0.4767, validation loss: 0.3168
2024-06-02 22:15:23 [INFO]: Epoch 023 - training loss: 0.4760, validation loss: 0.3151
2024-06-02 22:15:32 [INFO]: Epoch 024 - training loss: 0.4728, validation loss: 0.3143
2024-06-02 22:15:42 [INFO]: Epoch 025 - training loss: 0.4701, validation loss: 0.3129
2024-06-02 22:15:52 [INFO]: Epoch 026 - training loss: 0.4672, validation loss: 0.3113
2024-06-02 22:16:02 [INFO]: Epoch 027 - training loss: 0.4652, validation loss: 0.3097
2024-06-02 22:16:12 [INFO]: Epoch 028 - training loss: 0.4659, validation loss: 0.3090
2024-06-02 22:16:22 [INFO]: Epoch 029 - training loss: 0.4639, validation loss: 0.3067
2024-06-02 22:16:31 [INFO]: Epoch 030 - training loss: 0.4608, validation loss: 0.3076
2024-06-02 22:16:41 [INFO]: Epoch 031 - training loss: 0.4604, validation loss: 0.3073
2024-06-02 22:16:51 [INFO]: Epoch 032 - training loss: 0.4587, validation loss: 0.3032
2024-06-02 22:17:00 [INFO]: Epoch 033 - training loss: 0.4569, validation loss: 0.3037
2024-06-02 22:17:10 [INFO]: Epoch 034 - training loss: 0.4559, validation loss: 0.3027
2024-06-02 22:17:20 [INFO]: Epoch 035 - training loss: 0.4546, validation loss: 0.3021
2024-06-02 22:17:30 [INFO]: Epoch 036 - training loss: 0.4529, validation loss: 0.3011
2024-06-02 22:17:39 [INFO]: Epoch 037 - training loss: 0.4527, validation loss: 0.3025
2024-06-02 22:17:49 [INFO]: Epoch 038 - training loss: 0.4502, validation loss: 0.2993
2024-06-02 22:17:58 [INFO]: Epoch 039 - training loss: 0.4491, validation loss: 0.2987
2024-06-02 22:18:08 [INFO]: Epoch 040 - training loss: 0.4482, validation loss: 0.2983
2024-06-02 22:18:18 [INFO]: Epoch 041 - training loss: 0.4478, validation loss: 0.2964
2024-06-02 22:18:28 [INFO]: Epoch 042 - training loss: 0.4468, validation loss: 0.2958
2024-06-02 22:18:38 [INFO]: Epoch 043 - training loss: 0.4493, validation loss: 0.2974
2024-06-02 22:18:47 [INFO]: Epoch 044 - training loss: 0.4446, validation loss: 0.2963
2024-06-02 22:18:57 [INFO]: Epoch 045 - training loss: 0.4453, validation loss: 0.2952
2024-06-02 22:19:06 [INFO]: Epoch 046 - training loss: 0.4455, validation loss: 0.2947
2024-06-02 22:19:16 [INFO]: Epoch 047 - training loss: 0.4429, validation loss: 0.2930
2024-06-02 22:19:26 [INFO]: Epoch 048 - training loss: 0.4431, validation loss: 0.2918
2024-06-02 22:19:35 [INFO]: Epoch 049 - training loss: 0.4422, validation loss: 0.2914
2024-06-02 22:19:45 [INFO]: Epoch 050 - training loss: 0.4412, validation loss: 0.2909
2024-06-02 22:19:55 [INFO]: Epoch 051 - training loss: 0.4410, validation loss: 0.2915
2024-06-02 22:20:04 [INFO]: Epoch 052 - training loss: 0.4401, validation loss: 0.2912
2024-06-02 22:20:14 [INFO]: Epoch 053 - training loss: 0.4400, validation loss: 0.2901
2024-06-02 22:20:24 [INFO]: Epoch 054 - training loss: 0.4377, validation loss: 0.2902
2024-06-02 22:20:34 [INFO]: Epoch 055 - training loss: 0.4398, validation loss: 0.2881
2024-06-02 22:20:43 [INFO]: Epoch 056 - training loss: 0.4383, validation loss: 0.2866
2024-06-02 22:20:53 [INFO]: Epoch 057 - training loss: 0.4369, validation loss: 0.2895
2024-06-02 22:21:03 [INFO]: Epoch 058 - training loss: 0.4370, validation loss: 0.2877
2024-06-02 22:21:13 [INFO]: Epoch 059 - training loss: 0.4356, validation loss: 0.2874
2024-06-02 22:21:22 [INFO]: Epoch 060 - training loss: 0.4378, validation loss: 0.2875
2024-06-02 22:21:32 [INFO]: Epoch 061 - training loss: 0.4362, validation loss: 0.2861
2024-06-02 22:21:42 [INFO]: Epoch 062 - training loss: 0.4357, validation loss: 0.2858
2024-06-02 22:21:52 [INFO]: Epoch 063 - training loss: 0.4354, validation loss: 0.2868
2024-06-02 22:22:01 [INFO]: Epoch 064 - training loss: 0.4345, validation loss: 0.2856
2024-06-02 22:22:11 [INFO]: Epoch 065 - training loss: 0.4328, validation loss: 0.2835
2024-06-02 22:22:20 [INFO]: Epoch 066 - training loss: 0.4324, validation loss: 0.2836
2024-06-02 22:22:30 [INFO]: Epoch 067 - training loss: 0.4326, validation loss: 0.2847
2024-06-02 22:22:40 [INFO]: Epoch 068 - training loss: 0.4301, validation loss: 0.2840
2024-06-02 22:22:50 [INFO]: Epoch 069 - training loss: 0.4327, validation loss: 0.2830
2024-06-02 22:22:59 [INFO]: Epoch 070 - training loss: 0.4311, validation loss: 0.2814
2024-06-02 22:23:09 [INFO]: Epoch 071 - training loss: 0.4301, validation loss: 0.2802
2024-06-02 22:23:19 [INFO]: Epoch 072 - training loss: 0.4292, validation loss: 0.2819
2024-06-02 22:23:29 [INFO]: Epoch 073 - training loss: 0.4302, validation loss: 0.2813
2024-06-02 22:23:38 [INFO]: Epoch 074 - training loss: 0.4289, validation loss: 0.2812
2024-06-02 22:23:48 [INFO]: Epoch 075 - training loss: 0.4305, validation loss: 0.2791
2024-06-02 22:23:58 [INFO]: Epoch 076 - training loss: 0.4287, validation loss: 0.2795
2024-06-02 22:24:08 [INFO]: Epoch 077 - training loss: 0.4275, validation loss: 0.2804
2024-06-02 22:24:18 [INFO]: Epoch 078 - training loss: 0.4278, validation loss: 0.2813
2024-06-02 22:24:28 [INFO]: Epoch 079 - training loss: 0.4283, validation loss: 0.2788
2024-06-02 22:24:38 [INFO]: Epoch 080 - training loss: 0.4274, validation loss: 0.2798
2024-06-02 22:24:47 [INFO]: Epoch 081 - training loss: 0.4281, validation loss: 0.2797
2024-06-02 22:24:57 [INFO]: Epoch 082 - training loss: 0.4265, validation loss: 0.2800
2024-06-02 22:25:07 [INFO]: Epoch 083 - training loss: 0.4268, validation loss: 0.2778
2024-06-02 22:25:17 [INFO]: Epoch 084 - training loss: 0.4245, validation loss: 0.2763
2024-06-02 22:25:26 [INFO]: Epoch 085 - training loss: 0.4261, validation loss: 0.2778
2024-06-02 22:25:36 [INFO]: Epoch 086 - training loss: 0.4262, validation loss: 0.2781
2024-06-02 22:25:46 [INFO]: Epoch 087 - training loss: 0.4246, validation loss: 0.2772
2024-06-02 22:25:56 [INFO]: Epoch 088 - training loss: 0.4251, validation loss: 0.2771
2024-06-02 22:26:06 [INFO]: Epoch 089 - training loss: 0.4235, validation loss: 0.2776
2024-06-02 22:26:16 [INFO]: Epoch 090 - training loss: 0.4246, validation loss: 0.2764
2024-06-02 22:26:26 [INFO]: Epoch 091 - training loss: 0.4244, validation loss: 0.2755
2024-06-02 22:26:35 [INFO]: Epoch 092 - training loss: 0.4246, validation loss: 0.2767
2024-06-02 22:26:45 [INFO]: Epoch 093 - training loss: 0.4259, validation loss: 0.2757
2024-06-02 22:26:55 [INFO]: Epoch 094 - training loss: 0.4240, validation loss: 0.2761
2024-06-02 22:27:04 [INFO]: Epoch 095 - training loss: 0.4234, validation loss: 0.2757
2024-06-02 22:27:14 [INFO]: Epoch 096 - training loss: 0.4218, validation loss: 0.2758
2024-06-02 22:27:24 [INFO]: Epoch 097 - training loss: 0.4220, validation loss: 0.2754
2024-06-02 22:27:34 [INFO]: Epoch 098 - training loss: 0.4212, validation loss: 0.2750
2024-06-02 22:27:43 [INFO]: Epoch 099 - training loss: 0.4221, validation loss: 0.2738
2024-06-02 22:27:53 [INFO]: Epoch 100 - training loss: 0.4229, validation loss: 0.2752
2024-06-02 22:27:53 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 22:27:53 [INFO]: Saved the model to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240602_T221137/ETSformer.pypots
2024-06-02 22:28:01 [INFO]: Successfully saved to results_point_rate05/BeijingAir/ETSformer_BeijingAir/round_4/imputation.pkl
2024-06-02 22:28:01 [INFO]: Round4 - ETSformer on BeijingAir: MAE=0.2552, MSE=0.2681, MRE=0.3474
2024-06-02 22:28:01 [INFO]: Done! Final results:
Averaged ETSformer (7,928,510 params) on BeijingAir: MAE=0.2494 ± 0.003931434653866799, MSE=0.2614 ± 0.008544014614346949, MRE=0.3306 ± 0.0052108513231017735, average inference time=1.62