2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:04 [INFO]: Model files will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_0/20240604_T025904
2024-06-04 02:59:04 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_0/20240604_T025904/tensorboard
2024-06-04 02:59:05 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-04 02:59:26 [INFO]: Epoch 001 - training loss: 0.9511, validation loss: 2.0086
2024-06-04 02:59:41 [INFO]: Epoch 002 - training loss: 0.6939, validation loss: 1.9540
2024-06-04 02:59:57 [INFO]: Epoch 003 - training loss: 0.6309, validation loss: 1.9350
2024-06-04 03:00:13 [INFO]: Epoch 004 - training loss: 0.6054, validation loss: 1.9263
2024-06-04 03:00:29 [INFO]: Epoch 005 - training loss: 0.5856, validation loss: 1.9108
2024-06-04 03:00:45 [INFO]: Epoch 006 - training loss: 0.5714, validation loss: 1.9063
2024-06-04 03:01:01 [INFO]: Epoch 007 - training loss: 0.5607, validation loss: 1.8994
2024-06-04 03:01:18 [INFO]: Epoch 008 - training loss: 0.5510, validation loss: 1.8917
2024-06-04 03:01:34 [INFO]: Epoch 009 - training loss: 0.5418, validation loss: 1.8786
2024-06-04 03:01:51 [INFO]: Epoch 010 - training loss: 0.5339, validation loss: 1.8770
2024-06-04 03:02:07 [INFO]: Epoch 011 - training loss: 0.5264, validation loss: 1.8616
2024-06-04 03:02:24 [INFO]: Epoch 012 - training loss: 0.5208, validation loss: 1.8490
2024-06-04 03:02:40 [INFO]: Epoch 013 - training loss: 0.5139, validation loss: 1.8471
2024-06-04 03:02:57 [INFO]: Epoch 014 - training loss: 0.5086, validation loss: 1.8389
2024-06-04 03:03:13 [INFO]: Epoch 015 - training loss: 0.5056, validation loss: 1.8267
2024-06-04 03:03:28 [INFO]: Epoch 016 - training loss: 0.5005, validation loss: 1.8217
2024-06-04 03:03:44 [INFO]: Epoch 017 - training loss: 0.4964, validation loss: 1.8132
2024-06-04 03:03:59 [INFO]: Epoch 018 - training loss: 0.4928, validation loss: 1.8053
2024-06-04 03:04:15 [INFO]: Epoch 019 - training loss: 0.4880, validation loss: 1.7950
2024-06-04 03:04:32 [INFO]: Epoch 020 - training loss: 0.4854, validation loss: 1.7940
2024-06-04 03:04:48 [INFO]: Epoch 021 - training loss: 0.4824, validation loss: 1.7864
2024-06-04 03:05:05 [INFO]: Epoch 022 - training loss: 0.4790, validation loss: 1.7803
2024-06-04 03:05:22 [INFO]: Epoch 023 - training loss: 0.4761, validation loss: 1.7736
2024-06-04 03:05:38 [INFO]: Epoch 024 - training loss: 0.4727, validation loss: 1.7638
2024-06-04 03:05:55 [INFO]: Epoch 025 - training loss: 0.4712, validation loss: 1.7606
2024-06-04 03:06:11 [INFO]: Epoch 026 - training loss: 0.4689, validation loss: 1.7556
2024-06-04 03:06:28 [INFO]: Epoch 027 - training loss: 0.4671, validation loss: 1.7473
2024-06-04 03:06:44 [INFO]: Epoch 028 - training loss: 0.4653, validation loss: 1.7417
2024-06-04 03:07:00 [INFO]: Epoch 029 - training loss: 0.4639, validation loss: 1.7434
2024-06-04 03:07:16 [INFO]: Epoch 030 - training loss: 0.4617, validation loss: 1.7397
2024-06-04 03:07:31 [INFO]: Epoch 031 - training loss: 0.4601, validation loss: 1.7329
2024-06-04 03:07:46 [INFO]: Epoch 032 - training loss: 0.4583, validation loss: 1.7287
2024-06-04 03:08:01 [INFO]: Epoch 033 - training loss: 0.4565, validation loss: 1.7285
2024-06-04 03:08:17 [INFO]: Epoch 034 - training loss: 0.4548, validation loss: 1.7250
2024-06-04 03:08:34 [INFO]: Epoch 035 - training loss: 0.4537, validation loss: 1.7203
2024-06-04 03:08:48 [INFO]: Epoch 036 - training loss: 0.4521, validation loss: 1.7176
2024-06-04 03:09:02 [INFO]: Epoch 037 - training loss: 0.4509, validation loss: 1.7078
2024-06-04 03:09:16 [INFO]: Epoch 038 - training loss: 0.4500, validation loss: 1.7063
2024-06-04 03:09:31 [INFO]: Epoch 039 - training loss: 0.4489, validation loss: 1.7014
2024-06-04 03:09:45 [INFO]: Epoch 040 - training loss: 0.4479, validation loss: 1.7007
2024-06-04 03:09:59 [INFO]: Epoch 041 - training loss: 0.4466, validation loss: 1.6989
2024-06-04 03:10:14 [INFO]: Epoch 042 - training loss: 0.4452, validation loss: 1.6944
2024-06-04 03:10:28 [INFO]: Epoch 043 - training loss: 0.4452, validation loss: 1.6894
2024-06-04 03:10:42 [INFO]: Epoch 044 - training loss: 0.4438, validation loss: 1.6964
2024-06-04 03:10:56 [INFO]: Epoch 045 - training loss: 0.4428, validation loss: 1.6903
2024-06-04 03:11:11 [INFO]: Epoch 046 - training loss: 0.4425, validation loss: 1.6879
2024-06-04 03:11:24 [INFO]: Epoch 047 - training loss: 0.4408, validation loss: 1.6853
2024-06-04 03:11:37 [INFO]: Epoch 048 - training loss: 0.4403, validation loss: 1.6840
2024-06-04 03:11:51 [INFO]: Epoch 049 - training loss: 0.4394, validation loss: 1.6814
2024-06-04 03:12:05 [INFO]: Epoch 050 - training loss: 0.4392, validation loss: 1.6816
2024-06-04 03:12:19 [INFO]: Epoch 051 - training loss: 0.4389, validation loss: 1.6758
2024-06-04 03:12:34 [INFO]: Epoch 052 - training loss: 0.4385, validation loss: 1.6672
2024-06-04 03:12:48 [INFO]: Epoch 053 - training loss: 0.4376, validation loss: 1.6695
2024-06-04 03:13:02 [INFO]: Epoch 054 - training loss: 0.4361, validation loss: 1.6694
2024-06-04 03:13:17 [INFO]: Epoch 055 - training loss: 0.4352, validation loss: 1.6692
2024-06-04 03:13:31 [INFO]: Epoch 056 - training loss: 0.4357, validation loss: 1.6620
2024-06-04 03:13:46 [INFO]: Epoch 057 - training loss: 0.4351, validation loss: 1.6591
2024-06-04 03:14:01 [INFO]: Epoch 058 - training loss: 0.4345, validation loss: 1.6644
2024-06-04 03:14:15 [INFO]: Epoch 059 - training loss: 0.4338, validation loss: 1.6547
2024-06-04 03:14:30 [INFO]: Epoch 060 - training loss: 0.4330, validation loss: 1.6556
2024-06-04 03:14:44 [INFO]: Epoch 061 - training loss: 0.4326, validation loss: 1.6557
2024-06-04 03:14:59 [INFO]: Epoch 062 - training loss: 0.4319, validation loss: 1.6531
2024-06-04 03:15:13 [INFO]: Epoch 063 - training loss: 0.4314, validation loss: 1.6436
2024-06-04 03:15:26 [INFO]: Epoch 064 - training loss: 0.4309, validation loss: 1.6399
2024-06-04 03:15:41 [INFO]: Epoch 065 - training loss: 0.4304, validation loss: 1.6427
2024-06-04 03:15:54 [INFO]: Epoch 066 - training loss: 0.4301, validation loss: 1.6435
2024-06-04 03:16:08 [INFO]: Epoch 067 - training loss: 0.4293, validation loss: 1.6437
2024-06-04 03:16:22 [INFO]: Epoch 068 - training loss: 0.4292, validation loss: 1.6423
2024-06-04 03:16:37 [INFO]: Epoch 069 - training loss: 0.4293, validation loss: 1.6398
2024-06-04 03:16:51 [INFO]: Epoch 070 - training loss: 0.4286, validation loss: 1.6379
2024-06-04 03:17:05 [INFO]: Epoch 071 - training loss: 0.4284, validation loss: 1.6323
2024-06-04 03:17:20 [INFO]: Epoch 072 - training loss: 0.4270, validation loss: 1.6358
2024-06-04 03:17:34 [INFO]: Epoch 073 - training loss: 0.4262, validation loss: 1.6359
2024-06-04 03:17:49 [INFO]: Epoch 074 - training loss: 0.4262, validation loss: 1.6321
2024-06-04 03:18:03 [INFO]: Epoch 075 - training loss: 0.4272, validation loss: 1.6338
2024-06-04 03:18:17 [INFO]: Epoch 076 - training loss: 0.4254, validation loss: 1.6293
2024-06-04 03:18:31 [INFO]: Epoch 077 - training loss: 0.4254, validation loss: 1.6264
2024-06-04 03:18:45 [INFO]: Epoch 078 - training loss: 0.4254, validation loss: 1.6301
2024-06-04 03:19:00 [INFO]: Epoch 079 - training loss: 0.4249, validation loss: 1.6217
2024-06-04 03:19:14 [INFO]: Epoch 080 - training loss: 0.4242, validation loss: 1.6260
2024-06-04 03:19:27 [INFO]: Epoch 081 - training loss: 0.4237, validation loss: 1.6245
2024-06-04 03:19:41 [INFO]: Epoch 082 - training loss: 0.4235, validation loss: 1.6251
2024-06-04 03:19:55 [INFO]: Epoch 083 - training loss: 0.4233, validation loss: 1.6269
2024-06-04 03:20:09 [INFO]: Epoch 084 - training loss: 0.4228, validation loss: 1.6219
2024-06-04 03:20:24 [INFO]: Epoch 085 - training loss: 0.4222, validation loss: 1.6250
2024-06-04 03:20:38 [INFO]: Epoch 086 - training loss: 0.4219, validation loss: 1.6278
2024-06-04 03:20:52 [INFO]: Epoch 087 - training loss: 0.4213, validation loss: 1.6190
2024-06-04 03:21:06 [INFO]: Epoch 088 - training loss: 0.4214, validation loss: 1.6194
2024-06-04 03:21:21 [INFO]: Epoch 089 - training loss: 0.4213, validation loss: 1.6163
2024-06-04 03:21:35 [INFO]: Epoch 090 - training loss: 0.4208, validation loss: 1.6159
2024-06-04 03:21:50 [INFO]: Epoch 091 - training loss: 0.4198, validation loss: 1.6169
2024-06-04 03:22:04 [INFO]: Epoch 092 - training loss: 0.4202, validation loss: 1.6192
2024-06-04 03:22:19 [INFO]: Epoch 093 - training loss: 0.4198, validation loss: 1.6161
2024-06-04 03:22:34 [INFO]: Epoch 094 - training loss: 0.4188, validation loss: 1.6173
2024-06-04 03:22:48 [INFO]: Epoch 095 - training loss: 0.4191, validation loss: 1.6169
2024-06-04 03:23:02 [INFO]: Epoch 096 - training loss: 0.4186, validation loss: 1.6135
2024-06-04 03:23:16 [INFO]: Epoch 097 - training loss: 0.4188, validation loss: 1.6119
2024-06-04 03:23:30 [INFO]: Epoch 098 - training loss: 0.4183, validation loss: 1.6106
2024-06-04 03:23:42 [INFO]: Epoch 099 - training loss: 0.4176, validation loss: 1.6103
2024-06-04 03:23:56 [INFO]: Epoch 100 - training loss: 0.4181, validation loss: 1.6140
2024-06-04 03:23:56 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 03:23:56 [INFO]: Saved the model to results_point_rate05/Electricity/ETSformer_Electricity/round_0/20240604_T025904/ETSformer.pypots
2024-06-04 03:24:07 [INFO]: Successfully saved to results_point_rate05/Electricity/ETSformer_Electricity/round_0/imputation.pkl
2024-06-04 03:24:07 [INFO]: Round0 - ETSformer on Electricity: MAE=0.8779, MSE=1.6930, MRE=0.4700
2024-06-04 03:24:07 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:24:07 [INFO]: Using the given device: cuda:0
2024-06-04 03:24:07 [INFO]: Model files will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_1/20240604_T032407
2024-06-04 03:24:07 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_1/20240604_T032407/tensorboard
2024-06-04 03:24:07 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-04 03:24:22 [INFO]: Epoch 001 - training loss: 0.9446, validation loss: 1.9466
2024-06-04 03:24:36 [INFO]: Epoch 002 - training loss: 0.6903, validation loss: 1.9219
2024-06-04 03:24:51 [INFO]: Epoch 003 - training loss: 0.6269, validation loss: 1.9026
2024-06-04 03:25:05 [INFO]: Epoch 004 - training loss: 0.6002, validation loss: 1.8993
2024-06-04 03:25:20 [INFO]: Epoch 005 - training loss: 0.5820, validation loss: 1.8825
2024-06-04 03:25:35 [INFO]: Epoch 006 - training loss: 0.5686, validation loss: 1.8843
2024-06-04 03:25:49 [INFO]: Epoch 007 - training loss: 0.5561, validation loss: 1.8850
2024-06-04 03:26:03 [INFO]: Epoch 008 - training loss: 0.5463, validation loss: 1.8694
2024-06-04 03:26:18 [INFO]: Epoch 009 - training loss: 0.5385, validation loss: 1.8616
2024-06-04 03:26:32 [INFO]: Epoch 010 - training loss: 0.5310, validation loss: 1.8504
2024-06-04 03:26:46 [INFO]: Epoch 011 - training loss: 0.5239, validation loss: 1.8437
2024-06-04 03:27:00 [INFO]: Epoch 012 - training loss: 0.5177, validation loss: 1.8316
2024-06-04 03:27:14 [INFO]: Epoch 013 - training loss: 0.5132, validation loss: 1.8315
2024-06-04 03:27:28 [INFO]: Epoch 014 - training loss: 0.5076, validation loss: 1.8143
2024-06-04 03:27:42 [INFO]: Epoch 015 - training loss: 0.5026, validation loss: 1.8135
2024-06-04 03:27:56 [INFO]: Epoch 016 - training loss: 0.4981, validation loss: 1.8068
2024-06-04 03:28:11 [INFO]: Epoch 017 - training loss: 0.4946, validation loss: 1.7987
2024-06-04 03:28:25 [INFO]: Epoch 018 - training loss: 0.4906, validation loss: 1.7914
2024-06-04 03:28:40 [INFO]: Epoch 019 - training loss: 0.4861, validation loss: 1.7835
2024-06-04 03:28:54 [INFO]: Epoch 020 - training loss: 0.4838, validation loss: 1.7751
2024-06-04 03:29:09 [INFO]: Epoch 021 - training loss: 0.4804, validation loss: 1.7754
2024-06-04 03:29:23 [INFO]: Epoch 022 - training loss: 0.4788, validation loss: 1.7614
2024-06-04 03:29:37 [INFO]: Epoch 023 - training loss: 0.4754, validation loss: 1.7624
2024-06-04 03:29:52 [INFO]: Epoch 024 - training loss: 0.4727, validation loss: 1.7581
2024-06-04 03:30:06 [INFO]: Epoch 025 - training loss: 0.4696, validation loss: 1.7538
2024-06-04 03:30:20 [INFO]: Epoch 026 - training loss: 0.4687, validation loss: 1.7499
2024-06-04 03:30:35 [INFO]: Epoch 027 - training loss: 0.4656, validation loss: 1.7379
2024-06-04 03:30:49 [INFO]: Epoch 028 - training loss: 0.4636, validation loss: 1.7383
2024-06-04 03:31:04 [INFO]: Epoch 029 - training loss: 0.4621, validation loss: 1.7343
2024-06-04 03:31:17 [INFO]: Epoch 030 - training loss: 0.4603, validation loss: 1.7272
2024-06-04 03:31:31 [INFO]: Epoch 031 - training loss: 0.4596, validation loss: 1.7202
2024-06-04 03:31:45 [INFO]: Epoch 032 - training loss: 0.4588, validation loss: 1.7254
2024-06-04 03:31:59 [INFO]: Epoch 033 - training loss: 0.4580, validation loss: 1.7255
2024-06-04 03:32:14 [INFO]: Epoch 034 - training loss: 0.4564, validation loss: 1.7121
2024-06-04 03:32:28 [INFO]: Epoch 035 - training loss: 0.4539, validation loss: 1.7074
2024-06-04 03:32:42 [INFO]: Epoch 036 - training loss: 0.4523, validation loss: 1.7011
2024-06-04 03:32:57 [INFO]: Epoch 037 - training loss: 0.4506, validation loss: 1.6979
2024-06-04 03:33:11 [INFO]: Epoch 038 - training loss: 0.4494, validation loss: 1.6922
2024-06-04 03:33:25 [INFO]: Epoch 039 - training loss: 0.4484, validation loss: 1.6951
2024-06-04 03:33:40 [INFO]: Epoch 040 - training loss: 0.4470, validation loss: 1.6920
2024-06-04 03:33:54 [INFO]: Epoch 041 - training loss: 0.4464, validation loss: 1.6896
2024-06-04 03:34:09 [INFO]: Epoch 042 - training loss: 0.4452, validation loss: 1.6818
2024-06-04 03:34:24 [INFO]: Epoch 043 - training loss: 0.4447, validation loss: 1.6815
2024-06-04 03:34:38 [INFO]: Epoch 044 - training loss: 0.4434, validation loss: 1.6723
2024-06-04 03:34:52 [INFO]: Epoch 045 - training loss: 0.4428, validation loss: 1.6729
2024-06-04 03:35:06 [INFO]: Epoch 046 - training loss: 0.4418, validation loss: 1.6692
2024-06-04 03:35:20 [INFO]: Epoch 047 - training loss: 0.4417, validation loss: 1.6622
2024-06-04 03:35:34 [INFO]: Epoch 048 - training loss: 0.4407, validation loss: 1.6564
2024-06-04 03:35:48 [INFO]: Epoch 049 - training loss: 0.4394, validation loss: 1.6560
2024-06-04 03:36:02 [INFO]: Epoch 050 - training loss: 0.4385, validation loss: 1.6524
2024-06-04 03:36:17 [INFO]: Epoch 051 - training loss: 0.4383, validation loss: 1.6562
2024-06-04 03:36:30 [INFO]: Epoch 052 - training loss: 0.4380, validation loss: 1.6534
2024-06-04 03:36:42 [INFO]: Epoch 053 - training loss: 0.4367, validation loss: 1.6495
2024-06-04 03:36:54 [INFO]: Epoch 054 - training loss: 0.4365, validation loss: 1.6529
2024-06-04 03:37:06 [INFO]: Epoch 055 - training loss: 0.4363, validation loss: 1.6455
2024-06-04 03:37:18 [INFO]: Epoch 056 - training loss: 0.4349, validation loss: 1.6458
2024-06-04 03:37:30 [INFO]: Epoch 057 - training loss: 0.4342, validation loss: 1.6503
2024-06-04 03:37:42 [INFO]: Epoch 058 - training loss: 0.4332, validation loss: 1.6431
2024-06-04 03:37:55 [INFO]: Epoch 059 - training loss: 0.4331, validation loss: 1.6371
2024-06-04 03:38:07 [INFO]: Epoch 060 - training loss: 0.4328, validation loss: 1.6388
2024-06-04 03:38:19 [INFO]: Epoch 061 - training loss: 0.4320, validation loss: 1.6330
2024-06-04 03:38:31 [INFO]: Epoch 062 - training loss: 0.4316, validation loss: 1.6393
2024-06-04 03:38:43 [INFO]: Epoch 063 - training loss: 0.4312, validation loss: 1.6305
2024-06-04 03:38:55 [INFO]: Epoch 064 - training loss: 0.4302, validation loss: 1.6327
2024-06-04 03:39:07 [INFO]: Epoch 065 - training loss: 0.4301, validation loss: 1.6282
2024-06-04 03:39:19 [INFO]: Epoch 066 - training loss: 0.4293, validation loss: 1.6270
2024-06-04 03:39:30 [INFO]: Epoch 067 - training loss: 0.4293, validation loss: 1.6281
2024-06-04 03:39:41 [INFO]: Epoch 068 - training loss: 0.4287, validation loss: 1.6269
2024-06-04 03:39:53 [INFO]: Epoch 069 - training loss: 0.4277, validation loss: 1.6260
2024-06-04 03:40:06 [INFO]: Epoch 070 - training loss: 0.4276, validation loss: 1.6265
2024-06-04 03:40:18 [INFO]: Epoch 071 - training loss: 0.4274, validation loss: 1.6198
2024-06-04 03:40:29 [INFO]: Epoch 072 - training loss: 0.4274, validation loss: 1.6250
2024-06-04 03:40:41 [INFO]: Epoch 073 - training loss: 0.4262, validation loss: 1.6172
2024-06-04 03:40:53 [INFO]: Epoch 074 - training loss: 0.4265, validation loss: 1.6202
2024-06-04 03:41:05 [INFO]: Epoch 075 - training loss: 0.4254, validation loss: 1.6184
2024-06-04 03:41:17 [INFO]: Epoch 076 - training loss: 0.4252, validation loss: 1.6208
2024-06-04 03:41:29 [INFO]: Epoch 077 - training loss: 0.4242, validation loss: 1.6196
2024-06-04 03:41:41 [INFO]: Epoch 078 - training loss: 0.4240, validation loss: 1.6166
2024-06-04 03:41:53 [INFO]: Epoch 079 - training loss: 0.4239, validation loss: 1.6167
2024-06-04 03:42:05 [INFO]: Epoch 080 - training loss: 0.4244, validation loss: 1.6078
2024-06-04 03:42:17 [INFO]: Epoch 081 - training loss: 0.4234, validation loss: 1.6102
2024-06-04 03:42:30 [INFO]: Epoch 082 - training loss: 0.4220, validation loss: 1.6117
2024-06-04 03:42:42 [INFO]: Epoch 083 - training loss: 0.4226, validation loss: 1.6130
2024-06-04 03:42:53 [INFO]: Epoch 084 - training loss: 0.4217, validation loss: 1.6109
2024-06-04 03:43:05 [INFO]: Epoch 085 - training loss: 0.4219, validation loss: 1.6092
2024-06-04 03:43:17 [INFO]: Epoch 086 - training loss: 0.4208, validation loss: 1.6102
2024-06-04 03:43:28 [INFO]: Epoch 087 - training loss: 0.4205, validation loss: 1.6082
2024-06-04 03:43:40 [INFO]: Epoch 088 - training loss: 0.4204, validation loss: 1.6084
2024-06-04 03:43:51 [INFO]: Epoch 089 - training loss: 0.4198, validation loss: 1.6084
2024-06-04 03:44:04 [INFO]: Epoch 090 - training loss: 0.4204, validation loss: 1.6028
2024-06-04 03:44:16 [INFO]: Epoch 091 - training loss: 0.4197, validation loss: 1.6035
2024-06-04 03:44:28 [INFO]: Epoch 092 - training loss: 0.4190, validation loss: 1.5997
2024-06-04 03:44:40 [INFO]: Epoch 093 - training loss: 0.4183, validation loss: 1.5999
2024-06-04 03:44:52 [INFO]: Epoch 094 - training loss: 0.4179, validation loss: 1.6048
2024-06-04 03:45:04 [INFO]: Epoch 095 - training loss: 0.4181, validation loss: 1.6031
2024-06-04 03:45:16 [INFO]: Epoch 096 - training loss: 0.4179, validation loss: 1.6059
2024-06-04 03:45:29 [INFO]: Epoch 097 - training loss: 0.4174, validation loss: 1.6020
2024-06-04 03:45:41 [INFO]: Epoch 098 - training loss: 0.4169, validation loss: 1.5984
2024-06-04 03:45:53 [INFO]: Epoch 099 - training loss: 0.4168, validation loss: 1.6003
2024-06-04 03:46:05 [INFO]: Epoch 100 - training loss: 0.4166, validation loss: 1.6003
2024-06-04 03:46:05 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 03:46:05 [INFO]: Saved the model to results_point_rate05/Electricity/ETSformer_Electricity/round_1/20240604_T032407/ETSformer.pypots
2024-06-04 03:46:14 [INFO]: Successfully saved to results_point_rate05/Electricity/ETSformer_Electricity/round_1/imputation.pkl
2024-06-04 03:46:14 [INFO]: Round1 - ETSformer on Electricity: MAE=0.8812, MSE=1.6998, MRE=0.4718
2024-06-04 03:46:14 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:46:14 [INFO]: Using the given device: cuda:0
2024-06-04 03:46:14 [INFO]: Model files will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_2/20240604_T034614
2024-06-04 03:46:14 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_2/20240604_T034614/tensorboard
2024-06-04 03:46:14 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-04 03:46:27 [INFO]: Epoch 001 - training loss: 0.9585, validation loss: 1.9682
2024-06-04 03:46:39 [INFO]: Epoch 002 - training loss: 0.7004, validation loss: 1.9199
2024-06-04 03:46:51 [INFO]: Epoch 003 - training loss: 0.6366, validation loss: 1.9011
2024-06-04 03:47:02 [INFO]: Epoch 004 - training loss: 0.6059, validation loss: 1.8838
2024-06-04 03:47:13 [INFO]: Epoch 005 - training loss: 0.5877, validation loss: 1.8726
2024-06-04 03:47:24 [INFO]: Epoch 006 - training loss: 0.5740, validation loss: 1.8673
2024-06-04 03:47:35 [INFO]: Epoch 007 - training loss: 0.5626, validation loss: 1.8621
2024-06-04 03:47:48 [INFO]: Epoch 008 - training loss: 0.5514, validation loss: 1.8530
2024-06-04 03:47:59 [INFO]: Epoch 009 - training loss: 0.5446, validation loss: 1.8556
2024-06-04 03:48:11 [INFO]: Epoch 010 - training loss: 0.5361, validation loss: 1.8500
2024-06-04 03:48:23 [INFO]: Epoch 011 - training loss: 0.5296, validation loss: 1.8455
2024-06-04 03:48:35 [INFO]: Epoch 012 - training loss: 0.5233, validation loss: 1.8399
2024-06-04 03:48:47 [INFO]: Epoch 013 - training loss: 0.5181, validation loss: 1.8227
2024-06-04 03:48:59 [INFO]: Epoch 014 - training loss: 0.5124, validation loss: 1.8174
2024-06-04 03:49:11 [INFO]: Epoch 015 - training loss: 0.5081, validation loss: 1.8032
2024-06-04 03:49:24 [INFO]: Epoch 016 - training loss: 0.5038, validation loss: 1.8020
2024-06-04 03:49:35 [INFO]: Epoch 017 - training loss: 0.4994, validation loss: 1.7981
2024-06-04 03:49:48 [INFO]: Epoch 018 - training loss: 0.4946, validation loss: 1.7840
2024-06-04 03:50:00 [INFO]: Epoch 019 - training loss: 0.4914, validation loss: 1.7790
2024-06-04 03:50:12 [INFO]: Epoch 020 - training loss: 0.4883, validation loss: 1.7791
2024-06-04 03:50:24 [INFO]: Epoch 021 - training loss: 0.4857, validation loss: 1.7627
2024-06-04 03:50:36 [INFO]: Epoch 022 - training loss: 0.4836, validation loss: 1.7573
2024-06-04 03:50:48 [INFO]: Epoch 023 - training loss: 0.4804, validation loss: 1.7551
2024-06-04 03:51:00 [INFO]: Epoch 024 - training loss: 0.4776, validation loss: 1.7525
2024-06-04 03:51:11 [INFO]: Epoch 025 - training loss: 0.4757, validation loss: 1.7496
2024-06-04 03:51:23 [INFO]: Epoch 026 - training loss: 0.4736, validation loss: 1.7418
2024-06-04 03:51:34 [INFO]: Epoch 027 - training loss: 0.4729, validation loss: 1.7413
2024-06-04 03:51:46 [INFO]: Epoch 028 - training loss: 0.4714, validation loss: 1.7402
2024-06-04 03:51:59 [INFO]: Epoch 029 - training loss: 0.4687, validation loss: 1.7257
2024-06-04 03:52:11 [INFO]: Epoch 030 - training loss: 0.4663, validation loss: 1.7286
2024-06-04 03:52:23 [INFO]: Epoch 031 - training loss: 0.4644, validation loss: 1.7159
2024-06-04 03:52:34 [INFO]: Epoch 032 - training loss: 0.4618, validation loss: 1.7124
2024-06-04 03:52:46 [INFO]: Epoch 033 - training loss: 0.4606, validation loss: 1.7146
2024-06-04 03:52:58 [INFO]: Epoch 034 - training loss: 0.4597, validation loss: 1.7021
2024-06-04 03:53:10 [INFO]: Epoch 035 - training loss: 0.4575, validation loss: 1.7013
2024-06-04 03:53:23 [INFO]: Epoch 036 - training loss: 0.4569, validation loss: 1.7014
2024-06-04 03:53:35 [INFO]: Epoch 037 - training loss: 0.4549, validation loss: 1.6945
2024-06-04 03:53:47 [INFO]: Epoch 038 - training loss: 0.4542, validation loss: 1.6940
2024-06-04 03:53:59 [INFO]: Epoch 039 - training loss: 0.4525, validation loss: 1.6878
2024-06-04 03:54:11 [INFO]: Epoch 040 - training loss: 0.4514, validation loss: 1.6922
2024-06-04 03:54:23 [INFO]: Epoch 041 - training loss: 0.4502, validation loss: 1.6854
2024-06-04 03:54:35 [INFO]: Epoch 042 - training loss: 0.4495, validation loss: 1.6845
2024-06-04 03:54:47 [INFO]: Epoch 043 - training loss: 0.4483, validation loss: 1.6792
2024-06-04 03:54:59 [INFO]: Epoch 044 - training loss: 0.4481, validation loss: 1.6745
2024-06-04 03:55:10 [INFO]: Epoch 045 - training loss: 0.4476, validation loss: 1.6830
2024-06-04 03:55:22 [INFO]: Epoch 046 - training loss: 0.4474, validation loss: 1.6681
2024-06-04 03:55:33 [INFO]: Epoch 047 - training loss: 0.4459, validation loss: 1.6695
2024-06-04 03:55:45 [INFO]: Epoch 048 - training loss: 0.4457, validation loss: 1.6707
2024-06-04 03:55:57 [INFO]: Epoch 049 - training loss: 0.4437, validation loss: 1.6615
2024-06-04 03:56:08 [INFO]: Epoch 050 - training loss: 0.4430, validation loss: 1.6637
2024-06-04 03:56:20 [INFO]: Epoch 051 - training loss: 0.4416, validation loss: 1.6634
2024-06-04 03:56:33 [INFO]: Epoch 052 - training loss: 0.4414, validation loss: 1.6622
2024-06-04 03:56:45 [INFO]: Epoch 053 - training loss: 0.4406, validation loss: 1.6586
2024-06-04 03:56:57 [INFO]: Epoch 054 - training loss: 0.4402, validation loss: 1.6635
2024-06-04 03:57:09 [INFO]: Epoch 055 - training loss: 0.4397, validation loss: 1.6571
2024-06-04 03:57:21 [INFO]: Epoch 056 - training loss: 0.4392, validation loss: 1.6537
2024-06-04 03:57:33 [INFO]: Epoch 057 - training loss: 0.4384, validation loss: 1.6536
2024-06-04 03:57:45 [INFO]: Epoch 058 - training loss: 0.4374, validation loss: 1.6517
2024-06-04 03:57:57 [INFO]: Epoch 059 - training loss: 0.4369, validation loss: 1.6446
2024-06-04 03:58:09 [INFO]: Epoch 060 - training loss: 0.4366, validation loss: 1.6424
2024-06-04 03:58:21 [INFO]: Epoch 061 - training loss: 0.4355, validation loss: 1.6461
2024-06-04 03:58:33 [INFO]: Epoch 062 - training loss: 0.4359, validation loss: 1.6426
2024-06-04 03:58:45 [INFO]: Epoch 063 - training loss: 0.4348, validation loss: 1.6446
2024-06-04 03:58:57 [INFO]: Epoch 064 - training loss: 0.4343, validation loss: 1.6436
2024-06-04 03:59:08 [INFO]: Epoch 065 - training loss: 0.4337, validation loss: 1.6340
2024-06-04 03:59:20 [INFO]: Epoch 066 - training loss: 0.4336, validation loss: 1.6323
2024-06-04 03:59:31 [INFO]: Epoch 067 - training loss: 0.4335, validation loss: 1.6374
2024-06-04 03:59:43 [INFO]: Epoch 068 - training loss: 0.4327, validation loss: 1.6326
2024-06-04 03:59:55 [INFO]: Epoch 069 - training loss: 0.4320, validation loss: 1.6289
2024-06-04 04:00:07 [INFO]: Epoch 070 - training loss: 0.4316, validation loss: 1.6348
2024-06-04 04:00:19 [INFO]: Epoch 071 - training loss: 0.4311, validation loss: 1.6215
2024-06-04 04:00:31 [INFO]: Epoch 072 - training loss: 0.4306, validation loss: 1.6262
2024-06-04 04:00:43 [INFO]: Epoch 073 - training loss: 0.4300, validation loss: 1.6243
2024-06-04 04:00:55 [INFO]: Epoch 074 - training loss: 0.4303, validation loss: 1.6230
2024-06-04 04:01:07 [INFO]: Epoch 075 - training loss: 0.4294, validation loss: 1.6229
2024-06-04 04:01:19 [INFO]: Epoch 076 - training loss: 0.4289, validation loss: 1.6258
2024-06-04 04:01:31 [INFO]: Epoch 077 - training loss: 0.4283, validation loss: 1.6183
2024-06-04 04:01:43 [INFO]: Epoch 078 - training loss: 0.4285, validation loss: 1.6174
2024-06-04 04:01:55 [INFO]: Epoch 079 - training loss: 0.4281, validation loss: 1.6173
2024-06-04 04:02:07 [INFO]: Epoch 080 - training loss: 0.4278, validation loss: 1.6113
2024-06-04 04:02:18 [INFO]: Epoch 081 - training loss: 0.4276, validation loss: 1.6154
2024-06-04 04:02:30 [INFO]: Epoch 082 - training loss: 0.4272, validation loss: 1.6153
2024-06-04 04:02:42 [INFO]: Epoch 083 - training loss: 0.4262, validation loss: 1.6091
2024-06-04 04:02:54 [INFO]: Epoch 084 - training loss: 0.4269, validation loss: 1.6100
2024-06-04 04:03:05 [INFO]: Epoch 085 - training loss: 0.4264, validation loss: 1.6127
2024-06-04 04:03:17 [INFO]: Epoch 086 - training loss: 0.4253, validation loss: 1.6058
2024-06-04 04:03:28 [INFO]: Epoch 087 - training loss: 0.4253, validation loss: 1.6090
2024-06-04 04:03:41 [INFO]: Epoch 088 - training loss: 0.4246, validation loss: 1.6039
2024-06-04 04:03:53 [INFO]: Epoch 089 - training loss: 0.4241, validation loss: 1.6023
2024-06-04 04:04:04 [INFO]: Epoch 090 - training loss: 0.4245, validation loss: 1.6014
2024-06-04 04:04:17 [INFO]: Epoch 091 - training loss: 0.4239, validation loss: 1.6002
2024-06-04 04:04:28 [INFO]: Epoch 092 - training loss: 0.4238, validation loss: 1.6002
2024-06-04 04:04:41 [INFO]: Epoch 093 - training loss: 0.4233, validation loss: 1.6039
2024-06-04 04:04:53 [INFO]: Epoch 094 - training loss: 0.4227, validation loss: 1.6013
2024-06-04 04:05:05 [INFO]: Epoch 095 - training loss: 0.4223, validation loss: 1.6019
2024-06-04 04:05:17 [INFO]: Epoch 096 - training loss: 0.4220, validation loss: 1.5961
2024-06-04 04:05:29 [INFO]: Epoch 097 - training loss: 0.4224, validation loss: 1.5968
2024-06-04 04:05:41 [INFO]: Epoch 098 - training loss: 0.4214, validation loss: 1.5960
2024-06-04 04:05:53 [INFO]: Epoch 099 - training loss: 0.4213, validation loss: 1.5947
2024-06-04 04:06:05 [INFO]: Epoch 100 - training loss: 0.4221, validation loss: 1.6009
2024-06-04 04:06:05 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:06:05 [INFO]: Saved the model to results_point_rate05/Electricity/ETSformer_Electricity/round_2/20240604_T034614/ETSformer.pypots
2024-06-04 04:06:14 [INFO]: Successfully saved to results_point_rate05/Electricity/ETSformer_Electricity/round_2/imputation.pkl
2024-06-04 04:06:14 [INFO]: Round2 - ETSformer on Electricity: MAE=0.8639, MSE=1.6525, MRE=0.4626
2024-06-04 04:06:14 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 04:06:14 [INFO]: Using the given device: cuda:0
2024-06-04 04:06:14 [INFO]: Model files will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_3/20240604_T040614
2024-06-04 04:06:14 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_3/20240604_T040614/tensorboard
2024-06-04 04:06:14 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-04 04:06:26 [INFO]: Epoch 001 - training loss: 0.9538, validation loss: 1.9129
2024-06-04 04:06:38 [INFO]: Epoch 002 - training loss: 0.6960, validation loss: 1.8745
2024-06-04 04:06:49 [INFO]: Epoch 003 - training loss: 0.6332, validation loss: 1.8589
2024-06-04 04:07:01 [INFO]: Epoch 004 - training loss: 0.6049, validation loss: 1.8648
2024-06-04 04:07:12 [INFO]: Epoch 005 - training loss: 0.5840, validation loss: 1.8431
2024-06-04 04:07:24 [INFO]: Epoch 006 - training loss: 0.5705, validation loss: 1.8401
2024-06-04 04:07:36 [INFO]: Epoch 007 - training loss: 0.5600, validation loss: 1.8389
2024-06-04 04:07:48 [INFO]: Epoch 008 - training loss: 0.5494, validation loss: 1.8224
2024-06-04 04:08:00 [INFO]: Epoch 009 - training loss: 0.5422, validation loss: 1.8157
2024-06-04 04:08:12 [INFO]: Epoch 010 - training loss: 0.5347, validation loss: 1.8163
2024-06-04 04:08:24 [INFO]: Epoch 011 - training loss: 0.5273, validation loss: 1.8140
2024-06-04 04:08:36 [INFO]: Epoch 012 - training loss: 0.5200, validation loss: 1.8079
2024-06-04 04:08:48 [INFO]: Epoch 013 - training loss: 0.5152, validation loss: 1.8078
2024-06-04 04:08:59 [INFO]: Epoch 014 - training loss: 0.5090, validation loss: 1.7913
2024-06-04 04:09:11 [INFO]: Epoch 015 - training loss: 0.5052, validation loss: 1.7943
2024-06-04 04:09:23 [INFO]: Epoch 016 - training loss: 0.5000, validation loss: 1.7854
2024-06-04 04:09:35 [INFO]: Epoch 017 - training loss: 0.4963, validation loss: 1.7765
2024-06-04 04:09:47 [INFO]: Epoch 018 - training loss: 0.4930, validation loss: 1.7761
2024-06-04 04:09:59 [INFO]: Epoch 019 - training loss: 0.4893, validation loss: 1.7680
2024-06-04 04:10:11 [INFO]: Epoch 020 - training loss: 0.4873, validation loss: 1.7743
2024-06-04 04:10:23 [INFO]: Epoch 021 - training loss: 0.4838, validation loss: 1.7616
2024-06-04 04:10:35 [INFO]: Epoch 022 - training loss: 0.4805, validation loss: 1.7586
2024-06-04 04:10:47 [INFO]: Epoch 023 - training loss: 0.4788, validation loss: 1.7558
2024-06-04 04:10:58 [INFO]: Epoch 024 - training loss: 0.4759, validation loss: 1.7544
2024-06-04 04:11:10 [INFO]: Epoch 025 - training loss: 0.4728, validation loss: 1.7486
2024-06-04 04:11:22 [INFO]: Epoch 026 - training loss: 0.4711, validation loss: 1.7430
2024-06-04 04:11:34 [INFO]: Epoch 027 - training loss: 0.4694, validation loss: 1.7362
2024-06-04 04:11:46 [INFO]: Epoch 028 - training loss: 0.4664, validation loss: 1.7403
2024-06-04 04:11:58 [INFO]: Epoch 029 - training loss: 0.4644, validation loss: 1.7336
2024-06-04 04:12:10 [INFO]: Epoch 030 - training loss: 0.4629, validation loss: 1.7333
2024-06-04 04:12:22 [INFO]: Epoch 031 - training loss: 0.4614, validation loss: 1.7343
2024-06-04 04:12:34 [INFO]: Epoch 032 - training loss: 0.4603, validation loss: 1.7248
2024-06-04 04:12:46 [INFO]: Epoch 033 - training loss: 0.4576, validation loss: 1.7241
2024-06-04 04:12:58 [INFO]: Epoch 034 - training loss: 0.4567, validation loss: 1.7164
2024-06-04 04:13:11 [INFO]: Epoch 035 - training loss: 0.4550, validation loss: 1.7111
2024-06-04 04:13:23 [INFO]: Epoch 036 - training loss: 0.4542, validation loss: 1.7042
2024-06-04 04:13:35 [INFO]: Epoch 037 - training loss: 0.4526, validation loss: 1.6948
2024-06-04 04:13:47 [INFO]: Epoch 038 - training loss: 0.4511, validation loss: 1.7023
2024-06-04 04:13:59 [INFO]: Epoch 039 - training loss: 0.4504, validation loss: 1.7044
2024-06-04 04:14:11 [INFO]: Epoch 040 - training loss: 0.4495, validation loss: 1.6962
2024-06-04 04:14:23 [INFO]: Epoch 041 - training loss: 0.4488, validation loss: 1.6957
2024-06-04 04:14:35 [INFO]: Epoch 042 - training loss: 0.4474, validation loss: 1.6918
2024-06-04 04:14:46 [INFO]: Epoch 043 - training loss: 0.4467, validation loss: 1.6921
2024-06-04 04:14:58 [INFO]: Epoch 044 - training loss: 0.4452, validation loss: 1.6786
2024-06-04 04:15:09 [INFO]: Epoch 045 - training loss: 0.4445, validation loss: 1.6786
2024-06-04 04:15:21 [INFO]: Epoch 046 - training loss: 0.4437, validation loss: 1.6700
2024-06-04 04:15:33 [INFO]: Epoch 047 - training loss: 0.4426, validation loss: 1.6751
2024-06-04 04:15:44 [INFO]: Epoch 048 - training loss: 0.4416, validation loss: 1.6680
2024-06-04 04:15:57 [INFO]: Epoch 049 - training loss: 0.4410, validation loss: 1.6704
2024-06-04 04:16:09 [INFO]: Epoch 050 - training loss: 0.4402, validation loss: 1.6679
2024-06-04 04:16:21 [INFO]: Epoch 051 - training loss: 0.4394, validation loss: 1.6663
2024-06-04 04:16:33 [INFO]: Epoch 052 - training loss: 0.4383, validation loss: 1.6637
2024-06-04 04:16:45 [INFO]: Epoch 053 - training loss: 0.4381, validation loss: 1.6634
2024-06-04 04:16:57 [INFO]: Epoch 054 - training loss: 0.4374, validation loss: 1.6610
2024-06-04 04:17:09 [INFO]: Epoch 055 - training loss: 0.4371, validation loss: 1.6543
2024-06-04 04:17:21 [INFO]: Epoch 056 - training loss: 0.4363, validation loss: 1.6570
2024-06-04 04:17:32 [INFO]: Epoch 057 - training loss: 0.4357, validation loss: 1.6503
2024-06-04 04:17:44 [INFO]: Epoch 058 - training loss: 0.4348, validation loss: 1.6516
2024-06-04 04:17:57 [INFO]: Epoch 059 - training loss: 0.4343, validation loss: 1.6518
2024-06-04 04:18:09 [INFO]: Epoch 060 - training loss: 0.4335, validation loss: 1.6482
2024-06-04 04:18:20 [INFO]: Epoch 061 - training loss: 0.4331, validation loss: 1.6460
2024-06-04 04:18:32 [INFO]: Epoch 062 - training loss: 0.4322, validation loss: 1.6432
2024-06-04 04:18:44 [INFO]: Epoch 063 - training loss: 0.4315, validation loss: 1.6399
2024-06-04 04:18:56 [INFO]: Epoch 064 - training loss: 0.4311, validation loss: 1.6406
2024-06-04 04:19:07 [INFO]: Epoch 065 - training loss: 0.4305, validation loss: 1.6433
2024-06-04 04:19:19 [INFO]: Epoch 066 - training loss: 0.4300, validation loss: 1.6392
2024-06-04 04:19:31 [INFO]: Epoch 067 - training loss: 0.4300, validation loss: 1.6420
2024-06-04 04:19:43 [INFO]: Epoch 068 - training loss: 0.4288, validation loss: 1.6340
2024-06-04 04:19:55 [INFO]: Epoch 069 - training loss: 0.4286, validation loss: 1.6380
2024-06-04 04:20:07 [INFO]: Epoch 070 - training loss: 0.4283, validation loss: 1.6350
2024-06-04 04:20:19 [INFO]: Epoch 071 - training loss: 0.4277, validation loss: 1.6262
2024-06-04 04:20:31 [INFO]: Epoch 072 - training loss: 0.4272, validation loss: 1.6290
2024-06-04 04:20:43 [INFO]: Epoch 073 - training loss: 0.4268, validation loss: 1.6212
2024-06-04 04:20:55 [INFO]: Epoch 074 - training loss: 0.4264, validation loss: 1.6196
2024-06-04 04:21:07 [INFO]: Epoch 075 - training loss: 0.4256, validation loss: 1.6282
2024-06-04 04:21:19 [INFO]: Epoch 076 - training loss: 0.4250, validation loss: 1.6250
2024-06-04 04:21:31 [INFO]: Epoch 077 - training loss: 0.4250, validation loss: 1.6205
2024-06-04 04:21:43 [INFO]: Epoch 078 - training loss: 0.4248, validation loss: 1.6193
2024-06-04 04:21:55 [INFO]: Epoch 079 - training loss: 0.4238, validation loss: 1.6245
2024-06-04 04:22:07 [INFO]: Epoch 080 - training loss: 0.4236, validation loss: 1.6224
2024-06-04 04:22:19 [INFO]: Epoch 081 - training loss: 0.4234, validation loss: 1.6238
2024-06-04 04:22:31 [INFO]: Epoch 082 - training loss: 0.4229, validation loss: 1.6180
2024-06-04 04:22:43 [INFO]: Epoch 083 - training loss: 0.4224, validation loss: 1.6143
2024-06-04 04:22:54 [INFO]: Epoch 084 - training loss: 0.4228, validation loss: 1.6183
2024-06-04 04:23:06 [INFO]: Epoch 085 - training loss: 0.4217, validation loss: 1.6153
2024-06-04 04:23:17 [INFO]: Epoch 086 - training loss: 0.4216, validation loss: 1.6177
2024-06-04 04:23:29 [INFO]: Epoch 087 - training loss: 0.4218, validation loss: 1.6141
2024-06-04 04:23:42 [INFO]: Epoch 088 - training loss: 0.4208, validation loss: 1.6144
2024-06-04 04:23:53 [INFO]: Epoch 089 - training loss: 0.4202, validation loss: 1.6102
2024-06-04 04:24:05 [INFO]: Epoch 090 - training loss: 0.4196, validation loss: 1.6131
2024-06-04 04:24:17 [INFO]: Epoch 091 - training loss: 0.4196, validation loss: 1.6159
2024-06-04 04:24:29 [INFO]: Epoch 092 - training loss: 0.4191, validation loss: 1.6105
2024-06-04 04:24:41 [INFO]: Epoch 093 - training loss: 0.4184, validation loss: 1.6106
2024-06-04 04:24:53 [INFO]: Epoch 094 - training loss: 0.4181, validation loss: 1.6130
2024-06-04 04:25:05 [INFO]: Epoch 095 - training loss: 0.4180, validation loss: 1.6093
2024-06-04 04:25:17 [INFO]: Epoch 096 - training loss: 0.4173, validation loss: 1.6041
2024-06-04 04:25:29 [INFO]: Epoch 097 - training loss: 0.4179, validation loss: 1.6082
2024-06-04 04:25:41 [INFO]: Epoch 098 - training loss: 0.4173, validation loss: 1.6070
2024-06-04 04:25:53 [INFO]: Epoch 099 - training loss: 0.4170, validation loss: 1.6023
2024-06-04 04:26:05 [INFO]: Epoch 100 - training loss: 0.4162, validation loss: 1.6051
2024-06-04 04:26:05 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:26:05 [INFO]: Saved the model to results_point_rate05/Electricity/ETSformer_Electricity/round_3/20240604_T040614/ETSformer.pypots
2024-06-04 04:26:14 [INFO]: Successfully saved to results_point_rate05/Electricity/ETSformer_Electricity/round_3/imputation.pkl
2024-06-04 04:26:14 [INFO]: Round3 - ETSformer on Electricity: MAE=0.8876, MSE=1.7210, MRE=0.4752
2024-06-04 04:26:14 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:26:14 [INFO]: Using the given device: cuda:0
2024-06-04 04:26:14 [INFO]: Model files will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_4/20240604_T042614
2024-06-04 04:26:14 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/ETSformer_Electricity/round_4/20240604_T042614/tensorboard
2024-06-04 04:26:15 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 10,518,266
2024-06-04 04:26:27 [INFO]: Epoch 001 - training loss: 1.0215, validation loss: 1.9678
2024-06-04 04:26:38 [INFO]: Epoch 002 - training loss: 0.7303, validation loss: 1.9056
2024-06-04 04:26:50 [INFO]: Epoch 003 - training loss: 0.6504, validation loss: 1.8813
2024-06-04 04:27:01 [INFO]: Epoch 004 - training loss: 0.6147, validation loss: 1.8783
2024-06-04 04:27:13 [INFO]: Epoch 005 - training loss: 0.5947, validation loss: 1.8688
2024-06-04 04:27:25 [INFO]: Epoch 006 - training loss: 0.5798, validation loss: 1.8543
2024-06-04 04:27:37 [INFO]: Epoch 007 - training loss: 0.5669, validation loss: 1.8561
2024-06-04 04:27:49 [INFO]: Epoch 008 - training loss: 0.5573, validation loss: 1.8567
2024-06-04 04:28:01 [INFO]: Epoch 009 - training loss: 0.5496, validation loss: 1.8579
2024-06-04 04:28:13 [INFO]: Epoch 010 - training loss: 0.5421, validation loss: 1.8552
2024-06-04 04:28:25 [INFO]: Epoch 011 - training loss: 0.5351, validation loss: 1.8520
2024-06-04 04:28:37 [INFO]: Epoch 012 - training loss: 0.5291, validation loss: 1.8466
2024-06-04 04:28:49 [INFO]: Epoch 013 - training loss: 0.5235, validation loss: 1.8429
2024-06-04 04:29:01 [INFO]: Epoch 014 - training loss: 0.5177, validation loss: 1.8302
2024-06-04 04:29:14 [INFO]: Epoch 015 - training loss: 0.5145, validation loss: 1.8369
2024-06-04 04:29:26 [INFO]: Epoch 016 - training loss: 0.5086, validation loss: 1.8387
2024-06-04 04:29:38 [INFO]: Epoch 017 - training loss: 0.5048, validation loss: 1.8292
2024-06-04 04:29:50 [INFO]: Epoch 018 - training loss: 0.5005, validation loss: 1.8185
2024-06-04 04:30:02 [INFO]: Epoch 019 - training loss: 0.4973, validation loss: 1.8145
2024-06-04 04:30:14 [INFO]: Epoch 020 - training loss: 0.4936, validation loss: 1.8171
2024-06-04 04:30:26 [INFO]: Epoch 021 - training loss: 0.4907, validation loss: 1.8066
2024-06-04 04:30:38 [INFO]: Epoch 022 - training loss: 0.4874, validation loss: 1.7976
2024-06-04 04:30:50 [INFO]: Epoch 023 - training loss: 0.4870, validation loss: 1.7981
2024-06-04 04:31:01 [INFO]: Epoch 024 - training loss: 0.4831, validation loss: 1.7918
2024-06-04 04:31:12 [INFO]: Epoch 025 - training loss: 0.4808, validation loss: 1.7885
2024-06-04 04:31:24 [INFO]: Epoch 026 - training loss: 0.4780, validation loss: 1.7841
2024-06-04 04:31:36 [INFO]: Epoch 027 - training loss: 0.4756, validation loss: 1.7835
2024-06-04 04:31:47 [INFO]: Epoch 028 - training loss: 0.4733, validation loss: 1.7791
2024-06-04 04:31:59 [INFO]: Epoch 029 - training loss: 0.4716, validation loss: 1.7844
2024-06-04 04:32:11 [INFO]: Epoch 030 - training loss: 0.4693, validation loss: 1.7685
2024-06-04 04:32:23 [INFO]: Epoch 031 - training loss: 0.4673, validation loss: 1.7646
2024-06-04 04:32:35 [INFO]: Epoch 032 - training loss: 0.4651, validation loss: 1.7589
2024-06-04 04:32:47 [INFO]: Epoch 033 - training loss: 0.4642, validation loss: 1.7529
2024-06-04 04:32:59 [INFO]: Epoch 034 - training loss: 0.4628, validation loss: 1.7480
2024-06-04 04:33:11 [INFO]: Epoch 035 - training loss: 0.4612, validation loss: 1.7544
2024-06-04 04:33:23 [INFO]: Epoch 036 - training loss: 0.4591, validation loss: 1.7450
2024-06-04 04:33:35 [INFO]: Epoch 037 - training loss: 0.4576, validation loss: 1.7469
2024-06-04 04:33:47 [INFO]: Epoch 038 - training loss: 0.4566, validation loss: 1.7437
2024-06-04 04:33:59 [INFO]: Epoch 039 - training loss: 0.4552, validation loss: 1.7411
2024-06-04 04:34:11 [INFO]: Epoch 040 - training loss: 0.4543, validation loss: 1.7356
2024-06-04 04:34:23 [INFO]: Epoch 041 - training loss: 0.4530, validation loss: 1.7345
2024-06-04 04:34:35 [INFO]: Epoch 042 - training loss: 0.4525, validation loss: 1.7251
2024-06-04 04:34:46 [INFO]: Epoch 043 - training loss: 0.4510, validation loss: 1.7265
2024-06-04 04:34:57 [INFO]: Epoch 044 - training loss: 0.4501, validation loss: 1.7189
2024-06-04 04:35:09 [INFO]: Epoch 045 - training loss: 0.4492, validation loss: 1.7255
2024-06-04 04:35:20 [INFO]: Epoch 046 - training loss: 0.4481, validation loss: 1.7256
2024-06-04 04:35:33 [INFO]: Epoch 047 - training loss: 0.4466, validation loss: 1.7207
2024-06-04 04:35:45 [INFO]: Epoch 048 - training loss: 0.4468, validation loss: 1.7152
2024-06-04 04:35:57 [INFO]: Epoch 049 - training loss: 0.4453, validation loss: 1.7065
2024-06-04 04:36:09 [INFO]: Epoch 050 - training loss: 0.4447, validation loss: 1.7011
2024-06-04 04:36:21 [INFO]: Epoch 051 - training loss: 0.4440, validation loss: 1.7042
2024-06-04 04:36:32 [INFO]: Epoch 052 - training loss: 0.4432, validation loss: 1.6981
2024-06-04 04:36:44 [INFO]: Epoch 053 - training loss: 0.4427, validation loss: 1.6894
2024-06-04 04:36:57 [INFO]: Epoch 054 - training loss: 0.4413, validation loss: 1.6898
2024-06-04 04:37:09 [INFO]: Epoch 055 - training loss: 0.4405, validation loss: 1.6930
2024-06-04 04:37:21 [INFO]: Epoch 056 - training loss: 0.4411, validation loss: 1.6987
2024-06-04 04:37:33 [INFO]: Epoch 057 - training loss: 0.4404, validation loss: 1.6865
2024-06-04 04:37:45 [INFO]: Epoch 058 - training loss: 0.4404, validation loss: 1.6981
2024-06-04 04:37:57 [INFO]: Epoch 059 - training loss: 0.4388, validation loss: 1.6919
2024-06-04 04:38:09 [INFO]: Epoch 060 - training loss: 0.4384, validation loss: 1.6825
2024-06-04 04:38:21 [INFO]: Epoch 061 - training loss: 0.4374, validation loss: 1.6811
2024-06-04 04:38:33 [INFO]: Epoch 062 - training loss: 0.4363, validation loss: 1.6781
2024-06-04 04:38:44 [INFO]: Epoch 063 - training loss: 0.4359, validation loss: 1.6802
2024-06-04 04:38:55 [INFO]: Epoch 064 - training loss: 0.4350, validation loss: 1.6744
2024-06-04 04:39:07 [INFO]: Epoch 065 - training loss: 0.4349, validation loss: 1.6719
2024-06-04 04:39:18 [INFO]: Epoch 066 - training loss: 0.4360, validation loss: 1.6758
2024-06-04 04:39:31 [INFO]: Epoch 067 - training loss: 0.4345, validation loss: 1.6752
2024-06-04 04:39:43 [INFO]: Epoch 068 - training loss: 0.4343, validation loss: 1.6699
2024-06-04 04:39:55 [INFO]: Epoch 069 - training loss: 0.4337, validation loss: 1.6667
2024-06-04 04:40:07 [INFO]: Epoch 070 - training loss: 0.4326, validation loss: 1.6705
2024-06-04 04:40:19 [INFO]: Epoch 071 - training loss: 0.4327, validation loss: 1.6635
2024-06-04 04:40:31 [INFO]: Epoch 072 - training loss: 0.4313, validation loss: 1.6599
2024-06-04 04:40:43 [INFO]: Epoch 073 - training loss: 0.4307, validation loss: 1.6555
2024-06-04 04:40:55 [INFO]: Epoch 074 - training loss: 0.4309, validation loss: 1.6569
2024-06-04 04:41:07 [INFO]: Epoch 075 - training loss: 0.4300, validation loss: 1.6563
2024-06-04 04:41:19 [INFO]: Epoch 076 - training loss: 0.4295, validation loss: 1.6544
2024-06-04 04:41:31 [INFO]: Epoch 077 - training loss: 0.4287, validation loss: 1.6572
2024-06-04 04:41:43 [INFO]: Epoch 078 - training loss: 0.4285, validation loss: 1.6536
2024-06-04 04:41:55 [INFO]: Epoch 079 - training loss: 0.4287, validation loss: 1.6527
2024-06-04 04:42:07 [INFO]: Epoch 080 - training loss: 0.4289, validation loss: 1.6492
2024-06-04 04:42:19 [INFO]: Epoch 081 - training loss: 0.4283, validation loss: 1.6523
2024-06-04 04:42:31 [INFO]: Epoch 082 - training loss: 0.4273, validation loss: 1.6392
2024-06-04 04:42:43 [INFO]: Epoch 083 - training loss: 0.4266, validation loss: 1.6432
2024-06-04 04:42:54 [INFO]: Epoch 084 - training loss: 0.4264, validation loss: 1.6453
2024-06-04 04:43:06 [INFO]: Epoch 085 - training loss: 0.4263, validation loss: 1.6410
2024-06-04 04:43:18 [INFO]: Epoch 086 - training loss: 0.4257, validation loss: 1.6476
2024-06-04 04:43:30 [INFO]: Epoch 087 - training loss: 0.4254, validation loss: 1.6431
2024-06-04 04:43:42 [INFO]: Epoch 088 - training loss: 0.4251, validation loss: 1.6434
2024-06-04 04:43:54 [INFO]: Epoch 089 - training loss: 0.4244, validation loss: 1.6365
2024-06-04 04:44:06 [INFO]: Epoch 090 - training loss: 0.4238, validation loss: 1.6382
2024-06-04 04:44:18 [INFO]: Epoch 091 - training loss: 0.4237, validation loss: 1.6362
2024-06-04 04:44:30 [INFO]: Epoch 092 - training loss: 0.4231, validation loss: 1.6367
2024-06-04 04:44:42 [INFO]: Epoch 093 - training loss: 0.4235, validation loss: 1.6382
2024-06-04 04:44:54 [INFO]: Epoch 094 - training loss: 0.4228, validation loss: 1.6352
2024-06-04 04:45:07 [INFO]: Epoch 095 - training loss: 0.4226, validation loss: 1.6335
2024-06-04 04:45:18 [INFO]: Epoch 096 - training loss: 0.4222, validation loss: 1.6318
2024-06-04 04:45:30 [INFO]: Epoch 097 - training loss: 0.4217, validation loss: 1.6368
2024-06-04 04:45:43 [INFO]: Epoch 098 - training loss: 0.4218, validation loss: 1.6292
2024-06-04 04:45:55 [INFO]: Epoch 099 - training loss: 0.4209, validation loss: 1.6239
2024-06-04 04:46:07 [INFO]: Epoch 100 - training loss: 0.4209, validation loss: 1.6319
2024-06-04 04:46:07 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:46:07 [INFO]: Saved the model to results_point_rate05/Electricity/ETSformer_Electricity/round_4/20240604_T042614/ETSformer.pypots
2024-06-04 04:46:15 [INFO]: Successfully saved to results_point_rate05/Electricity/ETSformer_Electricity/round_4/imputation.pkl
2024-06-04 04:46:15 [INFO]: Round4 - ETSformer on Electricity: MAE=0.8793, MSE=1.6682, MRE=0.4708
2024-06-04 04:46:15 [INFO]: Done! Final results:
Averaged ETSformer (10,518,266 params) on Electricity: MAE=0.8780 ± 0.0077730178337244065, MSE=1.6869 ± 0.02409054812414389, MRE=0.4701 ± 0.0041617251260916, average inference time=1.84
