2024-06-04 02:52:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:52:46 [INFO]: Using the given device: cuda:0
2024-06-04 02:52:47 [INFO]: Model files will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_0/20240604_T025246
2024-06-04 02:52:47 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_0/20240604_T025246/tensorboard
2024-06-04 02:52:48 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-04 02:53:09 [INFO]: Epoch 001 - training loss: 1.4896, validation loss: 3.8438
2024-06-04 02:53:37 [INFO]: Epoch 002 - training loss: 1.1905, validation loss: 3.6989
2024-06-04 02:54:05 [INFO]: Epoch 003 - training loss: 1.0531, validation loss: 3.5919
2024-06-04 02:54:34 [INFO]: Epoch 004 - training loss: 0.8816, validation loss: 3.2822
2024-06-04 02:55:03 [INFO]: Epoch 005 - training loss: 0.7298, validation loss: 3.1358
2024-06-04 02:55:32 [INFO]: Epoch 006 - training loss: 0.6801, validation loss: 3.0836
2024-06-04 02:56:00 [INFO]: Epoch 007 - training loss: 0.6565, validation loss: 3.0464
2024-06-04 02:56:30 [INFO]: Epoch 008 - training loss: 0.6352, validation loss: 3.0172
2024-06-04 02:56:59 [INFO]: Epoch 009 - training loss: 0.6128, validation loss: 2.9966
2024-06-04 02:57:28 [INFO]: Epoch 010 - training loss: 0.5917, validation loss: 2.9769
2024-06-04 02:57:57 [INFO]: Epoch 011 - training loss: 0.5763, validation loss: 2.9650
2024-06-04 02:58:26 [INFO]: Epoch 012 - training loss: 0.5658, validation loss: 2.9529
2024-06-04 02:58:55 [INFO]: Epoch 013 - training loss: 0.5564, validation loss: 2.9340
2024-06-04 02:59:24 [INFO]: Epoch 014 - training loss: 0.5470, validation loss: 2.9315
2024-06-04 02:59:53 [INFO]: Epoch 015 - training loss: 0.5398, validation loss: 2.9239
2024-06-04 03:00:22 [INFO]: Epoch 016 - training loss: 0.5345, validation loss: 2.9116
2024-06-04 03:00:51 [INFO]: Epoch 017 - training loss: 0.5267, validation loss: 2.9031
2024-06-04 03:01:21 [INFO]: Epoch 018 - training loss: 0.5201, validation loss: 2.8965
2024-06-04 03:01:49 [INFO]: Epoch 019 - training loss: 0.5155, validation loss: 2.8929
2024-06-04 03:02:19 [INFO]: Epoch 020 - training loss: 0.5112, validation loss: 2.8846
2024-06-04 03:02:47 [INFO]: Epoch 021 - training loss: 0.5072, validation loss: 2.8885
2024-06-04 03:03:16 [INFO]: Epoch 022 - training loss: 0.5038, validation loss: 2.8714
2024-06-04 03:03:45 [INFO]: Epoch 023 - training loss: 0.4991, validation loss: 2.8608
2024-06-04 03:04:14 [INFO]: Epoch 024 - training loss: 0.4958, validation loss: 2.8540
2024-06-04 03:04:43 [INFO]: Epoch 025 - training loss: 0.4919, validation loss: 2.8455
2024-06-04 03:05:12 [INFO]: Epoch 026 - training loss: 0.4883, validation loss: 2.8363
2024-06-04 03:05:41 [INFO]: Epoch 027 - training loss: 0.4856, validation loss: 2.8325
2024-06-04 03:06:10 [INFO]: Epoch 028 - training loss: 0.4818, validation loss: 2.8226
2024-06-04 03:06:39 [INFO]: Epoch 029 - training loss: 0.4789, validation loss: 2.8150
2024-06-04 03:07:08 [INFO]: Epoch 030 - training loss: 0.4762, validation loss: 2.8138
2024-06-04 03:07:36 [INFO]: Epoch 031 - training loss: 0.4727, validation loss: 2.7996
2024-06-04 03:08:06 [INFO]: Epoch 032 - training loss: 0.4705, validation loss: 2.7963
2024-06-04 03:08:35 [INFO]: Epoch 033 - training loss: 0.4684, validation loss: 2.7976
2024-06-04 03:09:04 [INFO]: Epoch 034 - training loss: 0.4661, validation loss: 2.7893
2024-06-04 03:09:33 [INFO]: Epoch 035 - training loss: 0.4639, validation loss: 2.7778
2024-06-04 03:10:02 [INFO]: Epoch 036 - training loss: 0.4613, validation loss: 2.7753
2024-06-04 03:10:31 [INFO]: Epoch 037 - training loss: 0.4592, validation loss: 2.7699
2024-06-04 03:11:00 [INFO]: Epoch 038 - training loss: 0.4577, validation loss: 2.7626
2024-06-04 03:11:29 [INFO]: Epoch 039 - training loss: 0.4559, validation loss: 2.7583
2024-06-04 03:11:58 [INFO]: Epoch 040 - training loss: 0.4540, validation loss: 2.7526
2024-06-04 03:12:26 [INFO]: Epoch 041 - training loss: 0.4516, validation loss: 2.7482
2024-06-04 03:12:55 [INFO]: Epoch 042 - training loss: 0.4501, validation loss: 2.7412
2024-06-04 03:13:24 [INFO]: Epoch 043 - training loss: 0.4493, validation loss: 2.7391
2024-06-04 03:13:53 [INFO]: Epoch 044 - training loss: 0.4467, validation loss: 2.7338
2024-06-04 03:14:21 [INFO]: Epoch 045 - training loss: 0.4459, validation loss: 2.7276
2024-06-04 03:14:50 [INFO]: Epoch 046 - training loss: 0.4439, validation loss: 2.7262
2024-06-04 03:15:19 [INFO]: Epoch 047 - training loss: 0.4421, validation loss: 2.7163
2024-06-04 03:15:48 [INFO]: Epoch 048 - training loss: 0.4412, validation loss: 2.7106
2024-06-04 03:16:17 [INFO]: Epoch 049 - training loss: 0.4396, validation loss: 2.7096
2024-06-04 03:16:46 [INFO]: Epoch 050 - training loss: 0.4384, validation loss: 2.7079
2024-06-04 03:17:15 [INFO]: Epoch 051 - training loss: 0.4373, validation loss: 2.7035
2024-06-04 03:17:44 [INFO]: Epoch 052 - training loss: 0.4361, validation loss: 2.6947
2024-06-04 03:18:13 [INFO]: Epoch 053 - training loss: 0.4348, validation loss: 2.6935
2024-06-04 03:18:42 [INFO]: Epoch 054 - training loss: 0.4336, validation loss: 2.6880
2024-06-04 03:19:10 [INFO]: Epoch 055 - training loss: 0.4317, validation loss: 2.6851
2024-06-04 03:19:39 [INFO]: Epoch 056 - training loss: 0.4310, validation loss: 2.6763
2024-06-04 03:20:09 [INFO]: Epoch 057 - training loss: 0.4302, validation loss: 2.6736
2024-06-04 03:20:37 [INFO]: Epoch 058 - training loss: 0.4289, validation loss: 2.6662
2024-06-04 03:21:06 [INFO]: Epoch 059 - training loss: 0.4282, validation loss: 2.6633
2024-06-04 03:21:35 [INFO]: Epoch 060 - training loss: 0.4272, validation loss: 2.6601
2024-06-04 03:22:04 [INFO]: Epoch 061 - training loss: 0.4258, validation loss: 2.6530
2024-06-04 03:22:33 [INFO]: Epoch 062 - training loss: 0.4247, validation loss: 2.6542
2024-06-04 03:23:03 [INFO]: Epoch 063 - training loss: 0.4235, validation loss: 2.6498
2024-06-04 03:23:30 [INFO]: Epoch 064 - training loss: 0.4224, validation loss: 2.6492
2024-06-04 03:23:58 [INFO]: Epoch 065 - training loss: 0.4218, validation loss: 2.6391
2024-06-04 03:24:27 [INFO]: Epoch 066 - training loss: 0.4220, validation loss: 2.6440
2024-06-04 03:24:56 [INFO]: Epoch 067 - training loss: 0.4207, validation loss: 2.6407
2024-06-04 03:25:25 [INFO]: Epoch 068 - training loss: 0.4192, validation loss: 2.6294
2024-06-04 03:25:54 [INFO]: Epoch 069 - training loss: 0.4186, validation loss: 2.6270
2024-06-04 03:26:23 [INFO]: Epoch 070 - training loss: 0.4173, validation loss: 2.6294
2024-06-04 03:26:53 [INFO]: Epoch 071 - training loss: 0.4170, validation loss: 2.6251
2024-06-04 03:27:22 [INFO]: Epoch 072 - training loss: 0.4163, validation loss: 2.6267
2024-06-04 03:27:48 [INFO]: Epoch 073 - training loss: 0.4160, validation loss: 2.6216
2024-06-04 03:28:13 [INFO]: Epoch 074 - training loss: 0.4141, validation loss: 2.6140
2024-06-04 03:28:43 [INFO]: Epoch 075 - training loss: 0.4132, validation loss: 2.6143
2024-06-04 03:29:12 [INFO]: Epoch 076 - training loss: 0.4123, validation loss: 2.6100
2024-06-04 03:29:40 [INFO]: Epoch 077 - training loss: 0.4111, validation loss: 2.6071
2024-06-04 03:30:09 [INFO]: Epoch 078 - training loss: 0.4106, validation loss: 2.6067
2024-06-04 03:30:37 [INFO]: Epoch 079 - training loss: 0.4098, validation loss: 2.6007
2024-06-04 03:31:06 [INFO]: Epoch 080 - training loss: 0.4097, validation loss: 2.5986
2024-06-04 03:31:35 [INFO]: Epoch 081 - training loss: 0.4087, validation loss: 2.5973
2024-06-04 03:32:04 [INFO]: Epoch 082 - training loss: 0.4083, validation loss: 2.5955
2024-06-04 03:32:33 [INFO]: Epoch 083 - training loss: 0.4073, validation loss: 2.5891
2024-06-04 03:33:02 [INFO]: Epoch 084 - training loss: 0.4065, validation loss: 2.5877
2024-06-04 03:33:31 [INFO]: Epoch 085 - training loss: 0.4061, validation loss: 2.5887
2024-06-04 03:34:01 [INFO]: Epoch 086 - training loss: 0.4054, validation loss: 2.5859
2024-06-04 03:34:30 [INFO]: Epoch 087 - training loss: 0.4049, validation loss: 2.5756
2024-06-04 03:34:59 [INFO]: Epoch 088 - training loss: 0.4050, validation loss: 2.5734
2024-06-04 03:35:28 [INFO]: Epoch 089 - training loss: 0.4040, validation loss: 2.5756
2024-06-04 03:35:57 [INFO]: Epoch 090 - training loss: 0.4025, validation loss: 2.5764
2024-06-04 03:36:26 [INFO]: Epoch 091 - training loss: 0.4019, validation loss: 2.5702
2024-06-04 03:36:56 [INFO]: Epoch 092 - training loss: 0.4020, validation loss: 2.5676
2024-06-04 03:37:25 [INFO]: Epoch 093 - training loss: 0.4005, validation loss: 2.5677
2024-06-04 03:37:54 [INFO]: Epoch 094 - training loss: 0.4003, validation loss: 2.5633
2024-06-04 03:38:22 [INFO]: Epoch 095 - training loss: 0.4000, validation loss: 2.5672
2024-06-04 03:38:50 [INFO]: Epoch 096 - training loss: 0.3997, validation loss: 2.5654
2024-06-04 03:39:18 [INFO]: Epoch 097 - training loss: 0.3990, validation loss: 2.5615
2024-06-04 03:39:47 [INFO]: Epoch 098 - training loss: 0.3978, validation loss: 2.5563
2024-06-04 03:40:15 [INFO]: Epoch 099 - training loss: 0.3979, validation loss: 2.5673
2024-06-04 03:40:43 [INFO]: Epoch 100 - training loss: 0.3975, validation loss: 2.5565
2024-06-04 03:40:43 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 03:40:43 [INFO]: Saved the model to results_point_rate05/Electricity/StemGNN_Electricity/round_0/20240604_T025246/StemGNN.pypots
2024-06-04 03:40:57 [INFO]: Successfully saved to results_point_rate05/Electricity/StemGNN_Electricity/round_0/imputation.pkl
2024-06-04 03:40:57 [INFO]: Round0 - StemGNN on Electricity: MAE=1.2886, MSE=3.3272, MRE=0.6899
2024-06-04 03:40:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:40:57 [INFO]: Using the given device: cuda:0
2024-06-04 03:40:57 [INFO]: Model files will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_1/20240604_T034057
2024-06-04 03:40:57 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_1/20240604_T034057/tensorboard
2024-06-04 03:40:58 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-04 03:41:27 [INFO]: Epoch 001 - training loss: 1.4937, validation loss: 3.8289
2024-06-04 03:41:55 [INFO]: Epoch 002 - training loss: 1.1855, validation loss: 3.6841
2024-06-04 03:42:23 [INFO]: Epoch 003 - training loss: 1.0296, validation loss: 3.5924
2024-06-04 03:42:47 [INFO]: Epoch 004 - training loss: 0.8749, validation loss: 3.4324
2024-06-04 03:43:14 [INFO]: Epoch 005 - training loss: 0.7477, validation loss: 3.3353
2024-06-04 03:43:42 [INFO]: Epoch 006 - training loss: 0.6815, validation loss: 3.2532
2024-06-04 03:44:09 [INFO]: Epoch 007 - training loss: 0.6561, validation loss: 3.1676
2024-06-04 03:44:36 [INFO]: Epoch 008 - training loss: 0.6399, validation loss: 3.1166
2024-06-04 03:45:05 [INFO]: Epoch 009 - training loss: 0.6245, validation loss: 3.0683
2024-06-04 03:45:33 [INFO]: Epoch 010 - training loss: 0.6073, validation loss: 3.0219
2024-06-04 03:46:01 [INFO]: Epoch 011 - training loss: 0.5908, validation loss: 2.9936
2024-06-04 03:46:29 [INFO]: Epoch 012 - training loss: 0.5774, validation loss: 2.9749
2024-06-04 03:46:57 [INFO]: Epoch 013 - training loss: 0.5684, validation loss: 2.9548
2024-06-04 03:47:25 [INFO]: Epoch 014 - training loss: 0.5600, validation loss: 2.9285
2024-06-04 03:47:53 [INFO]: Epoch 015 - training loss: 0.5524, validation loss: 2.9007
2024-06-04 03:48:21 [INFO]: Epoch 016 - training loss: 0.5455, validation loss: 2.8860
2024-06-04 03:48:50 [INFO]: Epoch 017 - training loss: 0.5399, validation loss: 2.8704
2024-06-04 03:49:18 [INFO]: Epoch 018 - training loss: 0.5330, validation loss: 2.8545
2024-06-04 03:49:46 [INFO]: Epoch 019 - training loss: 0.5279, validation loss: 2.8390
2024-06-04 03:50:14 [INFO]: Epoch 020 - training loss: 0.5232, validation loss: 2.8304
2024-06-04 03:50:42 [INFO]: Epoch 021 - training loss: 0.5190, validation loss: 2.8300
2024-06-04 03:51:10 [INFO]: Epoch 022 - training loss: 0.5133, validation loss: 2.8178
2024-06-04 03:51:38 [INFO]: Epoch 023 - training loss: 0.5087, validation loss: 2.8049
2024-06-04 03:52:07 [INFO]: Epoch 024 - training loss: 0.5045, validation loss: 2.8019
2024-06-04 03:52:35 [INFO]: Epoch 025 - training loss: 0.5001, validation loss: 2.7919
2024-06-04 03:53:02 [INFO]: Epoch 026 - training loss: 0.4969, validation loss: 2.7818
2024-06-04 03:53:30 [INFO]: Epoch 027 - training loss: 0.4933, validation loss: 2.7846
2024-06-04 03:53:58 [INFO]: Epoch 028 - training loss: 0.4906, validation loss: 2.7799
2024-06-04 03:54:26 [INFO]: Epoch 029 - training loss: 0.4877, validation loss: 2.7650
2024-06-04 03:54:54 [INFO]: Epoch 030 - training loss: 0.4848, validation loss: 2.7629
2024-06-04 03:55:22 [INFO]: Epoch 031 - training loss: 0.4818, validation loss: 2.7481
2024-06-04 03:55:50 [INFO]: Epoch 032 - training loss: 0.4789, validation loss: 2.7461
2024-06-04 03:56:18 [INFO]: Epoch 033 - training loss: 0.4761, validation loss: 2.7423
2024-06-04 03:56:46 [INFO]: Epoch 034 - training loss: 0.4735, validation loss: 2.7383
2024-06-04 03:57:14 [INFO]: Epoch 035 - training loss: 0.4714, validation loss: 2.7290
2024-06-04 03:57:42 [INFO]: Epoch 036 - training loss: 0.4691, validation loss: 2.7222
2024-06-04 03:58:10 [INFO]: Epoch 037 - training loss: 0.4669, validation loss: 2.7217
2024-06-04 03:58:38 [INFO]: Epoch 038 - training loss: 0.4648, validation loss: 2.7183
2024-06-04 03:59:07 [INFO]: Epoch 039 - training loss: 0.4628, validation loss: 2.7056
2024-06-04 03:59:35 [INFO]: Epoch 040 - training loss: 0.4610, validation loss: 2.7053
2024-06-04 04:00:03 [INFO]: Epoch 041 - training loss: 0.4588, validation loss: 2.6954
2024-06-04 04:00:31 [INFO]: Epoch 042 - training loss: 0.4569, validation loss: 2.6846
2024-06-04 04:00:59 [INFO]: Epoch 043 - training loss: 0.4551, validation loss: 2.6866
2024-06-04 04:01:27 [INFO]: Epoch 044 - training loss: 0.4534, validation loss: 2.6768
2024-06-04 04:01:55 [INFO]: Epoch 045 - training loss: 0.4516, validation loss: 2.6751
2024-06-04 04:02:23 [INFO]: Epoch 046 - training loss: 0.4500, validation loss: 2.6640
2024-06-04 04:02:51 [INFO]: Epoch 047 - training loss: 0.4479, validation loss: 2.6669
2024-06-04 04:03:19 [INFO]: Epoch 048 - training loss: 0.4457, validation loss: 2.6596
2024-06-04 04:03:48 [INFO]: Epoch 049 - training loss: 0.4451, validation loss: 2.6581
2024-06-04 04:04:15 [INFO]: Epoch 050 - training loss: 0.4428, validation loss: 2.6498
2024-06-04 04:04:43 [INFO]: Epoch 051 - training loss: 0.4415, validation loss: 2.6405
2024-06-04 04:05:11 [INFO]: Epoch 052 - training loss: 0.4396, validation loss: 2.6428
2024-06-04 04:05:39 [INFO]: Epoch 053 - training loss: 0.4381, validation loss: 2.6337
2024-06-04 04:06:07 [INFO]: Epoch 054 - training loss: 0.4366, validation loss: 2.6347
2024-06-04 04:06:35 [INFO]: Epoch 055 - training loss: 0.4352, validation loss: 2.6329
2024-06-04 04:07:04 [INFO]: Epoch 056 - training loss: 0.4346, validation loss: 2.6278
2024-06-04 04:07:32 [INFO]: Epoch 057 - training loss: 0.4329, validation loss: 2.6240
2024-06-04 04:07:58 [INFO]: Epoch 058 - training loss: 0.4314, validation loss: 2.6168
2024-06-04 04:08:26 [INFO]: Epoch 059 - training loss: 0.4304, validation loss: 2.6167
2024-06-04 04:08:54 [INFO]: Epoch 060 - training loss: 0.4295, validation loss: 2.6108
2024-06-04 04:09:22 [INFO]: Epoch 061 - training loss: 0.4288, validation loss: 2.6071
2024-06-04 04:09:50 [INFO]: Epoch 062 - training loss: 0.4274, validation loss: 2.6121
2024-06-04 04:10:19 [INFO]: Epoch 063 - training loss: 0.4271, validation loss: 2.6014
2024-06-04 04:10:47 [INFO]: Epoch 064 - training loss: 0.4248, validation loss: 2.5987
2024-06-04 04:11:15 [INFO]: Epoch 065 - training loss: 0.4241, validation loss: 2.5928
2024-06-04 04:11:43 [INFO]: Epoch 066 - training loss: 0.4234, validation loss: 2.5913
2024-06-04 04:12:12 [INFO]: Epoch 067 - training loss: 0.4225, validation loss: 2.5923
2024-06-04 04:12:40 [INFO]: Epoch 068 - training loss: 0.4213, validation loss: 2.5823
2024-06-04 04:13:09 [INFO]: Epoch 069 - training loss: 0.4200, validation loss: 2.5843
2024-06-04 04:13:37 [INFO]: Epoch 070 - training loss: 0.4192, validation loss: 2.5810
2024-06-04 04:14:05 [INFO]: Epoch 071 - training loss: 0.4187, validation loss: 2.5840
2024-06-04 04:14:33 [INFO]: Epoch 072 - training loss: 0.4178, validation loss: 2.5722
2024-06-04 04:15:01 [INFO]: Epoch 073 - training loss: 0.4171, validation loss: 2.5669
2024-06-04 04:15:29 [INFO]: Epoch 074 - training loss: 0.4164, validation loss: 2.5637
2024-06-04 04:15:57 [INFO]: Epoch 075 - training loss: 0.4153, validation loss: 2.5598
2024-06-04 04:16:25 [INFO]: Epoch 076 - training loss: 0.4139, validation loss: 2.5639
2024-06-04 04:16:48 [INFO]: Epoch 077 - training loss: 0.4133, validation loss: 2.5567
2024-06-04 04:17:16 [INFO]: Epoch 078 - training loss: 0.4127, validation loss: 2.5594
2024-06-04 04:17:44 [INFO]: Epoch 079 - training loss: 0.4121, validation loss: 2.5521
2024-06-04 04:18:11 [INFO]: Epoch 080 - training loss: 0.4112, validation loss: 2.5555
2024-06-04 04:18:39 [INFO]: Epoch 081 - training loss: 0.4111, validation loss: 2.5490
2024-06-04 04:19:07 [INFO]: Epoch 082 - training loss: 0.4102, validation loss: 2.5416
2024-06-04 04:19:35 [INFO]: Epoch 083 - training loss: 0.4096, validation loss: 2.5409
2024-06-04 04:20:03 [INFO]: Epoch 084 - training loss: 0.4086, validation loss: 2.5344
2024-06-04 04:20:31 [INFO]: Epoch 085 - training loss: 0.4076, validation loss: 2.5377
2024-06-04 04:20:59 [INFO]: Epoch 086 - training loss: 0.4075, validation loss: 2.5300
2024-06-04 04:21:27 [INFO]: Epoch 087 - training loss: 0.4068, validation loss: 2.5297
2024-06-04 04:21:55 [INFO]: Epoch 088 - training loss: 0.4058, validation loss: 2.5243
2024-06-04 04:22:23 [INFO]: Epoch 089 - training loss: 0.4057, validation loss: 2.5297
2024-06-04 04:22:51 [INFO]: Epoch 090 - training loss: 0.4046, validation loss: 2.5246
2024-06-04 04:23:19 [INFO]: Epoch 091 - training loss: 0.4041, validation loss: 2.5204
2024-06-04 04:23:48 [INFO]: Epoch 092 - training loss: 0.4038, validation loss: 2.5172
2024-06-04 04:24:16 [INFO]: Epoch 093 - training loss: 0.4028, validation loss: 2.5201
2024-06-04 04:24:44 [INFO]: Epoch 094 - training loss: 0.4025, validation loss: 2.5172
2024-06-04 04:25:13 [INFO]: Epoch 095 - training loss: 0.4018, validation loss: 2.5198
2024-06-04 04:25:41 [INFO]: Epoch 096 - training loss: 0.4016, validation loss: 2.5094
2024-06-04 04:26:08 [INFO]: Epoch 097 - training loss: 0.4005, validation loss: 2.5079
2024-06-04 04:26:31 [INFO]: Epoch 098 - training loss: 0.3999, validation loss: 2.5049
2024-06-04 04:26:55 [INFO]: Epoch 099 - training loss: 0.3995, validation loss: 2.5015
2024-06-04 04:27:19 [INFO]: Epoch 100 - training loss: 0.3988, validation loss: 2.5090
2024-06-04 04:27:19 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:27:19 [INFO]: Saved the model to results_point_rate05/Electricity/StemGNN_Electricity/round_1/20240604_T034057/StemGNN.pypots
2024-06-04 04:27:32 [INFO]: Successfully saved to results_point_rate05/Electricity/StemGNN_Electricity/round_1/imputation.pkl
2024-06-04 04:27:32 [INFO]: Round1 - StemGNN on Electricity: MAE=1.1999, MSE=3.0218, MRE=0.6424
2024-06-04 04:27:32 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 04:27:32 [INFO]: Using the given device: cuda:0
2024-06-04 04:27:32 [INFO]: Model files will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_2/20240604_T042732
2024-06-04 04:27:32 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_2/20240604_T042732/tensorboard
2024-06-04 04:27:32 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-04 04:27:55 [INFO]: Epoch 001 - training loss: 1.4926, validation loss: 3.8611
2024-06-04 04:28:18 [INFO]: Epoch 002 - training loss: 1.2035, validation loss: 3.7249
2024-06-04 04:28:42 [INFO]: Epoch 003 - training loss: 1.0338, validation loss: 3.6217
2024-06-04 04:29:06 [INFO]: Epoch 004 - training loss: 0.8608, validation loss: 3.5147
2024-06-04 04:29:29 [INFO]: Epoch 005 - training loss: 0.7441, validation loss: 3.4665
2024-06-04 04:29:48 [INFO]: Epoch 006 - training loss: 0.6732, validation loss: 3.4139
2024-06-04 04:30:11 [INFO]: Epoch 007 - training loss: 0.6397, validation loss: 3.3626
2024-06-04 04:30:34 [INFO]: Epoch 008 - training loss: 0.6170, validation loss: 3.3263
2024-06-04 04:30:58 [INFO]: Epoch 009 - training loss: 0.6003, validation loss: 3.3071
2024-06-04 04:31:22 [INFO]: Epoch 010 - training loss: 0.5879, validation loss: 3.2864
2024-06-04 04:31:45 [INFO]: Epoch 011 - training loss: 0.5782, validation loss: 3.2558
2024-06-04 04:32:08 [INFO]: Epoch 012 - training loss: 0.5710, validation loss: 3.2586
2024-06-04 04:32:32 [INFO]: Epoch 013 - training loss: 0.5625, validation loss: 3.2337
2024-06-04 04:32:55 [INFO]: Epoch 014 - training loss: 0.5541, validation loss: 3.2217
2024-06-04 04:33:19 [INFO]: Epoch 015 - training loss: 0.5463, validation loss: 3.1948
2024-06-04 04:33:43 [INFO]: Epoch 016 - training loss: 0.5381, validation loss: 3.1909
2024-06-04 04:34:06 [INFO]: Epoch 017 - training loss: 0.5320, validation loss: 3.1781
2024-06-04 04:34:30 [INFO]: Epoch 018 - training loss: 0.5279, validation loss: 3.1749
2024-06-04 04:34:54 [INFO]: Epoch 019 - training loss: 0.5222, validation loss: 3.1656
2024-06-04 04:35:17 [INFO]: Epoch 020 - training loss: 0.5177, validation loss: 3.1613
2024-06-04 04:35:41 [INFO]: Epoch 021 - training loss: 0.5139, validation loss: 3.1484
2024-06-04 04:36:05 [INFO]: Epoch 022 - training loss: 0.5098, validation loss: 3.1531
2024-06-04 04:36:29 [INFO]: Epoch 023 - training loss: 0.5062, validation loss: 3.1462
2024-06-04 04:36:52 [INFO]: Epoch 024 - training loss: 0.5027, validation loss: 3.1421
2024-06-04 04:37:16 [INFO]: Epoch 025 - training loss: 0.4988, validation loss: 3.1432
2024-06-04 04:37:40 [INFO]: Epoch 026 - training loss: 0.4952, validation loss: 3.1387
2024-06-04 04:38:04 [INFO]: Epoch 027 - training loss: 0.4925, validation loss: 3.1196
2024-06-04 04:38:28 [INFO]: Epoch 028 - training loss: 0.4901, validation loss: 3.1293
2024-06-04 04:38:51 [INFO]: Epoch 029 - training loss: 0.4867, validation loss: 3.1274
2024-06-04 04:39:15 [INFO]: Epoch 030 - training loss: 0.4844, validation loss: 3.1263
2024-06-04 04:39:38 [INFO]: Epoch 031 - training loss: 0.4831, validation loss: 3.1279
2024-06-04 04:40:02 [INFO]: Epoch 032 - training loss: 0.4808, validation loss: 3.1252
2024-06-04 04:40:25 [INFO]: Epoch 033 - training loss: 0.4783, validation loss: 3.1271
2024-06-04 04:40:49 [INFO]: Epoch 034 - training loss: 0.4764, validation loss: 3.1225
2024-06-04 04:41:12 [INFO]: Epoch 035 - training loss: 0.4740, validation loss: 3.1140
2024-06-04 04:41:36 [INFO]: Epoch 036 - training loss: 0.4728, validation loss: 3.1160
2024-06-04 04:42:00 [INFO]: Epoch 037 - training loss: 0.4710, validation loss: 3.1143
2024-06-04 04:42:23 [INFO]: Epoch 038 - training loss: 0.4690, validation loss: 3.0985
2024-06-04 04:42:47 [INFO]: Epoch 039 - training loss: 0.4676, validation loss: 3.1049
2024-06-04 04:43:11 [INFO]: Epoch 040 - training loss: 0.4653, validation loss: 3.0938
2024-06-04 04:43:34 [INFO]: Epoch 041 - training loss: 0.4635, validation loss: 3.0833
2024-06-04 04:43:58 [INFO]: Epoch 042 - training loss: 0.4626, validation loss: 3.0925
2024-06-04 04:44:22 [INFO]: Epoch 043 - training loss: 0.4611, validation loss: 3.0969
2024-06-04 04:44:45 [INFO]: Epoch 044 - training loss: 0.4594, validation loss: 3.0860
2024-06-04 04:45:09 [INFO]: Epoch 045 - training loss: 0.4572, validation loss: 3.0702
2024-06-04 04:45:33 [INFO]: Epoch 046 - training loss: 0.4552, validation loss: 3.0814
2024-06-04 04:45:56 [INFO]: Epoch 047 - training loss: 0.4544, validation loss: 3.0682
2024-06-04 04:46:20 [INFO]: Epoch 048 - training loss: 0.4522, validation loss: 3.0695
2024-06-04 04:46:44 [INFO]: Epoch 049 - training loss: 0.4515, validation loss: 3.0665
2024-06-04 04:47:07 [INFO]: Epoch 050 - training loss: 0.4499, validation loss: 3.0716
2024-06-04 04:47:31 [INFO]: Epoch 051 - training loss: 0.4487, validation loss: 3.0574
2024-06-04 04:47:55 [INFO]: Epoch 052 - training loss: 0.4471, validation loss: 3.0547
2024-06-04 04:48:18 [INFO]: Epoch 053 - training loss: 0.4459, validation loss: 3.0559
2024-06-04 04:48:42 [INFO]: Epoch 054 - training loss: 0.4445, validation loss: 3.0563
2024-06-04 04:49:06 [INFO]: Epoch 055 - training loss: 0.4432, validation loss: 3.0504
2024-06-04 04:49:29 [INFO]: Epoch 056 - training loss: 0.4410, validation loss: 3.0529
2024-06-04 04:49:53 [INFO]: Epoch 057 - training loss: 0.4409, validation loss: 3.0411
2024-06-04 04:50:17 [INFO]: Epoch 058 - training loss: 0.4401, validation loss: 3.0466
2024-06-04 04:50:40 [INFO]: Epoch 059 - training loss: 0.4381, validation loss: 3.0240
2024-06-04 04:51:04 [INFO]: Epoch 060 - training loss: 0.4370, validation loss: 3.0391
2024-06-04 04:51:27 [INFO]: Epoch 061 - training loss: 0.4357, validation loss: 3.0264
2024-06-04 04:51:51 [INFO]: Epoch 062 - training loss: 0.4356, validation loss: 3.0383
2024-06-04 04:52:15 [INFO]: Epoch 063 - training loss: 0.4335, validation loss: 3.0244
2024-06-04 04:52:38 [INFO]: Epoch 064 - training loss: 0.4327, validation loss: 3.0242
2024-06-04 04:53:02 [INFO]: Epoch 065 - training loss: 0.4323, validation loss: 3.0332
2024-06-04 04:53:26 [INFO]: Epoch 066 - training loss: 0.4325, validation loss: 3.0323
2024-06-04 04:53:49 [INFO]: Epoch 067 - training loss: 0.4301, validation loss: 3.0312
2024-06-04 04:54:13 [INFO]: Epoch 068 - training loss: 0.4292, validation loss: 3.0273
2024-06-04 04:54:37 [INFO]: Epoch 069 - training loss: 0.4288, validation loss: 3.0174
2024-06-04 04:54:57 [INFO]: Epoch 070 - training loss: 0.4282, validation loss: 3.0220
2024-06-04 04:55:14 [INFO]: Epoch 071 - training loss: 0.4292, validation loss: 3.0203
2024-06-04 04:55:30 [INFO]: Epoch 072 - training loss: 0.4268, validation loss: 3.0225
2024-06-04 04:55:46 [INFO]: Epoch 073 - training loss: 0.4255, validation loss: 3.0179
2024-06-04 04:56:02 [INFO]: Epoch 074 - training loss: 0.4245, validation loss: 3.0212
2024-06-04 04:56:18 [INFO]: Epoch 075 - training loss: 0.4235, validation loss: 3.0193
2024-06-04 04:56:34 [INFO]: Epoch 076 - training loss: 0.4225, validation loss: 3.0167
2024-06-04 04:56:51 [INFO]: Epoch 077 - training loss: 0.4214, validation loss: 3.0130
2024-06-04 04:57:06 [INFO]: Epoch 078 - training loss: 0.4209, validation loss: 3.0149
2024-06-04 04:57:17 [INFO]: Epoch 079 - training loss: 0.4205, validation loss: 3.0170
2024-06-04 04:57:27 [INFO]: Epoch 080 - training loss: 0.4208, validation loss: 3.0083
2024-06-04 04:57:36 [INFO]: Epoch 081 - training loss: 0.4190, validation loss: 3.0001
2024-06-04 04:57:46 [INFO]: Epoch 082 - training loss: 0.4182, validation loss: 3.0053
2024-06-04 04:57:55 [INFO]: Epoch 083 - training loss: 0.4176, validation loss: 3.0025
2024-06-04 04:58:04 [INFO]: Epoch 084 - training loss: 0.4162, validation loss: 3.0072
2024-06-04 04:58:14 [INFO]: Epoch 085 - training loss: 0.4165, validation loss: 3.0212
2024-06-04 04:58:23 [INFO]: Epoch 086 - training loss: 0.4157, validation loss: 2.9982
2024-06-04 04:58:33 [INFO]: Epoch 087 - training loss: 0.4156, validation loss: 3.0046
2024-06-04 04:58:42 [INFO]: Epoch 088 - training loss: 0.4150, validation loss: 2.9950
2024-06-04 04:58:52 [INFO]: Epoch 089 - training loss: 0.4139, validation loss: 3.0036
2024-06-04 04:59:01 [INFO]: Epoch 090 - training loss: 0.4132, validation loss: 2.9961
2024-06-04 04:59:10 [INFO]: Epoch 091 - training loss: 0.4139, validation loss: 3.0007
2024-06-04 04:59:20 [INFO]: Epoch 092 - training loss: 0.4128, validation loss: 2.9993
2024-06-04 04:59:29 [INFO]: Epoch 093 - training loss: 0.4114, validation loss: 3.0009
2024-06-04 04:59:39 [INFO]: Epoch 094 - training loss: 0.4108, validation loss: 3.0037
2024-06-04 04:59:48 [INFO]: Epoch 095 - training loss: 0.4098, validation loss: 2.9878
2024-06-04 04:59:57 [INFO]: Epoch 096 - training loss: 0.4098, validation loss: 2.9918
2024-06-04 05:00:07 [INFO]: Epoch 097 - training loss: 0.4095, validation loss: 2.9889
2024-06-04 05:00:16 [INFO]: Epoch 098 - training loss: 0.4086, validation loss: 2.9845
2024-06-04 05:00:26 [INFO]: Epoch 099 - training loss: 0.4075, validation loss: 2.9825
2024-06-04 05:00:35 [INFO]: Epoch 100 - training loss: 0.4072, validation loss: 2.9873
2024-06-04 05:00:35 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 05:00:35 [INFO]: Saved the model to results_point_rate05/Electricity/StemGNN_Electricity/round_2/20240604_T042732/StemGNN.pypots
2024-06-04 05:00:40 [INFO]: Successfully saved to results_point_rate05/Electricity/StemGNN_Electricity/round_2/imputation.pkl
2024-06-04 05:00:40 [INFO]: Round2 - StemGNN on Electricity: MAE=1.5982, MSE=4.9475, MRE=0.8557
2024-06-04 05:00:40 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 05:00:40 [INFO]: Using the given device: cuda:0
2024-06-04 05:00:40 [INFO]: Model files will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_3/20240604_T050040
2024-06-04 05:00:40 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_3/20240604_T050040/tensorboard
2024-06-04 05:00:40 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-04 05:00:50 [INFO]: Epoch 001 - training loss: 1.4988, validation loss: 3.8701
2024-06-04 05:01:00 [INFO]: Epoch 002 - training loss: 1.2185, validation loss: 3.7195
2024-06-04 05:01:09 [INFO]: Epoch 003 - training loss: 1.0424, validation loss: 3.6605
2024-06-04 05:01:18 [INFO]: Epoch 004 - training loss: 0.8629, validation loss: 3.5148
2024-06-04 05:01:28 [INFO]: Epoch 005 - training loss: 0.7166, validation loss: 3.4220
2024-06-04 05:01:37 [INFO]: Epoch 006 - training loss: 0.6712, validation loss: 3.3584
2024-06-04 05:01:46 [INFO]: Epoch 007 - training loss: 0.6511, validation loss: 3.3163
2024-06-04 05:01:56 [INFO]: Epoch 008 - training loss: 0.6374, validation loss: 3.2944
2024-06-04 05:02:05 [INFO]: Epoch 009 - training loss: 0.6209, validation loss: 3.2607
2024-06-04 05:02:15 [INFO]: Epoch 010 - training loss: 0.6033, validation loss: 3.2282
2024-06-04 05:02:24 [INFO]: Epoch 011 - training loss: 0.5898, validation loss: 3.1976
2024-06-04 05:02:33 [INFO]: Epoch 012 - training loss: 0.5795, validation loss: 3.2022
2024-06-04 05:02:43 [INFO]: Epoch 013 - training loss: 0.5712, validation loss: 3.1917
2024-06-04 05:02:52 [INFO]: Epoch 014 - training loss: 0.5645, validation loss: 3.1778
2024-06-04 05:03:02 [INFO]: Epoch 015 - training loss: 0.5567, validation loss: 3.1746
2024-06-04 05:03:11 [INFO]: Epoch 016 - training loss: 0.5492, validation loss: 3.1545
2024-06-04 05:03:21 [INFO]: Epoch 017 - training loss: 0.5406, validation loss: 3.1411
2024-06-04 05:03:30 [INFO]: Epoch 018 - training loss: 0.5333, validation loss: 3.1445
2024-06-04 05:03:39 [INFO]: Epoch 019 - training loss: 0.5260, validation loss: 3.1473
2024-06-04 05:03:49 [INFO]: Epoch 020 - training loss: 0.5211, validation loss: 3.1288
2024-06-04 05:03:58 [INFO]: Epoch 021 - training loss: 0.5159, validation loss: 3.1453
2024-06-04 05:04:08 [INFO]: Epoch 022 - training loss: 0.5103, validation loss: 3.1414
2024-06-04 05:04:17 [INFO]: Epoch 023 - training loss: 0.5062, validation loss: 3.1534
2024-06-04 05:04:26 [INFO]: Epoch 024 - training loss: 0.5025, validation loss: 3.1242
2024-06-04 05:04:36 [INFO]: Epoch 025 - training loss: 0.5003, validation loss: 3.1462
2024-06-04 05:04:45 [INFO]: Epoch 026 - training loss: 0.4979, validation loss: 3.1492
2024-06-04 05:04:55 [INFO]: Epoch 027 - training loss: 0.4959, validation loss: 3.1462
2024-06-04 05:05:04 [INFO]: Epoch 028 - training loss: 0.4925, validation loss: 3.1416
2024-06-04 05:05:14 [INFO]: Epoch 029 - training loss: 0.4880, validation loss: 3.1198
2024-06-04 05:05:23 [INFO]: Epoch 030 - training loss: 0.4856, validation loss: 3.1292
2024-06-04 05:05:32 [INFO]: Epoch 031 - training loss: 0.4835, validation loss: 3.1218
2024-06-04 05:05:42 [INFO]: Epoch 032 - training loss: 0.4804, validation loss: 3.1150
2024-06-04 05:05:51 [INFO]: Epoch 033 - training loss: 0.4785, validation loss: 3.1106
2024-06-04 05:06:01 [INFO]: Epoch 034 - training loss: 0.4762, validation loss: 3.0897
2024-06-04 05:06:10 [INFO]: Epoch 035 - training loss: 0.4742, validation loss: 3.1060
2024-06-04 05:06:19 [INFO]: Epoch 036 - training loss: 0.4724, validation loss: 3.0988
2024-06-04 05:06:29 [INFO]: Epoch 037 - training loss: 0.4698, validation loss: 3.0936
2024-06-04 05:06:38 [INFO]: Epoch 038 - training loss: 0.4675, validation loss: 3.0903
2024-06-04 05:06:48 [INFO]: Epoch 039 - training loss: 0.4653, validation loss: 3.0794
2024-06-04 05:06:57 [INFO]: Epoch 040 - training loss: 0.4637, validation loss: 3.0740
2024-06-04 05:07:07 [INFO]: Epoch 041 - training loss: 0.4623, validation loss: 3.0645
2024-06-04 05:07:16 [INFO]: Epoch 042 - training loss: 0.4606, validation loss: 3.0692
2024-06-04 05:07:25 [INFO]: Epoch 043 - training loss: 0.4591, validation loss: 3.0556
2024-06-04 05:07:35 [INFO]: Epoch 044 - training loss: 0.4568, validation loss: 3.0454
2024-06-04 05:07:44 [INFO]: Epoch 045 - training loss: 0.4549, validation loss: 3.0471
2024-06-04 05:07:54 [INFO]: Epoch 046 - training loss: 0.4532, validation loss: 3.0440
2024-06-04 05:08:03 [INFO]: Epoch 047 - training loss: 0.4527, validation loss: 3.0371
2024-06-04 05:08:12 [INFO]: Epoch 048 - training loss: 0.4508, validation loss: 3.0303
2024-06-04 05:08:22 [INFO]: Epoch 049 - training loss: 0.4485, validation loss: 3.0221
2024-06-04 05:08:31 [INFO]: Epoch 050 - training loss: 0.4473, validation loss: 3.0198
2024-06-04 05:08:41 [INFO]: Epoch 051 - training loss: 0.4454, validation loss: 3.0148
2024-06-04 05:08:50 [INFO]: Epoch 052 - training loss: 0.4443, validation loss: 3.0138
2024-06-04 05:08:59 [INFO]: Epoch 053 - training loss: 0.4424, validation loss: 3.0168
2024-06-04 05:09:09 [INFO]: Epoch 054 - training loss: 0.4414, validation loss: 3.0054
2024-06-04 05:09:18 [INFO]: Epoch 055 - training loss: 0.4398, validation loss: 3.0026
2024-06-04 05:09:28 [INFO]: Epoch 056 - training loss: 0.4388, validation loss: 3.0061
2024-06-04 05:09:37 [INFO]: Epoch 057 - training loss: 0.4375, validation loss: 2.9963
2024-06-04 05:09:47 [INFO]: Epoch 058 - training loss: 0.4360, validation loss: 2.9878
2024-06-04 05:09:56 [INFO]: Epoch 059 - training loss: 0.4355, validation loss: 2.9886
2024-06-04 05:10:05 [INFO]: Epoch 060 - training loss: 0.4339, validation loss: 2.9886
2024-06-04 05:10:15 [INFO]: Epoch 061 - training loss: 0.4330, validation loss: 2.9814
2024-06-04 05:10:24 [INFO]: Epoch 062 - training loss: 0.4313, validation loss: 2.9768
2024-06-04 05:10:33 [INFO]: Epoch 063 - training loss: 0.4310, validation loss: 2.9770
2024-06-04 05:10:43 [INFO]: Epoch 064 - training loss: 0.4297, validation loss: 2.9747
2024-06-04 05:10:52 [INFO]: Epoch 065 - training loss: 0.4281, validation loss: 2.9731
2024-06-04 05:11:02 [INFO]: Epoch 066 - training loss: 0.4277, validation loss: 2.9671
2024-06-04 05:11:11 [INFO]: Epoch 067 - training loss: 0.4267, validation loss: 2.9682
2024-06-04 05:11:21 [INFO]: Epoch 068 - training loss: 0.4249, validation loss: 2.9589
2024-06-04 05:11:30 [INFO]: Epoch 069 - training loss: 0.4238, validation loss: 2.9547
2024-06-04 05:11:39 [INFO]: Epoch 070 - training loss: 0.4234, validation loss: 2.9500
2024-06-04 05:11:49 [INFO]: Epoch 071 - training loss: 0.4228, validation loss: 2.9568
2024-06-04 05:11:58 [INFO]: Epoch 072 - training loss: 0.4217, validation loss: 2.9532
2024-06-04 05:12:08 [INFO]: Epoch 073 - training loss: 0.4204, validation loss: 2.9548
2024-06-04 05:12:17 [INFO]: Epoch 074 - training loss: 0.4196, validation loss: 2.9484
2024-06-04 05:12:26 [INFO]: Epoch 075 - training loss: 0.4186, validation loss: 2.9577
2024-06-04 05:12:36 [INFO]: Epoch 076 - training loss: 0.4178, validation loss: 2.9506
2024-06-04 05:12:45 [INFO]: Epoch 077 - training loss: 0.4172, validation loss: 2.9467
2024-06-04 05:12:55 [INFO]: Epoch 078 - training loss: 0.4168, validation loss: 2.9456
2024-06-04 05:13:04 [INFO]: Epoch 079 - training loss: 0.4155, validation loss: 2.9417
2024-06-04 05:13:14 [INFO]: Epoch 080 - training loss: 0.4152, validation loss: 2.9439
2024-06-04 05:13:23 [INFO]: Epoch 081 - training loss: 0.4144, validation loss: 2.9408
2024-06-04 05:13:32 [INFO]: Epoch 082 - training loss: 0.4131, validation loss: 2.9386
2024-06-04 05:13:42 [INFO]: Epoch 083 - training loss: 0.4122, validation loss: 2.9381
2024-06-04 05:13:51 [INFO]: Epoch 084 - training loss: 0.4127, validation loss: 2.9349
2024-06-04 05:14:01 [INFO]: Epoch 085 - training loss: 0.4114, validation loss: 2.9362
2024-06-04 05:14:10 [INFO]: Epoch 086 - training loss: 0.4109, validation loss: 2.9335
2024-06-04 05:14:20 [INFO]: Epoch 087 - training loss: 0.4099, validation loss: 2.9412
2024-06-04 05:14:29 [INFO]: Epoch 088 - training loss: 0.4092, validation loss: 2.9359
2024-06-04 05:14:38 [INFO]: Epoch 089 - training loss: 0.4082, validation loss: 2.9330
2024-06-04 05:14:48 [INFO]: Epoch 090 - training loss: 0.4084, validation loss: 2.9319
2024-06-04 05:14:57 [INFO]: Epoch 091 - training loss: 0.4077, validation loss: 2.9314
2024-06-04 05:15:06 [INFO]: Epoch 092 - training loss: 0.4070, validation loss: 2.9275
2024-06-04 05:15:16 [INFO]: Epoch 093 - training loss: 0.4066, validation loss: 2.9306
2024-06-04 05:15:25 [INFO]: Epoch 094 - training loss: 0.4054, validation loss: 2.9290
2024-06-04 05:15:35 [INFO]: Epoch 095 - training loss: 0.4049, validation loss: 2.9316
2024-06-04 05:15:44 [INFO]: Epoch 096 - training loss: 0.4051, validation loss: 2.9299
2024-06-04 05:15:54 [INFO]: Epoch 097 - training loss: 0.4043, validation loss: 2.9316
2024-06-04 05:16:03 [INFO]: Epoch 098 - training loss: 0.4035, validation loss: 2.9259
2024-06-04 05:16:12 [INFO]: Epoch 099 - training loss: 0.4025, validation loss: 2.9312
2024-06-04 05:16:22 [INFO]: Epoch 100 - training loss: 0.4022, validation loss: 2.9267
2024-06-04 05:16:22 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 05:16:22 [INFO]: Saved the model to results_point_rate05/Electricity/StemGNN_Electricity/round_3/20240604_T050040/StemGNN.pypots
2024-06-04 05:16:27 [INFO]: Successfully saved to results_point_rate05/Electricity/StemGNN_Electricity/round_3/imputation.pkl
2024-06-04 05:16:27 [INFO]: Round3 - StemGNN on Electricity: MAE=1.5715, MSE=4.8799, MRE=0.8414
2024-06-04 05:16:27 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 05:16:27 [INFO]: Using the given device: cuda:0
2024-06-04 05:16:27 [INFO]: Model files will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_4/20240604_T051627
2024-06-04 05:16:27 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/StemGNN_Electricity/round_4/20240604_T051627/tensorboard
2024-06-04 05:16:27 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-04 05:16:37 [INFO]: Epoch 001 - training loss: 1.4782, validation loss: 3.8572
2024-06-04 05:16:46 [INFO]: Epoch 002 - training loss: 1.2126, validation loss: 3.7039
2024-06-04 05:16:56 [INFO]: Epoch 003 - training loss: 1.0156, validation loss: 3.5781
2024-06-04 05:17:05 [INFO]: Epoch 004 - training loss: 0.8280, validation loss: 3.3822
2024-06-04 05:17:14 [INFO]: Epoch 005 - training loss: 0.7187, validation loss: 3.2302
2024-06-04 05:17:24 [INFO]: Epoch 006 - training loss: 0.6833, validation loss: 3.1628
2024-06-04 05:17:33 [INFO]: Epoch 007 - training loss: 0.6555, validation loss: 3.1122
2024-06-04 05:17:43 [INFO]: Epoch 008 - training loss: 0.6309, validation loss: 3.0719
2024-06-04 05:17:52 [INFO]: Epoch 009 - training loss: 0.6090, validation loss: 3.0340
2024-06-04 05:18:02 [INFO]: Epoch 010 - training loss: 0.5927, validation loss: 3.0004
2024-06-04 05:18:11 [INFO]: Epoch 011 - training loss: 0.5812, validation loss: 2.9856
2024-06-04 05:18:20 [INFO]: Epoch 012 - training loss: 0.5719, validation loss: 2.9613
2024-06-04 05:18:30 [INFO]: Epoch 013 - training loss: 0.5612, validation loss: 2.9481
2024-06-04 05:18:39 [INFO]: Epoch 014 - training loss: 0.5522, validation loss: 2.9312
2024-06-04 05:18:48 [INFO]: Epoch 015 - training loss: 0.5447, validation loss: 2.9106
2024-06-04 05:18:58 [INFO]: Epoch 016 - training loss: 0.5366, validation loss: 2.8956
2024-06-04 05:19:07 [INFO]: Epoch 017 - training loss: 0.5303, validation loss: 2.8807
2024-06-04 05:19:17 [INFO]: Epoch 018 - training loss: 0.5245, validation loss: 2.8647
2024-06-04 05:19:26 [INFO]: Epoch 019 - training loss: 0.5195, validation loss: 2.8552
2024-06-04 05:19:36 [INFO]: Epoch 020 - training loss: 0.5145, validation loss: 2.8410
2024-06-04 05:19:45 [INFO]: Epoch 021 - training loss: 0.5093, validation loss: 2.8341
2024-06-04 05:19:54 [INFO]: Epoch 022 - training loss: 0.5057, validation loss: 2.8238
2024-06-04 05:20:04 [INFO]: Epoch 023 - training loss: 0.5012, validation loss: 2.8079
2024-06-04 05:20:13 [INFO]: Epoch 024 - training loss: 0.4973, validation loss: 2.8070
2024-06-04 05:20:23 [INFO]: Epoch 025 - training loss: 0.4957, validation loss: 2.7947
2024-06-04 05:20:32 [INFO]: Epoch 026 - training loss: 0.4914, validation loss: 2.7875
2024-06-04 05:20:42 [INFO]: Epoch 027 - training loss: 0.4879, validation loss: 2.7779
2024-06-04 05:20:51 [INFO]: Epoch 028 - training loss: 0.4853, validation loss: 2.7693
2024-06-04 05:21:00 [INFO]: Epoch 029 - training loss: 0.4828, validation loss: 2.7595
2024-06-04 05:21:10 [INFO]: Epoch 030 - training loss: 0.4797, validation loss: 2.7517
2024-06-04 05:21:19 [INFO]: Epoch 031 - training loss: 0.4765, validation loss: 2.7477
2024-06-04 05:21:28 [INFO]: Epoch 032 - training loss: 0.4744, validation loss: 2.7424
2024-06-04 05:21:38 [INFO]: Epoch 033 - training loss: 0.4711, validation loss: 2.7375
2024-06-04 05:21:47 [INFO]: Epoch 034 - training loss: 0.4701, validation loss: 2.7297
2024-06-04 05:21:57 [INFO]: Epoch 035 - training loss: 0.4665, validation loss: 2.7233
2024-06-04 05:22:06 [INFO]: Epoch 036 - training loss: 0.4651, validation loss: 2.7155
2024-06-04 05:22:16 [INFO]: Epoch 037 - training loss: 0.4621, validation loss: 2.7064
2024-06-04 05:22:25 [INFO]: Epoch 038 - training loss: 0.4604, validation loss: 2.7091
2024-06-04 05:22:35 [INFO]: Epoch 039 - training loss: 0.4581, validation loss: 2.6947
2024-06-04 05:22:44 [INFO]: Epoch 040 - training loss: 0.4560, validation loss: 2.6991
2024-06-04 05:22:53 [INFO]: Epoch 041 - training loss: 0.4546, validation loss: 2.6875
2024-06-04 05:23:03 [INFO]: Epoch 042 - training loss: 0.4530, validation loss: 2.6761
2024-06-04 05:23:12 [INFO]: Epoch 043 - training loss: 0.4510, validation loss: 2.6839
2024-06-04 05:23:21 [INFO]: Epoch 044 - training loss: 0.4494, validation loss: 2.6694
2024-06-04 05:23:31 [INFO]: Epoch 045 - training loss: 0.4476, validation loss: 2.6645
2024-06-04 05:23:40 [INFO]: Epoch 046 - training loss: 0.4459, validation loss: 2.6637
2024-06-04 05:23:50 [INFO]: Epoch 047 - training loss: 0.4441, validation loss: 2.6550
2024-06-04 05:23:59 [INFO]: Epoch 048 - training loss: 0.4433, validation loss: 2.6557
2024-06-04 05:24:09 [INFO]: Epoch 049 - training loss: 0.4422, validation loss: 2.6477
2024-06-04 05:24:18 [INFO]: Epoch 050 - training loss: 0.4401, validation loss: 2.6429
2024-06-04 05:24:27 [INFO]: Epoch 051 - training loss: 0.4384, validation loss: 2.6374
2024-06-04 05:24:37 [INFO]: Epoch 052 - training loss: 0.4368, validation loss: 2.6301
2024-06-04 05:24:46 [INFO]: Epoch 053 - training loss: 0.4356, validation loss: 2.6240
2024-06-04 05:24:56 [INFO]: Epoch 054 - training loss: 0.4344, validation loss: 2.6262
2024-06-04 05:25:05 [INFO]: Epoch 055 - training loss: 0.4332, validation loss: 2.6168
2024-06-04 05:25:14 [INFO]: Epoch 056 - training loss: 0.4316, validation loss: 2.6131
2024-06-04 05:25:24 [INFO]: Epoch 057 - training loss: 0.4305, validation loss: 2.6092
2024-06-04 05:25:33 [INFO]: Epoch 058 - training loss: 0.4294, validation loss: 2.6019
2024-06-04 05:25:43 [INFO]: Epoch 059 - training loss: 0.4283, validation loss: 2.5968
2024-06-04 05:25:52 [INFO]: Epoch 060 - training loss: 0.4273, validation loss: 2.5983
2024-06-04 05:26:01 [INFO]: Epoch 061 - training loss: 0.4267, validation loss: 2.5954
2024-06-04 05:26:11 [INFO]: Epoch 062 - training loss: 0.4260, validation loss: 2.5923
2024-06-04 05:26:20 [INFO]: Epoch 063 - training loss: 0.4244, validation loss: 2.5898
2024-06-04 05:26:30 [INFO]: Epoch 064 - training loss: 0.4237, validation loss: 2.5849
2024-06-04 05:26:39 [INFO]: Epoch 065 - training loss: 0.4230, validation loss: 2.5798
2024-06-04 05:26:49 [INFO]: Epoch 066 - training loss: 0.4219, validation loss: 2.5811
2024-06-04 05:26:58 [INFO]: Epoch 067 - training loss: 0.4208, validation loss: 2.5745
2024-06-04 05:27:07 [INFO]: Epoch 068 - training loss: 0.4192, validation loss: 2.5676
2024-06-04 05:27:17 [INFO]: Epoch 069 - training loss: 0.4191, validation loss: 2.5689
2024-06-04 05:27:26 [INFO]: Epoch 070 - training loss: 0.4181, validation loss: 2.5676
2024-06-04 05:27:35 [INFO]: Epoch 071 - training loss: 0.4176, validation loss: 2.5640
2024-06-04 05:27:45 [INFO]: Epoch 072 - training loss: 0.4160, validation loss: 2.5560
2024-06-04 05:27:54 [INFO]: Epoch 073 - training loss: 0.4154, validation loss: 2.5529
2024-06-04 05:28:04 [INFO]: Epoch 074 - training loss: 0.4145, validation loss: 2.5490
2024-06-04 05:28:13 [INFO]: Epoch 075 - training loss: 0.4140, validation loss: 2.5442
2024-06-04 05:28:23 [INFO]: Epoch 076 - training loss: 0.4135, validation loss: 2.5497
2024-06-04 05:28:32 [INFO]: Epoch 077 - training loss: 0.4123, validation loss: 2.5391
2024-06-04 05:28:41 [INFO]: Epoch 078 - training loss: 0.4117, validation loss: 2.5402
2024-06-04 05:28:51 [INFO]: Epoch 079 - training loss: 0.4112, validation loss: 2.5407
2024-06-04 05:29:00 [INFO]: Epoch 080 - training loss: 0.4102, validation loss: 2.5339
2024-06-04 05:29:10 [INFO]: Epoch 081 - training loss: 0.4102, validation loss: 2.5355
2024-06-04 05:29:19 [INFO]: Epoch 082 - training loss: 0.4094, validation loss: 2.5352
2024-06-04 05:29:28 [INFO]: Epoch 083 - training loss: 0.4084, validation loss: 2.5319
2024-06-04 05:29:38 [INFO]: Epoch 084 - training loss: 0.4075, validation loss: 2.5280
2024-06-04 05:29:47 [INFO]: Epoch 085 - training loss: 0.4072, validation loss: 2.5281
2024-06-04 05:29:57 [INFO]: Epoch 086 - training loss: 0.4066, validation loss: 2.5234
2024-06-04 05:30:06 [INFO]: Epoch 087 - training loss: 0.4066, validation loss: 2.5171
2024-06-04 05:30:16 [INFO]: Epoch 088 - training loss: 0.4053, validation loss: 2.5181
2024-06-04 05:30:25 [INFO]: Epoch 089 - training loss: 0.4049, validation loss: 2.5140
2024-06-04 05:30:34 [INFO]: Epoch 090 - training loss: 0.4042, validation loss: 2.5103
2024-06-04 05:30:44 [INFO]: Epoch 091 - training loss: 0.4038, validation loss: 2.5103
2024-06-04 05:30:53 [INFO]: Epoch 092 - training loss: 0.4032, validation loss: 2.5096
2024-06-04 05:31:03 [INFO]: Epoch 093 - training loss: 0.4021, validation loss: 2.5047
2024-06-04 05:31:12 [INFO]: Epoch 094 - training loss: 0.4016, validation loss: 2.5019
2024-06-04 05:31:22 [INFO]: Epoch 095 - training loss: 0.4011, validation loss: 2.4992
2024-06-04 05:31:31 [INFO]: Epoch 096 - training loss: 0.4001, validation loss: 2.4977
2024-06-04 05:31:40 [INFO]: Epoch 097 - training loss: 0.4004, validation loss: 2.4972
2024-06-04 05:31:50 [INFO]: Epoch 098 - training loss: 0.4001, validation loss: 2.4968
2024-06-04 05:31:59 [INFO]: Epoch 099 - training loss: 0.3994, validation loss: 2.4947
2024-06-04 05:32:08 [INFO]: Epoch 100 - training loss: 0.3988, validation loss: 2.4888
2024-06-04 05:32:08 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 05:32:09 [INFO]: Saved the model to results_point_rate05/Electricity/StemGNN_Electricity/round_4/20240604_T051627/StemGNN.pypots
2024-06-04 05:32:14 [INFO]: Successfully saved to results_point_rate05/Electricity/StemGNN_Electricity/round_4/imputation.pkl
2024-06-04 05:32:14 [INFO]: Round4 - StemGNN on Electricity: MAE=1.1536, MSE=2.8387, MRE=0.6176
2024-06-04 05:32:14 [INFO]: Done! Final results:
Averaged StemGNN (16,863,634 params) on Electricity: MAE=1.3623 ± 0.1869488799754569, MSE=3.8030 ± 0.9204480954804588, MRE=0.7294 ± 0.10009366602929272, average inference time=1.69
