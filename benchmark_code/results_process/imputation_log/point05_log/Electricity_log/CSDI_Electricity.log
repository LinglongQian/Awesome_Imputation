2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-04 03:03:13 [INFO]: Epoch 001 - training loss: 0.7114, validation loss: 0.5531
2024-06-04 03:07:18 [INFO]: Epoch 002 - training loss: 0.4224, validation loss: 0.4366
2024-06-04 03:11:17 [INFO]: Epoch 003 - training loss: 0.3681, validation loss: 0.4488
2024-06-04 03:15:15 [INFO]: Epoch 004 - training loss: 0.3637, validation loss: 0.4402
2024-06-04 03:19:12 [INFO]: Epoch 005 - training loss: 0.3810, validation loss: 0.4332
2024-06-04 03:23:09 [INFO]: Epoch 006 - training loss: 0.3427, validation loss: 0.4038
2024-06-04 03:27:05 [INFO]: Epoch 007 - training loss: 0.3307, validation loss: 0.4003
2024-06-04 03:31:02 [INFO]: Epoch 008 - training loss: 0.3119, validation loss: 0.3806
2024-06-04 03:34:59 [INFO]: Epoch 009 - training loss: 0.3109, validation loss: 0.3687
2024-06-04 03:38:58 [INFO]: Epoch 010 - training loss: 0.3099, validation loss: 0.3457
2024-06-04 03:42:56 [INFO]: Epoch 011 - training loss: 0.2890, validation loss: 0.3333
2024-06-04 03:46:55 [INFO]: Epoch 012 - training loss: 0.2867, validation loss: 0.3343
2024-06-04 03:50:53 [INFO]: Epoch 013 - training loss: 0.2711, validation loss: 0.3185
2024-06-04 03:54:51 [INFO]: Epoch 014 - training loss: 0.2739, validation loss: 0.3370
2024-06-04 03:58:49 [INFO]: Epoch 015 - training loss: 0.2463, validation loss: 0.3212
2024-06-04 04:02:48 [INFO]: Epoch 016 - training loss: 0.2702, validation loss: 0.3092
2024-06-04 04:06:46 [INFO]: Epoch 017 - training loss: 0.2714, validation loss: 0.3047
2024-06-04 04:10:44 [INFO]: Epoch 018 - training loss: 0.2482, validation loss: 0.3072
2024-06-04 04:14:43 [INFO]: Epoch 019 - training loss: 0.2761, validation loss: 0.2898
2024-06-04 04:18:41 [INFO]: Epoch 020 - training loss: 0.2572, validation loss: 0.2826
2024-06-04 04:22:40 [INFO]: Epoch 021 - training loss: 0.2322, validation loss: 0.2919
2024-06-04 04:26:38 [INFO]: Epoch 022 - training loss: 0.2293, validation loss: 0.2918
2024-06-04 04:30:37 [INFO]: Epoch 023 - training loss: 0.2526, validation loss: 0.2771
2024-06-04 04:34:35 [INFO]: Epoch 024 - training loss: 0.2434, validation loss: 0.2746
2024-06-04 04:38:34 [INFO]: Epoch 025 - training loss: 0.2371, validation loss: 0.2833
2024-06-04 04:42:32 [INFO]: Epoch 026 - training loss: 0.2385, validation loss: 0.2594
2024-06-04 04:46:28 [INFO]: Epoch 027 - training loss: 0.2307, validation loss: 0.2656
2024-06-04 04:50:05 [INFO]: Epoch 028 - training loss: 0.1960, validation loss: 0.2583
2024-06-04 04:53:41 [INFO]: Epoch 029 - training loss: 0.2372, validation loss: 0.2601
2024-06-04 04:57:18 [INFO]: Epoch 030 - training loss: 0.2244, validation loss: 0.2633
2024-06-04 05:00:54 [INFO]: Epoch 031 - training loss: 0.2261, validation loss: 0.2596
2024-06-04 05:04:30 [INFO]: Epoch 032 - training loss: 0.2314, validation loss: 0.2523
2024-06-04 05:07:11 [INFO]: Epoch 033 - training loss: 0.2062, validation loss: 0.2496
2024-06-04 05:09:17 [INFO]: Epoch 034 - training loss: 0.2232, validation loss: 0.2444
2024-06-04 05:11:23 [INFO]: Epoch 035 - training loss: 0.2230, validation loss: 0.2448
2024-06-04 05:13:29 [INFO]: Epoch 036 - training loss: 0.2297, validation loss: 0.2446
2024-06-04 05:15:36 [INFO]: Epoch 037 - training loss: 0.2285, validation loss: 0.2400
2024-06-04 05:17:42 [INFO]: Epoch 038 - training loss: 0.2235, validation loss: 0.2384
2024-06-04 05:19:48 [INFO]: Epoch 039 - training loss: 0.2106, validation loss: 0.2388
2024-06-04 05:21:53 [INFO]: Epoch 040 - training loss: 0.2384, validation loss: 0.2417
2024-06-04 05:23:59 [INFO]: Epoch 041 - training loss: 0.2140, validation loss: 0.2376
2024-06-04 05:26:05 [INFO]: Epoch 042 - training loss: 0.2139, validation loss: 0.2296
2024-06-04 05:28:11 [INFO]: Epoch 043 - training loss: 0.2197, validation loss: 0.2414
2024-06-04 05:30:17 [INFO]: Epoch 044 - training loss: 0.2291, validation loss: 0.2258
2024-06-04 05:32:23 [INFO]: Epoch 045 - training loss: 0.2206, validation loss: 0.2331
2024-06-04 05:34:29 [INFO]: Epoch 046 - training loss: 0.2198, validation loss: 0.2247
2024-06-04 05:36:35 [INFO]: Epoch 047 - training loss: 0.2217, validation loss: 0.2309
2024-06-04 05:38:42 [INFO]: Epoch 048 - training loss: 0.2221, validation loss: 0.2227
2024-06-04 05:40:48 [INFO]: Epoch 049 - training loss: 0.2172, validation loss: 0.2215
2024-06-04 05:42:54 [INFO]: Epoch 050 - training loss: 0.2004, validation loss: 0.2303
2024-06-04 05:45:00 [INFO]: Epoch 051 - training loss: 0.2049, validation loss: 0.2216
2024-06-04 05:47:06 [INFO]: Epoch 052 - training loss: 0.1999, validation loss: 0.2279
2024-06-04 05:49:12 [INFO]: Epoch 053 - training loss: 0.2317, validation loss: 0.2374
2024-06-04 05:51:18 [INFO]: Epoch 054 - training loss: 0.2151, validation loss: 0.2208
2024-06-04 05:53:23 [INFO]: Epoch 055 - training loss: 0.2002, validation loss: 0.2250
2024-06-04 05:55:29 [INFO]: Epoch 056 - training loss: 0.2000, validation loss: 0.2200
2024-06-04 05:57:35 [INFO]: Epoch 057 - training loss: 0.2047, validation loss: 0.2326
2024-06-04 05:59:41 [INFO]: Epoch 058 - training loss: 0.2054, validation loss: 0.2191
2024-06-04 06:01:47 [INFO]: Epoch 059 - training loss: 0.2126, validation loss: 0.2214
2024-06-04 06:03:53 [INFO]: Epoch 060 - training loss: 0.1917, validation loss: 0.2173
2024-06-04 06:05:59 [INFO]: Epoch 061 - training loss: 0.2100, validation loss: 0.2161
2024-06-04 06:08:05 [INFO]: Epoch 062 - training loss: 0.2213, validation loss: 0.2054
2024-06-04 06:10:12 [INFO]: Epoch 063 - training loss: 0.2155, validation loss: 0.2147
2024-06-04 06:12:18 [INFO]: Epoch 064 - training loss: 0.2029, validation loss: 0.2277
2024-06-04 06:14:24 [INFO]: Epoch 065 - training loss: 0.2077, validation loss: 0.2347
2024-06-04 06:16:30 [INFO]: Epoch 066 - training loss: 0.2134, validation loss: 0.2133
2024-06-04 06:18:36 [INFO]: Epoch 067 - training loss: 0.1870, validation loss: 0.2084
2024-06-04 06:20:42 [INFO]: Epoch 068 - training loss: 0.1967, validation loss: 0.2087
2024-06-04 06:22:48 [INFO]: Epoch 069 - training loss: 0.1952, validation loss: 0.2103
2024-06-04 06:24:53 [INFO]: Epoch 070 - training loss: 0.2048, validation loss: 0.1980
2024-06-04 06:26:59 [INFO]: Epoch 071 - training loss: 0.1951, validation loss: 0.2019
2024-06-04 06:29:05 [INFO]: Epoch 072 - training loss: 0.1911, validation loss: 0.2080
2024-06-04 06:31:11 [INFO]: Epoch 073 - training loss: 0.1853, validation loss: 0.2071
2024-06-04 06:33:17 [INFO]: Epoch 074 - training loss: 0.1947, validation loss: 0.2025
2024-06-04 06:35:23 [INFO]: Epoch 075 - training loss: 0.2130, validation loss: 0.2045
2024-06-04 06:37:29 [INFO]: Epoch 076 - training loss: 0.2104, validation loss: 0.2007
2024-06-04 06:39:36 [INFO]: Epoch 077 - training loss: 0.2006, validation loss: 0.2006
2024-06-04 06:41:42 [INFO]: Epoch 078 - training loss: 0.2200, validation loss: 0.1982
2024-06-04 06:43:48 [INFO]: Epoch 079 - training loss: 0.2060, validation loss: 0.1968
2024-06-04 06:45:54 [INFO]: Epoch 080 - training loss: 0.2172, validation loss: 0.1955
2024-06-04 06:48:00 [INFO]: Epoch 081 - training loss: 0.2079, validation loss: 0.2012
2024-06-04 06:50:06 [INFO]: Epoch 082 - training loss: 0.2073, validation loss: 0.1969
2024-06-04 06:52:12 [INFO]: Epoch 083 - training loss: 0.2081, validation loss: 0.1985
2024-06-04 06:54:18 [INFO]: Epoch 084 - training loss: 0.2258, validation loss: 0.1934
2024-06-04 06:56:23 [INFO]: Epoch 085 - training loss: 0.2199, validation loss: 0.1937
2024-06-04 06:58:29 [INFO]: Epoch 086 - training loss: 0.2058, validation loss: 0.1943
2024-06-04 07:00:35 [INFO]: Epoch 087 - training loss: 0.2086, validation loss: 0.2054
2024-06-04 07:02:41 [INFO]: Epoch 088 - training loss: 0.1857, validation loss: 0.1942
2024-06-04 07:04:47 [INFO]: Epoch 089 - training loss: 0.2005, validation loss: 0.1909
2024-06-04 07:06:53 [INFO]: Epoch 090 - training loss: 0.1840, validation loss: 0.1930
2024-06-04 07:08:59 [INFO]: Epoch 091 - training loss: 0.2131, validation loss: 0.1895
2024-06-04 07:11:06 [INFO]: Epoch 092 - training loss: 0.1965, validation loss: 0.1943
2024-06-04 07:13:12 [INFO]: Epoch 093 - training loss: 0.2083, validation loss: 0.1906
2024-06-04 07:15:18 [INFO]: Epoch 094 - training loss: 0.2086, validation loss: 0.1885
2024-06-04 07:17:24 [INFO]: Epoch 095 - training loss: 0.2053, validation loss: 0.1917
2024-06-04 07:19:30 [INFO]: Epoch 096 - training loss: 0.1997, validation loss: 0.1926
2024-06-04 07:21:36 [INFO]: Epoch 097 - training loss: 0.1867, validation loss: 0.1903
2024-06-04 07:23:42 [INFO]: Epoch 098 - training loss: 0.2019, validation loss: 0.1934
2024-06-04 07:25:47 [INFO]: Epoch 099 - training loss: 0.1986, validation loss: 0.1899
2024-06-04 07:27:53 [INFO]: Epoch 100 - training loss: 0.1945, validation loss: 0.1913
2024-06-04 07:27:53 [INFO]: Finished training. The best model is from epoch#94.
2024-06-04 07:27:53 [INFO]: Saved the model to results_point_rate05/Electricity/CSDI_Electricity/round_0/20240604_T025905/CSDI.pypots
2024-06-04 08:50:11 [INFO]: Successfully saved to results_point_rate05/Electricity/CSDI_Electricity/round_0/imputation.pkl
2024-06-04 08:50:11 [INFO]: Round0 - CSDI on Electricity: MAE=0.5699, MSE=2.2138, MRE=0.3051
2024-06-04 08:50:11 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 08:50:11 [INFO]: Using the given device: cuda:0
2024-06-04 08:50:11 [INFO]: Model files will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_1/20240604_T085011
2024-06-04 08:50:11 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_1/20240604_T085011/tensorboard
2024-06-04 08:50:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-04 08:52:18 [INFO]: Epoch 001 - training loss: 0.6920, validation loss: 0.4942
2024-06-04 08:54:23 [INFO]: Epoch 002 - training loss: 0.3814, validation loss: 0.4414
2024-06-04 08:56:29 [INFO]: Epoch 003 - training loss: 0.3625, validation loss: 0.4341
2024-06-04 08:58:35 [INFO]: Epoch 004 - training loss: 0.3709, validation loss: 0.4274
2024-06-04 09:00:41 [INFO]: Epoch 005 - training loss: 0.3412, validation loss: 0.3947
2024-06-04 09:02:47 [INFO]: Epoch 006 - training loss: 0.3179, validation loss: 0.3941
2024-06-04 09:04:54 [INFO]: Epoch 007 - training loss: 0.3255, validation loss: 0.4030
2024-06-04 09:07:00 [INFO]: Epoch 008 - training loss: 0.3159, validation loss: 0.3755
2024-06-04 09:09:06 [INFO]: Epoch 009 - training loss: 0.2841, validation loss: 0.3689
2024-06-04 09:11:12 [INFO]: Epoch 010 - training loss: 0.2748, validation loss: 0.3521
2024-06-04 09:13:19 [INFO]: Epoch 011 - training loss: 0.3130, validation loss: 0.3260
2024-06-04 09:15:25 [INFO]: Epoch 012 - training loss: 0.2812, validation loss: 0.3349
2024-06-04 09:17:31 [INFO]: Epoch 013 - training loss: 0.2590, validation loss: 0.3168
2024-06-04 09:19:37 [INFO]: Epoch 014 - training loss: 0.2653, validation loss: 0.3300
2024-06-04 09:21:43 [INFO]: Epoch 015 - training loss: 0.2627, validation loss: 0.3340
2024-06-04 09:23:49 [INFO]: Epoch 016 - training loss: 0.2609, validation loss: 0.3244
2024-06-04 09:25:55 [INFO]: Epoch 017 - training loss: 0.2669, validation loss: 0.3325
2024-06-04 09:28:01 [INFO]: Epoch 018 - training loss: 0.2511, validation loss: 0.3196
2024-06-04 09:30:07 [INFO]: Epoch 019 - training loss: 0.2362, validation loss: 0.3157
2024-06-04 09:32:13 [INFO]: Epoch 020 - training loss: 0.2455, validation loss: 0.3124
2024-06-04 09:34:19 [INFO]: Epoch 021 - training loss: 0.2628, validation loss: 0.3113
2024-06-04 09:36:25 [INFO]: Epoch 022 - training loss: 0.2402, validation loss: 0.3092
2024-06-04 09:38:32 [INFO]: Epoch 023 - training loss: 0.2406, validation loss: 0.3065
2024-06-04 09:40:38 [INFO]: Epoch 024 - training loss: 0.2328, validation loss: 0.2857
2024-06-04 09:42:44 [INFO]: Epoch 025 - training loss: 0.2449, validation loss: 0.2881
2024-06-04 09:44:50 [INFO]: Epoch 026 - training loss: 0.2381, validation loss: 0.2936
2024-06-04 09:46:56 [INFO]: Epoch 027 - training loss: 0.2312, validation loss: 0.2782
2024-06-04 09:49:03 [INFO]: Epoch 028 - training loss: 0.2443, validation loss: 0.2784
2024-06-04 09:51:08 [INFO]: Epoch 029 - training loss: 0.2416, validation loss: 0.2639
2024-06-04 09:53:14 [INFO]: Epoch 030 - training loss: 0.2222, validation loss: 0.2624
2024-06-04 09:55:20 [INFO]: Epoch 031 - training loss: 0.2234, validation loss: 0.2579
2024-06-04 09:57:26 [INFO]: Epoch 032 - training loss: 0.2547, validation loss: 0.2503
2024-06-04 09:59:32 [INFO]: Epoch 033 - training loss: 0.2277, validation loss: 0.2548
2024-06-04 10:01:38 [INFO]: Epoch 034 - training loss: 0.2171, validation loss: 0.2524
2024-06-04 10:03:44 [INFO]: Epoch 035 - training loss: 0.2013, validation loss: 0.2451
2024-06-04 10:05:51 [INFO]: Epoch 036 - training loss: 0.2421, validation loss: 0.2413
2024-06-04 10:07:57 [INFO]: Epoch 037 - training loss: 0.2455, validation loss: 0.2366
2024-06-04 10:10:03 [INFO]: Epoch 038 - training loss: 0.2068, validation loss: 0.2423
2024-06-04 10:12:09 [INFO]: Epoch 039 - training loss: 0.2065, validation loss: 0.2408
2024-06-04 10:14:15 [INFO]: Epoch 040 - training loss: 0.2170, validation loss: 0.2415
2024-06-04 10:16:22 [INFO]: Epoch 041 - training loss: 0.2349, validation loss: 0.2377
2024-06-04 10:18:28 [INFO]: Epoch 042 - training loss: 0.2122, validation loss: 0.2452
2024-06-04 10:20:34 [INFO]: Epoch 043 - training loss: 0.2240, validation loss: 0.2305
2024-06-04 10:22:40 [INFO]: Epoch 044 - training loss: 0.2290, validation loss: 0.2306
2024-06-04 10:24:46 [INFO]: Epoch 045 - training loss: 0.2042, validation loss: 0.2332
2024-06-04 10:26:51 [INFO]: Epoch 046 - training loss: 0.1981, validation loss: 0.2255
2024-06-04 10:28:58 [INFO]: Epoch 047 - training loss: 0.2200, validation loss: 0.2274
2024-06-04 10:31:04 [INFO]: Epoch 048 - training loss: 0.2087, validation loss: 0.2244
2024-06-04 10:33:10 [INFO]: Epoch 049 - training loss: 0.2291, validation loss: 0.2241
2024-06-04 10:35:16 [INFO]: Epoch 050 - training loss: 0.2095, validation loss: 0.2188
2024-06-04 10:37:22 [INFO]: Epoch 051 - training loss: 0.2188, validation loss: 0.2265
2024-06-04 10:39:28 [INFO]: Epoch 052 - training loss: 0.2094, validation loss: 0.2216
2024-06-04 10:41:35 [INFO]: Epoch 053 - training loss: 0.2101, validation loss: 0.2178
2024-06-04 10:43:41 [INFO]: Epoch 054 - training loss: 0.2217, validation loss: 0.2178
2024-06-04 10:45:47 [INFO]: Epoch 055 - training loss: 0.2101, validation loss: 0.2155
2024-06-04 10:47:53 [INFO]: Epoch 056 - training loss: 0.1921, validation loss: 0.2117
2024-06-04 10:49:59 [INFO]: Epoch 057 - training loss: 0.2066, validation loss: 0.2140
2024-06-04 10:52:05 [INFO]: Epoch 058 - training loss: 0.2120, validation loss: 0.2095
2024-06-04 10:54:11 [INFO]: Epoch 059 - training loss: 0.2078, validation loss: 0.2128
2024-06-04 10:56:17 [INFO]: Epoch 060 - training loss: 0.2142, validation loss: 0.2110
2024-06-04 10:58:23 [INFO]: Epoch 061 - training loss: 0.2063, validation loss: 0.2083
2024-06-04 11:00:29 [INFO]: Epoch 062 - training loss: 0.2168, validation loss: 0.2088
2024-06-04 11:02:35 [INFO]: Epoch 063 - training loss: 0.2066, validation loss: 0.2060
2024-06-04 11:04:41 [INFO]: Epoch 064 - training loss: 0.2030, validation loss: 0.2071
2024-06-04 11:06:47 [INFO]: Epoch 065 - training loss: 0.2120, validation loss: 0.2034
2024-06-04 11:08:53 [INFO]: Epoch 066 - training loss: 0.1966, validation loss: 0.2077
2024-06-04 11:11:00 [INFO]: Epoch 067 - training loss: 0.2081, validation loss: 0.1999
2024-06-04 11:13:06 [INFO]: Epoch 068 - training loss: 0.2085, validation loss: 0.2046
2024-06-04 11:15:12 [INFO]: Epoch 069 - training loss: 0.1845, validation loss: 0.2056
2024-06-04 11:17:18 [INFO]: Epoch 070 - training loss: 0.2004, validation loss: 0.2011
2024-06-04 11:19:24 [INFO]: Epoch 071 - training loss: 0.1940, validation loss: 0.2025
2024-06-04 11:21:30 [INFO]: Epoch 072 - training loss: 0.2072, validation loss: 0.2024
2024-06-04 11:23:36 [INFO]: Epoch 073 - training loss: 0.2077, validation loss: 0.1981
2024-06-04 11:25:42 [INFO]: Epoch 074 - training loss: 0.1991, validation loss: 0.2043
2024-06-04 11:27:48 [INFO]: Epoch 075 - training loss: 0.2041, validation loss: 0.1974
2024-06-04 11:29:54 [INFO]: Epoch 076 - training loss: 0.2070, validation loss: 0.1985
2024-06-04 11:32:00 [INFO]: Epoch 077 - training loss: 0.1890, validation loss: 0.1960
2024-06-04 11:34:06 [INFO]: Epoch 078 - training loss: 0.2027, validation loss: 0.1965
2024-06-04 11:36:12 [INFO]: Epoch 079 - training loss: 0.2062, validation loss: 0.1967
2024-06-04 11:38:18 [INFO]: Epoch 080 - training loss: 0.1908, validation loss: 0.1971
2024-06-04 11:40:25 [INFO]: Epoch 081 - training loss: 0.2119, validation loss: 0.1967
2024-06-04 11:42:31 [INFO]: Epoch 082 - training loss: 0.1986, validation loss: 0.1960
2024-06-04 11:44:37 [INFO]: Epoch 083 - training loss: 0.1947, validation loss: 0.1980
2024-06-04 11:46:43 [INFO]: Epoch 084 - training loss: 0.2183, validation loss: 0.1974
2024-06-04 11:48:49 [INFO]: Epoch 085 - training loss: 0.1984, validation loss: 0.1944
2024-06-04 11:50:55 [INFO]: Epoch 086 - training loss: 0.1881, validation loss: 0.1946
2024-06-04 11:53:01 [INFO]: Epoch 087 - training loss: 0.1991, validation loss: 0.1959
2024-06-04 11:55:07 [INFO]: Epoch 088 - training loss: 0.2078, validation loss: 0.1947
2024-06-04 11:57:13 [INFO]: Epoch 089 - training loss: 0.2200, validation loss: 0.1927
2024-06-04 11:59:19 [INFO]: Epoch 090 - training loss: 0.1896, validation loss: 0.1967
2024-06-04 12:01:25 [INFO]: Epoch 091 - training loss: 0.2031, validation loss: 0.1929
2024-06-04 12:03:31 [INFO]: Epoch 092 - training loss: 0.1908, validation loss: 0.1941
2024-06-04 12:05:37 [INFO]: Epoch 093 - training loss: 0.1972, validation loss: 0.1926
2024-06-04 12:07:43 [INFO]: Epoch 094 - training loss: 0.1913, validation loss: 0.1949
2024-06-04 12:09:50 [INFO]: Epoch 095 - training loss: 0.1858, validation loss: 0.1936
2024-06-04 12:11:56 [INFO]: Epoch 096 - training loss: 0.2128, validation loss: 0.2006
2024-06-04 12:14:02 [INFO]: Epoch 097 - training loss: 0.2148, validation loss: 0.1942
2024-06-04 12:16:05 [INFO]: Epoch 098 - training loss: 0.1854, validation loss: 0.1928
2024-06-04 12:18:09 [INFO]: Epoch 099 - training loss: 0.2161, validation loss: 0.1966
2024-06-04 12:20:15 [INFO]: Epoch 100 - training loss: 0.1900, validation loss: 0.1899
2024-06-04 12:20:15 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 12:20:15 [INFO]: Saved the model to results_point_rate05/Electricity/CSDI_Electricity/round_1/20240604_T085011/CSDI.pypots
2024-06-04 13:42:40 [INFO]: Successfully saved to results_point_rate05/Electricity/CSDI_Electricity/round_1/imputation.pkl
2024-06-04 13:42:40 [INFO]: Round1 - CSDI on Electricity: MAE=0.5191, MSE=13.3492, MRE=0.2779
2024-06-04 13:42:40 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 13:42:40 [INFO]: Using the given device: cuda:0
2024-06-04 13:42:40 [INFO]: Model files will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_2/20240604_T134240
2024-06-04 13:42:40 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_2/20240604_T134240/tensorboard
2024-06-04 13:42:40 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-04 13:44:47 [INFO]: Epoch 001 - training loss: 0.6935, validation loss: 0.4935
2024-06-04 13:46:53 [INFO]: Epoch 002 - training loss: 0.3999, validation loss: 0.4682
2024-06-04 13:48:59 [INFO]: Epoch 003 - training loss: 0.3873, validation loss: 0.4235
2024-06-04 13:51:06 [INFO]: Epoch 004 - training loss: 0.3709, validation loss: 0.4086
2024-06-04 13:53:12 [INFO]: Epoch 005 - training loss: 0.3162, validation loss: 0.3749
2024-06-04 13:55:18 [INFO]: Epoch 006 - training loss: 0.3086, validation loss: 0.3480
2024-06-04 13:57:24 [INFO]: Epoch 007 - training loss: 0.2980, validation loss: 0.3300
2024-06-04 13:59:30 [INFO]: Epoch 008 - training loss: 0.2795, validation loss: 0.3271
2024-06-04 14:01:36 [INFO]: Epoch 009 - training loss: 0.3139, validation loss: 0.3103
2024-06-04 14:03:42 [INFO]: Epoch 010 - training loss: 0.2633, validation loss: 0.3095
2024-06-04 14:05:48 [INFO]: Epoch 011 - training loss: 0.2694, validation loss: 0.3013
2024-06-04 14:07:54 [INFO]: Epoch 012 - training loss: 0.2781, validation loss: 0.2918
2024-06-04 14:10:00 [INFO]: Epoch 013 - training loss: 0.2386, validation loss: 0.2996
2024-06-04 14:12:06 [INFO]: Epoch 014 - training loss: 0.2261, validation loss: 0.2855
2024-06-04 14:14:13 [INFO]: Epoch 015 - training loss: 0.2653, validation loss: 0.2804
2024-06-04 14:16:19 [INFO]: Epoch 016 - training loss: 0.2661, validation loss: 0.2698
2024-06-04 14:18:25 [INFO]: Epoch 017 - training loss: 0.2502, validation loss: 0.2735
2024-06-04 14:20:31 [INFO]: Epoch 018 - training loss: 0.2394, validation loss: 0.2586
2024-06-04 14:22:37 [INFO]: Epoch 019 - training loss: 0.2587, validation loss: 0.2607
2024-06-04 14:24:43 [INFO]: Epoch 020 - training loss: 0.2425, validation loss: 0.2587
2024-06-04 14:26:49 [INFO]: Epoch 021 - training loss: 0.2279, validation loss: 0.2557
2024-06-04 14:28:55 [INFO]: Epoch 022 - training loss: 0.2152, validation loss: 0.2598
2024-06-04 14:31:01 [INFO]: Epoch 023 - training loss: 0.2415, validation loss: 0.2488
2024-06-04 14:33:07 [INFO]: Epoch 024 - training loss: 0.2641, validation loss: 0.2504
2024-06-04 14:35:13 [INFO]: Epoch 025 - training loss: 0.2445, validation loss: 0.2420
2024-06-04 14:37:20 [INFO]: Epoch 026 - training loss: 0.2423, validation loss: 0.2445
2024-06-04 14:39:26 [INFO]: Epoch 027 - training loss: 0.2249, validation loss: 0.2486
2024-06-04 14:41:32 [INFO]: Epoch 028 - training loss: 0.2372, validation loss: 0.2402
2024-06-04 14:43:38 [INFO]: Epoch 029 - training loss: 0.2075, validation loss: 0.2412
2024-06-04 14:45:45 [INFO]: Epoch 030 - training loss: 0.2308, validation loss: 0.2427
2024-06-04 14:47:51 [INFO]: Epoch 031 - training loss: 0.2394, validation loss: 0.2406
2024-06-04 14:49:57 [INFO]: Epoch 032 - training loss: 0.2445, validation loss: 0.2361
2024-06-04 14:52:03 [INFO]: Epoch 033 - training loss: 0.2211, validation loss: 0.2352
2024-06-04 14:54:09 [INFO]: Epoch 034 - training loss: 0.2531, validation loss: 0.2346
2024-06-04 14:56:15 [INFO]: Epoch 035 - training loss: 0.2357, validation loss: 0.2340
2024-06-04 14:58:21 [INFO]: Epoch 036 - training loss: 0.2314, validation loss: 0.2306
2024-06-04 15:00:27 [INFO]: Epoch 037 - training loss: 0.2469, validation loss: 0.2374
2024-06-04 15:02:33 [INFO]: Epoch 038 - training loss: 0.2184, validation loss: 0.2339
2024-06-04 15:04:39 [INFO]: Epoch 039 - training loss: 0.2267, validation loss: 0.2350
2024-06-04 15:06:45 [INFO]: Epoch 040 - training loss: 0.2187, validation loss: 0.2399
2024-06-04 15:08:51 [INFO]: Epoch 041 - training loss: 0.2427, validation loss: 0.2328
2024-06-04 15:10:58 [INFO]: Epoch 042 - training loss: 0.2165, validation loss: 0.2309
2024-06-04 15:13:04 [INFO]: Epoch 043 - training loss: 0.2210, validation loss: 0.2294
2024-06-04 15:15:10 [INFO]: Epoch 044 - training loss: 0.2354, validation loss: 0.2264
2024-06-04 15:17:16 [INFO]: Epoch 045 - training loss: 0.2334, validation loss: 0.2313
2024-06-04 15:19:23 [INFO]: Epoch 046 - training loss: 0.2071, validation loss: 0.2311
2024-06-04 15:21:29 [INFO]: Epoch 047 - training loss: 0.2150, validation loss: 0.2254
2024-06-04 15:23:35 [INFO]: Epoch 048 - training loss: 0.2238, validation loss: 0.2310
2024-06-04 15:25:41 [INFO]: Epoch 049 - training loss: 0.2242, validation loss: 0.2249
2024-06-04 15:27:47 [INFO]: Epoch 050 - training loss: 0.2229, validation loss: 0.2215
2024-06-04 15:29:53 [INFO]: Epoch 051 - training loss: 0.1967, validation loss: 0.2185
2024-06-04 15:31:59 [INFO]: Epoch 052 - training loss: 0.2249, validation loss: 0.2207
2024-06-04 15:34:05 [INFO]: Epoch 053 - training loss: 0.2235, validation loss: 0.2147
2024-06-04 15:36:11 [INFO]: Epoch 054 - training loss: 0.2042, validation loss: 0.2154
2024-06-04 15:38:17 [INFO]: Epoch 055 - training loss: 0.1993, validation loss: 0.2174
2024-06-04 15:40:23 [INFO]: Epoch 056 - training loss: 0.2021, validation loss: 0.2177
2024-06-04 15:42:30 [INFO]: Epoch 057 - training loss: 0.2083, validation loss: 0.2163
2024-06-04 15:44:36 [INFO]: Epoch 058 - training loss: 0.2197, validation loss: 0.2163
2024-06-04 15:46:42 [INFO]: Epoch 059 - training loss: 0.1999, validation loss: 0.2107
2024-06-04 15:48:48 [INFO]: Epoch 060 - training loss: 0.2128, validation loss: 0.2132
2024-06-04 15:50:54 [INFO]: Epoch 061 - training loss: 0.2278, validation loss: 0.2127
2024-06-04 15:53:00 [INFO]: Epoch 062 - training loss: 0.2135, validation loss: 0.2124
2024-06-04 15:55:06 [INFO]: Epoch 063 - training loss: 0.2041, validation loss: 0.2110
2024-06-04 15:57:12 [INFO]: Epoch 064 - training loss: 0.1951, validation loss: 0.2087
2024-06-04 15:59:18 [INFO]: Epoch 065 - training loss: 0.1982, validation loss: 0.2098
2024-06-04 16:01:24 [INFO]: Epoch 066 - training loss: 0.2222, validation loss: 0.2069
2024-06-04 16:03:30 [INFO]: Epoch 067 - training loss: 0.1866, validation loss: 0.2060
2024-06-04 16:05:36 [INFO]: Epoch 068 - training loss: 0.2168, validation loss: 0.2033
2024-06-04 16:07:43 [INFO]: Epoch 069 - training loss: 0.1952, validation loss: 0.2060
2024-06-04 16:09:49 [INFO]: Epoch 070 - training loss: 0.2028, validation loss: 0.2077
2024-06-04 16:11:55 [INFO]: Epoch 071 - training loss: 0.2054, validation loss: 0.2074
2024-06-04 16:14:01 [INFO]: Epoch 072 - training loss: 0.2037, validation loss: 0.2057
2024-06-04 16:16:07 [INFO]: Epoch 073 - training loss: 0.1941, validation loss: 0.2088
2024-06-04 16:18:11 [INFO]: Epoch 074 - training loss: 0.2016, validation loss: 0.2029
2024-06-04 16:20:15 [INFO]: Epoch 075 - training loss: 0.2042, validation loss: 0.2032
2024-06-04 16:22:21 [INFO]: Epoch 076 - training loss: 0.2063, validation loss: 0.2001
2024-06-04 16:24:27 [INFO]: Epoch 077 - training loss: 0.2212, validation loss: 0.2039
2024-06-04 16:26:33 [INFO]: Epoch 078 - training loss: 0.2055, validation loss: 0.2004
2024-06-04 16:28:39 [INFO]: Epoch 079 - training loss: 0.2025, validation loss: 0.1981
2024-06-04 16:30:45 [INFO]: Epoch 080 - training loss: 0.1862, validation loss: 0.2001
2024-06-04 16:32:51 [INFO]: Epoch 081 - training loss: 0.1905, validation loss: 0.1987
2024-06-04 16:34:58 [INFO]: Epoch 082 - training loss: 0.2056, validation loss: 0.1980
2024-06-04 16:37:04 [INFO]: Epoch 083 - training loss: 0.2005, validation loss: 0.1982
2024-06-04 16:39:10 [INFO]: Epoch 084 - training loss: 0.2130, validation loss: 0.1963
2024-06-04 16:41:16 [INFO]: Epoch 085 - training loss: 0.1916, validation loss: 0.1977
2024-06-04 16:43:22 [INFO]: Epoch 086 - training loss: 0.1887, validation loss: 0.1962
2024-06-04 16:45:28 [INFO]: Epoch 087 - training loss: 0.1810, validation loss: 0.1959
2024-06-04 16:47:34 [INFO]: Epoch 088 - training loss: 0.1848, validation loss: 0.1992
2024-06-04 16:49:40 [INFO]: Epoch 089 - training loss: 0.2054, validation loss: 0.1928
2024-06-04 16:51:46 [INFO]: Epoch 090 - training loss: 0.2044, validation loss: 0.1944
2024-06-04 16:53:52 [INFO]: Epoch 091 - training loss: 0.1951, validation loss: 0.1941
2024-06-04 16:55:58 [INFO]: Epoch 092 - training loss: 0.2031, validation loss: 0.1929
2024-06-04 16:58:04 [INFO]: Epoch 093 - training loss: 0.1872, validation loss: 0.1936
2024-06-04 17:00:10 [INFO]: Epoch 094 - training loss: 0.1920, validation loss: 0.1932
2024-06-04 17:02:17 [INFO]: Epoch 095 - training loss: 0.2037, validation loss: 0.1945
2024-06-04 17:04:23 [INFO]: Epoch 096 - training loss: 0.1858, validation loss: 0.1893
2024-06-04 17:06:29 [INFO]: Epoch 097 - training loss: 0.1813, validation loss: 0.1913
2024-06-04 17:08:35 [INFO]: Epoch 098 - training loss: 0.2015, validation loss: 0.2030
2024-06-04 17:10:41 [INFO]: Epoch 099 - training loss: 0.1999, validation loss: 0.1936
2024-06-04 17:12:48 [INFO]: Epoch 100 - training loss: 0.2104, validation loss: 0.1929
2024-06-04 17:12:48 [INFO]: Finished training. The best model is from epoch#96.
2024-06-04 17:12:48 [INFO]: Saved the model to results_point_rate05/Electricity/CSDI_Electricity/round_2/20240604_T134240/CSDI.pypots
2024-06-04 18:35:13 [INFO]: Successfully saved to results_point_rate05/Electricity/CSDI_Electricity/round_2/imputation.pkl
2024-06-04 18:35:13 [INFO]: Round2 - CSDI on Electricity: MAE=0.9242, MSE=31.0551, MRE=0.4948
2024-06-04 18:35:13 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 18:35:13 [INFO]: Using the given device: cuda:0
2024-06-04 18:35:13 [INFO]: Model files will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_3/20240604_T183513
2024-06-04 18:35:13 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_3/20240604_T183513/tensorboard
2024-06-04 18:35:13 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-04 18:37:20 [INFO]: Epoch 001 - training loss: 0.6916, validation loss: 0.5355
2024-06-04 18:39:26 [INFO]: Epoch 002 - training loss: 0.3706, validation loss: 0.4307
2024-06-04 18:41:32 [INFO]: Epoch 003 - training loss: 0.3987, validation loss: 0.4027
2024-06-04 18:43:38 [INFO]: Epoch 004 - training loss: 0.3307, validation loss: 0.4027
2024-06-04 18:45:45 [INFO]: Epoch 005 - training loss: 0.3365, validation loss: 0.3909
2024-06-04 18:47:51 [INFO]: Epoch 006 - training loss: 0.2882, validation loss: 0.3988
2024-06-04 18:49:57 [INFO]: Epoch 007 - training loss: 0.2950, validation loss: 0.3930
2024-06-04 18:52:04 [INFO]: Epoch 008 - training loss: 0.3086, validation loss: 0.3892
2024-06-04 18:54:10 [INFO]: Epoch 009 - training loss: 0.2855, validation loss: 0.3683
2024-06-04 18:56:16 [INFO]: Epoch 010 - training loss: 0.2697, validation loss: 0.3558
2024-06-04 18:58:22 [INFO]: Epoch 011 - training loss: 0.2619, validation loss: 0.3224
2024-06-04 19:00:28 [INFO]: Epoch 012 - training loss: 0.2813, validation loss: 0.3208
2024-06-04 19:02:34 [INFO]: Epoch 013 - training loss: 0.2295, validation loss: 0.3190
2024-06-04 19:04:40 [INFO]: Epoch 014 - training loss: 0.2641, validation loss: 0.3070
2024-06-04 19:06:46 [INFO]: Epoch 015 - training loss: 0.2380, validation loss: 0.2973
2024-06-04 19:08:52 [INFO]: Epoch 016 - training loss: 0.2570, validation loss: 0.3029
2024-06-04 19:10:58 [INFO]: Epoch 017 - training loss: 0.2573, validation loss: 0.2943
2024-06-04 19:13:04 [INFO]: Epoch 018 - training loss: 0.2545, validation loss: 0.2784
2024-06-04 19:15:11 [INFO]: Epoch 019 - training loss: 0.2394, validation loss: 0.2747
2024-06-04 19:17:17 [INFO]: Epoch 020 - training loss: 0.2487, validation loss: 0.2552
2024-06-04 19:19:24 [INFO]: Epoch 021 - training loss: 0.2358, validation loss: 0.2556
2024-06-04 19:21:30 [INFO]: Epoch 022 - training loss: 0.2332, validation loss: 0.2579
2024-06-04 19:23:36 [INFO]: Epoch 023 - training loss: 0.2479, validation loss: 0.2585
2024-06-04 19:25:42 [INFO]: Epoch 024 - training loss: 0.2403, validation loss: 0.2535
2024-06-04 19:27:49 [INFO]: Epoch 025 - training loss: 0.2242, validation loss: 0.2483
2024-06-04 19:29:55 [INFO]: Epoch 026 - training loss: 0.2154, validation loss: 0.2486
2024-06-04 19:32:01 [INFO]: Epoch 027 - training loss: 0.2396, validation loss: 0.2338
2024-06-04 19:34:07 [INFO]: Epoch 028 - training loss: 0.2085, validation loss: 0.2355
2024-06-04 19:36:13 [INFO]: Epoch 029 - training loss: 0.2360, validation loss: 0.2324
2024-06-04 19:38:19 [INFO]: Epoch 030 - training loss: 0.2170, validation loss: 0.2258
2024-06-04 19:40:25 [INFO]: Epoch 031 - training loss: 0.2088, validation loss: 0.2374
2024-06-04 19:42:31 [INFO]: Epoch 032 - training loss: 0.2216, validation loss: 0.2259
2024-06-04 19:44:37 [INFO]: Epoch 033 - training loss: 0.2187, validation loss: 0.2309
2024-06-04 19:46:44 [INFO]: Epoch 034 - training loss: 0.2011, validation loss: 0.2239
2024-06-04 19:48:50 [INFO]: Epoch 035 - training loss: 0.2181, validation loss: 0.2209
2024-06-04 19:50:56 [INFO]: Epoch 036 - training loss: 0.2287, validation loss: 0.2175
2024-06-04 19:53:03 [INFO]: Epoch 037 - training loss: 0.2093, validation loss: 0.2169
2024-06-04 19:55:09 [INFO]: Epoch 038 - training loss: 0.2074, validation loss: 0.2147
2024-06-04 19:57:15 [INFO]: Epoch 039 - training loss: 0.2359, validation loss: 0.2109
2024-06-04 19:59:21 [INFO]: Epoch 040 - training loss: 0.2000, validation loss: 0.2199
2024-06-04 20:01:28 [INFO]: Epoch 041 - training loss: 0.1998, validation loss: 0.2130
2024-06-04 20:03:34 [INFO]: Epoch 042 - training loss: 0.2251, validation loss: 0.2104
2024-06-04 20:05:40 [INFO]: Epoch 043 - training loss: 0.1908, validation loss: 0.2124
2024-06-04 20:07:46 [INFO]: Epoch 044 - training loss: 0.2119, validation loss: 0.2037
2024-06-04 20:09:52 [INFO]: Epoch 045 - training loss: 0.2033, validation loss: 0.2064
2024-06-04 20:11:58 [INFO]: Epoch 046 - training loss: 0.2242, validation loss: 0.2087
2024-06-04 20:14:04 [INFO]: Epoch 047 - training loss: 0.2041, validation loss: 0.2065
2024-06-04 20:16:10 [INFO]: Epoch 048 - training loss: 0.2110, validation loss: 0.2016
2024-06-04 20:18:16 [INFO]: Epoch 049 - training loss: 0.2154, validation loss: 0.2013
2024-06-04 20:20:20 [INFO]: Epoch 050 - training loss: 0.2079, validation loss: 0.2006
2024-06-04 20:22:24 [INFO]: Epoch 051 - training loss: 0.1982, validation loss: 0.2020
2024-06-04 20:24:31 [INFO]: Epoch 052 - training loss: 0.2123, validation loss: 0.2049
2024-06-04 20:26:37 [INFO]: Epoch 053 - training loss: 0.2166, validation loss: 0.1973
2024-06-04 20:28:43 [INFO]: Epoch 054 - training loss: 0.2036, validation loss: 0.1972
2024-06-04 20:30:49 [INFO]: Epoch 055 - training loss: 0.1849, validation loss: 0.1985
2024-06-04 20:32:55 [INFO]: Epoch 056 - training loss: 0.2026, validation loss: 0.1957
2024-06-04 20:35:01 [INFO]: Epoch 057 - training loss: 0.2100, validation loss: 0.1968
2024-06-04 20:37:07 [INFO]: Epoch 058 - training loss: 0.2101, validation loss: 0.1938
2024-06-04 20:39:13 [INFO]: Epoch 059 - training loss: 0.2095, validation loss: 0.1953
2024-06-04 20:41:20 [INFO]: Epoch 060 - training loss: 0.1973, validation loss: 0.1928
2024-06-04 20:43:26 [INFO]: Epoch 061 - training loss: 0.2286, validation loss: 0.1918
2024-06-04 20:45:32 [INFO]: Epoch 062 - training loss: 0.1962, validation loss: 0.1939
2024-06-04 20:47:39 [INFO]: Epoch 063 - training loss: 0.2027, validation loss: 0.1925
2024-06-04 20:49:45 [INFO]: Epoch 064 - training loss: 0.2068, validation loss: 0.1912
2024-06-04 20:51:51 [INFO]: Epoch 065 - training loss: 0.2117, validation loss: 0.1912
2024-06-04 20:53:57 [INFO]: Epoch 066 - training loss: 0.2021, validation loss: 0.1930
2024-06-04 20:56:03 [INFO]: Epoch 067 - training loss: 0.1977, validation loss: 0.1922
2024-06-04 20:58:09 [INFO]: Epoch 068 - training loss: 0.2029, validation loss: 0.1896
2024-06-04 21:00:16 [INFO]: Epoch 069 - training loss: 0.1831, validation loss: 0.1887
2024-06-04 21:02:22 [INFO]: Epoch 070 - training loss: 0.2197, validation loss: 0.1915
2024-06-04 21:04:28 [INFO]: Epoch 071 - training loss: 0.1960, validation loss: 0.1926
2024-06-04 21:06:34 [INFO]: Epoch 072 - training loss: 0.1958, validation loss: 0.1897
2024-06-04 21:08:40 [INFO]: Epoch 073 - training loss: 0.2118, validation loss: 0.1891
2024-06-04 21:10:46 [INFO]: Epoch 074 - training loss: 0.1895, validation loss: 0.1874
2024-06-04 21:12:53 [INFO]: Epoch 075 - training loss: 0.2347, validation loss: 0.1899
2024-06-04 21:14:59 [INFO]: Epoch 076 - training loss: 0.2071, validation loss: 0.1869
2024-06-04 21:17:05 [INFO]: Epoch 077 - training loss: 0.2052, validation loss: 0.1870
2024-06-04 21:19:12 [INFO]: Epoch 078 - training loss: 0.2002, validation loss: 0.1860
2024-06-04 21:21:18 [INFO]: Epoch 079 - training loss: 0.1869, validation loss: 0.1864
2024-06-04 21:23:24 [INFO]: Epoch 080 - training loss: 0.1926, validation loss: 0.1876
2024-06-04 21:25:30 [INFO]: Epoch 081 - training loss: 0.2118, validation loss: 0.1872
2024-06-04 21:27:36 [INFO]: Epoch 082 - training loss: 0.1895, validation loss: 0.1874
2024-06-04 21:29:42 [INFO]: Epoch 083 - training loss: 0.1872, validation loss: 0.1859
2024-06-04 21:31:48 [INFO]: Epoch 084 - training loss: 0.2051, validation loss: 0.1838
2024-06-04 21:33:54 [INFO]: Epoch 085 - training loss: 0.1930, validation loss: 0.1884
2024-06-04 21:36:01 [INFO]: Epoch 086 - training loss: 0.1847, validation loss: 0.1833
2024-06-04 21:38:07 [INFO]: Epoch 087 - training loss: 0.2021, validation loss: 0.1867
2024-06-04 21:40:13 [INFO]: Epoch 088 - training loss: 0.2122, validation loss: 0.1825
2024-06-04 21:42:19 [INFO]: Epoch 089 - training loss: 0.1931, validation loss: 0.1851
2024-06-04 21:44:25 [INFO]: Epoch 090 - training loss: 0.1926, validation loss: 0.1845
2024-06-04 21:46:32 [INFO]: Epoch 091 - training loss: 0.1786, validation loss: 0.1847
2024-06-04 21:48:38 [INFO]: Epoch 092 - training loss: 0.2153, validation loss: 0.1877
2024-06-04 21:50:44 [INFO]: Epoch 093 - training loss: 0.1902, validation loss: 0.1843
2024-06-04 21:52:51 [INFO]: Epoch 094 - training loss: 0.2009, validation loss: 0.1848
2024-06-04 21:54:57 [INFO]: Epoch 095 - training loss: 0.1979, validation loss: 0.1824
2024-06-04 21:57:03 [INFO]: Epoch 096 - training loss: 0.1962, validation loss: 0.1829
2024-06-04 21:59:09 [INFO]: Epoch 097 - training loss: 0.1961, validation loss: 0.1848
2024-06-04 22:01:15 [INFO]: Epoch 098 - training loss: 0.2012, validation loss: 0.1834
2024-06-04 22:03:21 [INFO]: Epoch 099 - training loss: 0.1997, validation loss: 0.1844
2024-06-04 22:05:27 [INFO]: Epoch 100 - training loss: 0.1935, validation loss: 0.1812
2024-06-04 22:05:27 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 22:05:27 [INFO]: Saved the model to results_point_rate05/Electricity/CSDI_Electricity/round_3/20240604_T183513/CSDI.pypots
2024-06-04 23:27:55 [INFO]: Successfully saved to results_point_rate05/Electricity/CSDI_Electricity/round_3/imputation.pkl
2024-06-04 23:27:55 [INFO]: Round3 - CSDI on Electricity: MAE=0.3476, MSE=1.9119, MRE=0.1861
2024-06-04 23:27:55 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 23:27:55 [INFO]: Using the given device: cuda:0
2024-06-04 23:27:55 [INFO]: Model files will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_4/20240604_T232755
2024-06-04 23:27:55 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/CSDI_Electricity/round_4/20240604_T232755/tensorboard
2024-06-04 23:27:56 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-04 23:30:02 [INFO]: Epoch 001 - training loss: 0.7083, validation loss: 0.5838
2024-06-04 23:32:09 [INFO]: Epoch 002 - training loss: 0.4229, validation loss: 0.4646
2024-06-04 23:34:15 [INFO]: Epoch 003 - training loss: 0.3710, validation loss: 0.4226
2024-06-04 23:36:21 [INFO]: Epoch 004 - training loss: 0.3429, validation loss: 0.4091
2024-06-04 23:38:28 [INFO]: Epoch 005 - training loss: 0.3491, validation loss: 0.3995
2024-06-04 23:40:34 [INFO]: Epoch 006 - training loss: 0.3370, validation loss: 0.3696
2024-06-04 23:42:40 [INFO]: Epoch 007 - training loss: 0.3238, validation loss: 0.3715
2024-06-04 23:44:46 [INFO]: Epoch 008 - training loss: 0.3127, validation loss: 0.3763
2024-06-04 23:46:53 [INFO]: Epoch 009 - training loss: 0.2855, validation loss: 0.3628
2024-06-04 23:48:59 [INFO]: Epoch 010 - training loss: 0.2683, validation loss: 0.3413
2024-06-04 23:51:05 [INFO]: Epoch 011 - training loss: 0.3036, validation loss: 0.3438
2024-06-04 23:53:11 [INFO]: Epoch 012 - training loss: 0.2864, validation loss: 0.3230
2024-06-04 23:55:17 [INFO]: Epoch 013 - training loss: 0.2566, validation loss: 0.3209
2024-06-04 23:57:24 [INFO]: Epoch 014 - training loss: 0.2543, validation loss: 0.3078
2024-06-04 23:59:30 [INFO]: Epoch 015 - training loss: 0.2592, validation loss: 0.2975
2024-06-05 00:01:36 [INFO]: Epoch 016 - training loss: 0.2568, validation loss: 0.3044
2024-06-05 00:03:43 [INFO]: Epoch 017 - training loss: 0.2560, validation loss: 0.2942
2024-06-05 00:05:49 [INFO]: Epoch 018 - training loss: 0.2740, validation loss: 0.2793
2024-06-05 00:07:56 [INFO]: Epoch 019 - training loss: 0.2413, validation loss: 0.2775
2024-06-05 00:10:02 [INFO]: Epoch 020 - training loss: 0.2205, validation loss: 0.2804
2024-06-05 00:12:08 [INFO]: Epoch 021 - training loss: 0.2336, validation loss: 0.2656
2024-06-05 00:14:15 [INFO]: Epoch 022 - training loss: 0.2530, validation loss: 0.2745
2024-06-05 00:16:21 [INFO]: Epoch 023 - training loss: 0.2198, validation loss: 0.2642
2024-06-05 00:18:27 [INFO]: Epoch 024 - training loss: 0.2240, validation loss: 0.2590
2024-06-05 00:20:32 [INFO]: Epoch 025 - training loss: 0.2451, validation loss: 0.2621
2024-06-05 00:22:36 [INFO]: Epoch 026 - training loss: 0.2372, validation loss: 0.2579
2024-06-05 00:24:19 [INFO]: Epoch 027 - training loss: 0.2243, validation loss: 0.2526
2024-06-05 00:26:00 [INFO]: Epoch 028 - training loss: 0.2243, validation loss: 0.2659
2024-06-05 00:27:42 [INFO]: Epoch 029 - training loss: 0.2082, validation loss: 0.2542
2024-06-05 00:29:24 [INFO]: Epoch 030 - training loss: 0.2199, validation loss: 0.2560
2024-06-05 00:31:06 [INFO]: Epoch 031 - training loss: 0.2183, validation loss: 0.2587
2024-06-05 00:32:48 [INFO]: Epoch 032 - training loss: 0.2315, validation loss: 0.2480
2024-06-05 00:34:30 [INFO]: Epoch 033 - training loss: 0.2273, validation loss: 0.2552
2024-06-05 00:36:12 [INFO]: Epoch 034 - training loss: 0.2377, validation loss: 0.2483
2024-06-05 00:37:53 [INFO]: Epoch 035 - training loss: 0.2650, validation loss: 0.2476
2024-06-05 00:39:35 [INFO]: Epoch 036 - training loss: 0.2341, validation loss: 0.2460
2024-06-05 00:41:17 [INFO]: Epoch 037 - training loss: 0.2206, validation loss: 0.2493
2024-06-05 00:42:59 [INFO]: Epoch 038 - training loss: 0.2067, validation loss: 0.2471
2024-06-05 00:44:41 [INFO]: Epoch 039 - training loss: 0.2254, validation loss: 0.2329
2024-06-05 00:46:23 [INFO]: Epoch 040 - training loss: 0.1910, validation loss: 0.2321
2024-06-05 00:48:05 [INFO]: Epoch 041 - training loss: 0.2018, validation loss: 0.2378
2024-06-05 00:49:46 [INFO]: Epoch 042 - training loss: 0.1823, validation loss: 0.2428
2024-06-05 00:51:28 [INFO]: Epoch 043 - training loss: 0.2288, validation loss: 0.2376
2024-06-05 00:53:10 [INFO]: Epoch 044 - training loss: 0.2093, validation loss: 0.2334
2024-06-05 00:54:52 [INFO]: Epoch 045 - training loss: 0.2187, validation loss: 0.2270
2024-06-05 00:56:34 [INFO]: Epoch 046 - training loss: 0.2192, validation loss: 0.2256
2024-06-05 00:58:16 [INFO]: Epoch 047 - training loss: 0.2153, validation loss: 0.2212
2024-06-05 00:59:58 [INFO]: Epoch 048 - training loss: 0.2076, validation loss: 0.2209
2024-06-05 01:01:39 [INFO]: Epoch 049 - training loss: 0.2247, validation loss: 0.2205
2024-06-05 01:03:21 [INFO]: Epoch 050 - training loss: 0.2366, validation loss: 0.2225
2024-06-05 01:05:03 [INFO]: Epoch 051 - training loss: 0.2297, validation loss: 0.2200
2024-06-05 01:06:45 [INFO]: Epoch 052 - training loss: 0.2202, validation loss: 0.2217
2024-06-05 01:08:27 [INFO]: Epoch 053 - training loss: 0.2077, validation loss: 0.2177
2024-06-05 01:10:09 [INFO]: Epoch 054 - training loss: 0.2277, validation loss: 0.2144
2024-06-05 01:11:51 [INFO]: Epoch 055 - training loss: 0.2064, validation loss: 0.2115
2024-06-05 01:13:32 [INFO]: Epoch 056 - training loss: 0.2237, validation loss: 0.2106
2024-06-05 01:15:14 [INFO]: Epoch 057 - training loss: 0.2189, validation loss: 0.2192
2024-06-05 01:16:56 [INFO]: Epoch 058 - training loss: 0.2175, validation loss: 0.2137
2024-06-05 01:18:38 [INFO]: Epoch 059 - training loss: 0.2329, validation loss: 0.2135
2024-06-05 01:20:20 [INFO]: Epoch 060 - training loss: 0.1978, validation loss: 0.2100
2024-06-05 01:22:02 [INFO]: Epoch 061 - training loss: 0.1846, validation loss: 0.2111
2024-06-05 01:23:44 [INFO]: Epoch 062 - training loss: 0.2025, validation loss: 0.2151
2024-06-05 01:25:25 [INFO]: Epoch 063 - training loss: 0.2113, validation loss: 0.2081
2024-06-05 01:27:07 [INFO]: Epoch 064 - training loss: 0.2016, validation loss: 0.2105
2024-06-05 01:28:49 [INFO]: Epoch 065 - training loss: 0.2120, validation loss: 0.2083
2024-06-05 01:30:31 [INFO]: Epoch 066 - training loss: 0.2011, validation loss: 0.2083
2024-06-05 01:32:13 [INFO]: Epoch 067 - training loss: 0.2047, validation loss: 0.2052
2024-06-05 01:33:55 [INFO]: Epoch 068 - training loss: 0.2084, validation loss: 0.2069
2024-06-05 01:35:36 [INFO]: Epoch 069 - training loss: 0.1916, validation loss: 0.2073
2024-06-05 01:37:18 [INFO]: Epoch 070 - training loss: 0.2026, validation loss: 0.2018
2024-06-05 01:39:00 [INFO]: Epoch 071 - training loss: 0.2007, validation loss: 0.2068
2024-06-05 01:40:42 [INFO]: Epoch 072 - training loss: 0.2037, validation loss: 0.2058
2024-06-05 01:42:24 [INFO]: Epoch 073 - training loss: 0.1933, validation loss: 0.2117
2024-06-05 01:44:06 [INFO]: Epoch 074 - training loss: 0.2005, validation loss: 0.2053
2024-06-05 01:45:47 [INFO]: Epoch 075 - training loss: 0.1902, validation loss: 0.2044
2024-06-05 01:47:29 [INFO]: Epoch 076 - training loss: 0.1898, validation loss: 0.2022
2024-06-05 01:49:11 [INFO]: Epoch 077 - training loss: 0.1872, validation loss: 0.2034
2024-06-05 01:50:53 [INFO]: Epoch 078 - training loss: 0.1914, validation loss: 0.2004
2024-06-05 01:52:35 [INFO]: Epoch 079 - training loss: 0.1973, validation loss: 0.2015
2024-06-05 01:54:17 [INFO]: Epoch 080 - training loss: 0.1952, validation loss: 0.2020
2024-06-05 01:55:59 [INFO]: Epoch 081 - training loss: 0.1990, validation loss: 0.1984
2024-06-05 01:57:40 [INFO]: Epoch 082 - training loss: 0.1993, validation loss: 0.1991
2024-06-05 01:59:22 [INFO]: Epoch 083 - training loss: 0.2114, validation loss: 0.1986
2024-06-05 02:01:04 [INFO]: Epoch 084 - training loss: 0.1986, validation loss: 0.2049
2024-06-05 02:02:46 [INFO]: Epoch 085 - training loss: 0.1813, validation loss: 0.2008
2024-06-05 02:04:28 [INFO]: Epoch 086 - training loss: 0.1773, validation loss: 0.1991
2024-06-05 02:06:10 [INFO]: Epoch 087 - training loss: 0.1942, validation loss: 0.1995
2024-06-05 02:07:51 [INFO]: Epoch 088 - training loss: 0.1868, validation loss: 0.2004
2024-06-05 02:09:33 [INFO]: Epoch 089 - training loss: 0.1771, validation loss: 0.1984
2024-06-05 02:11:15 [INFO]: Epoch 090 - training loss: 0.1887, validation loss: 0.2006
2024-06-05 02:12:57 [INFO]: Epoch 091 - training loss: 0.1868, validation loss: 0.1966
2024-06-05 02:14:39 [INFO]: Epoch 092 - training loss: 0.1932, validation loss: 0.1960
2024-06-05 02:16:21 [INFO]: Epoch 093 - training loss: 0.1735, validation loss: 0.2020
2024-06-05 02:18:02 [INFO]: Epoch 094 - training loss: 0.1848, validation loss: 0.2001
2024-06-05 02:19:44 [INFO]: Epoch 095 - training loss: 0.2020, validation loss: 0.1946
2024-06-05 02:21:26 [INFO]: Epoch 096 - training loss: 0.2114, validation loss: 0.1945
2024-06-05 02:23:08 [INFO]: Epoch 097 - training loss: 0.1842, validation loss: 0.1938
2024-06-05 02:24:50 [INFO]: Epoch 098 - training loss: 0.1890, validation loss: 0.1961
2024-06-05 02:26:32 [INFO]: Epoch 099 - training loss: 0.1873, validation loss: 0.1961
2024-06-05 02:28:13 [INFO]: Epoch 100 - training loss: 0.1969, validation loss: 0.1955
2024-06-05 02:28:13 [INFO]: Finished training. The best model is from epoch#97.
2024-06-05 02:28:13 [INFO]: Saved the model to results_point_rate05/Electricity/CSDI_Electricity/round_4/20240604_T232755/CSDI.pypots
2024-06-05 03:34:55 [INFO]: Successfully saved to results_point_rate05/Electricity/CSDI_Electricity/round_4/imputation.pkl
2024-06-05 03:34:55 [INFO]: Round4 - CSDI on Electricity: MAE=1.6270, MSE=60.7193, MRE=0.8711
2024-06-05 03:34:55 [INFO]: Done! Final results:
Averaged CSDI (43,185 params) on Electricity: MAE=0.7976 ± 0.4551619246242717, MSE=21.8499 ± 22.14011760173193, MRE=0.4270 ± 0.24369670296271911, average inference time=986.19
