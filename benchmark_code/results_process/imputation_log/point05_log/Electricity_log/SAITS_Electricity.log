2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:05 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 02:59:05 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 02:59:05 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 63,624,720
2024-06-04 02:59:22 [INFO]: Epoch 001 - training loss: 1.0000, validation loss: 3.1164
2024-06-04 02:59:38 [INFO]: Epoch 002 - training loss: 0.6669, validation loss: 2.9792
2024-06-04 02:59:53 [INFO]: Epoch 003 - training loss: 0.5998, validation loss: 2.8759
2024-06-04 03:00:10 [INFO]: Epoch 004 - training loss: 0.5682, validation loss: 2.8412
2024-06-04 03:00:27 [INFO]: Epoch 005 - training loss: 0.5452, validation loss: 2.8113
2024-06-04 03:00:43 [INFO]: Epoch 006 - training loss: 0.5294, validation loss: 2.7943
2024-06-04 03:01:00 [INFO]: Epoch 007 - training loss: 0.5118, validation loss: 2.7821
2024-06-04 03:01:16 [INFO]: Epoch 008 - training loss: 0.5013, validation loss: 2.7751
2024-06-04 03:01:33 [INFO]: Epoch 009 - training loss: 0.4907, validation loss: 2.7748
2024-06-04 03:01:49 [INFO]: Epoch 010 - training loss: 0.4807, validation loss: 2.7553
2024-06-04 03:02:05 [INFO]: Epoch 011 - training loss: 0.4755, validation loss: 2.7429
2024-06-04 03:02:21 [INFO]: Epoch 012 - training loss: 0.4712, validation loss: 2.7429
2024-06-04 03:02:36 [INFO]: Epoch 013 - training loss: 0.4667, validation loss: 2.7350
2024-06-04 03:02:52 [INFO]: Epoch 014 - training loss: 0.4574, validation loss: 2.7176
2024-06-04 03:03:08 [INFO]: Epoch 015 - training loss: 0.4577, validation loss: 2.7180
2024-06-04 03:03:24 [INFO]: Epoch 016 - training loss: 0.4480, validation loss: 2.7299
2024-06-04 03:03:41 [INFO]: Epoch 017 - training loss: 0.4440, validation loss: 2.7101
2024-06-04 03:03:57 [INFO]: Epoch 018 - training loss: 0.4380, validation loss: 2.7080
2024-06-04 03:04:13 [INFO]: Epoch 019 - training loss: 0.4319, validation loss: 2.7016
2024-06-04 03:04:29 [INFO]: Epoch 020 - training loss: 0.4268, validation loss: 2.6878
2024-06-04 03:04:46 [INFO]: Epoch 021 - training loss: 0.4268, validation loss: 2.6883
2024-06-04 03:05:03 [INFO]: Epoch 022 - training loss: 0.4234, validation loss: 2.6830
2024-06-04 03:05:19 [INFO]: Epoch 023 - training loss: 0.4194, validation loss: 2.6574
2024-06-04 03:05:35 [INFO]: Epoch 024 - training loss: 0.4139, validation loss: 2.6724
2024-06-04 03:05:52 [INFO]: Epoch 025 - training loss: 0.4096, validation loss: 2.6718
2024-06-04 03:06:08 [INFO]: Epoch 026 - training loss: 0.4060, validation loss: 2.6616
2024-06-04 03:06:25 [INFO]: Epoch 027 - training loss: 0.4061, validation loss: 2.6677
2024-06-04 03:06:41 [INFO]: Epoch 028 - training loss: 0.4004, validation loss: 2.6406
2024-06-04 03:06:58 [INFO]: Epoch 029 - training loss: 0.3988, validation loss: 2.6483
2024-06-04 03:07:15 [INFO]: Epoch 030 - training loss: 0.3961, validation loss: 2.6410
2024-06-04 03:07:31 [INFO]: Epoch 031 - training loss: 0.3932, validation loss: 2.6278
2024-06-04 03:07:47 [INFO]: Epoch 032 - training loss: 0.3935, validation loss: 2.6141
2024-06-04 03:08:03 [INFO]: Epoch 033 - training loss: 0.3873, validation loss: 2.6100
2024-06-04 03:08:19 [INFO]: Epoch 034 - training loss: 0.3822, validation loss: 2.6298
2024-06-04 03:08:35 [INFO]: Epoch 035 - training loss: 0.3808, validation loss: 2.6365
2024-06-04 03:08:51 [INFO]: Epoch 036 - training loss: 0.3794, validation loss: 2.6320
2024-06-04 03:09:07 [INFO]: Epoch 037 - training loss: 0.3757, validation loss: 2.6300
2024-06-04 03:09:23 [INFO]: Epoch 038 - training loss: 0.3726, validation loss: 2.6644
2024-06-04 03:09:39 [INFO]: Epoch 039 - training loss: 0.3747, validation loss: 2.6681
2024-06-04 03:09:55 [INFO]: Epoch 040 - training loss: 0.3684, validation loss: 2.6669
2024-06-04 03:10:11 [INFO]: Epoch 041 - training loss: 0.3672, validation loss: 2.6729
2024-06-04 03:10:26 [INFO]: Epoch 042 - training loss: 0.3627, validation loss: 2.6696
2024-06-04 03:10:40 [INFO]: Epoch 043 - training loss: 0.3621, validation loss: 2.6635
2024-06-04 03:10:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:10:40 [INFO]: Finished training. The best model is from epoch#33.
2024-06-04 03:10:40 [INFO]: Saved the model to results_point_rate05/Electricity/SAITS_Electricity/round_0/20240604_T025905/SAITS.pypots
2024-06-04 03:10:46 [INFO]: Successfully saved to results_point_rate05/Electricity/SAITS_Electricity/round_0/imputation.pkl
2024-06-04 03:10:46 [INFO]: Round0 - SAITS on Electricity: MAE=1.3866, MSE=3.7331, MRE=0.7424
2024-06-04 03:10:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:10:46 [INFO]: Using the given device: cuda:0
2024-06-04 03:10:46 [INFO]: Model files will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_1/20240604_T031046
2024-06-04 03:10:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_1/20240604_T031046/tensorboard
2024-06-04 03:10:46 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 03:10:46 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 03:10:47 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 63,624,720
2024-06-04 03:11:01 [INFO]: Epoch 001 - training loss: 1.0048, validation loss: 3.0903
2024-06-04 03:11:15 [INFO]: Epoch 002 - training loss: 0.6684, validation loss: 2.9759
2024-06-04 03:11:29 [INFO]: Epoch 003 - training loss: 0.5985, validation loss: 2.8679
2024-06-04 03:11:43 [INFO]: Epoch 004 - training loss: 0.5628, validation loss: 2.8633
2024-06-04 03:11:57 [INFO]: Epoch 005 - training loss: 0.5417, validation loss: 2.8494
2024-06-04 03:12:11 [INFO]: Epoch 006 - training loss: 0.5264, validation loss: 2.8231
2024-06-04 03:12:25 [INFO]: Epoch 007 - training loss: 0.5114, validation loss: 2.8195
2024-06-04 03:12:39 [INFO]: Epoch 008 - training loss: 0.4983, validation loss: 2.8102
2024-06-04 03:12:53 [INFO]: Epoch 009 - training loss: 0.4920, validation loss: 2.8099
2024-06-04 03:13:06 [INFO]: Epoch 010 - training loss: 0.4873, validation loss: 2.7922
2024-06-04 03:13:21 [INFO]: Epoch 011 - training loss: 0.4807, validation loss: 2.7926
2024-06-04 03:13:34 [INFO]: Epoch 012 - training loss: 0.4708, validation loss: 2.7764
2024-06-04 03:13:48 [INFO]: Epoch 013 - training loss: 0.4626, validation loss: 2.7668
2024-06-04 03:14:02 [INFO]: Epoch 014 - training loss: 0.4575, validation loss: 2.7574
2024-06-04 03:14:16 [INFO]: Epoch 015 - training loss: 0.4579, validation loss: 2.7635
2024-06-04 03:14:31 [INFO]: Epoch 016 - training loss: 0.4504, validation loss: 2.7599
2024-06-04 03:14:45 [INFO]: Epoch 017 - training loss: 0.4418, validation loss: 2.7425
2024-06-04 03:14:59 [INFO]: Epoch 018 - training loss: 0.4364, validation loss: 2.7340
2024-06-04 03:15:13 [INFO]: Epoch 019 - training loss: 0.4339, validation loss: 2.7294
2024-06-04 03:15:27 [INFO]: Epoch 020 - training loss: 0.4312, validation loss: 2.7196
2024-06-04 03:15:41 [INFO]: Epoch 021 - training loss: 0.4237, validation loss: 2.7260
2024-06-04 03:15:55 [INFO]: Epoch 022 - training loss: 0.4202, validation loss: 2.6954
2024-06-04 03:16:09 [INFO]: Epoch 023 - training loss: 0.4169, validation loss: 2.6937
2024-06-04 03:16:23 [INFO]: Epoch 024 - training loss: 0.4147, validation loss: 2.6991
2024-06-04 03:16:38 [INFO]: Epoch 025 - training loss: 0.4120, validation loss: 2.6916
2024-06-04 03:16:52 [INFO]: Epoch 026 - training loss: 0.4126, validation loss: 2.6860
2024-06-04 03:17:05 [INFO]: Epoch 027 - training loss: 0.4045, validation loss: 2.6939
2024-06-04 03:17:19 [INFO]: Epoch 028 - training loss: 0.3993, validation loss: 2.6922
2024-06-04 03:17:33 [INFO]: Epoch 029 - training loss: 0.3974, validation loss: 2.7025
2024-06-04 03:17:47 [INFO]: Epoch 030 - training loss: 0.3958, validation loss: 2.6972
2024-06-04 03:18:02 [INFO]: Epoch 031 - training loss: 0.3933, validation loss: 2.6996
2024-06-04 03:18:16 [INFO]: Epoch 032 - training loss: 0.3925, validation loss: 2.6994
2024-06-04 03:18:30 [INFO]: Epoch 033 - training loss: 0.3972, validation loss: 2.6936
2024-06-04 03:18:43 [INFO]: Epoch 034 - training loss: 0.3891, validation loss: 2.7120
2024-06-04 03:18:58 [INFO]: Epoch 035 - training loss: 0.3835, validation loss: 2.7020
2024-06-04 03:19:11 [INFO]: Epoch 036 - training loss: 0.3819, validation loss: 2.6873
2024-06-04 03:19:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:19:11 [INFO]: Finished training. The best model is from epoch#26.
2024-06-04 03:19:12 [INFO]: Saved the model to results_point_rate05/Electricity/SAITS_Electricity/round_1/20240604_T031046/SAITS.pypots
2024-06-04 03:19:18 [INFO]: Successfully saved to results_point_rate05/Electricity/SAITS_Electricity/round_1/imputation.pkl
2024-06-04 03:19:18 [INFO]: Round1 - SAITS on Electricity: MAE=1.2886, MSE=3.3794, MRE=0.6899
2024-06-04 03:19:18 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:19:18 [INFO]: Using the given device: cuda:0
2024-06-04 03:19:18 [INFO]: Model files will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_2/20240604_T031918
2024-06-04 03:19:18 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_2/20240604_T031918/tensorboard
2024-06-04 03:19:18 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 03:19:18 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 03:19:19 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 63,624,720
2024-06-04 03:19:34 [INFO]: Epoch 001 - training loss: 1.0038, validation loss: 3.1017
2024-06-04 03:19:48 [INFO]: Epoch 002 - training loss: 0.6680, validation loss: 2.9671
2024-06-04 03:20:02 [INFO]: Epoch 003 - training loss: 0.5989, validation loss: 2.8899
2024-06-04 03:20:16 [INFO]: Epoch 004 - training loss: 0.5638, validation loss: 2.8615
2024-06-04 03:20:30 [INFO]: Epoch 005 - training loss: 0.5437, validation loss: 2.8248
2024-06-04 03:20:44 [INFO]: Epoch 006 - training loss: 0.5287, validation loss: 2.8427
2024-06-04 03:20:58 [INFO]: Epoch 007 - training loss: 0.5116, validation loss: 2.8245
2024-06-04 03:21:12 [INFO]: Epoch 008 - training loss: 0.4990, validation loss: 2.8223
2024-06-04 03:21:26 [INFO]: Epoch 009 - training loss: 0.4953, validation loss: 2.8184
2024-06-04 03:21:40 [INFO]: Epoch 010 - training loss: 0.4858, validation loss: 2.8162
2024-06-04 03:21:54 [INFO]: Epoch 011 - training loss: 0.4754, validation loss: 2.8034
2024-06-04 03:22:08 [INFO]: Epoch 012 - training loss: 0.4679, validation loss: 2.7903
2024-06-04 03:22:22 [INFO]: Epoch 013 - training loss: 0.4607, validation loss: 2.7803
2024-06-04 03:22:36 [INFO]: Epoch 014 - training loss: 0.4547, validation loss: 2.7490
2024-06-04 03:22:50 [INFO]: Epoch 015 - training loss: 0.4516, validation loss: 2.7656
2024-06-04 03:23:04 [INFO]: Epoch 016 - training loss: 0.4491, validation loss: 2.7331
2024-06-04 03:23:18 [INFO]: Epoch 017 - training loss: 0.4422, validation loss: 2.7422
2024-06-04 03:23:32 [INFO]: Epoch 018 - training loss: 0.4354, validation loss: 2.7219
2024-06-04 03:23:46 [INFO]: Epoch 019 - training loss: 0.4306, validation loss: 2.7053
2024-06-04 03:24:00 [INFO]: Epoch 020 - training loss: 0.4298, validation loss: 2.7090
2024-06-04 03:24:14 [INFO]: Epoch 021 - training loss: 0.4266, validation loss: 2.7102
2024-06-04 03:24:28 [INFO]: Epoch 022 - training loss: 0.4284, validation loss: 2.7037
2024-06-04 03:24:42 [INFO]: Epoch 023 - training loss: 0.4189, validation loss: 2.6877
2024-06-04 03:24:56 [INFO]: Epoch 024 - training loss: 0.4113, validation loss: 2.6671
2024-06-04 03:25:11 [INFO]: Epoch 025 - training loss: 0.4072, validation loss: 2.6435
2024-06-04 03:25:25 [INFO]: Epoch 026 - training loss: 0.4057, validation loss: 2.6494
2024-06-04 03:25:39 [INFO]: Epoch 027 - training loss: 0.4032, validation loss: 2.6453
2024-06-04 03:25:53 [INFO]: Epoch 028 - training loss: 0.3990, validation loss: 2.6534
2024-06-04 03:26:07 [INFO]: Epoch 029 - training loss: 0.3992, validation loss: 2.6371
2024-06-04 03:26:21 [INFO]: Epoch 030 - training loss: 0.3947, validation loss: 2.6369
2024-06-04 03:26:35 [INFO]: Epoch 031 - training loss: 0.3900, validation loss: 2.6214
2024-06-04 03:26:49 [INFO]: Epoch 032 - training loss: 0.3886, validation loss: 2.6250
2024-06-04 03:27:04 [INFO]: Epoch 033 - training loss: 0.3862, validation loss: 2.6388
2024-06-04 03:27:18 [INFO]: Epoch 034 - training loss: 0.3808, validation loss: 2.6471
2024-06-04 03:27:32 [INFO]: Epoch 035 - training loss: 0.3773, validation loss: 2.6232
2024-06-04 03:27:46 [INFO]: Epoch 036 - training loss: 0.3749, validation loss: 2.6442
2024-06-04 03:27:59 [INFO]: Epoch 037 - training loss: 0.3743, validation loss: 2.6845
2024-06-04 03:28:14 [INFO]: Epoch 038 - training loss: 0.3729, validation loss: 2.6993
2024-06-04 03:28:28 [INFO]: Epoch 039 - training loss: 0.3723, validation loss: 2.6571
2024-06-04 03:28:42 [INFO]: Epoch 040 - training loss: 0.3696, validation loss: 2.6776
2024-06-04 03:28:56 [INFO]: Epoch 041 - training loss: 0.3643, validation loss: 2.7061
2024-06-04 03:28:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:28:56 [INFO]: Finished training. The best model is from epoch#31.
2024-06-04 03:28:57 [INFO]: Saved the model to results_point_rate05/Electricity/SAITS_Electricity/round_2/20240604_T031918/SAITS.pypots
2024-06-04 03:29:03 [INFO]: Successfully saved to results_point_rate05/Electricity/SAITS_Electricity/round_2/imputation.pkl
2024-06-04 03:29:03 [INFO]: Round2 - SAITS on Electricity: MAE=1.4181, MSE=3.9005, MRE=0.7593
2024-06-04 03:29:03 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:29:03 [INFO]: Using the given device: cuda:0
2024-06-04 03:29:03 [INFO]: Model files will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_3/20240604_T032903
2024-06-04 03:29:03 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_3/20240604_T032903/tensorboard
2024-06-04 03:29:03 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 03:29:03 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 03:29:04 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 63,624,720
2024-06-04 03:29:19 [INFO]: Epoch 001 - training loss: 1.0018, validation loss: 3.1136
2024-06-04 03:29:33 [INFO]: Epoch 002 - training loss: 0.6707, validation loss: 2.9644
2024-06-04 03:29:47 [INFO]: Epoch 003 - training loss: 0.5999, validation loss: 2.9035
2024-06-04 03:30:01 [INFO]: Epoch 004 - training loss: 0.5665, validation loss: 2.8635
2024-06-04 03:30:14 [INFO]: Epoch 005 - training loss: 0.5430, validation loss: 2.8311
2024-06-04 03:30:29 [INFO]: Epoch 006 - training loss: 0.5305, validation loss: 2.8230
2024-06-04 03:30:43 [INFO]: Epoch 007 - training loss: 0.5113, validation loss: 2.8253
2024-06-04 03:30:56 [INFO]: Epoch 008 - training loss: 0.5055, validation loss: 2.8072
2024-06-04 03:31:11 [INFO]: Epoch 009 - training loss: 0.4935, validation loss: 2.8038
2024-06-04 03:31:24 [INFO]: Epoch 010 - training loss: 0.4840, validation loss: 2.7852
2024-06-04 03:31:38 [INFO]: Epoch 011 - training loss: 0.4754, validation loss: 2.7822
2024-06-04 03:31:53 [INFO]: Epoch 012 - training loss: 0.4702, validation loss: 2.7703
2024-06-04 03:32:07 [INFO]: Epoch 013 - training loss: 0.4676, validation loss: 2.7688
2024-06-04 03:32:21 [INFO]: Epoch 014 - training loss: 0.4591, validation loss: 2.7549
2024-06-04 03:32:34 [INFO]: Epoch 015 - training loss: 0.4511, validation loss: 2.7438
2024-06-04 03:32:48 [INFO]: Epoch 016 - training loss: 0.4448, validation loss: 2.7296
2024-06-04 03:33:03 [INFO]: Epoch 017 - training loss: 0.4421, validation loss: 2.7233
2024-06-04 03:33:16 [INFO]: Epoch 018 - training loss: 0.4402, validation loss: 2.7272
2024-06-04 03:33:30 [INFO]: Epoch 019 - training loss: 0.4429, validation loss: 2.7042
2024-06-04 03:33:44 [INFO]: Epoch 020 - training loss: 0.4336, validation loss: 2.7210
2024-06-04 03:33:58 [INFO]: Epoch 021 - training loss: 0.4251, validation loss: 2.7018
2024-06-04 03:34:12 [INFO]: Epoch 022 - training loss: 0.4199, validation loss: 2.6953
2024-06-04 03:34:27 [INFO]: Epoch 023 - training loss: 0.4169, validation loss: 2.6741
2024-06-04 03:34:40 [INFO]: Epoch 024 - training loss: 0.4135, validation loss: 2.6709
2024-06-04 03:34:55 [INFO]: Epoch 025 - training loss: 0.4099, validation loss: 2.6655
2024-06-04 03:35:09 [INFO]: Epoch 026 - training loss: 0.4080, validation loss: 2.6665
2024-06-04 03:35:23 [INFO]: Epoch 027 - training loss: 0.4041, validation loss: 2.6555
2024-06-04 03:35:37 [INFO]: Epoch 028 - training loss: 0.4034, validation loss: 2.6566
2024-06-04 03:35:51 [INFO]: Epoch 029 - training loss: 0.4014, validation loss: 2.6621
2024-06-04 03:36:05 [INFO]: Epoch 030 - training loss: 0.3983, validation loss: 2.6511
2024-06-04 03:36:19 [INFO]: Epoch 031 - training loss: 0.3930, validation loss: 2.6665
2024-06-04 03:36:33 [INFO]: Epoch 032 - training loss: 0.3927, validation loss: 2.6407
2024-06-04 03:36:47 [INFO]: Epoch 033 - training loss: 0.3874, validation loss: 2.6470
2024-06-04 03:37:01 [INFO]: Epoch 034 - training loss: 0.3845, validation loss: 2.6501
2024-06-04 03:37:14 [INFO]: Epoch 035 - training loss: 0.3824, validation loss: 2.6500
2024-06-04 03:37:29 [INFO]: Epoch 036 - training loss: 0.3804, validation loss: 2.6256
2024-06-04 03:37:42 [INFO]: Epoch 037 - training loss: 0.3759, validation loss: 2.6227
2024-06-04 03:37:56 [INFO]: Epoch 038 - training loss: 0.3737, validation loss: 2.6296
2024-06-04 03:38:10 [INFO]: Epoch 039 - training loss: 0.3748, validation loss: 2.6657
2024-06-04 03:38:24 [INFO]: Epoch 040 - training loss: 0.3725, validation loss: 2.6652
2024-06-04 03:38:38 [INFO]: Epoch 041 - training loss: 0.3684, validation loss: 2.6983
2024-06-04 03:38:52 [INFO]: Epoch 042 - training loss: 0.3660, validation loss: 2.6829
2024-06-04 03:39:07 [INFO]: Epoch 043 - training loss: 0.3640, validation loss: 2.6933
2024-06-04 03:39:21 [INFO]: Epoch 044 - training loss: 0.3613, validation loss: 2.7184
2024-06-04 03:39:35 [INFO]: Epoch 045 - training loss: 0.3614, validation loss: 2.7010
2024-06-04 03:39:49 [INFO]: Epoch 046 - training loss: 0.3606, validation loss: 2.7151
2024-06-04 03:40:02 [INFO]: Epoch 047 - training loss: 0.3553, validation loss: 2.7021
2024-06-04 03:40:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:40:02 [INFO]: Finished training. The best model is from epoch#37.
2024-06-04 03:40:03 [INFO]: Saved the model to results_point_rate05/Electricity/SAITS_Electricity/round_3/20240604_T032903/SAITS.pypots
2024-06-04 03:40:09 [INFO]: Successfully saved to results_point_rate05/Electricity/SAITS_Electricity/round_3/imputation.pkl
2024-06-04 03:40:09 [INFO]: Round3 - SAITS on Electricity: MAE=1.3951, MSE=3.8102, MRE=0.7470
2024-06-04 03:40:09 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:40:09 [INFO]: Using the given device: cuda:0
2024-06-04 03:40:09 [INFO]: Model files will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_4/20240604_T034009
2024-06-04 03:40:09 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SAITS_Electricity/round_4/20240604_T034009/tensorboard
2024-06-04 03:40:09 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=256
2024-06-04 03:40:09 [WARNING]: ⚠️ d_model is reset to 2048 = n_heads (8) * d_k (256)
2024-06-04 03:40:10 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 63,624,720
2024-06-04 03:40:25 [INFO]: Epoch 001 - training loss: 0.9933, validation loss: 3.1296
2024-06-04 03:40:39 [INFO]: Epoch 002 - training loss: 0.6655, validation loss: 2.9984
2024-06-04 03:40:53 [INFO]: Epoch 003 - training loss: 0.5977, validation loss: 2.8915
2024-06-04 03:41:07 [INFO]: Epoch 004 - training loss: 0.5631, validation loss: 2.8663
2024-06-04 03:41:21 [INFO]: Epoch 005 - training loss: 0.5422, validation loss: 2.8356
2024-06-04 03:41:34 [INFO]: Epoch 006 - training loss: 0.5285, validation loss: 2.8286
2024-06-04 03:41:49 [INFO]: Epoch 007 - training loss: 0.5118, validation loss: 2.8267
2024-06-04 03:42:03 [INFO]: Epoch 008 - training loss: 0.4972, validation loss: 2.8082
2024-06-04 03:42:16 [INFO]: Epoch 009 - training loss: 0.4919, validation loss: 2.8216
2024-06-04 03:42:30 [INFO]: Epoch 010 - training loss: 0.4839, validation loss: 2.8047
2024-06-04 03:42:44 [INFO]: Epoch 011 - training loss: 0.4764, validation loss: 2.7839
2024-06-04 03:42:59 [INFO]: Epoch 012 - training loss: 0.4688, validation loss: 2.7754
2024-06-04 03:43:13 [INFO]: Epoch 013 - training loss: 0.4619, validation loss: 2.7595
2024-06-04 03:43:27 [INFO]: Epoch 014 - training loss: 0.4617, validation loss: 2.7636
2024-06-04 03:43:41 [INFO]: Epoch 015 - training loss: 0.4545, validation loss: 2.7483
2024-06-04 03:43:55 [INFO]: Epoch 016 - training loss: 0.4487, validation loss: 2.7250
2024-06-04 03:44:09 [INFO]: Epoch 017 - training loss: 0.4419, validation loss: 2.7280
2024-06-04 03:44:23 [INFO]: Epoch 018 - training loss: 0.4392, validation loss: 2.7346
2024-06-04 03:44:37 [INFO]: Epoch 019 - training loss: 0.4294, validation loss: 2.7076
2024-06-04 03:44:51 [INFO]: Epoch 020 - training loss: 0.4267, validation loss: 2.7031
2024-06-04 03:45:05 [INFO]: Epoch 021 - training loss: 0.4241, validation loss: 2.7090
2024-06-04 03:45:19 [INFO]: Epoch 022 - training loss: 0.4205, validation loss: 2.7023
2024-06-04 03:45:33 [INFO]: Epoch 023 - training loss: 0.4195, validation loss: 2.6965
2024-06-04 03:45:47 [INFO]: Epoch 024 - training loss: 0.4215, validation loss: 2.6795
2024-06-04 03:46:01 [INFO]: Epoch 025 - training loss: 0.4129, validation loss: 2.6961
2024-06-04 03:46:15 [INFO]: Epoch 026 - training loss: 0.4056, validation loss: 2.6850
2024-06-04 03:46:30 [INFO]: Epoch 027 - training loss: 0.4038, validation loss: 2.6892
2024-06-04 03:46:44 [INFO]: Epoch 028 - training loss: 0.4024, validation loss: 2.6670
2024-06-04 03:46:58 [INFO]: Epoch 029 - training loss: 0.3961, validation loss: 2.6607
2024-06-04 03:47:11 [INFO]: Epoch 030 - training loss: 0.3925, validation loss: 2.6360
2024-06-04 03:47:26 [INFO]: Epoch 031 - training loss: 0.3905, validation loss: 2.6271
2024-06-04 03:47:40 [INFO]: Epoch 032 - training loss: 0.3886, validation loss: 2.6535
2024-06-04 03:47:54 [INFO]: Epoch 033 - training loss: 0.3864, validation loss: 2.6413
2024-06-04 03:48:08 [INFO]: Epoch 034 - training loss: 0.3848, validation loss: 2.6243
2024-06-04 03:48:22 [INFO]: Epoch 035 - training loss: 0.3825, validation loss: 2.6038
2024-06-04 03:48:36 [INFO]: Epoch 036 - training loss: 0.3765, validation loss: 2.6010
2024-06-04 03:48:50 [INFO]: Epoch 037 - training loss: 0.3743, validation loss: 2.6107
2024-06-04 03:49:04 [INFO]: Epoch 038 - training loss: 0.3776, validation loss: 2.6008
2024-06-04 03:49:18 [INFO]: Epoch 039 - training loss: 0.3733, validation loss: 2.6028
2024-06-04 03:49:32 [INFO]: Epoch 040 - training loss: 0.3682, validation loss: 2.6045
2024-06-04 03:49:46 [INFO]: Epoch 041 - training loss: 0.3658, validation loss: 2.5846
2024-06-04 03:50:00 [INFO]: Epoch 042 - training loss: 0.3626, validation loss: 2.6187
2024-06-04 03:50:14 [INFO]: Epoch 043 - training loss: 0.3637, validation loss: 2.6480
2024-06-04 03:50:28 [INFO]: Epoch 044 - training loss: 0.3618, validation loss: 2.6727
2024-06-04 03:50:42 [INFO]: Epoch 045 - training loss: 0.3575, validation loss: 2.6828
2024-06-04 03:50:57 [INFO]: Epoch 046 - training loss: 0.3553, validation loss: 2.7142
2024-06-04 03:51:11 [INFO]: Epoch 047 - training loss: 0.3529, validation loss: 2.7475
2024-06-04 03:51:25 [INFO]: Epoch 048 - training loss: 0.3499, validation loss: 2.7773
2024-06-04 03:51:39 [INFO]: Epoch 049 - training loss: 0.3516, validation loss: 2.7539
2024-06-04 03:51:53 [INFO]: Epoch 050 - training loss: 0.3555, validation loss: 2.7596
2024-06-04 03:52:07 [INFO]: Epoch 051 - training loss: 0.3500, validation loss: 2.7704
2024-06-04 03:52:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:52:07 [INFO]: Finished training. The best model is from epoch#41.
2024-06-04 03:52:08 [INFO]: Saved the model to results_point_rate05/Electricity/SAITS_Electricity/round_4/20240604_T034009/SAITS.pypots
2024-06-04 03:52:14 [INFO]: Successfully saved to results_point_rate05/Electricity/SAITS_Electricity/round_4/imputation.pkl
2024-06-04 03:52:14 [INFO]: Round4 - SAITS on Electricity: MAE=1.5053, MSE=4.3622, MRE=0.8060
2024-06-04 03:52:14 [INFO]: Done! Final results:
Averaged SAITS (63,624,720 params) on Electricity: MAE=1.3987 ± 0.06932699697531404, MSE=3.8371 ± 0.316471406015846, MRE=0.7489 ± 0.037118132416582905, average inference time=1.11
