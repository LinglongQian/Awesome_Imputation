2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:06 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-04 02:59:26 [INFO]: Epoch 001 - training loss: 1.1541, validation loss: 3.4894
2024-06-04 02:59:45 [INFO]: Epoch 002 - training loss: 0.7719, validation loss: 3.0219
2024-06-04 03:00:06 [INFO]: Epoch 003 - training loss: 0.6595, validation loss: 2.8560
2024-06-04 03:00:28 [INFO]: Epoch 004 - training loss: 0.6135, validation loss: 2.7229
2024-06-04 03:00:49 [INFO]: Epoch 005 - training loss: 0.5819, validation loss: 2.6365
2024-06-04 03:01:10 [INFO]: Epoch 006 - training loss: 0.5602, validation loss: 2.5608
2024-06-04 03:01:31 [INFO]: Epoch 007 - training loss: 0.5421, validation loss: 2.4980
2024-06-04 03:01:53 [INFO]: Epoch 008 - training loss: 0.5281, validation loss: 2.4579
2024-06-04 03:02:14 [INFO]: Epoch 009 - training loss: 0.5123, validation loss: 2.3995
2024-06-04 03:02:35 [INFO]: Epoch 010 - training loss: 0.5003, validation loss: 2.3652
2024-06-04 03:02:57 [INFO]: Epoch 011 - training loss: 0.4930, validation loss: 2.3309
2024-06-04 03:03:17 [INFO]: Epoch 012 - training loss: 0.4843, validation loss: 2.2928
2024-06-04 03:03:37 [INFO]: Epoch 013 - training loss: 0.4796, validation loss: 2.2767
2024-06-04 03:03:57 [INFO]: Epoch 014 - training loss: 0.4710, validation loss: 2.2471
2024-06-04 03:04:18 [INFO]: Epoch 015 - training loss: 0.4665, validation loss: 2.2199
2024-06-04 03:04:39 [INFO]: Epoch 016 - training loss: 0.4618, validation loss: 2.2005
2024-06-04 03:05:01 [INFO]: Epoch 017 - training loss: 0.4580, validation loss: 2.1781
2024-06-04 03:05:22 [INFO]: Epoch 018 - training loss: 0.4536, validation loss: 2.1543
2024-06-04 03:05:43 [INFO]: Epoch 019 - training loss: 0.4499, validation loss: 2.1384
2024-06-04 03:06:04 [INFO]: Epoch 020 - training loss: 0.4465, validation loss: 2.1232
2024-06-04 03:06:25 [INFO]: Epoch 021 - training loss: 0.4460, validation loss: 2.1091
2024-06-04 03:06:46 [INFO]: Epoch 022 - training loss: 0.4415, validation loss: 2.1012
2024-06-04 03:07:07 [INFO]: Epoch 023 - training loss: 0.4389, validation loss: 2.0807
2024-06-04 03:07:28 [INFO]: Epoch 024 - training loss: 0.4343, validation loss: 2.0609
2024-06-04 03:07:48 [INFO]: Epoch 025 - training loss: 0.4320, validation loss: 2.0575
2024-06-04 03:08:08 [INFO]: Epoch 026 - training loss: 0.4308, validation loss: 2.0337
2024-06-04 03:08:29 [INFO]: Epoch 027 - training loss: 0.4287, validation loss: 2.0222
2024-06-04 03:08:49 [INFO]: Epoch 028 - training loss: 0.4292, validation loss: 2.0215
2024-06-04 03:09:09 [INFO]: Epoch 029 - training loss: 0.4245, validation loss: 2.0079
2024-06-04 03:09:29 [INFO]: Epoch 030 - training loss: 0.4224, validation loss: 1.9872
2024-06-04 03:09:49 [INFO]: Epoch 031 - training loss: 0.4212, validation loss: 1.9792
2024-06-04 03:10:09 [INFO]: Epoch 032 - training loss: 0.4193, validation loss: 1.9755
2024-06-04 03:10:29 [INFO]: Epoch 033 - training loss: 0.4171, validation loss: 1.9671
2024-06-04 03:10:49 [INFO]: Epoch 034 - training loss: 0.4166, validation loss: 1.9584
2024-06-04 03:11:09 [INFO]: Epoch 035 - training loss: 0.4142, validation loss: 1.9523
2024-06-04 03:11:28 [INFO]: Epoch 036 - training loss: 0.4139, validation loss: 1.9404
2024-06-04 03:11:47 [INFO]: Epoch 037 - training loss: 0.4131, validation loss: 1.9254
2024-06-04 03:12:05 [INFO]: Epoch 038 - training loss: 0.4119, validation loss: 1.9245
2024-06-04 03:12:25 [INFO]: Epoch 039 - training loss: 0.4102, validation loss: 1.9199
2024-06-04 03:12:45 [INFO]: Epoch 040 - training loss: 0.4095, validation loss: 1.9171
2024-06-04 03:13:05 [INFO]: Epoch 041 - training loss: 0.4094, validation loss: 1.9121
2024-06-04 03:13:25 [INFO]: Epoch 042 - training loss: 0.4064, validation loss: 1.8959
2024-06-04 03:13:45 [INFO]: Epoch 043 - training loss: 0.4060, validation loss: 1.8959
2024-06-04 03:14:05 [INFO]: Epoch 044 - training loss: 0.4049, validation loss: 1.8942
2024-06-04 03:14:25 [INFO]: Epoch 045 - training loss: 0.4040, validation loss: 1.8784
2024-06-04 03:14:44 [INFO]: Epoch 046 - training loss: 0.4022, validation loss: 1.8835
2024-06-04 03:15:04 [INFO]: Epoch 047 - training loss: 0.4026, validation loss: 1.8790
2024-06-04 03:15:23 [INFO]: Epoch 048 - training loss: 0.4011, validation loss: 1.8689
2024-06-04 03:15:42 [INFO]: Epoch 049 - training loss: 0.4002, validation loss: 1.8523
2024-06-04 03:16:01 [INFO]: Epoch 050 - training loss: 0.3989, validation loss: 1.8662
2024-06-04 03:16:21 [INFO]: Epoch 051 - training loss: 0.3995, validation loss: 1.8474
2024-06-04 03:16:40 [INFO]: Epoch 052 - training loss: 0.3981, validation loss: 1.8469
2024-06-04 03:17:00 [INFO]: Epoch 053 - training loss: 0.3975, validation loss: 1.8349
2024-06-04 03:17:20 [INFO]: Epoch 054 - training loss: 0.3963, validation loss: 1.8189
2024-06-04 03:17:41 [INFO]: Epoch 055 - training loss: 0.3961, validation loss: 1.8085
2024-06-04 03:18:00 [INFO]: Epoch 056 - training loss: 0.3969, validation loss: 1.8354
2024-06-04 03:18:20 [INFO]: Epoch 057 - training loss: 0.3953, validation loss: 1.8338
2024-06-04 03:18:40 [INFO]: Epoch 058 - training loss: 0.3935, validation loss: 1.8045
2024-06-04 03:19:00 [INFO]: Epoch 059 - training loss: 0.3928, validation loss: 1.8225
2024-06-04 03:19:19 [INFO]: Epoch 060 - training loss: 0.3932, validation loss: 1.8074
2024-06-04 03:19:38 [INFO]: Epoch 061 - training loss: 0.3918, validation loss: 1.8062
2024-06-04 03:19:57 [INFO]: Epoch 062 - training loss: 0.3912, validation loss: 1.7984
2024-06-04 03:20:16 [INFO]: Epoch 063 - training loss: 0.3915, validation loss: 1.8062
2024-06-04 03:20:36 [INFO]: Epoch 064 - training loss: 0.3904, validation loss: 1.8169
2024-06-04 03:20:56 [INFO]: Epoch 065 - training loss: 0.3895, validation loss: 1.8062
2024-06-04 03:21:16 [INFO]: Epoch 066 - training loss: 0.3892, validation loss: 1.7969
2024-06-04 03:21:36 [INFO]: Epoch 067 - training loss: 0.3901, validation loss: 1.8020
2024-06-04 03:21:56 [INFO]: Epoch 068 - training loss: 0.3898, validation loss: 1.8084
2024-06-04 03:22:15 [INFO]: Epoch 069 - training loss: 0.3884, validation loss: 1.7928
2024-06-04 03:22:35 [INFO]: Epoch 070 - training loss: 0.3869, validation loss: 1.7861
2024-06-04 03:22:55 [INFO]: Epoch 071 - training loss: 0.3873, validation loss: 1.7960
2024-06-04 03:23:15 [INFO]: Epoch 072 - training loss: 0.3871, validation loss: 1.8060
2024-06-04 03:23:34 [INFO]: Epoch 073 - training loss: 0.3865, validation loss: 1.7997
2024-06-04 03:23:53 [INFO]: Epoch 074 - training loss: 0.3860, validation loss: 1.7910
2024-06-04 03:24:12 [INFO]: Epoch 075 - training loss: 0.3868, validation loss: 1.8030
2024-06-04 03:24:32 [INFO]: Epoch 076 - training loss: 0.3849, validation loss: 1.7899
2024-06-04 03:24:52 [INFO]: Epoch 077 - training loss: 0.3836, validation loss: 1.8077
2024-06-04 03:25:11 [INFO]: Epoch 078 - training loss: 0.3835, validation loss: 1.7928
2024-06-04 03:25:31 [INFO]: Epoch 079 - training loss: 0.3829, validation loss: 1.7928
2024-06-04 03:25:51 [INFO]: Epoch 080 - training loss: 0.3831, validation loss: 1.7902
2024-06-04 03:25:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:25:51 [INFO]: Finished training. The best model is from epoch#70.
2024-06-04 03:25:51 [INFO]: Saved the model to results_point_rate05/Electricity/Crossformer_Electricity/round_0/20240604_T025905/Crossformer.pypots
2024-06-04 03:26:00 [INFO]: Successfully saved to results_point_rate05/Electricity/Crossformer_Electricity/round_0/imputation.pkl
2024-06-04 03:26:00 [INFO]: Round0 - Crossformer on Electricity: MAE=0.7786, MSE=1.3463, MRE=0.4169
2024-06-04 03:26:00 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:26:00 [INFO]: Using the given device: cuda:0
2024-06-04 03:26:00 [INFO]: Model files will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_1/20240604_T032600
2024-06-04 03:26:00 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_1/20240604_T032600/tensorboard
2024-06-04 03:26:01 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-04 03:26:21 [INFO]: Epoch 001 - training loss: 1.1405, validation loss: 3.4191
2024-06-04 03:26:41 [INFO]: Epoch 002 - training loss: 0.7469, validation loss: 2.9787
2024-06-04 03:27:00 [INFO]: Epoch 003 - training loss: 0.6453, validation loss: 2.8189
2024-06-04 03:27:19 [INFO]: Epoch 004 - training loss: 0.6016, validation loss: 2.6819
2024-06-04 03:27:38 [INFO]: Epoch 005 - training loss: 0.5722, validation loss: 2.5882
2024-06-04 03:27:57 [INFO]: Epoch 006 - training loss: 0.5486, validation loss: 2.5243
2024-06-04 03:28:17 [INFO]: Epoch 007 - training loss: 0.5284, validation loss: 2.4649
2024-06-04 03:28:37 [INFO]: Epoch 008 - training loss: 0.5144, validation loss: 2.4038
2024-06-04 03:28:57 [INFO]: Epoch 009 - training loss: 0.5067, validation loss: 2.3683
2024-06-04 03:29:17 [INFO]: Epoch 010 - training loss: 0.4951, validation loss: 2.3368
2024-06-04 03:29:37 [INFO]: Epoch 011 - training loss: 0.4859, validation loss: 2.2958
2024-06-04 03:29:57 [INFO]: Epoch 012 - training loss: 0.4809, validation loss: 2.2729
2024-06-04 03:30:17 [INFO]: Epoch 013 - training loss: 0.4751, validation loss: 2.2373
2024-06-04 03:30:37 [INFO]: Epoch 014 - training loss: 0.4683, validation loss: 2.2162
2024-06-04 03:30:56 [INFO]: Epoch 015 - training loss: 0.4637, validation loss: 2.1975
2024-06-04 03:31:15 [INFO]: Epoch 016 - training loss: 0.4593, validation loss: 2.1791
2024-06-04 03:31:34 [INFO]: Epoch 017 - training loss: 0.4554, validation loss: 2.1577
2024-06-04 03:31:53 [INFO]: Epoch 018 - training loss: 0.4524, validation loss: 2.1493
2024-06-04 03:32:13 [INFO]: Epoch 019 - training loss: 0.4485, validation loss: 2.1261
2024-06-04 03:32:33 [INFO]: Epoch 020 - training loss: 0.4453, validation loss: 2.1210
2024-06-04 03:32:52 [INFO]: Epoch 021 - training loss: 0.4430, validation loss: 2.0883
2024-06-04 03:33:12 [INFO]: Epoch 022 - training loss: 0.4397, validation loss: 2.0764
2024-06-04 03:33:32 [INFO]: Epoch 023 - training loss: 0.4362, validation loss: 2.0699
2024-06-04 03:33:52 [INFO]: Epoch 024 - training loss: 0.4333, validation loss: 2.0496
2024-06-04 03:34:12 [INFO]: Epoch 025 - training loss: 0.4311, validation loss: 2.0409
2024-06-04 03:34:32 [INFO]: Epoch 026 - training loss: 0.4290, validation loss: 2.0363
2024-06-04 03:34:52 [INFO]: Epoch 027 - training loss: 0.4269, validation loss: 2.0219
2024-06-04 03:35:11 [INFO]: Epoch 028 - training loss: 0.4249, validation loss: 2.0078
2024-06-04 03:35:29 [INFO]: Epoch 029 - training loss: 0.4246, validation loss: 2.0081
2024-06-04 03:35:48 [INFO]: Epoch 030 - training loss: 0.4217, validation loss: 1.9890
2024-06-04 03:36:08 [INFO]: Epoch 031 - training loss: 0.4189, validation loss: 1.9733
2024-06-04 03:36:28 [INFO]: Epoch 032 - training loss: 0.4179, validation loss: 1.9797
2024-06-04 03:36:47 [INFO]: Epoch 033 - training loss: 0.4168, validation loss: 1.9758
2024-06-04 03:37:06 [INFO]: Epoch 034 - training loss: 0.4159, validation loss: 1.9588
2024-06-04 03:37:25 [INFO]: Epoch 035 - training loss: 0.4139, validation loss: 1.9457
2024-06-04 03:37:44 [INFO]: Epoch 036 - training loss: 0.4150, validation loss: 1.9493
2024-06-04 03:38:03 [INFO]: Epoch 037 - training loss: 0.4125, validation loss: 1.9379
2024-06-04 03:38:21 [INFO]: Epoch 038 - training loss: 0.4103, validation loss: 1.9431
2024-06-04 03:38:40 [INFO]: Epoch 039 - training loss: 0.4085, validation loss: 1.9292
2024-06-04 03:38:59 [INFO]: Epoch 040 - training loss: 0.4072, validation loss: 1.9157
2024-06-04 03:39:17 [INFO]: Epoch 041 - training loss: 0.4057, validation loss: 1.9175
2024-06-04 03:39:35 [INFO]: Epoch 042 - training loss: 0.4045, validation loss: 1.9028
2024-06-04 03:39:54 [INFO]: Epoch 043 - training loss: 0.4042, validation loss: 1.9012
2024-06-04 03:40:12 [INFO]: Epoch 044 - training loss: 0.4030, validation loss: 1.8996
2024-06-04 03:40:31 [INFO]: Epoch 045 - training loss: 0.4019, validation loss: 1.9004
2024-06-04 03:40:50 [INFO]: Epoch 046 - training loss: 0.4011, validation loss: 1.8802
2024-06-04 03:41:09 [INFO]: Epoch 047 - training loss: 0.4003, validation loss: 1.8957
2024-06-04 03:41:28 [INFO]: Epoch 048 - training loss: 0.4010, validation loss: 1.8788
2024-06-04 03:41:47 [INFO]: Epoch 049 - training loss: 0.3993, validation loss: 1.8937
2024-06-04 03:42:06 [INFO]: Epoch 050 - training loss: 0.3985, validation loss: 1.8806
2024-06-04 03:42:25 [INFO]: Epoch 051 - training loss: 0.3972, validation loss: 1.8803
2024-06-04 03:42:44 [INFO]: Epoch 052 - training loss: 0.3959, validation loss: 1.8581
2024-06-04 03:43:02 [INFO]: Epoch 053 - training loss: 0.3957, validation loss: 1.8635
2024-06-04 03:43:20 [INFO]: Epoch 054 - training loss: 0.3954, validation loss: 1.8530
2024-06-04 03:43:38 [INFO]: Epoch 055 - training loss: 0.3965, validation loss: 1.8619
2024-06-04 03:43:57 [INFO]: Epoch 056 - training loss: 0.3956, validation loss: 1.8665
2024-06-04 03:44:16 [INFO]: Epoch 057 - training loss: 0.3933, validation loss: 1.8572
2024-06-04 03:44:35 [INFO]: Epoch 058 - training loss: 0.3921, validation loss: 1.8396
2024-06-04 03:44:54 [INFO]: Epoch 059 - training loss: 0.3922, validation loss: 1.8600
2024-06-04 03:45:13 [INFO]: Epoch 060 - training loss: 0.3916, validation loss: 1.8481
2024-06-04 03:45:32 [INFO]: Epoch 061 - training loss: 0.3910, validation loss: 1.8508
2024-06-04 03:45:51 [INFO]: Epoch 062 - training loss: 0.3906, validation loss: 1.8481
2024-06-04 03:46:10 [INFO]: Epoch 063 - training loss: 0.3895, validation loss: 1.8399
2024-06-04 03:46:29 [INFO]: Epoch 064 - training loss: 0.3902, validation loss: 1.8464
2024-06-04 03:46:48 [INFO]: Epoch 065 - training loss: 0.3894, validation loss: 1.8561
2024-06-04 03:47:06 [INFO]: Epoch 066 - training loss: 0.3882, validation loss: 1.8515
2024-06-04 03:47:24 [INFO]: Epoch 067 - training loss: 0.3889, validation loss: 1.8495
2024-06-04 03:47:42 [INFO]: Epoch 068 - training loss: 0.3887, validation loss: 1.8416
2024-06-04 03:47:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:47:42 [INFO]: Finished training. The best model is from epoch#58.
2024-06-04 03:47:42 [INFO]: Saved the model to results_point_rate05/Electricity/Crossformer_Electricity/round_1/20240604_T032600/Crossformer.pypots
2024-06-04 03:47:51 [INFO]: Successfully saved to results_point_rate05/Electricity/Crossformer_Electricity/round_1/imputation.pkl
2024-06-04 03:47:51 [INFO]: Round1 - Crossformer on Electricity: MAE=0.8524, MSE=1.5453, MRE=0.4564
2024-06-04 03:47:51 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:47:51 [INFO]: Using the given device: cuda:0
2024-06-04 03:47:51 [INFO]: Model files will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_2/20240604_T034751
2024-06-04 03:47:51 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_2/20240604_T034751/tensorboard
2024-06-04 03:47:51 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-04 03:48:10 [INFO]: Epoch 001 - training loss: 1.1540, validation loss: 3.3606
2024-06-04 03:48:29 [INFO]: Epoch 002 - training loss: 0.7536, validation loss: 2.9761
2024-06-04 03:48:48 [INFO]: Epoch 003 - training loss: 0.6478, validation loss: 2.8095
2024-06-04 03:49:07 [INFO]: Epoch 004 - training loss: 0.6057, validation loss: 2.6977
2024-06-04 03:49:26 [INFO]: Epoch 005 - training loss: 0.5744, validation loss: 2.6143
2024-06-04 03:49:45 [INFO]: Epoch 006 - training loss: 0.5517, validation loss: 2.5319
2024-06-04 03:50:04 [INFO]: Epoch 007 - training loss: 0.5314, validation loss: 2.4687
2024-06-04 03:50:23 [INFO]: Epoch 008 - training loss: 0.5180, validation loss: 2.4117
2024-06-04 03:50:42 [INFO]: Epoch 009 - training loss: 0.5064, validation loss: 2.3757
2024-06-04 03:51:00 [INFO]: Epoch 010 - training loss: 0.4978, validation loss: 2.3417
2024-06-04 03:51:18 [INFO]: Epoch 011 - training loss: 0.4881, validation loss: 2.3037
2024-06-04 03:51:37 [INFO]: Epoch 012 - training loss: 0.4821, validation loss: 2.2735
2024-06-04 03:51:56 [INFO]: Epoch 013 - training loss: 0.4765, validation loss: 2.2467
2024-06-04 03:52:14 [INFO]: Epoch 014 - training loss: 0.4707, validation loss: 2.2253
2024-06-04 03:52:34 [INFO]: Epoch 015 - training loss: 0.4660, validation loss: 2.2064
2024-06-04 03:52:52 [INFO]: Epoch 016 - training loss: 0.4614, validation loss: 2.1868
2024-06-04 03:53:11 [INFO]: Epoch 017 - training loss: 0.4558, validation loss: 2.1698
2024-06-04 03:53:31 [INFO]: Epoch 018 - training loss: 0.4519, validation loss: 2.1423
2024-06-04 03:53:50 [INFO]: Epoch 019 - training loss: 0.4480, validation loss: 2.1363
2024-06-04 03:54:09 [INFO]: Epoch 020 - training loss: 0.4458, validation loss: 2.1189
2024-06-04 03:54:27 [INFO]: Epoch 021 - training loss: 0.4424, validation loss: 2.1008
2024-06-04 03:54:46 [INFO]: Epoch 022 - training loss: 0.4398, validation loss: 2.0833
2024-06-04 03:55:04 [INFO]: Epoch 023 - training loss: 0.4375, validation loss: 2.0877
2024-06-04 03:55:22 [INFO]: Epoch 024 - training loss: 0.4348, validation loss: 2.0656
2024-06-04 03:55:41 [INFO]: Epoch 025 - training loss: 0.4320, validation loss: 2.0539
2024-06-04 03:56:00 [INFO]: Epoch 026 - training loss: 0.4317, validation loss: 2.0652
2024-06-04 03:56:19 [INFO]: Epoch 027 - training loss: 0.4272, validation loss: 2.0386
2024-06-04 03:56:38 [INFO]: Epoch 028 - training loss: 0.4265, validation loss: 2.0384
2024-06-04 03:56:57 [INFO]: Epoch 029 - training loss: 0.4239, validation loss: 2.0236
2024-06-04 03:57:16 [INFO]: Epoch 030 - training loss: 0.4213, validation loss: 2.0005
2024-06-04 03:57:35 [INFO]: Epoch 031 - training loss: 0.4205, validation loss: 2.0075
2024-06-04 03:57:54 [INFO]: Epoch 032 - training loss: 0.4184, validation loss: 2.0002
2024-06-04 03:58:13 [INFO]: Epoch 033 - training loss: 0.4170, validation loss: 1.9795
2024-06-04 03:58:32 [INFO]: Epoch 034 - training loss: 0.4157, validation loss: 1.9874
2024-06-04 03:58:50 [INFO]: Epoch 035 - training loss: 0.4141, validation loss: 1.9636
2024-06-04 03:59:08 [INFO]: Epoch 036 - training loss: 0.4126, validation loss: 1.9682
2024-06-04 03:59:26 [INFO]: Epoch 037 - training loss: 0.4118, validation loss: 1.9544
2024-06-04 03:59:45 [INFO]: Epoch 038 - training loss: 0.4098, validation loss: 1.9468
2024-06-04 04:00:04 [INFO]: Epoch 039 - training loss: 0.4096, validation loss: 1.9473
2024-06-04 04:00:23 [INFO]: Epoch 040 - training loss: 0.4079, validation loss: 1.9339
2024-06-04 04:00:42 [INFO]: Epoch 041 - training loss: 0.4059, validation loss: 1.9388
2024-06-04 04:01:01 [INFO]: Epoch 042 - training loss: 0.4064, validation loss: 1.9215
2024-06-04 04:01:20 [INFO]: Epoch 043 - training loss: 0.4063, validation loss: 1.9337
2024-06-04 04:01:39 [INFO]: Epoch 044 - training loss: 0.4036, validation loss: 1.9210
2024-06-04 04:01:58 [INFO]: Epoch 045 - training loss: 0.4020, validation loss: 1.9017
2024-06-04 04:02:17 [INFO]: Epoch 046 - training loss: 0.4021, validation loss: 1.9064
2024-06-04 04:02:35 [INFO]: Epoch 047 - training loss: 0.4022, validation loss: 1.9029
2024-06-04 04:02:54 [INFO]: Epoch 048 - training loss: 0.3996, validation loss: 1.8897
2024-06-04 04:03:12 [INFO]: Epoch 049 - training loss: 0.3992, validation loss: 1.8994
2024-06-04 04:03:30 [INFO]: Epoch 050 - training loss: 0.3977, validation loss: 1.8852
2024-06-04 04:03:49 [INFO]: Epoch 051 - training loss: 0.3975, validation loss: 1.8811
2024-06-04 04:04:08 [INFO]: Epoch 052 - training loss: 0.3977, validation loss: 1.8843
2024-06-04 04:04:27 [INFO]: Epoch 053 - training loss: 0.3969, validation loss: 1.8666
2024-06-04 04:04:46 [INFO]: Epoch 054 - training loss: 0.3991, validation loss: 1.8801
2024-06-04 04:05:05 [INFO]: Epoch 055 - training loss: 0.4011, validation loss: 1.9019
2024-06-04 04:05:25 [INFO]: Epoch 056 - training loss: 0.3972, validation loss: 1.8733
2024-06-04 04:05:44 [INFO]: Epoch 057 - training loss: 0.3940, validation loss: 1.8585
2024-06-04 04:06:03 [INFO]: Epoch 058 - training loss: 0.3922, validation loss: 1.8490
2024-06-04 04:06:21 [INFO]: Epoch 059 - training loss: 0.3926, validation loss: 1.8647
2024-06-04 04:06:40 [INFO]: Epoch 060 - training loss: 0.3915, validation loss: 1.8460
2024-06-04 04:06:59 [INFO]: Epoch 061 - training loss: 0.3907, validation loss: 1.8380
2024-06-04 04:07:17 [INFO]: Epoch 062 - training loss: 0.3907, validation loss: 1.8436
2024-06-04 04:07:35 [INFO]: Epoch 063 - training loss: 0.3897, validation loss: 1.8406
2024-06-04 04:07:54 [INFO]: Epoch 064 - training loss: 0.3891, validation loss: 1.8378
2024-06-04 04:08:13 [INFO]: Epoch 065 - training loss: 0.3886, validation loss: 1.8373
2024-06-04 04:08:32 [INFO]: Epoch 066 - training loss: 0.3881, validation loss: 1.8480
2024-06-04 04:08:51 [INFO]: Epoch 067 - training loss: 0.3871, validation loss: 1.8367
2024-06-04 04:09:10 [INFO]: Epoch 068 - training loss: 0.3877, validation loss: 1.8399
2024-06-04 04:09:29 [INFO]: Epoch 069 - training loss: 0.3876, validation loss: 1.8378
2024-06-04 04:09:48 [INFO]: Epoch 070 - training loss: 0.3872, validation loss: 1.8609
2024-06-04 04:10:07 [INFO]: Epoch 071 - training loss: 0.3880, validation loss: 1.8545
2024-06-04 04:10:25 [INFO]: Epoch 072 - training loss: 0.3860, validation loss: 1.8427
2024-06-04 04:10:44 [INFO]: Epoch 073 - training loss: 0.3860, validation loss: 1.8436
2024-06-04 04:11:02 [INFO]: Epoch 074 - training loss: 0.3858, validation loss: 1.8328
2024-06-04 04:11:20 [INFO]: Epoch 075 - training loss: 0.3865, validation loss: 1.8551
2024-06-04 04:11:39 [INFO]: Epoch 076 - training loss: 0.3840, validation loss: 1.8298
2024-06-04 04:11:58 [INFO]: Epoch 077 - training loss: 0.3840, validation loss: 1.8264
2024-06-04 04:12:17 [INFO]: Epoch 078 - training loss: 0.3837, validation loss: 1.8294
2024-06-04 04:12:36 [INFO]: Epoch 079 - training loss: 0.3826, validation loss: 1.8211
2024-06-04 04:12:55 [INFO]: Epoch 080 - training loss: 0.3841, validation loss: 1.8296
2024-06-04 04:13:14 [INFO]: Epoch 081 - training loss: 0.3822, validation loss: 1.7996
2024-06-04 04:13:33 [INFO]: Epoch 082 - training loss: 0.3817, validation loss: 1.8158
2024-06-04 04:13:52 [INFO]: Epoch 083 - training loss: 0.3816, validation loss: 1.8144
2024-06-04 04:14:10 [INFO]: Epoch 084 - training loss: 0.3815, validation loss: 1.8181
2024-06-04 04:14:29 [INFO]: Epoch 085 - training loss: 0.3807, validation loss: 1.8134
2024-06-04 04:14:48 [INFO]: Epoch 086 - training loss: 0.3812, validation loss: 1.8041
2024-06-04 04:15:06 [INFO]: Epoch 087 - training loss: 0.3811, validation loss: 1.8239
2024-06-04 04:15:24 [INFO]: Epoch 088 - training loss: 0.3800, validation loss: 1.8086
2024-06-04 04:15:43 [INFO]: Epoch 089 - training loss: 0.3795, validation loss: 1.8168
2024-06-04 04:16:02 [INFO]: Epoch 090 - training loss: 0.3789, validation loss: 1.8135
2024-06-04 04:16:21 [INFO]: Epoch 091 - training loss: 0.3792, validation loss: 1.8414
2024-06-04 04:16:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:16:21 [INFO]: Finished training. The best model is from epoch#81.
2024-06-04 04:16:21 [INFO]: Saved the model to results_point_rate05/Electricity/Crossformer_Electricity/round_2/20240604_T034751/Crossformer.pypots
2024-06-04 04:16:29 [INFO]: Successfully saved to results_point_rate05/Electricity/Crossformer_Electricity/round_2/imputation.pkl
2024-06-04 04:16:29 [INFO]: Round2 - Crossformer on Electricity: MAE=0.7873, MSE=1.3776, MRE=0.4215
2024-06-04 04:16:29 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 04:16:29 [INFO]: Using the given device: cuda:0
2024-06-04 04:16:29 [INFO]: Model files will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_3/20240604_T041629
2024-06-04 04:16:29 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_3/20240604_T041629/tensorboard
2024-06-04 04:16:30 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-04 04:16:49 [INFO]: Epoch 001 - training loss: 1.1766, validation loss: 3.6860
2024-06-04 04:17:08 [INFO]: Epoch 002 - training loss: 0.8352, validation loss: 3.0907
2024-06-04 04:17:27 [INFO]: Epoch 003 - training loss: 0.6798, validation loss: 2.9108
2024-06-04 04:17:46 [INFO]: Epoch 004 - training loss: 0.6290, validation loss: 2.7855
2024-06-04 04:18:04 [INFO]: Epoch 005 - training loss: 0.5924, validation loss: 2.6912
2024-06-04 04:18:23 [INFO]: Epoch 006 - training loss: 0.5652, validation loss: 2.6110
2024-06-04 04:18:42 [INFO]: Epoch 007 - training loss: 0.5474, validation loss: 2.5585
2024-06-04 04:19:00 [INFO]: Epoch 008 - training loss: 0.5284, validation loss: 2.4911
2024-06-04 04:19:18 [INFO]: Epoch 009 - training loss: 0.5150, validation loss: 2.4505
2024-06-04 04:19:37 [INFO]: Epoch 010 - training loss: 0.5027, validation loss: 2.4117
2024-06-04 04:19:56 [INFO]: Epoch 011 - training loss: 0.4938, validation loss: 2.3635
2024-06-04 04:20:15 [INFO]: Epoch 012 - training loss: 0.4859, validation loss: 2.3492
2024-06-04 04:20:34 [INFO]: Epoch 013 - training loss: 0.4799, validation loss: 2.3144
2024-06-04 04:20:53 [INFO]: Epoch 014 - training loss: 0.4734, validation loss: 2.2878
2024-06-04 04:21:12 [INFO]: Epoch 015 - training loss: 0.4688, validation loss: 2.2714
2024-06-04 04:21:31 [INFO]: Epoch 016 - training loss: 0.4639, validation loss: 2.2406
2024-06-04 04:21:50 [INFO]: Epoch 017 - training loss: 0.4581, validation loss: 2.2210
2024-06-04 04:22:09 [INFO]: Epoch 018 - training loss: 0.4544, validation loss: 2.1927
2024-06-04 04:22:28 [INFO]: Epoch 019 - training loss: 0.4522, validation loss: 2.1788
2024-06-04 04:22:47 [INFO]: Epoch 020 - training loss: 0.4469, validation loss: 2.1688
2024-06-04 04:23:05 [INFO]: Epoch 021 - training loss: 0.4444, validation loss: 2.1373
2024-06-04 04:23:23 [INFO]: Epoch 022 - training loss: 0.4411, validation loss: 2.1428
2024-06-04 04:23:42 [INFO]: Epoch 023 - training loss: 0.4390, validation loss: 2.1225
2024-06-04 04:24:01 [INFO]: Epoch 024 - training loss: 0.4369, validation loss: 2.1030
2024-06-04 04:24:20 [INFO]: Epoch 025 - training loss: 0.4344, validation loss: 2.0973
2024-06-04 04:24:39 [INFO]: Epoch 026 - training loss: 0.4322, validation loss: 2.0843
2024-06-04 04:24:57 [INFO]: Epoch 027 - training loss: 0.4295, validation loss: 2.0647
2024-06-04 04:25:16 [INFO]: Epoch 028 - training loss: 0.4273, validation loss: 2.0612
2024-06-04 04:25:35 [INFO]: Epoch 029 - training loss: 0.4250, validation loss: 2.0486
2024-06-04 04:25:54 [INFO]: Epoch 030 - training loss: 0.4231, validation loss: 2.0487
2024-06-04 04:26:13 [INFO]: Epoch 031 - training loss: 0.4205, validation loss: 2.0387
2024-06-04 04:26:32 [INFO]: Epoch 032 - training loss: 0.4189, validation loss: 2.0278
2024-06-04 04:26:50 [INFO]: Epoch 033 - training loss: 0.4185, validation loss: 2.0186
2024-06-04 04:27:08 [INFO]: Epoch 034 - training loss: 0.4172, validation loss: 2.0063
2024-06-04 04:27:26 [INFO]: Epoch 035 - training loss: 0.4151, validation loss: 2.0119
2024-06-04 04:27:45 [INFO]: Epoch 036 - training loss: 0.4134, validation loss: 1.9917
2024-06-04 04:28:04 [INFO]: Epoch 037 - training loss: 0.4121, validation loss: 1.9940
2024-06-04 04:28:23 [INFO]: Epoch 038 - training loss: 0.4109, validation loss: 1.9794
2024-06-04 04:28:42 [INFO]: Epoch 039 - training loss: 0.4108, validation loss: 1.9623
2024-06-04 04:29:01 [INFO]: Epoch 040 - training loss: 0.4092, validation loss: 1.9717
2024-06-04 04:29:20 [INFO]: Epoch 041 - training loss: 0.4081, validation loss: 1.9570
2024-06-04 04:29:39 [INFO]: Epoch 042 - training loss: 0.4065, validation loss: 1.9540
2024-06-04 04:29:58 [INFO]: Epoch 043 - training loss: 0.4056, validation loss: 1.9521
2024-06-04 04:30:17 [INFO]: Epoch 044 - training loss: 0.4048, validation loss: 1.9332
2024-06-04 04:30:36 [INFO]: Epoch 045 - training loss: 0.4041, validation loss: 1.9330
2024-06-04 04:30:54 [INFO]: Epoch 046 - training loss: 0.4033, validation loss: 1.9267
2024-06-04 04:31:12 [INFO]: Epoch 047 - training loss: 0.4017, validation loss: 1.9461
2024-06-04 04:31:30 [INFO]: Epoch 048 - training loss: 0.4018, validation loss: 1.9230
2024-06-04 04:31:49 [INFO]: Epoch 049 - training loss: 0.4004, validation loss: 1.9223
2024-06-04 04:32:08 [INFO]: Epoch 050 - training loss: 0.4001, validation loss: 1.9261
2024-06-04 04:32:27 [INFO]: Epoch 051 - training loss: 0.4006, validation loss: 1.8994
2024-06-04 04:32:46 [INFO]: Epoch 052 - training loss: 0.3984, validation loss: 1.9092
2024-06-04 04:33:05 [INFO]: Epoch 053 - training loss: 0.3967, validation loss: 1.8999
2024-06-04 04:33:24 [INFO]: Epoch 054 - training loss: 0.3961, validation loss: 1.8855
2024-06-04 04:33:43 [INFO]: Epoch 055 - training loss: 0.3954, validation loss: 1.9008
2024-06-04 04:34:02 [INFO]: Epoch 056 - training loss: 0.3945, validation loss: 1.8853
2024-06-04 04:34:21 [INFO]: Epoch 057 - training loss: 0.3947, validation loss: 1.8950
2024-06-04 04:34:40 [INFO]: Epoch 058 - training loss: 0.3946, validation loss: 1.8998
2024-06-04 04:34:58 [INFO]: Epoch 059 - training loss: 0.3936, validation loss: 1.8956
2024-06-04 04:35:16 [INFO]: Epoch 060 - training loss: 0.3926, validation loss: 1.8984
2024-06-04 04:35:35 [INFO]: Epoch 061 - training loss: 0.3921, validation loss: 1.8707
2024-06-04 04:35:54 [INFO]: Epoch 062 - training loss: 0.3910, validation loss: 1.8712
2024-06-04 04:36:13 [INFO]: Epoch 063 - training loss: 0.3914, validation loss: 1.8780
2024-06-04 04:36:32 [INFO]: Epoch 064 - training loss: 0.3915, validation loss: 1.8835
2024-06-04 04:36:50 [INFO]: Epoch 065 - training loss: 0.3895, validation loss: 1.8619
2024-06-04 04:37:09 [INFO]: Epoch 066 - training loss: 0.3892, validation loss: 1.8818
2024-06-04 04:37:28 [INFO]: Epoch 067 - training loss: 0.3886, validation loss: 1.8805
2024-06-04 04:37:47 [INFO]: Epoch 068 - training loss: 0.3887, validation loss: 1.8775
2024-06-04 04:38:07 [INFO]: Epoch 069 - training loss: 0.3881, validation loss: 1.8685
2024-06-04 04:38:25 [INFO]: Epoch 070 - training loss: 0.3870, validation loss: 1.8650
2024-06-04 04:38:44 [INFO]: Epoch 071 - training loss: 0.3874, validation loss: 1.8517
2024-06-04 04:39:01 [INFO]: Epoch 072 - training loss: 0.3869, validation loss: 1.8620
2024-06-04 04:39:19 [INFO]: Epoch 073 - training loss: 0.3856, validation loss: 1.8589
2024-06-04 04:39:38 [INFO]: Epoch 074 - training loss: 0.3849, validation loss: 1.8593
2024-06-04 04:39:57 [INFO]: Epoch 075 - training loss: 0.3844, validation loss: 1.8512
2024-06-04 04:40:16 [INFO]: Epoch 076 - training loss: 0.3846, validation loss: 1.8572
2024-06-04 04:40:35 [INFO]: Epoch 077 - training loss: 0.3844, validation loss: 1.8595
2024-06-04 04:40:54 [INFO]: Epoch 078 - training loss: 0.3841, validation loss: 1.8617
2024-06-04 04:41:13 [INFO]: Epoch 079 - training loss: 0.3833, validation loss: 1.8304
2024-06-04 04:41:32 [INFO]: Epoch 080 - training loss: 0.3829, validation loss: 1.8236
2024-06-04 04:41:51 [INFO]: Epoch 081 - training loss: 0.3827, validation loss: 1.8367
2024-06-04 04:42:10 [INFO]: Epoch 082 - training loss: 0.3823, validation loss: 1.8583
2024-06-04 04:42:29 [INFO]: Epoch 083 - training loss: 0.3818, validation loss: 1.8547
2024-06-04 04:42:47 [INFO]: Epoch 084 - training loss: 0.3814, validation loss: 1.8345
2024-06-04 04:43:05 [INFO]: Epoch 085 - training loss: 0.3814, validation loss: 1.8558
2024-06-04 04:43:24 [INFO]: Epoch 086 - training loss: 0.3834, validation loss: 1.8564
2024-06-04 04:43:42 [INFO]: Epoch 087 - training loss: 0.4401, validation loss: 2.7911
2024-06-04 04:44:02 [INFO]: Epoch 088 - training loss: 1.1546, validation loss: 3.8327
2024-06-04 04:44:21 [INFO]: Epoch 089 - training loss: 1.2430, validation loss: 3.7105
2024-06-04 04:44:40 [INFO]: Epoch 090 - training loss: 1.1400, validation loss: 3.7182
2024-06-04 04:44:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:44:40 [INFO]: Finished training. The best model is from epoch#80.
2024-06-04 04:44:40 [INFO]: Saved the model to results_point_rate05/Electricity/Crossformer_Electricity/round_3/20240604_T041629/Crossformer.pypots
2024-06-04 04:44:48 [INFO]: Successfully saved to results_point_rate05/Electricity/Crossformer_Electricity/round_3/imputation.pkl
2024-06-04 04:44:48 [INFO]: Round3 - Crossformer on Electricity: MAE=1.6674, MSE=5.5638, MRE=0.8927
2024-06-04 04:44:48 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:44:48 [INFO]: Using the given device: cuda:0
2024-06-04 04:44:48 [INFO]: Model files will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_4/20240604_T044448
2024-06-04 04:44:48 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Crossformer_Electricity/round_4/20240604_T044448/tensorboard
2024-06-04 04:44:49 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 9,967,314
2024-06-04 04:45:08 [INFO]: Epoch 001 - training loss: 1.1496, validation loss: 3.3824
2024-06-04 04:45:27 [INFO]: Epoch 002 - training loss: 0.7625, validation loss: 2.9973
2024-06-04 04:45:46 [INFO]: Epoch 003 - training loss: 0.6539, validation loss: 2.8368
2024-06-04 04:46:05 [INFO]: Epoch 004 - training loss: 0.6095, validation loss: 2.7033
2024-06-04 04:46:23 [INFO]: Epoch 005 - training loss: 0.5783, validation loss: 2.6125
2024-06-04 04:46:39 [INFO]: Epoch 006 - training loss: 0.5579, validation loss: 2.5312
2024-06-04 04:46:55 [INFO]: Epoch 007 - training loss: 0.5376, validation loss: 2.4617
2024-06-04 04:47:11 [INFO]: Epoch 008 - training loss: 0.5219, validation loss: 2.4072
2024-06-04 04:47:28 [INFO]: Epoch 009 - training loss: 0.5095, validation loss: 2.3587
2024-06-04 04:47:44 [INFO]: Epoch 010 - training loss: 0.4989, validation loss: 2.3180
2024-06-04 04:48:01 [INFO]: Epoch 011 - training loss: 0.4918, validation loss: 2.2932
2024-06-04 04:48:18 [INFO]: Epoch 012 - training loss: 0.4828, validation loss: 2.2650
2024-06-04 04:48:35 [INFO]: Epoch 013 - training loss: 0.4778, validation loss: 2.2314
2024-06-04 04:48:52 [INFO]: Epoch 014 - training loss: 0.4728, validation loss: 2.2054
2024-06-04 04:49:09 [INFO]: Epoch 015 - training loss: 0.4655, validation loss: 2.1905
2024-06-04 04:49:25 [INFO]: Epoch 016 - training loss: 0.4615, validation loss: 2.1678
2024-06-04 04:49:42 [INFO]: Epoch 017 - training loss: 0.4578, validation loss: 2.1430
2024-06-04 04:49:59 [INFO]: Epoch 018 - training loss: 0.4533, validation loss: 2.1270
2024-06-04 04:50:15 [INFO]: Epoch 019 - training loss: 0.4500, validation loss: 2.1090
2024-06-04 04:50:31 [INFO]: Epoch 020 - training loss: 0.4475, validation loss: 2.0926
2024-06-04 04:50:47 [INFO]: Epoch 021 - training loss: 0.4444, validation loss: 2.0814
2024-06-04 04:51:04 [INFO]: Epoch 022 - training loss: 0.4401, validation loss: 2.0649
2024-06-04 04:51:21 [INFO]: Epoch 023 - training loss: 0.4375, validation loss: 2.0498
2024-06-04 04:51:38 [INFO]: Epoch 024 - training loss: 0.4360, validation loss: 2.0413
2024-06-04 04:51:55 [INFO]: Epoch 025 - training loss: 0.4353, validation loss: 2.0323
2024-06-04 04:52:11 [INFO]: Epoch 026 - training loss: 0.4310, validation loss: 2.0261
2024-06-04 04:52:28 [INFO]: Epoch 027 - training loss: 0.4287, validation loss: 2.0137
2024-06-04 04:52:44 [INFO]: Epoch 028 - training loss: 0.4272, validation loss: 2.0087
2024-06-04 04:53:01 [INFO]: Epoch 029 - training loss: 0.4239, validation loss: 1.9955
2024-06-04 04:53:18 [INFO]: Epoch 030 - training loss: 0.4227, validation loss: 1.9869
2024-06-04 04:53:35 [INFO]: Epoch 031 - training loss: 0.4213, validation loss: 1.9869
2024-06-04 04:53:51 [INFO]: Epoch 032 - training loss: 0.4207, validation loss: 1.9767
2024-06-04 04:54:07 [INFO]: Epoch 033 - training loss: 0.4187, validation loss: 1.9701
2024-06-04 04:54:23 [INFO]: Epoch 034 - training loss: 0.4165, validation loss: 1.9646
2024-06-04 04:54:40 [INFO]: Epoch 035 - training loss: 0.4146, validation loss: 1.9507
2024-06-04 04:54:57 [INFO]: Epoch 036 - training loss: 0.4143, validation loss: 1.9511
2024-06-04 04:55:14 [INFO]: Epoch 037 - training loss: 0.4133, validation loss: 1.9360
2024-06-04 04:55:30 [INFO]: Epoch 038 - training loss: 0.4113, validation loss: 1.9269
2024-06-04 04:55:47 [INFO]: Epoch 039 - training loss: 0.4107, validation loss: 1.9449
2024-06-04 04:56:04 [INFO]: Epoch 040 - training loss: 0.4085, validation loss: 1.9347
2024-06-04 04:56:21 [INFO]: Epoch 041 - training loss: 0.4082, validation loss: 1.9177
2024-06-04 04:56:38 [INFO]: Epoch 042 - training loss: 0.4070, validation loss: 1.9056
2024-06-04 04:56:55 [INFO]: Epoch 043 - training loss: 0.4075, validation loss: 1.9041
2024-06-04 04:57:11 [INFO]: Epoch 044 - training loss: 0.4056, validation loss: 1.9013
2024-06-04 04:57:28 [INFO]: Epoch 045 - training loss: 0.4047, validation loss: 1.9245
2024-06-04 04:57:44 [INFO]: Epoch 046 - training loss: 0.4055, validation loss: 1.8952
2024-06-04 04:58:00 [INFO]: Epoch 047 - training loss: 0.4022, validation loss: 1.8921
2024-06-04 04:58:16 [INFO]: Epoch 048 - training loss: 0.4017, validation loss: 1.8837
2024-06-04 04:58:33 [INFO]: Epoch 049 - training loss: 0.4007, validation loss: 1.8833
2024-06-04 04:58:50 [INFO]: Epoch 050 - training loss: 0.4003, validation loss: 1.8734
2024-06-04 04:59:07 [INFO]: Epoch 051 - training loss: 0.3989, validation loss: 1.8924
2024-06-04 04:59:23 [INFO]: Epoch 052 - training loss: 0.3990, validation loss: 1.8831
2024-06-04 04:59:40 [INFO]: Epoch 053 - training loss: 0.3972, validation loss: 1.8619
2024-06-04 04:59:57 [INFO]: Epoch 054 - training loss: 0.3975, validation loss: 1.8707
2024-06-04 05:00:14 [INFO]: Epoch 055 - training loss: 0.3956, validation loss: 1.8723
2024-06-04 05:00:31 [INFO]: Epoch 056 - training loss: 0.3947, validation loss: 1.8605
2024-06-04 05:00:48 [INFO]: Epoch 057 - training loss: 0.3952, validation loss: 1.8891
2024-06-04 05:01:04 [INFO]: Epoch 058 - training loss: 0.3948, validation loss: 1.8578
2024-06-04 05:01:20 [INFO]: Epoch 059 - training loss: 0.3938, validation loss: 1.8838
2024-06-04 05:01:36 [INFO]: Epoch 060 - training loss: 0.3927, validation loss: 1.8731
2024-06-04 05:01:53 [INFO]: Epoch 061 - training loss: 0.3922, validation loss: 1.8734
2024-06-04 05:02:10 [INFO]: Epoch 062 - training loss: 0.3913, validation loss: 1.8612
2024-06-04 05:02:27 [INFO]: Epoch 063 - training loss: 0.3908, validation loss: 1.8787
2024-06-04 05:02:43 [INFO]: Epoch 064 - training loss: 0.3905, validation loss: 1.8732
2024-06-04 05:03:00 [INFO]: Epoch 065 - training loss: 0.3896, validation loss: 1.8385
2024-06-04 05:03:17 [INFO]: Epoch 066 - training loss: 0.3895, validation loss: 1.8503
2024-06-04 05:03:33 [INFO]: Epoch 067 - training loss: 0.3888, validation loss: 1.8653
2024-06-04 05:03:50 [INFO]: Epoch 068 - training loss: 0.3903, validation loss: 1.8698
2024-06-04 05:04:07 [INFO]: Epoch 069 - training loss: 0.3911, validation loss: 1.8678
2024-06-04 05:04:24 [INFO]: Epoch 070 - training loss: 0.3871, validation loss: 1.8642
2024-06-04 05:04:40 [INFO]: Epoch 071 - training loss: 0.3869, validation loss: 1.8793
2024-06-04 05:04:56 [INFO]: Epoch 072 - training loss: 0.3871, validation loss: 1.8413
2024-06-04 05:05:12 [INFO]: Epoch 073 - training loss: 0.3865, validation loss: 1.8621
2024-06-04 05:05:28 [INFO]: Epoch 074 - training loss: 0.3855, validation loss: 1.8580
2024-06-04 05:05:45 [INFO]: Epoch 075 - training loss: 0.3864, validation loss: 1.8689
2024-06-04 05:05:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 05:05:45 [INFO]: Finished training. The best model is from epoch#65.
2024-06-04 05:05:46 [INFO]: Saved the model to results_point_rate05/Electricity/Crossformer_Electricity/round_4/20240604_T044448/Crossformer.pypots
2024-06-04 05:05:53 [INFO]: Successfully saved to results_point_rate05/Electricity/Crossformer_Electricity/round_4/imputation.pkl
2024-06-04 05:05:53 [INFO]: Round4 - Crossformer on Electricity: MAE=0.8163, MSE=1.4413, MRE=0.4371
2024-06-04 05:05:53 [INFO]: Done! Final results:
Averaged Crossformer (9,967,314 params) on Electricity: MAE=0.9804 ± 0.344450688979671, MSE=2.2549 ± 1.6558753941307531, MRE=0.5249 ± 0.18442117562200552, average inference time=1.70
