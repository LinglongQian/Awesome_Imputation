2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:04 [INFO]: Model files will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_0/20240604_T025904
2024-06-04 02:59:04 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_0/20240604_T025904/tensorboard
2024-06-04 02:59:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 03:08:43 [INFO]: Epoch 001 - training loss: 1.0461, validation loss: 3.1636
2024-06-04 03:16:49 [INFO]: Epoch 002 - training loss: 0.7217, validation loss: 3.0011
2024-06-04 03:25:10 [INFO]: Epoch 003 - training loss: 0.6441, validation loss: 2.8807
2024-06-04 03:33:24 [INFO]: Epoch 004 - training loss: 0.6013, validation loss: 2.8223
2024-06-04 03:41:10 [INFO]: Epoch 005 - training loss: 0.5731, validation loss: 2.7896
2024-06-04 03:48:30 [INFO]: Epoch 006 - training loss: 0.5539, validation loss: 2.7706
2024-06-04 03:55:53 [INFO]: Epoch 007 - training loss: 0.5401, validation loss: 2.7532
2024-06-04 04:03:15 [INFO]: Epoch 008 - training loss: 0.5304, validation loss: 2.7483
2024-06-04 04:10:42 [INFO]: Epoch 009 - training loss: 0.5181, validation loss: 2.7390
2024-06-04 04:18:03 [INFO]: Epoch 010 - training loss: 0.5094, validation loss: 2.7227
2024-06-04 04:25:24 [INFO]: Epoch 011 - training loss: 0.5014, validation loss: 2.7209
2024-06-04 04:32:41 [INFO]: Epoch 012 - training loss: 0.4950, validation loss: 2.7147
2024-06-04 04:40:06 [INFO]: Epoch 013 - training loss: 0.4885, validation loss: 2.6990
2024-06-04 04:47:07 [INFO]: Epoch 014 - training loss: 0.4836, validation loss: 2.6934
2024-06-04 04:52:56 [INFO]: Epoch 015 - training loss: 0.4798, validation loss: 2.6897
2024-06-04 04:58:29 [INFO]: Epoch 016 - training loss: 0.4760, validation loss: 2.6814
2024-06-04 05:04:13 [INFO]: Epoch 017 - training loss: 0.4714, validation loss: 2.6754
2024-06-04 05:07:26 [INFO]: Epoch 018 - training loss: 0.4669, validation loss: 2.6730
2024-06-04 05:09:36 [INFO]: Epoch 019 - training loss: 0.4632, validation loss: 2.6611
2024-06-04 05:11:47 [INFO]: Epoch 020 - training loss: 0.4593, validation loss: 2.6607
2024-06-04 05:14:01 [INFO]: Epoch 021 - training loss: 0.4568, validation loss: 2.6544
2024-06-04 05:16:18 [INFO]: Epoch 022 - training loss: 0.4543, validation loss: 2.6456
2024-06-04 05:18:36 [INFO]: Epoch 023 - training loss: 0.4520, validation loss: 2.6416
2024-06-04 05:20:57 [INFO]: Epoch 024 - training loss: 0.4496, validation loss: 2.6420
2024-06-04 05:23:16 [INFO]: Epoch 025 - training loss: 0.4469, validation loss: 2.6435
2024-06-04 05:25:35 [INFO]: Epoch 026 - training loss: 0.4435, validation loss: 2.6291
2024-06-04 05:27:54 [INFO]: Epoch 027 - training loss: 0.4415, validation loss: 2.6324
2024-06-04 05:30:13 [INFO]: Epoch 028 - training loss: 0.4390, validation loss: 2.6260
2024-06-04 05:32:27 [INFO]: Epoch 029 - training loss: 0.4381, validation loss: 2.6189
2024-06-04 05:34:38 [INFO]: Epoch 030 - training loss: 0.4356, validation loss: 2.6168
2024-06-04 05:36:48 [INFO]: Epoch 031 - training loss: 0.4336, validation loss: 2.6157
2024-06-04 05:38:59 [INFO]: Epoch 032 - training loss: 0.4319, validation loss: 2.6143
2024-06-04 05:41:08 [INFO]: Epoch 033 - training loss: 0.4295, validation loss: 2.6123
2024-06-04 05:43:21 [INFO]: Epoch 034 - training loss: 0.4275, validation loss: 2.6076
2024-06-04 05:45:37 [INFO]: Epoch 035 - training loss: 0.4257, validation loss: 2.6044
2024-06-04 05:47:54 [INFO]: Epoch 036 - training loss: 0.4240, validation loss: 2.6038
2024-06-04 05:50:13 [INFO]: Epoch 037 - training loss: 0.4218, validation loss: 2.6026
2024-06-04 05:52:32 [INFO]: Epoch 038 - training loss: 0.4201, validation loss: 2.5997
2024-06-04 05:54:50 [INFO]: Epoch 039 - training loss: 0.4181, validation loss: 2.5990
2024-06-04 05:57:10 [INFO]: Epoch 040 - training loss: 0.4172, validation loss: 2.5948
2024-06-04 05:59:29 [INFO]: Epoch 041 - training loss: 0.4155, validation loss: 2.5890
2024-06-04 06:01:47 [INFO]: Epoch 042 - training loss: 0.4151, validation loss: 2.5935
2024-06-04 06:03:59 [INFO]: Epoch 043 - training loss: 0.4141, validation loss: 2.5930
2024-06-04 06:06:09 [INFO]: Epoch 044 - training loss: 0.4126, validation loss: 2.5876
2024-06-04 06:08:20 [INFO]: Epoch 045 - training loss: 0.4110, validation loss: 2.5815
2024-06-04 06:10:30 [INFO]: Epoch 046 - training loss: 0.4097, validation loss: 2.5867
2024-06-04 06:12:40 [INFO]: Epoch 047 - training loss: 0.4083, validation loss: 2.5849
2024-06-04 06:14:54 [INFO]: Epoch 048 - training loss: 0.4077, validation loss: 2.5809
2024-06-04 06:17:10 [INFO]: Epoch 049 - training loss: 0.4065, validation loss: 2.5799
2024-06-04 06:19:28 [INFO]: Epoch 050 - training loss: 0.4049, validation loss: 2.5798
2024-06-04 06:21:47 [INFO]: Epoch 051 - training loss: 0.4040, validation loss: 2.5756
2024-06-04 06:24:09 [INFO]: Epoch 052 - training loss: 0.4033, validation loss: 2.5755
2024-06-04 06:26:27 [INFO]: Epoch 053 - training loss: 0.4023, validation loss: 2.5777
2024-06-04 06:28:47 [INFO]: Epoch 054 - training loss: 0.4021, validation loss: 2.5696
2024-06-04 06:31:05 [INFO]: Epoch 055 - training loss: 0.4007, validation loss: 2.5703
2024-06-04 06:33:19 [INFO]: Epoch 056 - training loss: 0.3991, validation loss: 2.5706
2024-06-04 06:35:31 [INFO]: Epoch 057 - training loss: 0.3984, validation loss: 2.5605
2024-06-04 06:37:42 [INFO]: Epoch 058 - training loss: 0.3976, validation loss: 2.5631
2024-06-04 06:39:52 [INFO]: Epoch 059 - training loss: 0.3964, validation loss: 2.5642
2024-06-04 06:42:01 [INFO]: Epoch 060 - training loss: 0.3948, validation loss: 2.5626
2024-06-04 06:44:12 [INFO]: Epoch 061 - training loss: 0.3941, validation loss: 2.5592
2024-06-04 06:46:28 [INFO]: Epoch 062 - training loss: 0.3949, validation loss: 2.5527
2024-06-04 06:48:44 [INFO]: Epoch 063 - training loss: 0.3944, validation loss: 2.5575
2024-06-04 06:51:03 [INFO]: Epoch 064 - training loss: 0.3949, validation loss: 2.5499
2024-06-04 06:53:20 [INFO]: Epoch 065 - training loss: 0.3926, validation loss: 2.5580
2024-06-04 06:55:40 [INFO]: Epoch 066 - training loss: 0.3905, validation loss: 2.5533
2024-06-04 06:57:59 [INFO]: Epoch 067 - training loss: 0.3900, validation loss: 2.5518
2024-06-04 07:00:18 [INFO]: Epoch 068 - training loss: 0.3889, validation loss: 2.5512
2024-06-04 07:02:38 [INFO]: Epoch 069 - training loss: 0.3881, validation loss: 2.5519
2024-06-04 07:04:52 [INFO]: Epoch 070 - training loss: 0.3881, validation loss: 2.5490
2024-06-04 07:07:02 [INFO]: Epoch 071 - training loss: 0.3872, validation loss: 2.5455
2024-06-04 07:09:13 [INFO]: Epoch 072 - training loss: 0.3866, validation loss: 2.5441
2024-06-04 07:11:23 [INFO]: Epoch 073 - training loss: 0.3853, validation loss: 2.5460
2024-06-04 07:13:33 [INFO]: Epoch 074 - training loss: 0.3844, validation loss: 2.5423
2024-06-04 07:15:47 [INFO]: Epoch 075 - training loss: 0.3849, validation loss: 2.5443
2024-06-04 07:18:02 [INFO]: Epoch 076 - training loss: 0.3850, validation loss: 2.5402
2024-06-04 07:20:18 [INFO]: Epoch 077 - training loss: 0.3836, validation loss: 2.5414
2024-06-04 07:22:37 [INFO]: Epoch 078 - training loss: 0.3819, validation loss: 2.5416
2024-06-04 07:24:55 [INFO]: Epoch 079 - training loss: 0.3813, validation loss: 2.5384
2024-06-04 07:27:13 [INFO]: Epoch 080 - training loss: 0.3809, validation loss: 2.5395
2024-06-04 07:29:55 [INFO]: Epoch 081 - training loss: 0.3805, validation loss: 2.5433
2024-06-04 07:32:38 [INFO]: Epoch 082 - training loss: 0.3798, validation loss: 2.5349
2024-06-04 07:35:20 [INFO]: Epoch 083 - training loss: 0.3795, validation loss: 2.5346
2024-06-04 07:38:03 [INFO]: Epoch 084 - training loss: 0.3790, validation loss: 2.5402
2024-06-04 07:40:46 [INFO]: Epoch 085 - training loss: 0.3787, validation loss: 2.5301
2024-06-04 07:43:29 [INFO]: Epoch 086 - training loss: 0.3780, validation loss: 2.5336
2024-06-04 07:46:07 [INFO]: Epoch 087 - training loss: 0.3773, validation loss: 2.5310
2024-06-04 07:48:49 [INFO]: Epoch 088 - training loss: 0.3763, validation loss: 2.5323
2024-06-04 07:51:33 [INFO]: Epoch 089 - training loss: 0.3763, validation loss: 2.5276
2024-06-04 07:54:15 [INFO]: Epoch 090 - training loss: 0.3760, validation loss: 2.5269
2024-06-04 07:56:58 [INFO]: Epoch 091 - training loss: 0.3760, validation loss: 2.5255
2024-06-04 07:59:40 [INFO]: Epoch 092 - training loss: 0.3755, validation loss: 2.5276
2024-06-04 08:02:23 [INFO]: Epoch 093 - training loss: 0.3745, validation loss: 2.5231
2024-06-04 08:05:06 [INFO]: Epoch 094 - training loss: 0.3733, validation loss: 2.5240
2024-06-04 08:07:49 [INFO]: Epoch 095 - training loss: 0.3722, validation loss: 2.5236
2024-06-04 08:10:32 [INFO]: Epoch 096 - training loss: 0.3718, validation loss: 2.5203
2024-06-04 08:13:15 [INFO]: Epoch 097 - training loss: 0.3719, validation loss: 2.5237
2024-06-04 08:15:57 [INFO]: Epoch 098 - training loss: 0.3729, validation loss: 2.5193
2024-06-04 08:18:40 [INFO]: Epoch 099 - training loss: 0.3719, validation loss: 2.5220
2024-06-04 08:21:23 [INFO]: Epoch 100 - training loss: 0.3708, validation loss: 2.5214
2024-06-04 08:21:23 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 08:21:23 [INFO]: Saved the model to results_point_rate05/Electricity/BRITS_Electricity/round_0/20240604_T025904/BRITS.pypots
2024-06-04 08:24:48 [INFO]: Successfully saved to results_point_rate05/Electricity/BRITS_Electricity/round_0/imputation.pkl
2024-06-04 08:24:48 [INFO]: Round0 - BRITS on Electricity: MAE=1.1268, MSE=2.8571, MRE=0.6033
2024-06-04 08:24:48 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 08:24:48 [INFO]: Using the given device: cuda:0
2024-06-04 08:24:48 [INFO]: Model files will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_1/20240604_T082448
2024-06-04 08:24:48 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_1/20240604_T082448/tensorboard
2024-06-04 08:24:48 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 08:27:35 [INFO]: Epoch 001 - training loss: 1.0514, validation loss: 3.1808
2024-06-04 08:30:17 [INFO]: Epoch 002 - training loss: 0.7245, validation loss: 3.0081
2024-06-04 08:32:59 [INFO]: Epoch 003 - training loss: 0.6434, validation loss: 2.8851
2024-06-04 08:35:32 [INFO]: Epoch 004 - training loss: 0.6016, validation loss: 2.8215
2024-06-04 08:38:15 [INFO]: Epoch 005 - training loss: 0.5742, validation loss: 2.7917
2024-06-04 08:40:57 [INFO]: Epoch 006 - training loss: 0.5536, validation loss: 2.7696
2024-06-04 08:43:40 [INFO]: Epoch 007 - training loss: 0.5388, validation loss: 2.7495
2024-06-04 08:46:23 [INFO]: Epoch 008 - training loss: 0.5280, validation loss: 2.7370
2024-06-04 08:49:06 [INFO]: Epoch 009 - training loss: 0.5183, validation loss: 2.7323
2024-06-04 08:51:16 [INFO]: Epoch 010 - training loss: 0.5092, validation loss: 2.7227
2024-06-04 08:53:35 [INFO]: Epoch 011 - training loss: 0.5021, validation loss: 2.7112
2024-06-04 08:55:56 [INFO]: Epoch 012 - training loss: 0.4953, validation loss: 2.7065
2024-06-04 08:58:15 [INFO]: Epoch 013 - training loss: 0.4899, validation loss: 2.6989
2024-06-04 09:00:33 [INFO]: Epoch 014 - training loss: 0.4852, validation loss: 2.6964
2024-06-04 09:02:49 [INFO]: Epoch 015 - training loss: 0.4799, validation loss: 2.6861
2024-06-04 09:05:01 [INFO]: Epoch 016 - training loss: 0.4752, validation loss: 2.6863
2024-06-04 09:07:12 [INFO]: Epoch 017 - training loss: 0.4717, validation loss: 2.6790
2024-06-04 09:09:22 [INFO]: Epoch 018 - training loss: 0.4689, validation loss: 2.6712
2024-06-04 09:11:31 [INFO]: Epoch 019 - training loss: 0.4644, validation loss: 2.6685
2024-06-04 09:13:44 [INFO]: Epoch 020 - training loss: 0.4603, validation loss: 2.6622
2024-06-04 09:16:00 [INFO]: Epoch 021 - training loss: 0.4573, validation loss: 2.6564
2024-06-04 09:18:19 [INFO]: Epoch 022 - training loss: 0.4547, validation loss: 2.6491
2024-06-04 09:20:38 [INFO]: Epoch 023 - training loss: 0.4519, validation loss: 2.6468
2024-06-04 09:22:56 [INFO]: Epoch 024 - training loss: 0.4491, validation loss: 2.6386
2024-06-04 09:25:16 [INFO]: Epoch 025 - training loss: 0.4474, validation loss: 2.6407
2024-06-04 09:27:34 [INFO]: Epoch 026 - training loss: 0.4441, validation loss: 2.6363
2024-06-04 09:29:53 [INFO]: Epoch 027 - training loss: 0.4416, validation loss: 2.6304
2024-06-04 09:32:13 [INFO]: Epoch 028 - training loss: 0.4407, validation loss: 2.6292
2024-06-04 09:34:25 [INFO]: Epoch 029 - training loss: 0.4376, validation loss: 2.6288
2024-06-04 09:36:35 [INFO]: Epoch 030 - training loss: 0.4358, validation loss: 2.6229
2024-06-04 09:38:45 [INFO]: Epoch 031 - training loss: 0.4333, validation loss: 2.6177
2024-06-04 09:40:55 [INFO]: Epoch 032 - training loss: 0.4317, validation loss: 2.6142
2024-06-04 09:43:05 [INFO]: Epoch 033 - training loss: 0.4293, validation loss: 2.6122
2024-06-04 09:45:21 [INFO]: Epoch 034 - training loss: 0.4278, validation loss: 2.6148
2024-06-04 09:47:37 [INFO]: Epoch 035 - training loss: 0.4266, validation loss: 2.6038
2024-06-04 09:49:55 [INFO]: Epoch 036 - training loss: 0.4258, validation loss: 2.6053
2024-06-04 09:52:14 [INFO]: Epoch 037 - training loss: 0.4229, validation loss: 2.6035
2024-06-04 09:54:34 [INFO]: Epoch 038 - training loss: 0.4222, validation loss: 2.6020
2024-06-04 09:56:55 [INFO]: Epoch 039 - training loss: 0.4196, validation loss: 2.6019
2024-06-04 09:59:14 [INFO]: Epoch 040 - training loss: 0.4182, validation loss: 2.5992
2024-06-04 10:01:32 [INFO]: Epoch 041 - training loss: 0.4167, validation loss: 2.5975
2024-06-04 10:03:47 [INFO]: Epoch 042 - training loss: 0.4150, validation loss: 2.5942
2024-06-04 10:05:58 [INFO]: Epoch 043 - training loss: 0.4143, validation loss: 2.5945
2024-06-04 10:08:08 [INFO]: Epoch 044 - training loss: 0.4127, validation loss: 2.5894
2024-06-04 10:10:19 [INFO]: Epoch 045 - training loss: 0.4118, validation loss: 2.5897
2024-06-04 10:12:29 [INFO]: Epoch 046 - training loss: 0.4101, validation loss: 2.5876
2024-06-04 10:14:41 [INFO]: Epoch 047 - training loss: 0.4095, validation loss: 2.5835
2024-06-04 10:16:56 [INFO]: Epoch 048 - training loss: 0.4093, validation loss: 2.5820
2024-06-04 10:19:14 [INFO]: Epoch 049 - training loss: 0.4068, validation loss: 2.5816
2024-06-04 10:21:33 [INFO]: Epoch 050 - training loss: 0.4058, validation loss: 2.5770
2024-06-04 10:23:54 [INFO]: Epoch 051 - training loss: 0.4050, validation loss: 2.5774
2024-06-04 10:26:13 [INFO]: Epoch 052 - training loss: 0.4039, validation loss: 2.5759
2024-06-04 10:28:31 [INFO]: Epoch 053 - training loss: 0.4046, validation loss: 2.5734
2024-06-04 10:30:49 [INFO]: Epoch 054 - training loss: 0.4032, validation loss: 2.5731
2024-06-04 10:33:09 [INFO]: Epoch 055 - training loss: 0.4005, validation loss: 2.5682
2024-06-04 10:35:21 [INFO]: Epoch 056 - training loss: 0.3993, validation loss: 2.5675
2024-06-04 10:37:32 [INFO]: Epoch 057 - training loss: 0.3981, validation loss: 2.5696
2024-06-04 10:39:42 [INFO]: Epoch 058 - training loss: 0.3974, validation loss: 2.5624
2024-06-04 10:41:52 [INFO]: Epoch 059 - training loss: 0.3965, validation loss: 2.5685
2024-06-04 10:44:02 [INFO]: Epoch 060 - training loss: 0.3964, validation loss: 2.5644
2024-06-04 10:46:14 [INFO]: Epoch 061 - training loss: 0.3952, validation loss: 2.5641
2024-06-04 10:48:29 [INFO]: Epoch 062 - training loss: 0.3945, validation loss: 2.5597
2024-06-04 10:50:46 [INFO]: Epoch 063 - training loss: 0.3931, validation loss: 2.5604
2024-06-04 10:53:05 [INFO]: Epoch 064 - training loss: 0.3932, validation loss: 2.5576
2024-06-04 10:55:25 [INFO]: Epoch 065 - training loss: 0.3919, validation loss: 2.5559
2024-06-04 10:57:47 [INFO]: Epoch 066 - training loss: 0.3908, validation loss: 2.5573
2024-06-04 11:00:07 [INFO]: Epoch 067 - training loss: 0.3911, validation loss: 2.5515
2024-06-04 11:02:27 [INFO]: Epoch 068 - training loss: 0.3903, validation loss: 2.5566
2024-06-04 11:04:43 [INFO]: Epoch 069 - training loss: 0.3885, validation loss: 2.5561
2024-06-04 11:06:54 [INFO]: Epoch 070 - training loss: 0.3877, validation loss: 2.5516
2024-06-04 11:09:05 [INFO]: Epoch 071 - training loss: 0.3876, validation loss: 2.5488
2024-06-04 11:11:15 [INFO]: Epoch 072 - training loss: 0.3865, validation loss: 2.5535
2024-06-04 11:13:25 [INFO]: Epoch 073 - training loss: 0.3868, validation loss: 2.5472
2024-06-04 11:15:36 [INFO]: Epoch 074 - training loss: 0.3861, validation loss: 2.5499
2024-06-04 11:17:52 [INFO]: Epoch 075 - training loss: 0.3841, validation loss: 2.5477
2024-06-04 11:20:09 [INFO]: Epoch 076 - training loss: 0.3834, validation loss: 2.5477
2024-06-04 11:22:28 [INFO]: Epoch 077 - training loss: 0.3834, validation loss: 2.5503
2024-06-04 11:24:47 [INFO]: Epoch 078 - training loss: 0.3841, validation loss: 2.5421
2024-06-04 11:27:06 [INFO]: Epoch 079 - training loss: 0.3824, validation loss: 2.5437
2024-06-04 11:29:25 [INFO]: Epoch 080 - training loss: 0.3827, validation loss: 2.5399
2024-06-04 11:31:43 [INFO]: Epoch 081 - training loss: 0.3820, validation loss: 2.5446
2024-06-04 11:34:04 [INFO]: Epoch 082 - training loss: 0.3812, validation loss: 2.5437
2024-06-04 11:36:16 [INFO]: Epoch 083 - training loss: 0.3802, validation loss: 2.5451
2024-06-04 11:38:28 [INFO]: Epoch 084 - training loss: 0.3794, validation loss: 2.5425
2024-06-04 11:40:39 [INFO]: Epoch 085 - training loss: 0.3784, validation loss: 2.5394
2024-06-04 11:42:48 [INFO]: Epoch 086 - training loss: 0.3777, validation loss: 2.5368
2024-06-04 11:44:59 [INFO]: Epoch 087 - training loss: 0.3783, validation loss: 2.5320
2024-06-04 11:47:13 [INFO]: Epoch 088 - training loss: 0.3777, validation loss: 2.5332
2024-06-04 11:49:30 [INFO]: Epoch 089 - training loss: 0.3782, validation loss: 2.5345
2024-06-04 11:51:46 [INFO]: Epoch 090 - training loss: 0.3760, validation loss: 2.5338
2024-06-04 11:54:05 [INFO]: Epoch 091 - training loss: 0.3750, validation loss: 2.5342
2024-06-04 11:56:25 [INFO]: Epoch 092 - training loss: 0.3748, validation loss: 2.5354
2024-06-04 11:58:44 [INFO]: Epoch 093 - training loss: 0.3745, validation loss: 2.5295
2024-06-04 12:01:03 [INFO]: Epoch 094 - training loss: 0.3737, validation loss: 2.5341
2024-06-04 12:03:22 [INFO]: Epoch 095 - training loss: 0.3745, validation loss: 2.5254
2024-06-04 12:05:39 [INFO]: Epoch 096 - training loss: 0.3748, validation loss: 2.5296
2024-06-04 12:07:51 [INFO]: Epoch 097 - training loss: 0.3736, validation loss: 2.5258
2024-06-04 12:10:01 [INFO]: Epoch 098 - training loss: 0.3723, validation loss: 2.5292
2024-06-04 12:12:11 [INFO]: Epoch 099 - training loss: 0.3718, validation loss: 2.5253
2024-06-04 12:14:22 [INFO]: Epoch 100 - training loss: 0.3720, validation loss: 2.5231
2024-06-04 12:14:22 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 12:14:22 [INFO]: Saved the model to results_point_rate05/Electricity/BRITS_Electricity/round_1/20240604_T082448/BRITS.pypots
2024-06-04 12:17:17 [INFO]: Successfully saved to results_point_rate05/Electricity/BRITS_Electricity/round_1/imputation.pkl
2024-06-04 12:17:17 [INFO]: Round1 - BRITS on Electricity: MAE=1.1259, MSE=2.8407, MRE=0.6028
2024-06-04 12:17:17 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 12:17:17 [INFO]: Using the given device: cuda:0
2024-06-04 12:17:17 [INFO]: Model files will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_2/20240604_T121717
2024-06-04 12:17:17 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_2/20240604_T121717/tensorboard
2024-06-04 12:17:17 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 12:19:40 [INFO]: Epoch 001 - training loss: 1.0408, validation loss: 3.1703
2024-06-04 12:22:22 [INFO]: Epoch 002 - training loss: 0.7220, validation loss: 2.9983
2024-06-04 12:25:05 [INFO]: Epoch 003 - training loss: 0.6436, validation loss: 2.8766
2024-06-04 12:27:48 [INFO]: Epoch 004 - training loss: 0.6010, validation loss: 2.8243
2024-06-04 12:30:31 [INFO]: Epoch 005 - training loss: 0.5728, validation loss: 2.7912
2024-06-04 12:33:14 [INFO]: Epoch 006 - training loss: 0.5526, validation loss: 2.7737
2024-06-04 12:35:57 [INFO]: Epoch 007 - training loss: 0.5379, validation loss: 2.7580
2024-06-04 12:38:35 [INFO]: Epoch 008 - training loss: 0.5262, validation loss: 2.7497
2024-06-04 12:41:17 [INFO]: Epoch 009 - training loss: 0.5179, validation loss: 2.7384
2024-06-04 12:44:01 [INFO]: Epoch 010 - training loss: 0.5083, validation loss: 2.7287
2024-06-04 12:46:43 [INFO]: Epoch 011 - training loss: 0.5005, validation loss: 2.7186
2024-06-04 12:49:26 [INFO]: Epoch 012 - training loss: 0.4938, validation loss: 2.7132
2024-06-04 12:52:09 [INFO]: Epoch 013 - training loss: 0.4884, validation loss: 2.7022
2024-06-04 12:54:52 [INFO]: Epoch 014 - training loss: 0.4858, validation loss: 2.6942
2024-06-04 12:57:35 [INFO]: Epoch 015 - training loss: 0.4796, validation loss: 2.6879
2024-06-04 13:00:18 [INFO]: Epoch 016 - training loss: 0.4749, validation loss: 2.6811
2024-06-04 13:03:00 [INFO]: Epoch 017 - training loss: 0.4722, validation loss: 2.6720
2024-06-04 13:05:44 [INFO]: Epoch 018 - training loss: 0.4677, validation loss: 2.6727
2024-06-04 13:08:26 [INFO]: Epoch 019 - training loss: 0.4635, validation loss: 2.6595
2024-06-04 13:11:09 [INFO]: Epoch 020 - training loss: 0.4611, validation loss: 2.6591
2024-06-04 13:13:52 [INFO]: Epoch 021 - training loss: 0.4576, validation loss: 2.6544
2024-06-04 13:16:35 [INFO]: Epoch 022 - training loss: 0.4536, validation loss: 2.6485
2024-06-04 13:19:17 [INFO]: Epoch 023 - training loss: 0.4511, validation loss: 2.6431
2024-06-04 13:22:00 [INFO]: Epoch 024 - training loss: 0.4478, validation loss: 2.6320
2024-06-04 13:24:44 [INFO]: Epoch 025 - training loss: 0.4458, validation loss: 2.6310
2024-06-04 13:27:16 [INFO]: Epoch 026 - training loss: 0.4431, validation loss: 2.6268
2024-06-04 13:29:59 [INFO]: Epoch 027 - training loss: 0.4418, validation loss: 2.6216
2024-06-04 13:32:42 [INFO]: Epoch 028 - training loss: 0.4393, validation loss: 2.6201
2024-06-04 13:35:25 [INFO]: Epoch 029 - training loss: 0.4365, validation loss: 2.6200
2024-06-04 13:38:08 [INFO]: Epoch 030 - training loss: 0.4342, validation loss: 2.6105
2024-06-04 13:40:50 [INFO]: Epoch 031 - training loss: 0.4323, validation loss: 2.6067
2024-06-04 13:42:59 [INFO]: Epoch 032 - training loss: 0.4302, validation loss: 2.6055
2024-06-04 13:45:09 [INFO]: Epoch 033 - training loss: 0.4294, validation loss: 2.5974
2024-06-04 13:47:25 [INFO]: Epoch 034 - training loss: 0.4288, validation loss: 2.6009
2024-06-04 13:49:40 [INFO]: Epoch 035 - training loss: 0.4260, validation loss: 2.5929
2024-06-04 13:51:57 [INFO]: Epoch 036 - training loss: 0.4240, validation loss: 2.5947
2024-06-04 13:54:17 [INFO]: Epoch 037 - training loss: 0.4213, validation loss: 2.5989
2024-06-04 13:56:37 [INFO]: Epoch 038 - training loss: 0.4198, validation loss: 2.5888
2024-06-04 13:58:56 [INFO]: Epoch 039 - training loss: 0.4191, validation loss: 2.5881
2024-06-04 14:01:15 [INFO]: Epoch 040 - training loss: 0.4185, validation loss: 2.5887
2024-06-04 14:03:34 [INFO]: Epoch 041 - training loss: 0.4160, validation loss: 2.5910
2024-06-04 14:05:50 [INFO]: Epoch 042 - training loss: 0.4143, validation loss: 2.5891
2024-06-04 14:08:02 [INFO]: Epoch 043 - training loss: 0.4126, validation loss: 2.5823
2024-06-04 14:10:13 [INFO]: Epoch 044 - training loss: 0.4116, validation loss: 2.5811
2024-06-04 14:12:23 [INFO]: Epoch 045 - training loss: 0.4103, validation loss: 2.5780
2024-06-04 14:14:33 [INFO]: Epoch 046 - training loss: 0.4094, validation loss: 2.5766
2024-06-04 14:16:47 [INFO]: Epoch 047 - training loss: 0.4088, validation loss: 2.5740
2024-06-04 14:19:03 [INFO]: Epoch 048 - training loss: 0.4080, validation loss: 2.5778
2024-06-04 14:21:20 [INFO]: Epoch 049 - training loss: 0.4065, validation loss: 2.5695
2024-06-04 14:23:38 [INFO]: Epoch 050 - training loss: 0.4070, validation loss: 2.5779
2024-06-04 14:25:57 [INFO]: Epoch 051 - training loss: 0.4047, validation loss: 2.5699
2024-06-04 14:28:17 [INFO]: Epoch 052 - training loss: 0.4041, validation loss: 2.5665
2024-06-04 14:30:35 [INFO]: Epoch 053 - training loss: 0.4032, validation loss: 2.5658
2024-06-04 14:32:55 [INFO]: Epoch 054 - training loss: 0.4018, validation loss: 2.5669
2024-06-04 14:35:13 [INFO]: Epoch 055 - training loss: 0.4007, validation loss: 2.5615
2024-06-04 14:37:26 [INFO]: Epoch 056 - training loss: 0.3992, validation loss: 2.5619
2024-06-04 14:39:37 [INFO]: Epoch 057 - training loss: 0.3973, validation loss: 2.5609
2024-06-04 14:41:48 [INFO]: Epoch 058 - training loss: 0.3966, validation loss: 2.5614
2024-06-04 14:43:57 [INFO]: Epoch 059 - training loss: 0.3963, validation loss: 2.5550
2024-06-04 14:46:08 [INFO]: Epoch 060 - training loss: 0.3958, validation loss: 2.5571
2024-06-04 14:48:22 [INFO]: Epoch 061 - training loss: 0.3948, validation loss: 2.5562
2024-06-04 14:50:39 [INFO]: Epoch 062 - training loss: 0.3936, validation loss: 2.5535
2024-06-04 14:52:57 [INFO]: Epoch 063 - training loss: 0.3939, validation loss: 2.5553
2024-06-04 14:55:17 [INFO]: Epoch 064 - training loss: 0.3926, validation loss: 2.5509
2024-06-04 14:57:37 [INFO]: Epoch 065 - training loss: 0.3915, validation loss: 2.5482
2024-06-04 14:59:57 [INFO]: Epoch 066 - training loss: 0.3908, validation loss: 2.5507
2024-06-04 15:02:16 [INFO]: Epoch 067 - training loss: 0.3905, validation loss: 2.5432
2024-06-04 15:04:35 [INFO]: Epoch 068 - training loss: 0.3891, validation loss: 2.5469
2024-06-04 15:06:50 [INFO]: Epoch 069 - training loss: 0.3875, validation loss: 2.5455
2024-06-04 15:09:01 [INFO]: Epoch 070 - training loss: 0.3883, validation loss: 2.5436
2024-06-04 15:11:12 [INFO]: Epoch 071 - training loss: 0.3879, validation loss: 2.5446
2024-06-04 15:13:22 [INFO]: Epoch 072 - training loss: 0.3870, validation loss: 2.5414
2024-06-04 15:15:32 [INFO]: Epoch 073 - training loss: 0.3860, validation loss: 2.5426
2024-06-04 15:17:46 [INFO]: Epoch 074 - training loss: 0.3864, validation loss: 2.5400
2024-06-04 15:20:03 [INFO]: Epoch 075 - training loss: 0.3849, validation loss: 2.5360
2024-06-04 15:22:22 [INFO]: Epoch 076 - training loss: 0.3831, validation loss: 2.5411
2024-06-04 15:24:39 [INFO]: Epoch 077 - training loss: 0.3820, validation loss: 2.5391
2024-06-04 15:26:58 [INFO]: Epoch 078 - training loss: 0.3820, validation loss: 2.5410
2024-06-04 15:29:16 [INFO]: Epoch 079 - training loss: 0.3818, validation loss: 2.5362
2024-06-04 15:31:35 [INFO]: Epoch 080 - training loss: 0.3807, validation loss: 2.5369
2024-06-04 15:33:56 [INFO]: Epoch 081 - training loss: 0.3799, validation loss: 2.5345
2024-06-04 15:36:12 [INFO]: Epoch 082 - training loss: 0.3797, validation loss: 2.5333
2024-06-04 15:38:24 [INFO]: Epoch 083 - training loss: 0.3801, validation loss: 2.5317
2024-06-04 15:40:34 [INFO]: Epoch 084 - training loss: 0.3792, validation loss: 2.5326
2024-06-04 15:42:45 [INFO]: Epoch 085 - training loss: 0.3780, validation loss: 2.5305
2024-06-04 15:44:55 [INFO]: Epoch 086 - training loss: 0.3774, validation loss: 2.5267
2024-06-04 15:47:07 [INFO]: Epoch 087 - training loss: 0.3781, validation loss: 2.5270
2024-06-04 15:49:22 [INFO]: Epoch 088 - training loss: 0.3777, validation loss: 2.5286
2024-06-04 15:51:39 [INFO]: Epoch 089 - training loss: 0.3782, validation loss: 2.5271
2024-06-04 15:53:58 [INFO]: Epoch 090 - training loss: 0.3774, validation loss: 2.5298
2024-06-04 15:56:16 [INFO]: Epoch 091 - training loss: 0.3763, validation loss: 2.5265
2024-06-04 15:58:35 [INFO]: Epoch 092 - training loss: 0.3756, validation loss: 2.5262
2024-06-04 16:00:54 [INFO]: Epoch 093 - training loss: 0.3752, validation loss: 2.5234
2024-06-04 16:03:14 [INFO]: Epoch 094 - training loss: 0.3734, validation loss: 2.5278
2024-06-04 16:05:33 [INFO]: Epoch 095 - training loss: 0.3728, validation loss: 2.5239
2024-06-04 16:07:47 [INFO]: Epoch 096 - training loss: 0.3718, validation loss: 2.5243
2024-06-04 16:09:58 [INFO]: Epoch 097 - training loss: 0.3714, validation loss: 2.5240
2024-06-04 16:12:09 [INFO]: Epoch 098 - training loss: 0.3706, validation loss: 2.5238
2024-06-04 16:14:19 [INFO]: Epoch 099 - training loss: 0.3705, validation loss: 2.5226
2024-06-04 16:16:29 [INFO]: Epoch 100 - training loss: 0.3704, validation loss: 2.5182
2024-06-04 16:16:29 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 16:16:29 [INFO]: Saved the model to results_point_rate05/Electricity/BRITS_Electricity/round_2/20240604_T121717/BRITS.pypots
2024-06-04 16:19:23 [INFO]: Successfully saved to results_point_rate05/Electricity/BRITS_Electricity/round_2/imputation.pkl
2024-06-04 16:19:23 [INFO]: Round2 - BRITS on Electricity: MAE=1.1357, MSE=2.8330, MRE=0.6081
2024-06-04 16:19:23 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 16:19:23 [INFO]: Using the given device: cuda:0
2024-06-04 16:19:23 [INFO]: Model files will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_3/20240604_T161923
2024-06-04 16:19:23 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_3/20240604_T161923/tensorboard
2024-06-04 16:19:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 16:21:46 [INFO]: Epoch 001 - training loss: 1.0404, validation loss: 3.1485
2024-06-04 16:24:05 [INFO]: Epoch 002 - training loss: 0.7194, validation loss: 2.9803
2024-06-04 16:26:26 [INFO]: Epoch 003 - training loss: 0.6413, validation loss: 2.8684
2024-06-04 16:28:40 [INFO]: Epoch 004 - training loss: 0.5991, validation loss: 2.8148
2024-06-04 16:30:52 [INFO]: Epoch 005 - training loss: 0.5727, validation loss: 2.7802
2024-06-04 16:33:02 [INFO]: Epoch 006 - training loss: 0.5524, validation loss: 2.7614
2024-06-04 16:35:13 [INFO]: Epoch 007 - training loss: 0.5380, validation loss: 2.7460
2024-06-04 16:37:23 [INFO]: Epoch 008 - training loss: 0.5260, validation loss: 2.7316
2024-06-04 16:39:34 [INFO]: Epoch 009 - training loss: 0.5169, validation loss: 2.7280
2024-06-04 16:41:51 [INFO]: Epoch 010 - training loss: 0.5085, validation loss: 2.7143
2024-06-04 16:44:07 [INFO]: Epoch 011 - training loss: 0.5007, validation loss: 2.7065
2024-06-04 16:46:24 [INFO]: Epoch 012 - training loss: 0.4940, validation loss: 2.6993
2024-06-04 16:48:42 [INFO]: Epoch 013 - training loss: 0.4888, validation loss: 2.6934
2024-06-04 16:51:00 [INFO]: Epoch 014 - training loss: 0.4844, validation loss: 2.6844
2024-06-04 16:53:20 [INFO]: Epoch 015 - training loss: 0.4787, validation loss: 2.6812
2024-06-04 16:55:38 [INFO]: Epoch 016 - training loss: 0.4746, validation loss: 2.6741
2024-06-04 16:57:57 [INFO]: Epoch 017 - training loss: 0.4718, validation loss: 2.6683
2024-06-04 17:00:13 [INFO]: Epoch 018 - training loss: 0.4711, validation loss: 2.6655
2024-06-04 17:02:24 [INFO]: Epoch 019 - training loss: 0.4644, validation loss: 2.6564
2024-06-04 17:04:35 [INFO]: Epoch 020 - training loss: 0.4601, validation loss: 2.6546
2024-06-04 17:06:46 [INFO]: Epoch 021 - training loss: 0.4566, validation loss: 2.6443
2024-06-04 17:08:55 [INFO]: Epoch 022 - training loss: 0.4537, validation loss: 2.6390
2024-06-04 17:11:07 [INFO]: Epoch 023 - training loss: 0.4511, validation loss: 2.6364
2024-06-04 17:13:49 [INFO]: Epoch 024 - training loss: 0.4480, validation loss: 2.6356
2024-06-04 17:16:31 [INFO]: Epoch 025 - training loss: 0.4455, validation loss: 2.6287
2024-06-04 17:19:14 [INFO]: Epoch 026 - training loss: 0.4438, validation loss: 2.6238
2024-06-04 17:21:57 [INFO]: Epoch 027 - training loss: 0.4415, validation loss: 2.6224
2024-06-04 17:24:40 [INFO]: Epoch 028 - training loss: 0.4396, validation loss: 2.6210
2024-06-04 17:27:22 [INFO]: Epoch 029 - training loss: 0.4374, validation loss: 2.6113
2024-06-04 17:29:54 [INFO]: Epoch 030 - training loss: 0.4345, validation loss: 2.6097
2024-06-04 17:32:37 [INFO]: Epoch 031 - training loss: 0.4329, validation loss: 2.6057
2024-06-04 17:35:20 [INFO]: Epoch 032 - training loss: 0.4313, validation loss: 2.6041
2024-06-04 17:38:03 [INFO]: Epoch 033 - training loss: 0.4290, validation loss: 2.6041
2024-06-04 17:40:45 [INFO]: Epoch 034 - training loss: 0.4272, validation loss: 2.6006
2024-06-04 17:43:28 [INFO]: Epoch 035 - training loss: 0.4251, validation loss: 2.5975
2024-06-04 17:46:11 [INFO]: Epoch 036 - training loss: 0.4240, validation loss: 2.5923
2024-06-04 17:48:54 [INFO]: Epoch 037 - training loss: 0.4230, validation loss: 2.5959
2024-06-04 17:51:37 [INFO]: Epoch 038 - training loss: 0.4219, validation loss: 2.5939
2024-06-04 17:54:20 [INFO]: Epoch 039 - training loss: 0.4201, validation loss: 2.5876
2024-06-04 17:57:02 [INFO]: Epoch 040 - training loss: 0.4172, validation loss: 2.5845
2024-06-04 17:59:45 [INFO]: Epoch 041 - training loss: 0.4163, validation loss: 2.5833
2024-06-04 18:02:28 [INFO]: Epoch 042 - training loss: 0.4144, validation loss: 2.5826
2024-06-04 18:05:11 [INFO]: Epoch 043 - training loss: 0.4137, validation loss: 2.5792
2024-06-04 18:07:54 [INFO]: Epoch 044 - training loss: 0.4131, validation loss: 2.5793
2024-06-04 18:10:37 [INFO]: Epoch 045 - training loss: 0.4121, validation loss: 2.5765
2024-06-04 18:13:20 [INFO]: Epoch 046 - training loss: 0.4101, validation loss: 2.5774
2024-06-04 18:16:03 [INFO]: Epoch 047 - training loss: 0.4090, validation loss: 2.5700
2024-06-04 18:18:27 [INFO]: Epoch 048 - training loss: 0.4078, validation loss: 2.5692
2024-06-04 18:21:10 [INFO]: Epoch 049 - training loss: 0.4067, validation loss: 2.5639
2024-06-04 18:23:53 [INFO]: Epoch 050 - training loss: 0.4062, validation loss: 2.5671
2024-06-04 18:26:36 [INFO]: Epoch 051 - training loss: 0.4049, validation loss: 2.5679
2024-06-04 18:29:18 [INFO]: Epoch 052 - training loss: 0.4039, validation loss: 2.5628
2024-06-04 18:32:01 [INFO]: Epoch 053 - training loss: 0.4030, validation loss: 2.5595
2024-06-04 18:34:44 [INFO]: Epoch 054 - training loss: 0.4019, validation loss: 2.5601
2024-06-04 18:36:54 [INFO]: Epoch 055 - training loss: 0.4012, validation loss: 2.5572
2024-06-04 18:39:13 [INFO]: Epoch 056 - training loss: 0.3994, validation loss: 2.5566
2024-06-04 18:41:32 [INFO]: Epoch 057 - training loss: 0.3985, validation loss: 2.5533
2024-06-04 18:43:43 [INFO]: Epoch 058 - training loss: 0.3980, validation loss: 2.5530
2024-06-04 18:45:54 [INFO]: Epoch 059 - training loss: 0.3972, validation loss: 2.5513
2024-06-04 18:48:04 [INFO]: Epoch 060 - training loss: 0.3966, validation loss: 2.5468
2024-06-04 18:50:15 [INFO]: Epoch 061 - training loss: 0.3946, validation loss: 2.5458
2024-06-04 18:52:25 [INFO]: Epoch 062 - training loss: 0.3935, validation loss: 2.5483
2024-06-04 18:54:39 [INFO]: Epoch 063 - training loss: 0.3932, validation loss: 2.5401
2024-06-04 18:56:54 [INFO]: Epoch 064 - training loss: 0.3923, validation loss: 2.5431
2024-06-04 18:59:14 [INFO]: Epoch 065 - training loss: 0.3915, validation loss: 2.5380
2024-06-04 19:01:34 [INFO]: Epoch 066 - training loss: 0.3919, validation loss: 2.5426
2024-06-04 19:03:53 [INFO]: Epoch 067 - training loss: 0.3914, validation loss: 2.5340
2024-06-04 19:06:13 [INFO]: Epoch 068 - training loss: 0.3901, validation loss: 2.5386
2024-06-04 19:08:31 [INFO]: Epoch 069 - training loss: 0.3895, validation loss: 2.5327
2024-06-04 19:10:51 [INFO]: Epoch 070 - training loss: 0.3882, validation loss: 2.5359
2024-06-04 19:13:07 [INFO]: Epoch 071 - training loss: 0.3870, validation loss: 2.5327
2024-06-04 19:15:18 [INFO]: Epoch 072 - training loss: 0.3865, validation loss: 2.5311
2024-06-04 19:17:28 [INFO]: Epoch 073 - training loss: 0.3863, validation loss: 2.5279
2024-06-04 19:19:39 [INFO]: Epoch 074 - training loss: 0.3846, validation loss: 2.5264
2024-06-04 19:21:49 [INFO]: Epoch 075 - training loss: 0.3844, validation loss: 2.5267
2024-06-04 19:23:59 [INFO]: Epoch 076 - training loss: 0.3846, validation loss: 2.5277
2024-06-04 19:26:15 [INFO]: Epoch 077 - training loss: 0.3836, validation loss: 2.5248
2024-06-04 19:28:32 [INFO]: Epoch 078 - training loss: 0.3828, validation loss: 2.5228
2024-06-04 19:30:49 [INFO]: Epoch 079 - training loss: 0.3823, validation loss: 2.5216
2024-06-04 19:33:08 [INFO]: Epoch 080 - training loss: 0.3819, validation loss: 2.5186
2024-06-04 19:35:28 [INFO]: Epoch 081 - training loss: 0.3814, validation loss: 2.5203
2024-06-04 19:37:45 [INFO]: Epoch 082 - training loss: 0.3813, validation loss: 2.5169
2024-06-04 19:40:04 [INFO]: Epoch 083 - training loss: 0.3802, validation loss: 2.5181
2024-06-04 19:42:23 [INFO]: Epoch 084 - training loss: 0.3789, validation loss: 2.5176
2024-06-04 19:44:39 [INFO]: Epoch 085 - training loss: 0.3784, validation loss: 2.5138
2024-06-04 19:46:50 [INFO]: Epoch 086 - training loss: 0.3783, validation loss: 2.5130
2024-06-04 19:49:00 [INFO]: Epoch 087 - training loss: 0.3785, validation loss: 2.5125
2024-06-04 19:51:11 [INFO]: Epoch 088 - training loss: 0.3771, validation loss: 2.5115
2024-06-04 19:53:21 [INFO]: Epoch 089 - training loss: 0.3764, validation loss: 2.5090
2024-06-04 19:55:31 [INFO]: Epoch 090 - training loss: 0.3759, validation loss: 2.5078
2024-06-04 19:57:46 [INFO]: Epoch 091 - training loss: 0.3761, validation loss: 2.5089
2024-06-04 20:00:01 [INFO]: Epoch 092 - training loss: 0.3762, validation loss: 2.5082
2024-06-04 20:02:20 [INFO]: Epoch 093 - training loss: 0.3752, validation loss: 2.5053
2024-06-04 20:04:38 [INFO]: Epoch 094 - training loss: 0.3741, validation loss: 2.5079
2024-06-04 20:06:57 [INFO]: Epoch 095 - training loss: 0.3735, validation loss: 2.5023
2024-06-04 20:09:16 [INFO]: Epoch 096 - training loss: 0.3731, validation loss: 2.5053
2024-06-04 20:11:34 [INFO]: Epoch 097 - training loss: 0.3726, validation loss: 2.4996
2024-06-04 20:13:54 [INFO]: Epoch 098 - training loss: 0.3715, validation loss: 2.4978
2024-06-04 20:16:11 [INFO]: Epoch 099 - training loss: 0.3706, validation loss: 2.4998
2024-06-04 20:18:22 [INFO]: Epoch 100 - training loss: 0.3707, validation loss: 2.4993
2024-06-04 20:18:22 [INFO]: Finished training. The best model is from epoch#98.
2024-06-04 20:18:22 [INFO]: Saved the model to results_point_rate05/Electricity/BRITS_Electricity/round_3/20240604_T161923/BRITS.pypots
2024-06-04 20:20:58 [INFO]: Successfully saved to results_point_rate05/Electricity/BRITS_Electricity/round_3/imputation.pkl
2024-06-04 20:20:58 [INFO]: Round3 - BRITS on Electricity: MAE=1.1229, MSE=2.7899, MRE=0.6012
2024-06-04 20:20:58 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 20:20:58 [INFO]: Using the given device: cuda:0
2024-06-04 20:20:58 [INFO]: Model files will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_4/20240604_T202058
2024-06-04 20:20:58 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/BRITS_Electricity/round_4/20240604_T202058/tensorboard
2024-06-04 20:20:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 17,082,800
2024-06-04 20:23:19 [INFO]: Epoch 001 - training loss: 1.0410, validation loss: 3.1550
2024-06-04 20:25:37 [INFO]: Epoch 002 - training loss: 0.7179, validation loss: 2.9855
2024-06-04 20:27:57 [INFO]: Epoch 003 - training loss: 0.6414, validation loss: 2.8683
2024-06-04 20:30:16 [INFO]: Epoch 004 - training loss: 0.5992, validation loss: 2.8193
2024-06-04 20:32:36 [INFO]: Epoch 005 - training loss: 0.5731, validation loss: 2.7939
2024-06-04 20:34:54 [INFO]: Epoch 006 - training loss: 0.5533, validation loss: 2.7688
2024-06-04 20:37:09 [INFO]: Epoch 007 - training loss: 0.5379, validation loss: 2.7586
2024-06-04 20:39:21 [INFO]: Epoch 008 - training loss: 0.5265, validation loss: 2.7451
2024-06-04 20:41:31 [INFO]: Epoch 009 - training loss: 0.5167, validation loss: 2.7347
2024-06-04 20:43:42 [INFO]: Epoch 010 - training loss: 0.5081, validation loss: 2.7254
2024-06-04 20:45:52 [INFO]: Epoch 011 - training loss: 0.5006, validation loss: 2.7199
2024-06-04 20:48:03 [INFO]: Epoch 012 - training loss: 0.4944, validation loss: 2.7054
2024-06-04 20:50:19 [INFO]: Epoch 013 - training loss: 0.4888, validation loss: 2.7009
2024-06-04 20:52:35 [INFO]: Epoch 014 - training loss: 0.4832, validation loss: 2.6901
2024-06-04 20:54:51 [INFO]: Epoch 015 - training loss: 0.4778, validation loss: 2.6825
2024-06-04 20:57:11 [INFO]: Epoch 016 - training loss: 0.4733, validation loss: 2.6785
2024-06-04 20:59:30 [INFO]: Epoch 017 - training loss: 0.4696, validation loss: 2.6725
2024-06-04 21:01:48 [INFO]: Epoch 018 - training loss: 0.4658, validation loss: 2.6683
2024-06-04 21:04:06 [INFO]: Epoch 019 - training loss: 0.4621, validation loss: 2.6631
2024-06-04 21:06:25 [INFO]: Epoch 020 - training loss: 0.4589, validation loss: 2.6548
2024-06-04 21:08:42 [INFO]: Epoch 021 - training loss: 0.4567, validation loss: 2.6518
2024-06-04 21:10:53 [INFO]: Epoch 022 - training loss: 0.4535, validation loss: 2.6479
2024-06-04 21:13:04 [INFO]: Epoch 023 - training loss: 0.4503, validation loss: 2.6338
2024-06-04 21:15:14 [INFO]: Epoch 024 - training loss: 0.4487, validation loss: 2.6360
2024-06-04 21:17:24 [INFO]: Epoch 025 - training loss: 0.4454, validation loss: 2.6271
2024-06-04 21:19:34 [INFO]: Epoch 026 - training loss: 0.4427, validation loss: 2.6298
2024-06-04 21:21:49 [INFO]: Epoch 027 - training loss: 0.4408, validation loss: 2.6240
2024-06-04 21:24:05 [INFO]: Epoch 028 - training loss: 0.4379, validation loss: 2.6214
2024-06-04 21:26:20 [INFO]: Epoch 029 - training loss: 0.4364, validation loss: 2.6181
2024-06-04 21:28:38 [INFO]: Epoch 030 - training loss: 0.4343, validation loss: 2.6100
2024-06-04 21:30:57 [INFO]: Epoch 031 - training loss: 0.4327, validation loss: 2.6102
2024-06-04 21:33:16 [INFO]: Epoch 032 - training loss: 0.4306, validation loss: 2.6010
2024-06-04 21:35:36 [INFO]: Epoch 033 - training loss: 0.4299, validation loss: 2.6056
2024-06-04 21:37:55 [INFO]: Epoch 034 - training loss: 0.4274, validation loss: 2.6043
2024-06-04 21:40:13 [INFO]: Epoch 035 - training loss: 0.4250, validation loss: 2.5948
2024-06-04 21:42:25 [INFO]: Epoch 036 - training loss: 0.4243, validation loss: 2.6005
2024-06-04 21:44:35 [INFO]: Epoch 037 - training loss: 0.4219, validation loss: 2.5939
2024-06-04 21:46:45 [INFO]: Epoch 038 - training loss: 0.4196, validation loss: 2.5896
2024-06-04 21:48:55 [INFO]: Epoch 039 - training loss: 0.4181, validation loss: 2.5917
2024-06-04 21:51:04 [INFO]: Epoch 040 - training loss: 0.4167, validation loss: 2.5929
2024-06-04 21:53:17 [INFO]: Epoch 041 - training loss: 0.4160, validation loss: 2.5813
2024-06-04 21:55:34 [INFO]: Epoch 042 - training loss: 0.4141, validation loss: 2.5828
2024-06-04 21:57:49 [INFO]: Epoch 043 - training loss: 0.4142, validation loss: 2.5771
2024-06-04 22:00:08 [INFO]: Epoch 044 - training loss: 0.4126, validation loss: 2.5812
2024-06-04 22:02:27 [INFO]: Epoch 045 - training loss: 0.4112, validation loss: 2.5750
2024-06-04 22:04:46 [INFO]: Epoch 046 - training loss: 0.4096, validation loss: 2.5722
2024-06-04 22:07:27 [INFO]: Epoch 047 - training loss: 0.4081, validation loss: 2.5746
2024-06-04 22:10:11 [INFO]: Epoch 048 - training loss: 0.4083, validation loss: 2.5679
2024-06-04 22:12:53 [INFO]: Epoch 049 - training loss: 0.4071, validation loss: 2.5721
2024-06-04 22:15:36 [INFO]: Epoch 050 - training loss: 0.4053, validation loss: 2.5712
2024-06-04 22:18:18 [INFO]: Epoch 051 - training loss: 0.4031, validation loss: 2.5655
2024-06-04 22:21:02 [INFO]: Epoch 052 - training loss: 0.4027, validation loss: 2.5693
2024-06-04 22:23:39 [INFO]: Epoch 053 - training loss: 0.4021, validation loss: 2.5605
2024-06-04 22:26:21 [INFO]: Epoch 054 - training loss: 0.4011, validation loss: 2.5627
2024-06-04 22:29:04 [INFO]: Epoch 055 - training loss: 0.3985, validation loss: 2.5631
2024-06-04 22:31:46 [INFO]: Epoch 056 - training loss: 0.3978, validation loss: 2.5580
2024-06-04 22:34:29 [INFO]: Epoch 057 - training loss: 0.3974, validation loss: 2.5543
2024-06-04 22:37:12 [INFO]: Epoch 058 - training loss: 0.3975, validation loss: 2.5549
2024-06-04 22:39:55 [INFO]: Epoch 059 - training loss: 0.3964, validation loss: 2.5570
2024-06-04 22:42:38 [INFO]: Epoch 060 - training loss: 0.3966, validation loss: 2.5528
2024-06-04 22:45:21 [INFO]: Epoch 061 - training loss: 0.3963, validation loss: 2.5536
2024-06-04 22:48:04 [INFO]: Epoch 062 - training loss: 0.3948, validation loss: 2.5508
2024-06-04 22:50:47 [INFO]: Epoch 063 - training loss: 0.3931, validation loss: 2.5474
2024-06-04 22:53:30 [INFO]: Epoch 064 - training loss: 0.3920, validation loss: 2.5503
2024-06-04 22:56:13 [INFO]: Epoch 065 - training loss: 0.3912, validation loss: 2.5456
2024-06-04 22:58:56 [INFO]: Epoch 066 - training loss: 0.3905, validation loss: 2.5438
2024-06-04 23:01:38 [INFO]: Epoch 067 - training loss: 0.3895, validation loss: 2.5421
2024-06-04 23:04:21 [INFO]: Epoch 068 - training loss: 0.3895, validation loss: 2.5450
2024-06-04 23:07:04 [INFO]: Epoch 069 - training loss: 0.3882, validation loss: 2.5422
2024-06-04 23:09:47 [INFO]: Epoch 070 - training loss: 0.3867, validation loss: 2.5404
2024-06-04 23:12:19 [INFO]: Epoch 071 - training loss: 0.3864, validation loss: 2.5384
2024-06-04 23:15:01 [INFO]: Epoch 072 - training loss: 0.3856, validation loss: 2.5377
2024-06-04 23:17:45 [INFO]: Epoch 073 - training loss: 0.3859, validation loss: 2.5394
2024-06-04 23:20:27 [INFO]: Epoch 074 - training loss: 0.3848, validation loss: 2.5395
2024-06-04 23:23:10 [INFO]: Epoch 075 - training loss: 0.3839, validation loss: 2.5322
2024-06-04 23:25:53 [INFO]: Epoch 076 - training loss: 0.3833, validation loss: 2.5375
2024-06-04 23:28:05 [INFO]: Epoch 077 - training loss: 0.3829, validation loss: 2.5329
2024-06-04 23:30:15 [INFO]: Epoch 078 - training loss: 0.3819, validation loss: 2.5319
2024-06-04 23:32:25 [INFO]: Epoch 079 - training loss: 0.3821, validation loss: 2.5320
2024-06-04 23:34:35 [INFO]: Epoch 080 - training loss: 0.3819, validation loss: 2.5322
2024-06-04 23:36:46 [INFO]: Epoch 081 - training loss: 0.3807, validation loss: 2.5281
2024-06-04 23:39:02 [INFO]: Epoch 082 - training loss: 0.3800, validation loss: 2.5251
2024-06-04 23:41:19 [INFO]: Epoch 083 - training loss: 0.3798, validation loss: 2.5277
2024-06-04 23:43:36 [INFO]: Epoch 084 - training loss: 0.3789, validation loss: 2.5262
2024-06-04 23:45:54 [INFO]: Epoch 085 - training loss: 0.3785, validation loss: 2.5280
2024-06-04 23:48:12 [INFO]: Epoch 086 - training loss: 0.3790, validation loss: 2.5259
2024-06-04 23:50:32 [INFO]: Epoch 087 - training loss: 0.3774, validation loss: 2.5260
2024-06-04 23:52:52 [INFO]: Epoch 088 - training loss: 0.3771, validation loss: 2.5211
2024-06-04 23:55:12 [INFO]: Epoch 089 - training loss: 0.3769, validation loss: 2.5231
2024-06-04 23:57:27 [INFO]: Epoch 090 - training loss: 0.3759, validation loss: 2.5207
2024-06-04 23:59:38 [INFO]: Epoch 091 - training loss: 0.3752, validation loss: 2.5192
2024-06-05 00:01:49 [INFO]: Epoch 092 - training loss: 0.3746, validation loss: 2.5226
2024-06-05 00:03:59 [INFO]: Epoch 093 - training loss: 0.3740, validation loss: 2.5216
2024-06-05 00:06:09 [INFO]: Epoch 094 - training loss: 0.3736, validation loss: 2.5166
2024-06-05 00:08:21 [INFO]: Epoch 095 - training loss: 0.3725, validation loss: 2.5180
2024-06-05 00:10:36 [INFO]: Epoch 096 - training loss: 0.3724, validation loss: 2.5164
2024-06-05 00:12:53 [INFO]: Epoch 097 - training loss: 0.3723, validation loss: 2.5192
2024-06-05 00:15:11 [INFO]: Epoch 098 - training loss: 0.3716, validation loss: 2.5157
2024-06-05 00:17:31 [INFO]: Epoch 099 - training loss: 0.3703, validation loss: 2.5139
2024-06-05 00:19:49 [INFO]: Epoch 100 - training loss: 0.3699, validation loss: 2.5157
2024-06-05 00:19:49 [INFO]: Finished training. The best model is from epoch#99.
2024-06-05 00:19:49 [INFO]: Saved the model to results_point_rate05/Electricity/BRITS_Electricity/round_4/20240604_T202058/BRITS.pypots
2024-06-05 00:22:41 [INFO]: Successfully saved to results_point_rate05/Electricity/BRITS_Electricity/round_4/imputation.pkl
2024-06-05 00:22:41 [INFO]: Round4 - BRITS on Electricity: MAE=1.1065, MSE=2.8170, MRE=0.5924
2024-06-05 00:22:41 [INFO]: Done! Final results:
Averaged BRITS (17,082,800 params) on Electricity: MAE=1.1236 ± 0.00953090352942398, MSE=2.8275 ± 0.02282330024488635, MRE=0.6016 ± 0.005102908746801848, average inference time=39.21
