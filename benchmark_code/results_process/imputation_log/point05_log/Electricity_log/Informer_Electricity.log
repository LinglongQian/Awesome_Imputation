2024-06-02 19:59:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:59:13 [INFO]: Using the given device: cuda:0
2024-06-02 19:59:13 [INFO]: Model files will be saved to results_point_rate05/Electricity/Informer_Electricity/round_0/20240602_T195913
2024-06-02 19:59:13 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Informer_Electricity/round_0/20240602_T195913/tensorboard
2024-06-02 19:59:14 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 19:59:30 [INFO]: Epoch 001 - training loss: 1.0049, validation loss: 3.1597
2024-06-02 19:59:43 [INFO]: Epoch 002 - training loss: 0.6730, validation loss: 3.0500
2024-06-02 19:59:56 [INFO]: Epoch 003 - training loss: 0.6099, validation loss: 2.9414
2024-06-02 20:00:09 [INFO]: Epoch 004 - training loss: 0.5773, validation loss: 2.8807
2024-06-02 20:00:21 [INFO]: Epoch 005 - training loss: 0.5533, validation loss: 2.8652
2024-06-02 20:00:34 [INFO]: Epoch 006 - training loss: 0.5379, validation loss: 2.8381
2024-06-02 20:00:47 [INFO]: Epoch 007 - training loss: 0.5235, validation loss: 2.8048
2024-06-02 20:00:59 [INFO]: Epoch 008 - training loss: 0.5139, validation loss: 2.8194
2024-06-02 20:01:13 [INFO]: Epoch 009 - training loss: 0.5048, validation loss: 2.8241
2024-06-02 20:01:25 [INFO]: Epoch 010 - training loss: 0.4989, validation loss: 2.8134
2024-06-02 20:01:37 [INFO]: Epoch 011 - training loss: 0.4902, validation loss: 2.8093
2024-06-02 20:01:49 [INFO]: Epoch 012 - training loss: 0.4845, validation loss: 2.7960
2024-06-02 20:02:01 [INFO]: Epoch 013 - training loss: 0.4825, validation loss: 2.7802
2024-06-02 20:02:13 [INFO]: Epoch 014 - training loss: 0.4725, validation loss: 2.7801
2024-06-02 20:02:27 [INFO]: Epoch 015 - training loss: 0.4679, validation loss: 2.7697
2024-06-02 20:02:39 [INFO]: Epoch 016 - training loss: 0.4638, validation loss: 2.7620
2024-06-02 20:02:51 [INFO]: Epoch 017 - training loss: 0.4606, validation loss: 2.7565
2024-06-02 20:03:04 [INFO]: Epoch 018 - training loss: 0.4563, validation loss: 2.7425
2024-06-02 20:03:17 [INFO]: Epoch 019 - training loss: 0.4542, validation loss: 2.7343
2024-06-02 20:03:30 [INFO]: Epoch 020 - training loss: 0.4520, validation loss: 2.7354
2024-06-02 20:03:43 [INFO]: Epoch 021 - training loss: 0.4469, validation loss: 2.7236
2024-06-02 20:03:55 [INFO]: Epoch 022 - training loss: 0.4428, validation loss: 2.7269
2024-06-02 20:04:08 [INFO]: Epoch 023 - training loss: 0.4384, validation loss: 2.7119
2024-06-02 20:04:21 [INFO]: Epoch 024 - training loss: 0.4351, validation loss: 2.7085
2024-06-02 20:04:34 [INFO]: Epoch 025 - training loss: 0.4323, validation loss: 2.7042
2024-06-02 20:04:47 [INFO]: Epoch 026 - training loss: 0.4304, validation loss: 2.6963
2024-06-02 20:05:00 [INFO]: Epoch 027 - training loss: 0.4283, validation loss: 2.6925
2024-06-02 20:05:12 [INFO]: Epoch 028 - training loss: 0.4261, validation loss: 2.7005
2024-06-02 20:05:23 [INFO]: Epoch 029 - training loss: 0.4240, validation loss: 2.6758
2024-06-02 20:05:37 [INFO]: Epoch 030 - training loss: 0.4216, validation loss: 2.6876
2024-06-02 20:05:50 [INFO]: Epoch 031 - training loss: 0.4178, validation loss: 2.6885
2024-06-02 20:06:03 [INFO]: Epoch 032 - training loss: 0.4171, validation loss: 2.6829
2024-06-02 20:06:16 [INFO]: Epoch 033 - training loss: 0.4200, validation loss: 2.6875
2024-06-02 20:06:29 [INFO]: Epoch 034 - training loss: 0.4149, validation loss: 2.6839
2024-06-02 20:06:42 [INFO]: Epoch 035 - training loss: 0.4135, validation loss: 2.6729
2024-06-02 20:06:54 [INFO]: Epoch 036 - training loss: 0.4099, validation loss: 2.6752
2024-06-02 20:07:06 [INFO]: Epoch 037 - training loss: 0.4110, validation loss: 2.6691
2024-06-02 20:07:19 [INFO]: Epoch 038 - training loss: 0.4069, validation loss: 2.6658
2024-06-02 20:07:32 [INFO]: Epoch 039 - training loss: 0.4046, validation loss: 2.6636
2024-06-02 20:07:45 [INFO]: Epoch 040 - training loss: 0.4028, validation loss: 2.6581
2024-06-02 20:07:58 [INFO]: Epoch 041 - training loss: 0.4032, validation loss: 2.6539
2024-06-02 20:08:09 [INFO]: Epoch 042 - training loss: 0.4013, validation loss: 2.6519
2024-06-02 20:08:21 [INFO]: Epoch 043 - training loss: 0.4006, validation loss: 2.6500
2024-06-02 20:08:33 [INFO]: Epoch 044 - training loss: 0.3991, validation loss: 2.6463
2024-06-02 20:08:46 [INFO]: Epoch 045 - training loss: 0.3971, validation loss: 2.6390
2024-06-02 20:08:59 [INFO]: Epoch 046 - training loss: 0.3966, validation loss: 2.6324
2024-06-02 20:09:12 [INFO]: Epoch 047 - training loss: 0.3962, validation loss: 2.6262
2024-06-02 20:09:24 [INFO]: Epoch 048 - training loss: 0.3951, validation loss: 2.6173
2024-06-02 20:09:38 [INFO]: Epoch 049 - training loss: 0.3918, validation loss: 2.6245
2024-06-02 20:09:52 [INFO]: Epoch 050 - training loss: 0.3921, validation loss: 2.6179
2024-06-02 20:10:05 [INFO]: Epoch 051 - training loss: 0.3914, validation loss: 2.6251
2024-06-02 20:10:18 [INFO]: Epoch 052 - training loss: 0.3887, validation loss: 2.6088
2024-06-02 20:10:31 [INFO]: Epoch 053 - training loss: 0.3872, validation loss: 2.6096
2024-06-02 20:10:44 [INFO]: Epoch 054 - training loss: 0.3878, validation loss: 2.6031
2024-06-02 20:10:56 [INFO]: Epoch 055 - training loss: 0.3851, validation loss: 2.6154
2024-06-02 20:11:09 [INFO]: Epoch 056 - training loss: 0.3844, validation loss: 2.6106
2024-06-02 20:11:22 [INFO]: Epoch 057 - training loss: 0.3842, validation loss: 2.6062
2024-06-02 20:11:34 [INFO]: Epoch 058 - training loss: 0.3835, validation loss: 2.6129
2024-06-02 20:11:48 [INFO]: Epoch 059 - training loss: 0.3820, validation loss: 2.6057
2024-06-02 20:12:01 [INFO]: Epoch 060 - training loss: 0.3828, validation loss: 2.6098
2024-06-02 20:12:14 [INFO]: Epoch 061 - training loss: 0.3823, validation loss: 2.6196
2024-06-02 20:12:27 [INFO]: Epoch 062 - training loss: 0.3810, validation loss: 2.6097
2024-06-02 20:12:39 [INFO]: Epoch 063 - training loss: 0.3817, validation loss: 2.6198
2024-06-02 20:12:52 [INFO]: Epoch 064 - training loss: 0.3802, validation loss: 2.6173
2024-06-02 20:12:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:12:52 [INFO]: Finished training. The best model is from epoch#54.
2024-06-02 20:12:52 [INFO]: Saved the model to results_point_rate05/Electricity/Informer_Electricity/round_0/20240602_T195913/Informer.pypots
2024-06-02 20:12:54 [INFO]: Successfully saved to results_point_rate05/Electricity/Informer_Electricity/round_0/imputation.pkl
2024-06-02 20:12:54 [INFO]: Round0 - Informer on Electricity: MAE=1.2502, MSE=3.1697, MRE=0.6694
2024-06-02 20:12:54 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:12:54 [INFO]: Using the given device: cuda:0
2024-06-02 20:12:54 [INFO]: Model files will be saved to results_point_rate05/Electricity/Informer_Electricity/round_1/20240602_T201254
2024-06-02 20:12:54 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Informer_Electricity/round_1/20240602_T201254/tensorboard
2024-06-02 20:12:55 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 20:13:08 [INFO]: Epoch 001 - training loss: 1.0047, validation loss: 3.1711
2024-06-02 20:13:21 [INFO]: Epoch 002 - training loss: 0.6737, validation loss: 3.0169
2024-06-02 20:13:34 [INFO]: Epoch 003 - training loss: 0.6115, validation loss: 2.9500
2024-06-02 20:13:46 [INFO]: Epoch 004 - training loss: 0.5816, validation loss: 2.8748
2024-06-02 20:13:59 [INFO]: Epoch 005 - training loss: 0.5537, validation loss: 2.8761
2024-06-02 20:14:13 [INFO]: Epoch 006 - training loss: 0.5377, validation loss: 2.8424
2024-06-02 20:14:26 [INFO]: Epoch 007 - training loss: 0.5247, validation loss: 2.8329
2024-06-02 20:14:38 [INFO]: Epoch 008 - training loss: 0.5177, validation loss: 2.8358
2024-06-02 20:14:49 [INFO]: Epoch 009 - training loss: 0.5081, validation loss: 2.8115
2024-06-02 20:15:01 [INFO]: Epoch 010 - training loss: 0.4981, validation loss: 2.8069
2024-06-02 20:15:13 [INFO]: Epoch 011 - training loss: 0.4900, validation loss: 2.8016
2024-06-02 20:15:26 [INFO]: Epoch 012 - training loss: 0.4846, validation loss: 2.8063
2024-06-02 20:15:39 [INFO]: Epoch 013 - training loss: 0.4778, validation loss: 2.7994
2024-06-02 20:15:51 [INFO]: Epoch 014 - training loss: 0.4727, validation loss: 2.7923
2024-06-02 20:16:05 [INFO]: Epoch 015 - training loss: 0.4708, validation loss: 2.7868
2024-06-02 20:16:17 [INFO]: Epoch 016 - training loss: 0.4657, validation loss: 2.7816
2024-06-02 20:16:27 [INFO]: Epoch 017 - training loss: 0.4617, validation loss: 2.7696
2024-06-02 20:16:40 [INFO]: Epoch 018 - training loss: 0.4618, validation loss: 2.7682
2024-06-02 20:16:53 [INFO]: Epoch 019 - training loss: 0.4538, validation loss: 2.7562
2024-06-02 20:17:05 [INFO]: Epoch 020 - training loss: 0.4516, validation loss: 2.7522
2024-06-02 20:17:17 [INFO]: Epoch 021 - training loss: 0.4454, validation loss: 2.7517
2024-06-02 20:17:30 [INFO]: Epoch 022 - training loss: 0.4421, validation loss: 2.7449
2024-06-02 20:17:43 [INFO]: Epoch 023 - training loss: 0.4388, validation loss: 2.7382
2024-06-02 20:17:57 [INFO]: Epoch 024 - training loss: 0.4373, validation loss: 2.7360
2024-06-02 20:18:09 [INFO]: Epoch 025 - training loss: 0.4349, validation loss: 2.7254
2024-06-02 20:18:22 [INFO]: Epoch 026 - training loss: 0.4334, validation loss: 2.7244
2024-06-02 20:18:34 [INFO]: Epoch 027 - training loss: 0.4323, validation loss: 2.7192
2024-06-02 20:18:46 [INFO]: Epoch 028 - training loss: 0.4289, validation loss: 2.7186
2024-06-02 20:18:59 [INFO]: Epoch 029 - training loss: 0.4266, validation loss: 2.7196
2024-06-02 20:19:12 [INFO]: Epoch 030 - training loss: 0.4235, validation loss: 2.7046
2024-06-02 20:19:24 [INFO]: Epoch 031 - training loss: 0.4187, validation loss: 2.6998
2024-06-02 20:19:37 [INFO]: Epoch 032 - training loss: 0.4161, validation loss: 2.6965
2024-06-02 20:19:49 [INFO]: Epoch 033 - training loss: 0.4159, validation loss: 2.6849
2024-06-02 20:20:02 [INFO]: Epoch 034 - training loss: 0.4135, validation loss: 2.6959
2024-06-02 20:20:16 [INFO]: Epoch 035 - training loss: 0.4135, validation loss: 2.6979
2024-06-02 20:20:29 [INFO]: Epoch 036 - training loss: 0.4156, validation loss: 2.6902
2024-06-02 20:20:41 [INFO]: Epoch 037 - training loss: 0.4094, validation loss: 2.6821
2024-06-02 20:20:53 [INFO]: Epoch 038 - training loss: 0.4072, validation loss: 2.6791
2024-06-02 20:21:06 [INFO]: Epoch 039 - training loss: 0.4073, validation loss: 2.6795
2024-06-02 20:21:19 [INFO]: Epoch 040 - training loss: 0.4051, validation loss: 2.6749
2024-06-02 20:21:32 [INFO]: Epoch 041 - training loss: 0.4022, validation loss: 2.6726
2024-06-02 20:21:45 [INFO]: Epoch 042 - training loss: 0.3998, validation loss: 2.6630
2024-06-02 20:21:52 [INFO]: Epoch 043 - training loss: 0.3994, validation loss: 2.6580
2024-06-02 20:21:58 [INFO]: Epoch 044 - training loss: 0.3992, validation loss: 2.6631
2024-06-02 20:22:05 [INFO]: Epoch 045 - training loss: 0.3977, validation loss: 2.6557
2024-06-02 20:22:12 [INFO]: Epoch 046 - training loss: 0.3950, validation loss: 2.6482
2024-06-02 20:22:18 [INFO]: Epoch 047 - training loss: 0.3935, validation loss: 2.6448
2024-06-02 20:22:25 [INFO]: Epoch 048 - training loss: 0.3921, validation loss: 2.6431
2024-06-02 20:22:31 [INFO]: Epoch 049 - training loss: 0.3940, validation loss: 2.6380
2024-06-02 20:22:38 [INFO]: Epoch 050 - training loss: 0.3933, validation loss: 2.6538
2024-06-02 20:22:45 [INFO]: Epoch 051 - training loss: 0.3912, validation loss: 2.6461
2024-06-02 20:22:52 [INFO]: Epoch 052 - training loss: 0.3898, validation loss: 2.6444
2024-06-02 20:22:58 [INFO]: Epoch 053 - training loss: 0.3876, validation loss: 2.6566
2024-06-02 20:23:05 [INFO]: Epoch 054 - training loss: 0.3866, validation loss: 2.6444
2024-06-02 20:23:11 [INFO]: Epoch 055 - training loss: 0.3852, validation loss: 2.6505
2024-06-02 20:23:18 [INFO]: Epoch 056 - training loss: 0.3867, validation loss: 2.6440
2024-06-02 20:23:25 [INFO]: Epoch 057 - training loss: 0.3879, validation loss: 2.6410
2024-06-02 20:23:31 [INFO]: Epoch 058 - training loss: 0.3857, validation loss: 2.6352
2024-06-02 20:23:37 [INFO]: Epoch 059 - training loss: 0.3832, validation loss: 2.6348
2024-06-02 20:23:44 [INFO]: Epoch 060 - training loss: 0.3829, validation loss: 2.6329
2024-06-02 20:23:51 [INFO]: Epoch 061 - training loss: 0.3815, validation loss: 2.6481
2024-06-02 20:23:58 [INFO]: Epoch 062 - training loss: 0.3813, validation loss: 2.6408
2024-06-02 20:24:05 [INFO]: Epoch 063 - training loss: 0.3788, validation loss: 2.6397
2024-06-02 20:24:12 [INFO]: Epoch 064 - training loss: 0.3794, validation loss: 2.6389
2024-06-02 20:24:18 [INFO]: Epoch 065 - training loss: 0.3788, validation loss: 2.6401
2024-06-02 20:24:25 [INFO]: Epoch 066 - training loss: 0.3786, validation loss: 2.6356
2024-06-02 20:24:30 [INFO]: Epoch 067 - training loss: 0.3782, validation loss: 2.6414
2024-06-02 20:24:35 [INFO]: Epoch 068 - training loss: 0.3758, validation loss: 2.6383
2024-06-02 20:24:41 [INFO]: Epoch 069 - training loss: 0.3742, validation loss: 2.6362
2024-06-02 20:24:47 [INFO]: Epoch 070 - training loss: 0.3752, validation loss: 2.6403
2024-06-02 20:24:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:24:47 [INFO]: Finished training. The best model is from epoch#60.
2024-06-02 20:24:48 [INFO]: Saved the model to results_point_rate05/Electricity/Informer_Electricity/round_1/20240602_T201254/Informer.pypots
2024-06-02 20:24:49 [INFO]: Successfully saved to results_point_rate05/Electricity/Informer_Electricity/round_1/imputation.pkl
2024-06-02 20:24:49 [INFO]: Round1 - Informer on Electricity: MAE=1.3147, MSE=3.3468, MRE=0.7039
2024-06-02 20:24:49 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:24:49 [INFO]: Using the given device: cuda:0
2024-06-02 20:24:49 [INFO]: Model files will be saved to results_point_rate05/Electricity/Informer_Electricity/round_2/20240602_T202449
2024-06-02 20:24:49 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Informer_Electricity/round_2/20240602_T202449/tensorboard
2024-06-02 20:24:49 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 20:24:56 [INFO]: Epoch 001 - training loss: 1.0162, validation loss: 3.1643
2024-06-02 20:25:03 [INFO]: Epoch 002 - training loss: 0.6778, validation loss: 3.0520
2024-06-02 20:25:10 [INFO]: Epoch 003 - training loss: 0.6134, validation loss: 2.9459
2024-06-02 20:25:16 [INFO]: Epoch 004 - training loss: 0.5789, validation loss: 2.8801
2024-06-02 20:25:23 [INFO]: Epoch 005 - training loss: 0.5535, validation loss: 2.8474
2024-06-02 20:25:30 [INFO]: Epoch 006 - training loss: 0.5394, validation loss: 2.8158
2024-06-02 20:25:37 [INFO]: Epoch 007 - training loss: 0.5282, validation loss: 2.8082
2024-06-02 20:25:43 [INFO]: Epoch 008 - training loss: 0.5118, validation loss: 2.7847
2024-06-02 20:25:50 [INFO]: Epoch 009 - training loss: 0.5014, validation loss: 2.7925
2024-06-02 20:25:56 [INFO]: Epoch 010 - training loss: 0.4943, validation loss: 2.7858
2024-06-02 20:26:03 [INFO]: Epoch 011 - training loss: 0.4896, validation loss: 2.7831
2024-06-02 20:26:09 [INFO]: Epoch 012 - training loss: 0.4836, validation loss: 2.7758
2024-06-02 20:26:15 [INFO]: Epoch 013 - training loss: 0.4789, validation loss: 2.7746
2024-06-02 20:26:21 [INFO]: Epoch 014 - training loss: 0.4724, validation loss: 2.7649
2024-06-02 20:26:28 [INFO]: Epoch 015 - training loss: 0.4655, validation loss: 2.7505
2024-06-02 20:26:35 [INFO]: Epoch 016 - training loss: 0.4637, validation loss: 2.7561
2024-06-02 20:26:41 [INFO]: Epoch 017 - training loss: 0.4640, validation loss: 2.7564
2024-06-02 20:26:48 [INFO]: Epoch 018 - training loss: 0.4576, validation loss: 2.7337
2024-06-02 20:26:54 [INFO]: Epoch 019 - training loss: 0.4529, validation loss: 2.7245
2024-06-02 20:27:01 [INFO]: Epoch 020 - training loss: 0.4480, validation loss: 2.7359
2024-06-02 20:27:07 [INFO]: Epoch 021 - training loss: 0.4444, validation loss: 2.7197
2024-06-02 20:27:15 [INFO]: Epoch 022 - training loss: 0.4433, validation loss: 2.7211
2024-06-02 20:27:21 [INFO]: Epoch 023 - training loss: 0.4394, validation loss: 2.7219
2024-06-02 20:27:27 [INFO]: Epoch 024 - training loss: 0.4364, validation loss: 2.7014
2024-06-02 20:27:34 [INFO]: Epoch 025 - training loss: 0.4335, validation loss: 2.7108
2024-06-02 20:27:41 [INFO]: Epoch 026 - training loss: 0.4297, validation loss: 2.7031
2024-06-02 20:27:48 [INFO]: Epoch 027 - training loss: 0.4284, validation loss: 2.6963
2024-06-02 20:27:54 [INFO]: Epoch 028 - training loss: 0.4242, validation loss: 2.6978
2024-06-02 20:28:01 [INFO]: Epoch 029 - training loss: 0.4231, validation loss: 2.6954
2024-06-02 20:28:08 [INFO]: Epoch 030 - training loss: 0.4244, validation loss: 2.6864
2024-06-02 20:28:15 [INFO]: Epoch 031 - training loss: 0.4206, validation loss: 2.6842
2024-06-02 20:28:21 [INFO]: Epoch 032 - training loss: 0.4152, validation loss: 2.6817
2024-06-02 20:28:27 [INFO]: Epoch 033 - training loss: 0.4144, validation loss: 2.6721
2024-06-02 20:28:34 [INFO]: Epoch 034 - training loss: 0.4139, validation loss: 2.6802
2024-06-02 20:28:41 [INFO]: Epoch 035 - training loss: 0.4140, validation loss: 2.6655
2024-06-02 20:28:47 [INFO]: Epoch 036 - training loss: 0.4097, validation loss: 2.6578
2024-06-02 20:28:54 [INFO]: Epoch 037 - training loss: 0.4071, validation loss: 2.6468
2024-06-02 20:29:00 [INFO]: Epoch 038 - training loss: 0.4065, validation loss: 2.6499
2024-06-02 20:29:08 [INFO]: Epoch 039 - training loss: 0.4042, validation loss: 2.6485
2024-06-02 20:29:14 [INFO]: Epoch 040 - training loss: 0.4047, validation loss: 2.6585
2024-06-02 20:29:21 [INFO]: Epoch 041 - training loss: 0.4049, validation loss: 2.6422
2024-06-02 20:29:27 [INFO]: Epoch 042 - training loss: 0.4002, validation loss: 2.6443
2024-06-02 20:29:35 [INFO]: Epoch 043 - training loss: 0.3997, validation loss: 2.6334
2024-06-02 20:29:41 [INFO]: Epoch 044 - training loss: 0.3983, validation loss: 2.6394
2024-06-02 20:29:48 [INFO]: Epoch 045 - training loss: 0.3973, validation loss: 2.6218
2024-06-02 20:29:55 [INFO]: Epoch 046 - training loss: 0.3954, validation loss: 2.6366
2024-06-02 20:30:01 [INFO]: Epoch 047 - training loss: 0.3928, validation loss: 2.6206
2024-06-02 20:30:07 [INFO]: Epoch 048 - training loss: 0.3927, validation loss: 2.6311
2024-06-02 20:30:15 [INFO]: Epoch 049 - training loss: 0.3904, validation loss: 2.6257
2024-06-02 20:30:21 [INFO]: Epoch 050 - training loss: 0.3884, validation loss: 2.6273
2024-06-02 20:30:27 [INFO]: Epoch 051 - training loss: 0.3916, validation loss: 2.6219
2024-06-02 20:30:33 [INFO]: Epoch 052 - training loss: 0.3897, validation loss: 2.6323
2024-06-02 20:30:40 [INFO]: Epoch 053 - training loss: 0.3891, validation loss: 2.6173
2024-06-02 20:30:46 [INFO]: Epoch 054 - training loss: 0.3880, validation loss: 2.6287
2024-06-02 20:30:52 [INFO]: Epoch 055 - training loss: 0.3860, validation loss: 2.6271
2024-06-02 20:30:59 [INFO]: Epoch 056 - training loss: 0.3843, validation loss: 2.6186
2024-06-02 20:31:05 [INFO]: Epoch 057 - training loss: 0.3826, validation loss: 2.6095
2024-06-02 20:31:10 [INFO]: Epoch 058 - training loss: 0.3827, validation loss: 2.6110
2024-06-02 20:31:15 [INFO]: Epoch 059 - training loss: 0.3842, validation loss: 2.6200
2024-06-02 20:31:22 [INFO]: Epoch 060 - training loss: 0.3819, validation loss: 2.6268
2024-06-02 20:31:29 [INFO]: Epoch 061 - training loss: 0.3814, validation loss: 2.6076
2024-06-02 20:31:36 [INFO]: Epoch 062 - training loss: 0.3807, validation loss: 2.6028
2024-06-02 20:31:42 [INFO]: Epoch 063 - training loss: 0.3792, validation loss: 2.5996
2024-06-02 20:31:49 [INFO]: Epoch 064 - training loss: 0.3774, validation loss: 2.6121
2024-06-02 20:31:55 [INFO]: Epoch 065 - training loss: 0.3776, validation loss: 2.6122
2024-06-02 20:32:02 [INFO]: Epoch 066 - training loss: 0.3772, validation loss: 2.6055
2024-06-02 20:32:09 [INFO]: Epoch 067 - training loss: 0.3759, validation loss: 2.6079
2024-06-02 20:32:16 [INFO]: Epoch 068 - training loss: 0.3743, validation loss: 2.5996
2024-06-02 20:32:22 [INFO]: Epoch 069 - training loss: 0.3762, validation loss: 2.6133
2024-06-02 20:32:29 [INFO]: Epoch 070 - training loss: 0.3746, validation loss: 2.6027
2024-06-02 20:32:35 [INFO]: Epoch 071 - training loss: 0.3728, validation loss: 2.5983
2024-06-02 20:32:42 [INFO]: Epoch 072 - training loss: 0.3719, validation loss: 2.6106
2024-06-02 20:32:48 [INFO]: Epoch 073 - training loss: 0.3722, validation loss: 2.6019
2024-06-02 20:32:55 [INFO]: Epoch 074 - training loss: 0.3720, validation loss: 2.5899
2024-06-02 20:33:01 [INFO]: Epoch 075 - training loss: 0.3713, validation loss: 2.6082
2024-06-02 20:33:08 [INFO]: Epoch 076 - training loss: 0.3724, validation loss: 2.6187
2024-06-02 20:33:15 [INFO]: Epoch 077 - training loss: 0.3730, validation loss: 2.6057
2024-06-02 20:33:22 [INFO]: Epoch 078 - training loss: 0.3729, validation loss: 2.6132
2024-06-02 20:33:28 [INFO]: Epoch 079 - training loss: 0.3697, validation loss: 2.6146
2024-06-02 20:33:35 [INFO]: Epoch 080 - training loss: 0.3710, validation loss: 2.6044
2024-06-02 20:33:42 [INFO]: Epoch 081 - training loss: 0.3683, validation loss: 2.6026
2024-06-02 20:33:49 [INFO]: Epoch 082 - training loss: 0.3678, validation loss: 2.5983
2024-06-02 20:33:55 [INFO]: Epoch 083 - training loss: 0.3678, validation loss: 2.5980
2024-06-02 20:34:02 [INFO]: Epoch 084 - training loss: 0.3648, validation loss: 2.6008
2024-06-02 20:34:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:34:02 [INFO]: Finished training. The best model is from epoch#74.
2024-06-02 20:34:02 [INFO]: Saved the model to results_point_rate05/Electricity/Informer_Electricity/round_2/20240602_T202449/Informer.pypots
2024-06-02 20:34:04 [INFO]: Successfully saved to results_point_rate05/Electricity/Informer_Electricity/round_2/imputation.pkl
2024-06-02 20:34:04 [INFO]: Round2 - Informer on Electricity: MAE=1.2483, MSE=3.1300, MRE=0.6683
2024-06-02 20:34:04 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:34:04 [INFO]: Using the given device: cuda:0
2024-06-02 20:34:04 [INFO]: Model files will be saved to results_point_rate05/Electricity/Informer_Electricity/round_3/20240602_T203404
2024-06-02 20:34:04 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Informer_Electricity/round_3/20240602_T203404/tensorboard
2024-06-02 20:34:04 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 20:34:11 [INFO]: Epoch 001 - training loss: 1.0033, validation loss: 3.1458
2024-06-02 20:34:18 [INFO]: Epoch 002 - training loss: 0.6772, validation loss: 3.0408
2024-06-02 20:34:25 [INFO]: Epoch 003 - training loss: 0.6121, validation loss: 2.9228
2024-06-02 20:34:31 [INFO]: Epoch 004 - training loss: 0.5780, validation loss: 2.8862
2024-06-02 20:34:38 [INFO]: Epoch 005 - training loss: 0.5579, validation loss: 2.8769
2024-06-02 20:34:44 [INFO]: Epoch 006 - training loss: 0.5408, validation loss: 2.8561
2024-06-02 20:34:51 [INFO]: Epoch 007 - training loss: 0.5283, validation loss: 2.8252
2024-06-02 20:34:57 [INFO]: Epoch 008 - training loss: 0.5139, validation loss: 2.8049
2024-06-02 20:35:03 [INFO]: Epoch 009 - training loss: 0.5030, validation loss: 2.8098
2024-06-02 20:35:10 [INFO]: Epoch 010 - training loss: 0.4968, validation loss: 2.8043
2024-06-02 20:35:16 [INFO]: Epoch 011 - training loss: 0.4924, validation loss: 2.8141
2024-06-02 20:35:22 [INFO]: Epoch 012 - training loss: 0.4859, validation loss: 2.7951
2024-06-02 20:35:29 [INFO]: Epoch 013 - training loss: 0.4791, validation loss: 2.7857
2024-06-02 20:35:36 [INFO]: Epoch 014 - training loss: 0.4795, validation loss: 2.7981
2024-06-02 20:35:42 [INFO]: Epoch 015 - training loss: 0.4729, validation loss: 2.7889
2024-06-02 20:35:49 [INFO]: Epoch 016 - training loss: 0.4654, validation loss: 2.7700
2024-06-02 20:35:56 [INFO]: Epoch 017 - training loss: 0.4586, validation loss: 2.7619
2024-06-02 20:36:03 [INFO]: Epoch 018 - training loss: 0.4548, validation loss: 2.7554
2024-06-02 20:36:10 [INFO]: Epoch 019 - training loss: 0.4503, validation loss: 2.7384
2024-06-02 20:36:16 [INFO]: Epoch 020 - training loss: 0.4480, validation loss: 2.7345
2024-06-02 20:36:23 [INFO]: Epoch 021 - training loss: 0.4451, validation loss: 2.7351
2024-06-02 20:36:29 [INFO]: Epoch 022 - training loss: 0.4418, validation loss: 2.7364
2024-06-02 20:36:36 [INFO]: Epoch 023 - training loss: 0.4391, validation loss: 2.7253
2024-06-02 20:36:43 [INFO]: Epoch 024 - training loss: 0.4371, validation loss: 2.7266
2024-06-02 20:36:50 [INFO]: Epoch 025 - training loss: 0.4359, validation loss: 2.7190
2024-06-02 20:36:57 [INFO]: Epoch 026 - training loss: 0.4312, validation loss: 2.7157
2024-06-02 20:37:03 [INFO]: Epoch 027 - training loss: 0.4274, validation loss: 2.7155
2024-06-02 20:37:10 [INFO]: Epoch 028 - training loss: 0.4276, validation loss: 2.7056
2024-06-02 20:37:17 [INFO]: Epoch 029 - training loss: 0.4225, validation loss: 2.7032
2024-06-02 20:37:24 [INFO]: Epoch 030 - training loss: 0.4201, validation loss: 2.6877
2024-06-02 20:37:30 [INFO]: Epoch 031 - training loss: 0.4183, validation loss: 2.6779
2024-06-02 20:37:37 [INFO]: Epoch 032 - training loss: 0.4167, validation loss: 2.6915
2024-06-02 20:37:44 [INFO]: Epoch 033 - training loss: 0.4137, validation loss: 2.6790
2024-06-02 20:37:52 [INFO]: Epoch 034 - training loss: 0.4120, validation loss: 2.6696
2024-06-02 20:37:58 [INFO]: Epoch 035 - training loss: 0.4099, validation loss: 2.6592
2024-06-02 20:38:04 [INFO]: Epoch 036 - training loss: 0.4102, validation loss: 2.6621
2024-06-02 20:38:12 [INFO]: Epoch 037 - training loss: 0.4083, validation loss: 2.6518
2024-06-02 20:38:18 [INFO]: Epoch 038 - training loss: 0.4051, validation loss: 2.6513
2024-06-02 20:38:24 [INFO]: Epoch 039 - training loss: 0.4035, validation loss: 2.6375
2024-06-02 20:38:30 [INFO]: Epoch 040 - training loss: 0.4028, validation loss: 2.6432
2024-06-02 20:38:36 [INFO]: Epoch 041 - training loss: 0.4016, validation loss: 2.6356
2024-06-02 20:38:42 [INFO]: Epoch 042 - training loss: 0.4004, validation loss: 2.6319
2024-06-02 20:38:47 [INFO]: Epoch 043 - training loss: 0.3992, validation loss: 2.6408
2024-06-02 20:38:52 [INFO]: Epoch 044 - training loss: 0.3962, validation loss: 2.6302
2024-06-02 20:38:56 [INFO]: Epoch 045 - training loss: 0.3959, validation loss: 2.6424
2024-06-02 20:39:01 [INFO]: Epoch 046 - training loss: 0.3952, validation loss: 2.6260
2024-06-02 20:39:06 [INFO]: Epoch 047 - training loss: 0.3971, validation loss: 2.6285
2024-06-02 20:39:11 [INFO]: Epoch 048 - training loss: 0.3933, validation loss: 2.6176
2024-06-02 20:39:16 [INFO]: Epoch 049 - training loss: 0.3933, validation loss: 2.6198
2024-06-02 20:39:20 [INFO]: Epoch 050 - training loss: 0.3911, validation loss: 2.6256
2024-06-02 20:39:25 [INFO]: Epoch 051 - training loss: 0.3893, validation loss: 2.6258
2024-06-02 20:39:29 [INFO]: Epoch 052 - training loss: 0.3885, validation loss: 2.6352
2024-06-02 20:39:34 [INFO]: Epoch 053 - training loss: 0.3879, validation loss: 2.6210
2024-06-02 20:39:39 [INFO]: Epoch 054 - training loss: 0.3862, validation loss: 2.6273
2024-06-02 20:39:43 [INFO]: Epoch 055 - training loss: 0.3861, validation loss: 2.6165
2024-06-02 20:39:48 [INFO]: Epoch 056 - training loss: 0.3848, validation loss: 2.6108
2024-06-02 20:39:53 [INFO]: Epoch 057 - training loss: 0.3846, validation loss: 2.6078
2024-06-02 20:39:57 [INFO]: Epoch 058 - training loss: 0.3825, validation loss: 2.6114
2024-06-02 20:40:02 [INFO]: Epoch 059 - training loss: 0.3802, validation loss: 2.6176
2024-06-02 20:40:07 [INFO]: Epoch 060 - training loss: 0.3795, validation loss: 2.6061
2024-06-02 20:40:11 [INFO]: Epoch 061 - training loss: 0.3793, validation loss: 2.6111
2024-06-02 20:40:16 [INFO]: Epoch 062 - training loss: 0.3783, validation loss: 2.5985
2024-06-02 20:40:21 [INFO]: Epoch 063 - training loss: 0.3772, validation loss: 2.6130
2024-06-02 20:40:25 [INFO]: Epoch 064 - training loss: 0.3780, validation loss: 2.6087
2024-06-02 20:40:30 [INFO]: Epoch 065 - training loss: 0.3766, validation loss: 2.6079
2024-06-02 20:40:35 [INFO]: Epoch 066 - training loss: 0.3757, validation loss: 2.6158
2024-06-02 20:40:40 [INFO]: Epoch 067 - training loss: 0.3751, validation loss: 2.6029
2024-06-02 20:40:44 [INFO]: Epoch 068 - training loss: 0.3739, validation loss: 2.6107
2024-06-02 20:40:49 [INFO]: Epoch 069 - training loss: 0.3746, validation loss: 2.6118
2024-06-02 20:40:54 [INFO]: Epoch 070 - training loss: 0.3730, validation loss: 2.6185
2024-06-02 20:40:59 [INFO]: Epoch 071 - training loss: 0.3719, validation loss: 2.5980
2024-06-02 20:41:03 [INFO]: Epoch 072 - training loss: 0.3732, validation loss: 2.6109
2024-06-02 20:41:08 [INFO]: Epoch 073 - training loss: 0.3714, validation loss: 2.6078
2024-06-02 20:41:12 [INFO]: Epoch 074 - training loss: 0.3700, validation loss: 2.6164
2024-06-02 20:41:17 [INFO]: Epoch 075 - training loss: 0.3696, validation loss: 2.6074
2024-06-02 20:41:22 [INFO]: Epoch 076 - training loss: 0.3691, validation loss: 2.6048
2024-06-02 20:41:27 [INFO]: Epoch 077 - training loss: 0.3689, validation loss: 2.6259
2024-06-02 20:41:31 [INFO]: Epoch 078 - training loss: 0.3680, validation loss: 2.6217
2024-06-02 20:41:36 [INFO]: Epoch 079 - training loss: 0.3671, validation loss: 2.6138
2024-06-02 20:41:41 [INFO]: Epoch 080 - training loss: 0.3688, validation loss: 2.6177
2024-06-02 20:41:45 [INFO]: Epoch 081 - training loss: 0.3683, validation loss: 2.6234
2024-06-02 20:41:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:41:45 [INFO]: Finished training. The best model is from epoch#71.
2024-06-02 20:41:46 [INFO]: Saved the model to results_point_rate05/Electricity/Informer_Electricity/round_3/20240602_T203404/Informer.pypots
2024-06-02 20:41:47 [INFO]: Successfully saved to results_point_rate05/Electricity/Informer_Electricity/round_3/imputation.pkl
2024-06-02 20:41:47 [INFO]: Round3 - Informer on Electricity: MAE=1.3045, MSE=3.3003, MRE=0.6984
2024-06-02 20:41:47 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:41:47 [INFO]: Using the given device: cuda:0
2024-06-02 20:41:47 [INFO]: Model files will be saved to results_point_rate05/Electricity/Informer_Electricity/round_4/20240602_T204147
2024-06-02 20:41:47 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Informer_Electricity/round_4/20240602_T204147/tensorboard
2024-06-02 20:41:47 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 15,311,986
2024-06-02 20:41:52 [INFO]: Epoch 001 - training loss: 1.0054, validation loss: 3.1745
2024-06-02 20:41:57 [INFO]: Epoch 002 - training loss: 0.6764, validation loss: 3.0341
2024-06-02 20:42:01 [INFO]: Epoch 003 - training loss: 0.6118, validation loss: 2.9065
2024-06-02 20:42:06 [INFO]: Epoch 004 - training loss: 0.5771, validation loss: 2.8631
2024-06-02 20:42:11 [INFO]: Epoch 005 - training loss: 0.5552, validation loss: 2.8448
2024-06-02 20:42:16 [INFO]: Epoch 006 - training loss: 0.5389, validation loss: 2.8330
2024-06-02 20:42:20 [INFO]: Epoch 007 - training loss: 0.5262, validation loss: 2.8308
2024-06-02 20:42:24 [INFO]: Epoch 008 - training loss: 0.5159, validation loss: 2.7997
2024-06-02 20:42:29 [INFO]: Epoch 009 - training loss: 0.5065, validation loss: 2.8008
2024-06-02 20:42:33 [INFO]: Epoch 010 - training loss: 0.4963, validation loss: 2.7985
2024-06-02 20:42:38 [INFO]: Epoch 011 - training loss: 0.4917, validation loss: 2.7932
2024-06-02 20:42:42 [INFO]: Epoch 012 - training loss: 0.4840, validation loss: 2.7913
2024-06-02 20:42:47 [INFO]: Epoch 013 - training loss: 0.4777, validation loss: 2.7855
2024-06-02 20:42:51 [INFO]: Epoch 014 - training loss: 0.4731, validation loss: 2.7917
2024-06-02 20:42:56 [INFO]: Epoch 015 - training loss: 0.4687, validation loss: 2.7668
2024-06-02 20:43:00 [INFO]: Epoch 016 - training loss: 0.4640, validation loss: 2.7774
2024-06-02 20:43:04 [INFO]: Epoch 017 - training loss: 0.4604, validation loss: 2.7583
2024-06-02 20:43:09 [INFO]: Epoch 018 - training loss: 0.4555, validation loss: 2.7492
2024-06-02 20:43:14 [INFO]: Epoch 019 - training loss: 0.4513, validation loss: 2.7419
2024-06-02 20:43:18 [INFO]: Epoch 020 - training loss: 0.4500, validation loss: 2.7391
2024-06-02 20:43:23 [INFO]: Epoch 021 - training loss: 0.4492, validation loss: 2.7340
2024-06-02 20:43:28 [INFO]: Epoch 022 - training loss: 0.4440, validation loss: 2.7387
2024-06-02 20:43:33 [INFO]: Epoch 023 - training loss: 0.4400, validation loss: 2.7287
2024-06-02 20:43:38 [INFO]: Epoch 024 - training loss: 0.4360, validation loss: 2.7188
2024-06-02 20:43:42 [INFO]: Epoch 025 - training loss: 0.4347, validation loss: 2.7256
2024-06-02 20:43:47 [INFO]: Epoch 026 - training loss: 0.4323, validation loss: 2.7282
2024-06-02 20:43:52 [INFO]: Epoch 027 - training loss: 0.4297, validation loss: 2.7055
2024-06-02 20:43:57 [INFO]: Epoch 028 - training loss: 0.4265, validation loss: 2.7148
2024-06-02 20:44:01 [INFO]: Epoch 029 - training loss: 0.4266, validation loss: 2.7227
2024-06-02 20:44:06 [INFO]: Epoch 030 - training loss: 0.4229, validation loss: 2.7151
2024-06-02 20:44:10 [INFO]: Epoch 031 - training loss: 0.4182, validation loss: 2.7067
2024-06-02 20:44:15 [INFO]: Epoch 032 - training loss: 0.4203, validation loss: 2.7082
2024-06-02 20:44:20 [INFO]: Epoch 033 - training loss: 0.4164, validation loss: 2.7063
2024-06-02 20:44:24 [INFO]: Epoch 034 - training loss: 0.4133, validation loss: 2.6834
2024-06-02 20:44:29 [INFO]: Epoch 035 - training loss: 0.4107, validation loss: 2.6804
2024-06-02 20:44:34 [INFO]: Epoch 036 - training loss: 0.4097, validation loss: 2.6658
2024-06-02 20:44:38 [INFO]: Epoch 037 - training loss: 0.4080, validation loss: 2.6721
2024-06-02 20:44:43 [INFO]: Epoch 038 - training loss: 0.4069, validation loss: 2.6725
2024-06-02 20:44:48 [INFO]: Epoch 039 - training loss: 0.4046, validation loss: 2.6798
2024-06-02 20:44:52 [INFO]: Epoch 040 - training loss: 0.4031, validation loss: 2.6486
2024-06-02 20:44:57 [INFO]: Epoch 041 - training loss: 0.4022, validation loss: 2.6368
2024-06-02 20:45:02 [INFO]: Epoch 042 - training loss: 0.4006, validation loss: 2.6537
2024-06-02 20:45:06 [INFO]: Epoch 043 - training loss: 0.4006, validation loss: 2.6567
2024-06-02 20:45:11 [INFO]: Epoch 044 - training loss: 0.3981, validation loss: 2.6498
2024-06-02 20:45:15 [INFO]: Epoch 045 - training loss: 0.3949, validation loss: 2.6494
2024-06-02 20:45:20 [INFO]: Epoch 046 - training loss: 0.3958, validation loss: 2.6428
2024-06-02 20:45:25 [INFO]: Epoch 047 - training loss: 0.3948, validation loss: 2.6312
2024-06-02 20:45:30 [INFO]: Epoch 048 - training loss: 0.3943, validation loss: 2.6547
2024-06-02 20:45:35 [INFO]: Epoch 049 - training loss: 0.3932, validation loss: 2.6411
2024-06-02 20:45:39 [INFO]: Epoch 050 - training loss: 0.3931, validation loss: 2.6420
2024-06-02 20:45:44 [INFO]: Epoch 051 - training loss: 0.3954, validation loss: 2.6452
2024-06-02 20:45:48 [INFO]: Epoch 052 - training loss: 0.3910, validation loss: 2.6462
2024-06-02 20:45:53 [INFO]: Epoch 053 - training loss: 0.3887, validation loss: 2.6274
2024-06-02 20:45:58 [INFO]: Epoch 054 - training loss: 0.3873, validation loss: 2.6431
2024-06-02 20:46:02 [INFO]: Epoch 055 - training loss: 0.3862, validation loss: 2.6380
2024-06-02 20:46:07 [INFO]: Epoch 056 - training loss: 0.3863, validation loss: 2.6369
2024-06-02 20:46:11 [INFO]: Epoch 057 - training loss: 0.3849, validation loss: 2.6341
2024-06-02 20:46:15 [INFO]: Epoch 058 - training loss: 0.3834, validation loss: 2.6399
2024-06-02 20:46:19 [INFO]: Epoch 059 - training loss: 0.3820, validation loss: 2.6489
2024-06-02 20:46:22 [INFO]: Epoch 060 - training loss: 0.3829, validation loss: 2.6367
2024-06-02 20:46:26 [INFO]: Epoch 061 - training loss: 0.3811, validation loss: 2.6413
2024-06-02 20:46:30 [INFO]: Epoch 062 - training loss: 0.3811, validation loss: 2.6377
2024-06-02 20:46:34 [INFO]: Epoch 063 - training loss: 0.3795, validation loss: 2.6162
2024-06-02 20:46:38 [INFO]: Epoch 064 - training loss: 0.3795, validation loss: 2.6279
2024-06-02 20:46:41 [INFO]: Epoch 065 - training loss: 0.3787, validation loss: 2.6249
2024-06-02 20:46:45 [INFO]: Epoch 066 - training loss: 0.3792, validation loss: 2.6312
2024-06-02 20:46:49 [INFO]: Epoch 067 - training loss: 0.3768, validation loss: 2.6307
2024-06-02 20:46:52 [INFO]: Epoch 068 - training loss: 0.3760, validation loss: 2.6286
2024-06-02 20:46:56 [INFO]: Epoch 069 - training loss: 0.3760, validation loss: 2.6391
2024-06-02 20:47:00 [INFO]: Epoch 070 - training loss: 0.3743, validation loss: 2.6302
2024-06-02 20:47:03 [INFO]: Epoch 071 - training loss: 0.3725, validation loss: 2.6152
2024-06-02 20:47:07 [INFO]: Epoch 072 - training loss: 0.3725, validation loss: 2.6167
2024-06-02 20:47:11 [INFO]: Epoch 073 - training loss: 0.3739, validation loss: 2.6244
2024-06-02 20:47:13 [INFO]: Epoch 074 - training loss: 0.3718, validation loss: 2.6235
2024-06-02 20:47:17 [INFO]: Epoch 075 - training loss: 0.3704, validation loss: 2.6226
2024-06-02 20:47:21 [INFO]: Epoch 076 - training loss: 0.3689, validation loss: 2.6142
2024-06-02 20:47:25 [INFO]: Epoch 077 - training loss: 0.3693, validation loss: 2.6102
2024-06-02 20:47:27 [INFO]: Epoch 078 - training loss: 0.3697, validation loss: 2.6116
2024-06-02 20:47:29 [INFO]: Epoch 079 - training loss: 0.3682, validation loss: 2.6116
2024-06-02 20:47:31 [INFO]: Epoch 080 - training loss: 0.3667, validation loss: 2.6264
2024-06-02 20:47:32 [INFO]: Epoch 081 - training loss: 0.3683, validation loss: 2.6114
2024-06-02 20:47:34 [INFO]: Epoch 082 - training loss: 0.3661, validation loss: 2.6101
2024-06-02 20:47:36 [INFO]: Epoch 083 - training loss: 0.3659, validation loss: 2.6071
2024-06-02 20:47:37 [INFO]: Epoch 084 - training loss: 0.3669, validation loss: 2.6177
2024-06-02 20:47:39 [INFO]: Epoch 085 - training loss: 0.3659, validation loss: 2.6112
2024-06-02 20:47:40 [INFO]: Epoch 086 - training loss: 0.3650, validation loss: 2.6203
2024-06-02 20:47:42 [INFO]: Epoch 087 - training loss: 0.3662, validation loss: 2.6019
2024-06-02 20:47:44 [INFO]: Epoch 088 - training loss: 0.3676, validation loss: 2.6131
2024-06-02 20:47:45 [INFO]: Epoch 089 - training loss: 0.3656, validation loss: 2.5983
2024-06-02 20:47:47 [INFO]: Epoch 090 - training loss: 0.3644, validation loss: 2.6081
2024-06-02 20:47:48 [INFO]: Epoch 091 - training loss: 0.3623, validation loss: 2.6134
2024-06-02 20:47:50 [INFO]: Epoch 092 - training loss: 0.3610, validation loss: 2.6108
2024-06-02 20:47:52 [INFO]: Epoch 093 - training loss: 0.3608, validation loss: 2.6202
2024-06-02 20:47:53 [INFO]: Epoch 094 - training loss: 0.3599, validation loss: 2.6041
2024-06-02 20:47:55 [INFO]: Epoch 095 - training loss: 0.3595, validation loss: 2.6056
2024-06-02 20:47:56 [INFO]: Epoch 096 - training loss: 0.3599, validation loss: 2.5937
2024-06-02 20:47:58 [INFO]: Epoch 097 - training loss: 0.3604, validation loss: 2.6276
2024-06-02 20:48:00 [INFO]: Epoch 098 - training loss: 0.3613, validation loss: 2.6164
2024-06-02 20:48:01 [INFO]: Epoch 099 - training loss: 0.3610, validation loss: 2.6132
2024-06-02 20:48:03 [INFO]: Epoch 100 - training loss: 0.3617, validation loss: 2.6139
2024-06-02 20:48:03 [INFO]: Finished training. The best model is from epoch#96.
2024-06-02 20:48:03 [INFO]: Saved the model to results_point_rate05/Electricity/Informer_Electricity/round_4/20240602_T204147/Informer.pypots
2024-06-02 20:48:03 [INFO]: Successfully saved to results_point_rate05/Electricity/Informer_Electricity/round_4/imputation.pkl
2024-06-02 20:48:03 [INFO]: Round4 - Informer on Electricity: MAE=1.2682, MSE=3.2486, MRE=0.6790
2024-06-02 20:48:03 [INFO]: Done! Final results:
Averaged Informer (15,311,986 params) on Electricity: MAE=1.2772 ± 0.027553442593183368, MSE=3.2391 ± 0.08018035209893404, MRE=0.6838 ± 0.014752295286505304, average inference time=1.00
