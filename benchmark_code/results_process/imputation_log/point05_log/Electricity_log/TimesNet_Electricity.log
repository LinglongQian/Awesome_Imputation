2024-06-04 02:52:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:52:46 [INFO]: Using the given device: cuda:0
2024-06-04 02:52:46 [INFO]: Model files will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_0/20240604_T025246
2024-06-04 02:52:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_0/20240604_T025246/tensorboard
2024-06-04 02:52:49 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-04 02:53:05 [INFO]: Epoch 001 - training loss: 0.6390, validation loss: 3.2535
2024-06-04 02:53:16 [INFO]: Epoch 002 - training loss: 0.3131, validation loss: 3.0509
2024-06-04 02:53:27 [INFO]: Epoch 003 - training loss: 0.2587, validation loss: 2.9552
2024-06-04 02:53:38 [INFO]: Epoch 004 - training loss: 0.2350, validation loss: 2.8908
2024-06-04 02:53:50 [INFO]: Epoch 005 - training loss: 0.2197, validation loss: 2.8449
2024-06-04 02:54:02 [INFO]: Epoch 006 - training loss: 0.2096, validation loss: 2.8118
2024-06-04 02:54:13 [INFO]: Epoch 007 - training loss: 0.2001, validation loss: 2.7857
2024-06-04 02:54:25 [INFO]: Epoch 008 - training loss: 0.1939, validation loss: 2.7710
2024-06-04 02:54:36 [INFO]: Epoch 009 - training loss: 0.1881, validation loss: 2.7475
2024-06-04 02:54:48 [INFO]: Epoch 010 - training loss: 0.1835, validation loss: 2.7429
2024-06-04 02:54:59 [INFO]: Epoch 011 - training loss: 0.1788, validation loss: 2.7268
2024-06-04 02:55:11 [INFO]: Epoch 012 - training loss: 0.1757, validation loss: 2.7178
2024-06-04 02:55:23 [INFO]: Epoch 013 - training loss: 0.1732, validation loss: 2.7084
2024-06-04 02:55:35 [INFO]: Epoch 014 - training loss: 0.1695, validation loss: 2.6990
2024-06-04 02:55:47 [INFO]: Epoch 015 - training loss: 0.1676, validation loss: 2.6878
2024-06-04 02:55:59 [INFO]: Epoch 016 - training loss: 0.1648, validation loss: 2.6849
2024-06-04 02:56:10 [INFO]: Epoch 017 - training loss: 0.1625, validation loss: 2.6778
2024-06-04 02:56:21 [INFO]: Epoch 018 - training loss: 0.1603, validation loss: 2.6696
2024-06-04 02:56:33 [INFO]: Epoch 019 - training loss: 0.1592, validation loss: 2.6612
2024-06-04 02:56:45 [INFO]: Epoch 020 - training loss: 0.1569, validation loss: 2.6601
2024-06-04 02:56:56 [INFO]: Epoch 021 - training loss: 0.1554, validation loss: 2.6570
2024-06-04 02:57:08 [INFO]: Epoch 022 - training loss: 0.1532, validation loss: 2.6543
2024-06-04 02:57:20 [INFO]: Epoch 023 - training loss: 0.1526, validation loss: 2.6467
2024-06-04 02:57:32 [INFO]: Epoch 024 - training loss: 0.1512, validation loss: 2.6489
2024-06-04 02:57:44 [INFO]: Epoch 025 - training loss: 0.1500, validation loss: 2.6394
2024-06-04 02:57:56 [INFO]: Epoch 026 - training loss: 0.1480, validation loss: 2.6403
2024-06-04 02:58:07 [INFO]: Epoch 027 - training loss: 0.1473, validation loss: 2.6393
2024-06-04 02:58:19 [INFO]: Epoch 028 - training loss: 0.1463, validation loss: 2.6401
2024-06-04 02:58:31 [INFO]: Epoch 029 - training loss: 0.1445, validation loss: 2.6351
2024-06-04 02:58:42 [INFO]: Epoch 030 - training loss: 0.1437, validation loss: 2.6330
2024-06-04 02:58:54 [INFO]: Epoch 031 - training loss: 0.1429, validation loss: 2.6325
2024-06-04 02:59:06 [INFO]: Epoch 032 - training loss: 0.1420, validation loss: 2.6274
2024-06-04 02:59:17 [INFO]: Epoch 033 - training loss: 0.1414, validation loss: 2.6211
2024-06-04 02:59:29 [INFO]: Epoch 034 - training loss: 0.1402, validation loss: 2.6161
2024-06-04 02:59:40 [INFO]: Epoch 035 - training loss: 0.1385, validation loss: 2.6144
2024-06-04 02:59:52 [INFO]: Epoch 036 - training loss: 0.1381, validation loss: 2.6104
2024-06-04 03:00:03 [INFO]: Epoch 037 - training loss: 0.1374, validation loss: 2.6027
2024-06-04 03:00:15 [INFO]: Epoch 038 - training loss: 0.1360, validation loss: 2.5996
2024-06-04 03:00:27 [INFO]: Epoch 039 - training loss: 0.1360, validation loss: 2.5989
2024-06-04 03:00:39 [INFO]: Epoch 040 - training loss: 0.1345, validation loss: 2.5905
2024-06-04 03:00:50 [INFO]: Epoch 041 - training loss: 0.1338, validation loss: 2.5898
2024-06-04 03:01:02 [INFO]: Epoch 042 - training loss: 0.1342, validation loss: 2.5876
2024-06-04 03:01:13 [INFO]: Epoch 043 - training loss: 0.1332, validation loss: 2.5825
2024-06-04 03:01:24 [INFO]: Epoch 044 - training loss: 0.1322, validation loss: 2.5740
2024-06-04 03:01:36 [INFO]: Epoch 045 - training loss: 0.1312, validation loss: 2.5707
2024-06-04 03:01:48 [INFO]: Epoch 046 - training loss: 0.1312, validation loss: 2.5649
2024-06-04 03:02:00 [INFO]: Epoch 047 - training loss: 0.1306, validation loss: 2.5629
2024-06-04 03:02:12 [INFO]: Epoch 048 - training loss: 0.1298, validation loss: 2.5574
2024-06-04 03:02:23 [INFO]: Epoch 049 - training loss: 0.1295, validation loss: 2.5531
2024-06-04 03:02:34 [INFO]: Epoch 050 - training loss: 0.1289, validation loss: 2.5466
2024-06-04 03:02:46 [INFO]: Epoch 051 - training loss: 0.1279, validation loss: 2.5425
2024-06-04 03:02:58 [INFO]: Epoch 052 - training loss: 0.1279, validation loss: 2.5401
2024-06-04 03:03:10 [INFO]: Epoch 053 - training loss: 0.1270, validation loss: 2.5341
2024-06-04 03:03:21 [INFO]: Epoch 054 - training loss: 0.1268, validation loss: 2.5306
2024-06-04 03:03:33 [INFO]: Epoch 055 - training loss: 0.1258, validation loss: 2.5243
2024-06-04 03:03:45 [INFO]: Epoch 056 - training loss: 0.1258, validation loss: 2.5229
2024-06-04 03:03:56 [INFO]: Epoch 057 - training loss: 0.1253, validation loss: 2.5180
2024-06-04 03:04:08 [INFO]: Epoch 058 - training loss: 0.1248, validation loss: 2.5192
2024-06-04 03:04:19 [INFO]: Epoch 059 - training loss: 0.1242, validation loss: 2.5137
2024-06-04 03:04:30 [INFO]: Epoch 060 - training loss: 0.1234, validation loss: 2.5179
2024-06-04 03:04:42 [INFO]: Epoch 061 - training loss: 0.1238, validation loss: 2.5059
2024-06-04 03:04:53 [INFO]: Epoch 062 - training loss: 0.1230, validation loss: 2.5013
2024-06-04 03:05:05 [INFO]: Epoch 063 - training loss: 0.1228, validation loss: 2.4954
2024-06-04 03:05:17 [INFO]: Epoch 064 - training loss: 0.1217, validation loss: 2.4974
2024-06-04 03:05:29 [INFO]: Epoch 065 - training loss: 0.1222, validation loss: 2.5015
2024-06-04 03:05:41 [INFO]: Epoch 066 - training loss: 0.1213, validation loss: 2.4927
2024-06-04 03:05:52 [INFO]: Epoch 067 - training loss: 0.1214, validation loss: 2.4909
2024-06-04 03:06:04 [INFO]: Epoch 068 - training loss: 0.1207, validation loss: 2.4843
2024-06-04 03:06:16 [INFO]: Epoch 069 - training loss: 0.1199, validation loss: 2.4805
2024-06-04 03:06:27 [INFO]: Epoch 070 - training loss: 0.1196, validation loss: 2.4752
2024-06-04 03:06:39 [INFO]: Epoch 071 - training loss: 0.1198, validation loss: 2.4682
2024-06-04 03:06:51 [INFO]: Epoch 072 - training loss: 0.1196, validation loss: 2.4693
2024-06-04 03:07:02 [INFO]: Epoch 073 - training loss: 0.1192, validation loss: 2.4624
2024-06-04 03:07:13 [INFO]: Epoch 074 - training loss: 0.1192, validation loss: 2.4600
2024-06-04 03:07:25 [INFO]: Epoch 075 - training loss: 0.1183, validation loss: 2.4615
2024-06-04 03:07:36 [INFO]: Epoch 076 - training loss: 0.1187, validation loss: 2.4571
2024-06-04 03:07:48 [INFO]: Epoch 077 - training loss: 0.1177, validation loss: 2.4485
2024-06-04 03:07:59 [INFO]: Epoch 078 - training loss: 0.1173, validation loss: 2.4470
2024-06-04 03:08:11 [INFO]: Epoch 079 - training loss: 0.1174, validation loss: 2.4440
2024-06-04 03:08:22 [INFO]: Epoch 080 - training loss: 0.1167, validation loss: 2.4428
2024-06-04 03:08:33 [INFO]: Epoch 081 - training loss: 0.1164, validation loss: 2.4427
2024-06-04 03:08:45 [INFO]: Epoch 082 - training loss: 0.1171, validation loss: 2.4397
2024-06-04 03:08:56 [INFO]: Epoch 083 - training loss: 0.1159, validation loss: 2.4306
2024-06-04 03:09:08 [INFO]: Epoch 084 - training loss: 0.1162, validation loss: 2.4261
2024-06-04 03:09:19 [INFO]: Epoch 085 - training loss: 0.1161, validation loss: 2.4261
2024-06-04 03:09:30 [INFO]: Epoch 086 - training loss: 0.1162, validation loss: 2.4276
2024-06-04 03:09:42 [INFO]: Epoch 087 - training loss: 0.1153, validation loss: 2.4236
2024-06-04 03:09:54 [INFO]: Epoch 088 - training loss: 0.1155, validation loss: 2.4154
2024-06-04 03:10:06 [INFO]: Epoch 089 - training loss: 0.1152, validation loss: 2.4105
2024-06-04 03:10:18 [INFO]: Epoch 090 - training loss: 0.1142, validation loss: 2.4070
2024-06-04 03:10:29 [INFO]: Epoch 091 - training loss: 0.1142, validation loss: 2.4041
2024-06-04 03:10:41 [INFO]: Epoch 092 - training loss: 0.1142, validation loss: 2.4008
2024-06-04 03:10:52 [INFO]: Epoch 093 - training loss: 0.1139, validation loss: 2.3956
2024-06-04 03:11:04 [INFO]: Epoch 094 - training loss: 0.1136, validation loss: 2.3890
2024-06-04 03:11:15 [INFO]: Epoch 095 - training loss: 0.1135, validation loss: 2.3927
2024-06-04 03:11:27 [INFO]: Epoch 096 - training loss: 0.1134, validation loss: 2.3809
2024-06-04 03:11:38 [INFO]: Epoch 097 - training loss: 0.1125, validation loss: 2.3834
2024-06-04 03:11:50 [INFO]: Epoch 098 - training loss: 0.1126, validation loss: 2.3787
2024-06-04 03:12:01 [INFO]: Epoch 099 - training loss: 0.1122, validation loss: 2.3812
2024-06-04 03:12:13 [INFO]: Epoch 100 - training loss: 0.1124, validation loss: 2.3723
2024-06-04 03:12:13 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 03:12:14 [INFO]: Saved the model to results_point_rate05/Electricity/TimesNet_Electricity/round_0/20240604_T025246/TimesNet.pypots
2024-06-04 03:12:22 [INFO]: Successfully saved to results_point_rate05/Electricity/TimesNet_Electricity/round_0/imputation.pkl
2024-06-04 03:12:22 [INFO]: Round0 - TimesNet on Electricity: MAE=1.1158, MSE=2.5775, MRE=0.5974
2024-06-04 03:12:22 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:12:22 [INFO]: Using the given device: cuda:0
2024-06-04 03:12:22 [INFO]: Model files will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_1/20240604_T031222
2024-06-04 03:12:22 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_1/20240604_T031222/tensorboard
2024-06-04 03:12:25 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-04 03:12:37 [INFO]: Epoch 001 - training loss: 0.6436, validation loss: 3.2606
2024-06-04 03:12:49 [INFO]: Epoch 002 - training loss: 0.3118, validation loss: 3.0634
2024-06-04 03:13:01 [INFO]: Epoch 003 - training loss: 0.2559, validation loss: 2.9590
2024-06-04 03:13:12 [INFO]: Epoch 004 - training loss: 0.2306, validation loss: 2.8869
2024-06-04 03:13:24 [INFO]: Epoch 005 - training loss: 0.2182, validation loss: 2.8531
2024-06-04 03:13:36 [INFO]: Epoch 006 - training loss: 0.2097, validation loss: 2.8276
2024-06-04 03:13:47 [INFO]: Epoch 007 - training loss: 0.1997, validation loss: 2.7965
2024-06-04 03:13:59 [INFO]: Epoch 008 - training loss: 0.1938, validation loss: 2.7718
2024-06-04 03:14:11 [INFO]: Epoch 009 - training loss: 0.1881, validation loss: 2.7642
2024-06-04 03:14:23 [INFO]: Epoch 010 - training loss: 0.1832, validation loss: 2.7534
2024-06-04 03:14:35 [INFO]: Epoch 011 - training loss: 0.1793, validation loss: 2.7490
2024-06-04 03:14:47 [INFO]: Epoch 012 - training loss: 0.1758, validation loss: 2.7336
2024-06-04 03:14:59 [INFO]: Epoch 013 - training loss: 0.1729, validation loss: 2.7177
2024-06-04 03:15:11 [INFO]: Epoch 014 - training loss: 0.1700, validation loss: 2.7149
2024-06-04 03:15:22 [INFO]: Epoch 015 - training loss: 0.1666, validation loss: 2.7083
2024-06-04 03:15:34 [INFO]: Epoch 016 - training loss: 0.1654, validation loss: 2.7000
2024-06-04 03:15:46 [INFO]: Epoch 017 - training loss: 0.1633, validation loss: 2.6924
2024-06-04 03:15:58 [INFO]: Epoch 018 - training loss: 0.1605, validation loss: 2.6895
2024-06-04 03:16:10 [INFO]: Epoch 019 - training loss: 0.1584, validation loss: 2.6811
2024-06-04 03:16:21 [INFO]: Epoch 020 - training loss: 0.1568, validation loss: 2.6747
2024-06-04 03:16:33 [INFO]: Epoch 021 - training loss: 0.1556, validation loss: 2.6694
2024-06-04 03:16:44 [INFO]: Epoch 022 - training loss: 0.1542, validation loss: 2.6730
2024-06-04 03:16:56 [INFO]: Epoch 023 - training loss: 0.1524, validation loss: 2.6643
2024-06-04 03:17:08 [INFO]: Epoch 024 - training loss: 0.1502, validation loss: 2.6662
2024-06-04 03:17:19 [INFO]: Epoch 025 - training loss: 0.1489, validation loss: 2.6617
2024-06-04 03:17:31 [INFO]: Epoch 026 - training loss: 0.1481, validation loss: 2.6537
2024-06-04 03:17:42 [INFO]: Epoch 027 - training loss: 0.1476, validation loss: 2.6522
2024-06-04 03:17:53 [INFO]: Epoch 028 - training loss: 0.1464, validation loss: 2.6531
2024-06-04 03:18:05 [INFO]: Epoch 029 - training loss: 0.1446, validation loss: 2.6550
2024-06-04 03:18:17 [INFO]: Epoch 030 - training loss: 0.1446, validation loss: 2.6409
2024-06-04 03:18:29 [INFO]: Epoch 031 - training loss: 0.1427, validation loss: 2.6483
2024-06-04 03:18:41 [INFO]: Epoch 032 - training loss: 0.1420, validation loss: 2.6478
2024-06-04 03:18:53 [INFO]: Epoch 033 - training loss: 0.1411, validation loss: 2.6414
2024-06-04 03:19:05 [INFO]: Epoch 034 - training loss: 0.1398, validation loss: 2.6384
2024-06-04 03:19:16 [INFO]: Epoch 035 - training loss: 0.1390, validation loss: 2.6371
2024-06-04 03:19:28 [INFO]: Epoch 036 - training loss: 0.1381, validation loss: 2.6188
2024-06-04 03:19:40 [INFO]: Epoch 037 - training loss: 0.1373, validation loss: 2.6189
2024-06-04 03:19:51 [INFO]: Epoch 038 - training loss: 0.1364, validation loss: 2.6181
2024-06-04 03:20:03 [INFO]: Epoch 039 - training loss: 0.1359, validation loss: 2.6157
2024-06-04 03:20:14 [INFO]: Epoch 040 - training loss: 0.1354, validation loss: 2.6061
2024-06-04 03:20:25 [INFO]: Epoch 041 - training loss: 0.1340, validation loss: 2.6020
2024-06-04 03:20:37 [INFO]: Epoch 042 - training loss: 0.1333, validation loss: 2.5995
2024-06-04 03:20:48 [INFO]: Epoch 043 - training loss: 0.1321, validation loss: 2.5969
2024-06-04 03:21:00 [INFO]: Epoch 044 - training loss: 0.1325, validation loss: 2.5869
2024-06-04 03:21:11 [INFO]: Epoch 045 - training loss: 0.1314, validation loss: 2.5844
2024-06-04 03:21:23 [INFO]: Epoch 046 - training loss: 0.1310, validation loss: 2.5800
2024-06-04 03:21:35 [INFO]: Epoch 047 - training loss: 0.1301, validation loss: 2.5781
2024-06-04 03:21:47 [INFO]: Epoch 048 - training loss: 0.1295, validation loss: 2.5738
2024-06-04 03:21:59 [INFO]: Epoch 049 - training loss: 0.1293, validation loss: 2.5663
2024-06-04 03:22:10 [INFO]: Epoch 050 - training loss: 0.1285, validation loss: 2.5666
2024-06-04 03:22:22 [INFO]: Epoch 051 - training loss: 0.1278, validation loss: 2.5639
2024-06-04 03:22:34 [INFO]: Epoch 052 - training loss: 0.1280, validation loss: 2.5614
2024-06-04 03:22:46 [INFO]: Epoch 053 - training loss: 0.1268, validation loss: 2.5577
2024-06-04 03:22:57 [INFO]: Epoch 054 - training loss: 0.1268, validation loss: 2.5577
2024-06-04 03:23:09 [INFO]: Epoch 055 - training loss: 0.1265, validation loss: 2.5524
2024-06-04 03:23:21 [INFO]: Epoch 056 - training loss: 0.1255, validation loss: 2.5554
2024-06-04 03:23:32 [INFO]: Epoch 057 - training loss: 0.1251, validation loss: 2.5453
2024-06-04 03:23:42 [INFO]: Epoch 058 - training loss: 0.1249, validation loss: 2.5465
2024-06-04 03:23:54 [INFO]: Epoch 059 - training loss: 0.1246, validation loss: 2.5430
2024-06-04 03:24:05 [INFO]: Epoch 060 - training loss: 0.1243, validation loss: 2.5393
2024-06-04 03:24:17 [INFO]: Epoch 061 - training loss: 0.1232, validation loss: 2.5340
2024-06-04 03:24:28 [INFO]: Epoch 062 - training loss: 0.1230, validation loss: 2.5228
2024-06-04 03:24:40 [INFO]: Epoch 063 - training loss: 0.1220, validation loss: 2.5180
2024-06-04 03:24:52 [INFO]: Epoch 064 - training loss: 0.1220, validation loss: 2.5201
2024-06-04 03:25:04 [INFO]: Epoch 065 - training loss: 0.1217, validation loss: 2.5192
2024-06-04 03:25:15 [INFO]: Epoch 066 - training loss: 0.1214, validation loss: 2.5167
2024-06-04 03:25:27 [INFO]: Epoch 067 - training loss: 0.1213, validation loss: 2.5075
2024-06-04 03:25:39 [INFO]: Epoch 068 - training loss: 0.1208, validation loss: 2.5082
2024-06-04 03:25:50 [INFO]: Epoch 069 - training loss: 0.1207, validation loss: 2.5112
2024-06-04 03:26:01 [INFO]: Epoch 070 - training loss: 0.1202, validation loss: 2.5050
2024-06-04 03:26:13 [INFO]: Epoch 071 - training loss: 0.1201, validation loss: 2.4957
2024-06-04 03:26:24 [INFO]: Epoch 072 - training loss: 0.1190, validation loss: 2.4931
2024-06-04 03:26:36 [INFO]: Epoch 073 - training loss: 0.1187, validation loss: 2.4935
2024-06-04 03:26:48 [INFO]: Epoch 074 - training loss: 0.1184, validation loss: 2.4898
2024-06-04 03:27:00 [INFO]: Epoch 075 - training loss: 0.1186, validation loss: 2.4801
2024-06-04 03:27:11 [INFO]: Epoch 076 - training loss: 0.1182, validation loss: 2.4781
2024-06-04 03:27:23 [INFO]: Epoch 077 - training loss: 0.1174, validation loss: 2.4777
2024-06-04 03:27:34 [INFO]: Epoch 078 - training loss: 0.1178, validation loss: 2.4728
2024-06-04 03:27:44 [INFO]: Epoch 079 - training loss: 0.1177, validation loss: 2.4740
2024-06-04 03:27:56 [INFO]: Epoch 080 - training loss: 0.1171, validation loss: 2.4650
2024-06-04 03:28:05 [INFO]: Epoch 081 - training loss: 0.1171, validation loss: 2.4642
2024-06-04 03:28:16 [INFO]: Epoch 082 - training loss: 0.1167, validation loss: 2.4663
2024-06-04 03:28:28 [INFO]: Epoch 083 - training loss: 0.1163, validation loss: 2.4616
2024-06-04 03:28:39 [INFO]: Epoch 084 - training loss: 0.1160, validation loss: 2.4577
2024-06-04 03:28:50 [INFO]: Epoch 085 - training loss: 0.1156, validation loss: 2.4573
2024-06-04 03:29:02 [INFO]: Epoch 086 - training loss: 0.1156, validation loss: 2.4491
2024-06-04 03:29:14 [INFO]: Epoch 087 - training loss: 0.1154, validation loss: 2.4509
2024-06-04 03:29:25 [INFO]: Epoch 088 - training loss: 0.1151, validation loss: 2.4470
2024-06-04 03:29:37 [INFO]: Epoch 089 - training loss: 0.1146, validation loss: 2.4526
2024-06-04 03:29:49 [INFO]: Epoch 090 - training loss: 0.1146, validation loss: 2.4439
2024-06-04 03:30:01 [INFO]: Epoch 091 - training loss: 0.1146, validation loss: 2.4438
2024-06-04 03:30:13 [INFO]: Epoch 092 - training loss: 0.1143, validation loss: 2.4434
2024-06-04 03:30:24 [INFO]: Epoch 093 - training loss: 0.1134, validation loss: 2.4465
2024-06-04 03:30:36 [INFO]: Epoch 094 - training loss: 0.1137, validation loss: 2.4403
2024-06-04 03:30:48 [INFO]: Epoch 095 - training loss: 0.1138, validation loss: 2.4414
2024-06-04 03:31:00 [INFO]: Epoch 096 - training loss: 0.1128, validation loss: 2.4395
2024-06-04 03:31:12 [INFO]: Epoch 097 - training loss: 0.1134, validation loss: 2.4478
2024-06-04 03:31:24 [INFO]: Epoch 098 - training loss: 0.1127, validation loss: 2.4399
2024-06-04 03:31:36 [INFO]: Epoch 099 - training loss: 0.1129, validation loss: 2.4373
2024-06-04 03:31:48 [INFO]: Epoch 100 - training loss: 0.1120, validation loss: 2.4433
2024-06-04 03:31:48 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 03:31:49 [INFO]: Saved the model to results_point_rate05/Electricity/TimesNet_Electricity/round_1/20240604_T031222/TimesNet.pypots
2024-06-04 03:31:57 [INFO]: Successfully saved to results_point_rate05/Electricity/TimesNet_Electricity/round_1/imputation.pkl
2024-06-04 03:31:57 [INFO]: Round1 - TimesNet on Electricity: MAE=1.1612, MSE=2.7766, MRE=0.6217
2024-06-04 03:31:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:31:57 [INFO]: Using the given device: cuda:0
2024-06-04 03:31:57 [INFO]: Model files will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_2/20240604_T033157
2024-06-04 03:31:57 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_2/20240604_T033157/tensorboard
2024-06-04 03:31:59 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-04 03:32:11 [INFO]: Epoch 001 - training loss: 0.6308, validation loss: 3.2875
2024-06-04 03:32:23 [INFO]: Epoch 002 - training loss: 0.3126, validation loss: 3.0799
2024-06-04 03:32:34 [INFO]: Epoch 003 - training loss: 0.2571, validation loss: 2.9823
2024-06-04 03:32:46 [INFO]: Epoch 004 - training loss: 0.2344, validation loss: 2.9117
2024-06-04 03:32:58 [INFO]: Epoch 005 - training loss: 0.2199, validation loss: 2.8667
2024-06-04 03:33:09 [INFO]: Epoch 006 - training loss: 0.2096, validation loss: 2.8227
2024-06-04 03:33:21 [INFO]: Epoch 007 - training loss: 0.2012, validation loss: 2.7988
2024-06-04 03:33:33 [INFO]: Epoch 008 - training loss: 0.1950, validation loss: 2.7797
2024-06-04 03:33:44 [INFO]: Epoch 009 - training loss: 0.1895, validation loss: 2.7636
2024-06-04 03:33:56 [INFO]: Epoch 010 - training loss: 0.1842, validation loss: 2.7501
2024-06-04 03:34:08 [INFO]: Epoch 011 - training loss: 0.1797, validation loss: 2.7398
2024-06-04 03:34:20 [INFO]: Epoch 012 - training loss: 0.1765, validation loss: 2.7237
2024-06-04 03:34:32 [INFO]: Epoch 013 - training loss: 0.1732, validation loss: 2.7201
2024-06-04 03:34:43 [INFO]: Epoch 014 - training loss: 0.1697, validation loss: 2.7070
2024-06-04 03:34:55 [INFO]: Epoch 015 - training loss: 0.1684, validation loss: 2.6952
2024-06-04 03:35:07 [INFO]: Epoch 016 - training loss: 0.1656, validation loss: 2.6877
2024-06-04 03:35:18 [INFO]: Epoch 017 - training loss: 0.1642, validation loss: 2.6833
2024-06-04 03:35:31 [INFO]: Epoch 018 - training loss: 0.1610, validation loss: 2.6753
2024-06-04 03:35:42 [INFO]: Epoch 019 - training loss: 0.1592, validation loss: 2.6736
2024-06-04 03:35:53 [INFO]: Epoch 020 - training loss: 0.1579, validation loss: 2.6632
2024-06-04 03:36:05 [INFO]: Epoch 021 - training loss: 0.1563, validation loss: 2.6592
2024-06-04 03:36:16 [INFO]: Epoch 022 - training loss: 0.1548, validation loss: 2.6583
2024-06-04 03:36:28 [INFO]: Epoch 023 - training loss: 0.1534, validation loss: 2.6490
2024-06-04 03:36:39 [INFO]: Epoch 024 - training loss: 0.1510, validation loss: 2.6479
2024-06-04 03:36:51 [INFO]: Epoch 025 - training loss: 0.1499, validation loss: 2.6455
2024-06-04 03:37:02 [INFO]: Epoch 026 - training loss: 0.1477, validation loss: 2.6448
2024-06-04 03:37:14 [INFO]: Epoch 027 - training loss: 0.1470, validation loss: 2.6479
2024-06-04 03:37:26 [INFO]: Epoch 028 - training loss: 0.1465, validation loss: 2.6405
2024-06-04 03:37:37 [INFO]: Epoch 029 - training loss: 0.1453, validation loss: 2.6397
2024-06-04 03:37:48 [INFO]: Epoch 030 - training loss: 0.1442, validation loss: 2.6389
2024-06-04 03:37:58 [INFO]: Epoch 031 - training loss: 0.1427, validation loss: 2.6355
2024-06-04 03:38:09 [INFO]: Epoch 032 - training loss: 0.1427, validation loss: 2.6383
2024-06-04 03:38:20 [INFO]: Epoch 033 - training loss: 0.1405, validation loss: 2.6237
2024-06-04 03:38:30 [INFO]: Epoch 034 - training loss: 0.1394, validation loss: 2.6128
2024-06-04 03:38:41 [INFO]: Epoch 035 - training loss: 0.1395, validation loss: 2.6139
2024-06-04 03:38:51 [INFO]: Epoch 036 - training loss: 0.1388, validation loss: 2.6083
2024-06-04 03:39:02 [INFO]: Epoch 037 - training loss: 0.1373, validation loss: 2.6069
2024-06-04 03:39:13 [INFO]: Epoch 038 - training loss: 0.1361, validation loss: 2.5993
2024-06-04 03:39:23 [INFO]: Epoch 039 - training loss: 0.1362, validation loss: 2.5928
2024-06-04 03:39:34 [INFO]: Epoch 040 - training loss: 0.1349, validation loss: 2.5954
2024-06-04 03:39:45 [INFO]: Epoch 041 - training loss: 0.1335, validation loss: 2.5928
2024-06-04 03:39:56 [INFO]: Epoch 042 - training loss: 0.1331, validation loss: 2.5860
2024-06-04 03:40:06 [INFO]: Epoch 043 - training loss: 0.1328, validation loss: 2.5792
2024-06-04 03:40:17 [INFO]: Epoch 044 - training loss: 0.1327, validation loss: 2.5806
2024-06-04 03:40:28 [INFO]: Epoch 045 - training loss: 0.1311, validation loss: 2.5755
2024-06-04 03:40:38 [INFO]: Epoch 046 - training loss: 0.1317, validation loss: 2.5709
2024-06-04 03:40:49 [INFO]: Epoch 047 - training loss: 0.1303, validation loss: 2.5704
2024-06-04 03:40:59 [INFO]: Epoch 048 - training loss: 0.1292, validation loss: 2.5629
2024-06-04 03:41:10 [INFO]: Epoch 049 - training loss: 0.1287, validation loss: 2.5551
2024-06-04 03:41:20 [INFO]: Epoch 050 - training loss: 0.1282, validation loss: 2.5593
2024-06-04 03:41:31 [INFO]: Epoch 051 - training loss: 0.1280, validation loss: 2.5554
2024-06-04 03:41:42 [INFO]: Epoch 052 - training loss: 0.1274, validation loss: 2.5495
2024-06-04 03:41:52 [INFO]: Epoch 053 - training loss: 0.1269, validation loss: 2.5460
2024-06-04 03:42:03 [INFO]: Epoch 054 - training loss: 0.1268, validation loss: 2.5469
2024-06-04 03:42:14 [INFO]: Epoch 055 - training loss: 0.1261, validation loss: 2.5361
2024-06-04 03:42:24 [INFO]: Epoch 056 - training loss: 0.1257, validation loss: 2.5355
2024-06-04 03:42:33 [INFO]: Epoch 057 - training loss: 0.1247, validation loss: 2.5368
2024-06-04 03:42:43 [INFO]: Epoch 058 - training loss: 0.1243, validation loss: 2.5324
2024-06-04 03:42:52 [INFO]: Epoch 059 - training loss: 0.1239, validation loss: 2.5301
2024-06-04 03:43:03 [INFO]: Epoch 060 - training loss: 0.1240, validation loss: 2.5240
2024-06-04 03:43:14 [INFO]: Epoch 061 - training loss: 0.1231, validation loss: 2.5168
2024-06-04 03:43:24 [INFO]: Epoch 062 - training loss: 0.1230, validation loss: 2.5102
2024-06-04 03:43:35 [INFO]: Epoch 063 - training loss: 0.1228, validation loss: 2.5065
2024-06-04 03:43:46 [INFO]: Epoch 064 - training loss: 0.1218, validation loss: 2.5082
2024-06-04 03:43:57 [INFO]: Epoch 065 - training loss: 0.1224, validation loss: 2.5062
2024-06-04 03:44:08 [INFO]: Epoch 066 - training loss: 0.1215, validation loss: 2.5019
2024-06-04 03:44:18 [INFO]: Epoch 067 - training loss: 0.1211, validation loss: 2.4984
2024-06-04 03:44:27 [INFO]: Epoch 068 - training loss: 0.1209, validation loss: 2.4962
2024-06-04 03:44:38 [INFO]: Epoch 069 - training loss: 0.1206, validation loss: 2.4863
2024-06-04 03:44:48 [INFO]: Epoch 070 - training loss: 0.1201, validation loss: 2.4871
2024-06-04 03:44:59 [INFO]: Epoch 071 - training loss: 0.1199, validation loss: 2.4838
2024-06-04 03:45:10 [INFO]: Epoch 072 - training loss: 0.1192, validation loss: 2.4857
2024-06-04 03:45:21 [INFO]: Epoch 073 - training loss: 0.1190, validation loss: 2.4817
2024-06-04 03:45:31 [INFO]: Epoch 074 - training loss: 0.1187, validation loss: 2.4802
2024-06-04 03:45:42 [INFO]: Epoch 075 - training loss: 0.1186, validation loss: 2.4757
2024-06-04 03:45:53 [INFO]: Epoch 076 - training loss: 0.1182, validation loss: 2.4672
2024-06-04 03:46:03 [INFO]: Epoch 077 - training loss: 0.1181, validation loss: 2.4701
2024-06-04 03:46:14 [INFO]: Epoch 078 - training loss: 0.1176, validation loss: 2.4635
2024-06-04 03:46:24 [INFO]: Epoch 079 - training loss: 0.1172, validation loss: 2.4618
2024-06-04 03:46:35 [INFO]: Epoch 080 - training loss: 0.1164, validation loss: 2.4595
2024-06-04 03:46:46 [INFO]: Epoch 081 - training loss: 0.1164, validation loss: 2.4590
2024-06-04 03:46:56 [INFO]: Epoch 082 - training loss: 0.1164, validation loss: 2.4499
2024-06-04 03:47:07 [INFO]: Epoch 083 - training loss: 0.1165, validation loss: 2.4582
2024-06-04 03:47:18 [INFO]: Epoch 084 - training loss: 0.1165, validation loss: 2.4519
2024-06-04 03:47:28 [INFO]: Epoch 085 - training loss: 0.1160, validation loss: 2.4485
2024-06-04 03:47:39 [INFO]: Epoch 086 - training loss: 0.1153, validation loss: 2.4373
2024-06-04 03:47:50 [INFO]: Epoch 087 - training loss: 0.1155, validation loss: 2.4443
2024-06-04 03:48:00 [INFO]: Epoch 088 - training loss: 0.1146, validation loss: 2.4398
2024-06-04 03:48:11 [INFO]: Epoch 089 - training loss: 0.1148, validation loss: 2.4335
2024-06-04 03:48:22 [INFO]: Epoch 090 - training loss: 0.1146, validation loss: 2.4348
2024-06-04 03:48:32 [INFO]: Epoch 091 - training loss: 0.1142, validation loss: 2.4331
2024-06-04 03:48:42 [INFO]: Epoch 092 - training loss: 0.1139, validation loss: 2.4334
2024-06-04 03:48:53 [INFO]: Epoch 093 - training loss: 0.1134, validation loss: 2.4378
2024-06-04 03:49:04 [INFO]: Epoch 094 - training loss: 0.1136, validation loss: 2.4272
2024-06-04 03:49:14 [INFO]: Epoch 095 - training loss: 0.1135, validation loss: 2.4237
2024-06-04 03:49:25 [INFO]: Epoch 096 - training loss: 0.1130, validation loss: 2.4183
2024-06-04 03:49:35 [INFO]: Epoch 097 - training loss: 0.1131, validation loss: 2.4230
2024-06-04 03:49:46 [INFO]: Epoch 098 - training loss: 0.1124, validation loss: 2.4177
2024-06-04 03:49:57 [INFO]: Epoch 099 - training loss: 0.1115, validation loss: 2.4194
2024-06-04 03:50:08 [INFO]: Epoch 100 - training loss: 0.1124, validation loss: 2.4132
2024-06-04 03:50:08 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 03:50:08 [INFO]: Saved the model to results_point_rate05/Electricity/TimesNet_Electricity/round_2/20240604_T033157/TimesNet.pypots
2024-06-04 03:50:16 [INFO]: Successfully saved to results_point_rate05/Electricity/TimesNet_Electricity/round_2/imputation.pkl
2024-06-04 03:50:16 [INFO]: Round2 - TimesNet on Electricity: MAE=1.1145, MSE=2.6478, MRE=0.5967
2024-06-04 03:50:16 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:50:16 [INFO]: Using the given device: cuda:0
2024-06-04 03:50:16 [INFO]: Model files will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_3/20240604_T035016
2024-06-04 03:50:16 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_3/20240604_T035016/tensorboard
2024-06-04 03:50:18 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-04 03:50:29 [INFO]: Epoch 001 - training loss: 0.6385, validation loss: 3.2417
2024-06-04 03:50:39 [INFO]: Epoch 002 - training loss: 0.3107, validation loss: 3.0442
2024-06-04 03:50:50 [INFO]: Epoch 003 - training loss: 0.2542, validation loss: 2.9485
2024-06-04 03:51:00 [INFO]: Epoch 004 - training loss: 0.2335, validation loss: 2.8869
2024-06-04 03:51:11 [INFO]: Epoch 005 - training loss: 0.2201, validation loss: 2.8569
2024-06-04 03:51:22 [INFO]: Epoch 006 - training loss: 0.2111, validation loss: 2.8263
2024-06-04 03:51:33 [INFO]: Epoch 007 - training loss: 0.2035, validation loss: 2.7982
2024-06-04 03:51:43 [INFO]: Epoch 008 - training loss: 0.1958, validation loss: 2.7878
2024-06-04 03:51:54 [INFO]: Epoch 009 - training loss: 0.1913, validation loss: 2.7677
2024-06-04 03:52:05 [INFO]: Epoch 010 - training loss: 0.1854, validation loss: 2.7633
2024-06-04 03:52:15 [INFO]: Epoch 011 - training loss: 0.1809, validation loss: 2.7562
2024-06-04 03:52:26 [INFO]: Epoch 012 - training loss: 0.1773, validation loss: 2.7464
2024-06-04 03:52:36 [INFO]: Epoch 013 - training loss: 0.1745, validation loss: 2.7401
2024-06-04 03:52:47 [INFO]: Epoch 014 - training loss: 0.1701, validation loss: 2.7318
2024-06-04 03:52:58 [INFO]: Epoch 015 - training loss: 0.1680, validation loss: 2.7289
2024-06-04 03:53:08 [INFO]: Epoch 016 - training loss: 0.1651, validation loss: 2.7203
2024-06-04 03:53:19 [INFO]: Epoch 017 - training loss: 0.1629, validation loss: 2.7219
2024-06-04 03:53:30 [INFO]: Epoch 018 - training loss: 0.1615, validation loss: 2.7104
2024-06-04 03:53:41 [INFO]: Epoch 019 - training loss: 0.1596, validation loss: 2.6966
2024-06-04 03:53:51 [INFO]: Epoch 020 - training loss: 0.1577, validation loss: 2.6904
2024-06-04 03:54:02 [INFO]: Epoch 021 - training loss: 0.1563, validation loss: 2.6880
2024-06-04 03:54:13 [INFO]: Epoch 022 - training loss: 0.1539, validation loss: 2.6780
2024-06-04 03:54:23 [INFO]: Epoch 023 - training loss: 0.1523, validation loss: 2.6670
2024-06-04 03:54:34 [INFO]: Epoch 024 - training loss: 0.1515, validation loss: 2.6665
2024-06-04 03:54:44 [INFO]: Epoch 025 - training loss: 0.1503, validation loss: 2.6554
2024-06-04 03:54:55 [INFO]: Epoch 026 - training loss: 0.1492, validation loss: 2.6515
2024-06-04 03:55:06 [INFO]: Epoch 027 - training loss: 0.1474, validation loss: 2.6440
2024-06-04 03:55:17 [INFO]: Epoch 028 - training loss: 0.1466, validation loss: 2.6384
2024-06-04 03:55:27 [INFO]: Epoch 029 - training loss: 0.1452, validation loss: 2.6293
2024-06-04 03:55:38 [INFO]: Epoch 030 - training loss: 0.1438, validation loss: 2.6312
2024-06-04 03:55:48 [INFO]: Epoch 031 - training loss: 0.1430, validation loss: 2.6151
2024-06-04 03:55:59 [INFO]: Epoch 032 - training loss: 0.1418, validation loss: 2.6157
2024-06-04 03:56:10 [INFO]: Epoch 033 - training loss: 0.1401, validation loss: 2.6121
2024-06-04 03:56:20 [INFO]: Epoch 034 - training loss: 0.1402, validation loss: 2.6052
2024-06-04 03:56:31 [INFO]: Epoch 035 - training loss: 0.1393, validation loss: 2.6023
2024-06-04 03:56:41 [INFO]: Epoch 036 - training loss: 0.1385, validation loss: 2.6001
2024-06-04 03:56:52 [INFO]: Epoch 037 - training loss: 0.1369, validation loss: 2.5944
2024-06-04 03:57:03 [INFO]: Epoch 038 - training loss: 0.1365, validation loss: 2.5844
2024-06-04 03:57:13 [INFO]: Epoch 039 - training loss: 0.1357, validation loss: 2.5826
2024-06-04 03:57:24 [INFO]: Epoch 040 - training loss: 0.1346, validation loss: 2.5746
2024-06-04 03:57:35 [INFO]: Epoch 041 - training loss: 0.1338, validation loss: 2.5811
2024-06-04 03:57:45 [INFO]: Epoch 042 - training loss: 0.1339, validation loss: 2.5788
2024-06-04 03:57:56 [INFO]: Epoch 043 - training loss: 0.1326, validation loss: 2.5648
2024-06-04 03:58:07 [INFO]: Epoch 044 - training loss: 0.1321, validation loss: 2.5605
2024-06-04 03:58:17 [INFO]: Epoch 045 - training loss: 0.1319, validation loss: 2.5541
2024-06-04 03:58:28 [INFO]: Epoch 046 - training loss: 0.1313, validation loss: 2.5485
2024-06-04 03:58:39 [INFO]: Epoch 047 - training loss: 0.1305, validation loss: 2.5477
2024-06-04 03:58:49 [INFO]: Epoch 048 - training loss: 0.1294, validation loss: 2.5445
2024-06-04 03:59:00 [INFO]: Epoch 049 - training loss: 0.1294, validation loss: 2.5317
2024-06-04 03:59:11 [INFO]: Epoch 050 - training loss: 0.1284, validation loss: 2.5356
2024-06-04 03:59:21 [INFO]: Epoch 051 - training loss: 0.1282, validation loss: 2.5285
2024-06-04 03:59:32 [INFO]: Epoch 052 - training loss: 0.1275, validation loss: 2.5264
2024-06-04 03:59:43 [INFO]: Epoch 053 - training loss: 0.1276, validation loss: 2.5156
2024-06-04 03:59:53 [INFO]: Epoch 054 - training loss: 0.1264, validation loss: 2.5167
2024-06-04 04:00:04 [INFO]: Epoch 055 - training loss: 0.1262, validation loss: 2.5135
2024-06-04 04:00:15 [INFO]: Epoch 056 - training loss: 0.1255, validation loss: 2.5119
2024-06-04 04:00:25 [INFO]: Epoch 057 - training loss: 0.1246, validation loss: 2.5034
2024-06-04 04:00:36 [INFO]: Epoch 058 - training loss: 0.1243, validation loss: 2.4999
2024-06-04 04:00:46 [INFO]: Epoch 059 - training loss: 0.1237, validation loss: 2.4917
2024-06-04 04:00:56 [INFO]: Epoch 060 - training loss: 0.1234, validation loss: 2.4897
2024-06-04 04:01:07 [INFO]: Epoch 061 - training loss: 0.1225, validation loss: 2.4877
2024-06-04 04:01:17 [INFO]: Epoch 062 - training loss: 0.1225, validation loss: 2.4892
2024-06-04 04:01:28 [INFO]: Epoch 063 - training loss: 0.1220, validation loss: 2.4891
2024-06-04 04:01:39 [INFO]: Epoch 064 - training loss: 0.1224, validation loss: 2.4796
2024-06-04 04:01:49 [INFO]: Epoch 065 - training loss: 0.1217, validation loss: 2.4767
2024-06-04 04:02:00 [INFO]: Epoch 066 - training loss: 0.1213, validation loss: 2.4680
2024-06-04 04:02:11 [INFO]: Epoch 067 - training loss: 0.1211, validation loss: 2.4636
2024-06-04 04:02:21 [INFO]: Epoch 068 - training loss: 0.1206, validation loss: 2.4621
2024-06-04 04:02:32 [INFO]: Epoch 069 - training loss: 0.1204, validation loss: 2.4578
2024-06-04 04:02:42 [INFO]: Epoch 070 - training loss: 0.1194, validation loss: 2.4500
2024-06-04 04:02:53 [INFO]: Epoch 071 - training loss: 0.1186, validation loss: 2.4533
2024-06-04 04:03:04 [INFO]: Epoch 072 - training loss: 0.1193, validation loss: 2.4505
2024-06-04 04:03:14 [INFO]: Epoch 073 - training loss: 0.1189, validation loss: 2.4434
2024-06-04 04:03:25 [INFO]: Epoch 074 - training loss: 0.1185, validation loss: 2.4424
2024-06-04 04:03:35 [INFO]: Epoch 075 - training loss: 0.1185, validation loss: 2.4448
2024-06-04 04:03:46 [INFO]: Epoch 076 - training loss: 0.1178, validation loss: 2.4337
2024-06-04 04:03:57 [INFO]: Epoch 077 - training loss: 0.1174, validation loss: 2.4400
2024-06-04 04:04:08 [INFO]: Epoch 078 - training loss: 0.1172, validation loss: 2.4335
2024-06-04 04:04:19 [INFO]: Epoch 079 - training loss: 0.1170, validation loss: 2.4318
2024-06-04 04:04:29 [INFO]: Epoch 080 - training loss: 0.1164, validation loss: 2.4353
2024-06-04 04:04:40 [INFO]: Epoch 081 - training loss: 0.1171, validation loss: 2.4240
2024-06-04 04:04:50 [INFO]: Epoch 082 - training loss: 0.1171, validation loss: 2.4270
2024-06-04 04:05:01 [INFO]: Epoch 083 - training loss: 0.1163, validation loss: 2.4227
2024-06-04 04:05:11 [INFO]: Epoch 084 - training loss: 0.1164, validation loss: 2.4095
2024-06-04 04:05:22 [INFO]: Epoch 085 - training loss: 0.1154, validation loss: 2.4098
2024-06-04 04:05:32 [INFO]: Epoch 086 - training loss: 0.1152, validation loss: 2.4091
2024-06-04 04:05:43 [INFO]: Epoch 087 - training loss: 0.1153, validation loss: 2.4102
2024-06-04 04:05:53 [INFO]: Epoch 088 - training loss: 0.1154, validation loss: 2.3990
2024-06-04 04:06:04 [INFO]: Epoch 089 - training loss: 0.1153, validation loss: 2.4034
2024-06-04 04:06:14 [INFO]: Epoch 090 - training loss: 0.1140, validation loss: 2.4070
2024-06-04 04:06:25 [INFO]: Epoch 091 - training loss: 0.1141, validation loss: 2.4027
2024-06-04 04:06:36 [INFO]: Epoch 092 - training loss: 0.1143, validation loss: 2.3968
2024-06-04 04:06:46 [INFO]: Epoch 093 - training loss: 0.1140, validation loss: 2.3994
2024-06-04 04:06:57 [INFO]: Epoch 094 - training loss: 0.1133, validation loss: 2.3887
2024-06-04 04:07:07 [INFO]: Epoch 095 - training loss: 0.1135, validation loss: 2.3872
2024-06-04 04:07:18 [INFO]: Epoch 096 - training loss: 0.1129, validation loss: 2.3945
2024-06-04 04:07:27 [INFO]: Epoch 097 - training loss: 0.1132, validation loss: 2.3843
2024-06-04 04:07:37 [INFO]: Epoch 098 - training loss: 0.1125, validation loss: 2.3804
2024-06-04 04:07:47 [INFO]: Epoch 099 - training loss: 0.1127, validation loss: 2.3792
2024-06-04 04:07:58 [INFO]: Epoch 100 - training loss: 0.1118, validation loss: 2.3757
2024-06-04 04:07:58 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 04:07:59 [INFO]: Saved the model to results_point_rate05/Electricity/TimesNet_Electricity/round_3/20240604_T035016/TimesNet.pypots
2024-06-04 04:08:06 [INFO]: Successfully saved to results_point_rate05/Electricity/TimesNet_Electricity/round_3/imputation.pkl
2024-06-04 04:08:06 [INFO]: Round3 - TimesNet on Electricity: MAE=1.1261, MSE=2.5594, MRE=0.6029
2024-06-04 04:08:06 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:08:06 [INFO]: Using the given device: cuda:0
2024-06-04 04:08:06 [INFO]: Model files will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_4/20240604_T040806
2024-06-04 04:08:06 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/TimesNet_Electricity/round_4/20240604_T040806/tensorboard
2024-06-04 04:08:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 45,569,394
2024-06-04 04:08:19 [INFO]: Epoch 001 - training loss: 0.6430, validation loss: 3.2935
2024-06-04 04:08:30 [INFO]: Epoch 002 - training loss: 0.3152, validation loss: 3.0791
2024-06-04 04:08:40 [INFO]: Epoch 003 - training loss: 0.2580, validation loss: 2.9813
2024-06-04 04:08:51 [INFO]: Epoch 004 - training loss: 0.2366, validation loss: 2.9084
2024-06-04 04:09:02 [INFO]: Epoch 005 - training loss: 0.2206, validation loss: 2.8593
2024-06-04 04:09:12 [INFO]: Epoch 006 - training loss: 0.2092, validation loss: 2.8424
2024-06-04 04:09:22 [INFO]: Epoch 007 - training loss: 0.2005, validation loss: 2.8048
2024-06-04 04:09:33 [INFO]: Epoch 008 - training loss: 0.1940, validation loss: 2.7819
2024-06-04 04:09:44 [INFO]: Epoch 009 - training loss: 0.1890, validation loss: 2.7731
2024-06-04 04:09:54 [INFO]: Epoch 010 - training loss: 0.1841, validation loss: 2.7531
2024-06-04 04:10:04 [INFO]: Epoch 011 - training loss: 0.1809, validation loss: 2.7420
2024-06-04 04:10:15 [INFO]: Epoch 012 - training loss: 0.1760, validation loss: 2.7338
2024-06-04 04:10:26 [INFO]: Epoch 013 - training loss: 0.1732, validation loss: 2.7230
2024-06-04 04:10:37 [INFO]: Epoch 014 - training loss: 0.1702, validation loss: 2.7129
2024-06-04 04:10:47 [INFO]: Epoch 015 - training loss: 0.1677, validation loss: 2.7031
2024-06-04 04:10:58 [INFO]: Epoch 016 - training loss: 0.1648, validation loss: 2.6949
2024-06-04 04:11:08 [INFO]: Epoch 017 - training loss: 0.1629, validation loss: 2.6868
2024-06-04 04:11:19 [INFO]: Epoch 018 - training loss: 0.1613, validation loss: 2.6878
2024-06-04 04:11:29 [INFO]: Epoch 019 - training loss: 0.1597, validation loss: 2.6756
2024-06-04 04:11:40 [INFO]: Epoch 020 - training loss: 0.1568, validation loss: 2.6723
2024-06-04 04:11:51 [INFO]: Epoch 021 - training loss: 0.1549, validation loss: 2.6636
2024-06-04 04:12:01 [INFO]: Epoch 022 - training loss: 0.1540, validation loss: 2.6577
2024-06-04 04:12:12 [INFO]: Epoch 023 - training loss: 0.1519, validation loss: 2.6579
2024-06-04 04:12:22 [INFO]: Epoch 024 - training loss: 0.1505, validation loss: 2.6497
2024-06-04 04:12:33 [INFO]: Epoch 025 - training loss: 0.1496, validation loss: 2.6459
2024-06-04 04:12:43 [INFO]: Epoch 026 - training loss: 0.1480, validation loss: 2.6407
2024-06-04 04:12:54 [INFO]: Epoch 027 - training loss: 0.1466, validation loss: 2.6393
2024-06-04 04:13:05 [INFO]: Epoch 028 - training loss: 0.1460, validation loss: 2.6339
2024-06-04 04:13:15 [INFO]: Epoch 029 - training loss: 0.1443, validation loss: 2.6343
2024-06-04 04:13:26 [INFO]: Epoch 030 - training loss: 0.1433, validation loss: 2.6328
2024-06-04 04:13:36 [INFO]: Epoch 031 - training loss: 0.1422, validation loss: 2.6343
2024-06-04 04:13:47 [INFO]: Epoch 032 - training loss: 0.1414, validation loss: 2.6278
2024-06-04 04:13:58 [INFO]: Epoch 033 - training loss: 0.1408, validation loss: 2.6202
2024-06-04 04:14:08 [INFO]: Epoch 034 - training loss: 0.1394, validation loss: 2.6123
2024-06-04 04:14:19 [INFO]: Epoch 035 - training loss: 0.1385, validation loss: 2.6126
2024-06-04 04:14:29 [INFO]: Epoch 036 - training loss: 0.1378, validation loss: 2.6016
2024-06-04 04:14:40 [INFO]: Epoch 037 - training loss: 0.1368, validation loss: 2.6025
2024-06-04 04:14:51 [INFO]: Epoch 038 - training loss: 0.1363, validation loss: 2.5988
2024-06-04 04:15:01 [INFO]: Epoch 039 - training loss: 0.1350, validation loss: 2.5895
2024-06-04 04:15:12 [INFO]: Epoch 040 - training loss: 0.1345, validation loss: 2.5840
2024-06-04 04:15:23 [INFO]: Epoch 041 - training loss: 0.1340, validation loss: 2.5804
2024-06-04 04:15:33 [INFO]: Epoch 042 - training loss: 0.1337, validation loss: 2.5804
2024-06-04 04:15:44 [INFO]: Epoch 043 - training loss: 0.1332, validation loss: 2.5762
2024-06-04 04:15:54 [INFO]: Epoch 044 - training loss: 0.1327, validation loss: 2.5692
2024-06-04 04:16:05 [INFO]: Epoch 045 - training loss: 0.1309, validation loss: 2.5605
2024-06-04 04:16:16 [INFO]: Epoch 046 - training loss: 0.1309, validation loss: 2.5562
2024-06-04 04:16:26 [INFO]: Epoch 047 - training loss: 0.1302, validation loss: 2.5537
2024-06-04 04:16:35 [INFO]: Epoch 048 - training loss: 0.1288, validation loss: 2.5473
2024-06-04 04:16:45 [INFO]: Epoch 049 - training loss: 0.1286, validation loss: 2.5486
2024-06-04 04:16:54 [INFO]: Epoch 050 - training loss: 0.1281, validation loss: 2.5486
2024-06-04 04:17:05 [INFO]: Epoch 051 - training loss: 0.1279, validation loss: 2.5410
2024-06-04 04:17:16 [INFO]: Epoch 052 - training loss: 0.1273, validation loss: 2.5367
2024-06-04 04:17:27 [INFO]: Epoch 053 - training loss: 0.1266, validation loss: 2.5358
2024-06-04 04:17:37 [INFO]: Epoch 054 - training loss: 0.1264, validation loss: 2.5293
2024-06-04 04:17:48 [INFO]: Epoch 055 - training loss: 0.1255, validation loss: 2.5247
2024-06-04 04:17:58 [INFO]: Epoch 056 - training loss: 0.1255, validation loss: 2.5218
2024-06-04 04:18:09 [INFO]: Epoch 057 - training loss: 0.1249, validation loss: 2.5255
2024-06-04 04:18:20 [INFO]: Epoch 058 - training loss: 0.1242, validation loss: 2.5191
2024-06-04 04:18:31 [INFO]: Epoch 059 - training loss: 0.1239, validation loss: 2.5132
2024-06-04 04:18:42 [INFO]: Epoch 060 - training loss: 0.1236, validation loss: 2.5128
2024-06-04 04:18:52 [INFO]: Epoch 061 - training loss: 0.1233, validation loss: 2.5025
2024-06-04 04:19:02 [INFO]: Epoch 062 - training loss: 0.1226, validation loss: 2.5082
2024-06-04 04:19:13 [INFO]: Epoch 063 - training loss: 0.1220, validation loss: 2.5015
2024-06-04 04:19:24 [INFO]: Epoch 064 - training loss: 0.1219, validation loss: 2.5033
2024-06-04 04:19:35 [INFO]: Epoch 065 - training loss: 0.1210, validation loss: 2.4914
2024-06-04 04:19:45 [INFO]: Epoch 066 - training loss: 0.1219, validation loss: 2.4959
2024-06-04 04:19:56 [INFO]: Epoch 067 - training loss: 0.1201, validation loss: 2.4896
2024-06-04 04:20:06 [INFO]: Epoch 068 - training loss: 0.1201, validation loss: 2.4864
2024-06-04 04:20:17 [INFO]: Epoch 069 - training loss: 0.1201, validation loss: 2.4794
2024-06-04 04:20:28 [INFO]: Epoch 070 - training loss: 0.1197, validation loss: 2.4776
2024-06-04 04:20:38 [INFO]: Epoch 071 - training loss: 0.1196, validation loss: 2.4717
2024-06-04 04:20:49 [INFO]: Epoch 072 - training loss: 0.1184, validation loss: 2.4726
2024-06-04 04:21:00 [INFO]: Epoch 073 - training loss: 0.1186, validation loss: 2.4707
2024-06-04 04:21:11 [INFO]: Epoch 074 - training loss: 0.1190, validation loss: 2.4629
2024-06-04 04:21:21 [INFO]: Epoch 075 - training loss: 0.1181, validation loss: 2.4658
2024-06-04 04:21:32 [INFO]: Epoch 076 - training loss: 0.1181, validation loss: 2.4631
2024-06-04 04:21:43 [INFO]: Epoch 077 - training loss: 0.1176, validation loss: 2.4558
2024-06-04 04:21:53 [INFO]: Epoch 078 - training loss: 0.1176, validation loss: 2.4527
2024-06-04 04:22:04 [INFO]: Epoch 079 - training loss: 0.1171, validation loss: 2.4554
2024-06-04 04:22:15 [INFO]: Epoch 080 - training loss: 0.1174, validation loss: 2.4477
2024-06-04 04:22:26 [INFO]: Epoch 081 - training loss: 0.1169, validation loss: 2.4458
2024-06-04 04:22:37 [INFO]: Epoch 082 - training loss: 0.1164, validation loss: 2.4445
2024-06-04 04:22:47 [INFO]: Epoch 083 - training loss: 0.1159, validation loss: 2.4388
2024-06-04 04:22:58 [INFO]: Epoch 084 - training loss: 0.1159, validation loss: 2.4361
2024-06-04 04:23:09 [INFO]: Epoch 085 - training loss: 0.1155, validation loss: 2.4342
2024-06-04 04:23:19 [INFO]: Epoch 086 - training loss: 0.1155, validation loss: 2.4297
2024-06-04 04:23:30 [INFO]: Epoch 087 - training loss: 0.1147, validation loss: 2.4370
2024-06-04 04:23:41 [INFO]: Epoch 088 - training loss: 0.1143, validation loss: 2.4313
2024-06-04 04:23:51 [INFO]: Epoch 089 - training loss: 0.1147, validation loss: 2.4249
2024-06-04 04:24:02 [INFO]: Epoch 090 - training loss: 0.1139, validation loss: 2.4258
2024-06-04 04:24:12 [INFO]: Epoch 091 - training loss: 0.1140, validation loss: 2.4180
2024-06-04 04:24:23 [INFO]: Epoch 092 - training loss: 0.1135, validation loss: 2.4230
2024-06-04 04:24:34 [INFO]: Epoch 093 - training loss: 0.1131, validation loss: 2.4195
2024-06-04 04:24:44 [INFO]: Epoch 094 - training loss: 0.1136, validation loss: 2.4120
2024-06-04 04:24:55 [INFO]: Epoch 095 - training loss: 0.1141, validation loss: 2.4109
2024-06-04 04:25:06 [INFO]: Epoch 096 - training loss: 0.1130, validation loss: 2.4078
2024-06-04 04:25:16 [INFO]: Epoch 097 - training loss: 0.1132, validation loss: 2.4030
2024-06-04 04:25:27 [INFO]: Epoch 098 - training loss: 0.1126, validation loss: 2.4015
2024-06-04 04:25:38 [INFO]: Epoch 099 - training loss: 0.1121, validation loss: 2.4036
2024-06-04 04:25:48 [INFO]: Epoch 100 - training loss: 0.1121, validation loss: 2.3965
2024-06-04 04:25:48 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 04:25:49 [INFO]: Saved the model to results_point_rate05/Electricity/TimesNet_Electricity/round_4/20240604_T040806/TimesNet.pypots
2024-06-04 04:25:56 [INFO]: Successfully saved to results_point_rate05/Electricity/TimesNet_Electricity/round_4/imputation.pkl
2024-06-04 04:25:56 [INFO]: Round4 - TimesNet on Electricity: MAE=1.1402, MSE=2.6569, MRE=0.6105
2024-06-04 04:25:56 [INFO]: Done! Final results:
Averaged TimesNet (45,569,394 params) on Electricity: MAE=1.1315 ± 0.017470504822531707, MSE=2.6436 ± 0.07662053822483876, MRE=0.6058 ± 0.00935382375812686, average inference time=1.59
