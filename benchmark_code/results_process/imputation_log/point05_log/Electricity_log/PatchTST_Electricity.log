2024-06-04 02:59:05 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:05 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:05 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=4, d_k=128
2024-06-04 02:59:05 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (4) * d_k (128)
2024-06-04 02:59:06 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 4,419,410
2024-06-04 03:00:00 [INFO]: Epoch 001 - training loss: 1.2843, validation loss: 3.5081
2024-06-04 03:01:01 [INFO]: Epoch 002 - training loss: 0.8829, validation loss: 3.1528
2024-06-04 03:02:01 [INFO]: Epoch 003 - training loss: 0.7268, validation loss: 3.0041
2024-06-04 03:03:03 [INFO]: Epoch 004 - training loss: 0.6716, validation loss: 2.8623
2024-06-04 03:04:03 [INFO]: Epoch 005 - training loss: 0.6416, validation loss: 2.7695
2024-06-04 03:05:04 [INFO]: Epoch 006 - training loss: 0.6183, validation loss: 2.6776
2024-06-04 03:06:05 [INFO]: Epoch 007 - training loss: 0.6005, validation loss: 2.5927
2024-06-04 03:07:07 [INFO]: Epoch 008 - training loss: 0.5849, validation loss: 2.5149
2024-06-04 03:08:08 [INFO]: Epoch 009 - training loss: 0.5727, validation loss: 2.4522
2024-06-04 03:09:09 [INFO]: Epoch 010 - training loss: 0.5608, validation loss: 2.3897
2024-06-04 03:10:10 [INFO]: Epoch 011 - training loss: 0.5505, validation loss: 2.3557
2024-06-04 03:11:04 [INFO]: Epoch 012 - training loss: 0.5416, validation loss: 2.3081
2024-06-04 03:11:59 [INFO]: Epoch 013 - training loss: 0.5333, validation loss: 2.2732
2024-06-04 03:12:53 [INFO]: Epoch 014 - training loss: 0.5270, validation loss: 2.2442
2024-06-04 03:13:48 [INFO]: Epoch 015 - training loss: 0.5190, validation loss: 2.2136
2024-06-04 03:14:43 [INFO]: Epoch 016 - training loss: 0.5132, validation loss: 2.1744
2024-06-04 03:15:37 [INFO]: Epoch 017 - training loss: 0.5092, validation loss: 2.1575
2024-06-04 03:16:31 [INFO]: Epoch 018 - training loss: 0.5026, validation loss: 2.1256
2024-06-04 03:17:25 [INFO]: Epoch 019 - training loss: 0.4999, validation loss: 2.0995
2024-06-04 03:18:20 [INFO]: Epoch 020 - training loss: 0.4950, validation loss: 2.0761
2024-06-04 03:19:14 [INFO]: Epoch 021 - training loss: 0.4900, validation loss: 2.0640
2024-06-04 03:20:07 [INFO]: Epoch 022 - training loss: 0.4862, validation loss: 2.0389
2024-06-04 03:21:02 [INFO]: Epoch 023 - training loss: 0.4829, validation loss: 2.0231
2024-06-04 03:21:56 [INFO]: Epoch 024 - training loss: 0.4802, validation loss: 2.0048
2024-06-04 03:22:51 [INFO]: Epoch 025 - training loss: 0.4770, validation loss: 1.9885
2024-06-04 03:23:45 [INFO]: Epoch 026 - training loss: 0.4741, validation loss: 1.9702
2024-06-04 03:24:40 [INFO]: Epoch 027 - training loss: 0.4706, validation loss: 1.9605
2024-06-04 03:25:34 [INFO]: Epoch 028 - training loss: 0.4673, validation loss: 1.9442
2024-06-04 03:26:29 [INFO]: Epoch 029 - training loss: 0.4655, validation loss: 1.9345
2024-06-04 03:27:23 [INFO]: Epoch 030 - training loss: 0.4646, validation loss: 1.9309
2024-06-04 03:28:18 [INFO]: Epoch 031 - training loss: 0.4622, validation loss: 1.9091
2024-06-04 03:29:12 [INFO]: Epoch 032 - training loss: 0.4596, validation loss: 1.9036
2024-06-04 03:30:07 [INFO]: Epoch 033 - training loss: 0.4575, validation loss: 1.8892
2024-06-04 03:31:01 [INFO]: Epoch 034 - training loss: 0.4549, validation loss: 1.8756
2024-06-04 03:31:56 [INFO]: Epoch 035 - training loss: 0.4530, validation loss: 1.8774
2024-06-04 03:32:51 [INFO]: Epoch 036 - training loss: 0.4511, validation loss: 1.8695
2024-06-04 03:33:45 [INFO]: Epoch 037 - training loss: 0.4493, validation loss: 1.8494
2024-06-04 03:34:39 [INFO]: Epoch 038 - training loss: 0.4479, validation loss: 1.8542
2024-06-04 03:35:34 [INFO]: Epoch 039 - training loss: 0.4460, validation loss: 1.8388
2024-06-04 03:36:28 [INFO]: Epoch 040 - training loss: 0.4444, validation loss: 1.8296
2024-06-04 03:37:22 [INFO]: Epoch 041 - training loss: 0.4429, validation loss: 1.8166
2024-06-04 03:38:17 [INFO]: Epoch 042 - training loss: 0.4416, validation loss: 1.8140
2024-06-04 03:39:11 [INFO]: Epoch 043 - training loss: 0.4406, validation loss: 1.8125
2024-06-04 03:40:05 [INFO]: Epoch 044 - training loss: 0.4399, validation loss: 1.8033
2024-06-04 03:40:59 [INFO]: Epoch 045 - training loss: 0.4384, validation loss: 1.8058
2024-06-04 03:41:53 [INFO]: Epoch 046 - training loss: 0.4371, validation loss: 1.7979
2024-06-04 03:42:48 [INFO]: Epoch 047 - training loss: 0.4354, validation loss: 1.7922
2024-06-04 03:43:42 [INFO]: Epoch 048 - training loss: 0.4344, validation loss: 1.7782
2024-06-04 03:44:36 [INFO]: Epoch 049 - training loss: 0.4331, validation loss: 1.7742
2024-06-04 03:45:31 [INFO]: Epoch 050 - training loss: 0.4325, validation loss: 1.7729
2024-06-04 03:46:25 [INFO]: Epoch 051 - training loss: 0.4315, validation loss: 1.7829
2024-06-04 03:47:19 [INFO]: Epoch 052 - training loss: 0.4318, validation loss: 1.7706
2024-06-04 03:48:14 [INFO]: Epoch 053 - training loss: 0.4302, validation loss: 1.7807
2024-06-04 03:49:09 [INFO]: Epoch 054 - training loss: 0.4291, validation loss: 1.7610
2024-06-04 03:50:03 [INFO]: Epoch 055 - training loss: 0.4282, validation loss: 1.7555
2024-06-04 03:50:58 [INFO]: Epoch 056 - training loss: 0.4275, validation loss: 1.7660
2024-06-04 03:51:53 [INFO]: Epoch 057 - training loss: 0.4265, validation loss: 1.7714
2024-06-04 03:52:41 [INFO]: Epoch 058 - training loss: 0.4252, validation loss: 1.7625
2024-06-04 03:53:25 [INFO]: Epoch 059 - training loss: 0.4254, validation loss: 1.7563
2024-06-04 03:54:10 [INFO]: Epoch 060 - training loss: 0.4236, validation loss: 1.7431
2024-06-04 03:54:55 [INFO]: Epoch 061 - training loss: 0.4229, validation loss: 1.7516
2024-06-04 03:55:40 [INFO]: Epoch 062 - training loss: 0.4223, validation loss: 1.7499
2024-06-04 03:56:24 [INFO]: Epoch 063 - training loss: 0.4219, validation loss: 1.7490
2024-06-04 03:57:09 [INFO]: Epoch 064 - training loss: 0.4212, validation loss: 1.7534
2024-06-04 03:57:53 [INFO]: Epoch 065 - training loss: 0.4208, validation loss: 1.7571
2024-06-04 03:58:38 [INFO]: Epoch 066 - training loss: 0.4202, validation loss: 1.7570
2024-06-04 03:59:23 [INFO]: Epoch 067 - training loss: 0.4197, validation loss: 1.7390
2024-06-04 04:00:08 [INFO]: Epoch 068 - training loss: 0.4189, validation loss: 1.7560
2024-06-04 04:00:52 [INFO]: Epoch 069 - training loss: 0.4188, validation loss: 1.7582
2024-06-04 04:01:37 [INFO]: Epoch 070 - training loss: 0.4177, validation loss: 1.7546
2024-06-04 04:02:22 [INFO]: Epoch 071 - training loss: 0.4172, validation loss: 1.7472
2024-06-04 04:03:06 [INFO]: Epoch 072 - training loss: 0.4167, validation loss: 1.7529
2024-06-04 04:03:51 [INFO]: Epoch 073 - training loss: 0.4164, validation loss: 1.7433
2024-06-04 04:04:36 [INFO]: Epoch 074 - training loss: 0.4159, validation loss: 1.7349
2024-06-04 04:05:20 [INFO]: Epoch 075 - training loss: 0.4151, validation loss: 1.7441
2024-06-04 04:06:05 [INFO]: Epoch 076 - training loss: 0.4144, validation loss: 1.7486
2024-06-04 04:06:46 [INFO]: Epoch 077 - training loss: 0.4143, validation loss: 1.7414
2024-06-04 04:07:25 [INFO]: Epoch 078 - training loss: 0.4143, validation loss: 1.7469
2024-06-04 04:08:05 [INFO]: Epoch 079 - training loss: 0.4140, validation loss: 1.7622
2024-06-04 04:08:45 [INFO]: Epoch 080 - training loss: 0.4129, validation loss: 1.7555
2024-06-04 04:09:25 [INFO]: Epoch 081 - training loss: 0.4123, validation loss: 1.7576
2024-06-04 04:10:04 [INFO]: Epoch 082 - training loss: 0.4120, validation loss: 1.7416
2024-06-04 04:10:44 [INFO]: Epoch 083 - training loss: 0.4116, validation loss: 1.7443
2024-06-04 04:11:24 [INFO]: Epoch 084 - training loss: 0.4114, validation loss: 1.7591
2024-06-04 04:11:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:11:24 [INFO]: Finished training. The best model is from epoch#74.
2024-06-04 04:11:24 [INFO]: Saved the model to results_point_rate05/Electricity/PatchTST_Electricity/round_0/20240604_T025905/PatchTST.pypots
2024-06-04 04:11:45 [INFO]: Successfully saved to results_point_rate05/Electricity/PatchTST_Electricity/round_0/imputation.pkl
2024-06-04 04:11:45 [INFO]: Round0 - PatchTST on Electricity: MAE=0.9084, MSE=1.7353, MRE=0.4863
2024-06-04 04:11:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 04:11:45 [INFO]: Using the given device: cuda:0
2024-06-04 04:11:45 [INFO]: Model files will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_1/20240604_T041145
2024-06-04 04:11:45 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_1/20240604_T041145/tensorboard
2024-06-04 04:11:45 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=4, d_k=128
2024-06-04 04:11:45 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (4) * d_k (128)
2024-06-04 04:11:45 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 4,419,410
2024-06-04 04:12:25 [INFO]: Epoch 001 - training loss: 1.3419, validation loss: 3.7236
2024-06-04 04:13:04 [INFO]: Epoch 002 - training loss: 1.0353, validation loss: 3.6450
2024-06-04 04:13:44 [INFO]: Epoch 003 - training loss: 0.8931, validation loss: 3.4268
2024-06-04 04:14:24 [INFO]: Epoch 004 - training loss: 0.7385, validation loss: 3.1294
2024-06-04 04:15:03 [INFO]: Epoch 005 - training loss: 0.6748, validation loss: 2.9656
2024-06-04 04:15:43 [INFO]: Epoch 006 - training loss: 0.6361, validation loss: 2.8114
2024-06-04 04:16:22 [INFO]: Epoch 007 - training loss: 0.6105, validation loss: 2.7120
2024-06-04 04:17:02 [INFO]: Epoch 008 - training loss: 0.5916, validation loss: 2.6336
2024-06-04 04:17:41 [INFO]: Epoch 009 - training loss: 0.5764, validation loss: 2.5692
2024-06-04 04:18:21 [INFO]: Epoch 010 - training loss: 0.5646, validation loss: 2.5082
2024-06-04 04:19:01 [INFO]: Epoch 011 - training loss: 0.5540, validation loss: 2.4459
2024-06-04 04:19:40 [INFO]: Epoch 012 - training loss: 0.5452, validation loss: 2.4113
2024-06-04 04:20:20 [INFO]: Epoch 013 - training loss: 0.5367, validation loss: 2.3627
2024-06-04 04:20:59 [INFO]: Epoch 014 - training loss: 0.5293, validation loss: 2.3332
2024-06-04 04:21:39 [INFO]: Epoch 015 - training loss: 0.5229, validation loss: 2.3000
2024-06-04 04:22:18 [INFO]: Epoch 016 - training loss: 0.5168, validation loss: 2.2727
2024-06-04 04:22:58 [INFO]: Epoch 017 - training loss: 0.5110, validation loss: 2.2389
2024-06-04 04:23:38 [INFO]: Epoch 018 - training loss: 0.5059, validation loss: 2.2191
2024-06-04 04:24:17 [INFO]: Epoch 019 - training loss: 0.5011, validation loss: 2.1968
2024-06-04 04:24:57 [INFO]: Epoch 020 - training loss: 0.4969, validation loss: 2.1655
2024-06-04 04:25:37 [INFO]: Epoch 021 - training loss: 0.4937, validation loss: 2.1499
2024-06-04 04:26:16 [INFO]: Epoch 022 - training loss: 0.4889, validation loss: 2.1270
2024-06-04 04:26:56 [INFO]: Epoch 023 - training loss: 0.4843, validation loss: 2.1076
2024-06-04 04:27:36 [INFO]: Epoch 024 - training loss: 0.4815, validation loss: 2.0918
2024-06-04 04:28:15 [INFO]: Epoch 025 - training loss: 0.4781, validation loss: 2.0694
2024-06-04 04:28:55 [INFO]: Epoch 026 - training loss: 0.4749, validation loss: 2.0529
2024-06-04 04:29:35 [INFO]: Epoch 027 - training loss: 0.4720, validation loss: 2.0344
2024-06-04 04:30:14 [INFO]: Epoch 028 - training loss: 0.4691, validation loss: 2.0144
2024-06-04 04:30:54 [INFO]: Epoch 029 - training loss: 0.4665, validation loss: 1.9974
2024-06-04 04:31:33 [INFO]: Epoch 030 - training loss: 0.4648, validation loss: 1.9814
2024-06-04 04:32:13 [INFO]: Epoch 031 - training loss: 0.4619, validation loss: 1.9727
2024-06-04 04:32:53 [INFO]: Epoch 032 - training loss: 0.4603, validation loss: 1.9552
2024-06-04 04:33:32 [INFO]: Epoch 033 - training loss: 0.4582, validation loss: 1.9480
2024-06-04 04:34:12 [INFO]: Epoch 034 - training loss: 0.4567, validation loss: 1.9275
2024-06-04 04:34:52 [INFO]: Epoch 035 - training loss: 0.4538, validation loss: 1.9132
2024-06-04 04:35:31 [INFO]: Epoch 036 - training loss: 0.4524, validation loss: 1.8989
2024-06-04 04:36:11 [INFO]: Epoch 037 - training loss: 0.4519, validation loss: 1.9025
2024-06-04 04:36:51 [INFO]: Epoch 038 - training loss: 0.4494, validation loss: 1.8857
2024-06-04 04:37:30 [INFO]: Epoch 039 - training loss: 0.4479, validation loss: 1.8727
2024-06-04 04:38:10 [INFO]: Epoch 040 - training loss: 0.4460, validation loss: 1.8542
2024-06-04 04:38:49 [INFO]: Epoch 041 - training loss: 0.4448, validation loss: 1.8604
2024-06-04 04:39:29 [INFO]: Epoch 042 - training loss: 0.4431, validation loss: 1.8434
2024-06-04 04:40:09 [INFO]: Epoch 043 - training loss: 0.4414, validation loss: 1.8332
2024-06-04 04:40:48 [INFO]: Epoch 044 - training loss: 0.4406, validation loss: 1.8221
2024-06-04 04:41:28 [INFO]: Epoch 045 - training loss: 0.4395, validation loss: 1.8217
2024-06-04 04:42:08 [INFO]: Epoch 046 - training loss: 0.4382, validation loss: 1.8137
2024-06-04 04:42:47 [INFO]: Epoch 047 - training loss: 0.4370, validation loss: 1.8054
2024-06-04 04:43:27 [INFO]: Epoch 048 - training loss: 0.4367, validation loss: 1.7887
2024-06-04 04:44:06 [INFO]: Epoch 049 - training loss: 0.4348, validation loss: 1.7882
2024-06-04 04:44:46 [INFO]: Epoch 050 - training loss: 0.4338, validation loss: 1.7745
2024-06-04 04:45:26 [INFO]: Epoch 051 - training loss: 0.4335, validation loss: 1.7784
2024-06-04 04:46:05 [INFO]: Epoch 052 - training loss: 0.4319, validation loss: 1.7644
2024-06-04 04:46:45 [INFO]: Epoch 053 - training loss: 0.4310, validation loss: 1.7582
2024-06-04 04:47:25 [INFO]: Epoch 054 - training loss: 0.4304, validation loss: 1.7593
2024-06-04 04:48:04 [INFO]: Epoch 055 - training loss: 0.4295, validation loss: 1.7496
2024-06-04 04:48:44 [INFO]: Epoch 056 - training loss: 0.4285, validation loss: 1.7469
2024-06-04 04:49:23 [INFO]: Epoch 057 - training loss: 0.4285, validation loss: 1.7397
2024-06-04 04:50:03 [INFO]: Epoch 058 - training loss: 0.4280, validation loss: 1.7368
2024-06-04 04:50:43 [INFO]: Epoch 059 - training loss: 0.4267, validation loss: 1.7388
2024-06-04 04:51:22 [INFO]: Epoch 060 - training loss: 0.4257, validation loss: 1.7190
2024-06-04 04:52:02 [INFO]: Epoch 061 - training loss: 0.4251, validation loss: 1.7355
2024-06-04 04:52:41 [INFO]: Epoch 062 - training loss: 0.4247, validation loss: 1.7174
2024-06-04 04:53:21 [INFO]: Epoch 063 - training loss: 0.4237, validation loss: 1.7131
2024-06-04 04:54:00 [INFO]: Epoch 064 - training loss: 0.4225, validation loss: 1.7091
2024-06-04 04:54:40 [INFO]: Epoch 065 - training loss: 0.4225, validation loss: 1.7116
2024-06-04 04:55:20 [INFO]: Epoch 066 - training loss: 0.4222, validation loss: 1.7173
2024-06-04 04:55:59 [INFO]: Epoch 067 - training loss: 0.4213, validation loss: 1.7100
2024-06-04 04:56:39 [INFO]: Epoch 068 - training loss: 0.4200, validation loss: 1.7049
2024-06-04 04:57:19 [INFO]: Epoch 069 - training loss: 0.4199, validation loss: 1.7001
2024-06-04 04:57:58 [INFO]: Epoch 070 - training loss: 0.4188, validation loss: 1.6957
2024-06-04 04:58:38 [INFO]: Epoch 071 - training loss: 0.4186, validation loss: 1.6885
2024-06-04 04:59:17 [INFO]: Epoch 072 - training loss: 0.4185, validation loss: 1.6832
2024-06-04 04:59:57 [INFO]: Epoch 073 - training loss: 0.4179, validation loss: 1.7046
2024-06-04 05:00:36 [INFO]: Epoch 074 - training loss: 0.4176, validation loss: 1.6906
2024-06-04 05:01:16 [INFO]: Epoch 075 - training loss: 0.4166, validation loss: 1.6923
2024-06-04 05:01:56 [INFO]: Epoch 076 - training loss: 0.4165, validation loss: 1.6889
2024-06-04 05:02:36 [INFO]: Epoch 077 - training loss: 0.4158, validation loss: 1.6986
2024-06-04 05:03:15 [INFO]: Epoch 078 - training loss: 0.4154, validation loss: 1.7022
2024-06-04 05:03:55 [INFO]: Epoch 079 - training loss: 0.4152, validation loss: 1.6882
2024-06-04 05:04:34 [INFO]: Epoch 080 - training loss: 0.4145, validation loss: 1.6888
2024-06-04 05:05:14 [INFO]: Epoch 081 - training loss: 0.4140, validation loss: 1.6886
2024-06-04 05:05:54 [INFO]: Epoch 082 - training loss: 0.4133, validation loss: 1.6735
2024-06-04 05:06:33 [INFO]: Epoch 083 - training loss: 0.4129, validation loss: 1.6770
2024-06-04 05:07:13 [INFO]: Epoch 084 - training loss: 0.4128, validation loss: 1.6941
2024-06-04 05:07:53 [INFO]: Epoch 085 - training loss: 0.4121, validation loss: 1.6767
2024-06-04 05:08:32 [INFO]: Epoch 086 - training loss: 0.4115, validation loss: 1.6827
2024-06-04 05:09:12 [INFO]: Epoch 087 - training loss: 0.4116, validation loss: 1.6901
2024-06-04 05:09:52 [INFO]: Epoch 088 - training loss: 0.4107, validation loss: 1.6874
2024-06-04 05:10:31 [INFO]: Epoch 089 - training loss: 0.4106, validation loss: 1.6848
2024-06-04 05:11:11 [INFO]: Epoch 090 - training loss: 0.4109, validation loss: 1.6952
2024-06-04 05:11:51 [INFO]: Epoch 091 - training loss: 0.4097, validation loss: 1.6959
2024-06-04 05:12:30 [INFO]: Epoch 092 - training loss: 0.4095, validation loss: 1.6889
2024-06-04 05:12:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 05:12:30 [INFO]: Finished training. The best model is from epoch#82.
2024-06-04 05:12:30 [INFO]: Saved the model to results_point_rate05/Electricity/PatchTST_Electricity/round_1/20240604_T041145/PatchTST.pypots
2024-06-04 05:12:52 [INFO]: Successfully saved to results_point_rate05/Electricity/PatchTST_Electricity/round_1/imputation.pkl
2024-06-04 05:12:52 [INFO]: Round1 - PatchTST on Electricity: MAE=0.8892, MSE=1.6026, MRE=0.4761
2024-06-04 05:12:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 05:12:52 [INFO]: Using the given device: cuda:0
2024-06-04 05:12:52 [INFO]: Model files will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_2/20240604_T051252
2024-06-04 05:12:52 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_2/20240604_T051252/tensorboard
2024-06-04 05:12:52 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=4, d_k=128
2024-06-04 05:12:52 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (4) * d_k (128)
2024-06-04 05:12:52 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 4,419,410
2024-06-04 05:13:32 [INFO]: Epoch 001 - training loss: 1.3066, validation loss: 3.6533
2024-06-04 05:14:11 [INFO]: Epoch 002 - training loss: 0.9352, validation loss: 3.2959
2024-06-04 05:14:51 [INFO]: Epoch 003 - training loss: 0.7533, validation loss: 3.0694
2024-06-04 05:15:30 [INFO]: Epoch 004 - training loss: 0.6811, validation loss: 2.9057
2024-06-04 05:16:10 [INFO]: Epoch 005 - training loss: 0.6447, validation loss: 2.8048
2024-06-04 05:16:50 [INFO]: Epoch 006 - training loss: 0.6203, validation loss: 2.7059
2024-06-04 05:17:29 [INFO]: Epoch 007 - training loss: 0.6017, validation loss: 2.6302
2024-06-04 05:18:08 [INFO]: Epoch 008 - training loss: 0.5859, validation loss: 2.5585
2024-06-04 05:18:48 [INFO]: Epoch 009 - training loss: 0.5705, validation loss: 2.4952
2024-06-04 05:19:27 [INFO]: Epoch 010 - training loss: 0.5585, validation loss: 2.4503
2024-06-04 05:20:07 [INFO]: Epoch 011 - training loss: 0.5502, validation loss: 2.3933
2024-06-04 05:20:47 [INFO]: Epoch 012 - training loss: 0.5387, validation loss: 2.3442
2024-06-04 05:21:26 [INFO]: Epoch 013 - training loss: 0.5306, validation loss: 2.2979
2024-06-04 05:22:06 [INFO]: Epoch 014 - training loss: 0.5237, validation loss: 2.2705
2024-06-04 05:22:45 [INFO]: Epoch 015 - training loss: 0.5172, validation loss: 2.2377
2024-06-04 05:23:25 [INFO]: Epoch 016 - training loss: 0.5107, validation loss: 2.2059
2024-06-04 05:24:05 [INFO]: Epoch 017 - training loss: 0.5051, validation loss: 2.1775
2024-06-04 05:24:44 [INFO]: Epoch 018 - training loss: 0.5009, validation loss: 2.1499
2024-06-04 05:25:24 [INFO]: Epoch 019 - training loss: 0.4957, validation loss: 2.1203
2024-06-04 05:26:03 [INFO]: Epoch 020 - training loss: 0.4926, validation loss: 2.1005
2024-06-04 05:26:43 [INFO]: Epoch 021 - training loss: 0.4881, validation loss: 2.0767
2024-06-04 05:27:23 [INFO]: Epoch 022 - training loss: 0.4849, validation loss: 2.0567
2024-06-04 05:28:02 [INFO]: Epoch 023 - training loss: 0.4804, validation loss: 2.0356
2024-06-04 05:28:42 [INFO]: Epoch 024 - training loss: 0.4771, validation loss: 2.0102
2024-06-04 05:29:21 [INFO]: Epoch 025 - training loss: 0.4740, validation loss: 1.9913
2024-06-04 05:30:01 [INFO]: Epoch 026 - training loss: 0.4719, validation loss: 1.9818
2024-06-04 05:30:40 [INFO]: Epoch 027 - training loss: 0.4685, validation loss: 1.9661
2024-06-04 05:31:20 [INFO]: Epoch 028 - training loss: 0.4666, validation loss: 1.9410
2024-06-04 05:31:59 [INFO]: Epoch 029 - training loss: 0.4635, validation loss: 1.9192
2024-06-04 05:32:39 [INFO]: Epoch 030 - training loss: 0.4621, validation loss: 1.9053
2024-06-04 05:33:19 [INFO]: Epoch 031 - training loss: 0.4595, validation loss: 1.8922
2024-06-04 05:33:58 [INFO]: Epoch 032 - training loss: 0.4575, validation loss: 1.8759
2024-06-04 05:34:38 [INFO]: Epoch 033 - training loss: 0.4560, validation loss: 1.8643
2024-06-04 05:35:18 [INFO]: Epoch 034 - training loss: 0.4542, validation loss: 1.8486
2024-06-04 05:35:57 [INFO]: Epoch 035 - training loss: 0.4516, validation loss: 1.8372
2024-06-04 05:36:37 [INFO]: Epoch 036 - training loss: 0.4506, validation loss: 1.8289
2024-06-04 05:37:16 [INFO]: Epoch 037 - training loss: 0.4480, validation loss: 1.8082
2024-06-04 05:37:56 [INFO]: Epoch 038 - training loss: 0.4464, validation loss: 1.7950
2024-06-04 05:38:36 [INFO]: Epoch 039 - training loss: 0.4456, validation loss: 1.7890
2024-06-04 05:39:15 [INFO]: Epoch 040 - training loss: 0.4445, validation loss: 1.7768
2024-06-04 05:39:55 [INFO]: Epoch 041 - training loss: 0.4427, validation loss: 1.7703
2024-06-04 05:40:35 [INFO]: Epoch 042 - training loss: 0.4412, validation loss: 1.7619
2024-06-04 05:41:14 [INFO]: Epoch 043 - training loss: 0.4404, validation loss: 1.7598
2024-06-04 05:41:54 [INFO]: Epoch 044 - training loss: 0.4384, validation loss: 1.7557
2024-06-04 05:42:33 [INFO]: Epoch 045 - training loss: 0.4382, validation loss: 1.7285
2024-06-04 05:43:13 [INFO]: Epoch 046 - training loss: 0.4368, validation loss: 1.7303
2024-06-04 05:43:52 [INFO]: Epoch 047 - training loss: 0.4353, validation loss: 1.7337
2024-06-04 05:44:32 [INFO]: Epoch 048 - training loss: 0.4356, validation loss: 1.7193
2024-06-04 05:45:12 [INFO]: Epoch 049 - training loss: 0.4345, validation loss: 1.7190
2024-06-04 05:45:51 [INFO]: Epoch 050 - training loss: 0.4334, validation loss: 1.7106
2024-06-04 05:46:31 [INFO]: Epoch 051 - training loss: 0.4318, validation loss: 1.7028
2024-06-04 05:47:10 [INFO]: Epoch 052 - training loss: 0.4306, validation loss: 1.6809
2024-06-04 05:47:50 [INFO]: Epoch 053 - training loss: 0.4301, validation loss: 1.6900
2024-06-04 05:48:30 [INFO]: Epoch 054 - training loss: 0.4288, validation loss: 1.6908
2024-06-04 05:49:09 [INFO]: Epoch 055 - training loss: 0.4286, validation loss: 1.6783
2024-06-04 05:49:49 [INFO]: Epoch 056 - training loss: 0.4279, validation loss: 1.6720
2024-06-04 05:50:28 [INFO]: Epoch 057 - training loss: 0.4264, validation loss: 1.6602
2024-06-04 05:51:08 [INFO]: Epoch 058 - training loss: 0.4258, validation loss: 1.6671
2024-06-04 05:51:48 [INFO]: Epoch 059 - training loss: 0.4251, validation loss: 1.6453
2024-06-04 05:52:27 [INFO]: Epoch 060 - training loss: 0.4254, validation loss: 1.6500
2024-06-04 05:53:07 [INFO]: Epoch 061 - training loss: 0.4237, validation loss: 1.6562
2024-06-04 05:53:46 [INFO]: Epoch 062 - training loss: 0.4234, validation loss: 1.6437
2024-06-04 05:54:26 [INFO]: Epoch 063 - training loss: 0.4222, validation loss: 1.6431
2024-06-04 05:55:06 [INFO]: Epoch 064 - training loss: 0.4230, validation loss: 1.6502
2024-06-04 05:55:45 [INFO]: Epoch 065 - training loss: 0.4213, validation loss: 1.6372
2024-06-04 05:56:25 [INFO]: Epoch 066 - training loss: 0.4206, validation loss: 1.6304
2024-06-04 05:57:04 [INFO]: Epoch 067 - training loss: 0.4202, validation loss: 1.6164
2024-06-04 05:57:44 [INFO]: Epoch 068 - training loss: 0.4195, validation loss: 1.6239
2024-06-04 05:58:24 [INFO]: Epoch 069 - training loss: 0.4188, validation loss: 1.6263
2024-06-04 05:59:03 [INFO]: Epoch 070 - training loss: 0.4178, validation loss: 1.6223
2024-06-04 05:59:42 [INFO]: Epoch 071 - training loss: 0.4178, validation loss: 1.6085
2024-06-04 06:00:22 [INFO]: Epoch 072 - training loss: 0.4172, validation loss: 1.6247
2024-06-04 06:01:02 [INFO]: Epoch 073 - training loss: 0.4164, validation loss: 1.6176
2024-06-04 06:01:41 [INFO]: Epoch 074 - training loss: 0.4165, validation loss: 1.6036
2024-06-04 06:02:21 [INFO]: Epoch 075 - training loss: 0.4158, validation loss: 1.6203
2024-06-04 06:03:01 [INFO]: Epoch 076 - training loss: 0.4159, validation loss: 1.6047
2024-06-04 06:03:40 [INFO]: Epoch 077 - training loss: 0.4145, validation loss: 1.5793
2024-06-04 06:04:20 [INFO]: Epoch 078 - training loss: 0.4148, validation loss: 1.6089
2024-06-04 06:05:00 [INFO]: Epoch 079 - training loss: 0.4145, validation loss: 1.5950
2024-06-04 06:05:39 [INFO]: Epoch 080 - training loss: 0.4140, validation loss: 1.6058
2024-06-04 06:06:19 [INFO]: Epoch 081 - training loss: 0.4136, validation loss: 1.5861
2024-06-04 06:06:58 [INFO]: Epoch 082 - training loss: 0.4125, validation loss: 1.6094
2024-06-04 06:07:38 [INFO]: Epoch 083 - training loss: 0.4126, validation loss: 1.6165
2024-06-04 06:08:17 [INFO]: Epoch 084 - training loss: 0.4119, validation loss: 1.5870
2024-06-04 06:08:57 [INFO]: Epoch 085 - training loss: 0.4111, validation loss: 1.6013
2024-06-04 06:09:37 [INFO]: Epoch 086 - training loss: 0.4116, validation loss: 1.5988
2024-06-04 06:10:16 [INFO]: Epoch 087 - training loss: 0.4110, validation loss: 1.6027
2024-06-04 06:10:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 06:10:16 [INFO]: Finished training. The best model is from epoch#77.
2024-06-04 06:10:17 [INFO]: Saved the model to results_point_rate05/Electricity/PatchTST_Electricity/round_2/20240604_T051252/PatchTST.pypots
2024-06-04 06:10:38 [INFO]: Successfully saved to results_point_rate05/Electricity/PatchTST_Electricity/round_2/imputation.pkl
2024-06-04 06:10:38 [INFO]: Round2 - PatchTST on Electricity: MAE=0.7802, MSE=1.3149, MRE=0.4177
2024-06-04 06:10:38 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 06:10:38 [INFO]: Using the given device: cuda:0
2024-06-04 06:10:38 [INFO]: Model files will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_3/20240604_T061038
2024-06-04 06:10:38 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_3/20240604_T061038/tensorboard
2024-06-04 06:10:38 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=4, d_k=128
2024-06-04 06:10:38 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (4) * d_k (128)
2024-06-04 06:10:38 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 4,419,410
2024-06-04 06:11:18 [INFO]: Epoch 001 - training loss: 1.3210, validation loss: 3.6487
2024-06-04 06:11:58 [INFO]: Epoch 002 - training loss: 0.9768, validation loss: 3.3914
2024-06-04 06:12:37 [INFO]: Epoch 003 - training loss: 0.7742, validation loss: 3.1456
2024-06-04 06:13:17 [INFO]: Epoch 004 - training loss: 0.6912, validation loss: 2.9619
2024-06-04 06:13:56 [INFO]: Epoch 005 - training loss: 0.6514, validation loss: 2.8481
2024-06-04 06:14:36 [INFO]: Epoch 006 - training loss: 0.6242, validation loss: 2.7568
2024-06-04 06:15:16 [INFO]: Epoch 007 - training loss: 0.6030, validation loss: 2.6647
2024-06-04 06:15:55 [INFO]: Epoch 008 - training loss: 0.5863, validation loss: 2.5874
2024-06-04 06:16:35 [INFO]: Epoch 009 - training loss: 0.5718, validation loss: 2.5201
2024-06-04 06:17:14 [INFO]: Epoch 010 - training loss: 0.5589, validation loss: 2.4623
2024-06-04 06:17:54 [INFO]: Epoch 011 - training loss: 0.5491, validation loss: 2.4226
2024-06-04 06:18:34 [INFO]: Epoch 012 - training loss: 0.5397, validation loss: 2.3731
2024-06-04 06:19:13 [INFO]: Epoch 013 - training loss: 0.5315, validation loss: 2.3383
2024-06-04 06:19:53 [INFO]: Epoch 014 - training loss: 0.5245, validation loss: 2.3019
2024-06-04 06:20:32 [INFO]: Epoch 015 - training loss: 0.5190, validation loss: 2.2578
2024-06-04 06:21:12 [INFO]: Epoch 016 - training loss: 0.5139, validation loss: 2.2354
2024-06-04 06:21:52 [INFO]: Epoch 017 - training loss: 0.5070, validation loss: 2.1963
2024-06-04 06:22:31 [INFO]: Epoch 018 - training loss: 0.5016, validation loss: 2.1700
2024-06-04 06:23:11 [INFO]: Epoch 019 - training loss: 0.4966, validation loss: 2.1456
2024-06-04 06:23:50 [INFO]: Epoch 020 - training loss: 0.4927, validation loss: 2.1177
2024-06-04 06:24:30 [INFO]: Epoch 021 - training loss: 0.4902, validation loss: 2.1000
2024-06-04 06:25:10 [INFO]: Epoch 022 - training loss: 0.4859, validation loss: 2.0763
2024-06-04 06:25:49 [INFO]: Epoch 023 - training loss: 0.4822, validation loss: 2.0520
2024-06-04 06:26:29 [INFO]: Epoch 024 - training loss: 0.4777, validation loss: 2.0411
2024-06-04 06:27:08 [INFO]: Epoch 025 - training loss: 0.4752, validation loss: 2.0179
2024-06-04 06:27:48 [INFO]: Epoch 026 - training loss: 0.4720, validation loss: 2.0058
2024-06-04 06:28:27 [INFO]: Epoch 027 - training loss: 0.4691, validation loss: 1.9857
2024-06-04 06:29:07 [INFO]: Epoch 028 - training loss: 0.4674, validation loss: 1.9661
2024-06-04 06:29:47 [INFO]: Epoch 029 - training loss: 0.4649, validation loss: 1.9539
2024-06-04 06:30:26 [INFO]: Epoch 030 - training loss: 0.4620, validation loss: 1.9532
2024-06-04 06:31:06 [INFO]: Epoch 031 - training loss: 0.4602, validation loss: 1.9341
2024-06-04 06:31:45 [INFO]: Epoch 032 - training loss: 0.4594, validation loss: 1.9281
2024-06-04 06:32:25 [INFO]: Epoch 033 - training loss: 0.4566, validation loss: 1.9102
2024-06-04 06:33:05 [INFO]: Epoch 034 - training loss: 0.4549, validation loss: 1.9051
2024-06-04 06:33:44 [INFO]: Epoch 035 - training loss: 0.4526, validation loss: 1.8920
2024-06-04 06:34:24 [INFO]: Epoch 036 - training loss: 0.4516, validation loss: 1.8899
2024-06-04 06:35:04 [INFO]: Epoch 037 - training loss: 0.4497, validation loss: 1.8827
2024-06-04 06:35:43 [INFO]: Epoch 038 - training loss: 0.4476, validation loss: 1.8552
2024-06-04 06:36:23 [INFO]: Epoch 039 - training loss: 0.4460, validation loss: 1.8586
2024-06-04 06:37:03 [INFO]: Epoch 040 - training loss: 0.4448, validation loss: 1.8552
2024-06-04 06:37:41 [INFO]: Epoch 041 - training loss: 0.4436, validation loss: 1.8306
2024-06-04 06:38:16 [INFO]: Epoch 042 - training loss: 0.4413, validation loss: 1.8307
2024-06-04 06:38:56 [INFO]: Epoch 043 - training loss: 0.4409, validation loss: 1.8178
2024-06-04 06:39:28 [INFO]: Epoch 044 - training loss: 0.4396, validation loss: 1.8265
2024-06-04 06:40:07 [INFO]: Epoch 045 - training loss: 0.4390, validation loss: 1.8130
2024-06-04 06:40:47 [INFO]: Epoch 046 - training loss: 0.4375, validation loss: 1.8157
2024-06-04 06:41:26 [INFO]: Epoch 047 - training loss: 0.4362, validation loss: 1.7778
2024-06-04 06:42:06 [INFO]: Epoch 048 - training loss: 0.4366, validation loss: 1.8016
2024-06-04 06:42:46 [INFO]: Epoch 049 - training loss: 0.4343, validation loss: 1.8001
2024-06-04 06:43:25 [INFO]: Epoch 050 - training loss: 0.4331, validation loss: 1.7993
2024-06-04 06:44:05 [INFO]: Epoch 051 - training loss: 0.4324, validation loss: 1.7917
2024-06-04 06:44:44 [INFO]: Epoch 052 - training loss: 0.4314, validation loss: 1.7792
2024-06-04 06:45:24 [INFO]: Epoch 053 - training loss: 0.4304, validation loss: 1.7685
2024-06-04 06:46:03 [INFO]: Epoch 054 - training loss: 0.4297, validation loss: 1.7643
2024-06-04 06:46:43 [INFO]: Epoch 055 - training loss: 0.4297, validation loss: 1.7539
2024-06-04 06:47:22 [INFO]: Epoch 056 - training loss: 0.4283, validation loss: 1.7391
2024-06-04 06:48:02 [INFO]: Epoch 057 - training loss: 0.4277, validation loss: 1.7816
2024-06-04 06:48:42 [INFO]: Epoch 058 - training loss: 0.4276, validation loss: 1.7638
2024-06-04 06:49:21 [INFO]: Epoch 059 - training loss: 0.4260, validation loss: 1.7488
2024-06-04 06:50:01 [INFO]: Epoch 060 - training loss: 0.4255, validation loss: 1.7403
2024-06-04 06:50:40 [INFO]: Epoch 061 - training loss: 0.4242, validation loss: 1.7327
2024-06-04 06:51:20 [INFO]: Epoch 062 - training loss: 0.4249, validation loss: 1.7092
2024-06-04 06:52:00 [INFO]: Epoch 063 - training loss: 0.4242, validation loss: 1.7269
2024-06-04 06:52:39 [INFO]: Epoch 064 - training loss: 0.4226, validation loss: 1.7152
2024-06-04 06:53:19 [INFO]: Epoch 065 - training loss: 0.4221, validation loss: 1.7518
2024-06-04 06:53:58 [INFO]: Epoch 066 - training loss: 0.4205, validation loss: 1.7395
2024-06-04 06:54:38 [INFO]: Epoch 067 - training loss: 0.4208, validation loss: 1.7391
2024-06-04 06:55:18 [INFO]: Epoch 068 - training loss: 0.4203, validation loss: 1.7176
2024-06-04 06:55:57 [INFO]: Epoch 069 - training loss: 0.4199, validation loss: 1.7250
2024-06-04 06:56:37 [INFO]: Epoch 070 - training loss: 0.4194, validation loss: 1.7249
2024-06-04 06:57:17 [INFO]: Epoch 071 - training loss: 0.4187, validation loss: 1.7174
2024-06-04 06:57:56 [INFO]: Epoch 072 - training loss: 0.4190, validation loss: 1.7132
2024-06-04 06:57:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 06:57:56 [INFO]: Finished training. The best model is from epoch#62.
2024-06-04 06:57:56 [INFO]: Saved the model to results_point_rate05/Electricity/PatchTST_Electricity/round_3/20240604_T061038/PatchTST.pypots
2024-06-04 06:58:18 [INFO]: Successfully saved to results_point_rate05/Electricity/PatchTST_Electricity/round_3/imputation.pkl
2024-06-04 06:58:18 [INFO]: Round3 - PatchTST on Electricity: MAE=0.8595, MSE=1.6431, MRE=0.4602
2024-06-04 06:58:18 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 06:58:18 [INFO]: Using the given device: cuda:0
2024-06-04 06:58:18 [INFO]: Model files will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_4/20240604_T065818
2024-06-04 06:58:18 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/PatchTST_Electricity/round_4/20240604_T065818/tensorboard
2024-06-04 06:58:18 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=4, d_k=128
2024-06-04 06:58:18 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (4) * d_k (128)
2024-06-04 06:58:18 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 4,419,410
2024-06-04 06:58:58 [INFO]: Epoch 001 - training loss: 1.3051, validation loss: 3.5978
2024-06-04 06:59:37 [INFO]: Epoch 002 - training loss: 0.9043, validation loss: 3.2309
2024-06-04 07:00:17 [INFO]: Epoch 003 - training loss: 0.7381, validation loss: 3.1024
2024-06-04 07:00:57 [INFO]: Epoch 004 - training loss: 0.6803, validation loss: 2.9488
2024-06-04 07:01:36 [INFO]: Epoch 005 - training loss: 0.6453, validation loss: 2.8356
2024-06-04 07:02:15 [INFO]: Epoch 006 - training loss: 0.6205, validation loss: 2.7292
2024-06-04 07:02:55 [INFO]: Epoch 007 - training loss: 0.5997, validation loss: 2.6596
2024-06-04 07:03:34 [INFO]: Epoch 008 - training loss: 0.5825, validation loss: 2.5787
2024-06-04 07:04:14 [INFO]: Epoch 009 - training loss: 0.5678, validation loss: 2.5185
2024-06-04 07:04:53 [INFO]: Epoch 010 - training loss: 0.5563, validation loss: 2.4538
2024-06-04 07:05:33 [INFO]: Epoch 011 - training loss: 0.5472, validation loss: 2.4094
2024-06-04 07:06:13 [INFO]: Epoch 012 - training loss: 0.5395, validation loss: 2.3669
2024-06-04 07:06:52 [INFO]: Epoch 013 - training loss: 0.5321, validation loss: 2.3353
2024-06-04 07:07:32 [INFO]: Epoch 014 - training loss: 0.5248, validation loss: 2.3020
2024-06-04 07:08:11 [INFO]: Epoch 015 - training loss: 0.5184, validation loss: 2.2680
2024-06-04 07:08:51 [INFO]: Epoch 016 - training loss: 0.5128, validation loss: 2.2470
2024-06-04 07:09:31 [INFO]: Epoch 017 - training loss: 0.5087, validation loss: 2.2234
2024-06-04 07:10:10 [INFO]: Epoch 018 - training loss: 0.5031, validation loss: 2.1972
2024-06-04 07:10:50 [INFO]: Epoch 019 - training loss: 0.4983, validation loss: 2.1776
2024-06-04 07:11:29 [INFO]: Epoch 020 - training loss: 0.4947, validation loss: 2.1581
2024-06-04 07:12:09 [INFO]: Epoch 021 - training loss: 0.4902, validation loss: 2.1429
2024-06-04 07:12:48 [INFO]: Epoch 022 - training loss: 0.4867, validation loss: 2.1223
2024-06-04 07:13:28 [INFO]: Epoch 023 - training loss: 0.4834, validation loss: 2.0998
2024-06-04 07:14:08 [INFO]: Epoch 024 - training loss: 0.4791, validation loss: 2.0839
2024-06-04 07:14:47 [INFO]: Epoch 025 - training loss: 0.4768, validation loss: 2.0671
2024-06-04 07:15:27 [INFO]: Epoch 026 - training loss: 0.4734, validation loss: 2.0613
2024-06-04 07:16:06 [INFO]: Epoch 027 - training loss: 0.4704, validation loss: 2.0370
2024-06-04 07:16:46 [INFO]: Epoch 028 - training loss: 0.4677, validation loss: 2.0211
2024-06-04 07:17:26 [INFO]: Epoch 029 - training loss: 0.4654, validation loss: 2.0088
2024-06-04 07:18:05 [INFO]: Epoch 030 - training loss: 0.4650, validation loss: 1.9973
2024-06-04 07:18:45 [INFO]: Epoch 031 - training loss: 0.4613, validation loss: 1.9844
2024-06-04 07:19:25 [INFO]: Epoch 032 - training loss: 0.4575, validation loss: 1.9739
2024-06-04 07:20:04 [INFO]: Epoch 033 - training loss: 0.4565, validation loss: 1.9770
2024-06-04 07:20:44 [INFO]: Epoch 034 - training loss: 0.4547, validation loss: 1.9521
2024-06-04 07:21:23 [INFO]: Epoch 035 - training loss: 0.4529, validation loss: 1.9399
2024-06-04 07:22:03 [INFO]: Epoch 036 - training loss: 0.4522, validation loss: 1.9243
2024-06-04 07:22:43 [INFO]: Epoch 037 - training loss: 0.4498, validation loss: 1.9238
2024-06-04 07:23:22 [INFO]: Epoch 038 - training loss: 0.4478, validation loss: 1.9089
2024-06-04 07:24:02 [INFO]: Epoch 039 - training loss: 0.4459, validation loss: 1.8966
2024-06-04 07:24:41 [INFO]: Epoch 040 - training loss: 0.4445, validation loss: 1.8810
2024-06-04 07:25:21 [INFO]: Epoch 041 - training loss: 0.4436, validation loss: 1.8810
2024-06-04 07:26:00 [INFO]: Epoch 042 - training loss: 0.4424, validation loss: 1.8831
2024-06-04 07:26:40 [INFO]: Epoch 043 - training loss: 0.4411, validation loss: 1.8569
2024-06-04 07:27:20 [INFO]: Epoch 044 - training loss: 0.4400, validation loss: 1.8551
2024-06-04 07:27:59 [INFO]: Epoch 045 - training loss: 0.4385, validation loss: 1.8469
2024-06-04 07:28:39 [INFO]: Epoch 046 - training loss: 0.4366, validation loss: 1.8285
2024-06-04 07:29:18 [INFO]: Epoch 047 - training loss: 0.4354, validation loss: 1.8352
2024-06-04 07:29:58 [INFO]: Epoch 048 - training loss: 0.4353, validation loss: 1.8124
2024-06-04 07:30:37 [INFO]: Epoch 049 - training loss: 0.4333, validation loss: 1.8105
2024-06-04 07:31:17 [INFO]: Epoch 050 - training loss: 0.4325, validation loss: 1.8089
2024-06-04 07:31:57 [INFO]: Epoch 051 - training loss: 0.4315, validation loss: 1.8116
2024-06-04 07:32:37 [INFO]: Epoch 052 - training loss: 0.4311, validation loss: 1.7881
2024-06-04 07:33:16 [INFO]: Epoch 053 - training loss: 0.4301, validation loss: 1.7907
2024-06-04 07:33:56 [INFO]: Epoch 054 - training loss: 0.4296, validation loss: 1.7811
2024-06-04 07:34:36 [INFO]: Epoch 055 - training loss: 0.4291, validation loss: 1.7935
2024-06-04 07:35:15 [INFO]: Epoch 056 - training loss: 0.4275, validation loss: 1.7807
2024-06-04 07:35:55 [INFO]: Epoch 057 - training loss: 0.4274, validation loss: 1.7714
2024-06-04 07:36:34 [INFO]: Epoch 058 - training loss: 0.4269, validation loss: 1.7687
2024-06-04 07:37:14 [INFO]: Epoch 059 - training loss: 0.4260, validation loss: 1.7671
2024-06-04 07:37:54 [INFO]: Epoch 060 - training loss: 0.4241, validation loss: 1.7506
2024-06-04 07:38:33 [INFO]: Epoch 061 - training loss: 0.4243, validation loss: 1.7746
2024-06-04 07:39:13 [INFO]: Epoch 062 - training loss: 0.4240, validation loss: 1.7477
2024-06-04 07:39:53 [INFO]: Epoch 063 - training loss: 0.4238, validation loss: 1.7782
2024-06-04 07:40:32 [INFO]: Epoch 064 - training loss: 0.4227, validation loss: 1.7450
2024-06-04 07:41:12 [INFO]: Epoch 065 - training loss: 0.4214, validation loss: 1.7330
2024-06-04 07:41:52 [INFO]: Epoch 066 - training loss: 0.4209, validation loss: 1.7334
2024-06-04 07:42:31 [INFO]: Epoch 067 - training loss: 0.4195, validation loss: 1.7530
2024-06-04 07:43:11 [INFO]: Epoch 068 - training loss: 0.4194, validation loss: 1.7388
2024-06-04 07:43:50 [INFO]: Epoch 069 - training loss: 0.4189, validation loss: 1.7394
2024-06-04 07:44:30 [INFO]: Epoch 070 - training loss: 0.4183, validation loss: 1.7257
2024-06-04 07:45:10 [INFO]: Epoch 071 - training loss: 0.4179, validation loss: 1.7271
2024-06-04 07:45:49 [INFO]: Epoch 072 - training loss: 0.4175, validation loss: 1.7201
2024-06-04 07:46:29 [INFO]: Epoch 073 - training loss: 0.4167, validation loss: 1.7204
2024-06-04 07:47:08 [INFO]: Epoch 074 - training loss: 0.4163, validation loss: 1.7366
2024-06-04 07:47:48 [INFO]: Epoch 075 - training loss: 0.4157, validation loss: 1.7218
2024-06-04 07:48:27 [INFO]: Epoch 076 - training loss: 0.4155, validation loss: 1.7175
2024-06-04 07:49:07 [INFO]: Epoch 077 - training loss: 0.4161, validation loss: 1.7286
2024-06-04 07:49:46 [INFO]: Epoch 078 - training loss: 0.4144, validation loss: 1.7254
2024-06-04 07:50:26 [INFO]: Epoch 079 - training loss: 0.4139, validation loss: 1.7336
2024-06-04 07:51:06 [INFO]: Epoch 080 - training loss: 0.4136, validation loss: 1.7245
2024-06-04 07:51:45 [INFO]: Epoch 081 - training loss: 0.4137, validation loss: 1.7242
2024-06-04 07:52:25 [INFO]: Epoch 082 - training loss: 0.4128, validation loss: 1.7172
2024-06-04 07:53:04 [INFO]: Epoch 083 - training loss: 0.4121, validation loss: 1.7279
2024-06-04 07:53:44 [INFO]: Epoch 084 - training loss: 0.4114, validation loss: 1.7286
2024-06-04 07:54:23 [INFO]: Epoch 085 - training loss: 0.4110, validation loss: 1.7368
2024-06-04 07:55:03 [INFO]: Epoch 086 - training loss: 0.4113, validation loss: 1.7192
2024-06-04 07:55:43 [INFO]: Epoch 087 - training loss: 0.4110, validation loss: 1.7273
2024-06-04 07:56:22 [INFO]: Epoch 088 - training loss: 0.4106, validation loss: 1.7271
2024-06-04 07:57:02 [INFO]: Epoch 089 - training loss: 0.4094, validation loss: 1.7294
2024-06-04 07:57:41 [INFO]: Epoch 090 - training loss: 0.4095, validation loss: 1.7242
2024-06-04 07:58:21 [INFO]: Epoch 091 - training loss: 0.4100, validation loss: 1.7257
2024-06-04 07:59:00 [INFO]: Epoch 092 - training loss: 0.4090, validation loss: 1.7459
2024-06-04 07:59:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 07:59:00 [INFO]: Finished training. The best model is from epoch#82.
2024-06-04 07:59:00 [INFO]: Saved the model to results_point_rate05/Electricity/PatchTST_Electricity/round_4/20240604_T065818/PatchTST.pypots
2024-06-04 07:59:22 [INFO]: Successfully saved to results_point_rate05/Electricity/PatchTST_Electricity/round_4/imputation.pkl
2024-06-04 07:59:22 [INFO]: Round4 - PatchTST on Electricity: MAE=0.8444, MSE=1.5672, MRE=0.4521
2024-06-04 07:59:22 [INFO]: Done! Final results:
Averaged PatchTST (4,419,410 params) on Electricity: MAE=0.8563 ± 0.044119814146590094, MSE=1.5726 ± 0.14054741373007695, MRE=0.4585 ± 0.023622040116223268, average inference time=4.33
