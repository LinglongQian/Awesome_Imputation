2024-06-04 02:52:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:52:46 [INFO]: Using the given device: cuda:0
2024-06-04 02:52:47 [INFO]: Model files will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_0/20240604_T025246
2024-06-04 02:52:47 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_0/20240604_T025246/tensorboard
2024-06-04 02:52:47 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=512
2024-06-04 02:52:47 [WARNING]: ⚠️ d_model is reset to 4096 = n_heads (8) * d_k (512)
2024-06-04 02:52:51 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 155,610,482
2024-06-04 02:53:13 [INFO]: Epoch 001 - training loss: 1.3238, validation loss: 3.2216
2024-06-04 02:53:36 [INFO]: Epoch 002 - training loss: 0.8618, validation loss: 3.0625
2024-06-04 02:53:58 [INFO]: Epoch 003 - training loss: 0.7623, validation loss: 2.9592
2024-06-04 02:54:21 [INFO]: Epoch 004 - training loss: 0.7056, validation loss: 2.8647
2024-06-04 02:54:43 [INFO]: Epoch 005 - training loss: 0.6660, validation loss: 2.8706
2024-06-04 02:55:07 [INFO]: Epoch 006 - training loss: 0.6399, validation loss: 2.8401
2024-06-04 02:55:30 [INFO]: Epoch 007 - training loss: 0.6098, validation loss: 2.8158
2024-06-04 02:55:52 [INFO]: Epoch 008 - training loss: 0.5872, validation loss: 2.8092
2024-06-04 02:56:15 [INFO]: Epoch 009 - training loss: 0.5689, validation loss: 2.8215
2024-06-04 02:56:38 [INFO]: Epoch 010 - training loss: 0.5480, validation loss: 2.8078
2024-06-04 02:57:01 [INFO]: Epoch 011 - training loss: 0.5403, validation loss: 2.8274
2024-06-04 02:57:24 [INFO]: Epoch 012 - training loss: 0.5238, validation loss: 2.8101
2024-06-04 02:57:47 [INFO]: Epoch 013 - training loss: 0.5140, validation loss: 2.8223
2024-06-04 02:58:10 [INFO]: Epoch 014 - training loss: 0.5118, validation loss: 2.8078
2024-06-04 02:58:34 [INFO]: Epoch 015 - training loss: 0.5014, validation loss: 2.8091
2024-06-04 02:58:58 [INFO]: Epoch 016 - training loss: 0.4908, validation loss: 2.7981
2024-06-04 02:59:21 [INFO]: Epoch 017 - training loss: 0.4847, validation loss: 2.7966
2024-06-04 02:59:44 [INFO]: Epoch 018 - training loss: 0.4836, validation loss: 2.7728
2024-06-04 03:00:07 [INFO]: Epoch 019 - training loss: 0.4821, validation loss: 2.8081
2024-06-04 03:00:30 [INFO]: Epoch 020 - training loss: 0.4743, validation loss: 2.7604
2024-06-04 03:00:53 [INFO]: Epoch 021 - training loss: 0.4660, validation loss: 2.7544
2024-06-04 03:01:17 [INFO]: Epoch 022 - training loss: 0.4639, validation loss: 2.7670
2024-06-04 03:01:40 [INFO]: Epoch 023 - training loss: 0.4656, validation loss: 2.7443
2024-06-04 03:02:02 [INFO]: Epoch 024 - training loss: 0.4537, validation loss: 2.7282
2024-06-04 03:02:25 [INFO]: Epoch 025 - training loss: 0.4496, validation loss: 2.7366
2024-06-04 03:02:48 [INFO]: Epoch 026 - training loss: 0.4483, validation loss: 2.7177
2024-06-04 03:03:11 [INFO]: Epoch 027 - training loss: 0.4487, validation loss: 2.7202
2024-06-04 03:03:33 [INFO]: Epoch 028 - training loss: 0.4458, validation loss: 2.7172
2024-06-04 03:03:56 [INFO]: Epoch 029 - training loss: 0.4409, validation loss: 2.7245
2024-06-04 03:04:19 [INFO]: Epoch 030 - training loss: 0.4352, validation loss: 2.7078
2024-06-04 03:04:42 [INFO]: Epoch 031 - training loss: 0.4318, validation loss: 2.7175
2024-06-04 03:05:05 [INFO]: Epoch 032 - training loss: 0.4320, validation loss: 2.6825
2024-06-04 03:05:28 [INFO]: Epoch 033 - training loss: 0.4303, validation loss: 2.6932
2024-06-04 03:05:51 [INFO]: Epoch 034 - training loss: 0.4292, validation loss: 2.6773
2024-06-04 03:06:14 [INFO]: Epoch 035 - training loss: 0.4256, validation loss: 2.6915
2024-06-04 03:06:37 [INFO]: Epoch 036 - training loss: 0.4229, validation loss: 2.6796
2024-06-04 03:07:00 [INFO]: Epoch 037 - training loss: 0.4210, validation loss: 2.6757
2024-06-04 03:07:23 [INFO]: Epoch 038 - training loss: 0.4209, validation loss: 2.6785
2024-06-04 03:07:46 [INFO]: Epoch 039 - training loss: 0.4191, validation loss: 2.6769
2024-06-04 03:08:09 [INFO]: Epoch 040 - training loss: 0.4169, validation loss: 2.6743
2024-06-04 03:08:32 [INFO]: Epoch 041 - training loss: 0.4195, validation loss: 2.6836
2024-06-04 03:08:55 [INFO]: Epoch 042 - training loss: 0.4119, validation loss: 2.6790
2024-06-04 03:09:18 [INFO]: Epoch 043 - training loss: 0.4092, validation loss: 2.6816
2024-06-04 03:09:41 [INFO]: Epoch 044 - training loss: 0.4071, validation loss: 2.6688
2024-06-04 03:10:03 [INFO]: Epoch 045 - training loss: 0.4069, validation loss: 2.6654
2024-06-04 03:10:26 [INFO]: Epoch 046 - training loss: 0.4090, validation loss: 2.6832
2024-06-04 03:10:49 [INFO]: Epoch 047 - training loss: 0.4079, validation loss: 2.6879
2024-06-04 03:11:12 [INFO]: Epoch 048 - training loss: 0.4053, validation loss: 2.6602
2024-06-04 03:11:34 [INFO]: Epoch 049 - training loss: 0.4047, validation loss: 2.6586
2024-06-04 03:11:57 [INFO]: Epoch 050 - training loss: 0.4033, validation loss: 2.6597
2024-06-04 03:12:19 [INFO]: Epoch 051 - training loss: 0.4014, validation loss: 2.6784
2024-06-04 03:12:42 [INFO]: Epoch 052 - training loss: 0.3994, validation loss: 2.6749
2024-06-04 03:13:04 [INFO]: Epoch 053 - training loss: 0.3969, validation loss: 2.6665
2024-06-04 03:13:28 [INFO]: Epoch 054 - training loss: 0.3924, validation loss: 2.6681
2024-06-04 03:13:51 [INFO]: Epoch 055 - training loss: 0.3930, validation loss: 2.6555
2024-06-04 03:14:14 [INFO]: Epoch 056 - training loss: 0.3936, validation loss: 2.6770
2024-06-04 03:14:36 [INFO]: Epoch 057 - training loss: 0.3907, validation loss: 2.6763
2024-06-04 03:14:59 [INFO]: Epoch 058 - training loss: 0.3912, validation loss: 2.6623
2024-06-04 03:15:22 [INFO]: Epoch 059 - training loss: 0.3911, validation loss: 2.6624
2024-06-04 03:15:44 [INFO]: Epoch 060 - training loss: 0.3897, validation loss: 2.6450
2024-06-04 03:16:07 [INFO]: Epoch 061 - training loss: 0.3884, validation loss: 2.6559
2024-06-04 03:16:30 [INFO]: Epoch 062 - training loss: 0.3872, validation loss: 2.6454
2024-06-04 03:16:53 [INFO]: Epoch 063 - training loss: 0.3866, validation loss: 2.6582
2024-06-04 03:17:15 [INFO]: Epoch 064 - training loss: 0.3945, validation loss: 2.6628
2024-06-04 03:17:38 [INFO]: Epoch 065 - training loss: 0.3906, validation loss: 2.6714
2024-06-04 03:18:01 [INFO]: Epoch 066 - training loss: 0.3858, validation loss: 2.6532
2024-06-04 03:18:24 [INFO]: Epoch 067 - training loss: 0.3838, validation loss: 2.6417
2024-06-04 03:18:47 [INFO]: Epoch 068 - training loss: 0.3809, validation loss: 2.6470
2024-06-04 03:19:10 [INFO]: Epoch 069 - training loss: 0.3801, validation loss: 2.6246
2024-06-04 03:19:33 [INFO]: Epoch 070 - training loss: 0.3824, validation loss: 2.6229
2024-06-04 03:19:56 [INFO]: Epoch 071 - training loss: 0.3824, validation loss: 2.6409
2024-06-04 03:20:20 [INFO]: Epoch 072 - training loss: 0.3801, validation loss: 2.6278
2024-06-04 03:20:42 [INFO]: Epoch 073 - training loss: 0.3799, validation loss: 2.6421
2024-06-04 03:21:05 [INFO]: Epoch 074 - training loss: 0.3796, validation loss: 2.6398
2024-06-04 03:21:28 [INFO]: Epoch 075 - training loss: 0.3777, validation loss: 2.6477
2024-06-04 03:21:51 [INFO]: Epoch 076 - training loss: 0.3793, validation loss: 2.6794
2024-06-04 03:22:14 [INFO]: Epoch 077 - training loss: 0.3801, validation loss: 2.6852
2024-06-04 03:22:36 [INFO]: Epoch 078 - training loss: 0.3795, validation loss: 2.6654
2024-06-04 03:22:59 [INFO]: Epoch 079 - training loss: 0.3790, validation loss: 2.6960
2024-06-04 03:23:22 [INFO]: Epoch 080 - training loss: 0.3773, validation loss: 2.6942
2024-06-04 03:23:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:23:22 [INFO]: Finished training. The best model is from epoch#70.
2024-06-04 03:23:25 [INFO]: Saved the model to results_point_rate05/Electricity/Transformer_Electricity/round_0/20240604_T025246/Transformer.pypots
2024-06-04 03:23:36 [INFO]: Successfully saved to results_point_rate05/Electricity/Transformer_Electricity/round_0/imputation.pkl
2024-06-04 03:23:36 [INFO]: Round0 - Transformer on Electricity: MAE=1.4109, MSE=3.6004, MRE=0.7554
2024-06-04 03:23:36 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:23:36 [INFO]: Using the given device: cuda:0
2024-06-04 03:23:36 [INFO]: Model files will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_1/20240604_T032336
2024-06-04 03:23:36 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_1/20240604_T032336/tensorboard
2024-06-04 03:23:36 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=512
2024-06-04 03:23:36 [WARNING]: ⚠️ d_model is reset to 4096 = n_heads (8) * d_k (512)
2024-06-04 03:23:40 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 155,610,482
2024-06-04 03:24:03 [INFO]: Epoch 001 - training loss: 1.2928, validation loss: 3.2024
2024-06-04 03:24:27 [INFO]: Epoch 002 - training loss: 0.8411, validation loss: 3.0592
2024-06-04 03:24:50 [INFO]: Epoch 003 - training loss: 0.7412, validation loss: 2.9467
2024-06-04 03:25:13 [INFO]: Epoch 004 - training loss: 0.7001, validation loss: 2.9019
2024-06-04 03:25:36 [INFO]: Epoch 005 - training loss: 0.6576, validation loss: 2.8270
2024-06-04 03:25:59 [INFO]: Epoch 006 - training loss: 0.6295, validation loss: 2.8598
2024-06-04 03:26:22 [INFO]: Epoch 007 - training loss: 0.6042, validation loss: 2.8403
2024-06-04 03:26:44 [INFO]: Epoch 008 - training loss: 0.5773, validation loss: 2.8404
2024-06-04 03:27:07 [INFO]: Epoch 009 - training loss: 0.5655, validation loss: 2.8453
2024-06-04 03:27:30 [INFO]: Epoch 010 - training loss: 0.5459, validation loss: 2.8211
2024-06-04 03:27:50 [INFO]: Epoch 011 - training loss: 0.5269, validation loss: 2.8177
2024-06-04 03:28:09 [INFO]: Epoch 012 - training loss: 0.5155, validation loss: 2.8331
2024-06-04 03:28:31 [INFO]: Epoch 013 - training loss: 0.5109, validation loss: 2.8070
2024-06-04 03:28:54 [INFO]: Epoch 014 - training loss: 0.4992, validation loss: 2.8139
2024-06-04 03:29:17 [INFO]: Epoch 015 - training loss: 0.4986, validation loss: 2.8011
2024-06-04 03:29:39 [INFO]: Epoch 016 - training loss: 0.4903, validation loss: 2.8022
2024-06-04 03:30:02 [INFO]: Epoch 017 - training loss: 0.4838, validation loss: 2.7753
2024-06-04 03:30:25 [INFO]: Epoch 018 - training loss: 0.4751, validation loss: 2.7663
2024-06-04 03:30:48 [INFO]: Epoch 019 - training loss: 0.4717, validation loss: 2.7652
2024-06-04 03:31:11 [INFO]: Epoch 020 - training loss: 0.4723, validation loss: 2.7707
2024-06-04 03:31:34 [INFO]: Epoch 021 - training loss: 0.4631, validation loss: 2.7509
2024-06-04 03:31:57 [INFO]: Epoch 022 - training loss: 0.4588, validation loss: 2.7290
2024-06-04 03:32:19 [INFO]: Epoch 023 - training loss: 0.4609, validation loss: 2.7291
2024-06-04 03:32:42 [INFO]: Epoch 024 - training loss: 0.4549, validation loss: 2.7566
2024-06-04 03:33:04 [INFO]: Epoch 025 - training loss: 0.4512, validation loss: 2.7298
2024-06-04 03:33:27 [INFO]: Epoch 026 - training loss: 0.4490, validation loss: 2.7396
2024-06-04 03:33:50 [INFO]: Epoch 027 - training loss: 0.4441, validation loss: 2.7476
2024-06-04 03:34:12 [INFO]: Epoch 028 - training loss: 0.4402, validation loss: 2.7428
2024-06-04 03:34:35 [INFO]: Epoch 029 - training loss: 0.4363, validation loss: 2.7385
2024-06-04 03:34:58 [INFO]: Epoch 030 - training loss: 0.4309, validation loss: 2.7123
2024-06-04 03:35:20 [INFO]: Epoch 031 - training loss: 0.4299, validation loss: 2.7194
2024-06-04 03:35:43 [INFO]: Epoch 032 - training loss: 0.4303, validation loss: 2.7132
2024-06-04 03:36:07 [INFO]: Epoch 033 - training loss: 0.4269, validation loss: 2.6971
2024-06-04 03:36:30 [INFO]: Epoch 034 - training loss: 0.4222, validation loss: 2.6854
2024-06-04 03:36:53 [INFO]: Epoch 035 - training loss: 0.4210, validation loss: 2.7175
2024-06-04 03:37:15 [INFO]: Epoch 036 - training loss: 0.4248, validation loss: 2.7082
2024-06-04 03:37:38 [INFO]: Epoch 037 - training loss: 0.4261, validation loss: 2.7128
2024-06-04 03:38:00 [INFO]: Epoch 038 - training loss: 0.4183, validation loss: 2.7076
2024-06-04 03:38:22 [INFO]: Epoch 039 - training loss: 0.4164, validation loss: 2.6900
2024-06-04 03:38:44 [INFO]: Epoch 040 - training loss: 0.4139, validation loss: 2.7002
2024-06-04 03:39:07 [INFO]: Epoch 041 - training loss: 0.4142, validation loss: 2.7027
2024-06-04 03:39:29 [INFO]: Epoch 042 - training loss: 0.4085, validation loss: 2.6824
2024-06-04 03:39:50 [INFO]: Epoch 043 - training loss: 0.4073, validation loss: 2.6844
2024-06-04 03:40:12 [INFO]: Epoch 044 - training loss: 0.4059, validation loss: 2.6770
2024-06-04 03:40:34 [INFO]: Epoch 045 - training loss: 0.4051, validation loss: 2.6647
2024-06-04 03:40:56 [INFO]: Epoch 046 - training loss: 0.4032, validation loss: 2.6900
2024-06-04 03:41:18 [INFO]: Epoch 047 - training loss: 0.4031, validation loss: 2.6822
2024-06-04 03:41:40 [INFO]: Epoch 048 - training loss: 0.4041, validation loss: 2.6656
2024-06-04 03:42:02 [INFO]: Epoch 049 - training loss: 0.4027, validation loss: 2.6868
2024-06-04 03:42:24 [INFO]: Epoch 050 - training loss: 0.3993, validation loss: 2.6762
2024-06-04 03:42:42 [INFO]: Epoch 051 - training loss: 0.3995, validation loss: 2.6951
2024-06-04 03:43:02 [INFO]: Epoch 052 - training loss: 0.4020, validation loss: 2.7022
2024-06-04 03:43:23 [INFO]: Epoch 053 - training loss: 0.3989, validation loss: 2.7021
2024-06-04 03:43:45 [INFO]: Epoch 054 - training loss: 0.3938, validation loss: 2.6866
2024-06-04 03:44:07 [INFO]: Epoch 055 - training loss: 0.3906, validation loss: 2.6780
2024-06-04 03:44:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:44:07 [INFO]: Finished training. The best model is from epoch#45.
2024-06-04 03:44:09 [INFO]: Saved the model to results_point_rate05/Electricity/Transformer_Electricity/round_1/20240604_T032336/Transformer.pypots
2024-06-04 03:44:20 [INFO]: Successfully saved to results_point_rate05/Electricity/Transformer_Electricity/round_1/imputation.pkl
2024-06-04 03:44:20 [INFO]: Round1 - Transformer on Electricity: MAE=1.3443, MSE=3.5306, MRE=0.7197
2024-06-04 03:44:20 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:44:20 [INFO]: Using the given device: cuda:0
2024-06-04 03:44:20 [INFO]: Model files will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_2/20240604_T034420
2024-06-04 03:44:20 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_2/20240604_T034420/tensorboard
2024-06-04 03:44:20 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=512
2024-06-04 03:44:20 [WARNING]: ⚠️ d_model is reset to 4096 = n_heads (8) * d_k (512)
2024-06-04 03:44:23 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 155,610,482
2024-06-04 03:44:46 [INFO]: Epoch 001 - training loss: 1.2758, validation loss: 3.2313
2024-06-04 03:45:08 [INFO]: Epoch 002 - training loss: 0.8478, validation loss: 3.0817
2024-06-04 03:45:30 [INFO]: Epoch 003 - training loss: 0.7462, validation loss: 2.9125
2024-06-04 03:45:52 [INFO]: Epoch 004 - training loss: 0.6945, validation loss: 2.8764
2024-06-04 03:46:13 [INFO]: Epoch 005 - training loss: 0.6578, validation loss: 2.8385
2024-06-04 03:46:35 [INFO]: Epoch 006 - training loss: 0.6326, validation loss: 2.8409
2024-06-04 03:46:57 [INFO]: Epoch 007 - training loss: 0.6077, validation loss: 2.8414
2024-06-04 03:47:18 [INFO]: Epoch 008 - training loss: 0.5871, validation loss: 2.8553
2024-06-04 03:47:40 [INFO]: Epoch 009 - training loss: 0.5668, validation loss: 2.8359
2024-06-04 03:48:03 [INFO]: Epoch 010 - training loss: 0.5534, validation loss: 2.8541
2024-06-04 03:48:24 [INFO]: Epoch 011 - training loss: 0.5338, validation loss: 2.8252
2024-06-04 03:48:46 [INFO]: Epoch 012 - training loss: 0.5209, validation loss: 2.8282
2024-06-04 03:49:08 [INFO]: Epoch 013 - training loss: 0.5102, validation loss: 2.8101
2024-06-04 03:49:30 [INFO]: Epoch 014 - training loss: 0.5042, validation loss: 2.8282
2024-06-04 03:49:51 [INFO]: Epoch 015 - training loss: 0.5005, validation loss: 2.8124
2024-06-04 03:50:13 [INFO]: Epoch 016 - training loss: 0.4946, validation loss: 2.8075
2024-06-04 03:50:35 [INFO]: Epoch 017 - training loss: 0.4853, validation loss: 2.8127
2024-06-04 03:50:57 [INFO]: Epoch 018 - training loss: 0.4800, validation loss: 2.7791
2024-06-04 03:51:19 [INFO]: Epoch 019 - training loss: 0.4769, validation loss: 2.7717
2024-06-04 03:51:40 [INFO]: Epoch 020 - training loss: 0.4780, validation loss: 2.8265
2024-06-04 03:52:02 [INFO]: Epoch 021 - training loss: 0.4754, validation loss: 2.7512
2024-06-04 03:52:24 [INFO]: Epoch 022 - training loss: 0.4609, validation loss: 2.7489
2024-06-04 03:52:46 [INFO]: Epoch 023 - training loss: 0.4566, validation loss: 2.7456
2024-06-04 03:53:08 [INFO]: Epoch 024 - training loss: 0.4560, validation loss: 2.7641
2024-06-04 03:53:30 [INFO]: Epoch 025 - training loss: 0.4538, validation loss: 2.7280
2024-06-04 03:53:52 [INFO]: Epoch 026 - training loss: 0.4474, validation loss: 2.7489
2024-06-04 03:54:14 [INFO]: Epoch 027 - training loss: 0.4456, validation loss: 2.7287
2024-06-04 03:54:36 [INFO]: Epoch 028 - training loss: 0.4398, validation loss: 2.7074
2024-06-04 03:54:58 [INFO]: Epoch 029 - training loss: 0.4376, validation loss: 2.6832
2024-06-04 03:55:20 [INFO]: Epoch 030 - training loss: 0.4342, validation loss: 2.6868
2024-06-04 03:55:42 [INFO]: Epoch 031 - training loss: 0.4328, validation loss: 2.6978
2024-06-04 03:56:04 [INFO]: Epoch 032 - training loss: 0.4291, validation loss: 2.6867
2024-06-04 03:56:26 [INFO]: Epoch 033 - training loss: 0.4255, validation loss: 2.7001
2024-06-04 03:56:48 [INFO]: Epoch 034 - training loss: 0.4306, validation loss: 2.6968
2024-06-04 03:57:10 [INFO]: Epoch 035 - training loss: 0.4256, validation loss: 2.7059
2024-06-04 03:57:32 [INFO]: Epoch 036 - training loss: 0.4218, validation loss: 2.6822
2024-06-04 03:57:53 [INFO]: Epoch 037 - training loss: 0.4205, validation loss: 2.6942
2024-06-04 03:58:15 [INFO]: Epoch 038 - training loss: 0.4170, validation loss: 2.7035
2024-06-04 03:58:37 [INFO]: Epoch 039 - training loss: 0.4153, validation loss: 2.6835
2024-06-04 03:58:59 [INFO]: Epoch 040 - training loss: 0.4155, validation loss: 2.6886
2024-06-04 03:59:21 [INFO]: Epoch 041 - training loss: 0.4139, validation loss: 2.6747
2024-06-04 03:59:43 [INFO]: Epoch 042 - training loss: 0.4113, validation loss: 2.6662
2024-06-04 04:00:04 [INFO]: Epoch 043 - training loss: 0.4087, validation loss: 2.6643
2024-06-04 04:00:26 [INFO]: Epoch 044 - training loss: 0.4093, validation loss: 2.6804
2024-06-04 04:00:48 [INFO]: Epoch 045 - training loss: 0.4100, validation loss: 2.6651
2024-06-04 04:01:10 [INFO]: Epoch 046 - training loss: 0.4124, validation loss: 2.6769
2024-06-04 04:01:32 [INFO]: Epoch 047 - training loss: 0.4066, validation loss: 2.6939
2024-06-04 04:01:55 [INFO]: Epoch 048 - training loss: 0.4015, validation loss: 2.6685
2024-06-04 04:02:16 [INFO]: Epoch 049 - training loss: 0.3992, validation loss: 2.6616
2024-06-04 04:02:39 [INFO]: Epoch 050 - training loss: 0.4009, validation loss: 2.6684
2024-06-04 04:03:00 [INFO]: Epoch 051 - training loss: 0.3999, validation loss: 2.6840
2024-06-04 04:03:22 [INFO]: Epoch 052 - training loss: 0.3962, validation loss: 2.6823
2024-06-04 04:03:44 [INFO]: Epoch 053 - training loss: 0.3964, validation loss: 2.6375
2024-06-04 04:04:06 [INFO]: Epoch 054 - training loss: 0.3962, validation loss: 2.6651
2024-06-04 04:04:28 [INFO]: Epoch 055 - training loss: 0.3974, validation loss: 2.6568
2024-06-04 04:04:50 [INFO]: Epoch 056 - training loss: 0.3975, validation loss: 2.6738
2024-06-04 04:05:12 [INFO]: Epoch 057 - training loss: 0.3931, validation loss: 2.6383
2024-06-04 04:05:34 [INFO]: Epoch 058 - training loss: 0.3915, validation loss: 2.6596
2024-06-04 04:05:56 [INFO]: Epoch 059 - training loss: 0.3948, validation loss: 2.6473
2024-06-04 04:06:18 [INFO]: Epoch 060 - training loss: 0.3939, validation loss: 2.6589
2024-06-04 04:06:39 [INFO]: Epoch 061 - training loss: 0.3907, validation loss: 2.6548
2024-06-04 04:07:01 [INFO]: Epoch 062 - training loss: 0.3869, validation loss: 2.6508
2024-06-04 04:07:23 [INFO]: Epoch 063 - training loss: 0.3842, validation loss: 2.6583
2024-06-04 04:07:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:07:23 [INFO]: Finished training. The best model is from epoch#53.
2024-06-04 04:07:25 [INFO]: Saved the model to results_point_rate05/Electricity/Transformer_Electricity/round_2/20240604_T034420/Transformer.pypots
2024-06-04 04:07:36 [INFO]: Successfully saved to results_point_rate05/Electricity/Transformer_Electricity/round_2/imputation.pkl
2024-06-04 04:07:36 [INFO]: Round2 - Transformer on Electricity: MAE=1.3326, MSE=3.4477, MRE=0.7135
2024-06-04 04:07:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 04:07:36 [INFO]: Using the given device: cuda:0
2024-06-04 04:07:36 [INFO]: Model files will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_3/20240604_T040736
2024-06-04 04:07:36 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_3/20240604_T040736/tensorboard
2024-06-04 04:07:36 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=512
2024-06-04 04:07:36 [WARNING]: ⚠️ d_model is reset to 4096 = n_heads (8) * d_k (512)
2024-06-04 04:07:39 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 155,610,482
2024-06-04 04:08:01 [INFO]: Epoch 001 - training loss: 1.2424, validation loss: 3.2069
2024-06-04 04:08:23 [INFO]: Epoch 002 - training loss: 0.8255, validation loss: 3.0585
2024-06-04 04:08:44 [INFO]: Epoch 003 - training loss: 0.7432, validation loss: 2.9521
2024-06-04 04:09:06 [INFO]: Epoch 004 - training loss: 0.6898, validation loss: 2.8521
2024-06-04 04:09:29 [INFO]: Epoch 005 - training loss: 0.6554, validation loss: 2.9005
2024-06-04 04:09:51 [INFO]: Epoch 006 - training loss: 0.6302, validation loss: 2.8520
2024-06-04 04:10:13 [INFO]: Epoch 007 - training loss: 0.5983, validation loss: 2.8520
2024-06-04 04:10:35 [INFO]: Epoch 008 - training loss: 0.5770, validation loss: 2.8626
2024-06-04 04:10:56 [INFO]: Epoch 009 - training loss: 0.5585, validation loss: 2.8545
2024-06-04 04:11:18 [INFO]: Epoch 010 - training loss: 0.5413, validation loss: 2.8601
2024-06-04 04:11:40 [INFO]: Epoch 011 - training loss: 0.5279, validation loss: 2.8341
2024-06-04 04:12:02 [INFO]: Epoch 012 - training loss: 0.5233, validation loss: 2.8356
2024-06-04 04:12:23 [INFO]: Epoch 013 - training loss: 0.5146, validation loss: 2.8185
2024-06-04 04:12:45 [INFO]: Epoch 014 - training loss: 0.5033, validation loss: 2.8241
2024-06-04 04:13:07 [INFO]: Epoch 015 - training loss: 0.4939, validation loss: 2.8091
2024-06-04 04:13:29 [INFO]: Epoch 016 - training loss: 0.4889, validation loss: 2.8222
2024-06-04 04:13:51 [INFO]: Epoch 017 - training loss: 0.4855, validation loss: 2.8475
2024-06-04 04:14:13 [INFO]: Epoch 018 - training loss: 0.4858, validation loss: 2.8357
2024-06-04 04:14:36 [INFO]: Epoch 019 - training loss: 0.4788, validation loss: 2.7889
2024-06-04 04:14:57 [INFO]: Epoch 020 - training loss: 0.4693, validation loss: 2.7956
2024-06-04 04:15:19 [INFO]: Epoch 021 - training loss: 0.4638, validation loss: 2.7811
2024-06-04 04:15:41 [INFO]: Epoch 022 - training loss: 0.4600, validation loss: 2.7666
2024-06-04 04:16:04 [INFO]: Epoch 023 - training loss: 0.4540, validation loss: 2.7506
2024-06-04 04:16:25 [INFO]: Epoch 024 - training loss: 0.4496, validation loss: 2.7503
2024-06-04 04:16:43 [INFO]: Epoch 025 - training loss: 0.4465, validation loss: 2.7323
2024-06-04 04:17:03 [INFO]: Epoch 026 - training loss: 0.4433, validation loss: 2.7438
2024-06-04 04:17:25 [INFO]: Epoch 027 - training loss: 0.4399, validation loss: 2.7259
2024-06-04 04:17:47 [INFO]: Epoch 028 - training loss: 0.4427, validation loss: 2.7312
2024-06-04 04:18:09 [INFO]: Epoch 029 - training loss: 0.4375, validation loss: 2.7196
2024-06-04 04:18:31 [INFO]: Epoch 030 - training loss: 0.4320, validation loss: 2.7082
2024-06-04 04:18:53 [INFO]: Epoch 031 - training loss: 0.4298, validation loss: 2.7079
2024-06-04 04:19:15 [INFO]: Epoch 032 - training loss: 0.4286, validation loss: 2.7050
2024-06-04 04:19:36 [INFO]: Epoch 033 - training loss: 0.4276, validation loss: 2.6879
2024-06-04 04:19:58 [INFO]: Epoch 034 - training loss: 0.4244, validation loss: 2.6980
2024-06-04 04:20:20 [INFO]: Epoch 035 - training loss: 0.4235, validation loss: 2.6880
2024-06-04 04:20:42 [INFO]: Epoch 036 - training loss: 0.4180, validation loss: 2.6719
2024-06-04 04:21:04 [INFO]: Epoch 037 - training loss: 0.4187, validation loss: 2.6811
2024-06-04 04:21:26 [INFO]: Epoch 038 - training loss: 0.4219, validation loss: 2.7072
2024-06-04 04:21:48 [INFO]: Epoch 039 - training loss: 0.4166, validation loss: 2.7029
2024-06-04 04:22:10 [INFO]: Epoch 040 - training loss: 0.4122, validation loss: 2.6777
2024-06-04 04:22:32 [INFO]: Epoch 041 - training loss: 0.4085, validation loss: 2.6651
2024-06-04 04:22:54 [INFO]: Epoch 042 - training loss: 0.4068, validation loss: 2.6610
2024-06-04 04:23:16 [INFO]: Epoch 043 - training loss: 0.4122, validation loss: 2.6738
2024-06-04 04:23:38 [INFO]: Epoch 044 - training loss: 0.4117, validation loss: 2.6682
2024-06-04 04:24:00 [INFO]: Epoch 045 - training loss: 0.4053, validation loss: 2.6569
2024-06-04 04:24:22 [INFO]: Epoch 046 - training loss: 0.4056, validation loss: 2.6514
2024-06-04 04:24:44 [INFO]: Epoch 047 - training loss: 0.4032, validation loss: 2.6593
2024-06-04 04:25:05 [INFO]: Epoch 048 - training loss: 0.4009, validation loss: 2.6520
2024-06-04 04:25:27 [INFO]: Epoch 049 - training loss: 0.4049, validation loss: 2.6791
2024-06-04 04:25:49 [INFO]: Epoch 050 - training loss: 0.4040, validation loss: 2.6662
2024-06-04 04:26:09 [INFO]: Epoch 051 - training loss: 0.3997, validation loss: 2.6699
2024-06-04 04:26:27 [INFO]: Epoch 052 - training loss: 0.3959, validation loss: 2.6786
2024-06-04 04:26:46 [INFO]: Epoch 053 - training loss: 0.3945, validation loss: 2.6624
2024-06-04 04:27:05 [INFO]: Epoch 054 - training loss: 0.3929, validation loss: 2.6675
2024-06-04 04:27:24 [INFO]: Epoch 055 - training loss: 0.3931, validation loss: 2.6787
2024-06-04 04:27:43 [INFO]: Epoch 056 - training loss: 0.3932, validation loss: 2.6527
2024-06-04 04:27:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:27:43 [INFO]: Finished training. The best model is from epoch#46.
2024-06-04 04:27:45 [INFO]: Saved the model to results_point_rate05/Electricity/Transformer_Electricity/round_3/20240604_T040736/Transformer.pypots
2024-06-04 04:27:54 [INFO]: Successfully saved to results_point_rate05/Electricity/Transformer_Electricity/round_3/imputation.pkl
2024-06-04 04:27:54 [INFO]: Round3 - Transformer on Electricity: MAE=1.3346, MSE=3.4976, MRE=0.7146
2024-06-04 04:27:54 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:27:54 [INFO]: Using the given device: cuda:0
2024-06-04 04:27:54 [INFO]: Model files will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_4/20240604_T042754
2024-06-04 04:27:54 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Transformer_Electricity/round_4/20240604_T042754/tensorboard
2024-06-04 04:27:54 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=512
2024-06-04 04:27:54 [WARNING]: ⚠️ d_model is reset to 4096 = n_heads (8) * d_k (512)
2024-06-04 04:27:56 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 155,610,482
2024-06-04 04:28:15 [INFO]: Epoch 001 - training loss: 1.2633, validation loss: 3.2018
2024-06-04 04:28:34 [INFO]: Epoch 002 - training loss: 0.8378, validation loss: 3.0739
2024-06-04 04:28:52 [INFO]: Epoch 003 - training loss: 0.7479, validation loss: 2.9606
2024-06-04 04:29:11 [INFO]: Epoch 004 - training loss: 0.7000, validation loss: 2.9166
2024-06-04 04:29:30 [INFO]: Epoch 005 - training loss: 0.6660, validation loss: 2.8731
2024-06-04 04:29:45 [INFO]: Epoch 006 - training loss: 0.6307, validation loss: 2.8484
2024-06-04 04:30:02 [INFO]: Epoch 007 - training loss: 0.6016, validation loss: 2.8263
2024-06-04 04:30:21 [INFO]: Epoch 008 - training loss: 0.5786, validation loss: 2.8130
2024-06-04 04:30:40 [INFO]: Epoch 009 - training loss: 0.5600, validation loss: 2.8104
2024-06-04 04:30:58 [INFO]: Epoch 010 - training loss: 0.5470, validation loss: 2.8136
2024-06-04 04:31:17 [INFO]: Epoch 011 - training loss: 0.5299, validation loss: 2.8205
2024-06-04 04:31:36 [INFO]: Epoch 012 - training loss: 0.5188, validation loss: 2.8199
2024-06-04 04:31:55 [INFO]: Epoch 013 - training loss: 0.5200, validation loss: 2.8146
2024-06-04 04:32:14 [INFO]: Epoch 014 - training loss: 0.5060, validation loss: 2.8136
2024-06-04 04:32:33 [INFO]: Epoch 015 - training loss: 0.4953, validation loss: 2.8030
2024-06-04 04:32:51 [INFO]: Epoch 016 - training loss: 0.4876, validation loss: 2.7960
2024-06-04 04:33:10 [INFO]: Epoch 017 - training loss: 0.4814, validation loss: 2.7695
2024-06-04 04:33:29 [INFO]: Epoch 018 - training loss: 0.4752, validation loss: 2.7840
2024-06-04 04:33:47 [INFO]: Epoch 019 - training loss: 0.4719, validation loss: 2.7751
2024-06-04 04:34:06 [INFO]: Epoch 020 - training loss: 0.4778, validation loss: 2.7605
2024-06-04 04:34:24 [INFO]: Epoch 021 - training loss: 0.4632, validation loss: 2.7573
2024-06-04 04:34:43 [INFO]: Epoch 022 - training loss: 0.4596, validation loss: 2.7469
2024-06-04 04:35:02 [INFO]: Epoch 023 - training loss: 0.4559, validation loss: 2.7354
2024-06-04 04:35:20 [INFO]: Epoch 024 - training loss: 0.4523, validation loss: 2.7413
2024-06-04 04:35:39 [INFO]: Epoch 025 - training loss: 0.4477, validation loss: 2.7489
2024-06-04 04:35:58 [INFO]: Epoch 026 - training loss: 0.4477, validation loss: 2.7361
2024-06-04 04:36:16 [INFO]: Epoch 027 - training loss: 0.4459, validation loss: 2.7495
2024-06-04 04:36:35 [INFO]: Epoch 028 - training loss: 0.4411, validation loss: 2.7143
2024-06-04 04:36:54 [INFO]: Epoch 029 - training loss: 0.4352, validation loss: 2.7158
2024-06-04 04:37:12 [INFO]: Epoch 030 - training loss: 0.4311, validation loss: 2.6939
2024-06-04 04:37:31 [INFO]: Epoch 031 - training loss: 0.4321, validation loss: 2.6938
2024-06-04 04:37:50 [INFO]: Epoch 032 - training loss: 0.4273, validation loss: 2.6782
2024-06-04 04:38:08 [INFO]: Epoch 033 - training loss: 0.4294, validation loss: 2.6814
2024-06-04 04:38:27 [INFO]: Epoch 034 - training loss: 0.4282, validation loss: 2.6833
2024-06-04 04:38:45 [INFO]: Epoch 035 - training loss: 0.4232, validation loss: 2.6506
2024-06-04 04:39:04 [INFO]: Epoch 036 - training loss: 0.4295, validation loss: 2.6853
2024-06-04 04:39:23 [INFO]: Epoch 037 - training loss: 0.4251, validation loss: 2.6771
2024-06-04 04:39:42 [INFO]: Epoch 038 - training loss: 0.4182, validation loss: 2.6618
2024-06-04 04:40:01 [INFO]: Epoch 039 - training loss: 0.4136, validation loss: 2.6567
2024-06-04 04:40:19 [INFO]: Epoch 040 - training loss: 0.4110, validation loss: 2.6852
2024-06-04 04:40:38 [INFO]: Epoch 041 - training loss: 0.4105, validation loss: 2.6600
2024-06-04 04:40:57 [INFO]: Epoch 042 - training loss: 0.4088, validation loss: 2.6530
2024-06-04 04:41:16 [INFO]: Epoch 043 - training loss: 0.4052, validation loss: 2.6464
2024-06-04 04:41:35 [INFO]: Epoch 044 - training loss: 0.4049, validation loss: 2.6631
2024-06-04 04:41:54 [INFO]: Epoch 045 - training loss: 0.4058, validation loss: 2.6567
2024-06-04 04:42:13 [INFO]: Epoch 046 - training loss: 0.4037, validation loss: 2.6445
2024-06-04 04:42:32 [INFO]: Epoch 047 - training loss: 0.4038, validation loss: 2.6774
2024-06-04 04:42:50 [INFO]: Epoch 048 - training loss: 0.3983, validation loss: 2.6546
2024-06-04 04:43:09 [INFO]: Epoch 049 - training loss: 0.3977, validation loss: 2.6406
2024-06-04 04:43:28 [INFO]: Epoch 050 - training loss: 0.3957, validation loss: 2.6379
2024-06-04 04:43:47 [INFO]: Epoch 051 - training loss: 0.3971, validation loss: 2.6533
2024-06-04 04:44:05 [INFO]: Epoch 052 - training loss: 0.3995, validation loss: 2.6537
2024-06-04 04:44:24 [INFO]: Epoch 053 - training loss: 0.3970, validation loss: 2.6588
2024-06-04 04:44:43 [INFO]: Epoch 054 - training loss: 0.3946, validation loss: 2.6394
2024-06-04 04:45:02 [INFO]: Epoch 055 - training loss: 0.3933, validation loss: 2.6389
2024-06-04 04:45:20 [INFO]: Epoch 056 - training loss: 0.3917, validation loss: 2.6424
2024-06-04 04:45:39 [INFO]: Epoch 057 - training loss: 0.3951, validation loss: 2.6357
2024-06-04 04:45:58 [INFO]: Epoch 058 - training loss: 0.3921, validation loss: 2.6472
2024-06-04 04:46:17 [INFO]: Epoch 059 - training loss: 0.3898, validation loss: 2.6343
2024-06-04 04:46:35 [INFO]: Epoch 060 - training loss: 0.3914, validation loss: 2.6492
2024-06-04 04:46:54 [INFO]: Epoch 061 - training loss: 0.3896, validation loss: 2.6324
2024-06-04 04:47:12 [INFO]: Epoch 062 - training loss: 0.3891, validation loss: 2.6667
2024-06-04 04:47:31 [INFO]: Epoch 063 - training loss: 0.3953, validation loss: 2.6593
2024-06-04 04:47:50 [INFO]: Epoch 064 - training loss: 0.3893, validation loss: 2.6527
2024-06-04 04:48:08 [INFO]: Epoch 065 - training loss: 0.3841, validation loss: 2.6561
2024-06-04 04:48:27 [INFO]: Epoch 066 - training loss: 0.3833, validation loss: 2.6438
2024-06-04 04:48:45 [INFO]: Epoch 067 - training loss: 0.3818, validation loss: 2.6204
2024-06-04 04:49:04 [INFO]: Epoch 068 - training loss: 0.3851, validation loss: 2.6244
2024-06-04 04:49:22 [INFO]: Epoch 069 - training loss: 0.3846, validation loss: 2.6521
2024-06-04 04:49:41 [INFO]: Epoch 070 - training loss: 0.3836, validation loss: 2.6564
2024-06-04 04:50:00 [INFO]: Epoch 071 - training loss: 0.3854, validation loss: 2.6755
2024-06-04 04:50:19 [INFO]: Epoch 072 - training loss: 0.3868, validation loss: 2.6995
2024-06-04 04:50:37 [INFO]: Epoch 073 - training loss: 0.3816, validation loss: 2.6298
2024-06-04 04:50:56 [INFO]: Epoch 074 - training loss: 0.3769, validation loss: 2.6482
2024-06-04 04:51:14 [INFO]: Epoch 075 - training loss: 0.3752, validation loss: 2.6587
2024-06-04 04:51:33 [INFO]: Epoch 076 - training loss: 0.3746, validation loss: 2.6025
2024-06-04 04:51:52 [INFO]: Epoch 077 - training loss: 0.3731, validation loss: 2.6725
2024-06-04 04:52:10 [INFO]: Epoch 078 - training loss: 0.3711, validation loss: 2.6342
2024-06-04 04:52:29 [INFO]: Epoch 079 - training loss: 0.3699, validation loss: 2.6432
2024-06-04 04:52:48 [INFO]: Epoch 080 - training loss: 0.3705, validation loss: 2.6549
2024-06-04 04:53:06 [INFO]: Epoch 081 - training loss: 0.3704, validation loss: 2.6673
2024-06-04 04:53:25 [INFO]: Epoch 082 - training loss: 0.3707, validation loss: 2.6824
2024-06-04 04:53:44 [INFO]: Epoch 083 - training loss: 0.3686, validation loss: 2.6852
2024-06-04 04:54:02 [INFO]: Epoch 084 - training loss: 0.3672, validation loss: 2.6574
2024-06-04 04:54:21 [INFO]: Epoch 085 - training loss: 0.3701, validation loss: 2.6517
2024-06-04 04:54:39 [INFO]: Epoch 086 - training loss: 0.3694, validation loss: 2.6724
2024-06-04 04:54:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:54:39 [INFO]: Finished training. The best model is from epoch#76.
2024-06-04 04:54:41 [INFO]: Saved the model to results_point_rate05/Electricity/Transformer_Electricity/round_4/20240604_T042754/Transformer.pypots
2024-06-04 04:54:50 [INFO]: Successfully saved to results_point_rate05/Electricity/Transformer_Electricity/round_4/imputation.pkl
2024-06-04 04:54:50 [INFO]: Round4 - Transformer on Electricity: MAE=1.4002, MSE=3.6919, MRE=0.7497
2024-06-04 04:54:50 [INFO]: Done! Final results:
Averaged Transformer (155,610,482 params) on Electricity: MAE=1.3645 ± 0.033907244551743425, MSE=3.5536 ± 0.08507526767474942, MRE=0.7306 ± 0.018154162852333303, average inference time=1.91
