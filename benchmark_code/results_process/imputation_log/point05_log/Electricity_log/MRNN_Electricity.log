2024-06-04 02:59:04 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:04 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:06 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 949,749
2024-06-04 03:03:16 [INFO]: Epoch 001 - training loss: 1.0619, validation loss: 3.9153
2024-06-04 03:07:11 [INFO]: Epoch 002 - training loss: 0.6775, validation loss: 3.8703
2024-06-04 03:11:01 [INFO]: Epoch 003 - training loss: 0.6410, validation loss: 3.8464
2024-06-04 03:14:34 [INFO]: Epoch 004 - training loss: 0.6300, validation loss: 3.8246
2024-06-04 03:18:07 [INFO]: Epoch 005 - training loss: 0.6269, validation loss: 3.8078
2024-06-04 03:21:39 [INFO]: Epoch 006 - training loss: 0.6179, validation loss: 3.7951
2024-06-04 03:25:11 [INFO]: Epoch 007 - training loss: 0.6072, validation loss: 3.7928
2024-06-04 03:28:44 [INFO]: Epoch 008 - training loss: 0.6026, validation loss: 3.7889
2024-06-04 03:32:17 [INFO]: Epoch 009 - training loss: 0.6040, validation loss: 3.7907
2024-06-04 03:35:50 [INFO]: Epoch 010 - training loss: 0.5959, validation loss: 3.7867
2024-06-04 03:39:22 [INFO]: Epoch 011 - training loss: 0.5967, validation loss: 3.7847
2024-06-04 03:42:54 [INFO]: Epoch 012 - training loss: 0.5876, validation loss: 3.7851
2024-06-04 03:46:27 [INFO]: Epoch 013 - training loss: 0.5847, validation loss: 3.7864
2024-06-04 03:49:59 [INFO]: Epoch 014 - training loss: 0.5876, validation loss: 3.7802
2024-06-04 03:53:17 [INFO]: Epoch 015 - training loss: 0.5830, validation loss: 3.7774
2024-06-04 03:56:07 [INFO]: Epoch 016 - training loss: 0.5834, validation loss: 3.7787
2024-06-04 03:58:56 [INFO]: Epoch 017 - training loss: 0.5748, validation loss: 3.7779
2024-06-04 04:01:47 [INFO]: Epoch 018 - training loss: 0.5787, validation loss: 3.7764
2024-06-04 04:04:38 [INFO]: Epoch 019 - training loss: 0.5755, validation loss: 3.7786
2024-06-04 04:07:20 [INFO]: Epoch 020 - training loss: 0.5794, validation loss: 3.7738
2024-06-04 04:09:53 [INFO]: Epoch 021 - training loss: 0.5762, validation loss: 3.7751
2024-06-04 04:12:25 [INFO]: Epoch 022 - training loss: 0.5710, validation loss: 3.7748
2024-06-04 04:14:58 [INFO]: Epoch 023 - training loss: 0.5723, validation loss: 3.7747
2024-06-04 04:17:31 [INFO]: Epoch 024 - training loss: 0.5715, validation loss: 3.7754
2024-06-04 04:20:03 [INFO]: Epoch 025 - training loss: 0.5706, validation loss: 3.7715
2024-06-04 04:22:36 [INFO]: Epoch 026 - training loss: 0.5695, validation loss: 3.7748
2024-06-04 04:25:09 [INFO]: Epoch 027 - training loss: 0.5700, validation loss: 3.7742
2024-06-04 04:27:41 [INFO]: Epoch 028 - training loss: 0.5738, validation loss: 3.7735
2024-06-04 04:30:14 [INFO]: Epoch 029 - training loss: 0.5714, validation loss: 3.7729
2024-06-04 04:32:47 [INFO]: Epoch 030 - training loss: 0.5635, validation loss: 3.7683
2024-06-04 04:35:19 [INFO]: Epoch 031 - training loss: 0.5660, validation loss: 3.7669
2024-06-04 04:37:52 [INFO]: Epoch 032 - training loss: 0.5652, validation loss: 3.7683
2024-06-04 04:40:24 [INFO]: Epoch 033 - training loss: 0.5636, validation loss: 3.7721
2024-06-04 04:42:57 [INFO]: Epoch 034 - training loss: 0.5646, validation loss: 3.7667
2024-06-04 04:45:30 [INFO]: Epoch 035 - training loss: 0.5648, validation loss: 3.7720
2024-06-04 04:48:02 [INFO]: Epoch 036 - training loss: 0.5614, validation loss: 3.7728
2024-06-04 04:50:35 [INFO]: Epoch 037 - training loss: 0.5637, validation loss: 3.7657
2024-06-04 04:53:08 [INFO]: Epoch 038 - training loss: 0.5586, validation loss: 3.7651
2024-06-04 04:55:41 [INFO]: Epoch 039 - training loss: 0.5624, validation loss: 3.7655
2024-06-04 04:58:14 [INFO]: Epoch 040 - training loss: 0.5602, validation loss: 3.7675
2024-06-04 05:00:46 [INFO]: Epoch 041 - training loss: 0.5665, validation loss: 3.7683
2024-06-04 05:03:19 [INFO]: Epoch 042 - training loss: 0.5607, validation loss: 3.7616
2024-06-04 05:05:52 [INFO]: Epoch 043 - training loss: 0.5590, validation loss: 3.7663
2024-06-04 05:08:24 [INFO]: Epoch 044 - training loss: 0.5558, validation loss: 3.7632
2024-06-04 05:10:57 [INFO]: Epoch 045 - training loss: 0.5558, validation loss: 3.7691
2024-06-04 05:13:29 [INFO]: Epoch 046 - training loss: 0.5598, validation loss: 3.7633
2024-06-04 05:16:02 [INFO]: Epoch 047 - training loss: 0.5574, validation loss: 3.7637
2024-06-04 05:18:35 [INFO]: Epoch 048 - training loss: 0.5555, validation loss: 3.7586
2024-06-04 05:21:08 [INFO]: Epoch 049 - training loss: 0.5507, validation loss: 3.7616
2024-06-04 05:23:40 [INFO]: Epoch 050 - training loss: 0.5571, validation loss: 3.7585
2024-06-04 05:26:13 [INFO]: Epoch 051 - training loss: 0.5556, validation loss: 3.7641
2024-06-04 05:28:46 [INFO]: Epoch 052 - training loss: 0.5535, validation loss: 3.7631
2024-06-04 05:31:19 [INFO]: Epoch 053 - training loss: 0.5553, validation loss: 3.7611
2024-06-04 05:33:53 [INFO]: Epoch 054 - training loss: 0.5560, validation loss: 3.7560
2024-06-04 05:36:25 [INFO]: Epoch 055 - training loss: 0.5544, validation loss: 3.7607
2024-06-04 05:38:58 [INFO]: Epoch 056 - training loss: 0.5534, validation loss: 3.7591
2024-06-04 05:41:31 [INFO]: Epoch 057 - training loss: 0.5526, validation loss: 3.7612
2024-06-04 05:44:04 [INFO]: Epoch 058 - training loss: 0.5497, validation loss: 3.7586
2024-06-04 05:46:36 [INFO]: Epoch 059 - training loss: 0.5517, validation loss: 3.7581
2024-06-04 05:49:09 [INFO]: Epoch 060 - training loss: 0.5508, validation loss: 3.7568
2024-06-04 05:51:42 [INFO]: Epoch 061 - training loss: 0.5510, validation loss: 3.7595
2024-06-04 05:54:15 [INFO]: Epoch 062 - training loss: 0.5557, validation loss: 3.7535
2024-06-04 05:56:47 [INFO]: Epoch 063 - training loss: 0.5533, validation loss: 3.7570
2024-06-04 05:59:20 [INFO]: Epoch 064 - training loss: 0.5533, validation loss: 3.7529
2024-06-04 06:01:53 [INFO]: Epoch 065 - training loss: 0.5510, validation loss: 3.7563
2024-06-04 06:04:26 [INFO]: Epoch 066 - training loss: 0.5511, validation loss: 3.7570
2024-06-04 06:06:58 [INFO]: Epoch 067 - training loss: 0.5492, validation loss: 3.7559
2024-06-04 06:09:31 [INFO]: Epoch 068 - training loss: 0.5510, validation loss: 3.7578
2024-06-04 06:12:04 [INFO]: Epoch 069 - training loss: 0.5515, validation loss: 3.7500
2024-06-04 06:14:36 [INFO]: Epoch 070 - training loss: 0.5507, validation loss: 3.7529
2024-06-04 06:17:09 [INFO]: Epoch 071 - training loss: 0.5520, validation loss: 3.7501
2024-06-04 06:19:42 [INFO]: Epoch 072 - training loss: 0.5499, validation loss: 3.7552
2024-06-04 06:22:15 [INFO]: Epoch 073 - training loss: 0.5493, validation loss: 3.7588
2024-06-04 06:24:48 [INFO]: Epoch 074 - training loss: 0.5561, validation loss: 3.7507
2024-06-04 06:27:20 [INFO]: Epoch 075 - training loss: 0.5558, validation loss: 3.7550
2024-06-04 06:29:53 [INFO]: Epoch 076 - training loss: 0.5532, validation loss: 3.7607
2024-06-04 06:32:26 [INFO]: Epoch 077 - training loss: 0.5487, validation loss: 3.7609
2024-06-04 06:34:59 [INFO]: Epoch 078 - training loss: 0.5508, validation loss: 3.7553
2024-06-04 06:37:31 [INFO]: Epoch 079 - training loss: 0.5490, validation loss: 3.7526
2024-06-04 06:37:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 06:37:31 [INFO]: Finished training. The best model is from epoch#69.
2024-06-04 06:37:31 [INFO]: Saved the model to results_point_rate05/Electricity/MRNN_Electricity/round_0/20240604_T025905/MRNN.pypots
2024-06-04 06:39:18 [INFO]: Successfully saved to results_point_rate05/Electricity/MRNN_Electricity/round_0/imputation.pkl
2024-06-04 06:39:18 [INFO]: Round0 - MRNN on Electricity: MAE=1.8044, MSE=5.7847, MRE=0.9661
2024-06-04 06:39:18 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 06:39:18 [INFO]: Using the given device: cuda:0
2024-06-04 06:39:18 [INFO]: Model files will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_1/20240604_T063918
2024-06-04 06:39:18 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_1/20240604_T063918/tensorboard
2024-06-04 06:39:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 949,749
2024-06-04 06:41:58 [INFO]: Epoch 001 - training loss: 1.0498, validation loss: 3.9215
2024-06-04 06:44:31 [INFO]: Epoch 002 - training loss: 0.6799, validation loss: 3.8756
2024-06-04 06:47:03 [INFO]: Epoch 003 - training loss: 0.6426, validation loss: 3.8496
2024-06-04 06:49:36 [INFO]: Epoch 004 - training loss: 0.6350, validation loss: 3.8321
2024-06-04 06:52:09 [INFO]: Epoch 005 - training loss: 0.6291, validation loss: 3.8096
2024-06-04 06:54:42 [INFO]: Epoch 006 - training loss: 0.6180, validation loss: 3.7974
2024-06-04 06:57:15 [INFO]: Epoch 007 - training loss: 0.6112, validation loss: 3.7924
2024-06-04 06:59:47 [INFO]: Epoch 008 - training loss: 0.6083, validation loss: 3.7901
2024-06-04 07:02:20 [INFO]: Epoch 009 - training loss: 0.5976, validation loss: 3.7855
2024-06-04 07:04:53 [INFO]: Epoch 010 - training loss: 0.5986, validation loss: 3.7872
2024-06-04 07:07:26 [INFO]: Epoch 011 - training loss: 0.5953, validation loss: 3.7857
2024-06-04 07:09:58 [INFO]: Epoch 012 - training loss: 0.5899, validation loss: 3.7839
2024-06-04 07:12:31 [INFO]: Epoch 013 - training loss: 0.5864, validation loss: 3.7860
2024-06-04 07:15:04 [INFO]: Epoch 014 - training loss: 0.5873, validation loss: 3.7842
2024-06-04 07:17:36 [INFO]: Epoch 015 - training loss: 0.5860, validation loss: 3.7873
2024-06-04 07:20:09 [INFO]: Epoch 016 - training loss: 0.5772, validation loss: 3.7834
2024-06-04 07:22:42 [INFO]: Epoch 017 - training loss: 0.5801, validation loss: 3.7855
2024-06-04 07:25:15 [INFO]: Epoch 018 - training loss: 0.5779, validation loss: 3.7859
2024-06-04 07:27:47 [INFO]: Epoch 019 - training loss: 0.5764, validation loss: 3.7838
2024-06-04 07:30:20 [INFO]: Epoch 020 - training loss: 0.5772, validation loss: 3.7849
2024-06-04 07:32:52 [INFO]: Epoch 021 - training loss: 0.5822, validation loss: 3.7845
2024-06-04 07:35:25 [INFO]: Epoch 022 - training loss: 0.5753, validation loss: 3.7797
2024-06-04 07:37:57 [INFO]: Epoch 023 - training loss: 0.5693, validation loss: 3.7808
2024-06-04 07:40:30 [INFO]: Epoch 024 - training loss: 0.5714, validation loss: 3.7789
2024-06-04 07:43:03 [INFO]: Epoch 025 - training loss: 0.5708, validation loss: 3.7792
2024-06-04 07:45:35 [INFO]: Epoch 026 - training loss: 0.5715, validation loss: 3.7791
2024-06-04 07:48:08 [INFO]: Epoch 027 - training loss: 0.5661, validation loss: 3.7759
2024-06-04 07:50:41 [INFO]: Epoch 028 - training loss: 0.5666, validation loss: 3.7736
2024-06-04 07:53:14 [INFO]: Epoch 029 - training loss: 0.5656, validation loss: 3.7782
2024-06-04 07:55:47 [INFO]: Epoch 030 - training loss: 0.5647, validation loss: 3.7775
2024-06-04 07:58:20 [INFO]: Epoch 031 - training loss: 0.5624, validation loss: 3.7713
2024-06-04 08:00:11 [INFO]: Epoch 032 - training loss: 0.5612, validation loss: 3.7766
2024-06-04 08:01:32 [INFO]: Epoch 033 - training loss: 0.5664, validation loss: 3.7695
2024-06-04 08:02:54 [INFO]: Epoch 034 - training loss: 0.5630, validation loss: 3.7694
2024-06-04 08:04:16 [INFO]: Epoch 035 - training loss: 0.5594, validation loss: 3.7692
2024-06-04 08:05:38 [INFO]: Epoch 036 - training loss: 0.5606, validation loss: 3.7748
2024-06-04 08:07:00 [INFO]: Epoch 037 - training loss: 0.5603, validation loss: 3.7688
2024-06-04 08:08:22 [INFO]: Epoch 038 - training loss: 0.5606, validation loss: 3.7649
2024-06-04 08:09:44 [INFO]: Epoch 039 - training loss: 0.5660, validation loss: 3.7699
2024-06-04 08:11:05 [INFO]: Epoch 040 - training loss: 0.5597, validation loss: 3.7632
2024-06-04 08:12:17 [INFO]: Epoch 041 - training loss: 0.5595, validation loss: 3.7661
2024-06-04 08:13:26 [INFO]: Epoch 042 - training loss: 0.5631, validation loss: 3.7661
2024-06-04 08:14:36 [INFO]: Epoch 043 - training loss: 0.5619, validation loss: 3.7661
2024-06-04 08:15:45 [INFO]: Epoch 044 - training loss: 0.5553, validation loss: 3.7655
2024-06-04 08:16:54 [INFO]: Epoch 045 - training loss: 0.5588, validation loss: 3.7603
2024-06-04 08:18:03 [INFO]: Epoch 046 - training loss: 0.5571, validation loss: 3.7637
2024-06-04 08:19:12 [INFO]: Epoch 047 - training loss: 0.5569, validation loss: 3.7634
2024-06-04 08:20:22 [INFO]: Epoch 048 - training loss: 0.5631, validation loss: 3.7628
2024-06-04 08:21:31 [INFO]: Epoch 049 - training loss: 0.5533, validation loss: 3.7621
2024-06-04 08:22:40 [INFO]: Epoch 050 - training loss: 0.5588, validation loss: 3.7625
2024-06-04 08:23:49 [INFO]: Epoch 051 - training loss: 0.5546, validation loss: 3.7595
2024-06-04 08:24:58 [INFO]: Epoch 052 - training loss: 0.5554, validation loss: 3.7592
2024-06-04 08:26:07 [INFO]: Epoch 053 - training loss: 0.5546, validation loss: 3.7623
2024-06-04 08:27:17 [INFO]: Epoch 054 - training loss: 0.5518, validation loss: 3.7581
2024-06-04 08:28:26 [INFO]: Epoch 055 - training loss: 0.5598, validation loss: 3.7613
2024-06-04 08:29:35 [INFO]: Epoch 056 - training loss: 0.5589, validation loss: 3.7617
2024-06-04 08:30:44 [INFO]: Epoch 057 - training loss: 0.5553, validation loss: 3.7596
2024-06-04 08:31:53 [INFO]: Epoch 058 - training loss: 0.5545, validation loss: 3.7592
2024-06-04 08:33:03 [INFO]: Epoch 059 - training loss: 0.5510, validation loss: 3.7601
2024-06-04 08:34:12 [INFO]: Epoch 060 - training loss: 0.5558, validation loss: 3.7581
2024-06-04 08:35:21 [INFO]: Epoch 061 - training loss: 0.5539, validation loss: 3.7572
2024-06-04 08:36:30 [INFO]: Epoch 062 - training loss: 0.5503, validation loss: 3.7566
2024-06-04 08:37:39 [INFO]: Epoch 063 - training loss: 0.5517, validation loss: 3.7546
2024-06-04 08:38:48 [INFO]: Epoch 064 - training loss: 0.5515, validation loss: 3.7553
2024-06-04 08:39:58 [INFO]: Epoch 065 - training loss: 0.5499, validation loss: 3.7566
2024-06-04 08:41:07 [INFO]: Epoch 066 - training loss: 0.5498, validation loss: 3.7549
2024-06-04 08:42:16 [INFO]: Epoch 067 - training loss: 0.5518, validation loss: 3.7570
2024-06-04 08:43:25 [INFO]: Epoch 068 - training loss: 0.5505, validation loss: 3.7561
2024-06-04 08:44:34 [INFO]: Epoch 069 - training loss: 0.5607, validation loss: 3.7553
2024-06-04 08:45:44 [INFO]: Epoch 070 - training loss: 0.5536, validation loss: 3.7597
2024-06-04 08:46:53 [INFO]: Epoch 071 - training loss: 0.5511, validation loss: 3.7586
2024-06-04 08:48:02 [INFO]: Epoch 072 - training loss: 0.5502, validation loss: 3.7517
2024-06-04 08:49:11 [INFO]: Epoch 073 - training loss: 0.5486, validation loss: 3.7549
2024-06-04 08:50:20 [INFO]: Epoch 074 - training loss: 0.5512, validation loss: 3.7517
2024-06-04 08:51:29 [INFO]: Epoch 075 - training loss: 0.5561, validation loss: 3.7570
2024-06-04 08:52:39 [INFO]: Epoch 076 - training loss: 0.5560, validation loss: 3.7542
2024-06-04 08:53:48 [INFO]: Epoch 077 - training loss: 0.5532, validation loss: 3.7536
2024-06-04 08:54:57 [INFO]: Epoch 078 - training loss: 0.5465, validation loss: 3.7531
2024-06-04 08:56:06 [INFO]: Epoch 079 - training loss: 0.5511, validation loss: 3.7582
2024-06-04 08:57:15 [INFO]: Epoch 080 - training loss: 0.5501, validation loss: 3.7515
2024-06-04 08:58:25 [INFO]: Epoch 081 - training loss: 0.5498, validation loss: 3.7569
2024-06-04 08:59:34 [INFO]: Epoch 082 - training loss: 0.5467, validation loss: 3.7553
2024-06-04 09:00:43 [INFO]: Epoch 083 - training loss: 0.5484, validation loss: 3.7526
2024-06-04 09:01:52 [INFO]: Epoch 084 - training loss: 0.5485, validation loss: 3.7498
2024-06-04 09:03:01 [INFO]: Epoch 085 - training loss: 0.5476, validation loss: 3.7529
2024-06-04 09:04:11 [INFO]: Epoch 086 - training loss: 0.5480, validation loss: 3.7501
2024-06-04 09:05:20 [INFO]: Epoch 087 - training loss: 0.5468, validation loss: 3.7539
2024-06-04 09:06:29 [INFO]: Epoch 088 - training loss: 0.5497, validation loss: 3.7518
2024-06-04 09:07:38 [INFO]: Epoch 089 - training loss: 0.5477, validation loss: 3.7479
2024-06-04 09:08:47 [INFO]: Epoch 090 - training loss: 0.5458, validation loss: 3.7501
2024-06-04 09:09:57 [INFO]: Epoch 091 - training loss: 0.5470, validation loss: 3.7520
2024-06-04 09:11:06 [INFO]: Epoch 092 - training loss: 0.5491, validation loss: 3.7504
2024-06-04 09:12:15 [INFO]: Epoch 093 - training loss: 0.5467, validation loss: 3.7463
2024-06-04 09:13:24 [INFO]: Epoch 094 - training loss: 0.5474, validation loss: 3.7493
2024-06-04 09:14:33 [INFO]: Epoch 095 - training loss: 0.5477, validation loss: 3.7502
2024-06-04 09:15:42 [INFO]: Epoch 096 - training loss: 0.5475, validation loss: 3.7475
2024-06-04 09:16:52 [INFO]: Epoch 097 - training loss: 0.5470, validation loss: 3.7532
2024-06-04 09:18:01 [INFO]: Epoch 098 - training loss: 0.5463, validation loss: 3.7459
2024-06-04 09:19:10 [INFO]: Epoch 099 - training loss: 0.5455, validation loss: 3.7459
2024-06-04 09:20:19 [INFO]: Epoch 100 - training loss: 0.5450, validation loss: 3.7493
2024-06-04 09:20:19 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 09:20:19 [INFO]: Saved the model to results_point_rate05/Electricity/MRNN_Electricity/round_1/20240604_T063918/MRNN.pypots
2024-06-04 09:21:08 [INFO]: Successfully saved to results_point_rate05/Electricity/MRNN_Electricity/round_1/imputation.pkl
2024-06-04 09:21:08 [INFO]: Round1 - MRNN on Electricity: MAE=1.8145, MSE=5.7961, MRE=0.9715
2024-06-04 09:21:08 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 09:21:08 [INFO]: Using the given device: cuda:0
2024-06-04 09:21:08 [INFO]: Model files will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_2/20240604_T092108
2024-06-04 09:21:08 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_2/20240604_T092108/tensorboard
2024-06-04 09:21:08 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 949,749
2024-06-04 09:22:20 [INFO]: Epoch 001 - training loss: 1.0693, validation loss: 3.9188
2024-06-04 09:23:29 [INFO]: Epoch 002 - training loss: 0.6796, validation loss: 3.8714
2024-06-04 09:24:38 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 3.8516
2024-06-04 09:25:47 [INFO]: Epoch 004 - training loss: 0.6341, validation loss: 3.8290
2024-06-04 09:26:56 [INFO]: Epoch 005 - training loss: 0.6202, validation loss: 3.8101
2024-06-04 09:28:05 [INFO]: Epoch 006 - training loss: 0.6209, validation loss: 3.7964
2024-06-04 09:29:15 [INFO]: Epoch 007 - training loss: 0.6081, validation loss: 3.7926
2024-06-04 09:30:24 [INFO]: Epoch 008 - training loss: 0.6048, validation loss: 3.7910
2024-06-04 09:31:33 [INFO]: Epoch 009 - training loss: 0.6011, validation loss: 3.7883
2024-06-04 09:32:42 [INFO]: Epoch 010 - training loss: 0.6003, validation loss: 3.7868
2024-06-04 09:33:51 [INFO]: Epoch 011 - training loss: 0.5943, validation loss: 3.7852
2024-06-04 09:35:00 [INFO]: Epoch 012 - training loss: 0.5929, validation loss: 3.7895
2024-06-04 09:36:09 [INFO]: Epoch 013 - training loss: 0.5869, validation loss: 3.7894
2024-06-04 09:37:18 [INFO]: Epoch 014 - training loss: 0.5798, validation loss: 3.7873
2024-06-04 09:38:28 [INFO]: Epoch 015 - training loss: 0.5887, validation loss: 3.7857
2024-06-04 09:39:37 [INFO]: Epoch 016 - training loss: 0.5788, validation loss: 3.7851
2024-06-04 09:40:46 [INFO]: Epoch 017 - training loss: 0.5811, validation loss: 3.7819
2024-06-04 09:41:55 [INFO]: Epoch 018 - training loss: 0.5782, validation loss: 3.7812
2024-06-04 09:43:04 [INFO]: Epoch 019 - training loss: 0.5798, validation loss: 3.7870
2024-06-04 09:44:13 [INFO]: Epoch 020 - training loss: 0.5770, validation loss: 3.7807
2024-06-04 09:45:23 [INFO]: Epoch 021 - training loss: 0.5738, validation loss: 3.7820
2024-06-04 09:46:32 [INFO]: Epoch 022 - training loss: 0.5710, validation loss: 3.7765
2024-06-04 09:47:41 [INFO]: Epoch 023 - training loss: 0.5695, validation loss: 3.7800
2024-06-04 09:48:50 [INFO]: Epoch 024 - training loss: 0.5685, validation loss: 3.7832
2024-06-04 09:49:59 [INFO]: Epoch 025 - training loss: 0.5717, validation loss: 3.7854
2024-06-04 09:51:09 [INFO]: Epoch 026 - training loss: 0.5644, validation loss: 3.7810
2024-06-04 09:52:18 [INFO]: Epoch 027 - training loss: 0.5725, validation loss: 3.7765
2024-06-04 09:53:27 [INFO]: Epoch 028 - training loss: 0.5650, validation loss: 3.7795
2024-06-04 09:54:36 [INFO]: Epoch 029 - training loss: 0.5643, validation loss: 3.7757
2024-06-04 09:55:45 [INFO]: Epoch 030 - training loss: 0.5648, validation loss: 3.7765
2024-06-04 09:56:54 [INFO]: Epoch 031 - training loss: 0.5634, validation loss: 3.7775
2024-06-04 09:58:04 [INFO]: Epoch 032 - training loss: 0.5646, validation loss: 3.7750
2024-06-04 09:59:13 [INFO]: Epoch 033 - training loss: 0.5639, validation loss: 3.7793
2024-06-04 10:00:22 [INFO]: Epoch 034 - training loss: 0.5638, validation loss: 3.7771
2024-06-04 10:01:31 [INFO]: Epoch 035 - training loss: 0.5667, validation loss: 3.7775
2024-06-04 10:02:40 [INFO]: Epoch 036 - training loss: 0.5682, validation loss: 3.7713
2024-06-04 10:03:49 [INFO]: Epoch 037 - training loss: 0.5604, validation loss: 3.7711
2024-06-04 10:04:58 [INFO]: Epoch 038 - training loss: 0.5607, validation loss: 3.7733
2024-06-04 10:06:08 [INFO]: Epoch 039 - training loss: 0.5632, validation loss: 3.7734
2024-06-04 10:07:17 [INFO]: Epoch 040 - training loss: 0.5596, validation loss: 3.7704
2024-06-04 10:08:26 [INFO]: Epoch 041 - training loss: 0.5589, validation loss: 3.7700
2024-06-04 10:09:35 [INFO]: Epoch 042 - training loss: 0.5551, validation loss: 3.7695
2024-06-04 10:10:44 [INFO]: Epoch 043 - training loss: 0.5571, validation loss: 3.7712
2024-06-04 10:11:53 [INFO]: Epoch 044 - training loss: 0.5587, validation loss: 3.7693
2024-06-04 10:13:02 [INFO]: Epoch 045 - training loss: 0.5583, validation loss: 3.7690
2024-06-04 10:14:12 [INFO]: Epoch 046 - training loss: 0.5541, validation loss: 3.7695
2024-06-04 10:15:21 [INFO]: Epoch 047 - training loss: 0.5559, validation loss: 3.7684
2024-06-04 10:16:30 [INFO]: Epoch 048 - training loss: 0.5589, validation loss: 3.7681
2024-06-04 10:17:39 [INFO]: Epoch 049 - training loss: 0.5581, validation loss: 3.7655
2024-06-04 10:18:48 [INFO]: Epoch 050 - training loss: 0.5538, validation loss: 3.7672
2024-06-04 10:19:57 [INFO]: Epoch 051 - training loss: 0.5550, validation loss: 3.7730
2024-06-04 10:21:07 [INFO]: Epoch 052 - training loss: 0.5566, validation loss: 3.7672
2024-06-04 10:22:16 [INFO]: Epoch 053 - training loss: 0.5561, validation loss: 3.7644
2024-06-04 10:23:25 [INFO]: Epoch 054 - training loss: 0.5598, validation loss: 3.7680
2024-06-04 10:24:34 [INFO]: Epoch 055 - training loss: 0.5570, validation loss: 3.7633
2024-06-04 10:25:43 [INFO]: Epoch 056 - training loss: 0.5528, validation loss: 3.7636
2024-06-04 10:26:52 [INFO]: Epoch 057 - training loss: 0.5524, validation loss: 3.7645
2024-06-04 10:28:01 [INFO]: Epoch 058 - training loss: 0.5539, validation loss: 3.7603
2024-06-04 10:29:11 [INFO]: Epoch 059 - training loss: 0.5537, validation loss: 3.7628
2024-06-04 10:30:20 [INFO]: Epoch 060 - training loss: 0.5536, validation loss: 3.7625
2024-06-04 10:31:29 [INFO]: Epoch 061 - training loss: 0.5526, validation loss: 3.7637
2024-06-04 10:32:38 [INFO]: Epoch 062 - training loss: 0.5520, validation loss: 3.7659
2024-06-04 10:33:47 [INFO]: Epoch 063 - training loss: 0.5505, validation loss: 3.7646
2024-06-04 10:34:56 [INFO]: Epoch 064 - training loss: 0.5522, validation loss: 3.7606
2024-06-04 10:36:05 [INFO]: Epoch 065 - training loss: 0.5539, validation loss: 3.7598
2024-06-04 10:37:15 [INFO]: Epoch 066 - training loss: 0.5529, validation loss: 3.7615
2024-06-04 10:38:24 [INFO]: Epoch 067 - training loss: 0.5507, validation loss: 3.7630
2024-06-04 10:39:33 [INFO]: Epoch 068 - training loss: 0.5513, validation loss: 3.7588
2024-06-04 10:40:42 [INFO]: Epoch 069 - training loss: 0.5487, validation loss: 3.7614
2024-06-04 10:41:51 [INFO]: Epoch 070 - training loss: 0.5467, validation loss: 3.7593
2024-06-04 10:43:00 [INFO]: Epoch 071 - training loss: 0.5487, validation loss: 3.7550
2024-06-04 10:44:09 [INFO]: Epoch 072 - training loss: 0.5494, validation loss: 3.7595
2024-06-04 10:45:19 [INFO]: Epoch 073 - training loss: 0.5507, validation loss: 3.7591
2024-06-04 10:46:28 [INFO]: Epoch 074 - training loss: 0.5487, validation loss: 3.7624
2024-06-04 10:47:37 [INFO]: Epoch 075 - training loss: 0.5499, validation loss: 3.7567
2024-06-04 10:48:46 [INFO]: Epoch 076 - training loss: 0.5501, validation loss: 3.7572
2024-06-04 10:49:55 [INFO]: Epoch 077 - training loss: 0.5474, validation loss: 3.7553
2024-06-04 10:51:04 [INFO]: Epoch 078 - training loss: 0.5508, validation loss: 3.7645
2024-06-04 10:52:14 [INFO]: Epoch 079 - training loss: 0.5504, validation loss: 3.7577
2024-06-04 10:53:23 [INFO]: Epoch 080 - training loss: 0.5496, validation loss: 3.7596
2024-06-04 10:54:32 [INFO]: Epoch 081 - training loss: 0.5544, validation loss: 3.7564
2024-06-04 10:54:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 10:54:32 [INFO]: Finished training. The best model is from epoch#71.
2024-06-04 10:54:32 [INFO]: Saved the model to results_point_rate05/Electricity/MRNN_Electricity/round_2/20240604_T092108/MRNN.pypots
2024-06-04 10:55:21 [INFO]: Successfully saved to results_point_rate05/Electricity/MRNN_Electricity/round_2/imputation.pkl
2024-06-04 10:55:21 [INFO]: Round2 - MRNN on Electricity: MAE=1.8143, MSE=5.8102, MRE=0.9714
2024-06-04 10:55:21 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 10:55:21 [INFO]: Using the given device: cuda:0
2024-06-04 10:55:21 [INFO]: Model files will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_3/20240604_T105521
2024-06-04 10:55:21 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_3/20240604_T105521/tensorboard
2024-06-04 10:55:21 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 949,749
2024-06-04 10:56:33 [INFO]: Epoch 001 - training loss: 1.0640, validation loss: 3.9117
2024-06-04 10:57:42 [INFO]: Epoch 002 - training loss: 0.6784, validation loss: 3.8679
2024-06-04 10:58:51 [INFO]: Epoch 003 - training loss: 0.6420, validation loss: 3.8468
2024-06-04 11:00:00 [INFO]: Epoch 004 - training loss: 0.6304, validation loss: 3.8252
2024-06-04 11:01:09 [INFO]: Epoch 005 - training loss: 0.6218, validation loss: 3.8093
2024-06-04 11:02:18 [INFO]: Epoch 006 - training loss: 0.6147, validation loss: 3.8000
2024-06-04 11:03:27 [INFO]: Epoch 007 - training loss: 0.6093, validation loss: 3.7980
2024-06-04 11:04:37 [INFO]: Epoch 008 - training loss: 0.6029, validation loss: 3.7963
2024-06-04 11:05:46 [INFO]: Epoch 009 - training loss: 0.5944, validation loss: 3.7880
2024-06-04 11:06:55 [INFO]: Epoch 010 - training loss: 0.5940, validation loss: 3.7875
2024-06-04 11:08:04 [INFO]: Epoch 011 - training loss: 0.6114, validation loss: 3.7860
2024-06-04 11:09:13 [INFO]: Epoch 012 - training loss: 0.5983, validation loss: 3.7911
2024-06-04 11:10:22 [INFO]: Epoch 013 - training loss: 0.5871, validation loss: 3.7863
2024-06-04 11:11:32 [INFO]: Epoch 014 - training loss: 0.5876, validation loss: 3.7882
2024-06-04 11:12:41 [INFO]: Epoch 015 - training loss: 0.5850, validation loss: 3.7880
2024-06-04 11:13:50 [INFO]: Epoch 016 - training loss: 0.5774, validation loss: 3.7867
2024-06-04 11:14:59 [INFO]: Epoch 017 - training loss: 0.5809, validation loss: 3.7859
2024-06-04 11:16:08 [INFO]: Epoch 018 - training loss: 0.5793, validation loss: 3.7845
2024-06-04 11:17:17 [INFO]: Epoch 019 - training loss: 0.5770, validation loss: 3.7880
2024-06-04 11:18:26 [INFO]: Epoch 020 - training loss: 0.5784, validation loss: 3.7872
2024-06-04 11:19:36 [INFO]: Epoch 021 - training loss: 0.5734, validation loss: 3.7849
2024-06-04 11:20:45 [INFO]: Epoch 022 - training loss: 0.5768, validation loss: 3.7872
2024-06-04 11:21:54 [INFO]: Epoch 023 - training loss: 0.5722, validation loss: 3.7798
2024-06-04 11:23:03 [INFO]: Epoch 024 - training loss: 0.5709, validation loss: 3.7792
2024-06-04 11:24:12 [INFO]: Epoch 025 - training loss: 0.5692, validation loss: 3.7823
2024-06-04 11:25:21 [INFO]: Epoch 026 - training loss: 0.5760, validation loss: 3.7782
2024-06-04 11:26:30 [INFO]: Epoch 027 - training loss: 0.5732, validation loss: 3.7797
2024-06-04 11:27:39 [INFO]: Epoch 028 - training loss: 0.5677, validation loss: 3.7783
2024-06-04 11:28:48 [INFO]: Epoch 029 - training loss: 0.5633, validation loss: 3.7807
2024-06-04 11:29:58 [INFO]: Epoch 030 - training loss: 0.5675, validation loss: 3.7768
2024-06-04 11:31:07 [INFO]: Epoch 031 - training loss: 0.5624, validation loss: 3.7787
2024-06-04 11:32:16 [INFO]: Epoch 032 - training loss: 0.5637, validation loss: 3.7723
2024-06-04 11:33:25 [INFO]: Epoch 033 - training loss: 0.5649, validation loss: 3.7755
2024-06-04 11:34:34 [INFO]: Epoch 034 - training loss: 0.5602, validation loss: 3.7718
2024-06-04 11:35:43 [INFO]: Epoch 035 - training loss: 0.5633, validation loss: 3.7714
2024-06-04 11:36:52 [INFO]: Epoch 036 - training loss: 0.5651, validation loss: 3.7713
2024-06-04 11:38:01 [INFO]: Epoch 037 - training loss: 0.5582, validation loss: 3.7726
2024-06-04 11:39:11 [INFO]: Epoch 038 - training loss: 0.5592, validation loss: 3.7744
2024-06-04 11:40:20 [INFO]: Epoch 039 - training loss: 0.5650, validation loss: 3.7689
2024-06-04 11:41:29 [INFO]: Epoch 040 - training loss: 0.5637, validation loss: 3.7708
2024-06-04 11:42:38 [INFO]: Epoch 041 - training loss: 0.5568, validation loss: 3.7663
2024-06-04 11:43:47 [INFO]: Epoch 042 - training loss: 0.5591, validation loss: 3.7710
2024-06-04 11:44:56 [INFO]: Epoch 043 - training loss: 0.5586, validation loss: 3.7750
2024-06-04 11:46:05 [INFO]: Epoch 044 - training loss: 0.5584, validation loss: 3.7684
2024-06-04 11:47:14 [INFO]: Epoch 045 - training loss: 0.5554, validation loss: 3.7633
2024-06-04 11:48:24 [INFO]: Epoch 046 - training loss: 0.5532, validation loss: 3.7637
2024-06-04 11:49:33 [INFO]: Epoch 047 - training loss: 0.5571, validation loss: 3.7687
2024-06-04 11:50:42 [INFO]: Epoch 048 - training loss: 0.5584, validation loss: 3.7656
2024-06-04 11:51:51 [INFO]: Epoch 049 - training loss: 0.5594, validation loss: 3.7662
2024-06-04 11:53:00 [INFO]: Epoch 050 - training loss: 0.5547, validation loss: 3.7647
2024-06-04 11:54:09 [INFO]: Epoch 051 - training loss: 0.5558, validation loss: 3.7601
2024-06-04 11:55:18 [INFO]: Epoch 052 - training loss: 0.5515, validation loss: 3.7624
2024-06-04 11:56:27 [INFO]: Epoch 053 - training loss: 0.5548, validation loss: 3.7613
2024-06-04 11:57:36 [INFO]: Epoch 054 - training loss: 0.5536, validation loss: 3.7591
2024-06-04 11:58:46 [INFO]: Epoch 055 - training loss: 0.5539, validation loss: 3.7648
2024-06-04 11:59:55 [INFO]: Epoch 056 - training loss: 0.5574, validation loss: 3.7717
2024-06-04 12:01:04 [INFO]: Epoch 057 - training loss: 0.5588, validation loss: 3.7578
2024-06-04 12:02:13 [INFO]: Epoch 058 - training loss: 0.5544, validation loss: 3.7614
2024-06-04 12:03:22 [INFO]: Epoch 059 - training loss: 0.5549, validation loss: 3.7557
2024-06-04 12:04:31 [INFO]: Epoch 060 - training loss: 0.5496, validation loss: 3.7621
2024-06-04 12:05:40 [INFO]: Epoch 061 - training loss: 0.5502, validation loss: 3.7608
2024-06-04 12:06:49 [INFO]: Epoch 062 - training loss: 0.5518, validation loss: 3.7599
2024-06-04 12:07:58 [INFO]: Epoch 063 - training loss: 0.5519, validation loss: 3.7584
2024-06-04 12:09:08 [INFO]: Epoch 064 - training loss: 0.5513, validation loss: 3.7604
2024-06-04 12:10:17 [INFO]: Epoch 065 - training loss: 0.5502, validation loss: 3.7615
2024-06-04 12:11:26 [INFO]: Epoch 066 - training loss: 0.5544, validation loss: 3.7540
2024-06-04 12:12:35 [INFO]: Epoch 067 - training loss: 0.5508, validation loss: 3.7555
2024-06-04 12:13:44 [INFO]: Epoch 068 - training loss: 0.5493, validation loss: 3.7555
2024-06-04 12:14:53 [INFO]: Epoch 069 - training loss: 0.5510, validation loss: 3.7555
2024-06-04 12:16:02 [INFO]: Epoch 070 - training loss: 0.5511, validation loss: 3.7591
2024-06-04 12:17:11 [INFO]: Epoch 071 - training loss: 0.5503, validation loss: 3.7555
2024-06-04 12:18:21 [INFO]: Epoch 072 - training loss: 0.5496, validation loss: 3.7601
2024-06-04 12:19:30 [INFO]: Epoch 073 - training loss: 0.5508, validation loss: 3.7580
2024-06-04 12:20:39 [INFO]: Epoch 074 - training loss: 0.5479, validation loss: 3.7551
2024-06-04 12:21:48 [INFO]: Epoch 075 - training loss: 0.5465, validation loss: 3.7543
2024-06-04 12:22:57 [INFO]: Epoch 076 - training loss: 0.5492, validation loss: 3.7551
2024-06-04 12:22:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 12:22:57 [INFO]: Finished training. The best model is from epoch#66.
2024-06-04 12:22:57 [INFO]: Saved the model to results_point_rate05/Electricity/MRNN_Electricity/round_3/20240604_T105521/MRNN.pypots
2024-06-04 12:23:46 [INFO]: Successfully saved to results_point_rate05/Electricity/MRNN_Electricity/round_3/imputation.pkl
2024-06-04 12:23:46 [INFO]: Round3 - MRNN on Electricity: MAE=1.8112, MSE=5.7931, MRE=0.9697
2024-06-04 12:23:46 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 12:23:46 [INFO]: Using the given device: cuda:0
2024-06-04 12:23:46 [INFO]: Model files will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_4/20240604_T122346
2024-06-04 12:23:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/MRNN_Electricity/round_4/20240604_T122346/tensorboard
2024-06-04 12:23:46 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 949,749
2024-06-04 12:24:58 [INFO]: Epoch 001 - training loss: 1.0582, validation loss: 3.9222
2024-06-04 12:26:07 [INFO]: Epoch 002 - training loss: 0.6778, validation loss: 3.8761
2024-06-04 12:27:16 [INFO]: Epoch 003 - training loss: 0.6405, validation loss: 3.8484
2024-06-04 12:28:25 [INFO]: Epoch 004 - training loss: 0.6297, validation loss: 3.8312
2024-06-04 12:29:34 [INFO]: Epoch 005 - training loss: 0.6208, validation loss: 3.8064
2024-06-04 12:30:43 [INFO]: Epoch 006 - training loss: 0.6141, validation loss: 3.7956
2024-06-04 12:31:52 [INFO]: Epoch 007 - training loss: 0.6110, validation loss: 3.7947
2024-06-04 12:33:01 [INFO]: Epoch 008 - training loss: 0.6097, validation loss: 3.7924
2024-06-04 12:34:10 [INFO]: Epoch 009 - training loss: 0.6054, validation loss: 3.7875
2024-06-04 12:35:20 [INFO]: Epoch 010 - training loss: 0.5978, validation loss: 3.7860
2024-06-04 12:36:29 [INFO]: Epoch 011 - training loss: 0.5940, validation loss: 3.7808
2024-06-04 12:37:38 [INFO]: Epoch 012 - training loss: 0.5893, validation loss: 3.7829
2024-06-04 12:38:47 [INFO]: Epoch 013 - training loss: 0.5873, validation loss: 3.7831
2024-06-04 12:39:56 [INFO]: Epoch 014 - training loss: 0.5871, validation loss: 3.7839
2024-06-04 12:41:05 [INFO]: Epoch 015 - training loss: 0.5836, validation loss: 3.7828
2024-06-04 12:42:14 [INFO]: Epoch 016 - training loss: 0.5815, validation loss: 3.7833
2024-06-04 12:43:23 [INFO]: Epoch 017 - training loss: 0.5764, validation loss: 3.7820
2024-06-04 12:44:32 [INFO]: Epoch 018 - training loss: 0.5769, validation loss: 3.7851
2024-06-04 12:45:41 [INFO]: Epoch 019 - training loss: 0.5723, validation loss: 3.7788
2024-06-04 12:46:51 [INFO]: Epoch 020 - training loss: 0.5730, validation loss: 3.7797
2024-06-04 12:48:00 [INFO]: Epoch 021 - training loss: 0.5729, validation loss: 3.7822
2024-06-04 12:49:09 [INFO]: Epoch 022 - training loss: 0.5740, validation loss: 3.7774
2024-06-04 12:50:18 [INFO]: Epoch 023 - training loss: 0.5702, validation loss: 3.7792
2024-06-04 12:51:27 [INFO]: Epoch 024 - training loss: 0.5692, validation loss: 3.7783
2024-06-04 12:52:36 [INFO]: Epoch 025 - training loss: 0.5700, validation loss: 3.7766
2024-06-04 12:53:45 [INFO]: Epoch 026 - training loss: 0.5678, validation loss: 3.7774
2024-06-04 12:54:54 [INFO]: Epoch 027 - training loss: 0.5653, validation loss: 3.7800
2024-06-04 12:56:04 [INFO]: Epoch 028 - training loss: 0.5652, validation loss: 3.7741
2024-06-04 12:57:13 [INFO]: Epoch 029 - training loss: 0.5656, validation loss: 3.7729
2024-06-04 12:58:22 [INFO]: Epoch 030 - training loss: 0.5600, validation loss: 3.7725
2024-06-04 12:59:31 [INFO]: Epoch 031 - training loss: 0.5624, validation loss: 3.7755
2024-06-04 13:00:40 [INFO]: Epoch 032 - training loss: 0.5629, validation loss: 3.7730
2024-06-04 13:01:49 [INFO]: Epoch 033 - training loss: 0.5605, validation loss: 3.7725
2024-06-04 13:02:58 [INFO]: Epoch 034 - training loss: 0.5608, validation loss: 3.7713
2024-06-04 13:04:08 [INFO]: Epoch 035 - training loss: 0.5656, validation loss: 3.7694
2024-06-04 13:05:17 [INFO]: Epoch 036 - training loss: 0.5609, validation loss: 3.7686
2024-06-04 13:06:26 [INFO]: Epoch 037 - training loss: 0.5583, validation loss: 3.7664
2024-06-04 13:07:35 [INFO]: Epoch 038 - training loss: 0.5598, validation loss: 3.7678
2024-06-04 13:08:44 [INFO]: Epoch 039 - training loss: 0.5657, validation loss: 3.7677
2024-06-04 13:09:53 [INFO]: Epoch 040 - training loss: 0.5588, validation loss: 3.7694
2024-06-04 13:11:02 [INFO]: Epoch 041 - training loss: 0.5602, validation loss: 3.7664
2024-06-04 13:12:11 [INFO]: Epoch 042 - training loss: 0.5596, validation loss: 3.7647
2024-06-04 13:13:20 [INFO]: Epoch 043 - training loss: 0.5586, validation loss: 3.7651
2024-06-04 13:14:30 [INFO]: Epoch 044 - training loss: 0.5615, validation loss: 3.7653
2024-06-04 13:15:39 [INFO]: Epoch 045 - training loss: 0.5680, validation loss: 3.7646
2024-06-04 13:16:48 [INFO]: Epoch 046 - training loss: 0.5577, validation loss: 3.7632
2024-06-04 13:17:57 [INFO]: Epoch 047 - training loss: 0.5576, validation loss: 3.7664
2024-06-04 13:19:06 [INFO]: Epoch 048 - training loss: 0.5555, validation loss: 3.7649
2024-06-04 13:20:15 [INFO]: Epoch 049 - training loss: 0.5552, validation loss: 3.7651
2024-06-04 13:21:24 [INFO]: Epoch 050 - training loss: 0.5578, validation loss: 3.7611
2024-06-04 13:22:33 [INFO]: Epoch 051 - training loss: 0.5547, validation loss: 3.7600
2024-06-04 13:23:43 [INFO]: Epoch 052 - training loss: 0.5542, validation loss: 3.7614
2024-06-04 13:24:52 [INFO]: Epoch 053 - training loss: 0.5538, validation loss: 3.7635
2024-06-04 13:26:01 [INFO]: Epoch 054 - training loss: 0.5534, validation loss: 3.7634
2024-06-04 13:27:10 [INFO]: Epoch 055 - training loss: 0.5556, validation loss: 3.7575
2024-06-04 13:28:19 [INFO]: Epoch 056 - training loss: 0.5508, validation loss: 3.7588
2024-06-04 13:29:28 [INFO]: Epoch 057 - training loss: 0.5506, validation loss: 3.7613
2024-06-04 13:30:37 [INFO]: Epoch 058 - training loss: 0.5509, validation loss: 3.7589
2024-06-04 13:31:46 [INFO]: Epoch 059 - training loss: 0.5509, validation loss: 3.7602
2024-06-04 13:32:56 [INFO]: Epoch 060 - training loss: 0.5553, validation loss: 3.7566
2024-06-04 13:34:05 [INFO]: Epoch 061 - training loss: 0.5534, validation loss: 3.7609
2024-06-04 13:35:14 [INFO]: Epoch 062 - training loss: 0.5515, validation loss: 3.7561
2024-06-04 13:36:23 [INFO]: Epoch 063 - training loss: 0.5513, validation loss: 3.7567
2024-06-04 13:37:32 [INFO]: Epoch 064 - training loss: 0.5528, validation loss: 3.7600
2024-06-04 13:38:41 [INFO]: Epoch 065 - training loss: 0.5488, validation loss: 3.7562
2024-06-04 13:39:50 [INFO]: Epoch 066 - training loss: 0.5515, validation loss: 3.7581
2024-06-04 13:40:59 [INFO]: Epoch 067 - training loss: 0.5487, validation loss: 3.7528
2024-06-04 13:42:09 [INFO]: Epoch 068 - training loss: 0.5531, validation loss: 3.7537
2024-06-04 13:43:18 [INFO]: Epoch 069 - training loss: 0.5511, validation loss: 3.7554
2024-06-04 13:44:27 [INFO]: Epoch 070 - training loss: 0.5479, validation loss: 3.7557
2024-06-04 13:45:36 [INFO]: Epoch 071 - training loss: 0.5502, validation loss: 3.7541
2024-06-04 13:46:45 [INFO]: Epoch 072 - training loss: 0.5509, validation loss: 3.7552
2024-06-04 13:47:54 [INFO]: Epoch 073 - training loss: 0.5503, validation loss: 3.7543
2024-06-04 13:49:03 [INFO]: Epoch 074 - training loss: 0.5469, validation loss: 3.7543
2024-06-04 13:50:12 [INFO]: Epoch 075 - training loss: 0.5493, validation loss: 3.7552
2024-06-04 13:51:22 [INFO]: Epoch 076 - training loss: 0.5492, validation loss: 3.7528
2024-06-04 13:52:31 [INFO]: Epoch 077 - training loss: 0.5487, validation loss: 3.7529
2024-06-04 13:53:40 [INFO]: Epoch 078 - training loss: 0.5475, validation loss: 3.7511
2024-06-04 13:54:49 [INFO]: Epoch 079 - training loss: 0.5485, validation loss: 3.7527
2024-06-04 13:55:58 [INFO]: Epoch 080 - training loss: 0.5476, validation loss: 3.7514
2024-06-04 13:57:07 [INFO]: Epoch 081 - training loss: 0.5498, validation loss: 3.7517
2024-06-04 13:58:16 [INFO]: Epoch 082 - training loss: 0.5502, validation loss: 3.7514
2024-06-04 13:59:25 [INFO]: Epoch 083 - training loss: 0.5481, validation loss: 3.7503
2024-06-04 14:00:35 [INFO]: Epoch 084 - training loss: 0.5485, validation loss: 3.7502
2024-06-04 14:01:44 [INFO]: Epoch 085 - training loss: 0.5491, validation loss: 3.7484
2024-06-04 14:02:53 [INFO]: Epoch 086 - training loss: 0.5478, validation loss: 3.7503
2024-06-04 14:04:02 [INFO]: Epoch 087 - training loss: 0.5489, validation loss: 3.7486
2024-06-04 14:05:11 [INFO]: Epoch 088 - training loss: 0.5482, validation loss: 3.7517
2024-06-04 14:06:20 [INFO]: Epoch 089 - training loss: 0.5466, validation loss: 3.7481
2024-06-04 14:07:29 [INFO]: Epoch 090 - training loss: 0.5478, validation loss: 3.7504
2024-06-04 14:08:39 [INFO]: Epoch 091 - training loss: 0.5483, validation loss: 3.7529
2024-06-04 14:09:48 [INFO]: Epoch 092 - training loss: 0.5475, validation loss: 3.7517
2024-06-04 14:10:57 [INFO]: Epoch 093 - training loss: 0.5474, validation loss: 3.7513
2024-06-04 14:12:06 [INFO]: Epoch 094 - training loss: 0.5450, validation loss: 3.7457
2024-06-04 14:13:15 [INFO]: Epoch 095 - training loss: 0.5463, validation loss: 3.7453
2024-06-04 14:14:24 [INFO]: Epoch 096 - training loss: 0.5457, validation loss: 3.7473
2024-06-04 14:15:33 [INFO]: Epoch 097 - training loss: 0.5464, validation loss: 3.7459
2024-06-04 14:16:42 [INFO]: Epoch 098 - training loss: 0.5452, validation loss: 3.7451
2024-06-04 14:17:52 [INFO]: Epoch 099 - training loss: 0.5465, validation loss: 3.7469
2024-06-04 14:19:01 [INFO]: Epoch 100 - training loss: 0.5454, validation loss: 3.7450
2024-06-04 14:19:01 [INFO]: Finished training. The best model is from epoch#100.
2024-06-04 14:19:01 [INFO]: Saved the model to results_point_rate05/Electricity/MRNN_Electricity/round_4/20240604_T122346/MRNN.pypots
2024-06-04 14:19:49 [INFO]: Successfully saved to results_point_rate05/Electricity/MRNN_Electricity/round_4/imputation.pkl
2024-06-04 14:19:49 [INFO]: Round4 - MRNN on Electricity: MAE=1.8051, MSE=5.7789, MRE=0.9665
2024-06-04 14:19:49 [INFO]: Done! Final results:
Averaged MRNN (949,749 params) on Electricity: MAE=1.8099 ± 0.004358901947578485, MSE=5.7926 ± 0.010690111030906401, MRE=0.9690 ± 0.002333784914103979, average inference time=12.76
