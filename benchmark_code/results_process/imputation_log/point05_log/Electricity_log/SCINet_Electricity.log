2024-06-04 02:52:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:52:46 [INFO]: Using the given device: cuda:0
2024-06-04 02:52:46 [INFO]: Model files will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_0/20240604_T025246
2024-06-04 02:52:46 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_0/20240604_T025246/tensorboard
2024-06-04 02:52:58 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-04 02:53:23 [INFO]: Epoch 001 - training loss: 1.1743, validation loss: 3.4932
2024-06-04 02:53:44 [INFO]: Epoch 002 - training loss: 0.8157, validation loss: 3.2050
2024-06-04 02:54:06 [INFO]: Epoch 003 - training loss: 0.6829, validation loss: 3.0281
2024-06-04 02:54:27 [INFO]: Epoch 004 - training loss: 0.6274, validation loss: 2.8204
2024-06-04 02:54:48 [INFO]: Epoch 005 - training loss: 0.5939, validation loss: 2.6818
2024-06-04 02:55:09 [INFO]: Epoch 006 - training loss: 0.5684, validation loss: 2.5159
2024-06-04 02:55:29 [INFO]: Epoch 007 - training loss: 0.5500, validation loss: 2.4062
2024-06-04 02:55:51 [INFO]: Epoch 008 - training loss: 0.5338, validation loss: 2.2809
2024-06-04 02:56:11 [INFO]: Epoch 009 - training loss: 0.5222, validation loss: 2.1993
2024-06-04 02:56:33 [INFO]: Epoch 010 - training loss: 0.5117, validation loss: 2.1013
2024-06-04 02:56:54 [INFO]: Epoch 011 - training loss: 0.5033, validation loss: 2.0173
2024-06-04 02:57:15 [INFO]: Epoch 012 - training loss: 0.4964, validation loss: 1.9410
2024-06-04 02:57:36 [INFO]: Epoch 013 - training loss: 0.4909, validation loss: 1.8868
2024-06-04 02:57:57 [INFO]: Epoch 014 - training loss: 0.4866, validation loss: 1.8328
2024-06-04 02:58:18 [INFO]: Epoch 015 - training loss: 0.4829, validation loss: 1.7836
2024-06-04 02:58:39 [INFO]: Epoch 016 - training loss: 0.4800, validation loss: 1.7231
2024-06-04 02:59:00 [INFO]: Epoch 017 - training loss: 0.4762, validation loss: 1.6790
2024-06-04 02:59:22 [INFO]: Epoch 018 - training loss: 0.4737, validation loss: 1.6482
2024-06-04 02:59:43 [INFO]: Epoch 019 - training loss: 0.4716, validation loss: 1.6084
2024-06-04 03:00:04 [INFO]: Epoch 020 - training loss: 0.4681, validation loss: 1.5579
2024-06-04 03:00:25 [INFO]: Epoch 021 - training loss: 0.4683, validation loss: 1.5353
2024-06-04 03:00:45 [INFO]: Epoch 022 - training loss: 0.4670, validation loss: 1.5179
2024-06-04 03:01:07 [INFO]: Epoch 023 - training loss: 0.4655, validation loss: 1.4852
2024-06-04 03:01:28 [INFO]: Epoch 024 - training loss: 0.4628, validation loss: 1.4460
2024-06-04 03:01:49 [INFO]: Epoch 025 - training loss: 0.4614, validation loss: 1.4167
2024-06-04 03:02:11 [INFO]: Epoch 026 - training loss: 0.4606, validation loss: 1.4133
2024-06-04 03:02:32 [INFO]: Epoch 027 - training loss: 0.4590, validation loss: 1.3747
2024-06-04 03:02:53 [INFO]: Epoch 028 - training loss: 0.4576, validation loss: 1.3475
2024-06-04 03:03:15 [INFO]: Epoch 029 - training loss: 0.4568, validation loss: 1.3544
2024-06-04 03:03:36 [INFO]: Epoch 030 - training loss: 0.4555, validation loss: 1.3157
2024-06-04 03:03:57 [INFO]: Epoch 031 - training loss: 0.4545, validation loss: 1.3159
2024-06-04 03:04:19 [INFO]: Epoch 032 - training loss: 0.4531, validation loss: 1.2893
2024-06-04 03:04:40 [INFO]: Epoch 033 - training loss: 0.4525, validation loss: 1.2768
2024-06-04 03:05:02 [INFO]: Epoch 034 - training loss: 0.4514, validation loss: 1.2409
2024-06-04 03:05:23 [INFO]: Epoch 035 - training loss: 0.4506, validation loss: 1.2439
2024-06-04 03:05:45 [INFO]: Epoch 036 - training loss: 0.4500, validation loss: 1.2229
2024-06-04 03:06:05 [INFO]: Epoch 037 - training loss: 0.4492, validation loss: 1.2171
2024-06-04 03:06:26 [INFO]: Epoch 038 - training loss: 0.4481, validation loss: 1.1913
2024-06-04 03:06:48 [INFO]: Epoch 039 - training loss: 0.4463, validation loss: 1.1791
2024-06-04 03:07:09 [INFO]: Epoch 040 - training loss: 0.4448, validation loss: 1.1681
2024-06-04 03:07:31 [INFO]: Epoch 041 - training loss: 0.4444, validation loss: 1.1586
2024-06-04 03:07:52 [INFO]: Epoch 042 - training loss: 0.4422, validation loss: 1.1448
2024-06-04 03:08:13 [INFO]: Epoch 043 - training loss: 0.4421, validation loss: 1.1263
2024-06-04 03:08:34 [INFO]: Epoch 044 - training loss: 0.4408, validation loss: 1.0949
2024-06-04 03:08:55 [INFO]: Epoch 045 - training loss: 0.4399, validation loss: 1.0994
2024-06-04 03:09:16 [INFO]: Epoch 046 - training loss: 0.4380, validation loss: 1.0849
2024-06-04 03:09:37 [INFO]: Epoch 047 - training loss: 0.4363, validation loss: 1.0665
2024-06-04 03:09:58 [INFO]: Epoch 048 - training loss: 0.4342, validation loss: 1.0704
2024-06-04 03:10:20 [INFO]: Epoch 049 - training loss: 0.4340, validation loss: 1.0542
2024-06-04 03:10:41 [INFO]: Epoch 050 - training loss: 0.4324, validation loss: 1.0458
2024-06-04 03:11:03 [INFO]: Epoch 051 - training loss: 0.4317, validation loss: 1.0462
2024-06-04 03:11:24 [INFO]: Epoch 052 - training loss: 0.4307, validation loss: 1.0384
2024-06-04 03:11:46 [INFO]: Epoch 053 - training loss: 0.4296, validation loss: 1.0337
2024-06-04 03:12:07 [INFO]: Epoch 054 - training loss: 0.4297, validation loss: 1.0172
2024-06-04 03:12:28 [INFO]: Epoch 055 - training loss: 0.4298, validation loss: 1.0257
2024-06-04 03:12:50 [INFO]: Epoch 056 - training loss: 0.4291, validation loss: 1.0319
2024-06-04 03:13:11 [INFO]: Epoch 057 - training loss: 0.4286, validation loss: 1.0284
2024-06-04 03:13:32 [INFO]: Epoch 058 - training loss: 0.4275, validation loss: 1.0194
2024-06-04 03:13:53 [INFO]: Epoch 059 - training loss: 0.4278, validation loss: 1.0146
2024-06-04 03:14:14 [INFO]: Epoch 060 - training loss: 0.4282, validation loss: 1.0091
2024-06-04 03:14:36 [INFO]: Epoch 061 - training loss: 0.4276, validation loss: 1.0119
2024-06-04 03:14:56 [INFO]: Epoch 062 - training loss: 0.4274, validation loss: 1.0111
2024-06-04 03:15:17 [INFO]: Epoch 063 - training loss: 0.4273, validation loss: 1.0036
2024-06-04 03:15:39 [INFO]: Epoch 064 - training loss: 0.4271, validation loss: 0.9977
2024-06-04 03:16:01 [INFO]: Epoch 065 - training loss: 0.4270, validation loss: 1.0005
2024-06-04 03:16:22 [INFO]: Epoch 066 - training loss: 0.4263, validation loss: 0.9982
2024-06-04 03:16:44 [INFO]: Epoch 067 - training loss: 0.4267, validation loss: 1.0003
2024-06-04 03:17:05 [INFO]: Epoch 068 - training loss: 0.4264, validation loss: 1.0052
2024-06-04 03:17:26 [INFO]: Epoch 069 - training loss: 0.4271, validation loss: 0.9899
2024-06-04 03:17:47 [INFO]: Epoch 070 - training loss: 0.4270, validation loss: 0.9955
2024-06-04 03:18:08 [INFO]: Epoch 071 - training loss: 0.4270, validation loss: 0.9906
2024-06-04 03:18:29 [INFO]: Epoch 072 - training loss: 0.4269, validation loss: 0.9938
2024-06-04 03:18:51 [INFO]: Epoch 073 - training loss: 0.4264, validation loss: 0.9994
2024-06-04 03:19:12 [INFO]: Epoch 074 - training loss: 0.4268, validation loss: 0.9933
2024-06-04 03:19:33 [INFO]: Epoch 075 - training loss: 0.4264, validation loss: 0.9797
2024-06-04 03:19:54 [INFO]: Epoch 076 - training loss: 0.4264, validation loss: 0.9901
2024-06-04 03:20:15 [INFO]: Epoch 077 - training loss: 0.4263, validation loss: 0.9912
2024-06-04 03:20:37 [INFO]: Epoch 078 - training loss: 0.4256, validation loss: 0.9832
2024-06-04 03:20:58 [INFO]: Epoch 079 - training loss: 0.4260, validation loss: 0.9914
2024-06-04 03:21:20 [INFO]: Epoch 080 - training loss: 0.4253, validation loss: 0.9861
2024-06-04 03:21:41 [INFO]: Epoch 081 - training loss: 0.4253, validation loss: 0.9843
2024-06-04 03:22:02 [INFO]: Epoch 082 - training loss: 0.4261, validation loss: 0.9744
2024-06-04 03:22:24 [INFO]: Epoch 083 - training loss: 0.4253, validation loss: 0.9833
2024-06-04 03:22:45 [INFO]: Epoch 084 - training loss: 0.4251, validation loss: 0.9646
2024-06-04 03:23:06 [INFO]: Epoch 085 - training loss: 0.4257, validation loss: 0.9701
2024-06-04 03:23:26 [INFO]: Epoch 086 - training loss: 0.4250, validation loss: 0.9693
2024-06-04 03:23:46 [INFO]: Epoch 087 - training loss: 0.4252, validation loss: 0.9627
2024-06-04 03:24:08 [INFO]: Epoch 088 - training loss: 0.4246, validation loss: 0.9533
2024-06-04 03:24:29 [INFO]: Epoch 089 - training loss: 0.4245, validation loss: 0.9543
2024-06-04 03:24:49 [INFO]: Epoch 090 - training loss: 0.4248, validation loss: 0.9655
2024-06-04 03:25:10 [INFO]: Epoch 091 - training loss: 0.4244, validation loss: 0.9562
2024-06-04 03:25:31 [INFO]: Epoch 092 - training loss: 0.4246, validation loss: 0.9539
2024-06-04 03:25:53 [INFO]: Epoch 093 - training loss: 0.4245, validation loss: 0.9644
2024-06-04 03:26:14 [INFO]: Epoch 094 - training loss: 0.4243, validation loss: 0.9581
2024-06-04 03:26:35 [INFO]: Epoch 095 - training loss: 0.4240, validation loss: 0.9692
2024-06-04 03:26:57 [INFO]: Epoch 096 - training loss: 0.4247, validation loss: 0.9657
2024-06-04 03:27:17 [INFO]: Epoch 097 - training loss: 0.4244, validation loss: 0.9544
2024-06-04 03:27:39 [INFO]: Epoch 098 - training loss: 0.4248, validation loss: 0.9625
2024-06-04 03:27:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:27:39 [INFO]: Finished training. The best model is from epoch#88.
2024-06-04 03:27:48 [INFO]: Saved the model to results_point_rate05/Electricity/SCINet_Electricity/round_0/20240604_T025246/SCINet.pypots
2024-06-04 03:27:57 [INFO]: Successfully saved to results_point_rate05/Electricity/SCINet_Electricity/round_0/imputation.pkl
2024-06-04 03:27:57 [INFO]: Round0 - SCINet on Electricity: MAE=0.7571, MSE=1.0288, MRE=0.4054
2024-06-04 03:27:57 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:27:57 [INFO]: Using the given device: cuda:0
2024-06-04 03:27:57 [INFO]: Model files will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_1/20240604_T032757
2024-06-04 03:27:57 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_1/20240604_T032757/tensorboard
2024-06-04 03:28:08 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-04 03:28:30 [INFO]: Epoch 001 - training loss: 1.1876, validation loss: 3.6251
2024-06-04 03:28:51 [INFO]: Epoch 002 - training loss: 0.8113, validation loss: 3.2458
2024-06-04 03:29:13 [INFO]: Epoch 003 - training loss: 0.7006, validation loss: 3.1289
2024-06-04 03:29:34 [INFO]: Epoch 004 - training loss: 0.6481, validation loss: 3.0053
2024-06-04 03:29:56 [INFO]: Epoch 005 - training loss: 0.6158, validation loss: 2.9344
2024-06-04 03:30:17 [INFO]: Epoch 006 - training loss: 0.5930, validation loss: 2.8335
2024-06-04 03:30:39 [INFO]: Epoch 007 - training loss: 0.5753, validation loss: 2.7833
2024-06-04 03:31:00 [INFO]: Epoch 008 - training loss: 0.5609, validation loss: 2.7085
2024-06-04 03:31:21 [INFO]: Epoch 009 - training loss: 0.5486, validation loss: 2.5951
2024-06-04 03:31:42 [INFO]: Epoch 010 - training loss: 0.5371, validation loss: 2.5363
2024-06-04 03:32:03 [INFO]: Epoch 011 - training loss: 0.5273, validation loss: 2.4462
2024-06-04 03:32:24 [INFO]: Epoch 012 - training loss: 0.5181, validation loss: 2.3386
2024-06-04 03:32:45 [INFO]: Epoch 013 - training loss: 0.5050, validation loss: 2.2048
2024-06-04 03:33:06 [INFO]: Epoch 014 - training loss: 0.4914, validation loss: 2.0624
2024-06-04 03:33:27 [INFO]: Epoch 015 - training loss: 0.4783, validation loss: 1.9378
2024-06-04 03:33:48 [INFO]: Epoch 016 - training loss: 0.4649, validation loss: 1.8396
2024-06-04 03:34:10 [INFO]: Epoch 017 - training loss: 0.4520, validation loss: 1.7520
2024-06-04 03:34:31 [INFO]: Epoch 018 - training loss: 0.4402, validation loss: 1.6694
2024-06-04 03:34:52 [INFO]: Epoch 019 - training loss: 0.4309, validation loss: 1.6236
2024-06-04 03:35:14 [INFO]: Epoch 020 - training loss: 0.4212, validation loss: 1.5904
2024-06-04 03:35:35 [INFO]: Epoch 021 - training loss: 0.4131, validation loss: 1.5587
2024-06-04 03:35:56 [INFO]: Epoch 022 - training loss: 0.4074, validation loss: 1.5191
2024-06-04 03:36:17 [INFO]: Epoch 023 - training loss: 0.4005, validation loss: 1.4918
2024-06-04 03:36:38 [INFO]: Epoch 024 - training loss: 0.3954, validation loss: 1.4886
2024-06-04 03:36:59 [INFO]: Epoch 025 - training loss: 0.3899, validation loss: 1.4634
2024-06-04 03:37:20 [INFO]: Epoch 026 - training loss: 0.3837, validation loss: 1.4574
2024-06-04 03:37:41 [INFO]: Epoch 027 - training loss: 0.3795, validation loss: 1.4488
2024-06-04 03:38:02 [INFO]: Epoch 028 - training loss: 0.3756, validation loss: 1.4456
2024-06-04 03:38:22 [INFO]: Epoch 029 - training loss: 0.3704, validation loss: 1.4405
2024-06-04 03:38:42 [INFO]: Epoch 030 - training loss: 0.3664, validation loss: 1.4393
2024-06-04 03:39:03 [INFO]: Epoch 031 - training loss: 0.3625, validation loss: 1.4322
2024-06-04 03:39:23 [INFO]: Epoch 032 - training loss: 0.3591, validation loss: 1.4349
2024-06-04 03:39:43 [INFO]: Epoch 033 - training loss: 0.3524, validation loss: 1.4359
2024-06-04 03:40:03 [INFO]: Epoch 034 - training loss: 0.3491, validation loss: 1.4389
2024-06-04 03:40:23 [INFO]: Epoch 035 - training loss: 0.3458, validation loss: 1.4537
2024-06-04 03:40:44 [INFO]: Epoch 036 - training loss: 0.3417, validation loss: 1.4494
2024-06-04 03:41:03 [INFO]: Epoch 037 - training loss: 0.3364, validation loss: 1.4459
2024-06-04 03:41:23 [INFO]: Epoch 038 - training loss: 0.3349, validation loss: 1.4462
2024-06-04 03:41:44 [INFO]: Epoch 039 - training loss: 0.3309, validation loss: 1.4633
2024-06-04 03:42:04 [INFO]: Epoch 040 - training loss: 0.3285, validation loss: 1.4607
2024-06-04 03:42:24 [INFO]: Epoch 041 - training loss: 0.3239, validation loss: 1.4659
2024-06-04 03:42:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:42:24 [INFO]: Finished training. The best model is from epoch#31.
2024-06-04 03:42:32 [INFO]: Saved the model to results_point_rate05/Electricity/SCINet_Electricity/round_1/20240604_T032757/SCINet.pypots
2024-06-04 03:42:40 [INFO]: Successfully saved to results_point_rate05/Electricity/SCINet_Electricity/round_1/imputation.pkl
2024-06-04 03:42:40 [INFO]: Round1 - SCINet on Electricity: MAE=0.8163, MSE=1.3152, MRE=0.4371
2024-06-04 03:42:40 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:42:40 [INFO]: Using the given device: cuda:0
2024-06-04 03:42:40 [INFO]: Model files will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_2/20240604_T034240
2024-06-04 03:42:40 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_2/20240604_T034240/tensorboard
2024-06-04 03:42:49 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-04 03:43:09 [INFO]: Epoch 001 - training loss: 1.1928, validation loss: 3.5074
2024-06-04 03:43:29 [INFO]: Epoch 002 - training loss: 0.8198, validation loss: 3.1272
2024-06-04 03:43:50 [INFO]: Epoch 003 - training loss: 0.6985, validation loss: 2.9606
2024-06-04 03:44:09 [INFO]: Epoch 004 - training loss: 0.6359, validation loss: 2.8124
2024-06-04 03:44:28 [INFO]: Epoch 005 - training loss: 0.6019, validation loss: 2.6759
2024-06-04 03:44:48 [INFO]: Epoch 006 - training loss: 0.5795, validation loss: 2.5660
2024-06-04 03:45:08 [INFO]: Epoch 007 - training loss: 0.5603, validation loss: 2.4846
2024-06-04 03:45:28 [INFO]: Epoch 008 - training loss: 0.5464, validation loss: 2.4257
2024-06-04 03:45:48 [INFO]: Epoch 009 - training loss: 0.5357, validation loss: 2.3232
2024-06-04 03:46:09 [INFO]: Epoch 010 - training loss: 0.5269, validation loss: 2.2504
2024-06-04 03:46:29 [INFO]: Epoch 011 - training loss: 0.5202, validation loss: 2.2140
2024-06-04 03:46:49 [INFO]: Epoch 012 - training loss: 0.5134, validation loss: 2.1333
2024-06-04 03:47:08 [INFO]: Epoch 013 - training loss: 0.5080, validation loss: 2.0646
2024-06-04 03:47:29 [INFO]: Epoch 014 - training loss: 0.5043, validation loss: 2.0110
2024-06-04 03:47:49 [INFO]: Epoch 015 - training loss: 0.5013, validation loss: 1.9576
2024-06-04 03:48:09 [INFO]: Epoch 016 - training loss: 0.4981, validation loss: 1.9101
2024-06-04 03:48:29 [INFO]: Epoch 017 - training loss: 0.4971, validation loss: 1.8526
2024-06-04 03:48:50 [INFO]: Epoch 018 - training loss: 0.4938, validation loss: 1.8210
2024-06-04 03:49:10 [INFO]: Epoch 019 - training loss: 0.4890, validation loss: 1.7747
2024-06-04 03:49:31 [INFO]: Epoch 020 - training loss: 0.4878, validation loss: 1.7334
2024-06-04 03:49:51 [INFO]: Epoch 021 - training loss: 0.4869, validation loss: 1.6961
2024-06-04 03:50:10 [INFO]: Epoch 022 - training loss: 0.4847, validation loss: 1.6577
2024-06-04 03:50:30 [INFO]: Epoch 023 - training loss: 0.4826, validation loss: 1.6319
2024-06-04 03:50:50 [INFO]: Epoch 024 - training loss: 0.4812, validation loss: 1.5945
2024-06-04 03:51:10 [INFO]: Epoch 025 - training loss: 0.4812, validation loss: 1.5764
2024-06-04 03:51:31 [INFO]: Epoch 026 - training loss: 0.4803, validation loss: 1.5355
2024-06-04 03:51:51 [INFO]: Epoch 027 - training loss: 0.4788, validation loss: 1.5009
2024-06-04 03:52:11 [INFO]: Epoch 028 - training loss: 0.4771, validation loss: 1.4824
2024-06-04 03:52:31 [INFO]: Epoch 029 - training loss: 0.4764, validation loss: 1.4710
2024-06-04 03:52:51 [INFO]: Epoch 030 - training loss: 0.4753, validation loss: 1.4326
2024-06-04 03:53:11 [INFO]: Epoch 031 - training loss: 0.4746, validation loss: 1.4235
2024-06-04 03:53:31 [INFO]: Epoch 032 - training loss: 0.4731, validation loss: 1.3915
2024-06-04 03:53:51 [INFO]: Epoch 033 - training loss: 0.4725, validation loss: 1.3937
2024-06-04 03:54:12 [INFO]: Epoch 034 - training loss: 0.4715, validation loss: 1.3763
2024-06-04 03:54:32 [INFO]: Epoch 035 - training loss: 0.4715, validation loss: 1.3543
2024-06-04 03:54:53 [INFO]: Epoch 036 - training loss: 0.4697, validation loss: 1.3335
2024-06-04 03:55:13 [INFO]: Epoch 037 - training loss: 0.4702, validation loss: 1.3233
2024-06-04 03:55:33 [INFO]: Epoch 038 - training loss: 0.4690, validation loss: 1.3099
2024-06-04 03:55:53 [INFO]: Epoch 039 - training loss: 0.4683, validation loss: 1.2849
2024-06-04 03:56:14 [INFO]: Epoch 040 - training loss: 0.4663, validation loss: 1.2659
2024-06-04 03:56:34 [INFO]: Epoch 041 - training loss: 0.4653, validation loss: 1.2596
2024-06-04 03:56:54 [INFO]: Epoch 042 - training loss: 0.4642, validation loss: 1.2437
2024-06-04 03:57:15 [INFO]: Epoch 043 - training loss: 0.4629, validation loss: 1.2390
2024-06-04 03:57:35 [INFO]: Epoch 044 - training loss: 0.4608, validation loss: 1.2108
2024-06-04 03:57:56 [INFO]: Epoch 045 - training loss: 0.4597, validation loss: 1.2164
2024-06-04 03:58:16 [INFO]: Epoch 046 - training loss: 0.4586, validation loss: 1.2001
2024-06-04 03:58:36 [INFO]: Epoch 047 - training loss: 0.4571, validation loss: 1.1821
2024-06-04 03:58:56 [INFO]: Epoch 048 - training loss: 0.4560, validation loss: 1.1812
2024-06-04 03:59:17 [INFO]: Epoch 049 - training loss: 0.4545, validation loss: 1.1636
2024-06-04 03:59:37 [INFO]: Epoch 050 - training loss: 0.4529, validation loss: 1.1523
2024-06-04 03:59:57 [INFO]: Epoch 051 - training loss: 0.4517, validation loss: 1.1427
2024-06-04 04:00:17 [INFO]: Epoch 052 - training loss: 0.4499, validation loss: 1.1258
2024-06-04 04:00:38 [INFO]: Epoch 053 - training loss: 0.4483, validation loss: 1.1131
2024-06-04 04:00:59 [INFO]: Epoch 054 - training loss: 0.4468, validation loss: 1.0971
2024-06-04 04:01:19 [INFO]: Epoch 055 - training loss: 0.4450, validation loss: 1.0816
2024-06-04 04:01:39 [INFO]: Epoch 056 - training loss: 0.4426, validation loss: 1.0787
2024-06-04 04:01:59 [INFO]: Epoch 057 - training loss: 0.4401, validation loss: 1.0676
2024-06-04 04:02:19 [INFO]: Epoch 058 - training loss: 0.4382, validation loss: 1.0539
2024-06-04 04:02:39 [INFO]: Epoch 059 - training loss: 0.4374, validation loss: 1.0544
2024-06-04 04:02:59 [INFO]: Epoch 060 - training loss: 0.4366, validation loss: 1.0462
2024-06-04 04:03:20 [INFO]: Epoch 061 - training loss: 0.4349, validation loss: 1.0412
2024-06-04 04:03:39 [INFO]: Epoch 062 - training loss: 0.4351, validation loss: 1.0371
2024-06-04 04:03:59 [INFO]: Epoch 063 - training loss: 0.4346, validation loss: 1.0284
2024-06-04 04:04:19 [INFO]: Epoch 064 - training loss: 0.4332, validation loss: 1.0265
2024-06-04 04:04:40 [INFO]: Epoch 065 - training loss: 0.4337, validation loss: 1.0110
2024-06-04 04:05:00 [INFO]: Epoch 066 - training loss: 0.4335, validation loss: 1.0117
2024-06-04 04:05:20 [INFO]: Epoch 067 - training loss: 0.4333, validation loss: 1.0110
2024-06-04 04:05:40 [INFO]: Epoch 068 - training loss: 0.4333, validation loss: 1.0026
2024-06-04 04:06:01 [INFO]: Epoch 069 - training loss: 0.4321, validation loss: 0.9997
2024-06-04 04:06:21 [INFO]: Epoch 070 - training loss: 0.4324, validation loss: 1.0061
2024-06-04 04:06:41 [INFO]: Epoch 071 - training loss: 0.4321, validation loss: 1.0069
2024-06-04 04:07:01 [INFO]: Epoch 072 - training loss: 0.4309, validation loss: 1.0075
2024-06-04 04:07:21 [INFO]: Epoch 073 - training loss: 0.4326, validation loss: 0.9976
2024-06-04 04:07:40 [INFO]: Epoch 074 - training loss: 0.4317, validation loss: 0.9898
2024-06-04 04:08:00 [INFO]: Epoch 075 - training loss: 0.4310, validation loss: 0.9865
2024-06-04 04:08:20 [INFO]: Epoch 076 - training loss: 0.4312, validation loss: 0.9839
2024-06-04 04:08:40 [INFO]: Epoch 077 - training loss: 0.4317, validation loss: 0.9821
2024-06-04 04:09:01 [INFO]: Epoch 078 - training loss: 0.4309, validation loss: 0.9886
2024-06-04 04:09:21 [INFO]: Epoch 079 - training loss: 0.4313, validation loss: 0.9808
2024-06-04 04:09:41 [INFO]: Epoch 080 - training loss: 0.4314, validation loss: 0.9851
2024-06-04 04:10:01 [INFO]: Epoch 081 - training loss: 0.4311, validation loss: 0.9847
2024-06-04 04:10:21 [INFO]: Epoch 082 - training loss: 0.4309, validation loss: 0.9798
2024-06-04 04:10:42 [INFO]: Epoch 083 - training loss: 0.4306, validation loss: 0.9829
2024-06-04 04:11:02 [INFO]: Epoch 084 - training loss: 0.4302, validation loss: 0.9818
2024-06-04 04:11:22 [INFO]: Epoch 085 - training loss: 0.4305, validation loss: 0.9712
2024-06-04 04:11:42 [INFO]: Epoch 086 - training loss: 0.4302, validation loss: 0.9682
2024-06-04 04:12:02 [INFO]: Epoch 087 - training loss: 0.4301, validation loss: 0.9745
2024-06-04 04:12:22 [INFO]: Epoch 088 - training loss: 0.4302, validation loss: 0.9711
2024-06-04 04:12:43 [INFO]: Epoch 089 - training loss: 0.4302, validation loss: 0.9629
2024-06-04 04:13:03 [INFO]: Epoch 090 - training loss: 0.4299, validation loss: 0.9639
2024-06-04 04:13:23 [INFO]: Epoch 091 - training loss: 0.4300, validation loss: 0.9651
2024-06-04 04:13:43 [INFO]: Epoch 092 - training loss: 0.4308, validation loss: 0.9758
2024-06-04 04:14:03 [INFO]: Epoch 093 - training loss: 0.4300, validation loss: 0.9694
2024-06-04 04:14:24 [INFO]: Epoch 094 - training loss: 0.4301, validation loss: 0.9695
2024-06-04 04:14:44 [INFO]: Epoch 095 - training loss: 0.4297, validation loss: 0.9676
2024-06-04 04:15:04 [INFO]: Epoch 096 - training loss: 0.4292, validation loss: 0.9616
2024-06-04 04:15:24 [INFO]: Epoch 097 - training loss: 0.4298, validation loss: 0.9622
2024-06-04 04:15:44 [INFO]: Epoch 098 - training loss: 0.4297, validation loss: 0.9586
2024-06-04 04:16:04 [INFO]: Epoch 099 - training loss: 0.4296, validation loss: 0.9539
2024-06-04 04:16:24 [INFO]: Epoch 100 - training loss: 0.4298, validation loss: 0.9665
2024-06-04 04:16:24 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:16:32 [INFO]: Saved the model to results_point_rate05/Electricity/SCINet_Electricity/round_2/20240604_T034240/SCINet.pypots
2024-06-04 04:16:40 [INFO]: Successfully saved to results_point_rate05/Electricity/SCINet_Electricity/round_2/imputation.pkl
2024-06-04 04:16:40 [INFO]: Round2 - SCINet on Electricity: MAE=0.7703, MSE=1.0847, MRE=0.4124
2024-06-04 04:16:40 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 04:16:40 [INFO]: Using the given device: cuda:0
2024-06-04 04:16:40 [INFO]: Model files will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_3/20240604_T041640
2024-06-04 04:16:40 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_3/20240604_T041640/tensorboard
2024-06-04 04:16:49 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-04 04:17:10 [INFO]: Epoch 001 - training loss: 1.1197, validation loss: 3.2963
2024-06-04 04:17:30 [INFO]: Epoch 002 - training loss: 0.7330, validation loss: 2.9264
2024-06-04 04:17:50 [INFO]: Epoch 003 - training loss: 0.6112, validation loss: 2.6848
2024-06-04 04:18:10 [INFO]: Epoch 004 - training loss: 0.5450, validation loss: 2.5317
2024-06-04 04:18:30 [INFO]: Epoch 005 - training loss: 0.5058, validation loss: 2.4185
2024-06-04 04:18:50 [INFO]: Epoch 006 - training loss: 0.4791, validation loss: 2.3165
2024-06-04 04:19:10 [INFO]: Epoch 007 - training loss: 0.4601, validation loss: 2.2443
2024-06-04 04:19:30 [INFO]: Epoch 008 - training loss: 0.4435, validation loss: 2.1562
2024-06-04 04:19:50 [INFO]: Epoch 009 - training loss: 0.4319, validation loss: 2.0934
2024-06-04 04:20:10 [INFO]: Epoch 010 - training loss: 0.4239, validation loss: 2.0338
2024-06-04 04:20:31 [INFO]: Epoch 011 - training loss: 0.4153, validation loss: 1.9646
2024-06-04 04:20:51 [INFO]: Epoch 012 - training loss: 0.4065, validation loss: 1.9167
2024-06-04 04:21:11 [INFO]: Epoch 013 - training loss: 0.4002, validation loss: 1.8589
2024-06-04 04:21:31 [INFO]: Epoch 014 - training loss: 0.3945, validation loss: 1.8090
2024-06-04 04:21:51 [INFO]: Epoch 015 - training loss: 0.3891, validation loss: 1.7820
2024-06-04 04:22:11 [INFO]: Epoch 016 - training loss: 0.3836, validation loss: 1.7333
2024-06-04 04:22:31 [INFO]: Epoch 017 - training loss: 0.3799, validation loss: 1.7192
2024-06-04 04:22:51 [INFO]: Epoch 018 - training loss: 0.3766, validation loss: 1.6890
2024-06-04 04:23:11 [INFO]: Epoch 019 - training loss: 0.3716, validation loss: 1.6623
2024-06-04 04:23:31 [INFO]: Epoch 020 - training loss: 0.3686, validation loss: 1.6455
2024-06-04 04:23:51 [INFO]: Epoch 021 - training loss: 0.3651, validation loss: 1.6225
2024-06-04 04:24:11 [INFO]: Epoch 022 - training loss: 0.3628, validation loss: 1.5971
2024-06-04 04:24:31 [INFO]: Epoch 023 - training loss: 0.3595, validation loss: 1.5887
2024-06-04 04:24:51 [INFO]: Epoch 024 - training loss: 0.3562, validation loss: 1.5694
2024-06-04 04:25:12 [INFO]: Epoch 025 - training loss: 0.3534, validation loss: 1.5634
2024-06-04 04:25:32 [INFO]: Epoch 026 - training loss: 0.3512, validation loss: 1.5558
2024-06-04 04:25:51 [INFO]: Epoch 027 - training loss: 0.3480, validation loss: 1.5516
2024-06-04 04:26:09 [INFO]: Epoch 028 - training loss: 0.3469, validation loss: 1.5416
2024-06-04 04:26:26 [INFO]: Epoch 029 - training loss: 0.3432, validation loss: 1.5425
2024-06-04 04:26:43 [INFO]: Epoch 030 - training loss: 0.3413, validation loss: 1.5237
2024-06-04 04:27:00 [INFO]: Epoch 031 - training loss: 0.3394, validation loss: 1.5342
2024-06-04 04:27:16 [INFO]: Epoch 032 - training loss: 0.3350, validation loss: 1.5295
2024-06-04 04:27:33 [INFO]: Epoch 033 - training loss: 0.3319, validation loss: 1.5293
2024-06-04 04:27:49 [INFO]: Epoch 034 - training loss: 0.3296, validation loss: 1.5257
2024-06-04 04:28:05 [INFO]: Epoch 035 - training loss: 0.3279, validation loss: 1.5302
2024-06-04 04:28:22 [INFO]: Epoch 036 - training loss: 0.3269, validation loss: 1.5314
2024-06-04 04:28:39 [INFO]: Epoch 037 - training loss: 0.3254, validation loss: 1.5325
2024-06-04 04:28:56 [INFO]: Epoch 038 - training loss: 0.3235, validation loss: 1.5461
2024-06-04 04:29:13 [INFO]: Epoch 039 - training loss: 0.3185, validation loss: 1.5484
2024-06-04 04:29:30 [INFO]: Epoch 040 - training loss: 0.3175, validation loss: 1.5420
2024-06-04 04:29:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:29:30 [INFO]: Finished training. The best model is from epoch#30.
2024-06-04 04:29:36 [INFO]: Saved the model to results_point_rate05/Electricity/SCINet_Electricity/round_3/20240604_T041640/SCINet.pypots
2024-06-04 04:29:43 [INFO]: Successfully saved to results_point_rate05/Electricity/SCINet_Electricity/round_3/imputation.pkl
2024-06-04 04:29:43 [INFO]: Round3 - SCINet on Electricity: MAE=0.7572, MSE=1.2836, MRE=0.4054
2024-06-04 04:29:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 04:29:43 [INFO]: Using the given device: cuda:0
2024-06-04 04:29:43 [INFO]: Model files will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_4/20240604_T042943
2024-06-04 04:29:43 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/SCINet_Electricity/round_4/20240604_T042943/tensorboard
2024-06-04 04:29:50 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 421,053,386
2024-06-04 04:30:07 [INFO]: Epoch 001 - training loss: 1.1374, validation loss: 3.3275
2024-06-04 04:30:24 [INFO]: Epoch 002 - training loss: 0.7558, validation loss: 2.8858
2024-06-04 04:30:41 [INFO]: Epoch 003 - training loss: 0.6370, validation loss: 2.6922
2024-06-04 04:30:59 [INFO]: Epoch 004 - training loss: 0.5832, validation loss: 2.5553
2024-06-04 04:31:16 [INFO]: Epoch 005 - training loss: 0.5500, validation loss: 2.4457
2024-06-04 04:31:33 [INFO]: Epoch 006 - training loss: 0.5274, validation loss: 2.3513
2024-06-04 04:31:50 [INFO]: Epoch 007 - training loss: 0.5119, validation loss: 2.2627
2024-06-04 04:32:07 [INFO]: Epoch 008 - training loss: 0.4995, validation loss: 2.1653
2024-06-04 04:32:24 [INFO]: Epoch 009 - training loss: 0.4886, validation loss: 2.0818
2024-06-04 04:32:41 [INFO]: Epoch 010 - training loss: 0.4812, validation loss: 1.9920
2024-06-04 04:32:58 [INFO]: Epoch 011 - training loss: 0.4756, validation loss: 1.8981
2024-06-04 04:33:14 [INFO]: Epoch 012 - training loss: 0.4707, validation loss: 1.8329
2024-06-04 04:33:31 [INFO]: Epoch 013 - training loss: 0.4648, validation loss: 1.7662
2024-06-04 04:33:49 [INFO]: Epoch 014 - training loss: 0.4606, validation loss: 1.6924
2024-06-04 04:34:06 [INFO]: Epoch 015 - training loss: 0.4584, validation loss: 1.6309
2024-06-04 04:34:23 [INFO]: Epoch 016 - training loss: 0.4546, validation loss: 1.5725
2024-06-04 04:34:40 [INFO]: Epoch 017 - training loss: 0.4522, validation loss: 1.5344
2024-06-04 04:34:56 [INFO]: Epoch 018 - training loss: 0.4486, validation loss: 1.4778
2024-06-04 04:35:13 [INFO]: Epoch 019 - training loss: 0.4471, validation loss: 1.4312
2024-06-04 04:35:30 [INFO]: Epoch 020 - training loss: 0.4451, validation loss: 1.4055
2024-06-04 04:35:47 [INFO]: Epoch 021 - training loss: 0.4428, validation loss: 1.3662
2024-06-04 04:36:04 [INFO]: Epoch 022 - training loss: 0.4424, validation loss: 1.3345
2024-06-04 04:36:21 [INFO]: Epoch 023 - training loss: 0.4417, validation loss: 1.3087
2024-06-04 04:36:38 [INFO]: Epoch 024 - training loss: 0.4394, validation loss: 1.2710
2024-06-04 04:36:55 [INFO]: Epoch 025 - training loss: 0.4382, validation loss: 1.2630
2024-06-04 04:37:12 [INFO]: Epoch 026 - training loss: 0.4373, validation loss: 1.2356
2024-06-04 04:37:28 [INFO]: Epoch 027 - training loss: 0.4360, validation loss: 1.2106
2024-06-04 04:37:45 [INFO]: Epoch 028 - training loss: 0.4356, validation loss: 1.1884
2024-06-04 04:38:02 [INFO]: Epoch 029 - training loss: 0.4352, validation loss: 1.1827
2024-06-04 04:38:19 [INFO]: Epoch 030 - training loss: 0.4341, validation loss: 1.1614
2024-06-04 04:38:36 [INFO]: Epoch 031 - training loss: 0.4336, validation loss: 1.1499
2024-06-04 04:38:53 [INFO]: Epoch 032 - training loss: 0.4332, validation loss: 1.1462
2024-06-04 04:39:10 [INFO]: Epoch 033 - training loss: 0.4330, validation loss: 1.1262
2024-06-04 04:39:27 [INFO]: Epoch 034 - training loss: 0.4326, validation loss: 1.1217
2024-06-04 04:39:44 [INFO]: Epoch 035 - training loss: 0.4321, validation loss: 1.1131
2024-06-04 04:40:01 [INFO]: Epoch 036 - training loss: 0.4302, validation loss: 1.1009
2024-06-04 04:40:18 [INFO]: Epoch 037 - training loss: 0.4308, validation loss: 1.1036
2024-06-04 04:40:35 [INFO]: Epoch 038 - training loss: 0.4311, validation loss: 1.0925
2024-06-04 04:40:51 [INFO]: Epoch 039 - training loss: 0.4310, validation loss: 1.0876
2024-06-04 04:41:08 [INFO]: Epoch 040 - training loss: 0.4301, validation loss: 1.0734
2024-06-04 04:41:25 [INFO]: Epoch 041 - training loss: 0.4298, validation loss: 1.0683
2024-06-04 04:41:42 [INFO]: Epoch 042 - training loss: 0.4296, validation loss: 1.0778
2024-06-04 04:41:59 [INFO]: Epoch 043 - training loss: 0.4291, validation loss: 1.0694
2024-06-04 04:42:16 [INFO]: Epoch 044 - training loss: 0.4287, validation loss: 1.0543
2024-06-04 04:42:33 [INFO]: Epoch 045 - training loss: 0.4288, validation loss: 1.0551
2024-06-04 04:42:50 [INFO]: Epoch 046 - training loss: 0.4284, validation loss: 1.0497
2024-06-04 04:43:07 [INFO]: Epoch 047 - training loss: 0.4284, validation loss: 1.0468
2024-06-04 04:43:24 [INFO]: Epoch 048 - training loss: 0.4278, validation loss: 1.0517
2024-06-04 04:43:41 [INFO]: Epoch 049 - training loss: 0.4278, validation loss: 1.0400
2024-06-04 04:43:58 [INFO]: Epoch 050 - training loss: 0.4272, validation loss: 1.0383
2024-06-04 04:44:15 [INFO]: Epoch 051 - training loss: 0.4263, validation loss: 1.0321
2024-06-04 04:44:32 [INFO]: Epoch 052 - training loss: 0.4268, validation loss: 1.0319
2024-06-04 04:44:49 [INFO]: Epoch 053 - training loss: 0.4267, validation loss: 1.0407
2024-06-04 04:45:06 [INFO]: Epoch 054 - training loss: 0.4259, validation loss: 1.0288
2024-06-04 04:45:23 [INFO]: Epoch 055 - training loss: 0.4258, validation loss: 1.0161
2024-06-04 04:45:40 [INFO]: Epoch 056 - training loss: 0.4262, validation loss: 1.0175
2024-06-04 04:45:57 [INFO]: Epoch 057 - training loss: 0.4259, validation loss: 1.0098
2024-06-04 04:46:14 [INFO]: Epoch 058 - training loss: 0.4255, validation loss: 1.0138
2024-06-04 04:46:31 [INFO]: Epoch 059 - training loss: 0.4255, validation loss: 1.0144
2024-06-04 04:46:48 [INFO]: Epoch 060 - training loss: 0.4245, validation loss: 1.0107
2024-06-04 04:47:05 [INFO]: Epoch 061 - training loss: 0.4251, validation loss: 1.0024
2024-06-04 04:47:22 [INFO]: Epoch 062 - training loss: 0.4250, validation loss: 1.0104
2024-06-04 04:47:38 [INFO]: Epoch 063 - training loss: 0.4251, validation loss: 1.0049
2024-06-04 04:47:55 [INFO]: Epoch 064 - training loss: 0.4248, validation loss: 1.0014
2024-06-04 04:48:12 [INFO]: Epoch 065 - training loss: 0.4242, validation loss: 1.0071
2024-06-04 04:48:29 [INFO]: Epoch 066 - training loss: 0.4242, validation loss: 1.0035
2024-06-04 04:48:46 [INFO]: Epoch 067 - training loss: 0.4241, validation loss: 1.0042
2024-06-04 04:49:03 [INFO]: Epoch 068 - training loss: 0.4236, validation loss: 0.9965
2024-06-04 04:49:19 [INFO]: Epoch 069 - training loss: 0.4245, validation loss: 1.0067
2024-06-04 04:49:36 [INFO]: Epoch 070 - training loss: 0.4247, validation loss: 0.9873
2024-06-04 04:49:53 [INFO]: Epoch 071 - training loss: 0.4249, validation loss: 0.9881
2024-06-04 04:50:10 [INFO]: Epoch 072 - training loss: 0.4240, validation loss: 0.9779
2024-06-04 04:50:27 [INFO]: Epoch 073 - training loss: 0.4236, validation loss: 0.9905
2024-06-04 04:50:44 [INFO]: Epoch 074 - training loss: 0.4240, validation loss: 0.9857
2024-06-04 04:51:02 [INFO]: Epoch 075 - training loss: 0.4242, validation loss: 0.9827
2024-06-04 04:51:19 [INFO]: Epoch 076 - training loss: 0.4238, validation loss: 0.9876
2024-06-04 04:51:36 [INFO]: Epoch 077 - training loss: 0.4231, validation loss: 0.9912
2024-06-04 04:51:53 [INFO]: Epoch 078 - training loss: 0.4230, validation loss: 0.9840
2024-06-04 04:52:10 [INFO]: Epoch 079 - training loss: 0.4232, validation loss: 0.9829
2024-06-04 04:52:27 [INFO]: Epoch 080 - training loss: 0.4226, validation loss: 0.9762
2024-06-04 04:52:44 [INFO]: Epoch 081 - training loss: 0.4234, validation loss: 0.9762
2024-06-04 04:53:01 [INFO]: Epoch 082 - training loss: 0.4236, validation loss: 0.9807
2024-06-04 04:53:19 [INFO]: Epoch 083 - training loss: 0.4228, validation loss: 0.9750
2024-06-04 04:53:36 [INFO]: Epoch 084 - training loss: 0.4226, validation loss: 0.9636
2024-06-04 04:53:53 [INFO]: Epoch 085 - training loss: 0.4227, validation loss: 0.9776
2024-06-04 04:54:09 [INFO]: Epoch 086 - training loss: 0.4223, validation loss: 0.9718
2024-06-04 04:54:26 [INFO]: Epoch 087 - training loss: 0.4222, validation loss: 0.9704
2024-06-04 04:54:42 [INFO]: Epoch 088 - training loss: 0.4218, validation loss: 0.9641
2024-06-04 04:54:57 [INFO]: Epoch 089 - training loss: 0.4225, validation loss: 0.9649
2024-06-04 04:55:08 [INFO]: Epoch 090 - training loss: 0.4221, validation loss: 0.9611
2024-06-04 04:55:20 [INFO]: Epoch 091 - training loss: 0.4224, validation loss: 0.9614
2024-06-04 04:55:31 [INFO]: Epoch 092 - training loss: 0.4227, validation loss: 0.9615
2024-06-04 04:55:43 [INFO]: Epoch 093 - training loss: 0.4222, validation loss: 0.9624
2024-06-04 04:55:54 [INFO]: Epoch 094 - training loss: 0.4221, validation loss: 0.9618
2024-06-04 04:56:06 [INFO]: Epoch 095 - training loss: 0.4222, validation loss: 0.9723
2024-06-04 04:56:18 [INFO]: Epoch 096 - training loss: 0.4220, validation loss: 0.9545
2024-06-04 04:56:30 [INFO]: Epoch 097 - training loss: 0.4223, validation loss: 0.9586
2024-06-04 04:56:41 [INFO]: Epoch 098 - training loss: 0.4222, validation loss: 0.9553
2024-06-04 04:56:53 [INFO]: Epoch 099 - training loss: 0.4227, validation loss: 0.9542
2024-06-04 04:57:05 [INFO]: Epoch 100 - training loss: 0.4218, validation loss: 0.9573
2024-06-04 04:57:05 [INFO]: Finished training. The best model is from epoch#99.
2024-06-04 04:57:09 [INFO]: Saved the model to results_point_rate05/Electricity/SCINet_Electricity/round_4/20240604_T042943/SCINet.pypots
2024-06-04 04:57:14 [INFO]: Successfully saved to results_point_rate05/Electricity/SCINet_Electricity/round_4/imputation.pkl
2024-06-04 04:57:14 [INFO]: Round4 - SCINet on Electricity: MAE=0.7902, MSE=1.0977, MRE=0.4231
2024-06-04 04:57:14 [INFO]: Done! Final results:
Averaged SCINet (421,053,386 params) on Electricity: MAE=0.7783 ± 0.02256955015143511, MSE=1.1620 ± 0.1149822832660897, MRE=0.4167 ± 0.012083886330774993, average inference time=1.48
