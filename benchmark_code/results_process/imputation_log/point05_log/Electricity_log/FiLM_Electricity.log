2024-06-02 19:59:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 19:59:13 [INFO]: Using the given device: cuda:0
2024-06-02 19:59:13 [INFO]: Model files will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_0/20240602_T195913
2024-06-02 19:59:13 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_0/20240602_T195913/tensorboard
2024-06-02 19:59:14 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 19:59:23 [INFO]: Epoch 001 - training loss: 1.4507, validation loss: 3.9662
2024-06-02 19:59:29 [INFO]: Epoch 002 - training loss: 1.2283, validation loss: 3.8924
2024-06-02 19:59:36 [INFO]: Epoch 003 - training loss: 1.1157, validation loss: 3.9423
2024-06-02 19:59:44 [INFO]: Epoch 004 - training loss: 1.0814, validation loss: 3.8506
2024-06-02 19:59:51 [INFO]: Epoch 005 - training loss: 1.0651, validation loss: 3.8135
2024-06-02 19:59:58 [INFO]: Epoch 006 - training loss: 1.0516, validation loss: 3.7812
2024-06-02 20:00:05 [INFO]: Epoch 007 - training loss: 1.0440, validation loss: 3.7750
2024-06-02 20:00:12 [INFO]: Epoch 008 - training loss: 1.0390, validation loss: 3.7551
2024-06-02 20:00:20 [INFO]: Epoch 009 - training loss: 1.0326, validation loss: 3.6870
2024-06-02 20:00:27 [INFO]: Epoch 010 - training loss: 1.0298, validation loss: 3.5720
2024-06-02 20:00:35 [INFO]: Epoch 011 - training loss: 1.0260, validation loss: 3.6660
2024-06-02 20:00:42 [INFO]: Epoch 012 - training loss: 1.0229, validation loss: 3.5872
2024-06-02 20:00:49 [INFO]: Epoch 013 - training loss: 1.0198, validation loss: 3.6415
2024-06-02 20:00:56 [INFO]: Epoch 014 - training loss: 1.0185, validation loss: 3.4455
2024-06-02 20:01:03 [INFO]: Epoch 015 - training loss: 1.0158, validation loss: 3.5201
2024-06-02 20:01:11 [INFO]: Epoch 016 - training loss: 1.0139, validation loss: 3.5383
2024-06-02 20:01:18 [INFO]: Epoch 017 - training loss: 1.0128, validation loss: 3.4886
2024-06-02 20:01:25 [INFO]: Epoch 018 - training loss: 1.0107, validation loss: 3.4467
2024-06-02 20:01:32 [INFO]: Epoch 019 - training loss: 1.0095, validation loss: 3.4835
2024-06-02 20:01:40 [INFO]: Epoch 020 - training loss: 1.0081, validation loss: 3.4109
2024-06-02 20:01:47 [INFO]: Epoch 021 - training loss: 1.0054, validation loss: 3.3535
2024-06-02 20:01:54 [INFO]: Epoch 022 - training loss: 1.0033, validation loss: 3.3437
2024-06-02 20:02:01 [INFO]: Epoch 023 - training loss: 1.0013, validation loss: 3.3440
2024-06-02 20:02:08 [INFO]: Epoch 024 - training loss: 1.0017, validation loss: 3.3016
2024-06-02 20:02:16 [INFO]: Epoch 025 - training loss: 0.9990, validation loss: 3.2393
2024-06-02 20:02:23 [INFO]: Epoch 026 - training loss: 0.9966, validation loss: 3.2927
2024-06-02 20:02:30 [INFO]: Epoch 027 - training loss: 0.9995, validation loss: 3.2395
2024-06-02 20:02:37 [INFO]: Epoch 028 - training loss: 0.9955, validation loss: 3.3376
2024-06-02 20:02:45 [INFO]: Epoch 029 - training loss: 0.9954, validation loss: 3.2459
2024-06-02 20:02:52 [INFO]: Epoch 030 - training loss: 0.9937, validation loss: 3.2023
2024-06-02 20:02:59 [INFO]: Epoch 031 - training loss: 0.9937, validation loss: 3.1474
2024-06-02 20:03:07 [INFO]: Epoch 032 - training loss: 0.9917, validation loss: 3.2073
2024-06-02 20:03:14 [INFO]: Epoch 033 - training loss: 0.9906, validation loss: 3.1782
2024-06-02 20:03:21 [INFO]: Epoch 034 - training loss: 0.9895, validation loss: 3.2472
2024-06-02 20:03:28 [INFO]: Epoch 035 - training loss: 0.9897, validation loss: 3.1644
2024-06-02 20:03:35 [INFO]: Epoch 036 - training loss: 0.9880, validation loss: 3.1708
2024-06-02 20:03:43 [INFO]: Epoch 037 - training loss: 0.9886, validation loss: 3.1293
2024-06-02 20:03:50 [INFO]: Epoch 038 - training loss: 0.9862, validation loss: 3.1433
2024-06-02 20:03:57 [INFO]: Epoch 039 - training loss: 0.9852, validation loss: 3.1155
2024-06-02 20:04:05 [INFO]: Epoch 040 - training loss: 0.9853, validation loss: 3.1504
2024-06-02 20:04:12 [INFO]: Epoch 041 - training loss: 0.9840, validation loss: 3.1480
2024-06-02 20:04:19 [INFO]: Epoch 042 - training loss: 0.9835, validation loss: 3.1607
2024-06-02 20:04:26 [INFO]: Epoch 043 - training loss: 0.9836, validation loss: 3.0982
2024-06-02 20:04:33 [INFO]: Epoch 044 - training loss: 0.9823, validation loss: 3.1418
2024-06-02 20:04:40 [INFO]: Epoch 045 - training loss: 0.9816, validation loss: 3.1395
2024-06-02 20:04:48 [INFO]: Epoch 046 - training loss: 0.9823, validation loss: 3.1082
2024-06-02 20:04:55 [INFO]: Epoch 047 - training loss: 0.9813, validation loss: 3.0287
2024-06-02 20:05:02 [INFO]: Epoch 048 - training loss: 0.9813, validation loss: 3.1351
2024-06-02 20:05:10 [INFO]: Epoch 049 - training loss: 0.9800, validation loss: 3.0336
2024-06-02 20:05:17 [INFO]: Epoch 050 - training loss: 0.9786, validation loss: 3.0483
2024-06-02 20:05:24 [INFO]: Epoch 051 - training loss: 0.9779, validation loss: 2.9144
2024-06-02 20:05:32 [INFO]: Epoch 052 - training loss: 0.9785, validation loss: 2.9711
2024-06-02 20:05:39 [INFO]: Epoch 053 - training loss: 0.9774, validation loss: 2.9072
2024-06-02 20:05:46 [INFO]: Epoch 054 - training loss: 0.9763, validation loss: 2.9151
2024-06-02 20:05:54 [INFO]: Epoch 055 - training loss: 0.9751, validation loss: 2.8875
2024-06-02 20:06:01 [INFO]: Epoch 056 - training loss: 0.9768, validation loss: 2.7647
2024-06-02 20:06:08 [INFO]: Epoch 057 - training loss: 0.9747, validation loss: 2.8788
2024-06-02 20:06:15 [INFO]: Epoch 058 - training loss: 0.9734, validation loss: 2.8458
2024-06-02 20:06:23 [INFO]: Epoch 059 - training loss: 0.9742, validation loss: 2.7822
2024-06-02 20:06:30 [INFO]: Epoch 060 - training loss: 0.9729, validation loss: 2.7693
2024-06-02 20:06:38 [INFO]: Epoch 061 - training loss: 0.9717, validation loss: 2.7880
2024-06-02 20:06:45 [INFO]: Epoch 062 - training loss: 0.9722, validation loss: 2.7471
2024-06-02 20:06:52 [INFO]: Epoch 063 - training loss: 0.9712, validation loss: 2.7193
2024-06-02 20:06:59 [INFO]: Epoch 064 - training loss: 0.9715, validation loss: 2.7379
2024-06-02 20:07:06 [INFO]: Epoch 065 - training loss: 0.9701, validation loss: 2.6941
2024-06-02 20:07:14 [INFO]: Epoch 066 - training loss: 0.9699, validation loss: 2.7065
2024-06-02 20:07:21 [INFO]: Epoch 067 - training loss: 0.9689, validation loss: 2.6970
2024-06-02 20:07:29 [INFO]: Epoch 068 - training loss: 0.9683, validation loss: 2.6567
2024-06-02 20:07:36 [INFO]: Epoch 069 - training loss: 0.9688, validation loss: 2.6351
2024-06-02 20:07:43 [INFO]: Epoch 070 - training loss: 0.9675, validation loss: 2.6493
2024-06-02 20:07:50 [INFO]: Epoch 071 - training loss: 0.9674, validation loss: 2.5977
2024-06-02 20:07:57 [INFO]: Epoch 072 - training loss: 0.9664, validation loss: 2.5615
2024-06-02 20:08:05 [INFO]: Epoch 073 - training loss: 0.9663, validation loss: 2.5490
2024-06-02 20:08:11 [INFO]: Epoch 074 - training loss: 0.9662, validation loss: 2.5328
2024-06-02 20:08:18 [INFO]: Epoch 075 - training loss: 0.9645, validation loss: 2.5373
2024-06-02 20:08:25 [INFO]: Epoch 076 - training loss: 0.9649, validation loss: 2.4998
2024-06-02 20:08:33 [INFO]: Epoch 077 - training loss: 0.9657, validation loss: 2.4963
2024-06-02 20:08:40 [INFO]: Epoch 078 - training loss: 0.9647, validation loss: 2.5016
2024-06-02 20:08:47 [INFO]: Epoch 079 - training loss: 0.9640, validation loss: 2.4418
2024-06-02 20:08:55 [INFO]: Epoch 080 - training loss: 0.9630, validation loss: 2.4709
2024-06-02 20:09:03 [INFO]: Epoch 081 - training loss: 0.9634, validation loss: 2.4581
2024-06-02 20:09:10 [INFO]: Epoch 082 - training loss: 0.9627, validation loss: 2.4176
2024-06-02 20:09:17 [INFO]: Epoch 083 - training loss: 0.9625, validation loss: 2.3469
2024-06-02 20:09:24 [INFO]: Epoch 084 - training loss: 0.9623, validation loss: 2.3773
2024-06-02 20:09:31 [INFO]: Epoch 085 - training loss: 0.9629, validation loss: 2.3679
2024-06-02 20:09:39 [INFO]: Epoch 086 - training loss: 0.9615, validation loss: 2.3272
2024-06-02 20:09:46 [INFO]: Epoch 087 - training loss: 0.9610, validation loss: 2.3619
2024-06-02 20:09:54 [INFO]: Epoch 088 - training loss: 0.9615, validation loss: 2.2936
2024-06-02 20:10:01 [INFO]: Epoch 089 - training loss: 0.9613, validation loss: 2.3327
2024-06-02 20:10:09 [INFO]: Epoch 090 - training loss: 0.9616, validation loss: 2.3016
2024-06-02 20:10:16 [INFO]: Epoch 091 - training loss: 0.9604, validation loss: 2.3155
2024-06-02 20:10:23 [INFO]: Epoch 092 - training loss: 0.9607, validation loss: 2.2919
2024-06-02 20:10:31 [INFO]: Epoch 093 - training loss: 0.9591, validation loss: 2.2744
2024-06-02 20:10:38 [INFO]: Epoch 094 - training loss: 0.9600, validation loss: 2.2672
2024-06-02 20:10:45 [INFO]: Epoch 095 - training loss: 0.9600, validation loss: 2.2564
2024-06-02 20:10:52 [INFO]: Epoch 096 - training loss: 0.9590, validation loss: 2.2378
2024-06-02 20:10:59 [INFO]: Epoch 097 - training loss: 0.9592, validation loss: 2.2204
2024-06-02 20:11:07 [INFO]: Epoch 098 - training loss: 0.9584, validation loss: 2.2121
2024-06-02 20:11:14 [INFO]: Epoch 099 - training loss: 0.9591, validation loss: 2.1810
2024-06-02 20:11:21 [INFO]: Epoch 100 - training loss: 0.9584, validation loss: 2.2060
2024-06-02 20:11:21 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 20:11:21 [INFO]: Saved the model to results_point_rate05/Electricity/FiLM_Electricity/round_0/20240602_T195913/FiLM.pypots
2024-06-02 20:11:22 [INFO]: Successfully saved to results_point_rate05/Electricity/FiLM_Electricity/round_0/imputation.pkl
2024-06-02 20:11:22 [INFO]: Round0 - FiLM on Electricity: MAE=0.9344, MSE=1.5428, MRE=0.5003
2024-06-02 20:11:22 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:11:22 [INFO]: Using the given device: cuda:0
2024-06-02 20:11:22 [INFO]: Model files will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_1/20240602_T201122
2024-06-02 20:11:22 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_1/20240602_T201122/tensorboard
2024-06-02 20:11:23 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 20:11:31 [INFO]: Epoch 001 - training loss: 1.4017, validation loss: 3.8409
2024-06-02 20:11:38 [INFO]: Epoch 002 - training loss: 1.1743, validation loss: 3.6706
2024-06-02 20:11:45 [INFO]: Epoch 003 - training loss: 1.0934, validation loss: 3.6114
2024-06-02 20:11:52 [INFO]: Epoch 004 - training loss: 1.0626, validation loss: 3.5298
2024-06-02 20:11:59 [INFO]: Epoch 005 - training loss: 1.0494, validation loss: 3.4675
2024-06-02 20:12:07 [INFO]: Epoch 006 - training loss: 1.0403, validation loss: 3.3517
2024-06-02 20:12:14 [INFO]: Epoch 007 - training loss: 1.0322, validation loss: 3.2705
2024-06-02 20:12:21 [INFO]: Epoch 008 - training loss: 1.0256, validation loss: 3.2221
2024-06-02 20:12:28 [INFO]: Epoch 009 - training loss: 1.0201, validation loss: 3.1762
2024-06-02 20:12:35 [INFO]: Epoch 010 - training loss: 1.0162, validation loss: 3.1510
2024-06-02 20:12:43 [INFO]: Epoch 011 - training loss: 1.0118, validation loss: 3.1271
2024-06-02 20:12:50 [INFO]: Epoch 012 - training loss: 1.0081, validation loss: 3.1293
2024-06-02 20:12:57 [INFO]: Epoch 013 - training loss: 1.0043, validation loss: 3.0771
2024-06-02 20:13:04 [INFO]: Epoch 014 - training loss: 1.0014, validation loss: 3.0553
2024-06-02 20:13:11 [INFO]: Epoch 015 - training loss: 0.9994, validation loss: 3.0321
2024-06-02 20:13:19 [INFO]: Epoch 016 - training loss: 0.9968, validation loss: 3.0103
2024-06-02 20:13:25 [INFO]: Epoch 017 - training loss: 0.9944, validation loss: 2.9826
2024-06-02 20:13:33 [INFO]: Epoch 018 - training loss: 0.9925, validation loss: 3.0008
2024-06-02 20:13:40 [INFO]: Epoch 019 - training loss: 0.9901, validation loss: 2.9630
2024-06-02 20:13:47 [INFO]: Epoch 020 - training loss: 0.9892, validation loss: 2.9501
2024-06-02 20:13:54 [INFO]: Epoch 021 - training loss: 0.9879, validation loss: 2.9392
2024-06-02 20:14:02 [INFO]: Epoch 022 - training loss: 0.9851, validation loss: 2.8862
2024-06-02 20:14:09 [INFO]: Epoch 023 - training loss: 0.9845, validation loss: 2.8473
2024-06-02 20:14:16 [INFO]: Epoch 024 - training loss: 0.9831, validation loss: 2.8084
2024-06-02 20:14:23 [INFO]: Epoch 025 - training loss: 0.9828, validation loss: 2.8247
2024-06-02 20:14:31 [INFO]: Epoch 026 - training loss: 0.9817, validation loss: 2.7730
2024-06-02 20:14:38 [INFO]: Epoch 027 - training loss: 0.9822, validation loss: 2.7739
2024-06-02 20:14:46 [INFO]: Epoch 028 - training loss: 0.9789, validation loss: 2.7989
2024-06-02 20:14:53 [INFO]: Epoch 029 - training loss: 0.9778, validation loss: 2.7660
2024-06-02 20:15:00 [INFO]: Epoch 030 - training loss: 0.9779, validation loss: 2.7669
2024-06-02 20:15:07 [INFO]: Epoch 031 - training loss: 0.9774, validation loss: 2.7423
2024-06-02 20:15:14 [INFO]: Epoch 032 - training loss: 0.9769, validation loss: 2.7209
2024-06-02 20:15:21 [INFO]: Epoch 033 - training loss: 0.9750, validation loss: 2.7316
2024-06-02 20:15:29 [INFO]: Epoch 034 - training loss: 0.9750, validation loss: 2.6673
2024-06-02 20:15:36 [INFO]: Epoch 035 - training loss: 0.9735, validation loss: 2.7142
2024-06-02 20:15:43 [INFO]: Epoch 036 - training loss: 0.9736, validation loss: 2.6480
2024-06-02 20:15:50 [INFO]: Epoch 037 - training loss: 0.9733, validation loss: 2.6914
2024-06-02 20:15:57 [INFO]: Epoch 038 - training loss: 0.9724, validation loss: 2.6658
2024-06-02 20:16:04 [INFO]: Epoch 039 - training loss: 0.9718, validation loss: 2.6514
2024-06-02 20:16:12 [INFO]: Epoch 040 - training loss: 0.9706, validation loss: 2.6284
2024-06-02 20:16:18 [INFO]: Epoch 041 - training loss: 0.9697, validation loss: 2.6228
2024-06-02 20:16:25 [INFO]: Epoch 042 - training loss: 0.9690, validation loss: 2.5890
2024-06-02 20:16:32 [INFO]: Epoch 043 - training loss: 0.9682, validation loss: 2.5777
2024-06-02 20:16:39 [INFO]: Epoch 044 - training loss: 0.9683, validation loss: 2.5808
2024-06-02 20:16:46 [INFO]: Epoch 045 - training loss: 0.9682, validation loss: 2.5831
2024-06-02 20:16:54 [INFO]: Epoch 046 - training loss: 0.9680, validation loss: 2.6087
2024-06-02 20:17:01 [INFO]: Epoch 047 - training loss: 0.9671, validation loss: 2.5753
2024-06-02 20:17:08 [INFO]: Epoch 048 - training loss: 0.9680, validation loss: 2.5626
2024-06-02 20:17:15 [INFO]: Epoch 049 - training loss: 0.9665, validation loss: 2.5182
2024-06-02 20:17:22 [INFO]: Epoch 050 - training loss: 0.9659, validation loss: 2.4976
2024-06-02 20:17:29 [INFO]: Epoch 051 - training loss: 0.9661, validation loss: 2.5236
2024-06-02 20:17:36 [INFO]: Epoch 052 - training loss: 0.9653, validation loss: 2.4654
2024-06-02 20:17:44 [INFO]: Epoch 053 - training loss: 0.9654, validation loss: 2.4422
2024-06-02 20:17:51 [INFO]: Epoch 054 - training loss: 0.9646, validation loss: 2.4756
2024-06-02 20:17:58 [INFO]: Epoch 055 - training loss: 0.9636, validation loss: 2.4470
2024-06-02 20:18:05 [INFO]: Epoch 056 - training loss: 0.9632, validation loss: 2.4357
2024-06-02 20:18:12 [INFO]: Epoch 057 - training loss: 0.9651, validation loss: 2.4233
2024-06-02 20:18:19 [INFO]: Epoch 058 - training loss: 0.9641, validation loss: 2.3949
2024-06-02 20:18:26 [INFO]: Epoch 059 - training loss: 0.9631, validation loss: 2.3373
2024-06-02 20:18:34 [INFO]: Epoch 060 - training loss: 0.9625, validation loss: 2.3735
2024-06-02 20:18:41 [INFO]: Epoch 061 - training loss: 0.9629, validation loss: 2.3468
2024-06-02 20:18:48 [INFO]: Epoch 062 - training loss: 0.9630, validation loss: 2.3694
2024-06-02 20:18:54 [INFO]: Epoch 063 - training loss: 0.9621, validation loss: 2.3410
2024-06-02 20:19:01 [INFO]: Epoch 064 - training loss: 0.9622, validation loss: 2.3377
2024-06-02 20:19:09 [INFO]: Epoch 065 - training loss: 0.9626, validation loss: 2.3250
2024-06-02 20:19:16 [INFO]: Epoch 066 - training loss: 0.9619, validation loss: 2.2993
2024-06-02 20:19:23 [INFO]: Epoch 067 - training loss: 0.9611, validation loss: 2.2999
2024-06-02 20:19:30 [INFO]: Epoch 068 - training loss: 0.9612, validation loss: 2.2841
2024-06-02 20:19:38 [INFO]: Epoch 069 - training loss: 0.9604, validation loss: 2.2951
2024-06-02 20:19:45 [INFO]: Epoch 070 - training loss: 0.9604, validation loss: 2.2775
2024-06-02 20:19:52 [INFO]: Epoch 071 - training loss: 0.9605, validation loss: 2.2596
2024-06-02 20:20:00 [INFO]: Epoch 072 - training loss: 0.9596, validation loss: 2.2648
2024-06-02 20:20:07 [INFO]: Epoch 073 - training loss: 0.9604, validation loss: 2.2742
2024-06-02 20:20:14 [INFO]: Epoch 074 - training loss: 0.9597, validation loss: 2.2689
2024-06-02 20:20:21 [INFO]: Epoch 075 - training loss: 0.9601, validation loss: 2.2229
2024-06-02 20:20:28 [INFO]: Epoch 076 - training loss: 0.9601, validation loss: 2.2397
2024-06-02 20:20:36 [INFO]: Epoch 077 - training loss: 0.9601, validation loss: 2.2166
2024-06-02 20:20:43 [INFO]: Epoch 078 - training loss: 0.9594, validation loss: 2.2246
2024-06-02 20:20:51 [INFO]: Epoch 079 - training loss: 0.9591, validation loss: 2.1854
2024-06-02 20:20:57 [INFO]: Epoch 080 - training loss: 0.9580, validation loss: 2.2006
2024-06-02 20:21:05 [INFO]: Epoch 081 - training loss: 0.9594, validation loss: 2.2008
2024-06-02 20:21:12 [INFO]: Epoch 082 - training loss: 0.9582, validation loss: 2.2060
2024-06-02 20:21:19 [INFO]: Epoch 083 - training loss: 0.9579, validation loss: 2.1840
2024-06-02 20:21:26 [INFO]: Epoch 084 - training loss: 0.9581, validation loss: 2.1835
2024-06-02 20:21:33 [INFO]: Epoch 085 - training loss: 0.9586, validation loss: 2.1795
2024-06-02 20:21:40 [INFO]: Epoch 086 - training loss: 0.9578, validation loss: 2.1608
2024-06-02 20:21:47 [INFO]: Epoch 087 - training loss: 0.9572, validation loss: 2.1417
2024-06-02 20:21:52 [INFO]: Epoch 088 - training loss: 0.9567, validation loss: 2.1555
2024-06-02 20:21:57 [INFO]: Epoch 089 - training loss: 0.9574, validation loss: 2.1205
2024-06-02 20:22:02 [INFO]: Epoch 090 - training loss: 0.9590, validation loss: 2.1212
2024-06-02 20:22:07 [INFO]: Epoch 091 - training loss: 0.9570, validation loss: 2.1163
2024-06-02 20:22:12 [INFO]: Epoch 092 - training loss: 0.9576, validation loss: 2.1350
2024-06-02 20:22:17 [INFO]: Epoch 093 - training loss: 0.9575, validation loss: 2.1041
2024-06-02 20:22:22 [INFO]: Epoch 094 - training loss: 0.9569, validation loss: 2.1171
2024-06-02 20:22:27 [INFO]: Epoch 095 - training loss: 0.9557, validation loss: 2.1081
2024-06-02 20:22:32 [INFO]: Epoch 096 - training loss: 0.9562, validation loss: 2.1058
2024-06-02 20:22:38 [INFO]: Epoch 097 - training loss: 0.9563, validation loss: 2.0848
2024-06-02 20:22:43 [INFO]: Epoch 098 - training loss: 0.9564, validation loss: 2.0967
2024-06-02 20:22:48 [INFO]: Epoch 099 - training loss: 0.9565, validation loss: 2.0779
2024-06-02 20:22:53 [INFO]: Epoch 100 - training loss: 0.9561, validation loss: 2.0843
2024-06-02 20:22:53 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 20:22:53 [INFO]: Saved the model to results_point_rate05/Electricity/FiLM_Electricity/round_1/20240602_T201122/FiLM.pypots
2024-06-02 20:22:55 [INFO]: Successfully saved to results_point_rate05/Electricity/FiLM_Electricity/round_1/imputation.pkl
2024-06-02 20:22:55 [INFO]: Round1 - FiLM on Electricity: MAE=0.9291, MSE=1.5001, MRE=0.4974
2024-06-02 20:22:55 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:22:55 [INFO]: Using the given device: cuda:0
2024-06-02 20:22:55 [INFO]: Model files will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_2/20240602_T202255
2024-06-02 20:22:55 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_2/20240602_T202255/tensorboard
2024-06-02 20:22:55 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 20:23:00 [INFO]: Epoch 001 - training loss: 1.4876, validation loss: 4.0617
2024-06-02 20:23:05 [INFO]: Epoch 002 - training loss: 1.2098, validation loss: 3.8017
2024-06-02 20:23:11 [INFO]: Epoch 003 - training loss: 1.1007, validation loss: 3.7772
2024-06-02 20:23:15 [INFO]: Epoch 004 - training loss: 1.0701, validation loss: 3.7235
2024-06-02 20:23:20 [INFO]: Epoch 005 - training loss: 1.0571, validation loss: 3.6981
2024-06-02 20:23:25 [INFO]: Epoch 006 - training loss: 1.0482, validation loss: 3.6403
2024-06-02 20:23:31 [INFO]: Epoch 007 - training loss: 1.0396, validation loss: 3.6474
2024-06-02 20:23:36 [INFO]: Epoch 008 - training loss: 1.0341, validation loss: 3.5770
2024-06-02 20:23:41 [INFO]: Epoch 009 - training loss: 1.0285, validation loss: 3.5021
2024-06-02 20:23:47 [INFO]: Epoch 010 - training loss: 1.0249, validation loss: 3.3976
2024-06-02 20:23:52 [INFO]: Epoch 011 - training loss: 1.0188, validation loss: 3.3944
2024-06-02 20:23:57 [INFO]: Epoch 012 - training loss: 1.0145, validation loss: 3.3558
2024-06-02 20:24:01 [INFO]: Epoch 013 - training loss: 1.0102, validation loss: 3.3722
2024-06-02 20:24:07 [INFO]: Epoch 014 - training loss: 1.0063, validation loss: 3.3647
2024-06-02 20:24:12 [INFO]: Epoch 015 - training loss: 1.0026, validation loss: 3.3103
2024-06-02 20:24:17 [INFO]: Epoch 016 - training loss: 1.0007, validation loss: 3.3899
2024-06-02 20:24:22 [INFO]: Epoch 017 - training loss: 0.9987, validation loss: 3.1394
2024-06-02 20:24:27 [INFO]: Epoch 018 - training loss: 0.9949, validation loss: 3.1367
2024-06-02 20:24:31 [INFO]: Epoch 019 - training loss: 0.9917, validation loss: 3.0880
2024-06-02 20:24:36 [INFO]: Epoch 020 - training loss: 0.9899, validation loss: 3.0503
2024-06-02 20:24:41 [INFO]: Epoch 021 - training loss: 0.9883, validation loss: 3.0198
2024-06-02 20:24:46 [INFO]: Epoch 022 - training loss: 0.9871, validation loss: 2.9647
2024-06-02 20:24:51 [INFO]: Epoch 023 - training loss: 0.9846, validation loss: 2.9710
2024-06-02 20:24:56 [INFO]: Epoch 024 - training loss: 0.9831, validation loss: 2.8945
2024-06-02 20:25:01 [INFO]: Epoch 025 - training loss: 0.9824, validation loss: 2.9363
2024-06-02 20:25:06 [INFO]: Epoch 026 - training loss: 0.9803, validation loss: 2.8534
2024-06-02 20:25:11 [INFO]: Epoch 027 - training loss: 0.9805, validation loss: 2.9373
2024-06-02 20:25:17 [INFO]: Epoch 028 - training loss: 0.9793, validation loss: 2.8139
2024-06-02 20:25:22 [INFO]: Epoch 029 - training loss: 0.9769, validation loss: 2.8495
2024-06-02 20:25:27 [INFO]: Epoch 030 - training loss: 0.9766, validation loss: 2.8349
2024-06-02 20:25:32 [INFO]: Epoch 031 - training loss: 0.9764, validation loss: 2.7757
2024-06-02 20:25:38 [INFO]: Epoch 032 - training loss: 0.9747, validation loss: 2.7806
2024-06-02 20:25:43 [INFO]: Epoch 033 - training loss: 0.9732, validation loss: 2.8181
2024-06-02 20:25:47 [INFO]: Epoch 034 - training loss: 0.9741, validation loss: 2.7618
2024-06-02 20:25:53 [INFO]: Epoch 035 - training loss: 0.9729, validation loss: 2.7668
2024-06-02 20:25:58 [INFO]: Epoch 036 - training loss: 0.9715, validation loss: 2.7338
2024-06-02 20:26:04 [INFO]: Epoch 037 - training loss: 0.9712, validation loss: 2.7707
2024-06-02 20:26:10 [INFO]: Epoch 038 - training loss: 0.9714, validation loss: 2.7505
2024-06-02 20:26:15 [INFO]: Epoch 039 - training loss: 0.9702, validation loss: 2.6814
2024-06-02 20:26:20 [INFO]: Epoch 040 - training loss: 0.9704, validation loss: 2.7297
2024-06-02 20:26:25 [INFO]: Epoch 041 - training loss: 0.9698, validation loss: 2.7186
2024-06-02 20:26:30 [INFO]: Epoch 042 - training loss: 0.9683, validation loss: 2.6173
2024-06-02 20:26:35 [INFO]: Epoch 043 - training loss: 0.9678, validation loss: 2.6014
2024-06-02 20:26:40 [INFO]: Epoch 044 - training loss: 0.9676, validation loss: 2.5986
2024-06-02 20:26:45 [INFO]: Epoch 045 - training loss: 0.9687, validation loss: 2.5806
2024-06-02 20:26:51 [INFO]: Epoch 046 - training loss: 0.9665, validation loss: 2.5936
2024-06-02 20:26:56 [INFO]: Epoch 047 - training loss: 0.9655, validation loss: 2.5575
2024-06-02 20:27:01 [INFO]: Epoch 048 - training loss: 0.9660, validation loss: 2.5415
2024-06-02 20:27:07 [INFO]: Epoch 049 - training loss: 0.9651, validation loss: 2.5146
2024-06-02 20:27:12 [INFO]: Epoch 050 - training loss: 0.9645, validation loss: 2.4939
2024-06-02 20:27:17 [INFO]: Epoch 051 - training loss: 0.9643, validation loss: 2.4699
2024-06-02 20:27:22 [INFO]: Epoch 052 - training loss: 0.9644, validation loss: 2.4621
2024-06-02 20:27:27 [INFO]: Epoch 053 - training loss: 0.9641, validation loss: 2.4326
2024-06-02 20:27:32 [INFO]: Epoch 054 - training loss: 0.9636, validation loss: 2.4296
2024-06-02 20:27:37 [INFO]: Epoch 055 - training loss: 0.9637, validation loss: 2.4205
2024-06-02 20:27:42 [INFO]: Epoch 056 - training loss: 0.9637, validation loss: 2.4064
2024-06-02 20:27:47 [INFO]: Epoch 057 - training loss: 0.9638, validation loss: 2.3901
2024-06-02 20:27:52 [INFO]: Epoch 058 - training loss: 0.9647, validation loss: 2.3780
2024-06-02 20:27:57 [INFO]: Epoch 059 - training loss: 0.9624, validation loss: 2.3858
2024-06-02 20:28:03 [INFO]: Epoch 060 - training loss: 0.9623, validation loss: 2.3728
2024-06-02 20:28:08 [INFO]: Epoch 061 - training loss: 0.9613, validation loss: 2.3578
2024-06-02 20:28:13 [INFO]: Epoch 062 - training loss: 0.9613, validation loss: 2.3373
2024-06-02 20:28:18 [INFO]: Epoch 063 - training loss: 0.9606, validation loss: 2.3326
2024-06-02 20:28:24 [INFO]: Epoch 064 - training loss: 0.9604, validation loss: 2.3067
2024-06-02 20:28:29 [INFO]: Epoch 065 - training loss: 0.9606, validation loss: 2.2953
2024-06-02 20:28:34 [INFO]: Epoch 066 - training loss: 0.9601, validation loss: 2.3052
2024-06-02 20:28:39 [INFO]: Epoch 067 - training loss: 0.9606, validation loss: 2.2823
2024-06-02 20:28:44 [INFO]: Epoch 068 - training loss: 0.9596, validation loss: 2.2840
2024-06-02 20:28:49 [INFO]: Epoch 069 - training loss: 0.9610, validation loss: 2.2594
2024-06-02 20:28:54 [INFO]: Epoch 070 - training loss: 0.9601, validation loss: 2.2559
2024-06-02 20:29:00 [INFO]: Epoch 071 - training loss: 0.9596, validation loss: 2.2415
2024-06-02 20:29:05 [INFO]: Epoch 072 - training loss: 0.9602, validation loss: 2.2297
2024-06-02 20:29:10 [INFO]: Epoch 073 - training loss: 0.9595, validation loss: 2.2778
2024-06-02 20:29:15 [INFO]: Epoch 074 - training loss: 0.9594, validation loss: 2.2107
2024-06-02 20:29:20 [INFO]: Epoch 075 - training loss: 0.9594, validation loss: 2.2264
2024-06-02 20:29:25 [INFO]: Epoch 076 - training loss: 0.9585, validation loss: 2.1886
2024-06-02 20:29:30 [INFO]: Epoch 077 - training loss: 0.9579, validation loss: 2.1786
2024-06-02 20:29:36 [INFO]: Epoch 078 - training loss: 0.9580, validation loss: 2.1697
2024-06-02 20:29:41 [INFO]: Epoch 079 - training loss: 0.9581, validation loss: 2.1715
2024-06-02 20:29:46 [INFO]: Epoch 080 - training loss: 0.9579, validation loss: 2.1615
2024-06-02 20:29:52 [INFO]: Epoch 081 - training loss: 0.9601, validation loss: 2.1653
2024-06-02 20:29:57 [INFO]: Epoch 082 - training loss: 0.9582, validation loss: 2.1629
2024-06-02 20:30:02 [INFO]: Epoch 083 - training loss: 0.9581, validation loss: 2.1475
2024-06-02 20:30:08 [INFO]: Epoch 084 - training loss: 0.9570, validation loss: 2.1457
2024-06-02 20:30:13 [INFO]: Epoch 085 - training loss: 0.9565, validation loss: 2.1549
2024-06-02 20:30:18 [INFO]: Epoch 086 - training loss: 0.9568, validation loss: 2.1446
2024-06-02 20:30:23 [INFO]: Epoch 087 - training loss: 0.9568, validation loss: 2.1351
2024-06-02 20:30:28 [INFO]: Epoch 088 - training loss: 0.9572, validation loss: 2.1400
2024-06-02 20:30:33 [INFO]: Epoch 089 - training loss: 0.9564, validation loss: 2.1235
2024-06-02 20:30:39 [INFO]: Epoch 090 - training loss: 0.9573, validation loss: 2.1008
2024-06-02 20:30:43 [INFO]: Epoch 091 - training loss: 0.9563, validation loss: 2.1114
2024-06-02 20:30:49 [INFO]: Epoch 092 - training loss: 0.9570, validation loss: 2.1060
2024-06-02 20:30:54 [INFO]: Epoch 093 - training loss: 0.9570, validation loss: 2.0901
2024-06-02 20:30:59 [INFO]: Epoch 094 - training loss: 0.9573, validation loss: 2.0883
2024-06-02 20:31:03 [INFO]: Epoch 095 - training loss: 0.9566, validation loss: 2.0926
2024-06-02 20:31:08 [INFO]: Epoch 096 - training loss: 0.9560, validation loss: 2.0901
2024-06-02 20:31:12 [INFO]: Epoch 097 - training loss: 0.9567, validation loss: 2.0737
2024-06-02 20:31:17 [INFO]: Epoch 098 - training loss: 0.9553, validation loss: 2.0647
2024-06-02 20:31:22 [INFO]: Epoch 099 - training loss: 0.9551, validation loss: 2.0516
2024-06-02 20:31:27 [INFO]: Epoch 100 - training loss: 0.9555, validation loss: 2.0721
2024-06-02 20:31:27 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 20:31:27 [INFO]: Saved the model to results_point_rate05/Electricity/FiLM_Electricity/round_2/20240602_T202255/FiLM.pypots
2024-06-02 20:31:28 [INFO]: Successfully saved to results_point_rate05/Electricity/FiLM_Electricity/round_2/imputation.pkl
2024-06-02 20:31:28 [INFO]: Round2 - FiLM on Electricity: MAE=0.9057, MSE=1.4120, MRE=0.4849
2024-06-02 20:31:28 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:31:28 [INFO]: Using the given device: cuda:0
2024-06-02 20:31:28 [INFO]: Model files will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_3/20240602_T203128
2024-06-02 20:31:28 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_3/20240602_T203128/tensorboard
2024-06-02 20:31:28 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 20:31:34 [INFO]: Epoch 001 - training loss: 1.4303, validation loss: 3.7905
2024-06-02 20:31:39 [INFO]: Epoch 002 - training loss: 1.1457, validation loss: 3.5154
2024-06-02 20:31:44 [INFO]: Epoch 003 - training loss: 1.0749, validation loss: 3.5066
2024-06-02 20:31:49 [INFO]: Epoch 004 - training loss: 1.0528, validation loss: 3.4259
2024-06-02 20:31:54 [INFO]: Epoch 005 - training loss: 1.0435, validation loss: 3.4020
2024-06-02 20:31:59 [INFO]: Epoch 006 - training loss: 1.0347, validation loss: 3.3886
2024-06-02 20:32:04 [INFO]: Epoch 007 - training loss: 1.0281, validation loss: 3.2311
2024-06-02 20:32:09 [INFO]: Epoch 008 - training loss: 1.0214, validation loss: 3.2527
2024-06-02 20:32:14 [INFO]: Epoch 009 - training loss: 1.0156, validation loss: 3.1685
2024-06-02 20:32:20 [INFO]: Epoch 010 - training loss: 1.0100, validation loss: 3.1655
2024-06-02 20:32:25 [INFO]: Epoch 011 - training loss: 1.0059, validation loss: 3.1266
2024-06-02 20:32:30 [INFO]: Epoch 012 - training loss: 1.0018, validation loss: 3.1647
2024-06-02 20:32:35 [INFO]: Epoch 013 - training loss: 0.9985, validation loss: 3.0172
2024-06-02 20:32:40 [INFO]: Epoch 014 - training loss: 0.9964, validation loss: 3.0186
2024-06-02 20:32:45 [INFO]: Epoch 015 - training loss: 0.9920, validation loss: 2.9651
2024-06-02 20:32:50 [INFO]: Epoch 016 - training loss: 0.9910, validation loss: 2.9641
2024-06-02 20:32:55 [INFO]: Epoch 017 - training loss: 0.9892, validation loss: 2.9272
2024-06-02 20:33:01 [INFO]: Epoch 018 - training loss: 0.9874, validation loss: 2.9593
2024-06-02 20:33:05 [INFO]: Epoch 019 - training loss: 0.9851, validation loss: 2.8734
2024-06-02 20:33:11 [INFO]: Epoch 020 - training loss: 0.9833, validation loss: 2.9104
2024-06-02 20:33:16 [INFO]: Epoch 021 - training loss: 0.9829, validation loss: 2.8633
2024-06-02 20:33:21 [INFO]: Epoch 022 - training loss: 0.9811, validation loss: 2.8317
2024-06-02 20:33:25 [INFO]: Epoch 023 - training loss: 0.9797, validation loss: 2.7950
2024-06-02 20:33:31 [INFO]: Epoch 024 - training loss: 0.9786, validation loss: 2.7796
2024-06-02 20:33:35 [INFO]: Epoch 025 - training loss: 0.9777, validation loss: 2.7812
2024-06-02 20:33:40 [INFO]: Epoch 026 - training loss: 0.9789, validation loss: 2.7170
2024-06-02 20:33:46 [INFO]: Epoch 027 - training loss: 0.9762, validation loss: 2.7259
2024-06-02 20:33:51 [INFO]: Epoch 028 - training loss: 0.9761, validation loss: 2.7031
2024-06-02 20:33:56 [INFO]: Epoch 029 - training loss: 0.9750, validation loss: 2.6822
2024-06-02 20:34:01 [INFO]: Epoch 030 - training loss: 0.9734, validation loss: 2.6491
2024-06-02 20:34:06 [INFO]: Epoch 031 - training loss: 0.9734, validation loss: 2.6616
2024-06-02 20:34:11 [INFO]: Epoch 032 - training loss: 0.9729, validation loss: 2.6583
2024-06-02 20:34:16 [INFO]: Epoch 033 - training loss: 0.9717, validation loss: 2.6088
2024-06-02 20:34:22 [INFO]: Epoch 034 - training loss: 0.9722, validation loss: 2.5972
2024-06-02 20:34:26 [INFO]: Epoch 035 - training loss: 0.9699, validation loss: 2.5944
2024-06-02 20:34:31 [INFO]: Epoch 036 - training loss: 0.9695, validation loss: 2.5650
2024-06-02 20:34:37 [INFO]: Epoch 037 - training loss: 0.9687, validation loss: 2.5827
2024-06-02 20:34:42 [INFO]: Epoch 038 - training loss: 0.9691, validation loss: 2.5531
2024-06-02 20:34:47 [INFO]: Epoch 039 - training loss: 0.9682, validation loss: 2.5332
2024-06-02 20:34:52 [INFO]: Epoch 040 - training loss: 0.9676, validation loss: 2.5122
2024-06-02 20:34:57 [INFO]: Epoch 041 - training loss: 0.9673, validation loss: 2.5057
2024-06-02 20:35:02 [INFO]: Epoch 042 - training loss: 0.9665, validation loss: 2.4830
2024-06-02 20:35:08 [INFO]: Epoch 043 - training loss: 0.9661, validation loss: 2.4770
2024-06-02 20:35:13 [INFO]: Epoch 044 - training loss: 0.9650, validation loss: 2.4491
2024-06-02 20:35:19 [INFO]: Epoch 045 - training loss: 0.9659, validation loss: 2.4485
2024-06-02 20:35:24 [INFO]: Epoch 046 - training loss: 0.9652, validation loss: 2.4332
2024-06-02 20:35:29 [INFO]: Epoch 047 - training loss: 0.9643, validation loss: 2.4237
2024-06-02 20:35:34 [INFO]: Epoch 048 - training loss: 0.9637, validation loss: 2.4032
2024-06-02 20:35:39 [INFO]: Epoch 049 - training loss: 0.9638, validation loss: 2.3912
2024-06-02 20:35:45 [INFO]: Epoch 050 - training loss: 0.9639, validation loss: 2.3803
2024-06-02 20:35:50 [INFO]: Epoch 051 - training loss: 0.9635, validation loss: 2.3625
2024-06-02 20:35:55 [INFO]: Epoch 052 - training loss: 0.9626, validation loss: 2.3445
2024-06-02 20:36:00 [INFO]: Epoch 053 - training loss: 0.9632, validation loss: 2.3393
2024-06-02 20:36:05 [INFO]: Epoch 054 - training loss: 0.9637, validation loss: 2.3507
2024-06-02 20:36:10 [INFO]: Epoch 055 - training loss: 0.9623, validation loss: 2.3334
2024-06-02 20:36:15 [INFO]: Epoch 056 - training loss: 0.9616, validation loss: 2.3009
2024-06-02 20:36:20 [INFO]: Epoch 057 - training loss: 0.9614, validation loss: 2.2617
2024-06-02 20:36:26 [INFO]: Epoch 058 - training loss: 0.9616, validation loss: 2.2854
2024-06-02 20:36:31 [INFO]: Epoch 059 - training loss: 0.9611, validation loss: 2.2721
2024-06-02 20:36:36 [INFO]: Epoch 060 - training loss: 0.9620, validation loss: 2.2835
2024-06-02 20:36:41 [INFO]: Epoch 061 - training loss: 0.9620, validation loss: 2.2822
2024-06-02 20:36:46 [INFO]: Epoch 062 - training loss: 0.9598, validation loss: 2.2527
2024-06-02 20:36:51 [INFO]: Epoch 063 - training loss: 0.9605, validation loss: 2.2448
2024-06-02 20:36:57 [INFO]: Epoch 064 - training loss: 0.9610, validation loss: 2.2479
2024-06-02 20:37:02 [INFO]: Epoch 065 - training loss: 0.9594, validation loss: 2.2476
2024-06-02 20:37:07 [INFO]: Epoch 066 - training loss: 0.9597, validation loss: 2.2325
2024-06-02 20:37:13 [INFO]: Epoch 067 - training loss: 0.9585, validation loss: 2.2284
2024-06-02 20:37:18 [INFO]: Epoch 068 - training loss: 0.9594, validation loss: 2.2126
2024-06-02 20:37:23 [INFO]: Epoch 069 - training loss: 0.9599, validation loss: 2.2001
2024-06-02 20:37:28 [INFO]: Epoch 070 - training loss: 0.9592, validation loss: 2.1936
2024-06-02 20:37:33 [INFO]: Epoch 071 - training loss: 0.9593, validation loss: 2.1916
2024-06-02 20:37:38 [INFO]: Epoch 072 - training loss: 0.9583, validation loss: 2.1846
2024-06-02 20:37:43 [INFO]: Epoch 073 - training loss: 0.9587, validation loss: 2.1961
2024-06-02 20:37:48 [INFO]: Epoch 074 - training loss: 0.9587, validation loss: 2.1662
2024-06-02 20:37:54 [INFO]: Epoch 075 - training loss: 0.9585, validation loss: 2.1858
2024-06-02 20:37:59 [INFO]: Epoch 076 - training loss: 0.9590, validation loss: 2.1501
2024-06-02 20:38:04 [INFO]: Epoch 077 - training loss: 0.9620, validation loss: 2.1519
2024-06-02 20:38:09 [INFO]: Epoch 078 - training loss: 0.9592, validation loss: 2.1649
2024-06-02 20:38:14 [INFO]: Epoch 079 - training loss: 0.9573, validation loss: 2.1324
2024-06-02 20:38:19 [INFO]: Epoch 080 - training loss: 0.9576, validation loss: 2.1398
2024-06-02 20:38:24 [INFO]: Epoch 081 - training loss: 0.9570, validation loss: 2.1201
2024-06-02 20:38:30 [INFO]: Epoch 082 - training loss: 0.9572, validation loss: 2.1235
2024-06-02 20:38:35 [INFO]: Epoch 083 - training loss: 0.9582, validation loss: 2.1216
2024-06-02 20:38:40 [INFO]: Epoch 084 - training loss: 0.9569, validation loss: 2.1141
2024-06-02 20:38:44 [INFO]: Epoch 085 - training loss: 0.9563, validation loss: 2.1223
2024-06-02 20:38:48 [INFO]: Epoch 086 - training loss: 0.9568, validation loss: 2.1320
2024-06-02 20:38:52 [INFO]: Epoch 087 - training loss: 0.9568, validation loss: 2.1016
2024-06-02 20:38:56 [INFO]: Epoch 088 - training loss: 0.9571, validation loss: 2.1023
2024-06-02 20:39:00 [INFO]: Epoch 089 - training loss: 0.9568, validation loss: 2.0875
2024-06-02 20:39:03 [INFO]: Epoch 090 - training loss: 0.9563, validation loss: 2.1142
2024-06-02 20:39:07 [INFO]: Epoch 091 - training loss: 0.9560, validation loss: 2.0981
2024-06-02 20:39:11 [INFO]: Epoch 092 - training loss: 0.9563, validation loss: 2.0743
2024-06-02 20:39:15 [INFO]: Epoch 093 - training loss: 0.9552, validation loss: 2.0777
2024-06-02 20:39:18 [INFO]: Epoch 094 - training loss: 0.9567, validation loss: 2.0805
2024-06-02 20:39:22 [INFO]: Epoch 095 - training loss: 0.9563, validation loss: 2.0679
2024-06-02 20:39:26 [INFO]: Epoch 096 - training loss: 0.9558, validation loss: 2.0620
2024-06-02 20:39:30 [INFO]: Epoch 097 - training loss: 0.9555, validation loss: 2.0705
2024-06-02 20:39:34 [INFO]: Epoch 098 - training loss: 0.9556, validation loss: 2.0591
2024-06-02 20:39:38 [INFO]: Epoch 099 - training loss: 0.9550, validation loss: 2.0385
2024-06-02 20:39:42 [INFO]: Epoch 100 - training loss: 0.9559, validation loss: 2.0517
2024-06-02 20:39:42 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 20:39:42 [INFO]: Saved the model to results_point_rate05/Electricity/FiLM_Electricity/round_3/20240602_T203128/FiLM.pypots
2024-06-02 20:39:42 [INFO]: Successfully saved to results_point_rate05/Electricity/FiLM_Electricity/round_3/imputation.pkl
2024-06-02 20:39:42 [INFO]: Round3 - FiLM on Electricity: MAE=0.8681, MSE=1.3285, MRE=0.4648
2024-06-02 20:39:42 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:39:42 [INFO]: Using the given device: cuda:0
2024-06-02 20:39:42 [INFO]: Model files will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_4/20240602_T203942
2024-06-02 20:39:42 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/FiLM_Electricity/round_4/20240602_T203942/tensorboard
2024-06-02 20:39:42 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 570,613
2024-06-02 20:39:47 [INFO]: Epoch 001 - training loss: 1.4109, validation loss: 3.6250
2024-06-02 20:39:51 [INFO]: Epoch 002 - training loss: 1.1208, validation loss: 3.4387
2024-06-02 20:39:54 [INFO]: Epoch 003 - training loss: 1.0755, validation loss: 3.3950
2024-06-02 20:39:58 [INFO]: Epoch 004 - training loss: 1.0580, validation loss: 3.3588
2024-06-02 20:40:02 [INFO]: Epoch 005 - training loss: 1.0468, validation loss: 3.3669
2024-06-02 20:40:06 [INFO]: Epoch 006 - training loss: 1.0406, validation loss: 3.2925
2024-06-02 20:40:10 [INFO]: Epoch 007 - training loss: 1.0319, validation loss: 3.2724
2024-06-02 20:40:14 [INFO]: Epoch 008 - training loss: 1.0268, validation loss: 3.2580
2024-06-02 20:40:17 [INFO]: Epoch 009 - training loss: 1.0210, validation loss: 3.1725
2024-06-02 20:40:21 [INFO]: Epoch 010 - training loss: 1.0156, validation loss: 3.1438
2024-06-02 20:40:25 [INFO]: Epoch 011 - training loss: 1.0120, validation loss: 3.0801
2024-06-02 20:40:29 [INFO]: Epoch 012 - training loss: 1.0070, validation loss: 3.0889
2024-06-02 20:40:33 [INFO]: Epoch 013 - training loss: 1.0049, validation loss: 3.0166
2024-06-02 20:40:37 [INFO]: Epoch 014 - training loss: 1.0021, validation loss: 2.9681
2024-06-02 20:40:41 [INFO]: Epoch 015 - training loss: 0.9985, validation loss: 3.0092
2024-06-02 20:40:45 [INFO]: Epoch 016 - training loss: 0.9954, validation loss: 2.9231
2024-06-02 20:40:49 [INFO]: Epoch 017 - training loss: 0.9937, validation loss: 2.9713
2024-06-02 20:40:52 [INFO]: Epoch 018 - training loss: 0.9925, validation loss: 2.9129
2024-06-02 20:40:56 [INFO]: Epoch 019 - training loss: 0.9895, validation loss: 2.9193
2024-06-02 20:41:00 [INFO]: Epoch 020 - training loss: 0.9885, validation loss: 2.8977
2024-06-02 20:41:04 [INFO]: Epoch 021 - training loss: 0.9867, validation loss: 2.8291
2024-06-02 20:41:07 [INFO]: Epoch 022 - training loss: 0.9851, validation loss: 2.8168
2024-06-02 20:41:11 [INFO]: Epoch 023 - training loss: 0.9852, validation loss: 2.8136
2024-06-02 20:41:15 [INFO]: Epoch 024 - training loss: 0.9834, validation loss: 2.7654
2024-06-02 20:41:19 [INFO]: Epoch 025 - training loss: 0.9829, validation loss: 2.7899
2024-06-02 20:41:22 [INFO]: Epoch 026 - training loss: 0.9807, validation loss: 2.7639
2024-06-02 20:41:26 [INFO]: Epoch 027 - training loss: 0.9792, validation loss: 2.7617
2024-06-02 20:41:30 [INFO]: Epoch 028 - training loss: 0.9802, validation loss: 2.7545
2024-06-02 20:41:34 [INFO]: Epoch 029 - training loss: 0.9777, validation loss: 2.7482
2024-06-02 20:41:38 [INFO]: Epoch 030 - training loss: 0.9767, validation loss: 2.6987
2024-06-02 20:41:42 [INFO]: Epoch 031 - training loss: 0.9751, validation loss: 2.7227
2024-06-02 20:41:46 [INFO]: Epoch 032 - training loss: 0.9749, validation loss: 2.7068
2024-06-02 20:41:50 [INFO]: Epoch 033 - training loss: 0.9748, validation loss: 2.6728
2024-06-02 20:41:53 [INFO]: Epoch 034 - training loss: 0.9739, validation loss: 2.6758
2024-06-02 20:41:57 [INFO]: Epoch 035 - training loss: 0.9728, validation loss: 2.6482
2024-06-02 20:42:01 [INFO]: Epoch 036 - training loss: 0.9723, validation loss: 2.6386
2024-06-02 20:42:05 [INFO]: Epoch 037 - training loss: 0.9727, validation loss: 2.6203
2024-06-02 20:42:09 [INFO]: Epoch 038 - training loss: 0.9707, validation loss: 2.6161
2024-06-02 20:42:13 [INFO]: Epoch 039 - training loss: 0.9704, validation loss: 2.6019
2024-06-02 20:42:17 [INFO]: Epoch 040 - training loss: 0.9696, validation loss: 2.5875
2024-06-02 20:42:21 [INFO]: Epoch 041 - training loss: 0.9702, validation loss: 2.5953
2024-06-02 20:42:24 [INFO]: Epoch 042 - training loss: 0.9691, validation loss: 2.5590
2024-06-02 20:42:28 [INFO]: Epoch 043 - training loss: 0.9706, validation loss: 2.5405
2024-06-02 20:42:32 [INFO]: Epoch 044 - training loss: 0.9693, validation loss: 2.5334
2024-06-02 20:42:36 [INFO]: Epoch 045 - training loss: 0.9677, validation loss: 2.5272
2024-06-02 20:42:40 [INFO]: Epoch 046 - training loss: 0.9677, validation loss: 2.5254
2024-06-02 20:42:43 [INFO]: Epoch 047 - training loss: 0.9672, validation loss: 2.5051
2024-06-02 20:42:47 [INFO]: Epoch 048 - training loss: 0.9668, validation loss: 2.4892
2024-06-02 20:42:51 [INFO]: Epoch 049 - training loss: 0.9663, validation loss: 2.4814
2024-06-02 20:42:55 [INFO]: Epoch 050 - training loss: 0.9654, validation loss: 2.4761
2024-06-02 20:42:59 [INFO]: Epoch 051 - training loss: 0.9649, validation loss: 2.4420
2024-06-02 20:43:03 [INFO]: Epoch 052 - training loss: 0.9643, validation loss: 2.4412
2024-06-02 20:43:07 [INFO]: Epoch 053 - training loss: 0.9641, validation loss: 2.4447
2024-06-02 20:43:10 [INFO]: Epoch 054 - training loss: 0.9643, validation loss: 2.4118
2024-06-02 20:43:14 [INFO]: Epoch 055 - training loss: 0.9639, validation loss: 2.4119
2024-06-02 20:43:18 [INFO]: Epoch 056 - training loss: 0.9638, validation loss: 2.4348
2024-06-02 20:43:22 [INFO]: Epoch 057 - training loss: 0.9639, validation loss: 2.3901
2024-06-02 20:43:26 [INFO]: Epoch 058 - training loss: 0.9630, validation loss: 2.3590
2024-06-02 20:43:30 [INFO]: Epoch 059 - training loss: 0.9629, validation loss: 2.3354
2024-06-02 20:43:34 [INFO]: Epoch 060 - training loss: 0.9634, validation loss: 2.3263
2024-06-02 20:43:37 [INFO]: Epoch 061 - training loss: 0.9630, validation loss: 2.3042
2024-06-02 20:43:41 [INFO]: Epoch 062 - training loss: 0.9616, validation loss: 2.3272
2024-06-02 20:43:45 [INFO]: Epoch 063 - training loss: 0.9617, validation loss: 2.3273
2024-06-02 20:43:49 [INFO]: Epoch 064 - training loss: 0.9620, validation loss: 2.3051
2024-06-02 20:43:53 [INFO]: Epoch 065 - training loss: 0.9614, validation loss: 2.2962
2024-06-02 20:43:56 [INFO]: Epoch 066 - training loss: 0.9612, validation loss: 2.2822
2024-06-02 20:44:00 [INFO]: Epoch 067 - training loss: 0.9606, validation loss: 2.2764
2024-06-02 20:44:04 [INFO]: Epoch 068 - training loss: 0.9604, validation loss: 2.2598
2024-06-02 20:44:08 [INFO]: Epoch 069 - training loss: 0.9604, validation loss: 2.2702
2024-06-02 20:44:12 [INFO]: Epoch 070 - training loss: 0.9599, validation loss: 2.2528
2024-06-02 20:44:16 [INFO]: Epoch 071 - training loss: 0.9595, validation loss: 2.2311
2024-06-02 20:44:20 [INFO]: Epoch 072 - training loss: 0.9594, validation loss: 2.2301
2024-06-02 20:44:24 [INFO]: Epoch 073 - training loss: 0.9595, validation loss: 2.2462
2024-06-02 20:44:27 [INFO]: Epoch 074 - training loss: 0.9594, validation loss: 2.2307
2024-06-02 20:44:32 [INFO]: Epoch 075 - training loss: 0.9599, validation loss: 2.2288
2024-06-02 20:44:35 [INFO]: Epoch 076 - training loss: 0.9594, validation loss: 2.2076
2024-06-02 20:44:39 [INFO]: Epoch 077 - training loss: 0.9590, validation loss: 2.2025
2024-06-02 20:44:43 [INFO]: Epoch 078 - training loss: 0.9586, validation loss: 2.1946
2024-06-02 20:44:47 [INFO]: Epoch 079 - training loss: 0.9589, validation loss: 2.2031
2024-06-02 20:44:51 [INFO]: Epoch 080 - training loss: 0.9585, validation loss: 2.1789
2024-06-02 20:44:55 [INFO]: Epoch 081 - training loss: 0.9577, validation loss: 2.1878
2024-06-02 20:44:59 [INFO]: Epoch 082 - training loss: 0.9585, validation loss: 2.1756
2024-06-02 20:45:03 [INFO]: Epoch 083 - training loss: 0.9579, validation loss: 2.1647
2024-06-02 20:45:07 [INFO]: Epoch 084 - training loss: 0.9574, validation loss: 2.1443
2024-06-02 20:45:11 [INFO]: Epoch 085 - training loss: 0.9584, validation loss: 2.1580
2024-06-02 20:45:15 [INFO]: Epoch 086 - training loss: 0.9577, validation loss: 2.1554
2024-06-02 20:45:18 [INFO]: Epoch 087 - training loss: 0.9567, validation loss: 2.1286
2024-06-02 20:45:22 [INFO]: Epoch 088 - training loss: 0.9574, validation loss: 2.1222
2024-06-02 20:45:25 [INFO]: Epoch 089 - training loss: 0.9570, validation loss: 2.1254
2024-06-02 20:45:29 [INFO]: Epoch 090 - training loss: 0.9576, validation loss: 2.1041
2024-06-02 20:45:33 [INFO]: Epoch 091 - training loss: 0.9570, validation loss: 2.1375
2024-06-02 20:45:37 [INFO]: Epoch 092 - training loss: 0.9570, validation loss: 2.1174
2024-06-02 20:45:41 [INFO]: Epoch 093 - training loss: 0.9564, validation loss: 2.1045
2024-06-02 20:45:45 [INFO]: Epoch 094 - training loss: 0.9567, validation loss: 2.1068
2024-06-02 20:45:49 [INFO]: Epoch 095 - training loss: 0.9567, validation loss: 2.0936
2024-06-02 20:45:53 [INFO]: Epoch 096 - training loss: 0.9569, validation loss: 2.0800
2024-06-02 20:45:57 [INFO]: Epoch 097 - training loss: 0.9559, validation loss: 2.0965
2024-06-02 20:46:00 [INFO]: Epoch 098 - training loss: 0.9559, validation loss: 2.0962
2024-06-02 20:46:04 [INFO]: Epoch 099 - training loss: 0.9562, validation loss: 2.0771
2024-06-02 20:46:08 [INFO]: Epoch 100 - training loss: 0.9556, validation loss: 2.0887
2024-06-02 20:46:08 [INFO]: Finished training. The best model is from epoch#99.
2024-06-02 20:46:08 [INFO]: Saved the model to results_point_rate05/Electricity/FiLM_Electricity/round_4/20240602_T203942/FiLM.pypots
2024-06-02 20:46:09 [INFO]: Successfully saved to results_point_rate05/Electricity/FiLM_Electricity/round_4/imputation.pkl
2024-06-02 20:46:09 [INFO]: Round4 - FiLM on Electricity: MAE=0.8961, MSE=1.3855, MRE=0.4798
2024-06-02 20:46:09 [INFO]: Done! Final results:
Averaged FiLM (570,613 params) on Electricity: MAE=0.9067 ± 0.023954878017275614, MSE=1.4338 ± 0.07768607637602995, MRE=0.4855 ± 0.012825600026854466, average inference time=0.62
