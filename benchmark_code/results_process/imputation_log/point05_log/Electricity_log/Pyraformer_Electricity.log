2024-06-04 02:59:05 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-04 02:59:05 [INFO]: Using the given device: cuda:0
2024-06-04 02:59:05 [INFO]: Model files will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_0/20240604_T025905
2024-06-04 02:59:05 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_0/20240604_T025905/tensorboard
2024-06-04 02:59:06 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-04 02:59:23 [INFO]: Epoch 001 - training loss: 1.0595, validation loss: 3.1136
2024-06-04 02:59:36 [INFO]: Epoch 002 - training loss: 0.7950, validation loss: 2.9342
2024-06-04 02:59:50 [INFO]: Epoch 003 - training loss: 0.7151, validation loss: 2.8843
2024-06-04 03:00:03 [INFO]: Epoch 004 - training loss: 0.6685, validation loss: 2.8485
2024-06-04 03:00:17 [INFO]: Epoch 005 - training loss: 0.6344, validation loss: 2.8387
2024-06-04 03:00:31 [INFO]: Epoch 006 - training loss: 0.6223, validation loss: 2.8220
2024-06-04 03:00:44 [INFO]: Epoch 007 - training loss: 0.6154, validation loss: 2.7984
2024-06-04 03:00:57 [INFO]: Epoch 008 - training loss: 0.5873, validation loss: 2.8055
2024-06-04 03:01:11 [INFO]: Epoch 009 - training loss: 0.5770, validation loss: 2.8191
2024-06-04 03:01:24 [INFO]: Epoch 010 - training loss: 0.5646, validation loss: 2.8124
2024-06-04 03:01:38 [INFO]: Epoch 011 - training loss: 0.5537, validation loss: 2.7798
2024-06-04 03:01:51 [INFO]: Epoch 012 - training loss: 0.5433, validation loss: 2.7822
2024-06-04 03:02:04 [INFO]: Epoch 013 - training loss: 0.5363, validation loss: 2.7653
2024-06-04 03:02:17 [INFO]: Epoch 014 - training loss: 0.5322, validation loss: 2.7719
2024-06-04 03:02:29 [INFO]: Epoch 015 - training loss: 0.5275, validation loss: 2.7952
2024-06-04 03:02:42 [INFO]: Epoch 016 - training loss: 0.5251, validation loss: 2.7460
2024-06-04 03:02:56 [INFO]: Epoch 017 - training loss: 0.5176, validation loss: 2.7344
2024-06-04 03:03:09 [INFO]: Epoch 018 - training loss: 0.5114, validation loss: 2.7201
2024-06-04 03:03:22 [INFO]: Epoch 019 - training loss: 0.5079, validation loss: 2.7272
2024-06-04 03:03:35 [INFO]: Epoch 020 - training loss: 0.5002, validation loss: 2.7194
2024-06-04 03:03:48 [INFO]: Epoch 021 - training loss: 0.4980, validation loss: 2.7170
2024-06-04 03:04:01 [INFO]: Epoch 022 - training loss: 0.4968, validation loss: 2.7123
2024-06-04 03:04:15 [INFO]: Epoch 023 - training loss: 0.4942, validation loss: 2.7218
2024-06-04 03:04:29 [INFO]: Epoch 024 - training loss: 0.4915, validation loss: 2.6964
2024-06-04 03:04:43 [INFO]: Epoch 025 - training loss: 0.4867, validation loss: 2.7068
2024-06-04 03:04:57 [INFO]: Epoch 026 - training loss: 0.4862, validation loss: 2.7132
2024-06-04 03:05:11 [INFO]: Epoch 027 - training loss: 0.4821, validation loss: 2.6859
2024-06-04 03:05:25 [INFO]: Epoch 028 - training loss: 0.4756, validation loss: 2.6824
2024-06-04 03:05:39 [INFO]: Epoch 029 - training loss: 0.4748, validation loss: 2.6851
2024-06-04 03:05:52 [INFO]: Epoch 030 - training loss: 0.4722, validation loss: 2.6643
2024-06-04 03:06:06 [INFO]: Epoch 031 - training loss: 0.4676, validation loss: 2.6748
2024-06-04 03:06:18 [INFO]: Epoch 032 - training loss: 0.4683, validation loss: 2.6792
2024-06-04 03:06:31 [INFO]: Epoch 033 - training loss: 0.4648, validation loss: 2.6793
2024-06-04 03:06:44 [INFO]: Epoch 034 - training loss: 0.4649, validation loss: 2.6576
2024-06-04 03:06:57 [INFO]: Epoch 035 - training loss: 0.4631, validation loss: 2.6491
2024-06-04 03:07:09 [INFO]: Epoch 036 - training loss: 0.4594, validation loss: 2.6599
2024-06-04 03:07:22 [INFO]: Epoch 037 - training loss: 0.4591, validation loss: 2.6511
2024-06-04 03:07:35 [INFO]: Epoch 038 - training loss: 0.4569, validation loss: 2.6344
2024-06-04 03:07:48 [INFO]: Epoch 039 - training loss: 0.4546, validation loss: 2.6485
2024-06-04 03:08:00 [INFO]: Epoch 040 - training loss: 0.4529, validation loss: 2.6307
2024-06-04 03:08:14 [INFO]: Epoch 041 - training loss: 0.4537, validation loss: 2.6313
2024-06-04 03:08:28 [INFO]: Epoch 042 - training loss: 0.4522, validation loss: 2.6193
2024-06-04 03:08:42 [INFO]: Epoch 043 - training loss: 0.4519, validation loss: 2.6135
2024-06-04 03:08:56 [INFO]: Epoch 044 - training loss: 0.4505, validation loss: 2.6120
2024-06-04 03:09:10 [INFO]: Epoch 045 - training loss: 0.4476, validation loss: 2.6308
2024-06-04 03:09:24 [INFO]: Epoch 046 - training loss: 0.4462, validation loss: 2.6071
2024-06-04 03:09:38 [INFO]: Epoch 047 - training loss: 0.4435, validation loss: 2.6056
2024-06-04 03:09:52 [INFO]: Epoch 048 - training loss: 0.4447, validation loss: 2.5931
2024-06-04 03:10:06 [INFO]: Epoch 049 - training loss: 0.4438, validation loss: 2.5957
2024-06-04 03:10:18 [INFO]: Epoch 050 - training loss: 0.4431, validation loss: 2.6008
2024-06-04 03:10:29 [INFO]: Epoch 051 - training loss: 0.4442, validation loss: 2.5865
2024-06-04 03:10:40 [INFO]: Epoch 052 - training loss: 0.4424, validation loss: 2.5893
2024-06-04 03:10:52 [INFO]: Epoch 053 - training loss: 0.4397, validation loss: 2.6024
2024-06-04 03:11:03 [INFO]: Epoch 054 - training loss: 0.4385, validation loss: 2.5625
2024-06-04 03:11:14 [INFO]: Epoch 055 - training loss: 0.4385, validation loss: 2.5772
2024-06-04 03:11:25 [INFO]: Epoch 056 - training loss: 0.4412, validation loss: 2.5852
2024-06-04 03:11:37 [INFO]: Epoch 057 - training loss: 0.4365, validation loss: 2.5811
2024-06-04 03:11:48 [INFO]: Epoch 058 - training loss: 0.4326, validation loss: 2.5643
2024-06-04 03:11:59 [INFO]: Epoch 059 - training loss: 0.4352, validation loss: 2.5892
2024-06-04 03:12:10 [INFO]: Epoch 060 - training loss: 0.4329, validation loss: 2.5697
2024-06-04 03:12:21 [INFO]: Epoch 061 - training loss: 0.4316, validation loss: 2.5509
2024-06-04 03:12:32 [INFO]: Epoch 062 - training loss: 0.4320, validation loss: 2.5482
2024-06-04 03:12:43 [INFO]: Epoch 063 - training loss: 0.4320, validation loss: 2.5612
2024-06-04 03:12:54 [INFO]: Epoch 064 - training loss: 0.4303, validation loss: 2.5599
2024-06-04 03:13:06 [INFO]: Epoch 065 - training loss: 0.4299, validation loss: 2.5545
2024-06-04 03:13:17 [INFO]: Epoch 066 - training loss: 0.4272, validation loss: 2.5474
2024-06-04 03:13:28 [INFO]: Epoch 067 - training loss: 0.4274, validation loss: 2.5761
2024-06-04 03:13:39 [INFO]: Epoch 068 - training loss: 0.4272, validation loss: 2.5535
2024-06-04 03:13:50 [INFO]: Epoch 069 - training loss: 0.4261, validation loss: 2.5482
2024-06-04 03:14:01 [INFO]: Epoch 070 - training loss: 0.4233, validation loss: 2.5707
2024-06-04 03:14:13 [INFO]: Epoch 071 - training loss: 0.4229, validation loss: 2.5223
2024-06-04 03:14:24 [INFO]: Epoch 072 - training loss: 0.4227, validation loss: 2.5494
2024-06-04 03:14:35 [INFO]: Epoch 073 - training loss: 0.4230, validation loss: 2.5591
2024-06-04 03:14:46 [INFO]: Epoch 074 - training loss: 0.4227, validation loss: 2.5559
2024-06-04 03:14:58 [INFO]: Epoch 075 - training loss: 0.4208, validation loss: 2.5340
2024-06-04 03:15:09 [INFO]: Epoch 076 - training loss: 0.4207, validation loss: 2.5324
2024-06-04 03:15:20 [INFO]: Epoch 077 - training loss: 0.4187, validation loss: 2.5224
2024-06-04 03:15:31 [INFO]: Epoch 078 - training loss: 0.4187, validation loss: 2.5213
2024-06-04 03:15:42 [INFO]: Epoch 079 - training loss: 0.4181, validation loss: 2.5266
2024-06-04 03:15:53 [INFO]: Epoch 080 - training loss: 0.4175, validation loss: 2.5318
2024-06-04 03:16:04 [INFO]: Epoch 081 - training loss: 0.4170, validation loss: 2.5336
2024-06-04 03:16:15 [INFO]: Epoch 082 - training loss: 0.4162, validation loss: 2.5379
2024-06-04 03:16:26 [INFO]: Epoch 083 - training loss: 0.4160, validation loss: 2.5303
2024-06-04 03:16:37 [INFO]: Epoch 084 - training loss: 0.4163, validation loss: 2.5132
2024-06-04 03:16:49 [INFO]: Epoch 085 - training loss: 0.4159, validation loss: 2.5420
2024-06-04 03:17:00 [INFO]: Epoch 086 - training loss: 0.4142, validation loss: 2.5362
2024-06-04 03:17:11 [INFO]: Epoch 087 - training loss: 0.4149, validation loss: 2.5436
2024-06-04 03:17:23 [INFO]: Epoch 088 - training loss: 0.4142, validation loss: 2.5356
2024-06-04 03:17:34 [INFO]: Epoch 089 - training loss: 0.4146, validation loss: 2.5149
2024-06-04 03:17:45 [INFO]: Epoch 090 - training loss: 0.4150, validation loss: 2.5200
2024-06-04 03:17:56 [INFO]: Epoch 091 - training loss: 0.4167, validation loss: 2.5326
2024-06-04 03:18:08 [INFO]: Epoch 092 - training loss: 0.4156, validation loss: 2.5390
2024-06-04 03:18:19 [INFO]: Epoch 093 - training loss: 0.4134, validation loss: 2.5430
2024-06-04 03:18:30 [INFO]: Epoch 094 - training loss: 0.4147, validation loss: 2.5493
2024-06-04 03:18:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:18:30 [INFO]: Finished training. The best model is from epoch#84.
2024-06-04 03:18:31 [INFO]: Saved the model to results_point_rate05/Electricity/Pyraformer_Electricity/round_0/20240604_T025905/Pyraformer.pypots
2024-06-04 03:18:38 [INFO]: Successfully saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_0/imputation.pkl
2024-06-04 03:18:38 [INFO]: Round0 - Pyraformer on Electricity: MAE=1.1595, MSE=2.7031, MRE=0.6208
2024-06-04 03:18:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-04 03:18:38 [INFO]: Using the given device: cuda:0
2024-06-04 03:18:38 [INFO]: Model files will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_1/20240604_T031838
2024-06-04 03:18:38 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_1/20240604_T031838/tensorboard
2024-06-04 03:18:39 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-04 03:18:50 [INFO]: Epoch 001 - training loss: 1.0476, validation loss: 3.1001
2024-06-04 03:19:02 [INFO]: Epoch 002 - training loss: 0.7630, validation loss: 2.9293
2024-06-04 03:19:13 [INFO]: Epoch 003 - training loss: 0.6919, validation loss: 2.8729
2024-06-04 03:19:24 [INFO]: Epoch 004 - training loss: 0.6547, validation loss: 2.8509
2024-06-04 03:19:35 [INFO]: Epoch 005 - training loss: 0.6326, validation loss: 2.8283
2024-06-04 03:19:47 [INFO]: Epoch 006 - training loss: 0.6172, validation loss: 2.8383
2024-06-04 03:19:58 [INFO]: Epoch 007 - training loss: 0.5993, validation loss: 2.8396
2024-06-04 03:20:09 [INFO]: Epoch 008 - training loss: 0.5924, validation loss: 2.8264
2024-06-04 03:20:21 [INFO]: Epoch 009 - training loss: 0.5735, validation loss: 2.7950
2024-06-04 03:20:32 [INFO]: Epoch 010 - training loss: 0.5625, validation loss: 2.7781
2024-06-04 03:20:44 [INFO]: Epoch 011 - training loss: 0.5500, validation loss: 2.7823
2024-06-04 03:20:55 [INFO]: Epoch 012 - training loss: 0.5491, validation loss: 2.7510
2024-06-04 03:21:06 [INFO]: Epoch 013 - training loss: 0.5398, validation loss: 2.7744
2024-06-04 03:21:18 [INFO]: Epoch 014 - training loss: 0.5294, validation loss: 2.7648
2024-06-04 03:21:29 [INFO]: Epoch 015 - training loss: 0.5225, validation loss: 2.7375
2024-06-04 03:21:40 [INFO]: Epoch 016 - training loss: 0.5181, validation loss: 2.7245
2024-06-04 03:21:52 [INFO]: Epoch 017 - training loss: 0.5237, validation loss: 2.7033
2024-06-04 03:22:03 [INFO]: Epoch 018 - training loss: 0.5145, validation loss: 2.7065
2024-06-04 03:22:15 [INFO]: Epoch 019 - training loss: 0.5081, validation loss: 2.7160
2024-06-04 03:22:27 [INFO]: Epoch 020 - training loss: 0.5014, validation loss: 2.7392
2024-06-04 03:22:38 [INFO]: Epoch 021 - training loss: 0.5002, validation loss: 2.6824
2024-06-04 03:22:50 [INFO]: Epoch 022 - training loss: 0.4928, validation loss: 2.6863
2024-06-04 03:23:01 [INFO]: Epoch 023 - training loss: 0.4942, validation loss: 2.6868
2024-06-04 03:23:13 [INFO]: Epoch 024 - training loss: 0.4873, validation loss: 2.6652
2024-06-04 03:23:24 [INFO]: Epoch 025 - training loss: 0.4833, validation loss: 2.6612
2024-06-04 03:23:36 [INFO]: Epoch 026 - training loss: 0.4819, validation loss: 2.6511
2024-06-04 03:23:47 [INFO]: Epoch 027 - training loss: 0.4823, validation loss: 2.6442
2024-06-04 03:23:58 [INFO]: Epoch 028 - training loss: 0.4789, validation loss: 2.6515
2024-06-04 03:24:09 [INFO]: Epoch 029 - training loss: 0.4750, validation loss: 2.6640
2024-06-04 03:24:20 [INFO]: Epoch 030 - training loss: 0.4708, validation loss: 2.6402
2024-06-04 03:24:31 [INFO]: Epoch 031 - training loss: 0.4713, validation loss: 2.6243
2024-06-04 03:24:42 [INFO]: Epoch 032 - training loss: 0.4667, validation loss: 2.6449
2024-06-04 03:24:54 [INFO]: Epoch 033 - training loss: 0.4647, validation loss: 2.6481
2024-06-04 03:25:05 [INFO]: Epoch 034 - training loss: 0.4621, validation loss: 2.6344
2024-06-04 03:25:16 [INFO]: Epoch 035 - training loss: 0.4606, validation loss: 2.6095
2024-06-04 03:25:27 [INFO]: Epoch 036 - training loss: 0.4598, validation loss: 2.6156
2024-06-04 03:25:37 [INFO]: Epoch 037 - training loss: 0.4587, validation loss: 2.6297
2024-06-04 03:25:48 [INFO]: Epoch 038 - training loss: 0.4542, validation loss: 2.6457
2024-06-04 03:25:59 [INFO]: Epoch 039 - training loss: 0.4544, validation loss: 2.6148
2024-06-04 03:26:10 [INFO]: Epoch 040 - training loss: 0.4551, validation loss: 2.6173
2024-06-04 03:26:21 [INFO]: Epoch 041 - training loss: 0.4528, validation loss: 2.6163
2024-06-04 03:26:32 [INFO]: Epoch 042 - training loss: 0.4510, validation loss: 2.6042
2024-06-04 03:26:43 [INFO]: Epoch 043 - training loss: 0.4536, validation loss: 2.6208
2024-06-04 03:26:54 [INFO]: Epoch 044 - training loss: 0.4500, validation loss: 2.5974
2024-06-04 03:27:05 [INFO]: Epoch 045 - training loss: 0.4493, validation loss: 2.5996
2024-06-04 03:27:16 [INFO]: Epoch 046 - training loss: 0.4484, validation loss: 2.6038
2024-06-04 03:27:27 [INFO]: Epoch 047 - training loss: 0.4452, validation loss: 2.6168
2024-06-04 03:27:38 [INFO]: Epoch 048 - training loss: 0.4447, validation loss: 2.6200
2024-06-04 03:27:49 [INFO]: Epoch 049 - training loss: 0.4432, validation loss: 2.6074
2024-06-04 03:28:00 [INFO]: Epoch 050 - training loss: 0.4407, validation loss: 2.5996
2024-06-04 03:28:11 [INFO]: Epoch 051 - training loss: 0.4397, validation loss: 2.6041
2024-06-04 03:28:22 [INFO]: Epoch 052 - training loss: 0.4383, validation loss: 2.5810
2024-06-04 03:28:32 [INFO]: Epoch 053 - training loss: 0.4370, validation loss: 2.5722
2024-06-04 03:28:44 [INFO]: Epoch 054 - training loss: 0.4349, validation loss: 2.5950
2024-06-04 03:28:54 [INFO]: Epoch 055 - training loss: 0.4330, validation loss: 2.5834
2024-06-04 03:29:05 [INFO]: Epoch 056 - training loss: 0.4329, validation loss: 2.6021
2024-06-04 03:29:16 [INFO]: Epoch 057 - training loss: 0.4325, validation loss: 2.5833
2024-06-04 03:29:27 [INFO]: Epoch 058 - training loss: 0.4325, validation loss: 2.5712
2024-06-04 03:29:37 [INFO]: Epoch 059 - training loss: 0.4308, validation loss: 2.5804
2024-06-04 03:29:49 [INFO]: Epoch 060 - training loss: 0.4301, validation loss: 2.5845
2024-06-04 03:30:00 [INFO]: Epoch 061 - training loss: 0.4288, validation loss: 2.5745
2024-06-04 03:30:11 [INFO]: Epoch 062 - training loss: 0.4287, validation loss: 2.5706
2024-06-04 03:30:21 [INFO]: Epoch 063 - training loss: 0.4289, validation loss: 2.5800
2024-06-04 03:30:32 [INFO]: Epoch 064 - training loss: 0.4331, validation loss: 2.5644
2024-06-04 03:30:43 [INFO]: Epoch 065 - training loss: 0.4289, validation loss: 2.5816
2024-06-04 03:30:55 [INFO]: Epoch 066 - training loss: 0.4262, validation loss: 2.5699
2024-06-04 03:31:06 [INFO]: Epoch 067 - training loss: 0.4248, validation loss: 2.5556
2024-06-04 03:31:17 [INFO]: Epoch 068 - training loss: 0.4248, validation loss: 2.5447
2024-06-04 03:31:28 [INFO]: Epoch 069 - training loss: 0.4251, validation loss: 2.5563
2024-06-04 03:31:39 [INFO]: Epoch 070 - training loss: 0.4230, validation loss: 2.5740
2024-06-04 03:31:50 [INFO]: Epoch 071 - training loss: 0.4219, validation loss: 2.5570
2024-06-04 03:32:01 [INFO]: Epoch 072 - training loss: 0.4213, validation loss: 2.5662
2024-06-04 03:32:12 [INFO]: Epoch 073 - training loss: 0.4213, validation loss: 2.5513
2024-06-04 03:32:23 [INFO]: Epoch 074 - training loss: 0.4191, validation loss: 2.5621
2024-06-04 03:32:34 [INFO]: Epoch 075 - training loss: 0.4193, validation loss: 2.5694
2024-06-04 03:32:45 [INFO]: Epoch 076 - training loss: 0.4191, validation loss: 2.5502
2024-06-04 03:32:56 [INFO]: Epoch 077 - training loss: 0.4188, validation loss: 2.5776
2024-06-04 03:33:07 [INFO]: Epoch 078 - training loss: 0.4182, validation loss: 2.5452
2024-06-04 03:33:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:33:07 [INFO]: Finished training. The best model is from epoch#68.
2024-06-04 03:33:07 [INFO]: Saved the model to results_point_rate05/Electricity/Pyraformer_Electricity/round_1/20240604_T031838/Pyraformer.pypots
2024-06-04 03:33:15 [INFO]: Successfully saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_1/imputation.pkl
2024-06-04 03:33:15 [INFO]: Round1 - Pyraformer on Electricity: MAE=1.1497, MSE=2.7765, MRE=0.6156
2024-06-04 03:33:15 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-04 03:33:15 [INFO]: Using the given device: cuda:0
2024-06-04 03:33:15 [INFO]: Model files will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_2/20240604_T033315
2024-06-04 03:33:15 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_2/20240604_T033315/tensorboard
2024-06-04 03:33:16 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-04 03:33:27 [INFO]: Epoch 001 - training loss: 1.0701, validation loss: 3.1382
2024-06-04 03:33:38 [INFO]: Epoch 002 - training loss: 0.7738, validation loss: 2.9521
2024-06-04 03:33:49 [INFO]: Epoch 003 - training loss: 0.6995, validation loss: 2.8497
2024-06-04 03:34:00 [INFO]: Epoch 004 - training loss: 0.6585, validation loss: 2.8628
2024-06-04 03:34:11 [INFO]: Epoch 005 - training loss: 0.6335, validation loss: 2.8251
2024-06-04 03:34:22 [INFO]: Epoch 006 - training loss: 0.6195, validation loss: 2.7915
2024-06-04 03:34:33 [INFO]: Epoch 007 - training loss: 0.6057, validation loss: 2.7702
2024-06-04 03:34:44 [INFO]: Epoch 008 - training loss: 0.5842, validation loss: 2.7694
2024-06-04 03:34:55 [INFO]: Epoch 009 - training loss: 0.5756, validation loss: 2.7662
2024-06-04 03:35:06 [INFO]: Epoch 010 - training loss: 0.5652, validation loss: 2.7478
2024-06-04 03:35:17 [INFO]: Epoch 011 - training loss: 0.5557, validation loss: 2.7499
2024-06-04 03:35:28 [INFO]: Epoch 012 - training loss: 0.5435, validation loss: 2.7318
2024-06-04 03:35:39 [INFO]: Epoch 013 - training loss: 0.5338, validation loss: 2.7295
2024-06-04 03:35:50 [INFO]: Epoch 014 - training loss: 0.5347, validation loss: 2.7244
2024-06-04 03:36:01 [INFO]: Epoch 015 - training loss: 0.5272, validation loss: 2.7047
2024-06-04 03:36:12 [INFO]: Epoch 016 - training loss: 0.5230, validation loss: 2.7098
2024-06-04 03:36:24 [INFO]: Epoch 017 - training loss: 0.5129, validation loss: 2.6800
2024-06-04 03:36:35 [INFO]: Epoch 018 - training loss: 0.5141, validation loss: 2.6856
2024-06-04 03:36:47 [INFO]: Epoch 019 - training loss: 0.5085, validation loss: 2.6859
2024-06-04 03:36:58 [INFO]: Epoch 020 - training loss: 0.5042, validation loss: 2.6555
2024-06-04 03:37:10 [INFO]: Epoch 021 - training loss: 0.4961, validation loss: 2.6709
2024-06-04 03:37:21 [INFO]: Epoch 022 - training loss: 0.4948, validation loss: 2.6643
2024-06-04 03:37:33 [INFO]: Epoch 023 - training loss: 0.4893, validation loss: 2.6491
2024-06-04 03:37:44 [INFO]: Epoch 024 - training loss: 0.4859, validation loss: 2.6743
2024-06-04 03:37:56 [INFO]: Epoch 025 - training loss: 0.4890, validation loss: 2.6401
2024-06-04 03:38:07 [INFO]: Epoch 026 - training loss: 0.4861, validation loss: 2.6490
2024-06-04 03:38:18 [INFO]: Epoch 027 - training loss: 0.4797, validation loss: 2.6471
2024-06-04 03:38:30 [INFO]: Epoch 028 - training loss: 0.4786, validation loss: 2.6439
2024-06-04 03:38:41 [INFO]: Epoch 029 - training loss: 0.4773, validation loss: 2.6226
2024-06-04 03:38:53 [INFO]: Epoch 030 - training loss: 0.4721, validation loss: 2.6346
2024-06-04 03:39:04 [INFO]: Epoch 031 - training loss: 0.4688, validation loss: 2.6342
2024-06-04 03:39:15 [INFO]: Epoch 032 - training loss: 0.4705, validation loss: 2.6302
2024-06-04 03:39:27 [INFO]: Epoch 033 - training loss: 0.4675, validation loss: 2.6218
2024-06-04 03:39:38 [INFO]: Epoch 034 - training loss: 0.4648, validation loss: 2.6293
2024-06-04 03:39:49 [INFO]: Epoch 035 - training loss: 0.4625, validation loss: 2.6227
2024-06-04 03:40:01 [INFO]: Epoch 036 - training loss: 0.4615, validation loss: 2.6320
2024-06-04 03:40:12 [INFO]: Epoch 037 - training loss: 0.4594, validation loss: 2.6000
2024-06-04 03:40:23 [INFO]: Epoch 038 - training loss: 0.4589, validation loss: 2.6101
2024-06-04 03:40:34 [INFO]: Epoch 039 - training loss: 0.4565, validation loss: 2.5892
2024-06-04 03:40:45 [INFO]: Epoch 040 - training loss: 0.4580, validation loss: 2.6009
2024-06-04 03:40:57 [INFO]: Epoch 041 - training loss: 0.4536, validation loss: 2.5830
2024-06-04 03:41:09 [INFO]: Epoch 042 - training loss: 0.4518, validation loss: 2.5911
2024-06-04 03:41:21 [INFO]: Epoch 043 - training loss: 0.4495, validation loss: 2.6044
2024-06-04 03:41:33 [INFO]: Epoch 044 - training loss: 0.4488, validation loss: 2.5953
2024-06-04 03:41:44 [INFO]: Epoch 045 - training loss: 0.4486, validation loss: 2.5850
2024-06-04 03:41:56 [INFO]: Epoch 046 - training loss: 0.4449, validation loss: 2.5774
2024-06-04 03:42:07 [INFO]: Epoch 047 - training loss: 0.4441, validation loss: 2.6005
2024-06-04 03:42:19 [INFO]: Epoch 048 - training loss: 0.4446, validation loss: 2.5941
2024-06-04 03:42:30 [INFO]: Epoch 049 - training loss: 0.4428, validation loss: 2.5927
2024-06-04 03:42:42 [INFO]: Epoch 050 - training loss: 0.4416, validation loss: 2.5945
2024-06-04 03:42:53 [INFO]: Epoch 051 - training loss: 0.4421, validation loss: 2.5983
2024-06-04 03:43:04 [INFO]: Epoch 052 - training loss: 0.4412, validation loss: 2.5702
2024-06-04 03:43:16 [INFO]: Epoch 053 - training loss: 0.4384, validation loss: 2.5743
2024-06-04 03:43:27 [INFO]: Epoch 054 - training loss: 0.4375, validation loss: 2.5879
2024-06-04 03:43:38 [INFO]: Epoch 055 - training loss: 0.4370, validation loss: 2.5846
2024-06-04 03:43:50 [INFO]: Epoch 056 - training loss: 0.4353, validation loss: 2.5950
2024-06-04 03:44:01 [INFO]: Epoch 057 - training loss: 0.4374, validation loss: 2.5686
2024-06-04 03:44:13 [INFO]: Epoch 058 - training loss: 0.4374, validation loss: 2.5644
2024-06-04 03:44:24 [INFO]: Epoch 059 - training loss: 0.4355, validation loss: 2.5650
2024-06-04 03:44:36 [INFO]: Epoch 060 - training loss: 0.4328, validation loss: 2.5640
2024-06-04 03:44:47 [INFO]: Epoch 061 - training loss: 0.4322, validation loss: 2.5652
2024-06-04 03:44:58 [INFO]: Epoch 062 - training loss: 0.4327, validation loss: 2.5508
2024-06-04 03:45:10 [INFO]: Epoch 063 - training loss: 0.4290, validation loss: 2.5303
2024-06-04 03:45:21 [INFO]: Epoch 064 - training loss: 0.4292, validation loss: 2.5564
2024-06-04 03:45:33 [INFO]: Epoch 065 - training loss: 0.4291, validation loss: 2.5417
2024-06-04 03:45:44 [INFO]: Epoch 066 - training loss: 0.4305, validation loss: 2.5373
2024-06-04 03:45:55 [INFO]: Epoch 067 - training loss: 0.4304, validation loss: 2.5729
2024-06-04 03:46:07 [INFO]: Epoch 068 - training loss: 0.4290, validation loss: 2.5520
2024-06-04 03:46:18 [INFO]: Epoch 069 - training loss: 0.4285, validation loss: 2.5625
2024-06-04 03:46:29 [INFO]: Epoch 070 - training loss: 0.4277, validation loss: 2.5343
2024-06-04 03:46:41 [INFO]: Epoch 071 - training loss: 0.4256, validation loss: 2.5459
2024-06-04 03:46:52 [INFO]: Epoch 072 - training loss: 0.4264, validation loss: 2.5564
2024-06-04 03:47:03 [INFO]: Epoch 073 - training loss: 0.4237, validation loss: 2.5399
2024-06-04 03:47:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:47:03 [INFO]: Finished training. The best model is from epoch#63.
2024-06-04 03:47:03 [INFO]: Saved the model to results_point_rate05/Electricity/Pyraformer_Electricity/round_2/20240604_T033315/Pyraformer.pypots
2024-06-04 03:47:11 [INFO]: Successfully saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_2/imputation.pkl
2024-06-04 03:47:11 [INFO]: Round2 - Pyraformer on Electricity: MAE=1.0759, MSE=2.5767, MRE=0.5760
2024-06-04 03:47:11 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-04 03:47:11 [INFO]: Using the given device: cuda:0
2024-06-04 03:47:11 [INFO]: Model files will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_3/20240604_T034711
2024-06-04 03:47:11 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_3/20240604_T034711/tensorboard
2024-06-04 03:47:12 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-04 03:47:23 [INFO]: Epoch 001 - training loss: 1.0488, validation loss: 3.0888
2024-06-04 03:47:34 [INFO]: Epoch 002 - training loss: 0.7819, validation loss: 2.9490
2024-06-04 03:47:45 [INFO]: Epoch 003 - training loss: 0.7010, validation loss: 2.8392
2024-06-04 03:47:56 [INFO]: Epoch 004 - training loss: 0.6639, validation loss: 2.8313
2024-06-04 03:48:08 [INFO]: Epoch 005 - training loss: 0.6385, validation loss: 2.8252
2024-06-04 03:48:19 [INFO]: Epoch 006 - training loss: 0.6188, validation loss: 2.8028
2024-06-04 03:48:30 [INFO]: Epoch 007 - training loss: 0.6032, validation loss: 2.7699
2024-06-04 03:48:41 [INFO]: Epoch 008 - training loss: 0.5851, validation loss: 2.7489
2024-06-04 03:48:52 [INFO]: Epoch 009 - training loss: 0.5758, validation loss: 2.7656
2024-06-04 03:49:04 [INFO]: Epoch 010 - training loss: 0.5747, validation loss: 2.7684
2024-06-04 03:49:15 [INFO]: Epoch 011 - training loss: 0.5559, validation loss: 2.7564
2024-06-04 03:49:27 [INFO]: Epoch 012 - training loss: 0.5428, validation loss: 2.7478
2024-06-04 03:49:38 [INFO]: Epoch 013 - training loss: 0.5373, validation loss: 2.7309
2024-06-04 03:49:49 [INFO]: Epoch 014 - training loss: 0.5323, validation loss: 2.7189
2024-06-04 03:50:01 [INFO]: Epoch 015 - training loss: 0.5290, validation loss: 2.7200
2024-06-04 03:50:12 [INFO]: Epoch 016 - training loss: 0.5181, validation loss: 2.7007
2024-06-04 03:50:23 [INFO]: Epoch 017 - training loss: 0.5170, validation loss: 2.7201
2024-06-04 03:50:34 [INFO]: Epoch 018 - training loss: 0.5118, validation loss: 2.7301
2024-06-04 03:50:46 [INFO]: Epoch 019 - training loss: 0.5110, validation loss: 2.7143
2024-06-04 03:50:57 [INFO]: Epoch 020 - training loss: 0.5043, validation loss: 2.6784
2024-06-04 03:51:08 [INFO]: Epoch 021 - training loss: 0.4999, validation loss: 2.6843
2024-06-04 03:51:19 [INFO]: Epoch 022 - training loss: 0.4956, validation loss: 2.6635
2024-06-04 03:51:30 [INFO]: Epoch 023 - training loss: 0.4936, validation loss: 2.6867
2024-06-04 03:51:41 [INFO]: Epoch 024 - training loss: 0.4911, validation loss: 2.6546
2024-06-04 03:51:52 [INFO]: Epoch 025 - training loss: 0.4875, validation loss: 2.6716
2024-06-04 03:52:04 [INFO]: Epoch 026 - training loss: 0.4837, validation loss: 2.6460
2024-06-04 03:52:15 [INFO]: Epoch 027 - training loss: 0.4798, validation loss: 2.6417
2024-06-04 03:52:24 [INFO]: Epoch 028 - training loss: 0.4767, validation loss: 2.6449
2024-06-04 03:52:33 [INFO]: Epoch 029 - training loss: 0.4763, validation loss: 2.6353
2024-06-04 03:52:42 [INFO]: Epoch 030 - training loss: 0.4772, validation loss: 2.6448
2024-06-04 03:52:52 [INFO]: Epoch 031 - training loss: 0.4754, validation loss: 2.6072
2024-06-04 03:53:01 [INFO]: Epoch 032 - training loss: 0.4696, validation loss: 2.6157
2024-06-04 03:53:09 [INFO]: Epoch 033 - training loss: 0.4679, validation loss: 2.6123
2024-06-04 03:53:18 [INFO]: Epoch 034 - training loss: 0.4671, validation loss: 2.6043
2024-06-04 03:53:27 [INFO]: Epoch 035 - training loss: 0.4640, validation loss: 2.5925
2024-06-04 03:53:35 [INFO]: Epoch 036 - training loss: 0.4645, validation loss: 2.6305
2024-06-04 03:53:44 [INFO]: Epoch 037 - training loss: 0.4620, validation loss: 2.6196
2024-06-04 03:53:53 [INFO]: Epoch 038 - training loss: 0.4576, validation loss: 2.6040
2024-06-04 03:54:01 [INFO]: Epoch 039 - training loss: 0.4582, validation loss: 2.6120
2024-06-04 03:54:10 [INFO]: Epoch 040 - training loss: 0.4545, validation loss: 2.5994
2024-06-04 03:54:18 [INFO]: Epoch 041 - training loss: 0.4514, validation loss: 2.6118
2024-06-04 03:54:27 [INFO]: Epoch 042 - training loss: 0.4505, validation loss: 2.5911
2024-06-04 03:54:36 [INFO]: Epoch 043 - training loss: 0.4514, validation loss: 2.6056
2024-06-04 03:54:44 [INFO]: Epoch 044 - training loss: 0.4488, validation loss: 2.5806
2024-06-04 03:54:53 [INFO]: Epoch 045 - training loss: 0.4486, validation loss: 2.5714
2024-06-04 03:55:02 [INFO]: Epoch 046 - training loss: 0.4453, validation loss: 2.5816
2024-06-04 03:55:11 [INFO]: Epoch 047 - training loss: 0.4452, validation loss: 2.6078
2024-06-04 03:55:21 [INFO]: Epoch 048 - training loss: 0.4432, validation loss: 2.6020
2024-06-04 03:55:30 [INFO]: Epoch 049 - training loss: 0.4417, validation loss: 2.5987
2024-06-04 03:55:39 [INFO]: Epoch 050 - training loss: 0.4419, validation loss: 2.6100
2024-06-04 03:55:48 [INFO]: Epoch 051 - training loss: 0.4401, validation loss: 2.5883
2024-06-04 03:55:57 [INFO]: Epoch 052 - training loss: 0.4378, validation loss: 2.5941
2024-06-04 03:56:06 [INFO]: Epoch 053 - training loss: 0.4412, validation loss: 2.5918
2024-06-04 03:56:16 [INFO]: Epoch 054 - training loss: 0.4390, validation loss: 2.5919
2024-06-04 03:56:25 [INFO]: Epoch 055 - training loss: 0.4373, validation loss: 2.5729
2024-06-04 03:56:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 03:56:25 [INFO]: Finished training. The best model is from epoch#45.
2024-06-04 03:56:25 [INFO]: Saved the model to results_point_rate05/Electricity/Pyraformer_Electricity/round_3/20240604_T034711/Pyraformer.pypots
2024-06-04 03:56:32 [INFO]: Successfully saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_3/imputation.pkl
2024-06-04 03:56:32 [INFO]: Round3 - Pyraformer on Electricity: MAE=1.1694, MSE=2.8043, MRE=0.6261
2024-06-04 03:56:32 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-04 03:56:32 [INFO]: Using the given device: cuda:0
2024-06-04 03:56:32 [INFO]: Model files will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_4/20240604_T035632
2024-06-04 03:56:32 [INFO]: Tensorboard file will be saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_4/20240604_T035632/tensorboard
2024-06-04 03:56:32 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 15,940,914
2024-06-04 03:56:41 [INFO]: Epoch 001 - training loss: 1.0595, validation loss: 3.1081
2024-06-04 03:56:50 [INFO]: Epoch 002 - training loss: 0.7815, validation loss: 2.9483
2024-06-04 03:56:59 [INFO]: Epoch 003 - training loss: 0.7041, validation loss: 2.8693
2024-06-04 03:57:08 [INFO]: Epoch 004 - training loss: 0.6622, validation loss: 2.8431
2024-06-04 03:57:18 [INFO]: Epoch 005 - training loss: 0.6308, validation loss: 2.8466
2024-06-04 03:57:27 [INFO]: Epoch 006 - training loss: 0.6166, validation loss: 2.8270
2024-06-04 03:57:36 [INFO]: Epoch 007 - training loss: 0.6074, validation loss: 2.8197
2024-06-04 03:57:45 [INFO]: Epoch 008 - training loss: 0.5864, validation loss: 2.8201
2024-06-04 03:57:54 [INFO]: Epoch 009 - training loss: 0.5709, validation loss: 2.8048
2024-06-04 03:58:03 [INFO]: Epoch 010 - training loss: 0.5618, validation loss: 2.7957
2024-06-04 03:58:13 [INFO]: Epoch 011 - training loss: 0.5611, validation loss: 2.7735
2024-06-04 03:58:22 [INFO]: Epoch 012 - training loss: 0.5470, validation loss: 2.7698
2024-06-04 03:58:31 [INFO]: Epoch 013 - training loss: 0.5401, validation loss: 2.7563
2024-06-04 03:58:40 [INFO]: Epoch 014 - training loss: 0.5339, validation loss: 2.7486
2024-06-04 03:58:49 [INFO]: Epoch 015 - training loss: 0.5292, validation loss: 2.7362
2024-06-04 03:58:57 [INFO]: Epoch 016 - training loss: 0.5185, validation loss: 2.7399
2024-06-04 03:59:06 [INFO]: Epoch 017 - training loss: 0.5239, validation loss: 2.7179
2024-06-04 03:59:14 [INFO]: Epoch 018 - training loss: 0.5142, validation loss: 2.7036
2024-06-04 03:59:23 [INFO]: Epoch 019 - training loss: 0.5070, validation loss: 2.6926
2024-06-04 03:59:32 [INFO]: Epoch 020 - training loss: 0.5043, validation loss: 2.7036
2024-06-04 03:59:41 [INFO]: Epoch 021 - training loss: 0.5015, validation loss: 2.6884
2024-06-04 03:59:50 [INFO]: Epoch 022 - training loss: 0.4962, validation loss: 2.6618
2024-06-04 03:59:59 [INFO]: Epoch 023 - training loss: 0.4893, validation loss: 2.6541
2024-06-04 04:00:08 [INFO]: Epoch 024 - training loss: 0.4876, validation loss: 2.6762
2024-06-04 04:00:17 [INFO]: Epoch 025 - training loss: 0.4888, validation loss: 2.6499
2024-06-04 04:00:26 [INFO]: Epoch 026 - training loss: 0.4862, validation loss: 2.6625
2024-06-04 04:00:35 [INFO]: Epoch 027 - training loss: 0.4781, validation loss: 2.6487
2024-06-04 04:00:44 [INFO]: Epoch 028 - training loss: 0.4771, validation loss: 2.6366
2024-06-04 04:00:53 [INFO]: Epoch 029 - training loss: 0.4762, validation loss: 2.6308
2024-06-04 04:01:02 [INFO]: Epoch 030 - training loss: 0.4712, validation loss: 2.6383
2024-06-04 04:01:11 [INFO]: Epoch 031 - training loss: 0.4711, validation loss: 2.6366
2024-06-04 04:01:19 [INFO]: Epoch 032 - training loss: 0.4692, validation loss: 2.6319
2024-06-04 04:01:27 [INFO]: Epoch 033 - training loss: 0.4658, validation loss: 2.6289
2024-06-04 04:01:36 [INFO]: Epoch 034 - training loss: 0.4626, validation loss: 2.6241
2024-06-04 04:01:44 [INFO]: Epoch 035 - training loss: 0.4617, validation loss: 2.6129
2024-06-04 04:01:53 [INFO]: Epoch 036 - training loss: 0.4607, validation loss: 2.6272
2024-06-04 04:02:01 [INFO]: Epoch 037 - training loss: 0.4601, validation loss: 2.6386
2024-06-04 04:02:10 [INFO]: Epoch 038 - training loss: 0.4573, validation loss: 2.6447
2024-06-04 04:02:18 [INFO]: Epoch 039 - training loss: 0.4565, validation loss: 2.6209
2024-06-04 04:02:27 [INFO]: Epoch 040 - training loss: 0.4571, validation loss: 2.5982
2024-06-04 04:02:36 [INFO]: Epoch 041 - training loss: 0.4547, validation loss: 2.5917
2024-06-04 04:02:45 [INFO]: Epoch 042 - training loss: 0.4503, validation loss: 2.5869
2024-06-04 04:02:54 [INFO]: Epoch 043 - training loss: 0.4532, validation loss: 2.6013
2024-06-04 04:03:02 [INFO]: Epoch 044 - training loss: 0.4519, validation loss: 2.5933
2024-06-04 04:03:12 [INFO]: Epoch 045 - training loss: 0.4470, validation loss: 2.5996
2024-06-04 04:03:20 [INFO]: Epoch 046 - training loss: 0.4466, validation loss: 2.5881
2024-06-04 04:03:29 [INFO]: Epoch 047 - training loss: 0.4438, validation loss: 2.5987
2024-06-04 04:03:38 [INFO]: Epoch 048 - training loss: 0.4430, validation loss: 2.5752
2024-06-04 04:03:47 [INFO]: Epoch 049 - training loss: 0.4420, validation loss: 2.5953
2024-06-04 04:03:56 [INFO]: Epoch 050 - training loss: 0.4404, validation loss: 2.5797
2024-06-04 04:04:05 [INFO]: Epoch 051 - training loss: 0.4394, validation loss: 2.5686
2024-06-04 04:04:14 [INFO]: Epoch 052 - training loss: 0.4395, validation loss: 2.5619
2024-06-04 04:04:23 [INFO]: Epoch 053 - training loss: 0.4404, validation loss: 2.6039
2024-06-04 04:04:32 [INFO]: Epoch 054 - training loss: 0.4382, validation loss: 2.5814
2024-06-04 04:04:40 [INFO]: Epoch 055 - training loss: 0.4355, validation loss: 2.5592
2024-06-04 04:04:50 [INFO]: Epoch 056 - training loss: 0.4365, validation loss: 2.5819
2024-06-04 04:04:58 [INFO]: Epoch 057 - training loss: 0.4349, validation loss: 2.5776
2024-06-04 04:05:07 [INFO]: Epoch 058 - training loss: 0.4346, validation loss: 2.5836
2024-06-04 04:05:16 [INFO]: Epoch 059 - training loss: 0.4339, validation loss: 2.5778
2024-06-04 04:05:25 [INFO]: Epoch 060 - training loss: 0.4347, validation loss: 2.5751
2024-06-04 04:05:33 [INFO]: Epoch 061 - training loss: 0.4331, validation loss: 2.5948
2024-06-04 04:05:42 [INFO]: Epoch 062 - training loss: 0.4300, validation loss: 2.5696
2024-06-04 04:05:50 [INFO]: Epoch 063 - training loss: 0.4291, validation loss: 2.5779
2024-06-04 04:05:59 [INFO]: Epoch 064 - training loss: 0.4293, validation loss: 2.5646
2024-06-04 04:06:07 [INFO]: Epoch 065 - training loss: 0.4279, validation loss: 2.5657
2024-06-04 04:06:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-04 04:06:07 [INFO]: Finished training. The best model is from epoch#55.
2024-06-04 04:06:07 [INFO]: Saved the model to results_point_rate05/Electricity/Pyraformer_Electricity/round_4/20240604_T035632/Pyraformer.pypots
2024-06-04 04:06:14 [INFO]: Successfully saved to results_point_rate05/Electricity/Pyraformer_Electricity/round_4/imputation.pkl
2024-06-04 04:06:14 [INFO]: Round4 - Pyraformer on Electricity: MAE=1.1003, MSE=2.6918, MRE=0.5891
2024-06-04 04:06:14 [INFO]: Done! Final results:
Averaged Pyraformer (15,940,914 params) on Electricity: MAE=1.1310 ± 0.03637287158096149, MSE=2.7105 ± 0.07933720719430119, MRE=0.6055 ± 0.019474275861021857, average inference time=1.36
