2024-06-02 20:24:36 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:24:36 [INFO]: Using the given device: cuda:0
2024-06-02 20:24:36 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202436
2024-06-02 20:24:36 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202436/tensorboard
2024-06-02 20:24:36 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:24:52 [INFO]: Epoch 001 - training loss: 0.6473, validation loss: 0.4523
2024-06-02 20:25:01 [INFO]: Epoch 002 - training loss: 0.3989, validation loss: 0.4569
2024-06-02 20:25:10 [INFO]: Epoch 003 - training loss: 0.3314, validation loss: 0.3812
2024-06-02 20:25:19 [INFO]: Epoch 004 - training loss: 0.3631, validation loss: 0.3895
2024-06-02 20:25:28 [INFO]: Epoch 005 - training loss: 0.3295, validation loss: 0.4007
2024-06-02 20:25:38 [INFO]: Epoch 006 - training loss: 0.3552, validation loss: 0.3674
2024-06-02 20:25:46 [INFO]: Epoch 007 - training loss: 0.3326, validation loss: 0.3625
2024-06-02 20:25:55 [INFO]: Epoch 008 - training loss: 0.3202, validation loss: 0.3662
2024-06-02 20:26:04 [INFO]: Epoch 009 - training loss: 0.2986, validation loss: 0.3328
2024-06-02 20:26:14 [INFO]: Epoch 010 - training loss: 0.3052, validation loss: 0.3571
2024-06-02 20:26:23 [INFO]: Epoch 011 - training loss: 0.3295, validation loss: 0.3266
2024-06-02 20:26:31 [INFO]: Epoch 012 - training loss: 0.2924, validation loss: 0.3421
2024-06-02 20:26:41 [INFO]: Epoch 013 - training loss: 0.3065, validation loss: 0.3321
2024-06-02 20:26:50 [INFO]: Epoch 014 - training loss: 0.2679, validation loss: 0.3386
2024-06-02 20:26:58 [INFO]: Epoch 015 - training loss: 0.2852, validation loss: 0.3144
2024-06-02 20:27:07 [INFO]: Epoch 016 - training loss: 0.2763, validation loss: 0.3075
2024-06-02 20:27:17 [INFO]: Epoch 017 - training loss: 0.2774, validation loss: 0.3097
2024-06-02 20:27:24 [INFO]: Epoch 018 - training loss: 0.2472, validation loss: 0.3156
2024-06-02 20:27:32 [INFO]: Epoch 019 - training loss: 0.2451, validation loss: 0.2976
2024-06-02 20:27:40 [INFO]: Epoch 020 - training loss: 0.2476, validation loss: 0.2965
2024-06-02 20:27:48 [INFO]: Epoch 021 - training loss: 0.2727, validation loss: 0.2951
2024-06-02 20:27:55 [INFO]: Epoch 022 - training loss: 0.2604, validation loss: 0.2828
2024-06-02 20:28:03 [INFO]: Epoch 023 - training loss: 0.2431, validation loss: 0.2837
2024-06-02 20:28:10 [INFO]: Epoch 024 - training loss: 0.2404, validation loss: 0.2720
2024-06-02 20:28:16 [INFO]: Epoch 025 - training loss: 0.2325, validation loss: 0.2803
2024-06-02 20:28:23 [INFO]: Epoch 026 - training loss: 0.2437, validation loss: 0.2653
2024-06-02 20:28:28 [INFO]: Epoch 027 - training loss: 0.2708, validation loss: 0.2622
2024-06-02 20:28:34 [INFO]: Epoch 028 - training loss: 0.2595, validation loss: 0.2634
2024-06-02 20:28:40 [INFO]: Epoch 029 - training loss: 0.2348, validation loss: 0.2631
2024-06-02 20:28:45 [INFO]: Epoch 030 - training loss: 0.2241, validation loss: 0.2631
2024-06-02 20:28:51 [INFO]: Epoch 031 - training loss: 0.2328, validation loss: 0.2870
2024-06-02 20:28:56 [INFO]: Epoch 032 - training loss: 0.2645, validation loss: 0.2627
2024-06-02 20:29:01 [INFO]: Epoch 033 - training loss: 0.2230, validation loss: 0.2620
2024-06-02 20:29:06 [INFO]: Epoch 034 - training loss: 0.2358, validation loss: 0.2633
2024-06-02 20:29:10 [INFO]: Epoch 035 - training loss: 0.2345, validation loss: 0.2591
2024-06-02 20:29:15 [INFO]: Epoch 036 - training loss: 0.2201, validation loss: 0.2458
2024-06-02 20:29:19 [INFO]: Epoch 037 - training loss: 0.2382, validation loss: 0.2649
2024-06-02 20:29:24 [INFO]: Epoch 038 - training loss: 0.2455, validation loss: 0.2406
2024-06-02 20:29:28 [INFO]: Epoch 039 - training loss: 0.2305, validation loss: 0.2570
2024-06-02 20:29:32 [INFO]: Epoch 040 - training loss: 0.2366, validation loss: 0.2410
2024-06-02 20:29:36 [INFO]: Epoch 041 - training loss: 0.1975, validation loss: 0.2417
2024-06-02 20:29:41 [INFO]: Epoch 042 - training loss: 0.2134, validation loss: 0.2586
2024-06-02 20:29:46 [INFO]: Epoch 043 - training loss: 0.2448, validation loss: 0.2405
2024-06-02 20:29:50 [INFO]: Epoch 044 - training loss: 0.2269, validation loss: 0.2287
2024-06-02 20:29:55 [INFO]: Epoch 045 - training loss: 0.1963, validation loss: 0.2459
2024-06-02 20:29:59 [INFO]: Epoch 046 - training loss: 0.2101, validation loss: 0.2285
2024-06-02 20:30:04 [INFO]: Epoch 047 - training loss: 0.2209, validation loss: 0.2357
2024-06-02 20:30:08 [INFO]: Epoch 048 - training loss: 0.2176, validation loss: 0.2269
2024-06-02 20:30:13 [INFO]: Epoch 049 - training loss: 0.2032, validation loss: 0.2159
2024-06-02 20:30:17 [INFO]: Epoch 050 - training loss: 0.1788, validation loss: 0.2275
2024-06-02 20:30:22 [INFO]: Epoch 051 - training loss: 0.2230, validation loss: 0.2306
2024-06-02 20:30:25 [INFO]: Epoch 052 - training loss: 0.2036, validation loss: 0.2186
2024-06-02 20:30:27 [INFO]: Epoch 053 - training loss: 0.1984, validation loss: 0.2412
2024-06-02 20:30:30 [INFO]: Epoch 054 - training loss: 0.2215, validation loss: 0.2381
2024-06-02 20:30:33 [INFO]: Epoch 055 - training loss: 0.2183, validation loss: 0.2289
2024-06-02 20:30:35 [INFO]: Epoch 056 - training loss: 0.2051, validation loss: 0.2378
2024-06-02 20:30:38 [INFO]: Epoch 057 - training loss: 0.2218, validation loss: 0.2229
2024-06-02 20:30:41 [INFO]: Epoch 058 - training loss: 0.1905, validation loss: 0.2233
2024-06-02 20:30:43 [INFO]: Epoch 059 - training loss: 0.2271, validation loss: 0.2281
2024-06-02 20:30:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:30:43 [INFO]: Finished training. The best model is from epoch#49.
2024-06-02 20:30:43 [INFO]: Saved the model to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240602_T202436/CSDI.pypots
2024-06-02 20:32:14 [INFO]: Successfully saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_0/imputation.pkl
2024-06-02 20:32:14 [INFO]: Round0 - CSDI on ItalyAir: MAE=1.5742, MSE=52.8281, MRE=2.0586
2024-06-02 20:32:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:32:14 [INFO]: Using the given device: cuda:0
2024-06-02 20:32:14 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240602_T203214
2024-06-02 20:32:14 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240602_T203214/tensorboard
2024-06-02 20:32:14 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:32:17 [INFO]: Epoch 001 - training loss: 0.6617, validation loss: 0.4512
2024-06-02 20:32:19 [INFO]: Epoch 002 - training loss: 0.4087, validation loss: 0.4275
2024-06-02 20:32:22 [INFO]: Epoch 003 - training loss: 0.3863, validation loss: 0.3983
2024-06-02 20:32:25 [INFO]: Epoch 004 - training loss: 0.3861, validation loss: 0.4299
2024-06-02 20:32:27 [INFO]: Epoch 005 - training loss: 0.3861, validation loss: 0.3898
2024-06-02 20:32:30 [INFO]: Epoch 006 - training loss: 0.3345, validation loss: 0.4292
2024-06-02 20:32:32 [INFO]: Epoch 007 - training loss: 0.3046, validation loss: 0.3652
2024-06-02 20:32:34 [INFO]: Epoch 008 - training loss: 0.3160, validation loss: 0.3785
2024-06-02 20:32:37 [INFO]: Epoch 009 - training loss: 0.3239, validation loss: 0.3507
2024-06-02 20:32:39 [INFO]: Epoch 010 - training loss: 0.2792, validation loss: 0.3431
2024-06-02 20:32:42 [INFO]: Epoch 011 - training loss: 0.2883, validation loss: 0.3601
2024-06-02 20:32:45 [INFO]: Epoch 012 - training loss: 0.3007, validation loss: 0.3400
2024-06-02 20:32:47 [INFO]: Epoch 013 - training loss: 0.2704, validation loss: 0.3200
2024-06-02 20:32:50 [INFO]: Epoch 014 - training loss: 0.2645, validation loss: 0.3262
2024-06-02 20:32:52 [INFO]: Epoch 015 - training loss: 0.3330, validation loss: 0.3241
2024-06-02 20:32:53 [INFO]: Epoch 016 - training loss: 0.2990, validation loss: 0.3536
2024-06-02 20:32:55 [INFO]: Epoch 017 - training loss: 0.2845, validation loss: 0.3116
2024-06-02 20:32:57 [INFO]: Epoch 018 - training loss: 0.2721, validation loss: 0.3019
2024-06-02 20:32:58 [INFO]: Epoch 019 - training loss: 0.2763, validation loss: 0.2994
2024-06-02 20:33:00 [INFO]: Epoch 020 - training loss: 0.2814, validation loss: 0.2996
2024-06-02 20:33:02 [INFO]: Epoch 021 - training loss: 0.3097, validation loss: 0.2890
2024-06-02 20:33:03 [INFO]: Epoch 022 - training loss: 0.2340, validation loss: 0.2644
2024-06-02 20:33:05 [INFO]: Epoch 023 - training loss: 0.2624, validation loss: 0.2966
2024-06-02 20:33:07 [INFO]: Epoch 024 - training loss: 0.2564, validation loss: 0.2834
2024-06-02 20:33:08 [INFO]: Epoch 025 - training loss: 0.2369, validation loss: 0.2676
2024-06-02 20:33:10 [INFO]: Epoch 026 - training loss: 0.2276, validation loss: 0.2711
2024-06-02 20:33:12 [INFO]: Epoch 027 - training loss: 0.2036, validation loss: 0.2675
2024-06-02 20:33:13 [INFO]: Epoch 028 - training loss: 0.2210, validation loss: 0.2587
2024-06-02 20:33:15 [INFO]: Epoch 029 - training loss: 0.2193, validation loss: 0.2488
2024-06-02 20:33:17 [INFO]: Epoch 030 - training loss: 0.2363, validation loss: 0.2520
2024-06-02 20:33:18 [INFO]: Epoch 031 - training loss: 0.2277, validation loss: 0.2542
2024-06-02 20:33:20 [INFO]: Epoch 032 - training loss: 0.2674, validation loss: 0.2531
2024-06-02 20:33:22 [INFO]: Epoch 033 - training loss: 0.2323, validation loss: 0.2551
2024-06-02 20:33:23 [INFO]: Epoch 034 - training loss: 0.2149, validation loss: 0.2556
2024-06-02 20:33:25 [INFO]: Epoch 035 - training loss: 0.2452, validation loss: 0.2440
2024-06-02 20:33:26 [INFO]: Epoch 036 - training loss: 0.2207, validation loss: 0.2345
2024-06-02 20:33:28 [INFO]: Epoch 037 - training loss: 0.2015, validation loss: 0.2424
2024-06-02 20:33:30 [INFO]: Epoch 038 - training loss: 0.2109, validation loss: 0.2258
2024-06-02 20:33:31 [INFO]: Epoch 039 - training loss: 0.2084, validation loss: 0.2299
2024-06-02 20:33:33 [INFO]: Epoch 040 - training loss: 0.2155, validation loss: 0.2283
2024-06-02 20:33:35 [INFO]: Epoch 041 - training loss: 0.2415, validation loss: 0.2290
2024-06-02 20:33:36 [INFO]: Epoch 042 - training loss: 0.2255, validation loss: 0.2206
2024-06-02 20:33:38 [INFO]: Epoch 043 - training loss: 0.2164, validation loss: 0.2173
2024-06-02 20:33:40 [INFO]: Epoch 044 - training loss: 0.2192, validation loss: 0.2228
2024-06-02 20:33:41 [INFO]: Epoch 045 - training loss: 0.2180, validation loss: 0.2156
2024-06-02 20:33:43 [INFO]: Epoch 046 - training loss: 0.2023, validation loss: 0.2201
2024-06-02 20:33:45 [INFO]: Epoch 047 - training loss: 0.2056, validation loss: 0.2040
2024-06-02 20:33:46 [INFO]: Epoch 048 - training loss: 0.2177, validation loss: 0.2352
2024-06-02 20:33:48 [INFO]: Epoch 049 - training loss: 0.2153, validation loss: 0.2323
2024-06-02 20:33:50 [INFO]: Epoch 050 - training loss: 0.2194, validation loss: 0.2294
2024-06-02 20:33:51 [INFO]: Epoch 051 - training loss: 0.2147, validation loss: 0.2148
2024-06-02 20:33:53 [INFO]: Epoch 052 - training loss: 0.2202, validation loss: 0.2260
2024-06-02 20:33:55 [INFO]: Epoch 053 - training loss: 0.1894, validation loss: 0.2081
2024-06-02 20:33:56 [INFO]: Epoch 054 - training loss: 0.1982, validation loss: 0.2007
2024-06-02 20:33:58 [INFO]: Epoch 055 - training loss: 0.2102, validation loss: 0.1991
2024-06-02 20:34:00 [INFO]: Epoch 056 - training loss: 0.2153, validation loss: 0.2143
2024-06-02 20:34:01 [INFO]: Epoch 057 - training loss: 0.1904, validation loss: 0.1986
2024-06-02 20:34:03 [INFO]: Epoch 058 - training loss: 0.2149, validation loss: 0.2170
2024-06-02 20:34:05 [INFO]: Epoch 059 - training loss: 0.1717, validation loss: 0.2024
2024-06-02 20:34:06 [INFO]: Epoch 060 - training loss: 0.1977, validation loss: 0.2140
2024-06-02 20:34:08 [INFO]: Epoch 061 - training loss: 0.1960, validation loss: 0.2027
2024-06-02 20:34:09 [INFO]: Epoch 062 - training loss: 0.2113, validation loss: 0.1989
2024-06-02 20:34:11 [INFO]: Epoch 063 - training loss: 0.2065, validation loss: 0.2102
2024-06-02 20:34:13 [INFO]: Epoch 064 - training loss: 0.2082, validation loss: 0.1922
2024-06-02 20:34:14 [INFO]: Epoch 065 - training loss: 0.1685, validation loss: 0.1935
2024-06-02 20:34:16 [INFO]: Epoch 066 - training loss: 0.1683, validation loss: 0.1917
2024-06-02 20:34:18 [INFO]: Epoch 067 - training loss: 0.2094, validation loss: 0.2028
2024-06-02 20:34:19 [INFO]: Epoch 068 - training loss: 0.1976, validation loss: 0.2108
2024-06-02 20:34:21 [INFO]: Epoch 069 - training loss: 0.1742, validation loss: 0.1968
2024-06-02 20:34:23 [INFO]: Epoch 070 - training loss: 0.1919, validation loss: 0.1937
2024-06-02 20:34:24 [INFO]: Epoch 071 - training loss: 0.1740, validation loss: 0.2062
2024-06-02 20:34:26 [INFO]: Epoch 072 - training loss: 0.1975, validation loss: 0.2066
2024-06-02 20:34:28 [INFO]: Epoch 073 - training loss: 0.1761, validation loss: 0.1915
2024-06-02 20:34:29 [INFO]: Epoch 074 - training loss: 0.1818, validation loss: 0.1895
2024-06-02 20:34:31 [INFO]: Epoch 075 - training loss: 0.1936, validation loss: 0.1907
2024-06-02 20:34:33 [INFO]: Epoch 076 - training loss: 0.1927, validation loss: 0.1894
2024-06-02 20:34:34 [INFO]: Epoch 077 - training loss: 0.1787, validation loss: 0.1890
2024-06-02 20:34:36 [INFO]: Epoch 078 - training loss: 0.1635, validation loss: 0.1847
2024-06-02 20:34:38 [INFO]: Epoch 079 - training loss: 0.1886, validation loss: 0.1795
2024-06-02 20:34:39 [INFO]: Epoch 080 - training loss: 0.1984, validation loss: 0.1815
2024-06-02 20:34:41 [INFO]: Epoch 081 - training loss: 0.1958, validation loss: 0.2032
2024-06-02 20:34:43 [INFO]: Epoch 082 - training loss: 0.1591, validation loss: 0.1807
2024-06-02 20:34:44 [INFO]: Epoch 083 - training loss: 0.1761, validation loss: 0.1807
2024-06-02 20:34:46 [INFO]: Epoch 084 - training loss: 0.1928, validation loss: 0.1757
2024-06-02 20:34:48 [INFO]: Epoch 085 - training loss: 0.1756, validation loss: 0.1826
2024-06-02 20:34:49 [INFO]: Epoch 086 - training loss: 0.1641, validation loss: 0.1858
2024-06-02 20:34:51 [INFO]: Epoch 087 - training loss: 0.1914, validation loss: 0.1844
2024-06-02 20:34:53 [INFO]: Epoch 088 - training loss: 0.1927, validation loss: 0.1811
2024-06-02 20:34:54 [INFO]: Epoch 089 - training loss: 0.1832, validation loss: 0.1794
2024-06-02 20:34:56 [INFO]: Epoch 090 - training loss: 0.1679, validation loss: 0.1958
2024-06-02 20:34:58 [INFO]: Epoch 091 - training loss: 0.1902, validation loss: 0.1808
2024-06-02 20:34:59 [INFO]: Epoch 092 - training loss: 0.1780, validation loss: 0.1731
2024-06-02 20:35:01 [INFO]: Epoch 093 - training loss: 0.1601, validation loss: 0.1714
2024-06-02 20:35:03 [INFO]: Epoch 094 - training loss: 0.1786, validation loss: 0.1796
2024-06-02 20:35:04 [INFO]: Epoch 095 - training loss: 0.1548, validation loss: 0.1795
2024-06-02 20:35:06 [INFO]: Epoch 096 - training loss: 0.1674, validation loss: 0.1788
2024-06-02 20:35:07 [INFO]: Epoch 097 - training loss: 0.1835, validation loss: 0.1743
2024-06-02 20:35:09 [INFO]: Epoch 098 - training loss: 0.1858, validation loss: 0.1883
2024-06-02 20:35:11 [INFO]: Epoch 099 - training loss: 0.1749, validation loss: 0.1750
2024-06-02 20:35:12 [INFO]: Epoch 100 - training loss: 0.1728, validation loss: 0.1753
2024-06-02 20:35:12 [INFO]: Finished training. The best model is from epoch#93.
2024-06-02 20:35:12 [INFO]: Saved the model to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240602_T203214/CSDI.pypots
2024-06-02 20:36:09 [INFO]: Successfully saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_1/imputation.pkl
2024-06-02 20:36:09 [INFO]: Round1 - CSDI on ItalyAir: MAE=0.4073, MSE=1.8733, MRE=0.5326
2024-06-02 20:36:09 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:36:09 [INFO]: Using the given device: cuda:0
2024-06-02 20:36:09 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203609
2024-06-02 20:36:09 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203609/tensorboard
2024-06-02 20:36:09 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:36:11 [INFO]: Epoch 001 - training loss: 0.6368, validation loss: 0.4804
2024-06-02 20:36:12 [INFO]: Epoch 002 - training loss: 0.3728, validation loss: 0.4121
2024-06-02 20:36:14 [INFO]: Epoch 003 - training loss: 0.3444, validation loss: 0.3899
2024-06-02 20:36:16 [INFO]: Epoch 004 - training loss: 0.3720, validation loss: 0.4044
2024-06-02 20:36:17 [INFO]: Epoch 005 - training loss: 0.3453, validation loss: 0.3744
2024-06-02 20:36:19 [INFO]: Epoch 006 - training loss: 0.3514, validation loss: 0.4234
2024-06-02 20:36:21 [INFO]: Epoch 007 - training loss: 0.3155, validation loss: 0.3639
2024-06-02 20:36:22 [INFO]: Epoch 008 - training loss: 0.3117, validation loss: 0.3600
2024-06-02 20:36:24 [INFO]: Epoch 009 - training loss: 0.3057, validation loss: 0.3402
2024-06-02 20:36:26 [INFO]: Epoch 010 - training loss: 0.2988, validation loss: 0.3619
2024-06-02 20:36:27 [INFO]: Epoch 011 - training loss: 0.3146, validation loss: 0.3551
2024-06-02 20:36:29 [INFO]: Epoch 012 - training loss: 0.2890, validation loss: 0.3175
2024-06-02 20:36:30 [INFO]: Epoch 013 - training loss: 0.2748, validation loss: 0.3060
2024-06-02 20:36:32 [INFO]: Epoch 014 - training loss: 0.2612, validation loss: 0.3004
2024-06-02 20:36:34 [INFO]: Epoch 015 - training loss: 0.2592, validation loss: 0.3383
2024-06-02 20:36:35 [INFO]: Epoch 016 - training loss: 0.2629, validation loss: 0.3063
2024-06-02 20:36:37 [INFO]: Epoch 017 - training loss: 0.2698, validation loss: 0.3337
2024-06-02 20:36:39 [INFO]: Epoch 018 - training loss: 0.2906, validation loss: 0.3005
2024-06-02 20:36:40 [INFO]: Epoch 019 - training loss: 0.2610, validation loss: 0.2891
2024-06-02 20:36:42 [INFO]: Epoch 020 - training loss: 0.2521, validation loss: 0.2778
2024-06-02 20:36:44 [INFO]: Epoch 021 - training loss: 0.2563, validation loss: 0.2924
2024-06-02 20:36:45 [INFO]: Epoch 022 - training loss: 0.2676, validation loss: 0.2957
2024-06-02 20:36:47 [INFO]: Epoch 023 - training loss: 0.2556, validation loss: 0.2705
2024-06-02 20:36:49 [INFO]: Epoch 024 - training loss: 0.2620, validation loss: 0.2708
2024-06-02 20:36:50 [INFO]: Epoch 025 - training loss: 0.2215, validation loss: 0.2655
2024-06-02 20:36:52 [INFO]: Epoch 026 - training loss: 0.2095, validation loss: 0.2669
2024-06-02 20:36:54 [INFO]: Epoch 027 - training loss: 0.2356, validation loss: 0.2689
2024-06-02 20:36:55 [INFO]: Epoch 028 - training loss: 0.2164, validation loss: 0.2590
2024-06-02 20:36:57 [INFO]: Epoch 029 - training loss: 0.2277, validation loss: 0.2756
2024-06-02 20:36:59 [INFO]: Epoch 030 - training loss: 0.2530, validation loss: 0.2460
2024-06-02 20:37:00 [INFO]: Epoch 031 - training loss: 0.2069, validation loss: 0.2452
2024-06-02 20:37:02 [INFO]: Epoch 032 - training loss: 0.2410, validation loss: 0.2632
2024-06-02 20:37:03 [INFO]: Epoch 033 - training loss: 0.2585, validation loss: 0.2612
2024-06-02 20:37:05 [INFO]: Epoch 034 - training loss: 0.2472, validation loss: 0.2492
2024-06-02 20:37:07 [INFO]: Epoch 035 - training loss: 0.2225, validation loss: 0.2320
2024-06-02 20:37:08 [INFO]: Epoch 036 - training loss: 0.2529, validation loss: 0.2360
2024-06-02 20:37:10 [INFO]: Epoch 037 - training loss: 0.2118, validation loss: 0.2386
2024-06-02 20:37:12 [INFO]: Epoch 038 - training loss: 0.2098, validation loss: 0.2227
2024-06-02 20:37:13 [INFO]: Epoch 039 - training loss: 0.2001, validation loss: 0.2432
2024-06-02 20:37:15 [INFO]: Epoch 040 - training loss: 0.2012, validation loss: 0.2254
2024-06-02 20:37:17 [INFO]: Epoch 041 - training loss: 0.2162, validation loss: 0.2323
2024-06-02 20:37:19 [INFO]: Epoch 042 - training loss: 0.2318, validation loss: 0.2242
2024-06-02 20:37:20 [INFO]: Epoch 043 - training loss: 0.2138, validation loss: 0.2155
2024-06-02 20:37:22 [INFO]: Epoch 044 - training loss: 0.2021, validation loss: 0.2162
2024-06-02 20:37:23 [INFO]: Epoch 045 - training loss: 0.2010, validation loss: 0.2253
2024-06-02 20:37:25 [INFO]: Epoch 046 - training loss: 0.2192, validation loss: 0.2223
2024-06-02 20:37:27 [INFO]: Epoch 047 - training loss: 0.2097, validation loss: 0.2202
2024-06-02 20:37:28 [INFO]: Epoch 048 - training loss: 0.1951, validation loss: 0.2194
2024-06-02 20:37:30 [INFO]: Epoch 049 - training loss: 0.2135, validation loss: 0.2173
2024-06-02 20:37:32 [INFO]: Epoch 050 - training loss: 0.1782, validation loss: 0.2257
2024-06-02 20:37:33 [INFO]: Epoch 051 - training loss: 0.2051, validation loss: 0.2343
2024-06-02 20:37:35 [INFO]: Epoch 052 - training loss: 0.2060, validation loss: 0.2173
2024-06-02 20:37:37 [INFO]: Epoch 053 - training loss: 0.1966, validation loss: 0.2009
2024-06-02 20:37:38 [INFO]: Epoch 054 - training loss: 0.2091, validation loss: 0.2088
2024-06-02 20:37:40 [INFO]: Epoch 055 - training loss: 0.2104, validation loss: 0.2015
2024-06-02 20:37:42 [INFO]: Epoch 056 - training loss: 0.1797, validation loss: 0.2055
2024-06-02 20:37:43 [INFO]: Epoch 057 - training loss: 0.1991, validation loss: 0.2208
2024-06-02 20:37:45 [INFO]: Epoch 058 - training loss: 0.1871, validation loss: 0.2112
2024-06-02 20:37:47 [INFO]: Epoch 059 - training loss: 0.1871, validation loss: 0.1978
2024-06-02 20:37:48 [INFO]: Epoch 060 - training loss: 0.1735, validation loss: 0.2007
2024-06-02 20:37:50 [INFO]: Epoch 061 - training loss: 0.1954, validation loss: 0.2143
2024-06-02 20:37:51 [INFO]: Epoch 062 - training loss: 0.2084, validation loss: 0.2002
2024-06-02 20:37:53 [INFO]: Epoch 063 - training loss: 0.1952, validation loss: 0.1903
2024-06-02 20:37:55 [INFO]: Epoch 064 - training loss: 0.1955, validation loss: 0.1910
2024-06-02 20:37:56 [INFO]: Epoch 065 - training loss: 0.1944, validation loss: 0.1869
2024-06-02 20:37:58 [INFO]: Epoch 066 - training loss: 0.1865, validation loss: 0.2059
2024-06-02 20:38:00 [INFO]: Epoch 067 - training loss: 0.1682, validation loss: 0.1941
2024-06-02 20:38:01 [INFO]: Epoch 068 - training loss: 0.1756, validation loss: 0.1921
2024-06-02 20:38:03 [INFO]: Epoch 069 - training loss: 0.2013, validation loss: 0.1997
2024-06-02 20:38:05 [INFO]: Epoch 070 - training loss: 0.1868, validation loss: 0.2039
2024-06-02 20:38:06 [INFO]: Epoch 071 - training loss: 0.1944, validation loss: 0.1847
2024-06-02 20:38:08 [INFO]: Epoch 072 - training loss: 0.1887, validation loss: 0.1890
2024-06-02 20:38:10 [INFO]: Epoch 073 - training loss: 0.2130, validation loss: 0.1932
2024-06-02 20:38:11 [INFO]: Epoch 074 - training loss: 0.2032, validation loss: 0.1866
2024-06-02 20:38:13 [INFO]: Epoch 075 - training loss: 0.1699, validation loss: 0.1824
2024-06-02 20:38:14 [INFO]: Epoch 076 - training loss: 0.1636, validation loss: 0.1927
2024-06-02 20:38:16 [INFO]: Epoch 077 - training loss: 0.1941, validation loss: 0.1881
2024-06-02 20:38:18 [INFO]: Epoch 078 - training loss: 0.1728, validation loss: 0.1866
2024-06-02 20:38:19 [INFO]: Epoch 079 - training loss: 0.1772, validation loss: 0.1794
2024-06-02 20:38:21 [INFO]: Epoch 080 - training loss: 0.1837, validation loss: 0.1833
2024-06-02 20:38:23 [INFO]: Epoch 081 - training loss: 0.1938, validation loss: 0.1888
2024-06-02 20:38:24 [INFO]: Epoch 082 - training loss: 0.2071, validation loss: 0.1888
2024-06-02 20:38:26 [INFO]: Epoch 083 - training loss: 0.1680, validation loss: 0.1829
2024-06-02 20:38:27 [INFO]: Epoch 084 - training loss: 0.1832, validation loss: 0.1898
2024-06-02 20:38:29 [INFO]: Epoch 085 - training loss: 0.1749, validation loss: 0.1696
2024-06-02 20:38:31 [INFO]: Epoch 086 - training loss: 0.1810, validation loss: 0.1928
2024-06-02 20:38:32 [INFO]: Epoch 087 - training loss: 0.1883, validation loss: 0.1849
2024-06-02 20:38:34 [INFO]: Epoch 088 - training loss: 0.1894, validation loss: 0.1800
2024-06-02 20:38:36 [INFO]: Epoch 089 - training loss: 0.1611, validation loss: 0.1797
2024-06-02 20:38:37 [INFO]: Epoch 090 - training loss: 0.1754, validation loss: 0.1856
2024-06-02 20:38:39 [INFO]: Epoch 091 - training loss: 0.1972, validation loss: 0.1774
2024-06-02 20:38:41 [INFO]: Epoch 092 - training loss: 0.1606, validation loss: 0.1739
2024-06-02 20:38:42 [INFO]: Epoch 093 - training loss: 0.1621, validation loss: 0.1795
2024-06-02 20:38:44 [INFO]: Epoch 094 - training loss: 0.1865, validation loss: 0.1758
2024-06-02 20:38:46 [INFO]: Epoch 095 - training loss: 0.1674, validation loss: 0.1733
2024-06-02 20:38:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:38:46 [INFO]: Finished training. The best model is from epoch#85.
2024-06-02 20:38:46 [INFO]: Saved the model to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240602_T203609/CSDI.pypots
2024-06-02 20:39:42 [INFO]: Successfully saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_2/imputation.pkl
2024-06-02 20:39:42 [INFO]: Round2 - CSDI on ItalyAir: MAE=0.6012, MSE=7.6475, MRE=0.7862
2024-06-02 20:39:42 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:39:42 [INFO]: Using the given device: cuda:0
2024-06-02 20:39:42 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203942
2024-06-02 20:39:42 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203942/tensorboard
2024-06-02 20:39:42 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:39:43 [INFO]: Epoch 001 - training loss: 0.6604, validation loss: 0.4942
2024-06-02 20:39:45 [INFO]: Epoch 002 - training loss: 0.4071, validation loss: 0.4533
2024-06-02 20:39:47 [INFO]: Epoch 003 - training loss: 0.3415, validation loss: 0.3992
2024-06-02 20:39:48 [INFO]: Epoch 004 - training loss: 0.3594, validation loss: 0.4026
2024-06-02 20:39:50 [INFO]: Epoch 005 - training loss: 0.3588, validation loss: 0.3638
2024-06-02 20:39:51 [INFO]: Epoch 006 - training loss: 0.3283, validation loss: 0.3603
2024-06-02 20:39:53 [INFO]: Epoch 007 - training loss: 0.3215, validation loss: 0.3500
2024-06-02 20:39:55 [INFO]: Epoch 008 - training loss: 0.3429, validation loss: 0.3384
2024-06-02 20:39:56 [INFO]: Epoch 009 - training loss: 0.3566, validation loss: 0.3552
2024-06-02 20:39:58 [INFO]: Epoch 010 - training loss: 0.3069, validation loss: 0.3442
2024-06-02 20:40:00 [INFO]: Epoch 011 - training loss: 0.3319, validation loss: 0.3221
2024-06-02 20:40:01 [INFO]: Epoch 012 - training loss: 0.2539, validation loss: 0.3261
2024-06-02 20:40:03 [INFO]: Epoch 013 - training loss: 0.3004, validation loss: 0.3133
2024-06-02 20:40:05 [INFO]: Epoch 014 - training loss: 0.2860, validation loss: 0.3030
2024-06-02 20:40:06 [INFO]: Epoch 015 - training loss: 0.2719, validation loss: 0.3129
2024-06-02 20:40:08 [INFO]: Epoch 016 - training loss: 0.2646, validation loss: 0.2994
2024-06-02 20:40:10 [INFO]: Epoch 017 - training loss: 0.2531, validation loss: 0.3054
2024-06-02 20:40:11 [INFO]: Epoch 018 - training loss: 0.2734, validation loss: 0.3046
2024-06-02 20:40:13 [INFO]: Epoch 019 - training loss: 0.2753, validation loss: 0.3046
2024-06-02 20:40:15 [INFO]: Epoch 020 - training loss: 0.2807, validation loss: 0.2944
2024-06-02 20:40:16 [INFO]: Epoch 021 - training loss: 0.2594, validation loss: 0.2979
2024-06-02 20:40:18 [INFO]: Epoch 022 - training loss: 0.2418, validation loss: 0.3021
2024-06-02 20:40:19 [INFO]: Epoch 023 - training loss: 0.2656, validation loss: 0.2992
2024-06-02 20:40:21 [INFO]: Epoch 024 - training loss: 0.2675, validation loss: 0.2716
2024-06-02 20:40:23 [INFO]: Epoch 025 - training loss: 0.2499, validation loss: 0.2681
2024-06-02 20:40:24 [INFO]: Epoch 026 - training loss: 0.2293, validation loss: 0.2787
2024-06-02 20:40:26 [INFO]: Epoch 027 - training loss: 0.2538, validation loss: 0.2756
2024-06-02 20:40:28 [INFO]: Epoch 028 - training loss: 0.2086, validation loss: 0.2583
2024-06-02 20:40:29 [INFO]: Epoch 029 - training loss: 0.2618, validation loss: 0.2494
2024-06-02 20:40:31 [INFO]: Epoch 030 - training loss: 0.2183, validation loss: 0.2677
2024-06-02 20:40:33 [INFO]: Epoch 031 - training loss: 0.2559, validation loss: 0.2655
2024-06-02 20:40:34 [INFO]: Epoch 032 - training loss: 0.2257, validation loss: 0.2667
2024-06-02 20:40:36 [INFO]: Epoch 033 - training loss: 0.2341, validation loss: 0.2435
2024-06-02 20:40:38 [INFO]: Epoch 034 - training loss: 0.2149, validation loss: 0.2401
2024-06-02 20:40:39 [INFO]: Epoch 035 - training loss: 0.2190, validation loss: 0.2640
2024-06-02 20:40:41 [INFO]: Epoch 036 - training loss: 0.2466, validation loss: 0.2390
2024-06-02 20:40:42 [INFO]: Epoch 037 - training loss: 0.2354, validation loss: 0.2573
2024-06-02 20:40:44 [INFO]: Epoch 038 - training loss: 0.2181, validation loss: 0.2325
2024-06-02 20:40:46 [INFO]: Epoch 039 - training loss: 0.2229, validation loss: 0.2347
2024-06-02 20:40:47 [INFO]: Epoch 040 - training loss: 0.2272, validation loss: 0.2416
2024-06-02 20:40:49 [INFO]: Epoch 041 - training loss: 0.2447, validation loss: 0.2706
2024-06-02 20:40:51 [INFO]: Epoch 042 - training loss: 0.2047, validation loss: 0.2243
2024-06-02 20:40:52 [INFO]: Epoch 043 - training loss: 0.1938, validation loss: 0.2296
2024-06-02 20:40:54 [INFO]: Epoch 044 - training loss: 0.2181, validation loss: 0.2273
2024-06-02 20:40:56 [INFO]: Epoch 045 - training loss: 0.1979, validation loss: 0.2273
2024-06-02 20:40:57 [INFO]: Epoch 046 - training loss: 0.2008, validation loss: 0.2214
2024-06-02 20:40:59 [INFO]: Epoch 047 - training loss: 0.2325, validation loss: 0.2184
2024-06-02 20:41:01 [INFO]: Epoch 048 - training loss: 0.2273, validation loss: 0.2173
2024-06-02 20:41:02 [INFO]: Epoch 049 - training loss: 0.2050, validation loss: 0.2175
2024-06-02 20:41:04 [INFO]: Epoch 050 - training loss: 0.1996, validation loss: 0.2176
2024-06-02 20:41:06 [INFO]: Epoch 051 - training loss: 0.1873, validation loss: 0.2170
2024-06-02 20:41:07 [INFO]: Epoch 052 - training loss: 0.2230, validation loss: 0.2146
2024-06-02 20:41:09 [INFO]: Epoch 053 - training loss: 0.2002, validation loss: 0.2170
2024-06-02 20:41:11 [INFO]: Epoch 054 - training loss: 0.1938, validation loss: 0.2148
2024-06-02 20:41:12 [INFO]: Epoch 055 - training loss: 0.2180, validation loss: 0.2213
2024-06-02 20:41:14 [INFO]: Epoch 056 - training loss: 0.2014, validation loss: 0.2145
2024-06-02 20:41:15 [INFO]: Epoch 057 - training loss: 0.2043, validation loss: 0.2045
2024-06-02 20:41:17 [INFO]: Epoch 058 - training loss: 0.1931, validation loss: 0.2657
2024-06-02 20:41:19 [INFO]: Epoch 059 - training loss: 0.2107, validation loss: 0.2077
2024-06-02 20:41:20 [INFO]: Epoch 060 - training loss: 0.1977, validation loss: 0.2180
2024-06-02 20:41:22 [INFO]: Epoch 061 - training loss: 0.2214, validation loss: 0.2204
2024-06-02 20:41:24 [INFO]: Epoch 062 - training loss: 0.1892, validation loss: 0.2102
2024-06-02 20:41:25 [INFO]: Epoch 063 - training loss: 0.1764, validation loss: 0.1954
2024-06-02 20:41:27 [INFO]: Epoch 064 - training loss: 0.1842, validation loss: 0.2014
2024-06-02 20:41:29 [INFO]: Epoch 065 - training loss: 0.2007, validation loss: 0.2012
2024-06-02 20:41:30 [INFO]: Epoch 066 - training loss: 0.1806, validation loss: 0.1890
2024-06-02 20:41:32 [INFO]: Epoch 067 - training loss: 0.2133, validation loss: 0.1993
2024-06-02 20:41:34 [INFO]: Epoch 068 - training loss: 0.1801, validation loss: 0.1835
2024-06-02 20:41:35 [INFO]: Epoch 069 - training loss: 0.1980, validation loss: 0.1889
2024-06-02 20:41:37 [INFO]: Epoch 070 - training loss: 0.1922, validation loss: 0.2108
2024-06-02 20:41:38 [INFO]: Epoch 071 - training loss: 0.1917, validation loss: 0.1996
2024-06-02 20:41:40 [INFO]: Epoch 072 - training loss: 0.1570, validation loss: 0.1923
2024-06-02 20:41:42 [INFO]: Epoch 073 - training loss: 0.1909, validation loss: 0.2028
2024-06-02 20:41:43 [INFO]: Epoch 074 - training loss: 0.2140, validation loss: 0.1938
2024-06-02 20:41:45 [INFO]: Epoch 075 - training loss: 0.1983, validation loss: 0.1814
2024-06-02 20:41:47 [INFO]: Epoch 076 - training loss: 0.1849, validation loss: 0.1967
2024-06-02 20:41:48 [INFO]: Epoch 077 - training loss: 0.1650, validation loss: 0.2099
2024-06-02 20:41:50 [INFO]: Epoch 078 - training loss: 0.1842, validation loss: 0.1851
2024-06-02 20:41:52 [INFO]: Epoch 079 - training loss: 0.1756, validation loss: 0.1804
2024-06-02 20:41:53 [INFO]: Epoch 080 - training loss: 0.2086, validation loss: 0.1945
2024-06-02 20:41:55 [INFO]: Epoch 081 - training loss: 0.1819, validation loss: 0.1928
2024-06-02 20:41:56 [INFO]: Epoch 082 - training loss: 0.1830, validation loss: 0.1844
2024-06-02 20:41:58 [INFO]: Epoch 083 - training loss: 0.1996, validation loss: 0.1883
2024-06-02 20:42:00 [INFO]: Epoch 084 - training loss: 0.1995, validation loss: 0.1816
2024-06-02 20:42:01 [INFO]: Epoch 085 - training loss: 0.1844, validation loss: 0.1835
2024-06-02 20:42:03 [INFO]: Epoch 086 - training loss: 0.1834, validation loss: 0.1900
2024-06-02 20:42:05 [INFO]: Epoch 087 - training loss: 0.1789, validation loss: 0.1839
2024-06-02 20:42:06 [INFO]: Epoch 088 - training loss: 0.2083, validation loss: 0.1839
2024-06-02 20:42:08 [INFO]: Epoch 089 - training loss: 0.1864, validation loss: 0.1814
2024-06-02 20:42:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:42:08 [INFO]: Finished training. The best model is from epoch#79.
2024-06-02 20:42:08 [INFO]: Saved the model to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240602_T203942/CSDI.pypots
2024-06-02 20:43:04 [INFO]: Successfully saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_3/imputation.pkl
2024-06-02 20:43:04 [INFO]: Round3 - CSDI on ItalyAir: MAE=0.5285, MSE=4.8079, MRE=0.6911
2024-06-02 20:43:04 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:43:04 [INFO]: Using the given device: cuda:0
2024-06-02 20:43:04 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240602_T204304
2024-06-02 20:43:04 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240602_T204304/tensorboard
2024-06-02 20:43:04 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-02 20:43:06 [INFO]: Epoch 001 - training loss: 0.6503, validation loss: 0.4853
2024-06-02 20:43:08 [INFO]: Epoch 002 - training loss: 0.3756, validation loss: 0.4104
2024-06-02 20:43:09 [INFO]: Epoch 003 - training loss: 0.3865, validation loss: 0.4053
2024-06-02 20:43:11 [INFO]: Epoch 004 - training loss: 0.3513, validation loss: 0.3842
2024-06-02 20:43:13 [INFO]: Epoch 005 - training loss: 0.3410, validation loss: 0.3864
2024-06-02 20:43:14 [INFO]: Epoch 006 - training loss: 0.3117, validation loss: 0.3854
2024-06-02 20:43:16 [INFO]: Epoch 007 - training loss: 0.3007, validation loss: 0.3682
2024-06-02 20:43:18 [INFO]: Epoch 008 - training loss: 0.3020, validation loss: 0.3374
2024-06-02 20:43:19 [INFO]: Epoch 009 - training loss: 0.3276, validation loss: 0.3808
2024-06-02 20:43:21 [INFO]: Epoch 010 - training loss: 0.3110, validation loss: 0.3425
2024-06-02 20:43:22 [INFO]: Epoch 011 - training loss: 0.3246, validation loss: 0.3182
2024-06-02 20:43:24 [INFO]: Epoch 012 - training loss: 0.3299, validation loss: 0.3350
2024-06-02 20:43:26 [INFO]: Epoch 013 - training loss: 0.2834, validation loss: 0.3150
2024-06-02 20:43:27 [INFO]: Epoch 014 - training loss: 0.2828, validation loss: 0.3665
2024-06-02 20:43:29 [INFO]: Epoch 015 - training loss: 0.2714, validation loss: 0.3048
2024-06-02 20:43:31 [INFO]: Epoch 016 - training loss: 0.2947, validation loss: 0.3009
2024-06-02 20:43:32 [INFO]: Epoch 017 - training loss: 0.2792, validation loss: 0.2862
2024-06-02 20:43:34 [INFO]: Epoch 018 - training loss: 0.2727, validation loss: 0.2910
2024-06-02 20:43:35 [INFO]: Epoch 019 - training loss: 0.2602, validation loss: 0.3056
2024-06-02 20:43:37 [INFO]: Epoch 020 - training loss: 0.2747, validation loss: 0.2848
2024-06-02 20:43:39 [INFO]: Epoch 021 - training loss: 0.2585, validation loss: 0.2698
2024-06-02 20:43:40 [INFO]: Epoch 022 - training loss: 0.2601, validation loss: 0.2762
2024-06-02 20:43:42 [INFO]: Epoch 023 - training loss: 0.2389, validation loss: 0.2722
2024-06-02 20:43:44 [INFO]: Epoch 024 - training loss: 0.2481, validation loss: 0.2600
2024-06-02 20:43:45 [INFO]: Epoch 025 - training loss: 0.2286, validation loss: 0.2832
2024-06-02 20:43:47 [INFO]: Epoch 026 - training loss: 0.2240, validation loss: 0.2751
2024-06-02 20:43:49 [INFO]: Epoch 027 - training loss: 0.2231, validation loss: 0.2668
2024-06-02 20:43:50 [INFO]: Epoch 028 - training loss: 0.2539, validation loss: 0.2555
2024-06-02 20:43:52 [INFO]: Epoch 029 - training loss: 0.2500, validation loss: 0.2644
2024-06-02 20:43:53 [INFO]: Epoch 030 - training loss: 0.2475, validation loss: 0.2735
2024-06-02 20:43:55 [INFO]: Epoch 031 - training loss: 0.2205, validation loss: 0.2431
2024-06-02 20:43:57 [INFO]: Epoch 032 - training loss: 0.2088, validation loss: 0.2634
2024-06-02 20:43:58 [INFO]: Epoch 033 - training loss: 0.2152, validation loss: 0.2475
2024-06-02 20:44:00 [INFO]: Epoch 034 - training loss: 0.2300, validation loss: 0.2351
2024-06-02 20:44:02 [INFO]: Epoch 035 - training loss: 0.2198, validation loss: 0.2363
2024-06-02 20:44:03 [INFO]: Epoch 036 - training loss: 0.2314, validation loss: 0.2185
2024-06-02 20:44:05 [INFO]: Epoch 037 - training loss: 0.1910, validation loss: 0.2286
2024-06-02 20:44:06 [INFO]: Epoch 038 - training loss: 0.1875, validation loss: 0.2366
2024-06-02 20:44:08 [INFO]: Epoch 039 - training loss: 0.2227, validation loss: 0.2297
2024-06-02 20:44:10 [INFO]: Epoch 040 - training loss: 0.2222, validation loss: 0.2195
2024-06-02 20:44:11 [INFO]: Epoch 041 - training loss: 0.2089, validation loss: 0.2212
2024-06-02 20:44:13 [INFO]: Epoch 042 - training loss: 0.2008, validation loss: 0.2152
2024-06-02 20:44:15 [INFO]: Epoch 043 - training loss: 0.1981, validation loss: 0.2302
2024-06-02 20:44:16 [INFO]: Epoch 044 - training loss: 0.1896, validation loss: 0.2161
2024-06-02 20:44:18 [INFO]: Epoch 045 - training loss: 0.2141, validation loss: 0.2077
2024-06-02 20:44:19 [INFO]: Epoch 046 - training loss: 0.1923, validation loss: 0.1983
2024-06-02 20:44:21 [INFO]: Epoch 047 - training loss: 0.2226, validation loss: 0.2229
2024-06-02 20:44:23 [INFO]: Epoch 048 - training loss: 0.1972, validation loss: 0.2026
2024-06-02 20:44:24 [INFO]: Epoch 049 - training loss: 0.2116, validation loss: 0.2034
2024-06-02 20:44:26 [INFO]: Epoch 050 - training loss: 0.2032, validation loss: 0.2155
2024-06-02 20:44:28 [INFO]: Epoch 051 - training loss: 0.1985, validation loss: 0.2028
2024-06-02 20:44:29 [INFO]: Epoch 052 - training loss: 0.2171, validation loss: 0.2052
2024-06-02 20:44:31 [INFO]: Epoch 053 - training loss: 0.1952, validation loss: 0.2037
2024-06-02 20:44:33 [INFO]: Epoch 054 - training loss: 0.1929, validation loss: 0.1877
2024-06-02 20:44:34 [INFO]: Epoch 055 - training loss: 0.2139, validation loss: 0.2128
2024-06-02 20:44:36 [INFO]: Epoch 056 - training loss: 0.1584, validation loss: 0.2024
2024-06-02 20:44:38 [INFO]: Epoch 057 - training loss: 0.1950, validation loss: 0.1980
2024-06-02 20:44:39 [INFO]: Epoch 058 - training loss: 0.1978, validation loss: 0.1994
2024-06-02 20:44:41 [INFO]: Epoch 059 - training loss: 0.2154, validation loss: 0.2076
2024-06-02 20:44:42 [INFO]: Epoch 060 - training loss: 0.2153, validation loss: 0.1979
2024-06-02 20:44:44 [INFO]: Epoch 061 - training loss: 0.1835, validation loss: 0.2007
2024-06-02 20:44:46 [INFO]: Epoch 062 - training loss: 0.2014, validation loss: 0.1904
2024-06-02 20:44:47 [INFO]: Epoch 063 - training loss: 0.1910, validation loss: 0.1981
2024-06-02 20:44:49 [INFO]: Epoch 064 - training loss: 0.1585, validation loss: 0.1985
2024-06-02 20:44:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:44:49 [INFO]: Finished training. The best model is from epoch#54.
2024-06-02 20:44:49 [INFO]: Saved the model to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240602_T204304/CSDI.pypots
2024-06-02 20:45:46 [INFO]: Successfully saved to results_point_rate05/ItalyAir/CSDI_ItalyAir/round_4/imputation.pkl
2024-06-02 20:45:46 [INFO]: Round4 - CSDI on ItalyAir: MAE=1.6801, MSE=79.1745, MRE=2.1970
2024-06-02 20:45:46 [INFO]: Done! Final results:
Averaged CSDI (933,161 params) on ItalyAir: MAE=0.9583 ± 0.5506746001974189, MSE=29.2663 ± 31.18315478245746, MRE=1.2531 ± 0.7201123257454649, average inference time=12.62
