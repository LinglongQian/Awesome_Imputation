2024-06-02 20:46:37 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:46:37 [INFO]: Using the given device: cuda:0
2024-06-02 20:46:37 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240602_T204637
2024-06-02 20:46:37 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240602_T204637/tensorboard
2024-06-02 20:46:37 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-02 20:46:37 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-02 20:46:39 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-02 20:46:43 [INFO]: Epoch 001 - training loss: 1.1672, validation loss: 1.0094
2024-06-02 20:46:47 [INFO]: Epoch 002 - training loss: 0.6675, validation loss: 0.7279
2024-06-02 20:46:49 [INFO]: Epoch 003 - training loss: 0.6094, validation loss: 0.6473
2024-06-02 20:46:52 [INFO]: Epoch 004 - training loss: 0.5634, validation loss: 0.5840
2024-06-02 20:46:54 [INFO]: Epoch 005 - training loss: 0.5503, validation loss: 0.5770
2024-06-02 20:46:57 [INFO]: Epoch 006 - training loss: 0.5122, validation loss: 0.5535
2024-06-02 20:47:00 [INFO]: Epoch 007 - training loss: 0.5147, validation loss: 0.5220
2024-06-02 20:47:03 [INFO]: Epoch 008 - training loss: 0.4940, validation loss: 0.5172
2024-06-02 20:47:06 [INFO]: Epoch 009 - training loss: 0.4936, validation loss: 0.5063
2024-06-02 20:47:09 [INFO]: Epoch 010 - training loss: 0.4839, validation loss: 0.4846
2024-06-02 20:47:12 [INFO]: Epoch 011 - training loss: 0.4612, validation loss: 0.4880
2024-06-02 20:47:14 [INFO]: Epoch 012 - training loss: 0.4549, validation loss: 0.4685
2024-06-02 20:47:17 [INFO]: Epoch 013 - training loss: 0.4445, validation loss: 0.4522
2024-06-02 20:47:20 [INFO]: Epoch 014 - training loss: 0.4473, validation loss: 0.4757
2024-06-02 20:47:23 [INFO]: Epoch 015 - training loss: 0.4487, validation loss: 0.4505
2024-06-02 20:47:26 [INFO]: Epoch 016 - training loss: 0.4517, validation loss: 0.4796
2024-06-02 20:47:29 [INFO]: Epoch 017 - training loss: 0.4322, validation loss: 0.4488
2024-06-02 20:47:32 [INFO]: Epoch 018 - training loss: 0.4297, validation loss: 0.4146
2024-06-02 20:47:34 [INFO]: Epoch 019 - training loss: 0.4110, validation loss: 0.4058
2024-06-02 20:47:37 [INFO]: Epoch 020 - training loss: 0.4088, validation loss: 0.4105
2024-06-02 20:47:40 [INFO]: Epoch 021 - training loss: 0.4119, validation loss: 0.4162
2024-06-02 20:47:43 [INFO]: Epoch 022 - training loss: 0.4103, validation loss: 0.3971
2024-06-02 20:47:46 [INFO]: Epoch 023 - training loss: 0.3924, validation loss: 0.3927
2024-06-02 20:47:48 [INFO]: Epoch 024 - training loss: 0.3863, validation loss: 0.3840
2024-06-02 20:47:51 [INFO]: Epoch 025 - training loss: 0.3933, validation loss: 0.3844
2024-06-02 20:47:54 [INFO]: Epoch 026 - training loss: 0.3828, validation loss: 0.3830
2024-06-02 20:47:57 [INFO]: Epoch 027 - training loss: 0.3821, validation loss: 0.3917
2024-06-02 20:48:00 [INFO]: Epoch 028 - training loss: 0.3795, validation loss: 0.4043
2024-06-02 20:48:02 [INFO]: Epoch 029 - training loss: 0.3751, validation loss: 0.4289
2024-06-02 20:48:05 [INFO]: Epoch 030 - training loss: 0.3839, validation loss: 0.3911
2024-06-02 20:48:08 [INFO]: Epoch 031 - training loss: 0.3692, validation loss: 0.3917
2024-06-02 20:48:11 [INFO]: Epoch 032 - training loss: 0.3761, validation loss: 0.3758
2024-06-02 20:48:14 [INFO]: Epoch 033 - training loss: 0.3826, validation loss: 0.4139
2024-06-02 20:48:16 [INFO]: Epoch 034 - training loss: 0.3708, validation loss: 0.3687
2024-06-02 20:48:19 [INFO]: Epoch 035 - training loss: 0.3712, validation loss: 0.3786
2024-06-02 20:48:22 [INFO]: Epoch 036 - training loss: 0.3655, validation loss: 0.3668
2024-06-02 20:48:25 [INFO]: Epoch 037 - training loss: 0.3703, validation loss: 0.3781
2024-06-02 20:48:28 [INFO]: Epoch 038 - training loss: 0.3526, validation loss: 0.3880
2024-06-02 20:48:31 [INFO]: Epoch 039 - training loss: 0.3520, validation loss: 0.3761
2024-06-02 20:48:34 [INFO]: Epoch 040 - training loss: 0.3646, validation loss: 0.3707
2024-06-02 20:48:37 [INFO]: Epoch 041 - training loss: 0.3549, validation loss: 0.3805
2024-06-02 20:48:40 [INFO]: Epoch 042 - training loss: 0.3577, validation loss: 0.3493
2024-06-02 20:48:43 [INFO]: Epoch 043 - training loss: 0.3509, validation loss: 0.3633
2024-06-02 20:48:46 [INFO]: Epoch 044 - training loss: 0.3428, validation loss: 0.3470
2024-06-02 20:48:49 [INFO]: Epoch 045 - training loss: 0.3366, validation loss: 0.3743
2024-06-02 20:48:52 [INFO]: Epoch 046 - training loss: 0.3345, validation loss: 0.3678
2024-06-02 20:48:55 [INFO]: Epoch 047 - training loss: 0.3350, validation loss: 0.3766
2024-06-02 20:48:58 [INFO]: Epoch 048 - training loss: 0.3284, validation loss: 0.3775
2024-06-02 20:49:00 [INFO]: Epoch 049 - training loss: 0.3271, validation loss: 0.3773
2024-06-02 20:49:03 [INFO]: Epoch 050 - training loss: 0.3358, validation loss: 0.3590
2024-06-02 20:49:06 [INFO]: Epoch 051 - training loss: 0.3348, validation loss: 0.3592
2024-06-02 20:49:09 [INFO]: Epoch 052 - training loss: 0.3285, validation loss: 0.3387
2024-06-02 20:49:12 [INFO]: Epoch 053 - training loss: 0.3237, validation loss: 0.3548
2024-06-02 20:49:15 [INFO]: Epoch 054 - training loss: 0.3318, validation loss: 0.3498
2024-06-02 20:49:18 [INFO]: Epoch 055 - training loss: 0.3207, validation loss: 0.3311
2024-06-02 20:49:21 [INFO]: Epoch 056 - training loss: 0.3170, validation loss: 0.3422
2024-06-02 20:49:23 [INFO]: Epoch 057 - training loss: 0.3229, validation loss: 0.3776
2024-06-02 20:49:26 [INFO]: Epoch 058 - training loss: 0.3396, validation loss: 0.3779
2024-06-02 20:49:29 [INFO]: Epoch 059 - training loss: 0.3307, validation loss: 0.3611
2024-06-02 20:49:32 [INFO]: Epoch 060 - training loss: 0.3170, validation loss: 0.3712
2024-06-02 20:49:35 [INFO]: Epoch 061 - training loss: 0.3135, validation loss: 0.3510
2024-06-02 20:49:37 [INFO]: Epoch 062 - training loss: 0.3282, validation loss: 0.3350
2024-06-02 20:49:40 [INFO]: Epoch 063 - training loss: 0.3136, validation loss: 0.3508
2024-06-02 20:49:43 [INFO]: Epoch 064 - training loss: 0.3120, validation loss: 0.3352
2024-06-02 20:49:46 [INFO]: Epoch 065 - training loss: 0.3235, validation loss: 0.3414
2024-06-02 20:49:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:49:46 [INFO]: Finished training. The best model is from epoch#55.
2024-06-02 20:49:46 [INFO]: Saved the model to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_0/20240602_T204637/iTransformer.pypots
2024-06-02 20:49:47 [INFO]: Successfully saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_0/imputation.pkl
2024-06-02 20:49:47 [INFO]: Round0 - iTransformer on ItalyAir: MAE=0.3088, MSE=0.3138, MRE=0.4038
2024-06-02 20:49:47 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:49:47 [INFO]: Using the given device: cuda:0
2024-06-02 20:49:47 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240602_T204947
2024-06-02 20:49:47 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240602_T204947/tensorboard
2024-06-02 20:49:47 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-02 20:49:47 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-02 20:49:48 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-02 20:49:51 [INFO]: Epoch 001 - training loss: 1.1576, validation loss: 0.9974
2024-06-02 20:49:54 [INFO]: Epoch 002 - training loss: 0.6911, validation loss: 0.7235
2024-06-02 20:49:57 [INFO]: Epoch 003 - training loss: 0.5987, validation loss: 0.6254
2024-06-02 20:50:00 [INFO]: Epoch 004 - training loss: 0.5673, validation loss: 0.5826
2024-06-02 20:50:03 [INFO]: Epoch 005 - training loss: 0.5428, validation loss: 0.6118
2024-06-02 20:50:06 [INFO]: Epoch 006 - training loss: 0.5288, validation loss: 0.5194
2024-06-02 20:50:09 [INFO]: Epoch 007 - training loss: 0.5072, validation loss: 0.5203
2024-06-02 20:50:11 [INFO]: Epoch 008 - training loss: 0.5147, validation loss: 0.5389
2024-06-02 20:50:14 [INFO]: Epoch 009 - training loss: 0.4961, validation loss: 0.5023
2024-06-02 20:50:17 [INFO]: Epoch 010 - training loss: 0.4851, validation loss: 0.4886
2024-06-02 20:50:20 [INFO]: Epoch 011 - training loss: 0.4798, validation loss: 0.5444
2024-06-02 20:50:22 [INFO]: Epoch 012 - training loss: 0.4750, validation loss: 0.4768
2024-06-02 20:50:25 [INFO]: Epoch 013 - training loss: 0.4737, validation loss: 0.4684
2024-06-02 20:50:28 [INFO]: Epoch 014 - training loss: 0.4459, validation loss: 0.4736
2024-06-02 20:50:32 [INFO]: Epoch 015 - training loss: 0.4410, validation loss: 0.4326
2024-06-02 20:50:34 [INFO]: Epoch 016 - training loss: 0.4528, validation loss: 0.4689
2024-06-02 20:50:37 [INFO]: Epoch 017 - training loss: 0.4423, validation loss: 0.4547
2024-06-02 20:50:40 [INFO]: Epoch 018 - training loss: 0.4222, validation loss: 0.5260
2024-06-02 20:50:43 [INFO]: Epoch 019 - training loss: 0.4235, validation loss: 0.4482
2024-06-02 20:50:46 [INFO]: Epoch 020 - training loss: 0.4159, validation loss: 0.4448
2024-06-02 20:50:49 [INFO]: Epoch 021 - training loss: 0.4102, validation loss: 0.4534
2024-06-02 20:50:52 [INFO]: Epoch 022 - training loss: 0.4238, validation loss: 0.4513
2024-06-02 20:50:54 [INFO]: Epoch 023 - training loss: 0.4065, validation loss: 0.4078
2024-06-02 20:50:57 [INFO]: Epoch 024 - training loss: 0.3987, validation loss: 0.4398
2024-06-02 20:51:00 [INFO]: Epoch 025 - training loss: 0.3980, validation loss: 0.3853
2024-06-02 20:51:03 [INFO]: Epoch 026 - training loss: 0.3976, validation loss: 0.4051
2024-06-02 20:51:05 [INFO]: Epoch 027 - training loss: 0.3891, validation loss: 0.4432
2024-06-02 20:51:08 [INFO]: Epoch 028 - training loss: 0.3847, validation loss: 0.4517
2024-06-02 20:51:11 [INFO]: Epoch 029 - training loss: 0.3821, validation loss: 0.3983
2024-06-02 20:51:14 [INFO]: Epoch 030 - training loss: 0.3874, validation loss: 0.3873
2024-06-02 20:51:16 [INFO]: Epoch 031 - training loss: 0.3761, validation loss: 0.3785
2024-06-02 20:51:19 [INFO]: Epoch 032 - training loss: 0.3795, validation loss: 0.4190
2024-06-02 20:51:21 [INFO]: Epoch 033 - training loss: 0.3718, validation loss: 0.3803
2024-06-02 20:51:24 [INFO]: Epoch 034 - training loss: 0.3747, validation loss: 0.3927
2024-06-02 20:51:26 [INFO]: Epoch 035 - training loss: 0.3848, validation loss: 0.3751
2024-06-02 20:51:29 [INFO]: Epoch 036 - training loss: 0.3645, validation loss: 0.3876
2024-06-02 20:51:31 [INFO]: Epoch 037 - training loss: 0.3612, validation loss: 0.4005
2024-06-02 20:51:34 [INFO]: Epoch 038 - training loss: 0.3690, validation loss: 0.3894
2024-06-02 20:51:37 [INFO]: Epoch 039 - training loss: 0.3573, validation loss: 0.3659
2024-06-02 20:51:39 [INFO]: Epoch 040 - training loss: 0.3505, validation loss: 0.3591
2024-06-02 20:51:42 [INFO]: Epoch 041 - training loss: 0.3353, validation loss: 0.3663
2024-06-02 20:51:44 [INFO]: Epoch 042 - training loss: 0.3468, validation loss: 0.3618
2024-06-02 20:51:47 [INFO]: Epoch 043 - training loss: 0.3545, validation loss: 0.3600
2024-06-02 20:51:50 [INFO]: Epoch 044 - training loss: 0.3460, validation loss: 0.3603
2024-06-02 20:51:52 [INFO]: Epoch 045 - training loss: 0.3468, validation loss: 0.3556
2024-06-02 20:51:55 [INFO]: Epoch 046 - training loss: 0.3545, validation loss: 0.3840
2024-06-02 20:51:57 [INFO]: Epoch 047 - training loss: 0.3425, validation loss: 0.3479
2024-06-02 20:52:00 [INFO]: Epoch 048 - training loss: 0.3373, validation loss: 0.3590
2024-06-02 20:52:02 [INFO]: Epoch 049 - training loss: 0.3478, validation loss: 0.3988
2024-06-02 20:52:05 [INFO]: Epoch 050 - training loss: 0.3286, validation loss: 0.3720
2024-06-02 20:52:08 [INFO]: Epoch 051 - training loss: 0.3360, validation loss: 0.3939
2024-06-02 20:52:10 [INFO]: Epoch 052 - training loss: 0.3396, validation loss: 0.3603
2024-06-02 20:52:13 [INFO]: Epoch 053 - training loss: 0.3313, validation loss: 0.3841
2024-06-02 20:52:15 [INFO]: Epoch 054 - training loss: 0.3272, validation loss: 0.3613
2024-06-02 20:52:18 [INFO]: Epoch 055 - training loss: 0.3251, validation loss: 0.3590
2024-06-02 20:52:21 [INFO]: Epoch 056 - training loss: 0.3371, validation loss: 0.3755
2024-06-02 20:52:23 [INFO]: Epoch 057 - training loss: 0.3313, validation loss: 0.3685
2024-06-02 20:52:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:52:23 [INFO]: Finished training. The best model is from epoch#47.
2024-06-02 20:52:24 [INFO]: Saved the model to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_1/20240602_T204947/iTransformer.pypots
2024-06-02 20:52:25 [INFO]: Successfully saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_1/imputation.pkl
2024-06-02 20:52:25 [INFO]: Round1 - iTransformer on ItalyAir: MAE=0.3190, MSE=0.3191, MRE=0.4172
2024-06-02 20:52:25 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:52:25 [INFO]: Using the given device: cuda:0
2024-06-02 20:52:25 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240602_T205225
2024-06-02 20:52:25 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240602_T205225/tensorboard
2024-06-02 20:52:25 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-02 20:52:25 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-02 20:52:25 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-02 20:52:28 [INFO]: Epoch 001 - training loss: 1.1284, validation loss: 0.9804
2024-06-02 20:52:30 [INFO]: Epoch 002 - training loss: 0.6738, validation loss: 0.6948
2024-06-02 20:52:33 [INFO]: Epoch 003 - training loss: 0.5810, validation loss: 0.6008
2024-06-02 20:52:36 [INFO]: Epoch 004 - training loss: 0.5671, validation loss: 0.5644
2024-06-02 20:52:38 [INFO]: Epoch 005 - training loss: 0.5425, validation loss: 0.5385
2024-06-02 20:52:41 [INFO]: Epoch 006 - training loss: 0.5278, validation loss: 0.5244
2024-06-02 20:52:44 [INFO]: Epoch 007 - training loss: 0.5101, validation loss: 0.5341
2024-06-02 20:52:46 [INFO]: Epoch 008 - training loss: 0.5014, validation loss: 0.5182
2024-06-02 20:52:49 [INFO]: Epoch 009 - training loss: 0.4947, validation loss: 0.5172
2024-06-02 20:52:52 [INFO]: Epoch 010 - training loss: 0.4896, validation loss: 0.6081
2024-06-02 20:52:54 [INFO]: Epoch 011 - training loss: 0.4866, validation loss: 0.5009
2024-06-02 20:52:57 [INFO]: Epoch 012 - training loss: 0.4771, validation loss: 0.4707
2024-06-02 20:52:59 [INFO]: Epoch 013 - training loss: 0.4415, validation loss: 0.4941
2024-06-02 20:53:02 [INFO]: Epoch 014 - training loss: 0.4485, validation loss: 0.4711
2024-06-02 20:53:04 [INFO]: Epoch 015 - training loss: 0.4452, validation loss: 0.4623
2024-06-02 20:53:07 [INFO]: Epoch 016 - training loss: 0.4201, validation loss: 0.4893
2024-06-02 20:53:09 [INFO]: Epoch 017 - training loss: 0.4470, validation loss: 0.4747
2024-06-02 20:53:12 [INFO]: Epoch 018 - training loss: 0.4326, validation loss: 0.4337
2024-06-02 20:53:15 [INFO]: Epoch 019 - training loss: 0.4171, validation loss: 0.4858
2024-06-02 20:53:17 [INFO]: Epoch 020 - training loss: 0.4171, validation loss: 0.4042
2024-06-02 20:53:20 [INFO]: Epoch 021 - training loss: 0.4074, validation loss: 0.4052
2024-06-02 20:53:22 [INFO]: Epoch 022 - training loss: 0.4023, validation loss: 0.4398
2024-06-02 20:53:25 [INFO]: Epoch 023 - training loss: 0.4121, validation loss: 0.4211
2024-06-02 20:53:27 [INFO]: Epoch 024 - training loss: 0.4032, validation loss: 0.5231
2024-06-02 20:53:30 [INFO]: Epoch 025 - training loss: 0.4046, validation loss: 0.4222
2024-06-02 20:53:32 [INFO]: Epoch 026 - training loss: 0.3993, validation loss: 0.4152
2024-06-02 20:53:35 [INFO]: Epoch 027 - training loss: 0.3897, validation loss: 0.4474
2024-06-02 20:53:38 [INFO]: Epoch 028 - training loss: 0.3830, validation loss: 0.4325
2024-06-02 20:53:40 [INFO]: Epoch 029 - training loss: 0.3761, validation loss: 0.3675
2024-06-02 20:53:43 [INFO]: Epoch 030 - training loss: 0.3683, validation loss: 0.4169
2024-06-02 20:53:45 [INFO]: Epoch 031 - training loss: 0.3640, validation loss: 0.4060
2024-06-02 20:53:48 [INFO]: Epoch 032 - training loss: 0.3722, validation loss: 0.4148
2024-06-02 20:53:50 [INFO]: Epoch 033 - training loss: 0.3641, validation loss: 0.4413
2024-06-02 20:53:53 [INFO]: Epoch 034 - training loss: 0.3811, validation loss: 0.4112
2024-06-02 20:53:55 [INFO]: Epoch 035 - training loss: 0.3750, validation loss: 0.3886
2024-06-02 20:53:58 [INFO]: Epoch 036 - training loss: 0.3639, validation loss: 0.4068
2024-06-02 20:54:00 [INFO]: Epoch 037 - training loss: 0.3602, validation loss: 0.4004
2024-06-02 20:54:03 [INFO]: Epoch 038 - training loss: 0.3524, validation loss: 0.4086
2024-06-02 20:54:05 [INFO]: Epoch 039 - training loss: 0.3582, validation loss: 0.3824
2024-06-02 20:54:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:54:05 [INFO]: Finished training. The best model is from epoch#29.
2024-06-02 20:54:05 [INFO]: Saved the model to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_2/20240602_T205225/iTransformer.pypots
2024-06-02 20:54:06 [INFO]: Successfully saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_2/imputation.pkl
2024-06-02 20:54:06 [INFO]: Round2 - iTransformer on ItalyAir: MAE=0.3306, MSE=0.3364, MRE=0.4323
2024-06-02 20:54:06 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:54:06 [INFO]: Using the given device: cuda:0
2024-06-02 20:54:06 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240602_T205406
2024-06-02 20:54:06 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240602_T205406/tensorboard
2024-06-02 20:54:06 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-02 20:54:06 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-02 20:54:07 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-02 20:54:09 [INFO]: Epoch 001 - training loss: 1.0925, validation loss: 0.9953
2024-06-02 20:54:11 [INFO]: Epoch 002 - training loss: 0.6692, validation loss: 0.7037
2024-06-02 20:54:14 [INFO]: Epoch 003 - training loss: 0.5913, validation loss: 0.6055
2024-06-02 20:54:16 [INFO]: Epoch 004 - training loss: 0.5647, validation loss: 0.5680
2024-06-02 20:54:18 [INFO]: Epoch 005 - training loss: 0.5371, validation loss: 0.5764
2024-06-02 20:54:21 [INFO]: Epoch 006 - training loss: 0.5288, validation loss: 0.5507
2024-06-02 20:54:23 [INFO]: Epoch 007 - training loss: 0.5029, validation loss: 0.5171
2024-06-02 20:54:25 [INFO]: Epoch 008 - training loss: 0.5009, validation loss: 0.5043
2024-06-02 20:54:27 [INFO]: Epoch 009 - training loss: 0.4864, validation loss: 0.5184
2024-06-02 20:54:30 [INFO]: Epoch 010 - training loss: 0.4983, validation loss: 0.4724
2024-06-02 20:54:32 [INFO]: Epoch 011 - training loss: 0.4645, validation loss: 0.5301
2024-06-02 20:54:35 [INFO]: Epoch 012 - training loss: 0.4649, validation loss: 0.4640
2024-06-02 20:54:37 [INFO]: Epoch 013 - training loss: 0.4512, validation loss: 0.4700
2024-06-02 20:54:40 [INFO]: Epoch 014 - training loss: 0.4619, validation loss: 0.4466
2024-06-02 20:54:42 [INFO]: Epoch 015 - training loss: 0.4509, validation loss: 0.4423
2024-06-02 20:54:44 [INFO]: Epoch 016 - training loss: 0.4437, validation loss: 0.4493
2024-06-02 20:54:46 [INFO]: Epoch 017 - training loss: 0.4242, validation loss: 0.4488
2024-06-02 20:54:49 [INFO]: Epoch 018 - training loss: 0.4370, validation loss: 0.4008
2024-06-02 20:54:51 [INFO]: Epoch 019 - training loss: 0.4370, validation loss: 0.4455
2024-06-02 20:54:53 [INFO]: Epoch 020 - training loss: 0.4167, validation loss: 0.4330
2024-06-02 20:54:56 [INFO]: Epoch 021 - training loss: 0.3944, validation loss: 0.4294
2024-06-02 20:54:58 [INFO]: Epoch 022 - training loss: 0.4134, validation loss: 0.3965
2024-06-02 20:55:01 [INFO]: Epoch 023 - training loss: 0.4004, validation loss: 0.4026
2024-06-02 20:55:03 [INFO]: Epoch 024 - training loss: 0.3850, validation loss: 0.3988
2024-06-02 20:55:05 [INFO]: Epoch 025 - training loss: 0.3969, validation loss: 0.4125
2024-06-02 20:55:08 [INFO]: Epoch 026 - training loss: 0.3979, validation loss: 0.4199
2024-06-02 20:55:10 [INFO]: Epoch 027 - training loss: 0.3867, validation loss: 0.4176
2024-06-02 20:55:12 [INFO]: Epoch 028 - training loss: 0.3958, validation loss: 0.3883
2024-06-02 20:55:14 [INFO]: Epoch 029 - training loss: 0.3932, validation loss: 0.3895
2024-06-02 20:55:16 [INFO]: Epoch 030 - training loss: 0.3872, validation loss: 0.4218
2024-06-02 20:55:19 [INFO]: Epoch 031 - training loss: 0.3763, validation loss: 0.4017
2024-06-02 20:55:21 [INFO]: Epoch 032 - training loss: 0.3677, validation loss: 0.3891
2024-06-02 20:55:23 [INFO]: Epoch 033 - training loss: 0.3782, validation loss: 0.3711
2024-06-02 20:55:26 [INFO]: Epoch 034 - training loss: 0.3797, validation loss: 0.3701
2024-06-02 20:55:28 [INFO]: Epoch 035 - training loss: 0.3630, validation loss: 0.3798
2024-06-02 20:55:30 [INFO]: Epoch 036 - training loss: 0.3667, validation loss: 0.3828
2024-06-02 20:55:32 [INFO]: Epoch 037 - training loss: 0.3546, validation loss: 0.3905
2024-06-02 20:55:34 [INFO]: Epoch 038 - training loss: 0.3470, validation loss: 0.3927
2024-06-02 20:55:37 [INFO]: Epoch 039 - training loss: 0.3582, validation loss: 0.3864
2024-06-02 20:55:39 [INFO]: Epoch 040 - training loss: 0.3562, validation loss: 0.3676
2024-06-02 20:55:41 [INFO]: Epoch 041 - training loss: 0.3377, validation loss: 0.3802
2024-06-02 20:55:43 [INFO]: Epoch 042 - training loss: 0.3421, validation loss: 0.3670
2024-06-02 20:55:46 [INFO]: Epoch 043 - training loss: 0.3455, validation loss: 0.3729
2024-06-02 20:55:48 [INFO]: Epoch 044 - training loss: 0.3513, validation loss: 0.3934
2024-06-02 20:55:50 [INFO]: Epoch 045 - training loss: 0.3432, validation loss: 0.3722
2024-06-02 20:55:53 [INFO]: Epoch 046 - training loss: 0.3437, validation loss: 0.3938
2024-06-02 20:55:55 [INFO]: Epoch 047 - training loss: 0.3505, validation loss: 0.3744
2024-06-02 20:55:58 [INFO]: Epoch 048 - training loss: 0.3536, validation loss: 0.3677
2024-06-02 20:56:00 [INFO]: Epoch 049 - training loss: 0.3539, validation loss: 0.3813
2024-06-02 20:56:02 [INFO]: Epoch 050 - training loss: 0.3415, validation loss: 0.3782
2024-06-02 20:56:05 [INFO]: Epoch 051 - training loss: 0.3485, validation loss: 0.3773
2024-06-02 20:56:07 [INFO]: Epoch 052 - training loss: 0.3472, validation loss: 0.3995
2024-06-02 20:56:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:56:07 [INFO]: Finished training. The best model is from epoch#42.
2024-06-02 20:56:07 [INFO]: Saved the model to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_3/20240602_T205406/iTransformer.pypots
2024-06-02 20:56:08 [INFO]: Successfully saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_3/imputation.pkl
2024-06-02 20:56:08 [INFO]: Round3 - iTransformer on ItalyAir: MAE=0.3231, MSE=0.3415, MRE=0.4225
2024-06-02 20:56:08 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 20:56:08 [INFO]: Using the given device: cuda:0
2024-06-02 20:56:08 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240602_T205608
2024-06-02 20:56:08 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240602_T205608/tensorboard
2024-06-02 20:56:08 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=4, d_k=256
2024-06-02 20:56:08 [WARNING]: ⚠️ d_model is reset to 1024 = n_heads (4) * d_k (256)
2024-06-02 20:56:09 [INFO]: iTransformer initialized with the given hyperparameters, the number of trainable parameters: 18,932,236
2024-06-02 20:56:11 [INFO]: Epoch 001 - training loss: 1.1372, validation loss: 1.0277
2024-06-02 20:56:13 [INFO]: Epoch 002 - training loss: 0.6712, validation loss: 0.7774
2024-06-02 20:56:14 [INFO]: Epoch 003 - training loss: 0.5901, validation loss: 0.6207
2024-06-02 20:56:16 [INFO]: Epoch 004 - training loss: 0.5514, validation loss: 0.5836
2024-06-02 20:56:18 [INFO]: Epoch 005 - training loss: 0.5424, validation loss: 0.5795
2024-06-02 20:56:20 [INFO]: Epoch 006 - training loss: 0.5208, validation loss: 0.5280
2024-06-02 20:56:21 [INFO]: Epoch 007 - training loss: 0.5086, validation loss: 0.5591
2024-06-02 20:56:23 [INFO]: Epoch 008 - training loss: 0.4938, validation loss: 0.5379
2024-06-02 20:56:24 [INFO]: Epoch 009 - training loss: 0.4961, validation loss: 0.4845
2024-06-02 20:56:26 [INFO]: Epoch 010 - training loss: 0.4761, validation loss: 0.4758
2024-06-02 20:56:28 [INFO]: Epoch 011 - training loss: 0.4685, validation loss: 0.4579
2024-06-02 20:56:29 [INFO]: Epoch 012 - training loss: 0.4613, validation loss: 0.4723
2024-06-02 20:56:31 [INFO]: Epoch 013 - training loss: 0.4518, validation loss: 0.4635
2024-06-02 20:56:33 [INFO]: Epoch 014 - training loss: 0.4551, validation loss: 0.4439
2024-06-02 20:56:34 [INFO]: Epoch 015 - training loss: 0.4488, validation loss: 0.4649
2024-06-02 20:56:36 [INFO]: Epoch 016 - training loss: 0.4432, validation loss: 0.4462
2024-06-02 20:56:37 [INFO]: Epoch 017 - training loss: 0.4412, validation loss: 0.4439
2024-06-02 20:56:39 [INFO]: Epoch 018 - training loss: 0.4230, validation loss: 0.4402
2024-06-02 20:56:41 [INFO]: Epoch 019 - training loss: 0.4211, validation loss: 0.4144
2024-06-02 20:56:42 [INFO]: Epoch 020 - training loss: 0.4221, validation loss: 0.4075
2024-06-02 20:56:44 [INFO]: Epoch 021 - training loss: 0.4177, validation loss: 0.4237
2024-06-02 20:56:45 [INFO]: Epoch 022 - training loss: 0.4112, validation loss: 0.4013
2024-06-02 20:56:47 [INFO]: Epoch 023 - training loss: 0.3951, validation loss: 0.3866
2024-06-02 20:56:49 [INFO]: Epoch 024 - training loss: 0.3940, validation loss: 0.3901
2024-06-02 20:56:50 [INFO]: Epoch 025 - training loss: 0.3925, validation loss: 0.3804
2024-06-02 20:56:52 [INFO]: Epoch 026 - training loss: 0.3948, validation loss: 0.3821
2024-06-02 20:56:54 [INFO]: Epoch 027 - training loss: 0.3867, validation loss: 0.4177
2024-06-02 20:56:55 [INFO]: Epoch 028 - training loss: 0.3945, validation loss: 0.3933
2024-06-02 20:56:57 [INFO]: Epoch 029 - training loss: 0.3745, validation loss: 0.3743
2024-06-02 20:56:59 [INFO]: Epoch 030 - training loss: 0.3693, validation loss: 0.4095
2024-06-02 20:57:00 [INFO]: Epoch 031 - training loss: 0.3734, validation loss: 0.3740
2024-06-02 20:57:02 [INFO]: Epoch 032 - training loss: 0.3664, validation loss: 0.3897
2024-06-02 20:57:04 [INFO]: Epoch 033 - training loss: 0.3727, validation loss: 0.3718
2024-06-02 20:57:05 [INFO]: Epoch 034 - training loss: 0.3753, validation loss: 0.3747
2024-06-02 20:57:07 [INFO]: Epoch 035 - training loss: 0.3584, validation loss: 0.3707
2024-06-02 20:57:08 [INFO]: Epoch 036 - training loss: 0.3559, validation loss: 0.3857
2024-06-02 20:57:10 [INFO]: Epoch 037 - training loss: 0.3588, validation loss: 0.3571
2024-06-02 20:57:11 [INFO]: Epoch 038 - training loss: 0.3625, validation loss: 0.3828
2024-06-02 20:57:13 [INFO]: Epoch 039 - training loss: 0.3521, validation loss: 0.4005
2024-06-02 20:57:15 [INFO]: Epoch 040 - training loss: 0.3505, validation loss: 0.3708
2024-06-02 20:57:16 [INFO]: Epoch 041 - training loss: 0.3524, validation loss: 0.3626
2024-06-02 20:57:18 [INFO]: Epoch 042 - training loss: 0.3455, validation loss: 0.3670
2024-06-02 20:57:20 [INFO]: Epoch 043 - training loss: 0.3426, validation loss: 0.3843
2024-06-02 20:57:21 [INFO]: Epoch 044 - training loss: 0.3391, validation loss: 0.3575
2024-06-02 20:57:23 [INFO]: Epoch 045 - training loss: 0.3483, validation loss: 0.3729
2024-06-02 20:57:24 [INFO]: Epoch 046 - training loss: 0.3408, validation loss: 0.3730
2024-06-02 20:57:26 [INFO]: Epoch 047 - training loss: 0.3498, validation loss: 0.3903
2024-06-02 20:57:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:57:26 [INFO]: Finished training. The best model is from epoch#37.
2024-06-02 20:57:26 [INFO]: Saved the model to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_4/20240602_T205608/iTransformer.pypots
2024-06-02 20:57:27 [INFO]: Successfully saved to results_point_rate05/ItalyAir/iTransformer_ItalyAir/round_4/imputation.pkl
2024-06-02 20:57:27 [INFO]: Round4 - iTransformer on ItalyAir: MAE=0.3212, MSE=0.3230, MRE=0.4200
2024-06-02 20:57:27 [INFO]: Done! Final results:
Averaged iTransformer (18,932,236 params) on ItalyAir: MAE=0.3205 ± 0.007052794815389684, MSE=0.3268 ± 0.010514312679260894, MRE=0.4191 ± 0.009222877677116475, average inference time=0.18
