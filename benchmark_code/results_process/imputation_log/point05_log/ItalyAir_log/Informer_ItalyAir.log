2024-06-02 20:46:36 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-02 20:46:36 [INFO]: Using the given device: cuda:0
2024-06-02 20:46:36 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_0/20240602_T204636
2024-06-02 20:46:36 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_0/20240602_T204636/tensorboard
2024-06-02 20:46:38 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 10,540,045
2024-06-02 20:46:47 [INFO]: Epoch 001 - training loss: 1.2404, validation loss: 1.2343
2024-06-02 20:46:52 [INFO]: Epoch 002 - training loss: 0.7459, validation loss: 0.8236
2024-06-02 20:46:56 [INFO]: Epoch 003 - training loss: 0.5611, validation loss: 0.5604
2024-06-02 20:47:01 [INFO]: Epoch 004 - training loss: 0.5088, validation loss: 0.4136
2024-06-02 20:47:05 [INFO]: Epoch 005 - training loss: 0.4737, validation loss: 0.3919
2024-06-02 20:47:10 [INFO]: Epoch 006 - training loss: 0.4583, validation loss: 0.3803
2024-06-02 20:47:15 [INFO]: Epoch 007 - training loss: 0.4252, validation loss: 0.3350
2024-06-02 20:47:20 [INFO]: Epoch 008 - training loss: 0.4210, validation loss: 0.3461
2024-06-02 20:47:24 [INFO]: Epoch 009 - training loss: 0.4252, validation loss: 0.3409
2024-06-02 20:47:29 [INFO]: Epoch 010 - training loss: 0.4170, validation loss: 0.3114
2024-06-02 20:47:34 [INFO]: Epoch 011 - training loss: 0.4089, validation loss: 0.3327
2024-06-02 20:47:39 [INFO]: Epoch 012 - training loss: 0.3935, validation loss: 0.3076
2024-06-02 20:47:43 [INFO]: Epoch 013 - training loss: 0.3741, validation loss: 0.2956
2024-06-02 20:47:48 [INFO]: Epoch 014 - training loss: 0.3751, validation loss: 0.2927
2024-06-02 20:47:53 [INFO]: Epoch 015 - training loss: 0.3655, validation loss: 0.3119
2024-06-02 20:47:57 [INFO]: Epoch 016 - training loss: 0.3552, validation loss: 0.2997
2024-06-02 20:48:02 [INFO]: Epoch 017 - training loss: 0.3599, validation loss: 0.2821
2024-06-02 20:48:06 [INFO]: Epoch 018 - training loss: 0.3570, validation loss: 0.3079
2024-06-02 20:48:11 [INFO]: Epoch 019 - training loss: 0.3420, validation loss: 0.2987
2024-06-02 20:48:15 [INFO]: Epoch 020 - training loss: 0.3292, validation loss: 0.2738
2024-06-02 20:48:20 [INFO]: Epoch 021 - training loss: 0.3192, validation loss: 0.2742
2024-06-02 20:48:25 [INFO]: Epoch 022 - training loss: 0.3267, validation loss: 0.2784
2024-06-02 20:48:29 [INFO]: Epoch 023 - training loss: 0.3305, validation loss: 0.2647
2024-06-02 20:48:34 [INFO]: Epoch 024 - training loss: 0.3241, validation loss: 0.2509
2024-06-02 20:48:38 [INFO]: Epoch 025 - training loss: 0.3209, validation loss: 0.2658
2024-06-02 20:48:43 [INFO]: Epoch 026 - training loss: 0.3132, validation loss: 0.2718
2024-06-02 20:48:48 [INFO]: Epoch 027 - training loss: 0.3155, validation loss: 0.2698
2024-06-02 20:48:53 [INFO]: Epoch 028 - training loss: 0.3068, validation loss: 0.2623
2024-06-02 20:48:58 [INFO]: Epoch 029 - training loss: 0.3145, validation loss: 0.2791
2024-06-02 20:49:02 [INFO]: Epoch 030 - training loss: 0.3085, validation loss: 0.2718
2024-06-02 20:49:07 [INFO]: Epoch 031 - training loss: 0.3023, validation loss: 0.2845
2024-06-02 20:49:11 [INFO]: Epoch 032 - training loss: 0.3080, validation loss: 0.2497
2024-06-02 20:49:16 [INFO]: Epoch 033 - training loss: 0.3062, validation loss: 0.2575
2024-06-02 20:49:20 [INFO]: Epoch 034 - training loss: 0.2894, validation loss: 0.2414
2024-06-02 20:49:25 [INFO]: Epoch 035 - training loss: 0.2915, validation loss: 0.2688
2024-06-02 20:49:29 [INFO]: Epoch 036 - training loss: 0.2925, validation loss: 0.2325
2024-06-02 20:49:34 [INFO]: Epoch 037 - training loss: 0.2765, validation loss: 0.2534
2024-06-02 20:49:38 [INFO]: Epoch 038 - training loss: 0.2825, validation loss: 0.2642
2024-06-02 20:49:42 [INFO]: Epoch 039 - training loss: 0.2785, validation loss: 0.2623
2024-06-02 20:49:47 [INFO]: Epoch 040 - training loss: 0.2671, validation loss: 0.2354
2024-06-02 20:49:51 [INFO]: Epoch 041 - training loss: 0.2612, validation loss: 0.2615
2024-06-02 20:49:56 [INFO]: Epoch 042 - training loss: 0.2764, validation loss: 0.2144
2024-06-02 20:50:01 [INFO]: Epoch 043 - training loss: 0.2754, validation loss: 0.2363
2024-06-02 20:50:06 [INFO]: Epoch 044 - training loss: 0.2727, validation loss: 0.2241
2024-06-02 20:50:10 [INFO]: Epoch 045 - training loss: 0.2582, validation loss: 0.2395
2024-06-02 20:50:15 [INFO]: Epoch 046 - training loss: 0.2625, validation loss: 0.2239
2024-06-02 20:50:19 [INFO]: Epoch 047 - training loss: 0.2579, validation loss: 0.2345
2024-06-02 20:50:23 [INFO]: Epoch 048 - training loss: 0.2681, validation loss: 0.2408
2024-06-02 20:50:28 [INFO]: Epoch 049 - training loss: 0.2604, validation loss: 0.2242
2024-06-02 20:50:33 [INFO]: Epoch 050 - training loss: 0.2569, validation loss: 0.2179
2024-06-02 20:50:37 [INFO]: Epoch 051 - training loss: 0.2476, validation loss: 0.2342
2024-06-02 20:50:42 [INFO]: Epoch 052 - training loss: 0.2538, validation loss: 0.2337
2024-06-02 20:50:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:50:42 [INFO]: Finished training. The best model is from epoch#42.
2024-06-02 20:50:42 [INFO]: Saved the model to results_point_rate05/ItalyAir/Informer_ItalyAir/round_0/20240602_T204636/Informer.pypots
2024-06-02 20:50:45 [INFO]: Successfully saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_0/imputation.pkl
2024-06-02 20:50:45 [INFO]: Round0 - Informer on ItalyAir: MAE=0.3033, MSE=0.2545, MRE=0.3966
2024-06-02 20:50:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-02 20:50:45 [INFO]: Using the given device: cuda:0
2024-06-02 20:50:45 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_1/20240602_T205045
2024-06-02 20:50:45 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_1/20240602_T205045/tensorboard
2024-06-02 20:50:46 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 10,540,045
2024-06-02 20:50:51 [INFO]: Epoch 001 - training loss: 1.1825, validation loss: 1.1853
2024-06-02 20:50:55 [INFO]: Epoch 002 - training loss: 0.6899, validation loss: 0.8477
2024-06-02 20:50:59 [INFO]: Epoch 003 - training loss: 0.5734, validation loss: 0.4983
2024-06-02 20:51:04 [INFO]: Epoch 004 - training loss: 0.5146, validation loss: 0.3871
2024-06-02 20:51:08 [INFO]: Epoch 005 - training loss: 0.4710, validation loss: 0.3312
2024-06-02 20:51:13 [INFO]: Epoch 006 - training loss: 0.4485, validation loss: 0.3341
2024-06-02 20:51:17 [INFO]: Epoch 007 - training loss: 0.4417, validation loss: 0.3182
2024-06-02 20:51:21 [INFO]: Epoch 008 - training loss: 0.4368, validation loss: 0.3217
2024-06-02 20:51:25 [INFO]: Epoch 009 - training loss: 0.4267, validation loss: 0.3186
2024-06-02 20:51:29 [INFO]: Epoch 010 - training loss: 0.4175, validation loss: 0.3253
2024-06-02 20:51:34 [INFO]: Epoch 011 - training loss: 0.3946, validation loss: 0.3122
2024-06-02 20:51:38 [INFO]: Epoch 012 - training loss: 0.3969, validation loss: 0.3202
2024-06-02 20:51:43 [INFO]: Epoch 013 - training loss: 0.3779, validation loss: 0.3101
2024-06-02 20:51:47 [INFO]: Epoch 014 - training loss: 0.3874, validation loss: 0.2920
2024-06-02 20:51:52 [INFO]: Epoch 015 - training loss: 0.3721, validation loss: 0.2908
2024-06-02 20:51:56 [INFO]: Epoch 016 - training loss: 0.3687, validation loss: 0.2841
2024-06-02 20:52:00 [INFO]: Epoch 017 - training loss: 0.3702, validation loss: 0.2920
2024-06-02 20:52:04 [INFO]: Epoch 018 - training loss: 0.3542, validation loss: 0.2773
2024-06-02 20:52:09 [INFO]: Epoch 019 - training loss: 0.3475, validation loss: 0.2699
2024-06-02 20:52:14 [INFO]: Epoch 020 - training loss: 0.3489, validation loss: 0.2504
2024-06-02 20:52:19 [INFO]: Epoch 021 - training loss: 0.3382, validation loss: 0.2757
2024-06-02 20:52:23 [INFO]: Epoch 022 - training loss: 0.3304, validation loss: 0.2633
2024-06-02 20:52:27 [INFO]: Epoch 023 - training loss: 0.3318, validation loss: 0.2510
2024-06-02 20:52:31 [INFO]: Epoch 024 - training loss: 0.3195, validation loss: 0.2623
2024-06-02 20:52:35 [INFO]: Epoch 025 - training loss: 0.3322, validation loss: 0.2651
2024-06-02 20:52:39 [INFO]: Epoch 026 - training loss: 0.3248, validation loss: 0.2526
2024-06-02 20:52:43 [INFO]: Epoch 027 - training loss: 0.3277, validation loss: 0.2621
2024-06-02 20:52:48 [INFO]: Epoch 028 - training loss: 0.3274, validation loss: 0.2512
2024-06-02 20:52:53 [INFO]: Epoch 029 - training loss: 0.3147, validation loss: 0.2661
2024-06-02 20:52:57 [INFO]: Epoch 030 - training loss: 0.3059, validation loss: 0.2400
2024-06-02 20:53:01 [INFO]: Epoch 031 - training loss: 0.2954, validation loss: 0.2580
2024-06-02 20:53:05 [INFO]: Epoch 032 - training loss: 0.2997, validation loss: 0.2415
2024-06-02 20:53:10 [INFO]: Epoch 033 - training loss: 0.3005, validation loss: 0.2167
2024-06-02 20:53:14 [INFO]: Epoch 034 - training loss: 0.2908, validation loss: 0.2299
2024-06-02 20:53:18 [INFO]: Epoch 035 - training loss: 0.2875, validation loss: 0.2221
2024-06-02 20:53:22 [INFO]: Epoch 036 - training loss: 0.2789, validation loss: 0.2377
2024-06-02 20:53:26 [INFO]: Epoch 037 - training loss: 0.2824, validation loss: 0.2264
2024-06-02 20:53:30 [INFO]: Epoch 038 - training loss: 0.2807, validation loss: 0.2252
2024-06-02 20:53:35 [INFO]: Epoch 039 - training loss: 0.2756, validation loss: 0.2164
2024-06-02 20:53:39 [INFO]: Epoch 040 - training loss: 0.2797, validation loss: 0.2323
2024-06-02 20:53:43 [INFO]: Epoch 041 - training loss: 0.2720, validation loss: 0.2269
2024-06-02 20:53:47 [INFO]: Epoch 042 - training loss: 0.2740, validation loss: 0.2464
2024-06-02 20:53:51 [INFO]: Epoch 043 - training loss: 0.2721, validation loss: 0.2297
2024-06-02 20:53:56 [INFO]: Epoch 044 - training loss: 0.2749, validation loss: 0.2211
2024-06-02 20:54:00 [INFO]: Epoch 045 - training loss: 0.2682, validation loss: 0.2180
2024-06-02 20:54:03 [INFO]: Epoch 046 - training loss: 0.2592, validation loss: 0.2172
2024-06-02 20:54:07 [INFO]: Epoch 047 - training loss: 0.2563, validation loss: 0.2233
2024-06-02 20:54:10 [INFO]: Epoch 048 - training loss: 0.2609, validation loss: 0.2209
2024-06-02 20:54:14 [INFO]: Epoch 049 - training loss: 0.2633, validation loss: 0.2126
2024-06-02 20:54:18 [INFO]: Epoch 050 - training loss: 0.2431, validation loss: 0.2115
2024-06-02 20:54:21 [INFO]: Epoch 051 - training loss: 0.2558, validation loss: 0.2131
2024-06-02 20:54:25 [INFO]: Epoch 052 - training loss: 0.2416, validation loss: 0.2109
2024-06-02 20:54:29 [INFO]: Epoch 053 - training loss: 0.2390, validation loss: 0.2069
2024-06-02 20:54:33 [INFO]: Epoch 054 - training loss: 0.2564, validation loss: 0.2233
2024-06-02 20:54:37 [INFO]: Epoch 055 - training loss: 0.2487, validation loss: 0.2164
2024-06-02 20:54:41 [INFO]: Epoch 056 - training loss: 0.2385, validation loss: 0.2195
2024-06-02 20:54:45 [INFO]: Epoch 057 - training loss: 0.2422, validation loss: 0.2121
2024-06-02 20:54:49 [INFO]: Epoch 058 - training loss: 0.2467, validation loss: 0.2105
2024-06-02 20:54:53 [INFO]: Epoch 059 - training loss: 0.2513, validation loss: 0.2264
2024-06-02 20:54:57 [INFO]: Epoch 060 - training loss: 0.2509, validation loss: 0.2221
2024-06-02 20:55:02 [INFO]: Epoch 061 - training loss: 0.2347, validation loss: 0.1980
2024-06-02 20:55:06 [INFO]: Epoch 062 - training loss: 0.2433, validation loss: 0.1979
2024-06-02 20:55:10 [INFO]: Epoch 063 - training loss: 0.2401, validation loss: 0.2108
2024-06-02 20:55:13 [INFO]: Epoch 064 - training loss: 0.2307, validation loss: 0.2085
2024-06-02 20:55:17 [INFO]: Epoch 065 - training loss: 0.2288, validation loss: 0.2056
2024-06-02 20:55:20 [INFO]: Epoch 066 - training loss: 0.2398, validation loss: 0.1960
2024-06-02 20:55:25 [INFO]: Epoch 067 - training loss: 0.2371, validation loss: 0.1984
2024-06-02 20:55:28 [INFO]: Epoch 068 - training loss: 0.2379, validation loss: 0.2041
2024-06-02 20:55:32 [INFO]: Epoch 069 - training loss: 0.2349, validation loss: 0.2045
2024-06-02 20:55:35 [INFO]: Epoch 070 - training loss: 0.2419, validation loss: 0.2074
2024-06-02 20:55:40 [INFO]: Epoch 071 - training loss: 0.2413, validation loss: 0.2059
2024-06-02 20:55:43 [INFO]: Epoch 072 - training loss: 0.2403, validation loss: 0.2101
2024-06-02 20:55:47 [INFO]: Epoch 073 - training loss: 0.2347, validation loss: 0.2013
2024-06-02 20:55:50 [INFO]: Epoch 074 - training loss: 0.2230, validation loss: 0.2010
2024-06-02 20:55:54 [INFO]: Epoch 075 - training loss: 0.2192, validation loss: 0.2079
2024-06-02 20:55:58 [INFO]: Epoch 076 - training loss: 0.2192, validation loss: 0.1968
2024-06-02 20:55:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:55:58 [INFO]: Finished training. The best model is from epoch#66.
2024-06-02 20:55:59 [INFO]: Saved the model to results_point_rate05/ItalyAir/Informer_ItalyAir/round_1/20240602_T205045/Informer.pypots
2024-06-02 20:56:01 [INFO]: Successfully saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_1/imputation.pkl
2024-06-02 20:56:01 [INFO]: Round1 - Informer on ItalyAir: MAE=0.3047, MSE=0.2483, MRE=0.3984
2024-06-02 20:56:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-02 20:56:01 [INFO]: Using the given device: cuda:0
2024-06-02 20:56:01 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_2/20240602_T205601
2024-06-02 20:56:01 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_2/20240602_T205601/tensorboard
2024-06-02 20:56:02 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 10,540,045
2024-06-02 20:56:05 [INFO]: Epoch 001 - training loss: 1.2260, validation loss: 1.2794
2024-06-02 20:56:08 [INFO]: Epoch 002 - training loss: 0.7250, validation loss: 0.8626
2024-06-02 20:56:11 [INFO]: Epoch 003 - training loss: 0.5796, validation loss: 0.5666
2024-06-02 20:56:14 [INFO]: Epoch 004 - training loss: 0.5118, validation loss: 0.4418
2024-06-02 20:56:17 [INFO]: Epoch 005 - training loss: 0.4710, validation loss: 0.3677
2024-06-02 20:56:20 [INFO]: Epoch 006 - training loss: 0.4518, validation loss: 0.3273
2024-06-02 20:56:23 [INFO]: Epoch 007 - training loss: 0.4148, validation loss: 0.3395
2024-06-02 20:56:26 [INFO]: Epoch 008 - training loss: 0.4130, validation loss: 0.3257
2024-06-02 20:56:28 [INFO]: Epoch 009 - training loss: 0.4194, validation loss: 0.3238
2024-06-02 20:56:32 [INFO]: Epoch 010 - training loss: 0.4083, validation loss: 0.3222
2024-06-02 20:56:34 [INFO]: Epoch 011 - training loss: 0.3926, validation loss: 0.3037
2024-06-02 20:56:37 [INFO]: Epoch 012 - training loss: 0.3799, validation loss: 0.2912
2024-06-02 20:56:40 [INFO]: Epoch 013 - training loss: 0.3868, validation loss: 0.3311
2024-06-02 20:56:43 [INFO]: Epoch 014 - training loss: 0.3916, validation loss: 0.2742
2024-06-02 20:56:46 [INFO]: Epoch 015 - training loss: 0.3712, validation loss: 0.2740
2024-06-02 20:56:48 [INFO]: Epoch 016 - training loss: 0.3610, validation loss: 0.2841
2024-06-02 20:56:51 [INFO]: Epoch 017 - training loss: 0.3539, validation loss: 0.2673
2024-06-02 20:56:54 [INFO]: Epoch 018 - training loss: 0.3408, validation loss: 0.3170
2024-06-02 20:56:57 [INFO]: Epoch 019 - training loss: 0.3339, validation loss: 0.2884
2024-06-02 20:57:00 [INFO]: Epoch 020 - training loss: 0.3365, validation loss: 0.2663
2024-06-02 20:57:03 [INFO]: Epoch 021 - training loss: 0.3292, validation loss: 0.2734
2024-06-02 20:57:06 [INFO]: Epoch 022 - training loss: 0.3220, validation loss: 0.2576
2024-06-02 20:57:09 [INFO]: Epoch 023 - training loss: 0.3254, validation loss: 0.2535
2024-06-02 20:57:12 [INFO]: Epoch 024 - training loss: 0.3333, validation loss: 0.2554
2024-06-02 20:57:15 [INFO]: Epoch 025 - training loss: 0.3263, validation loss: 0.2593
2024-06-02 20:57:17 [INFO]: Epoch 026 - training loss: 0.3233, validation loss: 0.2587
2024-06-02 20:57:20 [INFO]: Epoch 027 - training loss: 0.3130, validation loss: 0.2561
2024-06-02 20:57:23 [INFO]: Epoch 028 - training loss: 0.3146, validation loss: 0.2692
2024-06-02 20:57:26 [INFO]: Epoch 029 - training loss: 0.2983, validation loss: 0.2706
2024-06-02 20:57:29 [INFO]: Epoch 030 - training loss: 0.3049, validation loss: 0.2451
2024-06-02 20:57:31 [INFO]: Epoch 031 - training loss: 0.3084, validation loss: 0.2339
2024-06-02 20:57:34 [INFO]: Epoch 032 - training loss: 0.2999, validation loss: 0.2446
2024-06-02 20:57:36 [INFO]: Epoch 033 - training loss: 0.2939, validation loss: 0.2333
2024-06-02 20:57:38 [INFO]: Epoch 034 - training loss: 0.2845, validation loss: 0.2251
2024-06-02 20:57:40 [INFO]: Epoch 035 - training loss: 0.2885, validation loss: 0.2286
2024-06-02 20:57:43 [INFO]: Epoch 036 - training loss: 0.2807, validation loss: 0.2481
2024-06-02 20:57:45 [INFO]: Epoch 037 - training loss: 0.2898, validation loss: 0.2310
2024-06-02 20:57:48 [INFO]: Epoch 038 - training loss: 0.2859, validation loss: 0.2281
2024-06-02 20:57:50 [INFO]: Epoch 039 - training loss: 0.2845, validation loss: 0.2297
2024-06-02 20:57:52 [INFO]: Epoch 040 - training loss: 0.2919, validation loss: 0.2238
2024-06-02 20:57:55 [INFO]: Epoch 041 - training loss: 0.2662, validation loss: 0.2236
2024-06-02 20:57:57 [INFO]: Epoch 042 - training loss: 0.2785, validation loss: 0.2306
2024-06-02 20:57:59 [INFO]: Epoch 043 - training loss: 0.2655, validation loss: 0.2251
2024-06-02 20:58:01 [INFO]: Epoch 044 - training loss: 0.2535, validation loss: 0.2108
2024-06-02 20:58:03 [INFO]: Epoch 045 - training loss: 0.2661, validation loss: 0.2170
2024-06-02 20:58:06 [INFO]: Epoch 046 - training loss: 0.2721, validation loss: 0.2259
2024-06-02 20:58:08 [INFO]: Epoch 047 - training loss: 0.2635, validation loss: 0.2070
2024-06-02 20:58:11 [INFO]: Epoch 048 - training loss: 0.2604, validation loss: 0.1998
2024-06-02 20:58:13 [INFO]: Epoch 049 - training loss: 0.2533, validation loss: 0.2183
2024-06-02 20:58:16 [INFO]: Epoch 050 - training loss: 0.2590, validation loss: 0.2135
2024-06-02 20:58:18 [INFO]: Epoch 051 - training loss: 0.2678, validation loss: 0.2147
2024-06-02 20:58:20 [INFO]: Epoch 052 - training loss: 0.2545, validation loss: 0.2091
2024-06-02 20:58:22 [INFO]: Epoch 053 - training loss: 0.2545, validation loss: 0.2100
2024-06-02 20:58:25 [INFO]: Epoch 054 - training loss: 0.2533, validation loss: 0.2019
2024-06-02 20:58:27 [INFO]: Epoch 055 - training loss: 0.2502, validation loss: 0.2110
2024-06-02 20:58:29 [INFO]: Epoch 056 - training loss: 0.2634, validation loss: 0.2169
2024-06-02 20:58:31 [INFO]: Epoch 057 - training loss: 0.2476, validation loss: 0.1959
2024-06-02 20:58:34 [INFO]: Epoch 058 - training loss: 0.2433, validation loss: 0.1892
2024-06-02 20:58:36 [INFO]: Epoch 059 - training loss: 0.2434, validation loss: 0.2060
2024-06-02 20:58:38 [INFO]: Epoch 060 - training loss: 0.2405, validation loss: 0.1950
2024-06-02 20:58:41 [INFO]: Epoch 061 - training loss: 0.2364, validation loss: 0.1931
2024-06-02 20:58:43 [INFO]: Epoch 062 - training loss: 0.2298, validation loss: 0.2042
2024-06-02 20:58:45 [INFO]: Epoch 063 - training loss: 0.2352, validation loss: 0.2053
2024-06-02 20:58:48 [INFO]: Epoch 064 - training loss: 0.2371, validation loss: 0.1992
2024-06-02 20:58:50 [INFO]: Epoch 065 - training loss: 0.2302, validation loss: 0.2077
2024-06-02 20:58:52 [INFO]: Epoch 066 - training loss: 0.2279, validation loss: 0.2128
2024-06-02 20:58:55 [INFO]: Epoch 067 - training loss: 0.2338, validation loss: 0.1865
2024-06-02 20:58:57 [INFO]: Epoch 068 - training loss: 0.2368, validation loss: 0.1838
2024-06-02 20:58:59 [INFO]: Epoch 069 - training loss: 0.2408, validation loss: 0.2049
2024-06-02 20:59:01 [INFO]: Epoch 070 - training loss: 0.2350, validation loss: 0.2088
2024-06-02 20:59:03 [INFO]: Epoch 071 - training loss: 0.2303, validation loss: 0.1963
2024-06-02 20:59:05 [INFO]: Epoch 072 - training loss: 0.2352, validation loss: 0.1936
2024-06-02 20:59:08 [INFO]: Epoch 073 - training loss: 0.2270, validation loss: 0.1823
2024-06-02 20:59:10 [INFO]: Epoch 074 - training loss: 0.2253, validation loss: 0.1959
2024-06-02 20:59:13 [INFO]: Epoch 075 - training loss: 0.2318, validation loss: 0.2045
2024-06-02 20:59:15 [INFO]: Epoch 076 - training loss: 0.2321, validation loss: 0.2081
2024-06-02 20:59:17 [INFO]: Epoch 077 - training loss: 0.2263, validation loss: 0.2097
2024-06-02 20:59:19 [INFO]: Epoch 078 - training loss: 0.2372, validation loss: 0.1924
2024-06-02 20:59:22 [INFO]: Epoch 079 - training loss: 0.2149, validation loss: 0.2030
2024-06-02 20:59:24 [INFO]: Epoch 080 - training loss: 0.2197, validation loss: 0.2044
2024-06-02 20:59:27 [INFO]: Epoch 081 - training loss: 0.2283, validation loss: 0.1916
2024-06-02 20:59:29 [INFO]: Epoch 082 - training loss: 0.2216, validation loss: 0.1936
2024-06-02 20:59:32 [INFO]: Epoch 083 - training loss: 0.2158, validation loss: 0.1900
2024-06-02 20:59:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 20:59:32 [INFO]: Finished training. The best model is from epoch#73.
2024-06-02 20:59:32 [INFO]: Saved the model to results_point_rate05/ItalyAir/Informer_ItalyAir/round_2/20240602_T205601/Informer.pypots
2024-06-02 20:59:33 [INFO]: Successfully saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_2/imputation.pkl
2024-06-02 20:59:33 [INFO]: Round2 - Informer on ItalyAir: MAE=0.2910, MSE=0.2170, MRE=0.3805
2024-06-02 20:59:33 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-02 20:59:33 [INFO]: Using the given device: cuda:0
2024-06-02 20:59:33 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_3/20240602_T205933
2024-06-02 20:59:33 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_3/20240602_T205933/tensorboard
2024-06-02 20:59:33 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 10,540,045
2024-06-02 20:59:35 [INFO]: Epoch 001 - training loss: 1.2019, validation loss: 1.1548
2024-06-02 20:59:38 [INFO]: Epoch 002 - training loss: 0.7131, validation loss: 0.7017
2024-06-02 20:59:40 [INFO]: Epoch 003 - training loss: 0.5631, validation loss: 0.4604
2024-06-02 20:59:42 [INFO]: Epoch 004 - training loss: 0.4931, validation loss: 0.4186
2024-06-02 20:59:45 [INFO]: Epoch 005 - training loss: 0.4655, validation loss: 0.3754
2024-06-02 20:59:47 [INFO]: Epoch 006 - training loss: 0.4649, validation loss: 0.3748
2024-06-02 20:59:49 [INFO]: Epoch 007 - training loss: 0.4370, validation loss: 0.3346
2024-06-02 20:59:51 [INFO]: Epoch 008 - training loss: 0.4268, validation loss: 0.3060
2024-06-02 20:59:54 [INFO]: Epoch 009 - training loss: 0.4091, validation loss: 0.3412
2024-06-02 20:59:56 [INFO]: Epoch 010 - training loss: 0.4088, validation loss: 0.3271
2024-06-02 20:59:59 [INFO]: Epoch 011 - training loss: 0.3929, validation loss: 0.3057
2024-06-02 21:00:01 [INFO]: Epoch 012 - training loss: 0.3862, validation loss: 0.3327
2024-06-02 21:00:04 [INFO]: Epoch 013 - training loss: 0.3818, validation loss: 0.3042
2024-06-02 21:00:06 [INFO]: Epoch 014 - training loss: 0.3635, validation loss: 0.2860
2024-06-02 21:00:08 [INFO]: Epoch 015 - training loss: 0.3706, validation loss: 0.3176
2024-06-02 21:00:11 [INFO]: Epoch 016 - training loss: 0.3573, validation loss: 0.2771
2024-06-02 21:00:13 [INFO]: Epoch 017 - training loss: 0.3440, validation loss: 0.2678
2024-06-02 21:00:15 [INFO]: Epoch 018 - training loss: 0.3436, validation loss: 0.2752
2024-06-02 21:00:17 [INFO]: Epoch 019 - training loss: 0.3366, validation loss: 0.2706
2024-06-02 21:00:19 [INFO]: Epoch 020 - training loss: 0.3436, validation loss: 0.2728
2024-06-02 21:00:22 [INFO]: Epoch 021 - training loss: 0.3432, validation loss: 0.2628
2024-06-02 21:00:24 [INFO]: Epoch 022 - training loss: 0.3310, validation loss: 0.2589
2024-06-02 21:00:26 [INFO]: Epoch 023 - training loss: 0.3195, validation loss: 0.2780
2024-06-02 21:00:29 [INFO]: Epoch 024 - training loss: 0.3089, validation loss: 0.2877
2024-06-02 21:00:31 [INFO]: Epoch 025 - training loss: 0.3217, validation loss: 0.2287
2024-06-02 21:00:33 [INFO]: Epoch 026 - training loss: 0.3158, validation loss: 0.2772
2024-06-02 21:00:35 [INFO]: Epoch 027 - training loss: 0.3173, validation loss: 0.2540
2024-06-02 21:00:37 [INFO]: Epoch 028 - training loss: 0.3049, validation loss: 0.2590
2024-06-02 21:00:39 [INFO]: Epoch 029 - training loss: 0.3046, validation loss: 0.2462
2024-06-02 21:00:42 [INFO]: Epoch 030 - training loss: 0.3011, validation loss: 0.2567
2024-06-02 21:00:44 [INFO]: Epoch 031 - training loss: 0.2952, validation loss: 0.2494
2024-06-02 21:00:46 [INFO]: Epoch 032 - training loss: 0.2989, validation loss: 0.2315
2024-06-02 21:00:49 [INFO]: Epoch 033 - training loss: 0.2959, validation loss: 0.2753
2024-06-02 21:00:51 [INFO]: Epoch 034 - training loss: 0.2956, validation loss: 0.2511
2024-06-02 21:00:53 [INFO]: Epoch 035 - training loss: 0.2862, validation loss: 0.2452
2024-06-02 21:00:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:00:53 [INFO]: Finished training. The best model is from epoch#25.
2024-06-02 21:00:54 [INFO]: Saved the model to results_point_rate05/ItalyAir/Informer_ItalyAir/round_3/20240602_T205933/Informer.pypots
2024-06-02 21:00:55 [INFO]: Successfully saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_3/imputation.pkl
2024-06-02 21:00:55 [INFO]: Round3 - Informer on ItalyAir: MAE=0.3124, MSE=0.2621, MRE=0.4085
2024-06-02 21:00:55 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-02 21:00:55 [INFO]: Using the given device: cuda:0
2024-06-02 21:00:55 [INFO]: Model files will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_4/20240602_T210055
2024-06-02 21:00:55 [INFO]: Tensorboard file will be saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_4/20240602_T210055/tensorboard
2024-06-02 21:00:55 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 10,540,045
2024-06-02 21:00:58 [INFO]: Epoch 001 - training loss: 1.1931, validation loss: 1.0996
2024-06-02 21:01:00 [INFO]: Epoch 002 - training loss: 0.7069, validation loss: 0.7136
2024-06-02 21:01:02 [INFO]: Epoch 003 - training loss: 0.5680, validation loss: 0.4484
2024-06-02 21:01:04 [INFO]: Epoch 004 - training loss: 0.4973, validation loss: 0.4022
2024-06-02 21:01:06 [INFO]: Epoch 005 - training loss: 0.4659, validation loss: 0.3684
2024-06-02 21:01:09 [INFO]: Epoch 006 - training loss: 0.4503, validation loss: 0.3505
2024-06-02 21:01:11 [INFO]: Epoch 007 - training loss: 0.4317, validation loss: 0.3422
2024-06-02 21:01:13 [INFO]: Epoch 008 - training loss: 0.4145, validation loss: 0.3300
2024-06-02 21:01:16 [INFO]: Epoch 009 - training loss: 0.4148, validation loss: 0.3344
2024-06-02 21:01:18 [INFO]: Epoch 010 - training loss: 0.4010, validation loss: 0.3001
2024-06-02 21:01:21 [INFO]: Epoch 011 - training loss: 0.3895, validation loss: 0.3163
2024-06-02 21:01:23 [INFO]: Epoch 012 - training loss: 0.3824, validation loss: 0.2951
2024-06-02 21:01:25 [INFO]: Epoch 013 - training loss: 0.3752, validation loss: 0.3029
2024-06-02 21:01:28 [INFO]: Epoch 014 - training loss: 0.3709, validation loss: 0.2783
2024-06-02 21:01:30 [INFO]: Epoch 015 - training loss: 0.3618, validation loss: 0.2960
2024-06-02 21:01:32 [INFO]: Epoch 016 - training loss: 0.3563, validation loss: 0.2931
2024-06-02 21:01:35 [INFO]: Epoch 017 - training loss: 0.3495, validation loss: 0.2742
2024-06-02 21:01:37 [INFO]: Epoch 018 - training loss: 0.3442, validation loss: 0.2785
2024-06-02 21:01:39 [INFO]: Epoch 019 - training loss: 0.3511, validation loss: 0.2853
2024-06-02 21:01:41 [INFO]: Epoch 020 - training loss: 0.3475, validation loss: 0.2746
2024-06-02 21:01:43 [INFO]: Epoch 021 - training loss: 0.3397, validation loss: 0.2615
2024-06-02 21:01:46 [INFO]: Epoch 022 - training loss: 0.3450, validation loss: 0.2678
2024-06-02 21:01:48 [INFO]: Epoch 023 - training loss: 0.3203, validation loss: 0.2723
2024-06-02 21:01:50 [INFO]: Epoch 024 - training loss: 0.3298, validation loss: 0.2627
2024-06-02 21:01:52 [INFO]: Epoch 025 - training loss: 0.3216, validation loss: 0.2555
2024-06-02 21:01:55 [INFO]: Epoch 026 - training loss: 0.3150, validation loss: 0.2493
2024-06-02 21:01:57 [INFO]: Epoch 027 - training loss: 0.3110, validation loss: 0.2399
2024-06-02 21:02:00 [INFO]: Epoch 028 - training loss: 0.3280, validation loss: 0.2576
2024-06-02 21:02:02 [INFO]: Epoch 029 - training loss: 0.3082, validation loss: 0.2438
2024-06-02 21:02:04 [INFO]: Epoch 030 - training loss: 0.3109, validation loss: 0.2434
2024-06-02 21:02:07 [INFO]: Epoch 031 - training loss: 0.3033, validation loss: 0.2506
2024-06-02 21:02:09 [INFO]: Epoch 032 - training loss: 0.3048, validation loss: 0.2456
2024-06-02 21:02:11 [INFO]: Epoch 033 - training loss: 0.2943, validation loss: 0.2534
2024-06-02 21:02:13 [INFO]: Epoch 034 - training loss: 0.2925, validation loss: 0.2240
2024-06-02 21:02:16 [INFO]: Epoch 035 - training loss: 0.2906, validation loss: 0.2626
2024-06-02 21:02:18 [INFO]: Epoch 036 - training loss: 0.2896, validation loss: 0.2439
2024-06-02 21:02:20 [INFO]: Epoch 037 - training loss: 0.2916, validation loss: 0.2389
2024-06-02 21:02:22 [INFO]: Epoch 038 - training loss: 0.2905, validation loss: 0.2507
2024-06-02 21:02:24 [INFO]: Epoch 039 - training loss: 0.2798, validation loss: 0.2300
2024-06-02 21:02:26 [INFO]: Epoch 040 - training loss: 0.2826, validation loss: 0.2277
2024-06-02 21:02:28 [INFO]: Epoch 041 - training loss: 0.2717, validation loss: 0.2142
2024-06-02 21:02:30 [INFO]: Epoch 042 - training loss: 0.2616, validation loss: 0.2233
2024-06-02 21:02:33 [INFO]: Epoch 043 - training loss: 0.2607, validation loss: 0.2163
2024-06-02 21:02:35 [INFO]: Epoch 044 - training loss: 0.2660, validation loss: 0.2234
2024-06-02 21:02:37 [INFO]: Epoch 045 - training loss: 0.2646, validation loss: 0.2305
2024-06-02 21:02:39 [INFO]: Epoch 046 - training loss: 0.2635, validation loss: 0.2084
2024-06-02 21:02:42 [INFO]: Epoch 047 - training loss: 0.2543, validation loss: 0.2213
2024-06-02 21:02:44 [INFO]: Epoch 048 - training loss: 0.2507, validation loss: 0.2401
2024-06-02 21:02:46 [INFO]: Epoch 049 - training loss: 0.2529, validation loss: 0.2264
2024-06-02 21:02:48 [INFO]: Epoch 050 - training loss: 0.2626, validation loss: 0.2097
2024-06-02 21:02:50 [INFO]: Epoch 051 - training loss: 0.2553, validation loss: 0.2247
2024-06-02 21:02:52 [INFO]: Epoch 052 - training loss: 0.2490, validation loss: 0.2146
2024-06-02 21:02:55 [INFO]: Epoch 053 - training loss: 0.2547, validation loss: 0.2099
2024-06-02 21:02:57 [INFO]: Epoch 054 - training loss: 0.2506, validation loss: 0.2179
2024-06-02 21:02:59 [INFO]: Epoch 055 - training loss: 0.2446, validation loss: 0.2093
2024-06-02 21:03:01 [INFO]: Epoch 056 - training loss: 0.2509, validation loss: 0.2128
2024-06-02 21:03:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-02 21:03:01 [INFO]: Finished training. The best model is from epoch#46.
2024-06-02 21:03:02 [INFO]: Saved the model to results_point_rate05/ItalyAir/Informer_ItalyAir/round_4/20240602_T210055/Informer.pypots
2024-06-02 21:03:03 [INFO]: Successfully saved to results_point_rate05/ItalyAir/Informer_ItalyAir/round_4/imputation.pkl
2024-06-02 21:03:03 [INFO]: Round4 - Informer on ItalyAir: MAE=0.3066, MSE=0.2511, MRE=0.4010
2024-06-02 21:03:03 [INFO]: Done! Final results:
Averaged Informer (10,540,045 params) on ItalyAir: MAE=0.3036 ± 0.007036923145893106, MSE=0.2466 ± 0.015489904546091074, MRE=0.3970 ± 0.009202122434672853, average inference time=0.42
