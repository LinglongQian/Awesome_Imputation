2024-06-03 03:58:19 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:58:19 [INFO]: Using the given device: cuda:0
2024-06-03 03:58:19 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T035819
2024-06-03 03:58:19 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T035819/tensorboard
2024-06-03 03:58:20 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 03:58:31 [INFO]: Epoch 001 - training loss: 1.7012, validation loss: 1.3010
2024-06-03 03:58:39 [INFO]: Epoch 002 - training loss: 1.6525, validation loss: 1.2258
2024-06-03 03:58:47 [INFO]: Epoch 003 - training loss: 1.6072, validation loss: 1.1712
2024-06-03 03:58:56 [INFO]: Epoch 004 - training loss: 1.5711, validation loss: 1.1340
2024-06-03 03:59:05 [INFO]: Epoch 005 - training loss: 1.5407, validation loss: 1.1080
2024-06-03 03:59:13 [INFO]: Epoch 006 - training loss: 1.5120, validation loss: 1.0903
2024-06-03 03:59:22 [INFO]: Epoch 007 - training loss: 1.4918, validation loss: 1.0796
2024-06-03 03:59:30 [INFO]: Epoch 008 - training loss: 1.4691, validation loss: 1.0725
2024-06-03 03:59:39 [INFO]: Epoch 009 - training loss: 1.4485, validation loss: 1.0676
2024-06-03 03:59:47 [INFO]: Epoch 010 - training loss: 1.4357, validation loss: 1.0638
2024-06-03 03:59:56 [INFO]: Epoch 011 - training loss: 1.4197, validation loss: 1.0606
2024-06-03 04:00:05 [INFO]: Epoch 012 - training loss: 1.4030, validation loss: 1.0576
2024-06-03 04:00:13 [INFO]: Epoch 013 - training loss: 1.3955, validation loss: 1.0541
2024-06-03 04:00:21 [INFO]: Epoch 014 - training loss: 1.3873, validation loss: 1.0517
2024-06-03 04:00:30 [INFO]: Epoch 015 - training loss: 1.3760, validation loss: 1.0497
2024-06-03 04:00:38 [INFO]: Epoch 016 - training loss: 1.3687, validation loss: 1.0465
2024-06-03 04:00:47 [INFO]: Epoch 017 - training loss: 1.3623, validation loss: 1.0448
2024-06-03 04:00:56 [INFO]: Epoch 018 - training loss: 1.3525, validation loss: 1.0431
2024-06-03 04:01:04 [INFO]: Epoch 019 - training loss: 1.3452, validation loss: 1.0408
2024-06-03 04:01:12 [INFO]: Epoch 020 - training loss: 1.3377, validation loss: 1.0395
2024-06-03 04:01:21 [INFO]: Epoch 021 - training loss: 1.3340, validation loss: 1.0377
2024-06-03 04:01:30 [INFO]: Epoch 022 - training loss: 1.3286, validation loss: 1.0367
2024-06-03 04:01:39 [INFO]: Epoch 023 - training loss: 1.3233, validation loss: 1.0348
2024-06-03 04:01:47 [INFO]: Epoch 024 - training loss: 1.3205, validation loss: 1.0351
2024-06-03 04:01:55 [INFO]: Epoch 025 - training loss: 1.3118, validation loss: 1.0332
2024-06-03 04:02:04 [INFO]: Epoch 026 - training loss: 1.3088, validation loss: 1.0330
2024-06-03 04:02:12 [INFO]: Epoch 027 - training loss: 1.3023, validation loss: 1.0319
2024-06-03 04:02:21 [INFO]: Epoch 028 - training loss: 1.3000, validation loss: 1.0320
2024-06-03 04:02:29 [INFO]: Epoch 029 - training loss: 1.2975, validation loss: 1.0313
2024-06-03 04:02:37 [INFO]: Epoch 030 - training loss: 1.2915, validation loss: 1.0303
2024-06-03 04:02:46 [INFO]: Epoch 031 - training loss: 1.2843, validation loss: 1.0300
2024-06-03 04:02:55 [INFO]: Epoch 032 - training loss: 1.2845, validation loss: 1.0293
2024-06-03 04:03:03 [INFO]: Epoch 033 - training loss: 1.2795, validation loss: 1.0295
2024-06-03 04:03:12 [INFO]: Epoch 034 - training loss: 1.2785, validation loss: 1.0297
2024-06-03 04:03:20 [INFO]: Epoch 035 - training loss: 1.2762, validation loss: 1.0294
2024-06-03 04:03:29 [INFO]: Epoch 036 - training loss: 1.2695, validation loss: 1.0297
2024-06-03 04:03:38 [INFO]: Epoch 037 - training loss: 1.2687, validation loss: 1.0299
2024-06-03 04:03:46 [INFO]: Epoch 038 - training loss: 1.2667, validation loss: 1.0305
2024-06-03 04:03:55 [INFO]: Epoch 039 - training loss: 1.2669, validation loss: 1.0294
2024-06-03 04:04:04 [INFO]: Epoch 040 - training loss: 1.2617, validation loss: 1.0303
2024-06-03 04:04:12 [INFO]: Epoch 041 - training loss: 1.2587, validation loss: 1.0293
2024-06-03 04:04:21 [INFO]: Epoch 042 - training loss: 1.2562, validation loss: 1.0297
2024-06-03 04:04:29 [INFO]: Epoch 043 - training loss: 1.2557, validation loss: 1.0294
2024-06-03 04:04:37 [INFO]: Epoch 044 - training loss: 1.2513, validation loss: 1.0285
2024-06-03 04:04:45 [INFO]: Epoch 045 - training loss: 1.2516, validation loss: 1.0295
2024-06-03 04:04:53 [INFO]: Epoch 046 - training loss: 1.2499, validation loss: 1.0290
2024-06-03 04:05:01 [INFO]: Epoch 047 - training loss: 1.2489, validation loss: 1.0298
2024-06-03 04:05:08 [INFO]: Epoch 048 - training loss: 1.2443, validation loss: 1.0304
2024-06-03 04:05:16 [INFO]: Epoch 049 - training loss: 1.2449, validation loss: 1.0306
2024-06-03 04:05:24 [INFO]: Epoch 050 - training loss: 1.2432, validation loss: 1.0322
2024-06-03 04:05:32 [INFO]: Epoch 051 - training loss: 1.2430, validation loss: 1.0313
2024-06-03 04:05:40 [INFO]: Epoch 052 - training loss: 1.2409, validation loss: 1.0322
2024-06-03 04:05:48 [INFO]: Epoch 053 - training loss: 1.2390, validation loss: 1.0333
2024-06-03 04:05:56 [INFO]: Epoch 054 - training loss: 1.2380, validation loss: 1.0317
2024-06-03 04:05:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:05:56 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 04:05:56 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_0/20240603_T035819/Autoformer.pypots
2024-06-03 04:05:58 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_0/imputation.pkl
2024-06-03 04:05:58 [INFO]: Round0 - Autoformer on BeijingAir: MAE=0.6871, MSE=1.0848, MRE=0.9379
2024-06-03 04:05:58 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:05:58 [INFO]: Using the given device: cuda:0
2024-06-03 04:05:58 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T040558
2024-06-03 04:05:58 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T040558/tensorboard
2024-06-03 04:05:58 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 04:06:06 [INFO]: Epoch 001 - training loss: 1.7060, validation loss: 1.3114
2024-06-03 04:06:14 [INFO]: Epoch 002 - training loss: 1.6547, validation loss: 1.2388
2024-06-03 04:06:22 [INFO]: Epoch 003 - training loss: 1.6107, validation loss: 1.1865
2024-06-03 04:06:29 [INFO]: Epoch 004 - training loss: 1.5741, validation loss: 1.1440
2024-06-03 04:06:36 [INFO]: Epoch 005 - training loss: 1.5442, validation loss: 1.1143
2024-06-03 04:06:43 [INFO]: Epoch 006 - training loss: 1.5132, validation loss: 1.0959
2024-06-03 04:06:50 [INFO]: Epoch 007 - training loss: 1.4907, validation loss: 1.0822
2024-06-03 04:06:57 [INFO]: Epoch 008 - training loss: 1.4697, validation loss: 1.0739
2024-06-03 04:07:04 [INFO]: Epoch 009 - training loss: 1.4480, validation loss: 1.0678
2024-06-03 04:07:12 [INFO]: Epoch 010 - training loss: 1.4329, validation loss: 1.0640
2024-06-03 04:07:19 [INFO]: Epoch 011 - training loss: 1.4182, validation loss: 1.0603
2024-06-03 04:07:26 [INFO]: Epoch 012 - training loss: 1.4035, validation loss: 1.0573
2024-06-03 04:07:33 [INFO]: Epoch 013 - training loss: 1.3948, validation loss: 1.0542
2024-06-03 04:07:40 [INFO]: Epoch 014 - training loss: 1.3823, validation loss: 1.0526
2024-06-03 04:07:47 [INFO]: Epoch 015 - training loss: 1.3731, validation loss: 1.0501
2024-06-03 04:07:54 [INFO]: Epoch 016 - training loss: 1.3666, validation loss: 1.0482
2024-06-03 04:08:01 [INFO]: Epoch 017 - training loss: 1.3593, validation loss: 1.0474
2024-06-03 04:08:09 [INFO]: Epoch 018 - training loss: 1.3519, validation loss: 1.0451
2024-06-03 04:08:16 [INFO]: Epoch 019 - training loss: 1.3450, validation loss: 1.0442
2024-06-03 04:08:23 [INFO]: Epoch 020 - training loss: 1.3406, validation loss: 1.0428
2024-06-03 04:08:30 [INFO]: Epoch 021 - training loss: 1.3326, validation loss: 1.0424
2024-06-03 04:08:37 [INFO]: Epoch 022 - training loss: 1.3287, validation loss: 1.0417
2024-06-03 04:08:44 [INFO]: Epoch 023 - training loss: 1.3233, validation loss: 1.0419
2024-06-03 04:08:52 [INFO]: Epoch 024 - training loss: 1.3159, validation loss: 1.0391
2024-06-03 04:08:59 [INFO]: Epoch 025 - training loss: 1.3128, validation loss: 1.0408
2024-06-03 04:09:06 [INFO]: Epoch 026 - training loss: 1.3077, validation loss: 1.0398
2024-06-03 04:09:13 [INFO]: Epoch 027 - training loss: 1.3020, validation loss: 1.0395
2024-06-03 04:09:20 [INFO]: Epoch 028 - training loss: 1.3015, validation loss: 1.0391
2024-06-03 04:09:28 [INFO]: Epoch 029 - training loss: 1.2947, validation loss: 1.0393
2024-06-03 04:09:35 [INFO]: Epoch 030 - training loss: 1.2948, validation loss: 1.0398
2024-06-03 04:09:42 [INFO]: Epoch 031 - training loss: 1.2866, validation loss: 1.0406
2024-06-03 04:09:49 [INFO]: Epoch 032 - training loss: 1.2809, validation loss: 1.0392
2024-06-03 04:09:56 [INFO]: Epoch 033 - training loss: 1.2800, validation loss: 1.0399
2024-06-03 04:10:02 [INFO]: Epoch 034 - training loss: 1.2773, validation loss: 1.0404
2024-06-03 04:10:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:10:02 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 04:10:02 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_1/20240603_T040558/Autoformer.pypots
2024-06-03 04:10:03 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_1/imputation.pkl
2024-06-03 04:10:03 [INFO]: Round1 - Autoformer on BeijingAir: MAE=0.6979, MSE=1.0955, MRE=0.9526
2024-06-03 04:10:03 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:10:03 [INFO]: Using the given device: cuda:0
2024-06-03 04:10:03 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T041003
2024-06-03 04:10:03 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T041003/tensorboard
2024-06-03 04:10:03 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 04:10:09 [INFO]: Epoch 001 - training loss: 1.7061, validation loss: 1.2941
2024-06-03 04:10:15 [INFO]: Epoch 002 - training loss: 1.6545, validation loss: 1.2150
2024-06-03 04:10:21 [INFO]: Epoch 003 - training loss: 1.6121, validation loss: 1.1555
2024-06-03 04:10:27 [INFO]: Epoch 004 - training loss: 1.5706, validation loss: 1.1160
2024-06-03 04:10:33 [INFO]: Epoch 005 - training loss: 1.5364, validation loss: 1.0925
2024-06-03 04:10:39 [INFO]: Epoch 006 - training loss: 1.5070, validation loss: 1.0807
2024-06-03 04:10:45 [INFO]: Epoch 007 - training loss: 1.4841, validation loss: 1.0746
2024-06-03 04:10:51 [INFO]: Epoch 008 - training loss: 1.4626, validation loss: 1.0698
2024-06-03 04:10:56 [INFO]: Epoch 009 - training loss: 1.4518, validation loss: 1.0664
2024-06-03 04:11:02 [INFO]: Epoch 010 - training loss: 1.4321, validation loss: 1.0629
2024-06-03 04:11:08 [INFO]: Epoch 011 - training loss: 1.4166, validation loss: 1.0597
2024-06-03 04:11:14 [INFO]: Epoch 012 - training loss: 1.4082, validation loss: 1.0553
2024-06-03 04:11:20 [INFO]: Epoch 013 - training loss: 1.3920, validation loss: 1.0527
2024-06-03 04:11:26 [INFO]: Epoch 014 - training loss: 1.3856, validation loss: 1.0500
2024-06-03 04:11:32 [INFO]: Epoch 015 - training loss: 1.3750, validation loss: 1.0477
2024-06-03 04:11:38 [INFO]: Epoch 016 - training loss: 1.3679, validation loss: 1.0464
2024-06-03 04:11:44 [INFO]: Epoch 017 - training loss: 1.3608, validation loss: 1.0443
2024-06-03 04:11:50 [INFO]: Epoch 018 - training loss: 1.3565, validation loss: 1.0429
2024-06-03 04:11:56 [INFO]: Epoch 019 - training loss: 1.3482, validation loss: 1.0413
2024-06-03 04:12:02 [INFO]: Epoch 020 - training loss: 1.3406, validation loss: 1.0396
2024-06-03 04:12:08 [INFO]: Epoch 021 - training loss: 1.3378, validation loss: 1.0380
2024-06-03 04:12:14 [INFO]: Epoch 022 - training loss: 1.3306, validation loss: 1.0377
2024-06-03 04:12:20 [INFO]: Epoch 023 - training loss: 1.3231, validation loss: 1.0372
2024-06-03 04:12:26 [INFO]: Epoch 024 - training loss: 1.3193, validation loss: 1.0355
2024-06-03 04:12:32 [INFO]: Epoch 025 - training loss: 1.3163, validation loss: 1.0342
2024-06-03 04:12:38 [INFO]: Epoch 026 - training loss: 1.3109, validation loss: 1.0333
2024-06-03 04:12:44 [INFO]: Epoch 027 - training loss: 1.3055, validation loss: 1.0329
2024-06-03 04:12:50 [INFO]: Epoch 028 - training loss: 1.3001, validation loss: 1.0318
2024-06-03 04:12:56 [INFO]: Epoch 029 - training loss: 1.2963, validation loss: 1.0313
2024-06-03 04:13:02 [INFO]: Epoch 030 - training loss: 1.2923, validation loss: 1.0307
2024-06-03 04:13:08 [INFO]: Epoch 031 - training loss: 1.2903, validation loss: 1.0300
2024-06-03 04:13:14 [INFO]: Epoch 032 - training loss: 1.2861, validation loss: 1.0294
2024-06-03 04:13:20 [INFO]: Epoch 033 - training loss: 1.2805, validation loss: 1.0291
2024-06-03 04:13:26 [INFO]: Epoch 034 - training loss: 1.2788, validation loss: 1.0290
2024-06-03 04:13:32 [INFO]: Epoch 035 - training loss: 1.2771, validation loss: 1.0286
2024-06-03 04:13:38 [INFO]: Epoch 036 - training loss: 1.2712, validation loss: 1.0287
2024-06-03 04:13:44 [INFO]: Epoch 037 - training loss: 1.2685, validation loss: 1.0283
2024-06-03 04:13:50 [INFO]: Epoch 038 - training loss: 1.2686, validation loss: 1.0280
2024-06-03 04:13:55 [INFO]: Epoch 039 - training loss: 1.2669, validation loss: 1.0271
2024-06-03 04:14:01 [INFO]: Epoch 040 - training loss: 1.2631, validation loss: 1.0274
2024-06-03 04:14:07 [INFO]: Epoch 041 - training loss: 1.2646, validation loss: 1.0281
2024-06-03 04:14:13 [INFO]: Epoch 042 - training loss: 1.2601, validation loss: 1.0277
2024-06-03 04:14:19 [INFO]: Epoch 043 - training loss: 1.2580, validation loss: 1.0274
2024-06-03 04:14:25 [INFO]: Epoch 044 - training loss: 1.2572, validation loss: 1.0289
2024-06-03 04:14:31 [INFO]: Epoch 045 - training loss: 1.2554, validation loss: 1.0278
2024-06-03 04:14:37 [INFO]: Epoch 046 - training loss: 1.2503, validation loss: 1.0273
2024-06-03 04:14:43 [INFO]: Epoch 047 - training loss: 1.2520, validation loss: 1.0274
2024-06-03 04:14:49 [INFO]: Epoch 048 - training loss: 1.2499, validation loss: 1.0273
2024-06-03 04:14:54 [INFO]: Epoch 049 - training loss: 1.2468, validation loss: 1.0268
2024-06-03 04:15:00 [INFO]: Epoch 050 - training loss: 1.2470, validation loss: 1.0274
2024-06-03 04:15:06 [INFO]: Epoch 051 - training loss: 1.2432, validation loss: 1.0279
2024-06-03 04:15:12 [INFO]: Epoch 052 - training loss: 1.2418, validation loss: 1.0279
2024-06-03 04:15:18 [INFO]: Epoch 053 - training loss: 1.2420, validation loss: 1.0270
2024-06-03 04:15:24 [INFO]: Epoch 054 - training loss: 1.2403, validation loss: 1.0279
2024-06-03 04:15:29 [INFO]: Epoch 055 - training loss: 1.2389, validation loss: 1.0273
2024-06-03 04:15:35 [INFO]: Epoch 056 - training loss: 1.2378, validation loss: 1.0282
2024-06-03 04:15:41 [INFO]: Epoch 057 - training loss: 1.2358, validation loss: 1.0285
2024-06-03 04:15:47 [INFO]: Epoch 058 - training loss: 1.2372, validation loss: 1.0288
2024-06-03 04:15:53 [INFO]: Epoch 059 - training loss: 1.2337, validation loss: 1.0288
2024-06-03 04:15:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:15:53 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 04:15:53 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_2/20240603_T041003/Autoformer.pypots
2024-06-03 04:15:54 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_2/imputation.pkl
2024-06-03 04:15:54 [INFO]: Round2 - Autoformer on BeijingAir: MAE=0.6876, MSE=1.0828, MRE=0.9385
2024-06-03 04:15:54 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:15:54 [INFO]: Using the given device: cuda:0
2024-06-03 04:15:54 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T041554
2024-06-03 04:15:54 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T041554/tensorboard
2024-06-03 04:15:55 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 04:16:00 [INFO]: Epoch 001 - training loss: 1.7049, validation loss: 1.3087
2024-06-03 04:16:06 [INFO]: Epoch 002 - training loss: 1.6523, validation loss: 1.2366
2024-06-03 04:16:12 [INFO]: Epoch 003 - training loss: 1.6114, validation loss: 1.1802
2024-06-03 04:16:18 [INFO]: Epoch 004 - training loss: 1.5722, validation loss: 1.1415
2024-06-03 04:16:24 [INFO]: Epoch 005 - training loss: 1.5443, validation loss: 1.1151
2024-06-03 04:16:30 [INFO]: Epoch 006 - training loss: 1.5160, validation loss: 1.0978
2024-06-03 04:16:36 [INFO]: Epoch 007 - training loss: 1.4915, validation loss: 1.0850
2024-06-03 04:16:42 [INFO]: Epoch 008 - training loss: 1.4708, validation loss: 1.0780
2024-06-03 04:16:48 [INFO]: Epoch 009 - training loss: 1.4499, validation loss: 1.0716
2024-06-03 04:16:54 [INFO]: Epoch 010 - training loss: 1.4363, validation loss: 1.0679
2024-06-03 04:17:00 [INFO]: Epoch 011 - training loss: 1.4209, validation loss: 1.0645
2024-06-03 04:17:06 [INFO]: Epoch 012 - training loss: 1.4055, validation loss: 1.0634
2024-06-03 04:17:12 [INFO]: Epoch 013 - training loss: 1.3955, validation loss: 1.0599
2024-06-03 04:17:18 [INFO]: Epoch 014 - training loss: 1.3868, validation loss: 1.0576
2024-06-03 04:17:23 [INFO]: Epoch 015 - training loss: 1.3774, validation loss: 1.0569
2024-06-03 04:17:30 [INFO]: Epoch 016 - training loss: 1.3707, validation loss: 1.0547
2024-06-03 04:17:36 [INFO]: Epoch 017 - training loss: 1.3636, validation loss: 1.0530
2024-06-03 04:17:42 [INFO]: Epoch 018 - training loss: 1.3530, validation loss: 1.0516
2024-06-03 04:17:48 [INFO]: Epoch 019 - training loss: 1.3441, validation loss: 1.0500
2024-06-03 04:17:54 [INFO]: Epoch 020 - training loss: 1.3386, validation loss: 1.0487
2024-06-03 04:18:00 [INFO]: Epoch 021 - training loss: 1.3322, validation loss: 1.0465
2024-06-03 04:18:06 [INFO]: Epoch 022 - training loss: 1.3303, validation loss: 1.0463
2024-06-03 04:18:13 [INFO]: Epoch 023 - training loss: 1.3232, validation loss: 1.0448
2024-06-03 04:18:18 [INFO]: Epoch 024 - training loss: 1.3195, validation loss: 1.0444
2024-06-03 04:18:24 [INFO]: Epoch 025 - training loss: 1.3147, validation loss: 1.0431
2024-06-03 04:18:30 [INFO]: Epoch 026 - training loss: 1.3103, validation loss: 1.0428
2024-06-03 04:18:36 [INFO]: Epoch 027 - training loss: 1.3083, validation loss: 1.0421
2024-06-03 04:18:42 [INFO]: Epoch 028 - training loss: 1.3025, validation loss: 1.0406
2024-06-03 04:18:48 [INFO]: Epoch 029 - training loss: 1.2972, validation loss: 1.0409
2024-06-03 04:18:54 [INFO]: Epoch 030 - training loss: 1.2916, validation loss: 1.0403
2024-06-03 04:19:00 [INFO]: Epoch 031 - training loss: 1.2895, validation loss: 1.0389
2024-06-03 04:19:06 [INFO]: Epoch 032 - training loss: 1.2860, validation loss: 1.0389
2024-06-03 04:19:12 [INFO]: Epoch 033 - training loss: 1.2834, validation loss: 1.0396
2024-06-03 04:19:18 [INFO]: Epoch 034 - training loss: 1.2823, validation loss: 1.0380
2024-06-03 04:19:24 [INFO]: Epoch 035 - training loss: 1.2766, validation loss: 1.0368
2024-06-03 04:19:30 [INFO]: Epoch 036 - training loss: 1.2755, validation loss: 1.0372
2024-06-03 04:19:36 [INFO]: Epoch 037 - training loss: 1.2729, validation loss: 1.0376
2024-06-03 04:19:42 [INFO]: Epoch 038 - training loss: 1.2678, validation loss: 1.0372
2024-06-03 04:19:48 [INFO]: Epoch 039 - training loss: 1.2644, validation loss: 1.0372
2024-06-03 04:19:54 [INFO]: Epoch 040 - training loss: 1.2633, validation loss: 1.0386
2024-06-03 04:19:59 [INFO]: Epoch 041 - training loss: 1.2605, validation loss: 1.0381
2024-06-03 04:20:05 [INFO]: Epoch 042 - training loss: 1.2591, validation loss: 1.0389
2024-06-03 04:20:11 [INFO]: Epoch 043 - training loss: 1.2571, validation loss: 1.0390
2024-06-03 04:20:18 [INFO]: Epoch 044 - training loss: 1.2538, validation loss: 1.0387
2024-06-03 04:20:23 [INFO]: Epoch 045 - training loss: 1.2544, validation loss: 1.0387
2024-06-03 04:20:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:20:23 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 04:20:24 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_3/20240603_T041554/Autoformer.pypots
2024-06-03 04:20:25 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_3/imputation.pkl
2024-06-03 04:20:25 [INFO]: Round3 - Autoformer on BeijingAir: MAE=0.6932, MSE=1.0939, MRE=0.9462
2024-06-03 04:20:25 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:20:25 [INFO]: Using the given device: cuda:0
2024-06-03 04:20:25 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T042025
2024-06-03 04:20:25 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T042025/tensorboard
2024-06-03 04:20:25 [INFO]: Autoformer initialized with the given hyperparameters, the number of trainable parameters: 6,700,164
2024-06-03 04:20:31 [INFO]: Epoch 001 - training loss: 1.7053, validation loss: 1.2997
2024-06-03 04:20:37 [INFO]: Epoch 002 - training loss: 1.6526, validation loss: 1.2196
2024-06-03 04:20:43 [INFO]: Epoch 003 - training loss: 1.6122, validation loss: 1.1578
2024-06-03 04:20:49 [INFO]: Epoch 004 - training loss: 1.5691, validation loss: 1.1165
2024-06-03 04:20:55 [INFO]: Epoch 005 - training loss: 1.5348, validation loss: 1.0923
2024-06-03 04:21:01 [INFO]: Epoch 006 - training loss: 1.5073, validation loss: 1.0800
2024-06-03 04:21:07 [INFO]: Epoch 007 - training loss: 1.4834, validation loss: 1.0743
2024-06-03 04:21:13 [INFO]: Epoch 008 - training loss: 1.4664, validation loss: 1.0708
2024-06-03 04:21:19 [INFO]: Epoch 009 - training loss: 1.4483, validation loss: 1.0676
2024-06-03 04:21:25 [INFO]: Epoch 010 - training loss: 1.4323, validation loss: 1.0648
2024-06-03 04:21:31 [INFO]: Epoch 011 - training loss: 1.4178, validation loss: 1.0617
2024-06-03 04:21:37 [INFO]: Epoch 012 - training loss: 1.4040, validation loss: 1.0582
2024-06-03 04:21:43 [INFO]: Epoch 013 - training loss: 1.3914, validation loss: 1.0544
2024-06-03 04:21:50 [INFO]: Epoch 014 - training loss: 1.3849, validation loss: 1.0511
2024-06-03 04:21:55 [INFO]: Epoch 015 - training loss: 1.3729, validation loss: 1.0479
2024-06-03 04:22:01 [INFO]: Epoch 016 - training loss: 1.3648, validation loss: 1.0462
2024-06-03 04:22:07 [INFO]: Epoch 017 - training loss: 1.3598, validation loss: 1.0438
2024-06-03 04:22:13 [INFO]: Epoch 018 - training loss: 1.3486, validation loss: 1.0414
2024-06-03 04:22:19 [INFO]: Epoch 019 - training loss: 1.3456, validation loss: 1.0400
2024-06-03 04:22:25 [INFO]: Epoch 020 - training loss: 1.3379, validation loss: 1.0385
2024-06-03 04:22:31 [INFO]: Epoch 021 - training loss: 1.3315, validation loss: 1.0367
2024-06-03 04:22:37 [INFO]: Epoch 022 - training loss: 1.3271, validation loss: 1.0352
2024-06-03 04:22:43 [INFO]: Epoch 023 - training loss: 1.3211, validation loss: 1.0339
2024-06-03 04:22:49 [INFO]: Epoch 024 - training loss: 1.3163, validation loss: 1.0334
2024-06-03 04:22:55 [INFO]: Epoch 025 - training loss: 1.3114, validation loss: 1.0321
2024-06-03 04:23:01 [INFO]: Epoch 026 - training loss: 1.3095, validation loss: 1.0314
2024-06-03 04:23:07 [INFO]: Epoch 027 - training loss: 1.3031, validation loss: 1.0302
2024-06-03 04:23:13 [INFO]: Epoch 028 - training loss: 1.3002, validation loss: 1.0302
2024-06-03 04:23:19 [INFO]: Epoch 029 - training loss: 1.2955, validation loss: 1.0292
2024-06-03 04:23:25 [INFO]: Epoch 030 - training loss: 1.2921, validation loss: 1.0291
2024-06-03 04:23:31 [INFO]: Epoch 031 - training loss: 1.2855, validation loss: 1.0281
2024-06-03 04:23:36 [INFO]: Epoch 032 - training loss: 1.2848, validation loss: 1.0277
2024-06-03 04:23:42 [INFO]: Epoch 033 - training loss: 1.2819, validation loss: 1.0274
2024-06-03 04:23:48 [INFO]: Epoch 034 - training loss: 1.2757, validation loss: 1.0273
2024-06-03 04:23:54 [INFO]: Epoch 035 - training loss: 1.2737, validation loss: 1.0272
2024-06-03 04:24:00 [INFO]: Epoch 036 - training loss: 1.2740, validation loss: 1.0268
2024-06-03 04:24:06 [INFO]: Epoch 037 - training loss: 1.2715, validation loss: 1.0266
2024-06-03 04:24:12 [INFO]: Epoch 038 - training loss: 1.2703, validation loss: 1.0263
2024-06-03 04:24:18 [INFO]: Epoch 039 - training loss: 1.2667, validation loss: 1.0261
2024-06-03 04:24:24 [INFO]: Epoch 040 - training loss: 1.2640, validation loss: 1.0255
2024-06-03 04:24:30 [INFO]: Epoch 041 - training loss: 1.2582, validation loss: 1.0261
2024-06-03 04:24:36 [INFO]: Epoch 042 - training loss: 1.2593, validation loss: 1.0258
2024-06-03 04:24:42 [INFO]: Epoch 043 - training loss: 1.2574, validation loss: 1.0258
2024-06-03 04:24:48 [INFO]: Epoch 044 - training loss: 1.2558, validation loss: 1.0264
2024-06-03 04:24:54 [INFO]: Epoch 045 - training loss: 1.2543, validation loss: 1.0264
2024-06-03 04:25:00 [INFO]: Epoch 046 - training loss: 1.2524, validation loss: 1.0259
2024-06-03 04:25:06 [INFO]: Epoch 047 - training loss: 1.2473, validation loss: 1.0266
2024-06-03 04:25:12 [INFO]: Epoch 048 - training loss: 1.2475, validation loss: 1.0266
2024-06-03 04:25:18 [INFO]: Epoch 049 - training loss: 1.2457, validation loss: 1.0265
2024-06-03 04:25:24 [INFO]: Epoch 050 - training loss: 1.2446, validation loss: 1.0270
2024-06-03 04:25:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:25:24 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 04:25:24 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_4/20240603_T042025/Autoformer.pypots
2024-06-03 04:25:25 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Autoformer_BeijingAir/round_4/imputation.pkl
2024-06-03 04:25:25 [INFO]: Round4 - Autoformer on BeijingAir: MAE=0.6911, MSE=1.0806, MRE=0.9433
2024-06-03 04:25:25 [INFO]: Done! Final results:
Averaged Autoformer (6,700,164 params) on BeijingAir: MAE=0.7042 ± 0.00417933934849572, MSE=1.1127 ± 0.00621904835949775, MRE=0.9357 ± 0.005553572566886954, average inference time=0.28