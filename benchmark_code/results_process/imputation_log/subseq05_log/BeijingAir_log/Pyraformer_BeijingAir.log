2024-06-03 12:03:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:03:08 [INFO]: Using the given device: cuda:0
2024-06-03 12:03:09 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T120309
2024-06-03 12:03:09 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T120309/tensorboard
2024-06-03 12:03:10 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 12:03:23 [INFO]: Epoch 001 - training loss: 1.0768, validation loss: 0.4181
2024-06-03 12:03:28 [INFO]: Epoch 002 - training loss: 0.7778, validation loss: 0.3509
2024-06-03 12:03:33 [INFO]: Epoch 003 - training loss: 0.6563, validation loss: 0.3243
2024-06-03 12:03:38 [INFO]: Epoch 004 - training loss: 0.6176, validation loss: 0.3155
2024-06-03 12:03:43 [INFO]: Epoch 005 - training loss: 0.5803, validation loss: 0.2959
2024-06-03 12:03:48 [INFO]: Epoch 006 - training loss: 0.5499, validation loss: 0.2945
2024-06-03 12:03:53 [INFO]: Epoch 007 - training loss: 0.5170, validation loss: 0.2813
2024-06-03 12:03:58 [INFO]: Epoch 008 - training loss: 0.5061, validation loss: 0.2801
2024-06-03 12:04:02 [INFO]: Epoch 009 - training loss: 0.5076, validation loss: 0.2719
2024-06-03 12:04:07 [INFO]: Epoch 010 - training loss: 0.4865, validation loss: 0.2726
2024-06-03 12:04:12 [INFO]: Epoch 011 - training loss: 0.4826, validation loss: 0.2713
2024-06-03 12:04:17 [INFO]: Epoch 012 - training loss: 0.4687, validation loss: 0.2762
2024-06-03 12:04:22 [INFO]: Epoch 013 - training loss: 0.4600, validation loss: 0.2658
2024-06-03 12:04:27 [INFO]: Epoch 014 - training loss: 0.4507, validation loss: 0.2709
2024-06-03 12:04:31 [INFO]: Epoch 015 - training loss: 0.4479, validation loss: 0.2617
2024-06-03 12:04:35 [INFO]: Epoch 016 - training loss: 0.4382, validation loss: 0.2603
2024-06-03 12:04:40 [INFO]: Epoch 017 - training loss: 0.4336, validation loss: 0.2587
2024-06-03 12:04:45 [INFO]: Epoch 018 - training loss: 0.4339, validation loss: 0.2536
2024-06-03 12:04:49 [INFO]: Epoch 019 - training loss: 0.4254, validation loss: 0.2556
2024-06-03 12:04:53 [INFO]: Epoch 020 - training loss: 0.4215, validation loss: 0.2522
2024-06-03 12:04:58 [INFO]: Epoch 021 - training loss: 0.4174, validation loss: 0.2488
2024-06-03 12:05:03 [INFO]: Epoch 022 - training loss: 0.4125, validation loss: 0.2471
2024-06-03 12:05:08 [INFO]: Epoch 023 - training loss: 0.4046, validation loss: 0.2460
2024-06-03 12:05:12 [INFO]: Epoch 024 - training loss: 0.4024, validation loss: 0.2455
2024-06-03 12:05:17 [INFO]: Epoch 025 - training loss: 0.4009, validation loss: 0.2538
2024-06-03 12:05:22 [INFO]: Epoch 026 - training loss: 0.3998, validation loss: 0.2429
2024-06-03 12:05:27 [INFO]: Epoch 027 - training loss: 0.4086, validation loss: 0.2454
2024-06-03 12:05:32 [INFO]: Epoch 028 - training loss: 0.4106, validation loss: 0.2448
2024-06-03 12:05:37 [INFO]: Epoch 029 - training loss: 0.4073, validation loss: 0.2449
2024-06-03 12:05:42 [INFO]: Epoch 030 - training loss: 0.3934, validation loss: 0.2421
2024-06-03 12:05:47 [INFO]: Epoch 031 - training loss: 0.3919, validation loss: 0.2462
2024-06-03 12:05:51 [INFO]: Epoch 032 - training loss: 0.3871, validation loss: 0.2374
2024-06-03 12:05:56 [INFO]: Epoch 033 - training loss: 0.3859, validation loss: 0.2439
2024-06-03 12:06:01 [INFO]: Epoch 034 - training loss: 0.3840, validation loss: 0.2361
2024-06-03 12:06:06 [INFO]: Epoch 035 - training loss: 0.3765, validation loss: 0.2400
2024-06-03 12:06:11 [INFO]: Epoch 036 - training loss: 0.3821, validation loss: 0.2399
2024-06-03 12:06:15 [INFO]: Epoch 037 - training loss: 0.3795, validation loss: 0.2332
2024-06-03 12:06:20 [INFO]: Epoch 038 - training loss: 0.3749, validation loss: 0.2354
2024-06-03 12:06:24 [INFO]: Epoch 039 - training loss: 0.3715, validation loss: 0.2378
2024-06-03 12:06:29 [INFO]: Epoch 040 - training loss: 0.3717, validation loss: 0.2390
2024-06-03 12:06:35 [INFO]: Epoch 041 - training loss: 0.3790, validation loss: 0.2364
2024-06-03 12:06:39 [INFO]: Epoch 042 - training loss: 0.3767, validation loss: 0.2420
2024-06-03 12:06:44 [INFO]: Epoch 043 - training loss: 0.3750, validation loss: 0.2410
2024-06-03 12:06:49 [INFO]: Epoch 044 - training loss: 0.3686, validation loss: 0.2327
2024-06-03 12:06:54 [INFO]: Epoch 045 - training loss: 0.3700, validation loss: 0.2383
2024-06-03 12:06:58 [INFO]: Epoch 046 - training loss: 0.3704, validation loss: 0.2367
2024-06-03 12:07:03 [INFO]: Epoch 047 - training loss: 0.3605, validation loss: 0.2351
2024-06-03 12:07:08 [INFO]: Epoch 048 - training loss: 0.3644, validation loss: 0.2359
2024-06-03 12:07:13 [INFO]: Epoch 049 - training loss: 0.3618, validation loss: 0.2391
2024-06-03 12:07:17 [INFO]: Epoch 050 - training loss: 0.3606, validation loss: 0.2344
2024-06-03 12:07:22 [INFO]: Epoch 051 - training loss: 0.3596, validation loss: 0.2364
2024-06-03 12:07:27 [INFO]: Epoch 052 - training loss: 0.3610, validation loss: 0.2382
2024-06-03 12:07:31 [INFO]: Epoch 053 - training loss: 0.3578, validation loss: 0.2316
2024-06-03 12:07:36 [INFO]: Epoch 054 - training loss: 0.3547, validation loss: 0.2330
2024-06-03 12:07:40 [INFO]: Epoch 055 - training loss: 0.3531, validation loss: 0.2321
2024-06-03 12:07:45 [INFO]: Epoch 056 - training loss: 0.3559, validation loss: 0.2374
2024-06-03 12:07:50 [INFO]: Epoch 057 - training loss: 0.3534, validation loss: 0.2362
2024-06-03 12:07:55 [INFO]: Epoch 058 - training loss: 0.3484, validation loss: 0.2288
2024-06-03 12:08:00 [INFO]: Epoch 059 - training loss: 0.3453, validation loss: 0.2303
2024-06-03 12:08:05 [INFO]: Epoch 060 - training loss: 0.3479, validation loss: 0.2376
2024-06-03 12:08:10 [INFO]: Epoch 061 - training loss: 0.3547, validation loss: 0.2356
2024-06-03 12:08:15 [INFO]: Epoch 062 - training loss: 0.3481, validation loss: 0.2358
2024-06-03 12:08:20 [INFO]: Epoch 063 - training loss: 0.3513, validation loss: 0.2336
2024-06-03 12:08:24 [INFO]: Epoch 064 - training loss: 0.3448, validation loss: 0.2351
2024-06-03 12:08:29 [INFO]: Epoch 065 - training loss: 0.3437, validation loss: 0.2333
2024-06-03 12:08:34 [INFO]: Epoch 066 - training loss: 0.3409, validation loss: 0.2299
2024-06-03 12:08:39 [INFO]: Epoch 067 - training loss: 0.3416, validation loss: 0.2320
2024-06-03 12:08:44 [INFO]: Epoch 068 - training loss: 0.3436, validation loss: 0.2345
2024-06-03 12:08:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:08:44 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 12:08:44 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/20240603_T120309/Pyraformer.pypots
2024-06-03 12:08:46 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_0/imputation.pkl
2024-06-03 12:08:46 [INFO]: Round0 - Pyraformer on BeijingAir: MAE=0.2386, MSE=0.3019, MRE=0.3256
2024-06-03 12:08:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:08:46 [INFO]: Using the given device: cuda:0
2024-06-03 12:08:47 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T120846
2024-06-03 12:08:47 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T120846/tensorboard
2024-06-03 12:08:47 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 12:08:51 [INFO]: Epoch 001 - training loss: 1.0717, validation loss: 0.4402
2024-06-03 12:08:57 [INFO]: Epoch 002 - training loss: 0.7542, validation loss: 0.3591
2024-06-03 12:09:02 [INFO]: Epoch 003 - training loss: 0.6586, validation loss: 0.3264
2024-06-03 12:09:06 [INFO]: Epoch 004 - training loss: 0.6014, validation loss: 0.2960
2024-06-03 12:09:11 [INFO]: Epoch 005 - training loss: 0.5832, validation loss: 0.2965
2024-06-03 12:09:16 [INFO]: Epoch 006 - training loss: 0.5465, validation loss: 0.2862
2024-06-03 12:09:21 [INFO]: Epoch 007 - training loss: 0.5276, validation loss: 0.2881
2024-06-03 12:09:25 [INFO]: Epoch 008 - training loss: 0.5226, validation loss: 0.2746
2024-06-03 12:09:30 [INFO]: Epoch 009 - training loss: 0.4964, validation loss: 0.2699
2024-06-03 12:09:35 [INFO]: Epoch 010 - training loss: 0.4823, validation loss: 0.2748
2024-06-03 12:09:39 [INFO]: Epoch 011 - training loss: 0.4758, validation loss: 0.2677
2024-06-03 12:09:44 [INFO]: Epoch 012 - training loss: 0.4632, validation loss: 0.2668
2024-06-03 12:09:49 [INFO]: Epoch 013 - training loss: 0.4600, validation loss: 0.2726
2024-06-03 12:09:53 [INFO]: Epoch 014 - training loss: 0.4612, validation loss: 0.2654
2024-06-03 12:09:58 [INFO]: Epoch 015 - training loss: 0.4555, validation loss: 0.2691
2024-06-03 12:10:03 [INFO]: Epoch 016 - training loss: 0.4410, validation loss: 0.2649
2024-06-03 12:10:07 [INFO]: Epoch 017 - training loss: 0.4336, validation loss: 0.2613
2024-06-03 12:10:12 [INFO]: Epoch 018 - training loss: 0.4387, validation loss: 0.2585
2024-06-03 12:10:17 [INFO]: Epoch 019 - training loss: 0.4276, validation loss: 0.2664
2024-06-03 12:10:22 [INFO]: Epoch 020 - training loss: 0.4235, validation loss: 0.2586
2024-06-03 12:10:27 [INFO]: Epoch 021 - training loss: 0.4191, validation loss: 0.2497
2024-06-03 12:10:31 [INFO]: Epoch 022 - training loss: 0.4128, validation loss: 0.2608
2024-06-03 12:10:36 [INFO]: Epoch 023 - training loss: 0.4087, validation loss: 0.2449
2024-06-03 12:10:41 [INFO]: Epoch 024 - training loss: 0.4174, validation loss: 0.2535
2024-06-03 12:10:45 [INFO]: Epoch 025 - training loss: 0.4066, validation loss: 0.2487
2024-06-03 12:10:50 [INFO]: Epoch 026 - training loss: 0.4068, validation loss: 0.2527
2024-06-03 12:10:55 [INFO]: Epoch 027 - training loss: 0.3970, validation loss: 0.2434
2024-06-03 12:10:59 [INFO]: Epoch 028 - training loss: 0.4054, validation loss: 0.2417
2024-06-03 12:11:04 [INFO]: Epoch 029 - training loss: 0.3988, validation loss: 0.2507
2024-06-03 12:11:08 [INFO]: Epoch 030 - training loss: 0.4004, validation loss: 0.2506
2024-06-03 12:11:13 [INFO]: Epoch 031 - training loss: 0.3951, validation loss: 0.2414
2024-06-03 12:11:18 [INFO]: Epoch 032 - training loss: 0.3944, validation loss: 0.2450
2024-06-03 12:11:23 [INFO]: Epoch 033 - training loss: 0.3860, validation loss: 0.2352
2024-06-03 12:11:27 [INFO]: Epoch 034 - training loss: 0.3812, validation loss: 0.2555
2024-06-03 12:11:32 [INFO]: Epoch 035 - training loss: 0.3812, validation loss: 0.2416
2024-06-03 12:11:36 [INFO]: Epoch 036 - training loss: 0.3903, validation loss: 0.2445
2024-06-03 12:11:41 [INFO]: Epoch 037 - training loss: 0.3827, validation loss: 0.2365
2024-06-03 12:11:45 [INFO]: Epoch 038 - training loss: 0.3785, validation loss: 0.2415
2024-06-03 12:11:50 [INFO]: Epoch 039 - training loss: 0.3716, validation loss: 0.2428
2024-06-03 12:11:55 [INFO]: Epoch 040 - training loss: 0.3765, validation loss: 0.2468
2024-06-03 12:11:59 [INFO]: Epoch 041 - training loss: 0.3788, validation loss: 0.2417
2024-06-03 12:12:04 [INFO]: Epoch 042 - training loss: 0.3734, validation loss: 0.2436
2024-06-03 12:12:09 [INFO]: Epoch 043 - training loss: 0.3734, validation loss: 0.2412
2024-06-03 12:12:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:12:09 [INFO]: Finished training. The best model is from epoch#33.
2024-06-03 12:12:09 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/20240603_T120846/Pyraformer.pypots
2024-06-03 12:12:11 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_1/imputation.pkl
2024-06-03 12:12:11 [INFO]: Round1 - Pyraformer on BeijingAir: MAE=0.2456, MSE=0.3125, MRE=0.3352
2024-06-03 12:12:11 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:12:11 [INFO]: Using the given device: cuda:0
2024-06-03 12:12:11 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T121211
2024-06-03 12:12:11 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T121211/tensorboard
2024-06-03 12:12:11 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 12:12:17 [INFO]: Epoch 001 - training loss: 1.0856, validation loss: 0.4345
2024-06-03 12:12:21 [INFO]: Epoch 002 - training loss: 0.7820, validation loss: 0.3466
2024-06-03 12:12:26 [INFO]: Epoch 003 - training loss: 0.6498, validation loss: 0.3193
2024-06-03 12:12:31 [INFO]: Epoch 004 - training loss: 0.6049, validation loss: 0.3014
2024-06-03 12:12:35 [INFO]: Epoch 005 - training loss: 0.5720, validation loss: 0.2990
2024-06-03 12:12:40 [INFO]: Epoch 006 - training loss: 0.5500, validation loss: 0.2970
2024-06-03 12:12:45 [INFO]: Epoch 007 - training loss: 0.5381, validation loss: 0.2837
2024-06-03 12:12:50 [INFO]: Epoch 008 - training loss: 0.5141, validation loss: 0.2928
2024-06-03 12:12:55 [INFO]: Epoch 009 - training loss: 0.5166, validation loss: 0.2785
2024-06-03 12:13:00 [INFO]: Epoch 010 - training loss: 0.4910, validation loss: 0.2833
2024-06-03 12:13:04 [INFO]: Epoch 011 - training loss: 0.4721, validation loss: 0.2783
2024-06-03 12:13:10 [INFO]: Epoch 012 - training loss: 0.4687, validation loss: 0.2676
2024-06-03 12:13:14 [INFO]: Epoch 013 - training loss: 0.4657, validation loss: 0.2658
2024-06-03 12:13:19 [INFO]: Epoch 014 - training loss: 0.4555, validation loss: 0.2584
2024-06-03 12:13:24 [INFO]: Epoch 015 - training loss: 0.4510, validation loss: 0.2739
2024-06-03 12:13:29 [INFO]: Epoch 016 - training loss: 0.4457, validation loss: 0.2654
2024-06-03 12:13:33 [INFO]: Epoch 017 - training loss: 0.4363, validation loss: 0.2558
2024-06-03 12:13:38 [INFO]: Epoch 018 - training loss: 0.4281, validation loss: 0.2614
2024-06-03 12:13:43 [INFO]: Epoch 019 - training loss: 0.4183, validation loss: 0.2656
2024-06-03 12:13:47 [INFO]: Epoch 020 - training loss: 0.4262, validation loss: 0.2529
2024-06-03 12:13:52 [INFO]: Epoch 021 - training loss: 0.4283, validation loss: 0.2667
2024-06-03 12:13:57 [INFO]: Epoch 022 - training loss: 0.4147, validation loss: 0.2428
2024-06-03 12:14:02 [INFO]: Epoch 023 - training loss: 0.4079, validation loss: 0.2537
2024-06-03 12:14:06 [INFO]: Epoch 024 - training loss: 0.4032, validation loss: 0.2454
2024-06-03 12:14:11 [INFO]: Epoch 025 - training loss: 0.4002, validation loss: 0.2510
2024-06-03 12:14:16 [INFO]: Epoch 026 - training loss: 0.3987, validation loss: 0.2452
2024-06-03 12:14:20 [INFO]: Epoch 027 - training loss: 0.3967, validation loss: 0.2482
2024-06-03 12:14:25 [INFO]: Epoch 028 - training loss: 0.3998, validation loss: 0.2427
2024-06-03 12:14:29 [INFO]: Epoch 029 - training loss: 0.3886, validation loss: 0.2401
2024-06-03 12:14:34 [INFO]: Epoch 030 - training loss: 0.3982, validation loss: 0.2470
2024-06-03 12:14:39 [INFO]: Epoch 031 - training loss: 0.3901, validation loss: 0.2451
2024-06-03 12:14:44 [INFO]: Epoch 032 - training loss: 0.3922, validation loss: 0.2471
2024-06-03 12:14:49 [INFO]: Epoch 033 - training loss: 0.3861, validation loss: 0.2467
2024-06-03 12:14:53 [INFO]: Epoch 034 - training loss: 0.3814, validation loss: 0.2526
2024-06-03 12:14:58 [INFO]: Epoch 035 - training loss: 0.3763, validation loss: 0.2459
2024-06-03 12:15:02 [INFO]: Epoch 036 - training loss: 0.3807, validation loss: 0.2614
2024-06-03 12:15:07 [INFO]: Epoch 037 - training loss: 0.3837, validation loss: 0.2387
2024-06-03 12:15:12 [INFO]: Epoch 038 - training loss: 0.3721, validation loss: 0.2399
2024-06-03 12:15:15 [INFO]: Epoch 039 - training loss: 0.3742, validation loss: 0.2456
2024-06-03 12:15:18 [INFO]: Epoch 040 - training loss: 0.3726, validation loss: 0.2358
2024-06-03 12:15:21 [INFO]: Epoch 041 - training loss: 0.3705, validation loss: 0.2467
2024-06-03 12:15:24 [INFO]: Epoch 042 - training loss: 0.3657, validation loss: 0.2473
2024-06-03 12:15:26 [INFO]: Epoch 043 - training loss: 0.3669, validation loss: 0.2413
2024-06-03 12:15:29 [INFO]: Epoch 044 - training loss: 0.3608, validation loss: 0.2503
2024-06-03 12:15:32 [INFO]: Epoch 045 - training loss: 0.3648, validation loss: 0.2344
2024-06-03 12:15:36 [INFO]: Epoch 046 - training loss: 0.3700, validation loss: 0.2415
2024-06-03 12:15:39 [INFO]: Epoch 047 - training loss: 0.3709, validation loss: 0.2467
2024-06-03 12:15:43 [INFO]: Epoch 048 - training loss: 0.3642, validation loss: 0.2465
2024-06-03 12:15:47 [INFO]: Epoch 049 - training loss: 0.3707, validation loss: 0.2363
2024-06-03 12:15:51 [INFO]: Epoch 050 - training loss: 0.3665, validation loss: 0.2373
2024-06-03 12:15:54 [INFO]: Epoch 051 - training loss: 0.3639, validation loss: 0.2432
2024-06-03 12:15:58 [INFO]: Epoch 052 - training loss: 0.3611, validation loss: 0.2358
2024-06-03 12:16:02 [INFO]: Epoch 053 - training loss: 0.3559, validation loss: 0.2329
2024-06-03 12:16:05 [INFO]: Epoch 054 - training loss: 0.3558, validation loss: 0.2464
2024-06-03 12:16:08 [INFO]: Epoch 055 - training loss: 0.3554, validation loss: 0.2335
2024-06-03 12:16:11 [INFO]: Epoch 056 - training loss: 0.3569, validation loss: 0.2414
2024-06-03 12:16:15 [INFO]: Epoch 057 - training loss: 0.3585, validation loss: 0.2384
2024-06-03 12:16:18 [INFO]: Epoch 058 - training loss: 0.3589, validation loss: 0.2402
2024-06-03 12:16:22 [INFO]: Epoch 059 - training loss: 0.3502, validation loss: 0.2394
2024-06-03 12:16:26 [INFO]: Epoch 060 - training loss: 0.3504, validation loss: 0.2374
2024-06-03 12:16:30 [INFO]: Epoch 061 - training loss: 0.3478, validation loss: 0.2374
2024-06-03 12:16:33 [INFO]: Epoch 062 - training loss: 0.3440, validation loss: 0.2355
2024-06-03 12:16:37 [INFO]: Epoch 063 - training loss: 0.3454, validation loss: 0.2336
2024-06-03 12:16:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:16:37 [INFO]: Finished training. The best model is from epoch#53.
2024-06-03 12:16:37 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/20240603_T121211/Pyraformer.pypots
2024-06-03 12:16:39 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_2/imputation.pkl
2024-06-03 12:16:39 [INFO]: Round2 - Pyraformer on BeijingAir: MAE=0.2334, MSE=0.2972, MRE=0.3186
2024-06-03 12:16:39 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 12:16:39 [INFO]: Using the given device: cuda:0
2024-06-03 12:16:39 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T121639
2024-06-03 12:16:39 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T121639/tensorboard
2024-06-03 12:16:39 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 12:16:43 [INFO]: Epoch 001 - training loss: 1.0469, validation loss: 0.4383
2024-06-03 12:16:46 [INFO]: Epoch 002 - training loss: 0.7522, validation loss: 0.3769
2024-06-03 12:16:50 [INFO]: Epoch 003 - training loss: 0.6623, validation loss: 0.3172
2024-06-03 12:16:54 [INFO]: Epoch 004 - training loss: 0.5985, validation loss: 0.3089
2024-06-03 12:16:58 [INFO]: Epoch 005 - training loss: 0.5748, validation loss: 0.2952
2024-06-03 12:17:01 [INFO]: Epoch 006 - training loss: 0.5497, validation loss: 0.2889
2024-06-03 12:17:05 [INFO]: Epoch 007 - training loss: 0.5257, validation loss: 0.2800
2024-06-03 12:17:08 [INFO]: Epoch 008 - training loss: 0.5049, validation loss: 0.2783
2024-06-03 12:17:12 [INFO]: Epoch 009 - training loss: 0.4885, validation loss: 0.2775
2024-06-03 12:17:16 [INFO]: Epoch 010 - training loss: 0.4809, validation loss: 0.2679
2024-06-03 12:17:20 [INFO]: Epoch 011 - training loss: 0.4715, validation loss: 0.2689
2024-06-03 12:17:24 [INFO]: Epoch 012 - training loss: 0.4621, validation loss: 0.2690
2024-06-03 12:17:28 [INFO]: Epoch 013 - training loss: 0.4543, validation loss: 0.2637
2024-06-03 12:17:31 [INFO]: Epoch 014 - training loss: 0.4486, validation loss: 0.2716
2024-06-03 12:17:35 [INFO]: Epoch 015 - training loss: 0.4452, validation loss: 0.2583
2024-06-03 12:17:38 [INFO]: Epoch 016 - training loss: 0.4298, validation loss: 0.2617
2024-06-03 12:17:41 [INFO]: Epoch 017 - training loss: 0.4425, validation loss: 0.2711
2024-06-03 12:17:44 [INFO]: Epoch 018 - training loss: 0.4312, validation loss: 0.2538
2024-06-03 12:17:48 [INFO]: Epoch 019 - training loss: 0.4193, validation loss: 0.2513
2024-06-03 12:17:51 [INFO]: Epoch 020 - training loss: 0.4188, validation loss: 0.2597
2024-06-03 12:17:54 [INFO]: Epoch 021 - training loss: 0.4205, validation loss: 0.2565
2024-06-03 12:17:58 [INFO]: Epoch 022 - training loss: 0.4165, validation loss: 0.2460
2024-06-03 12:18:01 [INFO]: Epoch 023 - training loss: 0.4054, validation loss: 0.2448
2024-06-03 12:18:04 [INFO]: Epoch 024 - training loss: 0.4017, validation loss: 0.2465
2024-06-03 12:18:08 [INFO]: Epoch 025 - training loss: 0.4026, validation loss: 0.2468
2024-06-03 12:18:11 [INFO]: Epoch 026 - training loss: 0.3954, validation loss: 0.2433
2024-06-03 12:18:14 [INFO]: Epoch 027 - training loss: 0.3958, validation loss: 0.2427
2024-06-03 12:18:17 [INFO]: Epoch 028 - training loss: 0.3932, validation loss: 0.2534
2024-06-03 12:18:20 [INFO]: Epoch 029 - training loss: 0.3954, validation loss: 0.2432
2024-06-03 12:18:24 [INFO]: Epoch 030 - training loss: 0.3919, validation loss: 0.2489
2024-06-03 12:18:27 [INFO]: Epoch 031 - training loss: 0.3926, validation loss: 0.2626
2024-06-03 12:18:30 [INFO]: Epoch 032 - training loss: 0.3914, validation loss: 0.2400
2024-06-03 12:18:33 [INFO]: Epoch 033 - training loss: 0.3896, validation loss: 0.2434
2024-06-03 12:18:35 [INFO]: Epoch 034 - training loss: 0.3856, validation loss: 0.2358
2024-06-03 12:18:37 [INFO]: Epoch 035 - training loss: 0.3773, validation loss: 0.2328
2024-06-03 12:18:40 [INFO]: Epoch 036 - training loss: 0.3817, validation loss: 0.2382
2024-06-03 12:18:42 [INFO]: Epoch 037 - training loss: 0.3750, validation loss: 0.2301
2024-06-03 12:18:44 [INFO]: Epoch 038 - training loss: 0.3709, validation loss: 0.2473
2024-06-03 12:18:46 [INFO]: Epoch 039 - training loss: 0.3707, validation loss: 0.2327
2024-06-03 12:18:49 [INFO]: Epoch 040 - training loss: 0.3722, validation loss: 0.2383
2024-06-03 12:18:52 [INFO]: Epoch 041 - training loss: 0.3701, validation loss: 0.2312
2024-06-03 12:18:55 [INFO]: Epoch 042 - training loss: 0.3710, validation loss: 0.2501
2024-06-03 12:18:59 [INFO]: Epoch 043 - training loss: 0.3662, validation loss: 0.2387
2024-06-03 12:19:02 [INFO]: Epoch 044 - training loss: 0.3664, validation loss: 0.2471
2024-06-03 12:19:05 [INFO]: Epoch 045 - training loss: 0.3682, validation loss: 0.2422
2024-06-03 12:19:09 [INFO]: Epoch 046 - training loss: 0.3595, validation loss: 0.2289
2024-06-03 12:19:12 [INFO]: Epoch 047 - training loss: 0.3689, validation loss: 0.2381
2024-06-03 12:19:15 [INFO]: Epoch 048 - training loss: 0.3697, validation loss: 0.2576
2024-06-03 12:19:18 [INFO]: Epoch 049 - training loss: 0.3667, validation loss: 0.2340
2024-06-03 12:19:21 [INFO]: Epoch 050 - training loss: 0.3582, validation loss: 0.2332
2024-06-03 12:19:25 [INFO]: Epoch 051 - training loss: 0.3544, validation loss: 0.2327
2024-06-03 12:19:28 [INFO]: Epoch 052 - training loss: 0.3557, validation loss: 0.2317
2024-06-03 12:19:31 [INFO]: Epoch 053 - training loss: 0.3542, validation loss: 0.2335
2024-06-03 12:19:34 [INFO]: Epoch 054 - training loss: 0.3554, validation loss: 0.2404
2024-06-03 12:19:37 [INFO]: Epoch 055 - training loss: 0.3553, validation loss: 0.2345
2024-06-03 12:19:41 [INFO]: Epoch 056 - training loss: 0.3542, validation loss: 0.2343
2024-06-03 12:19:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:19:41 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 12:19:41 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/20240603_T121639/Pyraformer.pypots
2024-06-03 12:19:42 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_3/imputation.pkl
2024-06-03 12:19:42 [INFO]: Round3 - Pyraformer on BeijingAir: MAE=0.2372, MSE=0.2973, MRE=0.3238
2024-06-03 12:19:42 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:19:42 [INFO]: Using the given device: cuda:0
2024-06-03 12:19:42 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T121942
2024-06-03 12:19:42 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T121942/tensorboard
2024-06-03 12:19:42 [INFO]: Pyraformer initialized with the given hyperparameters, the number of trainable parameters: 3,230,212
2024-06-03 12:19:46 [INFO]: Epoch 001 - training loss: 1.1046, validation loss: 0.4282
2024-06-03 12:19:49 [INFO]: Epoch 002 - training loss: 0.7693, validation loss: 0.3614
2024-06-03 12:19:52 [INFO]: Epoch 003 - training loss: 0.6930, validation loss: 0.3427
2024-06-03 12:19:55 [INFO]: Epoch 004 - training loss: 0.6377, validation loss: 0.3048
2024-06-03 12:19:58 [INFO]: Epoch 005 - training loss: 0.5825, validation loss: 0.2979
2024-06-03 12:20:01 [INFO]: Epoch 006 - training loss: 0.5520, validation loss: 0.2903
2024-06-03 12:20:05 [INFO]: Epoch 007 - training loss: 0.5225, validation loss: 0.2851
2024-06-03 12:20:08 [INFO]: Epoch 008 - training loss: 0.5120, validation loss: 0.2903
2024-06-03 12:20:11 [INFO]: Epoch 009 - training loss: 0.4965, validation loss: 0.2746
2024-06-03 12:20:14 [INFO]: Epoch 010 - training loss: 0.4957, validation loss: 0.2788
2024-06-03 12:20:17 [INFO]: Epoch 011 - training loss: 0.4793, validation loss: 0.2727
2024-06-03 12:20:20 [INFO]: Epoch 012 - training loss: 0.4660, validation loss: 0.2692
2024-06-03 12:20:23 [INFO]: Epoch 013 - training loss: 0.4568, validation loss: 0.2663
2024-06-03 12:20:26 [INFO]: Epoch 014 - training loss: 0.4534, validation loss: 0.2679
2024-06-03 12:20:30 [INFO]: Epoch 015 - training loss: 0.4621, validation loss: 0.2623
2024-06-03 12:20:33 [INFO]: Epoch 016 - training loss: 0.4432, validation loss: 0.2576
2024-06-03 12:20:36 [INFO]: Epoch 017 - training loss: 0.4331, validation loss: 0.2528
2024-06-03 12:20:39 [INFO]: Epoch 018 - training loss: 0.4212, validation loss: 0.2564
2024-06-03 12:20:42 [INFO]: Epoch 019 - training loss: 0.4195, validation loss: 0.2523
2024-06-03 12:20:45 [INFO]: Epoch 020 - training loss: 0.4189, validation loss: 0.2499
2024-06-03 12:20:49 [INFO]: Epoch 021 - training loss: 0.4176, validation loss: 0.2519
2024-06-03 12:20:52 [INFO]: Epoch 022 - training loss: 0.4103, validation loss: 0.2500
2024-06-03 12:20:55 [INFO]: Epoch 023 - training loss: 0.4092, validation loss: 0.2496
2024-06-03 12:20:58 [INFO]: Epoch 024 - training loss: 0.4005, validation loss: 0.2472
2024-06-03 12:21:01 [INFO]: Epoch 025 - training loss: 0.4049, validation loss: 0.2442
2024-06-03 12:21:04 [INFO]: Epoch 026 - training loss: 0.4049, validation loss: 0.2461
2024-06-03 12:21:07 [INFO]: Epoch 027 - training loss: 0.3963, validation loss: 0.2494
2024-06-03 12:21:09 [INFO]: Epoch 028 - training loss: 0.3909, validation loss: 0.2400
2024-06-03 12:21:12 [INFO]: Epoch 029 - training loss: 0.3873, validation loss: 0.2398
2024-06-03 12:21:15 [INFO]: Epoch 030 - training loss: 0.3848, validation loss: 0.2434
2024-06-03 12:21:17 [INFO]: Epoch 031 - training loss: 0.3810, validation loss: 0.2370
2024-06-03 12:21:20 [INFO]: Epoch 032 - training loss: 0.3829, validation loss: 0.2469
2024-06-03 12:21:22 [INFO]: Epoch 033 - training loss: 0.3814, validation loss: 0.2383
2024-06-03 12:21:25 [INFO]: Epoch 034 - training loss: 0.3763, validation loss: 0.2399
2024-06-03 12:21:28 [INFO]: Epoch 035 - training loss: 0.3778, validation loss: 0.2399
2024-06-03 12:21:31 [INFO]: Epoch 036 - training loss: 0.3762, validation loss: 0.2444
2024-06-03 12:21:33 [INFO]: Epoch 037 - training loss: 0.3708, validation loss: 0.2349
2024-06-03 12:21:35 [INFO]: Epoch 038 - training loss: 0.3779, validation loss: 0.2351
2024-06-03 12:21:38 [INFO]: Epoch 039 - training loss: 0.3713, validation loss: 0.2317
2024-06-03 12:21:40 [INFO]: Epoch 040 - training loss: 0.3761, validation loss: 0.2394
2024-06-03 12:21:43 [INFO]: Epoch 041 - training loss: 0.3690, validation loss: 0.2368
2024-06-03 12:21:46 [INFO]: Epoch 042 - training loss: 0.3728, validation loss: 0.2458
2024-06-03 12:21:49 [INFO]: Epoch 043 - training loss: 0.3705, validation loss: 0.2322
2024-06-03 12:21:51 [INFO]: Epoch 044 - training loss: 0.3607, validation loss: 0.2315
2024-06-03 12:21:54 [INFO]: Epoch 045 - training loss: 0.3586, validation loss: 0.2328
2024-06-03 12:21:57 [INFO]: Epoch 046 - training loss: 0.3566, validation loss: 0.2313
2024-06-03 12:22:00 [INFO]: Epoch 047 - training loss: 0.3534, validation loss: 0.2343
2024-06-03 12:22:02 [INFO]: Epoch 048 - training loss: 0.3595, validation loss: 0.2353
2024-06-03 12:22:05 [INFO]: Epoch 049 - training loss: 0.3542, validation loss: 0.2315
2024-06-03 12:22:07 [INFO]: Epoch 050 - training loss: 0.3526, validation loss: 0.2342
2024-06-03 12:22:09 [INFO]: Epoch 051 - training loss: 0.3539, validation loss: 0.2347
2024-06-03 12:22:11 [INFO]: Epoch 052 - training loss: 0.3538, validation loss: 0.2302
2024-06-03 12:22:13 [INFO]: Epoch 053 - training loss: 0.3502, validation loss: 0.2284
2024-06-03 12:22:15 [INFO]: Epoch 054 - training loss: 0.3524, validation loss: 0.2365
2024-06-03 12:22:18 [INFO]: Epoch 055 - training loss: 0.3474, validation loss: 0.2312
2024-06-03 12:22:20 [INFO]: Epoch 056 - training loss: 0.3492, validation loss: 0.2257
2024-06-03 12:22:22 [INFO]: Epoch 057 - training loss: 0.3455, validation loss: 0.2295
2024-06-03 12:22:24 [INFO]: Epoch 058 - training loss: 0.3435, validation loss: 0.2322
2024-06-03 12:22:26 [INFO]: Epoch 059 - training loss: 0.3478, validation loss: 0.2281
2024-06-03 12:22:28 [INFO]: Epoch 060 - training loss: 0.3458, validation loss: 0.2269
2024-06-03 12:22:30 [INFO]: Epoch 061 - training loss: 0.3459, validation loss: 0.2260
2024-06-03 12:22:33 [INFO]: Epoch 062 - training loss: 0.3400, validation loss: 0.2277
2024-06-03 12:22:35 [INFO]: Epoch 063 - training loss: 0.3398, validation loss: 0.2253
2024-06-03 12:22:37 [INFO]: Epoch 064 - training loss: 0.3398, validation loss: 0.2280
2024-06-03 12:22:39 [INFO]: Epoch 065 - training loss: 0.3398, validation loss: 0.2261
2024-06-03 12:22:41 [INFO]: Epoch 066 - training loss: 0.3366, validation loss: 0.2285
2024-06-03 12:22:43 [INFO]: Epoch 067 - training loss: 0.3344, validation loss: 0.2254
2024-06-03 12:22:45 [INFO]: Epoch 068 - training loss: 0.3357, validation loss: 0.2246
2024-06-03 12:22:47 [INFO]: Epoch 069 - training loss: 0.3360, validation loss: 0.2291
2024-06-03 12:22:50 [INFO]: Epoch 070 - training loss: 0.3328, validation loss: 0.2272
2024-06-03 12:22:52 [INFO]: Epoch 071 - training loss: 0.3309, validation loss: 0.2267
2024-06-03 12:22:54 [INFO]: Epoch 072 - training loss: 0.3368, validation loss: 0.2238
2024-06-03 12:22:56 [INFO]: Epoch 073 - training loss: 0.3334, validation loss: 0.2271
2024-06-03 12:22:59 [INFO]: Epoch 074 - training loss: 0.3340, validation loss: 0.2345
2024-06-03 12:23:01 [INFO]: Epoch 075 - training loss: 0.3311, validation loss: 0.2251
2024-06-03 12:23:03 [INFO]: Epoch 076 - training loss: 0.3288, validation loss: 0.2270
2024-06-03 12:23:05 [INFO]: Epoch 077 - training loss: 0.3280, validation loss: 0.2264
2024-06-03 12:23:07 [INFO]: Epoch 078 - training loss: 0.3275, validation loss: 0.2249
2024-06-03 12:23:10 [INFO]: Epoch 079 - training loss: 0.3291, validation loss: 0.2313
2024-06-03 12:23:12 [INFO]: Epoch 080 - training loss: 0.3303, validation loss: 0.2244
2024-06-03 12:23:14 [INFO]: Epoch 081 - training loss: 0.3307, validation loss: 0.2220
2024-06-03 12:23:16 [INFO]: Epoch 082 - training loss: 0.3285, validation loss: 0.2255
2024-06-03 12:23:18 [INFO]: Epoch 083 - training loss: 0.3314, validation loss: 0.2211
2024-06-03 12:23:21 [INFO]: Epoch 084 - training loss: 0.3292, validation loss: 0.2220
2024-06-03 12:23:23 [INFO]: Epoch 085 - training loss: 0.3285, validation loss: 0.2229
2024-06-03 12:23:25 [INFO]: Epoch 086 - training loss: 0.3288, validation loss: 0.2225
2024-06-03 12:23:28 [INFO]: Epoch 087 - training loss: 0.3241, validation loss: 0.2235
2024-06-03 12:23:30 [INFO]: Epoch 088 - training loss: 0.3209, validation loss: 0.2195
2024-06-03 12:23:32 [INFO]: Epoch 089 - training loss: 0.3221, validation loss: 0.2237
2024-06-03 12:23:34 [INFO]: Epoch 090 - training loss: 0.3216, validation loss: 0.2164
2024-06-03 12:23:36 [INFO]: Epoch 091 - training loss: 0.3188, validation loss: 0.2223
2024-06-03 12:23:38 [INFO]: Epoch 092 - training loss: 0.3199, validation loss: 0.2216
2024-06-03 12:23:40 [INFO]: Epoch 093 - training loss: 0.3188, validation loss: 0.2155
2024-06-03 12:23:41 [INFO]: Epoch 094 - training loss: 0.3163, validation loss: 0.2202
2024-06-03 12:23:43 [INFO]: Epoch 095 - training loss: 0.3169, validation loss: 0.2157
2024-06-03 12:23:45 [INFO]: Epoch 096 - training loss: 0.3164, validation loss: 0.2191
2024-06-03 12:23:46 [INFO]: Epoch 097 - training loss: 0.3171, validation loss: 0.2252
2024-06-03 12:23:46 [INFO]: Epoch 098 - training loss: 0.3179, validation loss: 0.2200
2024-06-03 12:23:48 [INFO]: Epoch 099 - training loss: 0.3197, validation loss: 0.2187
2024-06-03 12:23:51 [INFO]: Epoch 100 - training loss: 0.3192, validation loss: 0.2185
2024-06-03 12:23:51 [INFO]: Finished training. The best model is from epoch#93.
2024-06-03 12:23:51 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/20240603_T121942/Pyraformer.pypots
2024-06-03 12:23:51 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Pyraformer_BeijingAir/round_4/imputation.pkl
2024-06-03 12:23:51 [INFO]: Round4 - Pyraformer on BeijingAir: MAE=0.2239, MSE=0.2853, MRE=0.3056
2024-06-03 12:23:51 [INFO]: Done! Final results:
Averaged Pyraformer (3,230,212 params) on BeijingAir: MAE=0.2265 ± 0.00752730423110388, MSE=0.2896 ± 0.009478165302982256, MRE=0.3010 ± 0.010002401526814867, average inference time=0.34