2024-06-03 10:37:03 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 10:37:03 [INFO]: Using the given device: cuda:0
2024-06-03 10:37:04 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T103704
2024-06-03 10:37:04 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T103704/tensorboard
2024-06-03 10:37:05 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 10:37:15 [INFO]: Epoch 001 - training loss: 0.6303, validation loss: 0.5022
2024-06-03 10:37:21 [INFO]: Epoch 002 - training loss: 0.5508, validation loss: 0.4628
2024-06-03 10:37:27 [INFO]: Epoch 003 - training loss: 0.5337, validation loss: 0.4603
2024-06-03 10:37:33 [INFO]: Epoch 004 - training loss: 0.5270, validation loss: 0.4657
2024-06-03 10:37:39 [INFO]: Epoch 005 - training loss: 0.5214, validation loss: 0.4735
2024-06-03 10:37:45 [INFO]: Epoch 006 - training loss: 0.5158, validation loss: 0.4512
2024-06-03 10:37:51 [INFO]: Epoch 007 - training loss: 0.5105, validation loss: 0.4516
2024-06-03 10:37:57 [INFO]: Epoch 008 - training loss: 0.5062, validation loss: 0.4606
2024-06-03 10:38:03 [INFO]: Epoch 009 - training loss: 0.5027, validation loss: 0.4498
2024-06-03 10:38:09 [INFO]: Epoch 010 - training loss: 0.5006, validation loss: 0.4428
2024-06-03 10:38:14 [INFO]: Epoch 011 - training loss: 0.4977, validation loss: 0.4476
2024-06-03 10:38:20 [INFO]: Epoch 012 - training loss: 0.4934, validation loss: 0.4412
2024-06-03 10:38:26 [INFO]: Epoch 013 - training loss: 0.4902, validation loss: 0.4407
2024-06-03 10:38:31 [INFO]: Epoch 014 - training loss: 0.4877, validation loss: 0.4452
2024-06-03 10:38:37 [INFO]: Epoch 015 - training loss: 0.4858, validation loss: 0.4498
2024-06-03 10:38:43 [INFO]: Epoch 016 - training loss: 0.4844, validation loss: 0.4413
2024-06-03 10:38:48 [INFO]: Epoch 017 - training loss: 0.4810, validation loss: 0.4508
2024-06-03 10:38:54 [INFO]: Epoch 018 - training loss: 0.4787, validation loss: 0.4473
2024-06-03 10:39:00 [INFO]: Epoch 019 - training loss: 0.4776, validation loss: 0.4496
2024-06-03 10:39:06 [INFO]: Epoch 020 - training loss: 0.4751, validation loss: 0.4452
2024-06-03 10:39:11 [INFO]: Epoch 021 - training loss: 0.4749, validation loss: 0.4498
2024-06-03 10:39:17 [INFO]: Epoch 022 - training loss: 0.4715, validation loss: 0.4403
2024-06-03 10:39:23 [INFO]: Epoch 023 - training loss: 0.4698, validation loss: 0.4411
2024-06-03 10:39:28 [INFO]: Epoch 024 - training loss: 0.4682, validation loss: 0.4386
2024-06-03 10:39:34 [INFO]: Epoch 025 - training loss: 0.4663, validation loss: 0.4382
2024-06-03 10:39:40 [INFO]: Epoch 026 - training loss: 0.4640, validation loss: 0.4431
2024-06-03 10:39:46 [INFO]: Epoch 027 - training loss: 0.4627, validation loss: 0.4439
2024-06-03 10:39:52 [INFO]: Epoch 028 - training loss: 0.4623, validation loss: 0.4408
2024-06-03 10:39:57 [INFO]: Epoch 029 - training loss: 0.4597, validation loss: 0.4405
2024-06-03 10:40:03 [INFO]: Epoch 030 - training loss: 0.4597, validation loss: 0.4407
2024-06-03 10:40:09 [INFO]: Epoch 031 - training loss: 0.4591, validation loss: 0.4416
2024-06-03 10:40:15 [INFO]: Epoch 032 - training loss: 0.4555, validation loss: 0.4369
2024-06-03 10:40:21 [INFO]: Epoch 033 - training loss: 0.4547, validation loss: 0.4374
2024-06-03 10:40:27 [INFO]: Epoch 034 - training loss: 0.4524, validation loss: 0.4429
2024-06-03 10:40:32 [INFO]: Epoch 035 - training loss: 0.4514, validation loss: 0.4432
2024-06-03 10:40:38 [INFO]: Epoch 036 - training loss: 0.4507, validation loss: 0.4476
2024-06-03 10:40:44 [INFO]: Epoch 037 - training loss: 0.4492, validation loss: 0.4542
2024-06-03 10:40:49 [INFO]: Epoch 038 - training loss: 0.4476, validation loss: 0.4456
2024-06-03 10:40:55 [INFO]: Epoch 039 - training loss: 0.4462, validation loss: 0.4529
2024-06-03 10:41:01 [INFO]: Epoch 040 - training loss: 0.4460, validation loss: 0.4450
2024-06-03 10:41:07 [INFO]: Epoch 041 - training loss: 0.4449, validation loss: 0.4472
2024-06-03 10:41:13 [INFO]: Epoch 042 - training loss: 0.4416, validation loss: 0.4387
2024-06-03 10:41:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:41:13 [INFO]: Finished training. The best model is from epoch#32.
2024-06-03 10:41:13 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/20240603_T103704/NonstationaryTransformer.pypots
2024-06-03 10:41:15 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_0/imputation.pkl
2024-06-03 10:41:15 [INFO]: Round0 - NonstationaryTransformer on BeijingAir: MAE=0.3461, MSE=0.4634, MRE=0.4725
2024-06-03 10:41:15 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 10:41:15 [INFO]: Using the given device: cuda:0
2024-06-03 10:41:15 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T104115
2024-06-03 10:41:15 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T104115/tensorboard
2024-06-03 10:41:16 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 10:41:21 [INFO]: Epoch 001 - training loss: 0.6246, validation loss: 0.4876
2024-06-03 10:41:27 [INFO]: Epoch 002 - training loss: 0.5508, validation loss: 0.4784
2024-06-03 10:41:33 [INFO]: Epoch 003 - training loss: 0.5349, validation loss: 0.4735
2024-06-03 10:41:39 [INFO]: Epoch 004 - training loss: 0.5253, validation loss: 0.4772
2024-06-03 10:41:44 [INFO]: Epoch 005 - training loss: 0.5209, validation loss: 0.4826
2024-06-03 10:41:50 [INFO]: Epoch 006 - training loss: 0.5145, validation loss: 0.4670
2024-06-03 10:41:56 [INFO]: Epoch 007 - training loss: 0.5096, validation loss: 0.4823
2024-06-03 10:42:02 [INFO]: Epoch 008 - training loss: 0.5077, validation loss: 0.4510
2024-06-03 10:42:08 [INFO]: Epoch 009 - training loss: 0.5031, validation loss: 0.4677
2024-06-03 10:42:14 [INFO]: Epoch 010 - training loss: 0.5009, validation loss: 0.4564
2024-06-03 10:42:19 [INFO]: Epoch 011 - training loss: 0.4954, validation loss: 0.4536
2024-06-03 10:42:25 [INFO]: Epoch 012 - training loss: 0.4913, validation loss: 0.4511
2024-06-03 10:42:31 [INFO]: Epoch 013 - training loss: 0.4910, validation loss: 0.4708
2024-06-03 10:42:37 [INFO]: Epoch 014 - training loss: 0.4866, validation loss: 0.4585
2024-06-03 10:42:42 [INFO]: Epoch 015 - training loss: 0.4856, validation loss: 0.4548
2024-06-03 10:42:47 [INFO]: Epoch 016 - training loss: 0.4842, validation loss: 0.4494
2024-06-03 10:42:53 [INFO]: Epoch 017 - training loss: 0.4806, validation loss: 0.4492
2024-06-03 10:42:59 [INFO]: Epoch 018 - training loss: 0.4814, validation loss: 0.4577
2024-06-03 10:43:05 [INFO]: Epoch 019 - training loss: 0.4782, validation loss: 0.4893
2024-06-03 10:43:10 [INFO]: Epoch 020 - training loss: 0.4760, validation loss: 0.4648
2024-06-03 10:43:16 [INFO]: Epoch 021 - training loss: 0.4712, validation loss: 0.4498
2024-06-03 10:43:22 [INFO]: Epoch 022 - training loss: 0.4711, validation loss: 0.4642
2024-06-03 10:43:27 [INFO]: Epoch 023 - training loss: 0.4702, validation loss: 0.4635
2024-06-03 10:43:33 [INFO]: Epoch 024 - training loss: 0.4690, validation loss: 0.4584
2024-06-03 10:43:39 [INFO]: Epoch 025 - training loss: 0.4645, validation loss: 0.4578
2024-06-03 10:43:45 [INFO]: Epoch 026 - training loss: 0.4637, validation loss: 0.4572
2024-06-03 10:43:50 [INFO]: Epoch 027 - training loss: 0.4623, validation loss: 0.4520
2024-06-03 10:43:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:43:50 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 10:43:50 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/20240603_T104115/NonstationaryTransformer.pypots
2024-06-03 10:43:52 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_1/imputation.pkl
2024-06-03 10:43:52 [INFO]: Round1 - NonstationaryTransformer on BeijingAir: MAE=0.3461, MSE=0.4670, MRE=0.4724
2024-06-03 10:43:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 10:43:52 [INFO]: Using the given device: cuda:0
2024-06-03 10:43:52 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T104352
2024-06-03 10:43:52 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T104352/tensorboard
2024-06-03 10:43:53 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 10:43:59 [INFO]: Epoch 001 - training loss: 0.6240, validation loss: 0.4807
2024-06-03 10:44:05 [INFO]: Epoch 002 - training loss: 0.5485, validation loss: 0.4646
2024-06-03 10:44:10 [INFO]: Epoch 003 - training loss: 0.5329, validation loss: 0.4620
2024-06-03 10:44:16 [INFO]: Epoch 004 - training loss: 0.5272, validation loss: 0.4635
2024-06-03 10:44:21 [INFO]: Epoch 005 - training loss: 0.5191, validation loss: 0.4620
2024-06-03 10:44:27 [INFO]: Epoch 006 - training loss: 0.5143, validation loss: 0.4500
2024-06-03 10:44:33 [INFO]: Epoch 007 - training loss: 0.5115, validation loss: 0.4437
2024-06-03 10:44:39 [INFO]: Epoch 008 - training loss: 0.5069, validation loss: 0.4533
2024-06-03 10:44:44 [INFO]: Epoch 009 - training loss: 0.5023, validation loss: 0.4548
2024-06-03 10:44:50 [INFO]: Epoch 010 - training loss: 0.4989, validation loss: 0.4730
2024-06-03 10:44:56 [INFO]: Epoch 011 - training loss: 0.4956, validation loss: 0.4556
2024-06-03 10:45:02 [INFO]: Epoch 012 - training loss: 0.4936, validation loss: 0.4465
2024-06-03 10:45:08 [INFO]: Epoch 013 - training loss: 0.4901, validation loss: 0.4446
2024-06-03 10:45:14 [INFO]: Epoch 014 - training loss: 0.4865, validation loss: 0.4567
2024-06-03 10:45:20 [INFO]: Epoch 015 - training loss: 0.4859, validation loss: 0.4690
2024-06-03 10:45:26 [INFO]: Epoch 016 - training loss: 0.4843, validation loss: 0.4599
2024-06-03 10:45:32 [INFO]: Epoch 017 - training loss: 0.4823, validation loss: 0.4451
2024-06-03 10:45:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:45:32 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 10:45:32 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/20240603_T104352/NonstationaryTransformer.pypots
2024-06-03 10:45:34 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_2/imputation.pkl
2024-06-03 10:45:34 [INFO]: Round2 - NonstationaryTransformer on BeijingAir: MAE=0.3476, MSE=0.4690, MRE=0.4745
2024-06-03 10:45:34 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 10:45:34 [INFO]: Using the given device: cuda:0
2024-06-03 10:45:34 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T104534
2024-06-03 10:45:34 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T104534/tensorboard
2024-06-03 10:45:35 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 10:45:40 [INFO]: Epoch 001 - training loss: 0.6263, validation loss: 0.4882
2024-06-03 10:45:46 [INFO]: Epoch 002 - training loss: 0.5484, validation loss: 0.4717
2024-06-03 10:45:52 [INFO]: Epoch 003 - training loss: 0.5316, validation loss: 0.4965
2024-06-03 10:45:58 [INFO]: Epoch 004 - training loss: 0.5278, validation loss: 0.4757
2024-06-03 10:46:04 [INFO]: Epoch 005 - training loss: 0.5203, validation loss: 0.4631
2024-06-03 10:46:10 [INFO]: Epoch 006 - training loss: 0.5144, validation loss: 0.4666
2024-06-03 10:46:15 [INFO]: Epoch 007 - training loss: 0.5102, validation loss: 0.4531
2024-06-03 10:46:20 [INFO]: Epoch 008 - training loss: 0.5065, validation loss: 0.4455
2024-06-03 10:46:26 [INFO]: Epoch 009 - training loss: 0.5020, validation loss: 0.4596
2024-06-03 10:46:31 [INFO]: Epoch 010 - training loss: 0.5006, validation loss: 0.4566
2024-06-03 10:46:35 [INFO]: Epoch 011 - training loss: 0.4961, validation loss: 0.4557
2024-06-03 10:46:40 [INFO]: Epoch 012 - training loss: 0.4928, validation loss: 0.4562
2024-06-03 10:46:45 [INFO]: Epoch 013 - training loss: 0.4904, validation loss: 0.4584
2024-06-03 10:46:50 [INFO]: Epoch 014 - training loss: 0.4886, validation loss: 0.4516
2024-06-03 10:46:55 [INFO]: Epoch 015 - training loss: 0.4879, validation loss: 0.4491
2024-06-03 10:47:01 [INFO]: Epoch 016 - training loss: 0.4831, validation loss: 0.4624
2024-06-03 10:47:05 [INFO]: Epoch 017 - training loss: 0.4796, validation loss: 0.4554
2024-06-03 10:47:11 [INFO]: Epoch 018 - training loss: 0.4780, validation loss: 0.4733
2024-06-03 10:47:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:47:11 [INFO]: Finished training. The best model is from epoch#8.
2024-06-03 10:47:11 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/20240603_T104534/NonstationaryTransformer.pypots
2024-06-03 10:47:12 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_3/imputation.pkl
2024-06-03 10:47:12 [INFO]: Round3 - NonstationaryTransformer on BeijingAir: MAE=0.3462, MSE=0.4682, MRE=0.4726
2024-06-03 10:47:12 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 10:47:12 [INFO]: Using the given device: cuda:0
2024-06-03 10:47:12 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T104712
2024-06-03 10:47:12 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T104712/tensorboard
2024-06-03 10:47:13 [INFO]: NonstationaryTransformer initialized with the given hyperparameters, the number of trainable parameters: 6,978,068
2024-06-03 10:47:18 [INFO]: Epoch 001 - training loss: 0.6252, validation loss: 0.4848
2024-06-03 10:47:23 [INFO]: Epoch 002 - training loss: 0.5489, validation loss: 0.4831
2024-06-03 10:47:28 [INFO]: Epoch 003 - training loss: 0.5335, validation loss: 0.4796
2024-06-03 10:47:33 [INFO]: Epoch 004 - training loss: 0.5276, validation loss: 0.4679
2024-06-03 10:47:37 [INFO]: Epoch 005 - training loss: 0.5185, validation loss: 0.4558
2024-06-03 10:47:42 [INFO]: Epoch 006 - training loss: 0.5163, validation loss: 0.4731
2024-06-03 10:47:47 [INFO]: Epoch 007 - training loss: 0.5105, validation loss: 0.4666
2024-06-03 10:47:52 [INFO]: Epoch 008 - training loss: 0.5065, validation loss: 0.4657
2024-06-03 10:47:57 [INFO]: Epoch 009 - training loss: 0.5028, validation loss: 0.4718
2024-06-03 10:48:02 [INFO]: Epoch 010 - training loss: 0.4979, validation loss: 0.4576
2024-06-03 10:48:07 [INFO]: Epoch 011 - training loss: 0.4950, validation loss: 0.4540
2024-06-03 10:48:12 [INFO]: Epoch 012 - training loss: 0.4928, validation loss: 0.4632
2024-06-03 10:48:17 [INFO]: Epoch 013 - training loss: 0.4906, validation loss: 0.4414
2024-06-03 10:48:22 [INFO]: Epoch 014 - training loss: 0.4866, validation loss: 0.4475
2024-06-03 10:48:27 [INFO]: Epoch 015 - training loss: 0.4855, validation loss: 0.4478
2024-06-03 10:48:32 [INFO]: Epoch 016 - training loss: 0.4838, validation loss: 0.4385
2024-06-03 10:48:37 [INFO]: Epoch 017 - training loss: 0.4826, validation loss: 0.4401
2024-06-03 10:48:42 [INFO]: Epoch 018 - training loss: 0.4782, validation loss: 0.4383
2024-06-03 10:48:47 [INFO]: Epoch 019 - training loss: 0.4774, validation loss: 0.4377
2024-06-03 10:48:52 [INFO]: Epoch 020 - training loss: 0.4772, validation loss: 0.4565
2024-06-03 10:48:57 [INFO]: Epoch 021 - training loss: 0.4734, validation loss: 0.4455
2024-06-03 10:49:02 [INFO]: Epoch 022 - training loss: 0.4722, validation loss: 0.4557
2024-06-03 10:49:07 [INFO]: Epoch 023 - training loss: 0.4703, validation loss: 0.4436
2024-06-03 10:49:12 [INFO]: Epoch 024 - training loss: 0.4676, validation loss: 0.4332
2024-06-03 10:49:17 [INFO]: Epoch 025 - training loss: 0.4637, validation loss: 0.4358
2024-06-03 10:49:22 [INFO]: Epoch 026 - training loss: 0.4637, validation loss: 0.4460
2024-06-03 10:49:27 [INFO]: Epoch 027 - training loss: 0.4631, validation loss: 0.4446
2024-06-03 10:49:33 [INFO]: Epoch 028 - training loss: 0.4623, validation loss: 0.4403
2024-06-03 10:49:38 [INFO]: Epoch 029 - training loss: 0.4594, validation loss: 0.4436
2024-06-03 10:49:43 [INFO]: Epoch 030 - training loss: 0.4587, validation loss: 0.4332
2024-06-03 10:49:48 [INFO]: Epoch 031 - training loss: 0.4559, validation loss: 0.4333
2024-06-03 10:49:53 [INFO]: Epoch 032 - training loss: 0.4546, validation loss: 0.4425
2024-06-03 10:49:58 [INFO]: Epoch 033 - training loss: 0.4532, validation loss: 0.4495
2024-06-03 10:50:03 [INFO]: Epoch 034 - training loss: 0.4527, validation loss: 0.4494
2024-06-03 10:50:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:50:03 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 10:50:03 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/20240603_T104712/NonstationaryTransformer.pypots
2024-06-03 10:50:05 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/NonstationaryTransformer_BeijingAir/round_4/imputation.pkl
2024-06-03 10:50:05 [INFO]: Round4 - NonstationaryTransformer on BeijingAir: MAE=0.3497, MSE=0.4772, MRE=0.4773
2024-06-03 10:50:05 [INFO]: Done! Final results:
Averaged NonstationaryTransformer (6,978,068 params) on BeijingAir: MAE=0.3365 ± 0.0015838498669431644, MSE=0.4524 ± 0.00475623772649071, MRE=0.4471 ± 0.002104644882280061, average inference time=0.40