2024-06-03 03:58:18 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:58:18 [INFO]: Using the given device: cuda:0
2024-06-03 03:58:19 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240603_T035819
2024-06-03 03:58:19 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240603_T035819/tensorboard
2024-06-03 03:58:19 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 03:59:45 [INFO]: Epoch 001 - training loss: 0.5531, validation loss: 0.3475
2024-06-03 04:01:05 [INFO]: Epoch 002 - training loss: 0.3819, validation loss: 0.3031
2024-06-03 04:02:24 [INFO]: Epoch 003 - training loss: 0.3231, validation loss: 0.2947
2024-06-03 04:03:44 [INFO]: Epoch 004 - training loss: 0.3487, validation loss: 0.2816
2024-06-03 04:05:03 [INFO]: Epoch 005 - training loss: 0.2883, validation loss: 0.2376
2024-06-03 04:06:23 [INFO]: Epoch 006 - training loss: 0.2718, validation loss: 0.2196
2024-06-03 04:07:39 [INFO]: Epoch 007 - training loss: 0.2380, validation loss: 0.2009
2024-06-03 04:08:56 [INFO]: Epoch 008 - training loss: 0.2277, validation loss: 0.2077
2024-06-03 04:10:11 [INFO]: Epoch 009 - training loss: 0.2201, validation loss: 0.1892
2024-06-03 04:11:23 [INFO]: Epoch 010 - training loss: 0.2311, validation loss: 0.1893
2024-06-03 04:12:35 [INFO]: Epoch 011 - training loss: 0.2200, validation loss: 0.1801
2024-06-03 04:13:47 [INFO]: Epoch 012 - training loss: 0.2004, validation loss: 0.1832
2024-06-03 04:14:59 [INFO]: Epoch 013 - training loss: 0.2075, validation loss: 0.1781
2024-06-03 04:16:11 [INFO]: Epoch 014 - training loss: 0.2055, validation loss: 0.1738
2024-06-03 04:17:23 [INFO]: Epoch 015 - training loss: 0.1944, validation loss: 0.1727
2024-06-03 04:18:35 [INFO]: Epoch 016 - training loss: 0.1852, validation loss: 0.1714
2024-06-03 04:19:46 [INFO]: Epoch 017 - training loss: 0.1931, validation loss: 0.1757
2024-06-03 04:20:58 [INFO]: Epoch 018 - training loss: 0.2045, validation loss: 0.1713
2024-06-03 04:22:10 [INFO]: Epoch 019 - training loss: 0.2041, validation loss: 0.1704
2024-06-03 04:23:21 [INFO]: Epoch 020 - training loss: 0.1797, validation loss: 0.1718
2024-06-03 04:24:33 [INFO]: Epoch 021 - training loss: 0.1890, validation loss: 0.1674
2024-06-03 04:25:44 [INFO]: Epoch 022 - training loss: 0.1708, validation loss: 0.1672
2024-06-03 04:26:52 [INFO]: Epoch 023 - training loss: 0.1824, validation loss: 0.1667
2024-06-03 04:28:00 [INFO]: Epoch 024 - training loss: 0.1787, validation loss: 0.1670
2024-06-03 04:29:09 [INFO]: Epoch 025 - training loss: 0.1895, validation loss: 0.1651
2024-06-03 04:30:17 [INFO]: Epoch 026 - training loss: 0.1737, validation loss: 0.1653
2024-06-03 04:31:26 [INFO]: Epoch 027 - training loss: 0.1882, validation loss: 0.1596
2024-06-03 04:32:34 [INFO]: Epoch 028 - training loss: 0.1964, validation loss: 0.1683
2024-06-03 04:33:43 [INFO]: Epoch 029 - training loss: 0.1811, validation loss: 0.1591
2024-06-03 04:34:52 [INFO]: Epoch 030 - training loss: 0.1789, validation loss: 0.1593
2024-06-03 04:36:00 [INFO]: Epoch 031 - training loss: 0.1880, validation loss: 0.1583
2024-06-03 04:37:09 [INFO]: Epoch 032 - training loss: 0.1750, validation loss: 0.1749
2024-06-03 04:38:17 [INFO]: Epoch 033 - training loss: 0.1701, validation loss: 0.1607
2024-06-03 04:39:26 [INFO]: Epoch 034 - training loss: 0.1781, validation loss: 0.1605
2024-06-03 04:40:34 [INFO]: Epoch 035 - training loss: 0.1680, validation loss: 0.1554
2024-06-03 04:41:43 [INFO]: Epoch 036 - training loss: 0.1725, validation loss: 0.1521
2024-06-03 04:42:51 [INFO]: Epoch 037 - training loss: 0.1703, validation loss: 0.1506
2024-06-03 04:44:00 [INFO]: Epoch 038 - training loss: 0.1760, validation loss: 0.1562
2024-06-03 04:45:06 [INFO]: Epoch 039 - training loss: 0.1689, validation loss: 0.1476
2024-06-03 04:46:10 [INFO]: Epoch 040 - training loss: 0.1630, validation loss: 0.1530
2024-06-03 04:47:14 [INFO]: Epoch 041 - training loss: 0.1621, validation loss: 0.1501
2024-06-03 04:48:18 [INFO]: Epoch 042 - training loss: 0.1702, validation loss: 0.1523
2024-06-03 04:49:21 [INFO]: Epoch 043 - training loss: 0.1757, validation loss: 0.1472
2024-06-03 04:50:26 [INFO]: Epoch 044 - training loss: 0.1523, validation loss: 0.1460
2024-06-03 04:51:29 [INFO]: Epoch 045 - training loss: 0.1759, validation loss: 0.1515
2024-06-03 04:52:33 [INFO]: Epoch 046 - training loss: 0.1799, validation loss: 0.1445
2024-06-03 04:53:38 [INFO]: Epoch 047 - training loss: 0.1742, validation loss: 0.1487
2024-06-03 04:54:41 [INFO]: Epoch 048 - training loss: 0.1720, validation loss: 0.1406
2024-06-03 04:55:45 [INFO]: Epoch 049 - training loss: 0.1635, validation loss: 0.1402
2024-06-03 04:56:49 [INFO]: Epoch 050 - training loss: 0.1718, validation loss: 0.1364
2024-06-03 04:57:53 [INFO]: Epoch 051 - training loss: 0.1576, validation loss: 0.1502
2024-06-03 04:58:57 [INFO]: Epoch 052 - training loss: 0.1720, validation loss: 0.1447
2024-06-03 05:00:01 [INFO]: Epoch 053 - training loss: 0.1580, validation loss: 0.1365
2024-06-03 05:01:05 [INFO]: Epoch 054 - training loss: 0.1660, validation loss: 0.1421
2024-06-03 05:02:09 [INFO]: Epoch 055 - training loss: 0.1501, validation loss: 0.1364
2024-06-03 05:03:13 [INFO]: Epoch 056 - training loss: 0.1640, validation loss: 0.1400
2024-06-03 05:04:17 [INFO]: Epoch 057 - training loss: 0.1644, validation loss: 0.1443
2024-06-03 05:05:21 [INFO]: Epoch 058 - training loss: 0.1422, validation loss: 0.1374
2024-06-03 05:06:25 [INFO]: Epoch 059 - training loss: 0.1536, validation loss: 0.1480
2024-06-03 05:07:29 [INFO]: Epoch 060 - training loss: 0.1675, validation loss: 0.1369
2024-06-03 05:07:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:07:29 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 05:07:29 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_0/20240603_T035819/CSDI.pypots
2024-06-03 05:48:52 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_0/imputation.pkl
2024-06-03 05:48:52 [INFO]: Round0 - CSDI on BeijingAir: MAE=0.2892, MSE=1.2098, MRE=0.3948
2024-06-03 05:48:52 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 05:48:52 [INFO]: Using the given device: cuda:0
2024-06-03 05:48:52 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240603_T054852
2024-06-03 05:48:52 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240603_T054852/tensorboard
2024-06-03 05:48:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 05:49:57 [INFO]: Epoch 001 - training loss: 0.5402, validation loss: 0.3287
2024-06-03 05:51:00 [INFO]: Epoch 002 - training loss: 0.3641, validation loss: 0.2906
2024-06-03 05:52:04 [INFO]: Epoch 003 - training loss: 0.3385, validation loss: 0.2829
2024-06-03 05:53:07 [INFO]: Epoch 004 - training loss: 0.3112, validation loss: 0.2549
2024-06-03 05:54:11 [INFO]: Epoch 005 - training loss: 0.2791, validation loss: 0.2487
2024-06-03 05:55:15 [INFO]: Epoch 006 - training loss: 0.2604, validation loss: 0.2149
2024-06-03 05:56:19 [INFO]: Epoch 007 - training loss: 0.2539, validation loss: 0.2076
2024-06-03 05:57:22 [INFO]: Epoch 008 - training loss: 0.2232, validation loss: 0.1932
2024-06-03 05:58:26 [INFO]: Epoch 009 - training loss: 0.2141, validation loss: 0.1846
2024-06-03 05:59:30 [INFO]: Epoch 010 - training loss: 0.2094, validation loss: 0.1856
2024-06-03 06:00:34 [INFO]: Epoch 011 - training loss: 0.2123, validation loss: 0.1785
2024-06-03 06:01:37 [INFO]: Epoch 012 - training loss: 0.1901, validation loss: 0.1738
2024-06-03 06:02:41 [INFO]: Epoch 013 - training loss: 0.1871, validation loss: 0.1766
2024-06-03 06:03:45 [INFO]: Epoch 014 - training loss: 0.2030, validation loss: 0.1764
2024-06-03 06:04:49 [INFO]: Epoch 015 - training loss: 0.1947, validation loss: 0.1652
2024-06-03 06:05:52 [INFO]: Epoch 016 - training loss: 0.1857, validation loss: 0.1735
2024-06-03 06:06:57 [INFO]: Epoch 017 - training loss: 0.1922, validation loss: 0.1631
2024-06-03 06:08:00 [INFO]: Epoch 018 - training loss: 0.1790, validation loss: 0.1662
2024-06-03 06:09:04 [INFO]: Epoch 019 - training loss: 0.1850, validation loss: 0.1661
2024-06-03 06:10:08 [INFO]: Epoch 020 - training loss: 0.1875, validation loss: 0.1669
2024-06-03 06:11:12 [INFO]: Epoch 021 - training loss: 0.1929, validation loss: 0.1621
2024-06-03 06:12:16 [INFO]: Epoch 022 - training loss: 0.1888, validation loss: 0.1607
2024-06-03 06:13:21 [INFO]: Epoch 023 - training loss: 0.1717, validation loss: 0.1630
2024-06-03 06:14:25 [INFO]: Epoch 024 - training loss: 0.1645, validation loss: 0.1643
2024-06-03 06:15:29 [INFO]: Epoch 025 - training loss: 0.1720, validation loss: 0.1618
2024-06-03 06:16:32 [INFO]: Epoch 026 - training loss: 0.1796, validation loss: 0.1658
2024-06-03 06:17:36 [INFO]: Epoch 027 - training loss: 0.1734, validation loss: 0.1599
2024-06-03 06:18:40 [INFO]: Epoch 028 - training loss: 0.1599, validation loss: 0.1619
2024-06-03 06:19:44 [INFO]: Epoch 029 - training loss: 0.1798, validation loss: 0.1556
2024-06-03 06:20:48 [INFO]: Epoch 030 - training loss: 0.1990, validation loss: 0.1629
2024-06-03 06:21:52 [INFO]: Epoch 031 - training loss: 0.1946, validation loss: 0.1701
2024-06-03 06:22:56 [INFO]: Epoch 032 - training loss: 0.1744, validation loss: 0.1552
2024-06-03 06:24:00 [INFO]: Epoch 033 - training loss: 0.1779, validation loss: 0.1653
2024-06-03 06:25:04 [INFO]: Epoch 034 - training loss: 0.1665, validation loss: 0.1539
2024-06-03 06:26:08 [INFO]: Epoch 035 - training loss: 0.1632, validation loss: 0.1545
2024-06-03 06:27:12 [INFO]: Epoch 036 - training loss: 0.1863, validation loss: 0.1540
2024-06-03 06:28:15 [INFO]: Epoch 037 - training loss: 0.1712, validation loss: 0.1543
2024-06-03 06:29:19 [INFO]: Epoch 038 - training loss: 0.1632, validation loss: 0.1504
2024-06-03 06:30:23 [INFO]: Epoch 039 - training loss: 0.1739, validation loss: 0.1545
2024-06-03 06:31:27 [INFO]: Epoch 040 - training loss: 0.1613, validation loss: 0.1501
2024-06-03 06:32:31 [INFO]: Epoch 041 - training loss: 0.1781, validation loss: 0.1500
2024-06-03 06:33:34 [INFO]: Epoch 042 - training loss: 0.1732, validation loss: 0.1469
2024-06-03 06:34:39 [INFO]: Epoch 043 - training loss: 0.1652, validation loss: 0.1445
2024-06-03 06:35:42 [INFO]: Epoch 044 - training loss: 0.1724, validation loss: 0.1465
2024-06-03 06:36:46 [INFO]: Epoch 045 - training loss: 0.1502, validation loss: 0.1456
2024-06-03 06:37:50 [INFO]: Epoch 046 - training loss: 0.1460, validation loss: 0.1444
2024-06-03 06:38:54 [INFO]: Epoch 047 - training loss: 0.1590, validation loss: 0.1460
2024-06-03 06:39:58 [INFO]: Epoch 048 - training loss: 0.1675, validation loss: 0.1411
2024-06-03 06:41:01 [INFO]: Epoch 049 - training loss: 0.1565, validation loss: 0.1427
2024-06-03 06:42:05 [INFO]: Epoch 050 - training loss: 0.1542, validation loss: 0.1432
2024-06-03 06:43:09 [INFO]: Epoch 051 - training loss: 0.1537, validation loss: 0.1431
2024-06-03 06:44:13 [INFO]: Epoch 052 - training loss: 0.1613, validation loss: 0.1450
2024-06-03 06:45:17 [INFO]: Epoch 053 - training loss: 0.1491, validation loss: 0.1403
2024-06-03 06:46:20 [INFO]: Epoch 054 - training loss: 0.1527, validation loss: 0.1387
2024-06-03 06:47:24 [INFO]: Epoch 055 - training loss: 0.1631, validation loss: 0.1399
2024-06-03 06:48:27 [INFO]: Epoch 056 - training loss: 0.1498, validation loss: 0.1375
2024-06-03 06:49:31 [INFO]: Epoch 057 - training loss: 0.1690, validation loss: 0.1448
2024-06-03 06:50:35 [INFO]: Epoch 058 - training loss: 0.1603, validation loss: 0.1361
2024-06-03 06:51:39 [INFO]: Epoch 059 - training loss: 0.1710, validation loss: 0.1360
2024-06-03 06:52:43 [INFO]: Epoch 060 - training loss: 0.1595, validation loss: 0.1345
2024-06-03 06:53:47 [INFO]: Epoch 061 - training loss: 0.1683, validation loss: 0.1405
2024-06-03 06:54:51 [INFO]: Epoch 062 - training loss: 0.1558, validation loss: 0.1403
2024-06-03 06:55:55 [INFO]: Epoch 063 - training loss: 0.1640, validation loss: 0.1356
2024-06-03 06:56:59 [INFO]: Epoch 064 - training loss: 0.1652, validation loss: 0.1365
2024-06-03 06:58:02 [INFO]: Epoch 065 - training loss: 0.1643, validation loss: 0.1382
2024-06-03 06:59:06 [INFO]: Epoch 066 - training loss: 0.1662, validation loss: 0.1350
2024-06-03 07:00:10 [INFO]: Epoch 067 - training loss: 0.1544, validation loss: 0.1315
2024-06-03 07:01:14 [INFO]: Epoch 068 - training loss: 0.1469, validation loss: 0.1350
2024-06-03 07:02:18 [INFO]: Epoch 069 - training loss: 0.1658, validation loss: 0.1310
2024-06-03 07:02:57 [INFO]: Epoch 070 - training loss: 0.1513, validation loss: 0.1370
2024-06-03 07:03:29 [INFO]: Epoch 071 - training loss: 0.1629, validation loss: 0.1336
2024-06-03 07:04:02 [INFO]: Epoch 072 - training loss: 0.1424, validation loss: 0.1314
2024-06-03 07:04:34 [INFO]: Epoch 073 - training loss: 0.1602, validation loss: 0.1313
2024-06-03 07:05:07 [INFO]: Epoch 074 - training loss: 0.1577, validation loss: 0.1305
2024-06-03 07:05:39 [INFO]: Epoch 075 - training loss: 0.1578, validation loss: 0.1296
2024-06-03 07:06:11 [INFO]: Epoch 076 - training loss: 0.1529, validation loss: 0.1317
2024-06-03 07:06:44 [INFO]: Epoch 077 - training loss: 0.1457, validation loss: 0.1390
2024-06-03 07:07:16 [INFO]: Epoch 078 - training loss: 0.1674, validation loss: 0.1304
2024-06-03 07:07:49 [INFO]: Epoch 079 - training loss: 0.1652, validation loss: 0.1312
2024-06-03 07:08:21 [INFO]: Epoch 080 - training loss: 0.1645, validation loss: 0.1319
2024-06-03 07:08:53 [INFO]: Epoch 081 - training loss: 0.1622, validation loss: 0.1294
2024-06-03 07:09:26 [INFO]: Epoch 082 - training loss: 0.1482, validation loss: 0.1280
2024-06-03 07:09:58 [INFO]: Epoch 083 - training loss: 0.1493, validation loss: 0.1275
2024-06-03 07:10:31 [INFO]: Epoch 084 - training loss: 0.1495, validation loss: 0.1309
2024-06-03 07:11:03 [INFO]: Epoch 085 - training loss: 0.1598, validation loss: 0.1352
2024-06-03 07:11:35 [INFO]: Epoch 086 - training loss: 0.1428, validation loss: 0.1288
2024-06-03 07:12:08 [INFO]: Epoch 087 - training loss: 0.1532, validation loss: 0.1366
2024-06-03 07:12:40 [INFO]: Epoch 088 - training loss: 0.1581, validation loss: 0.1333
2024-06-03 07:13:13 [INFO]: Epoch 089 - training loss: 0.1604, validation loss: 0.1277
2024-06-03 07:13:45 [INFO]: Epoch 090 - training loss: 0.1575, validation loss: 0.1290
2024-06-03 07:14:17 [INFO]: Epoch 091 - training loss: 0.1461, validation loss: 0.1267
2024-06-03 07:14:50 [INFO]: Epoch 092 - training loss: 0.1467, validation loss: 0.1307
2024-06-03 07:15:22 [INFO]: Epoch 093 - training loss: 0.1498, validation loss: 0.1251
2024-06-03 07:15:55 [INFO]: Epoch 094 - training loss: 0.1500, validation loss: 0.1263
2024-06-03 07:16:27 [INFO]: Epoch 095 - training loss: 0.1456, validation loss: 0.1330
2024-06-03 07:16:58 [INFO]: Epoch 096 - training loss: 0.1500, validation loss: 0.1277
2024-06-03 07:17:31 [INFO]: Epoch 097 - training loss: 0.1605, validation loss: 0.1264
2024-06-03 07:18:03 [INFO]: Epoch 098 - training loss: 0.1463, validation loss: 0.1298
2024-06-03 07:18:36 [INFO]: Epoch 099 - training loss: 0.1625, validation loss: 0.1296
2024-06-03 07:19:08 [INFO]: Epoch 100 - training loss: 0.1426, validation loss: 0.1262
2024-06-03 07:19:08 [INFO]: Finished training. The best model is from epoch#93.
2024-06-03 07:19:08 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_1/20240603_T054852/CSDI.pypots
2024-06-03 07:39:50 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_1/imputation.pkl
2024-06-03 07:39:50 [INFO]: Round1 - CSDI on BeijingAir: MAE=0.2148, MSE=0.5125, MRE=0.2932
2024-06-03 07:39:50 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 07:39:50 [INFO]: Using the given device: cuda:0
2024-06-03 07:39:50 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T073950
2024-06-03 07:39:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T073950/tensorboard
2024-06-03 07:39:50 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 07:40:16 [INFO]: Epoch 001 - training loss: 0.5119, validation loss: 0.3235
2024-06-03 07:40:42 [INFO]: Epoch 002 - training loss: 0.3510, validation loss: 0.2882
2024-06-03 07:41:08 [INFO]: Epoch 003 - training loss: 0.3226, validation loss: 0.2674
2024-06-03 07:41:35 [INFO]: Epoch 004 - training loss: 0.2681, validation loss: 0.2596
2024-06-03 07:42:01 [INFO]: Epoch 005 - training loss: 0.2650, validation loss: 0.2153
2024-06-03 07:42:27 [INFO]: Epoch 006 - training loss: 0.2661, validation loss: 0.2118
2024-06-03 07:42:53 [INFO]: Epoch 007 - training loss: 0.2123, validation loss: 0.1968
2024-06-03 07:43:19 [INFO]: Epoch 008 - training loss: 0.2279, validation loss: 0.1921
2024-06-03 07:43:45 [INFO]: Epoch 009 - training loss: 0.2095, validation loss: 0.1837
2024-06-03 07:44:11 [INFO]: Epoch 010 - training loss: 0.2082, validation loss: 0.1797
2024-06-03 07:44:37 [INFO]: Epoch 011 - training loss: 0.2019, validation loss: 0.1851
2024-06-03 07:45:03 [INFO]: Epoch 012 - training loss: 0.1885, validation loss: 0.1817
2024-06-03 07:45:30 [INFO]: Epoch 013 - training loss: 0.1907, validation loss: 0.1729
2024-06-03 07:45:56 [INFO]: Epoch 014 - training loss: 0.1904, validation loss: 0.1797
2024-06-03 07:46:22 [INFO]: Epoch 015 - training loss: 0.1903, validation loss: 0.1697
2024-06-03 07:46:48 [INFO]: Epoch 016 - training loss: 0.1981, validation loss: 0.1746
2024-06-03 07:47:14 [INFO]: Epoch 017 - training loss: 0.1925, validation loss: 0.1657
2024-06-03 07:47:40 [INFO]: Epoch 018 - training loss: 0.1954, validation loss: 0.1687
2024-06-03 07:48:06 [INFO]: Epoch 019 - training loss: 0.1817, validation loss: 0.1654
2024-06-03 07:48:32 [INFO]: Epoch 020 - training loss: 0.1813, validation loss: 0.1688
2024-06-03 07:48:58 [INFO]: Epoch 021 - training loss: 0.1913, validation loss: 0.1615
2024-06-03 07:49:24 [INFO]: Epoch 022 - training loss: 0.1751, validation loss: 0.1674
2024-06-03 07:49:51 [INFO]: Epoch 023 - training loss: 0.1835, validation loss: 0.1579
2024-06-03 07:50:17 [INFO]: Epoch 024 - training loss: 0.1868, validation loss: 0.1656
2024-06-03 07:50:43 [INFO]: Epoch 025 - training loss: 0.1950, validation loss: 0.1616
2024-06-03 07:51:09 [INFO]: Epoch 026 - training loss: 0.1787, validation loss: 0.1603
2024-06-03 07:51:35 [INFO]: Epoch 027 - training loss: 0.1693, validation loss: 0.1549
2024-06-03 07:52:01 [INFO]: Epoch 028 - training loss: 0.1693, validation loss: 0.1567
2024-06-03 07:52:27 [INFO]: Epoch 029 - training loss: 0.1814, validation loss: 0.1599
2024-06-03 07:52:53 [INFO]: Epoch 030 - training loss: 0.1782, validation loss: 0.1584
2024-06-03 07:53:19 [INFO]: Epoch 031 - training loss: 0.1922, validation loss: 0.1519
2024-06-03 07:53:46 [INFO]: Epoch 032 - training loss: 0.1794, validation loss: 0.1532
2024-06-03 07:54:12 [INFO]: Epoch 033 - training loss: 0.1801, validation loss: 0.1508
2024-06-03 07:54:38 [INFO]: Epoch 034 - training loss: 0.1737, validation loss: 0.1488
2024-06-03 07:55:04 [INFO]: Epoch 035 - training loss: 0.1708, validation loss: 0.1479
2024-06-03 07:55:30 [INFO]: Epoch 036 - training loss: 0.1591, validation loss: 0.1481
2024-06-03 07:55:56 [INFO]: Epoch 037 - training loss: 0.1678, validation loss: 0.1458
2024-06-03 07:56:22 [INFO]: Epoch 038 - training loss: 0.1492, validation loss: 0.1470
2024-06-03 07:56:48 [INFO]: Epoch 039 - training loss: 0.1745, validation loss: 0.1448
2024-06-03 07:57:14 [INFO]: Epoch 040 - training loss: 0.1537, validation loss: 0.1486
2024-06-03 07:57:40 [INFO]: Epoch 041 - training loss: 0.1753, validation loss: 0.1429
2024-06-03 07:58:07 [INFO]: Epoch 042 - training loss: 0.1676, validation loss: 0.1474
2024-06-03 07:58:33 [INFO]: Epoch 043 - training loss: 0.1540, validation loss: 0.1384
2024-06-03 07:58:59 [INFO]: Epoch 044 - training loss: 0.1474, validation loss: 0.1496
2024-06-03 07:59:25 [INFO]: Epoch 045 - training loss: 0.1733, validation loss: 0.1358
2024-06-03 07:59:51 [INFO]: Epoch 046 - training loss: 0.1743, validation loss: 0.1398
2024-06-03 08:00:17 [INFO]: Epoch 047 - training loss: 0.1530, validation loss: 0.1387
2024-06-03 08:00:43 [INFO]: Epoch 048 - training loss: 0.1481, validation loss: 0.1522
2024-06-03 08:01:09 [INFO]: Epoch 049 - training loss: 0.1586, validation loss: 0.1363
2024-06-03 08:01:35 [INFO]: Epoch 050 - training loss: 0.1881, validation loss: 0.1359
2024-06-03 08:02:02 [INFO]: Epoch 051 - training loss: 0.1551, validation loss: 0.1364
2024-06-03 08:02:28 [INFO]: Epoch 052 - training loss: 0.1642, validation loss: 0.1401
2024-06-03 08:02:54 [INFO]: Epoch 053 - training loss: 0.1501, validation loss: 0.1345
2024-06-03 08:03:20 [INFO]: Epoch 054 - training loss: 0.1619, validation loss: 0.1446
2024-06-03 08:03:46 [INFO]: Epoch 055 - training loss: 0.1655, validation loss: 0.1329
2024-06-03 08:04:12 [INFO]: Epoch 056 - training loss: 0.1658, validation loss: 0.1340
2024-06-03 08:04:38 [INFO]: Epoch 057 - training loss: 0.1455, validation loss: 0.1347
2024-06-03 08:05:04 [INFO]: Epoch 058 - training loss: 0.1780, validation loss: 0.1338
2024-06-03 08:05:30 [INFO]: Epoch 059 - training loss: 0.1555, validation loss: 0.1316
2024-06-03 08:05:56 [INFO]: Epoch 060 - training loss: 0.1620, validation loss: 0.1337
2024-06-03 08:06:23 [INFO]: Epoch 061 - training loss: 0.1317, validation loss: 0.1341
2024-06-03 08:06:49 [INFO]: Epoch 062 - training loss: 0.1413, validation loss: 0.1315
2024-06-03 08:07:15 [INFO]: Epoch 063 - training loss: 0.1478, validation loss: 0.1349
2024-06-03 08:07:41 [INFO]: Epoch 064 - training loss: 0.1446, validation loss: 0.1302
2024-06-03 08:08:07 [INFO]: Epoch 065 - training loss: 0.1387, validation loss: 0.1327
2024-06-03 08:08:33 [INFO]: Epoch 066 - training loss: 0.1569, validation loss: 0.1353
2024-06-03 08:08:59 [INFO]: Epoch 067 - training loss: 0.1465, validation loss: 0.1278
2024-06-03 08:09:25 [INFO]: Epoch 068 - training loss: 0.1464, validation loss: 0.1395
2024-06-03 08:09:51 [INFO]: Epoch 069 - training loss: 0.1816, validation loss: 0.1339
2024-06-03 08:10:18 [INFO]: Epoch 070 - training loss: 0.1353, validation loss: 0.1291
2024-06-03 08:10:44 [INFO]: Epoch 071 - training loss: 0.1522, validation loss: 0.1293
2024-06-03 08:11:10 [INFO]: Epoch 072 - training loss: 0.1330, validation loss: 0.1318
2024-06-03 08:11:36 [INFO]: Epoch 073 - training loss: 0.1502, validation loss: 0.1278
2024-06-03 08:12:02 [INFO]: Epoch 074 - training loss: 0.1420, validation loss: 0.1291
2024-06-03 08:12:28 [INFO]: Epoch 075 - training loss: 0.1548, validation loss: 0.1295
2024-06-03 08:12:54 [INFO]: Epoch 076 - training loss: 0.1457, validation loss: 0.1262
2024-06-03 08:13:20 [INFO]: Epoch 077 - training loss: 0.1547, validation loss: 0.1298
2024-06-03 08:13:46 [INFO]: Epoch 078 - training loss: 0.1553, validation loss: 0.1249
2024-06-03 08:14:12 [INFO]: Epoch 079 - training loss: 0.1514, validation loss: 0.1302
2024-06-03 08:14:39 [INFO]: Epoch 080 - training loss: 0.1371, validation loss: 0.1266
2024-06-03 08:15:05 [INFO]: Epoch 081 - training loss: 0.1692, validation loss: 0.1277
2024-06-03 08:15:31 [INFO]: Epoch 082 - training loss: 0.1633, validation loss: 0.1258
2024-06-03 08:15:57 [INFO]: Epoch 083 - training loss: 0.1449, validation loss: 0.1288
2024-06-03 08:16:23 [INFO]: Epoch 084 - training loss: 0.1643, validation loss: 0.1262
2024-06-03 08:16:49 [INFO]: Epoch 085 - training loss: 0.1459, validation loss: 0.1238
2024-06-03 08:17:15 [INFO]: Epoch 086 - training loss: 0.1595, validation loss: 0.1252
2024-06-03 08:17:41 [INFO]: Epoch 087 - training loss: 0.1378, validation loss: 0.1233
2024-06-03 08:18:07 [INFO]: Epoch 088 - training loss: 0.1456, validation loss: 0.1271
2024-06-03 08:18:33 [INFO]: Epoch 089 - training loss: 0.1547, validation loss: 0.1289
2024-06-03 08:19:00 [INFO]: Epoch 090 - training loss: 0.1562, validation loss: 0.1286
2024-06-03 08:19:26 [INFO]: Epoch 091 - training loss: 0.1486, validation loss: 0.1263
2024-06-03 08:19:52 [INFO]: Epoch 092 - training loss: 0.1393, validation loss: 0.1234
2024-06-03 08:20:18 [INFO]: Epoch 093 - training loss: 0.1439, validation loss: 0.1246
2024-06-03 08:20:44 [INFO]: Epoch 094 - training loss: 0.1468, validation loss: 0.1243
2024-06-03 08:21:10 [INFO]: Epoch 095 - training loss: 0.1383, validation loss: 0.1265
2024-06-03 08:21:36 [INFO]: Epoch 096 - training loss: 0.1624, validation loss: 0.1243
2024-06-03 08:22:02 [INFO]: Epoch 097 - training loss: 0.1387, validation loss: 0.1242
2024-06-03 08:22:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:22:02 [INFO]: Finished training. The best model is from epoch#87.
2024-06-03 08:22:02 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_2/20240603_T073950/CSDI.pypots
2024-06-03 08:39:25 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_2/imputation.pkl
2024-06-03 08:39:25 [INFO]: Round2 - CSDI on BeijingAir: MAE=0.2069, MSE=0.4272, MRE=0.2824
2024-06-03 08:39:25 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:39:25 [INFO]: Using the given device: cuda:0
2024-06-03 08:39:25 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T083925
2024-06-03 08:39:25 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T083925/tensorboard
2024-06-03 08:39:25 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 08:39:51 [INFO]: Epoch 001 - training loss: 0.5551, validation loss: 0.3431
2024-06-03 08:40:17 [INFO]: Epoch 002 - training loss: 0.3680, validation loss: 0.3107
2024-06-03 08:40:43 [INFO]: Epoch 003 - training loss: 0.3354, validation loss: 0.2889
2024-06-03 08:41:09 [INFO]: Epoch 004 - training loss: 0.3156, validation loss: 0.2619
2024-06-03 08:41:35 [INFO]: Epoch 005 - training loss: 0.2697, validation loss: 0.2466
2024-06-03 08:42:02 [INFO]: Epoch 006 - training loss: 0.2601, validation loss: 0.2175
2024-06-03 08:42:28 [INFO]: Epoch 007 - training loss: 0.2463, validation loss: 0.2030
2024-06-03 08:42:54 [INFO]: Epoch 008 - training loss: 0.2222, validation loss: 0.1966
2024-06-03 08:43:20 [INFO]: Epoch 009 - training loss: 0.2066, validation loss: 0.1865
2024-06-03 08:43:46 [INFO]: Epoch 010 - training loss: 0.2054, validation loss: 0.1798
2024-06-03 08:44:12 [INFO]: Epoch 011 - training loss: 0.2001, validation loss: 0.1734
2024-06-03 08:44:38 [INFO]: Epoch 012 - training loss: 0.1851, validation loss: 0.1764
2024-06-03 08:45:04 [INFO]: Epoch 013 - training loss: 0.2095, validation loss: 0.1734
2024-06-03 08:45:30 [INFO]: Epoch 014 - training loss: 0.2022, validation loss: 0.1701
2024-06-03 08:45:56 [INFO]: Epoch 015 - training loss: 0.1957, validation loss: 0.1775
2024-06-03 08:46:23 [INFO]: Epoch 016 - training loss: 0.1948, validation loss: 0.1712
2024-06-03 08:46:49 [INFO]: Epoch 017 - training loss: 0.1883, validation loss: 0.1664
2024-06-03 08:47:15 [INFO]: Epoch 018 - training loss: 0.1730, validation loss: 0.1670
2024-06-03 08:47:41 [INFO]: Epoch 019 - training loss: 0.1803, validation loss: 0.1673
2024-06-03 08:48:07 [INFO]: Epoch 020 - training loss: 0.1890, validation loss: 0.1695
2024-06-03 08:48:33 [INFO]: Epoch 021 - training loss: 0.1757, validation loss: 0.1603
2024-06-03 08:48:59 [INFO]: Epoch 022 - training loss: 0.1635, validation loss: 0.1612
2024-06-03 08:49:25 [INFO]: Epoch 023 - training loss: 0.1911, validation loss: 0.1595
2024-06-03 08:49:51 [INFO]: Epoch 024 - training loss: 0.1781, validation loss: 0.1614
2024-06-03 08:50:18 [INFO]: Epoch 025 - training loss: 0.1578, validation loss: 0.1561
2024-06-03 08:50:44 [INFO]: Epoch 026 - training loss: 0.1642, validation loss: 0.1553
2024-06-03 08:51:10 [INFO]: Epoch 027 - training loss: 0.1794, validation loss: 0.1603
2024-06-03 08:51:36 [INFO]: Epoch 028 - training loss: 0.1765, validation loss: 0.1602
2024-06-03 08:52:02 [INFO]: Epoch 029 - training loss: 0.1689, validation loss: 0.1555
2024-06-03 08:52:28 [INFO]: Epoch 030 - training loss: 0.1735, validation loss: 0.1538
2024-06-03 08:52:54 [INFO]: Epoch 031 - training loss: 0.1755, validation loss: 0.1544
2024-06-03 08:53:21 [INFO]: Epoch 032 - training loss: 0.1843, validation loss: 0.1488
2024-06-03 08:53:47 [INFO]: Epoch 033 - training loss: 0.1724, validation loss: 0.1487
2024-06-03 08:54:13 [INFO]: Epoch 034 - training loss: 0.1678, validation loss: 0.1480
2024-06-03 08:54:39 [INFO]: Epoch 035 - training loss: 0.1735, validation loss: 0.1457
2024-06-03 08:55:05 [INFO]: Epoch 036 - training loss: 0.1734, validation loss: 0.1462
2024-06-03 08:55:31 [INFO]: Epoch 037 - training loss: 0.1702, validation loss: 0.1419
2024-06-03 08:55:57 [INFO]: Epoch 038 - training loss: 0.1601, validation loss: 0.1435
2024-06-03 08:56:23 [INFO]: Epoch 039 - training loss: 0.1533, validation loss: 0.1438
2024-06-03 08:56:49 [INFO]: Epoch 040 - training loss: 0.1722, validation loss: 0.1394
2024-06-03 08:57:15 [INFO]: Epoch 041 - training loss: 0.1678, validation loss: 0.1413
2024-06-03 08:57:42 [INFO]: Epoch 042 - training loss: 0.1377, validation loss: 0.1422
2024-06-03 08:58:08 [INFO]: Epoch 043 - training loss: 0.1704, validation loss: 0.1383
2024-06-03 08:58:34 [INFO]: Epoch 044 - training loss: 0.1542, validation loss: 0.1359
2024-06-03 08:59:00 [INFO]: Epoch 045 - training loss: 0.1657, validation loss: 0.1405
2024-06-03 08:59:26 [INFO]: Epoch 046 - training loss: 0.1566, validation loss: 0.1365
2024-06-03 08:59:52 [INFO]: Epoch 047 - training loss: 0.1667, validation loss: 0.1431
2024-06-03 09:00:18 [INFO]: Epoch 048 - training loss: 0.1464, validation loss: 0.1423
2024-06-03 09:00:44 [INFO]: Epoch 049 - training loss: 0.1727, validation loss: 0.1352
2024-06-03 09:01:10 [INFO]: Epoch 050 - training loss: 0.1571, validation loss: 0.1338
2024-06-03 09:01:36 [INFO]: Epoch 051 - training loss: 0.1337, validation loss: 0.1337
2024-06-03 09:02:03 [INFO]: Epoch 052 - training loss: 0.1676, validation loss: 0.1341
2024-06-03 09:02:29 [INFO]: Epoch 053 - training loss: 0.1451, validation loss: 0.1320
2024-06-03 09:02:55 [INFO]: Epoch 054 - training loss: 0.1504, validation loss: 0.1345
2024-06-03 09:03:21 [INFO]: Epoch 055 - training loss: 0.1616, validation loss: 0.1355
2024-06-03 09:03:47 [INFO]: Epoch 056 - training loss: 0.1330, validation loss: 0.1303
2024-06-03 09:04:13 [INFO]: Epoch 057 - training loss: 0.1505, validation loss: 0.1312
2024-06-03 09:04:39 [INFO]: Epoch 058 - training loss: 0.1446, validation loss: 0.1412
2024-06-03 09:05:05 [INFO]: Epoch 059 - training loss: 0.1694, validation loss: 0.1287
2024-06-03 09:05:31 [INFO]: Epoch 060 - training loss: 0.1478, validation loss: 0.1340
2024-06-03 09:05:57 [INFO]: Epoch 061 - training loss: 0.1607, validation loss: 0.1292
2024-06-03 09:06:24 [INFO]: Epoch 062 - training loss: 0.1740, validation loss: 0.1312
2024-06-03 09:06:50 [INFO]: Epoch 063 - training loss: 0.1536, validation loss: 0.1295
2024-06-03 09:07:16 [INFO]: Epoch 064 - training loss: 0.1549, validation loss: 0.1336
2024-06-03 09:07:42 [INFO]: Epoch 065 - training loss: 0.1553, validation loss: 0.1302
2024-06-03 09:08:08 [INFO]: Epoch 066 - training loss: 0.1584, validation loss: 0.1302
2024-06-03 09:08:34 [INFO]: Epoch 067 - training loss: 0.1567, validation loss: 0.1299
2024-06-03 09:09:00 [INFO]: Epoch 068 - training loss: 0.1556, validation loss: 0.1296
2024-06-03 09:09:26 [INFO]: Epoch 069 - training loss: 0.1380, validation loss: 0.1282
2024-06-03 09:09:52 [INFO]: Epoch 070 - training loss: 0.1528, validation loss: 0.1311
2024-06-03 09:10:18 [INFO]: Epoch 071 - training loss: 0.1705, validation loss: 0.1262
2024-06-03 09:10:45 [INFO]: Epoch 072 - training loss: 0.1419, validation loss: 0.1311
2024-06-03 09:11:11 [INFO]: Epoch 073 - training loss: 0.1528, validation loss: 0.1319
2024-06-03 09:11:37 [INFO]: Epoch 074 - training loss: 0.1548, validation loss: 0.1299
2024-06-03 09:12:03 [INFO]: Epoch 075 - training loss: 0.1617, validation loss: 0.1279
2024-06-03 09:12:29 [INFO]: Epoch 076 - training loss: 0.1504, validation loss: 0.1256
2024-06-03 09:12:55 [INFO]: Epoch 077 - training loss: 0.1498, validation loss: 0.1256
2024-06-03 09:13:21 [INFO]: Epoch 078 - training loss: 0.1389, validation loss: 0.1309
2024-06-03 09:13:47 [INFO]: Epoch 079 - training loss: 0.1638, validation loss: 0.1305
2024-06-03 09:14:13 [INFO]: Epoch 080 - training loss: 0.1484, validation loss: 0.1298
2024-06-03 09:14:39 [INFO]: Epoch 081 - training loss: 0.1385, validation loss: 0.1285
2024-06-03 09:15:05 [INFO]: Epoch 082 - training loss: 0.1420, validation loss: 0.1242
2024-06-03 09:15:32 [INFO]: Epoch 083 - training loss: 0.1361, validation loss: 0.1274
2024-06-03 09:15:58 [INFO]: Epoch 084 - training loss: 0.1611, validation loss: 0.1302
2024-06-03 09:16:24 [INFO]: Epoch 085 - training loss: 0.1428, validation loss: 0.1236
2024-06-03 09:16:50 [INFO]: Epoch 086 - training loss: 0.1423, validation loss: 0.1284
2024-06-03 09:17:16 [INFO]: Epoch 087 - training loss: 0.1617, validation loss: 0.1275
2024-06-03 09:17:42 [INFO]: Epoch 088 - training loss: 0.1403, validation loss: 0.1256
2024-06-03 09:18:08 [INFO]: Epoch 089 - training loss: 0.1549, validation loss: 0.1277
2024-06-03 09:18:34 [INFO]: Epoch 090 - training loss: 0.1465, validation loss: 0.1240
2024-06-03 09:19:00 [INFO]: Epoch 091 - training loss: 0.1336, validation loss: 0.1235
2024-06-03 09:19:26 [INFO]: Epoch 092 - training loss: 0.1514, validation loss: 0.1277
2024-06-03 09:19:53 [INFO]: Epoch 093 - training loss: 0.1340, validation loss: 0.1254
2024-06-03 09:20:19 [INFO]: Epoch 094 - training loss: 0.1588, validation loss: 0.1236
2024-06-03 09:20:45 [INFO]: Epoch 095 - training loss: 0.1371, validation loss: 0.1246
2024-06-03 09:21:11 [INFO]: Epoch 096 - training loss: 0.1409, validation loss: 0.1256
2024-06-03 09:21:37 [INFO]: Epoch 097 - training loss: 0.1443, validation loss: 0.1283
2024-06-03 09:22:03 [INFO]: Epoch 098 - training loss: 0.1512, validation loss: 0.1249
2024-06-03 09:22:29 [INFO]: Epoch 099 - training loss: 0.1495, validation loss: 0.1261
2024-06-03 09:22:55 [INFO]: Epoch 100 - training loss: 0.1609, validation loss: 0.1313
2024-06-03 09:22:55 [INFO]: Finished training. The best model is from epoch#91.
2024-06-03 09:22:55 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_3/20240603_T083925/CSDI.pypots
2024-06-03 09:40:16 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_3/imputation.pkl
2024-06-03 09:40:16 [INFO]: Round3 - CSDI on BeijingAir: MAE=0.2101, MSE=0.3203, MRE=0.2868
2024-06-03 09:40:16 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 09:40:16 [INFO]: Using the given device: cuda:0
2024-06-03 09:40:16 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T094016
2024-06-03 09:40:16 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T094016/tensorboard
2024-06-03 09:40:16 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 244,833
2024-06-03 09:40:42 [INFO]: Epoch 001 - training loss: 0.5191, validation loss: 0.3301
2024-06-03 09:41:08 [INFO]: Epoch 002 - training loss: 0.3553, validation loss: 0.2901
2024-06-03 09:41:34 [INFO]: Epoch 003 - training loss: 0.3294, validation loss: 0.2726
2024-06-03 09:42:00 [INFO]: Epoch 004 - training loss: 0.2865, validation loss: 0.2318
2024-06-03 09:42:27 [INFO]: Epoch 005 - training loss: 0.2519, validation loss: 0.2167
2024-06-03 09:42:53 [INFO]: Epoch 006 - training loss: 0.2343, validation loss: 0.1992
2024-06-03 09:43:19 [INFO]: Epoch 007 - training loss: 0.2172, validation loss: 0.1953
2024-06-03 09:43:45 [INFO]: Epoch 008 - training loss: 0.2359, validation loss: 0.1830
2024-06-03 09:44:11 [INFO]: Epoch 009 - training loss: 0.2051, validation loss: 0.1894
2024-06-03 09:44:37 [INFO]: Epoch 010 - training loss: 0.2064, validation loss: 0.1887
2024-06-03 09:45:03 [INFO]: Epoch 011 - training loss: 0.1924, validation loss: 0.1754
2024-06-03 09:45:29 [INFO]: Epoch 012 - training loss: 0.1883, validation loss: 0.1817
2024-06-03 09:45:55 [INFO]: Epoch 013 - training loss: 0.1893, validation loss: 0.1668
2024-06-03 09:46:21 [INFO]: Epoch 014 - training loss: 0.1888, validation loss: 0.1770
2024-06-03 09:46:48 [INFO]: Epoch 015 - training loss: 0.1956, validation loss: 0.1783
2024-06-03 09:47:14 [INFO]: Epoch 016 - training loss: 0.1904, validation loss: 0.1676
2024-06-03 09:47:40 [INFO]: Epoch 017 - training loss: 0.2023, validation loss: 0.1656
2024-06-03 09:48:06 [INFO]: Epoch 018 - training loss: 0.1884, validation loss: 0.1780
2024-06-03 09:48:32 [INFO]: Epoch 019 - training loss: 0.1864, validation loss: 0.1720
2024-06-03 09:48:58 [INFO]: Epoch 020 - training loss: 0.1861, validation loss: 0.1659
2024-06-03 09:49:24 [INFO]: Epoch 021 - training loss: 0.1850, validation loss: 0.1620
2024-06-03 09:49:50 [INFO]: Epoch 022 - training loss: 0.1726, validation loss: 0.1601
2024-06-03 09:50:16 [INFO]: Epoch 023 - training loss: 0.1821, validation loss: 0.1613
2024-06-03 09:50:42 [INFO]: Epoch 024 - training loss: 0.1932, validation loss: 0.1612
2024-06-03 09:51:09 [INFO]: Epoch 025 - training loss: 0.1860, validation loss: 0.1636
2024-06-03 09:51:35 [INFO]: Epoch 026 - training loss: 0.1916, validation loss: 0.1747
2024-06-03 09:52:01 [INFO]: Epoch 027 - training loss: 0.1887, validation loss: 0.1689
2024-06-03 09:52:27 [INFO]: Epoch 028 - training loss: 0.1817, validation loss: 0.1635
2024-06-03 09:52:53 [INFO]: Epoch 029 - training loss: 0.1749, validation loss: 0.1557
2024-06-03 09:53:19 [INFO]: Epoch 030 - training loss: 0.1966, validation loss: 0.1640
2024-06-03 09:53:45 [INFO]: Epoch 031 - training loss: 0.1875, validation loss: 0.1552
2024-06-03 09:54:11 [INFO]: Epoch 032 - training loss: 0.1684, validation loss: 0.1540
2024-06-03 09:54:37 [INFO]: Epoch 033 - training loss: 0.1574, validation loss: 0.1507
2024-06-03 09:55:03 [INFO]: Epoch 034 - training loss: 0.1657, validation loss: 0.1545
2024-06-03 09:55:30 [INFO]: Epoch 035 - training loss: 0.1759, validation loss: 0.1577
2024-06-03 09:55:56 [INFO]: Epoch 036 - training loss: 0.1710, validation loss: 0.1507
2024-06-03 09:56:22 [INFO]: Epoch 037 - training loss: 0.1694, validation loss: 0.1498
2024-06-03 09:56:48 [INFO]: Epoch 038 - training loss: 0.1733, validation loss: 0.1460
2024-06-03 09:57:14 [INFO]: Epoch 039 - training loss: 0.1735, validation loss: 0.1489
2024-06-03 09:57:40 [INFO]: Epoch 040 - training loss: 0.1738, validation loss: 0.1444
2024-06-03 09:58:06 [INFO]: Epoch 041 - training loss: 0.1704, validation loss: 0.1496
2024-06-03 09:58:32 [INFO]: Epoch 042 - training loss: 0.1778, validation loss: 0.1458
2024-06-03 09:58:58 [INFO]: Epoch 043 - training loss: 0.1813, validation loss: 0.1515
2024-06-03 09:59:24 [INFO]: Epoch 044 - training loss: 0.1495, validation loss: 0.1425
2024-06-03 09:59:51 [INFO]: Epoch 045 - training loss: 0.1708, validation loss: 0.1398
2024-06-03 10:00:17 [INFO]: Epoch 046 - training loss: 0.1507, validation loss: 0.1449
2024-06-03 10:00:43 [INFO]: Epoch 047 - training loss: 0.1505, validation loss: 0.1450
2024-06-03 10:01:09 [INFO]: Epoch 048 - training loss: 0.1570, validation loss: 0.1477
2024-06-03 10:01:35 [INFO]: Epoch 049 - training loss: 0.1659, validation loss: 0.1412
2024-06-03 10:02:01 [INFO]: Epoch 050 - training loss: 0.1756, validation loss: 0.1508
2024-06-03 10:02:27 [INFO]: Epoch 051 - training loss: 0.1542, validation loss: 0.1410
2024-06-03 10:02:53 [INFO]: Epoch 052 - training loss: 0.1668, validation loss: 0.1384
2024-06-03 10:03:19 [INFO]: Epoch 053 - training loss: 0.1575, validation loss: 0.1357
2024-06-03 10:03:45 [INFO]: Epoch 054 - training loss: 0.1733, validation loss: 0.1375
2024-06-03 10:04:12 [INFO]: Epoch 055 - training loss: 0.1757, validation loss: 0.1368
2024-06-03 10:04:38 [INFO]: Epoch 056 - training loss: 0.1597, validation loss: 0.1340
2024-06-03 10:05:04 [INFO]: Epoch 057 - training loss: 0.1460, validation loss: 0.1361
2024-06-03 10:05:30 [INFO]: Epoch 058 - training loss: 0.1531, validation loss: 0.1326
2024-06-03 10:05:56 [INFO]: Epoch 059 - training loss: 0.1642, validation loss: 0.1385
2024-06-03 10:06:22 [INFO]: Epoch 060 - training loss: 0.1496, validation loss: 0.1327
2024-06-03 10:06:48 [INFO]: Epoch 061 - training loss: 0.1583, validation loss: 0.1336
2024-06-03 10:07:14 [INFO]: Epoch 062 - training loss: 0.1668, validation loss: 0.1365
2024-06-03 10:07:40 [INFO]: Epoch 063 - training loss: 0.1426, validation loss: 0.1336
2024-06-03 10:08:06 [INFO]: Epoch 064 - training loss: 0.1427, validation loss: 0.1376
2024-06-03 10:08:33 [INFO]: Epoch 065 - training loss: 0.1398, validation loss: 0.1351
2024-06-03 10:08:59 [INFO]: Epoch 066 - training loss: 0.1379, validation loss: 0.1324
2024-06-03 10:09:25 [INFO]: Epoch 067 - training loss: 0.1502, validation loss: 0.1341
2024-06-03 10:09:51 [INFO]: Epoch 068 - training loss: 0.1580, validation loss: 0.1361
2024-06-03 10:10:17 [INFO]: Epoch 069 - training loss: 0.1527, validation loss: 0.1290
2024-06-03 10:10:43 [INFO]: Epoch 070 - training loss: 0.1529, validation loss: 0.1290
2024-06-03 10:11:09 [INFO]: Epoch 071 - training loss: 0.1545, validation loss: 0.1324
2024-06-03 10:11:35 [INFO]: Epoch 072 - training loss: 0.1502, validation loss: 0.1353
2024-06-03 10:12:02 [INFO]: Epoch 073 - training loss: 0.1454, validation loss: 0.1296
2024-06-03 10:12:28 [INFO]: Epoch 074 - training loss: 0.1631, validation loss: 0.1341
2024-06-03 10:12:54 [INFO]: Epoch 075 - training loss: 0.1715, validation loss: 0.1385
2024-06-03 10:13:20 [INFO]: Epoch 076 - training loss: 0.1616, validation loss: 0.1310
2024-06-03 10:13:46 [INFO]: Epoch 077 - training loss: 0.1502, validation loss: 0.1288
2024-06-03 10:14:12 [INFO]: Epoch 078 - training loss: 0.1562, validation loss: 0.1262
2024-06-03 10:14:38 [INFO]: Epoch 079 - training loss: 0.1422, validation loss: 0.1267
2024-06-03 10:15:04 [INFO]: Epoch 080 - training loss: 0.1476, validation loss: 0.1241
2024-06-03 10:15:31 [INFO]: Epoch 081 - training loss: 0.1458, validation loss: 0.1283
2024-06-03 10:15:57 [INFO]: Epoch 082 - training loss: 0.1351, validation loss: 0.1282
2024-06-03 10:16:23 [INFO]: Epoch 083 - training loss: 0.1626, validation loss: 0.1262
2024-06-03 10:16:49 [INFO]: Epoch 084 - training loss: 0.1428, validation loss: 0.1247
2024-06-03 10:17:15 [INFO]: Epoch 085 - training loss: 0.1481, validation loss: 0.1291
2024-06-03 10:17:41 [INFO]: Epoch 086 - training loss: 0.1419, validation loss: 0.1255
2024-06-03 10:18:07 [INFO]: Epoch 087 - training loss: 0.1577, validation loss: 0.1313
2024-06-03 10:18:33 [INFO]: Epoch 088 - training loss: 0.1290, validation loss: 0.1287
2024-06-03 10:18:59 [INFO]: Epoch 089 - training loss: 0.1407, validation loss: 0.1245
2024-06-03 10:19:26 [INFO]: Epoch 090 - training loss: 0.1477, validation loss: 0.1277
2024-06-03 10:19:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 10:19:26 [INFO]: Finished training. The best model is from epoch#80.
2024-06-03 10:19:26 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_4/20240603_T094016/CSDI.pypots
2024-06-03 10:36:47 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/CSDI_BeijingAir/round_4/imputation.pkl
2024-06-03 10:36:47 [INFO]: Round4 - CSDI on BeijingAir: MAE=0.2118, MSE=0.2896, MRE=0.2891
2024-06-03 10:36:47 [INFO]: Done! Final results:
Averaged CSDI (244,833 params) on BeijingAir: MAE=0.2108 ± 0.030723542677404722, MSE=0.5118 ± 0.32299651175369193, MRE=0.2801 ± 0.04082593193401025, average inference time=286.71