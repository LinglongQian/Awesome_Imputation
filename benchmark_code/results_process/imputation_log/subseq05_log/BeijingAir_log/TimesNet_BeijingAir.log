2024-06-03 12:03:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:03:08 [INFO]: Using the given device: cuda:0
2024-06-03 12:03:09 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_0/20240603_T120308
2024-06-03 12:03:09 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_0/20240603_T120308/tensorboard
2024-06-03 12:03:11 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 87,063,940
2024-06-03 12:03:25 [INFO]: Epoch 001 - training loss: 0.5363, validation loss: 0.3663
2024-06-03 12:03:30 [INFO]: Epoch 002 - training loss: 0.2795, validation loss: 0.3072
2024-06-03 12:03:35 [INFO]: Epoch 003 - training loss: 0.2233, validation loss: 0.2991
2024-06-03 12:03:40 [INFO]: Epoch 004 - training loss: 0.2294, validation loss: 0.2906
2024-06-03 12:03:46 [INFO]: Epoch 005 - training loss: 0.2087, validation loss: 0.2881
2024-06-03 12:03:51 [INFO]: Epoch 006 - training loss: 0.2025, validation loss: 0.2887
2024-06-03 12:03:56 [INFO]: Epoch 007 - training loss: 0.1831, validation loss: 0.2793
2024-06-03 12:04:01 [INFO]: Epoch 008 - training loss: 0.1708, validation loss: 0.2809
2024-06-03 12:04:06 [INFO]: Epoch 009 - training loss: 0.1795, validation loss: 0.2729
2024-06-03 12:04:11 [INFO]: Epoch 010 - training loss: 0.1572, validation loss: 0.2764
2024-06-03 12:04:16 [INFO]: Epoch 011 - training loss: 0.1990, validation loss: 0.2701
2024-06-03 12:04:21 [INFO]: Epoch 012 - training loss: 0.1625, validation loss: 0.2705
2024-06-03 12:04:26 [INFO]: Epoch 013 - training loss: 0.1425, validation loss: 0.2726
2024-06-03 12:04:31 [INFO]: Epoch 014 - training loss: 0.1613, validation loss: 0.2721
2024-06-03 12:04:36 [INFO]: Epoch 015 - training loss: 0.1618, validation loss: 0.2730
2024-06-03 12:04:41 [INFO]: Epoch 016 - training loss: 0.1618, validation loss: 0.2792
2024-06-03 12:04:46 [INFO]: Epoch 017 - training loss: 0.1785, validation loss: 0.2924
2024-06-03 12:04:51 [INFO]: Epoch 018 - training loss: 0.1665, validation loss: 0.2712
2024-06-03 12:04:56 [INFO]: Epoch 019 - training loss: 0.1624, validation loss: 0.2695
2024-06-03 12:05:01 [INFO]: Epoch 020 - training loss: 0.1501, validation loss: 0.2691
2024-06-03 12:05:06 [INFO]: Epoch 021 - training loss: 0.1614, validation loss: 0.2683
2024-06-03 12:05:12 [INFO]: Epoch 022 - training loss: 0.1405, validation loss: 0.2693
2024-06-03 12:05:17 [INFO]: Epoch 023 - training loss: 0.1348, validation loss: 0.2694
2024-06-03 12:05:22 [INFO]: Epoch 024 - training loss: 0.1297, validation loss: 0.2662
2024-06-03 12:05:27 [INFO]: Epoch 025 - training loss: 0.1227, validation loss: 0.2622
2024-06-03 12:05:32 [INFO]: Epoch 026 - training loss: 0.1339, validation loss: 0.2643
2024-06-03 12:05:38 [INFO]: Epoch 027 - training loss: 0.1591, validation loss: 0.2748
2024-06-03 12:05:43 [INFO]: Epoch 028 - training loss: 0.1385, validation loss: 0.2713
2024-06-03 12:05:48 [INFO]: Epoch 029 - training loss: 0.1572, validation loss: 0.2692
2024-06-03 12:05:53 [INFO]: Epoch 030 - training loss: 0.1457, validation loss: 0.2743
2024-06-03 12:05:58 [INFO]: Epoch 031 - training loss: 0.1365, validation loss: 0.2718
2024-06-03 12:06:03 [INFO]: Epoch 032 - training loss: 0.1309, validation loss: 0.2629
2024-06-03 12:06:08 [INFO]: Epoch 033 - training loss: 0.1523, validation loss: 0.2725
2024-06-03 12:06:13 [INFO]: Epoch 034 - training loss: 0.1300, validation loss: 0.2672
2024-06-03 12:06:17 [INFO]: Epoch 035 - training loss: 0.1395, validation loss: 0.2614
2024-06-03 12:06:22 [INFO]: Epoch 036 - training loss: 0.1196, validation loss: 0.2640
2024-06-03 12:06:27 [INFO]: Epoch 037 - training loss: 0.1377, validation loss: 0.2696
2024-06-03 12:06:32 [INFO]: Epoch 038 - training loss: 0.1294, validation loss: 0.2708
2024-06-03 12:06:37 [INFO]: Epoch 039 - training loss: 0.1258, validation loss: 0.2666
2024-06-03 12:06:42 [INFO]: Epoch 040 - training loss: 0.1182, validation loss: 0.2738
2024-06-03 12:06:47 [INFO]: Epoch 041 - training loss: 0.1262, validation loss: 0.2725
2024-06-03 12:06:53 [INFO]: Epoch 042 - training loss: 0.1296, validation loss: 0.2780
2024-06-03 12:06:58 [INFO]: Epoch 043 - training loss: 0.1178, validation loss: 0.2703
2024-06-03 12:07:03 [INFO]: Epoch 044 - training loss: 0.1220, validation loss: 0.2664
2024-06-03 12:07:08 [INFO]: Epoch 045 - training loss: 0.1126, validation loss: 0.2684
2024-06-03 12:07:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:07:08 [INFO]: Finished training. The best model is from epoch#35.
2024-06-03 12:07:11 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_0/20240603_T120308/TimesNet.pypots
2024-06-03 12:07:14 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_0/imputation.pkl
2024-06-03 12:07:14 [INFO]: Round0 - TimesNet on BeijingAir: MAE=0.3130, MSE=0.3414, MRE=0.4272
2024-06-03 12:07:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:07:14 [INFO]: Using the given device: cuda:0
2024-06-03 12:07:14 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_1/20240603_T120714
2024-06-03 12:07:14 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_1/20240603_T120714/tensorboard
2024-06-03 12:07:19 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 87,063,940
2024-06-03 12:07:24 [INFO]: Epoch 001 - training loss: 0.5222, validation loss: 0.3658
2024-06-03 12:07:30 [INFO]: Epoch 002 - training loss: 0.2920, validation loss: 0.3061
2024-06-03 12:07:35 [INFO]: Epoch 003 - training loss: 0.2652, validation loss: 0.2994
2024-06-03 12:07:40 [INFO]: Epoch 004 - training loss: 0.2446, validation loss: 0.2932
2024-06-03 12:07:46 [INFO]: Epoch 005 - training loss: 0.2030, validation loss: 0.2899
2024-06-03 12:07:51 [INFO]: Epoch 006 - training loss: 0.1996, validation loss: 0.2819
2024-06-03 12:07:56 [INFO]: Epoch 007 - training loss: 0.1911, validation loss: 0.2837
2024-06-03 12:08:01 [INFO]: Epoch 008 - training loss: 0.1838, validation loss: 0.2777
2024-06-03 12:08:06 [INFO]: Epoch 009 - training loss: 0.1912, validation loss: 0.2821
2024-06-03 12:08:11 [INFO]: Epoch 010 - training loss: 0.1741, validation loss: 0.2701
2024-06-03 12:08:17 [INFO]: Epoch 011 - training loss: 0.1656, validation loss: 0.2744
2024-06-03 12:08:22 [INFO]: Epoch 012 - training loss: 0.1653, validation loss: 0.2793
2024-06-03 12:08:28 [INFO]: Epoch 013 - training loss: 0.1861, validation loss: 0.2793
2024-06-03 12:08:33 [INFO]: Epoch 014 - training loss: 0.1626, validation loss: 0.2796
2024-06-03 12:08:39 [INFO]: Epoch 015 - training loss: 0.1475, validation loss: 0.2720
2024-06-03 12:08:44 [INFO]: Epoch 016 - training loss: 0.1615, validation loss: 0.2770
2024-06-03 12:08:49 [INFO]: Epoch 017 - training loss: 0.1397, validation loss: 0.2723
2024-06-03 12:08:54 [INFO]: Epoch 018 - training loss: 0.1545, validation loss: 0.2698
2024-06-03 12:09:00 [INFO]: Epoch 019 - training loss: 0.1595, validation loss: 0.2730
2024-06-03 12:09:05 [INFO]: Epoch 020 - training loss: 0.1416, validation loss: 0.2756
2024-06-03 12:09:10 [INFO]: Epoch 021 - training loss: 0.1524, validation loss: 0.2792
2024-06-03 12:09:15 [INFO]: Epoch 022 - training loss: 0.1487, validation loss: 0.2733
2024-06-03 12:09:20 [INFO]: Epoch 023 - training loss: 0.1427, validation loss: 0.2693
2024-06-03 12:09:25 [INFO]: Epoch 024 - training loss: 0.1414, validation loss: 0.2692
2024-06-03 12:09:31 [INFO]: Epoch 025 - training loss: 0.1590, validation loss: 0.2737
2024-06-03 12:09:35 [INFO]: Epoch 026 - training loss: 0.1412, validation loss: 0.2767
2024-06-03 12:09:41 [INFO]: Epoch 027 - training loss: 0.1390, validation loss: 0.2734
2024-06-03 12:09:46 [INFO]: Epoch 028 - training loss: 0.1399, validation loss: 0.2730
2024-06-03 12:09:51 [INFO]: Epoch 029 - training loss: 0.1445, validation loss: 0.2669
2024-06-03 12:09:56 [INFO]: Epoch 030 - training loss: 0.1394, validation loss: 0.2694
2024-06-03 12:10:01 [INFO]: Epoch 031 - training loss: 0.1563, validation loss: 0.2818
2024-06-03 12:10:06 [INFO]: Epoch 032 - training loss: 0.1219, validation loss: 0.2697
2024-06-03 12:10:11 [INFO]: Epoch 033 - training loss: 0.1346, validation loss: 0.2707
2024-06-03 12:10:16 [INFO]: Epoch 034 - training loss: 0.1428, validation loss: 0.2666
2024-06-03 12:10:21 [INFO]: Epoch 035 - training loss: 0.1360, validation loss: 0.2760
2024-06-03 12:10:27 [INFO]: Epoch 036 - training loss: 0.1388, validation loss: 0.2679
2024-06-03 12:10:32 [INFO]: Epoch 037 - training loss: 0.1333, validation loss: 0.2771
2024-06-03 12:10:37 [INFO]: Epoch 038 - training loss: 0.1190, validation loss: 0.2715
2024-06-03 12:10:42 [INFO]: Epoch 039 - training loss: 0.1381, validation loss: 0.2616
2024-06-03 12:10:47 [INFO]: Epoch 040 - training loss: 0.1288, validation loss: 0.2682
2024-06-03 12:10:52 [INFO]: Epoch 041 - training loss: 0.1311, validation loss: 0.2768
2024-06-03 12:10:57 [INFO]: Epoch 042 - training loss: 0.1345, validation loss: 0.2790
2024-06-03 12:11:02 [INFO]: Epoch 043 - training loss: 0.1286, validation loss: 0.2738
2024-06-03 12:11:07 [INFO]: Epoch 044 - training loss: 0.1160, validation loss: 0.2699
2024-06-03 12:11:12 [INFO]: Epoch 045 - training loss: 0.1231, validation loss: 0.2654
2024-06-03 12:11:17 [INFO]: Epoch 046 - training loss: 0.1205, validation loss: 0.2719
2024-06-03 12:11:22 [INFO]: Epoch 047 - training loss: 0.1258, validation loss: 0.2744
2024-06-03 12:11:27 [INFO]: Epoch 048 - training loss: 0.1179, validation loss: 0.2755
2024-06-03 12:11:31 [INFO]: Epoch 049 - training loss: 0.1196, validation loss: 0.2704
2024-06-03 12:11:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:11:31 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 12:11:34 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_1/20240603_T120714/TimesNet.pypots
2024-06-03 12:11:37 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_1/imputation.pkl
2024-06-03 12:11:37 [INFO]: Round1 - TimesNet on BeijingAir: MAE=0.3108, MSE=0.3396, MRE=0.4242
2024-06-03 12:11:37 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:11:37 [INFO]: Using the given device: cuda:0
2024-06-03 12:11:37 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_2/20240603_T121137
2024-06-03 12:11:37 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_2/20240603_T121137/tensorboard
2024-06-03 12:11:43 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 87,063,940
2024-06-03 12:11:48 [INFO]: Epoch 001 - training loss: 0.5076, validation loss: 0.3690
2024-06-03 12:11:54 [INFO]: Epoch 002 - training loss: 0.2841, validation loss: 0.3090
2024-06-03 12:11:59 [INFO]: Epoch 003 - training loss: 0.2432, validation loss: 0.2974
2024-06-03 12:12:04 [INFO]: Epoch 004 - training loss: 0.2337, validation loss: 0.2832
2024-06-03 12:12:10 [INFO]: Epoch 005 - training loss: 0.2290, validation loss: 0.2875
2024-06-03 12:12:15 [INFO]: Epoch 006 - training loss: 0.2405, validation loss: 0.2808
2024-06-03 12:12:20 [INFO]: Epoch 007 - training loss: 0.1921, validation loss: 0.2871
2024-06-03 12:12:25 [INFO]: Epoch 008 - training loss: 0.2135, validation loss: 0.2897
2024-06-03 12:12:30 [INFO]: Epoch 009 - training loss: 0.1820, validation loss: 0.2716
2024-06-03 12:12:35 [INFO]: Epoch 010 - training loss: 0.1878, validation loss: 0.2757
2024-06-03 12:12:41 [INFO]: Epoch 011 - training loss: 0.1596, validation loss: 0.2728
2024-06-03 12:12:46 [INFO]: Epoch 012 - training loss: 0.1563, validation loss: 0.2753
2024-06-03 12:12:51 [INFO]: Epoch 013 - training loss: 0.1568, validation loss: 0.2781
2024-06-03 12:12:56 [INFO]: Epoch 014 - training loss: 0.1958, validation loss: 0.2794
2024-06-03 12:13:02 [INFO]: Epoch 015 - training loss: 0.1864, validation loss: 0.2745
2024-06-03 12:13:07 [INFO]: Epoch 016 - training loss: 0.1475, validation loss: 0.2654
2024-06-03 12:13:12 [INFO]: Epoch 017 - training loss: 0.1614, validation loss: 0.2727
2024-06-03 12:13:17 [INFO]: Epoch 018 - training loss: 0.1606, validation loss: 0.2772
2024-06-03 12:13:23 [INFO]: Epoch 019 - training loss: 0.1577, validation loss: 0.2787
2024-06-03 12:13:28 [INFO]: Epoch 020 - training loss: 0.1475, validation loss: 0.2765
2024-06-03 12:13:33 [INFO]: Epoch 021 - training loss: 0.1423, validation loss: 0.2727
2024-06-03 12:13:39 [INFO]: Epoch 022 - training loss: 0.1389, validation loss: 0.2725
2024-06-03 12:13:44 [INFO]: Epoch 023 - training loss: 0.1443, validation loss: 0.2669
2024-06-03 12:13:49 [INFO]: Epoch 024 - training loss: 0.1496, validation loss: 0.2741
2024-06-03 12:13:54 [INFO]: Epoch 025 - training loss: 0.1380, validation loss: 0.2664
2024-06-03 12:14:00 [INFO]: Epoch 026 - training loss: 0.1321, validation loss: 0.2655
2024-06-03 12:14:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:14:00 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 12:14:02 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_2/20240603_T121137/TimesNet.pypots
2024-06-03 12:14:05 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_2/imputation.pkl
2024-06-03 12:14:05 [INFO]: Round2 - TimesNet on BeijingAir: MAE=0.3116, MSE=0.3406, MRE=0.4253
2024-06-03 12:14:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 12:14:05 [INFO]: Using the given device: cuda:0
2024-06-03 12:14:05 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_3/20240603_T121405
2024-06-03 12:14:05 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_3/20240603_T121405/tensorboard
2024-06-03 12:14:11 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 87,063,940
2024-06-03 12:14:16 [INFO]: Epoch 001 - training loss: 0.5074, validation loss: 0.3701
2024-06-03 12:14:21 [INFO]: Epoch 002 - training loss: 0.2877, validation loss: 0.3053
2024-06-03 12:14:26 [INFO]: Epoch 003 - training loss: 0.2220, validation loss: 0.2954
2024-06-03 12:14:31 [INFO]: Epoch 004 - training loss: 0.2114, validation loss: 0.2848
2024-06-03 12:14:36 [INFO]: Epoch 005 - training loss: 0.2243, validation loss: 0.2783
2024-06-03 12:14:41 [INFO]: Epoch 006 - training loss: 0.1892, validation loss: 0.2743
2024-06-03 12:14:47 [INFO]: Epoch 007 - training loss: 0.2375, validation loss: 0.2798
2024-06-03 12:14:52 [INFO]: Epoch 008 - training loss: 0.1856, validation loss: 0.2729
2024-06-03 12:14:57 [INFO]: Epoch 009 - training loss: 0.1816, validation loss: 0.2831
2024-06-03 12:15:02 [INFO]: Epoch 010 - training loss: 0.1684, validation loss: 0.2773
2024-06-03 12:15:07 [INFO]: Epoch 011 - training loss: 0.1977, validation loss: 0.2703
2024-06-03 12:15:12 [INFO]: Epoch 012 - training loss: 0.1880, validation loss: 0.2849
2024-06-03 12:15:16 [INFO]: Epoch 013 - training loss: 0.1643, validation loss: 0.2739
2024-06-03 12:15:20 [INFO]: Epoch 014 - training loss: 0.1614, validation loss: 0.2699
2024-06-03 12:15:23 [INFO]: Epoch 015 - training loss: 0.1616, validation loss: 0.2750
2024-06-03 12:15:26 [INFO]: Epoch 016 - training loss: 0.1790, validation loss: 0.2649
2024-06-03 12:15:29 [INFO]: Epoch 017 - training loss: 0.1650, validation loss: 0.2723
2024-06-03 12:15:33 [INFO]: Epoch 018 - training loss: 0.1484, validation loss: 0.2695
2024-06-03 12:15:37 [INFO]: Epoch 019 - training loss: 0.1538, validation loss: 0.2725
2024-06-03 12:15:41 [INFO]: Epoch 020 - training loss: 0.1731, validation loss: 0.2775
2024-06-03 12:15:45 [INFO]: Epoch 021 - training loss: 0.1562, validation loss: 0.2768
2024-06-03 12:15:49 [INFO]: Epoch 022 - training loss: 0.1601, validation loss: 0.2740
2024-06-03 12:15:53 [INFO]: Epoch 023 - training loss: 0.1377, validation loss: 0.2798
2024-06-03 12:15:57 [INFO]: Epoch 024 - training loss: 0.1379, validation loss: 0.2670
2024-06-03 12:16:01 [INFO]: Epoch 025 - training loss: 0.1532, validation loss: 0.2673
2024-06-03 12:16:05 [INFO]: Epoch 026 - training loss: 0.1520, validation loss: 0.2663
2024-06-03 12:16:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:16:05 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 12:16:07 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_3/20240603_T121405/TimesNet.pypots
2024-06-03 12:16:09 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_3/imputation.pkl
2024-06-03 12:16:09 [INFO]: Round3 - TimesNet on BeijingAir: MAE=0.3141, MSE=0.3421, MRE=0.4287
2024-06-03 12:16:09 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:16:09 [INFO]: Using the given device: cuda:0
2024-06-03 12:16:09 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_4/20240603_T121609
2024-06-03 12:16:09 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_4/20240603_T121609/tensorboard
2024-06-03 12:16:14 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 87,063,940
2024-06-03 12:16:18 [INFO]: Epoch 001 - training loss: 0.5379, validation loss: 0.3434
2024-06-03 12:16:22 [INFO]: Epoch 002 - training loss: 0.2908, validation loss: 0.3054
2024-06-03 12:16:26 [INFO]: Epoch 003 - training loss: 0.2448, validation loss: 0.2968
2024-06-03 12:16:30 [INFO]: Epoch 004 - training loss: 0.2403, validation loss: 0.2843
2024-06-03 12:16:34 [INFO]: Epoch 005 - training loss: 0.2095, validation loss: 0.2810
2024-06-03 12:16:38 [INFO]: Epoch 006 - training loss: 0.1955, validation loss: 0.2792
2024-06-03 12:16:42 [INFO]: Epoch 007 - training loss: 0.1855, validation loss: 0.2844
2024-06-03 12:16:46 [INFO]: Epoch 008 - training loss: 0.1820, validation loss: 0.2723
2024-06-03 12:16:51 [INFO]: Epoch 009 - training loss: 0.1796, validation loss: 0.2766
2024-06-03 12:16:54 [INFO]: Epoch 010 - training loss: 0.1864, validation loss: 0.2870
2024-06-03 12:16:59 [INFO]: Epoch 011 - training loss: 0.1664, validation loss: 0.2818
2024-06-03 12:17:03 [INFO]: Epoch 012 - training loss: 0.1744, validation loss: 0.2751
2024-06-03 12:17:07 [INFO]: Epoch 013 - training loss: 0.1723, validation loss: 0.2757
2024-06-03 12:17:11 [INFO]: Epoch 014 - training loss: 0.1647, validation loss: 0.2864
2024-06-03 12:17:15 [INFO]: Epoch 015 - training loss: 0.1421, validation loss: 0.2740
2024-06-03 12:17:19 [INFO]: Epoch 016 - training loss: 0.1462, validation loss: 0.2750
2024-06-03 12:17:23 [INFO]: Epoch 017 - training loss: 0.1540, validation loss: 0.2815
2024-06-03 12:17:27 [INFO]: Epoch 018 - training loss: 0.1683, validation loss: 0.2736
2024-06-03 12:17:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:17:27 [INFO]: Finished training. The best model is from epoch#8.
2024-06-03 12:17:29 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_4/20240603_T121609/TimesNet.pypots
2024-06-03 12:17:31 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/TimesNet_BeijingAir/round_4/imputation.pkl
2024-06-03 12:17:31 [INFO]: Round4 - TimesNet on BeijingAir: MAE=0.3156, MSE=0.3308, MRE=0.4308
2024-06-03 12:17:31 [INFO]: Done! Final results:
Averaged TimesNet (87,063,940 params) on BeijingAir: MAE=0.3072 ± 0.0018112672012538151, MSE=0.3313 ± 0.004163452778265771, MRE=0.4082 ± 0.0024068406514551276, average inference time=0.64