2024-06-03 03:58:19 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:58:19 [INFO]: Using the given device: cuda:0
2024-06-03 03:58:19 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T035819
2024-06-03 03:58:19 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T035819/tensorboard
2024-06-03 03:58:20 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 03:58:41 [INFO]: Epoch 001 - training loss: 0.9464, validation loss: 0.6390
2024-06-03 03:58:58 [INFO]: Epoch 002 - training loss: 0.7754, validation loss: 0.5782
2024-06-03 03:59:14 [INFO]: Epoch 003 - training loss: 0.7160, validation loss: 0.5563
2024-06-03 03:59:31 [INFO]: Epoch 004 - training loss: 0.6762, validation loss: 0.5288
2024-06-03 03:59:48 [INFO]: Epoch 005 - training loss: 0.6480, validation loss: 0.5266
2024-06-03 04:00:04 [INFO]: Epoch 006 - training loss: 0.6295, validation loss: 0.5138
2024-06-03 04:00:21 [INFO]: Epoch 007 - training loss: 0.6099, validation loss: 0.5106
2024-06-03 04:00:37 [INFO]: Epoch 008 - training loss: 0.5945, validation loss: 0.5044
2024-06-03 04:00:54 [INFO]: Epoch 009 - training loss: 0.5847, validation loss: 0.4990
2024-06-03 04:01:10 [INFO]: Epoch 010 - training loss: 0.5746, validation loss: 0.4899
2024-06-03 04:01:27 [INFO]: Epoch 011 - training loss: 0.5645, validation loss: 0.4872
2024-06-03 04:01:44 [INFO]: Epoch 012 - training loss: 0.5561, validation loss: 0.4895
2024-06-03 04:02:01 [INFO]: Epoch 013 - training loss: 0.5483, validation loss: 0.4866
2024-06-03 04:02:18 [INFO]: Epoch 014 - training loss: 0.5419, validation loss: 0.4769
2024-06-03 04:02:34 [INFO]: Epoch 015 - training loss: 0.5371, validation loss: 0.4802
2024-06-03 04:02:51 [INFO]: Epoch 016 - training loss: 0.5298, validation loss: 0.4782
2024-06-03 04:03:07 [INFO]: Epoch 017 - training loss: 0.5275, validation loss: 0.4819
2024-06-03 04:03:24 [INFO]: Epoch 018 - training loss: 0.5206, validation loss: 0.4763
2024-06-03 04:03:41 [INFO]: Epoch 019 - training loss: 0.5177, validation loss: 0.4793
2024-06-03 04:03:57 [INFO]: Epoch 020 - training loss: 0.5129, validation loss: 0.4797
2024-06-03 04:04:14 [INFO]: Epoch 021 - training loss: 0.5104, validation loss: 0.4752
2024-06-03 04:04:30 [INFO]: Epoch 022 - training loss: 0.5077, validation loss: 0.4774
2024-06-03 04:04:46 [INFO]: Epoch 023 - training loss: 0.5031, validation loss: 0.4727
2024-06-03 04:05:01 [INFO]: Epoch 024 - training loss: 0.5013, validation loss: 0.4778
2024-06-03 04:05:17 [INFO]: Epoch 025 - training loss: 0.4995, validation loss: 0.4736
2024-06-03 04:05:33 [INFO]: Epoch 026 - training loss: 0.4988, validation loss: 0.4703
2024-06-03 04:05:48 [INFO]: Epoch 027 - training loss: 0.4943, validation loss: 0.4701
2024-06-03 04:06:04 [INFO]: Epoch 028 - training loss: 0.4937, validation loss: 0.4755
2024-06-03 04:06:19 [INFO]: Epoch 029 - training loss: 0.4904, validation loss: 0.4739
2024-06-03 04:06:33 [INFO]: Epoch 030 - training loss: 0.4886, validation loss: 0.4642
2024-06-03 04:06:48 [INFO]: Epoch 031 - training loss: 0.4892, validation loss: 0.4697
2024-06-03 04:07:02 [INFO]: Epoch 032 - training loss: 0.4860, validation loss: 0.4687
2024-06-03 04:07:15 [INFO]: Epoch 033 - training loss: 0.4839, validation loss: 0.4678
2024-06-03 04:07:30 [INFO]: Epoch 034 - training loss: 0.4833, validation loss: 0.4664
2024-06-03 04:07:43 [INFO]: Epoch 035 - training loss: 0.4824, validation loss: 0.4622
2024-06-03 04:07:57 [INFO]: Epoch 036 - training loss: 0.4815, validation loss: 0.4696
2024-06-03 04:08:11 [INFO]: Epoch 037 - training loss: 0.4792, validation loss: 0.4717
2024-06-03 04:08:24 [INFO]: Epoch 038 - training loss: 0.4802, validation loss: 0.4662
2024-06-03 04:08:38 [INFO]: Epoch 039 - training loss: 0.4777, validation loss: 0.4681
2024-06-03 04:08:52 [INFO]: Epoch 040 - training loss: 0.4769, validation loss: 0.4699
2024-06-03 04:09:06 [INFO]: Epoch 041 - training loss: 0.4763, validation loss: 0.4637
2024-06-03 04:09:20 [INFO]: Epoch 042 - training loss: 0.4747, validation loss: 0.4702
2024-06-03 04:09:34 [INFO]: Epoch 043 - training loss: 0.4731, validation loss: 0.4602
2024-06-03 04:09:47 [INFO]: Epoch 044 - training loss: 0.4718, validation loss: 0.4657
2024-06-03 04:10:00 [INFO]: Epoch 045 - training loss: 0.4726, validation loss: 0.4645
2024-06-03 04:10:11 [INFO]: Epoch 046 - training loss: 0.4696, validation loss: 0.4595
2024-06-03 04:10:23 [INFO]: Epoch 047 - training loss: 0.4682, validation loss: 0.4567
2024-06-03 04:10:34 [INFO]: Epoch 048 - training loss: 0.4699, validation loss: 0.4624
2024-06-03 04:10:46 [INFO]: Epoch 049 - training loss: 0.4681, validation loss: 0.4545
2024-06-03 04:10:58 [INFO]: Epoch 050 - training loss: 0.4670, validation loss: 0.4566
2024-06-03 04:11:10 [INFO]: Epoch 051 - training loss: 0.4672, validation loss: 0.4578
2024-06-03 04:11:22 [INFO]: Epoch 052 - training loss: 0.4664, validation loss: 0.4573
2024-06-03 04:11:33 [INFO]: Epoch 053 - training loss: 0.4641, validation loss: 0.4502
2024-06-03 04:11:45 [INFO]: Epoch 054 - training loss: 0.4626, validation loss: 0.4595
2024-06-03 04:11:57 [INFO]: Epoch 055 - training loss: 0.4626, validation loss: 0.4538
2024-06-03 04:12:09 [INFO]: Epoch 056 - training loss: 0.4617, validation loss: 0.4559
2024-06-03 04:12:21 [INFO]: Epoch 057 - training loss: 0.4619, validation loss: 0.4509
2024-06-03 04:12:32 [INFO]: Epoch 058 - training loss: 0.4622, validation loss: 0.4487
2024-06-03 04:12:44 [INFO]: Epoch 059 - training loss: 0.4617, validation loss: 0.4508
2024-06-03 04:12:56 [INFO]: Epoch 060 - training loss: 0.4609, validation loss: 0.4489
2024-06-03 04:13:08 [INFO]: Epoch 061 - training loss: 0.4591, validation loss: 0.4513
2024-06-03 04:13:20 [INFO]: Epoch 062 - training loss: 0.4583, validation loss: 0.4487
2024-06-03 04:13:32 [INFO]: Epoch 063 - training loss: 0.4588, validation loss: 0.4462
2024-06-03 04:13:44 [INFO]: Epoch 064 - training loss: 0.4591, validation loss: 0.4430
2024-06-03 04:13:55 [INFO]: Epoch 065 - training loss: 0.4573, validation loss: 0.4418
2024-06-03 04:14:07 [INFO]: Epoch 066 - training loss: 0.4582, validation loss: 0.4484
2024-06-03 04:14:19 [INFO]: Epoch 067 - training loss: 0.4565, validation loss: 0.4425
2024-06-03 04:14:31 [INFO]: Epoch 068 - training loss: 0.4547, validation loss: 0.4380
2024-06-03 04:14:42 [INFO]: Epoch 069 - training loss: 0.4537, validation loss: 0.4364
2024-06-03 04:14:54 [INFO]: Epoch 070 - training loss: 0.4538, validation loss: 0.4403
2024-06-03 04:15:06 [INFO]: Epoch 071 - training loss: 0.4539, validation loss: 0.4415
2024-06-03 04:15:18 [INFO]: Epoch 072 - training loss: 0.4524, validation loss: 0.4425
2024-06-03 04:15:30 [INFO]: Epoch 073 - training loss: 0.4536, validation loss: 0.4408
2024-06-03 04:15:41 [INFO]: Epoch 074 - training loss: 0.4522, validation loss: 0.4349
2024-06-03 04:15:53 [INFO]: Epoch 075 - training loss: 0.4519, validation loss: 0.4377
2024-06-03 04:16:05 [INFO]: Epoch 076 - training loss: 0.4511, validation loss: 0.4328
2024-06-03 04:16:16 [INFO]: Epoch 077 - training loss: 0.4522, validation loss: 0.4361
2024-06-03 04:16:28 [INFO]: Epoch 078 - training loss: 0.4500, validation loss: 0.4316
2024-06-03 04:16:40 [INFO]: Epoch 079 - training loss: 0.4482, validation loss: 0.4337
2024-06-03 04:16:52 [INFO]: Epoch 080 - training loss: 0.4497, validation loss: 0.4273
2024-06-03 04:17:04 [INFO]: Epoch 081 - training loss: 0.4504, validation loss: 0.4272
2024-06-03 04:17:15 [INFO]: Epoch 082 - training loss: 0.4482, validation loss: 0.4339
2024-06-03 04:17:27 [INFO]: Epoch 083 - training loss: 0.4480, validation loss: 0.4313
2024-06-03 04:17:39 [INFO]: Epoch 084 - training loss: 0.4458, validation loss: 0.4219
2024-06-03 04:17:51 [INFO]: Epoch 085 - training loss: 0.4451, validation loss: 0.4255
2024-06-03 04:18:02 [INFO]: Epoch 086 - training loss: 0.4465, validation loss: 0.4220
2024-06-03 04:18:14 [INFO]: Epoch 087 - training loss: 0.4460, validation loss: 0.4217
2024-06-03 04:18:25 [INFO]: Epoch 088 - training loss: 0.4460, validation loss: 0.4168
2024-06-03 04:18:37 [INFO]: Epoch 089 - training loss: 0.4447, validation loss: 0.4195
2024-06-03 04:18:48 [INFO]: Epoch 090 - training loss: 0.4448, validation loss: 0.4207
2024-06-03 04:19:00 [INFO]: Epoch 091 - training loss: 0.4435, validation loss: 0.4200
2024-06-03 04:19:12 [INFO]: Epoch 092 - training loss: 0.4435, validation loss: 0.4152
2024-06-03 04:19:23 [INFO]: Epoch 093 - training loss: 0.4409, validation loss: 0.4204
2024-06-03 04:19:35 [INFO]: Epoch 094 - training loss: 0.4432, validation loss: 0.4183
2024-06-03 04:19:47 [INFO]: Epoch 095 - training loss: 0.4423, validation loss: 0.4155
2024-06-03 04:19:58 [INFO]: Epoch 096 - training loss: 0.4395, validation loss: 0.4098
2024-06-03 04:20:10 [INFO]: Epoch 097 - training loss: 0.4406, validation loss: 0.4183
2024-06-03 04:20:21 [INFO]: Epoch 098 - training loss: 0.4392, validation loss: 0.4169
2024-06-03 04:20:33 [INFO]: Epoch 099 - training loss: 0.4398, validation loss: 0.4060
2024-06-03 04:20:45 [INFO]: Epoch 100 - training loss: 0.4388, validation loss: 0.4042
2024-06-03 04:20:45 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 04:20:45 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_0/20240603_T035819/ETSformer.pypots
2024-06-03 04:20:55 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_0/imputation.pkl
2024-06-03 04:20:55 [INFO]: Round0 - ETSformer on BeijingAir: MAE=0.3721, MSE=0.4702, MRE=0.5079
2024-06-03 04:20:55 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:20:55 [INFO]: Using the given device: cuda:0
2024-06-03 04:20:55 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T042055
2024-06-03 04:20:55 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T042055/tensorboard
2024-06-03 04:20:55 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 04:21:07 [INFO]: Epoch 001 - training loss: 0.9220, validation loss: 0.6506
2024-06-03 04:21:18 [INFO]: Epoch 002 - training loss: 0.7675, validation loss: 0.6167
2024-06-03 04:21:30 [INFO]: Epoch 003 - training loss: 0.6980, validation loss: 0.5477
2024-06-03 04:21:42 [INFO]: Epoch 004 - training loss: 0.6519, validation loss: 0.5124
2024-06-03 04:21:54 [INFO]: Epoch 005 - training loss: 0.6235, validation loss: 0.5079
2024-06-03 04:22:06 [INFO]: Epoch 006 - training loss: 0.6022, validation loss: 0.4968
2024-06-03 04:22:18 [INFO]: Epoch 007 - training loss: 0.5884, validation loss: 0.5077
2024-06-03 04:22:30 [INFO]: Epoch 008 - training loss: 0.5745, validation loss: 0.4932
2024-06-03 04:22:42 [INFO]: Epoch 009 - training loss: 0.5652, validation loss: 0.4975
2024-06-03 04:22:54 [INFO]: Epoch 010 - training loss: 0.5546, validation loss: 0.4892
2024-06-03 04:23:06 [INFO]: Epoch 011 - training loss: 0.5465, validation loss: 0.4880
2024-06-03 04:23:18 [INFO]: Epoch 012 - training loss: 0.5394, validation loss: 0.4882
2024-06-03 04:23:29 [INFO]: Epoch 013 - training loss: 0.5358, validation loss: 0.4822
2024-06-03 04:23:41 [INFO]: Epoch 014 - training loss: 0.5291, validation loss: 0.4899
2024-06-03 04:23:53 [INFO]: Epoch 015 - training loss: 0.5254, validation loss: 0.4925
2024-06-03 04:24:05 [INFO]: Epoch 016 - training loss: 0.5223, validation loss: 0.4825
2024-06-03 04:24:16 [INFO]: Epoch 017 - training loss: 0.5161, validation loss: 0.4852
2024-06-03 04:24:28 [INFO]: Epoch 018 - training loss: 0.5144, validation loss: 0.4888
2024-06-03 04:24:39 [INFO]: Epoch 019 - training loss: 0.5131, validation loss: 0.4815
2024-06-03 04:24:51 [INFO]: Epoch 020 - training loss: 0.5065, validation loss: 0.4770
2024-06-03 04:25:03 [INFO]: Epoch 021 - training loss: 0.5042, validation loss: 0.4785
2024-06-03 04:25:15 [INFO]: Epoch 022 - training loss: 0.5030, validation loss: 0.4736
2024-06-03 04:25:27 [INFO]: Epoch 023 - training loss: 0.5005, validation loss: 0.4753
2024-06-03 04:25:37 [INFO]: Epoch 024 - training loss: 0.4973, validation loss: 0.4823
2024-06-03 04:25:46 [INFO]: Epoch 025 - training loss: 0.4972, validation loss: 0.4782
2024-06-03 04:25:56 [INFO]: Epoch 026 - training loss: 0.4947, validation loss: 0.4892
2024-06-03 04:26:06 [INFO]: Epoch 027 - training loss: 0.4933, validation loss: 0.4755
2024-06-03 04:26:15 [INFO]: Epoch 028 - training loss: 0.4914, validation loss: 0.4750
2024-06-03 04:26:25 [INFO]: Epoch 029 - training loss: 0.4905, validation loss: 0.4804
2024-06-03 04:26:35 [INFO]: Epoch 030 - training loss: 0.4895, validation loss: 0.4826
2024-06-03 04:26:44 [INFO]: Epoch 031 - training loss: 0.4878, validation loss: 0.4865
2024-06-03 04:26:54 [INFO]: Epoch 032 - training loss: 0.4842, validation loss: 0.4744
2024-06-03 04:26:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:26:54 [INFO]: Finished training. The best model is from epoch#22.
2024-06-03 04:26:54 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_1/20240603_T042055/ETSformer.pypots
2024-06-03 04:27:02 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_1/imputation.pkl
2024-06-03 04:27:02 [INFO]: Round1 - ETSformer on BeijingAir: MAE=0.4142, MSE=0.5166, MRE=0.5654
2024-06-03 04:27:02 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 04:27:02 [INFO]: Using the given device: cuda:0
2024-06-03 04:27:02 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T042702
2024-06-03 04:27:02 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T042702/tensorboard
2024-06-03 04:27:02 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 04:27:12 [INFO]: Epoch 001 - training loss: 0.9167, validation loss: 0.6271
2024-06-03 04:27:22 [INFO]: Epoch 002 - training loss: 0.7556, validation loss: 0.5893
2024-06-03 04:27:32 [INFO]: Epoch 003 - training loss: 0.6916, validation loss: 0.5402
2024-06-03 04:27:42 [INFO]: Epoch 004 - training loss: 0.6518, validation loss: 0.5101
2024-06-03 04:27:51 [INFO]: Epoch 005 - training loss: 0.6226, validation loss: 0.5046
2024-06-03 04:28:01 [INFO]: Epoch 006 - training loss: 0.6016, validation loss: 0.5008
2024-06-03 04:28:11 [INFO]: Epoch 007 - training loss: 0.5850, validation loss: 0.5004
2024-06-03 04:28:21 [INFO]: Epoch 008 - training loss: 0.5732, validation loss: 0.4991
2024-06-03 04:28:30 [INFO]: Epoch 009 - training loss: 0.5622, validation loss: 0.4892
2024-06-03 04:28:40 [INFO]: Epoch 010 - training loss: 0.5518, validation loss: 0.4879
2024-06-03 04:28:50 [INFO]: Epoch 011 - training loss: 0.5444, validation loss: 0.4958
2024-06-03 04:29:00 [INFO]: Epoch 012 - training loss: 0.5385, validation loss: 0.4959
2024-06-03 04:29:10 [INFO]: Epoch 013 - training loss: 0.5319, validation loss: 0.4940
2024-06-03 04:29:19 [INFO]: Epoch 014 - training loss: 0.5257, validation loss: 0.4887
2024-06-03 04:29:29 [INFO]: Epoch 015 - training loss: 0.5213, validation loss: 0.4934
2024-06-03 04:29:39 [INFO]: Epoch 016 - training loss: 0.5186, validation loss: 0.4870
2024-06-03 04:29:49 [INFO]: Epoch 017 - training loss: 0.5139, validation loss: 0.4843
2024-06-03 04:29:59 [INFO]: Epoch 018 - training loss: 0.5095, validation loss: 0.4961
2024-06-03 04:30:08 [INFO]: Epoch 019 - training loss: 0.5061, validation loss: 0.4990
2024-06-03 04:30:18 [INFO]: Epoch 020 - training loss: 0.5042, validation loss: 0.4904
2024-06-03 04:30:28 [INFO]: Epoch 021 - training loss: 0.5005, validation loss: 0.4951
2024-06-03 04:30:37 [INFO]: Epoch 022 - training loss: 0.4995, validation loss: 0.4945
2024-06-03 04:30:47 [INFO]: Epoch 023 - training loss: 0.4965, validation loss: 0.4972
2024-06-03 04:30:57 [INFO]: Epoch 024 - training loss: 0.4958, validation loss: 0.4929
2024-06-03 04:31:06 [INFO]: Epoch 025 - training loss: 0.4930, validation loss: 0.4959
2024-06-03 04:31:16 [INFO]: Epoch 026 - training loss: 0.4909, validation loss: 0.4960
2024-06-03 04:31:26 [INFO]: Epoch 027 - training loss: 0.4871, validation loss: 0.4963
2024-06-03 04:31:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:31:26 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 04:31:26 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_2/20240603_T042702/ETSformer.pypots
2024-06-03 04:31:34 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_2/imputation.pkl
2024-06-03 04:31:34 [INFO]: Round2 - ETSformer on BeijingAir: MAE=0.4273, MSE=0.5290, MRE=0.5832
2024-06-03 04:31:34 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 04:31:34 [INFO]: Using the given device: cuda:0
2024-06-03 04:31:34 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T043134
2024-06-03 04:31:34 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T043134/tensorboard
2024-06-03 04:31:34 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 04:31:43 [INFO]: Epoch 001 - training loss: 0.9425, validation loss: 0.6557
2024-06-03 04:31:53 [INFO]: Epoch 002 - training loss: 0.7798, validation loss: 0.6274
2024-06-03 04:32:03 [INFO]: Epoch 003 - training loss: 0.7161, validation loss: 0.5925
2024-06-03 04:32:13 [INFO]: Epoch 004 - training loss: 0.6716, validation loss: 0.5523
2024-06-03 04:32:23 [INFO]: Epoch 005 - training loss: 0.6409, validation loss: 0.5325
2024-06-03 04:32:33 [INFO]: Epoch 006 - training loss: 0.6170, validation loss: 0.5249
2024-06-03 04:32:42 [INFO]: Epoch 007 - training loss: 0.6011, validation loss: 0.5266
2024-06-03 04:32:52 [INFO]: Epoch 008 - training loss: 0.5898, validation loss: 0.5192
2024-06-03 04:33:02 [INFO]: Epoch 009 - training loss: 0.5735, validation loss: 0.5219
2024-06-03 04:33:12 [INFO]: Epoch 010 - training loss: 0.5649, validation loss: 0.5206
2024-06-03 04:33:21 [INFO]: Epoch 011 - training loss: 0.5576, validation loss: 0.5163
2024-06-03 04:33:31 [INFO]: Epoch 012 - training loss: 0.5481, validation loss: 0.5126
2024-06-03 04:33:41 [INFO]: Epoch 013 - training loss: 0.5426, validation loss: 0.5159
2024-06-03 04:33:51 [INFO]: Epoch 014 - training loss: 0.5357, validation loss: 0.5063
2024-06-03 04:34:00 [INFO]: Epoch 015 - training loss: 0.5314, validation loss: 0.5099
2024-06-03 04:34:10 [INFO]: Epoch 016 - training loss: 0.5240, validation loss: 0.5129
2024-06-03 04:34:20 [INFO]: Epoch 017 - training loss: 0.5220, validation loss: 0.5105
2024-06-03 04:34:30 [INFO]: Epoch 018 - training loss: 0.5175, validation loss: 0.5105
2024-06-03 04:34:39 [INFO]: Epoch 019 - training loss: 0.5137, validation loss: 0.5085
2024-06-03 04:34:49 [INFO]: Epoch 020 - training loss: 0.5133, validation loss: 0.5067
2024-06-03 04:34:58 [INFO]: Epoch 021 - training loss: 0.5065, validation loss: 0.5063
2024-06-03 04:35:08 [INFO]: Epoch 022 - training loss: 0.5048, validation loss: 0.5099
2024-06-03 04:35:18 [INFO]: Epoch 023 - training loss: 0.5017, validation loss: 0.5097
2024-06-03 04:35:28 [INFO]: Epoch 024 - training loss: 0.4983, validation loss: 0.5062
2024-06-03 04:35:38 [INFO]: Epoch 025 - training loss: 0.4984, validation loss: 0.5025
2024-06-03 04:35:47 [INFO]: Epoch 026 - training loss: 0.4960, validation loss: 0.5077
2024-06-03 04:35:57 [INFO]: Epoch 027 - training loss: 0.4941, validation loss: 0.5073
2024-06-03 04:36:07 [INFO]: Epoch 028 - training loss: 0.4911, validation loss: 0.5108
2024-06-03 04:36:17 [INFO]: Epoch 029 - training loss: 0.4909, validation loss: 0.5020
2024-06-03 04:36:26 [INFO]: Epoch 030 - training loss: 0.4885, validation loss: 0.5152
2024-06-03 04:36:36 [INFO]: Epoch 031 - training loss: 0.4882, validation loss: 0.5056
2024-06-03 04:36:45 [INFO]: Epoch 032 - training loss: 0.4871, validation loss: 0.5004
2024-06-03 04:36:55 [INFO]: Epoch 033 - training loss: 0.4843, validation loss: 0.5055
2024-06-03 04:37:04 [INFO]: Epoch 034 - training loss: 0.4836, validation loss: 0.5039
2024-06-03 04:37:14 [INFO]: Epoch 035 - training loss: 0.4811, validation loss: 0.5090
2024-06-03 04:37:23 [INFO]: Epoch 036 - training loss: 0.4810, validation loss: 0.5045
2024-06-03 04:37:33 [INFO]: Epoch 037 - training loss: 0.4787, validation loss: 0.5005
2024-06-03 04:37:43 [INFO]: Epoch 038 - training loss: 0.4762, validation loss: 0.5011
2024-06-03 04:37:53 [INFO]: Epoch 039 - training loss: 0.4774, validation loss: 0.4950
2024-06-03 04:38:03 [INFO]: Epoch 040 - training loss: 0.4774, validation loss: 0.4987
2024-06-03 04:38:12 [INFO]: Epoch 041 - training loss: 0.4755, validation loss: 0.5086
2024-06-03 04:38:22 [INFO]: Epoch 042 - training loss: 0.4771, validation loss: 0.5019
2024-06-03 04:38:32 [INFO]: Epoch 043 - training loss: 0.4739, validation loss: 0.5077
2024-06-03 04:38:42 [INFO]: Epoch 044 - training loss: 0.4733, validation loss: 0.5106
2024-06-03 04:38:52 [INFO]: Epoch 045 - training loss: 0.4731, validation loss: 0.5146
2024-06-03 04:39:02 [INFO]: Epoch 046 - training loss: 0.4720, validation loss: 0.4992
2024-06-03 04:39:12 [INFO]: Epoch 047 - training loss: 0.4700, validation loss: 0.5035
2024-06-03 04:39:21 [INFO]: Epoch 048 - training loss: 0.4685, validation loss: 0.4975
2024-06-03 04:39:31 [INFO]: Epoch 049 - training loss: 0.4696, validation loss: 0.5057
2024-06-03 04:39:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:39:31 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 04:39:31 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_3/20240603_T043134/ETSformer.pypots
2024-06-03 04:39:38 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_3/imputation.pkl
2024-06-03 04:39:38 [INFO]: Round3 - ETSformer on BeijingAir: MAE=0.4371, MSE=0.5518, MRE=0.5967
2024-06-03 04:39:38 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 04:39:38 [INFO]: Using the given device: cuda:0
2024-06-03 04:39:38 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T043938
2024-06-03 04:39:38 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T043938/tensorboard
2024-06-03 04:39:39 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 7,928,510
2024-06-03 04:39:49 [INFO]: Epoch 001 - training loss: 0.9303, validation loss: 0.6513
2024-06-03 04:39:58 [INFO]: Epoch 002 - training loss: 0.7678, validation loss: 0.6086
2024-06-03 04:40:08 [INFO]: Epoch 003 - training loss: 0.7011, validation loss: 0.5560
2024-06-03 04:40:18 [INFO]: Epoch 004 - training loss: 0.6611, validation loss: 0.5338
2024-06-03 04:40:28 [INFO]: Epoch 005 - training loss: 0.6314, validation loss: 0.5322
2024-06-03 04:40:37 [INFO]: Epoch 006 - training loss: 0.6102, validation loss: 0.5280
2024-06-03 04:40:47 [INFO]: Epoch 007 - training loss: 0.5953, validation loss: 0.5296
2024-06-03 04:40:57 [INFO]: Epoch 008 - training loss: 0.5785, validation loss: 0.5235
2024-06-03 04:41:06 [INFO]: Epoch 009 - training loss: 0.5687, validation loss: 0.5240
2024-06-03 04:41:17 [INFO]: Epoch 010 - training loss: 0.5613, validation loss: 0.5173
2024-06-03 04:41:26 [INFO]: Epoch 011 - training loss: 0.5499, validation loss: 0.5199
2024-06-03 04:41:36 [INFO]: Epoch 012 - training loss: 0.5428, validation loss: 0.5188
2024-06-03 04:41:45 [INFO]: Epoch 013 - training loss: 0.5366, validation loss: 0.5190
2024-06-03 04:41:55 [INFO]: Epoch 014 - training loss: 0.5293, validation loss: 0.5155
2024-06-03 04:42:05 [INFO]: Epoch 015 - training loss: 0.5248, validation loss: 0.5172
2024-06-03 04:42:15 [INFO]: Epoch 016 - training loss: 0.5200, validation loss: 0.5095
2024-06-03 04:42:24 [INFO]: Epoch 017 - training loss: 0.5168, validation loss: 0.5054
2024-06-03 04:42:34 [INFO]: Epoch 018 - training loss: 0.5145, validation loss: 0.5135
2024-06-03 04:42:44 [INFO]: Epoch 019 - training loss: 0.5130, validation loss: 0.5081
2024-06-03 04:42:54 [INFO]: Epoch 020 - training loss: 0.5095, validation loss: 0.5071
2024-06-03 04:43:03 [INFO]: Epoch 021 - training loss: 0.5031, validation loss: 0.4987
2024-06-03 04:43:13 [INFO]: Epoch 022 - training loss: 0.5016, validation loss: 0.5073
2024-06-03 04:43:22 [INFO]: Epoch 023 - training loss: 0.4995, validation loss: 0.5047
2024-06-03 04:43:32 [INFO]: Epoch 024 - training loss: 0.4987, validation loss: 0.5110
2024-06-03 04:43:42 [INFO]: Epoch 025 - training loss: 0.4944, validation loss: 0.5034
2024-06-03 04:43:52 [INFO]: Epoch 026 - training loss: 0.4910, validation loss: 0.5077
2024-06-03 04:44:02 [INFO]: Epoch 027 - training loss: 0.4899, validation loss: 0.5003
2024-06-03 04:44:12 [INFO]: Epoch 028 - training loss: 0.4917, validation loss: 0.5079
2024-06-03 04:44:21 [INFO]: Epoch 029 - training loss: 0.4895, validation loss: 0.5036
2024-06-03 04:44:32 [INFO]: Epoch 030 - training loss: 0.4842, validation loss: 0.5053
2024-06-03 04:44:41 [INFO]: Epoch 031 - training loss: 0.4850, validation loss: 0.5017
2024-06-03 04:44:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:44:41 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 04:44:41 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_4/20240603_T043938/ETSformer.pypots
2024-06-03 04:44:49 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/ETSformer_BeijingAir/round_4/imputation.pkl
2024-06-03 04:44:49 [INFO]: Round4 - ETSformer on BeijingAir: MAE=0.4325, MSE=0.5450, MRE=0.5903
2024-06-03 04:44:49 [INFO]: Done! Final results:
Averaged ETSformer (7,928,510 params) on BeijingAir: MAE=0.4175 ± 0.02469973144717417, MSE=0.5277 ± 0.030282294319343428, MRE=0.5547 ± 0.03282139580837705, average inference time=1.68