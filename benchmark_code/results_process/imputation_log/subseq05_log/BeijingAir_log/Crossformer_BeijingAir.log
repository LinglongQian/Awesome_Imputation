2024-06-03 03:58:18 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:58:18 [INFO]: Using the given device: cuda:0
2024-06-03 03:58:19 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240603_T035819
2024-06-03 03:58:19 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240603_T035819/tensorboard
2024-06-03 03:58:21 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 03:59:40 [INFO]: Epoch 001 - training loss: 1.2955, validation loss: 0.5471
2024-06-03 04:01:00 [INFO]: Epoch 002 - training loss: 0.8358, validation loss: 0.4288
2024-06-03 04:02:19 [INFO]: Epoch 003 - training loss: 0.7240, validation loss: 0.4053
2024-06-03 04:03:39 [INFO]: Epoch 004 - training loss: 0.6638, validation loss: 0.3564
2024-06-03 04:04:58 [INFO]: Epoch 005 - training loss: 0.6136, validation loss: 0.3552
2024-06-03 04:06:17 [INFO]: Epoch 006 - training loss: 0.5992, validation loss: 0.3189
2024-06-03 04:07:35 [INFO]: Epoch 007 - training loss: 0.5529, validation loss: 0.3147
2024-06-03 04:08:51 [INFO]: Epoch 008 - training loss: 0.5319, validation loss: 0.3132
2024-06-03 04:10:07 [INFO]: Epoch 009 - training loss: 0.5142, validation loss: 0.2994
2024-06-03 04:11:20 [INFO]: Epoch 010 - training loss: 0.4979, validation loss: 0.2935
2024-06-03 04:12:34 [INFO]: Epoch 011 - training loss: 0.4764, validation loss: 0.2937
2024-06-03 04:13:47 [INFO]: Epoch 012 - training loss: 0.4658, validation loss: 0.2896
2024-06-03 04:15:00 [INFO]: Epoch 013 - training loss: 0.4541, validation loss: 0.2828
2024-06-03 04:16:14 [INFO]: Epoch 014 - training loss: 0.4452, validation loss: 0.2873
2024-06-03 04:17:27 [INFO]: Epoch 015 - training loss: 0.4359, validation loss: 0.2829
2024-06-03 04:18:41 [INFO]: Epoch 016 - training loss: 0.4296, validation loss: 0.2849
2024-06-03 04:19:54 [INFO]: Epoch 017 - training loss: 0.4252, validation loss: 0.2809
2024-06-03 04:21:08 [INFO]: Epoch 018 - training loss: 0.4169, validation loss: 0.2816
2024-06-03 04:22:21 [INFO]: Epoch 019 - training loss: 0.4095, validation loss: 0.2813
2024-06-03 04:23:35 [INFO]: Epoch 020 - training loss: 0.4074, validation loss: 0.2746
2024-06-03 04:24:49 [INFO]: Epoch 021 - training loss: 0.4054, validation loss: 0.2817
2024-06-03 04:26:02 [INFO]: Epoch 022 - training loss: 0.3997, validation loss: 0.2877
2024-06-03 04:27:15 [INFO]: Epoch 023 - training loss: 0.3952, validation loss: 0.2905
2024-06-03 04:28:28 [INFO]: Epoch 024 - training loss: 0.3937, validation loss: 0.2811
2024-06-03 04:29:40 [INFO]: Epoch 025 - training loss: 0.3904, validation loss: 0.2823
2024-06-03 04:30:53 [INFO]: Epoch 026 - training loss: 0.3885, validation loss: 0.2845
2024-06-03 04:32:05 [INFO]: Epoch 027 - training loss: 0.3836, validation loss: 0.2818
2024-06-03 04:33:18 [INFO]: Epoch 028 - training loss: 0.3819, validation loss: 0.2849
2024-06-03 04:34:31 [INFO]: Epoch 029 - training loss: 0.3812, validation loss: 0.2920
2024-06-03 04:35:43 [INFO]: Epoch 030 - training loss: 0.3767, validation loss: 0.2881
2024-06-03 04:35:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 04:35:43 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 04:35:44 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_0/20240603_T035819/Crossformer.pypots
2024-06-03 04:36:17 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_0/imputation.pkl
2024-06-03 04:36:17 [INFO]: Round0 - Crossformer on BeijingAir: MAE=0.2774, MSE=0.3560, MRE=0.3786
2024-06-03 04:36:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 04:36:17 [INFO]: Using the given device: cuda:0
2024-06-03 04:36:17 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240603_T043617
2024-06-03 04:36:17 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240603_T043617/tensorboard
2024-06-03 04:36:18 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 04:37:31 [INFO]: Epoch 001 - training loss: 1.3561, validation loss: 0.6198
2024-06-03 04:38:43 [INFO]: Epoch 002 - training loss: 0.8559, validation loss: 0.4160
2024-06-03 04:39:56 [INFO]: Epoch 003 - training loss: 0.7203, validation loss: 0.3826
2024-06-03 04:41:09 [INFO]: Epoch 004 - training loss: 0.6564, validation loss: 0.3451
2024-06-03 04:42:21 [INFO]: Epoch 005 - training loss: 0.6171, validation loss: 0.3280
2024-06-03 04:43:34 [INFO]: Epoch 006 - training loss: 0.5744, validation loss: 0.3196
2024-06-03 04:44:47 [INFO]: Epoch 007 - training loss: 0.5458, validation loss: 0.3142
2024-06-03 04:45:56 [INFO]: Epoch 008 - training loss: 0.5231, validation loss: 0.2970
2024-06-03 04:47:06 [INFO]: Epoch 009 - training loss: 0.5045, validation loss: 0.2901
2024-06-03 04:48:15 [INFO]: Epoch 010 - training loss: 0.4856, validation loss: 0.2895
2024-06-03 04:49:25 [INFO]: Epoch 011 - training loss: 0.4721, validation loss: 0.2866
2024-06-03 04:50:34 [INFO]: Epoch 012 - training loss: 0.4577, validation loss: 0.2780
2024-06-03 04:51:44 [INFO]: Epoch 013 - training loss: 0.4493, validation loss: 0.2840
2024-06-03 04:52:53 [INFO]: Epoch 014 - training loss: 0.4435, validation loss: 0.2807
2024-06-03 04:54:02 [INFO]: Epoch 015 - training loss: 0.4337, validation loss: 0.2756
2024-06-03 04:55:12 [INFO]: Epoch 016 - training loss: 0.4228, validation loss: 0.2755
2024-06-03 04:56:22 [INFO]: Epoch 017 - training loss: 0.4157, validation loss: 0.2780
2024-06-03 04:57:31 [INFO]: Epoch 018 - training loss: 0.4135, validation loss: 0.2746
2024-06-03 04:58:41 [INFO]: Epoch 019 - training loss: 0.4102, validation loss: 0.2786
2024-06-03 04:59:50 [INFO]: Epoch 020 - training loss: 0.4039, validation loss: 0.2694
2024-06-03 05:00:59 [INFO]: Epoch 021 - training loss: 0.3992, validation loss: 0.2764
2024-06-03 05:02:09 [INFO]: Epoch 022 - training loss: 0.3970, validation loss: 0.2807
2024-06-03 05:03:18 [INFO]: Epoch 023 - training loss: 0.3952, validation loss: 0.2982
2024-06-03 05:04:27 [INFO]: Epoch 024 - training loss: 0.3908, validation loss: 0.2782
2024-06-03 05:05:37 [INFO]: Epoch 025 - training loss: 0.3888, validation loss: 0.2769
2024-06-03 05:06:46 [INFO]: Epoch 026 - training loss: 0.3839, validation loss: 0.2777
2024-06-03 05:07:57 [INFO]: Epoch 027 - training loss: 0.3832, validation loss: 0.2841
2024-06-03 05:09:09 [INFO]: Epoch 028 - training loss: 0.3826, validation loss: 0.2863
2024-06-03 05:10:20 [INFO]: Epoch 029 - training loss: 0.3785, validation loss: 0.2822
2024-06-03 05:11:32 [INFO]: Epoch 030 - training loss: 0.3765, validation loss: 0.2841
2024-06-03 05:11:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:11:32 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 05:11:33 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_1/20240603_T043617/Crossformer.pypots
2024-06-03 05:12:06 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_1/imputation.pkl
2024-06-03 05:12:06 [INFO]: Round1 - Crossformer on BeijingAir: MAE=0.2774, MSE=0.3511, MRE=0.3787
2024-06-03 05:12:06 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 05:12:06 [INFO]: Using the given device: cuda:0
2024-06-03 05:12:06 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240603_T051206
2024-06-03 05:12:06 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240603_T051206/tensorboard
2024-06-03 05:12:07 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 05:13:18 [INFO]: Epoch 001 - training loss: 1.3662, validation loss: 0.6111
2024-06-03 05:14:30 [INFO]: Epoch 002 - training loss: 0.8581, validation loss: 0.4241
2024-06-03 05:15:41 [INFO]: Epoch 003 - training loss: 0.7188, validation loss: 0.3892
2024-06-03 05:16:52 [INFO]: Epoch 004 - training loss: 0.6555, validation loss: 0.3390
2024-06-03 05:18:04 [INFO]: Epoch 005 - training loss: 0.6230, validation loss: 0.3318
2024-06-03 05:19:16 [INFO]: Epoch 006 - training loss: 0.5853, validation loss: 0.3275
2024-06-03 05:20:28 [INFO]: Epoch 007 - training loss: 0.5622, validation loss: 0.3081
2024-06-03 05:21:39 [INFO]: Epoch 008 - training loss: 0.5297, validation loss: 0.3059
2024-06-03 05:22:51 [INFO]: Epoch 009 - training loss: 0.5080, validation loss: 0.2923
2024-06-03 05:24:03 [INFO]: Epoch 010 - training loss: 0.4885, validation loss: 0.2951
2024-06-03 05:25:15 [INFO]: Epoch 011 - training loss: 0.4749, validation loss: 0.2896
2024-06-03 05:26:27 [INFO]: Epoch 012 - training loss: 0.4629, validation loss: 0.2895
2024-06-03 05:27:38 [INFO]: Epoch 013 - training loss: 0.4555, validation loss: 0.2875
2024-06-03 05:28:50 [INFO]: Epoch 014 - training loss: 0.4443, validation loss: 0.2820
2024-06-03 05:30:02 [INFO]: Epoch 015 - training loss: 0.4386, validation loss: 0.2844
2024-06-03 05:31:13 [INFO]: Epoch 016 - training loss: 0.4307, validation loss: 0.2806
2024-06-03 05:32:25 [INFO]: Epoch 017 - training loss: 0.4234, validation loss: 0.2935
2024-06-03 05:33:36 [INFO]: Epoch 018 - training loss: 0.4190, validation loss: 0.2799
2024-06-03 05:34:48 [INFO]: Epoch 019 - training loss: 0.4126, validation loss: 0.2795
2024-06-03 05:36:00 [INFO]: Epoch 020 - training loss: 0.4077, validation loss: 0.2799
2024-06-03 05:37:12 [INFO]: Epoch 021 - training loss: 0.4051, validation loss: 0.2846
2024-06-03 05:38:23 [INFO]: Epoch 022 - training loss: 0.3985, validation loss: 0.2785
2024-06-03 05:39:35 [INFO]: Epoch 023 - training loss: 0.3983, validation loss: 0.2779
2024-06-03 05:40:46 [INFO]: Epoch 024 - training loss: 0.3938, validation loss: 0.2829
2024-06-03 05:41:58 [INFO]: Epoch 025 - training loss: 0.3906, validation loss: 0.2959
2024-06-03 05:43:10 [INFO]: Epoch 026 - training loss: 0.3897, validation loss: 0.2890
2024-06-03 05:44:21 [INFO]: Epoch 027 - training loss: 0.3877, validation loss: 0.2878
2024-06-03 05:45:33 [INFO]: Epoch 028 - training loss: 0.3841, validation loss: 0.2827
2024-06-03 05:46:45 [INFO]: Epoch 029 - training loss: 0.3776, validation loss: 0.2844
2024-06-03 05:47:57 [INFO]: Epoch 030 - training loss: 0.3779, validation loss: 0.2989
2024-06-03 05:49:06 [INFO]: Epoch 031 - training loss: 0.3779, validation loss: 0.2959
2024-06-03 05:50:15 [INFO]: Epoch 032 - training loss: 0.3749, validation loss: 0.2883
2024-06-03 05:51:25 [INFO]: Epoch 033 - training loss: 0.3744, validation loss: 0.2968
2024-06-03 05:51:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:51:25 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 05:51:25 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_2/20240603_T051206/Crossformer.pypots
2024-06-03 05:51:58 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_2/imputation.pkl
2024-06-03 05:51:58 [INFO]: Round2 - Crossformer on BeijingAir: MAE=0.2826, MSE=0.3630, MRE=0.3858
2024-06-03 05:51:58 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 05:51:58 [INFO]: Using the given device: cuda:0
2024-06-03 05:51:58 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T055158
2024-06-03 05:51:58 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T055158/tensorboard
2024-06-03 05:51:59 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 05:53:08 [INFO]: Epoch 001 - training loss: 1.3355, validation loss: 0.6220
2024-06-03 05:54:18 [INFO]: Epoch 002 - training loss: 0.8576, validation loss: 0.4418
2024-06-03 05:55:27 [INFO]: Epoch 003 - training loss: 0.7294, validation loss: 0.3687
2024-06-03 05:56:37 [INFO]: Epoch 004 - training loss: 0.6675, validation loss: 0.3537
2024-06-03 05:57:46 [INFO]: Epoch 005 - training loss: 0.6121, validation loss: 0.3292
2024-06-03 05:58:56 [INFO]: Epoch 006 - training loss: 0.5810, validation loss: 0.3101
2024-06-03 06:00:05 [INFO]: Epoch 007 - training loss: 0.5514, validation loss: 0.3049
2024-06-03 06:01:15 [INFO]: Epoch 008 - training loss: 0.5279, validation loss: 0.3036
2024-06-03 06:02:24 [INFO]: Epoch 009 - training loss: 0.5071, validation loss: 0.3014
2024-06-03 06:03:34 [INFO]: Epoch 010 - training loss: 0.4857, validation loss: 0.2955
2024-06-03 06:04:43 [INFO]: Epoch 011 - training loss: 0.4830, validation loss: 0.2925
2024-06-03 06:05:52 [INFO]: Epoch 012 - training loss: 0.4650, validation loss: 0.2833
2024-06-03 06:07:02 [INFO]: Epoch 013 - training loss: 0.4502, validation loss: 0.2818
2024-06-03 06:08:11 [INFO]: Epoch 014 - training loss: 0.4430, validation loss: 0.2819
2024-06-03 06:09:20 [INFO]: Epoch 015 - training loss: 0.4350, validation loss: 0.2768
2024-06-03 06:10:30 [INFO]: Epoch 016 - training loss: 0.4274, validation loss: 0.2831
2024-06-03 06:11:39 [INFO]: Epoch 017 - training loss: 0.4217, validation loss: 0.2772
2024-06-03 06:12:49 [INFO]: Epoch 018 - training loss: 0.4168, validation loss: 0.2816
2024-06-03 06:13:58 [INFO]: Epoch 019 - training loss: 0.4115, validation loss: 0.2831
2024-06-03 06:15:07 [INFO]: Epoch 020 - training loss: 0.4075, validation loss: 0.2753
2024-06-03 06:16:17 [INFO]: Epoch 021 - training loss: 0.4014, validation loss: 0.2868
2024-06-03 06:17:26 [INFO]: Epoch 022 - training loss: 0.4000, validation loss: 0.2802
2024-06-03 06:18:36 [INFO]: Epoch 023 - training loss: 0.3968, validation loss: 0.2816
2024-06-03 06:19:45 [INFO]: Epoch 024 - training loss: 0.3916, validation loss: 0.2794
2024-06-03 06:20:54 [INFO]: Epoch 025 - training loss: 0.3873, validation loss: 0.2867
2024-06-03 06:22:04 [INFO]: Epoch 026 - training loss: 0.3844, validation loss: 0.2865
2024-06-03 06:23:13 [INFO]: Epoch 027 - training loss: 0.3846, validation loss: 0.3045
2024-06-03 06:24:22 [INFO]: Epoch 028 - training loss: 0.3829, validation loss: 0.2811
2024-06-03 06:25:32 [INFO]: Epoch 029 - training loss: 0.3801, validation loss: 0.2836
2024-06-03 06:26:41 [INFO]: Epoch 030 - training loss: 0.3754, validation loss: 0.2926
2024-06-03 06:26:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:26:41 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 06:26:42 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_3/20240603_T055158/Crossformer.pypots
2024-06-03 06:27:14 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_3/imputation.pkl
2024-06-03 06:27:14 [INFO]: Round3 - Crossformer on BeijingAir: MAE=0.2818, MSE=0.3632, MRE=0.3846
2024-06-03 06:27:14 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 06:27:14 [INFO]: Using the given device: cuda:0
2024-06-03 06:27:14 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T062714
2024-06-03 06:27:14 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T062714/tensorboard
2024-06-03 06:27:15 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 52,933,788
2024-06-03 06:28:24 [INFO]: Epoch 001 - training loss: 1.3740, validation loss: 0.6408
2024-06-03 06:29:34 [INFO]: Epoch 002 - training loss: 0.8616, validation loss: 0.4349
2024-06-03 06:30:43 [INFO]: Epoch 003 - training loss: 0.7196, validation loss: 0.3658
2024-06-03 06:31:53 [INFO]: Epoch 004 - training loss: 0.6565, validation loss: 0.3490
2024-06-03 06:33:02 [INFO]: Epoch 005 - training loss: 0.6121, validation loss: 0.3251
2024-06-03 06:34:12 [INFO]: Epoch 006 - training loss: 0.5730, validation loss: 0.3107
2024-06-03 06:35:21 [INFO]: Epoch 007 - training loss: 0.5441, validation loss: 0.3061
2024-06-03 06:36:30 [INFO]: Epoch 008 - training loss: 0.5273, validation loss: 0.3127
2024-06-03 06:37:40 [INFO]: Epoch 009 - training loss: 0.5049, validation loss: 0.3100
2024-06-03 06:38:50 [INFO]: Epoch 010 - training loss: 0.4850, validation loss: 0.2891
2024-06-03 06:39:59 [INFO]: Epoch 011 - training loss: 0.4725, validation loss: 0.2883
2024-06-03 06:41:09 [INFO]: Epoch 012 - training loss: 0.4619, validation loss: 0.2841
2024-06-03 06:42:19 [INFO]: Epoch 013 - training loss: 0.4541, validation loss: 0.2867
2024-06-03 06:43:28 [INFO]: Epoch 014 - training loss: 0.4428, validation loss: 0.2769
2024-06-03 06:44:38 [INFO]: Epoch 015 - training loss: 0.4361, validation loss: 0.2768
2024-06-03 06:45:47 [INFO]: Epoch 016 - training loss: 0.4249, validation loss: 0.2780
2024-06-03 06:46:57 [INFO]: Epoch 017 - training loss: 0.4204, validation loss: 0.2762
2024-06-03 06:48:06 [INFO]: Epoch 018 - training loss: 0.4173, validation loss: 0.2731
2024-06-03 06:49:15 [INFO]: Epoch 019 - training loss: 0.4094, validation loss: 0.2790
2024-06-03 06:50:25 [INFO]: Epoch 020 - training loss: 0.4010, validation loss: 0.2711
2024-06-03 06:51:34 [INFO]: Epoch 021 - training loss: 0.3989, validation loss: 0.2728
2024-06-03 06:52:43 [INFO]: Epoch 022 - training loss: 0.3978, validation loss: 0.2867
2024-06-03 06:53:53 [INFO]: Epoch 023 - training loss: 0.3977, validation loss: 0.2792
2024-06-03 06:55:02 [INFO]: Epoch 024 - training loss: 0.3931, validation loss: 0.2810
2024-06-03 06:56:11 [INFO]: Epoch 025 - training loss: 0.3878, validation loss: 0.2755
2024-06-03 06:57:21 [INFO]: Epoch 026 - training loss: 0.3866, validation loss: 0.2775
2024-06-03 06:58:30 [INFO]: Epoch 027 - training loss: 0.3823, validation loss: 0.2806
2024-06-03 06:59:40 [INFO]: Epoch 028 - training loss: 0.3819, validation loss: 0.2955
2024-06-03 07:00:49 [INFO]: Epoch 029 - training loss: 0.3799, validation loss: 0.2841
2024-06-03 07:01:59 [INFO]: Epoch 030 - training loss: 0.3756, validation loss: 0.2876
2024-06-03 07:01:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:01:59 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 07:01:59 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_4/20240603_T062714/Crossformer.pypots
2024-06-03 07:02:32 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/Crossformer_BeijingAir/round_4/imputation.pkl
2024-06-03 07:02:32 [INFO]: Round4 - Crossformer on BeijingAir: MAE=0.2798, MSE=0.3552, MRE=0.3819
2024-06-03 07:02:32 [INFO]: Done! Final results:
Averaged Crossformer (52,933,788 params) on BeijingAir: MAE=0.2742 ± 0.002526897429835327, MSE=0.3547 ± 0.0053519366389869335, MRE=0.3644 ± 0.0033577814758502028, average inference time=6.92