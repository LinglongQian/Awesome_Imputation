2024-06-03 12:03:08 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 12:03:08 [INFO]: Using the given device: cuda:0
2024-06-03 12:03:09 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T120309
2024-06-03 12:03:09 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T120309/tensorboard
2024-06-03 12:03:10 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 12:03:22 [INFO]: Epoch 001 - training loss: 0.7840, validation loss: 0.9645
2024-06-03 12:03:27 [INFO]: Epoch 002 - training loss: 0.6098, validation loss: 0.8747
2024-06-03 12:03:31 [INFO]: Epoch 003 - training loss: 0.5810, validation loss: 0.8536
2024-06-03 12:03:36 [INFO]: Epoch 004 - training loss: 0.5629, validation loss: 0.8360
2024-06-03 12:03:42 [INFO]: Epoch 005 - training loss: 0.5540, validation loss: 0.7974
2024-06-03 12:03:46 [INFO]: Epoch 006 - training loss: 0.5426, validation loss: 0.7731
2024-06-03 12:03:51 [INFO]: Epoch 007 - training loss: 0.5330, validation loss: 0.7950
2024-06-03 12:03:56 [INFO]: Epoch 008 - training loss: 0.5271, validation loss: 0.7711
2024-06-03 12:04:01 [INFO]: Epoch 009 - training loss: 0.5217, validation loss: 0.7763
2024-06-03 12:04:06 [INFO]: Epoch 010 - training loss: 0.5141, validation loss: 0.7475
2024-06-03 12:04:11 [INFO]: Epoch 011 - training loss: 0.5128, validation loss: 0.7670
2024-06-03 12:04:16 [INFO]: Epoch 012 - training loss: 0.5033, validation loss: 0.7437
2024-06-03 12:04:20 [INFO]: Epoch 013 - training loss: 0.4989, validation loss: 0.7591
2024-06-03 12:04:25 [INFO]: Epoch 014 - training loss: 0.4940, validation loss: 0.7533
2024-06-03 12:04:30 [INFO]: Epoch 015 - training loss: 0.4898, validation loss: 0.7339
2024-06-03 12:04:34 [INFO]: Epoch 016 - training loss: 0.4889, validation loss: 0.7359
2024-06-03 12:04:39 [INFO]: Epoch 017 - training loss: 0.4854, validation loss: 0.7318
2024-06-03 12:04:43 [INFO]: Epoch 018 - training loss: 0.4854, validation loss: 0.7162
2024-06-03 12:04:48 [INFO]: Epoch 019 - training loss: 0.4780, validation loss: 0.7314
2024-06-03 12:04:53 [INFO]: Epoch 020 - training loss: 0.4768, validation loss: 0.7278
2024-06-03 12:04:57 [INFO]: Epoch 021 - training loss: 0.4738, validation loss: 0.7145
2024-06-03 12:05:02 [INFO]: Epoch 022 - training loss: 0.4725, validation loss: 0.7299
2024-06-03 12:05:07 [INFO]: Epoch 023 - training loss: 0.4717, validation loss: 0.7272
2024-06-03 12:05:11 [INFO]: Epoch 024 - training loss: 0.4668, validation loss: 0.7037
2024-06-03 12:05:16 [INFO]: Epoch 025 - training loss: 0.4658, validation loss: 0.7077
2024-06-03 12:05:21 [INFO]: Epoch 026 - training loss: 0.4623, validation loss: 0.7091
2024-06-03 12:05:25 [INFO]: Epoch 027 - training loss: 0.4598, validation loss: 0.7047
2024-06-03 12:05:30 [INFO]: Epoch 028 - training loss: 0.4593, validation loss: 0.7197
2024-06-03 12:05:35 [INFO]: Epoch 029 - training loss: 0.4602, validation loss: 0.6965
2024-06-03 12:05:40 [INFO]: Epoch 030 - training loss: 0.4561, validation loss: 0.7001
2024-06-03 12:05:44 [INFO]: Epoch 031 - training loss: 0.4561, validation loss: 0.7008
2024-06-03 12:05:49 [INFO]: Epoch 032 - training loss: 0.4529, validation loss: 0.7040
2024-06-03 12:05:53 [INFO]: Epoch 033 - training loss: 0.4532, validation loss: 0.6982
2024-06-03 12:05:58 [INFO]: Epoch 034 - training loss: 0.4510, validation loss: 0.7040
2024-06-03 12:06:02 [INFO]: Epoch 035 - training loss: 0.4490, validation loss: 0.6981
2024-06-03 12:06:07 [INFO]: Epoch 036 - training loss: 0.4488, validation loss: 0.7045
2024-06-03 12:06:12 [INFO]: Epoch 037 - training loss: 0.4473, validation loss: 0.6883
2024-06-03 12:06:16 [INFO]: Epoch 038 - training loss: 0.4452, validation loss: 0.7042
2024-06-03 12:06:21 [INFO]: Epoch 039 - training loss: 0.4432, validation loss: 0.7034
2024-06-03 12:06:26 [INFO]: Epoch 040 - training loss: 0.4415, validation loss: 0.6925
2024-06-03 12:06:30 [INFO]: Epoch 041 - training loss: 0.4392, validation loss: 0.7035
2024-06-03 12:06:35 [INFO]: Epoch 042 - training loss: 0.4392, validation loss: 0.6882
2024-06-03 12:06:39 [INFO]: Epoch 043 - training loss: 0.4406, validation loss: 0.6877
2024-06-03 12:06:44 [INFO]: Epoch 044 - training loss: 0.4387, validation loss: 0.6965
2024-06-03 12:06:49 [INFO]: Epoch 045 - training loss: 0.4378, validation loss: 0.6979
2024-06-03 12:06:54 [INFO]: Epoch 046 - training loss: 0.4353, validation loss: 0.6934
2024-06-03 12:06:58 [INFO]: Epoch 047 - training loss: 0.4361, validation loss: 0.6955
2024-06-03 12:07:03 [INFO]: Epoch 048 - training loss: 0.4360, validation loss: 0.6892
2024-06-03 12:07:07 [INFO]: Epoch 049 - training loss: 0.4333, validation loss: 0.6926
2024-06-03 12:07:12 [INFO]: Epoch 050 - training loss: 0.4325, validation loss: 0.6825
2024-06-03 12:07:17 [INFO]: Epoch 051 - training loss: 0.4304, validation loss: 0.7001
2024-06-03 12:07:21 [INFO]: Epoch 052 - training loss: 0.4299, validation loss: 0.6845
2024-06-03 12:07:26 [INFO]: Epoch 053 - training loss: 0.4291, validation loss: 0.6785
2024-06-03 12:07:31 [INFO]: Epoch 054 - training loss: 0.4283, validation loss: 0.6780
2024-06-03 12:07:36 [INFO]: Epoch 055 - training loss: 0.4281, validation loss: 0.6799
2024-06-03 12:07:41 [INFO]: Epoch 056 - training loss: 0.4274, validation loss: 0.6721
2024-06-03 12:07:45 [INFO]: Epoch 057 - training loss: 0.4254, validation loss: 0.6786
2024-06-03 12:07:50 [INFO]: Epoch 058 - training loss: 0.4261, validation loss: 0.6793
2024-06-03 12:07:55 [INFO]: Epoch 059 - training loss: 0.4237, validation loss: 0.6826
2024-06-03 12:08:00 [INFO]: Epoch 060 - training loss: 0.4243, validation loss: 0.6693
2024-06-03 12:08:05 [INFO]: Epoch 061 - training loss: 0.4214, validation loss: 0.6689
2024-06-03 12:08:09 [INFO]: Epoch 062 - training loss: 0.4214, validation loss: 0.6688
2024-06-03 12:08:14 [INFO]: Epoch 063 - training loss: 0.4219, validation loss: 0.6722
2024-06-03 12:08:19 [INFO]: Epoch 064 - training loss: 0.4216, validation loss: 0.6669
2024-06-03 12:08:23 [INFO]: Epoch 065 - training loss: 0.4200, validation loss: 0.6754
2024-06-03 12:08:28 [INFO]: Epoch 066 - training loss: 0.4163, validation loss: 0.6707
2024-06-03 12:08:33 [INFO]: Epoch 067 - training loss: 0.4183, validation loss: 0.6658
2024-06-03 12:08:38 [INFO]: Epoch 068 - training loss: 0.4164, validation loss: 0.6722
2024-06-03 12:08:43 [INFO]: Epoch 069 - training loss: 0.4168, validation loss: 0.6735
2024-06-03 12:08:47 [INFO]: Epoch 070 - training loss: 0.4162, validation loss: 0.6679
2024-06-03 12:08:52 [INFO]: Epoch 071 - training loss: 0.4149, validation loss: 0.6712
2024-06-03 12:08:57 [INFO]: Epoch 072 - training loss: 0.4140, validation loss: 0.6703
2024-06-03 12:09:01 [INFO]: Epoch 073 - training loss: 0.4148, validation loss: 0.6740
2024-06-03 12:09:06 [INFO]: Epoch 074 - training loss: 0.4131, validation loss: 0.6682
2024-06-03 12:09:11 [INFO]: Epoch 075 - training loss: 0.4137, validation loss: 0.6771
2024-06-03 12:09:16 [INFO]: Epoch 076 - training loss: 0.4129, validation loss: 0.6591
2024-06-03 12:09:21 [INFO]: Epoch 077 - training loss: 0.4142, validation loss: 0.6872
2024-06-03 12:09:26 [INFO]: Epoch 078 - training loss: 0.4120, validation loss: 0.6614
2024-06-03 12:09:30 [INFO]: Epoch 079 - training loss: 0.4099, validation loss: 0.6636
2024-06-03 12:09:35 [INFO]: Epoch 080 - training loss: 0.4097, validation loss: 0.6704
2024-06-03 12:09:40 [INFO]: Epoch 081 - training loss: 0.4094, validation loss: 0.6613
2024-06-03 12:09:44 [INFO]: Epoch 082 - training loss: 0.4087, validation loss: 0.6608
2024-06-03 12:09:49 [INFO]: Epoch 083 - training loss: 0.4075, validation loss: 0.6698
2024-06-03 12:09:53 [INFO]: Epoch 084 - training loss: 0.4090, validation loss: 0.6693
2024-06-03 12:09:58 [INFO]: Epoch 085 - training loss: 0.4079, validation loss: 0.6622
2024-06-03 12:10:03 [INFO]: Epoch 086 - training loss: 0.4084, validation loss: 0.6791
2024-06-03 12:10:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:10:03 [INFO]: Finished training. The best model is from epoch#76.
2024-06-03 12:10:04 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_0/20240603_T120309/MICN.pypots
2024-06-03 12:10:06 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_0/imputation.pkl
2024-06-03 12:10:06 [INFO]: Round0 - MICN on BeijingAir: MAE=0.5472, MSE=0.7316, MRE=0.7469
2024-06-03 12:10:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 12:10:06 [INFO]: Using the given device: cuda:0
2024-06-03 12:10:06 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T121006
2024-06-03 12:10:06 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T121006/tensorboard
2024-06-03 12:10:08 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 12:10:13 [INFO]: Epoch 001 - training loss: 0.7999, validation loss: 0.9311
2024-06-03 12:10:17 [INFO]: Epoch 002 - training loss: 0.6247, validation loss: 0.9283
2024-06-03 12:10:22 [INFO]: Epoch 003 - training loss: 0.6234, validation loss: 0.9101
2024-06-03 12:10:27 [INFO]: Epoch 004 - training loss: 0.6040, validation loss: 0.8537
2024-06-03 12:10:31 [INFO]: Epoch 005 - training loss: 0.5763, validation loss: 0.8130
2024-06-03 12:10:36 [INFO]: Epoch 006 - training loss: 0.5563, validation loss: 0.8026
2024-06-03 12:10:40 [INFO]: Epoch 007 - training loss: 0.5474, validation loss: 0.7931
2024-06-03 12:10:45 [INFO]: Epoch 008 - training loss: 0.5336, validation loss: 0.7577
2024-06-03 12:10:50 [INFO]: Epoch 009 - training loss: 0.5194, validation loss: 0.7359
2024-06-03 12:10:54 [INFO]: Epoch 010 - training loss: 0.5096, validation loss: 0.7275
2024-06-03 12:10:58 [INFO]: Epoch 011 - training loss: 0.5046, validation loss: 0.7114
2024-06-03 12:11:03 [INFO]: Epoch 012 - training loss: 0.4975, validation loss: 0.7104
2024-06-03 12:11:08 [INFO]: Epoch 013 - training loss: 0.4954, validation loss: 0.6972
2024-06-03 12:11:13 [INFO]: Epoch 014 - training loss: 0.4870, validation loss: 0.6957
2024-06-03 12:11:17 [INFO]: Epoch 015 - training loss: 0.4806, validation loss: 0.6898
2024-06-03 12:11:22 [INFO]: Epoch 016 - training loss: 0.4780, validation loss: 0.7102
2024-06-03 12:11:27 [INFO]: Epoch 017 - training loss: 0.4758, validation loss: 0.7020
2024-06-03 12:11:32 [INFO]: Epoch 018 - training loss: 0.4706, validation loss: 0.6873
2024-06-03 12:11:37 [INFO]: Epoch 019 - training loss: 0.4651, validation loss: 0.6879
2024-06-03 12:11:41 [INFO]: Epoch 020 - training loss: 0.4660, validation loss: 0.7035
2024-06-03 12:11:46 [INFO]: Epoch 021 - training loss: 0.4615, validation loss: 0.6936
2024-06-03 12:11:51 [INFO]: Epoch 022 - training loss: 0.4597, validation loss: 0.6913
2024-06-03 12:11:55 [INFO]: Epoch 023 - training loss: 0.4615, validation loss: 0.6942
2024-06-03 12:12:00 [INFO]: Epoch 024 - training loss: 0.4569, validation loss: 0.6798
2024-06-03 12:12:05 [INFO]: Epoch 025 - training loss: 0.4522, validation loss: 0.6899
2024-06-03 12:12:10 [INFO]: Epoch 026 - training loss: 0.4525, validation loss: 0.6808
2024-06-03 12:12:15 [INFO]: Epoch 027 - training loss: 0.4510, validation loss: 0.6785
2024-06-03 12:12:19 [INFO]: Epoch 028 - training loss: 0.4486, validation loss: 0.6915
2024-06-03 12:12:24 [INFO]: Epoch 029 - training loss: 0.4464, validation loss: 0.6858
2024-06-03 12:12:29 [INFO]: Epoch 030 - training loss: 0.4462, validation loss: 0.6931
2024-06-03 12:12:33 [INFO]: Epoch 031 - training loss: 0.4449, validation loss: 0.6751
2024-06-03 12:12:38 [INFO]: Epoch 032 - training loss: 0.4440, validation loss: 0.6829
2024-06-03 12:12:43 [INFO]: Epoch 033 - training loss: 0.4413, validation loss: 0.6972
2024-06-03 12:12:47 [INFO]: Epoch 034 - training loss: 0.4430, validation loss: 0.6878
2024-06-03 12:12:52 [INFO]: Epoch 035 - training loss: 0.4421, validation loss: 0.6717
2024-06-03 12:12:57 [INFO]: Epoch 036 - training loss: 0.4392, validation loss: 0.6866
2024-06-03 12:13:02 [INFO]: Epoch 037 - training loss: 0.4350, validation loss: 0.6821
2024-06-03 12:13:07 [INFO]: Epoch 038 - training loss: 0.4338, validation loss: 0.6831
2024-06-03 12:13:11 [INFO]: Epoch 039 - training loss: 0.4347, validation loss: 0.6798
2024-06-03 12:13:16 [INFO]: Epoch 040 - training loss: 0.4337, validation loss: 0.6893
2024-06-03 12:13:21 [INFO]: Epoch 041 - training loss: 0.4325, validation loss: 0.6750
2024-06-03 12:13:26 [INFO]: Epoch 042 - training loss: 0.4329, validation loss: 0.6773
2024-06-03 12:13:30 [INFO]: Epoch 043 - training loss: 0.4322, validation loss: 0.6852
2024-06-03 12:13:35 [INFO]: Epoch 044 - training loss: 0.4295, validation loss: 0.6758
2024-06-03 12:13:40 [INFO]: Epoch 045 - training loss: 0.4273, validation loss: 0.6688
2024-06-03 12:13:45 [INFO]: Epoch 046 - training loss: 0.4280, validation loss: 0.6837
2024-06-03 12:13:50 [INFO]: Epoch 047 - training loss: 0.4289, validation loss: 0.6696
2024-06-03 12:13:55 [INFO]: Epoch 048 - training loss: 0.4265, validation loss: 0.6691
2024-06-03 12:14:00 [INFO]: Epoch 049 - training loss: 0.4236, validation loss: 0.6661
2024-06-03 12:14:04 [INFO]: Epoch 050 - training loss: 0.4253, validation loss: 0.6790
2024-06-03 12:14:09 [INFO]: Epoch 051 - training loss: 0.4247, validation loss: 0.6713
2024-06-03 12:14:14 [INFO]: Epoch 052 - training loss: 0.4243, validation loss: 0.6808
2024-06-03 12:14:18 [INFO]: Epoch 053 - training loss: 0.4211, validation loss: 0.6680
2024-06-03 12:14:23 [INFO]: Epoch 054 - training loss: 0.4218, validation loss: 0.6795
2024-06-03 12:14:28 [INFO]: Epoch 055 - training loss: 0.4205, validation loss: 0.6724
2024-06-03 12:14:32 [INFO]: Epoch 056 - training loss: 0.4191, validation loss: 0.6830
2024-06-03 12:14:37 [INFO]: Epoch 057 - training loss: 0.4193, validation loss: 0.6694
2024-06-03 12:14:42 [INFO]: Epoch 058 - training loss: 0.4174, validation loss: 0.6720
2024-06-03 12:14:47 [INFO]: Epoch 059 - training loss: 0.4182, validation loss: 0.6790
2024-06-03 12:14:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:14:47 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 12:14:48 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_1/20240603_T121006/MICN.pypots
2024-06-03 12:14:50 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_1/imputation.pkl
2024-06-03 12:14:50 [INFO]: Round1 - MICN on BeijingAir: MAE=0.5449, MSE=0.7309, MRE=0.7437
2024-06-03 12:14:50 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:14:50 [INFO]: Using the given device: cuda:0
2024-06-03 12:14:50 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T121450
2024-06-03 12:14:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T121450/tensorboard
2024-06-03 12:14:52 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 12:14:57 [INFO]: Epoch 001 - training loss: 0.7926, validation loss: 0.9427
2024-06-03 12:15:02 [INFO]: Epoch 002 - training loss: 0.6057, validation loss: 0.9292
2024-06-03 12:15:07 [INFO]: Epoch 003 - training loss: 0.5879, validation loss: 0.8774
2024-06-03 12:15:12 [INFO]: Epoch 004 - training loss: 0.5720, validation loss: 0.8198
2024-06-03 12:15:16 [INFO]: Epoch 005 - training loss: 0.5564, validation loss: 0.8185
2024-06-03 12:15:19 [INFO]: Epoch 006 - training loss: 0.5458, validation loss: 0.7859
2024-06-03 12:15:22 [INFO]: Epoch 007 - training loss: 0.5319, validation loss: 0.7716
2024-06-03 12:15:25 [INFO]: Epoch 008 - training loss: 0.5243, validation loss: 0.7594
2024-06-03 12:15:27 [INFO]: Epoch 009 - training loss: 0.5184, validation loss: 0.7702
2024-06-03 12:15:30 [INFO]: Epoch 010 - training loss: 0.5112, validation loss: 0.7565
2024-06-03 12:15:34 [INFO]: Epoch 011 - training loss: 0.5033, validation loss: 0.7530
2024-06-03 12:15:38 [INFO]: Epoch 012 - training loss: 0.4981, validation loss: 0.7373
2024-06-03 12:15:41 [INFO]: Epoch 013 - training loss: 0.4946, validation loss: 0.7277
2024-06-03 12:15:45 [INFO]: Epoch 014 - training loss: 0.4884, validation loss: 0.7204
2024-06-03 12:15:48 [INFO]: Epoch 015 - training loss: 0.4850, validation loss: 0.7230
2024-06-03 12:15:52 [INFO]: Epoch 016 - training loss: 0.4811, validation loss: 0.7258
2024-06-03 12:15:56 [INFO]: Epoch 017 - training loss: 0.4782, validation loss: 0.7225
2024-06-03 12:16:00 [INFO]: Epoch 018 - training loss: 0.4739, validation loss: 0.7341
2024-06-03 12:16:04 [INFO]: Epoch 019 - training loss: 0.4739, validation loss: 0.7322
2024-06-03 12:16:07 [INFO]: Epoch 020 - training loss: 0.4719, validation loss: 0.7156
2024-06-03 12:16:11 [INFO]: Epoch 021 - training loss: 0.4693, validation loss: 0.7164
2024-06-03 12:16:14 [INFO]: Epoch 022 - training loss: 0.4666, validation loss: 0.7211
2024-06-03 12:16:18 [INFO]: Epoch 023 - training loss: 0.4622, validation loss: 0.7035
2024-06-03 12:16:22 [INFO]: Epoch 024 - training loss: 0.4614, validation loss: 0.7096
2024-06-03 12:16:26 [INFO]: Epoch 025 - training loss: 0.4584, validation loss: 0.6867
2024-06-03 12:16:29 [INFO]: Epoch 026 - training loss: 0.4591, validation loss: 0.7066
2024-06-03 12:16:33 [INFO]: Epoch 027 - training loss: 0.4567, validation loss: 0.7065
2024-06-03 12:16:37 [INFO]: Epoch 028 - training loss: 0.4554, validation loss: 0.7013
2024-06-03 12:16:40 [INFO]: Epoch 029 - training loss: 0.4529, validation loss: 0.6977
2024-06-03 12:16:44 [INFO]: Epoch 030 - training loss: 0.4514, validation loss: 0.6902
2024-06-03 12:16:48 [INFO]: Epoch 031 - training loss: 0.4500, validation loss: 0.6962
2024-06-03 12:16:52 [INFO]: Epoch 032 - training loss: 0.4502, validation loss: 0.6960
2024-06-03 12:16:55 [INFO]: Epoch 033 - training loss: 0.4466, validation loss: 0.6996
2024-06-03 12:16:59 [INFO]: Epoch 034 - training loss: 0.4455, validation loss: 0.6948
2024-06-03 12:17:03 [INFO]: Epoch 035 - training loss: 0.4429, validation loss: 0.6973
2024-06-03 12:17:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:17:03 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 12:17:04 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_2/20240603_T121450/MICN.pypots
2024-06-03 12:17:05 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_2/imputation.pkl
2024-06-03 12:17:05 [INFO]: Round2 - MICN on BeijingAir: MAE=0.5552, MSE=0.7558, MRE=0.7578
2024-06-03 12:17:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 12:17:05 [INFO]: Using the given device: cuda:0
2024-06-03 12:17:05 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T121705
2024-06-03 12:17:05 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T121705/tensorboard
2024-06-03 12:17:07 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 12:17:11 [INFO]: Epoch 001 - training loss: 0.7877, validation loss: 0.9587
2024-06-03 12:17:14 [INFO]: Epoch 002 - training loss: 0.6130, validation loss: 0.9311
2024-06-03 12:17:18 [INFO]: Epoch 003 - training loss: 0.5951, validation loss: 0.8607
2024-06-03 12:17:22 [INFO]: Epoch 004 - training loss: 0.5724, validation loss: 0.8258
2024-06-03 12:17:26 [INFO]: Epoch 005 - training loss: 0.5526, validation loss: 0.8109
2024-06-03 12:17:29 [INFO]: Epoch 006 - training loss: 0.5465, validation loss: 0.7645
2024-06-03 12:17:33 [INFO]: Epoch 007 - training loss: 0.5329, validation loss: 0.7498
2024-06-03 12:17:36 [INFO]: Epoch 008 - training loss: 0.5251, validation loss: 0.7535
2024-06-03 12:17:39 [INFO]: Epoch 009 - training loss: 0.5161, validation loss: 0.7639
2024-06-03 12:17:43 [INFO]: Epoch 010 - training loss: 0.5080, validation loss: 0.7561
2024-06-03 12:17:46 [INFO]: Epoch 011 - training loss: 0.5070, validation loss: 0.7412
2024-06-03 12:17:49 [INFO]: Epoch 012 - training loss: 0.4999, validation loss: 0.7429
2024-06-03 12:17:52 [INFO]: Epoch 013 - training loss: 0.4950, validation loss: 0.7316
2024-06-03 12:17:56 [INFO]: Epoch 014 - training loss: 0.4888, validation loss: 0.7064
2024-06-03 12:17:59 [INFO]: Epoch 015 - training loss: 0.4868, validation loss: 0.7126
2024-06-03 12:18:02 [INFO]: Epoch 016 - training loss: 0.4833, validation loss: 0.7157
2024-06-03 12:18:06 [INFO]: Epoch 017 - training loss: 0.4799, validation loss: 0.7098
2024-06-03 12:18:09 [INFO]: Epoch 018 - training loss: 0.4752, validation loss: 0.7142
2024-06-03 12:18:12 [INFO]: Epoch 019 - training loss: 0.4750, validation loss: 0.7142
2024-06-03 12:18:15 [INFO]: Epoch 020 - training loss: 0.4716, validation loss: 0.6983
2024-06-03 12:18:19 [INFO]: Epoch 021 - training loss: 0.4682, validation loss: 0.7089
2024-06-03 12:18:22 [INFO]: Epoch 022 - training loss: 0.4683, validation loss: 0.7021
2024-06-03 12:18:25 [INFO]: Epoch 023 - training loss: 0.4634, validation loss: 0.7014
2024-06-03 12:18:28 [INFO]: Epoch 024 - training loss: 0.4607, validation loss: 0.7084
2024-06-03 12:18:32 [INFO]: Epoch 025 - training loss: 0.4602, validation loss: 0.7128
2024-06-03 12:18:35 [INFO]: Epoch 026 - training loss: 0.4575, validation loss: 0.7046
2024-06-03 12:18:37 [INFO]: Epoch 027 - training loss: 0.4546, validation loss: 0.7082
2024-06-03 12:18:40 [INFO]: Epoch 028 - training loss: 0.4537, validation loss: 0.7103
2024-06-03 12:18:42 [INFO]: Epoch 029 - training loss: 0.4519, validation loss: 0.7078
2024-06-03 12:18:44 [INFO]: Epoch 030 - training loss: 0.4502, validation loss: 0.7048
2024-06-03 12:18:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:18:44 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 12:18:45 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_3/20240603_T121705/MICN.pypots
2024-06-03 12:18:46 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_3/imputation.pkl
2024-06-03 12:18:46 [INFO]: Round3 - MICN on BeijingAir: MAE=0.5599, MSE=0.7598, MRE=0.7642
2024-06-03 12:18:46 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 12:18:46 [INFO]: Using the given device: cuda:0
2024-06-03 12:18:46 [INFO]: Model files will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T121846
2024-06-03 12:18:46 [INFO]: Tensorboard file will be saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T121846/tensorboard
2024-06-03 12:18:48 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 57,048,200
2024-06-03 12:18:51 [INFO]: Epoch 001 - training loss: 0.8029, validation loss: 0.9333
2024-06-03 12:18:54 [INFO]: Epoch 002 - training loss: 0.6201, validation loss: 0.8769
2024-06-03 12:18:58 [INFO]: Epoch 003 - training loss: 0.5894, validation loss: 0.8179
2024-06-03 12:19:01 [INFO]: Epoch 004 - training loss: 0.5676, validation loss: 0.7997
2024-06-03 12:19:05 [INFO]: Epoch 005 - training loss: 0.5546, validation loss: 0.7819
2024-06-03 12:19:08 [INFO]: Epoch 006 - training loss: 0.5431, validation loss: 0.7385
2024-06-03 12:19:11 [INFO]: Epoch 007 - training loss: 0.5315, validation loss: 0.7455
2024-06-03 12:19:14 [INFO]: Epoch 008 - training loss: 0.5245, validation loss: 0.7100
2024-06-03 12:19:18 [INFO]: Epoch 009 - training loss: 0.5119, validation loss: 0.7123
2024-06-03 12:19:21 [INFO]: Epoch 010 - training loss: 0.5062, validation loss: 0.7075
2024-06-03 12:19:24 [INFO]: Epoch 011 - training loss: 0.5033, validation loss: 0.7036
2024-06-03 12:19:27 [INFO]: Epoch 012 - training loss: 0.4965, validation loss: 0.7183
2024-06-03 12:19:31 [INFO]: Epoch 013 - training loss: 0.4922, validation loss: 0.7125
2024-06-03 12:19:34 [INFO]: Epoch 014 - training loss: 0.4870, validation loss: 0.7079
2024-06-03 12:19:38 [INFO]: Epoch 015 - training loss: 0.4826, validation loss: 0.6910
2024-06-03 12:19:41 [INFO]: Epoch 016 - training loss: 0.4801, validation loss: 0.7071
2024-06-03 12:19:44 [INFO]: Epoch 017 - training loss: 0.4797, validation loss: 0.6957
2024-06-03 12:19:48 [INFO]: Epoch 018 - training loss: 0.4750, validation loss: 0.6827
2024-06-03 12:19:51 [INFO]: Epoch 019 - training loss: 0.4707, validation loss: 0.6989
2024-06-03 12:19:54 [INFO]: Epoch 020 - training loss: 0.4654, validation loss: 0.6861
2024-06-03 12:19:57 [INFO]: Epoch 021 - training loss: 0.4626, validation loss: 0.6875
2024-06-03 12:20:00 [INFO]: Epoch 022 - training loss: 0.4625, validation loss: 0.6828
2024-06-03 12:20:04 [INFO]: Epoch 023 - training loss: 0.4606, validation loss: 0.6796
2024-06-03 12:20:07 [INFO]: Epoch 024 - training loss: 0.4598, validation loss: 0.6794
2024-06-03 12:20:10 [INFO]: Epoch 025 - training loss: 0.4581, validation loss: 0.6945
2024-06-03 12:20:13 [INFO]: Epoch 026 - training loss: 0.4554, validation loss: 0.7066
2024-06-03 12:20:17 [INFO]: Epoch 027 - training loss: 0.4535, validation loss: 0.6778
2024-06-03 12:20:20 [INFO]: Epoch 028 - training loss: 0.4506, validation loss: 0.6777
2024-06-03 12:20:23 [INFO]: Epoch 029 - training loss: 0.4506, validation loss: 0.6871
2024-06-03 12:20:26 [INFO]: Epoch 030 - training loss: 0.4475, validation loss: 0.6819
2024-06-03 12:20:30 [INFO]: Epoch 031 - training loss: 0.4473, validation loss: 0.6703
2024-06-03 12:20:33 [INFO]: Epoch 032 - training loss: 0.4446, validation loss: 0.6834
2024-06-03 12:20:36 [INFO]: Epoch 033 - training loss: 0.4459, validation loss: 0.6757
2024-06-03 12:20:39 [INFO]: Epoch 034 - training loss: 0.4465, validation loss: 0.6920
2024-06-03 12:20:42 [INFO]: Epoch 035 - training loss: 0.4403, validation loss: 0.6854
2024-06-03 12:20:46 [INFO]: Epoch 036 - training loss: 0.4431, validation loss: 0.6724
2024-06-03 12:20:49 [INFO]: Epoch 037 - training loss: 0.4378, validation loss: 0.6801
2024-06-03 12:20:52 [INFO]: Epoch 038 - training loss: 0.4397, validation loss: 0.6777
2024-06-03 12:20:56 [INFO]: Epoch 039 - training loss: 0.4383, validation loss: 0.6889
2024-06-03 12:20:59 [INFO]: Epoch 040 - training loss: 0.4367, validation loss: 0.6712
2024-06-03 12:21:02 [INFO]: Epoch 041 - training loss: 0.4350, validation loss: 0.6834
2024-06-03 12:21:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 12:21:02 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 12:21:03 [INFO]: Saved the model to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_4/20240603_T121846/MICN.pypots
2024-06-03 12:21:04 [INFO]: Successfully saved to results_subseq_rate05/BeijingAir/MICN_BeijingAir/round_4/imputation.pkl
2024-06-03 12:21:04 [INFO]: Round4 - MICN on BeijingAir: MAE=0.5494, MSE=0.7407, MRE=0.7499
2024-06-03 12:21:04 [INFO]: Done! Final results:
Averaged MICN (57,048,200 params) on BeijingAir: MAE=0.5586 ± 0.005851654130655406, MSE=0.7581 ± 0.012514591416845947, MRE=0.7423 ± 0.007775771034868423, average inference time=0.26