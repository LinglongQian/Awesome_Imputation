2024-06-03 02:48:15 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:48:15 [INFO]: Using the given device: cuda:0
2024-06-03 02:48:16 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240603_T024816
2024-06-03 02:48:16 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240603_T024816/tensorboard
2024-06-03 02:48:16 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-03 02:48:31 [INFO]: Epoch 001 - training loss: 0.6442, validation loss: 0.4732
2024-06-03 02:48:40 [INFO]: Epoch 002 - training loss: 0.4252, validation loss: 0.4110
2024-06-03 02:48:49 [INFO]: Epoch 003 - training loss: 0.3472, validation loss: 0.3791
2024-06-03 02:48:58 [INFO]: Epoch 004 - training loss: 0.3708, validation loss: 0.3523
2024-06-03 02:49:07 [INFO]: Epoch 005 - training loss: 0.3355, validation loss: 0.3363
2024-06-03 02:49:15 [INFO]: Epoch 006 - training loss: 0.3741, validation loss: 0.3403
2024-06-03 02:49:25 [INFO]: Epoch 007 - training loss: 0.3267, validation loss: 0.3334
2024-06-03 02:49:33 [INFO]: Epoch 008 - training loss: 0.3207, validation loss: 0.3237
2024-06-03 02:49:42 [INFO]: Epoch 009 - training loss: 0.3024, validation loss: 0.3249
2024-06-03 02:49:51 [INFO]: Epoch 010 - training loss: 0.2979, validation loss: 0.3046
2024-06-03 02:49:59 [INFO]: Epoch 011 - training loss: 0.3243, validation loss: 0.3031
2024-06-03 02:50:07 [INFO]: Epoch 012 - training loss: 0.2839, validation loss: 0.2773
2024-06-03 02:50:15 [INFO]: Epoch 013 - training loss: 0.3011, validation loss: 0.2984
2024-06-03 02:50:23 [INFO]: Epoch 014 - training loss: 0.2710, validation loss: 0.2816
2024-06-03 02:50:31 [INFO]: Epoch 015 - training loss: 0.2926, validation loss: 0.2845
2024-06-03 02:50:39 [INFO]: Epoch 016 - training loss: 0.2748, validation loss: 0.2717
2024-06-03 02:50:46 [INFO]: Epoch 017 - training loss: 0.2648, validation loss: 0.2828
2024-06-03 02:50:53 [INFO]: Epoch 018 - training loss: 0.2337, validation loss: 0.2643
2024-06-03 02:51:00 [INFO]: Epoch 019 - training loss: 0.2248, validation loss: 0.2590
2024-06-03 02:51:07 [INFO]: Epoch 020 - training loss: 0.2290, validation loss: 0.2526
2024-06-03 02:51:14 [INFO]: Epoch 021 - training loss: 0.2630, validation loss: 0.2525
2024-06-03 02:51:21 [INFO]: Epoch 022 - training loss: 0.2487, validation loss: 0.2561
2024-06-03 02:51:27 [INFO]: Epoch 023 - training loss: 0.2313, validation loss: 0.2361
2024-06-03 02:51:33 [INFO]: Epoch 024 - training loss: 0.2310, validation loss: 0.2462
2024-06-03 02:51:38 [INFO]: Epoch 025 - training loss: 0.2198, validation loss: 0.2492
2024-06-03 02:51:42 [INFO]: Epoch 026 - training loss: 0.2259, validation loss: 0.2381
2024-06-03 02:51:47 [INFO]: Epoch 027 - training loss: 0.2533, validation loss: 0.2345
2024-06-03 02:51:51 [INFO]: Epoch 028 - training loss: 0.2480, validation loss: 0.2366
2024-06-03 02:51:56 [INFO]: Epoch 029 - training loss: 0.2310, validation loss: 0.2326
2024-06-03 02:52:00 [INFO]: Epoch 030 - training loss: 0.2239, validation loss: 0.2372
2024-06-03 02:52:05 [INFO]: Epoch 031 - training loss: 0.2253, validation loss: 0.2230
2024-06-03 02:52:09 [INFO]: Epoch 032 - training loss: 0.2481, validation loss: 0.2187
2024-06-03 02:52:13 [INFO]: Epoch 033 - training loss: 0.2062, validation loss: 0.2149
2024-06-03 02:52:18 [INFO]: Epoch 034 - training loss: 0.2157, validation loss: 0.2158
2024-06-03 02:52:22 [INFO]: Epoch 035 - training loss: 0.2255, validation loss: 0.2131
2024-06-03 02:52:27 [INFO]: Epoch 036 - training loss: 0.2068, validation loss: 0.2132
2024-06-03 02:52:32 [INFO]: Epoch 037 - training loss: 0.2372, validation loss: 0.2188
2024-06-03 02:52:36 [INFO]: Epoch 038 - training loss: 0.2364, validation loss: 0.2281
2024-06-03 02:52:40 [INFO]: Epoch 039 - training loss: 0.2168, validation loss: 0.2096
2024-06-03 02:52:45 [INFO]: Epoch 040 - training loss: 0.2246, validation loss: 0.2094
2024-06-03 02:52:49 [INFO]: Epoch 041 - training loss: 0.1904, validation loss: 0.2080
2024-06-03 02:52:54 [INFO]: Epoch 042 - training loss: 0.2027, validation loss: 0.2083
2024-06-03 02:52:58 [INFO]: Epoch 043 - training loss: 0.2156, validation loss: 0.2033
2024-06-03 02:53:02 [INFO]: Epoch 044 - training loss: 0.2125, validation loss: 0.2119
2024-06-03 02:53:07 [INFO]: Epoch 045 - training loss: 0.1892, validation loss: 0.1998
2024-06-03 02:53:11 [INFO]: Epoch 046 - training loss: 0.1905, validation loss: 0.2020
2024-06-03 02:53:16 [INFO]: Epoch 047 - training loss: 0.2021, validation loss: 0.2178
2024-06-03 02:53:20 [INFO]: Epoch 048 - training loss: 0.2033, validation loss: 0.1995
2024-06-03 02:53:25 [INFO]: Epoch 049 - training loss: 0.2019, validation loss: 0.2012
2024-06-03 02:53:29 [INFO]: Epoch 050 - training loss: 0.1790, validation loss: 0.2133
2024-06-03 02:53:34 [INFO]: Epoch 051 - training loss: 0.2146, validation loss: 0.1956
2024-06-03 02:53:38 [INFO]: Epoch 052 - training loss: 0.1980, validation loss: 0.1898
2024-06-03 02:53:43 [INFO]: Epoch 053 - training loss: 0.1889, validation loss: 0.1917
2024-06-03 02:53:47 [INFO]: Epoch 054 - training loss: 0.2036, validation loss: 0.2019
2024-06-03 02:53:52 [INFO]: Epoch 055 - training loss: 0.2052, validation loss: 0.1945
2024-06-03 02:53:56 [INFO]: Epoch 056 - training loss: 0.1942, validation loss: 0.1940
2024-06-03 02:54:01 [INFO]: Epoch 057 - training loss: 0.1979, validation loss: 0.1906
2024-06-03 02:54:05 [INFO]: Epoch 058 - training loss: 0.1788, validation loss: 0.1931
2024-06-03 02:54:09 [INFO]: Epoch 059 - training loss: 0.2067, validation loss: 0.1876
2024-06-03 02:54:14 [INFO]: Epoch 060 - training loss: 0.1693, validation loss: 0.1928
2024-06-03 02:54:18 [INFO]: Epoch 061 - training loss: 0.2025, validation loss: 0.1918
2024-06-03 02:54:23 [INFO]: Epoch 062 - training loss: 0.1913, validation loss: 0.1905
2024-06-03 02:54:27 [INFO]: Epoch 063 - training loss: 0.1910, validation loss: 0.1947
2024-06-03 02:54:32 [INFO]: Epoch 064 - training loss: 0.1991, validation loss: 0.1888
2024-06-03 02:54:35 [INFO]: Epoch 065 - training loss: 0.2018, validation loss: 0.2003
2024-06-03 02:54:38 [INFO]: Epoch 066 - training loss: 0.1780, validation loss: 0.1922
2024-06-03 02:54:40 [INFO]: Epoch 067 - training loss: 0.1861, validation loss: 0.1817
2024-06-03 02:54:43 [INFO]: Epoch 068 - training loss: 0.1842, validation loss: 0.1849
2024-06-03 02:54:45 [INFO]: Epoch 069 - training loss: 0.2175, validation loss: 0.1937
2024-06-03 02:54:48 [INFO]: Epoch 070 - training loss: 0.1790, validation loss: 0.1773
2024-06-03 02:54:51 [INFO]: Epoch 071 - training loss: 0.1907, validation loss: 0.1819
2024-06-03 02:54:53 [INFO]: Epoch 072 - training loss: 0.1731, validation loss: 0.1852
2024-06-03 02:54:56 [INFO]: Epoch 073 - training loss: 0.1624, validation loss: 0.1839
2024-06-03 02:54:58 [INFO]: Epoch 074 - training loss: 0.1715, validation loss: 0.1859
2024-06-03 02:55:01 [INFO]: Epoch 075 - training loss: 0.1730, validation loss: 0.1905
2024-06-03 02:55:04 [INFO]: Epoch 076 - training loss: 0.1765, validation loss: 0.1806
2024-06-03 02:55:06 [INFO]: Epoch 077 - training loss: 0.1749, validation loss: 0.1784
2024-06-03 02:55:09 [INFO]: Epoch 078 - training loss: 0.1857, validation loss: 0.1839
2024-06-03 02:55:11 [INFO]: Epoch 079 - training loss: 0.1678, validation loss: 0.1780
2024-06-03 02:55:14 [INFO]: Epoch 080 - training loss: 0.1749, validation loss: 0.1774
2024-06-03 02:55:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:55:14 [INFO]: Finished training. The best model is from epoch#70.
2024-06-03 02:55:14 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_0/20240603_T024816/CSDI.pypots
2024-06-03 02:56:33 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_0/imputation.pkl
2024-06-03 02:56:33 [INFO]: Round0 - CSDI on ItalyAir: MAE=0.4671, MSE=2.1822, MRE=0.5988
2024-06-03 02:56:33 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:56:33 [INFO]: Using the given device: cuda:0
2024-06-03 02:56:33 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240603_T025633
2024-06-03 02:56:33 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240603_T025633/tensorboard
2024-06-03 02:56:33 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-03 02:56:35 [INFO]: Epoch 001 - training loss: 0.6539, validation loss: 0.4333
2024-06-03 02:56:37 [INFO]: Epoch 002 - training loss: 0.4061, validation loss: 0.3948
2024-06-03 02:56:38 [INFO]: Epoch 003 - training loss: 0.3944, validation loss: 0.3794
2024-06-03 02:56:40 [INFO]: Epoch 004 - training loss: 0.3833, validation loss: 0.3666
2024-06-03 02:56:42 [INFO]: Epoch 005 - training loss: 0.3816, validation loss: 0.3624
2024-06-03 02:56:43 [INFO]: Epoch 006 - training loss: 0.3518, validation loss: 0.3393
2024-06-03 02:56:45 [INFO]: Epoch 007 - training loss: 0.3176, validation loss: 0.3391
2024-06-03 02:56:46 [INFO]: Epoch 008 - training loss: 0.3251, validation loss: 0.3298
2024-06-03 02:56:48 [INFO]: Epoch 009 - training loss: 0.3187, validation loss: 0.3117
2024-06-03 02:56:50 [INFO]: Epoch 010 - training loss: 0.2804, validation loss: 0.3017
2024-06-03 02:56:51 [INFO]: Epoch 011 - training loss: 0.2942, validation loss: 0.3187
2024-06-03 02:56:53 [INFO]: Epoch 012 - training loss: 0.3118, validation loss: 0.3006
2024-06-03 02:56:55 [INFO]: Epoch 013 - training loss: 0.2796, validation loss: 0.2948
2024-06-03 02:56:56 [INFO]: Epoch 014 - training loss: 0.2598, validation loss: 0.2940
2024-06-03 02:56:58 [INFO]: Epoch 015 - training loss: 0.3375, validation loss: 0.2722
2024-06-03 02:56:59 [INFO]: Epoch 016 - training loss: 0.2838, validation loss: 0.2725
2024-06-03 02:57:01 [INFO]: Epoch 017 - training loss: 0.2759, validation loss: 0.2647
2024-06-03 02:57:03 [INFO]: Epoch 018 - training loss: 0.2735, validation loss: 0.2754
2024-06-03 02:57:04 [INFO]: Epoch 019 - training loss: 0.2678, validation loss: 0.2642
2024-06-03 02:57:06 [INFO]: Epoch 020 - training loss: 0.2711, validation loss: 0.2502
2024-06-03 02:57:08 [INFO]: Epoch 021 - training loss: 0.3112, validation loss: 0.2643
2024-06-03 02:57:09 [INFO]: Epoch 022 - training loss: 0.2276, validation loss: 0.2427
2024-06-03 02:57:11 [INFO]: Epoch 023 - training loss: 0.2499, validation loss: 0.2427
2024-06-03 02:57:12 [INFO]: Epoch 024 - training loss: 0.2469, validation loss: 0.2333
2024-06-03 02:57:14 [INFO]: Epoch 025 - training loss: 0.2266, validation loss: 0.2292
2024-06-03 02:57:16 [INFO]: Epoch 026 - training loss: 0.2134, validation loss: 0.2366
2024-06-03 02:57:17 [INFO]: Epoch 027 - training loss: 0.2021, validation loss: 0.2480
2024-06-03 02:57:19 [INFO]: Epoch 028 - training loss: 0.2158, validation loss: 0.2329
2024-06-03 02:57:21 [INFO]: Epoch 029 - training loss: 0.2068, validation loss: 0.2241
2024-06-03 02:57:22 [INFO]: Epoch 030 - training loss: 0.2339, validation loss: 0.2180
2024-06-03 02:57:24 [INFO]: Epoch 031 - training loss: 0.2257, validation loss: 0.2261
2024-06-03 02:57:26 [INFO]: Epoch 032 - training loss: 0.2502, validation loss: 0.2148
2024-06-03 02:57:27 [INFO]: Epoch 033 - training loss: 0.2267, validation loss: 0.2238
2024-06-03 02:57:29 [INFO]: Epoch 034 - training loss: 0.1949, validation loss: 0.2119
2024-06-03 02:57:30 [INFO]: Epoch 035 - training loss: 0.2284, validation loss: 0.2086
2024-06-03 02:57:32 [INFO]: Epoch 036 - training loss: 0.2181, validation loss: 0.2084
2024-06-03 02:57:34 [INFO]: Epoch 037 - training loss: 0.1951, validation loss: 0.2103
2024-06-03 02:57:35 [INFO]: Epoch 038 - training loss: 0.1881, validation loss: 0.2068
2024-06-03 02:57:37 [INFO]: Epoch 039 - training loss: 0.2129, validation loss: 0.2669
2024-06-03 02:57:39 [INFO]: Epoch 040 - training loss: 0.2153, validation loss: 0.2164
2024-06-03 02:57:40 [INFO]: Epoch 041 - training loss: 0.2411, validation loss: 0.2262
2024-06-03 02:57:42 [INFO]: Epoch 042 - training loss: 0.2151, validation loss: 0.2083
2024-06-03 02:57:43 [INFO]: Epoch 043 - training loss: 0.2184, validation loss: 0.2010
2024-06-03 02:57:45 [INFO]: Epoch 044 - training loss: 0.2046, validation loss: 0.1975
2024-06-03 02:57:47 [INFO]: Epoch 045 - training loss: 0.2037, validation loss: 0.1900
2024-06-03 02:57:48 [INFO]: Epoch 046 - training loss: 0.1813, validation loss: 0.2005
2024-06-03 02:57:50 [INFO]: Epoch 047 - training loss: 0.2018, validation loss: 0.2017
2024-06-03 02:57:52 [INFO]: Epoch 048 - training loss: 0.2038, validation loss: 0.1907
2024-06-03 02:57:53 [INFO]: Epoch 049 - training loss: 0.1869, validation loss: 0.1937
2024-06-03 02:57:55 [INFO]: Epoch 050 - training loss: 0.2129, validation loss: 0.1983
2024-06-03 02:57:57 [INFO]: Epoch 051 - training loss: 0.2028, validation loss: 0.1870
2024-06-03 02:57:58 [INFO]: Epoch 052 - training loss: 0.2062, validation loss: 0.1793
2024-06-03 02:58:00 [INFO]: Epoch 053 - training loss: 0.1755, validation loss: 0.1861
2024-06-03 02:58:01 [INFO]: Epoch 054 - training loss: 0.1924, validation loss: 0.1841
2024-06-03 02:58:03 [INFO]: Epoch 055 - training loss: 0.1972, validation loss: 0.1829
2024-06-03 02:58:05 [INFO]: Epoch 056 - training loss: 0.2041, validation loss: 0.1971
2024-06-03 02:58:06 [INFO]: Epoch 057 - training loss: 0.1850, validation loss: 0.1781
2024-06-03 02:58:08 [INFO]: Epoch 058 - training loss: 0.2111, validation loss: 0.1879
2024-06-03 02:58:10 [INFO]: Epoch 059 - training loss: 0.1667, validation loss: 0.1797
2024-06-03 02:58:11 [INFO]: Epoch 060 - training loss: 0.1915, validation loss: 0.1836
2024-06-03 02:58:13 [INFO]: Epoch 061 - training loss: 0.1881, validation loss: 0.1751
2024-06-03 02:58:14 [INFO]: Epoch 062 - training loss: 0.2077, validation loss: 0.1901
2024-06-03 02:58:16 [INFO]: Epoch 063 - training loss: 0.2025, validation loss: 0.1811
2024-06-03 02:58:18 [INFO]: Epoch 064 - training loss: 0.1875, validation loss: 0.1785
2024-06-03 02:58:19 [INFO]: Epoch 065 - training loss: 0.1546, validation loss: 0.1838
2024-06-03 02:58:21 [INFO]: Epoch 066 - training loss: 0.1562, validation loss: 0.1773
2024-06-03 02:58:22 [INFO]: Epoch 067 - training loss: 0.2005, validation loss: 0.1748
2024-06-03 02:58:24 [INFO]: Epoch 068 - training loss: 0.1874, validation loss: 0.1794
2024-06-03 02:58:26 [INFO]: Epoch 069 - training loss: 0.1532, validation loss: 0.1758
2024-06-03 02:58:27 [INFO]: Epoch 070 - training loss: 0.1859, validation loss: 0.1720
2024-06-03 02:58:29 [INFO]: Epoch 071 - training loss: 0.1610, validation loss: 0.1812
2024-06-03 02:58:31 [INFO]: Epoch 072 - training loss: 0.1776, validation loss: 0.1711
2024-06-03 02:58:32 [INFO]: Epoch 073 - training loss: 0.1652, validation loss: 0.1743
2024-06-03 02:58:34 [INFO]: Epoch 074 - training loss: 0.1773, validation loss: 0.1704
2024-06-03 02:58:36 [INFO]: Epoch 075 - training loss: 0.1669, validation loss: 0.1697
2024-06-03 02:58:37 [INFO]: Epoch 076 - training loss: 0.1709, validation loss: 0.1707
2024-06-03 02:58:39 [INFO]: Epoch 077 - training loss: 0.1692, validation loss: 0.1814
2024-06-03 02:58:40 [INFO]: Epoch 078 - training loss: 0.1600, validation loss: 0.1935
2024-06-03 02:58:42 [INFO]: Epoch 079 - training loss: 0.1774, validation loss: 0.1727
2024-06-03 02:58:44 [INFO]: Epoch 080 - training loss: 0.1922, validation loss: 0.1779
2024-06-03 02:58:45 [INFO]: Epoch 081 - training loss: 0.1842, validation loss: 0.1924
2024-06-03 02:58:47 [INFO]: Epoch 082 - training loss: 0.1497, validation loss: 0.1755
2024-06-03 02:58:49 [INFO]: Epoch 083 - training loss: 0.1626, validation loss: 0.1721
2024-06-03 02:58:50 [INFO]: Epoch 084 - training loss: 0.1822, validation loss: 0.1676
2024-06-03 02:58:52 [INFO]: Epoch 085 - training loss: 0.1751, validation loss: 0.1630
2024-06-03 02:58:54 [INFO]: Epoch 086 - training loss: 0.1518, validation loss: 0.1752
2024-06-03 02:58:55 [INFO]: Epoch 087 - training loss: 0.1745, validation loss: 0.1724
2024-06-03 02:58:57 [INFO]: Epoch 088 - training loss: 0.1816, validation loss: 0.1694
2024-06-03 02:58:58 [INFO]: Epoch 089 - training loss: 0.1694, validation loss: 0.1682
2024-06-03 02:59:00 [INFO]: Epoch 090 - training loss: 0.1643, validation loss: 0.1638
2024-06-03 02:59:02 [INFO]: Epoch 091 - training loss: 0.1669, validation loss: 0.1680
2024-06-03 02:59:03 [INFO]: Epoch 092 - training loss: 0.1663, validation loss: 0.1663
2024-06-03 02:59:05 [INFO]: Epoch 093 - training loss: 0.1477, validation loss: 0.1683
2024-06-03 02:59:07 [INFO]: Epoch 094 - training loss: 0.1709, validation loss: 0.1710
2024-06-03 02:59:08 [INFO]: Epoch 095 - training loss: 0.1492, validation loss: 0.1662
2024-06-03 02:59:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:59:08 [INFO]: Finished training. The best model is from epoch#85.
2024-06-03 02:59:08 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_1/20240603_T025633/CSDI.pypots
2024-06-03 03:00:05 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_1/imputation.pkl
2024-06-03 03:00:05 [INFO]: Round1 - CSDI on ItalyAir: MAE=0.4624, MSE=1.7180, MRE=0.5928
2024-06-03 03:00:05 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:00:05 [INFO]: Using the given device: cuda:0
2024-06-03 03:00:05 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240603_T030005
2024-06-03 03:00:05 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240603_T030005/tensorboard
2024-06-03 03:00:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-03 03:00:06 [INFO]: Epoch 001 - training loss: 0.6478, validation loss: 0.4484
2024-06-03 03:00:08 [INFO]: Epoch 002 - training loss: 0.3739, validation loss: 0.3764
2024-06-03 03:00:10 [INFO]: Epoch 003 - training loss: 0.3446, validation loss: 0.3596
2024-06-03 03:00:11 [INFO]: Epoch 004 - training loss: 0.3757, validation loss: 0.3435
2024-06-03 03:00:13 [INFO]: Epoch 005 - training loss: 0.3501, validation loss: 0.3333
2024-06-03 03:00:14 [INFO]: Epoch 006 - training loss: 0.3642, validation loss: 0.3210
2024-06-03 03:00:16 [INFO]: Epoch 007 - training loss: 0.3120, validation loss: 0.3443
2024-06-03 03:00:18 [INFO]: Epoch 008 - training loss: 0.3127, validation loss: 0.3249
2024-06-03 03:00:19 [INFO]: Epoch 009 - training loss: 0.3109, validation loss: 0.3058
2024-06-03 03:00:21 [INFO]: Epoch 010 - training loss: 0.2844, validation loss: 0.3223
2024-06-03 03:00:23 [INFO]: Epoch 011 - training loss: 0.3076, validation loss: 0.3118
2024-06-03 03:00:24 [INFO]: Epoch 012 - training loss: 0.2845, validation loss: 0.3048
2024-06-03 03:00:26 [INFO]: Epoch 013 - training loss: 0.2752, validation loss: 0.2784
2024-06-03 03:00:28 [INFO]: Epoch 014 - training loss: 0.2536, validation loss: 0.2673
2024-06-03 03:00:29 [INFO]: Epoch 015 - training loss: 0.2484, validation loss: 0.2689
2024-06-03 03:00:31 [INFO]: Epoch 016 - training loss: 0.2577, validation loss: 0.3020
2024-06-03 03:00:32 [INFO]: Epoch 017 - training loss: 0.2501, validation loss: 0.2687
2024-06-03 03:00:34 [INFO]: Epoch 018 - training loss: 0.2824, validation loss: 0.2829
2024-06-03 03:00:36 [INFO]: Epoch 019 - training loss: 0.2568, validation loss: 0.2504
2024-06-03 03:00:37 [INFO]: Epoch 020 - training loss: 0.2347, validation loss: 0.2426
2024-06-03 03:00:39 [INFO]: Epoch 021 - training loss: 0.2402, validation loss: 0.2620
2024-06-03 03:00:41 [INFO]: Epoch 022 - training loss: 0.2610, validation loss: 0.2497
2024-06-03 03:00:42 [INFO]: Epoch 023 - training loss: 0.2423, validation loss: 0.2483
2024-06-03 03:00:44 [INFO]: Epoch 024 - training loss: 0.2502, validation loss: 0.2653
2024-06-03 03:00:45 [INFO]: Epoch 025 - training loss: 0.2078, validation loss: 0.2541
2024-06-03 03:00:47 [INFO]: Epoch 026 - training loss: 0.1999, validation loss: 0.2331
2024-06-03 03:00:49 [INFO]: Epoch 027 - training loss: 0.2254, validation loss: 0.2529
2024-06-03 03:00:50 [INFO]: Epoch 028 - training loss: 0.2126, validation loss: 0.2195
2024-06-03 03:00:52 [INFO]: Epoch 029 - training loss: 0.2172, validation loss: 0.2198
2024-06-03 03:00:54 [INFO]: Epoch 030 - training loss: 0.2358, validation loss: 0.2317
2024-06-03 03:00:55 [INFO]: Epoch 031 - training loss: 0.1951, validation loss: 0.2211
2024-06-03 03:00:57 [INFO]: Epoch 032 - training loss: 0.2323, validation loss: 0.2314
2024-06-03 03:00:59 [INFO]: Epoch 033 - training loss: 0.2397, validation loss: 0.2414
2024-06-03 03:01:00 [INFO]: Epoch 034 - training loss: 0.2274, validation loss: 0.2096
2024-06-03 03:01:02 [INFO]: Epoch 035 - training loss: 0.2072, validation loss: 0.2129
2024-06-03 03:01:03 [INFO]: Epoch 036 - training loss: 0.2423, validation loss: 0.2100
2024-06-03 03:01:05 [INFO]: Epoch 037 - training loss: 0.1994, validation loss: 0.2093
2024-06-03 03:01:07 [INFO]: Epoch 038 - training loss: 0.2041, validation loss: 0.2345
2024-06-03 03:01:08 [INFO]: Epoch 039 - training loss: 0.1906, validation loss: 0.1992
2024-06-03 03:01:10 [INFO]: Epoch 040 - training loss: 0.1953, validation loss: 0.2059
2024-06-03 03:01:11 [INFO]: Epoch 041 - training loss: 0.1934, validation loss: 0.2026
2024-06-03 03:01:13 [INFO]: Epoch 042 - training loss: 0.2245, validation loss: 0.2025
2024-06-03 03:01:15 [INFO]: Epoch 043 - training loss: 0.2094, validation loss: 0.2040
2024-06-03 03:01:16 [INFO]: Epoch 044 - training loss: 0.1979, validation loss: 0.1991
2024-06-03 03:01:18 [INFO]: Epoch 045 - training loss: 0.1807, validation loss: 0.1994
2024-06-03 03:01:20 [INFO]: Epoch 046 - training loss: 0.2001, validation loss: 0.1949
2024-06-03 03:01:21 [INFO]: Epoch 047 - training loss: 0.1943, validation loss: 0.1899
2024-06-03 03:01:23 [INFO]: Epoch 048 - training loss: 0.1776, validation loss: 0.2049
2024-06-03 03:01:24 [INFO]: Epoch 049 - training loss: 0.2039, validation loss: 0.1935
2024-06-03 03:01:26 [INFO]: Epoch 050 - training loss: 0.1689, validation loss: 0.1899
2024-06-03 03:01:28 [INFO]: Epoch 051 - training loss: 0.2022, validation loss: 0.1874
2024-06-03 03:01:29 [INFO]: Epoch 052 - training loss: 0.1860, validation loss: 0.1947
2024-06-03 03:01:31 [INFO]: Epoch 053 - training loss: 0.1831, validation loss: 0.1873
2024-06-03 03:01:33 [INFO]: Epoch 054 - training loss: 0.1980, validation loss: 0.1886
2024-06-03 03:01:34 [INFO]: Epoch 055 - training loss: 0.1960, validation loss: 0.1784
2024-06-03 03:01:36 [INFO]: Epoch 056 - training loss: 0.1644, validation loss: 0.1886
2024-06-03 03:01:37 [INFO]: Epoch 057 - training loss: 0.1897, validation loss: 0.1861
2024-06-03 03:01:39 [INFO]: Epoch 058 - training loss: 0.1829, validation loss: 0.2128
2024-06-03 03:01:41 [INFO]: Epoch 059 - training loss: 0.1828, validation loss: 0.1880
2024-06-03 03:01:42 [INFO]: Epoch 060 - training loss: 0.1630, validation loss: 0.1849
2024-06-03 03:01:44 [INFO]: Epoch 061 - training loss: 0.1895, validation loss: 0.1896
2024-06-03 03:01:46 [INFO]: Epoch 062 - training loss: 0.1900, validation loss: 0.1795
2024-06-03 03:01:47 [INFO]: Epoch 063 - training loss: 0.1799, validation loss: 0.1767
2024-06-03 03:01:49 [INFO]: Epoch 064 - training loss: 0.1838, validation loss: 0.1818
2024-06-03 03:01:51 [INFO]: Epoch 065 - training loss: 0.1838, validation loss: 0.1792
2024-06-03 03:01:52 [INFO]: Epoch 066 - training loss: 0.1757, validation loss: 0.1817
2024-06-03 03:01:54 [INFO]: Epoch 067 - training loss: 0.1578, validation loss: 0.1782
2024-06-03 03:01:55 [INFO]: Epoch 068 - training loss: 0.1565, validation loss: 0.1760
2024-06-03 03:01:57 [INFO]: Epoch 069 - training loss: 0.1925, validation loss: 0.2226
2024-06-03 03:01:59 [INFO]: Epoch 070 - training loss: 0.1718, validation loss: 0.1928
2024-06-03 03:02:00 [INFO]: Epoch 071 - training loss: 0.1830, validation loss: 0.1729
2024-06-03 03:02:02 [INFO]: Epoch 072 - training loss: 0.1738, validation loss: 0.1977
2024-06-03 03:02:04 [INFO]: Epoch 073 - training loss: 0.1921, validation loss: 0.1705
2024-06-03 03:02:05 [INFO]: Epoch 074 - training loss: 0.1857, validation loss: 0.1711
2024-06-03 03:02:07 [INFO]: Epoch 075 - training loss: 0.1632, validation loss: 0.1745
2024-06-03 03:02:08 [INFO]: Epoch 076 - training loss: 0.1485, validation loss: 0.1742
2024-06-03 03:02:10 [INFO]: Epoch 077 - training loss: 0.1858, validation loss: 0.1727
2024-06-03 03:02:12 [INFO]: Epoch 078 - training loss: 0.1578, validation loss: 0.1710
2024-06-03 03:02:13 [INFO]: Epoch 079 - training loss: 0.1537, validation loss: 0.1680
2024-06-03 03:02:15 [INFO]: Epoch 080 - training loss: 0.1723, validation loss: 0.1749
2024-06-03 03:02:17 [INFO]: Epoch 081 - training loss: 0.1791, validation loss: 0.1861
2024-06-03 03:02:18 [INFO]: Epoch 082 - training loss: 0.1965, validation loss: 0.1828
2024-06-03 03:02:20 [INFO]: Epoch 083 - training loss: 0.1548, validation loss: 0.1775
2024-06-03 03:02:22 [INFO]: Epoch 084 - training loss: 0.1736, validation loss: 0.1768
2024-06-03 03:02:23 [INFO]: Epoch 085 - training loss: 0.1607, validation loss: 0.1695
2024-06-03 03:02:25 [INFO]: Epoch 086 - training loss: 0.1740, validation loss: 0.1765
2024-06-03 03:02:26 [INFO]: Epoch 087 - training loss: 0.1660, validation loss: 0.1785
2024-06-03 03:02:28 [INFO]: Epoch 088 - training loss: 0.1747, validation loss: 0.1662
2024-06-03 03:02:30 [INFO]: Epoch 089 - training loss: 0.1574, validation loss: 0.1649
2024-06-03 03:02:31 [INFO]: Epoch 090 - training loss: 0.1637, validation loss: 0.1648
2024-06-03 03:02:33 [INFO]: Epoch 091 - training loss: 0.1796, validation loss: 0.1744
2024-06-03 03:02:35 [INFO]: Epoch 092 - training loss: 0.1511, validation loss: 0.1660
2024-06-03 03:02:36 [INFO]: Epoch 093 - training loss: 0.1586, validation loss: 0.1778
2024-06-03 03:02:38 [INFO]: Epoch 094 - training loss: 0.1777, validation loss: 0.1812
2024-06-03 03:02:39 [INFO]: Epoch 095 - training loss: 0.1504, validation loss: 0.1690
2024-06-03 03:02:41 [INFO]: Epoch 096 - training loss: 0.1524, validation loss: 0.1718
2024-06-03 03:02:43 [INFO]: Epoch 097 - training loss: 0.1768, validation loss: 0.1644
2024-06-03 03:02:44 [INFO]: Epoch 098 - training loss: 0.1600, validation loss: 0.1698
2024-06-03 03:02:46 [INFO]: Epoch 099 - training loss: 0.1716, validation loss: 0.1635
2024-06-03 03:02:48 [INFO]: Epoch 100 - training loss: 0.1746, validation loss: 0.1657
2024-06-03 03:02:48 [INFO]: Finished training. The best model is from epoch#99.
2024-06-03 03:02:48 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_2/20240603_T030005/CSDI.pypots
2024-06-03 03:03:44 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_2/imputation.pkl
2024-06-03 03:03:44 [INFO]: Round2 - CSDI on ItalyAir: MAE=0.3036, MSE=0.3140, MRE=0.3893
2024-06-03 03:03:44 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:03:44 [INFO]: Using the given device: cuda:0
2024-06-03 03:03:44 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240603_T030344
2024-06-03 03:03:44 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240603_T030344/tensorboard
2024-06-03 03:03:44 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-03 03:03:46 [INFO]: Epoch 001 - training loss: 0.6497, validation loss: 0.6217
2024-06-03 03:03:47 [INFO]: Epoch 002 - training loss: 0.4280, validation loss: 0.3984
2024-06-03 03:03:49 [INFO]: Epoch 003 - training loss: 0.3511, validation loss: 0.3643
2024-06-03 03:03:51 [INFO]: Epoch 004 - training loss: 0.3647, validation loss: 0.3504
2024-06-03 03:03:52 [INFO]: Epoch 005 - training loss: 0.3629, validation loss: 0.3462
2024-06-03 03:03:54 [INFO]: Epoch 006 - training loss: 0.3388, validation loss: 0.3265
2024-06-03 03:03:56 [INFO]: Epoch 007 - training loss: 0.3159, validation loss: 0.3101
2024-06-03 03:03:57 [INFO]: Epoch 008 - training loss: 0.3389, validation loss: 0.3325
2024-06-03 03:03:59 [INFO]: Epoch 009 - training loss: 0.3462, validation loss: 0.3092
2024-06-03 03:04:00 [INFO]: Epoch 010 - training loss: 0.2935, validation loss: 0.3095
2024-06-03 03:04:02 [INFO]: Epoch 011 - training loss: 0.3161, validation loss: 0.3021
2024-06-03 03:04:04 [INFO]: Epoch 012 - training loss: 0.2339, validation loss: 0.2769
2024-06-03 03:04:05 [INFO]: Epoch 013 - training loss: 0.2860, validation loss: 0.2967
2024-06-03 03:04:07 [INFO]: Epoch 014 - training loss: 0.2687, validation loss: 0.2866
2024-06-03 03:04:09 [INFO]: Epoch 015 - training loss: 0.2503, validation loss: 0.2887
2024-06-03 03:04:10 [INFO]: Epoch 016 - training loss: 0.2395, validation loss: 0.2639
2024-06-03 03:04:12 [INFO]: Epoch 017 - training loss: 0.2413, validation loss: 0.2598
2024-06-03 03:04:13 [INFO]: Epoch 018 - training loss: 0.2568, validation loss: 0.2595
2024-06-03 03:04:15 [INFO]: Epoch 019 - training loss: 0.2619, validation loss: 0.2669
2024-06-03 03:04:17 [INFO]: Epoch 020 - training loss: 0.2718, validation loss: 0.2682
2024-06-03 03:04:18 [INFO]: Epoch 021 - training loss: 0.2367, validation loss: 0.2576
2024-06-03 03:04:20 [INFO]: Epoch 022 - training loss: 0.2202, validation loss: 0.2420
2024-06-03 03:04:22 [INFO]: Epoch 023 - training loss: 0.2462, validation loss: 0.2556
2024-06-03 03:04:23 [INFO]: Epoch 024 - training loss: 0.2493, validation loss: 0.2471
2024-06-03 03:04:25 [INFO]: Epoch 025 - training loss: 0.2312, validation loss: 0.2349
2024-06-03 03:04:26 [INFO]: Epoch 026 - training loss: 0.2236, validation loss: 0.2369
2024-06-03 03:04:28 [INFO]: Epoch 027 - training loss: 0.2312, validation loss: 0.2305
2024-06-03 03:04:30 [INFO]: Epoch 028 - training loss: 0.1983, validation loss: 0.2201
2024-06-03 03:04:31 [INFO]: Epoch 029 - training loss: 0.2473, validation loss: 0.2221
2024-06-03 03:04:33 [INFO]: Epoch 030 - training loss: 0.2121, validation loss: 0.2216
2024-06-03 03:04:35 [INFO]: Epoch 031 - training loss: 0.2356, validation loss: 0.2290
2024-06-03 03:04:36 [INFO]: Epoch 032 - training loss: 0.2030, validation loss: 0.2226
2024-06-03 03:04:38 [INFO]: Epoch 033 - training loss: 0.2269, validation loss: 0.2255
2024-06-03 03:04:40 [INFO]: Epoch 034 - training loss: 0.1960, validation loss: 0.2165
2024-06-03 03:04:41 [INFO]: Epoch 035 - training loss: 0.2132, validation loss: 0.2161
2024-06-03 03:04:43 [INFO]: Epoch 036 - training loss: 0.2310, validation loss: 0.2215
2024-06-03 03:04:44 [INFO]: Epoch 037 - training loss: 0.2251, validation loss: 0.2124
2024-06-03 03:04:46 [INFO]: Epoch 038 - training loss: 0.2025, validation loss: 0.2076
2024-06-03 03:04:48 [INFO]: Epoch 039 - training loss: 0.2186, validation loss: 0.2004
2024-06-03 03:04:49 [INFO]: Epoch 040 - training loss: 0.2108, validation loss: 0.2017
2024-06-03 03:04:51 [INFO]: Epoch 041 - training loss: 0.2273, validation loss: 0.2311
2024-06-03 03:04:53 [INFO]: Epoch 042 - training loss: 0.2012, validation loss: 0.2017
2024-06-03 03:04:54 [INFO]: Epoch 043 - training loss: 0.1751, validation loss: 0.2004
2024-06-03 03:04:56 [INFO]: Epoch 044 - training loss: 0.1985, validation loss: 0.2105
2024-06-03 03:04:57 [INFO]: Epoch 045 - training loss: 0.1884, validation loss: 0.2189
2024-06-03 03:04:59 [INFO]: Epoch 046 - training loss: 0.1917, validation loss: 0.2166
2024-06-03 03:05:01 [INFO]: Epoch 047 - training loss: 0.2154, validation loss: 0.2145
2024-06-03 03:05:02 [INFO]: Epoch 048 - training loss: 0.2117, validation loss: 0.1952
2024-06-03 03:05:04 [INFO]: Epoch 049 - training loss: 0.1970, validation loss: 0.1992
2024-06-03 03:05:06 [INFO]: Epoch 050 - training loss: 0.1993, validation loss: 0.2093
2024-06-03 03:05:07 [INFO]: Epoch 051 - training loss: 0.1784, validation loss: 0.1874
2024-06-03 03:05:09 [INFO]: Epoch 052 - training loss: 0.1928, validation loss: 0.1953
2024-06-03 03:05:10 [INFO]: Epoch 053 - training loss: 0.1927, validation loss: 0.2092
2024-06-03 03:05:12 [INFO]: Epoch 054 - training loss: 0.1889, validation loss: 0.1908
2024-06-03 03:05:14 [INFO]: Epoch 055 - training loss: 0.2091, validation loss: 0.1971
2024-06-03 03:05:15 [INFO]: Epoch 056 - training loss: 0.1802, validation loss: 0.1770
2024-06-03 03:05:17 [INFO]: Epoch 057 - training loss: 0.2013, validation loss: 0.1725
2024-06-03 03:05:19 [INFO]: Epoch 058 - training loss: 0.1747, validation loss: 0.1903
2024-06-03 03:05:20 [INFO]: Epoch 059 - training loss: 0.2008, validation loss: 0.1810
2024-06-03 03:05:22 [INFO]: Epoch 060 - training loss: 0.1765, validation loss: 0.1880
2024-06-03 03:05:23 [INFO]: Epoch 061 - training loss: 0.2013, validation loss: 0.1863
2024-06-03 03:05:25 [INFO]: Epoch 062 - training loss: 0.1738, validation loss: 0.1922
2024-06-03 03:05:27 [INFO]: Epoch 063 - training loss: 0.1746, validation loss: 0.1789
2024-06-03 03:05:28 [INFO]: Epoch 064 - training loss: 0.1784, validation loss: 0.1750
2024-06-03 03:05:30 [INFO]: Epoch 065 - training loss: 0.1881, validation loss: 0.1783
2024-06-03 03:05:32 [INFO]: Epoch 066 - training loss: 0.1723, validation loss: 0.1724
2024-06-03 03:05:33 [INFO]: Epoch 067 - training loss: 0.2066, validation loss: 0.1765
2024-06-03 03:05:35 [INFO]: Epoch 068 - training loss: 0.1794, validation loss: 0.1854
2024-06-03 03:05:36 [INFO]: Epoch 069 - training loss: 0.1971, validation loss: 0.1676
2024-06-03 03:05:38 [INFO]: Epoch 070 - training loss: 0.1895, validation loss: 0.1837
2024-06-03 03:05:40 [INFO]: Epoch 071 - training loss: 0.1810, validation loss: 0.1777
2024-06-03 03:05:41 [INFO]: Epoch 072 - training loss: 0.1465, validation loss: 0.1798
2024-06-03 03:05:43 [INFO]: Epoch 073 - training loss: 0.1766, validation loss: 0.1765
2024-06-03 03:05:45 [INFO]: Epoch 074 - training loss: 0.1989, validation loss: 0.1820
2024-06-03 03:05:46 [INFO]: Epoch 075 - training loss: 0.1870, validation loss: 0.1743
2024-06-03 03:05:48 [INFO]: Epoch 076 - training loss: 0.1656, validation loss: 0.1929
2024-06-03 03:05:49 [INFO]: Epoch 077 - training loss: 0.1488, validation loss: 0.1778
2024-06-03 03:05:51 [INFO]: Epoch 078 - training loss: 0.1665, validation loss: 0.1765
2024-06-03 03:05:53 [INFO]: Epoch 079 - training loss: 0.1600, validation loss: 0.1763
2024-06-03 03:05:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:05:53 [INFO]: Finished training. The best model is from epoch#69.
2024-06-03 03:05:53 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_3/20240603_T030344/CSDI.pypots
2024-06-03 03:06:49 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_3/imputation.pkl
2024-06-03 03:06:49 [INFO]: Round3 - CSDI on ItalyAir: MAE=0.4878, MSE=2.1292, MRE=0.6254
2024-06-03 03:06:49 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:06:49 [INFO]: Using the given device: cuda:0
2024-06-03 03:06:49 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240603_T030649
2024-06-03 03:06:49 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240603_T030649/tensorboard
2024-06-03 03:06:49 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 933,161
2024-06-03 03:06:51 [INFO]: Epoch 001 - training loss: 0.6508, validation loss: 0.5029
2024-06-03 03:06:53 [INFO]: Epoch 002 - training loss: 0.3917, validation loss: 0.3963
2024-06-03 03:06:54 [INFO]: Epoch 003 - training loss: 0.3927, validation loss: 0.3648
2024-06-03 03:06:56 [INFO]: Epoch 004 - training loss: 0.3546, validation loss: 0.3501
2024-06-03 03:06:58 [INFO]: Epoch 005 - training loss: 0.3475, validation loss: 0.3337
2024-06-03 03:06:59 [INFO]: Epoch 006 - training loss: 0.3126, validation loss: 0.3346
2024-06-03 03:07:01 [INFO]: Epoch 007 - training loss: 0.2980, validation loss: 0.3159
2024-06-03 03:07:03 [INFO]: Epoch 008 - training loss: 0.3154, validation loss: 0.3115
2024-06-03 03:07:04 [INFO]: Epoch 009 - training loss: 0.3279, validation loss: 0.3267
2024-06-03 03:07:06 [INFO]: Epoch 010 - training loss: 0.3097, validation loss: 0.3076
2024-06-03 03:07:07 [INFO]: Epoch 011 - training loss: 0.3218, validation loss: 0.2878
2024-06-03 03:07:09 [INFO]: Epoch 012 - training loss: 0.3179, validation loss: 0.2987
2024-06-03 03:07:11 [INFO]: Epoch 013 - training loss: 0.2883, validation loss: 0.2927
2024-06-03 03:07:12 [INFO]: Epoch 014 - training loss: 0.2802, validation loss: 0.2905
2024-06-03 03:07:14 [INFO]: Epoch 015 - training loss: 0.2572, validation loss: 0.2741
2024-06-03 03:07:16 [INFO]: Epoch 016 - training loss: 0.2914, validation loss: 0.2610
2024-06-03 03:07:17 [INFO]: Epoch 017 - training loss: 0.2766, validation loss: 0.2624
2024-06-03 03:07:19 [INFO]: Epoch 018 - training loss: 0.2748, validation loss: 0.2638
2024-06-03 03:07:21 [INFO]: Epoch 019 - training loss: 0.2504, validation loss: 0.2529
2024-06-03 03:07:22 [INFO]: Epoch 020 - training loss: 0.2661, validation loss: 0.2405
2024-06-03 03:07:24 [INFO]: Epoch 021 - training loss: 0.2470, validation loss: 0.2580
2024-06-03 03:07:25 [INFO]: Epoch 022 - training loss: 0.2534, validation loss: 0.2401
2024-06-03 03:07:27 [INFO]: Epoch 023 - training loss: 0.2360, validation loss: 0.2427
2024-06-03 03:07:29 [INFO]: Epoch 024 - training loss: 0.2339, validation loss: 0.2274
2024-06-03 03:07:30 [INFO]: Epoch 025 - training loss: 0.2235, validation loss: 0.2303
2024-06-03 03:07:32 [INFO]: Epoch 026 - training loss: 0.2156, validation loss: 0.2412
2024-06-03 03:07:34 [INFO]: Epoch 027 - training loss: 0.2264, validation loss: 0.2363
2024-06-03 03:07:35 [INFO]: Epoch 028 - training loss: 0.2539, validation loss: 0.2114
2024-06-03 03:07:37 [INFO]: Epoch 029 - training loss: 0.2269, validation loss: 0.2100
2024-06-03 03:07:38 [INFO]: Epoch 030 - training loss: 0.2258, validation loss: 0.2095
2024-06-03 03:07:40 [INFO]: Epoch 031 - training loss: 0.2184, validation loss: 0.2074
2024-06-03 03:07:42 [INFO]: Epoch 032 - training loss: 0.2039, validation loss: 0.2147
2024-06-03 03:07:43 [INFO]: Epoch 033 - training loss: 0.1931, validation loss: 0.2031
2024-06-03 03:07:45 [INFO]: Epoch 034 - training loss: 0.2231, validation loss: 0.1960
2024-06-03 03:07:47 [INFO]: Epoch 035 - training loss: 0.2044, validation loss: 0.2193
2024-06-03 03:07:48 [INFO]: Epoch 036 - training loss: 0.2153, validation loss: 0.1951
2024-06-03 03:07:50 [INFO]: Epoch 037 - training loss: 0.1886, validation loss: 0.1963
2024-06-03 03:07:52 [INFO]: Epoch 038 - training loss: 0.1765, validation loss: 0.1934
2024-06-03 03:07:53 [INFO]: Epoch 039 - training loss: 0.2132, validation loss: 0.2109
2024-06-03 03:07:55 [INFO]: Epoch 040 - training loss: 0.2192, validation loss: 0.1935
2024-06-03 03:07:56 [INFO]: Epoch 041 - training loss: 0.1836, validation loss: 0.1918
2024-06-03 03:07:58 [INFO]: Epoch 042 - training loss: 0.1862, validation loss: 0.1888
2024-06-03 03:08:00 [INFO]: Epoch 043 - training loss: 0.1899, validation loss: 0.1902
2024-06-03 03:08:01 [INFO]: Epoch 044 - training loss: 0.1810, validation loss: 0.1970
2024-06-03 03:08:03 [INFO]: Epoch 045 - training loss: 0.1914, validation loss: 0.1988
2024-06-03 03:08:04 [INFO]: Epoch 046 - training loss: 0.1863, validation loss: 0.1840
2024-06-03 03:08:06 [INFO]: Epoch 047 - training loss: 0.2080, validation loss: 0.1904
2024-06-03 03:08:08 [INFO]: Epoch 048 - training loss: 0.1924, validation loss: 0.1822
2024-06-03 03:08:09 [INFO]: Epoch 049 - training loss: 0.1971, validation loss: 0.1843
2024-06-03 03:08:10 [INFO]: Epoch 050 - training loss: 0.1936, validation loss: 0.1838
2024-06-03 03:08:11 [INFO]: Epoch 051 - training loss: 0.1891, validation loss: 0.1824
2024-06-03 03:08:13 [INFO]: Epoch 052 - training loss: 0.2060, validation loss: 0.1787
2024-06-03 03:08:14 [INFO]: Epoch 053 - training loss: 0.1832, validation loss: 0.1837
2024-06-03 03:08:15 [INFO]: Epoch 054 - training loss: 0.1814, validation loss: 0.1749
2024-06-03 03:08:16 [INFO]: Epoch 055 - training loss: 0.2054, validation loss: 0.1875
2024-06-03 03:08:17 [INFO]: Epoch 056 - training loss: 0.1538, validation loss: 0.1876
2024-06-03 03:08:19 [INFO]: Epoch 057 - training loss: 0.1866, validation loss: 0.1763
2024-06-03 03:08:20 [INFO]: Epoch 058 - training loss: 0.1852, validation loss: 0.1778
2024-06-03 03:08:21 [INFO]: Epoch 059 - training loss: 0.2020, validation loss: 0.1852
2024-06-03 03:08:22 [INFO]: Epoch 060 - training loss: 0.2074, validation loss: 0.1751
2024-06-03 03:08:23 [INFO]: Epoch 061 - training loss: 0.1856, validation loss: 0.1759
2024-06-03 03:08:25 [INFO]: Epoch 062 - training loss: 0.1976, validation loss: 0.1856
2024-06-03 03:08:26 [INFO]: Epoch 063 - training loss: 0.1760, validation loss: 0.1841
2024-06-03 03:08:27 [INFO]: Epoch 064 - training loss: 0.1464, validation loss: 0.1793
2024-06-03 03:08:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:08:27 [INFO]: Finished training. The best model is from epoch#54.
2024-06-03 03:08:27 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_4/20240603_T030649/CSDI.pypots
2024-06-03 03:09:13 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/CSDI_ItalyAir/round_4/imputation.pkl
2024-06-03 03:09:13 [INFO]: Round4 - CSDI on ItalyAir: MAE=0.6647, MSE=5.0230, MRE=0.8522
2024-06-03 03:09:13 [INFO]: Done! Final results:
Averaged CSDI (933,161 params) on ItalyAir: MAE=0.4771 ± 0.11464355155901634, MSE=2.2733 ± 1.532135832775597, MRE=0.6117 ± 0.1469752295357343, average inference time=12.48
