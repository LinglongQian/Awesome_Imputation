2024-06-03 03:22:34 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:22:34 [INFO]: Using the given device: cuda:0
2024-06-03 03:22:34 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_0/20240603_T032234
2024-06-03 03:22:34 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_0/20240603_T032234/tensorboard
2024-06-03 03:22:35 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 695,569
2024-06-03 03:22:39 [INFO]: Epoch 001 - training loss: 0.8082, validation loss: 1.9397
2024-06-03 03:22:40 [INFO]: Epoch 002 - training loss: 0.5911, validation loss: 1.9325
2024-06-03 03:22:41 [INFO]: Epoch 003 - training loss: 0.5759, validation loss: 1.9245
2024-06-03 03:22:43 [INFO]: Epoch 004 - training loss: 0.5600, validation loss: 1.9342
2024-06-03 03:22:44 [INFO]: Epoch 005 - training loss: 0.5631, validation loss: 1.9318
2024-06-03 03:22:45 [INFO]: Epoch 006 - training loss: 0.5557, validation loss: 1.9339
2024-06-03 03:22:46 [INFO]: Epoch 007 - training loss: 0.5672, validation loss: 1.9181
2024-06-03 03:22:48 [INFO]: Epoch 008 - training loss: 0.5451, validation loss: 1.9102
2024-06-03 03:22:49 [INFO]: Epoch 009 - training loss: 0.5415, validation loss: 1.8941
2024-06-03 03:22:50 [INFO]: Epoch 010 - training loss: 0.5315, validation loss: 1.9112
2024-06-03 03:22:51 [INFO]: Epoch 011 - training loss: 0.5432, validation loss: 1.9013
2024-06-03 03:22:52 [INFO]: Epoch 012 - training loss: 0.5458, validation loss: 1.9076
2024-06-03 03:22:54 [INFO]: Epoch 013 - training loss: 0.5411, validation loss: 1.8869
2024-06-03 03:22:55 [INFO]: Epoch 014 - training loss: 0.5194, validation loss: 1.8816
2024-06-03 03:22:56 [INFO]: Epoch 015 - training loss: 0.5233, validation loss: 1.8916
2024-06-03 03:22:57 [INFO]: Epoch 016 - training loss: 0.5192, validation loss: 1.8782
2024-06-03 03:22:59 [INFO]: Epoch 017 - training loss: 0.5094, validation loss: 1.8647
2024-06-03 03:23:00 [INFO]: Epoch 018 - training loss: 0.5037, validation loss: 1.8753
2024-06-03 03:23:01 [INFO]: Epoch 019 - training loss: 0.5141, validation loss: 1.8553
2024-06-03 03:23:02 [INFO]: Epoch 020 - training loss: 0.5109, validation loss: 1.8608
2024-06-03 03:23:03 [INFO]: Epoch 021 - training loss: 0.5190, validation loss: 1.8539
2024-06-03 03:23:04 [INFO]: Epoch 022 - training loss: 0.5213, validation loss: 1.8361
2024-06-03 03:23:06 [INFO]: Epoch 023 - training loss: 0.4975, validation loss: 1.8384
2024-06-03 03:23:07 [INFO]: Epoch 024 - training loss: 0.4956, validation loss: 1.8209
2024-06-03 03:23:08 [INFO]: Epoch 025 - training loss: 0.4994, validation loss: 1.8091
2024-06-03 03:23:09 [INFO]: Epoch 026 - training loss: 0.5007, validation loss: 1.8164
2024-06-03 03:23:10 [INFO]: Epoch 027 - training loss: 0.5093, validation loss: 1.8153
2024-06-03 03:23:11 [INFO]: Epoch 028 - training loss: 0.4861, validation loss: 1.8197
2024-06-03 03:23:13 [INFO]: Epoch 029 - training loss: 0.4980, validation loss: 1.8159
2024-06-03 03:23:14 [INFO]: Epoch 030 - training loss: 0.4875, validation loss: 1.8079
2024-06-03 03:23:15 [INFO]: Epoch 031 - training loss: 0.4872, validation loss: 1.7973
2024-06-03 03:23:16 [INFO]: Epoch 032 - training loss: 0.4781, validation loss: 1.7492
2024-06-03 03:23:18 [INFO]: Epoch 033 - training loss: 0.4793, validation loss: 1.7596
2024-06-03 03:23:19 [INFO]: Epoch 034 - training loss: 0.4820, validation loss: 1.7736
2024-06-03 03:23:20 [INFO]: Epoch 035 - training loss: 0.4840, validation loss: 1.7696
2024-06-03 03:23:21 [INFO]: Epoch 036 - training loss: 0.4711, validation loss: 1.7739
2024-06-03 03:23:23 [INFO]: Epoch 037 - training loss: 0.4698, validation loss: 1.7459
2024-06-03 03:23:24 [INFO]: Epoch 038 - training loss: 0.4564, validation loss: 1.7419
2024-06-03 03:23:25 [INFO]: Epoch 039 - training loss: 0.4533, validation loss: 1.7307
2024-06-03 03:23:26 [INFO]: Epoch 040 - training loss: 0.4688, validation loss: 1.7485
2024-06-03 03:23:28 [INFO]: Epoch 041 - training loss: 0.4619, validation loss: 1.7381
2024-06-03 03:23:29 [INFO]: Epoch 042 - training loss: 0.4506, validation loss: 1.7106
2024-06-03 03:23:30 [INFO]: Epoch 043 - training loss: 0.4582, validation loss: 1.6960
2024-06-03 03:23:31 [INFO]: Epoch 044 - training loss: 0.4674, validation loss: 1.6781
2024-06-03 03:23:32 [INFO]: Epoch 045 - training loss: 0.4595, validation loss: 1.6705
2024-06-03 03:23:33 [INFO]: Epoch 046 - training loss: 0.4610, validation loss: 1.7034
2024-06-03 03:23:34 [INFO]: Epoch 047 - training loss: 0.4567, validation loss: 1.7218
2024-06-03 03:23:36 [INFO]: Epoch 048 - training loss: 0.4437, validation loss: 1.6827
2024-06-03 03:23:37 [INFO]: Epoch 049 - training loss: 0.4558, validation loss: 1.6379
2024-06-03 03:23:38 [INFO]: Epoch 050 - training loss: 0.4527, validation loss: 1.5944
2024-06-03 03:23:39 [INFO]: Epoch 051 - training loss: 0.4508, validation loss: 1.5304
2024-06-03 03:23:41 [INFO]: Epoch 052 - training loss: 0.4337, validation loss: 1.5274
2024-06-03 03:23:42 [INFO]: Epoch 053 - training loss: 0.4383, validation loss: 1.5031
2024-06-03 03:23:43 [INFO]: Epoch 054 - training loss: 0.4527, validation loss: 1.5683
2024-06-03 03:23:44 [INFO]: Epoch 055 - training loss: 0.4582, validation loss: 1.5815
2024-06-03 03:23:46 [INFO]: Epoch 056 - training loss: 0.4540, validation loss: 1.5744
2024-06-03 03:23:47 [INFO]: Epoch 057 - training loss: 0.4452, validation loss: 1.5885
2024-06-03 03:23:48 [INFO]: Epoch 058 - training loss: 0.4374, validation loss: 1.6052
2024-06-03 03:23:49 [INFO]: Epoch 059 - training loss: 0.4325, validation loss: 1.4954
2024-06-03 03:23:50 [INFO]: Epoch 060 - training loss: 0.4379, validation loss: 1.4832
2024-06-03 03:23:52 [INFO]: Epoch 061 - training loss: 0.4313, validation loss: 1.4962
2024-06-03 03:23:53 [INFO]: Epoch 062 - training loss: 0.4370, validation loss: 1.4820
2024-06-03 03:23:54 [INFO]: Epoch 063 - training loss: 0.4336, validation loss: 1.4877
2024-06-03 03:23:55 [INFO]: Epoch 064 - training loss: 0.4294, validation loss: 1.5300
2024-06-03 03:23:56 [INFO]: Epoch 065 - training loss: 0.4261, validation loss: 1.5052
2024-06-03 03:23:57 [INFO]: Epoch 066 - training loss: 0.4326, validation loss: 1.4615
2024-06-03 03:23:58 [INFO]: Epoch 067 - training loss: 0.4316, validation loss: 1.4414
2024-06-03 03:23:59 [INFO]: Epoch 068 - training loss: 0.4127, validation loss: 1.5281
2024-06-03 03:24:01 [INFO]: Epoch 069 - training loss: 0.4292, validation loss: 1.4789
2024-06-03 03:24:02 [INFO]: Epoch 070 - training loss: 0.4235, validation loss: 1.4651
2024-06-03 03:24:03 [INFO]: Epoch 071 - training loss: 0.4217, validation loss: 1.5426
2024-06-03 03:24:04 [INFO]: Epoch 072 - training loss: 0.4254, validation loss: 1.4779
2024-06-03 03:24:05 [INFO]: Epoch 073 - training loss: 0.4242, validation loss: 1.4532
2024-06-03 03:24:07 [INFO]: Epoch 074 - training loss: 0.4228, validation loss: 1.4705
2024-06-03 03:24:08 [INFO]: Epoch 075 - training loss: 0.4057, validation loss: 1.5449
2024-06-03 03:24:09 [INFO]: Epoch 076 - training loss: 0.4282, validation loss: 1.5101
2024-06-03 03:24:10 [INFO]: Epoch 077 - training loss: 0.4232, validation loss: 1.4588
2024-06-03 03:24:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:24:10 [INFO]: Finished training. The best model is from epoch#67.
2024-06-03 03:24:10 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_0/20240603_T032234/MICN.pypots
2024-06-03 03:24:11 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_0/imputation.pkl
2024-06-03 03:24:11 [INFO]: Round0 - MICN on ItalyAir: MAE=0.6403, MSE=1.0111, MRE=0.8209
2024-06-03 03:24:11 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 03:24:11 [INFO]: Using the given device: cuda:0
2024-06-03 03:24:11 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_1/20240603_T032411
2024-06-03 03:24:11 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_1/20240603_T032411/tensorboard
2024-06-03 03:24:11 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 695,569
2024-06-03 03:24:12 [INFO]: Epoch 001 - training loss: 0.8120, validation loss: 1.8787
2024-06-03 03:24:13 [INFO]: Epoch 002 - training loss: 0.5950, validation loss: 1.8915
2024-06-03 03:24:14 [INFO]: Epoch 003 - training loss: 0.5848, validation loss: 1.8842
2024-06-03 03:24:15 [INFO]: Epoch 004 - training loss: 0.5589, validation loss: 1.8821
2024-06-03 03:24:17 [INFO]: Epoch 005 - training loss: 0.5603, validation loss: 1.8930
2024-06-03 03:24:18 [INFO]: Epoch 006 - training loss: 0.5437, validation loss: 1.8911
2024-06-03 03:24:19 [INFO]: Epoch 007 - training loss: 0.5475, validation loss: 1.8956
2024-06-03 03:24:20 [INFO]: Epoch 008 - training loss: 0.5563, validation loss: 1.8864
2024-06-03 03:24:21 [INFO]: Epoch 009 - training loss: 0.5300, validation loss: 1.8784
2024-06-03 03:24:22 [INFO]: Epoch 010 - training loss: 0.5329, validation loss: 1.8603
2024-06-03 03:24:23 [INFO]: Epoch 011 - training loss: 0.5247, validation loss: 1.8717
2024-06-03 03:24:24 [INFO]: Epoch 012 - training loss: 0.5309, validation loss: 1.9105
2024-06-03 03:24:25 [INFO]: Epoch 013 - training loss: 0.5220, validation loss: 1.8633
2024-06-03 03:24:27 [INFO]: Epoch 014 - training loss: 0.5140, validation loss: 1.8882
2024-06-03 03:24:28 [INFO]: Epoch 015 - training loss: 0.5075, validation loss: 1.8681
2024-06-03 03:24:29 [INFO]: Epoch 016 - training loss: 0.5014, validation loss: 1.8532
2024-06-03 03:24:30 [INFO]: Epoch 017 - training loss: 0.5044, validation loss: 1.8420
2024-06-03 03:24:31 [INFO]: Epoch 018 - training loss: 0.5030, validation loss: 1.8635
2024-06-03 03:24:32 [INFO]: Epoch 019 - training loss: 0.5061, validation loss: 1.8439
2024-06-03 03:24:34 [INFO]: Epoch 020 - training loss: 0.5028, validation loss: 1.8409
2024-06-03 03:24:35 [INFO]: Epoch 021 - training loss: 0.5095, validation loss: 1.8291
2024-06-03 03:24:36 [INFO]: Epoch 022 - training loss: 0.5084, validation loss: 1.8187
2024-06-03 03:24:37 [INFO]: Epoch 023 - training loss: 0.4871, validation loss: 1.8113
2024-06-03 03:24:38 [INFO]: Epoch 024 - training loss: 0.4894, validation loss: 1.7931
2024-06-03 03:24:39 [INFO]: Epoch 025 - training loss: 0.4910, validation loss: 1.8067
2024-06-03 03:24:41 [INFO]: Epoch 026 - training loss: 0.4821, validation loss: 1.7998
2024-06-03 03:24:42 [INFO]: Epoch 027 - training loss: 0.4783, validation loss: 1.7879
2024-06-03 03:24:42 [INFO]: Epoch 028 - training loss: 0.4840, validation loss: 1.7975
2024-06-03 03:24:43 [INFO]: Epoch 029 - training loss: 0.4813, validation loss: 1.7954
2024-06-03 03:24:44 [INFO]: Epoch 030 - training loss: 0.4701, validation loss: 1.7958
2024-06-03 03:24:45 [INFO]: Epoch 031 - training loss: 0.4705, validation loss: 1.8040
2024-06-03 03:24:46 [INFO]: Epoch 032 - training loss: 0.4764, validation loss: 1.7775
2024-06-03 03:24:48 [INFO]: Epoch 033 - training loss: 0.4789, validation loss: 1.7635
2024-06-03 03:24:49 [INFO]: Epoch 034 - training loss: 0.4787, validation loss: 1.7557
2024-06-03 03:24:50 [INFO]: Epoch 035 - training loss: 0.4642, validation loss: 1.7469
2024-06-03 03:24:51 [INFO]: Epoch 036 - training loss: 0.4648, validation loss: 1.7627
2024-06-03 03:24:52 [INFO]: Epoch 037 - training loss: 0.4581, validation loss: 1.7410
2024-06-03 03:24:53 [INFO]: Epoch 038 - training loss: 0.4552, validation loss: 1.7364
2024-06-03 03:24:54 [INFO]: Epoch 039 - training loss: 0.4569, validation loss: 1.7409
2024-06-03 03:24:55 [INFO]: Epoch 040 - training loss: 0.4516, validation loss: 1.7343
2024-06-03 03:24:56 [INFO]: Epoch 041 - training loss: 0.4529, validation loss: 1.7353
2024-06-03 03:24:57 [INFO]: Epoch 042 - training loss: 0.4410, validation loss: 1.6992
2024-06-03 03:24:58 [INFO]: Epoch 043 - training loss: 0.4542, validation loss: 1.6778
2024-06-03 03:24:59 [INFO]: Epoch 044 - training loss: 0.4597, validation loss: 1.6976
2024-06-03 03:25:00 [INFO]: Epoch 045 - training loss: 0.4605, validation loss: 1.6959
2024-06-03 03:25:01 [INFO]: Epoch 046 - training loss: 0.4601, validation loss: 1.6420
2024-06-03 03:25:02 [INFO]: Epoch 047 - training loss: 0.4424, validation loss: 1.6389
2024-06-03 03:25:03 [INFO]: Epoch 048 - training loss: 0.4485, validation loss: 1.6392
2024-06-03 03:25:04 [INFO]: Epoch 049 - training loss: 0.4385, validation loss: 1.6045
2024-06-03 03:25:05 [INFO]: Epoch 050 - training loss: 0.4501, validation loss: 1.5772
2024-06-03 03:25:06 [INFO]: Epoch 051 - training loss: 0.4455, validation loss: 1.6362
2024-06-03 03:25:07 [INFO]: Epoch 052 - training loss: 0.4406, validation loss: 1.6076
2024-06-03 03:25:08 [INFO]: Epoch 053 - training loss: 0.4596, validation loss: 1.5846
2024-06-03 03:25:09 [INFO]: Epoch 054 - training loss: 0.4460, validation loss: 1.6156
2024-06-03 03:25:10 [INFO]: Epoch 055 - training loss: 0.4395, validation loss: 1.5778
2024-06-03 03:25:11 [INFO]: Epoch 056 - training loss: 0.4294, validation loss: 1.5394
2024-06-03 03:25:12 [INFO]: Epoch 057 - training loss: 0.4264, validation loss: 1.5938
2024-06-03 03:25:13 [INFO]: Epoch 058 - training loss: 0.4434, validation loss: 1.5701
2024-06-03 03:25:14 [INFO]: Epoch 059 - training loss: 0.4360, validation loss: 1.5455
2024-06-03 03:25:15 [INFO]: Epoch 060 - training loss: 0.4262, validation loss: 1.5317
2024-06-03 03:25:16 [INFO]: Epoch 061 - training loss: 0.4329, validation loss: 1.4990
2024-06-03 03:25:17 [INFO]: Epoch 062 - training loss: 0.4271, validation loss: 1.5053
2024-06-03 03:25:18 [INFO]: Epoch 063 - training loss: 0.4347, validation loss: 1.4928
2024-06-03 03:25:19 [INFO]: Epoch 064 - training loss: 0.4313, validation loss: 1.4281
2024-06-03 03:25:20 [INFO]: Epoch 065 - training loss: 0.4301, validation loss: 1.4023
2024-06-03 03:25:21 [INFO]: Epoch 066 - training loss: 0.4336, validation loss: 1.4164
2024-06-03 03:25:21 [INFO]: Epoch 067 - training loss: 0.4303, validation loss: 1.4857
2024-06-03 03:25:22 [INFO]: Epoch 068 - training loss: 0.4220, validation loss: 1.4085
2024-06-03 03:25:23 [INFO]: Epoch 069 - training loss: 0.4494, validation loss: 1.4096
2024-06-03 03:25:24 [INFO]: Epoch 070 - training loss: 0.4244, validation loss: 1.4965
2024-06-03 03:25:25 [INFO]: Epoch 071 - training loss: 0.4267, validation loss: 1.4685
2024-06-03 03:25:26 [INFO]: Epoch 072 - training loss: 0.4184, validation loss: 1.4531
2024-06-03 03:25:27 [INFO]: Epoch 073 - training loss: 0.4194, validation loss: 1.4469
2024-06-03 03:25:28 [INFO]: Epoch 074 - training loss: 0.4289, validation loss: 1.3463
2024-06-03 03:25:29 [INFO]: Epoch 075 - training loss: 0.4182, validation loss: 1.4213
2024-06-03 03:25:30 [INFO]: Epoch 076 - training loss: 0.4199, validation loss: 1.4193
2024-06-03 03:25:31 [INFO]: Epoch 077 - training loss: 0.4139, validation loss: 1.4473
2024-06-03 03:25:32 [INFO]: Epoch 078 - training loss: 0.4132, validation loss: 1.4072
2024-06-03 03:25:33 [INFO]: Epoch 079 - training loss: 0.4122, validation loss: 1.4023
2024-06-03 03:25:34 [INFO]: Epoch 080 - training loss: 0.4154, validation loss: 1.3980
2024-06-03 03:25:35 [INFO]: Epoch 081 - training loss: 0.4203, validation loss: 1.3346
2024-06-03 03:25:36 [INFO]: Epoch 082 - training loss: 0.4165, validation loss: 1.5084
2024-06-03 03:25:37 [INFO]: Epoch 083 - training loss: 0.4156, validation loss: 1.4583
2024-06-03 03:25:37 [INFO]: Epoch 084 - training loss: 0.4103, validation loss: 1.4523
2024-06-03 03:25:38 [INFO]: Epoch 085 - training loss: 0.4137, validation loss: 1.3939
2024-06-03 03:25:39 [INFO]: Epoch 086 - training loss: 0.4129, validation loss: 1.3658
2024-06-03 03:25:40 [INFO]: Epoch 087 - training loss: 0.4270, validation loss: 1.2604
2024-06-03 03:25:41 [INFO]: Epoch 088 - training loss: 0.4222, validation loss: 1.3405
2024-06-03 03:25:42 [INFO]: Epoch 089 - training loss: 0.4154, validation loss: 1.2984
2024-06-03 03:25:43 [INFO]: Epoch 090 - training loss: 0.4035, validation loss: 1.2422
2024-06-03 03:25:44 [INFO]: Epoch 091 - training loss: 0.4103, validation loss: 1.2960
2024-06-03 03:25:45 [INFO]: Epoch 092 - training loss: 0.4104, validation loss: 1.4157
2024-06-03 03:25:46 [INFO]: Epoch 093 - training loss: 0.4131, validation loss: 1.3362
2024-06-03 03:25:47 [INFO]: Epoch 094 - training loss: 0.4113, validation loss: 1.3580
2024-06-03 03:25:47 [INFO]: Epoch 095 - training loss: 0.4115, validation loss: 1.3335
2024-06-03 03:25:48 [INFO]: Epoch 096 - training loss: 0.4105, validation loss: 1.3720
2024-06-03 03:25:49 [INFO]: Epoch 097 - training loss: 0.4047, validation loss: 1.3328
2024-06-03 03:25:50 [INFO]: Epoch 098 - training loss: 0.4071, validation loss: 1.2358
2024-06-03 03:25:51 [INFO]: Epoch 099 - training loss: 0.3986, validation loss: 1.3597
2024-06-03 03:25:52 [INFO]: Epoch 100 - training loss: 0.4216, validation loss: 1.2847
2024-06-03 03:25:52 [INFO]: Finished training. The best model is from epoch#98.
2024-06-03 03:25:52 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_1/20240603_T032411/MICN.pypots
2024-06-03 03:25:52 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_1/imputation.pkl
2024-06-03 03:25:52 [INFO]: Round1 - MICN on ItalyAir: MAE=0.6383, MSE=0.9792, MRE=0.8183
2024-06-03 03:25:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:25:52 [INFO]: Using the given device: cuda:0
2024-06-03 03:25:52 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_2/20240603_T032552
2024-06-03 03:25:52 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_2/20240603_T032552/tensorboard
2024-06-03 03:25:52 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 695,569
2024-06-03 03:25:53 [INFO]: Epoch 001 - training loss: 0.8211, validation loss: 1.8882
2024-06-03 03:25:54 [INFO]: Epoch 002 - training loss: 0.5995, validation loss: 1.8818
2024-06-03 03:25:55 [INFO]: Epoch 003 - training loss: 0.5682, validation loss: 1.8426
2024-06-03 03:25:56 [INFO]: Epoch 004 - training loss: 0.5714, validation loss: 1.8882
2024-06-03 03:25:56 [INFO]: Epoch 005 - training loss: 0.5606, validation loss: 1.9011
2024-06-03 03:25:57 [INFO]: Epoch 006 - training loss: 0.5541, validation loss: 1.8856
2024-06-03 03:25:58 [INFO]: Epoch 007 - training loss: 0.5564, validation loss: 1.8831
2024-06-03 03:25:59 [INFO]: Epoch 008 - training loss: 0.5355, validation loss: 1.8721
2024-06-03 03:26:00 [INFO]: Epoch 009 - training loss: 0.5462, validation loss: 1.8293
2024-06-03 03:26:01 [INFO]: Epoch 010 - training loss: 0.5439, validation loss: 1.9064
2024-06-03 03:26:02 [INFO]: Epoch 011 - training loss: 0.5309, validation loss: 1.8699
2024-06-03 03:26:03 [INFO]: Epoch 012 - training loss: 0.5224, validation loss: 1.8839
2024-06-03 03:26:03 [INFO]: Epoch 013 - training loss: 0.5217, validation loss: 1.8785
2024-06-03 03:26:04 [INFO]: Epoch 014 - training loss: 0.5357, validation loss: 1.8205
2024-06-03 03:26:05 [INFO]: Epoch 015 - training loss: 0.5322, validation loss: 1.8658
2024-06-03 03:26:06 [INFO]: Epoch 016 - training loss: 0.5019, validation loss: 1.8399
2024-06-03 03:26:07 [INFO]: Epoch 017 - training loss: 0.5093, validation loss: 1.8375
2024-06-03 03:26:08 [INFO]: Epoch 018 - training loss: 0.5054, validation loss: 1.8160
2024-06-03 03:26:09 [INFO]: Epoch 019 - training loss: 0.5007, validation loss: 1.8231
2024-06-03 03:26:10 [INFO]: Epoch 020 - training loss: 0.5058, validation loss: 1.8307
2024-06-03 03:26:11 [INFO]: Epoch 021 - training loss: 0.4934, validation loss: 1.7918
2024-06-03 03:26:11 [INFO]: Epoch 022 - training loss: 0.4996, validation loss: 1.7630
2024-06-03 03:26:12 [INFO]: Epoch 023 - training loss: 0.4987, validation loss: 1.7926
2024-06-03 03:26:13 [INFO]: Epoch 024 - training loss: 0.4849, validation loss: 1.7877
2024-06-03 03:26:14 [INFO]: Epoch 025 - training loss: 0.4967, validation loss: 1.7863
2024-06-03 03:26:15 [INFO]: Epoch 026 - training loss: 0.4873, validation loss: 1.8462
2024-06-03 03:26:16 [INFO]: Epoch 027 - training loss: 0.4907, validation loss: 1.8043
2024-06-03 03:26:16 [INFO]: Epoch 028 - training loss: 0.4806, validation loss: 1.7564
2024-06-03 03:26:17 [INFO]: Epoch 029 - training loss: 0.4747, validation loss: 1.7486
2024-06-03 03:26:18 [INFO]: Epoch 030 - training loss: 0.4947, validation loss: 1.7292
2024-06-03 03:26:19 [INFO]: Epoch 031 - training loss: 0.4693, validation loss: 1.6330
2024-06-03 03:26:20 [INFO]: Epoch 032 - training loss: 0.4834, validation loss: 1.6858
2024-06-03 03:26:21 [INFO]: Epoch 033 - training loss: 0.4610, validation loss: 1.6294
2024-06-03 03:26:22 [INFO]: Epoch 034 - training loss: 0.4741, validation loss: 1.6042
2024-06-03 03:26:23 [INFO]: Epoch 035 - training loss: 0.4728, validation loss: 1.6597
2024-06-03 03:26:24 [INFO]: Epoch 036 - training loss: 0.4689, validation loss: 1.7277
2024-06-03 03:26:25 [INFO]: Epoch 037 - training loss: 0.4776, validation loss: 1.6572
2024-06-03 03:26:26 [INFO]: Epoch 038 - training loss: 0.4623, validation loss: 1.6561
2024-06-03 03:26:27 [INFO]: Epoch 039 - training loss: 0.4612, validation loss: 1.6233
2024-06-03 03:26:28 [INFO]: Epoch 040 - training loss: 0.4670, validation loss: 1.6051
2024-06-03 03:26:29 [INFO]: Epoch 041 - training loss: 0.4636, validation loss: 1.6208
2024-06-03 03:26:29 [INFO]: Epoch 042 - training loss: 0.4485, validation loss: 1.6091
2024-06-03 03:26:30 [INFO]: Epoch 043 - training loss: 0.4487, validation loss: 1.5037
2024-06-03 03:26:31 [INFO]: Epoch 044 - training loss: 0.4534, validation loss: 1.5213
2024-06-03 03:26:33 [INFO]: Epoch 045 - training loss: 0.4444, validation loss: 1.4221
2024-06-03 03:26:33 [INFO]: Epoch 046 - training loss: 0.4430, validation loss: 1.4856
2024-06-03 03:26:34 [INFO]: Epoch 047 - training loss: 0.4615, validation loss: 1.4481
2024-06-03 03:26:36 [INFO]: Epoch 048 - training loss: 0.4459, validation loss: 1.3860
2024-06-03 03:26:36 [INFO]: Epoch 049 - training loss: 0.4435, validation loss: 1.3705
2024-06-03 03:26:38 [INFO]: Epoch 050 - training loss: 0.4400, validation loss: 1.3744
2024-06-03 03:26:39 [INFO]: Epoch 051 - training loss: 0.4377, validation loss: 1.3849
2024-06-03 03:26:39 [INFO]: Epoch 052 - training loss: 0.4323, validation loss: 1.3898
2024-06-03 03:26:40 [INFO]: Epoch 053 - training loss: 0.4298, validation loss: 1.4272
2024-06-03 03:26:41 [INFO]: Epoch 054 - training loss: 0.4417, validation loss: 1.3762
2024-06-03 03:26:42 [INFO]: Epoch 055 - training loss: 0.4340, validation loss: 1.3546
2024-06-03 03:26:43 [INFO]: Epoch 056 - training loss: 0.4355, validation loss: 1.3508
2024-06-03 03:26:44 [INFO]: Epoch 057 - training loss: 0.4347, validation loss: 1.3648
2024-06-03 03:26:45 [INFO]: Epoch 058 - training loss: 0.4272, validation loss: 1.3296
2024-06-03 03:26:46 [INFO]: Epoch 059 - training loss: 0.4192, validation loss: 1.3235
2024-06-03 03:26:46 [INFO]: Epoch 060 - training loss: 0.4262, validation loss: 1.3558
2024-06-03 03:26:47 [INFO]: Epoch 061 - training loss: 0.4122, validation loss: 1.4167
2024-06-03 03:26:48 [INFO]: Epoch 062 - training loss: 0.4284, validation loss: 1.3896
2024-06-03 03:26:49 [INFO]: Epoch 063 - training loss: 0.4204, validation loss: 1.3632
2024-06-03 03:26:50 [INFO]: Epoch 064 - training loss: 0.4297, validation loss: 1.3952
2024-06-03 03:26:51 [INFO]: Epoch 065 - training loss: 0.4288, validation loss: 1.3736
2024-06-03 03:26:52 [INFO]: Epoch 066 - training loss: 0.4297, validation loss: 1.4001
2024-06-03 03:26:53 [INFO]: Epoch 067 - training loss: 0.4197, validation loss: 1.4835
2024-06-03 03:26:54 [INFO]: Epoch 068 - training loss: 0.4136, validation loss: 1.5253
2024-06-03 03:26:55 [INFO]: Epoch 069 - training loss: 0.4199, validation loss: 1.4021
2024-06-03 03:26:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:26:55 [INFO]: Finished training. The best model is from epoch#59.
2024-06-03 03:26:55 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_2/20240603_T032552/MICN.pypots
2024-06-03 03:26:55 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_2/imputation.pkl
2024-06-03 03:26:55 [INFO]: Round2 - MICN on ItalyAir: MAE=0.6426, MSE=1.0673, MRE=0.8238
2024-06-03 03:26:55 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:26:55 [INFO]: Using the given device: cuda:0
2024-06-03 03:26:55 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_3/20240603_T032655
2024-06-03 03:26:55 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_3/20240603_T032655/tensorboard
2024-06-03 03:26:55 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 695,569
2024-06-03 03:26:56 [INFO]: Epoch 001 - training loss: 0.8256, validation loss: 1.8888
2024-06-03 03:26:57 [INFO]: Epoch 002 - training loss: 0.6005, validation loss: 1.8853
2024-06-03 03:26:58 [INFO]: Epoch 003 - training loss: 0.5701, validation loss: 1.8775
2024-06-03 03:26:59 [INFO]: Epoch 004 - training loss: 0.5659, validation loss: 1.8800
2024-06-03 03:26:59 [INFO]: Epoch 005 - training loss: 0.5647, validation loss: 1.8915
2024-06-03 03:27:00 [INFO]: Epoch 006 - training loss: 0.5500, validation loss: 1.8821
2024-06-03 03:27:01 [INFO]: Epoch 007 - training loss: 0.5459, validation loss: 1.8878
2024-06-03 03:27:02 [INFO]: Epoch 008 - training loss: 0.5428, validation loss: 1.9088
2024-06-03 03:27:03 [INFO]: Epoch 009 - training loss: 0.5235, validation loss: 1.8976
2024-06-03 03:27:04 [INFO]: Epoch 010 - training loss: 0.5199, validation loss: 1.8949
2024-06-03 03:27:05 [INFO]: Epoch 011 - training loss: 0.5327, validation loss: 1.9061
2024-06-03 03:27:05 [INFO]: Epoch 012 - training loss: 0.5222, validation loss: 1.8978
2024-06-03 03:27:06 [INFO]: Epoch 013 - training loss: 0.5246, validation loss: 1.8901
2024-06-03 03:27:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:27:06 [INFO]: Finished training. The best model is from epoch#3.
2024-06-03 03:27:06 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_3/20240603_T032655/MICN.pypots
2024-06-03 03:27:07 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_3/imputation.pkl
2024-06-03 03:27:07 [INFO]: Round3 - MICN on ItalyAir: MAE=0.7000, MSE=1.3017, MRE=0.8974
2024-06-03 03:27:07 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:27:07 [INFO]: Using the given device: cuda:0
2024-06-03 03:27:07 [INFO]: Model files will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_4/20240603_T032707
2024-06-03 03:27:07 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_4/20240603_T032707/tensorboard
2024-06-03 03:27:07 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 695,569
2024-06-03 03:27:08 [INFO]: Epoch 001 - training loss: 0.8418, validation loss: 1.8794
2024-06-03 03:27:09 [INFO]: Epoch 002 - training loss: 0.5962, validation loss: 1.8646
2024-06-03 03:27:10 [INFO]: Epoch 003 - training loss: 0.5783, validation loss: 1.8765
2024-06-03 03:27:11 [INFO]: Epoch 004 - training loss: 0.5744, validation loss: 1.8661
2024-06-03 03:27:11 [INFO]: Epoch 005 - training loss: 0.5583, validation loss: 1.8677
2024-06-03 03:27:12 [INFO]: Epoch 006 - training loss: 0.5464, validation loss: 1.8609
2024-06-03 03:27:13 [INFO]: Epoch 007 - training loss: 0.5442, validation loss: 1.8558
2024-06-03 03:27:14 [INFO]: Epoch 008 - training loss: 0.5472, validation loss: 1.8536
2024-06-03 03:27:15 [INFO]: Epoch 009 - training loss: 0.5435, validation loss: 1.8567
2024-06-03 03:27:16 [INFO]: Epoch 010 - training loss: 0.5402, validation loss: 1.8496
2024-06-03 03:27:17 [INFO]: Epoch 011 - training loss: 0.5214, validation loss: 1.8342
2024-06-03 03:27:18 [INFO]: Epoch 012 - training loss: 0.5287, validation loss: 1.8217
2024-06-03 03:27:18 [INFO]: Epoch 013 - training loss: 0.5196, validation loss: 1.7953
2024-06-03 03:27:19 [INFO]: Epoch 014 - training loss: 0.5189, validation loss: 1.8184
2024-06-03 03:27:20 [INFO]: Epoch 015 - training loss: 0.5064, validation loss: 1.7960
2024-06-03 03:27:21 [INFO]: Epoch 016 - training loss: 0.5052, validation loss: 1.8073
2024-06-03 03:27:22 [INFO]: Epoch 017 - training loss: 0.5075, validation loss: 1.8243
2024-06-03 03:27:22 [INFO]: Epoch 018 - training loss: 0.5097, validation loss: 1.8031
2024-06-03 03:27:23 [INFO]: Epoch 019 - training loss: 0.4970, validation loss: 1.7929
2024-06-03 03:27:24 [INFO]: Epoch 020 - training loss: 0.4932, validation loss: 1.8013
2024-06-03 03:27:25 [INFO]: Epoch 021 - training loss: 0.4955, validation loss: 1.7927
2024-06-03 03:27:25 [INFO]: Epoch 022 - training loss: 0.4891, validation loss: 1.7689
2024-06-03 03:27:26 [INFO]: Epoch 023 - training loss: 0.4946, validation loss: 1.7842
2024-06-03 03:27:27 [INFO]: Epoch 024 - training loss: 0.5026, validation loss: 1.7585
2024-06-03 03:27:28 [INFO]: Epoch 025 - training loss: 0.5001, validation loss: 1.7459
2024-06-03 03:27:29 [INFO]: Epoch 026 - training loss: 0.4818, validation loss: 1.7658
2024-06-03 03:27:30 [INFO]: Epoch 027 - training loss: 0.4753, validation loss: 1.7668
2024-06-03 03:27:30 [INFO]: Epoch 028 - training loss: 0.4885, validation loss: 1.7298
2024-06-03 03:27:31 [INFO]: Epoch 029 - training loss: 0.4800, validation loss: 1.7130
2024-06-03 03:27:32 [INFO]: Epoch 030 - training loss: 0.4820, validation loss: 1.7046
2024-06-03 03:27:33 [INFO]: Epoch 031 - training loss: 0.4751, validation loss: 1.7358
2024-06-03 03:27:34 [INFO]: Epoch 032 - training loss: 0.4727, validation loss: 1.7375
2024-06-03 03:27:34 [INFO]: Epoch 033 - training loss: 0.4828, validation loss: 1.7015
2024-06-03 03:27:35 [INFO]: Epoch 034 - training loss: 0.4663, validation loss: 1.7001
2024-06-03 03:27:36 [INFO]: Epoch 035 - training loss: 0.4776, validation loss: 1.6812
2024-06-03 03:27:37 [INFO]: Epoch 036 - training loss: 0.4621, validation loss: 1.6629
2024-06-03 03:27:38 [INFO]: Epoch 037 - training loss: 0.4635, validation loss: 1.6588
2024-06-03 03:27:39 [INFO]: Epoch 038 - training loss: 0.4825, validation loss: 1.6514
2024-06-03 03:27:40 [INFO]: Epoch 039 - training loss: 0.4717, validation loss: 1.6504
2024-06-03 03:27:41 [INFO]: Epoch 040 - training loss: 0.4519, validation loss: 1.6402
2024-06-03 03:27:41 [INFO]: Epoch 041 - training loss: 0.4537, validation loss: 1.6352
2024-06-03 03:27:42 [INFO]: Epoch 042 - training loss: 0.4557, validation loss: 1.6551
2024-06-03 03:27:43 [INFO]: Epoch 043 - training loss: 0.4471, validation loss: 1.6201
2024-06-03 03:27:44 [INFO]: Epoch 044 - training loss: 0.4533, validation loss: 1.6100
2024-06-03 03:27:45 [INFO]: Epoch 045 - training loss: 0.4474, validation loss: 1.6191
2024-06-03 03:27:46 [INFO]: Epoch 046 - training loss: 0.4517, validation loss: 1.6213
2024-06-03 03:27:46 [INFO]: Epoch 047 - training loss: 0.4405, validation loss: 1.6366
2024-06-03 03:27:47 [INFO]: Epoch 048 - training loss: 0.4613, validation loss: 1.6056
2024-06-03 03:27:48 [INFO]: Epoch 049 - training loss: 0.4565, validation loss: 1.5775
2024-06-03 03:27:49 [INFO]: Epoch 050 - training loss: 0.4507, validation loss: 1.5632
2024-06-03 03:27:50 [INFO]: Epoch 051 - training loss: 0.4434, validation loss: 1.5862
2024-06-03 03:27:50 [INFO]: Epoch 052 - training loss: 0.4480, validation loss: 1.5748
2024-06-03 03:27:51 [INFO]: Epoch 053 - training loss: 0.4352, validation loss: 1.5805
2024-06-03 03:27:52 [INFO]: Epoch 054 - training loss: 0.4412, validation loss: 1.5143
2024-06-03 03:27:53 [INFO]: Epoch 055 - training loss: 0.4421, validation loss: 1.4738
2024-06-03 03:27:54 [INFO]: Epoch 056 - training loss: 0.4440, validation loss: 1.4745
2024-06-03 03:27:54 [INFO]: Epoch 057 - training loss: 0.4442, validation loss: 1.4958
2024-06-03 03:27:55 [INFO]: Epoch 058 - training loss: 0.4282, validation loss: 1.4844
2024-06-03 03:27:56 [INFO]: Epoch 059 - training loss: 0.4362, validation loss: 1.4522
2024-06-03 03:27:57 [INFO]: Epoch 060 - training loss: 0.4432, validation loss: 1.4417
2024-06-03 03:27:58 [INFO]: Epoch 061 - training loss: 0.4410, validation loss: 1.3500
2024-06-03 03:27:59 [INFO]: Epoch 062 - training loss: 0.4316, validation loss: 1.3730
2024-06-03 03:27:59 [INFO]: Epoch 063 - training loss: 0.4321, validation loss: 1.4700
2024-06-03 03:28:00 [INFO]: Epoch 064 - training loss: 0.4292, validation loss: 1.3710
2024-06-03 03:28:01 [INFO]: Epoch 065 - training loss: 0.4149, validation loss: 1.3996
2024-06-03 03:28:02 [INFO]: Epoch 066 - training loss: 0.4195, validation loss: 1.4656
2024-06-03 03:28:02 [INFO]: Epoch 067 - training loss: 0.4311, validation loss: 1.3952
2024-06-03 03:28:03 [INFO]: Epoch 068 - training loss: 0.4173, validation loss: 1.3872
2024-06-03 03:28:04 [INFO]: Epoch 069 - training loss: 0.4325, validation loss: 1.3836
2024-06-03 03:28:05 [INFO]: Epoch 070 - training loss: 0.4203, validation loss: 1.3809
2024-06-03 03:28:06 [INFO]: Epoch 071 - training loss: 0.4256, validation loss: 1.3774
2024-06-03 03:28:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:28:06 [INFO]: Finished training. The best model is from epoch#61.
2024-06-03 03:28:06 [INFO]: Saved the model to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_4/20240603_T032707/MICN.pypots
2024-06-03 03:28:06 [INFO]: Successfully saved to results_subseq_rate05/ItalyAir/MICN_ItalyAir/round_4/imputation.pkl
2024-06-03 03:28:06 [INFO]: Round4 - MICN on ItalyAir: MAE=0.6528, MSE=1.0654, MRE=0.8369
2024-06-03 03:28:06 [INFO]: Done! Final results:
Averaged MICN (695,569 params) on ItalyAir: MAE=0.6548 ± 0.023137685713649547, MSE=1.0849 ± 0.11338209396748831, MRE=0.8395 ± 0.029662956376039416, average inference time=0.09
