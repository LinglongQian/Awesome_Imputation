2024-06-03 07:57:40 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:57:40 [INFO]: Using the given device: cuda:0
2024-06-03 07:57:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_0/20240603_T075740
2024-06-03 07:57:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_0/20240603_T075740/tensorboard
2024-06-03 07:58:21 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 07:58:34 [INFO]: Epoch 001 - training loss: 1.5806, validation loss: 1.3863
2024-06-03 07:58:43 [INFO]: Epoch 002 - training loss: 1.0602, validation loss: 1.1584
2024-06-03 07:58:50 [INFO]: Epoch 003 - training loss: 0.9153, validation loss: 1.0895
2024-06-03 07:58:58 [INFO]: Epoch 004 - training loss: 0.8412, validation loss: 1.0790
2024-06-03 07:59:06 [INFO]: Epoch 005 - training loss: 0.7864, validation loss: 1.0470
2024-06-03 07:59:15 [INFO]: Epoch 006 - training loss: 0.7357, validation loss: 1.0194
2024-06-03 07:59:23 [INFO]: Epoch 007 - training loss: 0.6962, validation loss: 1.0022
2024-06-03 07:59:32 [INFO]: Epoch 008 - training loss: 0.6525, validation loss: 0.9645
2024-06-03 07:59:40 [INFO]: Epoch 009 - training loss: 0.6212, validation loss: 0.9619
2024-06-03 07:59:49 [INFO]: Epoch 010 - training loss: 0.5943, validation loss: 0.9381
2024-06-03 07:59:57 [INFO]: Epoch 011 - training loss: 0.5787, validation loss: 0.9369
2024-06-03 08:00:06 [INFO]: Epoch 012 - training loss: 0.5703, validation loss: 0.9493
2024-06-03 08:00:13 [INFO]: Epoch 013 - training loss: 0.5657, validation loss: 0.9102
2024-06-03 08:00:21 [INFO]: Epoch 014 - training loss: 0.5583, validation loss: 0.9137
2024-06-03 08:00:30 [INFO]: Epoch 015 - training loss: 0.5507, validation loss: 0.9181
2024-06-03 08:00:38 [INFO]: Epoch 016 - training loss: 0.5426, validation loss: 0.8911
2024-06-03 08:00:46 [INFO]: Epoch 017 - training loss: 0.5406, validation loss: 0.8945
2024-06-03 08:00:55 [INFO]: Epoch 018 - training loss: 0.5376, validation loss: 0.8960
2024-06-03 08:01:03 [INFO]: Epoch 019 - training loss: 0.5294, validation loss: 0.8704
2024-06-03 08:01:12 [INFO]: Epoch 020 - training loss: 0.5291, validation loss: 0.8672
2024-06-03 08:01:20 [INFO]: Epoch 021 - training loss: 0.5304, validation loss: 0.8696
2024-06-03 08:01:29 [INFO]: Epoch 022 - training loss: 0.5257, validation loss: 0.8543
2024-06-03 08:01:37 [INFO]: Epoch 023 - training loss: 0.5250, validation loss: 0.8473
2024-06-03 08:01:46 [INFO]: Epoch 024 - training loss: 0.5244, validation loss: 0.8514
2024-06-03 08:01:54 [INFO]: Epoch 025 - training loss: 0.5188, validation loss: 0.8397
2024-06-03 08:02:02 [INFO]: Epoch 026 - training loss: 0.5184, validation loss: 0.8333
2024-06-03 08:02:10 [INFO]: Epoch 027 - training loss: 0.5153, validation loss: 0.8334
2024-06-03 08:02:18 [INFO]: Epoch 028 - training loss: 0.5158, validation loss: 0.8415
2024-06-03 08:02:27 [INFO]: Epoch 029 - training loss: 0.5202, validation loss: 0.8254
2024-06-03 08:02:35 [INFO]: Epoch 030 - training loss: 0.5142, validation loss: 0.8408
2024-06-03 08:02:44 [INFO]: Epoch 031 - training loss: 0.5143, validation loss: 0.8223
2024-06-03 08:02:52 [INFO]: Epoch 032 - training loss: 0.5138, validation loss: 0.8108
2024-06-03 08:03:00 [INFO]: Epoch 033 - training loss: 0.5102, validation loss: 0.8163
2024-06-03 08:03:09 [INFO]: Epoch 034 - training loss: 0.5109, validation loss: 0.8187
2024-06-03 08:03:17 [INFO]: Epoch 035 - training loss: 0.5077, validation loss: 0.8125
2024-06-03 08:03:25 [INFO]: Epoch 036 - training loss: 0.5121, validation loss: 0.8026
2024-06-03 08:03:33 [INFO]: Epoch 037 - training loss: 0.5099, validation loss: 0.8096
2024-06-03 08:03:41 [INFO]: Epoch 038 - training loss: 0.5049, validation loss: 0.8101
2024-06-03 08:03:50 [INFO]: Epoch 039 - training loss: 0.5129, validation loss: 0.8175
2024-06-03 08:03:59 [INFO]: Epoch 040 - training loss: 0.5052, validation loss: 0.8092
2024-06-03 08:04:07 [INFO]: Epoch 041 - training loss: 0.5066, validation loss: 0.8026
2024-06-03 08:04:16 [INFO]: Epoch 042 - training loss: 0.5023, validation loss: 0.8101
2024-06-03 08:04:24 [INFO]: Epoch 043 - training loss: 0.5046, validation loss: 0.8134
2024-06-03 08:04:33 [INFO]: Epoch 044 - training loss: 0.5039, validation loss: 0.8106
2024-06-03 08:04:42 [INFO]: Epoch 045 - training loss: 0.5011, validation loss: 0.8144
2024-06-03 08:04:50 [INFO]: Epoch 046 - training loss: 0.5062, validation loss: 0.8169
2024-06-03 08:04:59 [INFO]: Epoch 047 - training loss: 0.5032, validation loss: 0.8054
2024-06-03 08:05:07 [INFO]: Epoch 048 - training loss: 0.5006, validation loss: 0.8023
2024-06-03 08:05:16 [INFO]: Epoch 049 - training loss: 0.5021, validation loss: 0.8075
2024-06-03 08:05:24 [INFO]: Epoch 050 - training loss: 0.5013, validation loss: 0.8089
2024-06-03 08:05:31 [INFO]: Epoch 051 - training loss: 0.5017, validation loss: 0.8048
2024-06-03 08:05:39 [INFO]: Epoch 052 - training loss: 0.5006, validation loss: 0.8073
2024-06-03 08:05:46 [INFO]: Epoch 053 - training loss: 0.4978, validation loss: 0.8134
2024-06-03 08:05:53 [INFO]: Epoch 054 - training loss: 0.5038, validation loss: 0.8217
2024-06-03 08:06:01 [INFO]: Epoch 055 - training loss: 0.4989, validation loss: 0.8169
2024-06-03 08:06:08 [INFO]: Epoch 056 - training loss: 0.4993, validation loss: 0.7976
2024-06-03 08:06:15 [INFO]: Epoch 057 - training loss: 0.4990, validation loss: 0.8102
2024-06-03 08:06:22 [INFO]: Epoch 058 - training loss: 0.5038, validation loss: 0.8142
2024-06-03 08:06:30 [INFO]: Epoch 059 - training loss: 0.4997, validation loss: 0.8076
2024-06-03 08:06:37 [INFO]: Epoch 060 - training loss: 0.5002, validation loss: 0.8046
2024-06-03 08:06:44 [INFO]: Epoch 061 - training loss: 0.4986, validation loss: 0.8212
2024-06-03 08:06:52 [INFO]: Epoch 062 - training loss: 0.4978, validation loss: 0.8144
2024-06-03 08:06:59 [INFO]: Epoch 063 - training loss: 0.4991, validation loss: 0.8175
2024-06-03 08:07:06 [INFO]: Epoch 064 - training loss: 0.4979, validation loss: 0.8263
2024-06-03 08:07:14 [INFO]: Epoch 065 - training loss: 0.4962, validation loss: 0.8123
2024-06-03 08:07:21 [INFO]: Epoch 066 - training loss: 0.4952, validation loss: 0.8029
2024-06-03 08:07:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:07:21 [INFO]: Finished training. The best model is from epoch#56.
2024-06-03 08:07:47 [INFO]: Saved the model to results_subseq_rate05/PeMS/SCINet_PeMS/round_0/20240603_T075740/SCINet.pypots
2024-06-03 08:07:50 [INFO]: Successfully saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_0/imputation.pkl
2024-06-03 08:07:50 [INFO]: Round0 - SCINet on PeMS: MAE=0.5962, MSE=1.2144, MRE=0.7046
2024-06-03 08:07:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 08:07:50 [INFO]: Using the given device: cuda:0
2024-06-03 08:07:50 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_1/20240603_T080750
2024-06-03 08:07:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_1/20240603_T080750/tensorboard
2024-06-03 08:08:20 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 08:08:28 [INFO]: Epoch 001 - training loss: 1.5856, validation loss: 1.2563
2024-06-03 08:08:35 [INFO]: Epoch 002 - training loss: 1.0224, validation loss: 1.1316
2024-06-03 08:08:42 [INFO]: Epoch 003 - training loss: 0.8833, validation loss: 1.0805
2024-06-03 08:08:49 [INFO]: Epoch 004 - training loss: 0.8154, validation loss: 1.0602
2024-06-03 08:08:56 [INFO]: Epoch 005 - training loss: 0.7705, validation loss: 1.0369
2024-06-03 08:09:03 [INFO]: Epoch 006 - training loss: 0.7278, validation loss: 1.0304
2024-06-03 08:09:11 [INFO]: Epoch 007 - training loss: 0.6946, validation loss: 1.0011
2024-06-03 08:09:18 [INFO]: Epoch 008 - training loss: 0.6645, validation loss: 1.0090
2024-06-03 08:09:25 [INFO]: Epoch 009 - training loss: 0.6442, validation loss: 1.0245
2024-06-03 08:09:32 [INFO]: Epoch 010 - training loss: 0.6288, validation loss: 1.0267
2024-06-03 08:09:39 [INFO]: Epoch 011 - training loss: 0.6119, validation loss: 1.0046
2024-06-03 08:09:46 [INFO]: Epoch 012 - training loss: 0.6001, validation loss: 1.0240
2024-06-03 08:09:53 [INFO]: Epoch 013 - training loss: 0.5836, validation loss: 1.0036
2024-06-03 08:10:00 [INFO]: Epoch 014 - training loss: 0.5760, validation loss: 1.0138
2024-06-03 08:10:08 [INFO]: Epoch 015 - training loss: 0.5664, validation loss: 0.9995
2024-06-03 08:10:15 [INFO]: Epoch 016 - training loss: 0.5609, validation loss: 1.0117
2024-06-03 08:10:22 [INFO]: Epoch 017 - training loss: 0.5518, validation loss: 1.0111
2024-06-03 08:10:29 [INFO]: Epoch 018 - training loss: 0.5524, validation loss: 0.9746
2024-06-03 08:10:36 [INFO]: Epoch 019 - training loss: 0.5474, validation loss: 0.9859
2024-06-03 08:10:43 [INFO]: Epoch 020 - training loss: 0.5436, validation loss: 0.9925
2024-06-03 08:10:50 [INFO]: Epoch 021 - training loss: 0.5432, validation loss: 0.9841
2024-06-03 08:10:57 [INFO]: Epoch 022 - training loss: 0.5399, validation loss: 0.9847
2024-06-03 08:11:04 [INFO]: Epoch 023 - training loss: 0.5365, validation loss: 0.9972
2024-06-03 08:11:11 [INFO]: Epoch 024 - training loss: 0.5350, validation loss: 0.9953
2024-06-03 08:11:18 [INFO]: Epoch 025 - training loss: 0.5300, validation loss: 0.9919
2024-06-03 08:11:26 [INFO]: Epoch 026 - training loss: 0.5363, validation loss: 0.9820
2024-06-03 08:11:33 [INFO]: Epoch 027 - training loss: 0.5332, validation loss: 0.9787
2024-06-03 08:11:40 [INFO]: Epoch 028 - training loss: 0.5276, validation loss: 0.9784
2024-06-03 08:11:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:11:40 [INFO]: Finished training. The best model is from epoch#18.
2024-06-03 08:11:58 [INFO]: Saved the model to results_subseq_rate05/PeMS/SCINet_PeMS/round_1/20240603_T080750/SCINet.pypots
2024-06-03 08:12:00 [INFO]: Successfully saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_1/imputation.pkl
2024-06-03 08:12:00 [INFO]: Round1 - SCINet on PeMS: MAE=0.7376, MSE=1.4699, MRE=0.8716
2024-06-03 08:12:00 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:12:00 [INFO]: Using the given device: cuda:0
2024-06-03 08:12:00 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_2/20240603_T081200
2024-06-03 08:12:00 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_2/20240603_T081200/tensorboard
2024-06-03 08:12:14 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 08:12:20 [INFO]: Epoch 001 - training loss: 1.7115, validation loss: 1.3430
2024-06-03 08:12:25 [INFO]: Epoch 002 - training loss: 1.0545, validation loss: 1.1332
2024-06-03 08:12:30 [INFO]: Epoch 003 - training loss: 0.9045, validation loss: 1.1076
2024-06-03 08:12:36 [INFO]: Epoch 004 - training loss: 0.8300, validation loss: 1.0971
2024-06-03 08:12:41 [INFO]: Epoch 005 - training loss: 0.7928, validation loss: 1.0699
2024-06-03 08:12:47 [INFO]: Epoch 006 - training loss: 0.7574, validation loss: 1.0665
2024-06-03 08:12:52 [INFO]: Epoch 007 - training loss: 0.7296, validation loss: 1.0517
2024-06-03 08:12:58 [INFO]: Epoch 008 - training loss: 0.6999, validation loss: 1.0395
2024-06-03 08:13:03 [INFO]: Epoch 009 - training loss: 0.6750, validation loss: 1.0083
2024-06-03 08:13:09 [INFO]: Epoch 010 - training loss: 0.6477, validation loss: 0.9989
2024-06-03 08:13:14 [INFO]: Epoch 011 - training loss: 0.6314, validation loss: 0.9788
2024-06-03 08:13:20 [INFO]: Epoch 012 - training loss: 0.6153, validation loss: 0.9619
2024-06-03 08:13:25 [INFO]: Epoch 013 - training loss: 0.5946, validation loss: 0.9521
2024-06-03 08:13:31 [INFO]: Epoch 014 - training loss: 0.5771, validation loss: 0.9344
2024-06-03 08:13:36 [INFO]: Epoch 015 - training loss: 0.5725, validation loss: 0.9174
2024-06-03 08:13:42 [INFO]: Epoch 016 - training loss: 0.5627, validation loss: 0.9112
2024-06-03 08:13:47 [INFO]: Epoch 017 - training loss: 0.5509, validation loss: 0.9111
2024-06-03 08:13:52 [INFO]: Epoch 018 - training loss: 0.5438, validation loss: 0.9058
2024-06-03 08:13:58 [INFO]: Epoch 019 - training loss: 0.5362, validation loss: 0.8947
2024-06-03 08:14:03 [INFO]: Epoch 020 - training loss: 0.5291, validation loss: 0.9028
2024-06-03 08:14:09 [INFO]: Epoch 021 - training loss: 0.5238, validation loss: 0.8988
2024-06-03 08:14:14 [INFO]: Epoch 022 - training loss: 0.5236, validation loss: 0.8899
2024-06-03 08:14:20 [INFO]: Epoch 023 - training loss: 0.5201, validation loss: 0.8829
2024-06-03 08:14:25 [INFO]: Epoch 024 - training loss: 0.5131, validation loss: 0.8987
2024-06-03 08:14:31 [INFO]: Epoch 025 - training loss: 0.5128, validation loss: 0.8797
2024-06-03 08:14:36 [INFO]: Epoch 026 - training loss: 0.5110, validation loss: 0.8924
2024-06-03 08:14:41 [INFO]: Epoch 027 - training loss: 0.5069, validation loss: 0.8916
2024-06-03 08:14:47 [INFO]: Epoch 028 - training loss: 0.5080, validation loss: 0.8812
2024-06-03 08:14:52 [INFO]: Epoch 029 - training loss: 0.5055, validation loss: 0.8849
2024-06-03 08:14:58 [INFO]: Epoch 030 - training loss: 0.5053, validation loss: 0.8837
2024-06-03 08:15:03 [INFO]: Epoch 031 - training loss: 0.5026, validation loss: 0.8942
2024-06-03 08:15:09 [INFO]: Epoch 032 - training loss: 0.5067, validation loss: 0.8910
2024-06-03 08:15:14 [INFO]: Epoch 033 - training loss: 0.5018, validation loss: 0.9003
2024-06-03 08:15:20 [INFO]: Epoch 034 - training loss: 0.5029, validation loss: 0.9005
2024-06-03 08:15:25 [INFO]: Epoch 035 - training loss: 0.5014, validation loss: 0.8975
2024-06-03 08:15:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:15:25 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 08:15:37 [INFO]: Saved the model to results_subseq_rate05/PeMS/SCINet_PeMS/round_2/20240603_T081200/SCINet.pypots
2024-06-03 08:15:39 [INFO]: Successfully saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_2/imputation.pkl
2024-06-03 08:15:39 [INFO]: Round2 - SCINet on PeMS: MAE=0.6812, MSE=1.3643, MRE=0.8050
2024-06-03 08:15:39 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:15:39 [INFO]: Using the given device: cuda:0
2024-06-03 08:15:39 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_3/20240603_T081539
2024-06-03 08:15:39 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_3/20240603_T081539/tensorboard
2024-06-03 08:15:53 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 08:15:59 [INFO]: Epoch 001 - training loss: 1.5639, validation loss: 1.1994
2024-06-03 08:16:04 [INFO]: Epoch 002 - training loss: 0.9949, validation loss: 1.1022
2024-06-03 08:16:10 [INFO]: Epoch 003 - training loss: 0.8483, validation loss: 1.0574
2024-06-03 08:16:15 [INFO]: Epoch 004 - training loss: 0.7853, validation loss: 1.0102
2024-06-03 08:16:20 [INFO]: Epoch 005 - training loss: 0.7485, validation loss: 0.9974
2024-06-03 08:16:26 [INFO]: Epoch 006 - training loss: 0.7154, validation loss: 0.9703
2024-06-03 08:16:31 [INFO]: Epoch 007 - training loss: 0.6872, validation loss: 0.9573
2024-06-03 08:16:37 [INFO]: Epoch 008 - training loss: 0.6705, validation loss: 0.9705
2024-06-03 08:16:42 [INFO]: Epoch 009 - training loss: 0.6715, validation loss: 0.9429
2024-06-03 08:16:48 [INFO]: Epoch 010 - training loss: 0.6389, validation loss: 0.9431
2024-06-03 08:16:53 [INFO]: Epoch 011 - training loss: 0.6133, validation loss: 0.9383
2024-06-03 08:16:59 [INFO]: Epoch 012 - training loss: 0.6000, validation loss: 0.9294
2024-06-03 08:17:04 [INFO]: Epoch 013 - training loss: 0.5883, validation loss: 0.9246
2024-06-03 08:17:10 [INFO]: Epoch 014 - training loss: 0.5776, validation loss: 0.9206
2024-06-03 08:17:15 [INFO]: Epoch 015 - training loss: 0.5663, validation loss: 0.9146
2024-06-03 08:17:21 [INFO]: Epoch 016 - training loss: 0.5716, validation loss: 0.9031
2024-06-03 08:17:26 [INFO]: Epoch 017 - training loss: 0.5592, validation loss: 0.8982
2024-06-03 08:17:31 [INFO]: Epoch 018 - training loss: 0.5482, validation loss: 0.8943
2024-06-03 08:17:37 [INFO]: Epoch 019 - training loss: 0.5401, validation loss: 0.8818
2024-06-03 08:17:42 [INFO]: Epoch 020 - training loss: 0.5405, validation loss: 0.8805
2024-06-03 08:17:48 [INFO]: Epoch 021 - training loss: 0.5344, validation loss: 0.8858
2024-06-03 08:17:54 [INFO]: Epoch 022 - training loss: 0.5299, validation loss: 0.8773
2024-06-03 08:17:59 [INFO]: Epoch 023 - training loss: 0.5286, validation loss: 0.8840
2024-06-03 08:18:04 [INFO]: Epoch 024 - training loss: 0.5299, validation loss: 0.8638
2024-06-03 08:18:10 [INFO]: Epoch 025 - training loss: 0.5263, validation loss: 0.8775
2024-06-03 08:18:15 [INFO]: Epoch 026 - training loss: 0.5492, validation loss: 0.8691
2024-06-03 08:18:21 [INFO]: Epoch 027 - training loss: 0.5518, validation loss: 0.8762
2024-06-03 08:18:26 [INFO]: Epoch 028 - training loss: 0.5364, validation loss: 0.8451
2024-06-03 08:18:32 [INFO]: Epoch 029 - training loss: 0.5276, validation loss: 0.8538
2024-06-03 08:18:37 [INFO]: Epoch 030 - training loss: 0.5241, validation loss: 0.8422
2024-06-03 08:18:43 [INFO]: Epoch 031 - training loss: 0.5189, validation loss: 0.8300
2024-06-03 08:18:48 [INFO]: Epoch 032 - training loss: 0.5151, validation loss: 0.8457
2024-06-03 08:18:54 [INFO]: Epoch 033 - training loss: 0.5170, validation loss: 0.8402
2024-06-03 08:18:59 [INFO]: Epoch 034 - training loss: 0.5168, validation loss: 0.8399
2024-06-03 08:19:05 [INFO]: Epoch 035 - training loss: 0.5155, validation loss: 0.8227
2024-06-03 08:19:10 [INFO]: Epoch 036 - training loss: 0.5102, validation loss: 0.8292
2024-06-03 08:19:16 [INFO]: Epoch 037 - training loss: 0.5149, validation loss: 0.8333
2024-06-03 08:19:20 [INFO]: Epoch 038 - training loss: 0.5143, validation loss: 0.8426
2024-06-03 08:19:24 [INFO]: Epoch 039 - training loss: 0.5095, validation loss: 0.8292
2024-06-03 08:19:28 [INFO]: Epoch 040 - training loss: 0.5057, validation loss: 0.8352
2024-06-03 08:19:32 [INFO]: Epoch 041 - training loss: 0.5035, validation loss: 0.8239
2024-06-03 08:19:36 [INFO]: Epoch 042 - training loss: 0.5069, validation loss: 0.8255
2024-06-03 08:19:40 [INFO]: Epoch 043 - training loss: 0.5067, validation loss: 0.8268
2024-06-03 08:19:44 [INFO]: Epoch 044 - training loss: 0.5031, validation loss: 0.8207
2024-06-03 08:19:48 [INFO]: Epoch 045 - training loss: 0.5033, validation loss: 0.8360
2024-06-03 08:19:52 [INFO]: Epoch 046 - training loss: 0.5039, validation loss: 0.8243
2024-06-03 08:19:57 [INFO]: Epoch 047 - training loss: 0.5028, validation loss: 0.8249
2024-06-03 08:20:01 [INFO]: Epoch 048 - training loss: 0.5014, validation loss: 0.8258
2024-06-03 08:20:05 [INFO]: Epoch 049 - training loss: 0.4981, validation loss: 0.8267
2024-06-03 08:20:09 [INFO]: Epoch 050 - training loss: 0.5012, validation loss: 0.8192
2024-06-03 08:20:13 [INFO]: Epoch 051 - training loss: 0.4995, validation loss: 0.8119
2024-06-03 08:20:17 [INFO]: Epoch 052 - training loss: 0.4995, validation loss: 0.8195
2024-06-03 08:20:21 [INFO]: Epoch 053 - training loss: 0.5000, validation loss: 0.8123
2024-06-03 08:20:25 [INFO]: Epoch 054 - training loss: 0.4948, validation loss: 0.8227
2024-06-03 08:20:29 [INFO]: Epoch 055 - training loss: 0.4975, validation loss: 0.8294
2024-06-03 08:20:33 [INFO]: Epoch 056 - training loss: 0.5005, validation loss: 0.8288
2024-06-03 08:20:38 [INFO]: Epoch 057 - training loss: 0.4971, validation loss: 0.8198
2024-06-03 08:20:42 [INFO]: Epoch 058 - training loss: 0.4971, validation loss: 0.8317
2024-06-03 08:20:46 [INFO]: Epoch 059 - training loss: 0.4961, validation loss: 0.8143
2024-06-03 08:20:50 [INFO]: Epoch 060 - training loss: 0.4966, validation loss: 0.8136
2024-06-03 08:20:54 [INFO]: Epoch 061 - training loss: 0.4963, validation loss: 0.8199
2024-06-03 08:20:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:20:54 [INFO]: Finished training. The best model is from epoch#51.
2024-06-03 08:21:02 [INFO]: Saved the model to results_subseq_rate05/PeMS/SCINet_PeMS/round_3/20240603_T081539/SCINet.pypots
2024-06-03 08:21:04 [INFO]: Successfully saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_3/imputation.pkl
2024-06-03 08:21:04 [INFO]: Round3 - SCINet on PeMS: MAE=0.6986, MSE=1.2860, MRE=0.8255
2024-06-03 08:21:04 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:21:04 [INFO]: Using the given device: cuda:0
2024-06-03 08:21:04 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_4/20240603_T082104
2024-06-03 08:21:04 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_4/20240603_T082104/tensorboard
2024-06-03 08:21:13 [INFO]: SCINet initialized with the given hyperparameters, the number of trainable parameters: 1,143,027,230
2024-06-03 08:21:17 [INFO]: Epoch 001 - training loss: 1.5568, validation loss: 1.2720
2024-06-03 08:21:21 [INFO]: Epoch 002 - training loss: 1.0198, validation loss: 1.1090
2024-06-03 08:21:25 [INFO]: Epoch 003 - training loss: 0.8580, validation loss: 1.0429
2024-06-03 08:21:29 [INFO]: Epoch 004 - training loss: 0.7814, validation loss: 1.0052
2024-06-03 08:21:33 [INFO]: Epoch 005 - training loss: 0.7326, validation loss: 0.9952
2024-06-03 08:21:37 [INFO]: Epoch 006 - training loss: 0.6865, validation loss: 1.0069
2024-06-03 08:21:41 [INFO]: Epoch 007 - training loss: 0.6629, validation loss: 0.9618
2024-06-03 08:21:45 [INFO]: Epoch 008 - training loss: 0.6349, validation loss: 0.9521
2024-06-03 08:21:50 [INFO]: Epoch 009 - training loss: 0.6198, validation loss: 0.9421
2024-06-03 08:21:54 [INFO]: Epoch 010 - training loss: 0.5959, validation loss: 0.9064
2024-06-03 08:21:58 [INFO]: Epoch 011 - training loss: 0.5760, validation loss: 0.8841
2024-06-03 08:22:02 [INFO]: Epoch 012 - training loss: 0.5571, validation loss: 0.8637
2024-06-03 08:22:06 [INFO]: Epoch 013 - training loss: 0.5451, validation loss: 0.8419
2024-06-03 08:22:10 [INFO]: Epoch 014 - training loss: 0.5375, validation loss: 0.8226
2024-06-03 08:22:14 [INFO]: Epoch 015 - training loss: 0.5306, validation loss: 0.8406
2024-06-03 08:22:18 [INFO]: Epoch 016 - training loss: 0.5213, validation loss: 0.8232
2024-06-03 08:22:22 [INFO]: Epoch 017 - training loss: 0.5166, validation loss: 0.8105
2024-06-03 08:22:26 [INFO]: Epoch 018 - training loss: 0.5178, validation loss: 0.8432
2024-06-03 08:22:31 [INFO]: Epoch 019 - training loss: 0.5151, validation loss: 0.8263
2024-06-03 08:22:35 [INFO]: Epoch 020 - training loss: 0.5140, validation loss: 0.8227
2024-06-03 08:22:39 [INFO]: Epoch 021 - training loss: 0.5128, validation loss: 0.8174
2024-06-03 08:22:43 [INFO]: Epoch 022 - training loss: 0.5135, validation loss: 0.8429
2024-06-03 08:22:47 [INFO]: Epoch 023 - training loss: 0.5099, validation loss: 0.8289
2024-06-03 08:22:51 [INFO]: Epoch 024 - training loss: 0.5086, validation loss: 0.8321
2024-06-03 08:22:55 [INFO]: Epoch 025 - training loss: 0.5096, validation loss: 0.8295
2024-06-03 08:22:59 [INFO]: Epoch 026 - training loss: 0.5090, validation loss: 0.8392
2024-06-03 08:23:03 [INFO]: Epoch 027 - training loss: 0.5050, validation loss: 0.8250
2024-06-03 08:23:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:23:03 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 08:23:11 [INFO]: Saved the model to results_subseq_rate05/PeMS/SCINet_PeMS/round_4/20240603_T082104/SCINet.pypots
2024-06-03 08:23:13 [INFO]: Successfully saved to results_subseq_rate05/PeMS/SCINet_PeMS/round_4/imputation.pkl
2024-06-03 08:23:13 [INFO]: Round4 - SCINet on PeMS: MAE=0.6262, MSE=1.1586, MRE=0.7400
2024-06-03 08:23:13 [INFO]: Done! Final results:
Averaged SCINet (1,143,027,230 params) on PeMS: MAE=0.6679 ± 0.05067549308087413, MSE=1.2986 ± 0.10998939055767723, MRE=0.7893 ± 0.059884506518659814, average inference time=0.40
