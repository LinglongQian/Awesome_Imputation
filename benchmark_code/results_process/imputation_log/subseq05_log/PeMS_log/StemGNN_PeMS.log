2024-06-03 07:57:40 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:57:40 [INFO]: Using the given device: cuda:0
2024-06-03 07:57:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_0/20240603_T075740
2024-06-03 07:57:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_0/20240603_T075740/tensorboard
2024-06-03 07:57:41 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 07:57:46 [INFO]: Epoch 001 - training loss: 1.0913, validation loss: 1.2884
2024-06-03 07:57:48 [INFO]: Epoch 002 - training loss: 0.7549, validation loss: 1.0639
2024-06-03 07:57:51 [INFO]: Epoch 003 - training loss: 0.6643, validation loss: 1.0213
2024-06-03 07:57:54 [INFO]: Epoch 004 - training loss: 0.6133, validation loss: 1.0074
2024-06-03 07:57:56 [INFO]: Epoch 005 - training loss: 0.5674, validation loss: 0.9188
2024-06-03 07:57:59 [INFO]: Epoch 006 - training loss: 0.5299, validation loss: 0.8782
2024-06-03 07:58:02 [INFO]: Epoch 007 - training loss: 0.5063, validation loss: 0.8543
2024-06-03 07:58:05 [INFO]: Epoch 008 - training loss: 0.4872, validation loss: 0.8355
2024-06-03 07:58:08 [INFO]: Epoch 009 - training loss: 0.4768, validation loss: 0.8206
2024-06-03 07:58:11 [INFO]: Epoch 010 - training loss: 0.4664, validation loss: 0.7887
2024-06-03 07:58:14 [INFO]: Epoch 011 - training loss: 0.4515, validation loss: 0.7867
2024-06-03 07:58:17 [INFO]: Epoch 012 - training loss: 0.4405, validation loss: 0.7628
2024-06-03 07:58:20 [INFO]: Epoch 013 - training loss: 0.4313, validation loss: 0.7575
2024-06-03 07:58:23 [INFO]: Epoch 014 - training loss: 0.4290, validation loss: 0.7435
2024-06-03 07:58:26 [INFO]: Epoch 015 - training loss: 0.4216, validation loss: 0.7404
2024-06-03 07:58:30 [INFO]: Epoch 016 - training loss: 0.4179, validation loss: 0.7374
2024-06-03 07:58:34 [INFO]: Epoch 017 - training loss: 0.4069, validation loss: 0.7327
2024-06-03 07:58:38 [INFO]: Epoch 018 - training loss: 0.4008, validation loss: 0.7242
2024-06-03 07:58:42 [INFO]: Epoch 019 - training loss: 0.3989, validation loss: 0.7415
2024-06-03 07:58:46 [INFO]: Epoch 020 - training loss: 0.3961, validation loss: 0.7124
2024-06-03 07:58:50 [INFO]: Epoch 021 - training loss: 0.3919, validation loss: 0.6968
2024-06-03 07:58:53 [INFO]: Epoch 022 - training loss: 0.3843, validation loss: 0.7001
2024-06-03 07:58:58 [INFO]: Epoch 023 - training loss: 0.3761, validation loss: 0.6970
2024-06-03 07:59:02 [INFO]: Epoch 024 - training loss: 0.3768, validation loss: 0.6992
2024-06-03 07:59:06 [INFO]: Epoch 025 - training loss: 0.3777, validation loss: 0.7032
2024-06-03 07:59:10 [INFO]: Epoch 026 - training loss: 0.3745, validation loss: 0.6892
2024-06-03 07:59:14 [INFO]: Epoch 027 - training loss: 0.3679, validation loss: 0.6957
2024-06-03 07:59:18 [INFO]: Epoch 028 - training loss: 0.3639, validation loss: 0.6785
2024-06-03 07:59:22 [INFO]: Epoch 029 - training loss: 0.3606, validation loss: 0.6918
2024-06-03 07:59:26 [INFO]: Epoch 030 - training loss: 0.3561, validation loss: 0.6773
2024-06-03 07:59:30 [INFO]: Epoch 031 - training loss: 0.3531, validation loss: 0.6773
2024-06-03 07:59:34 [INFO]: Epoch 032 - training loss: 0.3548, validation loss: 0.6774
2024-06-03 07:59:38 [INFO]: Epoch 033 - training loss: 0.3485, validation loss: 0.6839
2024-06-03 07:59:42 [INFO]: Epoch 034 - training loss: 0.3445, validation loss: 0.6738
2024-06-03 07:59:45 [INFO]: Epoch 035 - training loss: 0.3476, validation loss: 0.6722
2024-06-03 07:59:49 [INFO]: Epoch 036 - training loss: 0.3424, validation loss: 0.6733
2024-06-03 07:59:53 [INFO]: Epoch 037 - training loss: 0.3394, validation loss: 0.6755
2024-06-03 07:59:57 [INFO]: Epoch 038 - training loss: 0.3360, validation loss: 0.6789
2024-06-03 08:00:01 [INFO]: Epoch 039 - training loss: 0.3309, validation loss: 0.6795
2024-06-03 08:00:05 [INFO]: Epoch 040 - training loss: 0.3273, validation loss: 0.6745
2024-06-03 08:00:09 [INFO]: Epoch 041 - training loss: 0.3344, validation loss: 0.6796
2024-06-03 08:00:13 [INFO]: Epoch 042 - training loss: 0.3302, validation loss: 0.6718
2024-06-03 08:00:17 [INFO]: Epoch 043 - training loss: 0.3257, validation loss: 0.6677
2024-06-03 08:00:21 [INFO]: Epoch 044 - training loss: 0.3252, validation loss: 0.6683
2024-06-03 08:00:24 [INFO]: Epoch 045 - training loss: 0.3260, validation loss: 0.6652
2024-06-03 08:00:28 [INFO]: Epoch 046 - training loss: 0.3234, validation loss: 0.6664
2024-06-03 08:00:32 [INFO]: Epoch 047 - training loss: 0.3193, validation loss: 0.6655
2024-06-03 08:00:36 [INFO]: Epoch 048 - training loss: 0.3148, validation loss: 0.6674
2024-06-03 08:00:40 [INFO]: Epoch 049 - training loss: 0.3199, validation loss: 0.6612
2024-06-03 08:00:44 [INFO]: Epoch 050 - training loss: 0.3126, validation loss: 0.6622
2024-06-03 08:00:48 [INFO]: Epoch 051 - training loss: 0.3094, validation loss: 0.6751
2024-06-03 08:00:52 [INFO]: Epoch 052 - training loss: 0.3108, validation loss: 0.6677
2024-06-03 08:00:56 [INFO]: Epoch 053 - training loss: 0.3063, validation loss: 0.6648
2024-06-03 08:01:00 [INFO]: Epoch 054 - training loss: 0.3046, validation loss: 0.6594
2024-06-03 08:01:04 [INFO]: Epoch 055 - training loss: 0.3019, validation loss: 0.6812
2024-06-03 08:01:08 [INFO]: Epoch 056 - training loss: 0.3064, validation loss: 0.6674
2024-06-03 08:01:12 [INFO]: Epoch 057 - training loss: 0.3032, validation loss: 0.6730
2024-06-03 08:01:16 [INFO]: Epoch 058 - training loss: 0.3022, validation loss: 0.6759
2024-06-03 08:01:20 [INFO]: Epoch 059 - training loss: 0.3022, validation loss: 0.6606
2024-06-03 08:01:24 [INFO]: Epoch 060 - training loss: 0.2973, validation loss: 0.6670
2024-06-03 08:01:28 [INFO]: Epoch 061 - training loss: 0.2964, validation loss: 0.6640
2024-06-03 08:01:32 [INFO]: Epoch 062 - training loss: 0.2950, validation loss: 0.6557
2024-06-03 08:01:36 [INFO]: Epoch 063 - training loss: 0.2989, validation loss: 0.6703
2024-06-03 08:01:40 [INFO]: Epoch 064 - training loss: 0.2937, validation loss: 0.6723
2024-06-03 08:01:44 [INFO]: Epoch 065 - training loss: 0.2911, validation loss: 0.6592
2024-06-03 08:01:48 [INFO]: Epoch 066 - training loss: 0.2906, validation loss: 0.6612
2024-06-03 08:01:52 [INFO]: Epoch 067 - training loss: 0.2891, validation loss: 0.6599
2024-06-03 08:01:56 [INFO]: Epoch 068 - training loss: 0.2885, validation loss: 0.6601
2024-06-03 08:01:59 [INFO]: Epoch 069 - training loss: 0.2838, validation loss: 0.6736
2024-06-03 08:02:03 [INFO]: Epoch 070 - training loss: 0.2839, validation loss: 0.6700
2024-06-03 08:02:07 [INFO]: Epoch 071 - training loss: 0.2874, validation loss: 0.6542
2024-06-03 08:02:11 [INFO]: Epoch 072 - training loss: 0.2860, validation loss: 0.6656
2024-06-03 08:02:15 [INFO]: Epoch 073 - training loss: 0.2819, validation loss: 0.6732
2024-06-03 08:02:19 [INFO]: Epoch 074 - training loss: 0.2835, validation loss: 0.6583
2024-06-03 08:02:23 [INFO]: Epoch 075 - training loss: 0.2817, validation loss: 0.6685
2024-06-03 08:02:27 [INFO]: Epoch 076 - training loss: 0.2835, validation loss: 0.6655
2024-06-03 08:02:32 [INFO]: Epoch 077 - training loss: 0.2806, validation loss: 0.6670
2024-06-03 08:02:36 [INFO]: Epoch 078 - training loss: 0.2788, validation loss: 0.6668
2024-06-03 08:02:40 [INFO]: Epoch 079 - training loss: 0.2783, validation loss: 0.6646
2024-06-03 08:02:44 [INFO]: Epoch 080 - training loss: 0.2755, validation loss: 0.6608
2024-06-03 08:02:48 [INFO]: Epoch 081 - training loss: 0.2788, validation loss: 0.6794
2024-06-03 08:02:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:02:48 [INFO]: Finished training. The best model is from epoch#71.
2024-06-03 08:02:48 [INFO]: Saved the model to results_subseq_rate05/PeMS/StemGNN_PeMS/round_0/20240603_T075740/StemGNN.pypots
2024-06-03 08:02:50 [INFO]: Successfully saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_0/imputation.pkl
2024-06-03 08:02:50 [INFO]: Round0 - StemGNN on PeMS: MAE=0.4794, MSE=1.0201, MRE=0.5665
2024-06-03 08:02:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 08:02:50 [INFO]: Using the given device: cuda:0
2024-06-03 08:02:50 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_1/20240603_T080250
2024-06-03 08:02:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_1/20240603_T080250/tensorboard
2024-06-03 08:02:50 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 08:02:55 [INFO]: Epoch 001 - training loss: 1.1309, validation loss: 1.1553
2024-06-03 08:02:59 [INFO]: Epoch 002 - training loss: 0.7596, validation loss: 1.1019
2024-06-03 08:03:03 [INFO]: Epoch 003 - training loss: 0.6952, validation loss: 1.0338
2024-06-03 08:03:07 [INFO]: Epoch 004 - training loss: 0.6639, validation loss: 0.9842
2024-06-03 08:03:11 [INFO]: Epoch 005 - training loss: 0.6090, validation loss: 1.0075
2024-06-03 08:03:15 [INFO]: Epoch 006 - training loss: 0.5715, validation loss: 0.9439
2024-06-03 08:03:19 [INFO]: Epoch 007 - training loss: 0.5393, validation loss: 0.9128
2024-06-03 08:03:23 [INFO]: Epoch 008 - training loss: 0.5125, validation loss: 0.8643
2024-06-03 08:03:26 [INFO]: Epoch 009 - training loss: 0.4880, validation loss: 0.8182
2024-06-03 08:03:30 [INFO]: Epoch 010 - training loss: 0.4705, validation loss: 0.7783
2024-06-03 08:03:34 [INFO]: Epoch 011 - training loss: 0.4635, validation loss: 0.7600
2024-06-03 08:03:38 [INFO]: Epoch 012 - training loss: 0.4519, validation loss: 0.7684
2024-06-03 08:03:42 [INFO]: Epoch 013 - training loss: 0.4396, validation loss: 0.7333
2024-06-03 08:03:46 [INFO]: Epoch 014 - training loss: 0.4351, validation loss: 0.7243
2024-06-03 08:03:50 [INFO]: Epoch 015 - training loss: 0.4221, validation loss: 0.7170
2024-06-03 08:03:54 [INFO]: Epoch 016 - training loss: 0.4200, validation loss: 0.7135
2024-06-03 08:03:58 [INFO]: Epoch 017 - training loss: 0.4114, validation loss: 0.7052
2024-06-03 08:04:02 [INFO]: Epoch 018 - training loss: 0.4074, validation loss: 0.6988
2024-06-03 08:04:05 [INFO]: Epoch 019 - training loss: 0.4030, validation loss: 0.7056
2024-06-03 08:04:09 [INFO]: Epoch 020 - training loss: 0.4037, validation loss: 0.7168
2024-06-03 08:04:13 [INFO]: Epoch 021 - training loss: 0.3991, validation loss: 0.7075
2024-06-03 08:04:17 [INFO]: Epoch 022 - training loss: 0.3911, validation loss: 0.7060
2024-06-03 08:04:21 [INFO]: Epoch 023 - training loss: 0.3890, validation loss: 0.7050
2024-06-03 08:04:25 [INFO]: Epoch 024 - training loss: 0.3857, validation loss: 0.7046
2024-06-03 08:04:29 [INFO]: Epoch 025 - training loss: 0.3833, validation loss: 0.7091
2024-06-03 08:04:33 [INFO]: Epoch 026 - training loss: 0.3796, validation loss: 0.6940
2024-06-03 08:04:37 [INFO]: Epoch 027 - training loss: 0.3698, validation loss: 0.6953
2024-06-03 08:04:41 [INFO]: Epoch 028 - training loss: 0.3703, validation loss: 0.6881
2024-06-03 08:04:45 [INFO]: Epoch 029 - training loss: 0.3697, validation loss: 0.7164
2024-06-03 08:04:49 [INFO]: Epoch 030 - training loss: 0.3746, validation loss: 0.6872
2024-06-03 08:04:53 [INFO]: Epoch 031 - training loss: 0.3649, validation loss: 0.6936
2024-06-03 08:04:57 [INFO]: Epoch 032 - training loss: 0.3603, validation loss: 0.6832
2024-06-03 08:05:01 [INFO]: Epoch 033 - training loss: 0.3551, validation loss: 0.6926
2024-06-03 08:05:04 [INFO]: Epoch 034 - training loss: 0.3530, validation loss: 0.6924
2024-06-03 08:05:08 [INFO]: Epoch 035 - training loss: 0.3539, validation loss: 0.7077
2024-06-03 08:05:12 [INFO]: Epoch 036 - training loss: 0.3489, validation loss: 0.7056
2024-06-03 08:05:16 [INFO]: Epoch 037 - training loss: 0.3441, validation loss: 0.6870
2024-06-03 08:05:20 [INFO]: Epoch 038 - training loss: 0.3398, validation loss: 0.6858
2024-06-03 08:05:24 [INFO]: Epoch 039 - training loss: 0.3443, validation loss: 0.6805
2024-06-03 08:05:28 [INFO]: Epoch 040 - training loss: 0.3412, validation loss: 0.6845
2024-06-03 08:05:31 [INFO]: Epoch 041 - training loss: 0.3368, validation loss: 0.6956
2024-06-03 08:05:34 [INFO]: Epoch 042 - training loss: 0.3352, validation loss: 0.6959
2024-06-03 08:05:38 [INFO]: Epoch 043 - training loss: 0.3399, validation loss: 0.6851
2024-06-03 08:05:41 [INFO]: Epoch 044 - training loss: 0.3369, validation loss: 0.6842
2024-06-03 08:05:45 [INFO]: Epoch 045 - training loss: 0.3335, validation loss: 0.6776
2024-06-03 08:05:48 [INFO]: Epoch 046 - training loss: 0.3314, validation loss: 0.6775
2024-06-03 08:05:52 [INFO]: Epoch 047 - training loss: 0.3262, validation loss: 0.6887
2024-06-03 08:05:55 [INFO]: Epoch 048 - training loss: 0.3249, validation loss: 0.6861
2024-06-03 08:05:59 [INFO]: Epoch 049 - training loss: 0.3227, validation loss: 0.6838
2024-06-03 08:06:02 [INFO]: Epoch 050 - training loss: 0.3224, validation loss: 0.6760
2024-06-03 08:06:06 [INFO]: Epoch 051 - training loss: 0.3177, validation loss: 0.6777
2024-06-03 08:06:09 [INFO]: Epoch 052 - training loss: 0.3165, validation loss: 0.6719
2024-06-03 08:06:12 [INFO]: Epoch 053 - training loss: 0.3190, validation loss: 0.6699
2024-06-03 08:06:16 [INFO]: Epoch 054 - training loss: 0.3156, validation loss: 0.6650
2024-06-03 08:06:19 [INFO]: Epoch 055 - training loss: 0.3140, validation loss: 0.6606
2024-06-03 08:06:22 [INFO]: Epoch 056 - training loss: 0.3121, validation loss: 0.6790
2024-06-03 08:06:26 [INFO]: Epoch 057 - training loss: 0.3117, validation loss: 0.6755
2024-06-03 08:06:30 [INFO]: Epoch 058 - training loss: 0.3110, validation loss: 0.6629
2024-06-03 08:06:33 [INFO]: Epoch 059 - training loss: 0.3136, validation loss: 0.6708
2024-06-03 08:06:36 [INFO]: Epoch 060 - training loss: 0.3084, validation loss: 0.6786
2024-06-03 08:06:40 [INFO]: Epoch 061 - training loss: 0.3063, validation loss: 0.6790
2024-06-03 08:06:43 [INFO]: Epoch 062 - training loss: 0.3047, validation loss: 0.6805
2024-06-03 08:06:47 [INFO]: Epoch 063 - training loss: 0.3033, validation loss: 0.6688
2024-06-03 08:06:50 [INFO]: Epoch 064 - training loss: 0.2993, validation loss: 0.6718
2024-06-03 08:06:54 [INFO]: Epoch 065 - training loss: 0.2994, validation loss: 0.6837
2024-06-03 08:06:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:06:54 [INFO]: Finished training. The best model is from epoch#55.
2024-06-03 08:06:54 [INFO]: Saved the model to results_subseq_rate05/PeMS/StemGNN_PeMS/round_1/20240603_T080250/StemGNN.pypots
2024-06-03 08:06:55 [INFO]: Successfully saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_1/imputation.pkl
2024-06-03 08:06:55 [INFO]: Round1 - StemGNN on PeMS: MAE=0.4664, MSE=1.0117, MRE=0.5512
2024-06-03 08:06:55 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:06:55 [INFO]: Using the given device: cuda:0
2024-06-03 08:06:55 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_2/20240603_T080655
2024-06-03 08:06:55 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_2/20240603_T080655/tensorboard
2024-06-03 08:06:56 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 08:06:59 [INFO]: Epoch 001 - training loss: 1.2030, validation loss: 1.1247
2024-06-03 08:07:03 [INFO]: Epoch 002 - training loss: 0.7582, validation loss: 1.0548
2024-06-03 08:07:06 [INFO]: Epoch 003 - training loss: 0.7065, validation loss: 1.0501
2024-06-03 08:07:10 [INFO]: Epoch 004 - training loss: 0.6929, validation loss: 1.0475
2024-06-03 08:07:13 [INFO]: Epoch 005 - training loss: 0.6847, validation loss: 1.0585
2024-06-03 08:07:16 [INFO]: Epoch 006 - training loss: 0.6824, validation loss: 1.0553
2024-06-03 08:07:20 [INFO]: Epoch 007 - training loss: 0.6794, validation loss: 1.0595
2024-06-03 08:07:23 [INFO]: Epoch 008 - training loss: 0.6720, validation loss: 1.0764
2024-06-03 08:07:25 [INFO]: Epoch 009 - training loss: 0.6718, validation loss: 1.0557
2024-06-03 08:07:27 [INFO]: Epoch 010 - training loss: 0.6696, validation loss: 1.0639
2024-06-03 08:07:29 [INFO]: Epoch 011 - training loss: 0.6801, validation loss: 1.0696
2024-06-03 08:07:31 [INFO]: Epoch 012 - training loss: 0.6696, validation loss: 1.0662
2024-06-03 08:07:33 [INFO]: Epoch 013 - training loss: 0.6714, validation loss: 1.0727
2024-06-03 08:07:36 [INFO]: Epoch 014 - training loss: 0.6702, validation loss: 1.0724
2024-06-03 08:07:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:07:36 [INFO]: Finished training. The best model is from epoch#4.
2024-06-03 08:07:36 [INFO]: Saved the model to results_subseq_rate05/PeMS/StemGNN_PeMS/round_2/20240603_T080655/StemGNN.pypots
2024-06-03 08:07:37 [INFO]: Successfully saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_2/imputation.pkl
2024-06-03 08:07:37 [INFO]: Round2 - StemGNN on PeMS: MAE=0.6428, MSE=1.4094, MRE=0.7597
2024-06-03 08:07:37 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:07:37 [INFO]: Using the given device: cuda:0
2024-06-03 08:07:37 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_3/20240603_T080737
2024-06-03 08:07:37 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_3/20240603_T080737/tensorboard
2024-06-03 08:07:37 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 08:07:40 [INFO]: Epoch 001 - training loss: 1.2804, validation loss: 1.1915
2024-06-03 08:07:42 [INFO]: Epoch 002 - training loss: 0.8503, validation loss: 1.0515
2024-06-03 08:07:44 [INFO]: Epoch 003 - training loss: 0.6926, validation loss: 1.0411
2024-06-03 08:07:46 [INFO]: Epoch 004 - training loss: 0.6587, validation loss: 0.9960
2024-06-03 08:07:49 [INFO]: Epoch 005 - training loss: 0.6338, validation loss: 0.9625
2024-06-03 08:07:51 [INFO]: Epoch 006 - training loss: 0.5942, validation loss: 0.9289
2024-06-03 08:07:53 [INFO]: Epoch 007 - training loss: 0.5500, validation loss: 0.8641
2024-06-03 08:07:56 [INFO]: Epoch 008 - training loss: 0.5082, validation loss: 0.7988
2024-06-03 08:07:58 [INFO]: Epoch 009 - training loss: 0.4744, validation loss: 0.7692
2024-06-03 08:08:00 [INFO]: Epoch 010 - training loss: 0.4504, validation loss: 0.7658
2024-06-03 08:08:02 [INFO]: Epoch 011 - training loss: 0.4417, validation loss: 0.7498
2024-06-03 08:08:04 [INFO]: Epoch 012 - training loss: 0.4342, validation loss: 0.7479
2024-06-03 08:08:07 [INFO]: Epoch 013 - training loss: 0.4209, validation loss: 0.7398
2024-06-03 08:08:09 [INFO]: Epoch 014 - training loss: 0.4166, validation loss: 0.7248
2024-06-03 08:08:11 [INFO]: Epoch 015 - training loss: 0.4035, validation loss: 0.7149
2024-06-03 08:08:13 [INFO]: Epoch 016 - training loss: 0.3978, validation loss: 0.7082
2024-06-03 08:08:16 [INFO]: Epoch 017 - training loss: 0.3850, validation loss: 0.7164
2024-06-03 08:08:18 [INFO]: Epoch 018 - training loss: 0.3792, validation loss: 0.7080
2024-06-03 08:08:20 [INFO]: Epoch 019 - training loss: 0.3721, validation loss: 0.7019
2024-06-03 08:08:23 [INFO]: Epoch 020 - training loss: 0.3654, validation loss: 0.6977
2024-06-03 08:08:26 [INFO]: Epoch 021 - training loss: 0.3615, validation loss: 0.6963
2024-06-03 08:08:29 [INFO]: Epoch 022 - training loss: 0.3548, validation loss: 0.6887
2024-06-03 08:08:32 [INFO]: Epoch 023 - training loss: 0.3466, validation loss: 0.6829
2024-06-03 08:08:35 [INFO]: Epoch 024 - training loss: 0.3478, validation loss: 0.6822
2024-06-03 08:08:39 [INFO]: Epoch 025 - training loss: 0.3417, validation loss: 0.6706
2024-06-03 08:08:42 [INFO]: Epoch 026 - training loss: 0.3405, validation loss: 0.6755
2024-06-03 08:08:45 [INFO]: Epoch 027 - training loss: 0.3349, validation loss: 0.6673
2024-06-03 08:08:48 [INFO]: Epoch 028 - training loss: 0.3294, validation loss: 0.6664
2024-06-03 08:08:51 [INFO]: Epoch 029 - training loss: 0.3277, validation loss: 0.6645
2024-06-03 08:08:54 [INFO]: Epoch 030 - training loss: 0.3196, validation loss: 0.6611
2024-06-03 08:08:57 [INFO]: Epoch 031 - training loss: 0.3166, validation loss: 0.6637
2024-06-03 08:09:00 [INFO]: Epoch 032 - training loss: 0.3146, validation loss: 0.6573
2024-06-03 08:09:03 [INFO]: Epoch 033 - training loss: 0.3112, validation loss: 0.6538
2024-06-03 08:09:06 [INFO]: Epoch 034 - training loss: 0.3122, validation loss: 0.6582
2024-06-03 08:09:09 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.6526
2024-06-03 08:09:13 [INFO]: Epoch 036 - training loss: 0.3057, validation loss: 0.6476
2024-06-03 08:09:16 [INFO]: Epoch 037 - training loss: 0.3042, validation loss: 0.6488
2024-06-03 08:09:19 [INFO]: Epoch 038 - training loss: 0.3038, validation loss: 0.6515
2024-06-03 08:09:22 [INFO]: Epoch 039 - training loss: 0.2987, validation loss: 0.6440
2024-06-03 08:09:25 [INFO]: Epoch 040 - training loss: 0.2965, validation loss: 0.6452
2024-06-03 08:09:29 [INFO]: Epoch 041 - training loss: 0.2991, validation loss: 0.6490
2024-06-03 08:09:32 [INFO]: Epoch 042 - training loss: 0.2950, validation loss: 0.6432
2024-06-03 08:09:35 [INFO]: Epoch 043 - training loss: 0.2910, validation loss: 0.6421
2024-06-03 08:09:38 [INFO]: Epoch 044 - training loss: 0.2924, validation loss: 0.6496
2024-06-03 08:09:41 [INFO]: Epoch 045 - training loss: 0.2899, validation loss: 0.6463
2024-06-03 08:09:45 [INFO]: Epoch 046 - training loss: 0.2900, validation loss: 0.6424
2024-06-03 08:09:48 [INFO]: Epoch 047 - training loss: 0.2893, validation loss: 0.6425
2024-06-03 08:09:51 [INFO]: Epoch 048 - training loss: 0.2848, validation loss: 0.6384
2024-06-03 08:09:54 [INFO]: Epoch 049 - training loss: 0.2810, validation loss: 0.6461
2024-06-03 08:09:57 [INFO]: Epoch 050 - training loss: 0.2796, validation loss: 0.6366
2024-06-03 08:10:01 [INFO]: Epoch 051 - training loss: 0.2808, validation loss: 0.6402
2024-06-03 08:10:04 [INFO]: Epoch 052 - training loss: 0.2812, validation loss: 0.6389
2024-06-03 08:10:07 [INFO]: Epoch 053 - training loss: 0.2755, validation loss: 0.6427
2024-06-03 08:10:10 [INFO]: Epoch 054 - training loss: 0.2769, validation loss: 0.6430
2024-06-03 08:10:13 [INFO]: Epoch 055 - training loss: 0.2736, validation loss: 0.6461
2024-06-03 08:10:16 [INFO]: Epoch 056 - training loss: 0.2732, validation loss: 0.6495
2024-06-03 08:10:19 [INFO]: Epoch 057 - training loss: 0.2768, validation loss: 0.6419
2024-06-03 08:10:22 [INFO]: Epoch 058 - training loss: 0.2743, validation loss: 0.6483
2024-06-03 08:10:25 [INFO]: Epoch 059 - training loss: 0.2736, validation loss: 0.6392
2024-06-03 08:10:28 [INFO]: Epoch 060 - training loss: 0.2710, validation loss: 0.6381
2024-06-03 08:10:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:10:28 [INFO]: Finished training. The best model is from epoch#50.
2024-06-03 08:10:28 [INFO]: Saved the model to results_subseq_rate05/PeMS/StemGNN_PeMS/round_3/20240603_T080737/StemGNN.pypots
2024-06-03 08:10:30 [INFO]: Successfully saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_3/imputation.pkl
2024-06-03 08:10:30 [INFO]: Round3 - StemGNN on PeMS: MAE=0.4583, MSE=0.9564, MRE=0.5415
2024-06-03 08:10:30 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:10:30 [INFO]: Using the given device: cuda:0
2024-06-03 08:10:30 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_4/20240603_T081030
2024-06-03 08:10:30 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_4/20240603_T081030/tensorboard
2024-06-03 08:10:30 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 2,386,294
2024-06-03 08:10:33 [INFO]: Epoch 001 - training loss: 1.0921, validation loss: 1.1171
2024-06-03 08:10:36 [INFO]: Epoch 002 - training loss: 0.7470, validation loss: 1.0525
2024-06-03 08:10:39 [INFO]: Epoch 003 - training loss: 0.6799, validation loss: 1.0277
2024-06-03 08:10:42 [INFO]: Epoch 004 - training loss: 0.6067, validation loss: 1.0210
2024-06-03 08:10:46 [INFO]: Epoch 005 - training loss: 0.5555, validation loss: 0.9183
2024-06-03 08:10:49 [INFO]: Epoch 006 - training loss: 0.5187, validation loss: 0.8514
2024-06-03 08:10:52 [INFO]: Epoch 007 - training loss: 0.4881, validation loss: 0.8254
2024-06-03 08:10:55 [INFO]: Epoch 008 - training loss: 0.4681, validation loss: 0.7917
2024-06-03 08:10:58 [INFO]: Epoch 009 - training loss: 0.4506, validation loss: 0.7701
2024-06-03 08:11:01 [INFO]: Epoch 010 - training loss: 0.4347, validation loss: 0.7496
2024-06-03 08:11:03 [INFO]: Epoch 011 - training loss: 0.4205, validation loss: 0.7330
2024-06-03 08:11:06 [INFO]: Epoch 012 - training loss: 0.4122, validation loss: 0.7197
2024-06-03 08:11:09 [INFO]: Epoch 013 - training loss: 0.4001, validation loss: 0.7025
2024-06-03 08:11:12 [INFO]: Epoch 014 - training loss: 0.3964, validation loss: 0.6997
2024-06-03 08:11:15 [INFO]: Epoch 015 - training loss: 0.3875, validation loss: 0.6830
2024-06-03 08:11:17 [INFO]: Epoch 016 - training loss: 0.3792, validation loss: 0.7197
2024-06-03 08:11:20 [INFO]: Epoch 017 - training loss: 0.3679, validation loss: 0.6857
2024-06-03 08:11:23 [INFO]: Epoch 018 - training loss: 0.3606, validation loss: 0.6843
2024-06-03 08:11:25 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.6675
2024-06-03 08:11:28 [INFO]: Epoch 020 - training loss: 0.3532, validation loss: 0.6628
2024-06-03 08:11:31 [INFO]: Epoch 021 - training loss: 0.3464, validation loss: 0.6657
2024-06-03 08:11:34 [INFO]: Epoch 022 - training loss: 0.3408, validation loss: 0.6613
2024-06-03 08:11:37 [INFO]: Epoch 023 - training loss: 0.3380, validation loss: 0.6539
2024-06-03 08:11:40 [INFO]: Epoch 024 - training loss: 0.3334, validation loss: 0.6338
2024-06-03 08:11:41 [INFO]: Epoch 025 - training loss: 0.3352, validation loss: 0.6368
2024-06-03 08:11:43 [INFO]: Epoch 026 - training loss: 0.3341, validation loss: 0.6416
2024-06-03 08:11:45 [INFO]: Epoch 027 - training loss: 0.3271, validation loss: 0.6529
2024-06-03 08:11:47 [INFO]: Epoch 028 - training loss: 0.3208, validation loss: 0.6591
2024-06-03 08:11:49 [INFO]: Epoch 029 - training loss: 0.3182, validation loss: 0.6552
2024-06-03 08:11:50 [INFO]: Epoch 030 - training loss: 0.3144, validation loss: 0.6492
2024-06-03 08:11:52 [INFO]: Epoch 031 - training loss: 0.3085, validation loss: 0.6499
2024-06-03 08:11:53 [INFO]: Epoch 032 - training loss: 0.3050, validation loss: 0.6425
2024-06-03 08:11:55 [INFO]: Epoch 033 - training loss: 0.3033, validation loss: 0.6444
2024-06-03 08:11:56 [INFO]: Epoch 034 - training loss: 0.3033, validation loss: 0.6471
2024-06-03 08:11:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:11:56 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 08:11:56 [INFO]: Saved the model to results_subseq_rate05/PeMS/StemGNN_PeMS/round_4/20240603_T081030/StemGNN.pypots
2024-06-03 08:11:57 [INFO]: Successfully saved to results_subseq_rate05/PeMS/StemGNN_PeMS/round_4/imputation.pkl
2024-06-03 08:11:57 [INFO]: Round4 - StemGNN on PeMS: MAE=0.4490, MSE=0.9845, MRE=0.5307
2024-06-03 08:11:57 [INFO]: Done! Final results:
Averaged StemGNN (2,386,294 params) on PeMS: MAE=0.4992 ± 0.07251736339810348, MSE=1.0764 ± 0.1680035820689978, MRE=0.5899 ± 0.08569559479567751, average inference time=0.26
