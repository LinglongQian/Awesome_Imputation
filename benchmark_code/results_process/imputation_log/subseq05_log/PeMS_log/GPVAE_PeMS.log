2024-06-03 07:12:01 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:12:01 [INFO]: Using the given device: cuda:0
2024-06-03 07:12:01 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T071201
2024-06-03 07:12:01 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T071201/tensorboard
2024-06-03 07:12:02 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 07:12:19 [INFO]: Epoch 001 - training loss: 630514.9479, validation loss: 1.3419
2024-06-03 07:12:27 [INFO]: Epoch 002 - training loss: 367702.7583, validation loss: 1.2178
2024-06-03 07:12:35 [INFO]: Epoch 003 - training loss: 276429.3063, validation loss: 1.0694
2024-06-03 07:12:43 [INFO]: Epoch 004 - training loss: 263424.9510, validation loss: 0.8570
2024-06-03 07:12:51 [INFO]: Epoch 005 - training loss: 260417.2135, validation loss: 0.6683
2024-06-03 07:12:58 [INFO]: Epoch 006 - training loss: 259716.6760, validation loss: 0.6227
2024-06-03 07:13:06 [INFO]: Epoch 007 - training loss: 259455.5865, validation loss: 0.6349
2024-06-03 07:13:14 [INFO]: Epoch 008 - training loss: 259316.9500, validation loss: 0.5958
2024-06-03 07:13:22 [INFO]: Epoch 009 - training loss: 259216.9719, validation loss: 0.6179
2024-06-03 07:13:30 [INFO]: Epoch 010 - training loss: 259166.7687, validation loss: 0.5987
2024-06-03 07:13:38 [INFO]: Epoch 011 - training loss: 259111.8333, validation loss: 0.6454
2024-06-03 07:13:46 [INFO]: Epoch 012 - training loss: 259143.0667, validation loss: 0.6116
2024-06-03 07:13:53 [INFO]: Epoch 013 - training loss: 259071.3490, validation loss: 0.5750
2024-06-03 07:14:01 [INFO]: Epoch 014 - training loss: 259044.2396, validation loss: 0.5969
2024-06-03 07:14:09 [INFO]: Epoch 015 - training loss: 259045.8052, validation loss: 0.5983
2024-06-03 07:14:16 [INFO]: Epoch 016 - training loss: 259046.6792, validation loss: 0.5525
2024-06-03 07:14:24 [INFO]: Epoch 017 - training loss: 258992.2875, validation loss: 0.6283
2024-06-03 07:14:32 [INFO]: Epoch 018 - training loss: 258990.7229, validation loss: 0.5534
2024-06-03 07:14:40 [INFO]: Epoch 019 - training loss: 258968.8667, validation loss: 0.6008
2024-06-03 07:14:47 [INFO]: Epoch 020 - training loss: 258951.6302, validation loss: 0.5765
2024-06-03 07:14:55 [INFO]: Epoch 021 - training loss: 258938.5729, validation loss: 0.5794
2024-06-03 07:15:03 [INFO]: Epoch 022 - training loss: 258903.5302, validation loss: 0.5671
2024-06-03 07:15:10 [INFO]: Epoch 023 - training loss: 258927.9677, validation loss: 0.5439
2024-06-03 07:15:18 [INFO]: Epoch 024 - training loss: 258932.8906, validation loss: 0.5816
2024-06-03 07:15:25 [INFO]: Epoch 025 - training loss: 258997.8083, validation loss: 0.5781
2024-06-03 07:15:33 [INFO]: Epoch 026 - training loss: 258977.4333, validation loss: 0.5517
2024-06-03 07:15:41 [INFO]: Epoch 027 - training loss: 258946.6083, validation loss: 0.5352
2024-06-03 07:15:49 [INFO]: Epoch 028 - training loss: 258926.4844, validation loss: 0.5533
2024-06-03 07:15:57 [INFO]: Epoch 029 - training loss: 258943.8448, validation loss: 0.5368
2024-06-03 07:16:04 [INFO]: Epoch 030 - training loss: 258964.7740, validation loss: 0.5392
2024-06-03 07:16:12 [INFO]: Epoch 031 - training loss: 258965.1354, validation loss: 0.5575
2024-06-03 07:16:20 [INFO]: Epoch 032 - training loss: 259000.2281, validation loss: 0.5464
2024-06-03 07:16:27 [INFO]: Epoch 033 - training loss: 259000.6031, validation loss: 0.5713
2024-06-03 07:16:35 [INFO]: Epoch 034 - training loss: 258976.0594, validation loss: 0.5528
2024-06-03 07:16:43 [INFO]: Epoch 035 - training loss: 258985.1052, validation loss: 0.5647
2024-06-03 07:16:50 [INFO]: Epoch 036 - training loss: 258971.3792, validation loss: 0.5411
2024-06-03 07:16:57 [INFO]: Epoch 037 - training loss: 258974.1073, validation loss: 0.5351
2024-06-03 07:17:04 [INFO]: Epoch 038 - training loss: 259050.9052, validation loss: 0.5273
2024-06-03 07:17:11 [INFO]: Epoch 039 - training loss: 259047.4740, validation loss: 0.5614
2024-06-03 07:17:18 [INFO]: Epoch 040 - training loss: 258996.7521, validation loss: 0.5488
2024-06-03 07:17:25 [INFO]: Epoch 041 - training loss: 258982.3469, validation loss: 0.5503
2024-06-03 07:17:32 [INFO]: Epoch 042 - training loss: 258969.8823, validation loss: 0.5365
2024-06-03 07:17:39 [INFO]: Epoch 043 - training loss: 258939.2521, validation loss: 0.5407
2024-06-03 07:17:46 [INFO]: Epoch 044 - training loss: 259003.6187, validation loss: 0.5407
2024-06-03 07:17:53 [INFO]: Epoch 045 - training loss: 259077.7313, validation loss: 0.5448
2024-06-03 07:18:00 [INFO]: Epoch 046 - training loss: 259057.6010, validation loss: 0.5548
2024-06-03 07:18:06 [INFO]: Epoch 047 - training loss: 258958.6521, validation loss: 0.5395
2024-06-03 07:18:13 [INFO]: Epoch 048 - training loss: 258915.3490, validation loss: 0.5522
2024-06-03 07:18:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:18:13 [INFO]: Finished training. The best model is from epoch#38.
2024-06-03 07:18:13 [INFO]: Saved the model to results_subseq_rate05/PeMS/GPVAE_PeMS/round_0/20240603_T071201/GPVAE.pypots
2024-06-03 07:19:03 [INFO]: Successfully saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_0/imputation.pkl
2024-06-03 07:19:03 [INFO]: Round0 - GPVAE on PeMS: MAE=0.4144, MSE=0.8107, MRE=0.4898
2024-06-03 07:19:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 07:19:03 [INFO]: Using the given device: cuda:0
2024-06-03 07:19:03 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T071903
2024-06-03 07:19:03 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T071903/tensorboard
2024-06-03 07:19:03 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 07:19:10 [INFO]: Epoch 001 - training loss: 641311.2958, validation loss: 1.3722
2024-06-03 07:19:16 [INFO]: Epoch 002 - training loss: 375801.6437, validation loss: 1.2317
2024-06-03 07:19:22 [INFO]: Epoch 003 - training loss: 276934.0479, validation loss: 1.0806
2024-06-03 07:19:28 [INFO]: Epoch 004 - training loss: 263542.1458, validation loss: 0.8262
2024-06-03 07:19:34 [INFO]: Epoch 005 - training loss: 260535.8563, validation loss: 0.6975
2024-06-03 07:19:40 [INFO]: Epoch 006 - training loss: 259753.5583, validation loss: 0.6672
2024-06-03 07:19:47 [INFO]: Epoch 007 - training loss: 259514.6427, validation loss: 0.6145
2024-06-03 07:19:52 [INFO]: Epoch 008 - training loss: 259350.3604, validation loss: 0.6321
2024-06-03 07:19:57 [INFO]: Epoch 009 - training loss: 259288.3646, validation loss: 0.6095
2024-06-03 07:20:01 [INFO]: Epoch 010 - training loss: 259216.6469, validation loss: 0.5888
2024-06-03 07:20:06 [INFO]: Epoch 011 - training loss: 259146.4844, validation loss: 0.5982
2024-06-03 07:20:10 [INFO]: Epoch 012 - training loss: 259102.1542, validation loss: 0.6080
2024-06-03 07:20:14 [INFO]: Epoch 013 - training loss: 259081.8208, validation loss: 0.5708
2024-06-03 07:20:18 [INFO]: Epoch 014 - training loss: 259043.2500, validation loss: 0.5816
2024-06-03 07:20:22 [INFO]: Epoch 015 - training loss: 258764.9385, validation loss: 0.5694
2024-06-03 07:20:26 [INFO]: Epoch 016 - training loss: 258725.4969, validation loss: 0.5823
2024-06-03 07:20:31 [INFO]: Epoch 017 - training loss: 258680.5635, validation loss: 0.5881
2024-06-03 07:20:35 [INFO]: Epoch 018 - training loss: 258661.9010, validation loss: 0.5832
2024-06-03 07:20:39 [INFO]: Epoch 019 - training loss: 258670.8552, validation loss: 0.6531
2024-06-03 07:20:44 [INFO]: Epoch 020 - training loss: 258758.2729, validation loss: 0.5583
2024-06-03 07:20:47 [INFO]: Epoch 021 - training loss: 258683.2500, validation loss: 0.5633
2024-06-03 07:20:52 [INFO]: Epoch 022 - training loss: 258639.5854, validation loss: 0.5656
2024-06-03 07:20:56 [INFO]: Epoch 023 - training loss: 258628.5875, validation loss: 0.5709
2024-06-03 07:21:00 [INFO]: Epoch 024 - training loss: 258609.9177, validation loss: 0.5624
2024-06-03 07:21:04 [INFO]: Epoch 025 - training loss: 258606.1375, validation loss: 0.5611
2024-06-03 07:21:08 [INFO]: Epoch 026 - training loss: 258597.0010, validation loss: 0.5762
2024-06-03 07:21:12 [INFO]: Epoch 027 - training loss: 258621.2135, validation loss: 0.5845
2024-06-03 07:21:16 [INFO]: Epoch 028 - training loss: 258596.7031, validation loss: 0.5559
2024-06-03 07:21:20 [INFO]: Epoch 029 - training loss: 258572.5875, validation loss: 0.5597
2024-06-03 07:21:25 [INFO]: Epoch 030 - training loss: 258647.9083, validation loss: 0.6388
2024-06-03 07:21:29 [INFO]: Epoch 031 - training loss: 258706.4031, validation loss: 0.5575
2024-06-03 07:21:33 [INFO]: Epoch 032 - training loss: 258667.4385, validation loss: 0.5444
2024-06-03 07:21:36 [INFO]: Epoch 033 - training loss: 258695.5031, validation loss: 0.5811
2024-06-03 07:21:41 [INFO]: Epoch 034 - training loss: 258712.7979, validation loss: 0.5734
2024-06-03 07:21:45 [INFO]: Epoch 035 - training loss: 258681.8240, validation loss: 0.6196
2024-06-03 07:21:49 [INFO]: Epoch 036 - training loss: 258672.5312, validation loss: 0.5610
2024-06-03 07:21:52 [INFO]: Epoch 037 - training loss: 258687.3250, validation loss: 0.5510
2024-06-03 07:21:56 [INFO]: Epoch 038 - training loss: 258682.5073, validation loss: 0.5521
2024-06-03 07:22:00 [INFO]: Epoch 039 - training loss: 258716.2458, validation loss: 0.5377
2024-06-03 07:22:05 [INFO]: Epoch 040 - training loss: 258715.7125, validation loss: 0.5477
2024-06-03 07:22:09 [INFO]: Epoch 041 - training loss: 258701.0021, validation loss: 0.5481
2024-06-03 07:22:13 [INFO]: Epoch 042 - training loss: 258673.2792, validation loss: 0.5327
2024-06-03 07:22:17 [INFO]: Epoch 043 - training loss: 258639.1042, validation loss: 0.6171
2024-06-03 07:22:21 [INFO]: Epoch 044 - training loss: 258718.7385, validation loss: 0.5472
2024-06-03 07:22:25 [INFO]: Epoch 045 - training loss: 258681.1708, validation loss: 0.5368
2024-06-03 07:22:30 [INFO]: Epoch 046 - training loss: 258649.3250, validation loss: 0.5474
2024-06-03 07:22:34 [INFO]: Epoch 047 - training loss: 258628.7031, validation loss: 0.5520
2024-06-03 07:22:38 [INFO]: Epoch 048 - training loss: 258586.3354, validation loss: 0.5509
2024-06-03 07:22:42 [INFO]: Epoch 049 - training loss: 258611.1250, validation loss: 0.5562
2024-06-03 07:22:46 [INFO]: Epoch 050 - training loss: 258574.6990, validation loss: 0.5840
2024-06-03 07:22:50 [INFO]: Epoch 051 - training loss: 258587.5573, validation loss: 0.5568
2024-06-03 07:22:55 [INFO]: Epoch 052 - training loss: 258558.6594, validation loss: 0.5476
2024-06-03 07:22:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:22:55 [INFO]: Finished training. The best model is from epoch#42.
2024-06-03 07:22:55 [INFO]: Saved the model to results_subseq_rate05/PeMS/GPVAE_PeMS/round_1/20240603_T071903/GPVAE.pypots
2024-06-03 07:23:32 [INFO]: Successfully saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_1/imputation.pkl
2024-06-03 07:23:32 [INFO]: Round1 - GPVAE on PeMS: MAE=0.4152, MSE=0.8103, MRE=0.4906
2024-06-03 07:23:32 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 07:23:32 [INFO]: Using the given device: cuda:0
2024-06-03 07:23:32 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T072332
2024-06-03 07:23:32 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T072332/tensorboard
2024-06-03 07:23:32 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 07:23:36 [INFO]: Epoch 001 - training loss: 630451.0312, validation loss: 1.3034
2024-06-03 07:23:40 [INFO]: Epoch 002 - training loss: 368523.7833, validation loss: 1.1939
2024-06-03 07:23:44 [INFO]: Epoch 003 - training loss: 274485.5208, validation loss: 0.9665
2024-06-03 07:23:48 [INFO]: Epoch 004 - training loss: 262985.7177, validation loss: 0.8146
2024-06-03 07:23:52 [INFO]: Epoch 005 - training loss: 261018.9656, validation loss: 0.7139
2024-06-03 07:23:56 [INFO]: Epoch 006 - training loss: 260351.6865, validation loss: 0.6860
2024-06-03 07:24:01 [INFO]: Epoch 007 - training loss: 260028.2896, validation loss: 0.6362
2024-06-03 07:24:05 [INFO]: Epoch 008 - training loss: 259876.2323, validation loss: 0.6587
2024-06-03 07:24:09 [INFO]: Epoch 009 - training loss: 259785.2812, validation loss: 0.6640
2024-06-03 07:24:14 [INFO]: Epoch 010 - training loss: 259783.1115, validation loss: 0.6184
2024-06-03 07:24:18 [INFO]: Epoch 011 - training loss: 259688.4292, validation loss: 0.6192
2024-06-03 07:24:22 [INFO]: Epoch 012 - training loss: 259695.0740, validation loss: 0.6240
2024-06-03 07:24:26 [INFO]: Epoch 013 - training loss: 259631.1562, validation loss: 0.5731
2024-06-03 07:24:30 [INFO]: Epoch 014 - training loss: 259627.7437, validation loss: 0.5679
2024-06-03 07:24:34 [INFO]: Epoch 015 - training loss: 259588.2073, validation loss: 0.5934
2024-06-03 07:24:38 [INFO]: Epoch 016 - training loss: 259584.9188, validation loss: 0.6103
2024-06-03 07:24:42 [INFO]: Epoch 017 - training loss: 259540.2313, validation loss: 0.5683
2024-06-03 07:24:46 [INFO]: Epoch 018 - training loss: 259548.5281, validation loss: 0.5585
2024-06-03 07:24:50 [INFO]: Epoch 019 - training loss: 259543.4562, validation loss: 0.5604
2024-06-03 07:24:55 [INFO]: Epoch 020 - training loss: 259638.2031, validation loss: 0.5525
2024-06-03 07:24:59 [INFO]: Epoch 021 - training loss: 259599.2552, validation loss: 0.5504
2024-06-03 07:25:03 [INFO]: Epoch 022 - training loss: 259543.3906, validation loss: 0.5568
2024-06-03 07:25:07 [INFO]: Epoch 023 - training loss: 259521.4510, validation loss: 0.5794
2024-06-03 07:25:11 [INFO]: Epoch 024 - training loss: 259491.2094, validation loss: 0.5456
2024-06-03 07:25:14 [INFO]: Epoch 025 - training loss: 259479.6667, validation loss: 0.5638
2024-06-03 07:25:18 [INFO]: Epoch 026 - training loss: 259487.0802, validation loss: 0.5545
2024-06-03 07:25:22 [INFO]: Epoch 027 - training loss: 259476.5656, validation loss: 0.5670
2024-06-03 07:25:26 [INFO]: Epoch 028 - training loss: 259475.0708, validation loss: 0.5682
2024-06-03 07:25:30 [INFO]: Epoch 029 - training loss: 259482.8927, validation loss: 0.5581
2024-06-03 07:25:34 [INFO]: Epoch 030 - training loss: 259490.6187, validation loss: 0.5504
2024-06-03 07:25:38 [INFO]: Epoch 031 - training loss: 259489.9583, validation loss: 0.5594
2024-06-03 07:25:42 [INFO]: Epoch 032 - training loss: 259493.9552, validation loss: 0.5759
2024-06-03 07:25:46 [INFO]: Epoch 033 - training loss: 259531.2938, validation loss: 0.5487
2024-06-03 07:25:50 [INFO]: Epoch 034 - training loss: 259552.2417, validation loss: 0.5492
2024-06-03 07:25:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:25:50 [INFO]: Finished training. The best model is from epoch#24.
2024-06-03 07:25:50 [INFO]: Saved the model to results_subseq_rate05/PeMS/GPVAE_PeMS/round_2/20240603_T072332/GPVAE.pypots
2024-06-03 07:26:24 [INFO]: Successfully saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_2/imputation.pkl
2024-06-03 07:26:24 [INFO]: Round2 - GPVAE on PeMS: MAE=0.4048, MSE=0.7970, MRE=0.4783
2024-06-03 07:26:24 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 07:26:24 [INFO]: Using the given device: cuda:0
2024-06-03 07:26:24 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T072624
2024-06-03 07:26:24 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T072624/tensorboard
2024-06-03 07:26:24 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 07:26:27 [INFO]: Epoch 001 - training loss: 633952.3500, validation loss: 1.3454
2024-06-03 07:26:31 [INFO]: Epoch 002 - training loss: 371688.6354, validation loss: 1.2063
2024-06-03 07:26:34 [INFO]: Epoch 003 - training loss: 275009.9917, validation loss: 0.9761
2024-06-03 07:26:37 [INFO]: Epoch 004 - training loss: 261993.6115, validation loss: 0.7523
2024-06-03 07:26:41 [INFO]: Epoch 005 - training loss: 259928.5438, validation loss: 0.6542
2024-06-03 07:26:45 [INFO]: Epoch 006 - training loss: 259334.2917, validation loss: 0.6282
2024-06-03 07:26:48 [INFO]: Epoch 007 - training loss: 259096.5302, validation loss: 0.6123
2024-06-03 07:26:51 [INFO]: Epoch 008 - training loss: 258969.6167, validation loss: 0.5900
2024-06-03 07:26:54 [INFO]: Epoch 009 - training loss: 258895.4875, validation loss: 0.5861
2024-06-03 07:26:58 [INFO]: Epoch 010 - training loss: 258896.5792, validation loss: 0.5892
2024-06-03 07:27:01 [INFO]: Epoch 011 - training loss: 258926.4260, validation loss: 0.5594
2024-06-03 07:27:05 [INFO]: Epoch 012 - training loss: 258830.4635, validation loss: 0.5671
2024-06-03 07:27:08 [INFO]: Epoch 013 - training loss: 258748.7094, validation loss: 0.5618
2024-06-03 07:27:11 [INFO]: Epoch 014 - training loss: 258699.7469, validation loss: 0.5621
2024-06-03 07:27:15 [INFO]: Epoch 015 - training loss: 258690.4094, validation loss: 0.5663
2024-06-03 07:27:18 [INFO]: Epoch 016 - training loss: 258673.4000, validation loss: 0.5576
2024-06-03 07:27:21 [INFO]: Epoch 017 - training loss: 258661.6094, validation loss: 0.6013
2024-06-03 07:27:25 [INFO]: Epoch 018 - training loss: 258671.3500, validation loss: 0.5689
2024-06-03 07:27:28 [INFO]: Epoch 019 - training loss: 258700.0760, validation loss: 0.5832
2024-06-03 07:27:31 [INFO]: Epoch 020 - training loss: 258651.5375, validation loss: 0.5658
2024-06-03 07:27:35 [INFO]: Epoch 021 - training loss: 258646.1198, validation loss: 0.5583
2024-06-03 07:27:38 [INFO]: Epoch 022 - training loss: 258631.4594, validation loss: 0.5433
2024-06-03 07:27:41 [INFO]: Epoch 023 - training loss: 258639.3948, validation loss: 0.5434
2024-06-03 07:27:45 [INFO]: Epoch 024 - training loss: 258640.6927, validation loss: 0.5587
2024-06-03 07:27:49 [INFO]: Epoch 025 - training loss: 258610.5521, validation loss: 0.5457
2024-06-03 07:27:52 [INFO]: Epoch 026 - training loss: 258618.8625, validation loss: 0.5633
2024-06-03 07:27:55 [INFO]: Epoch 027 - training loss: 258607.0542, validation loss: 0.5561
2024-06-03 07:27:59 [INFO]: Epoch 028 - training loss: 258611.2417, validation loss: 0.5459
2024-06-03 07:28:02 [INFO]: Epoch 029 - training loss: 258648.8948, validation loss: 0.5763
2024-06-03 07:28:05 [INFO]: Epoch 030 - training loss: 258670.3073, validation loss: 0.5555
2024-06-03 07:28:09 [INFO]: Epoch 031 - training loss: 258809.5063, validation loss: 0.5430
2024-06-03 07:28:12 [INFO]: Epoch 032 - training loss: 258755.2625, validation loss: 0.5472
2024-06-03 07:28:15 [INFO]: Epoch 033 - training loss: 258750.8604, validation loss: 0.5401
2024-06-03 07:28:19 [INFO]: Epoch 034 - training loss: 258789.6885, validation loss: 0.5394
2024-06-03 07:28:22 [INFO]: Epoch 035 - training loss: 258861.3865, validation loss: 0.5342
2024-06-03 07:28:25 [INFO]: Epoch 036 - training loss: 258879.1740, validation loss: 0.5432
2024-06-03 07:28:28 [INFO]: Epoch 037 - training loss: 258772.9990, validation loss: 0.5440
2024-06-03 07:28:32 [INFO]: Epoch 038 - training loss: 258731.5365, validation loss: 0.5609
2024-06-03 07:28:35 [INFO]: Epoch 039 - training loss: 258657.9615, validation loss: 0.5937
2024-06-03 07:28:39 [INFO]: Epoch 040 - training loss: 258647.8177, validation loss: 0.5469
2024-06-03 07:28:42 [INFO]: Epoch 041 - training loss: 258575.1281, validation loss: 0.5398
2024-06-03 07:28:45 [INFO]: Epoch 042 - training loss: 258586.6802, validation loss: 0.5595
2024-06-03 07:28:49 [INFO]: Epoch 043 - training loss: 258582.9083, validation loss: 0.5352
2024-06-03 07:28:52 [INFO]: Epoch 044 - training loss: 258581.4646, validation loss: 0.5445
2024-06-03 07:28:55 [INFO]: Epoch 045 - training loss: 258548.1562, validation loss: 0.5322
2024-06-03 07:28:59 [INFO]: Epoch 046 - training loss: 258601.7635, validation loss: 0.5422
2024-06-03 07:29:02 [INFO]: Epoch 047 - training loss: 258604.6260, validation loss: 0.5463
2024-06-03 07:29:05 [INFO]: Epoch 048 - training loss: 258545.0260, validation loss: 0.5405
2024-06-03 07:29:09 [INFO]: Epoch 049 - training loss: 258533.6875, validation loss: 0.5370
2024-06-03 07:29:13 [INFO]: Epoch 050 - training loss: 258548.7729, validation loss: 0.5317
2024-06-03 07:29:16 [INFO]: Epoch 051 - training loss: 258551.9594, validation loss: 0.5441
2024-06-03 07:29:19 [INFO]: Epoch 052 - training loss: 258476.9083, validation loss: 0.5404
2024-06-03 07:29:22 [INFO]: Epoch 053 - training loss: 258481.6854, validation loss: 0.5251
2024-06-03 07:29:26 [INFO]: Epoch 054 - training loss: 258474.2333, validation loss: 0.5509
2024-06-03 07:29:28 [INFO]: Epoch 055 - training loss: 258482.4156, validation loss: 0.5374
2024-06-03 07:29:32 [INFO]: Epoch 056 - training loss: 258527.4271, validation loss: 0.5554
2024-06-03 07:29:35 [INFO]: Epoch 057 - training loss: 258508.1354, validation loss: 0.5272
2024-06-03 07:29:38 [INFO]: Epoch 058 - training loss: 258491.6521, validation loss: 0.5449
2024-06-03 07:29:41 [INFO]: Epoch 059 - training loss: 258491.0375, validation loss: 0.5364
2024-06-03 07:29:45 [INFO]: Epoch 060 - training loss: 258487.8771, validation loss: 0.5240
2024-06-03 07:29:48 [INFO]: Epoch 061 - training loss: 258472.6667, validation loss: 0.5250
2024-06-03 07:29:51 [INFO]: Epoch 062 - training loss: 258495.3760, validation loss: 0.5328
2024-06-03 07:29:54 [INFO]: Epoch 063 - training loss: 258456.9844, validation loss: 0.5271
2024-06-03 07:29:58 [INFO]: Epoch 064 - training loss: 258456.5115, validation loss: 0.5242
2024-06-03 07:30:01 [INFO]: Epoch 065 - training loss: 258458.6979, validation loss: 0.5251
2024-06-03 07:30:04 [INFO]: Epoch 066 - training loss: 258450.6375, validation loss: 0.5454
2024-06-03 07:30:07 [INFO]: Epoch 067 - training loss: 258462.2385, validation loss: 0.5253
2024-06-03 07:30:11 [INFO]: Epoch 068 - training loss: 258435.3375, validation loss: 0.5317
2024-06-03 07:30:14 [INFO]: Epoch 069 - training loss: 258438.0812, validation loss: 0.5592
2024-06-03 07:30:18 [INFO]: Epoch 070 - training loss: 258505.0667, validation loss: 0.5291
2024-06-03 07:30:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:30:18 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 07:30:18 [INFO]: Saved the model to results_subseq_rate05/PeMS/GPVAE_PeMS/round_3/20240603_T072624/GPVAE.pypots
2024-06-03 07:30:46 [INFO]: Successfully saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_3/imputation.pkl
2024-06-03 07:30:46 [INFO]: Round3 - GPVAE on PeMS: MAE=0.3849, MSE=0.7888, MRE=0.4548
2024-06-03 07:30:46 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 07:30:46 [INFO]: Using the given device: cuda:0
2024-06-03 07:30:46 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T073046
2024-06-03 07:30:46 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T073046/tensorboard
2024-06-03 07:30:46 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,396,536
2024-06-03 07:30:49 [INFO]: Epoch 001 - training loss: 641836.2542, validation loss: 1.3688
2024-06-03 07:30:53 [INFO]: Epoch 002 - training loss: 383607.9938, validation loss: 1.2306
2024-06-03 07:30:56 [INFO]: Epoch 003 - training loss: 277698.5500, validation loss: 1.0844
2024-06-03 07:30:59 [INFO]: Epoch 004 - training loss: 262836.7844, validation loss: 0.8169
2024-06-03 07:31:02 [INFO]: Epoch 005 - training loss: 259946.9583, validation loss: 0.6904
2024-06-03 07:31:06 [INFO]: Epoch 006 - training loss: 259307.3354, validation loss: 0.6593
2024-06-03 07:31:09 [INFO]: Epoch 007 - training loss: 259078.1948, validation loss: 0.6320
2024-06-03 07:31:12 [INFO]: Epoch 008 - training loss: 259000.6146, validation loss: 0.6507
2024-06-03 07:31:15 [INFO]: Epoch 009 - training loss: 258886.5844, validation loss: 0.6024
2024-06-03 07:31:18 [INFO]: Epoch 010 - training loss: 258844.0438, validation loss: 0.5851
2024-06-03 07:31:22 [INFO]: Epoch 011 - training loss: 258786.8208, validation loss: 0.5801
2024-06-03 07:31:25 [INFO]: Epoch 012 - training loss: 258753.6771, validation loss: 0.5841
2024-06-03 07:31:28 [INFO]: Epoch 013 - training loss: 258710.2615, validation loss: 0.5783
2024-06-03 07:31:32 [INFO]: Epoch 014 - training loss: 258711.5583, validation loss: 0.5768
2024-06-03 07:31:35 [INFO]: Epoch 015 - training loss: 258699.5990, validation loss: 0.5761
2024-06-03 07:31:39 [INFO]: Epoch 016 - training loss: 258698.5729, validation loss: 0.5825
2024-06-03 07:31:42 [INFO]: Epoch 017 - training loss: 258666.9083, validation loss: 0.5773
2024-06-03 07:31:45 [INFO]: Epoch 018 - training loss: 258690.5260, validation loss: 0.5612
2024-06-03 07:31:49 [INFO]: Epoch 019 - training loss: 258675.6010, validation loss: 0.5762
2024-06-03 07:31:52 [INFO]: Epoch 020 - training loss: 258649.4271, validation loss: 0.5493
2024-06-03 07:31:55 [INFO]: Epoch 021 - training loss: 258631.4854, validation loss: 0.5587
2024-06-03 07:31:59 [INFO]: Epoch 022 - training loss: 258623.2687, validation loss: 0.5468
2024-06-03 07:32:02 [INFO]: Epoch 023 - training loss: 258650.5354, validation loss: 0.5674
2024-06-03 07:32:05 [INFO]: Epoch 024 - training loss: 258625.0948, validation loss: 0.5508
2024-06-03 07:32:08 [INFO]: Epoch 025 - training loss: 258640.4010, validation loss: 0.5461
2024-06-03 07:32:11 [INFO]: Epoch 026 - training loss: 258643.0719, validation loss: 0.5613
2024-06-03 07:32:15 [INFO]: Epoch 027 - training loss: 258632.1781, validation loss: 0.6153
2024-06-03 07:32:18 [INFO]: Epoch 028 - training loss: 258626.8229, validation loss: 0.5879
2024-06-03 07:32:21 [INFO]: Epoch 029 - training loss: 258619.6010, validation loss: 0.5760
2024-06-03 07:32:24 [INFO]: Epoch 030 - training loss: 258660.2542, validation loss: 0.5828
2024-06-03 07:32:28 [INFO]: Epoch 031 - training loss: 258708.6583, validation loss: 0.5499
2024-06-03 07:32:31 [INFO]: Epoch 032 - training loss: 258713.9198, validation loss: 0.5615
2024-06-03 07:32:34 [INFO]: Epoch 033 - training loss: 258742.6063, validation loss: 0.5734
2024-06-03 07:32:38 [INFO]: Epoch 034 - training loss: 258695.9969, validation loss: 0.5588
2024-06-03 07:32:41 [INFO]: Epoch 035 - training loss: 258687.4552, validation loss: 0.5468
2024-06-03 07:32:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:32:41 [INFO]: Finished training. The best model is from epoch#25.
2024-06-03 07:32:41 [INFO]: Saved the model to results_subseq_rate05/PeMS/GPVAE_PeMS/round_4/20240603_T073046/GPVAE.pypots
2024-06-03 07:33:09 [INFO]: Successfully saved to results_subseq_rate05/PeMS/GPVAE_PeMS/round_4/imputation.pkl
2024-06-03 07:33:09 [INFO]: Round4 - GPVAE on PeMS: MAE=0.3992, MSE=0.7936, MRE=0.4718
2024-06-03 07:33:09 [INFO]: Done! Final results:
Averaged GPVAE (2,396,536 params) on PeMS: MAE=0.4037 ± 0.011165116845985234, MSE=0.8001 ± 0.008919669661765906, MRE=0.4771 ± 0.01319409978858893, average inference time=7.33
