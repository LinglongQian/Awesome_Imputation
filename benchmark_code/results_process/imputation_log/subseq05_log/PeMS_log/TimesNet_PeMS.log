2024-06-03 07:57:39 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:57:39 [INFO]: Using the given device: cuda:0
2024-06-03 07:57:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T075740
2024-06-03 07:57:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T075740/tensorboard
2024-06-03 07:57:46 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 07:57:57 [INFO]: Epoch 001 - training loss: 0.4067, validation loss: 0.6072
2024-06-03 07:57:59 [INFO]: Epoch 002 - training loss: 0.2092, validation loss: 0.5662
2024-06-03 07:58:02 [INFO]: Epoch 003 - training loss: 0.1877, validation loss: 0.5638
2024-06-03 07:58:05 [INFO]: Epoch 004 - training loss: 0.1865, validation loss: 0.5612
2024-06-03 07:58:07 [INFO]: Epoch 005 - training loss: 0.1856, validation loss: 0.5541
2024-06-03 07:58:10 [INFO]: Epoch 006 - training loss: 0.1778, validation loss: 0.5638
2024-06-03 07:58:12 [INFO]: Epoch 007 - training loss: 0.1762, validation loss: 0.5432
2024-06-03 07:58:15 [INFO]: Epoch 008 - training loss: 0.1765, validation loss: 0.5507
2024-06-03 07:58:18 [INFO]: Epoch 009 - training loss: 0.1653, validation loss: 0.5510
2024-06-03 07:58:20 [INFO]: Epoch 010 - training loss: 0.1628, validation loss: 0.5567
2024-06-03 07:58:23 [INFO]: Epoch 011 - training loss: 0.1544, validation loss: 0.5481
2024-06-03 07:58:26 [INFO]: Epoch 012 - training loss: 0.1497, validation loss: 0.5748
2024-06-03 07:58:30 [INFO]: Epoch 013 - training loss: 0.1433, validation loss: 0.5432
2024-06-03 07:58:33 [INFO]: Epoch 014 - training loss: 0.1406, validation loss: 0.5468
2024-06-03 07:58:37 [INFO]: Epoch 015 - training loss: 0.1331, validation loss: 0.5463
2024-06-03 07:58:40 [INFO]: Epoch 016 - training loss: 0.1283, validation loss: 0.5594
2024-06-03 07:58:44 [INFO]: Epoch 017 - training loss: 0.1225, validation loss: 0.5529
2024-06-03 07:58:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:58:44 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 07:58:46 [INFO]: Saved the model to results_subseq_rate05/PeMS/TimesNet_PeMS/round_0/20240603_T075740/TimesNet.pypots
2024-06-03 07:58:48 [INFO]: Successfully saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_0/imputation.pkl
2024-06-03 07:58:48 [INFO]: Round0 - TimesNet on PeMS: MAE=0.4083, MSE=0.8014, MRE=0.4825
2024-06-03 07:58:48 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 07:58:48 [INFO]: Using the given device: cuda:0
2024-06-03 07:58:48 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T075848
2024-06-03 07:58:48 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T075848/tensorboard
2024-06-03 07:58:54 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 07:58:58 [INFO]: Epoch 001 - training loss: 0.4047, validation loss: 0.6141
2024-06-03 07:59:01 [INFO]: Epoch 002 - training loss: 0.2143, validation loss: 0.5640
2024-06-03 07:59:05 [INFO]: Epoch 003 - training loss: 0.1933, validation loss: 0.5608
2024-06-03 07:59:08 [INFO]: Epoch 004 - training loss: 0.1888, validation loss: 0.5662
2024-06-03 07:59:12 [INFO]: Epoch 005 - training loss: 0.1858, validation loss: 0.5467
2024-06-03 07:59:16 [INFO]: Epoch 006 - training loss: 0.1821, validation loss: 0.5393
2024-06-03 07:59:19 [INFO]: Epoch 007 - training loss: 0.1744, validation loss: 0.5432
2024-06-03 07:59:23 [INFO]: Epoch 008 - training loss: 0.1689, validation loss: 0.5421
2024-06-03 07:59:26 [INFO]: Epoch 009 - training loss: 0.1668, validation loss: 0.5439
2024-06-03 07:59:30 [INFO]: Epoch 010 - training loss: 0.1564, validation loss: 0.5353
2024-06-03 07:59:34 [INFO]: Epoch 011 - training loss: 0.1587, validation loss: 0.5416
2024-06-03 07:59:37 [INFO]: Epoch 012 - training loss: 0.1527, validation loss: 0.5478
2024-06-03 07:59:41 [INFO]: Epoch 013 - training loss: 0.1434, validation loss: 0.5570
2024-06-03 07:59:45 [INFO]: Epoch 014 - training loss: 0.1372, validation loss: 0.5662
2024-06-03 07:59:48 [INFO]: Epoch 015 - training loss: 0.1348, validation loss: 0.5426
2024-06-03 07:59:52 [INFO]: Epoch 016 - training loss: 0.1265, validation loss: 0.5531
2024-06-03 07:59:55 [INFO]: Epoch 017 - training loss: 0.1216, validation loss: 0.5473
2024-06-03 07:59:59 [INFO]: Epoch 018 - training loss: 0.1211, validation loss: 0.5492
2024-06-03 08:00:02 [INFO]: Epoch 019 - training loss: 0.1139, validation loss: 0.5429
2024-06-03 08:00:06 [INFO]: Epoch 020 - training loss: 0.1085, validation loss: 0.5476
2024-06-03 08:00:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:00:06 [INFO]: Finished training. The best model is from epoch#10.
2024-06-03 08:00:09 [INFO]: Saved the model to results_subseq_rate05/PeMS/TimesNet_PeMS/round_1/20240603_T075848/TimesNet.pypots
2024-06-03 08:00:10 [INFO]: Successfully saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_1/imputation.pkl
2024-06-03 08:00:10 [INFO]: Round1 - TimesNet on PeMS: MAE=0.4068, MSE=0.7994, MRE=0.4808
2024-06-03 08:00:10 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:00:10 [INFO]: Using the given device: cuda:0
2024-06-03 08:00:10 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T080010
2024-06-03 08:00:10 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T080010/tensorboard
2024-06-03 08:00:16 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 08:00:20 [INFO]: Epoch 001 - training loss: 0.4053, validation loss: 0.6117
2024-06-03 08:00:23 [INFO]: Epoch 002 - training loss: 0.2133, validation loss: 0.5602
2024-06-03 08:00:27 [INFO]: Epoch 003 - training loss: 0.1935, validation loss: 0.5631
2024-06-03 08:00:30 [INFO]: Epoch 004 - training loss: 0.1885, validation loss: 0.5571
2024-06-03 08:00:34 [INFO]: Epoch 005 - training loss: 0.1848, validation loss: 0.5575
2024-06-03 08:00:37 [INFO]: Epoch 006 - training loss: 0.1793, validation loss: 0.5458
2024-06-03 08:00:41 [INFO]: Epoch 007 - training loss: 0.1689, validation loss: 0.5520
2024-06-03 08:00:45 [INFO]: Epoch 008 - training loss: 0.1708, validation loss: 0.5531
2024-06-03 08:00:48 [INFO]: Epoch 009 - training loss: 0.1648, validation loss: 0.5447
2024-06-03 08:00:52 [INFO]: Epoch 010 - training loss: 0.1606, validation loss: 0.5500
2024-06-03 08:00:55 [INFO]: Epoch 011 - training loss: 0.1554, validation loss: 0.5534
2024-06-03 08:00:59 [INFO]: Epoch 012 - training loss: 0.1488, validation loss: 0.5470
2024-06-03 08:01:03 [INFO]: Epoch 013 - training loss: 0.1427, validation loss: 0.5608
2024-06-03 08:01:06 [INFO]: Epoch 014 - training loss: 0.1361, validation loss: 0.5470
2024-06-03 08:01:10 [INFO]: Epoch 015 - training loss: 0.1330, validation loss: 0.5522
2024-06-03 08:01:14 [INFO]: Epoch 016 - training loss: 0.1242, validation loss: 0.5464
2024-06-03 08:01:17 [INFO]: Epoch 017 - training loss: 0.1227, validation loss: 0.5410
2024-06-03 08:01:21 [INFO]: Epoch 018 - training loss: 0.1159, validation loss: 0.5482
2024-06-03 08:01:25 [INFO]: Epoch 019 - training loss: 0.1107, validation loss: 0.5550
2024-06-03 08:01:28 [INFO]: Epoch 020 - training loss: 0.1073, validation loss: 0.5491
2024-06-03 08:01:32 [INFO]: Epoch 021 - training loss: 0.1070, validation loss: 0.5514
2024-06-03 08:01:36 [INFO]: Epoch 022 - training loss: 0.1049, validation loss: 0.5484
2024-06-03 08:01:39 [INFO]: Epoch 023 - training loss: 0.0996, validation loss: 0.5551
2024-06-03 08:01:43 [INFO]: Epoch 024 - training loss: 0.0983, validation loss: 0.5561
2024-06-03 08:01:46 [INFO]: Epoch 025 - training loss: 0.0960, validation loss: 0.5429
2024-06-03 08:01:50 [INFO]: Epoch 026 - training loss: 0.0935, validation loss: 0.5465
2024-06-03 08:01:54 [INFO]: Epoch 027 - training loss: 0.0913, validation loss: 0.5461
2024-06-03 08:01:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:01:54 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 08:01:56 [INFO]: Saved the model to results_subseq_rate05/PeMS/TimesNet_PeMS/round_2/20240603_T080010/TimesNet.pypots
2024-06-03 08:01:58 [INFO]: Successfully saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_2/imputation.pkl
2024-06-03 08:01:58 [INFO]: Round2 - TimesNet on PeMS: MAE=0.4018, MSE=0.7946, MRE=0.4748
2024-06-03 08:01:58 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:01:58 [INFO]: Using the given device: cuda:0
2024-06-03 08:01:58 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T080158
2024-06-03 08:01:58 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T080158/tensorboard
2024-06-03 08:02:03 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 08:02:07 [INFO]: Epoch 001 - training loss: 0.4134, validation loss: 0.6220
2024-06-03 08:02:11 [INFO]: Epoch 002 - training loss: 0.2171, validation loss: 0.5744
2024-06-03 08:02:14 [INFO]: Epoch 003 - training loss: 0.1937, validation loss: 0.5599
2024-06-03 08:02:18 [INFO]: Epoch 004 - training loss: 0.1904, validation loss: 0.5610
2024-06-03 08:02:21 [INFO]: Epoch 005 - training loss: 0.1858, validation loss: 0.5579
2024-06-03 08:02:25 [INFO]: Epoch 006 - training loss: 0.1846, validation loss: 0.5564
2024-06-03 08:02:28 [INFO]: Epoch 007 - training loss: 0.1774, validation loss: 0.5489
2024-06-03 08:02:32 [INFO]: Epoch 008 - training loss: 0.1737, validation loss: 0.5512
2024-06-03 08:02:36 [INFO]: Epoch 009 - training loss: 0.1655, validation loss: 0.5652
2024-06-03 08:02:39 [INFO]: Epoch 010 - training loss: 0.1569, validation loss: 0.5538
2024-06-03 08:02:43 [INFO]: Epoch 011 - training loss: 0.1523, validation loss: 0.5472
2024-06-03 08:02:46 [INFO]: Epoch 012 - training loss: 0.1473, validation loss: 0.5384
2024-06-03 08:02:50 [INFO]: Epoch 013 - training loss: 0.1423, validation loss: 0.5439
2024-06-03 08:02:53 [INFO]: Epoch 014 - training loss: 0.1362, validation loss: 0.5565
2024-06-03 08:02:57 [INFO]: Epoch 015 - training loss: 0.1329, validation loss: 0.5496
2024-06-03 08:03:01 [INFO]: Epoch 016 - training loss: 0.1282, validation loss: 0.5586
2024-06-03 08:03:04 [INFO]: Epoch 017 - training loss: 0.1220, validation loss: 0.5452
2024-06-03 08:03:08 [INFO]: Epoch 018 - training loss: 0.1155, validation loss: 0.5558
2024-06-03 08:03:11 [INFO]: Epoch 019 - training loss: 0.1133, validation loss: 0.5452
2024-06-03 08:03:15 [INFO]: Epoch 020 - training loss: 0.1087, validation loss: 0.5545
2024-06-03 08:03:19 [INFO]: Epoch 021 - training loss: 0.1074, validation loss: 0.5518
2024-06-03 08:03:22 [INFO]: Epoch 022 - training loss: 0.1035, validation loss: 0.5525
2024-06-03 08:03:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:03:22 [INFO]: Finished training. The best model is from epoch#12.
2024-06-03 08:03:25 [INFO]: Saved the model to results_subseq_rate05/PeMS/TimesNet_PeMS/round_3/20240603_T080158/TimesNet.pypots
2024-06-03 08:03:26 [INFO]: Successfully saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_3/imputation.pkl
2024-06-03 08:03:26 [INFO]: Round3 - TimesNet on PeMS: MAE=0.4089, MSE=0.8025, MRE=0.4832
2024-06-03 08:03:26 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:03:26 [INFO]: Using the given device: cuda:0
2024-06-03 08:03:27 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T080326
2024-06-03 08:03:27 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T080326/tensorboard
2024-06-03 08:03:32 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 91,622,238
2024-06-03 08:03:36 [INFO]: Epoch 001 - training loss: 0.3965, validation loss: 0.6081
2024-06-03 08:03:39 [INFO]: Epoch 002 - training loss: 0.2141, validation loss: 0.5830
2024-06-03 08:03:43 [INFO]: Epoch 003 - training loss: 0.1947, validation loss: 0.5656
2024-06-03 08:03:47 [INFO]: Epoch 004 - training loss: 0.1893, validation loss: 0.5560
2024-06-03 08:03:50 [INFO]: Epoch 005 - training loss: 0.1840, validation loss: 0.5507
2024-06-03 08:03:54 [INFO]: Epoch 006 - training loss: 0.1819, validation loss: 0.5526
2024-06-03 08:03:58 [INFO]: Epoch 007 - training loss: 0.1828, validation loss: 0.5561
2024-06-03 08:04:01 [INFO]: Epoch 008 - training loss: 0.1740, validation loss: 0.5591
2024-06-03 08:04:05 [INFO]: Epoch 009 - training loss: 0.1651, validation loss: 0.5551
2024-06-03 08:04:08 [INFO]: Epoch 010 - training loss: 0.1591, validation loss: 0.5646
2024-06-03 08:04:12 [INFO]: Epoch 011 - training loss: 0.1533, validation loss: 0.5614
2024-06-03 08:04:16 [INFO]: Epoch 012 - training loss: 0.1466, validation loss: 0.5483
2024-06-03 08:04:19 [INFO]: Epoch 013 - training loss: 0.1434, validation loss: 0.5474
2024-06-03 08:04:23 [INFO]: Epoch 014 - training loss: 0.1382, validation loss: 0.5652
2024-06-03 08:04:26 [INFO]: Epoch 015 - training loss: 0.1357, validation loss: 0.5459
2024-06-03 08:04:30 [INFO]: Epoch 016 - training loss: 0.1299, validation loss: 0.5622
2024-06-03 08:04:33 [INFO]: Epoch 017 - training loss: 0.1215, validation loss: 0.5636
2024-06-03 08:04:37 [INFO]: Epoch 018 - training loss: 0.1204, validation loss: 0.5473
2024-06-03 08:04:40 [INFO]: Epoch 019 - training loss: 0.1157, validation loss: 0.5469
2024-06-03 08:04:44 [INFO]: Epoch 020 - training loss: 0.1122, validation loss: 0.5436
2024-06-03 08:04:48 [INFO]: Epoch 021 - training loss: 0.1081, validation loss: 0.5496
2024-06-03 08:04:51 [INFO]: Epoch 022 - training loss: 0.1031, validation loss: 0.5504
2024-06-03 08:04:55 [INFO]: Epoch 023 - training loss: 0.1021, validation loss: 0.5455
2024-06-03 08:04:58 [INFO]: Epoch 024 - training loss: 0.0979, validation loss: 0.5545
2024-06-03 08:05:02 [INFO]: Epoch 025 - training loss: 0.0976, validation loss: 0.5505
2024-06-03 08:05:05 [INFO]: Epoch 026 - training loss: 0.0920, validation loss: 0.5507
2024-06-03 08:05:08 [INFO]: Epoch 027 - training loss: 0.0917, validation loss: 0.5564
2024-06-03 08:05:12 [INFO]: Epoch 028 - training loss: 0.0914, validation loss: 0.5532
2024-06-03 08:05:16 [INFO]: Epoch 029 - training loss: 0.0897, validation loss: 0.5471
2024-06-03 08:05:19 [INFO]: Epoch 030 - training loss: 0.0859, validation loss: 0.5492
2024-06-03 08:05:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:05:19 [INFO]: Finished training. The best model is from epoch#20.
2024-06-03 08:05:22 [INFO]: Saved the model to results_subseq_rate05/PeMS/TimesNet_PeMS/round_4/20240603_T080326/TimesNet.pypots
2024-06-03 08:05:24 [INFO]: Successfully saved to results_subseq_rate05/PeMS/TimesNet_PeMS/round_4/imputation.pkl
2024-06-03 08:05:24 [INFO]: Round4 - TimesNet on PeMS: MAE=0.4098, MSE=0.8038, MRE=0.4843
2024-06-03 08:05:24 [INFO]: Done! Final results:
Averaged TimesNet (91,622,238 params) on PeMS: MAE=0.4071 ± 0.0028255378651955063, MSE=0.8003 ± 0.0032153859343997298, MRE=0.4811 ± 0.0033390092610836837, average inference time=0.39
