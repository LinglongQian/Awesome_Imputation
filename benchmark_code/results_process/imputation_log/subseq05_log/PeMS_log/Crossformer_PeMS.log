2024-06-03 02:53:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:53:54 [INFO]: Using the given device: cuda:0
2024-06-03 02:53:54 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T025354
2024-06-03 02:53:54 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T025354/tensorboard
2024-06-03 02:53:56 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 02:54:02 [INFO]: Epoch 001 - training loss: 1.1564, validation loss: 1.0081
2024-06-03 02:54:06 [INFO]: Epoch 002 - training loss: 0.6822, validation loss: 0.8977
2024-06-03 02:54:11 [INFO]: Epoch 003 - training loss: 0.5531, validation loss: 0.7421
2024-06-03 02:54:16 [INFO]: Epoch 004 - training loss: 0.5064, validation loss: 0.7191
2024-06-03 02:54:21 [INFO]: Epoch 005 - training loss: 0.4633, validation loss: 0.6876
2024-06-03 02:54:27 [INFO]: Epoch 006 - training loss: 0.4528, validation loss: 0.6615
2024-06-03 02:54:32 [INFO]: Epoch 007 - training loss: 0.4317, validation loss: 0.6370
2024-06-03 02:54:37 [INFO]: Epoch 008 - training loss: 0.4342, validation loss: 0.6444
2024-06-03 02:54:43 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.6336
2024-06-03 02:54:48 [INFO]: Epoch 010 - training loss: 0.4168, validation loss: 0.6144
2024-06-03 02:54:53 [INFO]: Epoch 011 - training loss: 0.3964, validation loss: 0.6123
2024-06-03 02:54:58 [INFO]: Epoch 012 - training loss: 0.3822, validation loss: 0.6071
2024-06-03 02:55:02 [INFO]: Epoch 013 - training loss: 0.3742, validation loss: 0.5993
2024-06-03 02:55:07 [INFO]: Epoch 014 - training loss: 0.3742, validation loss: 0.5944
2024-06-03 02:55:12 [INFO]: Epoch 015 - training loss: 0.3626, validation loss: 0.5938
2024-06-03 02:55:17 [INFO]: Epoch 016 - training loss: 0.3575, validation loss: 0.6052
2024-06-03 02:55:22 [INFO]: Epoch 017 - training loss: 0.3490, validation loss: 0.5909
2024-06-03 02:55:27 [INFO]: Epoch 018 - training loss: 0.3346, validation loss: 0.5926
2024-06-03 02:55:32 [INFO]: Epoch 019 - training loss: 0.3314, validation loss: 0.5919
2024-06-03 02:55:37 [INFO]: Epoch 020 - training loss: 0.3295, validation loss: 0.5900
2024-06-03 02:55:42 [INFO]: Epoch 021 - training loss: 0.3271, validation loss: 0.5897
2024-06-03 02:55:47 [INFO]: Epoch 022 - training loss: 0.3254, validation loss: 0.5854
2024-06-03 02:55:52 [INFO]: Epoch 023 - training loss: 0.3257, validation loss: 0.5817
2024-06-03 02:55:56 [INFO]: Epoch 024 - training loss: 0.3151, validation loss: 0.5836
2024-06-03 02:56:01 [INFO]: Epoch 025 - training loss: 0.3081, validation loss: 0.5780
2024-06-03 02:56:07 [INFO]: Epoch 026 - training loss: 0.3031, validation loss: 0.5773
2024-06-03 02:56:12 [INFO]: Epoch 027 - training loss: 0.2972, validation loss: 0.5753
2024-06-03 02:56:17 [INFO]: Epoch 028 - training loss: 0.2991, validation loss: 0.5735
2024-06-03 02:56:22 [INFO]: Epoch 029 - training loss: 0.2969, validation loss: 0.5748
2024-06-03 02:56:27 [INFO]: Epoch 030 - training loss: 0.2968, validation loss: 0.5773
2024-06-03 02:56:32 [INFO]: Epoch 031 - training loss: 0.2980, validation loss: 0.5745
2024-06-03 02:56:37 [INFO]: Epoch 032 - training loss: 0.2971, validation loss: 0.5808
2024-06-03 02:56:42 [INFO]: Epoch 033 - training loss: 0.2863, validation loss: 0.5777
2024-06-03 02:56:47 [INFO]: Epoch 034 - training loss: 0.2850, validation loss: 0.5738
2024-06-03 02:56:52 [INFO]: Epoch 035 - training loss: 0.2855, validation loss: 0.5707
2024-06-03 02:56:57 [INFO]: Epoch 036 - training loss: 0.2832, validation loss: 0.5747
2024-06-03 02:57:02 [INFO]: Epoch 037 - training loss: 0.2794, validation loss: 0.5743
2024-06-03 02:57:07 [INFO]: Epoch 038 - training loss: 0.2765, validation loss: 0.5729
2024-06-03 02:57:12 [INFO]: Epoch 039 - training loss: 0.2804, validation loss: 0.5701
2024-06-03 02:57:17 [INFO]: Epoch 040 - training loss: 0.2748, validation loss: 0.5774
2024-06-03 02:57:22 [INFO]: Epoch 041 - training loss: 0.2713, validation loss: 0.5752
2024-06-03 02:57:28 [INFO]: Epoch 042 - training loss: 0.2716, validation loss: 0.5727
2024-06-03 02:57:33 [INFO]: Epoch 043 - training loss: 0.2705, validation loss: 0.5736
2024-06-03 02:57:37 [INFO]: Epoch 044 - training loss: 0.2720, validation loss: 0.5752
2024-06-03 02:57:42 [INFO]: Epoch 045 - training loss: 0.2687, validation loss: 0.5745
2024-06-03 02:57:47 [INFO]: Epoch 046 - training loss: 0.2643, validation loss: 0.5743
2024-06-03 02:57:52 [INFO]: Epoch 047 - training loss: 0.2658, validation loss: 0.5726
2024-06-03 02:57:57 [INFO]: Epoch 048 - training loss: 0.2673, validation loss: 0.5832
2024-06-03 02:58:02 [INFO]: Epoch 049 - training loss: 0.2646, validation loss: 0.5725
2024-06-03 02:58:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:58:02 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 02:58:02 [INFO]: Saved the model to results_subseq_rate05/PeMS/Crossformer_PeMS/round_0/20240603_T025354/Crossformer.pypots
2024-06-03 02:58:05 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_0/imputation.pkl
2024-06-03 02:58:05 [INFO]: Round0 - Crossformer on PeMS: MAE=0.4223, MSE=0.8497, MRE=0.4991
2024-06-03 02:58:05 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:58:05 [INFO]: Using the given device: cuda:0
2024-06-03 02:58:05 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T025805
2024-06-03 02:58:05 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T025805/tensorboard
2024-06-03 02:58:05 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 02:58:11 [INFO]: Epoch 001 - training loss: 1.0956, validation loss: 1.0380
2024-06-03 02:58:16 [INFO]: Epoch 002 - training loss: 0.6745, validation loss: 0.8604
2024-06-03 02:58:21 [INFO]: Epoch 003 - training loss: 0.5520, validation loss: 0.7752
2024-06-03 02:58:26 [INFO]: Epoch 004 - training loss: 0.5073, validation loss: 0.7337
2024-06-03 02:58:30 [INFO]: Epoch 005 - training loss: 0.4939, validation loss: 0.7161
2024-06-03 02:58:35 [INFO]: Epoch 006 - training loss: 0.4680, validation loss: 0.6757
2024-06-03 02:58:40 [INFO]: Epoch 007 - training loss: 0.4446, validation loss: 0.6616
2024-06-03 02:58:45 [INFO]: Epoch 008 - training loss: 0.4295, validation loss: 0.6445
2024-06-03 02:58:50 [INFO]: Epoch 009 - training loss: 0.4180, validation loss: 0.6506
2024-06-03 02:58:55 [INFO]: Epoch 010 - training loss: 0.4047, validation loss: 0.6289
2024-06-03 02:59:00 [INFO]: Epoch 011 - training loss: 0.3963, validation loss: 0.6217
2024-06-03 02:59:06 [INFO]: Epoch 012 - training loss: 0.3877, validation loss: 0.6142
2024-06-03 02:59:11 [INFO]: Epoch 013 - training loss: 0.3824, validation loss: 0.5997
2024-06-03 02:59:16 [INFO]: Epoch 014 - training loss: 0.3695, validation loss: 0.6013
2024-06-03 02:59:21 [INFO]: Epoch 015 - training loss: 0.3613, validation loss: 0.6003
2024-06-03 02:59:25 [INFO]: Epoch 016 - training loss: 0.3543, validation loss: 0.6032
2024-06-03 02:59:30 [INFO]: Epoch 017 - training loss: 0.3484, validation loss: 0.5897
2024-06-03 02:59:35 [INFO]: Epoch 018 - training loss: 0.3485, validation loss: 0.5925
2024-06-03 02:59:39 [INFO]: Epoch 019 - training loss: 0.3445, validation loss: 0.5926
2024-06-03 02:59:44 [INFO]: Epoch 020 - training loss: 0.3316, validation loss: 0.5872
2024-06-03 02:59:48 [INFO]: Epoch 021 - training loss: 0.3236, validation loss: 0.5841
2024-06-03 02:59:53 [INFO]: Epoch 022 - training loss: 0.3218, validation loss: 0.5842
2024-06-03 02:59:58 [INFO]: Epoch 023 - training loss: 0.3223, validation loss: 0.5867
2024-06-03 03:00:03 [INFO]: Epoch 024 - training loss: 0.3141, validation loss: 0.5793
2024-06-03 03:00:07 [INFO]: Epoch 025 - training loss: 0.3066, validation loss: 0.5774
2024-06-03 03:00:12 [INFO]: Epoch 026 - training loss: 0.3133, validation loss: 0.5823
2024-06-03 03:00:16 [INFO]: Epoch 027 - training loss: 0.3117, validation loss: 0.5845
2024-06-03 03:00:20 [INFO]: Epoch 028 - training loss: 0.3023, validation loss: 0.5759
2024-06-03 03:00:25 [INFO]: Epoch 029 - training loss: 0.3040, validation loss: 0.5809
2024-06-03 03:00:30 [INFO]: Epoch 030 - training loss: 0.2973, validation loss: 0.5739
2024-06-03 03:00:35 [INFO]: Epoch 031 - training loss: 0.2862, validation loss: 0.5781
2024-06-03 03:00:39 [INFO]: Epoch 032 - training loss: 0.2874, validation loss: 0.5760
2024-06-03 03:00:44 [INFO]: Epoch 033 - training loss: 0.2862, validation loss: 0.5724
2024-06-03 03:00:49 [INFO]: Epoch 034 - training loss: 0.2838, validation loss: 0.5816
2024-06-03 03:00:53 [INFO]: Epoch 035 - training loss: 0.2816, validation loss: 0.5765
2024-06-03 03:00:58 [INFO]: Epoch 036 - training loss: 0.2787, validation loss: 0.5750
2024-06-03 03:01:03 [INFO]: Epoch 037 - training loss: 0.2805, validation loss: 0.5728
2024-06-03 03:01:07 [INFO]: Epoch 038 - training loss: 0.2770, validation loss: 0.5748
2024-06-03 03:01:11 [INFO]: Epoch 039 - training loss: 0.2798, validation loss: 0.5703
2024-06-03 03:01:16 [INFO]: Epoch 040 - training loss: 0.2709, validation loss: 0.5812
2024-06-03 03:01:21 [INFO]: Epoch 041 - training loss: 0.2751, validation loss: 0.5762
2024-06-03 03:01:26 [INFO]: Epoch 042 - training loss: 0.2756, validation loss: 0.5801
2024-06-03 03:01:31 [INFO]: Epoch 043 - training loss: 0.2704, validation loss: 0.5738
2024-06-03 03:01:35 [INFO]: Epoch 044 - training loss: 0.2704, validation loss: 0.5789
2024-06-03 03:01:40 [INFO]: Epoch 045 - training loss: 0.2662, validation loss: 0.5756
2024-06-03 03:01:45 [INFO]: Epoch 046 - training loss: 0.2699, validation loss: 0.5846
2024-06-03 03:01:49 [INFO]: Epoch 047 - training loss: 0.2678, validation loss: 0.5789
2024-06-03 03:01:54 [INFO]: Epoch 048 - training loss: 0.2674, validation loss: 0.5794
2024-06-03 03:01:58 [INFO]: Epoch 049 - training loss: 0.2648, validation loss: 0.5860
2024-06-03 03:01:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:01:58 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 03:01:58 [INFO]: Saved the model to results_subseq_rate05/PeMS/Crossformer_PeMS/round_1/20240603_T025805/Crossformer.pypots
2024-06-03 03:02:00 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_1/imputation.pkl
2024-06-03 03:02:00 [INFO]: Round1 - Crossformer on PeMS: MAE=0.4276, MSE=0.8639, MRE=0.5053
2024-06-03 03:02:00 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:02:00 [INFO]: Using the given device: cuda:0
2024-06-03 03:02:00 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T030200
2024-06-03 03:02:00 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T030200/tensorboard
2024-06-03 03:02:01 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 03:02:05 [INFO]: Epoch 001 - training loss: 1.1056, validation loss: 1.0563
2024-06-03 03:02:10 [INFO]: Epoch 002 - training loss: 0.7215, validation loss: 0.9755
2024-06-03 03:02:15 [INFO]: Epoch 003 - training loss: 0.5852, validation loss: 0.7649
2024-06-03 03:02:20 [INFO]: Epoch 004 - training loss: 0.5158, validation loss: 0.7572
2024-06-03 03:02:25 [INFO]: Epoch 005 - training loss: 0.4842, validation loss: 0.7170
2024-06-03 03:02:30 [INFO]: Epoch 006 - training loss: 0.4664, validation loss: 0.6982
2024-06-03 03:02:34 [INFO]: Epoch 007 - training loss: 0.4450, validation loss: 0.6706
2024-06-03 03:02:39 [INFO]: Epoch 008 - training loss: 0.4262, validation loss: 0.6507
2024-06-03 03:02:43 [INFO]: Epoch 009 - training loss: 0.4123, validation loss: 0.6453
2024-06-03 03:02:47 [INFO]: Epoch 010 - training loss: 0.4196, validation loss: 0.6643
2024-06-03 03:02:52 [INFO]: Epoch 011 - training loss: 0.4091, validation loss: 0.6511
2024-06-03 03:02:57 [INFO]: Epoch 012 - training loss: 0.3864, validation loss: 0.6239
2024-06-03 03:03:01 [INFO]: Epoch 013 - training loss: 0.3748, validation loss: 0.6119
2024-06-03 03:03:06 [INFO]: Epoch 014 - training loss: 0.3734, validation loss: 0.6129
2024-06-03 03:03:11 [INFO]: Epoch 015 - training loss: 0.3653, validation loss: 0.5977
2024-06-03 03:03:16 [INFO]: Epoch 016 - training loss: 0.3522, validation loss: 0.5910
2024-06-03 03:03:20 [INFO]: Epoch 017 - training loss: 0.3569, validation loss: 0.6074
2024-06-03 03:03:25 [INFO]: Epoch 018 - training loss: 0.3516, validation loss: 0.6073
2024-06-03 03:03:30 [INFO]: Epoch 019 - training loss: 0.3491, validation loss: 0.6019
2024-06-03 03:03:34 [INFO]: Epoch 020 - training loss: 0.3365, validation loss: 0.5845
2024-06-03 03:03:38 [INFO]: Epoch 021 - training loss: 0.3306, validation loss: 0.5861
2024-06-03 03:03:43 [INFO]: Epoch 022 - training loss: 0.3235, validation loss: 0.5897
2024-06-03 03:03:47 [INFO]: Epoch 023 - training loss: 0.3224, validation loss: 0.5856
2024-06-03 03:03:52 [INFO]: Epoch 024 - training loss: 0.3155, validation loss: 0.5882
2024-06-03 03:03:56 [INFO]: Epoch 025 - training loss: 0.3201, validation loss: 0.5828
2024-06-03 03:04:01 [INFO]: Epoch 026 - training loss: 0.3144, validation loss: 0.5816
2024-06-03 03:04:05 [INFO]: Epoch 027 - training loss: 0.3108, validation loss: 0.5765
2024-06-03 03:04:09 [INFO]: Epoch 028 - training loss: 0.3042, validation loss: 0.5809
2024-06-03 03:04:14 [INFO]: Epoch 029 - training loss: 0.3024, validation loss: 0.5812
2024-06-03 03:04:18 [INFO]: Epoch 030 - training loss: 0.3007, validation loss: 0.5808
2024-06-03 03:04:22 [INFO]: Epoch 031 - training loss: 0.2996, validation loss: 0.5896
2024-06-03 03:04:25 [INFO]: Epoch 032 - training loss: 0.3104, validation loss: 0.5805
2024-06-03 03:04:29 [INFO]: Epoch 033 - training loss: 0.2978, validation loss: 0.5763
2024-06-03 03:04:33 [INFO]: Epoch 034 - training loss: 0.2926, validation loss: 0.5719
2024-06-03 03:04:37 [INFO]: Epoch 035 - training loss: 0.2880, validation loss: 0.5797
2024-06-03 03:04:41 [INFO]: Epoch 036 - training loss: 0.2855, validation loss: 0.5765
2024-06-03 03:04:45 [INFO]: Epoch 037 - training loss: 0.2883, validation loss: 0.5749
2024-06-03 03:04:49 [INFO]: Epoch 038 - training loss: 0.2836, validation loss: 0.5852
2024-06-03 03:04:53 [INFO]: Epoch 039 - training loss: 0.2785, validation loss: 0.5807
2024-06-03 03:04:57 [INFO]: Epoch 040 - training loss: 0.2784, validation loss: 0.5801
2024-06-03 03:05:01 [INFO]: Epoch 041 - training loss: 0.2783, validation loss: 0.5768
2024-06-03 03:05:05 [INFO]: Epoch 042 - training loss: 0.2783, validation loss: 0.5827
2024-06-03 03:05:09 [INFO]: Epoch 043 - training loss: 0.2780, validation loss: 0.5807
2024-06-03 03:05:12 [INFO]: Epoch 044 - training loss: 0.2814, validation loss: 0.5791
2024-06-03 03:05:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:05:12 [INFO]: Finished training. The best model is from epoch#34.
2024-06-03 03:05:13 [INFO]: Saved the model to results_subseq_rate05/PeMS/Crossformer_PeMS/round_2/20240603_T030200/Crossformer.pypots
2024-06-03 03:05:14 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_2/imputation.pkl
2024-06-03 03:05:14 [INFO]: Round2 - Crossformer on PeMS: MAE=0.4265, MSE=0.8594, MRE=0.5040
2024-06-03 03:05:14 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:05:14 [INFO]: Using the given device: cuda:0
2024-06-03 03:05:14 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T030514
2024-06-03 03:05:14 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T030514/tensorboard
2024-06-03 03:05:15 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 03:05:19 [INFO]: Epoch 001 - training loss: 1.1180, validation loss: 1.0750
2024-06-03 03:05:23 [INFO]: Epoch 002 - training loss: 0.6872, validation loss: 0.9496
2024-06-03 03:05:27 [INFO]: Epoch 003 - training loss: 0.5685, validation loss: 0.8030
2024-06-03 03:05:31 [INFO]: Epoch 004 - training loss: 0.5276, validation loss: 0.7495
2024-06-03 03:05:35 [INFO]: Epoch 005 - training loss: 0.4846, validation loss: 0.6941
2024-06-03 03:05:39 [INFO]: Epoch 006 - training loss: 0.4806, validation loss: 0.6848
2024-06-03 03:05:43 [INFO]: Epoch 007 - training loss: 0.4540, validation loss: 0.6592
2024-06-03 03:05:47 [INFO]: Epoch 008 - training loss: 0.4363, validation loss: 0.6505
2024-06-03 03:05:51 [INFO]: Epoch 009 - training loss: 0.4351, validation loss: 0.6515
2024-06-03 03:05:55 [INFO]: Epoch 010 - training loss: 0.4181, validation loss: 0.6368
2024-06-03 03:05:58 [INFO]: Epoch 011 - training loss: 0.4003, validation loss: 0.6361
2024-06-03 03:06:02 [INFO]: Epoch 012 - training loss: 0.3980, validation loss: 0.6163
2024-06-03 03:06:06 [INFO]: Epoch 013 - training loss: 0.3865, validation loss: 0.6052
2024-06-03 03:06:10 [INFO]: Epoch 014 - training loss: 0.3802, validation loss: 0.6054
2024-06-03 03:06:14 [INFO]: Epoch 015 - training loss: 0.3713, validation loss: 0.6034
2024-06-03 03:06:18 [INFO]: Epoch 016 - training loss: 0.3642, validation loss: 0.6002
2024-06-03 03:06:22 [INFO]: Epoch 017 - training loss: 0.3585, validation loss: 0.5984
2024-06-03 03:06:26 [INFO]: Epoch 018 - training loss: 0.3469, validation loss: 0.5970
2024-06-03 03:06:29 [INFO]: Epoch 019 - training loss: 0.3501, validation loss: 0.5929
2024-06-03 03:06:33 [INFO]: Epoch 020 - training loss: 0.3412, validation loss: 0.5898
2024-06-03 03:06:37 [INFO]: Epoch 021 - training loss: 0.3340, validation loss: 0.5872
2024-06-03 03:06:41 [INFO]: Epoch 022 - training loss: 0.3273, validation loss: 0.5856
2024-06-03 03:06:45 [INFO]: Epoch 023 - training loss: 0.3290, validation loss: 0.5873
2024-06-03 03:06:48 [INFO]: Epoch 024 - training loss: 0.3258, validation loss: 0.5861
2024-06-03 03:06:52 [INFO]: Epoch 025 - training loss: 0.3279, validation loss: 0.5834
2024-06-03 03:06:56 [INFO]: Epoch 026 - training loss: 0.3137, validation loss: 0.5757
2024-06-03 03:07:00 [INFO]: Epoch 027 - training loss: 0.3073, validation loss: 0.5840
2024-06-03 03:07:04 [INFO]: Epoch 028 - training loss: 0.3088, validation loss: 0.5760
2024-06-03 03:07:08 [INFO]: Epoch 029 - training loss: 0.3001, validation loss: 0.5721
2024-06-03 03:07:12 [INFO]: Epoch 030 - training loss: 0.3038, validation loss: 0.5707
2024-06-03 03:07:17 [INFO]: Epoch 031 - training loss: 0.2960, validation loss: 0.5725
2024-06-03 03:07:20 [INFO]: Epoch 032 - training loss: 0.2978, validation loss: 0.5741
2024-06-03 03:07:24 [INFO]: Epoch 033 - training loss: 0.2946, validation loss: 0.5681
2024-06-03 03:07:28 [INFO]: Epoch 034 - training loss: 0.2904, validation loss: 0.5712
2024-06-03 03:07:32 [INFO]: Epoch 035 - training loss: 0.2893, validation loss: 0.5665
2024-06-03 03:07:36 [INFO]: Epoch 036 - training loss: 0.2846, validation loss: 0.5658
2024-06-03 03:07:39 [INFO]: Epoch 037 - training loss: 0.2847, validation loss: 0.5644
2024-06-03 03:07:43 [INFO]: Epoch 038 - training loss: 0.2869, validation loss: 0.5719
2024-06-03 03:07:47 [INFO]: Epoch 039 - training loss: 0.2794, validation loss: 0.5678
2024-06-03 03:07:52 [INFO]: Epoch 040 - training loss: 0.2803, validation loss: 0.5716
2024-06-03 03:07:56 [INFO]: Epoch 041 - training loss: 0.2777, validation loss: 0.5711
2024-06-03 03:08:00 [INFO]: Epoch 042 - training loss: 0.2762, validation loss: 0.5661
2024-06-03 03:08:04 [INFO]: Epoch 043 - training loss: 0.2778, validation loss: 0.5685
2024-06-03 03:08:08 [INFO]: Epoch 044 - training loss: 0.2724, validation loss: 0.5693
2024-06-03 03:08:12 [INFO]: Epoch 045 - training loss: 0.2726, validation loss: 0.5698
2024-06-03 03:08:16 [INFO]: Epoch 046 - training loss: 0.2689, validation loss: 0.5683
2024-06-03 03:08:20 [INFO]: Epoch 047 - training loss: 0.2684, validation loss: 0.5665
2024-06-03 03:08:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:08:20 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 03:08:20 [INFO]: Saved the model to results_subseq_rate05/PeMS/Crossformer_PeMS/round_3/20240603_T030514/Crossformer.pypots
2024-06-03 03:08:21 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_3/imputation.pkl
2024-06-03 03:08:21 [INFO]: Round3 - Crossformer on PeMS: MAE=0.4174, MSE=0.8409, MRE=0.4932
2024-06-03 03:08:21 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:08:21 [INFO]: Using the given device: cuda:0
2024-06-03 03:08:21 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T030821
2024-06-03 03:08:21 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T030821/tensorboard
2024-06-03 03:08:22 [INFO]: Crossformer initialized with the given hyperparameters, the number of trainable parameters: 12,645,238
2024-06-03 03:08:26 [INFO]: Epoch 001 - training loss: 1.1256, validation loss: 0.9725
2024-06-03 03:08:30 [INFO]: Epoch 002 - training loss: 0.6949, validation loss: 0.9584
2024-06-03 03:08:34 [INFO]: Epoch 003 - training loss: 0.6017, validation loss: 0.7908
2024-06-03 03:08:37 [INFO]: Epoch 004 - training loss: 0.5166, validation loss: 0.7256
2024-06-03 03:08:41 [INFO]: Epoch 005 - training loss: 0.4778, validation loss: 0.7007
2024-06-03 03:08:45 [INFO]: Epoch 006 - training loss: 0.4562, validation loss: 0.6801
2024-06-03 03:08:49 [INFO]: Epoch 007 - training loss: 0.4439, validation loss: 0.6661
2024-06-03 03:08:53 [INFO]: Epoch 008 - training loss: 0.4302, validation loss: 0.6586
2024-06-03 03:08:57 [INFO]: Epoch 009 - training loss: 0.4264, validation loss: 0.6479
2024-06-03 03:09:01 [INFO]: Epoch 010 - training loss: 0.4189, validation loss: 0.6488
2024-06-03 03:09:05 [INFO]: Epoch 011 - training loss: 0.4004, validation loss: 0.6211
2024-06-03 03:09:09 [INFO]: Epoch 012 - training loss: 0.3877, validation loss: 0.6199
2024-06-03 03:09:12 [INFO]: Epoch 013 - training loss: 0.3849, validation loss: 0.6125
2024-06-03 03:09:16 [INFO]: Epoch 014 - training loss: 0.3721, validation loss: 0.6080
2024-06-03 03:09:20 [INFO]: Epoch 015 - training loss: 0.3570, validation loss: 0.5990
2024-06-03 03:09:24 [INFO]: Epoch 016 - training loss: 0.3536, validation loss: 0.5980
2024-06-03 03:09:28 [INFO]: Epoch 017 - training loss: 0.3458, validation loss: 0.5997
2024-06-03 03:09:32 [INFO]: Epoch 018 - training loss: 0.3428, validation loss: 0.5904
2024-06-03 03:09:36 [INFO]: Epoch 019 - training loss: 0.3359, validation loss: 0.5913
2024-06-03 03:09:40 [INFO]: Epoch 020 - training loss: 0.3298, validation loss: 0.5931
2024-06-03 03:09:44 [INFO]: Epoch 021 - training loss: 0.3239, validation loss: 0.5912
2024-06-03 03:09:48 [INFO]: Epoch 022 - training loss: 0.3214, validation loss: 0.5893
2024-06-03 03:09:51 [INFO]: Epoch 023 - training loss: 0.3192, validation loss: 0.5850
2024-06-03 03:09:55 [INFO]: Epoch 024 - training loss: 0.3156, validation loss: 0.5820
2024-06-03 03:09:59 [INFO]: Epoch 025 - training loss: 0.3134, validation loss: 0.5817
2024-06-03 03:10:03 [INFO]: Epoch 026 - training loss: 0.3063, validation loss: 0.5805
2024-06-03 03:10:06 [INFO]: Epoch 027 - training loss: 0.3044, validation loss: 0.5811
2024-06-03 03:10:10 [INFO]: Epoch 028 - training loss: 0.3020, validation loss: 0.5794
2024-06-03 03:10:15 [INFO]: Epoch 029 - training loss: 0.3016, validation loss: 0.5739
2024-06-03 03:10:19 [INFO]: Epoch 030 - training loss: 0.2984, validation loss: 0.5749
2024-06-03 03:10:23 [INFO]: Epoch 031 - training loss: 0.2938, validation loss: 0.5788
2024-06-03 03:10:27 [INFO]: Epoch 032 - training loss: 0.2920, validation loss: 0.5753
2024-06-03 03:10:31 [INFO]: Epoch 033 - training loss: 0.2920, validation loss: 0.5862
2024-06-03 03:10:35 [INFO]: Epoch 034 - training loss: 0.2932, validation loss: 0.5754
2024-06-03 03:10:38 [INFO]: Epoch 035 - training loss: 0.2849, validation loss: 0.5739
2024-06-03 03:10:42 [INFO]: Epoch 036 - training loss: 0.2776, validation loss: 0.5726
2024-06-03 03:10:46 [INFO]: Epoch 037 - training loss: 0.2757, validation loss: 0.5736
2024-06-03 03:10:50 [INFO]: Epoch 038 - training loss: 0.2758, validation loss: 0.5823
2024-06-03 03:10:54 [INFO]: Epoch 039 - training loss: 0.2823, validation loss: 0.5739
2024-06-03 03:10:58 [INFO]: Epoch 040 - training loss: 0.2770, validation loss: 0.5755
2024-06-03 03:11:02 [INFO]: Epoch 041 - training loss: 0.2737, validation loss: 0.5767
2024-06-03 03:11:06 [INFO]: Epoch 042 - training loss: 0.2706, validation loss: 0.5772
2024-06-03 03:11:10 [INFO]: Epoch 043 - training loss: 0.2697, validation loss: 0.5784
2024-06-03 03:11:14 [INFO]: Epoch 044 - training loss: 0.2683, validation loss: 0.5759
2024-06-03 03:11:18 [INFO]: Epoch 045 - training loss: 0.2671, validation loss: 0.5722
2024-06-03 03:11:22 [INFO]: Epoch 046 - training loss: 0.2667, validation loss: 0.5721
2024-06-03 03:11:26 [INFO]: Epoch 047 - training loss: 0.2666, validation loss: 0.5778
2024-06-03 03:11:30 [INFO]: Epoch 048 - training loss: 0.2605, validation loss: 0.5733
2024-06-03 03:11:33 [INFO]: Epoch 049 - training loss: 0.2575, validation loss: 0.5744
2024-06-03 03:11:37 [INFO]: Epoch 050 - training loss: 0.2601, validation loss: 0.5731
2024-06-03 03:11:41 [INFO]: Epoch 051 - training loss: 0.2601, validation loss: 0.5801
2024-06-03 03:11:45 [INFO]: Epoch 052 - training loss: 0.2576, validation loss: 0.5772
2024-06-03 03:11:49 [INFO]: Epoch 053 - training loss: 0.2582, validation loss: 0.5786
2024-06-03 03:11:53 [INFO]: Epoch 054 - training loss: 0.2567, validation loss: 0.5787
2024-06-03 03:11:57 [INFO]: Epoch 055 - training loss: 0.2550, validation loss: 0.5779
2024-06-03 03:12:01 [INFO]: Epoch 056 - training loss: 0.2531, validation loss: 0.5754
2024-06-03 03:12:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:12:01 [INFO]: Finished training. The best model is from epoch#46.
2024-06-03 03:12:01 [INFO]: Saved the model to results_subseq_rate05/PeMS/Crossformer_PeMS/round_4/20240603_T030821/Crossformer.pypots
2024-06-03 03:12:03 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Crossformer_PeMS/round_4/imputation.pkl
2024-06-03 03:12:03 [INFO]: Round4 - Crossformer on PeMS: MAE=0.4317, MSE=0.8528, MRE=0.5102
2024-06-03 03:12:03 [INFO]: Done! Final results:
Averaged Crossformer (12,645,238 params) on PeMS: MAE=0.4251 ± 0.004904341962717187, MSE=0.8533 ± 0.007956191068057934, MRE=0.5024 ± 0.005795584421198632, average inference time=0.29
