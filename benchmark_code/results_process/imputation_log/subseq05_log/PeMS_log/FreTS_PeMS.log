2024-06-03 02:53:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:53:54 [INFO]: Using the given device: cuda:0
2024-06-03 02:53:54 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_0/20240603_T025354
2024-06-03 02:53:54 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_0/20240603_T025354/tensorboard
2024-06-03 02:53:56 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-03 02:54:00 [INFO]: Epoch 001 - training loss: 1.1717, validation loss: 1.0052
2024-06-03 02:54:03 [INFO]: Epoch 002 - training loss: 0.7550, validation loss: 0.8846
2024-06-03 02:54:06 [INFO]: Epoch 003 - training loss: 0.6624, validation loss: 0.7899
2024-06-03 02:54:09 [INFO]: Epoch 004 - training loss: 0.5515, validation loss: 0.7100
2024-06-03 02:54:12 [INFO]: Epoch 005 - training loss: 0.5617, validation loss: 0.7170
2024-06-03 02:54:16 [INFO]: Epoch 006 - training loss: 0.5100, validation loss: 0.6896
2024-06-03 02:54:19 [INFO]: Epoch 007 - training loss: 0.5228, validation loss: 0.6788
2024-06-03 02:54:23 [INFO]: Epoch 008 - training loss: 0.5040, validation loss: 0.6756
2024-06-03 02:54:26 [INFO]: Epoch 009 - training loss: 0.4596, validation loss: 0.6542
2024-06-03 02:54:29 [INFO]: Epoch 010 - training loss: 0.4420, validation loss: 0.6528
2024-06-03 02:54:33 [INFO]: Epoch 011 - training loss: 0.4415, validation loss: 0.6502
2024-06-03 02:54:36 [INFO]: Epoch 012 - training loss: 0.4333, validation loss: 0.6491
2024-06-03 02:54:39 [INFO]: Epoch 013 - training loss: 0.4391, validation loss: 0.6542
2024-06-03 02:54:43 [INFO]: Epoch 014 - training loss: 0.4295, validation loss: 0.6474
2024-06-03 02:54:46 [INFO]: Epoch 015 - training loss: 0.4165, validation loss: 0.6512
2024-06-03 02:54:50 [INFO]: Epoch 016 - training loss: 0.4077, validation loss: 0.6448
2024-06-03 02:54:53 [INFO]: Epoch 017 - training loss: 0.3952, validation loss: 0.6441
2024-06-03 02:54:56 [INFO]: Epoch 018 - training loss: 0.3904, validation loss: 0.6505
2024-06-03 02:54:59 [INFO]: Epoch 019 - training loss: 0.3827, validation loss: 0.6348
2024-06-03 02:55:02 [INFO]: Epoch 020 - training loss: 0.3891, validation loss: 0.6413
2024-06-03 02:55:05 [INFO]: Epoch 021 - training loss: 0.3872, validation loss: 0.6333
2024-06-03 02:55:09 [INFO]: Epoch 022 - training loss: 0.3703, validation loss: 0.6333
2024-06-03 02:55:12 [INFO]: Epoch 023 - training loss: 0.3765, validation loss: 0.6458
2024-06-03 02:55:15 [INFO]: Epoch 024 - training loss: 0.3620, validation loss: 0.6425
2024-06-03 02:55:18 [INFO]: Epoch 025 - training loss: 0.3635, validation loss: 0.6488
2024-06-03 02:55:22 [INFO]: Epoch 026 - training loss: 0.3569, validation loss: 0.6510
2024-06-03 02:55:25 [INFO]: Epoch 027 - training loss: 0.3540, validation loss: 0.6278
2024-06-03 02:55:28 [INFO]: Epoch 028 - training loss: 0.3474, validation loss: 0.6372
2024-06-03 02:55:32 [INFO]: Epoch 029 - training loss: 0.3503, validation loss: 0.6316
2024-06-03 02:55:35 [INFO]: Epoch 030 - training loss: 0.3471, validation loss: 0.6355
2024-06-03 02:55:38 [INFO]: Epoch 031 - training loss: 0.3442, validation loss: 0.6467
2024-06-03 02:55:42 [INFO]: Epoch 032 - training loss: 0.3400, validation loss: 0.6389
2024-06-03 02:55:45 [INFO]: Epoch 033 - training loss: 0.3477, validation loss: 0.6522
2024-06-03 02:55:48 [INFO]: Epoch 034 - training loss: 0.3344, validation loss: 0.6403
2024-06-03 02:55:52 [INFO]: Epoch 035 - training loss: 0.3331, validation loss: 0.6415
2024-06-03 02:55:55 [INFO]: Epoch 036 - training loss: 0.3457, validation loss: 0.6371
2024-06-03 02:55:58 [INFO]: Epoch 037 - training loss: 0.3391, validation loss: 0.6344
2024-06-03 02:55:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:55:58 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 02:55:58 [INFO]: Saved the model to results_subseq_rate05/PeMS/FreTS_PeMS/round_0/20240603_T025354/FreTS.pypots
2024-06-03 02:56:00 [INFO]: Successfully saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_0/imputation.pkl
2024-06-03 02:56:00 [INFO]: Round0 - FreTS on PeMS: MAE=0.4759, MSE=0.9192, MRE=0.5624
2024-06-03 02:56:00 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:56:00 [INFO]: Using the given device: cuda:0
2024-06-03 02:56:00 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_1/20240603_T025600
2024-06-03 02:56:00 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_1/20240603_T025600/tensorboard
2024-06-03 02:56:00 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-03 02:56:03 [INFO]: Epoch 001 - training loss: 1.1982, validation loss: 1.0539
2024-06-03 02:56:06 [INFO]: Epoch 002 - training loss: 0.7262, validation loss: 1.0366
2024-06-03 02:56:10 [INFO]: Epoch 003 - training loss: 0.6160, validation loss: 0.7787
2024-06-03 02:56:13 [INFO]: Epoch 004 - training loss: 0.5477, validation loss: 0.7299
2024-06-03 02:56:17 [INFO]: Epoch 005 - training loss: 0.5263, validation loss: 0.7164
2024-06-03 02:56:20 [INFO]: Epoch 006 - training loss: 0.5143, validation loss: 0.7176
2024-06-03 02:56:23 [INFO]: Epoch 007 - training loss: 0.5129, validation loss: 0.7018
2024-06-03 02:56:27 [INFO]: Epoch 008 - training loss: 0.4845, validation loss: 0.6827
2024-06-03 02:56:30 [INFO]: Epoch 009 - training loss: 0.4612, validation loss: 0.6743
2024-06-03 02:56:33 [INFO]: Epoch 010 - training loss: 0.4510, validation loss: 0.6658
2024-06-03 02:56:37 [INFO]: Epoch 011 - training loss: 0.4409, validation loss: 0.6833
2024-06-03 02:56:40 [INFO]: Epoch 012 - training loss: 0.4486, validation loss: 0.7024
2024-06-03 02:56:43 [INFO]: Epoch 013 - training loss: 0.4452, validation loss: 0.6679
2024-06-03 02:56:46 [INFO]: Epoch 014 - training loss: 0.4132, validation loss: 0.6699
2024-06-03 02:56:49 [INFO]: Epoch 015 - training loss: 0.4140, validation loss: 0.6608
2024-06-03 02:56:52 [INFO]: Epoch 016 - training loss: 0.4060, validation loss: 0.6552
2024-06-03 02:56:56 [INFO]: Epoch 017 - training loss: 0.3900, validation loss: 0.6683
2024-06-03 02:56:59 [INFO]: Epoch 018 - training loss: 0.4012, validation loss: 0.6867
2024-06-03 02:57:02 [INFO]: Epoch 019 - training loss: 0.3953, validation loss: 0.6627
2024-06-03 02:57:05 [INFO]: Epoch 020 - training loss: 0.3793, validation loss: 0.6472
2024-06-03 02:57:09 [INFO]: Epoch 021 - training loss: 0.3711, validation loss: 0.6551
2024-06-03 02:57:12 [INFO]: Epoch 022 - training loss: 0.3654, validation loss: 0.6628
2024-06-03 02:57:15 [INFO]: Epoch 023 - training loss: 0.3662, validation loss: 0.6585
2024-06-03 02:57:18 [INFO]: Epoch 024 - training loss: 0.3656, validation loss: 0.6441
2024-06-03 02:57:22 [INFO]: Epoch 025 - training loss: 0.3819, validation loss: 0.6653
2024-06-03 02:57:25 [INFO]: Epoch 026 - training loss: 0.3737, validation loss: 0.6606
2024-06-03 02:57:28 [INFO]: Epoch 027 - training loss: 0.3592, validation loss: 0.6356
2024-06-03 02:57:31 [INFO]: Epoch 028 - training loss: 0.3617, validation loss: 0.6433
2024-06-03 02:57:35 [INFO]: Epoch 029 - training loss: 0.3589, validation loss: 0.6427
2024-06-03 02:57:38 [INFO]: Epoch 030 - training loss: 0.3469, validation loss: 0.6411
2024-06-03 02:57:41 [INFO]: Epoch 031 - training loss: 0.3403, validation loss: 0.6585
2024-06-03 02:57:44 [INFO]: Epoch 032 - training loss: 0.3392, validation loss: 0.6518
2024-06-03 02:57:47 [INFO]: Epoch 033 - training loss: 0.3394, validation loss: 0.6464
2024-06-03 02:57:50 [INFO]: Epoch 034 - training loss: 0.3325, validation loss: 0.6559
2024-06-03 02:57:54 [INFO]: Epoch 035 - training loss: 0.3311, validation loss: 0.6459
2024-06-03 02:57:57 [INFO]: Epoch 036 - training loss: 0.3296, validation loss: 0.6526
2024-06-03 02:58:00 [INFO]: Epoch 037 - training loss: 0.3202, validation loss: 0.6398
2024-06-03 02:58:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:58:00 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 02:58:00 [INFO]: Saved the model to results_subseq_rate05/PeMS/FreTS_PeMS/round_1/20240603_T025600/FreTS.pypots
2024-06-03 02:58:02 [INFO]: Successfully saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_1/imputation.pkl
2024-06-03 02:58:02 [INFO]: Round1 - FreTS on PeMS: MAE=0.4839, MSE=0.9401, MRE=0.5718
2024-06-03 02:58:02 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 02:58:02 [INFO]: Using the given device: cuda:0
2024-06-03 02:58:02 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_2/20240603_T025802
2024-06-03 02:58:02 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_2/20240603_T025802/tensorboard
2024-06-03 02:58:02 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-03 02:58:05 [INFO]: Epoch 001 - training loss: 1.1922, validation loss: 1.1086
2024-06-03 02:58:08 [INFO]: Epoch 002 - training loss: 0.7602, validation loss: 0.8735
2024-06-03 02:58:12 [INFO]: Epoch 003 - training loss: 0.6150, validation loss: 0.7696
2024-06-03 02:58:15 [INFO]: Epoch 004 - training loss: 0.5616, validation loss: 0.7372
2024-06-03 02:58:18 [INFO]: Epoch 005 - training loss: 0.5191, validation loss: 0.6990
2024-06-03 02:58:21 [INFO]: Epoch 006 - training loss: 0.4997, validation loss: 0.6988
2024-06-03 02:58:25 [INFO]: Epoch 007 - training loss: 0.4861, validation loss: 0.6940
2024-06-03 02:58:28 [INFO]: Epoch 008 - training loss: 0.4926, validation loss: 0.7252
2024-06-03 02:58:31 [INFO]: Epoch 009 - training loss: 0.4514, validation loss: 0.6792
2024-06-03 02:58:34 [INFO]: Epoch 010 - training loss: 0.4350, validation loss: 0.6596
2024-06-03 02:58:37 [INFO]: Epoch 011 - training loss: 0.4293, validation loss: 0.6703
2024-06-03 02:58:40 [INFO]: Epoch 012 - training loss: 0.4155, validation loss: 0.6520
2024-06-03 02:58:43 [INFO]: Epoch 013 - training loss: 0.4152, validation loss: 0.6559
2024-06-03 02:58:47 [INFO]: Epoch 014 - training loss: 0.3987, validation loss: 0.6504
2024-06-03 02:58:50 [INFO]: Epoch 015 - training loss: 0.3958, validation loss: 0.6576
2024-06-03 02:58:54 [INFO]: Epoch 016 - training loss: 0.3861, validation loss: 0.6526
2024-06-03 02:58:57 [INFO]: Epoch 017 - training loss: 0.3913, validation loss: 0.6509
2024-06-03 02:59:00 [INFO]: Epoch 018 - training loss: 0.3787, validation loss: 0.6514
2024-06-03 02:59:03 [INFO]: Epoch 019 - training loss: 0.3708, validation loss: 0.6506
2024-06-03 02:59:07 [INFO]: Epoch 020 - training loss: 0.3708, validation loss: 0.6521
2024-06-03 02:59:10 [INFO]: Epoch 021 - training loss: 0.3599, validation loss: 0.6548
2024-06-03 02:59:13 [INFO]: Epoch 022 - training loss: 0.3668, validation loss: 0.6345
2024-06-03 02:59:17 [INFO]: Epoch 023 - training loss: 0.3792, validation loss: 0.6622
2024-06-03 02:59:20 [INFO]: Epoch 024 - training loss: 0.3668, validation loss: 0.6489
2024-06-03 02:59:23 [INFO]: Epoch 025 - training loss: 0.3496, validation loss: 0.6385
2024-06-03 02:59:26 [INFO]: Epoch 026 - training loss: 0.3483, validation loss: 0.6358
2024-06-03 02:59:29 [INFO]: Epoch 027 - training loss: 0.3395, validation loss: 0.6438
2024-06-03 02:59:33 [INFO]: Epoch 028 - training loss: 0.3386, validation loss: 0.6431
2024-06-03 02:59:36 [INFO]: Epoch 029 - training loss: 0.3360, validation loss: 0.6306
2024-06-03 02:59:38 [INFO]: Epoch 030 - training loss: 0.3487, validation loss: 0.6294
2024-06-03 02:59:42 [INFO]: Epoch 031 - training loss: 0.3300, validation loss: 0.6343
2024-06-03 02:59:45 [INFO]: Epoch 032 - training loss: 0.3269, validation loss: 0.6366
2024-06-03 02:59:48 [INFO]: Epoch 033 - training loss: 0.3230, validation loss: 0.6410
2024-06-03 02:59:51 [INFO]: Epoch 034 - training loss: 0.3261, validation loss: 0.6176
2024-06-03 02:59:54 [INFO]: Epoch 035 - training loss: 0.3214, validation loss: 0.6280
2024-06-03 02:59:57 [INFO]: Epoch 036 - training loss: 0.3317, validation loss: 0.6343
2024-06-03 03:00:00 [INFO]: Epoch 037 - training loss: 0.3161, validation loss: 0.6186
2024-06-03 03:00:03 [INFO]: Epoch 038 - training loss: 0.3092, validation loss: 0.6337
2024-06-03 03:00:06 [INFO]: Epoch 039 - training loss: 0.3137, validation loss: 0.6155
2024-06-03 03:00:09 [INFO]: Epoch 040 - training loss: 0.3163, validation loss: 0.6189
2024-06-03 03:00:11 [INFO]: Epoch 041 - training loss: 0.3148, validation loss: 0.6348
2024-06-03 03:00:14 [INFO]: Epoch 042 - training loss: 0.3096, validation loss: 0.6491
2024-06-03 03:00:17 [INFO]: Epoch 043 - training loss: 0.3226, validation loss: 0.6286
2024-06-03 03:00:20 [INFO]: Epoch 044 - training loss: 0.3100, validation loss: 0.6259
2024-06-03 03:00:23 [INFO]: Epoch 045 - training loss: 0.3128, validation loss: 0.6183
2024-06-03 03:00:26 [INFO]: Epoch 046 - training loss: 0.3093, validation loss: 0.6230
2024-06-03 03:00:29 [INFO]: Epoch 047 - training loss: 0.3113, validation loss: 0.6222
2024-06-03 03:00:32 [INFO]: Epoch 048 - training loss: 0.3052, validation loss: 0.6309
2024-06-03 03:00:35 [INFO]: Epoch 049 - training loss: 0.2996, validation loss: 0.6156
2024-06-03 03:00:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:00:35 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 03:00:35 [INFO]: Saved the model to results_subseq_rate05/PeMS/FreTS_PeMS/round_2/20240603_T025802/FreTS.pypots
2024-06-03 03:00:36 [INFO]: Successfully saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_2/imputation.pkl
2024-06-03 03:00:36 [INFO]: Round2 - FreTS on PeMS: MAE=0.4698, MSE=0.9033, MRE=0.5552
2024-06-03 03:00:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:00:36 [INFO]: Using the given device: cuda:0
2024-06-03 03:00:36 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_3/20240603_T030036
2024-06-03 03:00:36 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_3/20240603_T030036/tensorboard
2024-06-03 03:00:36 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-03 03:00:39 [INFO]: Epoch 001 - training loss: 1.1127, validation loss: 1.0072
2024-06-03 03:00:42 [INFO]: Epoch 002 - training loss: 0.7326, validation loss: 0.9171
2024-06-03 03:00:45 [INFO]: Epoch 003 - training loss: 0.6512, validation loss: 0.8452
2024-06-03 03:00:48 [INFO]: Epoch 004 - training loss: 0.5884, validation loss: 0.7371
2024-06-03 03:00:51 [INFO]: Epoch 005 - training loss: 0.5456, validation loss: 0.7384
2024-06-03 03:00:54 [INFO]: Epoch 006 - training loss: 0.5277, validation loss: 0.7316
2024-06-03 03:00:57 [INFO]: Epoch 007 - training loss: 0.4904, validation loss: 0.7122
2024-06-03 03:01:00 [INFO]: Epoch 008 - training loss: 0.4821, validation loss: 0.7087
2024-06-03 03:01:03 [INFO]: Epoch 009 - training loss: 0.4666, validation loss: 0.7034
2024-06-03 03:01:05 [INFO]: Epoch 010 - training loss: 0.4545, validation loss: 0.7096
2024-06-03 03:01:08 [INFO]: Epoch 011 - training loss: 0.4605, validation loss: 0.7065
2024-06-03 03:01:11 [INFO]: Epoch 012 - training loss: 0.4329, validation loss: 0.6829
2024-06-03 03:01:14 [INFO]: Epoch 013 - training loss: 0.4108, validation loss: 0.6708
2024-06-03 03:01:17 [INFO]: Epoch 014 - training loss: 0.4119, validation loss: 0.6650
2024-06-03 03:01:20 [INFO]: Epoch 015 - training loss: 0.4332, validation loss: 0.6756
2024-06-03 03:01:23 [INFO]: Epoch 016 - training loss: 0.4182, validation loss: 0.6771
2024-06-03 03:01:26 [INFO]: Epoch 017 - training loss: 0.3982, validation loss: 0.6677
2024-06-03 03:01:29 [INFO]: Epoch 018 - training loss: 0.3762, validation loss: 0.6717
2024-06-03 03:01:32 [INFO]: Epoch 019 - training loss: 0.3848, validation loss: 0.6774
2024-06-03 03:01:35 [INFO]: Epoch 020 - training loss: 0.3785, validation loss: 0.6550
2024-06-03 03:01:38 [INFO]: Epoch 021 - training loss: 0.3728, validation loss: 0.6495
2024-06-03 03:01:41 [INFO]: Epoch 022 - training loss: 0.3778, validation loss: 0.6550
2024-06-03 03:01:45 [INFO]: Epoch 023 - training loss: 0.3714, validation loss: 0.6508
2024-06-03 03:01:48 [INFO]: Epoch 024 - training loss: 0.3720, validation loss: 0.6684
2024-06-03 03:01:50 [INFO]: Epoch 025 - training loss: 0.3605, validation loss: 0.6620
2024-06-03 03:01:53 [INFO]: Epoch 026 - training loss: 0.3514, validation loss: 0.6495
2024-06-03 03:01:56 [INFO]: Epoch 027 - training loss: 0.3570, validation loss: 0.6457
2024-06-03 03:01:59 [INFO]: Epoch 028 - training loss: 0.3435, validation loss: 0.6480
2024-06-03 03:02:02 [INFO]: Epoch 029 - training loss: 0.3364, validation loss: 0.6549
2024-06-03 03:02:05 [INFO]: Epoch 030 - training loss: 0.3309, validation loss: 0.6366
2024-06-03 03:02:08 [INFO]: Epoch 031 - training loss: 0.3430, validation loss: 0.6498
2024-06-03 03:02:11 [INFO]: Epoch 032 - training loss: 0.3348, validation loss: 0.6505
2024-06-03 03:02:14 [INFO]: Epoch 033 - training loss: 0.3262, validation loss: 0.6380
2024-06-03 03:02:17 [INFO]: Epoch 034 - training loss: 0.3290, validation loss: 0.6454
2024-06-03 03:02:20 [INFO]: Epoch 035 - training loss: 0.3292, validation loss: 0.6512
2024-06-03 03:02:23 [INFO]: Epoch 036 - training loss: 0.3259, validation loss: 0.6423
2024-06-03 03:02:26 [INFO]: Epoch 037 - training loss: 0.3308, validation loss: 0.6528
2024-06-03 03:02:29 [INFO]: Epoch 038 - training loss: 0.3410, validation loss: 0.6590
2024-06-03 03:02:32 [INFO]: Epoch 039 - training loss: 0.3329, validation loss: 0.6592
2024-06-03 03:02:34 [INFO]: Epoch 040 - training loss: 0.3276, validation loss: 0.6451
2024-06-03 03:02:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:02:34 [INFO]: Finished training. The best model is from epoch#30.
2024-06-03 03:02:34 [INFO]: Saved the model to results_subseq_rate05/PeMS/FreTS_PeMS/round_3/20240603_T030036/FreTS.pypots
2024-06-03 03:02:36 [INFO]: Successfully saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_3/imputation.pkl
2024-06-03 03:02:36 [INFO]: Round3 - FreTS on PeMS: MAE=0.5136, MSE=0.9712, MRE=0.6069
2024-06-03 03:02:36 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:02:36 [INFO]: Using the given device: cuda:0
2024-06-03 03:02:36 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_4/20240603_T030236
2024-06-03 03:02:36 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_4/20240603_T030236/tensorboard
2024-06-03 03:02:36 [INFO]: FreTS initialized with the given hyperparameters, the number of trainable parameters: 1,715,958
2024-06-03 03:02:39 [INFO]: Epoch 001 - training loss: 1.0795, validation loss: 0.9897
2024-06-03 03:02:42 [INFO]: Epoch 002 - training loss: 0.7255, validation loss: 0.8811
2024-06-03 03:02:44 [INFO]: Epoch 003 - training loss: 0.6224, validation loss: 0.8610
2024-06-03 03:02:47 [INFO]: Epoch 004 - training loss: 0.5678, validation loss: 0.8203
2024-06-03 03:02:50 [INFO]: Epoch 005 - training loss: 0.5460, validation loss: 0.7532
2024-06-03 03:02:53 [INFO]: Epoch 006 - training loss: 0.5145, validation loss: 0.7456
2024-06-03 03:02:56 [INFO]: Epoch 007 - training loss: 0.4856, validation loss: 0.7538
2024-06-03 03:02:59 [INFO]: Epoch 008 - training loss: 0.4836, validation loss: 0.7189
2024-06-03 03:03:02 [INFO]: Epoch 009 - training loss: 0.4946, validation loss: 0.7248
2024-06-03 03:03:05 [INFO]: Epoch 010 - training loss: 0.4580, validation loss: 0.7050
2024-06-03 03:03:08 [INFO]: Epoch 011 - training loss: 0.4498, validation loss: 0.6913
2024-06-03 03:03:11 [INFO]: Epoch 012 - training loss: 0.4358, validation loss: 0.7186
2024-06-03 03:03:14 [INFO]: Epoch 013 - training loss: 0.4370, validation loss: 0.7309
2024-06-03 03:03:17 [INFO]: Epoch 014 - training loss: 0.4334, validation loss: 0.7392
2024-06-03 03:03:20 [INFO]: Epoch 015 - training loss: 0.4128, validation loss: 0.6857
2024-06-03 03:03:23 [INFO]: Epoch 016 - training loss: 0.3971, validation loss: 0.7000
2024-06-03 03:03:26 [INFO]: Epoch 017 - training loss: 0.3999, validation loss: 0.7005
2024-06-03 03:03:29 [INFO]: Epoch 018 - training loss: 0.3993, validation loss: 0.6889
2024-06-03 03:03:32 [INFO]: Epoch 019 - training loss: 0.3802, validation loss: 0.6942
2024-06-03 03:03:35 [INFO]: Epoch 020 - training loss: 0.3844, validation loss: 0.7154
2024-06-03 03:03:37 [INFO]: Epoch 021 - training loss: 0.3803, validation loss: 0.6889
2024-06-03 03:03:40 [INFO]: Epoch 022 - training loss: 0.3855, validation loss: 0.6953
2024-06-03 03:03:43 [INFO]: Epoch 023 - training loss: 0.3742, validation loss: 0.7035
2024-06-03 03:03:46 [INFO]: Epoch 024 - training loss: 0.3630, validation loss: 0.6954
2024-06-03 03:03:49 [INFO]: Epoch 025 - training loss: 0.3694, validation loss: 0.6930
2024-06-03 03:03:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:03:49 [INFO]: Finished training. The best model is from epoch#15.
2024-06-03 03:03:49 [INFO]: Saved the model to results_subseq_rate05/PeMS/FreTS_PeMS/round_4/20240603_T030236/FreTS.pypots
2024-06-03 03:03:50 [INFO]: Successfully saved to results_subseq_rate05/PeMS/FreTS_PeMS/round_4/imputation.pkl
2024-06-03 03:03:50 [INFO]: Round4 - FreTS on PeMS: MAE=0.5382, MSE=1.0313, MRE=0.6360
2024-06-03 03:03:50 [INFO]: Done! Final results:
Averaged FreTS (1,715,958 params) on PeMS: MAE=0.4963 ± 0.025786344703988315, MSE=0.9530 ± 0.04526950986441594, MRE=0.5865 ± 0.030472373007875243, average inference time=0.20
