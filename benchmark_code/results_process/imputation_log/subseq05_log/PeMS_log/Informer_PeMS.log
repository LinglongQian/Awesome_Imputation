2024-06-03 07:12:01 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:12:01 [INFO]: Using the given device: cuda:0
2024-06-03 07:12:01 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_0/20240603_T071201
2024-06-03 07:12:01 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_0/20240603_T071201/tensorboard
2024-06-03 07:12:02 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 07:12:18 [INFO]: Epoch 001 - training loss: 0.8764, validation loss: 0.7407
2024-06-03 07:12:24 [INFO]: Epoch 002 - training loss: 0.5705, validation loss: 0.6615
2024-06-03 07:12:30 [INFO]: Epoch 003 - training loss: 0.5124, validation loss: 0.6131
2024-06-03 07:12:35 [INFO]: Epoch 004 - training loss: 0.4842, validation loss: 0.5904
2024-06-03 07:12:40 [INFO]: Epoch 005 - training loss: 0.4640, validation loss: 0.5861
2024-06-03 07:12:47 [INFO]: Epoch 006 - training loss: 0.4522, validation loss: 0.5758
2024-06-03 07:12:52 [INFO]: Epoch 007 - training loss: 0.4443, validation loss: 0.5664
2024-06-03 07:12:58 [INFO]: Epoch 008 - training loss: 0.4367, validation loss: 0.5699
2024-06-03 07:13:04 [INFO]: Epoch 009 - training loss: 0.4260, validation loss: 0.5767
2024-06-03 07:13:09 [INFO]: Epoch 010 - training loss: 0.4161, validation loss: 0.5691
2024-06-03 07:13:15 [INFO]: Epoch 011 - training loss: 0.4079, validation loss: 0.5656
2024-06-03 07:13:20 [INFO]: Epoch 012 - training loss: 0.4057, validation loss: 0.5667
2024-06-03 07:13:26 [INFO]: Epoch 013 - training loss: 0.3978, validation loss: 0.5646
2024-06-03 07:13:32 [INFO]: Epoch 014 - training loss: 0.3887, validation loss: 0.5547
2024-06-03 07:13:37 [INFO]: Epoch 015 - training loss: 0.3826, validation loss: 0.5622
2024-06-03 07:13:43 [INFO]: Epoch 016 - training loss: 0.3782, validation loss: 0.5574
2024-06-03 07:13:48 [INFO]: Epoch 017 - training loss: 0.3733, validation loss: 0.5662
2024-06-03 07:13:54 [INFO]: Epoch 018 - training loss: 0.3673, validation loss: 0.5639
2024-06-03 07:13:59 [INFO]: Epoch 019 - training loss: 0.3604, validation loss: 0.5571
2024-06-03 07:14:04 [INFO]: Epoch 020 - training loss: 0.3540, validation loss: 0.5608
2024-06-03 07:14:09 [INFO]: Epoch 021 - training loss: 0.3601, validation loss: 0.5470
2024-06-03 07:14:15 [INFO]: Epoch 022 - training loss: 0.3522, validation loss: 0.5482
2024-06-03 07:14:21 [INFO]: Epoch 023 - training loss: 0.3411, validation loss: 0.5495
2024-06-03 07:14:26 [INFO]: Epoch 024 - training loss: 0.3371, validation loss: 0.5407
2024-06-03 07:14:32 [INFO]: Epoch 025 - training loss: 0.3350, validation loss: 0.5473
2024-06-03 07:14:37 [INFO]: Epoch 026 - training loss: 0.3301, validation loss: 0.5437
2024-06-03 07:14:43 [INFO]: Epoch 027 - training loss: 0.3249, validation loss: 0.5402
2024-06-03 07:14:49 [INFO]: Epoch 028 - training loss: 0.3222, validation loss: 0.5395
2024-06-03 07:14:54 [INFO]: Epoch 029 - training loss: 0.3216, validation loss: 0.5406
2024-06-03 07:14:59 [INFO]: Epoch 030 - training loss: 0.3166, validation loss: 0.5395
2024-06-03 07:15:04 [INFO]: Epoch 031 - training loss: 0.3079, validation loss: 0.5325
2024-06-03 07:15:09 [INFO]: Epoch 032 - training loss: 0.3051, validation loss: 0.5342
2024-06-03 07:15:15 [INFO]: Epoch 033 - training loss: 0.2999, validation loss: 0.5382
2024-06-03 07:15:20 [INFO]: Epoch 034 - training loss: 0.2965, validation loss: 0.5355
2024-06-03 07:15:26 [INFO]: Epoch 035 - training loss: 0.2958, validation loss: 0.5403
2024-06-03 07:15:32 [INFO]: Epoch 036 - training loss: 0.2956, validation loss: 0.5402
2024-06-03 07:15:38 [INFO]: Epoch 037 - training loss: 0.2917, validation loss: 0.5336
2024-06-03 07:15:43 [INFO]: Epoch 038 - training loss: 0.2889, validation loss: 0.5377
2024-06-03 07:15:49 [INFO]: Epoch 039 - training loss: 0.2876, validation loss: 0.5366
2024-06-03 07:15:54 [INFO]: Epoch 040 - training loss: 0.2821, validation loss: 0.5372
2024-06-03 07:15:59 [INFO]: Epoch 041 - training loss: 0.2779, validation loss: 0.5380
2024-06-03 07:15:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:15:59 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 07:15:59 [INFO]: Saved the model to results_subseq_rate05/PeMS/Informer_PeMS/round_0/20240603_T071201/Informer.pypots
2024-06-03 07:16:04 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Informer_PeMS/round_0/imputation.pkl
2024-06-03 07:16:04 [INFO]: Round0 - Informer on PeMS: MAE=0.3669, MSE=0.7856, MRE=0.4335
2024-06-03 07:16:04 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 07:16:04 [INFO]: Using the given device: cuda:0
2024-06-03 07:16:04 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_1/20240603_T071604
2024-06-03 07:16:04 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_1/20240603_T071604/tensorboard
2024-06-03 07:16:04 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 07:16:11 [INFO]: Epoch 001 - training loss: 0.8728, validation loss: 0.7136
2024-06-03 07:16:17 [INFO]: Epoch 002 - training loss: 0.5772, validation loss: 0.6577
2024-06-03 07:16:23 [INFO]: Epoch 003 - training loss: 0.5113, validation loss: 0.6093
2024-06-03 07:16:29 [INFO]: Epoch 004 - training loss: 0.4891, validation loss: 0.6201
2024-06-03 07:16:35 [INFO]: Epoch 005 - training loss: 0.4676, validation loss: 0.5774
2024-06-03 07:16:41 [INFO]: Epoch 006 - training loss: 0.4542, validation loss: 0.5847
2024-06-03 07:16:47 [INFO]: Epoch 007 - training loss: 0.4429, validation loss: 0.5799
2024-06-03 07:16:52 [INFO]: Epoch 008 - training loss: 0.4370, validation loss: 0.5716
2024-06-03 07:16:56 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.5672
2024-06-03 07:17:02 [INFO]: Epoch 010 - training loss: 0.4151, validation loss: 0.5727
2024-06-03 07:17:07 [INFO]: Epoch 011 - training loss: 0.4086, validation loss: 0.5607
2024-06-03 07:17:12 [INFO]: Epoch 012 - training loss: 0.4029, validation loss: 0.5645
2024-06-03 07:17:17 [INFO]: Epoch 013 - training loss: 0.3916, validation loss: 0.5699
2024-06-03 07:17:22 [INFO]: Epoch 014 - training loss: 0.3870, validation loss: 0.5624
2024-06-03 07:17:27 [INFO]: Epoch 015 - training loss: 0.3834, validation loss: 0.5660
2024-06-03 07:17:32 [INFO]: Epoch 016 - training loss: 0.3854, validation loss: 0.5654
2024-06-03 07:17:38 [INFO]: Epoch 017 - training loss: 0.3781, validation loss: 0.5600
2024-06-03 07:17:43 [INFO]: Epoch 018 - training loss: 0.3668, validation loss: 0.5610
2024-06-03 07:17:48 [INFO]: Epoch 019 - training loss: 0.3595, validation loss: 0.5603
2024-06-03 07:17:53 [INFO]: Epoch 020 - training loss: 0.3555, validation loss: 0.5568
2024-06-03 07:17:58 [INFO]: Epoch 021 - training loss: 0.3568, validation loss: 0.5679
2024-06-03 07:18:03 [INFO]: Epoch 022 - training loss: 0.3459, validation loss: 0.5581
2024-06-03 07:18:09 [INFO]: Epoch 023 - training loss: 0.3457, validation loss: 0.5534
2024-06-03 07:18:13 [INFO]: Epoch 024 - training loss: 0.3389, validation loss: 0.5558
2024-06-03 07:18:18 [INFO]: Epoch 025 - training loss: 0.3319, validation loss: 0.5548
2024-06-03 07:18:23 [INFO]: Epoch 026 - training loss: 0.3275, validation loss: 0.5522
2024-06-03 07:18:29 [INFO]: Epoch 027 - training loss: 0.3223, validation loss: 0.5520
2024-06-03 07:18:33 [INFO]: Epoch 028 - training loss: 0.3218, validation loss: 0.5560
2024-06-03 07:18:39 [INFO]: Epoch 029 - training loss: 0.3164, validation loss: 0.5526
2024-06-03 07:18:44 [INFO]: Epoch 030 - training loss: 0.3123, validation loss: 0.5464
2024-06-03 07:18:49 [INFO]: Epoch 031 - training loss: 0.3091, validation loss: 0.5497
2024-06-03 07:18:54 [INFO]: Epoch 032 - training loss: 0.3124, validation loss: 0.5504
2024-06-03 07:18:59 [INFO]: Epoch 033 - training loss: 0.3043, validation loss: 0.5440
2024-06-03 07:19:04 [INFO]: Epoch 034 - training loss: 0.2972, validation loss: 0.5452
2024-06-03 07:19:09 [INFO]: Epoch 035 - training loss: 0.2963, validation loss: 0.5461
2024-06-03 07:19:14 [INFO]: Epoch 036 - training loss: 0.2967, validation loss: 0.5408
2024-06-03 07:19:19 [INFO]: Epoch 037 - training loss: 0.2946, validation loss: 0.5492
2024-06-03 07:19:24 [INFO]: Epoch 038 - training loss: 0.2884, validation loss: 0.5451
2024-06-03 07:19:29 [INFO]: Epoch 039 - training loss: 0.2863, validation loss: 0.5503
2024-06-03 07:19:34 [INFO]: Epoch 040 - training loss: 0.2837, validation loss: 0.5448
2024-06-03 07:19:39 [INFO]: Epoch 041 - training loss: 0.2804, validation loss: 0.5469
2024-06-03 07:19:44 [INFO]: Epoch 042 - training loss: 0.2787, validation loss: 0.5482
2024-06-03 07:19:48 [INFO]: Epoch 043 - training loss: 0.2796, validation loss: 0.5458
2024-06-03 07:19:51 [INFO]: Epoch 044 - training loss: 0.2773, validation loss: 0.5482
2024-06-03 07:19:53 [INFO]: Epoch 045 - training loss: 0.2755, validation loss: 0.5470
2024-06-03 07:19:56 [INFO]: Epoch 046 - training loss: 0.2745, validation loss: 0.5373
2024-06-03 07:19:58 [INFO]: Epoch 047 - training loss: 0.2757, validation loss: 0.5484
2024-06-03 07:20:00 [INFO]: Epoch 048 - training loss: 0.2781, validation loss: 0.5398
2024-06-03 07:20:02 [INFO]: Epoch 049 - training loss: 0.2755, validation loss: 0.5477
2024-06-03 07:20:05 [INFO]: Epoch 050 - training loss: 0.2723, validation loss: 0.5405
2024-06-03 07:20:07 [INFO]: Epoch 051 - training loss: 0.2655, validation loss: 0.5405
2024-06-03 07:20:09 [INFO]: Epoch 052 - training loss: 0.2645, validation loss: 0.5397
2024-06-03 07:20:12 [INFO]: Epoch 053 - training loss: 0.2615, validation loss: 0.5417
2024-06-03 07:20:14 [INFO]: Epoch 054 - training loss: 0.2605, validation loss: 0.5432
2024-06-03 07:20:16 [INFO]: Epoch 055 - training loss: 0.2668, validation loss: 0.5373
2024-06-03 07:20:19 [INFO]: Epoch 056 - training loss: 0.2637, validation loss: 0.5361
2024-06-03 07:20:21 [INFO]: Epoch 057 - training loss: 0.2576, validation loss: 0.5399
2024-06-03 07:20:23 [INFO]: Epoch 058 - training loss: 0.2589, validation loss: 0.5338
2024-06-03 07:20:25 [INFO]: Epoch 059 - training loss: 0.2556, validation loss: 0.5349
2024-06-03 07:20:27 [INFO]: Epoch 060 - training loss: 0.2538, validation loss: 0.5366
2024-06-03 07:20:30 [INFO]: Epoch 061 - training loss: 0.2528, validation loss: 0.5413
2024-06-03 07:20:32 [INFO]: Epoch 062 - training loss: 0.2491, validation loss: 0.5380
2024-06-03 07:20:34 [INFO]: Epoch 063 - training loss: 0.2508, validation loss: 0.5388
2024-06-03 07:20:36 [INFO]: Epoch 064 - training loss: 0.2483, validation loss: 0.5403
2024-06-03 07:20:39 [INFO]: Epoch 065 - training loss: 0.2481, validation loss: 0.5390
2024-06-03 07:20:41 [INFO]: Epoch 066 - training loss: 0.2474, validation loss: 0.5364
2024-06-03 07:20:43 [INFO]: Epoch 067 - training loss: 0.2466, validation loss: 0.5386
2024-06-03 07:20:45 [INFO]: Epoch 068 - training loss: 0.2518, validation loss: 0.5387
2024-06-03 07:20:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:20:45 [INFO]: Finished training. The best model is from epoch#58.
2024-06-03 07:20:46 [INFO]: Saved the model to results_subseq_rate05/PeMS/Informer_PeMS/round_1/20240603_T071604/Informer.pypots
2024-06-03 07:20:47 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Informer_PeMS/round_1/imputation.pkl
2024-06-03 07:20:47 [INFO]: Round1 - Informer on PeMS: MAE=0.3735, MSE=0.7876, MRE=0.4414
2024-06-03 07:20:47 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 07:20:47 [INFO]: Using the given device: cuda:0
2024-06-03 07:20:47 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_2/20240603_T072047
2024-06-03 07:20:47 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_2/20240603_T072047/tensorboard
2024-06-03 07:20:48 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 07:20:50 [INFO]: Epoch 001 - training loss: 0.8766, validation loss: 0.7326
2024-06-03 07:20:52 [INFO]: Epoch 002 - training loss: 0.5722, validation loss: 0.6420
2024-06-03 07:20:55 [INFO]: Epoch 003 - training loss: 0.5231, validation loss: 0.6207
2024-06-03 07:20:57 [INFO]: Epoch 004 - training loss: 0.4868, validation loss: 0.5994
2024-06-03 07:20:59 [INFO]: Epoch 005 - training loss: 0.4678, validation loss: 0.5900
2024-06-03 07:21:02 [INFO]: Epoch 006 - training loss: 0.4547, validation loss: 0.5839
2024-06-03 07:21:04 [INFO]: Epoch 007 - training loss: 0.4451, validation loss: 0.5942
2024-06-03 07:21:06 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.5776
2024-06-03 07:21:08 [INFO]: Epoch 009 - training loss: 0.4260, validation loss: 0.5748
2024-06-03 07:21:11 [INFO]: Epoch 010 - training loss: 0.4154, validation loss: 0.5628
2024-06-03 07:21:13 [INFO]: Epoch 011 - training loss: 0.4090, validation loss: 0.5625
2024-06-03 07:21:16 [INFO]: Epoch 012 - training loss: 0.4038, validation loss: 0.5635
2024-06-03 07:21:18 [INFO]: Epoch 013 - training loss: 0.4023, validation loss: 0.5584
2024-06-03 07:21:21 [INFO]: Epoch 014 - training loss: 0.3961, validation loss: 0.5559
2024-06-03 07:21:23 [INFO]: Epoch 015 - training loss: 0.3839, validation loss: 0.5582
2024-06-03 07:21:26 [INFO]: Epoch 016 - training loss: 0.3805, validation loss: 0.5540
2024-06-03 07:21:28 [INFO]: Epoch 017 - training loss: 0.3746, validation loss: 0.5522
2024-06-03 07:21:30 [INFO]: Epoch 018 - training loss: 0.3698, validation loss: 0.5532
2024-06-03 07:21:32 [INFO]: Epoch 019 - training loss: 0.3629, validation loss: 0.5534
2024-06-03 07:21:35 [INFO]: Epoch 020 - training loss: 0.3591, validation loss: 0.5463
2024-06-03 07:21:37 [INFO]: Epoch 021 - training loss: 0.3561, validation loss: 0.5525
2024-06-03 07:21:39 [INFO]: Epoch 022 - training loss: 0.3495, validation loss: 0.5503
2024-06-03 07:21:42 [INFO]: Epoch 023 - training loss: 0.3422, validation loss: 0.5411
2024-06-03 07:21:44 [INFO]: Epoch 024 - training loss: 0.3418, validation loss: 0.5483
2024-06-03 07:21:47 [INFO]: Epoch 025 - training loss: 0.3344, validation loss: 0.5433
2024-06-03 07:21:49 [INFO]: Epoch 026 - training loss: 0.3273, validation loss: 0.5501
2024-06-03 07:21:52 [INFO]: Epoch 027 - training loss: 0.3223, validation loss: 0.5398
2024-06-03 07:21:54 [INFO]: Epoch 028 - training loss: 0.3219, validation loss: 0.5433
2024-06-03 07:21:56 [INFO]: Epoch 029 - training loss: 0.3212, validation loss: 0.5420
2024-06-03 07:21:59 [INFO]: Epoch 030 - training loss: 0.3122, validation loss: 0.5508
2024-06-03 07:22:01 [INFO]: Epoch 031 - training loss: 0.3114, validation loss: 0.5450
2024-06-03 07:22:03 [INFO]: Epoch 032 - training loss: 0.3094, validation loss: 0.5440
2024-06-03 07:22:05 [INFO]: Epoch 033 - training loss: 0.3017, validation loss: 0.5425
2024-06-03 07:22:08 [INFO]: Epoch 034 - training loss: 0.3024, validation loss: 0.5391
2024-06-03 07:22:10 [INFO]: Epoch 035 - training loss: 0.2953, validation loss: 0.5384
2024-06-03 07:22:12 [INFO]: Epoch 036 - training loss: 0.2916, validation loss: 0.5356
2024-06-03 07:22:15 [INFO]: Epoch 037 - training loss: 0.2898, validation loss: 0.5399
2024-06-03 07:22:17 [INFO]: Epoch 038 - training loss: 0.2875, validation loss: 0.5382
2024-06-03 07:22:19 [INFO]: Epoch 039 - training loss: 0.2951, validation loss: 0.5355
2024-06-03 07:22:22 [INFO]: Epoch 040 - training loss: 0.2883, validation loss: 0.5425
2024-06-03 07:22:25 [INFO]: Epoch 041 - training loss: 0.2796, validation loss: 0.5344
2024-06-03 07:22:27 [INFO]: Epoch 042 - training loss: 0.2782, validation loss: 0.5376
2024-06-03 07:22:29 [INFO]: Epoch 043 - training loss: 0.2764, validation loss: 0.5398
2024-06-03 07:22:32 [INFO]: Epoch 044 - training loss: 0.2751, validation loss: 0.5354
2024-06-03 07:22:34 [INFO]: Epoch 045 - training loss: 0.2727, validation loss: 0.5343
2024-06-03 07:22:37 [INFO]: Epoch 046 - training loss: 0.2723, validation loss: 0.5360
2024-06-03 07:22:39 [INFO]: Epoch 047 - training loss: 0.2734, validation loss: 0.5434
2024-06-03 07:22:41 [INFO]: Epoch 048 - training loss: 0.2678, validation loss: 0.5371
2024-06-03 07:22:43 [INFO]: Epoch 049 - training loss: 0.2741, validation loss: 0.5324
2024-06-03 07:22:46 [INFO]: Epoch 050 - training loss: 0.2651, validation loss: 0.5362
2024-06-03 07:22:48 [INFO]: Epoch 051 - training loss: 0.2682, validation loss: 0.5335
2024-06-03 07:22:50 [INFO]: Epoch 052 - training loss: 0.2653, validation loss: 0.5331
2024-06-03 07:22:53 [INFO]: Epoch 053 - training loss: 0.2628, validation loss: 0.5388
2024-06-03 07:22:55 [INFO]: Epoch 054 - training loss: 0.2591, validation loss: 0.5393
2024-06-03 07:22:57 [INFO]: Epoch 055 - training loss: 0.2601, validation loss: 0.5359
2024-06-03 07:23:00 [INFO]: Epoch 056 - training loss: 0.2593, validation loss: 0.5344
2024-06-03 07:23:02 [INFO]: Epoch 057 - training loss: 0.2562, validation loss: 0.5357
2024-06-03 07:23:04 [INFO]: Epoch 058 - training loss: 0.2603, validation loss: 0.5338
2024-06-03 07:23:06 [INFO]: Epoch 059 - training loss: 0.2588, validation loss: 0.5352
2024-06-03 07:23:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:23:06 [INFO]: Finished training. The best model is from epoch#49.
2024-06-03 07:23:06 [INFO]: Saved the model to results_subseq_rate05/PeMS/Informer_PeMS/round_2/20240603_T072047/Informer.pypots
2024-06-03 07:23:08 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Informer_PeMS/round_2/imputation.pkl
2024-06-03 07:23:08 [INFO]: Round2 - Informer on PeMS: MAE=0.3691, MSE=0.7819, MRE=0.4362
2024-06-03 07:23:08 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 07:23:08 [INFO]: Using the given device: cuda:0
2024-06-03 07:23:08 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_3/20240603_T072308
2024-06-03 07:23:08 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_3/20240603_T072308/tensorboard
2024-06-03 07:23:08 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 07:23:11 [INFO]: Epoch 001 - training loss: 0.8773, validation loss: 0.7139
2024-06-03 07:23:13 [INFO]: Epoch 002 - training loss: 0.5739, validation loss: 0.6493
2024-06-03 07:23:16 [INFO]: Epoch 003 - training loss: 0.5159, validation loss: 0.6114
2024-06-03 07:23:18 [INFO]: Epoch 004 - training loss: 0.4832, validation loss: 0.5981
2024-06-03 07:23:20 [INFO]: Epoch 005 - training loss: 0.4679, validation loss: 0.5832
2024-06-03 07:23:22 [INFO]: Epoch 006 - training loss: 0.4546, validation loss: 0.5842
2024-06-03 07:23:24 [INFO]: Epoch 007 - training loss: 0.4447, validation loss: 0.5767
2024-06-03 07:23:26 [INFO]: Epoch 008 - training loss: 0.4334, validation loss: 0.5767
2024-06-03 07:23:28 [INFO]: Epoch 009 - training loss: 0.4251, validation loss: 0.5719
2024-06-03 07:23:30 [INFO]: Epoch 010 - training loss: 0.4184, validation loss: 0.5665
2024-06-03 07:23:33 [INFO]: Epoch 011 - training loss: 0.4091, validation loss: 0.5683
2024-06-03 07:23:35 [INFO]: Epoch 012 - training loss: 0.3995, validation loss: 0.5589
2024-06-03 07:23:37 [INFO]: Epoch 013 - training loss: 0.3951, validation loss: 0.5596
2024-06-03 07:23:39 [INFO]: Epoch 014 - training loss: 0.3917, validation loss: 0.5685
2024-06-03 07:23:42 [INFO]: Epoch 015 - training loss: 0.3821, validation loss: 0.5588
2024-06-03 07:23:44 [INFO]: Epoch 016 - training loss: 0.3781, validation loss: 0.5617
2024-06-03 07:23:47 [INFO]: Epoch 017 - training loss: 0.3769, validation loss: 0.5578
2024-06-03 07:23:49 [INFO]: Epoch 018 - training loss: 0.3711, validation loss: 0.5592
2024-06-03 07:23:51 [INFO]: Epoch 019 - training loss: 0.3641, validation loss: 0.5574
2024-06-03 07:23:53 [INFO]: Epoch 020 - training loss: 0.3577, validation loss: 0.5558
2024-06-03 07:23:56 [INFO]: Epoch 021 - training loss: 0.3520, validation loss: 0.5483
2024-06-03 07:23:58 [INFO]: Epoch 022 - training loss: 0.3501, validation loss: 0.5471
2024-06-03 07:24:01 [INFO]: Epoch 023 - training loss: 0.3425, validation loss: 0.5580
2024-06-03 07:24:03 [INFO]: Epoch 024 - training loss: 0.3363, validation loss: 0.5464
2024-06-03 07:24:06 [INFO]: Epoch 025 - training loss: 0.3359, validation loss: 0.5520
2024-06-03 07:24:08 [INFO]: Epoch 026 - training loss: 0.3351, validation loss: 0.5392
2024-06-03 07:24:10 [INFO]: Epoch 027 - training loss: 0.3262, validation loss: 0.5538
2024-06-03 07:24:13 [INFO]: Epoch 028 - training loss: 0.3182, validation loss: 0.5380
2024-06-03 07:24:15 [INFO]: Epoch 029 - training loss: 0.3159, validation loss: 0.5410
2024-06-03 07:24:17 [INFO]: Epoch 030 - training loss: 0.3105, validation loss: 0.5406
2024-06-03 07:24:19 [INFO]: Epoch 031 - training loss: 0.3108, validation loss: 0.5402
2024-06-03 07:24:22 [INFO]: Epoch 032 - training loss: 0.3122, validation loss: 0.5521
2024-06-03 07:24:25 [INFO]: Epoch 033 - training loss: 0.3049, validation loss: 0.5378
2024-06-03 07:24:27 [INFO]: Epoch 034 - training loss: 0.2991, validation loss: 0.5383
2024-06-03 07:24:29 [INFO]: Epoch 035 - training loss: 0.3020, validation loss: 0.5434
2024-06-03 07:24:32 [INFO]: Epoch 036 - training loss: 0.2996, validation loss: 0.5395
2024-06-03 07:24:34 [INFO]: Epoch 037 - training loss: 0.2970, validation loss: 0.5342
2024-06-03 07:24:36 [INFO]: Epoch 038 - training loss: 0.2900, validation loss: 0.5366
2024-06-03 07:24:39 [INFO]: Epoch 039 - training loss: 0.2895, validation loss: 0.5437
2024-06-03 07:24:41 [INFO]: Epoch 040 - training loss: 0.2844, validation loss: 0.5389
2024-06-03 07:24:43 [INFO]: Epoch 041 - training loss: 0.2808, validation loss: 0.5445
2024-06-03 07:24:46 [INFO]: Epoch 042 - training loss: 0.2800, validation loss: 0.5380
2024-06-03 07:24:48 [INFO]: Epoch 043 - training loss: 0.2770, validation loss: 0.5418
2024-06-03 07:24:50 [INFO]: Epoch 044 - training loss: 0.2738, validation loss: 0.5422
2024-06-03 07:24:53 [INFO]: Epoch 045 - training loss: 0.2769, validation loss: 0.5356
2024-06-03 07:24:55 [INFO]: Epoch 046 - training loss: 0.2733, validation loss: 0.5436
2024-06-03 07:24:58 [INFO]: Epoch 047 - training loss: 0.2725, validation loss: 0.5355
2024-06-03 07:24:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:24:58 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 07:24:58 [INFO]: Saved the model to results_subseq_rate05/PeMS/Informer_PeMS/round_3/20240603_T072308/Informer.pypots
2024-06-03 07:25:00 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Informer_PeMS/round_3/imputation.pkl
2024-06-03 07:25:00 [INFO]: Round3 - Informer on PeMS: MAE=0.3689, MSE=0.7843, MRE=0.4360
2024-06-03 07:25:00 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 07:25:00 [INFO]: Using the given device: cuda:0
2024-06-03 07:25:00 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_4/20240603_T072500
2024-06-03 07:25:00 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/Informer_PeMS/round_4/20240603_T072500/tensorboard
2024-06-03 07:25:00 [INFO]: Informer initialized with the given hyperparameters, the number of trainable parameters: 13,149,022
2024-06-03 07:25:03 [INFO]: Epoch 001 - training loss: 0.8826, validation loss: 0.7141
2024-06-03 07:25:05 [INFO]: Epoch 002 - training loss: 0.5775, validation loss: 0.6589
2024-06-03 07:25:07 [INFO]: Epoch 003 - training loss: 0.5164, validation loss: 0.6081
2024-06-03 07:25:10 [INFO]: Epoch 004 - training loss: 0.4842, validation loss: 0.5906
2024-06-03 07:25:12 [INFO]: Epoch 005 - training loss: 0.4661, validation loss: 0.5792
2024-06-03 07:25:15 [INFO]: Epoch 006 - training loss: 0.4538, validation loss: 0.5760
2024-06-03 07:25:17 [INFO]: Epoch 007 - training loss: 0.4420, validation loss: 0.5765
2024-06-03 07:25:19 [INFO]: Epoch 008 - training loss: 0.4324, validation loss: 0.5839
2024-06-03 07:25:22 [INFO]: Epoch 009 - training loss: 0.4252, validation loss: 0.5639
2024-06-03 07:25:24 [INFO]: Epoch 010 - training loss: 0.4145, validation loss: 0.5651
2024-06-03 07:25:27 [INFO]: Epoch 011 - training loss: 0.4089, validation loss: 0.5781
2024-06-03 07:25:29 [INFO]: Epoch 012 - training loss: 0.3984, validation loss: 0.5663
2024-06-03 07:25:31 [INFO]: Epoch 013 - training loss: 0.3929, validation loss: 0.5611
2024-06-03 07:25:33 [INFO]: Epoch 014 - training loss: 0.3851, validation loss: 0.5578
2024-06-03 07:25:36 [INFO]: Epoch 015 - training loss: 0.3809, validation loss: 0.5566
2024-06-03 07:25:38 [INFO]: Epoch 016 - training loss: 0.3723, validation loss: 0.5568
2024-06-03 07:25:41 [INFO]: Epoch 017 - training loss: 0.3704, validation loss: 0.5615
2024-06-03 07:25:43 [INFO]: Epoch 018 - training loss: 0.3671, validation loss: 0.5609
2024-06-03 07:25:45 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.5534
2024-06-03 07:25:47 [INFO]: Epoch 020 - training loss: 0.3537, validation loss: 0.5529
2024-06-03 07:25:50 [INFO]: Epoch 021 - training loss: 0.3517, validation loss: 0.5503
2024-06-03 07:25:52 [INFO]: Epoch 022 - training loss: 0.3451, validation loss: 0.5527
2024-06-03 07:25:55 [INFO]: Epoch 023 - training loss: 0.3425, validation loss: 0.5410
2024-06-03 07:25:57 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.5480
2024-06-03 07:25:59 [INFO]: Epoch 025 - training loss: 0.3302, validation loss: 0.5546
2024-06-03 07:26:01 [INFO]: Epoch 026 - training loss: 0.3397, validation loss: 0.5453
2024-06-03 07:26:03 [INFO]: Epoch 027 - training loss: 0.3260, validation loss: 0.5455
2024-06-03 07:26:06 [INFO]: Epoch 028 - training loss: 0.3186, validation loss: 0.5483
2024-06-03 07:26:08 [INFO]: Epoch 029 - training loss: 0.3178, validation loss: 0.5420
2024-06-03 07:26:10 [INFO]: Epoch 030 - training loss: 0.3094, validation loss: 0.5434
2024-06-03 07:26:12 [INFO]: Epoch 031 - training loss: 0.3042, validation loss: 0.5474
2024-06-03 07:26:15 [INFO]: Epoch 032 - training loss: 0.3051, validation loss: 0.5519
2024-06-03 07:26:17 [INFO]: Epoch 033 - training loss: 0.2984, validation loss: 0.5443
2024-06-03 07:26:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:26:17 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 07:26:17 [INFO]: Saved the model to results_subseq_rate05/PeMS/Informer_PeMS/round_4/20240603_T072500/Informer.pypots
2024-06-03 07:26:19 [INFO]: Successfully saved to results_subseq_rate05/PeMS/Informer_PeMS/round_4/imputation.pkl
2024-06-03 07:26:19 [INFO]: Round4 - Informer on PeMS: MAE=0.3669, MSE=0.7906, MRE=0.4336
2024-06-03 07:26:19 [INFO]: Done! Final results:
Averaged Informer (13,149,022 params) on PeMS: MAE=0.3691 ± 0.002415791563206935, MSE=0.7860 ± 0.002930880730240932, MRE=0.4361 ± 0.0028548017358944995, average inference time=0.43
