2024-06-03 02:53:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 02:53:54 [INFO]: Using the given device: cuda:0
2024-06-03 02:53:54 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T025354
2024-06-03 02:53:54 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T025354/tensorboard
2024-06-03 02:53:55 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 02:54:04 [INFO]: Epoch 001 - training loss: 1.7469, validation loss: 1.0610
2024-06-03 02:54:10 [INFO]: Epoch 002 - training loss: 0.8666, validation loss: 0.8004
2024-06-03 02:54:18 [INFO]: Epoch 003 - training loss: 0.6408, validation loss: 0.7564
2024-06-03 02:54:26 [INFO]: Epoch 004 - training loss: 0.5762, validation loss: 0.7276
2024-06-03 02:54:33 [INFO]: Epoch 005 - training loss: 0.5425, validation loss: 0.7446
2024-06-03 02:54:40 [INFO]: Epoch 006 - training loss: 0.5101, validation loss: 0.7223
2024-06-03 02:54:48 [INFO]: Epoch 007 - training loss: 0.4982, validation loss: 0.7176
2024-06-03 02:54:55 [INFO]: Epoch 008 - training loss: 0.4834, validation loss: 0.7188
2024-06-03 02:55:01 [INFO]: Epoch 009 - training loss: 0.4742, validation loss: 0.7066
2024-06-03 02:55:08 [INFO]: Epoch 010 - training loss: 0.4628, validation loss: 0.7080
2024-06-03 02:55:15 [INFO]: Epoch 011 - training loss: 0.4467, validation loss: 0.6926
2024-06-03 02:55:23 [INFO]: Epoch 012 - training loss: 0.4339, validation loss: 0.6746
2024-06-03 02:55:30 [INFO]: Epoch 013 - training loss: 0.4350, validation loss: 0.6640
2024-06-03 02:55:38 [INFO]: Epoch 014 - training loss: 0.4285, validation loss: 0.6541
2024-06-03 02:55:45 [INFO]: Epoch 015 - training loss: 0.4284, validation loss: 0.6830
2024-06-03 02:55:52 [INFO]: Epoch 016 - training loss: 0.4208, validation loss: 0.6534
2024-06-03 02:55:58 [INFO]: Epoch 017 - training loss: 0.4124, validation loss: 0.6774
2024-06-03 02:56:06 [INFO]: Epoch 018 - training loss: 0.4036, validation loss: 0.6470
2024-06-03 02:56:14 [INFO]: Epoch 019 - training loss: 0.4071, validation loss: 0.6467
2024-06-03 02:56:21 [INFO]: Epoch 020 - training loss: 0.4122, validation loss: 0.6463
2024-06-03 02:56:29 [INFO]: Epoch 021 - training loss: 0.4020, validation loss: 0.6546
2024-06-03 02:56:36 [INFO]: Epoch 022 - training loss: 0.3987, validation loss: 0.6518
2024-06-03 02:56:42 [INFO]: Epoch 023 - training loss: 0.3916, validation loss: 0.6600
2024-06-03 02:56:48 [INFO]: Epoch 024 - training loss: 0.3938, validation loss: 0.6493
2024-06-03 02:56:56 [INFO]: Epoch 025 - training loss: 0.3904, validation loss: 0.6455
2024-06-03 02:57:03 [INFO]: Epoch 026 - training loss: 0.3888, validation loss: 0.6389
2024-06-03 02:57:11 [INFO]: Epoch 027 - training loss: 0.3881, validation loss: 0.6459
2024-06-03 02:57:18 [INFO]: Epoch 028 - training loss: 0.3805, validation loss: 0.6448
2024-06-03 02:57:25 [INFO]: Epoch 029 - training loss: 0.3839, validation loss: 0.6447
2024-06-03 02:57:33 [INFO]: Epoch 030 - training loss: 0.3787, validation loss: 0.6472
2024-06-03 02:57:39 [INFO]: Epoch 031 - training loss: 0.3794, validation loss: 0.6476
2024-06-03 02:57:46 [INFO]: Epoch 032 - training loss: 0.3780, validation loss: 0.6507
2024-06-03 02:57:53 [INFO]: Epoch 033 - training loss: 0.3840, validation loss: 0.6371
2024-06-03 02:58:01 [INFO]: Epoch 034 - training loss: 0.3762, validation loss: 0.6449
2024-06-03 02:58:08 [INFO]: Epoch 035 - training loss: 0.3760, validation loss: 0.6340
2024-06-03 02:58:15 [INFO]: Epoch 036 - training loss: 0.3752, validation loss: 0.6514
2024-06-03 02:58:23 [INFO]: Epoch 037 - training loss: 0.3792, validation loss: 0.6273
2024-06-03 02:58:29 [INFO]: Epoch 038 - training loss: 0.3800, validation loss: 0.6444
2024-06-03 02:58:36 [INFO]: Epoch 039 - training loss: 0.3842, validation loss: 0.6389
2024-06-03 02:58:44 [INFO]: Epoch 040 - training loss: 0.3737, validation loss: 0.6439
2024-06-03 02:58:52 [INFO]: Epoch 041 - training loss: 0.3770, validation loss: 0.6491
2024-06-03 02:58:59 [INFO]: Epoch 042 - training loss: 0.3695, validation loss: 0.6550
2024-06-03 02:59:07 [INFO]: Epoch 043 - training loss: 0.3695, validation loss: 0.6446
2024-06-03 02:59:14 [INFO]: Epoch 044 - training loss: 0.3713, validation loss: 0.6416
2024-06-03 02:59:20 [INFO]: Epoch 045 - training loss: 0.3680, validation loss: 0.6404
2024-06-03 02:59:27 [INFO]: Epoch 046 - training loss: 0.3670, validation loss: 0.6318
2024-06-03 02:59:34 [INFO]: Epoch 047 - training loss: 0.3660, validation loss: 0.6412
2024-06-03 02:59:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 02:59:34 [INFO]: Finished training. The best model is from epoch#37.
2024-06-03 02:59:34 [INFO]: Saved the model to results_subseq_rate05/PeMS/ETSformer_PeMS/round_0/20240603_T025354/ETSformer.pypots
2024-06-03 02:59:40 [INFO]: Successfully saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_0/imputation.pkl
2024-06-03 02:59:40 [INFO]: Round0 - ETSformer on PeMS: MAE=0.4914, MSE=0.9081, MRE=0.5807
2024-06-03 02:59:40 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 02:59:40 [INFO]: Using the given device: cuda:0
2024-06-03 02:59:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T025940
2024-06-03 02:59:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T025940/tensorboard
2024-06-03 02:59:40 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 02:59:48 [INFO]: Epoch 001 - training loss: 2.3747, validation loss: 1.1851
2024-06-03 02:59:55 [INFO]: Epoch 002 - training loss: 1.0216, validation loss: 0.8133
2024-06-03 03:00:01 [INFO]: Epoch 003 - training loss: 0.7293, validation loss: 0.7615
2024-06-03 03:00:08 [INFO]: Epoch 004 - training loss: 0.6482, validation loss: 0.7367
2024-06-03 03:00:13 [INFO]: Epoch 005 - training loss: 0.6007, validation loss: 0.7263
2024-06-03 03:00:19 [INFO]: Epoch 006 - training loss: 0.5491, validation loss: 0.7144
2024-06-03 03:00:26 [INFO]: Epoch 007 - training loss: 0.5228, validation loss: 0.7213
2024-06-03 03:00:33 [INFO]: Epoch 008 - training loss: 0.5013, validation loss: 0.6788
2024-06-03 03:00:40 [INFO]: Epoch 009 - training loss: 0.4864, validation loss: 0.6733
2024-06-03 03:00:46 [INFO]: Epoch 010 - training loss: 0.4753, validation loss: 0.6723
2024-06-03 03:00:53 [INFO]: Epoch 011 - training loss: 0.4682, validation loss: 0.6750
2024-06-03 03:01:00 [INFO]: Epoch 012 - training loss: 0.4561, validation loss: 0.6683
2024-06-03 03:01:05 [INFO]: Epoch 013 - training loss: 0.4534, validation loss: 0.6776
2024-06-03 03:01:11 [INFO]: Epoch 014 - training loss: 0.4398, validation loss: 0.6619
2024-06-03 03:01:18 [INFO]: Epoch 015 - training loss: 0.4456, validation loss: 0.6630
2024-06-03 03:01:25 [INFO]: Epoch 016 - training loss: 0.4449, validation loss: 0.6647
2024-06-03 03:01:32 [INFO]: Epoch 017 - training loss: 0.4332, validation loss: 0.6466
2024-06-03 03:01:38 [INFO]: Epoch 018 - training loss: 0.4248, validation loss: 0.6550
2024-06-03 03:01:46 [INFO]: Epoch 019 - training loss: 0.4209, validation loss: 0.6448
2024-06-03 03:01:52 [INFO]: Epoch 020 - training loss: 0.4101, validation loss: 0.6618
2024-06-03 03:01:58 [INFO]: Epoch 021 - training loss: 0.4049, validation loss: 0.6425
2024-06-03 03:02:05 [INFO]: Epoch 022 - training loss: 0.4106, validation loss: 0.6422
2024-06-03 03:02:12 [INFO]: Epoch 023 - training loss: 0.4147, validation loss: 0.6427
2024-06-03 03:02:19 [INFO]: Epoch 024 - training loss: 0.4010, validation loss: 0.6422
2024-06-03 03:02:25 [INFO]: Epoch 025 - training loss: 0.3940, validation loss: 0.6508
2024-06-03 03:02:32 [INFO]: Epoch 026 - training loss: 0.3936, validation loss: 0.6469
2024-06-03 03:02:39 [INFO]: Epoch 027 - training loss: 0.3910, validation loss: 0.6473
2024-06-03 03:02:45 [INFO]: Epoch 028 - training loss: 0.3913, validation loss: 0.6455
2024-06-03 03:02:51 [INFO]: Epoch 029 - training loss: 0.3922, validation loss: 0.6344
2024-06-03 03:02:57 [INFO]: Epoch 030 - training loss: 0.3903, validation loss: 0.6479
2024-06-03 03:03:04 [INFO]: Epoch 031 - training loss: 0.3899, validation loss: 0.6440
2024-06-03 03:03:11 [INFO]: Epoch 032 - training loss: 0.3865, validation loss: 0.6379
2024-06-03 03:03:18 [INFO]: Epoch 033 - training loss: 0.3805, validation loss: 0.6433
2024-06-03 03:03:25 [INFO]: Epoch 034 - training loss: 0.3786, validation loss: 0.6385
2024-06-03 03:03:31 [INFO]: Epoch 035 - training loss: 0.3805, validation loss: 0.6413
2024-06-03 03:03:37 [INFO]: Epoch 036 - training loss: 0.3831, validation loss: 0.6228
2024-06-03 03:03:43 [INFO]: Epoch 037 - training loss: 0.3797, validation loss: 0.6662
2024-06-03 03:03:50 [INFO]: Epoch 038 - training loss: 0.3889, validation loss: 0.6425
2024-06-03 03:03:56 [INFO]: Epoch 039 - training loss: 0.3745, validation loss: 0.6286
2024-06-03 03:04:02 [INFO]: Epoch 040 - training loss: 0.3746, validation loss: 0.6416
2024-06-03 03:04:07 [INFO]: Epoch 041 - training loss: 0.3753, validation loss: 0.6446
2024-06-03 03:04:13 [INFO]: Epoch 042 - training loss: 0.3723, validation loss: 0.6368
2024-06-03 03:04:18 [INFO]: Epoch 043 - training loss: 0.3702, validation loss: 0.6332
2024-06-03 03:04:23 [INFO]: Epoch 044 - training loss: 0.3726, validation loss: 0.6400
2024-06-03 03:04:27 [INFO]: Epoch 045 - training loss: 0.3717, validation loss: 0.6271
2024-06-03 03:04:32 [INFO]: Epoch 046 - training loss: 0.3701, validation loss: 0.6497
2024-06-03 03:04:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:04:32 [INFO]: Finished training. The best model is from epoch#36.
2024-06-03 03:04:32 [INFO]: Saved the model to results_subseq_rate05/PeMS/ETSformer_PeMS/round_1/20240603_T025940/ETSformer.pypots
2024-06-03 03:04:36 [INFO]: Successfully saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_1/imputation.pkl
2024-06-03 03:04:36 [INFO]: Round1 - ETSformer on PeMS: MAE=0.5035, MSE=0.9194, MRE=0.5950
2024-06-03 03:04:36 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:04:36 [INFO]: Using the given device: cuda:0
2024-06-03 03:04:36 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T030436
2024-06-03 03:04:36 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T030436/tensorboard
2024-06-03 03:04:36 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 03:04:41 [INFO]: Epoch 001 - training loss: 1.7197, validation loss: 1.0392
2024-06-03 03:04:47 [INFO]: Epoch 002 - training loss: 0.8190, validation loss: 0.7981
2024-06-03 03:04:52 [INFO]: Epoch 003 - training loss: 0.6625, validation loss: 0.7407
2024-06-03 03:04:58 [INFO]: Epoch 004 - training loss: 0.5887, validation loss: 0.7313
2024-06-03 03:05:03 [INFO]: Epoch 005 - training loss: 0.5504, validation loss: 0.7764
2024-06-03 03:05:08 [INFO]: Epoch 006 - training loss: 0.5269, validation loss: 0.7399
2024-06-03 03:05:12 [INFO]: Epoch 007 - training loss: 0.4946, validation loss: 0.7395
2024-06-03 03:05:16 [INFO]: Epoch 008 - training loss: 0.4858, validation loss: 0.7183
2024-06-03 03:05:21 [INFO]: Epoch 009 - training loss: 0.4713, validation loss: 0.7049
2024-06-03 03:05:27 [INFO]: Epoch 010 - training loss: 0.4677, validation loss: 0.6988
2024-06-03 03:05:32 [INFO]: Epoch 011 - training loss: 0.4491, validation loss: 0.7254
2024-06-03 03:05:37 [INFO]: Epoch 012 - training loss: 0.4452, validation loss: 0.6874
2024-06-03 03:05:42 [INFO]: Epoch 013 - training loss: 0.4416, validation loss: 0.6781
2024-06-03 03:05:47 [INFO]: Epoch 014 - training loss: 0.4232, validation loss: 0.6657
2024-06-03 03:05:53 [INFO]: Epoch 015 - training loss: 0.4250, validation loss: 0.6750
2024-06-03 03:05:57 [INFO]: Epoch 016 - training loss: 0.4160, validation loss: 0.6721
2024-06-03 03:06:02 [INFO]: Epoch 017 - training loss: 0.4105, validation loss: 0.6623
2024-06-03 03:06:07 [INFO]: Epoch 018 - training loss: 0.4166, validation loss: 0.6541
2024-06-03 03:06:12 [INFO]: Epoch 019 - training loss: 0.4059, validation loss: 0.6498
2024-06-03 03:06:18 [INFO]: Epoch 020 - training loss: 0.4090, validation loss: 0.6842
2024-06-03 03:06:23 [INFO]: Epoch 021 - training loss: 0.4026, validation loss: 0.6553
2024-06-03 03:06:28 [INFO]: Epoch 022 - training loss: 0.3994, validation loss: 0.6599
2024-06-03 03:06:34 [INFO]: Epoch 023 - training loss: 0.3960, validation loss: 0.6618
2024-06-03 03:06:39 [INFO]: Epoch 024 - training loss: 0.3865, validation loss: 0.6534
2024-06-03 03:06:44 [INFO]: Epoch 025 - training loss: 0.3892, validation loss: 0.6577
2024-06-03 03:06:49 [INFO]: Epoch 026 - training loss: 0.3909, validation loss: 0.6474
2024-06-03 03:06:53 [INFO]: Epoch 027 - training loss: 0.3895, validation loss: 0.6506
2024-06-03 03:06:58 [INFO]: Epoch 028 - training loss: 0.3859, validation loss: 0.6494
2024-06-03 03:07:04 [INFO]: Epoch 029 - training loss: 0.3838, validation loss: 0.6646
2024-06-03 03:07:09 [INFO]: Epoch 030 - training loss: 0.3841, validation loss: 0.6512
2024-06-03 03:07:14 [INFO]: Epoch 031 - training loss: 0.3772, validation loss: 0.6548
2024-06-03 03:07:19 [INFO]: Epoch 032 - training loss: 0.3814, validation loss: 0.6586
2024-06-03 03:07:24 [INFO]: Epoch 033 - training loss: 0.3760, validation loss: 0.6441
2024-06-03 03:07:29 [INFO]: Epoch 034 - training loss: 0.3775, validation loss: 0.6549
2024-06-03 03:07:33 [INFO]: Epoch 035 - training loss: 0.3746, validation loss: 0.6426
2024-06-03 03:07:38 [INFO]: Epoch 036 - training loss: 0.3774, validation loss: 0.6423
2024-06-03 03:07:43 [INFO]: Epoch 037 - training loss: 0.3757, validation loss: 0.6402
2024-06-03 03:07:48 [INFO]: Epoch 038 - training loss: 0.3724, validation loss: 0.6538
2024-06-03 03:07:53 [INFO]: Epoch 039 - training loss: 0.3731, validation loss: 0.6510
2024-06-03 03:07:58 [INFO]: Epoch 040 - training loss: 0.3743, validation loss: 0.6414
2024-06-03 03:08:04 [INFO]: Epoch 041 - training loss: 0.3715, validation loss: 0.6453
2024-06-03 03:08:09 [INFO]: Epoch 042 - training loss: 0.3747, validation loss: 0.6472
2024-06-03 03:08:14 [INFO]: Epoch 043 - training loss: 0.3789, validation loss: 0.6511
2024-06-03 03:08:18 [INFO]: Epoch 044 - training loss: 0.3855, validation loss: 0.6364
2024-06-03 03:08:22 [INFO]: Epoch 045 - training loss: 0.3793, validation loss: 0.6511
2024-06-03 03:08:28 [INFO]: Epoch 046 - training loss: 0.3791, validation loss: 0.6491
2024-06-03 03:08:33 [INFO]: Epoch 047 - training loss: 0.3810, validation loss: 0.6466
2024-06-03 03:08:38 [INFO]: Epoch 048 - training loss: 0.3720, validation loss: 0.6505
2024-06-03 03:08:43 [INFO]: Epoch 049 - training loss: 0.3813, validation loss: 0.6489
2024-06-03 03:08:48 [INFO]: Epoch 050 - training loss: 0.3871, validation loss: 0.6574
2024-06-03 03:08:54 [INFO]: Epoch 051 - training loss: 0.4491, validation loss: 0.7224
2024-06-03 03:08:58 [INFO]: Epoch 052 - training loss: 0.6714, validation loss: 0.8715
2024-06-03 03:09:03 [INFO]: Epoch 053 - training loss: 0.8211, validation loss: 1.0444
2024-06-03 03:09:08 [INFO]: Epoch 054 - training loss: 0.8868, validation loss: 1.1228
2024-06-03 03:09:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:09:08 [INFO]: Finished training. The best model is from epoch#44.
2024-06-03 03:09:08 [INFO]: Saved the model to results_subseq_rate05/PeMS/ETSformer_PeMS/round_2/20240603_T030436/ETSformer.pypots
2024-06-03 03:09:12 [INFO]: Successfully saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_2/imputation.pkl
2024-06-03 03:09:12 [INFO]: Round2 - ETSformer on PeMS: MAE=0.7506, MSE=1.4000, MRE=0.8870
2024-06-03 03:09:12 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:09:12 [INFO]: Using the given device: cuda:0
2024-06-03 03:09:12 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T030912
2024-06-03 03:09:12 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T030912/tensorboard
2024-06-03 03:09:12 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 03:09:18 [INFO]: Epoch 001 - training loss: 1.5192, validation loss: 0.9279
2024-06-03 03:09:23 [INFO]: Epoch 002 - training loss: 0.7812, validation loss: 0.7627
2024-06-03 03:09:28 [INFO]: Epoch 003 - training loss: 0.6387, validation loss: 0.7233
2024-06-03 03:09:33 [INFO]: Epoch 004 - training loss: 0.5626, validation loss: 0.7521
2024-06-03 03:09:39 [INFO]: Epoch 005 - training loss: 0.5277, validation loss: 0.7340
2024-06-03 03:09:44 [INFO]: Epoch 006 - training loss: 0.5143, validation loss: 0.7064
2024-06-03 03:09:49 [INFO]: Epoch 007 - training loss: 0.4924, validation loss: 0.7002
2024-06-03 03:09:53 [INFO]: Epoch 008 - training loss: 0.4831, validation loss: 0.6983
2024-06-03 03:09:58 [INFO]: Epoch 009 - training loss: 0.4742, validation loss: 0.6738
2024-06-03 03:10:04 [INFO]: Epoch 010 - training loss: 0.4627, validation loss: 0.6737
2024-06-03 03:10:09 [INFO]: Epoch 011 - training loss: 0.4581, validation loss: 0.6927
2024-06-03 03:10:14 [INFO]: Epoch 012 - training loss: 0.4432, validation loss: 0.6680
2024-06-03 03:10:19 [INFO]: Epoch 013 - training loss: 0.4303, validation loss: 0.6628
2024-06-03 03:10:24 [INFO]: Epoch 014 - training loss: 0.4257, validation loss: 0.6728
2024-06-03 03:10:29 [INFO]: Epoch 015 - training loss: 0.4227, validation loss: 0.6678
2024-06-03 03:10:34 [INFO]: Epoch 016 - training loss: 0.4202, validation loss: 0.6590
2024-06-03 03:10:38 [INFO]: Epoch 017 - training loss: 0.4120, validation loss: 0.6407
2024-06-03 03:10:43 [INFO]: Epoch 018 - training loss: 0.4148, validation loss: 0.6612
2024-06-03 03:10:47 [INFO]: Epoch 019 - training loss: 0.4160, validation loss: 0.6597
2024-06-03 03:10:53 [INFO]: Epoch 020 - training loss: 0.4143, validation loss: 0.6799
2024-06-03 03:10:58 [INFO]: Epoch 021 - training loss: 0.4055, validation loss: 0.6631
2024-06-03 03:11:03 [INFO]: Epoch 022 - training loss: 0.3973, validation loss: 0.6558
2024-06-03 03:11:08 [INFO]: Epoch 023 - training loss: 0.3982, validation loss: 0.6534
2024-06-03 03:11:14 [INFO]: Epoch 024 - training loss: 0.3889, validation loss: 0.6630
2024-06-03 03:11:19 [INFO]: Epoch 025 - training loss: 0.3864, validation loss: 0.6487
2024-06-03 03:11:24 [INFO]: Epoch 026 - training loss: 0.3874, validation loss: 0.6609
2024-06-03 03:11:28 [INFO]: Epoch 027 - training loss: 0.3965, validation loss: 0.6568
2024-06-03 03:11:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:11:28 [INFO]: Finished training. The best model is from epoch#17.
2024-06-03 03:11:28 [INFO]: Saved the model to results_subseq_rate05/PeMS/ETSformer_PeMS/round_3/20240603_T030912/ETSformer.pypots
2024-06-03 03:11:32 [INFO]: Successfully saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_3/imputation.pkl
2024-06-03 03:11:32 [INFO]: Round3 - ETSformer on PeMS: MAE=0.5123, MSE=0.9319, MRE=0.6054
2024-06-03 03:11:32 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:11:32 [INFO]: Using the given device: cuda:0
2024-06-03 03:11:32 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T031132
2024-06-03 03:11:32 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T031132/tensorboard
2024-06-03 03:11:32 [INFO]: ETSformer initialized with the given hyperparameters, the number of trainable parameters: 5,962,188
2024-06-03 03:11:37 [INFO]: Epoch 001 - training loss: 1.6320, validation loss: 0.9922
2024-06-03 03:11:42 [INFO]: Epoch 002 - training loss: 0.8345, validation loss: 0.8367
2024-06-03 03:11:47 [INFO]: Epoch 003 - training loss: 0.6405, validation loss: 0.7613
2024-06-03 03:11:52 [INFO]: Epoch 004 - training loss: 0.5974, validation loss: 0.7703
2024-06-03 03:11:57 [INFO]: Epoch 005 - training loss: 0.5419, validation loss: 0.7543
2024-06-03 03:12:03 [INFO]: Epoch 006 - training loss: 0.5396, validation loss: 0.7355
2024-06-03 03:12:06 [INFO]: Epoch 007 - training loss: 0.5123, validation loss: 0.7401
2024-06-03 03:12:09 [INFO]: Epoch 008 - training loss: 0.4800, validation loss: 0.7172
2024-06-03 03:12:12 [INFO]: Epoch 009 - training loss: 0.4735, validation loss: 0.7100
2024-06-03 03:12:14 [INFO]: Epoch 010 - training loss: 0.4703, validation loss: 0.7383
2024-06-03 03:12:17 [INFO]: Epoch 011 - training loss: 0.4595, validation loss: 0.6905
2024-06-03 03:12:21 [INFO]: Epoch 012 - training loss: 0.4502, validation loss: 0.7117
2024-06-03 03:12:24 [INFO]: Epoch 013 - training loss: 0.4399, validation loss: 0.6918
2024-06-03 03:12:27 [INFO]: Epoch 014 - training loss: 0.4354, validation loss: 0.7121
2024-06-03 03:12:31 [INFO]: Epoch 015 - training loss: 0.4292, validation loss: 0.6958
2024-06-03 03:12:34 [INFO]: Epoch 016 - training loss: 0.4201, validation loss: 0.6726
2024-06-03 03:12:38 [INFO]: Epoch 017 - training loss: 0.4240, validation loss: 0.6717
2024-06-03 03:12:41 [INFO]: Epoch 018 - training loss: 0.4134, validation loss: 0.6619
2024-06-03 03:12:44 [INFO]: Epoch 019 - training loss: 0.4131, validation loss: 0.6906
2024-06-03 03:12:47 [INFO]: Epoch 020 - training loss: 0.4083, validation loss: 0.6727
2024-06-03 03:12:49 [INFO]: Epoch 021 - training loss: 0.3983, validation loss: 0.6651
2024-06-03 03:12:52 [INFO]: Epoch 022 - training loss: 0.4068, validation loss: 0.6634
2024-06-03 03:12:56 [INFO]: Epoch 023 - training loss: 0.4011, validation loss: 0.6703
2024-06-03 03:12:59 [INFO]: Epoch 024 - training loss: 0.3995, validation loss: 0.6579
2024-06-03 03:13:02 [INFO]: Epoch 025 - training loss: 0.3938, validation loss: 0.6610
2024-06-03 03:13:06 [INFO]: Epoch 026 - training loss: 0.3907, validation loss: 0.6627
2024-06-03 03:13:09 [INFO]: Epoch 027 - training loss: 0.3866, validation loss: 0.6659
2024-06-03 03:13:12 [INFO]: Epoch 028 - training loss: 0.3916, validation loss: 0.6666
2024-06-03 03:13:16 [INFO]: Epoch 029 - training loss: 0.3873, validation loss: 0.6580
2024-06-03 03:13:19 [INFO]: Epoch 030 - training loss: 0.3834, validation loss: 0.6688
2024-06-03 03:13:21 [INFO]: Epoch 031 - training loss: 0.3856, validation loss: 0.6627
2024-06-03 03:13:24 [INFO]: Epoch 032 - training loss: 0.3902, validation loss: 0.6664
2024-06-03 03:13:27 [INFO]: Epoch 033 - training loss: 0.3894, validation loss: 0.6812
2024-06-03 03:13:30 [INFO]: Epoch 034 - training loss: 0.3897, validation loss: 0.6565
2024-06-03 03:13:34 [INFO]: Epoch 035 - training loss: 0.3838, validation loss: 0.6547
2024-06-03 03:13:37 [INFO]: Epoch 036 - training loss: 0.3816, validation loss: 0.6717
2024-06-03 03:13:40 [INFO]: Epoch 037 - training loss: 0.3797, validation loss: 0.6625
2024-06-03 03:13:44 [INFO]: Epoch 038 - training loss: 0.3782, validation loss: 0.6710
2024-06-03 03:13:48 [INFO]: Epoch 039 - training loss: 0.3812, validation loss: 0.6660
2024-06-03 03:13:51 [INFO]: Epoch 040 - training loss: 0.3884, validation loss: 0.6614
2024-06-03 03:13:54 [INFO]: Epoch 041 - training loss: 0.3810, validation loss: 0.6539
2024-06-03 03:13:56 [INFO]: Epoch 042 - training loss: 0.3808, validation loss: 0.6642
2024-06-03 03:13:59 [INFO]: Epoch 043 - training loss: 0.3788, validation loss: 0.6602
2024-06-03 03:14:02 [INFO]: Epoch 044 - training loss: 0.3769, validation loss: 0.6510
2024-06-03 03:14:05 [INFO]: Epoch 045 - training loss: 0.3814, validation loss: 0.6505
2024-06-03 03:14:08 [INFO]: Epoch 046 - training loss: 0.3963, validation loss: 0.6758
2024-06-03 03:14:12 [INFO]: Epoch 047 - training loss: 0.5409, validation loss: 0.7152
2024-06-03 03:14:15 [INFO]: Epoch 048 - training loss: 1.0320, validation loss: 2.5382
2024-06-03 03:14:18 [INFO]: Epoch 049 - training loss: 2.4271, validation loss: 9.3628
2024-06-03 03:14:22 [INFO]: Epoch 050 - training loss: 3.4474, validation loss: 4.1080
2024-06-03 03:14:25 [INFO]: Epoch 051 - training loss: 1.8802, validation loss: 1.4187
2024-06-03 03:14:28 [INFO]: Epoch 052 - training loss: 1.0904, validation loss: 1.0018
2024-06-03 03:14:31 [INFO]: Epoch 053 - training loss: 0.7979, validation loss: 0.8445
2024-06-03 03:14:34 [INFO]: Epoch 054 - training loss: 0.6479, validation loss: 0.7707
2024-06-03 03:14:37 [INFO]: Epoch 055 - training loss: 0.5740, validation loss: 0.7544
2024-06-03 03:14:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:14:37 [INFO]: Finished training. The best model is from epoch#45.
2024-06-03 03:14:37 [INFO]: Saved the model to results_subseq_rate05/PeMS/ETSformer_PeMS/round_4/20240603_T031132/ETSformer.pypots
2024-06-03 03:14:40 [INFO]: Successfully saved to results_subseq_rate05/PeMS/ETSformer_PeMS/round_4/imputation.pkl
2024-06-03 03:14:40 [INFO]: Round4 - ETSformer on PeMS: MAE=0.5630, MSE=1.0112, MRE=0.6653
2024-06-03 03:14:40 [INFO]: Done! Final results:
Averaged ETSformer (5,962,188 params) on PeMS: MAE=0.5642 ± 0.09636345008682573, MSE=1.0341 ± 0.18647774728607455, MRE=0.6667 ± 0.11387511603834842, average inference time=0.76
