2024-06-03 07:57:40 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 07:57:40 [INFO]: Using the given device: cuda:0
2024-06-03 07:57:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_0/20240603_T075740
2024-06-03 07:57:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_0/20240603_T075740/tensorboard
2024-06-03 07:57:41 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 07:57:46 [INFO]: Epoch 001 - training loss: 0.7271, validation loss: 1.1058
2024-06-03 07:57:48 [INFO]: Epoch 002 - training loss: 0.5049, validation loss: 1.0986
2024-06-03 07:57:50 [INFO]: Epoch 003 - training loss: 0.4890, validation loss: 1.0937
2024-06-03 07:57:52 [INFO]: Epoch 004 - training loss: 0.4738, validation loss: 1.0805
2024-06-03 07:57:54 [INFO]: Epoch 005 - training loss: 0.4600, validation loss: 1.0724
2024-06-03 07:57:56 [INFO]: Epoch 006 - training loss: 0.4511, validation loss: 1.0468
2024-06-03 07:57:58 [INFO]: Epoch 007 - training loss: 0.4440, validation loss: 1.0500
2024-06-03 07:58:00 [INFO]: Epoch 008 - training loss: 0.4415, validation loss: 1.0243
2024-06-03 07:58:02 [INFO]: Epoch 009 - training loss: 0.4391, validation loss: 1.0031
2024-06-03 07:58:04 [INFO]: Epoch 010 - training loss: 0.4359, validation loss: 0.9972
2024-06-03 07:58:06 [INFO]: Epoch 011 - training loss: 0.4336, validation loss: 0.9967
2024-06-03 07:58:08 [INFO]: Epoch 012 - training loss: 0.4318, validation loss: 1.0093
2024-06-03 07:58:10 [INFO]: Epoch 013 - training loss: 0.4319, validation loss: 0.9949
2024-06-03 07:58:12 [INFO]: Epoch 014 - training loss: 0.4305, validation loss: 1.0015
2024-06-03 07:58:14 [INFO]: Epoch 015 - training loss: 0.4245, validation loss: 0.9902
2024-06-03 07:58:16 [INFO]: Epoch 016 - training loss: 0.4250, validation loss: 0.9793
2024-06-03 07:58:18 [INFO]: Epoch 017 - training loss: 0.4267, validation loss: 0.9649
2024-06-03 07:58:20 [INFO]: Epoch 018 - training loss: 0.4287, validation loss: 0.9793
2024-06-03 07:58:23 [INFO]: Epoch 019 - training loss: 0.4261, validation loss: 0.9611
2024-06-03 07:58:25 [INFO]: Epoch 020 - training loss: 0.4225, validation loss: 0.9728
2024-06-03 07:58:27 [INFO]: Epoch 021 - training loss: 0.4245, validation loss: 0.9556
2024-06-03 07:58:30 [INFO]: Epoch 022 - training loss: 0.4215, validation loss: 0.9517
2024-06-03 07:58:33 [INFO]: Epoch 023 - training loss: 0.4213, validation loss: 0.9346
2024-06-03 07:58:36 [INFO]: Epoch 024 - training loss: 0.4228, validation loss: 0.9661
2024-06-03 07:58:39 [INFO]: Epoch 025 - training loss: 0.4224, validation loss: 0.9570
2024-06-03 07:58:42 [INFO]: Epoch 026 - training loss: 0.4209, validation loss: 0.9465
2024-06-03 07:58:44 [INFO]: Epoch 027 - training loss: 0.4218, validation loss: 0.9412
2024-06-03 07:58:47 [INFO]: Epoch 028 - training loss: 0.4209, validation loss: 0.9625
2024-06-03 07:58:50 [INFO]: Epoch 029 - training loss: 0.4189, validation loss: 0.9575
2024-06-03 07:58:53 [INFO]: Epoch 030 - training loss: 0.4189, validation loss: 0.9449
2024-06-03 07:58:56 [INFO]: Epoch 031 - training loss: 0.4163, validation loss: 0.9386
2024-06-03 07:58:59 [INFO]: Epoch 032 - training loss: 0.4181, validation loss: 0.9530
2024-06-03 07:59:01 [INFO]: Epoch 033 - training loss: 0.4168, validation loss: 0.9597
2024-06-03 07:59:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 07:59:01 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 07:59:02 [INFO]: Saved the model to results_subseq_rate05/PeMS/MICN_PeMS/round_0/20240603_T075740/MICN.pypots
2024-06-03 07:59:03 [INFO]: Successfully saved to results_subseq_rate05/PeMS/MICN_PeMS/round_0/imputation.pkl
2024-06-03 07:59:03 [INFO]: Round0 - MICN on PeMS: MAE=0.6765, MSE=1.3098, MRE=0.7995
2024-06-03 07:59:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 07:59:03 [INFO]: Using the given device: cuda:0
2024-06-03 07:59:03 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_1/20240603_T075903
2024-06-03 07:59:03 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_1/20240603_T075903/tensorboard
2024-06-03 07:59:04 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 07:59:07 [INFO]: Epoch 001 - training loss: 0.7326, validation loss: 1.0811
2024-06-03 07:59:09 [INFO]: Epoch 002 - training loss: 0.5060, validation loss: 1.0942
2024-06-03 07:59:13 [INFO]: Epoch 003 - training loss: 0.4848, validation loss: 1.0687
2024-06-03 07:59:15 [INFO]: Epoch 004 - training loss: 0.4657, validation loss: 1.0956
2024-06-03 07:59:19 [INFO]: Epoch 005 - training loss: 0.4598, validation loss: 1.0201
2024-06-03 07:59:22 [INFO]: Epoch 006 - training loss: 0.4501, validation loss: 1.0200
2024-06-03 07:59:24 [INFO]: Epoch 007 - training loss: 0.4429, validation loss: 1.0579
2024-06-03 07:59:27 [INFO]: Epoch 008 - training loss: 0.4428, validation loss: 1.0192
2024-06-03 07:59:30 [INFO]: Epoch 009 - training loss: 0.4396, validation loss: 1.0276
2024-06-03 07:59:33 [INFO]: Epoch 010 - training loss: 0.4352, validation loss: 1.0044
2024-06-03 07:59:36 [INFO]: Epoch 011 - training loss: 0.4348, validation loss: 1.0192
2024-06-03 07:59:39 [INFO]: Epoch 012 - training loss: 0.4294, validation loss: 1.0124
2024-06-03 07:59:42 [INFO]: Epoch 013 - training loss: 0.4301, validation loss: 1.0350
2024-06-03 07:59:45 [INFO]: Epoch 014 - training loss: 0.4303, validation loss: 1.0284
2024-06-03 07:59:48 [INFO]: Epoch 015 - training loss: 0.4280, validation loss: 1.0270
2024-06-03 07:59:51 [INFO]: Epoch 016 - training loss: 0.4271, validation loss: 1.0443
2024-06-03 07:59:54 [INFO]: Epoch 017 - training loss: 0.4253, validation loss: 0.9856
2024-06-03 07:59:57 [INFO]: Epoch 018 - training loss: 0.4233, validation loss: 1.0098
2024-06-03 08:00:00 [INFO]: Epoch 019 - training loss: 0.4250, validation loss: 0.9982
2024-06-03 08:00:03 [INFO]: Epoch 020 - training loss: 0.4234, validation loss: 0.9944
2024-06-03 08:00:06 [INFO]: Epoch 021 - training loss: 0.4201, validation loss: 0.9942
2024-06-03 08:00:09 [INFO]: Epoch 022 - training loss: 0.4248, validation loss: 0.9890
2024-06-03 08:00:11 [INFO]: Epoch 023 - training loss: 0.4198, validation loss: 0.9797
2024-06-03 08:00:14 [INFO]: Epoch 024 - training loss: 0.4211, validation loss: 0.9900
2024-06-03 08:00:17 [INFO]: Epoch 025 - training loss: 0.4219, validation loss: 0.9769
2024-06-03 08:00:20 [INFO]: Epoch 026 - training loss: 0.4238, validation loss: 1.0027
2024-06-03 08:00:23 [INFO]: Epoch 027 - training loss: 0.4201, validation loss: 0.9648
2024-06-03 08:00:26 [INFO]: Epoch 028 - training loss: 0.4200, validation loss: 0.9989
2024-06-03 08:00:29 [INFO]: Epoch 029 - training loss: 0.4179, validation loss: 0.9689
2024-06-03 08:00:32 [INFO]: Epoch 030 - training loss: 0.4181, validation loss: 0.9742
2024-06-03 08:00:35 [INFO]: Epoch 031 - training loss: 0.4179, validation loss: 0.9634
2024-06-03 08:00:38 [INFO]: Epoch 032 - training loss: 0.4154, validation loss: 0.9775
2024-06-03 08:00:41 [INFO]: Epoch 033 - training loss: 0.4159, validation loss: 0.9739
2024-06-03 08:00:44 [INFO]: Epoch 034 - training loss: 0.4154, validation loss: 0.9704
2024-06-03 08:00:47 [INFO]: Epoch 035 - training loss: 0.4146, validation loss: 0.9564
2024-06-03 08:00:50 [INFO]: Epoch 036 - training loss: 0.4156, validation loss: 1.0037
2024-06-03 08:00:53 [INFO]: Epoch 037 - training loss: 0.4138, validation loss: 0.9702
2024-06-03 08:00:56 [INFO]: Epoch 038 - training loss: 0.4147, validation loss: 0.9551
2024-06-03 08:00:59 [INFO]: Epoch 039 - training loss: 0.4142, validation loss: 0.9592
2024-06-03 08:01:02 [INFO]: Epoch 040 - training loss: 0.4160, validation loss: 0.9393
2024-06-03 08:01:05 [INFO]: Epoch 041 - training loss: 0.4150, validation loss: 0.9601
2024-06-03 08:01:08 [INFO]: Epoch 042 - training loss: 0.4096, validation loss: 0.9797
2024-06-03 08:01:11 [INFO]: Epoch 043 - training loss: 0.4122, validation loss: 0.9426
2024-06-03 08:01:14 [INFO]: Epoch 044 - training loss: 0.4133, validation loss: 0.9506
2024-06-03 08:01:17 [INFO]: Epoch 045 - training loss: 0.4113, validation loss: 0.9722
2024-06-03 08:01:20 [INFO]: Epoch 046 - training loss: 0.4098, validation loss: 0.9530
2024-06-03 08:01:23 [INFO]: Epoch 047 - training loss: 0.4099, validation loss: 0.9700
2024-06-03 08:01:26 [INFO]: Epoch 048 - training loss: 0.4103, validation loss: 0.9490
2024-06-03 08:01:28 [INFO]: Epoch 049 - training loss: 0.4099, validation loss: 0.9530
2024-06-03 08:01:31 [INFO]: Epoch 050 - training loss: 0.4074, validation loss: 0.9529
2024-06-03 08:01:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:01:31 [INFO]: Finished training. The best model is from epoch#40.
2024-06-03 08:01:32 [INFO]: Saved the model to results_subseq_rate05/PeMS/MICN_PeMS/round_1/20240603_T075903/MICN.pypots
2024-06-03 08:01:33 [INFO]: Successfully saved to results_subseq_rate05/PeMS/MICN_PeMS/round_1/imputation.pkl
2024-06-03 08:01:33 [INFO]: Round1 - MICN on PeMS: MAE=0.6632, MSE=1.2934, MRE=0.7837
2024-06-03 08:01:33 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 08:01:33 [INFO]: Using the given device: cuda:0
2024-06-03 08:01:33 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_2/20240603_T080133
2024-06-03 08:01:33 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_2/20240603_T080133/tensorboard
2024-06-03 08:01:33 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 08:01:36 [INFO]: Epoch 001 - training loss: 0.7460, validation loss: 1.0758
2024-06-03 08:01:40 [INFO]: Epoch 002 - training loss: 0.5185, validation loss: 1.0734
2024-06-03 08:01:43 [INFO]: Epoch 003 - training loss: 0.4982, validation loss: 1.0559
2024-06-03 08:01:46 [INFO]: Epoch 004 - training loss: 0.4769, validation loss: 1.0241
2024-06-03 08:01:49 [INFO]: Epoch 005 - training loss: 0.4623, validation loss: 0.9944
2024-06-03 08:01:52 [INFO]: Epoch 006 - training loss: 0.4577, validation loss: 0.9842
2024-06-03 08:01:55 [INFO]: Epoch 007 - training loss: 0.4476, validation loss: 0.9809
2024-06-03 08:01:58 [INFO]: Epoch 008 - training loss: 0.4435, validation loss: 0.9789
2024-06-03 08:02:00 [INFO]: Epoch 009 - training loss: 0.4419, validation loss: 0.9681
2024-06-03 08:02:03 [INFO]: Epoch 010 - training loss: 0.4370, validation loss: 0.9565
2024-06-03 08:02:06 [INFO]: Epoch 011 - training loss: 0.4341, validation loss: 0.9504
2024-06-03 08:02:09 [INFO]: Epoch 012 - training loss: 0.4333, validation loss: 0.9385
2024-06-03 08:02:12 [INFO]: Epoch 013 - training loss: 0.4320, validation loss: 0.9384
2024-06-03 08:02:15 [INFO]: Epoch 014 - training loss: 0.4287, validation loss: 0.9596
2024-06-03 08:02:18 [INFO]: Epoch 015 - training loss: 0.4294, validation loss: 0.9331
2024-06-03 08:02:20 [INFO]: Epoch 016 - training loss: 0.4263, validation loss: 0.9571
2024-06-03 08:02:23 [INFO]: Epoch 017 - training loss: 0.4290, validation loss: 0.9266
2024-06-03 08:02:26 [INFO]: Epoch 018 - training loss: 0.4236, validation loss: 0.9245
2024-06-03 08:02:29 [INFO]: Epoch 019 - training loss: 0.4233, validation loss: 0.9180
2024-06-03 08:02:32 [INFO]: Epoch 020 - training loss: 0.4251, validation loss: 0.9263
2024-06-03 08:02:35 [INFO]: Epoch 021 - training loss: 0.4248, validation loss: 0.9320
2024-06-03 08:02:38 [INFO]: Epoch 022 - training loss: 0.4225, validation loss: 0.9013
2024-06-03 08:02:41 [INFO]: Epoch 023 - training loss: 0.4215, validation loss: 0.9251
2024-06-03 08:02:44 [INFO]: Epoch 024 - training loss: 0.4214, validation loss: 0.9346
2024-06-03 08:02:47 [INFO]: Epoch 025 - training loss: 0.4225, validation loss: 0.9227
2024-06-03 08:02:50 [INFO]: Epoch 026 - training loss: 0.4208, validation loss: 0.9196
2024-06-03 08:02:53 [INFO]: Epoch 027 - training loss: 0.4191, validation loss: 0.9053
2024-06-03 08:02:56 [INFO]: Epoch 028 - training loss: 0.4185, validation loss: 0.9191
2024-06-03 08:02:59 [INFO]: Epoch 029 - training loss: 0.4183, validation loss: 0.9167
2024-06-03 08:03:02 [INFO]: Epoch 030 - training loss: 0.4187, validation loss: 0.9241
2024-06-03 08:03:05 [INFO]: Epoch 031 - training loss: 0.4167, validation loss: 0.9086
2024-06-03 08:03:08 [INFO]: Epoch 032 - training loss: 0.4170, validation loss: 0.9216
2024-06-03 08:03:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:03:08 [INFO]: Finished training. The best model is from epoch#22.
2024-06-03 08:03:09 [INFO]: Saved the model to results_subseq_rate05/PeMS/MICN_PeMS/round_2/20240603_T080133/MICN.pypots
2024-06-03 08:03:10 [INFO]: Successfully saved to results_subseq_rate05/PeMS/MICN_PeMS/round_2/imputation.pkl
2024-06-03 08:03:10 [INFO]: Round2 - MICN on PeMS: MAE=0.6621, MSE=1.2557, MRE=0.7824
2024-06-03 08:03:10 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 08:03:10 [INFO]: Using the given device: cuda:0
2024-06-03 08:03:10 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_3/20240603_T080310
2024-06-03 08:03:10 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_3/20240603_T080310/tensorboard
2024-06-03 08:03:11 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 08:03:14 [INFO]: Epoch 001 - training loss: 0.7169, validation loss: 1.1258
2024-06-03 08:03:17 [INFO]: Epoch 002 - training loss: 0.4932, validation loss: 1.1155
2024-06-03 08:03:20 [INFO]: Epoch 003 - training loss: 0.4749, validation loss: 1.0829
2024-06-03 08:03:23 [INFO]: Epoch 004 - training loss: 0.4662, validation loss: 1.0560
2024-06-03 08:03:26 [INFO]: Epoch 005 - training loss: 0.4557, validation loss: 1.0658
2024-06-03 08:03:28 [INFO]: Epoch 006 - training loss: 0.4498, validation loss: 1.0480
2024-06-03 08:03:31 [INFO]: Epoch 007 - training loss: 0.4418, validation loss: 1.0515
2024-06-03 08:03:34 [INFO]: Epoch 008 - training loss: 0.4387, validation loss: 1.0609
2024-06-03 08:03:37 [INFO]: Epoch 009 - training loss: 0.4340, validation loss: 1.0461
2024-06-03 08:03:39 [INFO]: Epoch 010 - training loss: 0.4342, validation loss: 1.0478
2024-06-03 08:03:42 [INFO]: Epoch 011 - training loss: 0.4310, validation loss: 1.0339
2024-06-03 08:03:45 [INFO]: Epoch 012 - training loss: 0.4281, validation loss: 1.0429
2024-06-03 08:03:48 [INFO]: Epoch 013 - training loss: 0.4271, validation loss: 1.0459
2024-06-03 08:03:51 [INFO]: Epoch 014 - training loss: 0.4251, validation loss: 1.0475
2024-06-03 08:03:54 [INFO]: Epoch 015 - training loss: 0.4223, validation loss: 1.0362
2024-06-03 08:03:57 [INFO]: Epoch 016 - training loss: 0.4226, validation loss: 1.0187
2024-06-03 08:04:00 [INFO]: Epoch 017 - training loss: 0.4219, validation loss: 1.0196
2024-06-03 08:04:03 [INFO]: Epoch 018 - training loss: 0.4214, validation loss: 1.0387
2024-06-03 08:04:06 [INFO]: Epoch 019 - training loss: 0.4182, validation loss: 1.0067
2024-06-03 08:04:09 [INFO]: Epoch 020 - training loss: 0.4196, validation loss: 1.0368
2024-06-03 08:04:12 [INFO]: Epoch 021 - training loss: 0.4207, validation loss: 1.0462
2024-06-03 08:04:15 [INFO]: Epoch 022 - training loss: 0.4179, validation loss: 1.0124
2024-06-03 08:04:18 [INFO]: Epoch 023 - training loss: 0.4193, validation loss: 0.9943
2024-06-03 08:04:21 [INFO]: Epoch 024 - training loss: 0.4180, validation loss: 1.0176
2024-06-03 08:04:24 [INFO]: Epoch 025 - training loss: 0.4150, validation loss: 1.0222
2024-06-03 08:04:27 [INFO]: Epoch 026 - training loss: 0.4153, validation loss: 1.0024
2024-06-03 08:04:30 [INFO]: Epoch 027 - training loss: 0.4166, validation loss: 1.0103
2024-06-03 08:04:33 [INFO]: Epoch 028 - training loss: 0.4153, validation loss: 1.0192
2024-06-03 08:04:36 [INFO]: Epoch 029 - training loss: 0.4160, validation loss: 0.9919
2024-06-03 08:04:39 [INFO]: Epoch 030 - training loss: 0.4137, validation loss: 1.0197
2024-06-03 08:04:42 [INFO]: Epoch 031 - training loss: 0.4145, validation loss: 1.0277
2024-06-03 08:04:45 [INFO]: Epoch 032 - training loss: 0.4145, validation loss: 0.9931
2024-06-03 08:04:48 [INFO]: Epoch 033 - training loss: 0.4115, validation loss: 1.0155
2024-06-03 08:04:51 [INFO]: Epoch 034 - training loss: 0.4104, validation loss: 0.9971
2024-06-03 08:04:54 [INFO]: Epoch 035 - training loss: 0.4132, validation loss: 0.9993
2024-06-03 08:04:57 [INFO]: Epoch 036 - training loss: 0.4105, validation loss: 1.0009
2024-06-03 08:05:00 [INFO]: Epoch 037 - training loss: 0.4133, validation loss: 0.9767
2024-06-03 08:05:03 [INFO]: Epoch 038 - training loss: 0.4124, validation loss: 1.0233
2024-06-03 08:05:06 [INFO]: Epoch 039 - training loss: 0.4127, validation loss: 1.0096
2024-06-03 08:05:08 [INFO]: Epoch 040 - training loss: 0.4120, validation loss: 0.9972
2024-06-03 08:05:12 [INFO]: Epoch 041 - training loss: 0.4090, validation loss: 1.0021
2024-06-03 08:05:15 [INFO]: Epoch 042 - training loss: 0.4086, validation loss: 0.9832
2024-06-03 08:05:18 [INFO]: Epoch 043 - training loss: 0.4078, validation loss: 1.0089
2024-06-03 08:05:20 [INFO]: Epoch 044 - training loss: 0.4075, validation loss: 0.9749
2024-06-03 08:05:23 [INFO]: Epoch 045 - training loss: 0.4082, validation loss: 1.0035
2024-06-03 08:05:26 [INFO]: Epoch 046 - training loss: 0.4089, validation loss: 0.9814
2024-06-03 08:05:28 [INFO]: Epoch 047 - training loss: 0.4073, validation loss: 1.0110
2024-06-03 08:05:31 [INFO]: Epoch 048 - training loss: 0.4085, validation loss: 0.9679
2024-06-03 08:05:33 [INFO]: Epoch 049 - training loss: 0.4084, validation loss: 0.9834
2024-06-03 08:05:36 [INFO]: Epoch 050 - training loss: 0.4074, validation loss: 0.9667
2024-06-03 08:05:38 [INFO]: Epoch 051 - training loss: 0.4059, validation loss: 0.9599
2024-06-03 08:05:40 [INFO]: Epoch 052 - training loss: 0.4059, validation loss: 0.9923
2024-06-03 08:05:43 [INFO]: Epoch 053 - training loss: 0.4069, validation loss: 0.9564
2024-06-03 08:05:45 [INFO]: Epoch 054 - training loss: 0.4055, validation loss: 0.9717
2024-06-03 08:05:48 [INFO]: Epoch 055 - training loss: 0.4061, validation loss: 0.9850
2024-06-03 08:05:50 [INFO]: Epoch 056 - training loss: 0.4049, validation loss: 0.9478
2024-06-03 08:05:53 [INFO]: Epoch 057 - training loss: 0.4040, validation loss: 0.9673
2024-06-03 08:05:55 [INFO]: Epoch 058 - training loss: 0.4064, validation loss: 0.9415
2024-06-03 08:05:58 [INFO]: Epoch 059 - training loss: 0.4057, validation loss: 0.9743
2024-06-03 08:06:01 [INFO]: Epoch 060 - training loss: 0.4034, validation loss: 0.9548
2024-06-03 08:06:03 [INFO]: Epoch 061 - training loss: 0.4039, validation loss: 0.9690
2024-06-03 08:06:06 [INFO]: Epoch 062 - training loss: 0.4007, validation loss: 0.9684
2024-06-03 08:06:08 [INFO]: Epoch 063 - training loss: 0.4016, validation loss: 0.9498
2024-06-03 08:06:11 [INFO]: Epoch 064 - training loss: 0.4053, validation loss: 0.9719
2024-06-03 08:06:13 [INFO]: Epoch 065 - training loss: 0.4022, validation loss: 0.9323
2024-06-03 08:06:16 [INFO]: Epoch 066 - training loss: 0.4008, validation loss: 0.9606
2024-06-03 08:06:19 [INFO]: Epoch 067 - training loss: 0.4033, validation loss: 0.9519
2024-06-03 08:06:21 [INFO]: Epoch 068 - training loss: 0.4022, validation loss: 0.9491
2024-06-03 08:06:23 [INFO]: Epoch 069 - training loss: 0.4023, validation loss: 0.9929
2024-06-03 08:06:26 [INFO]: Epoch 070 - training loss: 0.4017, validation loss: 0.9610
2024-06-03 08:06:28 [INFO]: Epoch 071 - training loss: 0.3987, validation loss: 0.9732
2024-06-03 08:06:31 [INFO]: Epoch 072 - training loss: 0.3999, validation loss: 0.9391
2024-06-03 08:06:33 [INFO]: Epoch 073 - training loss: 0.3993, validation loss: 0.9765
2024-06-03 08:06:36 [INFO]: Epoch 074 - training loss: 0.3991, validation loss: 0.9595
2024-06-03 08:06:39 [INFO]: Epoch 075 - training loss: 0.3995, validation loss: 0.9531
2024-06-03 08:06:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:06:39 [INFO]: Finished training. The best model is from epoch#65.
2024-06-03 08:06:39 [INFO]: Saved the model to results_subseq_rate05/PeMS/MICN_PeMS/round_3/20240603_T080310/MICN.pypots
2024-06-03 08:06:40 [INFO]: Successfully saved to results_subseq_rate05/PeMS/MICN_PeMS/round_3/imputation.pkl
2024-06-03 08:06:40 [INFO]: Round3 - MICN on PeMS: MAE=0.6703, MSE=1.3081, MRE=0.7921
2024-06-03 08:06:40 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 08:06:40 [INFO]: Using the given device: cuda:0
2024-06-03 08:06:40 [INFO]: Model files will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_4/20240603_T080640
2024-06-03 08:06:40 [INFO]: Tensorboard file will be saved to results_subseq_rate05/PeMS/MICN_PeMS/round_4/20240603_T080640/tensorboard
2024-06-03 08:06:41 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 15,490,402
2024-06-03 08:06:43 [INFO]: Epoch 001 - training loss: 0.7245, validation loss: 1.0871
2024-06-03 08:06:46 [INFO]: Epoch 002 - training loss: 0.5025, validation loss: 1.0701
2024-06-03 08:06:48 [INFO]: Epoch 003 - training loss: 0.4767, validation loss: 1.0833
2024-06-03 08:06:50 [INFO]: Epoch 004 - training loss: 0.4677, validation loss: 1.0686
2024-06-03 08:06:53 [INFO]: Epoch 005 - training loss: 0.4581, validation loss: 1.0025
2024-06-03 08:06:55 [INFO]: Epoch 006 - training loss: 0.4478, validation loss: 0.9851
2024-06-03 08:06:58 [INFO]: Epoch 007 - training loss: 0.4431, validation loss: 1.0092
2024-06-03 08:07:00 [INFO]: Epoch 008 - training loss: 0.4386, validation loss: 1.0314
2024-06-03 08:07:03 [INFO]: Epoch 009 - training loss: 0.4344, validation loss: 1.0155
2024-06-03 08:07:05 [INFO]: Epoch 010 - training loss: 0.4347, validation loss: 1.0071
2024-06-03 08:07:08 [INFO]: Epoch 011 - training loss: 0.4331, validation loss: 1.0271
2024-06-03 08:07:10 [INFO]: Epoch 012 - training loss: 0.4284, validation loss: 0.9969
2024-06-03 08:07:13 [INFO]: Epoch 013 - training loss: 0.4284, validation loss: 1.0160
2024-06-03 08:07:15 [INFO]: Epoch 014 - training loss: 0.4273, validation loss: 0.9979
2024-06-03 08:07:17 [INFO]: Epoch 015 - training loss: 0.4238, validation loss: 0.9970
2024-06-03 08:07:20 [INFO]: Epoch 016 - training loss: 0.4226, validation loss: 1.0096
2024-06-03 08:07:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 08:07:20 [INFO]: Finished training. The best model is from epoch#6.
2024-06-03 08:07:20 [INFO]: Saved the model to results_subseq_rate05/PeMS/MICN_PeMS/round_4/20240603_T080640/MICN.pypots
2024-06-03 08:07:21 [INFO]: Successfully saved to results_subseq_rate05/PeMS/MICN_PeMS/round_4/imputation.pkl
2024-06-03 08:07:21 [INFO]: Round4 - MICN on PeMS: MAE=0.6850, MSE=1.3403, MRE=0.8095
2024-06-03 08:07:21 [INFO]: Done! Final results:
Averaged MICN (15,490,402 params) on PeMS: MAE=0.6714 ± 0.008568343173752912, MSE=1.3015 ± 0.027486458924456787, MRE=0.7934 ± 0.010125426936129403, average inference time=0.17
