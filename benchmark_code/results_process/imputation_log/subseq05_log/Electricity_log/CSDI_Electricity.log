2024-06-03 04:09:26 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 04:09:26 [INFO]: Using the given device: cuda:0
2024-06-03 04:09:26 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_0/20240603_T040926
2024-06-03 04:09:26 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_0/20240603_T040926/tensorboard
2024-06-03 04:09:26 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 04:13:42 [INFO]: Epoch 001 - training loss: 0.7082, validation loss: 0.4736
2024-06-03 04:17:47 [INFO]: Epoch 002 - training loss: 0.4161, validation loss: 0.3803
2024-06-03 04:21:51 [INFO]: Epoch 003 - training loss: 0.3637, validation loss: 0.3652
2024-06-03 04:25:58 [INFO]: Epoch 004 - training loss: 0.3585, validation loss: 0.3597
2024-06-03 04:29:49 [INFO]: Epoch 005 - training loss: 0.3750, validation loss: 0.3472
2024-06-03 04:33:38 [INFO]: Epoch 006 - training loss: 0.3360, validation loss: 0.3236
2024-06-03 04:37:15 [INFO]: Epoch 007 - training loss: 0.3225, validation loss: 0.3061
2024-06-03 04:40:53 [INFO]: Epoch 008 - training loss: 0.2988, validation loss: 0.2933
2024-06-03 04:44:32 [INFO]: Epoch 009 - training loss: 0.2933, validation loss: 0.2878
2024-06-03 04:48:10 [INFO]: Epoch 010 - training loss: 0.2908, validation loss: 0.2723
2024-06-03 04:51:47 [INFO]: Epoch 011 - training loss: 0.2667, validation loss: 0.2655
2024-06-03 04:54:14 [INFO]: Epoch 012 - training loss: 0.2624, validation loss: 0.2611
2024-06-03 04:56:20 [INFO]: Epoch 013 - training loss: 0.2456, validation loss: 0.2514
2024-06-03 04:58:27 [INFO]: Epoch 014 - training loss: 0.2478, validation loss: 0.2485
2024-06-03 05:00:33 [INFO]: Epoch 015 - training loss: 0.2167, validation loss: 0.2429
2024-06-03 05:02:39 [INFO]: Epoch 016 - training loss: 0.2412, validation loss: 0.2367
2024-06-03 05:04:45 [INFO]: Epoch 017 - training loss: 0.2431, validation loss: 0.2303
2024-06-03 05:06:52 [INFO]: Epoch 018 - training loss: 0.2198, validation loss: 0.2273
2024-06-03 05:08:58 [INFO]: Epoch 019 - training loss: 0.2462, validation loss: 0.2267
2024-06-03 05:11:04 [INFO]: Epoch 020 - training loss: 0.2267, validation loss: 0.2234
2024-06-03 05:13:11 [INFO]: Epoch 021 - training loss: 0.2013, validation loss: 0.2230
2024-06-03 05:15:17 [INFO]: Epoch 022 - training loss: 0.2012, validation loss: 0.2193
2024-06-03 05:17:24 [INFO]: Epoch 023 - training loss: 0.2210, validation loss: 0.2176
2024-06-03 05:19:30 [INFO]: Epoch 024 - training loss: 0.2073, validation loss: 0.2163
2024-06-03 05:21:36 [INFO]: Epoch 025 - training loss: 0.2016, validation loss: 0.2159
2024-06-03 05:23:42 [INFO]: Epoch 026 - training loss: 0.2049, validation loss: 0.2156
2024-06-03 05:25:48 [INFO]: Epoch 027 - training loss: 0.1947, validation loss: 0.2133
2024-06-03 05:27:54 [INFO]: Epoch 028 - training loss: 0.1627, validation loss: 0.2124
2024-06-03 05:30:00 [INFO]: Epoch 029 - training loss: 0.2027, validation loss: 0.2125
2024-06-03 05:32:06 [INFO]: Epoch 030 - training loss: 0.1919, validation loss: 0.2100
2024-06-03 05:34:11 [INFO]: Epoch 031 - training loss: 0.1919, validation loss: 0.2086
2024-06-03 05:36:18 [INFO]: Epoch 032 - training loss: 0.1974, validation loss: 0.2103
2024-06-03 05:38:24 [INFO]: Epoch 033 - training loss: 0.1718, validation loss: 0.2125
2024-06-03 05:40:31 [INFO]: Epoch 034 - training loss: 0.1913, validation loss: 0.2092
2024-06-03 05:42:37 [INFO]: Epoch 035 - training loss: 0.1895, validation loss: 0.2067
2024-06-03 05:44:44 [INFO]: Epoch 036 - training loss: 0.1938, validation loss: 0.2043
2024-06-03 05:46:51 [INFO]: Epoch 037 - training loss: 0.1935, validation loss: 0.2037
2024-06-03 05:48:58 [INFO]: Epoch 038 - training loss: 0.1900, validation loss: 0.2051
2024-06-03 05:51:04 [INFO]: Epoch 039 - training loss: 0.1799, validation loss: 0.2058
2024-06-03 05:53:10 [INFO]: Epoch 040 - training loss: 0.2067, validation loss: 0.2017
2024-06-03 05:55:17 [INFO]: Epoch 041 - training loss: 0.1817, validation loss: 0.2038
2024-06-03 05:57:23 [INFO]: Epoch 042 - training loss: 0.1846, validation loss: 0.2075
2024-06-03 05:59:30 [INFO]: Epoch 043 - training loss: 0.1895, validation loss: 0.2017
2024-06-03 06:01:36 [INFO]: Epoch 044 - training loss: 0.1979, validation loss: 0.2027
2024-06-03 06:03:43 [INFO]: Epoch 045 - training loss: 0.1910, validation loss: 0.2021
2024-06-03 06:05:50 [INFO]: Epoch 046 - training loss: 0.1926, validation loss: 0.2071
2024-06-03 06:07:57 [INFO]: Epoch 047 - training loss: 0.1946, validation loss: 0.2020
2024-06-03 06:10:01 [INFO]: Epoch 048 - training loss: 0.1956, validation loss: 0.2013
2024-06-03 06:12:08 [INFO]: Epoch 049 - training loss: 0.1854, validation loss: 0.1994
2024-06-03 06:14:14 [INFO]: Epoch 050 - training loss: 0.1726, validation loss: 0.1996
2024-06-03 06:16:21 [INFO]: Epoch 051 - training loss: 0.1752, validation loss: 0.2037
2024-06-03 06:18:28 [INFO]: Epoch 052 - training loss: 0.1723, validation loss: 0.1996
2024-06-03 06:20:34 [INFO]: Epoch 053 - training loss: 0.2022, validation loss: 0.1997
2024-06-03 06:22:41 [INFO]: Epoch 054 - training loss: 0.1833, validation loss: 0.1990
2024-06-03 06:24:48 [INFO]: Epoch 055 - training loss: 0.1726, validation loss: 0.1994
2024-06-03 06:26:55 [INFO]: Epoch 056 - training loss: 0.1742, validation loss: 0.1980
2024-06-03 06:29:01 [INFO]: Epoch 057 - training loss: 0.1747, validation loss: 0.1987
2024-06-03 06:31:08 [INFO]: Epoch 058 - training loss: 0.1772, validation loss: 0.1994
2024-06-03 06:33:14 [INFO]: Epoch 059 - training loss: 0.1826, validation loss: 0.1976
2024-06-03 06:35:20 [INFO]: Epoch 060 - training loss: 0.1656, validation loss: 0.2063
2024-06-03 06:37:26 [INFO]: Epoch 061 - training loss: 0.1842, validation loss: 0.1997
2024-06-03 06:39:32 [INFO]: Epoch 062 - training loss: 0.1917, validation loss: 0.1972
2024-06-03 06:41:39 [INFO]: Epoch 063 - training loss: 0.1858, validation loss: 0.1975
2024-06-03 06:43:46 [INFO]: Epoch 064 - training loss: 0.1756, validation loss: 0.1981
2024-06-03 06:45:53 [INFO]: Epoch 065 - training loss: 0.1772, validation loss: 0.1989
2024-06-03 06:47:59 [INFO]: Epoch 066 - training loss: 0.1809, validation loss: 0.1971
2024-06-03 06:50:06 [INFO]: Epoch 067 - training loss: 0.1610, validation loss: 0.1988
2024-06-03 06:52:13 [INFO]: Epoch 068 - training loss: 0.1699, validation loss: 0.1965
2024-06-03 06:54:19 [INFO]: Epoch 069 - training loss: 0.1688, validation loss: 0.2005
2024-06-03 06:56:26 [INFO]: Epoch 070 - training loss: 0.1780, validation loss: 0.1964
2024-06-03 06:58:32 [INFO]: Epoch 071 - training loss: 0.1683, validation loss: 0.1964
2024-06-03 07:00:39 [INFO]: Epoch 072 - training loss: 0.1656, validation loss: 0.1984
2024-06-03 07:02:45 [INFO]: Epoch 073 - training loss: 0.1587, validation loss: 0.1950
2024-06-03 07:04:52 [INFO]: Epoch 074 - training loss: 0.1678, validation loss: 0.1953
2024-06-03 07:06:58 [INFO]: Epoch 075 - training loss: 0.1853, validation loss: 0.1966
2024-06-03 07:09:05 [INFO]: Epoch 076 - training loss: 0.1847, validation loss: 0.1966
2024-06-03 07:11:12 [INFO]: Epoch 077 - training loss: 0.1743, validation loss: 0.1967
2024-06-03 07:13:19 [INFO]: Epoch 078 - training loss: 0.1925, validation loss: 0.1998
2024-06-03 07:15:25 [INFO]: Epoch 079 - training loss: 0.1801, validation loss: 0.1958
2024-06-03 07:17:31 [INFO]: Epoch 080 - training loss: 0.1889, validation loss: 0.1945
2024-06-03 07:19:37 [INFO]: Epoch 081 - training loss: 0.1805, validation loss: 0.1949
2024-06-03 07:21:43 [INFO]: Epoch 082 - training loss: 0.1814, validation loss: 0.1936
2024-06-03 07:23:48 [INFO]: Epoch 083 - training loss: 0.1785, validation loss: 0.1931
2024-06-03 07:25:54 [INFO]: Epoch 084 - training loss: 0.1962, validation loss: 0.1954
2024-06-03 07:28:00 [INFO]: Epoch 085 - training loss: 0.1945, validation loss: 0.1949
2024-06-03 07:30:06 [INFO]: Epoch 086 - training loss: 0.1790, validation loss: 0.1939
2024-06-03 07:32:12 [INFO]: Epoch 087 - training loss: 0.1850, validation loss: 0.1942
2024-06-03 07:34:18 [INFO]: Epoch 088 - training loss: 0.1611, validation loss: 0.1933
2024-06-03 07:36:24 [INFO]: Epoch 089 - training loss: 0.1753, validation loss: 0.1955
2024-06-03 07:38:30 [INFO]: Epoch 090 - training loss: 0.1608, validation loss: 0.1936
2024-06-03 07:40:36 [INFO]: Epoch 091 - training loss: 0.1878, validation loss: 0.1937
2024-06-03 07:42:42 [INFO]: Epoch 092 - training loss: 0.1699, validation loss: 0.1943
2024-06-03 07:44:48 [INFO]: Epoch 093 - training loss: 0.1821, validation loss: 0.1915
2024-06-03 07:46:55 [INFO]: Epoch 094 - training loss: 0.1809, validation loss: 0.1933
2024-06-03 07:49:01 [INFO]: Epoch 095 - training loss: 0.1781, validation loss: 0.1918
2024-06-03 07:51:07 [INFO]: Epoch 096 - training loss: 0.1744, validation loss: 0.1933
2024-06-03 07:53:13 [INFO]: Epoch 097 - training loss: 0.1643, validation loss: 0.1933
2024-06-03 07:55:20 [INFO]: Epoch 098 - training loss: 0.1769, validation loss: 0.1931
2024-06-03 07:57:26 [INFO]: Epoch 099 - training loss: 0.1716, validation loss: 0.1923
2024-06-03 07:59:33 [INFO]: Epoch 100 - training loss: 0.1685, validation loss: 0.1936
2024-06-03 07:59:33 [INFO]: Finished training. The best model is from epoch#93.
2024-06-03 07:59:33 [INFO]: Saved the model to results_subseq_rate05/Electricity/CSDI_Electricity/round_0/20240603_T040926/CSDI.pypots
2024-06-03 08:16:44 [INFO]: Successfully saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_0/imputation.pkl
2024-06-03 08:16:44 [INFO]: Round0 - CSDI on Electricity: MAE=0.8696, MSE=2.0621, MRE=0.4613
2024-06-03 08:16:44 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 08:16:44 [INFO]: Using the given device: cuda:0
2024-06-03 08:16:44 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_1/20240603_T081644
2024-06-03 08:16:44 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_1/20240603_T081644/tensorboard
2024-06-03 08:16:44 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 08:18:51 [INFO]: Epoch 001 - training loss: 0.6857, validation loss: 0.4603
2024-06-03 08:20:57 [INFO]: Epoch 002 - training loss: 0.3788, validation loss: 0.3883
2024-06-03 08:23:03 [INFO]: Epoch 003 - training loss: 0.3587, validation loss: 0.3652
2024-06-03 08:25:09 [INFO]: Epoch 004 - training loss: 0.3639, validation loss: 0.3383
2024-06-03 08:27:15 [INFO]: Epoch 005 - training loss: 0.3287, validation loss: 0.3200
2024-06-03 08:29:22 [INFO]: Epoch 006 - training loss: 0.3014, validation loss: 0.3076
2024-06-03 08:31:28 [INFO]: Epoch 007 - training loss: 0.3102, validation loss: 0.2968
2024-06-03 08:33:35 [INFO]: Epoch 008 - training loss: 0.3002, validation loss: 0.2915
2024-06-03 08:35:42 [INFO]: Epoch 009 - training loss: 0.2695, validation loss: 0.2809
2024-06-03 08:37:48 [INFO]: Epoch 010 - training loss: 0.2564, validation loss: 0.2664
2024-06-03 08:39:54 [INFO]: Epoch 011 - training loss: 0.2846, validation loss: 0.2575
2024-06-03 08:42:01 [INFO]: Epoch 012 - training loss: 0.2502, validation loss: 0.2512
2024-06-03 08:44:07 [INFO]: Epoch 013 - training loss: 0.2331, validation loss: 0.2490
2024-06-03 08:46:13 [INFO]: Epoch 014 - training loss: 0.2355, validation loss: 0.2432
2024-06-03 08:48:18 [INFO]: Epoch 015 - training loss: 0.2353, validation loss: 0.2380
2024-06-03 08:50:24 [INFO]: Epoch 016 - training loss: 0.2275, validation loss: 0.2351
2024-06-03 08:52:30 [INFO]: Epoch 017 - training loss: 0.2383, validation loss: 0.2364
2024-06-03 08:54:37 [INFO]: Epoch 018 - training loss: 0.2210, validation loss: 0.2333
2024-06-03 08:56:43 [INFO]: Epoch 019 - training loss: 0.2054, validation loss: 0.2292
2024-06-03 08:58:50 [INFO]: Epoch 020 - training loss: 0.2154, validation loss: 0.2255
2024-06-03 09:00:56 [INFO]: Epoch 021 - training loss: 0.2307, validation loss: 0.2241
2024-06-03 09:03:01 [INFO]: Epoch 022 - training loss: 0.2110, validation loss: 0.2225
2024-06-03 09:05:08 [INFO]: Epoch 023 - training loss: 0.2138, validation loss: 0.2247
2024-06-03 09:07:14 [INFO]: Epoch 024 - training loss: 0.2035, validation loss: 0.2186
2024-06-03 09:09:21 [INFO]: Epoch 025 - training loss: 0.2123, validation loss: 0.2211
2024-06-03 09:11:27 [INFO]: Epoch 026 - training loss: 0.2028, validation loss: 0.2159
2024-06-03 09:13:34 [INFO]: Epoch 027 - training loss: 0.1929, validation loss: 0.2162
2024-06-03 09:15:41 [INFO]: Epoch 028 - training loss: 0.2123, validation loss: 0.2128
2024-06-03 09:17:47 [INFO]: Epoch 029 - training loss: 0.2100, validation loss: 0.2133
2024-06-03 09:19:54 [INFO]: Epoch 030 - training loss: 0.1928, validation loss: 0.2114
2024-06-03 09:22:01 [INFO]: Epoch 031 - training loss: 0.1938, validation loss: 0.2106
2024-06-03 09:24:07 [INFO]: Epoch 032 - training loss: 0.2219, validation loss: 0.2092
2024-06-03 09:26:14 [INFO]: Epoch 033 - training loss: 0.1974, validation loss: 0.2077
2024-06-03 09:28:20 [INFO]: Epoch 034 - training loss: 0.1885, validation loss: 0.2065
2024-06-03 09:30:27 [INFO]: Epoch 035 - training loss: 0.1733, validation loss: 0.2051
2024-06-03 09:32:33 [INFO]: Epoch 036 - training loss: 0.2066, validation loss: 0.2045
2024-06-03 09:34:40 [INFO]: Epoch 037 - training loss: 0.2087, validation loss: 0.2062
2024-06-03 09:36:46 [INFO]: Epoch 038 - training loss: 0.1743, validation loss: 0.2037
2024-06-03 09:38:53 [INFO]: Epoch 039 - training loss: 0.1780, validation loss: 0.2032
2024-06-03 09:41:00 [INFO]: Epoch 040 - training loss: 0.1863, validation loss: 0.2037
2024-06-03 09:43:07 [INFO]: Epoch 041 - training loss: 0.2023, validation loss: 0.2006
2024-06-03 09:45:13 [INFO]: Epoch 042 - training loss: 0.1802, validation loss: 0.2016
2024-06-03 09:47:20 [INFO]: Epoch 043 - training loss: 0.1917, validation loss: 0.2006
2024-06-03 09:49:26 [INFO]: Epoch 044 - training loss: 0.1976, validation loss: 0.1995
2024-06-03 09:51:33 [INFO]: Epoch 045 - training loss: 0.1770, validation loss: 0.1988
2024-06-03 09:53:39 [INFO]: Epoch 046 - training loss: 0.1697, validation loss: 0.1982
2024-06-03 09:55:46 [INFO]: Epoch 047 - training loss: 0.1908, validation loss: 0.1965
2024-06-03 09:57:52 [INFO]: Epoch 048 - training loss: 0.1783, validation loss: 0.1988
2024-06-03 09:59:59 [INFO]: Epoch 049 - training loss: 0.1969, validation loss: 0.1958
2024-06-03 10:02:05 [INFO]: Epoch 050 - training loss: 0.1791, validation loss: 0.1960
2024-06-03 10:04:12 [INFO]: Epoch 051 - training loss: 0.1858, validation loss: 0.1948
2024-06-03 10:06:19 [INFO]: Epoch 052 - training loss: 0.1810, validation loss: 0.1956
2024-06-03 10:08:26 [INFO]: Epoch 053 - training loss: 0.1762, validation loss: 0.1964
2024-06-03 10:10:32 [INFO]: Epoch 054 - training loss: 0.1913, validation loss: 0.1967
2024-06-03 10:12:39 [INFO]: Epoch 055 - training loss: 0.1846, validation loss: 0.2077
2024-06-03 10:14:46 [INFO]: Epoch 056 - training loss: 0.1685, validation loss: 0.1935
2024-06-03 10:16:52 [INFO]: Epoch 057 - training loss: 0.1774, validation loss: 0.1942
2024-06-03 10:18:59 [INFO]: Epoch 058 - training loss: 0.1832, validation loss: 0.1944
2024-06-03 10:21:04 [INFO]: Epoch 059 - training loss: 0.1797, validation loss: 0.1944
2024-06-03 10:23:10 [INFO]: Epoch 060 - training loss: 0.1853, validation loss: 0.1935
2024-06-03 10:25:17 [INFO]: Epoch 061 - training loss: 0.1761, validation loss: 0.1933
2024-06-03 10:27:24 [INFO]: Epoch 062 - training loss: 0.1866, validation loss: 0.1930
2024-06-03 10:29:30 [INFO]: Epoch 063 - training loss: 0.1785, validation loss: 0.1935
2024-06-03 10:31:37 [INFO]: Epoch 064 - training loss: 0.1757, validation loss: 0.1925
2024-06-03 10:33:43 [INFO]: Epoch 065 - training loss: 0.1851, validation loss: 0.1941
2024-06-03 10:35:50 [INFO]: Epoch 066 - training loss: 0.1698, validation loss: 0.1920
2024-06-03 10:37:56 [INFO]: Epoch 067 - training loss: 0.1796, validation loss: 0.1900
2024-06-03 10:40:02 [INFO]: Epoch 068 - training loss: 0.1802, validation loss: 0.1920
2024-06-03 10:42:09 [INFO]: Epoch 069 - training loss: 0.1614, validation loss: 0.1914
2024-06-03 10:44:15 [INFO]: Epoch 070 - training loss: 0.1720, validation loss: 0.1908
2024-06-03 10:46:22 [INFO]: Epoch 071 - training loss: 0.1653, validation loss: 0.1897
2024-06-03 10:48:28 [INFO]: Epoch 072 - training loss: 0.1794, validation loss: 0.1898
2024-06-03 10:50:34 [INFO]: Epoch 073 - training loss: 0.1797, validation loss: 0.1924
2024-06-03 10:52:41 [INFO]: Epoch 074 - training loss: 0.1746, validation loss: 0.1948
2024-06-03 10:54:48 [INFO]: Epoch 075 - training loss: 0.1793, validation loss: 0.1914
2024-06-03 10:56:54 [INFO]: Epoch 076 - training loss: 0.1801, validation loss: 0.1931
2024-06-03 10:59:01 [INFO]: Epoch 077 - training loss: 0.1661, validation loss: 0.1932
2024-06-03 11:01:07 [INFO]: Epoch 078 - training loss: 0.1811, validation loss: 0.1933
2024-06-03 11:03:14 [INFO]: Epoch 079 - training loss: 0.1811, validation loss: 0.1885
2024-06-03 11:05:20 [INFO]: Epoch 080 - training loss: 0.1658, validation loss: 0.1890
2024-06-03 11:07:27 [INFO]: Epoch 081 - training loss: 0.1827, validation loss: 0.1907
2024-06-03 11:09:33 [INFO]: Epoch 082 - training loss: 0.1724, validation loss: 0.1892
2024-06-03 11:11:40 [INFO]: Epoch 083 - training loss: 0.1690, validation loss: 0.1889
2024-06-03 11:13:47 [INFO]: Epoch 084 - training loss: 0.1931, validation loss: 0.1913
2024-06-03 11:15:54 [INFO]: Epoch 085 - training loss: 0.1729, validation loss: 0.1942
2024-06-03 11:18:00 [INFO]: Epoch 086 - training loss: 0.1646, validation loss: 0.1888
2024-06-03 11:20:07 [INFO]: Epoch 087 - training loss: 0.1717, validation loss: 0.1877
2024-06-03 11:22:14 [INFO]: Epoch 088 - training loss: 0.1813, validation loss: 0.1895
2024-06-03 11:24:20 [INFO]: Epoch 089 - training loss: 0.1963, validation loss: 0.1889
2024-06-03 11:26:27 [INFO]: Epoch 090 - training loss: 0.1643, validation loss: 0.1915
2024-06-03 11:28:33 [INFO]: Epoch 091 - training loss: 0.1786, validation loss: 0.1889
2024-06-03 11:30:39 [INFO]: Epoch 092 - training loss: 0.1667, validation loss: 0.1889
2024-06-03 11:32:46 [INFO]: Epoch 093 - training loss: 0.1702, validation loss: 0.1884
2024-06-03 11:34:53 [INFO]: Epoch 094 - training loss: 0.1668, validation loss: 0.1868
2024-06-03 11:36:59 [INFO]: Epoch 095 - training loss: 0.1618, validation loss: 0.1889
2024-06-03 11:39:06 [INFO]: Epoch 096 - training loss: 0.1792, validation loss: 0.1857
2024-06-03 11:41:13 [INFO]: Epoch 097 - training loss: 0.1825, validation loss: 0.1884
2024-06-03 11:43:07 [INFO]: Epoch 098 - training loss: 0.1632, validation loss: 0.1896
2024-06-03 11:44:49 [INFO]: Epoch 099 - training loss: 0.1896, validation loss: 0.1866
2024-06-03 11:46:31 [INFO]: Epoch 100 - training loss: 0.1655, validation loss: 0.1881
2024-06-03 11:46:31 [INFO]: Finished training. The best model is from epoch#96.
2024-06-03 11:46:31 [INFO]: Saved the model to results_subseq_rate05/Electricity/CSDI_Electricity/round_1/20240603_T081644/CSDI.pypots
2024-06-03 12:00:27 [INFO]: Successfully saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_1/imputation.pkl
2024-06-03 12:00:27 [INFO]: Round1 - CSDI on Electricity: MAE=0.8081, MSE=2.4678, MRE=0.4286
2024-06-03 12:00:27 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 12:00:27 [INFO]: Using the given device: cuda:0
2024-06-03 12:00:28 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_2/20240603_T120027
2024-06-03 12:00:28 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_2/20240603_T120027/tensorboard
2024-06-03 12:00:28 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 12:02:10 [INFO]: Epoch 001 - training loss: 0.6907, validation loss: 0.4677
2024-06-03 12:03:52 [INFO]: Epoch 002 - training loss: 0.3922, validation loss: 0.4242
2024-06-03 12:05:35 [INFO]: Epoch 003 - training loss: 0.3786, validation loss: 0.3784
2024-06-03 12:07:18 [INFO]: Epoch 004 - training loss: 0.3559, validation loss: 0.3702
2024-06-03 12:09:00 [INFO]: Epoch 005 - training loss: 0.2964, validation loss: 0.3645
2024-06-03 12:10:43 [INFO]: Epoch 006 - training loss: 0.2872, validation loss: 0.3362
2024-06-03 12:12:25 [INFO]: Epoch 007 - training loss: 0.2774, validation loss: 0.3116
2024-06-03 12:14:08 [INFO]: Epoch 008 - training loss: 0.2590, validation loss: 0.3009
2024-06-03 12:15:50 [INFO]: Epoch 009 - training loss: 0.2929, validation loss: 0.2837
2024-06-03 12:17:33 [INFO]: Epoch 010 - training loss: 0.2426, validation loss: 0.2774
2024-06-03 12:19:15 [INFO]: Epoch 011 - training loss: 0.2482, validation loss: 0.2662
2024-06-03 12:20:58 [INFO]: Epoch 012 - training loss: 0.2576, validation loss: 0.2602
2024-06-03 12:22:40 [INFO]: Epoch 013 - training loss: 0.2175, validation loss: 0.2597
2024-06-03 12:24:23 [INFO]: Epoch 014 - training loss: 0.2065, validation loss: 0.2571
2024-06-03 12:26:05 [INFO]: Epoch 015 - training loss: 0.2434, validation loss: 0.2495
2024-06-03 12:27:47 [INFO]: Epoch 016 - training loss: 0.2432, validation loss: 0.2494
2024-06-03 12:29:30 [INFO]: Epoch 017 - training loss: 0.2293, validation loss: 0.2515
2024-06-03 12:31:12 [INFO]: Epoch 018 - training loss: 0.2187, validation loss: 0.2443
2024-06-03 12:32:54 [INFO]: Epoch 019 - training loss: 0.2356, validation loss: 0.2429
2024-06-03 12:34:36 [INFO]: Epoch 020 - training loss: 0.2204, validation loss: 0.2391
2024-06-03 12:36:19 [INFO]: Epoch 021 - training loss: 0.2054, validation loss: 0.2386
2024-06-03 12:38:01 [INFO]: Epoch 022 - training loss: 0.1922, validation loss: 0.2344
2024-06-03 12:39:43 [INFO]: Epoch 023 - training loss: 0.2148, validation loss: 0.2327
2024-06-03 12:41:25 [INFO]: Epoch 024 - training loss: 0.2374, validation loss: 0.2295
2024-06-03 12:43:07 [INFO]: Epoch 025 - training loss: 0.2191, validation loss: 0.2263
2024-06-03 12:44:50 [INFO]: Epoch 026 - training loss: 0.2149, validation loss: 0.2226
2024-06-03 12:46:32 [INFO]: Epoch 027 - training loss: 0.1984, validation loss: 0.2237
2024-06-03 12:48:14 [INFO]: Epoch 028 - training loss: 0.2075, validation loss: 0.2234
2024-06-03 12:49:56 [INFO]: Epoch 029 - training loss: 0.1801, validation loss: 0.2201
2024-06-03 12:51:38 [INFO]: Epoch 030 - training loss: 0.2015, validation loss: 0.2180
2024-06-03 12:53:20 [INFO]: Epoch 031 - training loss: 0.2097, validation loss: 0.2220
2024-06-03 12:55:03 [INFO]: Epoch 032 - training loss: 0.2177, validation loss: 0.2191
2024-06-03 12:56:45 [INFO]: Epoch 033 - training loss: 0.1945, validation loss: 0.2136
2024-06-03 12:58:27 [INFO]: Epoch 034 - training loss: 0.2232, validation loss: 0.2139
2024-06-03 13:00:09 [INFO]: Epoch 035 - training loss: 0.2039, validation loss: 0.2142
2024-06-03 13:01:51 [INFO]: Epoch 036 - training loss: 0.2024, validation loss: 0.2114
2024-06-03 13:03:34 [INFO]: Epoch 037 - training loss: 0.2181, validation loss: 0.2114
2024-06-03 13:05:16 [INFO]: Epoch 038 - training loss: 0.1893, validation loss: 0.2109
2024-06-03 13:06:58 [INFO]: Epoch 039 - training loss: 0.1983, validation loss: 0.2113
2024-06-03 13:08:40 [INFO]: Epoch 040 - training loss: 0.1922, validation loss: 0.2105
2024-06-03 13:10:22 [INFO]: Epoch 041 - training loss: 0.2109, validation loss: 0.2065
2024-06-03 13:12:04 [INFO]: Epoch 042 - training loss: 0.1879, validation loss: 0.2068
2024-06-03 13:13:47 [INFO]: Epoch 043 - training loss: 0.1923, validation loss: 0.2066
2024-06-03 13:15:29 [INFO]: Epoch 044 - training loss: 0.2059, validation loss: 0.2036
2024-06-03 13:17:11 [INFO]: Epoch 045 - training loss: 0.2024, validation loss: 0.2041
2024-06-03 13:18:53 [INFO]: Epoch 046 - training loss: 0.1790, validation loss: 0.2048
2024-06-03 13:20:35 [INFO]: Epoch 047 - training loss: 0.1869, validation loss: 0.2009
2024-06-03 13:22:17 [INFO]: Epoch 048 - training loss: 0.1948, validation loss: 0.2016
2024-06-03 13:24:00 [INFO]: Epoch 049 - training loss: 0.1928, validation loss: 0.2010
2024-06-03 13:25:42 [INFO]: Epoch 050 - training loss: 0.1953, validation loss: 0.2011
2024-06-03 13:27:24 [INFO]: Epoch 051 - training loss: 0.1700, validation loss: 0.2002
2024-06-03 13:29:07 [INFO]: Epoch 052 - training loss: 0.1957, validation loss: 0.1976
2024-06-03 13:30:49 [INFO]: Epoch 053 - training loss: 0.1950, validation loss: 0.2001
2024-06-03 13:32:32 [INFO]: Epoch 054 - training loss: 0.1776, validation loss: 0.1968
2024-06-03 13:34:15 [INFO]: Epoch 055 - training loss: 0.1723, validation loss: 0.1967
2024-06-03 13:35:57 [INFO]: Epoch 056 - training loss: 0.1749, validation loss: 0.2000
2024-06-03 13:37:40 [INFO]: Epoch 057 - training loss: 0.1818, validation loss: 0.1955
2024-06-03 13:39:22 [INFO]: Epoch 058 - training loss: 0.1915, validation loss: 0.1963
2024-06-03 13:41:04 [INFO]: Epoch 059 - training loss: 0.1720, validation loss: 0.1954
2024-06-03 13:42:47 [INFO]: Epoch 060 - training loss: 0.1829, validation loss: 0.1934
2024-06-03 13:44:29 [INFO]: Epoch 061 - training loss: 0.2006, validation loss: 0.1954
2024-06-03 13:46:12 [INFO]: Epoch 062 - training loss: 0.1860, validation loss: 0.1963
2024-06-03 13:47:54 [INFO]: Epoch 063 - training loss: 0.1805, validation loss: 0.1969
2024-06-03 13:49:37 [INFO]: Epoch 064 - training loss: 0.1688, validation loss: 0.1987
2024-06-03 13:51:19 [INFO]: Epoch 065 - training loss: 0.1729, validation loss: 0.1966
2024-06-03 13:53:01 [INFO]: Epoch 066 - training loss: 0.1941, validation loss: 0.1930
2024-06-03 13:54:44 [INFO]: Epoch 067 - training loss: 0.1623, validation loss: 0.1940
2024-06-03 13:56:26 [INFO]: Epoch 068 - training loss: 0.1861, validation loss: 0.1968
2024-06-03 13:58:09 [INFO]: Epoch 069 - training loss: 0.1692, validation loss: 0.1962
2024-06-03 13:59:51 [INFO]: Epoch 070 - training loss: 0.1784, validation loss: 0.1991
2024-06-03 14:01:34 [INFO]: Epoch 071 - training loss: 0.1806, validation loss: 0.1932
2024-06-03 14:03:16 [INFO]: Epoch 072 - training loss: 0.1773, validation loss: 0.1962
2024-06-03 14:04:58 [INFO]: Epoch 073 - training loss: 0.1678, validation loss: 0.1934
2024-06-03 14:06:41 [INFO]: Epoch 074 - training loss: 0.1730, validation loss: 0.1931
2024-06-03 14:08:23 [INFO]: Epoch 075 - training loss: 0.1774, validation loss: 0.1912
2024-06-03 14:10:06 [INFO]: Epoch 076 - training loss: 0.1827, validation loss: 0.1908
2024-06-03 14:11:49 [INFO]: Epoch 077 - training loss: 0.1939, validation loss: 0.1943
2024-06-03 14:13:31 [INFO]: Epoch 078 - training loss: 0.1819, validation loss: 0.1925
2024-06-03 14:15:14 [INFO]: Epoch 079 - training loss: 0.1783, validation loss: 0.1941
2024-06-03 14:16:56 [INFO]: Epoch 080 - training loss: 0.1623, validation loss: 0.1917
2024-06-03 14:18:39 [INFO]: Epoch 081 - training loss: 0.1672, validation loss: 0.1922
2024-06-03 14:20:21 [INFO]: Epoch 082 - training loss: 0.1816, validation loss: 0.1923
2024-06-03 14:22:04 [INFO]: Epoch 083 - training loss: 0.1749, validation loss: 0.1909
2024-06-03 14:23:47 [INFO]: Epoch 084 - training loss: 0.1878, validation loss: 0.1897
2024-06-03 14:25:29 [INFO]: Epoch 085 - training loss: 0.1691, validation loss: 0.1909
2024-06-03 14:27:12 [INFO]: Epoch 086 - training loss: 0.1658, validation loss: 0.1958
2024-06-03 14:28:55 [INFO]: Epoch 087 - training loss: 0.1584, validation loss: 0.1892
2024-06-03 14:30:37 [INFO]: Epoch 088 - training loss: 0.1626, validation loss: 0.1890
2024-06-03 14:32:20 [INFO]: Epoch 089 - training loss: 0.1822, validation loss: 0.1884
2024-06-03 14:34:02 [INFO]: Epoch 090 - training loss: 0.1810, validation loss: 0.1891
2024-06-03 14:35:45 [INFO]: Epoch 091 - training loss: 0.1717, validation loss: 0.1897
2024-06-03 14:37:27 [INFO]: Epoch 092 - training loss: 0.1789, validation loss: 0.1901
2024-06-03 14:39:10 [INFO]: Epoch 093 - training loss: 0.1632, validation loss: 0.1900
2024-06-03 14:40:52 [INFO]: Epoch 094 - training loss: 0.1699, validation loss: 0.1887
2024-06-03 14:42:35 [INFO]: Epoch 095 - training loss: 0.1814, validation loss: 0.1885
2024-06-03 14:44:17 [INFO]: Epoch 096 - training loss: 0.1631, validation loss: 0.1894
2024-06-03 14:46:00 [INFO]: Epoch 097 - training loss: 0.1599, validation loss: 0.1889
2024-06-03 14:47:42 [INFO]: Epoch 098 - training loss: 0.1745, validation loss: 0.1905
2024-06-03 14:49:24 [INFO]: Epoch 099 - training loss: 0.1740, validation loss: 0.1882
2024-06-03 14:51:07 [INFO]: Epoch 100 - training loss: 0.1872, validation loss: 0.1853
2024-06-03 14:51:07 [INFO]: Finished training. The best model is from epoch#100.
2024-06-03 14:51:07 [INFO]: Saved the model to results_subseq_rate05/Electricity/CSDI_Electricity/round_2/20240603_T120027/CSDI.pypots
2024-06-03 15:05:03 [INFO]: Successfully saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_2/imputation.pkl
2024-06-03 15:05:03 [INFO]: Round2 - CSDI on Electricity: MAE=0.7443, MSE=4.0164, MRE=0.3948
2024-06-03 15:05:03 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 15:05:03 [INFO]: Using the given device: cuda:0
2024-06-03 15:05:03 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_3/20240603_T150503
2024-06-03 15:05:03 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_3/20240603_T150503/tensorboard
2024-06-03 15:05:03 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 15:06:46 [INFO]: Epoch 001 - training loss: 0.6823, validation loss: 0.4844
2024-06-03 15:08:29 [INFO]: Epoch 002 - training loss: 0.3593, validation loss: 0.3815
2024-06-03 15:10:11 [INFO]: Epoch 003 - training loss: 0.3883, validation loss: 0.3538
2024-06-03 15:11:54 [INFO]: Epoch 004 - training loss: 0.3216, validation loss: 0.3295
2024-06-03 15:13:37 [INFO]: Epoch 005 - training loss: 0.3251, validation loss: 0.3241
2024-06-03 15:15:19 [INFO]: Epoch 006 - training loss: 0.2736, validation loss: 0.3120
2024-06-03 15:17:02 [INFO]: Epoch 007 - training loss: 0.2806, validation loss: 0.2929
2024-06-03 15:18:44 [INFO]: Epoch 008 - training loss: 0.2942, validation loss: 0.2759
2024-06-03 15:20:27 [INFO]: Epoch 009 - training loss: 0.2721, validation loss: 0.2696
2024-06-03 15:22:10 [INFO]: Epoch 010 - training loss: 0.2533, validation loss: 0.2595
2024-06-03 15:23:53 [INFO]: Epoch 011 - training loss: 0.2439, validation loss: 0.2544
2024-06-03 15:25:35 [INFO]: Epoch 012 - training loss: 0.2601, validation loss: 0.2510
2024-06-03 15:27:18 [INFO]: Epoch 013 - training loss: 0.2080, validation loss: 0.2439
2024-06-03 15:29:01 [INFO]: Epoch 014 - training loss: 0.2360, validation loss: 0.2388
2024-06-03 15:30:43 [INFO]: Epoch 015 - training loss: 0.2132, validation loss: 0.2346
2024-06-03 15:32:26 [INFO]: Epoch 016 - training loss: 0.2287, validation loss: 0.2359
2024-06-03 15:34:09 [INFO]: Epoch 017 - training loss: 0.2295, validation loss: 0.2287
2024-06-03 15:35:51 [INFO]: Epoch 018 - training loss: 0.2286, validation loss: 0.2298
2024-06-03 15:37:34 [INFO]: Epoch 019 - training loss: 0.2073, validation loss: 0.2200
2024-06-03 15:39:17 [INFO]: Epoch 020 - training loss: 0.2207, validation loss: 0.2173
2024-06-03 15:40:59 [INFO]: Epoch 021 - training loss: 0.2040, validation loss: 0.2166
2024-06-03 15:42:42 [INFO]: Epoch 022 - training loss: 0.2024, validation loss: 0.2151
2024-06-03 15:44:24 [INFO]: Epoch 023 - training loss: 0.2170, validation loss: 0.2155
2024-06-03 15:46:07 [INFO]: Epoch 024 - training loss: 0.2062, validation loss: 0.2099
2024-06-03 15:47:49 [INFO]: Epoch 025 - training loss: 0.1925, validation loss: 0.2066
2024-06-03 15:49:32 [INFO]: Epoch 026 - training loss: 0.1837, validation loss: 0.2084
2024-06-03 15:51:14 [INFO]: Epoch 027 - training loss: 0.2051, validation loss: 0.2063
2024-06-03 15:52:56 [INFO]: Epoch 028 - training loss: 0.1783, validation loss: 0.2034
2024-06-03 15:54:39 [INFO]: Epoch 029 - training loss: 0.2042, validation loss: 0.2034
2024-06-03 15:56:21 [INFO]: Epoch 030 - training loss: 0.1862, validation loss: 0.2024
2024-06-03 15:58:03 [INFO]: Epoch 031 - training loss: 0.1768, validation loss: 0.2102
2024-06-03 15:59:45 [INFO]: Epoch 032 - training loss: 0.1903, validation loss: 0.2006
2024-06-03 16:01:27 [INFO]: Epoch 033 - training loss: 0.1865, validation loss: 0.2032
2024-06-03 16:03:09 [INFO]: Epoch 034 - training loss: 0.1720, validation loss: 0.1972
2024-06-03 16:04:51 [INFO]: Epoch 035 - training loss: 0.1889, validation loss: 0.1960
2024-06-03 16:06:33 [INFO]: Epoch 036 - training loss: 0.1980, validation loss: 0.1956
2024-06-03 16:08:15 [INFO]: Epoch 037 - training loss: 0.1813, validation loss: 0.1958
2024-06-03 16:09:57 [INFO]: Epoch 038 - training loss: 0.1803, validation loss: 0.1927
2024-06-03 16:11:39 [INFO]: Epoch 039 - training loss: 0.2030, validation loss: 0.1944
2024-06-03 16:13:21 [INFO]: Epoch 040 - training loss: 0.1689, validation loss: 0.1942
2024-06-03 16:15:03 [INFO]: Epoch 041 - training loss: 0.1704, validation loss: 0.1935
2024-06-03 16:16:45 [INFO]: Epoch 042 - training loss: 0.1955, validation loss: 0.1919
2024-06-03 16:18:27 [INFO]: Epoch 043 - training loss: 0.1640, validation loss: 0.1927
2024-06-03 16:20:09 [INFO]: Epoch 044 - training loss: 0.1841, validation loss: 0.1931
2024-06-03 16:21:51 [INFO]: Epoch 045 - training loss: 0.1761, validation loss: 0.1946
2024-06-03 16:23:34 [INFO]: Epoch 046 - training loss: 0.1972, validation loss: 0.1894
2024-06-03 16:25:16 [INFO]: Epoch 047 - training loss: 0.1771, validation loss: 0.1907
2024-06-03 16:26:58 [INFO]: Epoch 048 - training loss: 0.1814, validation loss: 0.1897
2024-06-03 16:28:41 [INFO]: Epoch 049 - training loss: 0.1876, validation loss: 0.1923
2024-06-03 16:30:23 [INFO]: Epoch 050 - training loss: 0.1797, validation loss: 0.1907
2024-06-03 16:32:06 [INFO]: Epoch 051 - training loss: 0.1719, validation loss: 0.1898
2024-06-03 16:33:48 [INFO]: Epoch 052 - training loss: 0.1827, validation loss: 0.1888
2024-06-03 16:35:31 [INFO]: Epoch 053 - training loss: 0.1865, validation loss: 0.1887
2024-06-03 16:37:14 [INFO]: Epoch 054 - training loss: 0.1765, validation loss: 0.1890
2024-06-03 16:38:56 [INFO]: Epoch 055 - training loss: 0.1584, validation loss: 0.1873
2024-06-03 16:40:39 [INFO]: Epoch 056 - training loss: 0.1779, validation loss: 0.1863
2024-06-03 16:42:22 [INFO]: Epoch 057 - training loss: 0.1851, validation loss: 0.1876
2024-06-03 16:44:04 [INFO]: Epoch 058 - training loss: 0.1845, validation loss: 0.1872
2024-06-03 16:45:47 [INFO]: Epoch 059 - training loss: 0.1827, validation loss: 0.1885
2024-06-03 16:47:29 [INFO]: Epoch 060 - training loss: 0.1718, validation loss: 0.1866
2024-06-03 16:49:12 [INFO]: Epoch 061 - training loss: 0.2015, validation loss: 0.1904
2024-06-03 16:50:54 [INFO]: Epoch 062 - training loss: 0.1698, validation loss: 0.1872
2024-06-03 16:52:37 [INFO]: Epoch 063 - training loss: 0.1765, validation loss: 0.1957
2024-06-03 16:54:20 [INFO]: Epoch 064 - training loss: 0.1829, validation loss: 0.1873
2024-06-03 16:56:02 [INFO]: Epoch 065 - training loss: 0.1853, validation loss: 0.1901
2024-06-03 16:57:45 [INFO]: Epoch 066 - training loss: 0.1761, validation loss: 0.1900
2024-06-03 16:57:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 16:57:45 [INFO]: Finished training. The best model is from epoch#56.
2024-06-03 16:57:45 [INFO]: Saved the model to results_subseq_rate05/Electricity/CSDI_Electricity/round_3/20240603_T150503/CSDI.pypots
2024-06-03 17:11:43 [INFO]: Successfully saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_3/imputation.pkl
2024-06-03 17:11:43 [INFO]: Round3 - CSDI on Electricity: MAE=1.0693, MSE=10.3539, MRE=0.5672
2024-06-03 17:11:43 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 17:11:43 [INFO]: Using the given device: cuda:0
2024-06-03 17:11:43 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_4/20240603_T171143
2024-06-03 17:11:43 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_4/20240603_T171143/tensorboard
2024-06-03 17:11:43 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 43,185
2024-06-03 17:13:25 [INFO]: Epoch 001 - training loss: 0.7019, validation loss: 0.5284
2024-06-03 17:15:07 [INFO]: Epoch 002 - training loss: 0.4045, validation loss: 0.3861
2024-06-03 17:16:49 [INFO]: Epoch 003 - training loss: 0.3587, validation loss: 0.3840
2024-06-03 17:18:32 [INFO]: Epoch 004 - training loss: 0.3321, validation loss: 0.3778
2024-06-03 17:20:14 [INFO]: Epoch 005 - training loss: 0.3376, validation loss: 0.3762
2024-06-03 17:21:56 [INFO]: Epoch 006 - training loss: 0.3244, validation loss: 0.3595
2024-06-03 17:23:38 [INFO]: Epoch 007 - training loss: 0.3085, validation loss: 0.3479
2024-06-03 17:25:20 [INFO]: Epoch 008 - training loss: 0.2965, validation loss: 0.3151
2024-06-03 17:27:02 [INFO]: Epoch 009 - training loss: 0.2629, validation loss: 0.2998
2024-06-03 17:28:44 [INFO]: Epoch 010 - training loss: 0.2486, validation loss: 0.2916
2024-06-03 17:30:26 [INFO]: Epoch 011 - training loss: 0.2763, validation loss: 0.2783
2024-06-03 17:32:09 [INFO]: Epoch 012 - training loss: 0.2540, validation loss: 0.2644
2024-06-03 17:33:51 [INFO]: Epoch 013 - training loss: 0.2265, validation loss: 0.2581
2024-06-03 17:35:33 [INFO]: Epoch 014 - training loss: 0.2226, validation loss: 0.2517
2024-06-03 17:37:15 [INFO]: Epoch 015 - training loss: 0.2257, validation loss: 0.2502
2024-06-03 17:38:57 [INFO]: Epoch 016 - training loss: 0.2208, validation loss: 0.2448
2024-06-03 17:40:39 [INFO]: Epoch 017 - training loss: 0.2181, validation loss: 0.2378
2024-06-03 17:42:21 [INFO]: Epoch 018 - training loss: 0.2385, validation loss: 0.2346
2024-06-03 17:44:03 [INFO]: Epoch 019 - training loss: 0.2049, validation loss: 0.2329
2024-06-03 17:45:45 [INFO]: Epoch 020 - training loss: 0.1858, validation loss: 0.2278
2024-06-03 17:47:27 [INFO]: Epoch 021 - training loss: 0.1950, validation loss: 0.2233
2024-06-03 17:49:09 [INFO]: Epoch 022 - training loss: 0.2108, validation loss: 0.2194
2024-06-03 17:50:51 [INFO]: Epoch 023 - training loss: 0.1818, validation loss: 0.2173
2024-06-03 17:52:33 [INFO]: Epoch 024 - training loss: 0.1861, validation loss: 0.2186
2024-06-03 17:54:15 [INFO]: Epoch 025 - training loss: 0.2082, validation loss: 0.2180
2024-06-03 17:55:57 [INFO]: Epoch 026 - training loss: 0.1971, validation loss: 0.2118
2024-06-03 17:57:39 [INFO]: Epoch 027 - training loss: 0.1860, validation loss: 0.2116
2024-06-03 17:59:21 [INFO]: Epoch 028 - training loss: 0.1877, validation loss: 0.2102
2024-06-03 18:01:04 [INFO]: Epoch 029 - training loss: 0.1732, validation loss: 0.2135
2024-06-03 18:02:46 [INFO]: Epoch 030 - training loss: 0.1848, validation loss: 0.2098
2024-06-03 18:04:28 [INFO]: Epoch 031 - training loss: 0.1799, validation loss: 0.2080
2024-06-03 18:06:10 [INFO]: Epoch 032 - training loss: 0.1956, validation loss: 0.2056
2024-06-03 18:07:52 [INFO]: Epoch 033 - training loss: 0.1904, validation loss: 0.2085
2024-06-03 18:09:34 [INFO]: Epoch 034 - training loss: 0.2021, validation loss: 0.2061
2024-06-03 18:11:16 [INFO]: Epoch 035 - training loss: 0.2262, validation loss: 0.2047
2024-06-03 18:12:58 [INFO]: Epoch 036 - training loss: 0.1986, validation loss: 0.2030
2024-06-03 18:14:40 [INFO]: Epoch 037 - training loss: 0.1848, validation loss: 0.2044
2024-06-03 18:16:22 [INFO]: Epoch 038 - training loss: 0.1726, validation loss: 0.2019
2024-06-03 18:18:04 [INFO]: Epoch 039 - training loss: 0.1884, validation loss: 0.2008
2024-06-03 18:19:46 [INFO]: Epoch 040 - training loss: 0.1611, validation loss: 0.2027
2024-06-03 18:21:28 [INFO]: Epoch 041 - training loss: 0.1715, validation loss: 0.2109
2024-06-03 18:23:10 [INFO]: Epoch 042 - training loss: 0.1549, validation loss: 0.2021
2024-06-03 18:24:52 [INFO]: Epoch 043 - training loss: 0.1929, validation loss: 0.2008
2024-06-03 18:26:34 [INFO]: Epoch 044 - training loss: 0.1763, validation loss: 0.1990
2024-06-03 18:28:16 [INFO]: Epoch 045 - training loss: 0.1836, validation loss: 0.2028
2024-06-03 18:29:58 [INFO]: Epoch 046 - training loss: 0.1860, validation loss: 0.2000
2024-06-03 18:31:40 [INFO]: Epoch 047 - training loss: 0.1824, validation loss: 0.1989
2024-06-03 18:33:22 [INFO]: Epoch 048 - training loss: 0.1752, validation loss: 0.1986
2024-06-03 18:35:05 [INFO]: Epoch 049 - training loss: 0.1908, validation loss: 0.1981
2024-06-03 18:36:47 [INFO]: Epoch 050 - training loss: 0.1998, validation loss: 0.1995
2024-06-03 18:38:29 [INFO]: Epoch 051 - training loss: 0.1960, validation loss: 0.1966
2024-06-03 18:40:11 [INFO]: Epoch 052 - training loss: 0.1879, validation loss: 0.1982
2024-06-03 18:41:53 [INFO]: Epoch 053 - training loss: 0.1753, validation loss: 0.1966
2024-06-03 18:43:35 [INFO]: Epoch 054 - training loss: 0.1964, validation loss: 0.1956
2024-06-03 18:45:17 [INFO]: Epoch 055 - training loss: 0.1764, validation loss: 0.1975
2024-06-03 18:46:59 [INFO]: Epoch 056 - training loss: 0.1946, validation loss: 0.1978
2024-06-03 18:48:42 [INFO]: Epoch 057 - training loss: 0.1852, validation loss: 0.2076
2024-06-03 18:50:24 [INFO]: Epoch 058 - training loss: 0.1884, validation loss: 0.1991
2024-06-03 18:52:06 [INFO]: Epoch 059 - training loss: 0.2026, validation loss: 0.1970
2024-06-03 18:53:48 [INFO]: Epoch 060 - training loss: 0.1694, validation loss: 0.1975
2024-06-03 18:55:30 [INFO]: Epoch 061 - training loss: 0.1568, validation loss: 0.1957
2024-06-03 18:57:12 [INFO]: Epoch 062 - training loss: 0.1742, validation loss: 0.1947
2024-06-03 18:58:54 [INFO]: Epoch 063 - training loss: 0.1812, validation loss: 0.1953
2024-06-03 19:00:35 [INFO]: Epoch 064 - training loss: 0.1726, validation loss: 0.1966
2024-06-03 19:02:17 [INFO]: Epoch 065 - training loss: 0.1829, validation loss: 0.1962
2024-06-03 19:03:59 [INFO]: Epoch 066 - training loss: 0.1742, validation loss: 0.1963
2024-06-03 19:05:41 [INFO]: Epoch 067 - training loss: 0.1753, validation loss: 0.1968
2024-06-03 19:07:23 [INFO]: Epoch 068 - training loss: 0.1811, validation loss: 0.1949
2024-06-03 19:09:05 [INFO]: Epoch 069 - training loss: 0.1661, validation loss: 0.1937
2024-06-03 19:10:47 [INFO]: Epoch 070 - training loss: 0.1772, validation loss: 0.1996
2024-06-03 19:12:29 [INFO]: Epoch 071 - training loss: 0.1787, validation loss: 0.1973
2024-06-03 19:14:12 [INFO]: Epoch 072 - training loss: 0.1756, validation loss: 0.1955
2024-06-03 19:15:54 [INFO]: Epoch 073 - training loss: 0.1687, validation loss: 0.1931
2024-06-03 19:17:36 [INFO]: Epoch 074 - training loss: 0.1706, validation loss: 0.1941
2024-06-03 19:19:18 [INFO]: Epoch 075 - training loss: 0.1656, validation loss: 0.1938
2024-06-03 19:21:01 [INFO]: Epoch 076 - training loss: 0.1651, validation loss: 0.1930
2024-06-03 19:22:43 [INFO]: Epoch 077 - training loss: 0.1637, validation loss: 0.1946
2024-06-03 19:24:25 [INFO]: Epoch 078 - training loss: 0.1682, validation loss: 0.1957
2024-06-03 19:26:08 [INFO]: Epoch 079 - training loss: 0.1721, validation loss: 0.1954
2024-06-03 19:27:50 [INFO]: Epoch 080 - training loss: 0.1699, validation loss: 0.1962
2024-06-03 19:29:33 [INFO]: Epoch 081 - training loss: 0.1737, validation loss: 0.1934
2024-06-03 19:31:15 [INFO]: Epoch 082 - training loss: 0.1770, validation loss: 0.1938
2024-06-03 19:32:57 [INFO]: Epoch 083 - training loss: 0.1872, validation loss: 0.1934
2024-06-03 19:34:40 [INFO]: Epoch 084 - training loss: 0.1732, validation loss: 0.1934
2024-06-03 19:36:22 [INFO]: Epoch 085 - training loss: 0.1562, validation loss: 0.1957
2024-06-03 19:38:04 [INFO]: Epoch 086 - training loss: 0.1536, validation loss: 0.1914
2024-06-03 19:39:47 [INFO]: Epoch 087 - training loss: 0.1713, validation loss: 0.1909
2024-06-03 19:41:29 [INFO]: Epoch 088 - training loss: 0.1631, validation loss: 0.1898
2024-06-03 19:43:11 [INFO]: Epoch 089 - training loss: 0.1537, validation loss: 0.1925
2024-06-03 19:44:54 [INFO]: Epoch 090 - training loss: 0.1640, validation loss: 0.1923
2024-06-03 19:46:36 [INFO]: Epoch 091 - training loss: 0.1638, validation loss: 0.1914
2024-06-03 19:48:19 [INFO]: Epoch 092 - training loss: 0.1703, validation loss: 0.1928
2024-06-03 19:50:01 [INFO]: Epoch 093 - training loss: 0.1507, validation loss: 0.1944
2024-06-03 19:51:43 [INFO]: Epoch 094 - training loss: 0.1599, validation loss: 0.1916
2024-06-03 19:53:26 [INFO]: Epoch 095 - training loss: 0.1765, validation loss: 0.1906
2024-06-03 19:55:08 [INFO]: Epoch 096 - training loss: 0.1884, validation loss: 0.1964
2024-06-03 19:56:50 [INFO]: Epoch 097 - training loss: 0.1617, validation loss: 0.1986
2024-06-03 19:58:33 [INFO]: Epoch 098 - training loss: 0.1651, validation loss: 0.1929
2024-06-03 19:58:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 19:58:33 [INFO]: Finished training. The best model is from epoch#88.
2024-06-03 19:58:33 [INFO]: Saved the model to results_subseq_rate05/Electricity/CSDI_Electricity/round_4/20240603_T171143/CSDI.pypots
2024-06-03 20:12:29 [INFO]: Successfully saved to results_subseq_rate05/Electricity/CSDI_Electricity/round_4/imputation.pkl
2024-06-03 20:12:29 [INFO]: Round4 - CSDI on Electricity: MAE=1.1210, MSE=14.1720, MRE=0.5946
2024-06-03 20:12:29 [INFO]: Done! Final results:
Averaged CSDI (43,185 params) on Electricity: MAE=0.9225 ± 0.14735233173053294, MSE=6.6144 ± 4.8118247838482056, MRE=0.4893 ± 0.07816193517471606, average inference time=875.36
