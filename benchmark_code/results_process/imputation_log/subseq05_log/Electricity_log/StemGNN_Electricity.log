2024-06-03 05:05:50 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 05:05:50 [INFO]: Using the given device: cuda:0
2024-06-03 05:05:50 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_0/20240603_T050550
2024-06-03 05:05:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_0/20240603_T050550/tensorboard
2024-06-03 05:05:51 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 05:06:12 [INFO]: Epoch 001 - training loss: 1.4856, validation loss: 3.8997
2024-06-03 05:06:40 [INFO]: Epoch 002 - training loss: 1.1384, validation loss: 3.7765
2024-06-03 05:07:08 [INFO]: Epoch 003 - training loss: 0.9824, validation loss: 3.7327
2024-06-03 05:07:37 [INFO]: Epoch 004 - training loss: 0.8818, validation loss: 3.5945
2024-06-03 05:08:06 [INFO]: Epoch 005 - training loss: 0.7852, validation loss: 3.3967
2024-06-03 05:08:33 [INFO]: Epoch 006 - training loss: 0.7094, validation loss: 3.2958
2024-06-03 05:09:02 [INFO]: Epoch 007 - training loss: 0.6729, validation loss: 3.2370
2024-06-03 05:09:30 [INFO]: Epoch 008 - training loss: 0.6522, validation loss: 3.2164
2024-06-03 05:09:58 [INFO]: Epoch 009 - training loss: 0.6361, validation loss: 3.1819
2024-06-03 05:10:26 [INFO]: Epoch 010 - training loss: 0.6195, validation loss: 3.1547
2024-06-03 05:10:54 [INFO]: Epoch 011 - training loss: 0.6034, validation loss: 3.1445
2024-06-03 05:11:21 [INFO]: Epoch 012 - training loss: 0.5897, validation loss: 3.1285
2024-06-03 05:11:50 [INFO]: Epoch 013 - training loss: 0.5784, validation loss: 3.1059
2024-06-03 05:12:18 [INFO]: Epoch 014 - training loss: 0.5687, validation loss: 3.0927
2024-06-03 05:12:46 [INFO]: Epoch 015 - training loss: 0.5592, validation loss: 3.0971
2024-06-03 05:13:14 [INFO]: Epoch 016 - training loss: 0.5499, validation loss: 3.0657
2024-06-03 05:13:42 [INFO]: Epoch 017 - training loss: 0.5404, validation loss: 3.0687
2024-06-03 05:14:10 [INFO]: Epoch 018 - training loss: 0.5316, validation loss: 3.0619
2024-06-03 05:14:38 [INFO]: Epoch 019 - training loss: 0.5236, validation loss: 3.0463
2024-06-03 05:15:07 [INFO]: Epoch 020 - training loss: 0.5162, validation loss: 3.0546
2024-06-03 05:15:35 [INFO]: Epoch 021 - training loss: 0.5111, validation loss: 3.0556
2024-06-03 05:16:03 [INFO]: Epoch 022 - training loss: 0.5053, validation loss: 3.0478
2024-06-03 05:16:26 [INFO]: Epoch 023 - training loss: 0.5004, validation loss: 3.0548
2024-06-03 05:16:53 [INFO]: Epoch 024 - training loss: 0.4961, validation loss: 3.0307
2024-06-03 05:17:21 [INFO]: Epoch 025 - training loss: 0.4912, validation loss: 3.0305
2024-06-03 05:17:49 [INFO]: Epoch 026 - training loss: 0.4872, validation loss: 3.0470
2024-06-03 05:18:18 [INFO]: Epoch 027 - training loss: 0.4827, validation loss: 3.0310
2024-06-03 05:18:46 [INFO]: Epoch 028 - training loss: 0.4793, validation loss: 3.0245
2024-06-03 05:19:15 [INFO]: Epoch 029 - training loss: 0.4758, validation loss: 3.0355
2024-06-03 05:19:43 [INFO]: Epoch 030 - training loss: 0.4722, validation loss: 3.0423
2024-06-03 05:20:11 [INFO]: Epoch 031 - training loss: 0.4688, validation loss: 3.0283
2024-06-03 05:20:39 [INFO]: Epoch 032 - training loss: 0.4664, validation loss: 3.0303
2024-06-03 05:21:08 [INFO]: Epoch 033 - training loss: 0.4629, validation loss: 3.0263
2024-06-03 05:21:36 [INFO]: Epoch 034 - training loss: 0.4601, validation loss: 3.0274
2024-06-03 05:22:04 [INFO]: Epoch 035 - training loss: 0.4580, validation loss: 3.0314
2024-06-03 05:22:33 [INFO]: Epoch 036 - training loss: 0.4560, validation loss: 3.0300
2024-06-03 05:23:01 [INFO]: Epoch 037 - training loss: 0.4534, validation loss: 3.0074
2024-06-03 05:23:30 [INFO]: Epoch 038 - training loss: 0.4508, validation loss: 3.0232
2024-06-03 05:23:58 [INFO]: Epoch 039 - training loss: 0.4483, validation loss: 3.0334
2024-06-03 05:24:27 [INFO]: Epoch 040 - training loss: 0.4458, validation loss: 3.0185
2024-06-03 05:24:54 [INFO]: Epoch 041 - training loss: 0.4440, validation loss: 3.0318
2024-06-03 05:25:23 [INFO]: Epoch 042 - training loss: 0.4424, validation loss: 3.0057
2024-06-03 05:25:51 [INFO]: Epoch 043 - training loss: 0.4408, validation loss: 3.0195
2024-06-03 05:26:20 [INFO]: Epoch 044 - training loss: 0.4381, validation loss: 3.0279
2024-06-03 05:26:48 [INFO]: Epoch 045 - training loss: 0.4366, validation loss: 3.0170
2024-06-03 05:27:16 [INFO]: Epoch 046 - training loss: 0.4344, validation loss: 3.0245
2024-06-03 05:27:44 [INFO]: Epoch 047 - training loss: 0.4324, validation loss: 3.0269
2024-06-03 05:28:13 [INFO]: Epoch 048 - training loss: 0.4306, validation loss: 3.0254
2024-06-03 05:28:41 [INFO]: Epoch 049 - training loss: 0.4286, validation loss: 3.0180
2024-06-03 05:29:10 [INFO]: Epoch 050 - training loss: 0.4275, validation loss: 3.0287
2024-06-03 05:29:36 [INFO]: Epoch 051 - training loss: 0.4266, validation loss: 3.0227
2024-06-03 05:30:03 [INFO]: Epoch 052 - training loss: 0.4246, validation loss: 3.0356
2024-06-03 05:30:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:30:03 [INFO]: Finished training. The best model is from epoch#42.
2024-06-03 05:30:03 [INFO]: Saved the model to results_subseq_rate05/Electricity/StemGNN_Electricity/round_0/20240603_T050550/StemGNN.pypots
2024-06-03 05:30:06 [INFO]: Successfully saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_0/imputation.pkl
2024-06-03 05:30:06 [INFO]: Round0 - StemGNN on Electricity: MAE=1.5078, MSE=4.5262, MRE=0.7998
2024-06-03 05:30:06 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 05:30:06 [INFO]: Using the given device: cuda:0
2024-06-03 05:30:06 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_1/20240603_T053006
2024-06-03 05:30:06 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_1/20240603_T053006/tensorboard
2024-06-03 05:30:07 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 05:30:36 [INFO]: Epoch 001 - training loss: 1.4932, validation loss: 3.8801
2024-06-03 05:30:57 [INFO]: Epoch 002 - training loss: 1.1750, validation loss: 3.7783
2024-06-03 05:31:24 [INFO]: Epoch 003 - training loss: 1.0523, validation loss: 3.7819
2024-06-03 05:31:53 [INFO]: Epoch 004 - training loss: 0.9348, validation loss: 3.6132
2024-06-03 05:32:21 [INFO]: Epoch 005 - training loss: 0.8059, validation loss: 3.4081
2024-06-03 05:32:49 [INFO]: Epoch 006 - training loss: 0.7169, validation loss: 3.2551
2024-06-03 05:33:17 [INFO]: Epoch 007 - training loss: 0.6673, validation loss: 3.1650
2024-06-03 05:33:45 [INFO]: Epoch 008 - training loss: 0.6437, validation loss: 3.1372
2024-06-03 05:34:14 [INFO]: Epoch 009 - training loss: 0.6247, validation loss: 3.1036
2024-06-03 05:34:42 [INFO]: Epoch 010 - training loss: 0.6080, validation loss: 3.0981
2024-06-03 05:35:10 [INFO]: Epoch 011 - training loss: 0.5940, validation loss: 3.0852
2024-06-03 05:35:38 [INFO]: Epoch 012 - training loss: 0.5812, validation loss: 3.0710
2024-06-03 05:36:06 [INFO]: Epoch 013 - training loss: 0.5697, validation loss: 3.0635
2024-06-03 05:36:35 [INFO]: Epoch 014 - training loss: 0.5576, validation loss: 3.0514
2024-06-03 05:37:04 [INFO]: Epoch 015 - training loss: 0.5465, validation loss: 3.0447
2024-06-03 05:37:32 [INFO]: Epoch 016 - training loss: 0.5367, validation loss: 3.0265
2024-06-03 05:38:00 [INFO]: Epoch 017 - training loss: 0.5290, validation loss: 3.0220
2024-06-03 05:38:24 [INFO]: Epoch 018 - training loss: 0.5209, validation loss: 3.0112
2024-06-03 05:38:49 [INFO]: Epoch 019 - training loss: 0.5145, validation loss: 3.0061
2024-06-03 05:39:13 [INFO]: Epoch 020 - training loss: 0.5083, validation loss: 2.9990
2024-06-03 05:39:38 [INFO]: Epoch 021 - training loss: 0.5036, validation loss: 2.9951
2024-06-03 05:40:01 [INFO]: Epoch 022 - training loss: 0.4971, validation loss: 2.9906
2024-06-03 05:40:23 [INFO]: Epoch 023 - training loss: 0.4925, validation loss: 2.9880
2024-06-03 05:40:48 [INFO]: Epoch 024 - training loss: 0.4872, validation loss: 2.9945
2024-06-03 05:41:12 [INFO]: Epoch 025 - training loss: 0.4826, validation loss: 2.9924
2024-06-03 05:41:37 [INFO]: Epoch 026 - training loss: 0.4786, validation loss: 2.9845
2024-06-03 05:42:02 [INFO]: Epoch 027 - training loss: 0.4757, validation loss: 2.9858
2024-06-03 05:42:21 [INFO]: Epoch 028 - training loss: 0.4717, validation loss: 2.9822
2024-06-03 05:42:44 [INFO]: Epoch 029 - training loss: 0.4687, validation loss: 2.9752
2024-06-03 05:43:09 [INFO]: Epoch 030 - training loss: 0.4648, validation loss: 2.9649
2024-06-03 05:43:33 [INFO]: Epoch 031 - training loss: 0.4610, validation loss: 2.9602
2024-06-03 05:43:58 [INFO]: Epoch 032 - training loss: 0.4583, validation loss: 2.9605
2024-06-03 05:44:23 [INFO]: Epoch 033 - training loss: 0.4558, validation loss: 2.9585
2024-06-03 05:44:48 [INFO]: Epoch 034 - training loss: 0.4536, validation loss: 2.9492
2024-06-03 05:45:12 [INFO]: Epoch 035 - training loss: 0.4516, validation loss: 2.9565
2024-06-03 05:45:36 [INFO]: Epoch 036 - training loss: 0.4494, validation loss: 2.9545
2024-06-03 05:46:01 [INFO]: Epoch 037 - training loss: 0.4462, validation loss: 2.9566
2024-06-03 05:46:25 [INFO]: Epoch 038 - training loss: 0.4437, validation loss: 2.9529
2024-06-03 05:46:50 [INFO]: Epoch 039 - training loss: 0.4415, validation loss: 2.9532
2024-06-03 05:47:13 [INFO]: Epoch 040 - training loss: 0.4399, validation loss: 2.9485
2024-06-03 05:47:36 [INFO]: Epoch 041 - training loss: 0.4378, validation loss: 2.9403
2024-06-03 05:47:59 [INFO]: Epoch 042 - training loss: 0.4359, validation loss: 2.9472
2024-06-03 05:48:22 [INFO]: Epoch 043 - training loss: 0.4338, validation loss: 2.9465
2024-06-03 05:48:45 [INFO]: Epoch 044 - training loss: 0.4313, validation loss: 2.9412
2024-06-03 05:49:06 [INFO]: Epoch 045 - training loss: 0.4305, validation loss: 2.9355
2024-06-03 05:49:27 [INFO]: Epoch 046 - training loss: 0.4285, validation loss: 2.9369
2024-06-03 05:49:47 [INFO]: Epoch 047 - training loss: 0.4260, validation loss: 2.9435
2024-06-03 05:50:10 [INFO]: Epoch 048 - training loss: 0.4246, validation loss: 2.9364
2024-06-03 05:50:33 [INFO]: Epoch 049 - training loss: 0.4230, validation loss: 2.9399
2024-06-03 05:50:56 [INFO]: Epoch 050 - training loss: 0.4216, validation loss: 2.9401
2024-06-03 05:51:20 [INFO]: Epoch 051 - training loss: 0.4199, validation loss: 2.9385
2024-06-03 05:51:43 [INFO]: Epoch 052 - training loss: 0.4178, validation loss: 2.9422
2024-06-03 05:52:06 [INFO]: Epoch 053 - training loss: 0.4165, validation loss: 2.9412
2024-06-03 05:52:30 [INFO]: Epoch 054 - training loss: 0.4157, validation loss: 2.9351
2024-06-03 05:52:53 [INFO]: Epoch 055 - training loss: 0.4140, validation loss: 2.9407
2024-06-03 05:53:16 [INFO]: Epoch 056 - training loss: 0.4118, validation loss: 2.9361
2024-06-03 05:53:39 [INFO]: Epoch 057 - training loss: 0.4105, validation loss: 2.9353
2024-06-03 05:54:01 [INFO]: Epoch 058 - training loss: 0.4097, validation loss: 2.9465
2024-06-03 05:54:24 [INFO]: Epoch 059 - training loss: 0.4091, validation loss: 2.9412
2024-06-03 05:54:47 [INFO]: Epoch 060 - training loss: 0.4071, validation loss: 2.9280
2024-06-03 05:55:10 [INFO]: Epoch 061 - training loss: 0.4057, validation loss: 2.9396
2024-06-03 05:55:34 [INFO]: Epoch 062 - training loss: 0.4045, validation loss: 2.9332
2024-06-03 05:55:56 [INFO]: Epoch 063 - training loss: 0.4035, validation loss: 2.9286
2024-06-03 05:56:19 [INFO]: Epoch 064 - training loss: 0.4021, validation loss: 2.9315
2024-06-03 05:56:40 [INFO]: Epoch 065 - training loss: 0.4006, validation loss: 2.9273
2024-06-03 05:57:03 [INFO]: Epoch 066 - training loss: 0.3999, validation loss: 2.9281
2024-06-03 05:57:26 [INFO]: Epoch 067 - training loss: 0.3989, validation loss: 2.9311
2024-06-03 05:57:48 [INFO]: Epoch 068 - training loss: 0.3977, validation loss: 2.9385
2024-06-03 05:58:11 [INFO]: Epoch 069 - training loss: 0.3968, validation loss: 2.9363
2024-06-03 05:58:34 [INFO]: Epoch 070 - training loss: 0.3954, validation loss: 2.9331
2024-06-03 05:58:58 [INFO]: Epoch 071 - training loss: 0.3950, validation loss: 2.9367
2024-06-03 05:59:21 [INFO]: Epoch 072 - training loss: 0.3935, validation loss: 2.9568
2024-06-03 05:59:44 [INFO]: Epoch 073 - training loss: 0.3924, validation loss: 2.9544
2024-06-03 06:00:07 [INFO]: Epoch 074 - training loss: 0.3918, validation loss: 2.9595
2024-06-03 06:00:30 [INFO]: Epoch 075 - training loss: 0.3908, validation loss: 2.9536
2024-06-03 06:00:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:00:30 [INFO]: Finished training. The best model is from epoch#65.
2024-06-03 06:00:30 [INFO]: Saved the model to results_subseq_rate05/Electricity/StemGNN_Electricity/round_1/20240603_T053006/StemGNN.pypots
2024-06-03 06:00:33 [INFO]: Successfully saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_1/imputation.pkl
2024-06-03 06:00:33 [INFO]: Round1 - StemGNN on Electricity: MAE=1.4140, MSE=4.2270, MRE=0.7500
2024-06-03 06:00:33 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 06:00:33 [INFO]: Using the given device: cuda:0
2024-06-03 06:00:33 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_2/20240603_T060033
2024-06-03 06:00:33 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_2/20240603_T060033/tensorboard
2024-06-03 06:00:34 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 06:00:57 [INFO]: Epoch 001 - training loss: 1.4902, validation loss: 3.9210
2024-06-03 06:01:20 [INFO]: Epoch 002 - training loss: 1.1778, validation loss: 3.8064
2024-06-03 06:01:43 [INFO]: Epoch 003 - training loss: 1.0092, validation loss: 3.7100
2024-06-03 06:02:06 [INFO]: Epoch 004 - training loss: 0.8783, validation loss: 3.5652
2024-06-03 06:02:30 [INFO]: Epoch 005 - training loss: 0.7822, validation loss: 3.3914
2024-06-03 06:02:53 [INFO]: Epoch 006 - training loss: 0.6931, validation loss: 3.2723
2024-06-03 06:03:16 [INFO]: Epoch 007 - training loss: 0.6464, validation loss: 3.2205
2024-06-03 06:03:39 [INFO]: Epoch 008 - training loss: 0.6190, validation loss: 3.1825
2024-06-03 06:04:02 [INFO]: Epoch 009 - training loss: 0.6014, validation loss: 3.1610
2024-06-03 06:04:25 [INFO]: Epoch 010 - training loss: 0.5851, validation loss: 3.1380
2024-06-03 06:04:46 [INFO]: Epoch 011 - training loss: 0.5734, validation loss: 3.1358
2024-06-03 06:05:02 [INFO]: Epoch 012 - training loss: 0.5625, validation loss: 3.1196
2024-06-03 06:05:18 [INFO]: Epoch 013 - training loss: 0.5527, validation loss: 3.1283
2024-06-03 06:05:34 [INFO]: Epoch 014 - training loss: 0.5423, validation loss: 3.0911
2024-06-03 06:05:51 [INFO]: Epoch 015 - training loss: 0.5326, validation loss: 3.0960
2024-06-03 06:06:07 [INFO]: Epoch 016 - training loss: 0.5238, validation loss: 3.0937
2024-06-03 06:06:23 [INFO]: Epoch 017 - training loss: 0.5156, validation loss: 3.0942
2024-06-03 06:06:39 [INFO]: Epoch 018 - training loss: 0.5097, validation loss: 3.0786
2024-06-03 06:06:55 [INFO]: Epoch 019 - training loss: 0.5034, validation loss: 3.0822
2024-06-03 06:07:11 [INFO]: Epoch 020 - training loss: 0.4990, validation loss: 3.0769
2024-06-03 06:07:21 [INFO]: Epoch 021 - training loss: 0.4941, validation loss: 3.0809
2024-06-03 06:07:31 [INFO]: Epoch 022 - training loss: 0.4898, validation loss: 3.0791
2024-06-03 06:07:40 [INFO]: Epoch 023 - training loss: 0.4855, validation loss: 3.1059
2024-06-03 06:07:49 [INFO]: Epoch 024 - training loss: 0.4819, validation loss: 3.0897
2024-06-03 06:07:59 [INFO]: Epoch 025 - training loss: 0.4784, validation loss: 3.0857
2024-06-03 06:08:08 [INFO]: Epoch 026 - training loss: 0.4750, validation loss: 3.0839
2024-06-03 06:08:17 [INFO]: Epoch 027 - training loss: 0.4721, validation loss: 3.0727
2024-06-03 06:08:27 [INFO]: Epoch 028 - training loss: 0.4689, validation loss: 3.0596
2024-06-03 06:08:36 [INFO]: Epoch 029 - training loss: 0.4661, validation loss: 3.0807
2024-06-03 06:08:45 [INFO]: Epoch 030 - training loss: 0.4620, validation loss: 3.0742
2024-06-03 06:08:54 [INFO]: Epoch 031 - training loss: 0.4604, validation loss: 3.0707
2024-06-03 06:09:04 [INFO]: Epoch 032 - training loss: 0.4575, validation loss: 3.0807
2024-06-03 06:09:13 [INFO]: Epoch 033 - training loss: 0.4538, validation loss: 3.0836
2024-06-03 06:09:22 [INFO]: Epoch 034 - training loss: 0.4517, validation loss: 3.0853
2024-06-03 06:09:32 [INFO]: Epoch 035 - training loss: 0.4488, validation loss: 3.0915
2024-06-03 06:09:41 [INFO]: Epoch 036 - training loss: 0.4467, validation loss: 3.0855
2024-06-03 06:09:50 [INFO]: Epoch 037 - training loss: 0.4442, validation loss: 3.0989
2024-06-03 06:09:59 [INFO]: Epoch 038 - training loss: 0.4413, validation loss: 3.0886
2024-06-03 06:09:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:09:59 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 06:10:00 [INFO]: Saved the model to results_subseq_rate05/Electricity/StemGNN_Electricity/round_2/20240603_T060033/StemGNN.pypots
2024-06-03 06:10:01 [INFO]: Successfully saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_2/imputation.pkl
2024-06-03 06:10:01 [INFO]: Round2 - StemGNN on Electricity: MAE=1.5834, MSE=4.8736, MRE=0.8399
2024-06-03 06:10:01 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 06:10:01 [INFO]: Using the given device: cuda:0
2024-06-03 06:10:01 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_3/20240603_T061001
2024-06-03 06:10:01 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_3/20240603_T061001/tensorboard
2024-06-03 06:10:01 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 06:10:10 [INFO]: Epoch 001 - training loss: 1.4995, validation loss: 3.9802
2024-06-03 06:10:20 [INFO]: Epoch 002 - training loss: 1.1574, validation loss: 3.7926
2024-06-03 06:10:29 [INFO]: Epoch 003 - training loss: 1.0017, validation loss: 3.6892
2024-06-03 06:10:38 [INFO]: Epoch 004 - training loss: 0.8692, validation loss: 3.5273
2024-06-03 06:10:47 [INFO]: Epoch 005 - training loss: 0.7602, validation loss: 3.3854
2024-06-03 06:10:57 [INFO]: Epoch 006 - training loss: 0.7016, validation loss: 3.2949
2024-06-03 06:11:06 [INFO]: Epoch 007 - training loss: 0.6730, validation loss: 3.2516
2024-06-03 06:11:15 [INFO]: Epoch 008 - training loss: 0.6571, validation loss: 3.2288
2024-06-03 06:11:25 [INFO]: Epoch 009 - training loss: 0.6404, validation loss: 3.2067
2024-06-03 06:11:34 [INFO]: Epoch 010 - training loss: 0.6230, validation loss: 3.1966
2024-06-03 06:11:43 [INFO]: Epoch 011 - training loss: 0.6085, validation loss: 3.1922
2024-06-03 06:11:52 [INFO]: Epoch 012 - training loss: 0.5930, validation loss: 3.1783
2024-06-03 06:12:02 [INFO]: Epoch 013 - training loss: 0.5787, validation loss: 3.1767
2024-06-03 06:12:11 [INFO]: Epoch 014 - training loss: 0.5673, validation loss: 3.1668
2024-06-03 06:12:20 [INFO]: Epoch 015 - training loss: 0.5574, validation loss: 3.1618
2024-06-03 06:12:30 [INFO]: Epoch 016 - training loss: 0.5488, validation loss: 3.1519
2024-06-03 06:12:39 [INFO]: Epoch 017 - training loss: 0.5395, validation loss: 3.1450
2024-06-03 06:12:48 [INFO]: Epoch 018 - training loss: 0.5316, validation loss: 3.1394
2024-06-03 06:12:58 [INFO]: Epoch 019 - training loss: 0.5231, validation loss: 3.1317
2024-06-03 06:13:07 [INFO]: Epoch 020 - training loss: 0.5162, validation loss: 3.1281
2024-06-03 06:13:16 [INFO]: Epoch 021 - training loss: 0.5104, validation loss: 3.1318
2024-06-03 06:13:25 [INFO]: Epoch 022 - training loss: 0.5028, validation loss: 3.1241
2024-06-03 06:13:35 [INFO]: Epoch 023 - training loss: 0.4983, validation loss: 3.1224
2024-06-03 06:13:44 [INFO]: Epoch 024 - training loss: 0.4932, validation loss: 3.1239
2024-06-03 06:13:53 [INFO]: Epoch 025 - training loss: 0.4889, validation loss: 3.1141
2024-06-03 06:14:03 [INFO]: Epoch 026 - training loss: 0.4845, validation loss: 3.1140
2024-06-03 06:14:12 [INFO]: Epoch 027 - training loss: 0.4803, validation loss: 3.1141
2024-06-03 06:14:21 [INFO]: Epoch 028 - training loss: 0.4773, validation loss: 3.1220
2024-06-03 06:14:31 [INFO]: Epoch 029 - training loss: 0.4741, validation loss: 3.1143
2024-06-03 06:14:40 [INFO]: Epoch 030 - training loss: 0.4703, validation loss: 3.1105
2024-06-03 06:14:49 [INFO]: Epoch 031 - training loss: 0.4685, validation loss: 3.1199
2024-06-03 06:14:59 [INFO]: Epoch 032 - training loss: 0.4644, validation loss: 3.1174
2024-06-03 06:15:08 [INFO]: Epoch 033 - training loss: 0.4620, validation loss: 3.1118
2024-06-03 06:15:17 [INFO]: Epoch 034 - training loss: 0.4595, validation loss: 3.1145
2024-06-03 06:15:26 [INFO]: Epoch 035 - training loss: 0.4570, validation loss: 3.1179
2024-06-03 06:15:36 [INFO]: Epoch 036 - training loss: 0.4554, validation loss: 3.1173
2024-06-03 06:15:45 [INFO]: Epoch 037 - training loss: 0.4535, validation loss: 3.1127
2024-06-03 06:15:54 [INFO]: Epoch 038 - training loss: 0.4497, validation loss: 3.1154
2024-06-03 06:16:03 [INFO]: Epoch 039 - training loss: 0.4484, validation loss: 3.1102
2024-06-03 06:16:13 [INFO]: Epoch 040 - training loss: 0.4456, validation loss: 3.1112
2024-06-03 06:16:22 [INFO]: Epoch 041 - training loss: 0.4435, validation loss: 3.1119
2024-06-03 06:16:31 [INFO]: Epoch 042 - training loss: 0.4414, validation loss: 3.1170
2024-06-03 06:16:41 [INFO]: Epoch 043 - training loss: 0.4396, validation loss: 3.1140
2024-06-03 06:16:50 [INFO]: Epoch 044 - training loss: 0.4383, validation loss: 3.1172
2024-06-03 06:16:59 [INFO]: Epoch 045 - training loss: 0.4366, validation loss: 3.1147
2024-06-03 06:17:09 [INFO]: Epoch 046 - training loss: 0.4342, validation loss: 3.1129
2024-06-03 06:17:18 [INFO]: Epoch 047 - training loss: 0.4332, validation loss: 3.1104
2024-06-03 06:17:27 [INFO]: Epoch 048 - training loss: 0.4313, validation loss: 3.1203
2024-06-03 06:17:36 [INFO]: Epoch 049 - training loss: 0.4290, validation loss: 3.1232
2024-06-03 06:17:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:17:36 [INFO]: Finished training. The best model is from epoch#39.
2024-06-03 06:17:37 [INFO]: Saved the model to results_subseq_rate05/Electricity/StemGNN_Electricity/round_3/20240603_T061001/StemGNN.pypots
2024-06-03 06:17:38 [INFO]: Successfully saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_3/imputation.pkl
2024-06-03 06:17:38 [INFO]: Round3 - StemGNN on Electricity: MAE=1.6133, MSE=5.0422, MRE=0.8558
2024-06-03 06:17:38 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 06:17:38 [INFO]: Using the given device: cuda:0
2024-06-03 06:17:38 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_4/20240603_T061738
2024-06-03 06:17:38 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_4/20240603_T061738/tensorboard
2024-06-03 06:17:38 [INFO]: StemGNN initialized with the given hyperparameters, the number of trainable parameters: 16,863,634
2024-06-03 06:17:47 [INFO]: Epoch 001 - training loss: 1.4670, validation loss: 3.9302
2024-06-03 06:17:57 [INFO]: Epoch 002 - training loss: 1.1893, validation loss: 3.7907
2024-06-03 06:18:06 [INFO]: Epoch 003 - training loss: 1.0119, validation loss: 3.7249
2024-06-03 06:18:15 [INFO]: Epoch 004 - training loss: 0.8983, validation loss: 3.5463
2024-06-03 06:18:25 [INFO]: Epoch 005 - training loss: 0.8060, validation loss: 3.3076
2024-06-03 06:18:34 [INFO]: Epoch 006 - training loss: 0.7200, validation loss: 3.1235
2024-06-03 06:18:43 [INFO]: Epoch 007 - training loss: 0.6751, validation loss: 3.0732
2024-06-03 06:18:52 [INFO]: Epoch 008 - training loss: 0.6523, validation loss: 3.0515
2024-06-03 06:19:02 [INFO]: Epoch 009 - training loss: 0.6319, validation loss: 3.0265
2024-06-03 06:19:11 [INFO]: Epoch 010 - training loss: 0.6130, validation loss: 2.9999
2024-06-03 06:19:20 [INFO]: Epoch 011 - training loss: 0.5967, validation loss: 2.9837
2024-06-03 06:19:29 [INFO]: Epoch 012 - training loss: 0.5835, validation loss: 2.9697
2024-06-03 06:19:39 [INFO]: Epoch 013 - training loss: 0.5708, validation loss: 2.9525
2024-06-03 06:19:48 [INFO]: Epoch 014 - training loss: 0.5602, validation loss: 2.9505
2024-06-03 06:19:57 [INFO]: Epoch 015 - training loss: 0.5514, validation loss: 2.9473
2024-06-03 06:20:07 [INFO]: Epoch 016 - training loss: 0.5436, validation loss: 2.9307
2024-06-03 06:20:16 [INFO]: Epoch 017 - training loss: 0.5349, validation loss: 2.9287
2024-06-03 06:20:25 [INFO]: Epoch 018 - training loss: 0.5274, validation loss: 2.9153
2024-06-03 06:20:35 [INFO]: Epoch 019 - training loss: 0.5207, validation loss: 2.9131
2024-06-03 06:20:44 [INFO]: Epoch 020 - training loss: 0.5146, validation loss: 2.9064
2024-06-03 06:20:53 [INFO]: Epoch 021 - training loss: 0.5083, validation loss: 2.9047
2024-06-03 06:21:03 [INFO]: Epoch 022 - training loss: 0.5032, validation loss: 2.8982
2024-06-03 06:21:12 [INFO]: Epoch 023 - training loss: 0.4984, validation loss: 2.8958
2024-06-03 06:21:21 [INFO]: Epoch 024 - training loss: 0.4943, validation loss: 2.8969
2024-06-03 06:21:30 [INFO]: Epoch 025 - training loss: 0.4903, validation loss: 2.8921
2024-06-03 06:21:39 [INFO]: Epoch 026 - training loss: 0.4865, validation loss: 2.8841
2024-06-03 06:21:49 [INFO]: Epoch 027 - training loss: 0.4818, validation loss: 2.8896
2024-06-03 06:21:58 [INFO]: Epoch 028 - training loss: 0.4788, validation loss: 2.8818
2024-06-03 06:22:07 [INFO]: Epoch 029 - training loss: 0.4741, validation loss: 2.8878
2024-06-03 06:22:17 [INFO]: Epoch 030 - training loss: 0.4704, validation loss: 2.8846
2024-06-03 06:22:26 [INFO]: Epoch 031 - training loss: 0.4673, validation loss: 2.8873
2024-06-03 06:22:35 [INFO]: Epoch 032 - training loss: 0.4637, validation loss: 2.8867
2024-06-03 06:22:45 [INFO]: Epoch 033 - training loss: 0.4607, validation loss: 2.8874
2024-06-03 06:22:54 [INFO]: Epoch 034 - training loss: 0.4580, validation loss: 2.8915
2024-06-03 06:23:03 [INFO]: Epoch 035 - training loss: 0.4555, validation loss: 2.8870
2024-06-03 06:23:13 [INFO]: Epoch 036 - training loss: 0.4529, validation loss: 2.8881
2024-06-03 06:23:22 [INFO]: Epoch 037 - training loss: 0.4502, validation loss: 2.8951
2024-06-03 06:23:31 [INFO]: Epoch 038 - training loss: 0.4472, validation loss: 2.8988
2024-06-03 06:23:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 06:23:31 [INFO]: Finished training. The best model is from epoch#28.
2024-06-03 06:23:31 [INFO]: Saved the model to results_subseq_rate05/Electricity/StemGNN_Electricity/round_4/20240603_T061738/StemGNN.pypots
2024-06-03 06:23:32 [INFO]: Successfully saved to results_subseq_rate05/Electricity/StemGNN_Electricity/round_4/imputation.pkl
2024-06-03 06:23:32 [INFO]: Round4 - StemGNN on Electricity: MAE=1.4018, MSE=3.8890, MRE=0.7436
2024-06-03 06:23:32 [INFO]: Done! Final results:
Averaged StemGNN (16,863,634 params) on Electricity: MAE=1.5041 ± 0.08580278327552804, MSE=4.5116 ± 0.41987105885085085, MRE=0.7978 ± 0.04551344050975999, average inference time=1.67
