2024-06-03 05:05:50 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 05:05:50 [INFO]: Using the given device: cuda:0
2024-06-03 05:05:50 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_0/20240603_T050550
2024-06-03 05:05:50 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_0/20240603_T050550/tensorboard
2024-06-03 05:05:51 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-03 05:05:59 [INFO]: Epoch 001 - training loss: 0.6737, validation loss: 3.8618
2024-06-03 05:06:05 [INFO]: Epoch 002 - training loss: 0.5366, validation loss: 3.7290
2024-06-03 05:06:13 [INFO]: Epoch 003 - training loss: 0.4885, validation loss: 3.7237
2024-06-03 05:06:20 [INFO]: Epoch 004 - training loss: 0.4776, validation loss: 3.7094
2024-06-03 05:06:28 [INFO]: Epoch 005 - training loss: 0.4704, validation loss: 3.7068
2024-06-03 05:06:35 [INFO]: Epoch 006 - training loss: 0.4641, validation loss: 3.6989
2024-06-03 05:06:42 [INFO]: Epoch 007 - training loss: 0.4622, validation loss: 3.6942
2024-06-03 05:06:50 [INFO]: Epoch 008 - training loss: 0.4588, validation loss: 3.6877
2024-06-03 05:06:57 [INFO]: Epoch 009 - training loss: 0.4567, validation loss: 3.6941
2024-06-03 05:07:04 [INFO]: Epoch 010 - training loss: 0.4551, validation loss: 3.6898
2024-06-03 05:07:12 [INFO]: Epoch 011 - training loss: 0.4535, validation loss: 3.6872
2024-06-03 05:07:19 [INFO]: Epoch 012 - training loss: 0.4529, validation loss: 3.6917
2024-06-03 05:07:26 [INFO]: Epoch 013 - training loss: 0.4517, validation loss: 3.6904
2024-06-03 05:07:34 [INFO]: Epoch 014 - training loss: 0.4502, validation loss: 3.6838
2024-06-03 05:07:41 [INFO]: Epoch 015 - training loss: 0.4496, validation loss: 3.6797
2024-06-03 05:07:49 [INFO]: Epoch 016 - training loss: 0.4487, validation loss: 3.6845
2024-06-03 05:07:57 [INFO]: Epoch 017 - training loss: 0.4476, validation loss: 3.6841
2024-06-03 05:08:04 [INFO]: Epoch 018 - training loss: 0.4475, validation loss: 3.6813
2024-06-03 05:08:11 [INFO]: Epoch 019 - training loss: 0.4465, validation loss: 3.6858
2024-06-03 05:08:18 [INFO]: Epoch 020 - training loss: 0.4457, validation loss: 3.6811
2024-06-03 05:08:25 [INFO]: Epoch 021 - training loss: 0.4450, validation loss: 3.6828
2024-06-03 05:08:32 [INFO]: Epoch 022 - training loss: 0.4443, validation loss: 3.6841
2024-06-03 05:08:39 [INFO]: Epoch 023 - training loss: 0.4440, validation loss: 3.6796
2024-06-03 05:08:47 [INFO]: Epoch 024 - training loss: 0.4438, validation loss: 3.6805
2024-06-03 05:08:54 [INFO]: Epoch 025 - training loss: 0.4433, validation loss: 3.6772
2024-06-03 05:09:01 [INFO]: Epoch 026 - training loss: 0.4432, validation loss: 3.6736
2024-06-03 05:09:09 [INFO]: Epoch 027 - training loss: 0.4425, validation loss: 3.6766
2024-06-03 05:09:16 [INFO]: Epoch 028 - training loss: 0.4418, validation loss: 3.6738
2024-06-03 05:09:24 [INFO]: Epoch 029 - training loss: 0.4413, validation loss: 3.6707
2024-06-03 05:09:31 [INFO]: Epoch 030 - training loss: 0.4399, validation loss: 3.6805
2024-06-03 05:09:38 [INFO]: Epoch 031 - training loss: 0.4377, validation loss: 3.6554
2024-06-03 05:09:46 [INFO]: Epoch 032 - training loss: 0.4363, validation loss: 3.6554
2024-06-03 05:09:53 [INFO]: Epoch 033 - training loss: 0.4358, validation loss: 3.6567
2024-06-03 05:10:01 [INFO]: Epoch 034 - training loss: 0.4343, validation loss: 3.6547
2024-06-03 05:10:08 [INFO]: Epoch 035 - training loss: 0.4337, validation loss: 3.6519
2024-06-03 05:10:15 [INFO]: Epoch 036 - training loss: 0.4322, validation loss: 3.6439
2024-06-03 05:10:22 [INFO]: Epoch 037 - training loss: 0.4315, validation loss: 3.6461
2024-06-03 05:10:30 [INFO]: Epoch 038 - training loss: 0.4313, validation loss: 3.6559
2024-06-03 05:10:37 [INFO]: Epoch 039 - training loss: 0.4304, validation loss: 3.6407
2024-06-03 05:10:45 [INFO]: Epoch 040 - training loss: 0.4295, validation loss: 3.6414
2024-06-03 05:10:52 [INFO]: Epoch 041 - training loss: 0.4287, validation loss: 3.6414
2024-06-03 05:11:00 [INFO]: Epoch 042 - training loss: 0.4285, validation loss: 3.6395
2024-06-03 05:11:07 [INFO]: Epoch 043 - training loss: 0.4282, validation loss: 3.6402
2024-06-03 05:11:15 [INFO]: Epoch 044 - training loss: 0.4277, validation loss: 3.6388
2024-06-03 05:11:22 [INFO]: Epoch 045 - training loss: 0.4270, validation loss: 3.6371
2024-06-03 05:11:29 [INFO]: Epoch 046 - training loss: 0.4270, validation loss: 3.6391
2024-06-03 05:11:37 [INFO]: Epoch 047 - training loss: 0.4264, validation loss: 3.6312
2024-06-03 05:11:44 [INFO]: Epoch 048 - training loss: 0.4254, validation loss: 3.6387
2024-06-03 05:11:52 [INFO]: Epoch 049 - training loss: 0.4253, validation loss: 3.6308
2024-06-03 05:11:59 [INFO]: Epoch 050 - training loss: 0.4251, validation loss: 3.6282
2024-06-03 05:12:07 [INFO]: Epoch 051 - training loss: 0.4245, validation loss: 3.6347
2024-06-03 05:12:14 [INFO]: Epoch 052 - training loss: 0.4248, validation loss: 3.6329
2024-06-03 05:12:22 [INFO]: Epoch 053 - training loss: 0.4240, validation loss: 3.6319
2024-06-03 05:12:29 [INFO]: Epoch 054 - training loss: 0.4240, validation loss: 3.6244
2024-06-03 05:12:36 [INFO]: Epoch 055 - training loss: 0.4241, validation loss: 3.6271
2024-06-03 05:12:44 [INFO]: Epoch 056 - training loss: 0.4229, validation loss: 3.6265
2024-06-03 05:12:51 [INFO]: Epoch 057 - training loss: 0.4232, validation loss: 3.6220
2024-06-03 05:12:59 [INFO]: Epoch 058 - training loss: 0.4234, validation loss: 3.6191
2024-06-03 05:13:06 [INFO]: Epoch 059 - training loss: 0.4228, validation loss: 3.6241
2024-06-03 05:13:13 [INFO]: Epoch 060 - training loss: 0.4227, validation loss: 3.6189
2024-06-03 05:13:20 [INFO]: Epoch 061 - training loss: 0.4221, validation loss: 3.6224
2024-06-03 05:13:28 [INFO]: Epoch 062 - training loss: 0.4218, validation loss: 3.6263
2024-06-03 05:13:35 [INFO]: Epoch 063 - training loss: 0.4212, validation loss: 3.6246
2024-06-03 05:13:43 [INFO]: Epoch 064 - training loss: 0.4216, validation loss: 3.6280
2024-06-03 05:13:50 [INFO]: Epoch 065 - training loss: 0.4217, validation loss: 3.6272
2024-06-03 05:13:58 [INFO]: Epoch 066 - training loss: 0.4212, validation loss: 3.6248
2024-06-03 05:14:06 [INFO]: Epoch 067 - training loss: 0.4204, validation loss: 3.6204
2024-06-03 05:14:13 [INFO]: Epoch 068 - training loss: 0.4201, validation loss: 3.6215
2024-06-03 05:14:21 [INFO]: Epoch 069 - training loss: 0.4201, validation loss: 3.6134
2024-06-03 05:14:28 [INFO]: Epoch 070 - training loss: 0.4195, validation loss: 3.6222
2024-06-03 05:14:35 [INFO]: Epoch 071 - training loss: 0.4189, validation loss: 3.6266
2024-06-03 05:14:43 [INFO]: Epoch 072 - training loss: 0.4187, validation loss: 3.6144
2024-06-03 05:14:51 [INFO]: Epoch 073 - training loss: 0.4184, validation loss: 3.6130
2024-06-03 05:14:58 [INFO]: Epoch 074 - training loss: 0.4174, validation loss: 3.6127
2024-06-03 05:15:06 [INFO]: Epoch 075 - training loss: 0.4170, validation loss: 3.5998
2024-06-03 05:15:13 [INFO]: Epoch 076 - training loss: 0.4148, validation loss: 3.5828
2024-06-03 05:15:21 [INFO]: Epoch 077 - training loss: 0.4125, validation loss: 3.6011
2024-06-03 05:15:28 [INFO]: Epoch 078 - training loss: 0.4114, validation loss: 3.5798
2024-06-03 05:15:35 [INFO]: Epoch 079 - training loss: 0.4100, validation loss: 3.5858
2024-06-03 05:15:42 [INFO]: Epoch 080 - training loss: 0.4082, validation loss: 3.5833
2024-06-03 05:15:49 [INFO]: Epoch 081 - training loss: 0.4066, validation loss: 3.5819
2024-06-03 05:15:56 [INFO]: Epoch 082 - training loss: 0.4064, validation loss: 3.5742
2024-06-03 05:16:03 [INFO]: Epoch 083 - training loss: 0.4062, validation loss: 3.5791
2024-06-03 05:16:10 [INFO]: Epoch 084 - training loss: 0.4049, validation loss: 3.5829
2024-06-03 05:16:16 [INFO]: Epoch 085 - training loss: 0.4044, validation loss: 3.5782
2024-06-03 05:16:22 [INFO]: Epoch 086 - training loss: 0.4039, validation loss: 3.5674
2024-06-03 05:16:29 [INFO]: Epoch 087 - training loss: 0.4045, validation loss: 3.5683
2024-06-03 05:16:36 [INFO]: Epoch 088 - training loss: 0.4039, validation loss: 3.5791
2024-06-03 05:16:43 [INFO]: Epoch 089 - training loss: 0.4034, validation loss: 3.5693
2024-06-03 05:16:51 [INFO]: Epoch 090 - training loss: 0.4024, validation loss: 3.5724
2024-06-03 05:16:58 [INFO]: Epoch 091 - training loss: 0.4025, validation loss: 3.5761
2024-06-03 05:17:06 [INFO]: Epoch 092 - training loss: 0.4019, validation loss: 3.5758
2024-06-03 05:17:13 [INFO]: Epoch 093 - training loss: 0.4013, validation loss: 3.5775
2024-06-03 05:17:21 [INFO]: Epoch 094 - training loss: 0.4014, validation loss: 3.5835
2024-06-03 05:17:29 [INFO]: Epoch 095 - training loss: 0.4009, validation loss: 3.5693
2024-06-03 05:17:36 [INFO]: Epoch 096 - training loss: 0.4013, validation loss: 3.5724
2024-06-03 05:17:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:17:36 [INFO]: Finished training. The best model is from epoch#86.
2024-06-03 05:17:36 [INFO]: Saved the model to results_subseq_rate05/Electricity/MICN_Electricity/round_0/20240603_T050550/MICN.pypots
2024-06-03 05:17:37 [INFO]: Successfully saved to results_subseq_rate05/Electricity/MICN_Electricity/round_0/imputation.pkl
2024-06-03 05:17:37 [INFO]: Round0 - MICN on Electricity: MAE=1.7311, MSE=5.3384, MRE=0.9183
2024-06-03 05:17:37 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 05:17:37 [INFO]: Using the given device: cuda:0
2024-06-03 05:17:37 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_1/20240603_T051737
2024-06-03 05:17:37 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_1/20240603_T051737/tensorboard
2024-06-03 05:17:38 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-03 05:17:46 [INFO]: Epoch 001 - training loss: 0.6738, validation loss: 3.8856
2024-06-03 05:17:53 [INFO]: Epoch 002 - training loss: 0.5276, validation loss: 3.7548
2024-06-03 05:18:00 [INFO]: Epoch 003 - training loss: 0.4852, validation loss: 3.7321
2024-06-03 05:18:07 [INFO]: Epoch 004 - training loss: 0.4760, validation loss: 3.7282
2024-06-03 05:18:14 [INFO]: Epoch 005 - training loss: 0.4684, validation loss: 3.7174
2024-06-03 05:18:21 [INFO]: Epoch 006 - training loss: 0.4638, validation loss: 3.7165
2024-06-03 05:18:28 [INFO]: Epoch 007 - training loss: 0.4607, validation loss: 3.7089
2024-06-03 05:18:35 [INFO]: Epoch 008 - training loss: 0.4590, validation loss: 3.7068
2024-06-03 05:18:43 [INFO]: Epoch 009 - training loss: 0.4574, validation loss: 3.6945
2024-06-03 05:18:50 [INFO]: Epoch 010 - training loss: 0.4564, validation loss: 3.6977
2024-06-03 05:18:58 [INFO]: Epoch 011 - training loss: 0.4551, validation loss: 3.6973
2024-06-03 05:19:05 [INFO]: Epoch 012 - training loss: 0.4537, validation loss: 3.6958
2024-06-03 05:19:13 [INFO]: Epoch 013 - training loss: 0.4527, validation loss: 3.6892
2024-06-03 05:19:20 [INFO]: Epoch 014 - training loss: 0.4515, validation loss: 3.6887
2024-06-03 05:19:27 [INFO]: Epoch 015 - training loss: 0.4499, validation loss: 3.6804
2024-06-03 05:19:34 [INFO]: Epoch 016 - training loss: 0.4476, validation loss: 3.6815
2024-06-03 05:19:42 [INFO]: Epoch 017 - training loss: 0.4458, validation loss: 3.6737
2024-06-03 05:19:49 [INFO]: Epoch 018 - training loss: 0.4441, validation loss: 3.6650
2024-06-03 05:19:56 [INFO]: Epoch 019 - training loss: 0.4415, validation loss: 3.6682
2024-06-03 05:20:03 [INFO]: Epoch 020 - training loss: 0.4402, validation loss: 3.6633
2024-06-03 05:20:10 [INFO]: Epoch 021 - training loss: 0.4387, validation loss: 3.6562
2024-06-03 05:20:17 [INFO]: Epoch 022 - training loss: 0.4375, validation loss: 3.6515
2024-06-03 05:20:24 [INFO]: Epoch 023 - training loss: 0.4360, validation loss: 3.6449
2024-06-03 05:20:32 [INFO]: Epoch 024 - training loss: 0.4349, validation loss: 3.6421
2024-06-03 05:20:39 [INFO]: Epoch 025 - training loss: 0.4340, validation loss: 3.6476
2024-06-03 05:20:47 [INFO]: Epoch 026 - training loss: 0.4335, validation loss: 3.6423
2024-06-03 05:20:54 [INFO]: Epoch 027 - training loss: 0.4326, validation loss: 3.6536
2024-06-03 05:21:02 [INFO]: Epoch 028 - training loss: 0.4321, validation loss: 3.6388
2024-06-03 05:21:09 [INFO]: Epoch 029 - training loss: 0.4307, validation loss: 3.6416
2024-06-03 05:21:16 [INFO]: Epoch 030 - training loss: 0.4302, validation loss: 3.6494
2024-06-03 05:21:23 [INFO]: Epoch 031 - training loss: 0.4302, validation loss: 3.6373
2024-06-03 05:21:29 [INFO]: Epoch 032 - training loss: 0.4296, validation loss: 3.6327
2024-06-03 05:21:36 [INFO]: Epoch 033 - training loss: 0.4288, validation loss: 3.6355
2024-06-03 05:21:43 [INFO]: Epoch 034 - training loss: 0.4283, validation loss: 3.6365
2024-06-03 05:21:51 [INFO]: Epoch 035 - training loss: 0.4280, validation loss: 3.6332
2024-06-03 05:21:58 [INFO]: Epoch 036 - training loss: 0.4274, validation loss: 3.6330
2024-06-03 05:22:05 [INFO]: Epoch 037 - training loss: 0.4270, validation loss: 3.6313
2024-06-03 05:22:12 [INFO]: Epoch 038 - training loss: 0.4269, validation loss: 3.6297
2024-06-03 05:22:19 [INFO]: Epoch 039 - training loss: 0.4264, validation loss: 3.6378
2024-06-03 05:22:27 [INFO]: Epoch 040 - training loss: 0.4262, validation loss: 3.6313
2024-06-03 05:22:34 [INFO]: Epoch 041 - training loss: 0.4255, validation loss: 3.6327
2024-06-03 05:22:42 [INFO]: Epoch 042 - training loss: 0.4254, validation loss: 3.6339
2024-06-03 05:22:49 [INFO]: Epoch 043 - training loss: 0.4241, validation loss: 3.6322
2024-06-03 05:22:56 [INFO]: Epoch 044 - training loss: 0.4239, validation loss: 3.6262
2024-06-03 05:23:04 [INFO]: Epoch 045 - training loss: 0.4223, validation loss: 3.6234
2024-06-03 05:23:11 [INFO]: Epoch 046 - training loss: 0.4197, validation loss: 3.6066
2024-06-03 05:23:19 [INFO]: Epoch 047 - training loss: 0.4180, validation loss: 3.6068
2024-06-03 05:23:26 [INFO]: Epoch 048 - training loss: 0.4176, validation loss: 3.6115
2024-06-03 05:23:34 [INFO]: Epoch 049 - training loss: 0.4163, validation loss: 3.6079
2024-06-03 05:23:42 [INFO]: Epoch 050 - training loss: 0.4159, validation loss: 3.6098
2024-06-03 05:23:49 [INFO]: Epoch 051 - training loss: 0.4141, validation loss: 3.6170
2024-06-03 05:23:56 [INFO]: Epoch 052 - training loss: 0.4135, validation loss: 3.6018
2024-06-03 05:24:04 [INFO]: Epoch 053 - training loss: 0.4131, validation loss: 3.6088
2024-06-03 05:24:11 [INFO]: Epoch 054 - training loss: 0.4133, validation loss: 3.5935
2024-06-03 05:24:18 [INFO]: Epoch 055 - training loss: 0.4123, validation loss: 3.5980
2024-06-03 05:24:26 [INFO]: Epoch 056 - training loss: 0.4116, validation loss: 3.6006
2024-06-03 05:24:33 [INFO]: Epoch 057 - training loss: 0.4117, validation loss: 3.6036
2024-06-03 05:24:40 [INFO]: Epoch 058 - training loss: 0.4112, validation loss: 3.5956
2024-06-03 05:24:47 [INFO]: Epoch 059 - training loss: 0.4103, validation loss: 3.5960
2024-06-03 05:24:54 [INFO]: Epoch 060 - training loss: 0.4093, validation loss: 3.5852
2024-06-03 05:25:01 [INFO]: Epoch 061 - training loss: 0.4084, validation loss: 3.5894
2024-06-03 05:25:09 [INFO]: Epoch 062 - training loss: 0.4081, validation loss: 3.6019
2024-06-03 05:25:16 [INFO]: Epoch 063 - training loss: 0.4073, validation loss: 3.5906
2024-06-03 05:25:24 [INFO]: Epoch 064 - training loss: 0.4062, validation loss: 3.5816
2024-06-03 05:25:31 [INFO]: Epoch 065 - training loss: 0.4065, validation loss: 3.6020
2024-06-03 05:25:39 [INFO]: Epoch 066 - training loss: 0.4057, validation loss: 3.5768
2024-06-03 05:25:46 [INFO]: Epoch 067 - training loss: 0.4051, validation loss: 3.5844
2024-06-03 05:25:53 [INFO]: Epoch 068 - training loss: 0.4047, validation loss: 3.5655
2024-06-03 05:26:00 [INFO]: Epoch 069 - training loss: 0.4036, validation loss: 3.5691
2024-06-03 05:26:08 [INFO]: Epoch 070 - training loss: 0.4039, validation loss: 3.5582
2024-06-03 05:26:15 [INFO]: Epoch 071 - training loss: 0.4031, validation loss: 3.5813
2024-06-03 05:26:22 [INFO]: Epoch 072 - training loss: 0.4024, validation loss: 3.5741
2024-06-03 05:26:30 [INFO]: Epoch 073 - training loss: 0.4022, validation loss: 3.5727
2024-06-03 05:26:37 [INFO]: Epoch 074 - training loss: 0.4020, validation loss: 3.5569
2024-06-03 05:26:45 [INFO]: Epoch 075 - training loss: 0.4011, validation loss: 3.5765
2024-06-03 05:26:52 [INFO]: Epoch 076 - training loss: 0.4007, validation loss: 3.5619
2024-06-03 05:27:00 [INFO]: Epoch 077 - training loss: 0.4006, validation loss: 3.5763
2024-06-03 05:27:07 [INFO]: Epoch 078 - training loss: 0.4002, validation loss: 3.5802
2024-06-03 05:27:15 [INFO]: Epoch 079 - training loss: 0.4004, validation loss: 3.5760
2024-06-03 05:27:22 [INFO]: Epoch 080 - training loss: 0.3997, validation loss: 3.5639
2024-06-03 05:27:29 [INFO]: Epoch 081 - training loss: 0.3994, validation loss: 3.5641
2024-06-03 05:27:37 [INFO]: Epoch 082 - training loss: 0.3989, validation loss: 3.5738
2024-06-03 05:27:44 [INFO]: Epoch 083 - training loss: 0.3988, validation loss: 3.5676
2024-06-03 05:27:51 [INFO]: Epoch 084 - training loss: 0.3981, validation loss: 3.5733
2024-06-03 05:27:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:27:51 [INFO]: Finished training. The best model is from epoch#74.
2024-06-03 05:27:51 [INFO]: Saved the model to results_subseq_rate05/Electricity/MICN_Electricity/round_1/20240603_T051737/MICN.pypots
2024-06-03 05:27:52 [INFO]: Successfully saved to results_subseq_rate05/Electricity/MICN_Electricity/round_1/imputation.pkl
2024-06-03 05:27:52 [INFO]: Round1 - MICN on Electricity: MAE=1.7380, MSE=5.3630, MRE=0.9219
2024-06-03 05:27:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 05:27:52 [INFO]: Using the given device: cuda:0
2024-06-03 05:27:52 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_2/20240603_T052752
2024-06-03 05:27:52 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_2/20240603_T052752/tensorboard
2024-06-03 05:27:53 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-03 05:28:01 [INFO]: Epoch 001 - training loss: 0.6661, validation loss: 3.9029
2024-06-03 05:28:08 [INFO]: Epoch 002 - training loss: 0.5561, validation loss: 3.8463
2024-06-03 05:28:15 [INFO]: Epoch 003 - training loss: 0.5000, validation loss: 3.7667
2024-06-03 05:28:22 [INFO]: Epoch 004 - training loss: 0.4796, validation loss: 3.7628
2024-06-03 05:28:29 [INFO]: Epoch 005 - training loss: 0.4725, validation loss: 3.7348
2024-06-03 05:28:36 [INFO]: Epoch 006 - training loss: 0.4656, validation loss: 3.7280
2024-06-03 05:28:43 [INFO]: Epoch 007 - training loss: 0.4621, validation loss: 3.7231
2024-06-03 05:28:50 [INFO]: Epoch 008 - training loss: 0.4594, validation loss: 3.7222
2024-06-03 05:28:57 [INFO]: Epoch 009 - training loss: 0.4573, validation loss: 3.7126
2024-06-03 05:29:05 [INFO]: Epoch 010 - training loss: 0.4559, validation loss: 3.7097
2024-06-03 05:29:12 [INFO]: Epoch 011 - training loss: 0.4545, validation loss: 3.7095
2024-06-03 05:29:19 [INFO]: Epoch 012 - training loss: 0.4532, validation loss: 3.7098
2024-06-03 05:29:27 [INFO]: Epoch 013 - training loss: 0.4524, validation loss: 3.7099
2024-06-03 05:29:33 [INFO]: Epoch 014 - training loss: 0.4514, validation loss: 3.7088
2024-06-03 05:29:40 [INFO]: Epoch 015 - training loss: 0.4504, validation loss: 3.7006
2024-06-03 05:29:48 [INFO]: Epoch 016 - training loss: 0.4496, validation loss: 3.6986
2024-06-03 05:29:55 [INFO]: Epoch 017 - training loss: 0.4485, validation loss: 3.6972
2024-06-03 05:30:02 [INFO]: Epoch 018 - training loss: 0.4482, validation loss: 3.7006
2024-06-03 05:30:10 [INFO]: Epoch 019 - training loss: 0.4470, validation loss: 3.6933
2024-06-03 05:30:17 [INFO]: Epoch 020 - training loss: 0.4464, validation loss: 3.6916
2024-06-03 05:30:24 [INFO]: Epoch 021 - training loss: 0.4460, validation loss: 3.6938
2024-06-03 05:30:32 [INFO]: Epoch 022 - training loss: 0.4455, validation loss: 3.6911
2024-06-03 05:30:39 [INFO]: Epoch 023 - training loss: 0.4451, validation loss: 3.6874
2024-06-03 05:30:46 [INFO]: Epoch 024 - training loss: 0.4452, validation loss: 3.6941
2024-06-03 05:30:53 [INFO]: Epoch 025 - training loss: 0.4450, validation loss: 3.6850
2024-06-03 05:30:59 [INFO]: Epoch 026 - training loss: 0.4439, validation loss: 3.6911
2024-06-03 05:31:06 [INFO]: Epoch 027 - training loss: 0.4437, validation loss: 3.6798
2024-06-03 05:31:13 [INFO]: Epoch 028 - training loss: 0.4435, validation loss: 3.6889
2024-06-03 05:31:20 [INFO]: Epoch 029 - training loss: 0.4434, validation loss: 3.6869
2024-06-03 05:31:28 [INFO]: Epoch 030 - training loss: 0.4428, validation loss: 3.6826
2024-06-03 05:31:35 [INFO]: Epoch 031 - training loss: 0.4430, validation loss: 3.6848
2024-06-03 05:31:42 [INFO]: Epoch 032 - training loss: 0.4426, validation loss: 3.6848
2024-06-03 05:31:50 [INFO]: Epoch 033 - training loss: 0.4425, validation loss: 3.6838
2024-06-03 05:31:57 [INFO]: Epoch 034 - training loss: 0.4423, validation loss: 3.6840
2024-06-03 05:32:04 [INFO]: Epoch 035 - training loss: 0.4419, validation loss: 3.6864
2024-06-03 05:32:12 [INFO]: Epoch 036 - training loss: 0.4416, validation loss: 3.6818
2024-06-03 05:32:20 [INFO]: Epoch 037 - training loss: 0.4416, validation loss: 3.6806
2024-06-03 05:32:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:32:20 [INFO]: Finished training. The best model is from epoch#27.
2024-06-03 05:32:20 [INFO]: Saved the model to results_subseq_rate05/Electricity/MICN_Electricity/round_2/20240603_T052752/MICN.pypots
2024-06-03 05:32:21 [INFO]: Successfully saved to results_subseq_rate05/Electricity/MICN_Electricity/round_2/imputation.pkl
2024-06-03 05:32:21 [INFO]: Round2 - MICN on Electricity: MAE=1.7624, MSE=5.5172, MRE=0.9348
2024-06-03 05:32:21 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 05:32:21 [INFO]: Using the given device: cuda:0
2024-06-03 05:32:21 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_3/20240603_T053221
2024-06-03 05:32:21 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_3/20240603_T053221/tensorboard
2024-06-03 05:32:21 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-03 05:32:29 [INFO]: Epoch 001 - training loss: 0.6728, validation loss: 3.8877
2024-06-03 05:32:36 [INFO]: Epoch 002 - training loss: 0.5442, validation loss: 3.7729
2024-06-03 05:32:44 [INFO]: Epoch 003 - training loss: 0.4935, validation loss: 3.7454
2024-06-03 05:32:51 [INFO]: Epoch 004 - training loss: 0.4838, validation loss: 3.7405
2024-06-03 05:32:59 [INFO]: Epoch 005 - training loss: 0.4785, validation loss: 3.7277
2024-06-03 05:33:06 [INFO]: Epoch 006 - training loss: 0.4712, validation loss: 3.7154
2024-06-03 05:33:13 [INFO]: Epoch 007 - training loss: 0.4673, validation loss: 3.7151
2024-06-03 05:33:21 [INFO]: Epoch 008 - training loss: 0.4645, validation loss: 3.7132
2024-06-03 05:33:28 [INFO]: Epoch 009 - training loss: 0.4631, validation loss: 3.7111
2024-06-03 05:33:36 [INFO]: Epoch 010 - training loss: 0.4615, validation loss: 3.7079
2024-06-03 05:33:44 [INFO]: Epoch 011 - training loss: 0.4596, validation loss: 3.7020
2024-06-03 05:33:51 [INFO]: Epoch 012 - training loss: 0.4588, validation loss: 3.6984
2024-06-03 05:33:58 [INFO]: Epoch 013 - training loss: 0.4579, validation loss: 3.7022
2024-06-03 05:34:06 [INFO]: Epoch 014 - training loss: 0.4568, validation loss: 3.6892
2024-06-03 05:34:13 [INFO]: Epoch 015 - training loss: 0.4552, validation loss: 3.6931
2024-06-03 05:34:20 [INFO]: Epoch 016 - training loss: 0.4545, validation loss: 3.6901
2024-06-03 05:34:28 [INFO]: Epoch 017 - training loss: 0.4528, validation loss: 3.6788
2024-06-03 05:34:35 [INFO]: Epoch 018 - training loss: 0.4502, validation loss: 3.6779
2024-06-03 05:34:43 [INFO]: Epoch 019 - training loss: 0.4484, validation loss: 3.6700
2024-06-03 05:34:50 [INFO]: Epoch 020 - training loss: 0.4461, validation loss: 3.6588
2024-06-03 05:34:57 [INFO]: Epoch 021 - training loss: 0.4454, validation loss: 3.6661
2024-06-03 05:35:05 [INFO]: Epoch 022 - training loss: 0.4425, validation loss: 3.6509
2024-06-03 05:35:12 [INFO]: Epoch 023 - training loss: 0.4407, validation loss: 3.6490
2024-06-03 05:35:19 [INFO]: Epoch 024 - training loss: 0.4392, validation loss: 3.6422
2024-06-03 05:35:26 [INFO]: Epoch 025 - training loss: 0.4382, validation loss: 3.6485
2024-06-03 05:35:33 [INFO]: Epoch 026 - training loss: 0.4374, validation loss: 3.6439
2024-06-03 05:35:40 [INFO]: Epoch 027 - training loss: 0.4355, validation loss: 3.6299
2024-06-03 05:35:47 [INFO]: Epoch 028 - training loss: 0.4350, validation loss: 3.6393
2024-06-03 05:35:54 [INFO]: Epoch 029 - training loss: 0.4349, validation loss: 3.6405
2024-06-03 05:36:02 [INFO]: Epoch 030 - training loss: 0.4333, validation loss: 3.6448
2024-06-03 05:36:09 [INFO]: Epoch 031 - training loss: 0.4326, validation loss: 3.6356
2024-06-03 05:36:16 [INFO]: Epoch 032 - training loss: 0.4319, validation loss: 3.6325
2024-06-03 05:36:23 [INFO]: Epoch 033 - training loss: 0.4313, validation loss: 3.6372
2024-06-03 05:36:31 [INFO]: Epoch 034 - training loss: 0.4307, validation loss: 3.6371
2024-06-03 05:36:38 [INFO]: Epoch 035 - training loss: 0.4301, validation loss: 3.6336
2024-06-03 05:36:45 [INFO]: Epoch 036 - training loss: 0.4298, validation loss: 3.6279
2024-06-03 05:36:52 [INFO]: Epoch 037 - training loss: 0.4294, validation loss: 3.6274
2024-06-03 05:36:59 [INFO]: Epoch 038 - training loss: 0.4291, validation loss: 3.6335
2024-06-03 05:37:06 [INFO]: Epoch 039 - training loss: 0.4288, validation loss: 3.6265
2024-06-03 05:37:13 [INFO]: Epoch 040 - training loss: 0.4273, validation loss: 3.6241
2024-06-03 05:37:20 [INFO]: Epoch 041 - training loss: 0.4275, validation loss: 3.6278
2024-06-03 05:37:27 [INFO]: Epoch 042 - training loss: 0.4263, validation loss: 3.6217
2024-06-03 05:37:34 [INFO]: Epoch 043 - training loss: 0.4263, validation loss: 3.6220
2024-06-03 05:37:41 [INFO]: Epoch 044 - training loss: 0.4255, validation loss: 3.6248
2024-06-03 05:37:49 [INFO]: Epoch 045 - training loss: 0.4251, validation loss: 3.6294
2024-06-03 05:37:56 [INFO]: Epoch 046 - training loss: 0.4246, validation loss: 3.6284
2024-06-03 05:38:03 [INFO]: Epoch 047 - training loss: 0.4237, validation loss: 3.6292
2024-06-03 05:38:09 [INFO]: Epoch 048 - training loss: 0.4232, validation loss: 3.6219
2024-06-03 05:38:15 [INFO]: Epoch 049 - training loss: 0.4229, validation loss: 3.6125
2024-06-03 05:38:21 [INFO]: Epoch 050 - training loss: 0.4199, validation loss: 3.6056
2024-06-03 05:38:27 [INFO]: Epoch 051 - training loss: 0.4187, validation loss: 3.6085
2024-06-03 05:38:33 [INFO]: Epoch 052 - training loss: 0.4168, validation loss: 3.5939
2024-06-03 05:38:39 [INFO]: Epoch 053 - training loss: 0.4154, validation loss: 3.5954
2024-06-03 05:38:45 [INFO]: Epoch 054 - training loss: 0.4137, validation loss: 3.5948
2024-06-03 05:38:51 [INFO]: Epoch 055 - training loss: 0.4126, validation loss: 3.5977
2024-06-03 05:38:57 [INFO]: Epoch 056 - training loss: 0.4123, validation loss: 3.5758
2024-06-03 05:39:03 [INFO]: Epoch 057 - training loss: 0.4113, validation loss: 3.5779
2024-06-03 05:39:08 [INFO]: Epoch 058 - training loss: 0.4105, validation loss: 3.5895
2024-06-03 05:39:14 [INFO]: Epoch 059 - training loss: 0.4102, validation loss: 3.5874
2024-06-03 05:39:20 [INFO]: Epoch 060 - training loss: 0.4084, validation loss: 3.5766
2024-06-03 05:39:26 [INFO]: Epoch 061 - training loss: 0.4084, validation loss: 3.5988
2024-06-03 05:39:32 [INFO]: Epoch 062 - training loss: 0.4079, validation loss: 3.5796
2024-06-03 05:39:38 [INFO]: Epoch 063 - training loss: 0.4070, validation loss: 3.5780
2024-06-03 05:39:44 [INFO]: Epoch 064 - training loss: 0.4067, validation loss: 3.5828
2024-06-03 05:39:50 [INFO]: Epoch 065 - training loss: 0.4066, validation loss: 3.5871
2024-06-03 05:39:56 [INFO]: Epoch 066 - training loss: 0.4051, validation loss: 3.5780
2024-06-03 05:39:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:39:56 [INFO]: Finished training. The best model is from epoch#56.
2024-06-03 05:39:56 [INFO]: Saved the model to results_subseq_rate05/Electricity/MICN_Electricity/round_3/20240603_T053221/MICN.pypots
2024-06-03 05:39:56 [INFO]: Successfully saved to results_subseq_rate05/Electricity/MICN_Electricity/round_3/imputation.pkl
2024-06-03 05:39:56 [INFO]: Round3 - MICN on Electricity: MAE=1.7439, MSE=5.3719, MRE=0.9250
2024-06-03 05:39:56 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 05:39:56 [INFO]: Using the given device: cuda:0
2024-06-03 05:39:56 [INFO]: Model files will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_4/20240603_T053956
2024-06-03 05:39:56 [INFO]: Tensorboard file will be saved to results_subseq_rate05/Electricity/MICN_Electricity/round_4/20240603_T053956/tensorboard
2024-06-03 05:39:57 [INFO]: MICN initialized with the given hyperparameters, the number of trainable parameters: 5,457,910
2024-06-03 05:40:03 [INFO]: Epoch 001 - training loss: 0.6694, validation loss: 3.9110
2024-06-03 05:40:09 [INFO]: Epoch 002 - training loss: 0.5640, validation loss: 3.9016
2024-06-03 05:40:15 [INFO]: Epoch 003 - training loss: 0.5390, validation loss: 3.7912
2024-06-03 05:40:20 [INFO]: Epoch 004 - training loss: 0.4932, validation loss: 3.7596
2024-06-03 05:40:26 [INFO]: Epoch 005 - training loss: 0.4832, validation loss: 3.7521
2024-06-03 05:40:32 [INFO]: Epoch 006 - training loss: 0.4779, validation loss: 3.7332
2024-06-03 05:40:38 [INFO]: Epoch 007 - training loss: 0.4714, validation loss: 3.7214
2024-06-03 05:40:45 [INFO]: Epoch 008 - training loss: 0.4690, validation loss: 3.7315
2024-06-03 05:40:50 [INFO]: Epoch 009 - training loss: 0.4657, validation loss: 3.7268
2024-06-03 05:40:57 [INFO]: Epoch 010 - training loss: 0.4640, validation loss: 3.7210
2024-06-03 05:41:03 [INFO]: Epoch 011 - training loss: 0.4621, validation loss: 3.7227
2024-06-03 05:41:09 [INFO]: Epoch 012 - training loss: 0.4609, validation loss: 3.7163
2024-06-03 05:41:15 [INFO]: Epoch 013 - training loss: 0.4592, validation loss: 3.7121
2024-06-03 05:41:21 [INFO]: Epoch 014 - training loss: 0.4581, validation loss: 3.7172
2024-06-03 05:41:27 [INFO]: Epoch 015 - training loss: 0.4562, validation loss: 3.7017
2024-06-03 05:41:33 [INFO]: Epoch 016 - training loss: 0.4538, validation loss: 3.6955
2024-06-03 05:41:39 [INFO]: Epoch 017 - training loss: 0.4528, validation loss: 3.6952
2024-06-03 05:41:45 [INFO]: Epoch 018 - training loss: 0.4497, validation loss: 3.6770
2024-06-03 05:41:51 [INFO]: Epoch 019 - training loss: 0.4486, validation loss: 3.6756
2024-06-03 05:41:57 [INFO]: Epoch 020 - training loss: 0.4459, validation loss: 3.6692
2024-06-03 05:42:03 [INFO]: Epoch 021 - training loss: 0.4437, validation loss: 3.6756
2024-06-03 05:42:08 [INFO]: Epoch 022 - training loss: 0.4425, validation loss: 3.6715
2024-06-03 05:42:13 [INFO]: Epoch 023 - training loss: 0.4411, validation loss: 3.6684
2024-06-03 05:42:18 [INFO]: Epoch 024 - training loss: 0.4396, validation loss: 3.6655
2024-06-03 05:42:23 [INFO]: Epoch 025 - training loss: 0.4383, validation loss: 3.6588
2024-06-03 05:42:29 [INFO]: Epoch 026 - training loss: 0.4374, validation loss: 3.6645
2024-06-03 05:42:35 [INFO]: Epoch 027 - training loss: 0.4367, validation loss: 3.6717
2024-06-03 05:42:41 [INFO]: Epoch 028 - training loss: 0.4355, validation loss: 3.6471
2024-06-03 05:42:47 [INFO]: Epoch 029 - training loss: 0.4348, validation loss: 3.6621
2024-06-03 05:42:53 [INFO]: Epoch 030 - training loss: 0.4336, validation loss: 3.6451
2024-06-03 05:42:59 [INFO]: Epoch 031 - training loss: 0.4330, validation loss: 3.6447
2024-06-03 05:43:05 [INFO]: Epoch 032 - training loss: 0.4327, validation loss: 3.6469
2024-06-03 05:43:11 [INFO]: Epoch 033 - training loss: 0.4322, validation loss: 3.6434
2024-06-03 05:43:17 [INFO]: Epoch 034 - training loss: 0.4316, validation loss: 3.6405
2024-06-03 05:43:23 [INFO]: Epoch 035 - training loss: 0.4312, validation loss: 3.6437
2024-06-03 05:43:29 [INFO]: Epoch 036 - training loss: 0.4300, validation loss: 3.6442
2024-06-03 05:43:35 [INFO]: Epoch 037 - training loss: 0.4305, validation loss: 3.6376
2024-06-03 05:43:40 [INFO]: Epoch 038 - training loss: 0.4292, validation loss: 3.6468
2024-06-03 05:43:46 [INFO]: Epoch 039 - training loss: 0.4296, validation loss: 3.6421
2024-06-03 05:43:52 [INFO]: Epoch 040 - training loss: 0.4282, validation loss: 3.6340
2024-06-03 05:43:58 [INFO]: Epoch 041 - training loss: 0.4275, validation loss: 3.6383
2024-06-03 05:44:04 [INFO]: Epoch 042 - training loss: 0.4274, validation loss: 3.6412
2024-06-03 05:44:10 [INFO]: Epoch 043 - training loss: 0.4267, validation loss: 3.6311
2024-06-03 05:44:17 [INFO]: Epoch 044 - training loss: 0.4266, validation loss: 3.6361
2024-06-03 05:44:23 [INFO]: Epoch 045 - training loss: 0.4255, validation loss: 3.6431
2024-06-03 05:44:28 [INFO]: Epoch 046 - training loss: 0.4253, validation loss: 3.6399
2024-06-03 05:44:34 [INFO]: Epoch 047 - training loss: 0.4250, validation loss: 3.6388
2024-06-03 05:44:40 [INFO]: Epoch 048 - training loss: 0.4233, validation loss: 3.6310
2024-06-03 05:44:46 [INFO]: Epoch 049 - training loss: 0.4229, validation loss: 3.6319
2024-06-03 05:44:52 [INFO]: Epoch 050 - training loss: 0.4216, validation loss: 3.6303
2024-06-03 05:44:58 [INFO]: Epoch 051 - training loss: 0.4218, validation loss: 3.6133
2024-06-03 05:45:04 [INFO]: Epoch 052 - training loss: 0.4192, validation loss: 3.6141
2024-06-03 05:45:10 [INFO]: Epoch 053 - training loss: 0.4177, validation loss: 3.6107
2024-06-03 05:45:16 [INFO]: Epoch 054 - training loss: 0.4160, validation loss: 3.6079
2024-06-03 05:45:22 [INFO]: Epoch 055 - training loss: 0.4158, validation loss: 3.6089
2024-06-03 05:45:28 [INFO]: Epoch 056 - training loss: 0.4149, validation loss: 3.6163
2024-06-03 05:45:33 [INFO]: Epoch 057 - training loss: 0.4160, validation loss: 3.6119
2024-06-03 05:45:40 [INFO]: Epoch 058 - training loss: 0.4137, validation loss: 3.6099
2024-06-03 05:45:45 [INFO]: Epoch 059 - training loss: 0.4142, validation loss: 3.6045
2024-06-03 05:45:51 [INFO]: Epoch 060 - training loss: 0.4127, validation loss: 3.5997
2024-06-03 05:45:57 [INFO]: Epoch 061 - training loss: 0.4120, validation loss: 3.6096
2024-06-03 05:46:03 [INFO]: Epoch 062 - training loss: 0.4124, validation loss: 3.6054
2024-06-03 05:46:09 [INFO]: Epoch 063 - training loss: 0.4114, validation loss: 3.6024
2024-06-03 05:46:15 [INFO]: Epoch 064 - training loss: 0.4109, validation loss: 3.6008
2024-06-03 05:46:21 [INFO]: Epoch 065 - training loss: 0.4107, validation loss: 3.6007
2024-06-03 05:46:27 [INFO]: Epoch 066 - training loss: 0.4094, validation loss: 3.6033
2024-06-03 05:46:33 [INFO]: Epoch 067 - training loss: 0.4097, validation loss: 3.6090
2024-06-03 05:46:39 [INFO]: Epoch 068 - training loss: 0.4094, validation loss: 3.6030
2024-06-03 05:46:45 [INFO]: Epoch 069 - training loss: 0.4086, validation loss: 3.5998
2024-06-03 05:46:51 [INFO]: Epoch 070 - training loss: 0.4083, validation loss: 3.6023
2024-06-03 05:46:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 05:46:51 [INFO]: Finished training. The best model is from epoch#60.
2024-06-03 05:46:51 [INFO]: Saved the model to results_subseq_rate05/Electricity/MICN_Electricity/round_4/20240603_T053956/MICN.pypots
2024-06-03 05:46:52 [INFO]: Successfully saved to results_subseq_rate05/Electricity/MICN_Electricity/round_4/imputation.pkl
2024-06-03 05:46:52 [INFO]: Round4 - MICN on Electricity: MAE=1.7459, MSE=5.3859, MRE=0.9261
2024-06-03 05:46:52 [INFO]: Done! Final results:
Averaged MICN (5,457,910 params) on Electricity: MAE=1.7443 ± 0.01040486809922822, MSE=5.3953 ± 0.06289882356393876, MRE=0.9252 ± 0.0055191839607980075, average inference time=0.44
