2024-06-03 03:45:33 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:45:33 [INFO]: Using the given device: cuda:0
2024-06-03 03:45:34 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_0/20240603_T034534
2024-06-03 03:45:34 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_0/20240603_T034534/tensorboard
2024-06-03 03:45:36 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 03:45:42 [INFO]: Epoch 001 - training loss: 3.9623, validation loss: 2.0601
2024-06-03 03:45:47 [INFO]: Epoch 002 - training loss: 1.7970, validation loss: 1.2081
2024-06-03 03:45:53 [INFO]: Epoch 003 - training loss: 1.5879, validation loss: 1.1771
2024-06-03 03:45:58 [INFO]: Epoch 004 - training loss: 1.5102, validation loss: 1.1834
2024-06-03 03:46:04 [INFO]: Epoch 005 - training loss: 1.5131, validation loss: 1.0852
2024-06-03 03:46:10 [INFO]: Epoch 006 - training loss: 1.4687, validation loss: 1.0825
2024-06-03 03:46:15 [INFO]: Epoch 007 - training loss: 1.4119, validation loss: 1.1515
2024-06-03 03:46:20 [INFO]: Epoch 008 - training loss: 1.3242, validation loss: 1.1230
2024-06-03 03:46:24 [INFO]: Epoch 009 - training loss: 1.2207, validation loss: 1.0115
2024-06-03 03:46:29 [INFO]: Epoch 010 - training loss: 1.2233, validation loss: 1.0034
2024-06-03 03:46:33 [INFO]: Epoch 011 - training loss: 1.1965, validation loss: 1.0262
2024-06-03 03:46:37 [INFO]: Epoch 012 - training loss: 1.1283, validation loss: 0.8218
2024-06-03 03:46:42 [INFO]: Epoch 013 - training loss: 0.9869, validation loss: 0.7575
2024-06-03 03:46:46 [INFO]: Epoch 014 - training loss: 0.9333, validation loss: 0.7482
2024-06-03 03:46:50 [INFO]: Epoch 015 - training loss: 0.8958, validation loss: 0.6657
2024-06-03 03:46:52 [INFO]: Epoch 016 - training loss: 0.8911, validation loss: 0.6618
2024-06-03 03:46:56 [INFO]: Epoch 017 - training loss: 0.8335, validation loss: 0.6685
2024-06-03 03:47:01 [INFO]: Epoch 018 - training loss: 0.8640, validation loss: 0.5715
2024-06-03 03:47:05 [INFO]: Epoch 019 - training loss: 0.7825, validation loss: 0.6364
2024-06-03 03:47:06 [INFO]: Epoch 020 - training loss: 0.7724, validation loss: 0.5183
2024-06-03 03:47:09 [INFO]: Epoch 021 - training loss: 0.7253, validation loss: 0.5331
2024-06-03 03:47:12 [INFO]: Epoch 022 - training loss: 0.7060, validation loss: 0.5462
2024-06-03 03:47:15 [INFO]: Epoch 023 - training loss: 0.6819, validation loss: 0.4706
2024-06-03 03:47:19 [INFO]: Epoch 024 - training loss: 0.6752, validation loss: 0.5077
2024-06-03 03:47:22 [INFO]: Epoch 025 - training loss: 0.6530, validation loss: 0.4784
2024-06-03 03:47:25 [INFO]: Epoch 026 - training loss: 0.6386, validation loss: 0.4934
2024-06-03 03:47:27 [INFO]: Epoch 027 - training loss: 0.6448, validation loss: 0.5475
2024-06-03 03:47:30 [INFO]: Epoch 028 - training loss: 0.6518, validation loss: 0.5322
2024-06-03 03:47:33 [INFO]: Epoch 029 - training loss: 0.6281, validation loss: 0.5907
2024-06-03 03:47:34 [INFO]: Epoch 030 - training loss: 0.7085, validation loss: 0.6230
2024-06-03 03:47:36 [INFO]: Epoch 031 - training loss: 0.6834, validation loss: 0.5977
2024-06-03 03:47:39 [INFO]: Epoch 032 - training loss: 0.6358, validation loss: 0.5731
2024-06-03 03:47:41 [INFO]: Epoch 033 - training loss: 0.5975, validation loss: 0.5729
2024-06-03 03:47:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:47:41 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 03:47:41 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_0/20240603_T034534/Koopa.pypots
2024-06-03 03:47:41 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_0/imputation.pkl
2024-06-03 03:47:41 [INFO]: Round0 - Koopa on ETT_h1: MAE=0.6524, MSE=0.9087, MRE=0.7349
2024-06-03 03:47:41 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 03:47:41 [INFO]: Using the given device: cuda:0
2024-06-03 03:47:41 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_1/20240603_T034741
2024-06-03 03:47:41 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_1/20240603_T034741/tensorboard
2024-06-03 03:47:41 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 03:47:42 [INFO]: Epoch 001 - training loss: 6.0311, validation loss: 13.3392
2024-06-03 03:47:44 [INFO]: Epoch 002 - training loss: 2.6237, validation loss: 1.7510
2024-06-03 03:47:45 [INFO]: Epoch 003 - training loss: 2.0332, validation loss: 1.5199
2024-06-03 03:47:47 [INFO]: Epoch 004 - training loss: 1.6681, validation loss: 1.0344
2024-06-03 03:47:47 [INFO]: Epoch 005 - training loss: 1.4814, validation loss: 1.0864
2024-06-03 03:47:48 [INFO]: Epoch 006 - training loss: 1.4354, validation loss: 1.0394
2024-06-03 03:47:48 [INFO]: Epoch 007 - training loss: 1.3326, validation loss: 1.0964
2024-06-03 03:47:49 [INFO]: Epoch 008 - training loss: 1.2923, validation loss: 1.1561
2024-06-03 03:47:49 [INFO]: Epoch 009 - training loss: 1.1895, validation loss: 1.0672
2024-06-03 03:47:49 [INFO]: Epoch 010 - training loss: 1.0758, validation loss: 1.0710
2024-06-03 03:47:50 [INFO]: Epoch 011 - training loss: 1.0173, validation loss: 1.0278
2024-06-03 03:47:50 [INFO]: Epoch 012 - training loss: 0.9985, validation loss: 0.8661
2024-06-03 03:47:50 [INFO]: Epoch 013 - training loss: 0.9410, validation loss: 0.8039
2024-06-03 03:47:51 [INFO]: Epoch 014 - training loss: 0.9219, validation loss: 0.7640
2024-06-03 03:47:51 [INFO]: Epoch 015 - training loss: 0.9045, validation loss: 0.6446
2024-06-03 03:47:51 [INFO]: Epoch 016 - training loss: 0.8395, validation loss: 0.5541
2024-06-03 03:47:52 [INFO]: Epoch 017 - training loss: 0.8187, validation loss: 0.5674
2024-06-03 03:47:52 [INFO]: Epoch 018 - training loss: 0.8055, validation loss: 0.5301
2024-06-03 03:47:53 [INFO]: Epoch 019 - training loss: 0.7760, validation loss: 0.5657
2024-06-03 03:47:53 [INFO]: Epoch 020 - training loss: 0.7675, validation loss: 0.5303
2024-06-03 03:47:53 [INFO]: Epoch 021 - training loss: 0.7641, validation loss: 0.5292
2024-06-03 03:47:54 [INFO]: Epoch 022 - training loss: 0.7914, validation loss: 0.5883
2024-06-03 03:47:54 [INFO]: Epoch 023 - training loss: 0.7913, validation loss: 0.5499
2024-06-03 03:47:54 [INFO]: Epoch 024 - training loss: 0.7597, validation loss: 0.6220
2024-06-03 03:47:55 [INFO]: Epoch 025 - training loss: 0.7948, validation loss: 0.6671
2024-06-03 03:47:55 [INFO]: Epoch 026 - training loss: 0.8178, validation loss: 0.6268
2024-06-03 03:47:55 [INFO]: Epoch 027 - training loss: 0.7889, validation loss: 0.5726
2024-06-03 03:47:56 [INFO]: Epoch 028 - training loss: 0.7419, validation loss: 0.6361
2024-06-03 03:47:56 [INFO]: Epoch 029 - training loss: 0.7182, validation loss: 0.5808
2024-06-03 03:47:57 [INFO]: Epoch 030 - training loss: 0.6972, validation loss: 0.5706
2024-06-03 03:47:57 [INFO]: Epoch 031 - training loss: 0.6896, validation loss: 0.5783
2024-06-03 03:47:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:47:57 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 03:47:57 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_1/20240603_T034741/Koopa.pypots
2024-06-03 03:47:57 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_1/imputation.pkl
2024-06-03 03:47:57 [INFO]: Round1 - Koopa on ETT_h1: MAE=0.6593, MSE=1.0589, MRE=0.7426
2024-06-03 03:47:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:47:57 [INFO]: Using the given device: cuda:0
2024-06-03 03:47:57 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_2/20240603_T034757
2024-06-03 03:47:57 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_2/20240603_T034757/tensorboard
2024-06-03 03:47:57 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 03:47:57 [INFO]: Epoch 001 - training loss: 4.5259, validation loss: 3.0238
2024-06-03 03:47:58 [INFO]: Epoch 002 - training loss: 2.0238, validation loss: 1.8114
2024-06-03 03:47:58 [INFO]: Epoch 003 - training loss: 1.7237, validation loss: 1.2685
2024-06-03 03:47:58 [INFO]: Epoch 004 - training loss: 1.5168, validation loss: 1.1049
2024-06-03 03:47:59 [INFO]: Epoch 005 - training loss: 1.5319, validation loss: 1.0913
2024-06-03 03:47:59 [INFO]: Epoch 006 - training loss: 1.4934, validation loss: 1.1118
2024-06-03 03:48:00 [INFO]: Epoch 007 - training loss: 1.4782, validation loss: 1.0869
2024-06-03 03:48:00 [INFO]: Epoch 008 - training loss: 1.4824, validation loss: 1.0886
2024-06-03 03:48:00 [INFO]: Epoch 009 - training loss: 1.4666, validation loss: 1.0721
2024-06-03 03:48:01 [INFO]: Epoch 010 - training loss: 1.4648, validation loss: 1.0698
2024-06-03 03:48:01 [INFO]: Epoch 011 - training loss: 1.4728, validation loss: 1.0997
2024-06-03 03:48:01 [INFO]: Epoch 012 - training loss: 1.4594, validation loss: 1.0628
2024-06-03 03:48:02 [INFO]: Epoch 013 - training loss: 1.4698, validation loss: 1.1226
2024-06-03 03:48:02 [INFO]: Epoch 014 - training loss: 1.4825, validation loss: 1.1038
2024-06-03 03:48:02 [INFO]: Epoch 015 - training loss: 1.4729, validation loss: 1.0480
2024-06-03 03:48:03 [INFO]: Epoch 016 - training loss: 1.4639, validation loss: 1.0741
2024-06-03 03:48:03 [INFO]: Epoch 017 - training loss: 1.4576, validation loss: 1.0710
2024-06-03 03:48:04 [INFO]: Epoch 018 - training loss: 1.4644, validation loss: 1.0690
2024-06-03 03:48:04 [INFO]: Epoch 019 - training loss: 1.4657, validation loss: 1.0905
2024-06-03 03:48:04 [INFO]: Epoch 020 - training loss: 1.4625, validation loss: 1.0723
2024-06-03 03:48:05 [INFO]: Epoch 021 - training loss: 1.4659, validation loss: 1.0747
2024-06-03 03:48:05 [INFO]: Epoch 022 - training loss: 1.4435, validation loss: 1.0743
2024-06-03 03:48:05 [INFO]: Epoch 023 - training loss: 1.4587, validation loss: 1.0776
2024-06-03 03:48:06 [INFO]: Epoch 024 - training loss: 1.4631, validation loss: 1.0871
2024-06-03 03:48:06 [INFO]: Epoch 025 - training loss: 1.4568, validation loss: 1.0883
2024-06-03 03:48:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:48:06 [INFO]: Finished training. The best model is from epoch#15.
2024-06-03 03:48:06 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_2/20240603_T034757/Koopa.pypots
2024-06-03 03:48:06 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_2/imputation.pkl
2024-06-03 03:48:06 [INFO]: Round2 - Koopa on ETT_h1: MAE=0.8637, MSE=1.4378, MRE=0.9728
2024-06-03 03:48:06 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:48:06 [INFO]: Using the given device: cuda:0
2024-06-03 03:48:06 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_3/20240603_T034806
2024-06-03 03:48:06 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_3/20240603_T034806/tensorboard
2024-06-03 03:48:06 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 03:48:07 [INFO]: Epoch 001 - training loss: 4.7453, validation loss: 1.8340
2024-06-03 03:48:07 [INFO]: Epoch 002 - training loss: 1.8166, validation loss: 1.1634
2024-06-03 03:48:07 [INFO]: Epoch 003 - training loss: 1.5899, validation loss: 1.2367
2024-06-03 03:48:08 [INFO]: Epoch 004 - training loss: 1.5106, validation loss: 1.1472
2024-06-03 03:48:08 [INFO]: Epoch 005 - training loss: 1.3861, validation loss: 1.0815
2024-06-03 03:48:08 [INFO]: Epoch 006 - training loss: 1.2239, validation loss: 0.9264
2024-06-03 03:48:09 [INFO]: Epoch 007 - training loss: 1.0924, validation loss: 0.7661
2024-06-03 03:48:09 [INFO]: Epoch 008 - training loss: 0.9950, validation loss: 0.7885
2024-06-03 03:48:09 [INFO]: Epoch 009 - training loss: 0.9013, validation loss: 0.5878
2024-06-03 03:48:10 [INFO]: Epoch 010 - training loss: 0.8688, validation loss: 0.4916
2024-06-03 03:48:10 [INFO]: Epoch 011 - training loss: 0.8350, validation loss: 0.4655
2024-06-03 03:48:11 [INFO]: Epoch 012 - training loss: 0.8081, validation loss: 0.5025
2024-06-03 03:48:11 [INFO]: Epoch 013 - training loss: 0.7831, validation loss: 0.4701
2024-06-03 03:48:11 [INFO]: Epoch 014 - training loss: 0.7499, validation loss: 0.5173
2024-06-03 03:48:12 [INFO]: Epoch 015 - training loss: 0.7173, validation loss: 0.5487
2024-06-03 03:48:12 [INFO]: Epoch 016 - training loss: 0.7055, validation loss: 0.4840
2024-06-03 03:48:12 [INFO]: Epoch 017 - training loss: 0.6808, validation loss: 0.4662
2024-06-03 03:48:13 [INFO]: Epoch 018 - training loss: 0.7023, validation loss: 0.4913
2024-06-03 03:48:13 [INFO]: Epoch 019 - training loss: 0.6973, validation loss: 0.5771
2024-06-03 03:48:13 [INFO]: Epoch 020 - training loss: 0.6707, validation loss: 0.6130
2024-06-03 03:48:14 [INFO]: Epoch 021 - training loss: 0.6836, validation loss: 0.6238
2024-06-03 03:48:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:48:14 [INFO]: Finished training. The best model is from epoch#11.
2024-06-03 03:48:14 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_3/20240603_T034806/Koopa.pypots
2024-06-03 03:48:14 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_3/imputation.pkl
2024-06-03 03:48:14 [INFO]: Round3 - Koopa on ETT_h1: MAE=0.6707, MSE=0.9836, MRE=0.7554
2024-06-03 03:48:14 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:48:14 [INFO]: Using the given device: cuda:0
2024-06-03 03:48:14 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_4/20240603_T034814
2024-06-03 03:48:14 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_4/20240603_T034814/tensorboard
2024-06-03 03:48:14 [INFO]: Koopa initialized with the given hyperparameters, the number of trainable parameters: 465,389
2024-06-03 03:48:14 [INFO]: Epoch 001 - training loss: 4.2828, validation loss: 1.4063
2024-06-03 03:48:15 [INFO]: Epoch 002 - training loss: 1.7290, validation loss: 1.1473
2024-06-03 03:48:15 [INFO]: Epoch 003 - training loss: 1.5511, validation loss: 1.1332
2024-06-03 03:48:15 [INFO]: Epoch 004 - training loss: 1.5343, validation loss: 1.1160
2024-06-03 03:48:16 [INFO]: Epoch 005 - training loss: 1.4846, validation loss: 1.1129
2024-06-03 03:48:16 [INFO]: Epoch 006 - training loss: 1.4837, validation loss: 1.1005
2024-06-03 03:48:16 [INFO]: Epoch 007 - training loss: 1.4752, validation loss: 1.1068
2024-06-03 03:48:17 [INFO]: Epoch 008 - training loss: 1.4997, validation loss: 1.0679
2024-06-03 03:48:17 [INFO]: Epoch 009 - training loss: 1.4740, validation loss: 1.0650
2024-06-03 03:48:18 [INFO]: Epoch 010 - training loss: 1.4727, validation loss: 1.0928
2024-06-03 03:48:18 [INFO]: Epoch 011 - training loss: 1.4702, validation loss: 1.0804
2024-06-03 03:48:18 [INFO]: Epoch 012 - training loss: 1.4624, validation loss: 1.0501
2024-06-03 03:48:19 [INFO]: Epoch 013 - training loss: 1.4699, validation loss: 1.1383
2024-06-03 03:48:19 [INFO]: Epoch 014 - training loss: 1.4686, validation loss: 1.0450
2024-06-03 03:48:19 [INFO]: Epoch 015 - training loss: 1.4799, validation loss: 1.0900
2024-06-03 03:48:20 [INFO]: Epoch 016 - training loss: 1.4691, validation loss: 1.0886
2024-06-03 03:48:20 [INFO]: Epoch 017 - training loss: 1.4631, validation loss: 1.0632
2024-06-03 03:48:20 [INFO]: Epoch 018 - training loss: 1.4678, validation loss: 1.0835
2024-06-03 03:48:21 [INFO]: Epoch 019 - training loss: 1.4572, validation loss: 1.0723
2024-06-03 03:48:21 [INFO]: Epoch 020 - training loss: 1.4531, validation loss: 1.0658
2024-06-03 03:48:22 [INFO]: Epoch 021 - training loss: 1.4721, validation loss: 1.0837
2024-06-03 03:48:22 [INFO]: Epoch 022 - training loss: 1.4656, validation loss: 1.0858
2024-06-03 03:48:22 [INFO]: Epoch 023 - training loss: 1.4621, validation loss: 1.0797
2024-06-03 03:48:23 [INFO]: Epoch 024 - training loss: 1.4675, validation loss: 1.0719
2024-06-03 03:48:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:48:23 [INFO]: Finished training. The best model is from epoch#14.
2024-06-03 03:48:23 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_4/20240603_T034814/Koopa.pypots
2024-06-03 03:48:23 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/Koopa_ETT_h1/round_4/imputation.pkl
2024-06-03 03:48:23 [INFO]: Round4 - Koopa on ETT_h1: MAE=0.8585, MSE=1.4229, MRE=0.9669
2024-06-03 03:48:23 [INFO]: Done! Final results:
Averaged Koopa (465,389 params) on ETT_h1: MAE=0.7409 ± 0.0983052345279773, MSE=1.1624 ± 0.22393572427517014, MRE=0.8345 ± 0.11072689448595516, average inference time=0.03
