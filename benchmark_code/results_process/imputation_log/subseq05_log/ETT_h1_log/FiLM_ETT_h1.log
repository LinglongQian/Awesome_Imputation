2024-06-03 03:32:35 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:32:35 [INFO]: Using the given device: cuda:0
2024-06-03 03:32:37 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T033237
2024-06-03 03:32:37 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T033237/tensorboard
2024-06-03 03:32:38 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 03:32:40 [INFO]: Epoch 001 - training loss: 1.6892, validation loss: 1.1342
2024-06-03 03:32:41 [INFO]: Epoch 002 - training loss: 1.4780, validation loss: 1.1049
2024-06-03 03:32:42 [INFO]: Epoch 003 - training loss: 1.2392, validation loss: 1.0517
2024-06-03 03:32:42 [INFO]: Epoch 004 - training loss: 1.0709, validation loss: 0.9513
2024-06-03 03:32:43 [INFO]: Epoch 005 - training loss: 0.9624, validation loss: 0.8975
2024-06-03 03:32:44 [INFO]: Epoch 006 - training loss: 0.9482, validation loss: 0.7933
2024-06-03 03:32:45 [INFO]: Epoch 007 - training loss: 0.8919, validation loss: 0.8685
2024-06-03 03:32:46 [INFO]: Epoch 008 - training loss: 0.8604, validation loss: 0.7841
2024-06-03 03:32:47 [INFO]: Epoch 009 - training loss: 0.8218, validation loss: 0.8274
2024-06-03 03:32:47 [INFO]: Epoch 010 - training loss: 0.8199, validation loss: 0.7799
2024-06-03 03:32:48 [INFO]: Epoch 011 - training loss: 0.8070, validation loss: 0.7726
2024-06-03 03:32:49 [INFO]: Epoch 012 - training loss: 0.7862, validation loss: 0.7613
2024-06-03 03:32:50 [INFO]: Epoch 013 - training loss: 0.7993, validation loss: 0.7706
2024-06-03 03:32:51 [INFO]: Epoch 014 - training loss: 0.7879, validation loss: 0.7593
2024-06-03 03:32:52 [INFO]: Epoch 015 - training loss: 0.7874, validation loss: 0.7650
2024-06-03 03:32:53 [INFO]: Epoch 016 - training loss: 0.7943, validation loss: 0.7547
2024-06-03 03:32:54 [INFO]: Epoch 017 - training loss: 0.7871, validation loss: 0.7275
2024-06-03 03:32:55 [INFO]: Epoch 018 - training loss: 0.7983, validation loss: 0.7963
2024-06-03 03:32:56 [INFO]: Epoch 019 - training loss: 0.7977, validation loss: 0.7292
2024-06-03 03:32:56 [INFO]: Epoch 020 - training loss: 0.7827, validation loss: 0.7782
2024-06-03 03:32:57 [INFO]: Epoch 021 - training loss: 0.7921, validation loss: 0.7385
2024-06-03 03:32:58 [INFO]: Epoch 022 - training loss: 0.7913, validation loss: 0.7530
2024-06-03 03:32:59 [INFO]: Epoch 023 - training loss: 0.7906, validation loss: 0.7242
2024-06-03 03:33:00 [INFO]: Epoch 024 - training loss: 0.7871, validation loss: 0.7744
2024-06-03 03:33:01 [INFO]: Epoch 025 - training loss: 0.7857, validation loss: 0.7355
2024-06-03 03:33:02 [INFO]: Epoch 026 - training loss: 0.7924, validation loss: 0.7719
2024-06-03 03:33:03 [INFO]: Epoch 027 - training loss: 0.7908, validation loss: 0.7357
2024-06-03 03:33:03 [INFO]: Epoch 028 - training loss: 0.7895, validation loss: 0.7594
2024-06-03 03:33:04 [INFO]: Epoch 029 - training loss: 0.7859, validation loss: 0.7586
2024-06-03 03:33:05 [INFO]: Epoch 030 - training loss: 0.7765, validation loss: 0.7584
2024-06-03 03:33:06 [INFO]: Epoch 031 - training loss: 0.7868, validation loss: 0.7406
2024-06-03 03:33:07 [INFO]: Epoch 032 - training loss: 0.7891, validation loss: 0.7768
2024-06-03 03:33:08 [INFO]: Epoch 033 - training loss: 0.7876, validation loss: 0.7600
2024-06-03 03:33:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:33:08 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 03:33:08 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_0/20240603_T033237/FiLM.pypots
2024-06-03 03:33:08 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_0/imputation.pkl
2024-06-03 03:33:08 [INFO]: Round0 - FiLM on ETT_h1: MAE=0.7402, MSE=1.3284, MRE=0.8337
2024-06-03 03:33:08 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 03:33:08 [INFO]: Using the given device: cuda:0
2024-06-03 03:33:08 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T033308
2024-06-03 03:33:08 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T033308/tensorboard
2024-06-03 03:33:08 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 03:33:09 [INFO]: Epoch 001 - training loss: 2.3386, validation loss: 1.4567
2024-06-03 03:33:10 [INFO]: Epoch 002 - training loss: 1.7840, validation loss: 1.0473
2024-06-03 03:33:11 [INFO]: Epoch 003 - training loss: 1.4774, validation loss: 1.1831
2024-06-03 03:33:11 [INFO]: Epoch 004 - training loss: 1.1606, validation loss: 1.0613
2024-06-03 03:33:12 [INFO]: Epoch 005 - training loss: 1.0350, validation loss: 0.8915
2024-06-03 03:33:13 [INFO]: Epoch 006 - training loss: 0.9458, validation loss: 0.8369
2024-06-03 03:33:14 [INFO]: Epoch 007 - training loss: 0.8769, validation loss: 0.8101
2024-06-03 03:33:15 [INFO]: Epoch 008 - training loss: 0.8434, validation loss: 0.8290
2024-06-03 03:33:15 [INFO]: Epoch 009 - training loss: 0.8259, validation loss: 0.7854
2024-06-03 03:33:16 [INFO]: Epoch 010 - training loss: 0.8113, validation loss: 0.8119
2024-06-03 03:33:17 [INFO]: Epoch 011 - training loss: 0.8056, validation loss: 0.7416
2024-06-03 03:33:18 [INFO]: Epoch 012 - training loss: 0.8027, validation loss: 0.7598
2024-06-03 03:33:19 [INFO]: Epoch 013 - training loss: 0.7917, validation loss: 0.7812
2024-06-03 03:33:19 [INFO]: Epoch 014 - training loss: 0.7883, validation loss: 0.7364
2024-06-03 03:33:20 [INFO]: Epoch 015 - training loss: 0.7905, validation loss: 0.7555
2024-06-03 03:33:21 [INFO]: Epoch 016 - training loss: 0.7931, validation loss: 0.7105
2024-06-03 03:33:22 [INFO]: Epoch 017 - training loss: 0.7889, validation loss: 0.7504
2024-06-03 03:33:22 [INFO]: Epoch 018 - training loss: 0.7857, validation loss: 0.7392
2024-06-03 03:33:23 [INFO]: Epoch 019 - training loss: 0.7828, validation loss: 0.7531
2024-06-03 03:33:24 [INFO]: Epoch 020 - training loss: 0.7827, validation loss: 0.7579
2024-06-03 03:33:25 [INFO]: Epoch 021 - training loss: 0.7951, validation loss: 0.7261
2024-06-03 03:33:26 [INFO]: Epoch 022 - training loss: 0.7831, validation loss: 0.7924
2024-06-03 03:33:26 [INFO]: Epoch 023 - training loss: 0.7831, validation loss: 0.7264
2024-06-03 03:33:27 [INFO]: Epoch 024 - training loss: 0.7821, validation loss: 0.7443
2024-06-03 03:33:28 [INFO]: Epoch 025 - training loss: 0.7811, validation loss: 0.7582
2024-06-03 03:33:29 [INFO]: Epoch 026 - training loss: 0.7903, validation loss: 0.7639
2024-06-03 03:33:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:33:29 [INFO]: Finished training. The best model is from epoch#16.
2024-06-03 03:33:29 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_1/20240603_T033308/FiLM.pypots
2024-06-03 03:33:29 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_1/imputation.pkl
2024-06-03 03:33:29 [INFO]: Round1 - FiLM on ETT_h1: MAE=0.7356, MSE=1.3356, MRE=0.8286
2024-06-03 03:33:29 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:33:29 [INFO]: Using the given device: cuda:0
2024-06-03 03:33:29 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T033329
2024-06-03 03:33:29 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T033329/tensorboard
2024-06-03 03:33:29 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 03:33:30 [INFO]: Epoch 001 - training loss: 1.8353, validation loss: 1.0359
2024-06-03 03:33:31 [INFO]: Epoch 002 - training loss: 1.5855, validation loss: 1.2185
2024-06-03 03:33:32 [INFO]: Epoch 003 - training loss: 1.3611, validation loss: 1.0578
2024-06-03 03:33:32 [INFO]: Epoch 004 - training loss: 1.1231, validation loss: 1.0815
2024-06-03 03:33:33 [INFO]: Epoch 005 - training loss: 1.0305, validation loss: 0.8646
2024-06-03 03:33:34 [INFO]: Epoch 006 - training loss: 0.9753, validation loss: 0.9123
2024-06-03 03:33:34 [INFO]: Epoch 007 - training loss: 0.9200, validation loss: 0.8222
2024-06-03 03:33:35 [INFO]: Epoch 008 - training loss: 0.8859, validation loss: 0.8458
2024-06-03 03:33:36 [INFO]: Epoch 009 - training loss: 0.8534, validation loss: 0.8360
2024-06-03 03:33:36 [INFO]: Epoch 010 - training loss: 0.8290, validation loss: 0.7838
2024-06-03 03:33:37 [INFO]: Epoch 011 - training loss: 0.8202, validation loss: 0.7762
2024-06-03 03:33:38 [INFO]: Epoch 012 - training loss: 0.8083, validation loss: 0.7663
2024-06-03 03:33:38 [INFO]: Epoch 013 - training loss: 0.7968, validation loss: 0.7756
2024-06-03 03:33:39 [INFO]: Epoch 014 - training loss: 0.7903, validation loss: 0.7567
2024-06-03 03:33:39 [INFO]: Epoch 015 - training loss: 0.8027, validation loss: 0.7524
2024-06-03 03:33:40 [INFO]: Epoch 016 - training loss: 0.7925, validation loss: 0.7837
2024-06-03 03:33:40 [INFO]: Epoch 017 - training loss: 0.7926, validation loss: 0.7715
2024-06-03 03:33:41 [INFO]: Epoch 018 - training loss: 0.7945, validation loss: 0.7428
2024-06-03 03:33:41 [INFO]: Epoch 019 - training loss: 0.7870, validation loss: 0.7696
2024-06-03 03:33:42 [INFO]: Epoch 020 - training loss: 0.7865, validation loss: 0.7638
2024-06-03 03:33:43 [INFO]: Epoch 021 - training loss: 0.7865, validation loss: 0.7494
2024-06-03 03:33:43 [INFO]: Epoch 022 - training loss: 0.7909, validation loss: 0.7513
2024-06-03 03:33:44 [INFO]: Epoch 023 - training loss: 0.7785, validation loss: 0.7300
2024-06-03 03:33:44 [INFO]: Epoch 024 - training loss: 0.7894, validation loss: 0.7568
2024-06-03 03:33:45 [INFO]: Epoch 025 - training loss: 0.7938, validation loss: 0.7494
2024-06-03 03:33:45 [INFO]: Epoch 026 - training loss: 0.7922, validation loss: 0.7761
2024-06-03 03:33:46 [INFO]: Epoch 027 - training loss: 0.7901, validation loss: 0.7418
2024-06-03 03:33:46 [INFO]: Epoch 028 - training loss: 0.7863, validation loss: 0.7442
2024-06-03 03:33:47 [INFO]: Epoch 029 - training loss: 0.7836, validation loss: 0.7474
2024-06-03 03:33:47 [INFO]: Epoch 030 - training loss: 0.7953, validation loss: 0.7377
2024-06-03 03:33:48 [INFO]: Epoch 031 - training loss: 0.7779, validation loss: 0.7605
2024-06-03 03:33:48 [INFO]: Epoch 032 - training loss: 0.7843, validation loss: 0.7742
2024-06-03 03:33:49 [INFO]: Epoch 033 - training loss: 0.7766, validation loss: 0.7311
2024-06-03 03:33:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:33:49 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 03:33:49 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_2/20240603_T033329/FiLM.pypots
2024-06-03 03:33:49 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_2/imputation.pkl
2024-06-03 03:33:49 [INFO]: Round2 - FiLM on ETT_h1: MAE=0.7222, MSE=1.2992, MRE=0.8135
2024-06-03 03:33:49 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:33:49 [INFO]: Using the given device: cuda:0
2024-06-03 03:33:49 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T033349
2024-06-03 03:33:49 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T033349/tensorboard
2024-06-03 03:33:49 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 03:33:50 [INFO]: Epoch 001 - training loss: 1.5952, validation loss: 1.1364
2024-06-03 03:33:50 [INFO]: Epoch 002 - training loss: 1.4365, validation loss: 1.0851
2024-06-03 03:33:51 [INFO]: Epoch 003 - training loss: 1.1494, validation loss: 1.0032
2024-06-03 03:33:52 [INFO]: Epoch 004 - training loss: 1.0484, validation loss: 0.8906
2024-06-03 03:33:52 [INFO]: Epoch 005 - training loss: 0.9945, validation loss: 0.8224
2024-06-03 03:33:53 [INFO]: Epoch 006 - training loss: 0.9121, validation loss: 0.8223
2024-06-03 03:33:53 [INFO]: Epoch 007 - training loss: 0.8603, validation loss: 0.7976
2024-06-03 03:33:54 [INFO]: Epoch 008 - training loss: 0.8350, validation loss: 0.7868
2024-06-03 03:33:54 [INFO]: Epoch 009 - training loss: 0.8206, validation loss: 0.7754
2024-06-03 03:33:55 [INFO]: Epoch 010 - training loss: 0.7989, validation loss: 0.7677
2024-06-03 03:33:56 [INFO]: Epoch 011 - training loss: 0.8036, validation loss: 0.7562
2024-06-03 03:33:56 [INFO]: Epoch 012 - training loss: 0.8014, validation loss: 0.7215
2024-06-03 03:33:57 [INFO]: Epoch 013 - training loss: 0.8006, validation loss: 0.7637
2024-06-03 03:33:57 [INFO]: Epoch 014 - training loss: 0.7909, validation loss: 0.7646
2024-06-03 03:33:58 [INFO]: Epoch 015 - training loss: 0.7945, validation loss: 0.7485
2024-06-03 03:33:58 [INFO]: Epoch 016 - training loss: 0.7903, validation loss: 0.7517
2024-06-03 03:33:59 [INFO]: Epoch 017 - training loss: 0.7766, validation loss: 0.7621
2024-06-03 03:33:59 [INFO]: Epoch 018 - training loss: 0.7910, validation loss: 0.7509
2024-06-03 03:34:00 [INFO]: Epoch 019 - training loss: 0.7822, validation loss: 0.7979
2024-06-03 03:34:00 [INFO]: Epoch 020 - training loss: 0.7807, validation loss: 0.7469
2024-06-03 03:34:01 [INFO]: Epoch 021 - training loss: 0.7898, validation loss: 0.7187
2024-06-03 03:34:01 [INFO]: Epoch 022 - training loss: 0.7862, validation loss: 0.7485
2024-06-03 03:34:01 [INFO]: Epoch 023 - training loss: 0.7844, validation loss: 0.7556
2024-06-03 03:34:02 [INFO]: Epoch 024 - training loss: 0.7925, validation loss: 0.7635
2024-06-03 03:34:02 [INFO]: Epoch 025 - training loss: 0.7827, validation loss: 0.7454
2024-06-03 03:34:02 [INFO]: Epoch 026 - training loss: 0.7863, validation loss: 0.7441
2024-06-03 03:34:03 [INFO]: Epoch 027 - training loss: 0.7856, validation loss: 0.7651
2024-06-03 03:34:03 [INFO]: Epoch 028 - training loss: 0.7836, validation loss: 0.7651
2024-06-03 03:34:04 [INFO]: Epoch 029 - training loss: 0.7832, validation loss: 0.7545
2024-06-03 03:34:04 [INFO]: Epoch 030 - training loss: 0.7942, validation loss: 0.7346
2024-06-03 03:34:05 [INFO]: Epoch 031 - training loss: 0.7790, validation loss: 0.7550
2024-06-03 03:34:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:34:05 [INFO]: Finished training. The best model is from epoch#21.
2024-06-03 03:34:05 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_3/20240603_T033349/FiLM.pypots
2024-06-03 03:34:05 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_3/imputation.pkl
2024-06-03 03:34:05 [INFO]: Round3 - FiLM on ETT_h1: MAE=0.7401, MSE=1.3221, MRE=0.8336
2024-06-03 03:34:05 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:34:05 [INFO]: Using the given device: cuda:0
2024-06-03 03:34:05 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T033405
2024-06-03 03:34:05 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T033405/tensorboard
2024-06-03 03:34:05 [INFO]: FiLM initialized with the given hyperparameters, the number of trainable parameters: 12,490
2024-06-03 03:34:05 [INFO]: Epoch 001 - training loss: 1.7552, validation loss: 1.1575
2024-06-03 03:34:06 [INFO]: Epoch 002 - training loss: 1.5863, validation loss: 1.1821
2024-06-03 03:34:06 [INFO]: Epoch 003 - training loss: 1.4438, validation loss: 1.0985
2024-06-03 03:34:07 [INFO]: Epoch 004 - training loss: 1.2483, validation loss: 1.0791
2024-06-03 03:34:07 [INFO]: Epoch 005 - training loss: 1.0113, validation loss: 1.0120
2024-06-03 03:34:07 [INFO]: Epoch 006 - training loss: 0.9306, validation loss: 0.8867
2024-06-03 03:34:08 [INFO]: Epoch 007 - training loss: 0.8986, validation loss: 0.8613
2024-06-03 03:34:08 [INFO]: Epoch 008 - training loss: 0.8606, validation loss: 0.8717
2024-06-03 03:34:09 [INFO]: Epoch 009 - training loss: 0.8445, validation loss: 0.8492
2024-06-03 03:34:09 [INFO]: Epoch 010 - training loss: 0.8320, validation loss: 0.8298
2024-06-03 03:34:09 [INFO]: Epoch 011 - training loss: 0.8216, validation loss: 0.8203
2024-06-03 03:34:10 [INFO]: Epoch 012 - training loss: 0.8087, validation loss: 0.7761
2024-06-03 03:34:10 [INFO]: Epoch 013 - training loss: 0.8023, validation loss: 0.7463
2024-06-03 03:34:10 [INFO]: Epoch 014 - training loss: 0.8006, validation loss: 0.7853
2024-06-03 03:34:11 [INFO]: Epoch 015 - training loss: 0.8027, validation loss: 0.7497
2024-06-03 03:34:11 [INFO]: Epoch 016 - training loss: 0.7955, validation loss: 0.7612
2024-06-03 03:34:12 [INFO]: Epoch 017 - training loss: 0.7912, validation loss: 0.7710
2024-06-03 03:34:12 [INFO]: Epoch 018 - training loss: 0.7897, validation loss: 0.7338
2024-06-03 03:34:12 [INFO]: Epoch 019 - training loss: 0.8025, validation loss: 0.7761
2024-06-03 03:34:13 [INFO]: Epoch 020 - training loss: 0.7968, validation loss: 0.7295
2024-06-03 03:34:13 [INFO]: Epoch 021 - training loss: 0.7812, validation loss: 0.7405
2024-06-03 03:34:13 [INFO]: Epoch 022 - training loss: 0.7930, validation loss: 0.7781
2024-06-03 03:34:14 [INFO]: Epoch 023 - training loss: 0.7843, validation loss: 0.7278
2024-06-03 03:34:14 [INFO]: Epoch 024 - training loss: 0.7851, validation loss: 0.7650
2024-06-03 03:34:14 [INFO]: Epoch 025 - training loss: 0.7959, validation loss: 0.7534
2024-06-03 03:34:15 [INFO]: Epoch 026 - training loss: 0.7947, validation loss: 0.7610
2024-06-03 03:34:15 [INFO]: Epoch 027 - training loss: 0.7921, validation loss: 0.7512
2024-06-03 03:34:16 [INFO]: Epoch 028 - training loss: 0.7942, validation loss: 0.7533
2024-06-03 03:34:16 [INFO]: Epoch 029 - training loss: 0.7789, validation loss: 0.7737
2024-06-03 03:34:16 [INFO]: Epoch 030 - training loss: 0.7901, validation loss: 0.7542
2024-06-03 03:34:17 [INFO]: Epoch 031 - training loss: 0.7870, validation loss: 0.7209
2024-06-03 03:34:17 [INFO]: Epoch 032 - training loss: 0.7919, validation loss: 0.7796
2024-06-03 03:34:17 [INFO]: Epoch 033 - training loss: 0.7954, validation loss: 0.7523
2024-06-03 03:34:18 [INFO]: Epoch 034 - training loss: 0.7676, validation loss: 0.7640
2024-06-03 03:34:18 [INFO]: Epoch 035 - training loss: 0.7837, validation loss: 0.7468
2024-06-03 03:34:19 [INFO]: Epoch 036 - training loss: 0.7761, validation loss: 0.7834
2024-06-03 03:34:19 [INFO]: Epoch 037 - training loss: 0.7847, validation loss: 0.7250
2024-06-03 03:34:20 [INFO]: Epoch 038 - training loss: 0.7987, validation loss: 0.7688
2024-06-03 03:34:20 [INFO]: Epoch 039 - training loss: 0.7887, validation loss: 0.7491
2024-06-03 03:34:20 [INFO]: Epoch 040 - training loss: 0.7756, validation loss: 0.7606
2024-06-03 03:34:21 [INFO]: Epoch 041 - training loss: 0.7845, validation loss: 0.7687
2024-06-03 03:34:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:34:21 [INFO]: Finished training. The best model is from epoch#31.
2024-06-03 03:34:21 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_4/20240603_T033405/FiLM.pypots
2024-06-03 03:34:21 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/FiLM_ETT_h1/round_4/imputation.pkl
2024-06-03 03:34:21 [INFO]: Round4 - FiLM on ETT_h1: MAE=0.7370, MSE=1.3323, MRE=0.8302
2024-06-03 03:34:21 [INFO]: Done! Final results:
Averaged FiLM (12,490 params) on ETT_h1: MAE=0.7350 ± 0.006633080761529634, MSE=1.3235 ± 0.01297431380404102, MRE=0.8279 ± 0.007471224061722636, average inference time=0.09
