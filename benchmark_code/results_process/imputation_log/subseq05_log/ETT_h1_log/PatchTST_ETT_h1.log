2024-06-03 03:45:34 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:45:34 [INFO]: Using the given device: cuda:0
2024-06-03 03:45:34 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_0/20240603_T034534
2024-06-03 03:45:34 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_0/20240603_T034534/tensorboard
2024-06-03 03:45:34 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-03 03:45:34 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-03 03:45:35 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-03 03:45:38 [INFO]: Epoch 001 - training loss: 1.6796, validation loss: 1.1628
2024-06-03 03:45:38 [INFO]: Epoch 002 - training loss: 1.4372, validation loss: 1.2860
2024-06-03 03:45:38 [INFO]: Epoch 003 - training loss: 1.1577, validation loss: 0.9290
2024-06-03 03:45:38 [INFO]: Epoch 004 - training loss: 0.9781, validation loss: 0.7886
2024-06-03 03:45:39 [INFO]: Epoch 005 - training loss: 0.9331, validation loss: 0.6947
2024-06-03 03:45:39 [INFO]: Epoch 006 - training loss: 0.8620, validation loss: 0.6259
2024-06-03 03:45:39 [INFO]: Epoch 007 - training loss: 0.7832, validation loss: 0.8035
2024-06-03 03:45:40 [INFO]: Epoch 008 - training loss: 0.6837, validation loss: 0.7621
2024-06-03 03:45:40 [INFO]: Epoch 009 - training loss: 0.5839, validation loss: 0.6716
2024-06-03 03:45:41 [INFO]: Epoch 010 - training loss: 0.5478, validation loss: 0.6934
2024-06-03 03:45:41 [INFO]: Epoch 011 - training loss: 0.5205, validation loss: 0.7935
2024-06-03 03:45:42 [INFO]: Epoch 012 - training loss: 0.5071, validation loss: 0.7687
2024-06-03 03:45:42 [INFO]: Epoch 013 - training loss: 0.4965, validation loss: 0.7944
2024-06-03 03:45:43 [INFO]: Epoch 014 - training loss: 0.4876, validation loss: 0.7878
2024-06-03 03:45:43 [INFO]: Epoch 015 - training loss: 0.4834, validation loss: 0.7637
2024-06-03 03:45:44 [INFO]: Epoch 016 - training loss: 0.4931, validation loss: 0.8304
2024-06-03 03:45:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:45:44 [INFO]: Finished training. The best model is from epoch#6.
2024-06-03 03:45:44 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_0/20240603_T034534/PatchTST.pypots
2024-06-03 03:45:44 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_0/imputation.pkl
2024-06-03 03:45:44 [INFO]: Round0 - PatchTST on ETT_h1: MAE=0.7685, MSE=1.1667, MRE=0.8656
2024-06-03 03:45:44 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 03:45:44 [INFO]: Using the given device: cuda:0
2024-06-03 03:45:44 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_1/20240603_T034544
2024-06-03 03:45:44 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_1/20240603_T034544/tensorboard
2024-06-03 03:45:44 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-03 03:45:44 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-03 03:45:44 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-03 03:45:45 [INFO]: Epoch 001 - training loss: 1.8329, validation loss: 1.5804
2024-06-03 03:45:45 [INFO]: Epoch 002 - training loss: 1.3320, validation loss: 0.9416
2024-06-03 03:45:46 [INFO]: Epoch 003 - training loss: 1.1157, validation loss: 0.7293
2024-06-03 03:45:46 [INFO]: Epoch 004 - training loss: 0.9784, validation loss: 0.6937
2024-06-03 03:45:47 [INFO]: Epoch 005 - training loss: 0.9069, validation loss: 0.6717
2024-06-03 03:45:47 [INFO]: Epoch 006 - training loss: 0.8659, validation loss: 0.6439
2024-06-03 03:45:48 [INFO]: Epoch 007 - training loss: 0.8321, validation loss: 0.6332
2024-06-03 03:45:48 [INFO]: Epoch 008 - training loss: 0.7975, validation loss: 0.6481
2024-06-03 03:45:49 [INFO]: Epoch 009 - training loss: 0.7671, validation loss: 0.6694
2024-06-03 03:45:49 [INFO]: Epoch 010 - training loss: 0.6948, validation loss: 0.6821
2024-06-03 03:45:50 [INFO]: Epoch 011 - training loss: 0.6452, validation loss: 0.7235
2024-06-03 03:45:50 [INFO]: Epoch 012 - training loss: 0.6019, validation loss: 0.7413
2024-06-03 03:45:51 [INFO]: Epoch 013 - training loss: 0.5571, validation loss: 0.7080
2024-06-03 03:45:51 [INFO]: Epoch 014 - training loss: 0.5540, validation loss: 0.7624
2024-06-03 03:45:52 [INFO]: Epoch 015 - training loss: 0.5499, validation loss: 0.7377
2024-06-03 03:45:52 [INFO]: Epoch 016 - training loss: 0.5358, validation loss: 0.8017
2024-06-03 03:45:53 [INFO]: Epoch 017 - training loss: 0.5165, validation loss: 0.7505
2024-06-03 03:45:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:45:53 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 03:45:53 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_1/20240603_T034544/PatchTST.pypots
2024-06-03 03:45:53 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_1/imputation.pkl
2024-06-03 03:45:53 [INFO]: Round1 - PatchTST on ETT_h1: MAE=0.7361, MSE=1.0791, MRE=0.8292
2024-06-03 03:45:53 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:45:53 [INFO]: Using the given device: cuda:0
2024-06-03 03:45:53 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_2/20240603_T034553
2024-06-03 03:45:53 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_2/20240603_T034553/tensorboard
2024-06-03 03:45:53 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-03 03:45:53 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-03 03:45:53 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-03 03:45:54 [INFO]: Epoch 001 - training loss: 1.4854, validation loss: 1.1758
2024-06-03 03:45:54 [INFO]: Epoch 002 - training loss: 1.1436, validation loss: 0.7480
2024-06-03 03:45:54 [INFO]: Epoch 003 - training loss: 0.9850, validation loss: 0.6776
2024-06-03 03:45:55 [INFO]: Epoch 004 - training loss: 0.9206, validation loss: 0.6862
2024-06-03 03:45:55 [INFO]: Epoch 005 - training loss: 0.7680, validation loss: 0.9740
2024-06-03 03:45:56 [INFO]: Epoch 006 - training loss: 0.6679, validation loss: 0.7284
2024-06-03 03:45:56 [INFO]: Epoch 007 - training loss: 0.6013, validation loss: 0.8023
2024-06-03 03:45:56 [INFO]: Epoch 008 - training loss: 0.5706, validation loss: 0.7652
2024-06-03 03:45:57 [INFO]: Epoch 009 - training loss: 0.5379, validation loss: 0.7709
2024-06-03 03:45:57 [INFO]: Epoch 010 - training loss: 0.5066, validation loss: 0.8099
2024-06-03 03:45:58 [INFO]: Epoch 011 - training loss: 0.4992, validation loss: 0.7918
2024-06-03 03:45:58 [INFO]: Epoch 012 - training loss: 0.5031, validation loss: 0.8158
2024-06-03 03:45:59 [INFO]: Epoch 013 - training loss: 0.4957, validation loss: 0.8298
2024-06-03 03:45:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:45:59 [INFO]: Finished training. The best model is from epoch#3.
2024-06-03 03:45:59 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_2/20240603_T034553/PatchTST.pypots
2024-06-03 03:45:59 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_2/imputation.pkl
2024-06-03 03:45:59 [INFO]: Round2 - PatchTST on ETT_h1: MAE=0.7661, MSE=1.1651, MRE=0.8629
2024-06-03 03:45:59 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:45:59 [INFO]: Using the given device: cuda:0
2024-06-03 03:45:59 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_3/20240603_T034559
2024-06-03 03:45:59 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_3/20240603_T034559/tensorboard
2024-06-03 03:45:59 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-03 03:45:59 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-03 03:45:59 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-03 03:46:00 [INFO]: Epoch 001 - training loss: 1.5771, validation loss: 1.1253
2024-06-03 03:46:00 [INFO]: Epoch 002 - training loss: 1.4416, validation loss: 1.0969
2024-06-03 03:46:01 [INFO]: Epoch 003 - training loss: 1.2436, validation loss: 0.9978
2024-06-03 03:46:01 [INFO]: Epoch 004 - training loss: 1.0605, validation loss: 0.9038
2024-06-03 03:46:02 [INFO]: Epoch 005 - training loss: 0.9209, validation loss: 0.7387
2024-06-03 03:46:02 [INFO]: Epoch 006 - training loss: 0.8980, validation loss: 0.6823
2024-06-03 03:46:03 [INFO]: Epoch 007 - training loss: 0.8564, validation loss: 0.6918
2024-06-03 03:46:03 [INFO]: Epoch 008 - training loss: 0.8301, validation loss: 0.6776
2024-06-03 03:46:04 [INFO]: Epoch 009 - training loss: 0.8075, validation loss: 0.6365
2024-06-03 03:46:04 [INFO]: Epoch 010 - training loss: 0.7336, validation loss: 0.7850
2024-06-03 03:46:05 [INFO]: Epoch 011 - training loss: 0.6913, validation loss: 0.6954
2024-06-03 03:46:05 [INFO]: Epoch 012 - training loss: 0.6086, validation loss: 0.7853
2024-06-03 03:46:06 [INFO]: Epoch 013 - training loss: 0.5531, validation loss: 0.7752
2024-06-03 03:46:06 [INFO]: Epoch 014 - training loss: 0.5387, validation loss: 0.7460
2024-06-03 03:46:07 [INFO]: Epoch 015 - training loss: 0.5148, validation loss: 0.7555
2024-06-03 03:46:07 [INFO]: Epoch 016 - training loss: 0.5002, validation loss: 0.7675
2024-06-03 03:46:08 [INFO]: Epoch 017 - training loss: 0.4871, validation loss: 0.8194
2024-06-03 03:46:08 [INFO]: Epoch 018 - training loss: 0.4932, validation loss: 0.7700
2024-06-03 03:46:08 [INFO]: Epoch 019 - training loss: 0.4869, validation loss: 0.8096
2024-06-03 03:46:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:46:08 [INFO]: Finished training. The best model is from epoch#9.
2024-06-03 03:46:08 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_3/20240603_T034559/PatchTST.pypots
2024-06-03 03:46:09 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_3/imputation.pkl
2024-06-03 03:46:09 [INFO]: Round3 - PatchTST on ETT_h1: MAE=0.7560, MSE=1.1669, MRE=0.8515
2024-06-03 03:46:09 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:46:09 [INFO]: Using the given device: cuda:0
2024-06-03 03:46:09 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_4/20240603_T034609
2024-06-03 03:46:09 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_4/20240603_T034609/tensorboard
2024-06-03 03:46:09 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=1, d_k=32
2024-06-03 03:46:09 [WARNING]: ⚠️ d_model is reset to 32 = n_heads (1) * d_k (32)
2024-06-03 03:46:09 [INFO]: PatchTST initialized with the given hyperparameters, the number of trainable parameters: 72,247
2024-06-03 03:46:09 [INFO]: Epoch 001 - training loss: 1.6869, validation loss: 1.1931
2024-06-03 03:46:09 [INFO]: Epoch 002 - training loss: 1.3969, validation loss: 0.9880
2024-06-03 03:46:10 [INFO]: Epoch 003 - training loss: 1.1816, validation loss: 0.8035
2024-06-03 03:46:10 [INFO]: Epoch 004 - training loss: 1.0205, validation loss: 0.7094
2024-06-03 03:46:11 [INFO]: Epoch 005 - training loss: 0.9582, validation loss: 0.6239
2024-06-03 03:46:11 [INFO]: Epoch 006 - training loss: 0.8925, validation loss: 0.6717
2024-06-03 03:46:12 [INFO]: Epoch 007 - training loss: 0.8422, validation loss: 0.6045
2024-06-03 03:46:12 [INFO]: Epoch 008 - training loss: 0.7939, validation loss: 0.6727
2024-06-03 03:46:12 [INFO]: Epoch 009 - training loss: 0.7531, validation loss: 0.6497
2024-06-03 03:46:13 [INFO]: Epoch 010 - training loss: 0.7016, validation loss: 0.6314
2024-06-03 03:46:13 [INFO]: Epoch 011 - training loss: 0.6529, validation loss: 0.7925
2024-06-03 03:46:14 [INFO]: Epoch 012 - training loss: 0.5915, validation loss: 0.6390
2024-06-03 03:46:14 [INFO]: Epoch 013 - training loss: 0.5419, validation loss: 0.7338
2024-06-03 03:46:15 [INFO]: Epoch 014 - training loss: 0.5137, validation loss: 0.7774
2024-06-03 03:46:15 [INFO]: Epoch 015 - training loss: 0.5024, validation loss: 0.8004
2024-06-03 03:46:16 [INFO]: Epoch 016 - training loss: 0.5036, validation loss: 0.7786
2024-06-03 03:46:16 [INFO]: Epoch 017 - training loss: 0.4963, validation loss: 0.7981
2024-06-03 03:46:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:46:16 [INFO]: Finished training. The best model is from epoch#7.
2024-06-03 03:46:16 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_4/20240603_T034609/PatchTST.pypots
2024-06-03 03:46:17 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/PatchTST_ETT_h1/round_4/imputation.pkl
2024-06-03 03:46:17 [INFO]: Round4 - PatchTST on ETT_h1: MAE=0.7481, MSE=1.1506, MRE=0.8426
2024-06-03 03:46:17 [INFO]: Done! Final results:
Averaged PatchTST (72,247 params) on ETT_h1: MAE=0.7550 ± 0.011928967762769738, MSE=1.1457 ± 0.033824141181939764, MRE=0.8504 ± 0.013436289136959984, average inference time=0.05
