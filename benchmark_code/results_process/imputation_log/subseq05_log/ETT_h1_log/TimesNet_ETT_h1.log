2024-06-03 03:48:38 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-06-03 03:48:38 [INFO]: Using the given device: cuda:0
2024-06-03 03:48:39 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T034839
2024-06-03 03:48:39 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T034839/tensorboard
2024-06-03 03:48:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 03:48:47 [INFO]: Epoch 001 - training loss: 0.7776, validation loss: 1.1466
2024-06-03 03:48:48 [INFO]: Epoch 002 - training loss: 0.4244, validation loss: 0.9191
2024-06-03 03:48:49 [INFO]: Epoch 003 - training loss: 0.2711, validation loss: 0.8809
2024-06-03 03:48:50 [INFO]: Epoch 004 - training loss: 0.2324, validation loss: 0.8593
2024-06-03 03:48:51 [INFO]: Epoch 005 - training loss: 0.1940, validation loss: 0.8235
2024-06-03 03:48:51 [INFO]: Epoch 006 - training loss: 0.1753, validation loss: 0.7887
2024-06-03 03:48:52 [INFO]: Epoch 007 - training loss: 0.1764, validation loss: 0.8287
2024-06-03 03:48:53 [INFO]: Epoch 008 - training loss: 0.1540, validation loss: 0.7818
2024-06-03 03:48:54 [INFO]: Epoch 009 - training loss: 0.1550, validation loss: 0.8593
2024-06-03 03:48:55 [INFO]: Epoch 010 - training loss: 0.1412, validation loss: 0.8339
2024-06-03 03:48:56 [INFO]: Epoch 011 - training loss: 0.1383, validation loss: 0.8887
2024-06-03 03:48:57 [INFO]: Epoch 012 - training loss: 0.1310, validation loss: 0.8827
2024-06-03 03:48:58 [INFO]: Epoch 013 - training loss: 0.1440, validation loss: 0.7804
2024-06-03 03:48:59 [INFO]: Epoch 014 - training loss: 0.1391, validation loss: 0.8407
2024-06-03 03:49:00 [INFO]: Epoch 015 - training loss: 0.1216, validation loss: 0.8039
2024-06-03 03:49:02 [INFO]: Epoch 016 - training loss: 0.1250, validation loss: 0.8487
2024-06-03 03:49:03 [INFO]: Epoch 017 - training loss: 0.1246, validation loss: 0.7521
2024-06-03 03:49:04 [INFO]: Epoch 018 - training loss: 0.1206, validation loss: 0.7784
2024-06-03 03:49:05 [INFO]: Epoch 019 - training loss: 0.1207, validation loss: 0.8009
2024-06-03 03:49:06 [INFO]: Epoch 020 - training loss: 0.1149, validation loss: 0.7783
2024-06-03 03:49:07 [INFO]: Epoch 021 - training loss: 0.1155, validation loss: 0.7615
2024-06-03 03:49:08 [INFO]: Epoch 022 - training loss: 0.1297, validation loss: 0.8211
2024-06-03 03:49:09 [INFO]: Epoch 023 - training loss: 0.1245, validation loss: 0.7775
2024-06-03 03:49:10 [INFO]: Epoch 024 - training loss: 0.1212, validation loss: 0.7444
2024-06-03 03:49:11 [INFO]: Epoch 025 - training loss: 0.1157, validation loss: 0.7435
2024-06-03 03:49:12 [INFO]: Epoch 026 - training loss: 0.1229, validation loss: 0.7664
2024-06-03 03:49:13 [INFO]: Epoch 027 - training loss: 0.1285, validation loss: 0.7642
2024-06-03 03:49:14 [INFO]: Epoch 028 - training loss: 0.1171, validation loss: 0.8232
2024-06-03 03:49:15 [INFO]: Epoch 029 - training loss: 0.1098, validation loss: 0.7754
2024-06-03 03:49:16 [INFO]: Epoch 030 - training loss: 0.1053, validation loss: 0.8026
2024-06-03 03:49:17 [INFO]: Epoch 031 - training loss: 0.1111, validation loss: 0.7936
2024-06-03 03:49:18 [INFO]: Epoch 032 - training loss: 0.1166, validation loss: 0.8109
2024-06-03 03:49:19 [INFO]: Epoch 033 - training loss: 0.1202, validation loss: 0.7388
2024-06-03 03:49:20 [INFO]: Epoch 034 - training loss: 0.1224, validation loss: 0.7666
2024-06-03 03:49:21 [INFO]: Epoch 035 - training loss: 0.1180, validation loss: 0.7730
2024-06-03 03:49:22 [INFO]: Epoch 036 - training loss: 0.1130, validation loss: 0.7615
2024-06-03 03:49:23 [INFO]: Epoch 037 - training loss: 0.1162, validation loss: 0.7730
2024-06-03 03:49:24 [INFO]: Epoch 038 - training loss: 0.1094, validation loss: 0.8229
2024-06-03 03:49:25 [INFO]: Epoch 039 - training loss: 0.1157, validation loss: 0.7512
2024-06-03 03:49:26 [INFO]: Epoch 040 - training loss: 0.1094, validation loss: 0.7372
2024-06-03 03:49:27 [INFO]: Epoch 041 - training loss: 0.1104, validation loss: 0.7890
2024-06-03 03:49:28 [INFO]: Epoch 042 - training loss: 0.1126, validation loss: 0.7663
2024-06-03 03:49:28 [INFO]: Epoch 043 - training loss: 0.1026, validation loss: 0.7622
2024-06-03 03:49:29 [INFO]: Epoch 044 - training loss: 0.1064, validation loss: 0.7569
2024-06-03 03:49:30 [INFO]: Epoch 045 - training loss: 0.1088, validation loss: 0.7417
2024-06-03 03:49:31 [INFO]: Epoch 046 - training loss: 0.1081, validation loss: 0.7739
2024-06-03 03:49:31 [INFO]: Epoch 047 - training loss: 0.1015, validation loss: 0.7339
2024-06-03 03:49:32 [INFO]: Epoch 048 - training loss: 0.1113, validation loss: 0.7431
2024-06-03 03:49:33 [INFO]: Epoch 049 - training loss: 0.1061, validation loss: 0.7605
2024-06-03 03:49:34 [INFO]: Epoch 050 - training loss: 0.1049, validation loss: 0.7629
2024-06-03 03:49:35 [INFO]: Epoch 051 - training loss: 0.1099, validation loss: 0.7531
2024-06-03 03:49:36 [INFO]: Epoch 052 - training loss: 0.1236, validation loss: 0.7756
2024-06-03 03:49:37 [INFO]: Epoch 053 - training loss: 0.1144, validation loss: 0.7380
2024-06-03 03:49:38 [INFO]: Epoch 054 - training loss: 0.1162, validation loss: 0.7658
2024-06-03 03:49:39 [INFO]: Epoch 055 - training loss: 0.1074, validation loss: 0.7397
2024-06-03 03:49:40 [INFO]: Epoch 056 - training loss: 0.1038, validation loss: 0.7496
2024-06-03 03:49:41 [INFO]: Epoch 057 - training loss: 0.1025, validation loss: 0.7175
2024-06-03 03:49:42 [INFO]: Epoch 058 - training loss: 0.1073, validation loss: 0.7546
2024-06-03 03:49:43 [INFO]: Epoch 059 - training loss: 0.1022, validation loss: 0.7192
2024-06-03 03:49:44 [INFO]: Epoch 060 - training loss: 0.0984, validation loss: 0.7497
2024-06-03 03:49:45 [INFO]: Epoch 061 - training loss: 0.0944, validation loss: 0.7427
2024-06-03 03:49:46 [INFO]: Epoch 062 - training loss: 0.1002, validation loss: 0.7232
2024-06-03 03:49:47 [INFO]: Epoch 063 - training loss: 0.1002, validation loss: 0.7353
2024-06-03 03:49:48 [INFO]: Epoch 064 - training loss: 0.1010, validation loss: 0.7568
2024-06-03 03:49:49 [INFO]: Epoch 065 - training loss: 0.0930, validation loss: 0.7313
2024-06-03 03:49:50 [INFO]: Epoch 066 - training loss: 0.0970, validation loss: 0.7190
2024-06-03 03:49:50 [INFO]: Epoch 067 - training loss: 0.1026, validation loss: 0.7090
2024-06-03 03:49:51 [INFO]: Epoch 068 - training loss: 0.1064, validation loss: 0.7508
2024-06-03 03:49:52 [INFO]: Epoch 069 - training loss: 0.1001, validation loss: 0.7551
2024-06-03 03:49:54 [INFO]: Epoch 070 - training loss: 0.1013, validation loss: 0.7133
2024-06-03 03:49:55 [INFO]: Epoch 071 - training loss: 0.1041, validation loss: 0.7297
2024-06-03 03:49:56 [INFO]: Epoch 072 - training loss: 0.0993, validation loss: 0.7144
2024-06-03 03:49:57 [INFO]: Epoch 073 - training loss: 0.1045, validation loss: 0.7231
2024-06-03 03:49:58 [INFO]: Epoch 074 - training loss: 0.0974, validation loss: 0.7206
2024-06-03 03:49:59 [INFO]: Epoch 075 - training loss: 0.0994, validation loss: 0.7228
2024-06-03 03:50:00 [INFO]: Epoch 076 - training loss: 0.1026, validation loss: 0.7274
2024-06-03 03:50:01 [INFO]: Epoch 077 - training loss: 0.1023, validation loss: 0.7331
2024-06-03 03:50:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:50:01 [INFO]: Finished training. The best model is from epoch#67.
2024-06-03 03:50:01 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_0/20240603_T034839/TimesNet.pypots
2024-06-03 03:50:02 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_0/imputation.pkl
2024-06-03 03:50:02 [INFO]: Round0 - TimesNet on ETT_h1: MAE=0.7112, MSE=0.9707, MRE=0.8011
2024-06-03 03:50:02 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-06-03 03:50:02 [INFO]: Using the given device: cuda:0
2024-06-03 03:50:02 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T035002
2024-06-03 03:50:02 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T035002/tensorboard
2024-06-03 03:50:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 03:50:03 [INFO]: Epoch 001 - training loss: 0.7401, validation loss: 1.1119
2024-06-03 03:50:04 [INFO]: Epoch 002 - training loss: 0.3685, validation loss: 0.8766
2024-06-03 03:50:05 [INFO]: Epoch 003 - training loss: 0.2548, validation loss: 0.8801
2024-06-03 03:50:06 [INFO]: Epoch 004 - training loss: 0.2137, validation loss: 0.9132
2024-06-03 03:50:07 [INFO]: Epoch 005 - training loss: 0.1939, validation loss: 0.8484
2024-06-03 03:50:08 [INFO]: Epoch 006 - training loss: 0.1652, validation loss: 0.7232
2024-06-03 03:50:09 [INFO]: Epoch 007 - training loss: 0.1614, validation loss: 0.7832
2024-06-03 03:50:10 [INFO]: Epoch 008 - training loss: 0.1519, validation loss: 0.7853
2024-06-03 03:50:11 [INFO]: Epoch 009 - training loss: 0.1410, validation loss: 0.8286
2024-06-03 03:50:12 [INFO]: Epoch 010 - training loss: 0.1412, validation loss: 0.7287
2024-06-03 03:50:13 [INFO]: Epoch 011 - training loss: 0.1408, validation loss: 0.7830
2024-06-03 03:50:14 [INFO]: Epoch 012 - training loss: 0.1430, validation loss: 0.7607
2024-06-03 03:50:15 [INFO]: Epoch 013 - training loss: 0.1249, validation loss: 0.7946
2024-06-03 03:50:16 [INFO]: Epoch 014 - training loss: 0.1331, validation loss: 0.7613
2024-06-03 03:50:17 [INFO]: Epoch 015 - training loss: 0.1231, validation loss: 0.7550
2024-06-03 03:50:18 [INFO]: Epoch 016 - training loss: 0.1233, validation loss: 0.7725
2024-06-03 03:50:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:50:18 [INFO]: Finished training. The best model is from epoch#6.
2024-06-03 03:50:18 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_1/20240603_T035002/TimesNet.pypots
2024-06-03 03:50:19 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_1/imputation.pkl
2024-06-03 03:50:19 [INFO]: Round1 - TimesNet on ETT_h1: MAE=0.7433, MSE=1.0660, MRE=0.8372
2024-06-03 03:50:19 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-06-03 03:50:19 [INFO]: Using the given device: cuda:0
2024-06-03 03:50:19 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T035019
2024-06-03 03:50:19 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T035019/tensorboard
2024-06-03 03:50:19 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 03:50:20 [INFO]: Epoch 001 - training loss: 0.7504, validation loss: 0.9480
2024-06-03 03:50:21 [INFO]: Epoch 002 - training loss: 0.3263, validation loss: 0.8982
2024-06-03 03:50:22 [INFO]: Epoch 003 - training loss: 0.2513, validation loss: 0.9411
2024-06-03 03:50:23 [INFO]: Epoch 004 - training loss: 0.2138, validation loss: 0.7876
2024-06-03 03:50:24 [INFO]: Epoch 005 - training loss: 0.1780, validation loss: 0.7849
2024-06-03 03:50:25 [INFO]: Epoch 006 - training loss: 0.1811, validation loss: 0.8099
2024-06-03 03:50:26 [INFO]: Epoch 007 - training loss: 0.1661, validation loss: 0.7769
2024-06-03 03:50:27 [INFO]: Epoch 008 - training loss: 0.1505, validation loss: 0.7824
2024-06-03 03:50:28 [INFO]: Epoch 009 - training loss: 0.1372, validation loss: 0.7393
2024-06-03 03:50:29 [INFO]: Epoch 010 - training loss: 0.1450, validation loss: 0.7462
2024-06-03 03:50:29 [INFO]: Epoch 011 - training loss: 0.1486, validation loss: 0.7251
2024-06-03 03:50:30 [INFO]: Epoch 012 - training loss: 0.1317, validation loss: 0.7810
2024-06-03 03:50:31 [INFO]: Epoch 013 - training loss: 0.1405, validation loss: 0.7576
2024-06-03 03:50:32 [INFO]: Epoch 014 - training loss: 0.1182, validation loss: 0.7423
2024-06-03 03:50:33 [INFO]: Epoch 015 - training loss: 0.1298, validation loss: 0.7533
2024-06-03 03:50:34 [INFO]: Epoch 016 - training loss: 0.1183, validation loss: 0.7644
2024-06-03 03:50:35 [INFO]: Epoch 017 - training loss: 0.1154, validation loss: 0.7443
2024-06-03 03:50:35 [INFO]: Epoch 018 - training loss: 0.1226, validation loss: 0.7820
2024-06-03 03:50:36 [INFO]: Epoch 019 - training loss: 0.1227, validation loss: 0.7884
2024-06-03 03:50:37 [INFO]: Epoch 020 - training loss: 0.1248, validation loss: 0.7617
2024-06-03 03:50:38 [INFO]: Epoch 021 - training loss: 0.1232, validation loss: 0.7733
2024-06-03 03:50:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:50:38 [INFO]: Finished training. The best model is from epoch#11.
2024-06-03 03:50:38 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_2/20240603_T035019/TimesNet.pypots
2024-06-03 03:50:39 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_2/imputation.pkl
2024-06-03 03:50:39 [INFO]: Round2 - TimesNet on ETT_h1: MAE=0.7515, MSE=1.0879, MRE=0.8464
2024-06-03 03:50:39 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-06-03 03:50:39 [INFO]: Using the given device: cuda:0
2024-06-03 03:50:39 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T035039
2024-06-03 03:50:39 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T035039/tensorboard
2024-06-03 03:50:39 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 03:50:40 [INFO]: Epoch 001 - training loss: 0.8416, validation loss: 1.2093
2024-06-03 03:50:41 [INFO]: Epoch 002 - training loss: 0.4027, validation loss: 0.8935
2024-06-03 03:50:42 [INFO]: Epoch 003 - training loss: 0.2561, validation loss: 0.9135
2024-06-03 03:50:42 [INFO]: Epoch 004 - training loss: 0.2345, validation loss: 0.9036
2024-06-03 03:50:43 [INFO]: Epoch 005 - training loss: 0.2057, validation loss: 0.8019
2024-06-03 03:50:44 [INFO]: Epoch 006 - training loss: 0.1729, validation loss: 0.7931
2024-06-03 03:50:45 [INFO]: Epoch 007 - training loss: 0.1555, validation loss: 0.7669
2024-06-03 03:50:46 [INFO]: Epoch 008 - training loss: 0.1610, validation loss: 0.8076
2024-06-03 03:50:47 [INFO]: Epoch 009 - training loss: 0.1540, validation loss: 0.7432
2024-06-03 03:50:47 [INFO]: Epoch 010 - training loss: 0.1425, validation loss: 0.8103
2024-06-03 03:50:48 [INFO]: Epoch 011 - training loss: 0.1455, validation loss: 0.7934
2024-06-03 03:50:49 [INFO]: Epoch 012 - training loss: 0.1423, validation loss: 0.7796
2024-06-03 03:50:50 [INFO]: Epoch 013 - training loss: 0.1267, validation loss: 0.7713
2024-06-03 03:50:50 [INFO]: Epoch 014 - training loss: 0.1391, validation loss: 0.7509
2024-06-03 03:50:51 [INFO]: Epoch 015 - training loss: 0.1281, validation loss: 0.7873
2024-06-03 03:50:52 [INFO]: Epoch 016 - training loss: 0.1291, validation loss: 0.7655
2024-06-03 03:50:52 [INFO]: Epoch 017 - training loss: 0.1290, validation loss: 0.8346
2024-06-03 03:50:53 [INFO]: Epoch 018 - training loss: 0.1215, validation loss: 0.7581
2024-06-03 03:50:53 [INFO]: Epoch 019 - training loss: 0.1256, validation loss: 0.7939
2024-06-03 03:50:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:50:53 [INFO]: Finished training. The best model is from epoch#9.
2024-06-03 03:50:54 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_3/20240603_T035039/TimesNet.pypots
2024-06-03 03:50:54 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_3/imputation.pkl
2024-06-03 03:50:54 [INFO]: Round3 - TimesNet on ETT_h1: MAE=0.7279, MSE=1.0554, MRE=0.8198
2024-06-03 03:50:54 [INFO]: Have set the random seed as 2028 for numpy and pytorch.
2024-06-03 03:50:54 [INFO]: Using the given device: cuda:0
2024-06-03 03:50:54 [INFO]: Model files will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T035054
2024-06-03 03:50:54 [INFO]: Tensorboard file will be saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T035054/tensorboard
2024-06-03 03:50:54 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 5,510,663
2024-06-03 03:50:55 [INFO]: Epoch 001 - training loss: 0.7096, validation loss: 0.9439
2024-06-03 03:50:56 [INFO]: Epoch 002 - training loss: 0.3707, validation loss: 0.8829
2024-06-03 03:50:57 [INFO]: Epoch 003 - training loss: 0.2592, validation loss: 0.8631
2024-06-03 03:50:58 [INFO]: Epoch 004 - training loss: 0.2026, validation loss: 0.8028
2024-06-03 03:50:59 [INFO]: Epoch 005 - training loss: 0.1939, validation loss: 0.7745
2024-06-03 03:50:59 [INFO]: Epoch 006 - training loss: 0.1719, validation loss: 0.7905
2024-06-03 03:51:00 [INFO]: Epoch 007 - training loss: 0.1594, validation loss: 0.7734
2024-06-03 03:51:01 [INFO]: Epoch 008 - training loss: 0.1511, validation loss: 0.7859
2024-06-03 03:51:02 [INFO]: Epoch 009 - training loss: 0.1427, validation loss: 0.7772
2024-06-03 03:51:03 [INFO]: Epoch 010 - training loss: 0.1357, validation loss: 0.7679
2024-06-03 03:51:04 [INFO]: Epoch 011 - training loss: 0.1459, validation loss: 0.8003
2024-06-03 03:51:04 [INFO]: Epoch 012 - training loss: 0.1365, validation loss: 0.7671
2024-06-03 03:51:05 [INFO]: Epoch 013 - training loss: 0.1310, validation loss: 0.7873
2024-06-03 03:51:06 [INFO]: Epoch 014 - training loss: 0.1265, validation loss: 0.7503
2024-06-03 03:51:07 [INFO]: Epoch 015 - training loss: 0.1206, validation loss: 0.7870
2024-06-03 03:51:08 [INFO]: Epoch 016 - training loss: 0.1193, validation loss: 0.7990
2024-06-03 03:51:08 [INFO]: Epoch 017 - training loss: 0.1212, validation loss: 0.7455
2024-06-03 03:51:09 [INFO]: Epoch 018 - training loss: 0.1181, validation loss: 0.7888
2024-06-03 03:51:10 [INFO]: Epoch 019 - training loss: 0.1181, validation loss: 0.7689
2024-06-03 03:51:11 [INFO]: Epoch 020 - training loss: 0.1207, validation loss: 0.8000
2024-06-03 03:51:12 [INFO]: Epoch 021 - training loss: 0.1209, validation loss: 0.7549
2024-06-03 03:51:13 [INFO]: Epoch 022 - training loss: 0.1156, validation loss: 0.7961
2024-06-03 03:51:13 [INFO]: Epoch 023 - training loss: 0.1192, validation loss: 0.7439
2024-06-03 03:51:14 [INFO]: Epoch 024 - training loss: 0.1138, validation loss: 0.7888
2024-06-03 03:51:15 [INFO]: Epoch 025 - training loss: 0.1154, validation loss: 0.7868
2024-06-03 03:51:16 [INFO]: Epoch 026 - training loss: 0.1090, validation loss: 0.7874
2024-06-03 03:51:17 [INFO]: Epoch 027 - training loss: 0.1122, validation loss: 0.7700
2024-06-03 03:51:17 [INFO]: Epoch 028 - training loss: 0.1133, validation loss: 0.7537
2024-06-03 03:51:18 [INFO]: Epoch 029 - training loss: 0.1196, validation loss: 0.7515
2024-06-03 03:51:19 [INFO]: Epoch 030 - training loss: 0.1082, validation loss: 0.8173
2024-06-03 03:51:20 [INFO]: Epoch 031 - training loss: 0.1104, validation loss: 0.7710
2024-06-03 03:51:21 [INFO]: Epoch 032 - training loss: 0.1108, validation loss: 0.7877
2024-06-03 03:51:21 [INFO]: Epoch 033 - training loss: 0.1135, validation loss: 0.7706
2024-06-03 03:51:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-06-03 03:51:21 [INFO]: Finished training. The best model is from epoch#23.
2024-06-03 03:51:21 [INFO]: Saved the model to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_4/20240603_T035054/TimesNet.pypots
2024-06-03 03:51:22 [INFO]: Successfully saved to results_subseq_rate05/ETT_h1/TimesNet_ETT_h1/round_4/imputation.pkl
2024-06-03 03:51:22 [INFO]: Round4 - TimesNet on ETT_h1: MAE=0.7277, MSE=1.0330, MRE=0.8196
2024-06-03 03:51:22 [INFO]: Done! Final results:
Averaged TimesNet (5,510,663 params) on ETT_h1: MAE=0.7323 ± 0.013952811879361792, MSE=1.0426 ± 0.04007616708349217, MRE=0.8248 ± 0.015715862295296076, average inference time=0.17
